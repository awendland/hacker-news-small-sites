<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 14 Nov 2020 00:50:54 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 14 Nov 2020 00:50:54 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[You don't need a blockchain solution for your next project]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25067702">thread link</a>) | @shrmv
<br/>
November 12, 2020 | https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project | <a href="https://web.archive.org/web/*/https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Blockchain is one of the hottest technology fields of the last decade, together with machine learning and big data. According to the <a rel="nofollow" href="https://www2.deloitte.com/content/dam/insights/us/articles/6608_2020-global-blockchain-survey/DI_CIR%202020%20global%20blockchain%20survey.pdf">Deloitte 2020 Global Blockchain Survey</a>, businesses worldwide find blockchain an integral part of organizational innovation. </p>
<p>Properly implemented, a blockchain solution can make parts of your business transparent or enable different actors to cooperate quickly and trustlessly. </p>
<p>But today, we won√¢‚Ç¨‚Ñ¢t examine blockchain√¢‚Ç¨‚Ñ¢s strengths. Instead, we will look at why it√¢‚Ç¨‚Ñ¢s not the perfect choice for all your software projects.  </p>
<h2>Blockchain is more expensive</h2>
<p>From our experience, infrastructure and maintenance costs for a blockchain solution are typically 10-15 times higher compared to an ordinary server with a database running on AWS or a custom AWS/GCP/Azure solution.</p>
<p>Even when using economically efficient Azure solutions, it can cost up to ten times more when compared to a centralized DB with similar functionality running on AWS.</p>
<p>Therefore, it√¢‚Ç¨‚Ñ¢s necessary to seriously weigh the costs of running your solution vs. the need for transparency and distribution that blockchain offers. </p>
<h2>Blockchain scales worse</h2>
<p>Performance and scalability are the two major bottlenecks for any blockchain project. </p>
<p>From our experience working for large enterprise companies such as Bayer AG, Delta, PwC, and others, blockchain solutions that work fine for hundreds and thousands of users degrade in performance quite quickly when they need to serve more than ten thousand users.</p>
<p>Scaling blockchain, on the other hand, usually requires a complete rework of the core. Sometimes, there might even be no viable solution. So, despite some ambitious claims by blockchain companies, scaling is still an immature topic in the blockchain world.</p>
<h2>Blockchain is about transparency, not privacy</h2>
<p>Privacy is an issue. It is challenging to maintain privacy on the blockchain. In contrast to regular solutions, existing blockchain solutions are often all about transparency rather than privacy.</p>
<p>Solutions that provide the required level of privacy typically have to compromise on performance through zero-knowledge proofs or other kinds of encryption, which is costly.</p>
<p>Another problem with privacy is that most of the time, blockchain is permissionless or has very primitive permissions levels. Therefore, solutions for permissions are built on top of it as an additional middle layer, which, of course, adds performance overhead, degrades scalability, adds implementation and execution costs, etc.
Conclusion</p>
<p>There are three significant challenges that blockchain projects face: performance, scalability, and privacy. While there are multiple benefits for using blockchain, such as transparency and the ability to operate trustlessly, they need to be weighed against the downsides. </p>
<p>We want to share our knowledge with you about potential problems not to talk you away from blockchain, but to make sure the choice is clear and the right one for your project. If you still aren√¢‚Ç¨‚Ñ¢t sure and would like to have a 30-minute consultation with an expert in the field, you√¢‚Ç¨‚Ñ¢re welcome to <a href="https://exyte.com/contacts">contact us</a>. </p>
                </div></div>]]>
            </description>
            <link>https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067702</guid>
            <pubDate>Thu, 12 Nov 2020 08:25:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL explained ‚Äì crucial Q&A to get to know near-native Linux experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067677">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;Windows Subsystem for Linux (WSL) explained ‚Äì Q&amp;A
                </p>
                <p>No matter if you program in <a href="https://solidstudio.io/technologies/java.html">Java</a> or <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> or with other technologies, operating on Linux has a number of advantages. One of them is access to Linux Bash with its useful commands.</p>
                <p>However, some developers have to or prefer working on Windows. As stackoverflow.com 2020 <a href="https://insights.stackoverflow.com/survey/2020#development-environments-and-tools" rel="nofollow">survey</a> showed, almost half of developers (45,8%) work in the Windows environment. There are tools that bring them closer to the Linux world like <a href="https://www.cygwin.com/" ref="nofollow">Cygwin</a>.</p>
                
                <h2>The WSL provides a near-native Linux experience</h2>
                <p>Some time ago Microsoft introduced WSL, a new tool that brings Windows users even closer to the Linux experience. Here you can find gathered some frequently asked questions and our expert‚Äôs experience to help you get a better understanding of the WSL.</p>
                
                <h3>What is WSL?</h3>
                <p>WSL or Windows Subsystem for Linux is a part of the Windows operating system that allows running native Linux binaries. A number of distributions exist that can be installed and used. </p>
                
                <h3>How can I install WSL?</h3>
                <p>First thing to do before installing any Linux distribution is to install the WSL itself.</p>
                <p>Go to <i>Control Panel</i> ‚Üí <i>Programs</i> ‚Üí <i>Programs and Features</i> ‚Üí <i>Turn Windows features on and off</i>.</p>
                <p>Select <i>Windows Subsystem for Windows</i>, confirm, and restart the system.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/wsl-install.png" alt="Turn Windows features on and off dialog with Windows Subsystem for Linux selected"></p><p>Now you are ready to select and install a Linux distribution of your choice.</p>
                                
                <h3>What Linux distributions are available on WSL?</h3>
                <p>To find a list of available distributions open Windows Store and search for "Linux".<br>
                The most popular are:
                </p><ul>
                <li>Ubuntu 18.04 and 20.04</li>
                <li>SUSE Linux Enterprise Server</li>
                <li>Debian</li>
                <li>Fedora Remix for WSL</li>
                <li>Kali Linux</li>
                </ul>                
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-store-search.png" alt="Windows Store search result for term Linux"></p><h3>Is it possible to run graphical Linux applications from WSL?</h3>
                <p>Yes, it is possible. You need to install an X Window System server application on your Windows, for example <a href="https://sourceforge.net/projects/xming/" rel="nofollow">Xming X Server for Windows</a>.</p>
                <p>Then check if your WSL system has a <span>DISPLAY</span> environment variable set up. If not set it to <span>:0</span>.</p>
                <pre>export DISPLAY=:0</pre>
                <p>After this configuration you are free to run native Linux applications with user interface.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/xclock.png" alt="WSL running xclock via Xming"></p><h3>Where is wsl.conf located?</h3>
                <p>Each WSL instance can be further configured by creating and editing a config file <span>/etc/wsl.conf</span>.</p>
                
                <h3>How to access Windows files from WSL?</h3>
                <p>All fixed drives with the NTFS or ReFS file system are automatically mounted in <span>/mnt</span> directory. For example a C: drive can be accessed in <span>/mnt/c/</span>. The directory where drives are mounted can be specified in <span>/etc/wsl.conf</span> as follows:</p>
                <pre>[automount]
root=/</pre>
                <p>This setting will cause drives to be mounted under the root folder, so the C: drive would be accessible through <span>/c</span> folder.</p>

                <h3>How to access pendrive from WSL?</h3>
                <p>Unlike fixed drives, removable drives are not mounted automatically. To access files stored on a USB stick you need to mount it yourself. For this purpose, use these commands (assume the drive letter in Windows is F):</p>
                <pre>sudo mkdir /mnt/f
sudo mount -t drvfs H: /mnt/f</pre>

                <h3>How to connect to a DVD drive from WSL?</h3>
                <p>Optical drives are not as popular nowadays as they used to be. Nonetheless, they can be accessed the same way as pendrives (assume G is the drive letter):</p>
                <pre>sudo mkdir /mnt/g
sudo mount -t drvfs G: /mnt/g</pre>

                <h3>Where are WSL files stored?</h3>
                <p>WSL files are exposed through a network share <span>\\wsl$\[distro name]</span>, for example my home directory is at <span "="">\\wsl$\Ubuntu-20.04\home\pawelb</span>.</p>
                <p>Physically the WSL files are located at <span>%USERPROFILE%\AppData\Local\Packages\[distro name]</span>. My home folder is at this rather long path <span>C:\Users\pawelb\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\LocalState\rootfs\home\pawelb</span>.</p>
                <p>However, it is worth noting that manipulating WSL files from within Windows should be avoided as it can destroy Linux-specific file metadata. If you need to manipulate files on both WSL and Windows, store them on a Windows drive and access them from within WSL via <span>/mnt</span>.</p>
                
                <h3>Is it possible to run Windows programs from within WSL?</h3>
                <p>Yes, the WSL was built with interoperability in mind. It can run native Windows programs. However, if this feature is not needed, the user can disable it by adding <span>enabled=false</span> into <span>[interop]</span> section in <span>wsl.conf</span>.</p>
                <pre>[interop]
enabled=false</pre>

                
                <h3>What terminal application to use?</h3>
                <p>Any terminal can do the job, even the good old <span>cmd.exe</span>. Just run the WSL command in. There is however one great application that makes running the WSL console easier. It‚Äôs <a href="https://docs.microsoft.com/en-us/windows/terminal/get-started" rel="nofollow">Windows Terminal</a> and it can be installed from Windows Store. It automatically detects any WSL distributions installed and adds an option to run its console. It also supports regular Windows Command Line, PowerShell, and Azure console out of the box. Also, it supports tabs and split view inside a tab.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-terminal.png" alt="Windows Terminal application"></p><h3>Caveats of interoperability with Windows</h3>
                <p>By default, WSL can run Windows binaries and also appends its <span>%PATH%</span> variable into the <span>$PATH</span> variable of Linux running under WSL. In most cases, this is useful or at least does no harm. However, sometimes unexpected behavior occurs.</p>
                <p>This happened when I tried to run <span>npm</span>.</p>
                <pre>$ npm -v
module.js:471
    throw err;
    ^

Error: Cannot find module '\\wsl$\Ubuntu-20.04\c\Programs\nvm\v6.10.2\node_modules\npm\bin\npm-cli.js'
    at Function.Module._resolveFilename (module.js:469:15)
    at Function.Module._load (module.js:417:25)
    at Module.runMain (module.js:604:10)
    at run (bootstrap_node.js:393:7)
    at startup (bootstrap_node.js:150:9)
    at bootstrap_node.js:508:3</pre>
                
                <p>This error message is not helpful at all. What happened?</p>
                <p>After some investigation, I found out that I had also installed npm on Windows and WSL was using this executable to run. This unfortunately failed under WSL environment.</p>
                <p>A fix was rather simple. I disabled appending Windows <span>%PATH%</span> to WSL <span>$PATH</span>.</p>
                <p>This can be done in two ways.</p>
                <p>The first is to use the Registry Editor (regedit) to add a DWORD <span>AppendNtPath</span> with value <span>0</span> under <span>HKEY_CURRENT_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Lxss</span>. This affects all WSL distributions.</p>
                <p>The second way is to set a property in <span>/etc/wsl.conf</span>. This affects only a single distribution.</p>
                <pre>[interop]
appendWindowsPath=false</pre>

                <h2>The WSL is a great subsystem for Windows </h2>
                <p>With the introduction of Windows 10, a lot has changed. It seems that the system and its features are more and more thought-out and intuitive. A programmer needs a proper working environment. With WSL, Windows is keeping up with developments in this area, and looks like it is a step in the right direction. It‚Äôs worth having an eye on the development of this solution, hoping that in the future the developers will have a variety of systems that can really compete with each other. Looking for a good and stable, seamless tool, it is worth trying with the WSL.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067677</guid>
            <pubDate>Thu, 12 Nov 2020 08:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Custom GitHub Actions with Docker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066079">thread link</a>) | @sethetter
<br/>
November 11, 2020 | https://sethetter.com/posts/github-actions-with-docker/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/github-actions-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I finally decided to dip my toes into GitHub actions recently, for a relatively simple task: build and deploy my personal site. The site is built with <a href="https://getzola.org/">zola</a> and deployed to <a href="https://netlify.com/">netlify</a>.</p>
<p>My needs are pretty straightforward.</p>
<ul>
<li>The zola binary</li>
<li>Node, and <a href="https://www.npmjs.com/package/netlify-cli">netlify-cli</a> installed</li>
<li>Secure way to provide netlify config</li>
</ul>
<p>Then I simply make sure my site source is checked out and run the <code>build</code> and <code>deploy</code> commands.</p>
<h2 id="some-terminology">Some terminology</h2>
<p>An <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/about-actions"><strong>action</strong></a> is a single step that may be performed in a larger <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions"><strong>workflow</strong></a>, which strings together multiple actions and is kicked off in response to various events (like a <code>git push</code>, or a PR). You can have a workflow that calls a single action, but an action can't be used without being called in a workflow.</p>
<h2 id="first-impression-with-actions">First impression with Actions</h2>
<p>I noticed the marketplace approach first of all, and the emphasis on actions that did one small thing which you compose together. This can definitely be a nice approach to things, but my preferred way of working on CI tasks like this is to have access to a Docker container where I have a bit more control of my environment, and can codify it into a familiar Dockerfile.</p>
<p>My thinking is, if I can get this sort of approach to work, I'll have less required domain knowledge of GitHub actions, and can instead just lean on my Docker knowledge to set up whatever operations I may need.</p>
<p>Needless to say, I simply sidestepped the marketplace and found the <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/creating-a-docker-container-action">documentation for utilizing Docker</a>, which thankfully is a valid option! üéâ</p>
<h2 id="my-setup">My setup</h2>
<p>I stumbled through this quite a bit, but ultimately am happy with the approach. I'm able to have a <code>Dockerfile</code> and custom <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>entrypoint.sh</code></a> file that can receive inputs via env vars from the action configuration. I'm also able to pipe secrets, stored in my GitHub repo, into the action from the workflow file.</p>
<h3 id="the-action-file"><a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/action.yml">The action file</a></h3>
<pre><code><span># .github/actions/build-and-deploy/action.yml
</span><span>name</span><span>: </span><span>'</span><span>Build and deploy</span><span>'
</span><span>description</span><span>: </span><span>'</span><span>Build site with Zola and deploy to Netlify</span><span>'
</span><span>inputs</span><span>:
  </span><span>auth_token</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify auth token</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>site_id</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify site ID to deploy to</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>deploy_dir</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Directory to deploy to netlify</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>zola_version</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Version of zola to pull</span><span>'
    </span><span>required</span><span>: </span><span>true
    </span><span>default</span><span>: </span><span>'</span><span>0.12.2</span><span>'
</span><span>runs</span><span>:
  </span><span>using</span><span>: </span><span>'</span><span>docker</span><span>'
  </span><span>image</span><span>: </span><span>'</span><span>Dockerfile</span><span>'
  </span><span>env</span><span>:
    </span><span>ZOLA_VERSION</span><span>: </span><span>${{ inputs.zola_version }}
    NETLIFY_AUTH_TOKEN</span><span>: </span><span>${{ inputs.auth_token }}
    NETLIFY_SITE_ID</span><span>: </span><span>${{ inputs.site_id }}
    NETLIFY_DEPLOY_DIR</span><span>: </span><span>${{ inputs.deploy_dir }}
</span></code></pre>
<p>This file defines our action, which will be called from a workflow which we will configure later. The main thing to notice here is how we are accepting inputs, and passing those on to our Docker container through environment variables.</p>
<p><strong>This was one of the things I stumbled over</strong>. Currently there is no support for passing <a href="https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables---build-arg">build args</a> to our Dockerfile, and the environment variables we provide are not available during the build stage, only once the <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>ENTRYPOINT</code></a> is called.</p>
<p>I was stuck on this for a decent chunk of time before realizing that <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/metadata-syntax-for-github-actions#runsargs"><code>runs.args</code> with <code>docker</code> are <em>not</em> build args</a>, they are arguments sent to the <code>entrypoint</code>. Don't make the same mistakes I did!</p>
<p>The implication here is that any steps in your action that require one of these inputs must happen in the <code>ENTRYPOINT</code> provided via <code>env</code>. I'll mention this again shortly.</p>
<h3 id="docker-setup">Docker setup</h3>
<p>The <a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/actions/build-and-deploy/Dockerfile">Dockerfile</a> is pretty minimal, simply setting up the base environment I want, which is <code>node:lts</code> in this case, and then copy in my custom <code>[entrypoint.sh](http://entrypoint.sh)</code> script.</p>
<pre><code><span># .github/actions/build-and-deploy/Dockerfile
</span><span>FROM node:lts
COPY entrypoint.sh /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
</span></code></pre>
<p><strong>Tip!</strong> <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/dockerfile-support-for-github-actions#workdir">Don't set a <code>WORKDIR</code></a>. The action sets the workdir to the <code>$GITHUB_WORKSPACE</code> variable which is where your project source will be located.</p>
<p>All the action happens in the <a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/entrypoint.sh"><code>entrypoint.sh</code></a> file.</p>
<pre><code><span># .github/actions/build-and-deploy/entrypoint.sh

#!/usr/bin/env bash
</span><span>ZOLA_URL=https://github.com/getzola/zola/releases/download/v${ZOLA_VERSION}/zola-v${ZOLA_VERSION}-x86_64-unknown-linux-gnu.tar.gz
curl -L $ZOLA_URL | tar xz -C /usr/local/bin

</span><span># Install netlify
</span><span>npm i -g netlify-cli

</span><span># Kick off build and deploy
</span><span>zola build
netlify deploy \
  --prod \
  --dir=$NETLIFY_DEPLOY_DIR \
 --auth=$NETLIFY_AUTH_TOKEN \
 --site=$NETLIFY_SITE_ID
</span></code></pre>
<p>You can see here we're referencing the <code>env</code> vars we defined in our action file. Originally I had the zola and netlify install steps happening in the <code>Dockerfile</code>, but due to the inability to pass build args to the image, I wasn't able to get the <code>$ZOLA_VERSION</code> passed in. Once I had that realization, it seemed just as viable to put everything in <code>entrypoint.sh</code>.</p>
<h3 id="the-workflow-file"><a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/workflows/build-and-deploy.yml">The workflow file</a></h3>
<pre><code><span># .github/workflows/build-and-deploy.yml
</span><span>name</span><span>: </span><span>build-and-deploy
</span><span>on</span><span>:
  </span><span>push</span><span>:
    </span><span>branches</span><span>: [</span><span>master</span><span>]
</span><span>jobs</span><span>:
  </span><span>build-and-deploy</span><span>:
    </span><span>runs-on</span><span>: </span><span>ubuntu-latest
    steps</span><span>:
      - </span><span>uses</span><span>: </span><span>actions/checkout@v2
      </span><span>- </span><span>uses</span><span>: </span><span>./.github/actions/build-and-deploy
        with</span><span>:
          </span><span>zola_version</span><span>: </span><span>'</span><span>0.12.2</span><span>'
          </span><span>auth_token</span><span>: </span><span>${{ secrets.NETLIFY_AUTH_TOKEN }}
          site_id</span><span>: </span><span>${{ secrets.NETLIFY_SITE_ID }}
          deploy_dir</span><span>: </span><span>'</span><span>public</span><span>'
</span></code></pre>
<p>This is our final configuration file, turning our new custom action into a workflow. We start by setting our workflow triggers in the <code>on</code> block. In this case we just want to run this workflow on pushes to <code>master</code>.</p>
<p>Next is our <code>jobs</code> block. We can define multiple jobs which would all run in parallel. If we need anything serial, it should happen within a single job. In our case, we have just one job with two actions.</p>
<p>The job itself starts with the checkout action, which handles checking out the repo's source into the job workspace, then we call our custom action by providing a path to the action folder.</p>
<p>In our <code>with</code> block we provide values for the inputs we defined on our action. You'll notice that two of the values are provided via <code>secrets</code>, which is a <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets">feature of GitHub</a> I wasn't aware of before this. It's very easy to work with!</p>
<h2 id="room-for-improvement">Room for improvement</h2>
<p>I think the main drawback here is potentially slow job run times, since we're installing our dependencies each time. Depending on what's actually slow, there are a number of ways it could be addressed.</p>
<p>In general, finding a base Docker image that has as much of what you need as possible (without too much bloat) is going to help. Maintaining your own images in a registry somewhere comes with it's own overhead, but that's also an option.</p>
<p>I'm sure using the marketplace approach could also be a way to address the performance issues, assuming you find actions that have your dependencies installed and configured appropriately, but the goal of this post was to explore a minimal action configuration while leveraging the power of Docker üòÑ.</p>
<p><strong>That's it!</strong> üëã</p>

    </section>
</article></div>]]>
            </description>
            <link>https://sethetter.com/posts/github-actions-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066079</guid>
            <pubDate>Thu, 12 Nov 2020 03:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pyxell ‚Äì a programming language that combines Python's elegance with C++'s speed]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066058">thread link</a>) | @masijo
<br/>
November 11, 2020 | https://www.pyxell.org/docs/manual.html | <a href="https://web.archive.org/web/*/https://www.pyxell.org/docs/manual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Pyxell [<em>pixel</em>] is a multi-paradigm, statically typed programming language, compiled to machine code via C++.</p> <p>This manual should let you quickly learn all the details to start programming in Pyxell.
It is assumed that you already know some programming language (preferably Python), since basic programming concepts are not explained here.</p> <p>You are encouraged to run the code snippets and experiment with them for yourself.
To run Pyxell code, go to the <a href="https://www.pyxell.org/docs/playground.html">Playground</a>,
clone the repository and follow the instructions on <a href="https://github.com/adamsol/Pyxell#requirements" target="_blank" rel="noopener noreferrer">Github<span> <span>(opens new window)</span></span></a>,
or download Windows binaries from the <a href="https://github.com/adamsol/Pyxell/releases" target="_blank" rel="noopener noreferrer">Releases<span> <span>(opens new window)</span></span></a>.</p> <h2 id="hello-world"><a href="#hello-world">#</a> Hello, world!</h2> <p>If you can run the following code and see the message on the screen, you are ready to start.</p> <h2 id="variables-and-types"><a href="#variables-and-types">#</a> Variables and types</h2> <h3 id="variable-declaration"><a href="#variable-declaration">#</a> Variable declaration</h3> <p>Pyxell is statically typed. Variables have types assigned during compilation.
In most cases, type of an expression is automatically inferred and the value can be directly assigned to a variable.</p> <p>In other cases, when the type cannot be inferred or you want to declare a variable without initializing it, you can set the type explicitly.
When not directly initialized, variable is automatically initialized with the default value for a given type.
You can find the list of all available types and their default values in the <a href="https://www.pyxell.org/docs/specification.html#types">Specification</a>.</p> <p>Variable name must start with a letter, but may also contain digits, underscores, and apostrophes.
Once a variable has been created, its type cannot be changed.</p> <h3 id="type-coercion"><a href="#type-coercion">#</a> Type coercion</h3> <p>Values of some types can be automatically converted to more general types: <code>Int -&gt; Rat -&gt; Float</code> or <code>Char -&gt; String</code>.</p> <p>The coercion doesn't work in the other direction.</p> <h2 id="arithmetic-and-logic"><a href="#arithmetic-and-logic">#</a> Arithmetic and logic</h2> <h3 id="numbers"><a href="#numbers">#</a> Numbers</h3> <p>Standard integers in Pyxell have 64 bits of precision and range from <code>-2^63</code> to <code>2^63-1</code>.
Binary, octal, and hexadecimal literals are supported.</p> <p>Rational numbers have unlimited precision.
They can be written either as integers with <code>r</code> suffix, or non-integers in decimal form.
They are also created as the result of division or exponentiation
(to obtain an integer from a division or exponentiation, use lossy <code>//</code> and <code>^^</code> operators).</p> <p>You can retrieve the numerator and denominator from a rational number.</p> <p>Floating-point numbers have 64 bits of precision and follow the IEEE 754 standard.
They can be written with <code>f</code> suffix or in scientific notation.</p> <p>Underscores can be additionally used in all numeric literals, to enhance readability of long numbers.</p> <h3 id="boolean-values"><a href="#boolean-values">#</a> Boolean values</h3> <p>There are two boolean values: <code>true</code> and <code>false</code>.
Logical negation and short-circuiting conjunction and disjunction operators are available.</p> <p>Boolean values are most often obtained in the result of comparisons.
When comparison operators are chained, they behave as if connected with <code>and</code> operator.</p> <h2 id="characters-and-strings"><a href="#characters-and-strings">#</a> Characters and strings</h2> <h3 id="characters"><a href="#characters">#</a> Characters</h3> <p>Characters are written in single quotes.</p> <p>You can get character's ASCII code, as well as obtain character corresponding to a given integer.</p> <p>You can also perform some arithmetic operations on characters.</p> <h3 id="strings"><a href="#strings">#</a> Strings</h3> <p>Strings are immutable sequences of characters. They are written in double quotes.</p> <p>You can access string's length, as well as its individual characters. Negative indexing and slicing is also supported, like in Python.</p> <p>Strings can be concatenated with <code>+</code> operator and repeated with <code>*</code> operator.</p> <p>You can construct formatted strings using interpolation syntax.</p> <h2 id="control-flow"><a href="#control-flow">#</a> Control flow</h2> <p>Pyxell uses indentation-based syntax, similar to Python's. Only spaces are allowed (tab character will cause a syntax error).
Rather than <code>:</code> character, Pyxell uses <code>do</code> keyword for indicating beginning of a block, and <code>def</code> keyword for function and class definitions.
The scope of a variable declared in a block is limited to that block.</p> <h3 id="if-statement"><a href="#if-statement">#</a> <code>if</code> statement</h3> <p>The first branch whose condition evaluates to <code>true</code> is executed.</p> <h3 id="while-loop"><a href="#while-loop">#</a> <code>while</code> loop</h3> <p>The loop runs while the condition is satisfied.</p> <h3 id="until-loop"><a href="#until-loop">#</a> <code>until</code> loop</h3> <p>This loop is similar to <code>while</code> loop, but it is always executed at least once and runs until the condition is satisfied.</p> <h3 id="for-loop"><a href="#for-loop">#</a> <code>for</code> loop</h3> <p>It can be used to loop over ranges (of numbers or characters) and other iterables.
Range can be inclusive (<code>a..b</code>), exclusive (<code>a...b</code>), or infinite (<code>a...</code>).</p> <p>You can optionally provide a step value, which can be either positive or negative (it is 1 by default).</p> <p>It is possible to loop over multiple iterables at once and provide custom step values to any of them.</p> <h3 id="continue-and-break"><a href="#continue-and-break">#</a> <code>continue</code> and <code>break</code></h3> <p>Inside loops you can use statements to exit the current iteration or the whole loop.</p> <h2 id="containers"><a href="#containers">#</a> Containers</h2> <h3 id="arrays"><a href="#arrays">#</a> Arrays</h3> <p>Arrays are similar to strings, but they are mutable and can have elements of any type.</p> <p>Containers have reference semantics, so they are not implicitly copied when variables are passed.
Mutation of one instance is reflected in all other instances of the same container.</p> <p>When an empty array is used, its type must be explicitly given.</p> <p>Arrays can be concatenated, repeated, and compared using standard operators.</p> <p>You can use array comprehension, as well as range literals and spread operator with optional step.</p> <p>For type safety, containers in Pyxell are invariant, which means they cannot be implicitly converted to another type,
even if types of the elements match (see <a href="https://stackoverflow.com/q/2745265" target="_blank" rel="noopener noreferrer">here<span> <span>(opens new window)</span></span></a> for a broader explanation).
However, container literals can be automatically converted.</p> <h3 id="sets"><a href="#sets">#</a> Sets</h3> <p>Sets contain no duplicates and do not preserve order of elements.</p> <p>Empty set can be created like an empty array.</p> <p>To check if an element is in the set, use <code>in</code> operator.</p> <p>There exist operators for set union, difference, and intersection.</p> <p>Like with arrays, you can use comprehensions, ranges, and spread syntax to create sets.</p> <p>Containers are not hashable, so they cannot be stored in sets.</p> <h3 id="dictionaries"><a href="#dictionaries">#</a> Dictionaries</h3> <p>Dictionaries are hash maps. Like sets, they do not preserve order of elements.
They work similarly to <code>defaultdict</code> in Python: if a key is not present, the default value for a given type is automatically created in the dictionary.</p> <p>Empty dictionary literal has an additional colon.</p> <p>Use <code>in</code> operator for checking if the dictionary contains a given key.</p> <p>Dictionaries can be merged with <code>+</code> operator. In the case of repeated keys, the second value wins.</p> <p>Dictionary comprehension works similarly to array and set comprehension.</p> <p>When iterated over, dictionaries produce pairs of key and value.</p> <p>Spread operator for dictionaries consists of an extra colon.</p> <h2 id="nullable-types"><a href="#nullable-types">#</a> Nullable types</h2> <p>To accept <code>null</code> value, variable's type must be explicitly marked as nullable.</p> <p>You can either directly check if a value is <code>null</code>, or use special coalescing and conditional operators.</p> <p>There is also an operator to directly retrieve the value, for cases when you are sure it is not null.</p> <h2 id="tuples"><a href="#tuples">#</a> Tuples</h2> <p>Two or more values separated with a comma (outside of a container, function call, and print statement) form a tuple.</p> <p>Values can be retrieved using alphabetical properties or tuple destructuring (unneeded part can be discarded with an underscore).</p> <p>Tuples are mutable, but they have value semantics, so they are hashable and can be passed around as if they were immutable.</p> <h2 id="functions"><a href="#functions">#</a> Functions</h2> <h3 id="function-definition-and-call"><a href="#function-definition-and-call">#</a> Function definition and call</h3> <p>Basic definition of a function consists of its name, list of arguments, return type, and body.</p> <p>When a function does not return anything, the return type may be written as <code>Void</code> or may be omitted completely.</p> <p>You can provide default values for optional arguments.
The expressions will be evaluated every time the function is called (if they are needed), so mutable container literals can be safely used.</p> <p>Arguments can be also passed in any order using their names.</p> <p>Variadic functions are supported too. This is just a syntactic sugar for passing an array.
Ranges and spread syntax can be used when such a function is called.</p> <p>Functions can be stored in variables, passed to other functions as arguments, etc.
However, when a function is converted to a variable, all information about its arguments except for their types is lost.</p> <h3 id="generic-functions"><a href="#generic-functions">#</a> Generic functions</h3> <p>Generic functions are standard functions with additional type variables, which can be used just like normal types.
They are compiled independently for each combination of types they are called with.</p> <p>Function declaration may contain default values for generic arguments, and the body may contain any code dependent on the real types.
Errors will be reported when the function cannot be compiled with given types.</p> <p>When a type name is used more than once, the compiler will try to unify types of the arguments, following the coercion rules.</p> <h3 id="lambda-functions"><a href="#lambda-functions">#</a> Lambda functions</h3> <p>Lambda is a simpler version of generic function, where all arguments, as well as the return type, are generic.</p> <p>You can use placeholder syntax to write even more concise functions. Each underscore corresponds to one argument.</p> <p>Placeholder resolving doesn't run through function calls by default (placeholders inside a function call form their own functions for corresponding arguments).
To create a partial function, add <code>@</code> character.</p> <p>Lambdas can also be multi-line, so that you can define normal functions without any type annotations.</p> <p>Note that lambda functions currently work only with arguments of known types.
You cannot pass a lambda function to another lambda function.
In the case of functional arguments, it's better to use the full generic definition instead.</p> <h3 id="generators"><a href="#generators">#</a> Generators</h3> <p>Generator is a function producing a sequence of values that can be iterated over without storing it in memory.
To create a generator, add an asterisk symbol to the function definition.</p> <p>Lambdas can be generators as well.</p> <p>Note that generators are currently supported only with Clang.</p> <h2 id="classes"><a href="#classes">#</a> Classes</h2> <h3 id="class-definition-and-object-construction"><a href="#class-definition-and-object-construction">#</a> Class definition and object construction</h3> <p>Definition of a class consists of its name and list of fields.
Each field may have an explicit default value; if not provided, it will be the default value for a given type.</p> <p>Every class has a default constructor function that accepts field values in the order of definition, or as named arguments.
Fields not directly initialized will receive their default values.</p> <p>Remember that class objects must always be explicitly constructed before use (they have no valid default ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pyxell.org/docs/manual.html">https://www.pyxell.org/docs/manual.html</a></em></p>]]>
            </description>
            <link>https://www.pyxell.org/docs/manual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066058</guid>
            <pubDate>Thu, 12 Nov 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Guide to PyTorch for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065771">thread link</a>) | @shirappu
<br/>
November 11, 2020 | https://mlwhiz.com/blog/2020/09/09/pytorch_guide/ | <a href="https://web.archive.org/web/*/https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>PyTorch</strong></em> has sort of became one of the de facto standards for creating Neural Networks now, and I love its interface. Yet, it is somehow a little difficult for beginners to get a hold of.</p><p>I remember picking PyTorch up only after some extensive experimentation a couple of years back. To tell you the truth, it took me a lot of time to pick it up but am I glad that I moved from
<a href="https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79" target="_blank" rel="nofollow noopener">Keras to PyTorch</a>
. With its high customizability and pythonic syntax,PyTorch is just a joy to work with, and I would recommend it to anyone who wants to do some heavy lifting with Deep Learning.</p><p>So, in this PyTorch guide, <em><strong>I will try to ease some of the pain with PyTorch for starters</strong></em> and go through some of the most important classes and modules that you will require while creating any Neural Network with Pytorch.</p><p>But, that is not to say that this is aimed at beginners only as <em><strong>I will also talk about the</strong></em> <em><strong>high customizability PyTorch provides and will talk about custom Layers, Datasets, Dataloaders, and Loss functions</strong></em>.</p><p>So let‚Äôs get some coffee ‚òï Ô∏èand start it up.</p><hr><h2 id="tensors">Tensors</h2><p>Tensors are the basic building blocks in PyTorch and put very simply, they are NumPy arrays but on GPU. In this part, I will list down some of the most used operations we can use while working with Tensors. This is by no means an exhaustive list of operations you can do with Tensors, but it is helpful to understand what tensors are before going towards the more exciting parts.</p><h3 id="1-create-a-tensor">1. Create a Tensor</h3><p>We can create a PyTorch tensor in multiple ways. This includes converting to tensor from a NumPy array. Below is just a small gist with some examples to start with, but you can do a whole lot of
<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="nofollow noopener">more things</a>
with tensors just like you can do with NumPy arrays.</p><div><pre><code data-lang="py"><span># Using torch.Tensor</span>
t <span>=</span> torch<span>.</span>Tensor([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
<span>print</span>(f<span>"Created Tensor Using torch.Tensor:</span><span>\n</span><span>{t}"</span>)

<span># Using torch.randn</span>
t <span>=</span> torch<span>.</span>randn(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.randn:</span><span>\n</span><span>{t}"</span>)

<span># using torch.[ones|zeros](*size)</span>
t <span>=</span> torch<span>.</span>ones(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.ones:</span><span>\n</span><span>{t}"</span>)
t <span>=</span> torch<span>.</span>zeros(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.zeros:</span><span>\n</span><span>{t}"</span>)

<span># using torch.randint - a tensor of size 4,5 with entries between 0 and 10(excluded)</span>
t <span>=</span> torch<span>.</span>randint(low <span>=</span> <span>0</span>,high <span>=</span> <span>10</span>,size <span>=</span> (<span>4</span>,<span>5</span>))
<span>print</span>(f<span>"Created Tensor Using torch.randint:</span><span>\n</span><span>{t}"</span>)

<span># Using from_numpy to convert from Numpy Array to Tensor</span>
a <span>=</span> np<span>.</span>array([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
t <span>=</span> torch<span>.</span>from_numpy(a)
<span>print</span>(f<span>"Convert to Tensor From Numpy Array:</span><span>\n</span><span>{t}"</span>)

<span># Using .numpy() to convert from Tensor to Numpy array</span>
t <span>=</span> t<span>.</span>numpy()
<span>print</span>(f<span>"Convert to Numpy Array From Tensor:</span><span>\n</span><span>{t}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/0.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><h3 id="2-tensor-operations">2. Tensor Operations</h3><p>Again, there are a lot of operations you can do on these tensors. The full list of functions can be found
<a href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations" target="_blank" rel="nofollow noopener">here</a>
.</p><div><pre><code data-lang="py">A <span>=</span> torch<span>.</span>randn(<span>3</span>,<span>4</span>)
W <span>=</span> torch<span>.</span>randn(<span>4</span>,<span>2</span>)
<span># Multiply Matrix A and W</span>
t <span>=</span> A<span>.</span>mm(W)
<span>print</span>(f<span>"Created Tensor t by Multiplying A and W:</span><span>\n</span><span>{t}"</span>)
<span># Transpose Tensor t</span>
t <span>=</span> t<span>.</span>t()
<span>print</span>(f<span>"Transpose of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># Square each element of t</span>
t <span>=</span> t<span>**</span><span>2</span>
<span>print</span>(f<span>"Square each element of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># return the size of a tensor</span>
<span>print</span>(f<span>"Size of Tensor t using .size():</span><span>\n</span><span>{t.size()}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/1.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><strong>Note:</strong> What are PyTorch Variables? In the previous versions of Pytorch, Tensor and Variables used to be different and provided different functionality, but now the Variable API is
<a href="https://pytorch.org/docs/stable/autograd.html#variable-deprecated" target="_blank" rel="nofollow noopener">deprecated</a>
, and all methods for variables work with Tensors. So, if you don‚Äôt know about them, it‚Äôs fine as they re not needed, and if you know them, you can forget about them.</p><hr><h2 id="the-nnmodule">The nn.Module</h2><p>Photo by
<a href="https://unsplash.com/@fernanddecanne?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="nofollow noopener">Fernand De Canne</a>
on
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1200x0_resize_box_2.png 1200w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1500x0_resize_box_2.png 1500w" src="https://mlwhiz.com/images/pytorch_guide/2.png" alt="<a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;>Unsplash</a>"></p><p>Here comes the fun part as we are now going to talk about some of the most used constructs in Pytorch while creating deep learning projects. nn.Module lets you create your Deep Learning models as a class. You can inherit from nn.Moduleto define any model as a class. Every model class necessarily contains an<code> __init__</code> procedure block and a block for the <code>forward</code> pass.</p><ul><li><p>In the <code>__init__</code> part, the user can define all the layers the network is going to have but doesn‚Äôt yet define how those layers would be connected to each other.</p></li><li><p>In the <code>forward</code> pass block, the user defines how data flows from one layer to another inside the network.</p></li></ul><p>So, put simply, any network we define will look like:</p><div><pre><code data-lang="py"><span>class</span> <span>myNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)
    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        x <span>=</span> self<span>.</span>lin2(x)
        <span>return</span> x
</code></pre></div><p>Here we have defined a very simple Network that takes an input of size 784 and passes it through two linear layers in a sequential manner. But the thing to note is that we can define any sort of calculation while defining the forward pass, and that makes PyTorch highly customizable for research purposes. For example, in our crazy experimentation mode, we might have used the below network where we arbitrarily attach our layers. Here we send back the output from the second linear layer back again to the first one after adding the input to it(skip connection) back again(I honestly don‚Äôt know what that will do).</p><div><pre><code data-lang="py"><span>class</span> <span>myCrazyNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>784</span>)
        self<span>.</span>lin3 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x_lin1 <span>=</span> self<span>.</span>lin1(x)
        x_lin2 <span>=</span> x <span>+</span> self<span>.</span>lin2(x_lin1)
        x_lin2 <span>=</span> self<span>.</span>lin1(x_lin2)
        x <span>=</span> self<span>.</span>lin3(x_lin2)
        <span>return</span> x
</code></pre></div><p>We can also check if the neural network forward pass works. I usually do that by first creating some random input and just passing that through the network I have created.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCrazyNeuralNet()
model(x)<span>.</span>size()
<span>--------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><hr><h2 id="a-word-about-layers">A word about Layers</h2><p>Pytorch is pretty powerful, and you can actually create any new experimental layer by yourself using <code>nn.Module</code>. For example, rather than using the predefined Linear Layer <code>nn.Linear</code> from Pytorch above, we could have created our <strong>custom linear layer</strong>.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomLinearLayer</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self,in_size,out_size):
        super()<span>.</span>__init__()
        self<span>.</span>weights <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>randn(in_size, out_size))
        self<span>.</span>bias <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>zeros(out_size))
    <span>def</span> <span>forward</span>(self, x):
        <span>return</span> x<span>.</span>mm(self<span>.</span>weights) <span>+</span> self<span>.</span>bias
</code></pre></div><p>You can see how we wrap our weights tensor in nn.Parameter. This is done to make the tensor to be considered as a model parameter. From PyTorch
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter" target="_blank" rel="nofollow noopener">docs</a>
:</p><blockquote><p>Parameters are
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="nofollow noopener">&lt;code&gt;*Tensor*&lt;/code&gt;</a>
subclasses, that have a very special property when used with <em>Module</em> - when they‚Äôre assigned as Module attributes they are automatically added to the list of its parameters, and will appear in <em><code>parameters()</code></em> iterator</p></blockquote><p>As you will later see, the <code>model.parameters()</code> iterator will be an input to the optimizer. But more on that later.</p><p>Right now, we can now use this custom layer in any PyTorch network, just like any other layer.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> myCustomLinearLayer(<span>784</span>,<span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        <span>return</span> x
x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCustomNeuralNet()
model(x)<span>.</span>size()
<span>------------------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><p>But then again, Pytorch would not be so widely used if it didn‚Äôt provide a lot of ready to made layers used very frequently in wide varieties of Neural Network architectures. Some examples are:
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" target="_blank" rel="nofollow noopener">nn.Linear</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" target="_blank" rel="nofollow noopener">nn.Conv2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" target="_blank" rel="nofollow noopener">nn.MaxPool2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" target="_blank" rel="nofollow noopener">nn.ReLU</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" target="_blank" rel="nofollow noopener">nn.BatchNorm2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" target="_blank" rel="nofollow noopener">nn.Dropout</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" target="_blank" rel="nofollow noopener">nn.Embedding</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" target="_blank" rel="nofollow noopener">nn.GRU</a>
/
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM" target="_blank" rel="nofollow noopener">nn.LSTM</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax" target="_blank" rel="nofollow noopener">nn.Softmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" target="_blank" rel="nofollow noopener">nn.LogSoftmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention" target="_blank" rel="nofollow noopener">nn.MultiheadAttention</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder" target="_blank" rel="nofollow noopener">nn.TransformerEncoder</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder" target="_blank" rel="nofollow noopener">nn.TransformerDecoder</a></p><p>I have linked all the layers to their source where you could read all about them, but to show how I usually try to understand a layer and read the docs, I would try to look at a very simple convolutional layer here.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/3.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>So, a Conv2d Layer needs as input an Image of height H and width W, with <code>Cin</code> channels. Now, for the first layer in a convnet, the number of <code>in_channels</code> would be 3(RGB), and the number of <code>out_channels</code> can be defined by the user. The <code>kernel_size</code> mostly used is 3x3, and the <code>stride</code> normally used is 1.</p><p>To check a new layer which I don‚Äôt know much about, I usually try to see the input as well as output for the layer like below where I would first initialize the layer:</p><div><pre><code data-lang="py">conv_layer <span>=</span> nn<span>.</span>Conv2d(in_channels <span>=</span> <span>3</span>, out_channels <span>=</span> <span>64</span>, kernel_size <span>=</span> (<span>3</span>,<span>3</span>), stride <span>=</span> <span>1</span>, padding<span>=</span><span>1</span>)
</code></pre></div><p>And then pass some random input through it. Here 100 is the batch size.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>3</span>,<span>24</span>,<span>24</span>))
conv_layer(x)<span>.</span>size()
<span>--------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>64</span>, <span>24</span>, <span>24</span>])
</code></pre></div><p>So, we get the output from the convolution operation as required, and I have sufficient information on how to use this layer in any Neural Network I design.</p><hr><h2 id="datasets-and-dataloaders">Datasets and DataLoaders</h2><p>How would we pass data to our Neural nets while training or while testing? We can definitely pass tensors as we have done above, but Pytorch also provides us with pre-built Datasets to make it easier for us to pass data to our neural nets. You can check out the complete list of datasets provided at
<a href="https://pytorch.org/docs/stable/torchvision/datasets.html" target="_blank" rel="nofollow noopener">torchvision.datasets</a>
and
<a href="https://pytorch.org/text/datasets.html" target="_blank" rel="nofollow noopener">torchtext.datasets</a>
. But, to give a concrete example for datasets, let‚Äôs say we had to pass images to an Image Neural net using a folder which has images in this structure:</p><pre><code>data
    train
        sailboat
        kayak
        .
        .
</code></pre><p>We can use torchvision.datasets.ImageFolder dataset to get an example image like below:</p><div><pre><code data-lang="py"><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.datasets <span>import</span> ImageFolder
traindir <span>=</span> <span>"data/train/"</span>
t <span>=</span> transforms<span>.</span>Compose([
        transforms<span>.</span>Resize(size<span>=</span><span>256</span>),
    transforms<span>.</span>CenterCrop(size<span>=</span><span>224</span>),
        transforms<span>.</span>ToTensor()])
train_dataset <span>=</span> ImageFolder(root<span>=</span>traindir,transform<span>=</span>t)
<span>print</span>(‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</a></em></p>]]>
            </description>
            <link>https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065771</guid>
            <pubDate>Thu, 12 Nov 2020 02:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Children's Guide to Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065144">thread link</a>) | @tomasreimers
<br/>
November 11, 2020 | https://www.cncf.io/phippy/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/phippy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
<div><figure><img loading="lazy" width="472" height="487" src="https://www.cncf.io/wp-content/uploads/2020/07/phippy-01-1.svg" alt=""></figure><p><strong>Phippy</strong>&nbsp;is a simple PHP app, trying to find a home in a cloud native world.</p></div>







<div><div>




<h2>Introducing Phippy and friends</h2>












</div></div>







<div>
<div>
<figure><img loading="lazy" width="849" height="651" src="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg 849w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-300x230.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-768x589.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-261x200.jpg 261w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-700x537.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-222x170.jpg 222w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-352x270.jpg 352w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-443x340.jpg 443w" sizes="(max-width: 849px) 100vw, 849px"></figure>




</div>



<div>
<h3>The Illustrated Children‚Äôs Guide to Kubernetes</h3>



<p><em>The Illustrated Children‚Äôs Guide to Kubernetes</em> is a simple, gentle answer a father gave his daughter when she inquisitively asked about Kubernetes. It‚Äôs dedicated to all the parents who try to explain software engineering to their children.</p>



<p>The star of <em>The Illustrated Children‚Äôs Guide to Kubernetes</em>, Phippy and her friends explain the core concepts of Kubernetes in simple terms.</p>




</div>
</div>







<div>
<div>
<h3>Phippy Goes to the Zoo</h3>



<p>Follow the tale of Phippy and her niece Zee as they take an educational trip to the Kubernetes Zoo.</p>








</div>



<div>
<figure><img loading="lazy" width="851" height="655" src="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg 851w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-300x231.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-768x591.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-260x200.jpg 260w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-700x539.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-221x170.jpg 221w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-351x270.jpg 351w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-442x340.jpg 442w" sizes="(max-width: 851px) 100vw, 851px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy and Zee go to the Mountains</h3>



<p>Another work featuring Phippy and friends: Join Phippy and Zee on a 4-dimensional hike!</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="768" src="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-300x225.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-768x576.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-267x200.jpg 267w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-700x525.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-227x170.jpg 227w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-360x270.jpg 360w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-453x340.jpg 453w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8.jpg 1367w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy In Space: Adventures in Cloud-Native Recovery</h3>



<p>In the not-so-distant future, space outposts (cloud-native infrastructure) are the next frontier for settlement and Captain Kube is in charge of the cutting-edge Mars outpost. As the outpost has grown in size and complexity, Captain Kube needs to find solutions for many of the settlement‚Äôs growing pains. He has recruited Phippy to work with him on the outpost‚Äôs Day 2 challenges.</p>



<p>Join them on their adventure, as they journey to Mars and brainstorm solutions.</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="792" src="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-300x232.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-768x594.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1536x1187.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-259x200.jpg 259w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-700x541.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-220x170.jpg 220w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-349x270.jpg 349w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-440x340.jpg 440w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>















<p>The characters Phippy, Captain Kube, Goldie, and Zee and the two books are owned by The Linux Foundation, on behalf of the Cloud Native Computing Foundation, and licensed under the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>), which means that you can remix, transform, and build upon the material for any purpose, even commercially. If you use the characters, please include the text ‚Äú<a href="https://phippy.io/">phippy.io</a>‚Äù to provide attribution (and online, please include a link to&nbsp;<a href="https://phippy.io/">https://phippy.io</a>).</p>



<p>The characters and the two books were created by&nbsp;<a href="https://twitter.com/technosophos">Matt Butcher</a>,&nbsp;<a href="https://twitter.com/karenhchu">Karen Chu</a>, and&nbsp;<a href="https://www.baileyjeanstudio.com/">Bailey Beougher</a>&nbsp;and donated by Microsoft to CNCF. Goldie is based on the Go Gopher, created by&nbsp;<a href="https://blog.golang.org/gopher">Renee French</a>, which is also licensed under&nbsp;<a href="https://creativecommons.org/licenses/by/3.0/" target="_blank" rel="noreferrer noopener">CC-BY</a>.</p>



<p>Images of Phippy, Captain Kube, Goldie, and Zee are available in the CNCF&nbsp;<a href="https://github.com/cncf/artwork/blob/master/examples/other.md#phippy--friends-group-logos">artwork</a>&nbsp;repo in svg and png formats and in color, black, and white.</p>
	</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/phippy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065144</guid>
            <pubDate>Thu, 12 Nov 2020 01:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Version 11 of Angular Now Available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25065091">thread link</a>) | @mgechev
<br/>
November 11, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we‚Äôve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let‚Äôs dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular‚Äôs Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We‚Äôve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we‚Äôve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we‚Äôre planning the next steps to support the Angular community. We‚Äôll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we‚Äôre introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We‚Äôve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We‚Äôve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we‚Äôre giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we‚Äôre able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we‚Äôve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We‚Äôre bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2‚Äì4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don‚Äôt recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you‚Äôll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we‚Äôve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We‚Äôve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We‚Äôre deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we‚Äôre removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We‚Äôve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We‚Äôve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065091</guid>
            <pubDate>Thu, 12 Nov 2020 01:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacBook Air in Pure CSS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064721">thread link</a>) | @ent101
<br/>
November 11, 2020 | https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/e47219f7aa-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>7</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064721</guid>
            <pubDate>Thu, 12 Nov 2020 00:24:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a macOS Apple Silicon Kernel in QEMU]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25064593">thread link</a>) | @empyrical
<br/>
November 11, 2020 | https://worthdoingbadly.com/xnuqemu3/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/xnuqemu3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I booted the arm64e kernel of macOS 11.0.1 beta 1 kernel in QEMU up to launchd. It‚Äôs completely useless, but may be interesting if you‚Äôre wondering how an Apple Silicon Mac will boot.</p>

<h2 id="howto">Howto</h2>

<p>This is similar to my previous guide on running <a href="https://worthdoingbadly.com/xnuqemu2/">iOS kernel in QEMU</a>:</p>

<ul>
  <li>install macOS 11.0.1 beta 1 (20B5012D)</li>
  <li>run <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh"><code>build_arm64e_kcache.sh</code></a> to create an Apple Silicon Boot Kext Collection</li>
  <li>build the modified QEMU:
    <div><div><pre><code>git clone https://github.com/zhuowei/qemu
cd qemu
git checkout a12z-macos
mkdir build
cd build
../configure --target-list=aarch64-softmmu
make
</code></pre></div>    </div>
  </li>
  <li>create a modified device tree by running <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">DTRewriter</a> on <a href="https://updates.cdn-apple.com/2020SummerSeed/fullrestores/001-30235/6D8C0CA3-5952-4FD8-AEB3-4B4CADB626BC/iPad8,11,iPad8,12_14.0_18A5332f_Restore.ipsw">iPad Pro firmware</a>:
    <div><div><pre><code>python3 extractfilefromim4p.py Firmware/all_flash/DeviceTree.j421ap.im4p DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree
java DTRewriter DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb
</code></pre></div>    </div>
  </li>
  <li>run QEMU:
    <div><div><pre><code>./aarch64-softmmu/qemu-system-aarch64 -M virt -cpu max \
  -kernel /path/to/bootcache-arm64e \
  -dtb /path/to/DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb  \
  -monitor stdio -m 6G -s -S -d unimp,mmu \
  -serial file:/dev/stdout -serial file:/dev/stdout -serial file:/dev/stdout \
  -append "-noprogress cs_enforcement_disable=1 amfi_get_out_of_my_way=1 nvram-log=1 debug=0x8 kextlog=0xffff io=0xfff serial=0x7 cpus=1 rd=md0 apcie=0xffffffff" \
  -initrd /path/to/ios14.0b3/ramdisk.dmg $@
</code></pre></div>    </div>
  </li>
  <li>run gdb with <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/bootit.gdbscript">this script</a>:
    <div><div><pre><code>~/Library/Android/sdk/ndk/21.0.6113669/prebuilt/darwin-x86_64/bin/gdb \
-D /any/emptydir \
-x bootit.gdbscript
</code></pre></div>    </div>
    
  </li>
</ul>

<p>And the macOS kernel will <a href="https://gist.github.com/zhuowei/5aa668e76f387374cd56848313aa2197">boot into launchd</a>.</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p><img src="https://worthdoingbadly.com/assets/blog/xnuqemu3/wwdc2018_no.jpg" alt="&quot;No.&quot; - Craig Federighi, WWDC 2018"></p>

<p>No:</p>

<ul>
  <li>Absolutely nothing is supported: literally only the kernel and the serial port works, not even the userspace since there‚Äôs no disk driver</li>
  <li>Userspace is instead borrowed from iOS 14 b3</li>
  <li>This will never boot anything close to graphical macOS UI</li>
  <li>Most importantly, even if I ever managed to fully boot the macOS kernel, emulating macOS is useless anyways.</li>
</ul>

<p>There are only three reasons I can think of for emulating macOS: security research, software development without a real Apple Silicon machine, and Hackintoshing. This approach will help with none of these:</p>

<ul>
  <li>Emulating iOS is useful for security research when jailbreak is not available. Apple Silicon Macs already support kernel debugging.</li>
  <li>Not useful for software dev: QEMU‚Äôs CPU emulation doesn‚Äôt support Apple Silicon-specific features, such as Rosetta‚Äôs memory ordering or the APRR JIT.</li>
  <li>as for Hackintosh: macOS uses CPU instructions that aren‚Äôt available yet on non-Apple ARM CPUs, so you can‚Äôt have hardware accelerated virtualization, only very slow emulation. Besides, Hackintoshes are often built when Apple‚Äôs own hardware isn‚Äôt fast enough; in this case, Apple‚Äôs ARM processors are already some of the fastest in the industry.</li>
</ul>

<p>I researched this this not because it‚Äôll be practical, but only to understand how an Apple Silicon Mac works. This will never be a <a href="https://www.youtube.com/watch?v=1AtE54HpXBM">Time Train</a>: only a <a href="https://youtu.be/UswpJh6Zvd8?t=119">science experiment</a>.</p>

<h2 id="what-i-did">What I did</h2>

<h2 id="create-kext-collection">Create kext collection</h2>

<p>On iOS, the kernel and its Kexts are packed together into a bootable file called the <strong>Kernel Cache</strong>.</p>

<p>macOS 11 uses an evolved version of this format, called the <strong>Boot Kext Collection</strong>.</p>

<p>Like the iOS kernelcache, it contains all Kexts required for booting, so the bootloader only needs to load it into memory and jump into it.</p>

<p>To create a boot kext collection, macOS 11 introduces the <a href="https://developer.apple.com/documentation/kernel/installing_a_custom_kernel_extension?language=objc"><code>kmutil</code></a> tool.</p>

<p>Here‚Äôs <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh">my script</a> to get <code>kmutil</code> to generate an arm64e kext collection.</p>

<p>It manually excludes some kexts because they cause kmutil to error out. Most are because they depend on ACPI, which is not available on Apple Silicon. I made a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/printexcludekexts.sh">script</a> to detect them.</p>

<p>Debugging <code>kmutil</code> failures on macOS 11 beta 3 was easy because it dumped out the entire NSError message. However, on macOS 11.0.1 beta, Apple decided to hide the full error message and only print an error code. I had to disable SIP and put a breakpoint on <code>swift_errorRetain</code> to get at the underlying error.</p>

<p>Once the <code>build_arm64e_kcache.sh</code> runs, a Boot Kext Collection is created at <code>~/kcache_out/bootcache-arm64e</code>, which can be booted in QEMU.</p>

<h2 id="disassembling-the-boot-kext-collection">Disassembling the boot kext collection</h2>

<p>For debugging, I also had to disassemble the newly created Boot Kext Collection in Ghidra.</p>

<p>Unfortunately, Ghidra isn‚Äôt updated for macOS 11 and will refuse to load the file, first giving an error about XML DOCTYPE, then - once that‚Äôs worked around - an <a href="https://github.com/NationalSecurityAgency/ghidra/issues/2192">IOException</a> from the invalid <code>ntools</code> value in the <code>LC_BUILD_VERSION</code> load command.</p>

<p>I created a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/patch_boot_kext_collection_for_ghidra.py">script</a> to fix up the kext collection so that Ghidra can load it.</p>

<p>Note that this is still not perfect - Ghidra still doesn‚Äôt fixup pointers or read symbols.</p>

<p>To get method names, I also disassembled the raw kernel file (<code>/System/Library/Kernels/kernel.release.t8020</code>) for cross reference. Note that the raw kernel is based at a different address - you can either rebase it in Ghidra, or just be careful to convert addresses.</p>

<h2 id="disable-pac">Disable PAC</h2>

<p>I already had a <a href="https://worthdoingbadly.com/xnuqemu2/">modified QEMU to boot an iOS kernel</a> (which has inspired others, such as <a href="https://alephsecurity.com/">Aleph Security</a>, to build much better open-source iOS emulation platforms)</p>

<p>In early 2019 I updated my modified QEMU to work with PAC for the iPhone Xs/Xr.</p>

<p>QEMU by that time already supported PAC instructions; however, Apple <a href="https://googleprojectzero.blogspot.com/2019/02/examining-pointer-authentication-on.html">modified</a> the crypto algorithm when implementing PAC, so the kernel fails to boot.</p>

<p>I decided to instead <a href="https://github.com/zhuowei/qemu/commit/16613b67ad15a902791109077ebfb1091f1873aa">turn PAC instructions</a> into no-ops, since I don‚Äôt know how Apple‚Äôs algorithm worked. This also makes it easier to debug the kernel.</p>

<p>Since the macOS DTK used an A12z processor, the modified QEMU just worked.</p>

<h2 id="device-tree">Device tree</h2>

<p>Like iOS, macOS on Apple Silicon uses a <strong>device tree</strong> to describe hardware to the kernel, and to pass boot arguments.</p>

<p>macOS 11.0.1 beta‚Äôs installer doesn‚Äôt contain a device tree for the DTK: I suspect it would be in the .ipsw files, which are not publically available. Instead, I borrowed the iPad Pro‚Äôs device tree from iOS 14 beta 3.</p>

<p>Like the <a href="https://worthdoingbadly.com/xnuqemu2/">iOS in QEMU experiments</a>, I first disabled every piece of hardware in the device tree except the serial port.</p>

<p>Unlike iOS, macOS expects some more information in the device tree:</p>
<ul>
  <li>ram size (since Macs have upgradeable RAM)</li>
  <li>nvram, otherwise panics with a null pointer while reading nonce-seed. (I copied nvram from <a href="https://gist.github.com/bazad/1faef1a6fe396b820a43170b43e38be1">bazad‚Äôs dump of an iPhone device tree</a>.)</li>
  <li>AMCC (KTRR) register positions</li>
  <li>System Integrity Protection status</li>
</ul>

<p>I rewrote my <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">device tree editor</a> to allow populating these extra params.</p>

<h2 id="up-to-launchd">Up to launchd</h2>

<p>I can‚Äôt actually boot a macOS root filesystem as I don‚Äôt have an emulated hard disk.</p>

<p>I don‚Äôt have a recovery ramdisk either: that would likely only be included in the DTK IPSW, which is not public.</p>

<p>Instead, I decided to boot with an iOS ramdisk to test the kernel, and disable signature checking using a GDB breakpoint.</p>

<p>I also couldn‚Äôt get the trustcache (list of executables trusted by the kernel) to load. I tried following <a href="https://alephsecurity.com/2019/06/25/xnu-qemu-arm64-2/">Aleph Security‚Äôs guide</a>, but macOS 11 is more strict than iOS 12 and needs it below the kernel; I couldn‚Äôt figure out the correct memory address.</p>

<h2 id="why-it-took-so-long">Why it took so long</h2>

<p>I actually had this blog post ready since <a href="https://gist.github.com/zhuowei/27816d39f234468cf2956479c0dea7ad">August 9th</a>, but I spent an extra 3 months trying to fix issues, since I really wanted to at least get to a shell!</p>

<p>Unfortunately:</p>
<ul>
  <li>debugging why drivers wasn‚Äôt loading was hard</li>
  <li>I couldn‚Äôt disable signature checking properly</li>
  <li>I wanted to wait until Apple released an A14 kernel instead of the DTK‚Äôs A12, so that we can look at how virtualization works, but they never did</li>
</ul>

<p>It‚Äôs now November 9th and Apple‚Äôs holding their press conference tomorrow: so it‚Äôs <a href="https://www.youtube.com/watch?v=9tAbhrDUrqM">now or never</a>.</p>

<h2 id="whats-left">What‚Äôs left</h2>

<p>I‚Äôm probably not going to be working further on this, but here‚Äôs what one can do to make this an actual useful research platform:</p>

<ul>
  <li>Figure out why half the drivers aren‚Äôt loading at all</li>
  <li>Write basic drivers/emulations:
    <ul>
      <li>probably emulate AIC in QEMU (based on Project Sandcastle‚Äôs Linux driver) since a custom interrupt controller Kext would be hard to write</li>
      <li>port Apple‚Äôs old <a href="https://opensource.apple.com/source/AppleMacRiscPCI/AppleMacRiscPCI-3.4/AppleMacRiscPCI.cpp.auto.html">PowerPC PCIE</a> drivers, since it‚Äôs too hard to emulate the Apple Silicon PCIE controller. This will allow us to connect a virtual hard drive.</li>
    </ul>
  </li>
  <li>Switch to the A14 kernel when Apple releases Apple Silicon Macs, so we can test virtualization</li>
</ul>

<h2 id="what-i-learned">What I learned</h2>

<ul>
  <li>How to modify QEMU to disable PAC</li>
  <li>How iBoot on Apple Silicon passes boot options in the device tree</li>
  <li>How to generate an Apple Silicon kernel cache without an Apple Silicon Mac</li>
  <li>How to fight <code>kmutil</code> for the real error message</li>
  <li>Never procrastinate on a blog post for three months</li>
</ul>

  </div>
</article>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://worthdoingbadly.com/xnuqemu3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064593</guid>
            <pubDate>Thu, 12 Nov 2020 00:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlooked source of Apple M1 performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064570">thread link</a>) | @kwiromeo
<br/>
November 11, 2020 | https://kwiromeo.com/explaining-apple-m1-products-performance/ | <a href="https://web.archive.org/web/*/https://kwiromeo.com/explaining-apple-m1-products-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>When watching <a href="https://youtu.be/5AwdkGKmZ0I">Apple's Arm laptops</a> event, I couldn't help but wonder: where is all that performance coming from? During the event, there were two key points (that are not obvious, IMHO), that further explain where they are getting all that extra performance from.</p><p>But first, let's mention the obvious stuff, that plenty of analysts will anchor on, and that are valid:</p><ul><li><strong>More transistors is better</strong>: 5nm process allows more transistors in a chip. More transistors = more instructions processed = faster performance</li><li><strong>Small means low power consumption:</strong> 5nm process allows for lower power consumption. This is because, at that size, the transistor can operate between 0.7V - 1.2V per transistor[<a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">1</a>] (instead of 1V - 1.35V)[<a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">2</a>]. At the numbers of billions of transistors, a small voltage difference means a lot for battery consumption.</li><li><strong>Specialized hardware gives an edge</strong>: Accelerators (like the neural engine) allow the Mac to offload specific tasks to another core, which leaves the main processor, M1 to do the work that is less specific (like compiling your code from XCode üòâ )</li></ul><h2 id="unified-memory-architecture-or-making-friends-with-physics-">Unified Memory Architecture (or Making Friends with Physics)</h2><p>When I was transitions careers to become a software developer, I came across this post about latency numbers of common computer components ( a link at <a href="http://norvig.com/21-days.html#answers">Peter Norvig post about it</a>), it occurred to me that all these numbers were proportional to the distance between the CPU and the location of the data. The further the electrons need to travel, the more time they will take. This is a massive oversimplification but illustrates the point well. There are other details to take into account as well. &nbsp;The one that comes to mind is that having the electrical signal only traveling though the SoC instead of the printed circuit board, avoid a lot of signal conditioning that would need to happen to keep signal integrity. Apple brought all their chips closer, which reduced the amount of travel time for every critical signal, as well as reduced the number of medium transitions (from an integrated circuit to a printed circuit board, back to an integrated circuit) as shown in the figure below. This results in higher data access speed by the CPU and the GPU, which translates to a faster experience for the end-user.</p><figure><img src="https://kwiromeo.com/content/images/2020/11/apple_m1_soc_vs_logic_board.jpg" alt="sketch of a logic board with separate chips compared to an apple M1 SoC"><figcaption>Showing the reduced distance of signal traveling for a logic board vs. a SoC :-)&nbsp;</figcaption></figure><h2 id="avoid-unnecessary-copies-or-the-gospel-by-a-c-performance-engineer-">Avoid Unnecessary Copies (or the gospel by a C++ performance engineer)</h2><p>In my year of learning and using C++, I've learned that (unnecessary) copies are bad, and Craig Federighi also knows this. During the presentation, he says</p><blockquote>"We built macOS on Apple Silicon to use the same data formats for things like video decode, GPU and display, so there's no need for expensive copying or translation"</blockquote><p>Why are copies they bad? This has to do with what happens when an object is copied. Here's a simple way to look at the process. Whenever a program issues a copy command, then the CPU needs to:</p><ul><li>read the memory location of the data,</li><li>then reserve memory where the data will be copied</li><li>then copy the data</li><li>then decide what to do with the original data</li></ul><p>When the source of the data copied remains, then the CPU is done. However, when the source data needs to be deleted, then there's the additional step of de-allocating memory space so that other instructions can use it. This problem is sometimes caught by the compiler, whenever possible, and performs an optimization called <a href="https://en.wikipedia.org/wiki/Copy_elision">copy elision</a> whenever it is obvious that a copy is unnecessary. However, while <a href="https://youtu.be/bSkpMdDe4g4">compilers are awesome</a>, they can't undo a programmer's lack of optimization knowledge. One solution that the C++ community found useful, is that we can help the compiler by specifying when copies are not needed. Since C++ 14, programmers can also tell the compilers that we don't need to go through a deep copy, instead, use a command <code>std::move</code>, which does the magic of not destroying and recreate the same thing. This saves CPU cycles, and improves performance.</p><p>From the Apple M1 MacBook presentation, Apple makes the above behavior default: <strong>instead of having the programmer choose between copying or reusing data, reuse of the data is the default</strong>. This makes the efficient behavior to be the default, and save programs from being slowed down by unnecessary copies</p><h2 id="things-i-may-have-missed-and-things-i-don-t-know-about-">Things I May Have Missed (and Things I Don't Know About)</h2><p>The above is a simplified view of the programming model of Apple's new M1 chip. By not having programmed for one, the above is my best guess at how the items noted in the keynote mentions would translate in hardware and software. It's possible that Apple simplified the programming paradigm of CPU vs GPU programming by obfuscating calls to GPU instructions in the macOS APIs. If all the hardware is one the same chip, the programmer doesn't need to know what sub-chip (CPU, GPU, Neural Engine, etc...) is doing the job, but just that the chip (M1) is doing it. From there, the job is for compiler optimization to take over, and make the best decision as to which sub-chip needs to process the instruction.</p><p>‚Äî</p><p>PS: if someone who knows the nitty gritty details of this, hit me up <a href="https://twitter.com/kwiromeo">@kwiromeo</a> on twitter. I would love to learn more about this.</p><hr><p>[1] AnandTech - <a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">Early TSMC 5nm Test Chip Yields 80%, HVM Coming in H1 2020</a></p><p>[2] AnandTech - <a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">What Products Use Intel 10nm? SuperFin and 10++ Demystified</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://kwiromeo.com/explaining-apple-m1-products-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064570</guid>
            <pubDate>Thu, 12 Nov 2020 00:06:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python on .NET 5]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064143">thread link</a>) | @eatox
<br/>
November 11, 2020 | https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html | <a href="https://web.archive.org/web/*/https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <p><em>This post is an update on the Pyjion project to plug the .NET 5 CLR JIT compiler into Python 3.9.</em></p>
<p>.NET 5 was released on November 10, 2020. It is the cross-platform and open-source replacement of the <a href="https://github.com/dotnet/core"><strong>.NET Core</strong></a> project and the <strong>.NET</strong> project that ran exclusively on Windows since the late 90‚Äôs.</p>
<p>.NET is formed of many components:</p>
<ul>
<li>3 builtin languages, C#, F# and VB.NET, each with its own compiler</li>
<li>A standard library</li>
<li>A common intermediate language to abstract the high level languages from the core runtime. This is a standard known as <a href="https://github.com/tonybaloney/ecma-335/tree/master/docs">ECMA 335 CIL</a>.</li>
<li>A common language runtime (CLR) that compiles CIL into native machine code so that it can be executed and packages executables into .exe formats.</li>
</ul>
<p><img alt=".NET architecture" src="https://tonybaloney.github.io/img/posts/Common_Language_Infrastructure.png"></p>
<p>.NET 5 CLR comes bundled with a performant JIT compiler (codenamed RyuJIT) that will compile .NETs CIL into native machine instructions on Intel x86, x86-64, and ARM CPU architectures.</p>
<p>You can write code in a number of languages, like C++, C#, F# and compile those into CIL and then into native machine code (as a binary executable) on macOS, Linux, and Windows. Pretty neat.</p>
<p>But this is a blog about Python. So what does this have to do with Python?</p>
<p>Pyjion is a project to replace the core execution loop of CPython by transpiling CPython bytecode to ECMA CIL and then using the .NET 5 CLR to compile that into machine code. It then executes the machine-code compiled JIT frames at runtime instead of using the native execution loop of CPython.</p>
<h2>Very-quick overview of Python‚Äôs compiler</h2>
<p>When CPython compiles Python code, it compiles it into an intermediate format, similar to .NET, called Python bytecode. This bytecode is cached on disk so that when you import a module that hasn‚Äôt changed, it doesn‚Äôt compile it every time. You can see the bytecode by disassembling any Python function:</p>
<pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; def half(x):
...    return x/2
... 
&gt;&gt;&gt; dis.dis(half)
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (2)
              4 BINARY_TRUE_DIVIDE
              6 RETURN_VALUE
</code></pre>

<p>To execute anything on a CPU, you have to provide the OS with machine-code instructions. This can be accomplished by compiling them up-front using a compiled like the C or C++ compilers. They compile code into executable formats as either shared libraries or standalone executables. <a href="https://tonybaloney.github.io/posts/extending-python-with-assembly.html"><em>See my post on Python/assembly for a bit more info on this topic</em></a>.</p>
<p>CPython converts the bytecode into machine code instructions like looping over them in a precompiled function, called the evaluation loop. This is essentially a big for loop with a switch statement. The compiled version of CPython that you‚Äôre running already has the instructions required. This is why CPython‚Äôs evaluation loop is an ‚ÄúAOT‚Äù, or ‚ÄúAhead of Time‚Äù compiled library:</p>
<p><img alt="diagram 1" src="https://tonybaloney.github.io/img/posts/Slide1.png"></p>
<p><strong>Note: There is a lot more to CPython‚Äôs compiler. I‚Äôve written a <a href="https://realpython.com/products/cpython-internals-book/">whole book on the CPython compiler and the internals of CPython</a> if you want to learn more.</strong></p>
<p>There are a few issues with this approach. The biggest is speed. A series of inline machine-code instructions is very performant. CPython has to make judgements at runtime for which code branch to follow every time your function is run. This leads to CPython being 100x slower in ‚Äútight-loop‚Äù problems where its executing the same thing again and again. The machine-code is compiled ahead of time and it has to loop around to get to the right instructions. Checkout my PyCon talk for a more in-depth explanation:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/I4nkgJdVZFA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The most common way around this performance barrier is to compile Python extensions from C. This produces a custom binary with inline machine-code instructions for the task at hand. This is how most machine-learning and data science libraries like numpy, pandas, SKL are put together. This approach is still AOT compiling the code. It also requires a lot of knowledge of C. This approach has worked really well for the data science community, where algorithms can be performant and leverage low-level platforms <a href="https://numba.pydata.org/numba-doc/latest/cuda/index.html">like GPUs or specialised AI chipsets</a>.</p>
<p>There are a few issues with the AOT extension module approach. One is that it still uses the evaluation loop. C extension modules are a set of functions. Once you call the C-compiled function, its in the performant code, but your Python code that‚Äôs calling it still lives inside Python‚Äôs loop. If you want to leverage a compiled library and your Python code is doing some heavy number crunching, you end up having to use an API of functions, like numpy, instead of a more fluent Python API:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.ones([9, 5, 7, 4])
&gt;&gt;&gt; c = np.ones([9, 5, 4, 3])
&gt;&gt;&gt; np.dot(a, c).shape
(9, 5, 7, 9, 5, 3)
&gt;&gt;&gt; np.matmul(a, c).shape
(9, 5, 7, 3)
</code></pre>

<h2>What Pyjion does to solve this issue</h2>
<p>A few releases of Python ago (CPython specifically, the most commonly used version of Python) in 3.7 a new API was added to be able to swap out ‚Äúframe execution‚Äù with a replacement implementation. This is otherwise known as <a href="https://www.python.org/dev/peps/pep-0523/">PEP 523</a>. PEP 523 also added the capability to store additional attributes in <em>code objects</em> (compiled Python code.</p>
<p>Pyjion does not compile Python code. It compiles Python frames (code objects, like blocks, functions, methods, classes) into machine-code at runtime using a performant JIT:</p>
<p><img alt="diagram 2" src="https://tonybaloney.github.io/img/posts/Slide2.png"></p>
<p>CPython compiles the Python code, so whatever language features and behaviours there are in CPython 3.9, like the walrus operator, <a href="https://www.python.org/dev/peps/pep-0584">the dictionary union operator</a>, will all work exactly the same with this extension enabled. This also means that this extension uses the same standard library as Python 3.9.</p>
<p>Pyjion is a ‚Äúpip installable‚Äù package for standard CPython that JIT compiles all Python code at runtime using the .NET 5 JIT compiler. You can use off-the-shelf CPython 3.9 on macOS, Linux or Windows. After installing this package you just import the module and enable the JIT.</p>
<p>Once a frame has been compiled, the binary code is cached in memory and reused every time the function is called:</p>
<p><img alt="diagram 3" src="https://tonybaloney.github.io/img/posts/Slide3.png"></p>
<h2>Using Pyjion</h2>
<p>To get started, you need to have .NET 5 installed, with Python 3.9 and the Pyjion package (I also recommend using a virtual environment).</p>
<p>After importing pyjion, enable it by calling <code>pyjion.enable()</code> which sets a compilation threshold to 0 (the code only needs to be run once to be compiled by the JIT):</p>
<pre><code>&gt;&gt;&gt; import pyjion
&gt;&gt;&gt; pyjion.enable()
</code></pre>

<p>Any Python code you define or import after enabling pyjion will be JIT compiled. You don‚Äôt need to execute functions in any special API, its completely transparent:</p>
<pre><code>&gt;&gt;&gt; def half(x):
...    return x/2
&gt;&gt;&gt; half(2)
1.0
</code></pre>

<p>Pyjion will have compiled the <code>half</code> function into machine code on-the-fly and stored a cached version of that compiled function inside the function object.
You can see some basic stats by running <code>pyjion.info(f)</code>, where <code>f</code> is the function object:</p>
<pre><code>&gt;&gt;&gt; pyjion.info(half)
{'failed': False, 'compiled': True, 'run_count': 1}
</code></pre>

<p>You can see the machine code for the compiled function by disassembling it in the Python REPL.
Pyjion has essentially compiled your small Python function into a small, standalone application.
Install <code>distorm3</code> first to disassemble x86-64 assembly and run <code>pyjion.dis.dis_native(f)</code>:</p>
<pre><code>&gt;&gt;&gt; import pyjion.dis
&gt;&gt;&gt; pyjion.dis.dis_native(half)
00000000: PUSH RBP
00000001: MOV RBP, RSP
00000004: PUSH R14
00000006: PUSH RBX
00000007: MOV RBX, RSI
0000000a: MOV R14, [RDI+0x40]
0000000e: CALL 0x1b34
00000013: CMP DWORD [RAX+0x30], 0x0
00000017: JZ 0x31
00000019: CMP QWORD [RAX+0x40], 0x0
0000001e: JZ 0x31
00000020: MOV RDI, RAX
00000023: MOV RSI, RBX
00000026: XOR EDX, EDX
00000028: POP RBX
00000029: POP R14
...
</code></pre>

<p>The complex logic of converting a portable instruction set into low-level machine instructions is done by .NET‚Äôs CLR JIT compiler.</p>
<p>All Python code executed after the JIT is enabled will be compiled into native machine code at runtime and cached on disk. For example, to enable the JIT on a simple <code>app.py</code> for a Flask web app:</p>
<pre><code>import pyjion
pyjion.enable()

from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

app.run()
</code></pre>

<p>That‚Äôs it.</p>
<h2>Will this be compatible with my existing Python code? What about C Extensions?</h2>
<p>The short answer is- if your existing Python code runs on CPython 3.9 ‚Äì <strong>yes</strong> it will be compatible. To make sure, Pyjion has been tested against the full CPython ‚Äútest suite‚Äù on all platforms. In fact, it was the first JIT ever to pass the test suite.</p>
<p>Thats because this isn‚Äôt a Python runtime, it uses the existing Python compiler to compile your code into Python bytecode (low level instructions).</p>
<p>Pyjion uses the same dynamic module loader as CPython, so if you import a Python extension from your virtual environment, it will work just the same in Pyjion.</p>
<h2>Project History</h2>
<p>Pyjion isn‚Äôt new. Brett Cannon and Dino Viehland started the Pyjion project 4 years ago. This was the first JIT to pass the full CPython test suite.
There were some limitations to the original proof-of-concept:</p>
<ul>
<li>Written against an old version of .NET Core</li>
<li>Required custom patches of .NET and compiling from source</li>
<li>Required custom patches of CPython and compiling from source</li>
<li>Only worked on Windows</li>
<li>It was written for Python 3.6 before PEP 523 was agreed and merged</li>
</ul>
<p>Has much changed since Python 3.6? To the average user, not really. But under the hood, the implementation of a few things has completely changed:</p>
<ul>
<li>Function calls</li>
<li>Iterators</li>
<li>Exception Handling</li>
<li>Dictionary, list and set comprehensions</li>
<li>Generators and coroutines</li>
</ul>
<p>Actually, a <strong>lot</strong> has changed in the last few releases of CPython. The <a href="https://github.com/microsoft/Pyjion/pull/237">patch that I‚Äôm talking about</a> to get Pyjion working with the latest version of everything was a big undertaking‚Ä¶</p>
<p><img alt="not-much-has-changed" src="https://tonybaloney.github.io/img/posts-original/not-much-has-changed.png"></p>
<p>The goal with the latest patch was to get the project up to the condition of:</p>
<ul>
<li>Using the release binaries of .NET 5 and CPython 3.9</li>
<li>Making it work across all platforms</li>
<li>Implement the PEP523 interface</li>
<li>Implement all the new features of Python 3.9</li>
<li>Making the package ‚Äúpip installable‚Äù from PyPi</li>
<li>Improving the test coverage</li>
<li>Adding a disassembler (both machine-code and CIL) to aid development</li>
</ul>
<h2>Is this faster?</h2>
<p>The short answer a little, but not by much (yet).</p>
<p>JIT ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</a></em></p>]]>
            </description>
            <link>https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064143</guid>
            <pubDate>Wed, 11 Nov 2020 23:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy professionally built algo-traders in 5 mins with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25063678">thread link</a>) | @tjs8rj
<br/>
November 11, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users‚Äô algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063678</guid>
            <pubDate>Wed, 11 Nov 2020 22:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reviving Yo: How to Patch an APK]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063163">thread link</a>) | @wesleyac
<br/>
November 11, 2020 | https://blog.wesleyac.com/posts/patching-apks | <a href="https://web.archive.org/web/*/https://blog.wesleyac.com/posts/patching-apks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I got talking to a friend the other day about <a href="https://en.wikipedia.org/wiki/Yo_(app)">Yo</a>, the app where you can send your friends the word "Yo." It's nominally still around, run off donations, but the SSL certificate for the API server has been expired for a little while, so the app doesn't work anymore. Not to worry, though, that's something we can fix by patching the APK pretty quickly.</p>

<p>First, <a href="https://play.google.com/store/apps/details?id=com.justyo">download Yo on the Play Store</a>. Then, download <a href="https://play.google.com/store/apps/details?id=com.ext.ui">APK Extractor</a>, and use it to download the APK off your phone (you'll need to get it onto your computer somehow, I emailed it to myself). You should have a file called <code>Yo_base.apk</code>.</p>

<p>Next, install <a href="https://ibotpeaches.github.io/Apktool/"><code>apktool</code></a>, and use it to decompile the APK:</p>
<div><pre><code data-lang="">apktool if Yo_base.apk
apktool d Yo_base.apk
</code></pre></div>
<p>This should make a directory called <code>Yo_base</code>, which you can edit however you want. I changed <code>https://newapi.justyo.co</code> to <code>http://newapi.justyo.co</code> in <code>res/values/strings.xml</code>, but you could also make other changes as well. Once you've done that, recompile the APK like so:</p>

<p>Now there should be a <code>Yo_base/dist/Yo_base.apk</code> file, but it's not signed, so we can't use it. Signing it isn't too tricky though. Using the <code>keytool</code> and <code>jarsigner</code> tools that come with the JDK:</p>
<div><pre><code data-lang="">keytool -genkey -v -keystore my-release-key.keystore -alias alias_name -keyalg RSA -keysize 2048 -validity 10000
jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore my-release-key.keystore Yo_base/dist/Yo_base.apk alias_name
</code></pre></div>
<p>It'll ask you to make a password and enter your name and things, I don't think it really matters what you choose. Once you've done all that, you can move the <code>Yo_base/dist/Yo_base.apk</code> file to your phone, click through all the fuss that Android makes about running a unsigned APK, and start Yoing away! This also works for other apps just as well :)</p>

          </div></div>]]>
            </description>
            <link>https://blog.wesleyac.com/posts/patching-apks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063163</guid>
            <pubDate>Wed, 11 Nov 2020 21:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Owning Your Own Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062764">thread link</a>) | @rossdavidh
<br/>
November 11, 2020 | https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/ | <a href="https://web.archive.org/web/*/https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>So, you want to strike out on your own, and start your own business?  Great!  Here are a few things you might want to know about that.  They are based on my own experience as an independent contractor (computer programmer), what I've seen being married to an owner (with a partner) of a small retail shop, and what I've seen and heard talking to multiple small business owners of various kinds in the last twenty years.  Some of them are successful, some of them were not, and some were successful but didn't like it, and stopped.  The recurring thing I've seen (and my own lived experience) is that owning and running your own business is not what most people think it is like, so perhaps this will be useful to you as you set out on a different path.</p>



<h2>Lesson 1: You Still Have A Boss</h2>
<p>The most important thing to know, is that being a business owner is NOT like being an employee, except without the boss.  This is, I think, the number one misconception that most people have.  In fact, not only do you still have a boss, but your boss:</p>
<ul>
<li>gives you no paid vacation</li>
<li>gives you no paid sick leave</li>
<li>docks your pay if you break the rules</li>
<li>...but doesn't tell you what those rules are</li>
<li>doesn't (generally) pay overtime if you work long hours or on weekends</li>
<li>does (usually) dock your pay if you take off early</li>
<li>may occasionally pay bonuses, but won't tell you ahead of time what you have to do to get them</li>
</ul>

<p>Your boss is, of course, the market.  New small business owners (and even old ones, sometimes) think they get to decide when they will work, and therefore that customers will show up when they want them to.  But in practice, customers show up when THEY want to, and you need to be ready for them.  If you are not, generally speaking, they will go elsewhere or just forego spending entirely.  The same logic applies to all of the rest of the items in the list above.  The market does all of this, and it is up to you to figure it out, because it won't tell you ahead of time.</p>

<p>Which means really, you have to figure out the rules, and impose them on yourself.  So, when owning your own business, it is not as if you no longer have a boss who makes you do stuff you don't want to do.  It's more like, you also have to be that boss, forcing yourself to do things you don't feel like doing, because there isn't anyone else there to tell you to do it.  That's what "being your own boss" really means; it's not the same as not having a boss.  If you aren't able to make yourself do things when they need doing, even though you don't feel like it right then, then being your own boss may not be for you.</p>

<h2>Lesson 2: The Loop</h2>
<p>There is a process, which you need to know about and think about, as you run a small business.  It is a loop, which can be divided into four parts:</p>
<ol>
<li>Try something (typically involves spending $$ and/or time)</li>
<li>Get results (typically involves receiving $$ or saving time)</li>
<li>Observe that result (notice what just happened)</li>
<li>Plan your next thing to try</li>
</ol>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop.png">

<p>It may seem so simple and straightforward, that there's no point in stating it.  But, most business failures can be traced ultimately to one of the following breaks in the loop:</p>
<ul>
<li>Not keeping enough data about what happened (failure in the "observe" step, above)</li>
<li>Not taking time to plan what to do (failure in the "plan" step)</li>
<li>Not actually doing what was planned (failure in the "try" step)</li>
</ul>

<p>Let's look at each of these failures in more detail.</p>
<h3>Failure to Observe</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_observe.png">

<p>Part of this, is the common conception that keeping a lot of data about what happened is a drag, and only corporate losers do that sort of thing and starting your own business is all about getting away from that.  Part of it is a failure to understand (per Lesson 1: You Still Have A Boss) that having your own business doesn't mean you get to do whatever you want.  One example I've often seen, is in the decision of what hours a day, and what days of the week, to be open.</p>

<p>Now, it is certainly true that you have the right to close your store whenever you want to.  Perhaps you don't want to be open on Sundays, because your religious beliefs prohibit it.  It's your life.  More typically, though, people just sort of don't want to be open on Sundays, but don't want to pay any penalty for this.  Therefore, they convince themselves that nobody shops on Sundays anyway.  This is, essentially, trying to get out of working on Sundays, without letting your boss see you doing it and docking your pay.  This is employee-type thinking.  Once you are a business owner, not an employee, this way of thinking makes no sense anymore.  If you want to know the cost of not being open on Sundays, you need to collect some data.  For example, you can keep your store open 7 days a week at the beginning, and keep track of how much your sales are each day.  If you do, you will probably find that, just as you want to do a good bit of your shopping on Sunday, so do your (potential) customers.  Sunday is not quite as busy as Saturday, but probably it is more busy than, say, Monday or Tuesday.</p>

<p>But, the lesson is NOT that you should be open on Sundays.  The lesson is that you should not take my word for it, or your own intuition; you should keep track of exactly what happens when you do stay open on Sundays, and look at the cold, hard, unfeeling, pitiless numbers in a spreadsheet before you decide that it's not worth staying open on Sunday.  Of course, if it's a religious thing, or you just don't care about making money, or for whatever other reason you decide to close on Sundays anyway, that is entirely up to you.  But DON'T fail to collect the data.  Don't make decisions based only on your intuition, because when you do that it's the equivalent of the boss asking his employees, "I dunno, should we be open on Sundays?".  What they tell him is based on what they want, not what's good for the business.  You are the boss, and your intuition is like the employees here.  Your intuition will tell you what it wants to be true.  Keep track, numerically, in a spreadsheet, of what happened.  That's what tells you what really is true.</p>

<p>The same logic applies to having a 25% off sale, having a special event at your business, selling a new product, and so forth.  It's your decision, but fortify yourself against wishful thinking by keeping careful, numerical, track of what happened.  You should have, in a spreadsheet, a record of what happened at this time last week, last month, last year.  If sales are slow, is this because they always are slow this time of year?  Or this day of the week?  Or is there something new going on, that you need to look into?  If you spent money to get a new kind of merchandise in your store, how much did you pay for it, and how much did it sell for?  How much do you spend on things, and how much of that goes to waste?  You should know, and you should not rely on your memory or your intuitive hunch.  Put it in a spreadsheet, and look at it.  When it comes time to pay the bills, the bank's computer will take a cold, hard, pitiless look at how much money is in your bank account.  Therefore, you need to be taking a cold, hard, pitiless look at what is working, and what isn't, so that you will be able to pay those bills.</p>

<h3>Failure to Plan</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_plan.png">

<p>Let's assume, for the moment, that you have a decent work ethic.  You're willing to hustle to get things done.  This is mostly a good thing, but there is one case where it can get you into trouble, and that's when you're not willing to pause, and plan, because there's so much work to do and you want to get started.  Many times, there are more things that need doing, than there is time to get it all done.  It may seem like this means you need to hustle more.  In fact, it means you need to stop hustling, at least for a little while, and think carefully about what needs to be done first.</p>

<p>Once again,this may mean you end up acting a little like those boring loser corporations that you were wanting to get away from when you decided to start your own business.  Planning, to some people, is boring and seems pointless because nothing gets actually accomplished.  But you don't have enough time, energy, and money to do everything you can think of that needs doing.  When you have your own business, you NEVER run out of things that need doing.  This means you need to carefully plan, and prioritize, so that what you actually do is what is most likely to help.  Just because you are working hard, doesn't mean you are doing what is most important right then.  Make a list of all the things that need doing, put them in an order from highest priority to lowest, and start from the top.  Don't work on the first thing you happen to see that needs doing.  Work on the thing at the top of the list of priorities, and leave some time in your schedule for making sure that list is right.  Is the thing at the top more important than what is below it?  If you cannot get everything done, is the stuff at the top of your list what you would choose to do?  Or will you discover that you have been sprinting nonstop for weeks and much of what you did turned out to be pointless, because (for example) you spent a lot of time painting the great looking sign for your bakery's special Easter sidewalk sale, but never got the permit from the city to have a sidewalk sale so you cannot do that, and the time spent on painting that sign is wasted.  Work on the most necessary things first, and realize that not everything you can think of, will get done.  Even though stopping to plan takes away some of your (already insufficient) time, it also helps increase the odds that you are spending your time wisely, and not wasting it.</p>

<p>All of the above discussion about prioritizing your time, also applies to prioritizing your money.  You will run out of money, if you spend it on anything that seems like a good idea.  There are absolutely more sensible-sounding, good ideas to spend your money on, than you have money.  So prioritize.  You cannot run your business, if you don't pay rent.  You cannot ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</a></em></p>]]>
            </description>
            <link>https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062764</guid>
            <pubDate>Wed, 11 Nov 2020 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software engineering photonics and color science]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062325">thread link</a>) | @pete314
<br/>
November 11, 2020 | https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/ | <a href="https://web.archive.org/web/*/https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<hr><h2>Software engineering photonics and color science</h2>

<p>

<img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science.png">

</p>
<p>Hi everybody, I am Petri Piirainen, a co-founder and chief technology officer of SoftColor company. Welcome to this video lecture about SoftColor's fifteen-year software engineering photonics and color science story. </p>

<p>This lecture is part of the University of Eastern Finland's photonics applications course and lecture series. </p>

<p>Since 2005 we have made photo editing automation software. Our photonics journey is slightly different from traditional optics-focused companies, which you have met during this lecture series. </p>

<p>During this lecture, I will tell you what we have learned about developing and selling photonics applications. </p>

<hr><h2>My history with photonics and software engineering </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_2.png"></p><p>I have an MSc degree in computer science (from the University of Eastern Finland). I studied computer science in a digital signal processing program, and then I had mandatory applied mathematics and physics as minor studies. With physics studies, there was a lot of photonics and color science courses. </p>

<p>I started by software business and engineering career during high school in the 90s.  In 2005 we founded SoftColor Oy, and since that, we have developed faster, easier, and better photo editing automation software.</p>


<hr><h2>Photonics applications: What have we learned?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_3.png"></p><p>First, I would like to talk a little bit about photonics applications, the beauty and the beast of engineering photonics applications. We have learned that developing useful photonics applications is very hard and requires a lot of engineering and math knowledge. It is challenging because photonics applications (software or hardware) usually have to quickly process tons of data and calculations. </p>

<hr><h2>Technical elements of useful photonics application</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_4.png"></p><p>My favorite thing with photonics is that all photonics applications contain four types of engineering. </p>
<ul>
<li>Physics</li>
<li>Mathematics</li>
<li>Electrical engineering</li>
<li>Computer science </li>

</ul>

<p>But there is also one thing, which is fascinating.  All photonics applications require a lot of arts too.</p>

<ul>
<li>Image quality</li>
<li>Industrial design</li>
<li>User experience</li>
<li>User interaction</li>
<li>User interfaces</li>

</ul>

<p>This mixture of arts and engineering is my main topic for you today.</p>

<hr><h2>Topics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_5.png"></p><p>My topics today are:</p>

<ul>
<li>A short history and introduction to our company</li>
<li>What we do and how products work</li>
<li>How have we mixed photonics with software engineering</li>
<li>What we learned about to make useful photonics applications</li>
<li>And there will be a bonus "homework" for  you</li>

</ul>


<hr><h2>Story of SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_6.png"></p><p>Let's have a quick look at our products and technology. </p>

<hr><h2>What we do</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_7.png"></p><p>We make faster, easier, and better photo edition automation software. Our software runs on Windows PCs and servers.</p>

<hr><h2>SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_8.png"></p><p>We founded SoftColor in 2005, so our company is now a teenager. </p>

<p>We have three products: Automata Server, Automata Pro, and PhotoEQ.</p>

<p>We are located in Joensuu, Finland. </p>

<hr><h2>Our business</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_9.png"></p><p>We sell our software on the internet. And all our products are free to try before buying.  Our customers are:</p>

<ul>
<li>Printing industry</li>
<li>Photographers</li>
<li>360 photography</li>
<li>Newspapers</li>
<li>Ad agencies</li>
<li>Repro</li>
<li>Real estate</li>
<li>Car retail</li>
<li>Photo editors</li>
<li>Office workers</li>
<li>Developers</li>

</ul>

<p>Our customers are from the English speaking world. But we have a lof customers from Germany and Spain too.</p>

<hr><h2>Our research and development</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_10.png"></p><p>Our research and development work is to make our photo editing automation software faster, more comfortable, and better to use.</p>

<hr><h2>SoftColor engine </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_11.png"></p><p>Our applications use the SoftColor engine. It is the brains and heart of our software. </p>

<p>SoftColor engine does all photo editing automation tasks, color correction, image editing, and color management. </p>

<p>To get this automation working. We have combined computer vision, color science, computer graphics, digital signal processing, and machine learning techniques into one packet. </p>

<p>This combination of different engineering tools has made our photo editing automation to work very well.</p>

<hr><h2>How does our color and tone correction work?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_12.png"></p><p>Let's check how our photo enhancement automation works, with good or bad photos. </p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_13.png"></p><p>We can fix white balance, exposure, and contrast problems automatically. Results are very natural and good looking.</p>

<p>Our correction works with challenging photos too.</p>

<p>Our white balance correction will you very natural results.</p>

<p>It works with all kinds of photos and cameras.</p>

<p>You will never lose any shots. We can fix them.</p>

<hr><h2>SoftColor and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_14.png"></p><p>Let's talk a little bit about photonics. </p>

<hr><h2>We are processing colors, not pixels.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_15.png"></p><p>To get photo editing automation working better. We have learned computers to process colors, not pixels. </p>

<hr><h2>A good photo is a combination of art and science.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_16.png"></p><p>The most challenging part of photo editing automation is to get results that make our customers happy. The problem is that the excellent photo is a combination of art and science. There is eighty percent of art in the superb picture and only twenty percent of engineering.  </p>

<p>For this problem, we managed to create an excellent solution.</p>

<hr><h2>Traditional image editing and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_17.png"></p><p>There is photonics behind every camera, display, and photo-editing algorithms. </p>

<hr><h2>SoftColor engine and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_18.png"></p><p>We have changed to traditional photo editing. We built our engine to take colors first.  This solution has helped us to make better photo enhancement automation.</p>

<hr><h2>We have made a color correction automation that has tools for science and art.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_19.png"></p><p>Our applications offer tools to our customers to combine art and science with photo editing automation. </p>

<p>Science part:</p>

<ul>
<li>Layer based processing</li>
<li>Statistical analysis </li>
<li>Metadata analysis</li>
<li>Machine vision</li>
<li>Machine learning</li>

</ul>

<p>and the arts:</p>

<ul>
<li>Color grading for mass photo processing</li>
<li>Selective color adjustments </li>
<li>No workflow limitations</li>

</ul>

<hr><h2>SoftColor engine benefits</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_20.png"></p><p>We are processing the colors, not pixels. This approach gives three significant benefits:</p>

<ul>
<li>More accurate automatic correction</li>
<li>Batch color grading for photos</li>
<li>Easier and accurate customization</li>

</ul>


<hr><h2>SoftColor engine technical details</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_21.png"></p><p>Let's take a look inside our engine.</p>

<hr><h2>Layer based processing</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_22.png"></p><p>We use layers based processing, which means that all correction and image processing tools are separate layers. </p>

<p>You will full control of how each step works. For automatic color and tone correction, we have six layers. </p>

<ul>
<li>Rich dynamics enhancer</li>
<li>Luminosity enhancer</li>
<li>White balance </li>
<li>Natural color temperature</li>
<li>Exposure and contrast</li>
<li>Color grading</li>

</ul>


<hr><h2>Spectral illumination estimation technology for better color correction</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_23.png"></p><p>To get better automatic results for all kinds of photos. We have developed spectral illumination estimation technology. </p>

<hr><h2>Same parameters for human and computer</h2>
<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_24.png"></p><p>We use spectral illumination detection to create the same parameters for the user and the computer. </p>

<p>We calculate these parameters from the original image by using:</p>

<ul>
<li>Spectral  illumination estimation from RGB image</li>
<li>Metadata analysis EXIF &amp; camera data</li>
<li>Machine learning for estimated data</li>

</ul>

<p>From this data, we generate parameters for automatic correction.</p>

<p>When users change parameters, they will alter the same settings as our automatic correction uses.</p>

<p>The solution is possible by mixing spectral illumination data with computer graphics techniques.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_25.png"></p><hr><h2>What we have learned about photonics applications during the last fifteen years</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_26.png"></p><p>There six things which we have learned. Which are the requirements for good photonics software or hardware applications.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_27.png"></p><ol>
<li>Software is the glue for photonics applications</li>
<li>Optical engineering</li>
<li>Software engineering</li>
<li>Electrical engineering</li>
<li>User experience engineering</li>

</ol>

<p>These are things and skills which are required. But there is always one challenge, battery, and CPU limitations.  It is the reason why we all need to tune our algorithms, software, and hardware better every day.</p>

<hr><h2>Bonus "homework." Useful resources for your entrepreneur career</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_28.png"></p><p>There has been a lot of questions about how to get started with the photonics business.  Here are two great resources to read or watch.</p>


<hr><h2>To watch "Halt and Catch Fire" tv-series.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_29.png"></p><p>Halt and Catch Fire is an excellent and very realistic business world tv-series.  The tv-series follows some players in the 80s technological revolution that lead to an information society. It is quite an unknown series, but now it is available in streaming services. </p>



<p>You will learn a lot about the hardware and software business. </p>

<p>The tv-series covers the following useful topics:</p>

<ul>
<li>Venture capital</li>
<li>Bootstrapping</li>
<li>Human resources</li>
<li>Risk management </li>
<li>Work/life balance</li>
<li>Legal stuff (due diligence, intellectual property rights, revenge engineering process) </li>
<li>Fortune 500 vs. startup life </li>

</ul>

<p>And there is a lot of 80s and 90s retro computing and nostalgia too.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Halt_and_Catch_Fire_(TV_series)" target="_blank">Halt and Catch Fire in Wikipedia</a>
</p>


<hr><h2>To read "Masters of Doom" book.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_30.png"></p><p>Masters of Doom book tells the story of ID software. The makers of Wolf3D, Doom, and Quake games. </p>

<p>There are fascinating stories about how small teams can change the world. For the photonics industry, there is interesting how ID software took the latest research topics from computer graphics and science. And how they utilized them to make their games better.</p>

<p>This book is also available as an audiobook.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Masters_of_Doom" target="_blank">Masters of Doom book in Wikipedia</a>
</p>


<hr><h2>Summary </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_31.png"></p><p>That was our 15 years story with software engineering, photonics, and color science. I hope that you have learned something new for photonics career or business.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_32.png"></p><p>Here is a summary of the main topics:</p>

<ul>
<li>A good photo is a combination of art and science</li>

</ul>

<ul>
<li>Software is the glue for photonics applications.</li>

</ul>

<ul>
<li>Photonics is a mixture of science, engineering, and arts.</li>

</ul>

<hr><h2>Feedback and comments</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_33.png"></p><p>
It would be great to hear your feedback about this lecture! <a href="https://www.softcolorsoftware.com/contact/">
</a></p><a href="https://www.softcolorsoftware.com/contact/">
</a><center><a href="https://www.softcolorsoftware.com/contact/">
Just drop us a message.</a>
</center>


</div></div>]]>
            </description>
            <link>https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062325</guid>
            <pubDate>Wed, 11 Nov 2020 20:02:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062055">thread link</a>) | @praveenperera
<br/>
November 11, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven‚Äôt been using Rust for production much; maybe a bit more than a year. The static type checks means I‚Äôm getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn‚Äôt have a running syslog service by default.</p>

<p>Now that‚Äôs fine, the program functioned correctly. But I don‚Äôt care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let‚Äôs take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don‚Äôt want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that‚Äôs it. This code now compiles and runs correctly. If syslog is running, it‚Äôll write logs to syslog and the terminal. Otherwise, it‚Äôll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it‚Äôs perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>132</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>132</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062055</guid>
            <pubDate>Wed, 11 Nov 2020 19:40:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion Timeline View]]>
            </title>
            <description>
<![CDATA[
Score 287 | Comments 147 (<a href="https://news.ycombinator.com/item?id=25061781">thread link</a>) | @AlphaWeaver
<br/>
November 11, 2020 | https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team | <a href="https://web.archive.org/web/*/https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061781</guid>
            <pubDate>Wed, 11 Nov 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Source Code Is Not the Whole Story: Understanding Software Through APIs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061745">thread link</a>) | @jeanyang
<br/>
November 11, 2020 | https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0b8680fe602586cc73eb"><div><p>üëã hunters!</p><p>After putting out an early iteration a few months ago, we‚Äôre excited to officially launch our private beta‚Äîand to make our docs public for the first time!</p><p>And we'd like to give a big thank-you to all the users and friends of Akita who got us here. üòä<br></p><h2><strong>üöó How we got here</strong></h2><p>In 2018, I was a <a href="http://jeanyang.com/">CS professor at Carnegie Mellon University</a>. When Cambridge Analytica hit, I started asking friends in industry how they knew what data their apps were sending around. It turned out that there was no good solution for understanding interactions across APIs‚Äînot just for privacy and security but also for reliability and diagnostics. When I realized that this was the exact problem I‚Äôd been teeing up to solve, I took leave from my job, sold my furniture, and drove across the country to start Akita.</p><p>There is now a small team of us working on Akita, coming from places like Twilio and Amazon. Our team‚Äôs experience building in service-oriented environments made everyone especially excited to build a product that would help developers move faster together.</p><h2><strong>üîé Source code isn‚Äôt the whole story.</strong></h2><p>At Akita, we believe the way to understand your software is through your APIs. Our solution builds dynamic models of API behavior to automatically:</p><p>‚úÖCatch breaking changes on every pull request<br>‚úÖGenerate specs for any API<br>‚úÖUpdate API specs on every pull request<br>‚úÖDiscover and document endpoints</p><h2>üèó <strong>How we built it</strong></h2><p>From the beginning of Akita, I knew where I wanted us to go: automatically map out the graph of API interactions. This would be key to improving reliability, diagnostics, and security in modern web apps.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605055841399_25008"><div><p>What we didn‚Äôt know was exactly how we would get there. Should we integrate with a tracing library? Should we build a proxy?</p><p>After <a href="https://blog.sigplan.org/2020/10/27/whats-the-role-of-developer-experience-in-programming-languages-research/">talking with dozens of developers and engineering leaders</a>, we came up with three main requirements. First, whatever we built needed to work with any tech stack. Second, people needed to be able to integrate our solution in minutes. Finally, we wanted something that could run in production without adding overhead or exposing sensitive data. These were not easy requirements to balance!</p><p>After over a year of building, we‚Äôre super excited to launch a solution that requires no code changes, no proxies, works with any language, and integrates in just minutes. Akita works by watching API traffic, analyzing, and sanitizing the traffic locally to share only metadata back to our cloud. This means you can Akita deploy Akita anywhere: your laptop, CI/CD, or production‚Äîwithout having to worry about us seeing your data. We are really proud of our approach and believe it is the future of cloud observability.</p><p>And for those who are curious, our tech stack is Go, typed Python, and React. üòä</p><h2><strong>üíñ Let‚Äôs make software development better</strong></h2><p>We believe that Akita can help anybody with a web app who wants to move quickly without losing customers. We understand that we have a long way to go to achieve the vision‚Äîand that the only way to get there is by getting feedback early and often from people like you.</p><p>We‚Äôd love to have you <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_private_launch&amp;utm_medium=blog&amp;utm_source=2020_11_11_producthunt">try out the private beta</a>! We‚Äôll also be checking the comments on <a href="https://www.producthunt.com/posts/akita-private-beta">ProductHunt</a> for feedback and questions. We look forward to hearing from you.</p><p>Onward ‚ö°Ô∏è,<br>Jean Yang (<a href="https://www.linkedin.com/in/jean-yang-96575030/">LinkedIn</a>; <a href="https://twitter.com/jeanqasaur">Twitter</a>)<br>Founder and CEO, Akita Software</p><p>P.S. Thank you to the veterans out there!<br>P.P.S. Follow our updates and tell us what you think on Twitter <a href="https://twitter.com/AkitaSoftware">@AkitaSoftware</a>!</p></div></div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061745</guid>
            <pubDate>Wed, 11 Nov 2020 19:12:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gantt Charts Arrive in Notion]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061649">thread link</a>) | @saviorand
<br/>
November 11, 2020 | https://optemization.com/timeline-view-notion | <a href="https://web.archive.org/web/*/https://optemization.com/timeline-view-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-timeline-view-notion"><blockquote id="block-659ced01cffc486ca3fa1b6e01fb482d"><span><span>It's about time: gantt charts, page customization and more arrive to Notion ‚Äî
here's our breakdown.</span></span></blockquote><div id="block-9ce0f17fa5904c5ba88176d78f03d8ff"><div id="block-f4c2486805a1467cb60c4a5aa1db40e5"><p><span><span>Hello there! Welcome to </span><span><em>Digital Opsessions</em></span><span> issue #0003</span></span></p></div></div><div id="block-e49dbd8e89f34444b7a9118c475aa629"><div id="block-2c66366dc9994fae8d874f1f30735471"><p><span><span>Today, marvelous talents at Notion decided to make it a bright Wednesday for us and share three major updates in the app! As part of the Notion Ambassadors group, we were fortunate enough to beta test these features and help spread the announcement news. </span></span></p><p><span><span>Here's what's up </span></span></p></div></div><div id="block-d85f6c16c65a4a098d6794d204a0267b"><div id="block-67d522c072b8469b8543221c3b19634a"><p><span><span>It has been a loooong dark 469 days since this Tweet has swept the world of project management. Frankly, it feels like the gap between season seven and season eight of the Game of Thrones. Only this time, you're going to be very happy. </span></span></p><p><span><span>Now that I think about it: Pfizer's vaccine announcement to COVID-19 is like Arya to the Night King (if you know what I mean ‚Äî </span><span><span><span>no spoilers</span></span></span><span>). </span></span></p></div></div><h2 id="block-8854e6d47bc8427ba082691fcd7e95e6"><span id="8854e6d47bc8427ba082691fcd7e95e6"></span><span><span>How to Timeline View</span></span></h2><p><span><span>Starting today, you will see the timeline view option show up in all your databases and linked database views. This is how it looks like:</span></span></p><div id="block-cb36fbb3f3d742e59a7052a3434dc403"><picture><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Here are some main configuration options to be aware of.</span></span></p><h3 id="block-3a98d91ea0c7408b9d38b302d0a9cf96"><span id="3a98d91ea0c7408b9d38b302d0a9cf96"></span><span><span>Timeline by</span></span></h3><p><span><span>Just like with board and calendar views, you can choose what dates the Timeline view indexes by. </span></span></p><div id="block-056fc67a35f34ed38fe2deff5ea12a8b"><picture><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>In our case, we're arranging our content calendar by two date properties. To do that, toggle the </span><span><code>use separate start and end dates</code></span><span> option. We also like to enter both start and end dates in one property, but needed filtered visibility in the view. 
So we added a two simple formula properties:</span></span></p><ol><li id="block-f89f02f1bac2425789e0f9ecddeee9f4"><span><span>Start date: </span><span><code>start(prop("Promotion Dates"))</code></span></span></li><li id="block-7861a869b8284263831a9a9b58104177"><span><span>End date </span><span><code>end(prop("Promotion Dates"))</code></span></span></li></ol><div id="block-afad72a4ccbe4f1580bd7a0f1f142601"><p><span><span>Note that the "timeline by" setting will </span><span><strong>not</strong></span><span> sort your records chronologically by default. You need to enable this option if you need it.</span></span></p></div><h3 id="block-afa3f89aff864e099417bc191809b611"><span id="afa3f89aff864e099417bc191809b611"></span><span><span>Show table </span></span></h3><p><span><span>For the first time in Notion databases-and-views history you can fully hide the table! That comes in handy with timeline view ‚Äî if you just want to see that beautiful timeline. 
You'll also notice that you can limit the amount of records that show up without filtering, but more on that below</span></span></p><div id="block-2f1dc0d7047146d095c018880c646883"><picture><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-2f419ddfbd474c8e9744b4b41831f8f7"><span id="2f419ddfbd474c8e9744b4b41831f8f7"></span><span><span>The Good / The Bad</span></span></h2><div id="block-98a043c9f3d54cbfaf16507beddb2f56"><picture><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-3595a6e3558e48f9815ea8277e41a6dd"><span id="3595a6e3558e48f9815ea8277e41a6dd"></span><span><span>Things we love</span></span></h3><p><span><span><strong>Moving multiple date-specific records is seamless</strong></span><span>. Now, if you need to adjust a project timeline that has multiple pieces to it, whether its tasks, milestones, or events, you can just select them all, drag and all the dates will adjust accordingly. We use this, for example, to adjust whole complex project schedules to start from a given date ‚Äî very handy!</span></span></p><div id="block-633f34747c1f45bb9bcd4b392939fe48"><picture><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Hiding the property table is possible! </strong></span><span>If you'd like to see the timeline view in its full glory you can now toggle the table on and off. In the other Notion views, you cannot hide the main "Name" / ID property. </span></span></p><div id="block-50d1fed52f7c4101beb7d215660af070"><picture><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>You can timeline by separate properties. </strong></span><span>The default Notion date property does not allow filtering or sorting by the date range. It uses the start date. That can be tricky and annoying when you want to filter your timeline view. Luckily, you have the option to timeline by separate fields!</span></span></p><div id="block-e347aea8615f4fb68f3dd07579d1d4af"><picture><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-b01c6b44c6eb42b8a0e4d062c85b586f"><span id="b01c6b44c6eb42b8a0e4d062c85b586f"></span><span><span>Things we hate</span></span></h3><p><span><span><strong>Data overflow: </strong></span><span>Items look bad when you show more than one property in the timeline, or when an event takes place on a single day (then item is just a small white dot, and text overflows). When more than a few properties toggled on the timeline, the UI of each becomes visible cluttered. For both the table and timeline, a "wrap cells" options would be great.</span></span></p><div id="block-b126bbb5b6e546db81fe1c95982de683"><picture><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Only full width. C</strong></span><span>urrently timelines with a table toggles "on", do not adjust to standard width.That's annoying because for some it might be useful to see the table and timeline on the standard width.</span></span></p><div id="block-9c638003ac144730b036479a2d56bf6c"><picture><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Paid plans limits</strong></span></span></p><div id="block-4058fc818edf482ab647cb0d6a4790ba"><div id="block-6c4afe4fb0934ecba8c9d341c6e955e9"><div id="block-6fc04eb8d9bf427c81b524a58a270ae5"><picture><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" alt="image" loading="lazy"></picture></div></div><div id="block-ad57120d749247d08823002a95441e09"><p><span><span>With the introduction of Timelines, Notion team added a new pricing tweak ‚Äî a limit on the number of Timelines you can use. You can only add 3 timelines on a Personal plan and up to 5 on Team plan. For unlimited timelines you have to buy Enterprise</span></span></p></div></div><p><span><span>We managed to lay our hands on the Timeline view before the release, and had the chance to prepare this proposal template with a Gantt chart included!</span></span></p><p><span><span>It's easy to try ‚Äî just duplicate it into your workspace and drag all milestones, meetings, deliverables and billing activities to your project's start date. Voila! You now have a complete, detailed project schedule aligned with your preferred dates.</span></span></p><p><span><span>You can change any part of this template ‚Äî remove or add new records, change default structure, introduce new types of project activities, such as legal (marking the date when the contract is signed), holidays, events.</span></span></p><p><span><span>We use this template ourselves to spin up new client proposals ‚Äî it saves tons of time on routine editing and allows us to focus on things that are essential, like pain points we help clients address, or our unique approach. </span></span></p><p><span><span>Making these kinds of documents in Notion is enjoyable ‚Äî you can templatize pretty much any common structure. If the lack of Gantt Charts is something that was stopping you from going all-in on Notion, now is the time. </span></span></p><h2 id="block-3c4bd798e6b34e7abd3977fbe0825efb"><span id="3c4bd798e6b34e7abd3977fbe0825efb"></span><span><span>Get the template!</span></span></h2><h3 id="block-f851a8c9110c4392a445c1f5aa42fd57"><span id="f851a8c9110c4392a445c1f5aa42fd57"></span><span><span>Properties</span></span></h3><p><span><span>Power users know that complex. data-heavy workflows in Notion were tough to work with so far. When making structures that's more sophisticated than a simple "Basic CRM" workflow, properties tend to pile up ‚Äî at some point, when opening a page, you don't see its content on the first screen, just properties.</span></span></p><p><span><span>Not anymore! Now you can hide properties you don't use and get straight to that page content every time you open a page. </span></span></p><div id="block-1fd0baefcc3d4939af7c1f0dcf418a19"><picture><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" alt="image" loading="lazy"></picture></div><p><span><span>The best part is that you can set up advanced rules on when to show or hide specific properties ‚Äî for example, you can show a property only when it's not empty for the current page, or always hide a specific property on a page (you can always open it up manually).</span></span></p><div id="block-6b34b9caaab340d9a69316d845cee4cb"><picture><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" alt="image" loading="lazy"></picture></div><h3 id="block-e0e751d263f64ecc9596b3e091381dd9"><span id="e0e751d263f64ecc9596b3e091381dd9"></span><span><span>Comments, Backlinks</span></span></h3><p><span><span>It's simple with comments ‚Äî you can just hide them for a page. Same with backlinks, but you can also select "Show in a popover". That option will display a small "X backlinks" button indicating how many backlinks a page has. Then you can press that button and view the backlinks.</span></span></p><div id="block-3e1f67ea498d4fa0ad79e33295222f8e"><picture><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" alt="image" loading="lazy"></picture></div><p><span><span>This functionality allows to keep any workspace clean, and the main use case is for large organizations managing tons of data. </span></span></p><p><span><span>Previously, when you shared access to a page with someone, they would automatically get access to all the subpages in it. Now when you open up a subpage you can see exactly what page it inherits permissions form ‚Äî and then change permissions for this specific subpage.</span></span></p><div id="block-87a9344e6a4a4313aaa9430e7ef34cdc"><picture><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" alt="image" loading="lazy"></picture></div><p><span><span>This is useful when you have private pages that live inside a larger page ‚Äî and you want to share the parent one without sharing these specific private pages. Think company's internal wiki with a subpage that contains sensitive data. </span></span></p><p><span><span>You can also add group permissions ‚Äî Notion team mentions the use case of giving Engineering team access to most of the workspace except a couple read-only pages.</span></span></p><p><span><span>Notion will now show you a "Show X records" option when working with database settings ‚Äî and will clip all the records above the number selected. Previously, if you had a huge database, it will display all the records in an infinite scroll as you move down the page ‚Äî this might have been okay for small databases, but quickly got hard to manage with additional information load.</span></span></p><p><span><span>Timeline view, page customization, advanced permissions and row number limits ‚Äî all of this seems to be targeting enterprise users, who need more control over large setups, Notion team is obviously hitting the nerve with big teams here. </span></span></p><p><span><span>Some features will also be handy for small teams and individual makers ‚Äî authors can use the timeline view to manage their content editorial, freelancers can use it to control their work load. Advanced customization is valuable for anyone who keeps data in Notion.</span></span></p><div id="block-35eebc7612e34ff79f23e056bf85977e"><div id="block-ca65c34a263e4c7881ef4767fca59df4"><p><span><span>The </span><span><em>Digital Opsessions</em></span><span> newsletter helps you figure out how to use digital productivity systems, tools and habits to free up time, energy and focus </span><span><span>for more important or fun </span></span><span>things in life.</span></span></p><p><span><span><strong>Subscribe + share</strong></span><span> </span><span><span><span>(if you haven't already)</span></span></span><span> üëâ</span></span></p></div></div></article></div></div></div>]]>
            </description>
            <link>https://optemization.com/timeline-view-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061649</guid>
            <pubDate>Wed, 11 Nov 2020 19:05:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AndroWish ‚Äì run desktop Tcl/Tk programs almost unaltered on the Android Platform]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25061292">thread link</a>) | @jakobdabo
<br/>
November 11, 2020 | https://www.androwish.org/index.html/home | <a href="https://web.archive.org/web/*/https://www.androwish.org/index.html/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody><tr><td>
<p>Tcl (Tool Command Language) is a very powerful but easy to learn dynamic programming language, suitable for a very wide range of uses, including web and desktop applications, networking, administration, testing and many more. Open source and business-friendly, Tcl is a mature yet evolving language that is truly cross platform, easily deployed and highly extensible.

</p><p>Tk is a graphical user interface toolkit that takes developing desktop applications to a higher level than conventional approaches. Tk is the standard GUI not only for Tcl, but for many other dynamic languages, and can produce rich, native applications that run unchanged across Windows, Mac OS X, Linux and more. 

</p><p>AndroWish allows to run desktop Tcl and Tk programs almost unaltered on the Android Platform while it opens the door to script a rich feature set of a mobile platform. Its sibling <a href="https://www.androwish.org/index.html/wiki?name=undroidwish">undroidwish</a> uses the same code base and  offers a similar feature set on various desktop and embedded platforms.

</p></td><td>
<img width="160px" height="160px" src="data:image/png;base64,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">
</td></tr>
</tbody></div><p>The current AndroWish-debug.apk can be downloaded <a href="https://www.androwish.org/download/AndroWish-c48f047f5b-debug.apk">here</a> (about 36 MByte, requires "install from unknown sources" in Android settings). Prehistoric versions are <a href="http://www.ch-werner.de/sdltk/AndroWish">still available here</a>.


</p></div>]]>
            </description>
            <link>https://www.androwish.org/index.html/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061292</guid>
            <pubDate>Wed, 11 Nov 2020 18:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061259">thread link</a>) | @haunter
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can‚Äìand should‚Äìbe better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we‚Äôll be more transparent with what‚Äôs happening and what tools and resources we‚Äôre building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won‚Äôt be a brief post. We‚Äôll do our best to keep the legalese to a minimum, though there‚Äôs bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (‚ÄúDMCA‚Äù) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators‚Äô archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don‚Äôt expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven‚Äôt already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn‚Äôt include all the information that you‚Äôd typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You‚Äôre rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn‚Äôt is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries ‚Äì that was a miss as well. We‚Äôre truly sorry for these mistakes, and we‚Äôll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we‚Äôve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don‚Äôt play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you‚Äôre unsure whether you own all the rights, it‚Äôs pretty likely you don‚Äôt. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven‚Äôt received more than a handful of DMCA notifications targeting in-game music, if you‚Äôre playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game‚Äôs official EULA online and then do a ctrl+f (Command+f on Mac) search for words like ‚Äústream,‚Äù ‚Äúlicensed,‚Äù and ‚Äúmusic‚Äù to point you toward the correct sections. If you‚Äôre unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the ‚Äúdelete all‚Äù tool we‚Äôve provided. We understand both of these options have downsides, and we‚Äôre working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we‚Äôre committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won‚Äôt be visible to the community, but we‚Äôre focused on three areas where we heard you need more support from us:</p>

<p>First, you don‚Äôt have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a ‚Äúdelete all‚Äù option.</p>

<p>Second, we‚Äôll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we‚Äôll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we‚Äôve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content‚Äìfor example, because you‚Äôve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don‚Äôt have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don‚Äôt have recorded music as a part of their streams, and the revenue implications to creators of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061259</guid>
            <pubDate>Wed, 11 Nov 2020 18:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyxt Release 2 Pre-release 4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061101">thread link</a>) | @jmercouris
<br/>
November 11, 2020 | https://nyxt.atlas.engineer/article/release-2-pre-release-4.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/release-2-pre-release-4.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Nyxt 2 Pre-release 4</title>
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>

</header>
<p>We are happy to announce the fourth pre-release of Nyxt version 2.0.0. If you missed the previous pre-release announcement, see <a href="https://nyxt.atlas.engineer/article/release-2-pre-release-3.org">here</a>.</p>
<p>Nyxt 2 is a massive overhaul of the Nyxt 1 series. A lot of effort has been geared towards improving the code quality under the hood which should reflect on the overall user experience with better performance, increased stability and better accessibility.</p>
<p>This is a test release for everyone to try out before the final release. It contains experimental features and some parts are still unfinished. Please feel free to share your feedback on our <a href="https://github.com/atlas-engineer/nyxt/issues">GitHub issue tracker</a>!</p>
<p>Notable highlights:</p>
<ul>
<li><p>Overhauled status area view to resemble powerline.</p>
<ul>
<li>Hold <code>shift</code> to scroll the tabs horizontally.</li>
</ul></li>
<li><p>New <code>dark-mode</code> (experimental).</p></li>
<li><p>New universal package manager interface.</p>
<p>Install, uninstall, describe packages, list their files, change generations, etc. See the various <code>*-package-*</code> and <code>*-generation-*</code> commands.</p>
<ul>
<li><p>Currently only interfaces the Guix package manager.</p></li>
<li><p>Help to implement additional backends is welcome!</p></li>
</ul></li>
<li><p>New <code>nowebgl-mode</code>.</p></li>
<li><p>New <code>nyxt-init-file</code> helper to derive a file name relative to the Nyxt configuration folder.</p></li>
<li><p>No longer ask to restore session when there is none.</p></li>
</ul>
<p>For the complete change list, please consult the <a href="https://github.com/atlas-engineer/nyxt/blob/2-pre-release-4/documents/CHANGELOG.org#2-pre-release-4">CHANGELOG.org</a> file.</p>
<p>We hope you enjoy these new features, and that they help make you more productive. Thanks for reading :-)</p>

<h2 id="nyxt-powerline">Nyxt Powerline</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/status-area.png"></p>
<h2 id="package-manager">Package Manager</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/describe-os-package.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/git-package.png"></p>
<h2 id="dark-mode">Dark Mode</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-normal.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-dark.png"></p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/release-2-pre-release-4.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061101</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Homelab with Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25061097">thread link</a>) | @amitpm
<br/>
November 11, 2020 | https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/ | <a href="https://web.archive.org/web/*/https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>I‚Äôve been running <a href="https://pi-hole.net/">Pi-Hole</a> on a Raspberry Pi 3b wired into my wifi router for most of last year and its been great. So when the new Raspberry Pi 4 came out, I picked one up. It sits on my desk, mostly for easy access to its USB ports, which allows me to hook it up to some of my esp32 devkits and push micropython code onto them. The pi4 has been a great general purpose development environment.</p><p>Recently, I‚Äôve been wanting to write some trivial web endpoints for ‚Äúinternal‚Äù dashboards and such for the house. Plus, its a great excuse to learn Golang. In this day and age, clearly a dockerized golang dev environment is the way to go. Have I truly built something, if my dev environment isn‚Äôt dockerized?</p><p>So we‚Äôre agreed that dockerizing my dev environment is the way to go. Surely if my dev environment is dockerized, how much more should my app deployments use containers? Nothing less will do. But now I need a way to deploy and orchestrate said containers? I know! I should run a kubernetes cluster across my two Pi‚Äôs! Might as well run the Pi-hole on it as well, how hard can it be?</p><p>So that is what I spent the better part of last week figuring out.</p><figure><img src="https://imgs.xkcd.com/comics/automation.png" alt="Mandatory xkcd"><figcaption><center>Mandatory xkcd</center></figcaption></figure><p>This blog post walks through what I did, and how I did it, It‚Äôs purpose is two-fold -</p><ol><li>It is a map to allow me to retrace my steps if I need to</li><li>Perhaps it may prove of (dubious) use to you.</li></ol><p>So, both my Pi‚Äôs run Ubuntu server. I decided I should start from scratch, and flashed the latest ubuntu server image onto the SD cards for both Pi‚Äôs. Being a very optimistic person by nature, I expected to have Pi-hole back up and running on this new Kubernetes cluster within a day, and a day of unfiltered ads was a small price to pay for the experience. Alas, it was close to a week before I had Pi-Hole working on my network again, but yay! you get to learn from my experience!</p><p>I didn‚Äôt have much of an understanding of Kubernetes components going into this project - but hey, that‚Äôs what these projects are meant to give you, and boy, did it. So fret not if you don‚Äôt understand some of these terms, the kubernetes documentation pages are great!</p><p>None of this work is original. I cobbled together guides and walkthroughts from various sources to get to this frankenstein‚Äôs monster of a post that you see here. You can find links to the sources I used at the end of this page.</p><p>The first step to this journey involves making sure you have the required packages on all your machines. In my case, this was two machines - the Pi4 (called Terminus) and the Pi3b (called Trantor). You need <code>docker</code>, <code>kubelet</code>, <code>kubeadm</code> and <code>kubectl</code>. You want this installed on all your nodes. Terminus will be my master node, Trantor will be my worker. Asimov fans may protest that the Second Foundation was on Trantor after all, but let‚Äôs go with this for now. Setting static IPs on the master and workers on your cluster also helps, but I won‚Äôt cover that here.</p><p>Update apt repos and packages.</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get upgrade
</code></pre></div><p>Install Docker using the Convenience script. Yes, shame on you for blindly running a script you downloaded from the internet.</p><div><pre><code data-lang="bash">curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
</code></pre></div><p>Let‚Äôs make sure our non-root user can use Docker.</p><div><pre><code data-lang="bash">sudo usermod -aG docker $USER
</code></pre></div><p>Now there‚Äôs some additional setup that needs to be done in order to get Kubernetes to work on the Raspberry Pi - specifically enabling <code>cgroups</code>. You can do this by editing the file <code>/boot/firmware/cmdline.txt</code> and adding the following options at the end.</p><pre><code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 swapaccount=1
</code></pre><p>You‚Äôll need to reboot the Pi after this.</p><p>Add the K8s apt repo.</p><div><pre><code data-lang="bash">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

cat <span>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span><span>deb https://apt.kubernetes.io/ kubernetes-xenial main
</span><span>EOF</span>
</code></pre></div><p>You‚Äôll notice we‚Äôre using <code>kubernetes-xenial</code> which was the latest release at the time of writing this. Update this to the latest release available if you need to.</p><p>Let‚Äôs install our main K8s helpers. We‚Äôll also make sure they‚Äôre excluded freom any system upgrades. As the kubernetes <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">documentation</a> says, ‚Äú<code>kubeadm</code> and <code>kubectl</code> require special attention to upgrade.‚Äù</p><div><pre><code data-lang="bash">sudo apt update <span>&amp;&amp;</span> sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre></div><figure><img src="https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.png" width="200" height="200"></figure><p>Create the cluster by running the following commands on the master node only. Pay special attention to the <code>--pod-network-cidr</code> parameter. You‚Äôll need this CIDR range later on when setting up Flannel.</p><div><pre><code data-lang="bash"><span># Create the bootstrap token</span>
TOKEN<span>=</span><span>$(</span>sudo kubeadm token generate<span>)</span>
sudo kubeadm init --token<span>=</span><span>${</span>TOKEN<span>}</span> --pod-network-cidr<span>=</span>10.10.0.0/16
</code></pre></div><p>Congratulations. You are now the proud owner of a bare-metal kubernetes cluster (with one node). Admire the output, and consider running the commands they ask you to. For example, you‚Äôll need a config file in <code>$HOME/.kube/config</code> if you want <code>kubectl</code> to work without too much hassle. Also make special note of the <code>kubeadm join</code> command as well, you‚Äôll need to run that on your worker nodes.</p><p>These are the commands that the output from the previous step suggest you to run. Run this on the master node, in case that isn‚Äôt clear.</p><div><pre><code data-lang="bash">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown <span>$(</span>id -u<span>)</span>:<span>$(</span>id -g<span>)</span> $HOME/.kube/config
</code></pre></div><p>Go run the <code>kubeadm join</code> commands on all the worker nodes you‚Äôd like to dedicate to this cluster. I‚Äôll wait.</p><p>Going through this guide, you‚Äôll quickly become familiar with the command <code>kubectl apply</code>. This command ‚Äúapplies a configuration to a resource‚Äù in kubernetes parlance and is typically provided a YAML ‚Äúmanifest‚Äù file as parameter.</p><p>So now we have a cluster, but technically Kubernetes doesn‚Äôt know how to handle networking between any pods that are scheduled on this cluster - atleast, that‚Äôs what I‚Äôve understood. This is why you need an addon like Flannel to handle this for you. You can find a full list of Networking and Network Policy Addons <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">here</a>. But in case it isn‚Äôt clear yet, we‚Äôll use Flannel.</p><figure><img src="https://raw.githubusercontent.com/coreos/flannel/master/logos/flannel-horizontal-color.png"></figure><p>If you‚Äôve specified a <code>pod-network-cidr</code> parameter when creating your cluster, you‚Äôll need to edit the Flannel manifest with this CIDR before you apply it to the cluster.</p><p>Let‚Äôs download the default flannel manifest</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml --output kube-flannel-updated.yml
</code></pre></div><p>Open it the file up in your favourite editor, and find the key <code>net-conf.json</code>. Update the CIDR given there with the right CIDR for your cluster. Once done, apply the manifest like so.</p><div><pre><code data-lang="bash">kubectl apply -f ./kube-flannel-updated.yml
</code></pre></div><p>To check if this worked, run the following command to get all pods running on your cluster.</p><p>You should see <code>core-dns</code> and <code>kube-flannel</code> pods running like so. I have two pods for each because I have two nodes in my cluster.</p><div><pre><code data-lang="bash">NAMESPACE              NAME                                          READY   STATUS    RESTARTS   AGE
kube-system            coredns-f9fd979d6-h9m47                       1/1     Running   <span>1</span>          3d2h
kube-system            coredns-f9fd979d6-m5jrd                       1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-2ngxd                         1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-kqflv                         1/1     Running   <span>1</span>          3d2h
</code></pre></div><p>Namespaces are used to isolate pods and services running on the same cluster. My data engineer brain thinks of the cluster as a database and namespaces as schemas, but I could be mistaken and maybe should be thinking of the cluster as a single database install, and the namespaces as individual databases. Or maybe, this is entirely the wrong abstraction to bring in. Scratch all of this, let‚Äôs move on.</p><p>We now have a cluster, that knows how to handle pod networking. Let‚Äôs run something on it! How about the <a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">Kubernetes dashboard</a>, so that you have something pretty to show your non-technically inclined significant other as the output of your hard work?</p><figure><img src="https://raw.githubusercontent.com/kubernetes/dashboard/master/docs/images/dashboard-ui.png" alt="Behold! The fruits of your labour!"><figcaption><center>Behold! The fruits of your labour!</center></figcaption></figure><p>We‚Äôll create a namespace to hold everything related to the Kubernetes Dashboard. I‚Äôm calling the namespace - <code>kubernetes-dashboard</code>. Very imaginative, no?</p><div><pre><code data-lang="bash">kubectl create namespace kubernetes-dashboard
</code></pre></div><p>We‚Äôll now download the manifest file for Kubernetes dashboard, because we need to make some changes.</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml --output kubernetes-dashboard.yaml
</code></pre></div><p>I spent a few days trying to figure out why the manifest did not work out of the box, it kept failing when trying to pull the docker image. I worked around this by doing two things -</p><ol><li>Ran <code>docker pull kubernetesui/dashboard:v2.0.0</code> to cache a local copy of the docker image.</li><li>Commented out the <code>imagePullPolicy: Always</code> in the manifest file under the <code>kubernetes-dashboard</code> deployment block.</li></ol><p>For the more K8s experienced among you, you may be wondering why I did not try using the Helm chart - I did. Kubernetes-dashboard needs to run two services - <code>dashboard-metrics-scraper</code> and <code>kubernetes-dashboard</code>. The Helm chart only seemed to bring up <code>kubernetes-dashboard</code>. I‚Äôm sure I must be doing something wrong, but at this point my patience was wearing thin and I just wanted to get on with it.</p><p>Ok, so now we have an edited manifest, let‚Äôs apply it.</p><div><pre><code data-lang="bash">kubectl apply -f kubernetes-dashboard.yaml
</code></pre></div><p>It takes a little bit of time for the dashboard to come up. You can amuse yourself by looking at the pods as they spin up as follows -</p><div><pre><code data-lang="bash">watch kubectl get pods -n kubernetes-dashboard
</code></pre></div><p>You can get details on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl describe pod &lt;pod_name&gt; -n kubernetes-dashboard
</code></pre></div><p>You can also tail logs on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl -n kubernetes-dashboard logs &lt;pod_name&gt; -f
</code></pre></div><p>Once you see the dashbaord services up and running, let‚Äôs figure out how we actually get access to the dashboard UI.</p><p>We‚Äôll assume that you haven‚Äôt configured kubectl on your local machine and are instead, running all these commands from your (headless) raspberry pi.</p><p>Run <code>kubectl proxy</code> first. This exposes the cluster API server over HTTP to the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</a></em></p>]]>
            </description>
            <link>https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061097</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking Structured Interviewing: Hiring for Jobs You Don't Understand]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061052">thread link</a>) | @nickpresta
<br/>
November 11, 2020 | https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/ | <a href="https://web.archive.org/web/*/https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Have you ever hired for a job you didn‚Äôt understand? It‚Äôs scary. If you don‚Äôt know how to do the job yourself, how can you assess what a strong candidate looks like?</p>

<p>In this post, we‚Äôll see how to modify a well-researched interview methodology to quickly build a process  that helps you hire for the unknown in 4 steps. And, in the spirit of incrementalism, you‚Äôll have something useful after each step.</p>

<!--more-->

<p>(This post was also published as a series of articles on LinkedIn. See part <a href="https://www.linkedin.com/pulse/hacking-structured-interviewing-hiring-jobs-you-dont-part-dibernardo/">one.</a>)</p>

<h2 id="different-people-same-problem">Different People, Same Problem</h2>

<p>A couple of weeks ago, I spoke to two very different people who had the same problem. The first was a senior engineering leader at a ~300 person company who needed to hire a data analytics lead, a role that was very unfamiliar to them. The second was a founder who was hiring their first software engineer.</p>

<p>They were pretty stressed about it. Perhaps you can relate.</p>

<p>In my experience, people tend to approach this problem in one of two ways:</p>
<ol>
  <li>‚ÄúWe don‚Äôt know how to hire for this position, and we could spend a lot of time creating an interview process that doesn‚Äôt even work. We should hire based on ‚Äòculture fit‚Äô, which we can figure out by getting to know them. Sometimes we have to take risks.‚Äù</li>
  <li>‚ÄúWe don‚Äôt know how to hire for this position, It would be very expensive to hire the wrong person. We should create an exhaustive interview that assesses everything needed in this role, since this is a foundational hire. We don‚Äôt want to take too many risks.‚Äù</li>
</ol>

<p>These are both natural reactions. Both have clear downsides, and my experience is that both can easily lead to bad hiring decisions. So, perhaps the lesson is that if these are your only options, it‚Äôs probably better to take the former!</p>

<p>However, I think we can do better.</p>

<p>With a few hours of work, we can build a process that:</p>
<ul>
  <li>Reduces hiring risk</li>
  <li>Reduces bias and unfairness</li>
  <li>Creates a good experience for both candidate and the interviewers</li>
</ul>

<p>Furthermore, you can have something <em>usable</em>‚Äînot great, but usable‚Äîin under an hour.</p>

<p>How will we do this?</p>

<p>Starting from scratch would take too long. Luckily, there‚Äôs a lot of research-based practice that we can hack to make a good first hire without prohibitive effort.</p>

<p>In this article, we‚Äôll look to and oldie-but-goodie as a guide.</p>

<h2 id="hacking-structured-interviewing">Hacking Structured Interviewing</h2>

<p>Structured interviewing is a hiring methodology that has been heavily researched and practices for decades. Google has summarized the research and their own experiences with it on <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/introduction/">re:work</a>, which is a super useful resource that I‚Äôve often referred to.</p>

<p>In their introduction to the topic, the writers state:</p>

<blockquote>
  <p>Structured interviewing simply means using the same interviewing methods to
assess candidates applying for the same job. Research shows that structured
interviews can be predictive of candidate performance, even for jobs that are
themselves unstructured.</p>
</blockquote>

<p>Sounds great! If we‚Äôre hiring this role for the first time, the job is likely to be pretty unstructured.</p>

<p>However, in the very next paragraph, we read:</p>

<blockquote>
  <p>So why don‚Äôt more organizations use structured interview questions? Well,
they are hard to develop. You have to write them, test them, and make sure
interviewers stick to them.</p>
</blockquote>

<p>Oof. And here I am assuring you this won‚Äôt take long. Maybe it‚Äôll just be easier to go with what you were originally planning. After all, how hard can it be?</p>

<p>Well:</p>

<blockquote>
  <p>Research has also shown that structured interviews aren‚Äôt more frequently used because, in general, interviewers everywhere think they‚Äôre good at interviewing and don‚Äôt need the help. Surely many of us like to think we‚Äôre excellent judges of character.</p>
</blockquote>

<blockquote>
  <p>But when it comes to hiring, don‚Äôt trust your gut. Research shows that during first encounters we make snap, unconscious judgments heavily influenced by our existing unconscious biases and beliefs. For example, in an interview context, without realizing it, we shift from assessing the complexities of a candidate‚Äôs competencies to hunting for evidence that confirms our initial impression. Psychologists call this <em>confirmation bias</em>.</p>
</blockquote>

<p>This cautionary clause helps us define our design problem.</p>

<p>We want to <em>quickly</em> create a hiring process that reduces our confirmation bias, because that will lead to better decisions.</p>

<p>The resources in re:work help with the confirmation bias part, but they don‚Äôt show us how to do it quickly. Let‚Äôs see how we can hack what they‚Äôve shown us to get some speed out of it.</p>

<h2 id="the-raw-materials">The Raw Materials</h2>

<p>There are a handful of <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/know-the-components/">key elements</a> to a structured interview:</p>

<ol>
  <li>A small set of <strong>competencies</strong> that we‚Äôre looking for from candidates.</li>
  <li>Standard <strong>questions</strong> that test those competencies.</li>
  <li>Comprehensive <strong>feedback</strong> gathered by interviewers asking the questions.</li>
  <li>A <strong>rubric</strong> that helps interviewers consistently deliver their feedback.</li>
</ol>

<p>That seems like a lot to consider. However, this short list helps focus our hacking on techniques that are known to work.</p>

<p>We‚Äôre going to transform this list into a 4-step recipe for your own structured interview process. In the spirit of incrementalism, you‚Äôll have something useful after each step.</p>

<p>If you follow the whole thing, it should take about 3-4 hours.</p>

<h2 id="step-1-define-competencies">Step 1: Define Competencies</h2>

<p>Take 15-30 mins. and come up with a list of 3-5 <em>competencies</em> that are important in this role.</p>

<p>It can be tempting to pick more than that, but please start small. If Google can reduce their hiring criteria to <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/define-hiring-attributes/">4 competencies</a>, I think we can get there too.</p>

<p>Each one should have a short 1-3 word ‚Äúslug‚Äù that captures its spirit, and a sentence or two to describe what it means in more detail.</p>

<p>If you‚Äôre not sure how to start, you can hack this boring-but-effective list:</p>

<ol>
  <li><strong>Technically Skilled.</strong> Has the hard skills and knowledge required to do the job well.</li>
  <li><strong>Effective Communicator.</strong> Talks about their work in a way that we understand and trust.</li>
  <li><strong>Has Soft Skills We Value.</strong> There are certain strengths or skills that each company uniquely values, so articulate this here.</li>
</ol>

<p>Each of these higher-level competencies can be broken down into more specific ones, but remember to keep the total to 5 or fewer.</p>

<p>To help with the hacking, let‚Äôs explore each of these suggested competencies a bit further.</p>

<h3 id="technical-skills">Technical Skills</h3>

<p>‚ÄúWait,‚Äù you may be thinking. ‚ÄúThe whole reason I‚Äôm reading this article is because I don‚Äôt know how to do this person‚Äôs job. Now you‚Äôre telling me to figure out how to assess their technical ability? What gives?!‚Äù</p>

<p>I know. It sucks. This will likely be the hardest competency for you to define. If you are hiring for a role that is the first of its kind in your company, you may not be able to describe it any more precisely than I already have, and that‚Äôs OK. We‚Äôll talk about some ways to manage this in the next step.</p>

<p>Most people in this position will get help from a teammate or other connection who knows the technicals of the job. This is especially true if you‚Äôre hiring a new leader to level-up a more junior team that is already doing the work.</p>

<p>Your role is to keep their ideas <em>focused</em>. This is important, because subject-matter experts can have a hard time keeping this list under control. I‚Äôve seen people struggle to pick fewer than 10 separate technical competencies that are important in their jobs.</p>

<p>You can help by finding ways to:</p>

<ul>
  <li>Coalesce competencies into larger areas of concern, and</li>
  <li>Eliminate things.</li>
</ul>

<p>If this is nerve-wracking, remember that time is always a constraint. More things on the list means longer interviews, and longer interviews mean less time for other important work. We‚Äôre not trying to cover every single thing that is important to the job; we‚Äôre trying to assess the most critical things with the time that we have.</p>

<h3 id="effective-communicator">Effective Communicator</h3>

<p>You may be unsurprised to find this in the list, but I want to highlight why I think this is especially important for a pioneering role.</p>

<p>If you‚Äôre creating a new kind of job in your team‚Äîeven if it already exists somewhere else at your company‚Äî it‚Äôs really important that you can trust this person to furnish you with information in a way that helps you make effective decisions.</p>

<p>When we‚Äôre hiring for something new, we can get so focused on the person‚Äôs ability to do the job that we lose sight of how important it is for everyone to meaningfully understand <em>how the work is going</em>. This is especially important if this person is responsible for building an entirely new competency within the company, because it‚Äôs hard for new things to build momentum without understanding and trust.</p>

<p>To summarize: It‚Äôs important that this person can do the job. It‚Äôs also super important that they can explain it to you and others in a way that‚Äôs easy to understand. This understanding creates trust, and trust fuels meaningful results.</p>

<h3 id="has-soft-skills-we-value">Has Soft Skills We Value</h3>

<p>I once spoke to a founder who was looking for people who were ‚Äúnaturally inquisitive.‚Äù That sounded off to me, because it requires more than testing for curiosity; it requires us to determine whether that curiosity is <em>intrinsic</em>.</p>

<p>I asked for a concrete example of what ‚Äúnatural inquisitiveness‚Äù looked like. They said: ‚ÄúWell, at the lunch table, we‚Äôll often have big debates about political or social issues. These are really fun, because people won‚Äôt just state their thoughts: They‚Äôll try to find the logical arguments or fallacies behind the different positions. It‚Äôs not just an emotional conversation. We‚Äôre always looking to verify the underlying principles.‚Äù</p>

<p>From this starting point, we were eventually able to articulate the ‚Äúsoft skill‚Äù that they were looking for: A good candidate would <em>effectively apply the scientific method to everyday problems</em>.</p>

<p>This re-framing improves on the original in several ways:</p>

<ul>
  <li>It‚Äôs easier to assess than ‚Äúnaturally inquisitive‚Äù.</li>
  <li>It has less to do with <em>identity</em> and more to do with <em>ability</em>.</li>
  <li>It connects to a unique part of the company‚Äôs history, which was founded by scientists out of a university research project.</li>
</ul>

<p>Because first-time hires tend to be fraught with risk, I find that interviewers naturally want to latch onto something that helps ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</a></em></p>]]>
            </description>
            <link>https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061052</guid>
            <pubDate>Wed, 11 Nov 2020 18:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of 3D meshing methods using open source tools]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060942">thread link</a>) | @alibabaSX
<br/>
November 11, 2020 | https://www.sesamx.io/blog/3d_mesh_with_free_tools/ | <a href="https://web.archive.org/web/*/https://www.sesamx.io/blog/3d_mesh_with_free_tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        

<p>The Internet is full of beautiful 3D mesh examples, but it is difficult to get clues
about how they were constructed. In fact, <strong>creating a good 3D mesh can be very
painful without the right tools or training</strong>. Furthermore, most of commercial
pre-processing software have been improving and propose powerful 3D meshing algorithm,
capable of building hybrid or full hexahedron mesh. <strong>The aim of
this article is to give an overview of the constraints involved when building
a 3D mesh for structural finite element, as well as exposing various meshing
methods relying on free and open source tools</strong>.</p>

<h2 id="introduction">Introduction</h2>

<p>Before we start, let‚Äôs give some background information about 3D mesh
construction. Usually a 3D mesh can be composed of 4 types of elements:</p>

<ul>
<li><p>tetrahedron (4 corners),</p></li>

<li><p>wedge (6 corners),</p></li>

<li><p>hexahedron (8 corners),</p></li>

<li><p>and rarely pyramids (5 corners).</p></li>
</ul>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/3d_mesh_element_types.png" alt="3D mesh element types"></p>

<p><strong>The goal is to get a mesh with the lowest number of
degrees of freedom (‚Äúdofs‚Äù), while maintaining a good representative capability</strong>.
We may be
tempted to race for tetrahedrons, which have only 4 nodes (for a linear
element). But reality is more involved: <strong>certain types of elements behave better
than others</strong>. Without entering to much into the details, we can provide some hints
about this:</p>

<ul>
<li><p><strong>4-node tetrahedron (linear element) must be avoided as mush as possible</strong>. It
behaves poorly and a lot of them are needed to get meaningful results. If you
have no other choice, try to convert them to 10-node tetrahedron which is much
better.</p></li>

<li><p>if you want to stay with linear elements, <strong>you must aim towards hexahedron</strong>. Most
finite element software (you can guess that SesamX is part of them) propose an
improved version of the hexahedron element. That makes it a better choice than
the other elements.</p></li>

<li><p><strong>6-node wedge (linear element)</strong> is better than 4-node tetrahedron but worse than
8-node hexahedron. <strong>It is ok to use them, but go for hexahedron wherever possible</strong>.</p></li>

<li><p>I have not tested the pyramid enough to give relevant advice. Nevertheless,
from the fact that this element is seldom used in 3D mesh, this article will not
shed light on it.</p></li>
</ul>

<p>It is easy to build a full tetrahedron mesh using an automatic mesher
(and it is widespread among various software). On the contrary, <strong>full hexahedron or
hybrid automatic meshers are more involved and harder to find</strong> (you can find them
among commercial solutions but almost not among free ones).</p>

<p><strong>However, using only free and open source tools, we are still able to build
quality 3D meshes</strong>.</p>

<p>The remaining of <strong>this article exhibits 4 methods to build 3D meshes using Salome or
Gmsh</strong>. The goal is not to enter into every detail about the options used, but to
give an overview of how 3D meshes can be built. Whatever the tool we use, changing
the element order is usually a trivial task (either linear or quadratic).
Therefore I will not detail it here. Instead, <strong>I will focus on controlling the
element shapes while meshing</strong>.</p>

<p>For each method, I provide a step by step guide with illustrative screenshots. And, when
appropriate, I also provide the final result file that you can edit and modify
on your own.</p>

<h2 id="geometry-used">Geometry used</h2>

<p>I will use the following con rod to showcase how to build each mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/con_rod_geometry.PNG" alt="Con rod geometry"></p>

<p>One important feature to mention here, is that <strong>this con rod geometry is made of
a compound of 3 solids</strong> (this reason will make sense when talking about the hybrid
mesh generation method) corresponding to each color on the image above.</p>

<p>You can find the corresponding step file
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/con_rod_to_mesh.step">here</a>.</p>

<h2 id="full-tetrahedron-automatic-meshing-method">Full tetrahedron automatic meshing method</h2>

<p>As mentioned before, <strong>it is pretty straightforward to get a full tetrahedron<br>
mesh</strong>. To build this mesh, we use <strong>Salome</strong>.</p>

<p>First, we go to the geometry module and import the step file. The Salome tree
should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_import_tree.PNG" alt="Salome import tree"></p>

<p>Then we have to explode the compound geometry into its 3 sub-solids and create a
partition from these solids. <strong>This step is necessary to ensure that Salome will merge
coincident nodes from each solid faces</strong>. The result tree is then:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree.PNG" alt="Salome partition"></p>

<p>Next we go to the mesh module, and create a new mesh on the partition. Under
algorithm we can select ‚ÄúNETGEN 1D-2D-3D‚Äù and under hypothesis ‚ÄúNETGEN 3D
Simple Parameters‚Äù. Finally we have to input the edge size that our elements should
have.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome tetrahedron mesh parameters"></p>

<p>Eventually we have to right click on the mesh and hit ‚ÄúCompute‚Äù. The mesh should
look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh.PNG" alt="Salome tetrahedron mesh"></p>

<p>As you can see, the mesh is made of tetrahedron but also triangles and edges
elements. To get rid of the 2D and 1D elements, the first step is to
click on the mesh and select ‚ÄúCreate Group‚Äù. A panel appear and we can create one
group containing all the 2D elements (as shown on the picture below) and
similarly for the 1D elements.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_create_group.png" alt="Salome create group"></p>

<p>Next to delete these elements, we have to right
click on each group and select ‚ÄúDelete Group with Content‚Äù. <strong>And we get
the following full tetrahedron mesh</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_tetrahedron_mesh.PNG" alt="Salome final tetrahedron mesh"></p>

<p>Finally, <strong>to check that the mesh does not contain any duplicated nodes</strong> we have to
select the mesh and use ‚ÄúControls / Node Controls / Double Nodes‚Äù.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_tet_double_nodes.PNG" alt="Tetrahedron duplicated nodes check"></p>

<p>If you want to manipulate this mesh, you can find the corresponding Salome database
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/full_tet_con_rod.hdf">here</a>.</p>

<h2 id="full-hexahedron-automatic-meshing-method">Full hexahedron automatic meshing method</h2>

<p>Next come the full hexahedron mesh. To build this mesh, we use <strong>Gmsh</strong>.</p>

<p>First, <strong>it is necessary to create a volume physical group containing the 3
solids of the model. It ensure afterwards that the mesh export will, in fact,
export only the 3D elements.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_volume_physical_group.PNG" alt="Gmsh volume physical group"></p>

<p>Next we go to ‚ÄúTools / Options‚Äù then ‚ÄúMesh / General‚Äù to select the meshing
parameters. We can
choose whatever makes it for the 2D algorithm, 3D algorithm and 2D recombination
algorithm. These parameters influence how the mesh is built, feel free to change
them to notice the difference in the mesh. As a first guess, we can
stay with ‚ÄúDelaunay‚Äù and ‚ÄúBlossom‚Äù. However, <strong>make sure to select ‚ÄúAll Hexas‚Äù as the
‚ÄúSubdivision algorithm‚Äù so that the volumes will be filled with hexahedron only.</strong></p>

<p>Finally under ‚ÄúMin/Max element size‚Äù we can fix the element size.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_meshing_parameters.PNG" alt="Gmsh meshing parameters"></p>

<p>Eventually, we have to go back to the Gmsh tree and click ‚Äú3D‚Äù under ‚ÄúMesh‚Äù to
build the mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_mesh_creation.png" alt="Gmsh mesh creation"></p>

<p>We can check the mesh content under ‚ÄúTools / Statistics‚Äù. As you can see, the mesh
is made of 1D, 2D and 3D-hexahedron elements. <strong>Because we have created a physical
group for the 3 volumes, only the 3D mesh will be exported.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_hexaedron_mesh.PNG" alt="Gmsh mesh creation"></p>

<p>If you have troubles visualizing the 3D elements, you can adjust the visibility
parameters in the ‚ÄúMesh‚Äù options window under the ‚ÄúVisibility‚Äù tab.</p>

<p>Unfortunately, there is a trap here. <strong>The mesh obtained has duplicated nodes</strong>
at the interfaces between the 3 solids. To visualize them, we can export the mesh
as a .med file, import it in Salome, and use the ‚Äúdouble nodes‚Äù tool mentioned
previously.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_duplicated_nodes.PNG" alt="Hexahedron duplicated nodes"></p>

<p>Finally, to solve this issue, we have to use the ‚ÄúMerge Nodes‚Äù tool under
‚ÄúModification / Transformation‚Äù.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_remove_duplicated.PNG" alt="Hexahedron remove duplicated nodes"></p>

<h2 id="hybrid-meshing-method">Hybrid meshing method</h2>

<p>Next <strong>I am showcasing how to build an efficient hybrid mesh with Salome.</strong> This
method is my favorite because <strong>it leads to a well structured mesh, which can
capture more efficiently the details of the geometry</strong> (if you have a close look
to the automatic tetrahedron and hexadreon meshes, you can see that the fillet
is not always ‚Äúwell captured‚Äù for instance). The drawback of this method is that it does not
lead to a full hexahedron mesh but an hybrid mesh made with a majority of
hexahedrons, and a minority of wedges used to fill gaps.</p>

<p><strong>The 3D mesh will be built first by meshing 2D surfaces and then by extruding
them.</strong> To make this process workable, the geometry has been split into 3 solids
beforehand. Each of these solids can then be meshed as an extrusion of the surface
meshes.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_1.PNG" alt="Solid 1"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_2.PNG" alt="Solid 2"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_3.PNG" alt="Solid 3"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>Solid 1</em></center></td>
<td><center><em>Solid 2</em></center></td>
<td><center><em>Solid 3</em></center></td>
</tr>
</tbody>
</table>

<p>As explained for the full-tetrahedron mesh, <strong>we first need to explode the
compound geometry and build a partition.</strong></p>

<p>Then, in order to build the 2D meshes on the surfaces and the 3D extrusion meshes,
we need to extract (using explode) the relevant geometries from this partition:</p>

<ul>
<li>the 3 solids geometries,</li>
<li>the top face of solid 1 (red face on solid 1 image), that will drive the
3D mesh on solid 1,</li>
<li>the ‚Äúfillet face‚Äù of solid 2 and 3 (red face on solid 3 image) that will drive
the 3D mesh on solid 2 and solid 3.</li>
</ul>

<p>The Salome tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree_hybrid.PNG" alt="Salome tree for hybrid mesh"></p>

<p>Next, we go to the mesh module. The meshing process is the following:</p>

<ul>
<li><p>Create a mesh object and assign default 3D mesh parameters to the whole
partition,</p></li>

<li><p>Create 2 sub-meshes for the 2 surfaces to mesh,</p></li>

<li><p>Create 3 sub-meshes for the 3 solids to mesh.</p></li>
</ul>

<p><strong>The default 3D meshing parameters will not be used while computing the mesh,
because the sub-meshes definition will cover the whole partition.</strong> Nevertheless, Salome
still requires these default parameters.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome import tree"></p>

<p>To create the faces sub-meshes, we have to right click on the mesh and
select ‚ÄúCreate Sub-mesh‚Äù. We then need to select one of the faces and choose the
‚ÄúNETGEN 1D-2D‚Äù
algorithm with ‚ÄúNETGEN 2D Simple Parameters‚Äù. Then we can input the element size
and <strong>make sure to check ‚ÄúQuad-dominated‚Äù (to avoid at most triangles)</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/face_submesh_parameters.png" alt="Salome face submesh parameters"></p>

<p>To compute the sub-mesh, we have to right click on it and select ‚ÄúCompute
Sub-mesh‚Äù. And we repeat these operations for the second face.</p>

<p><strong>Creating the 3D sub-meshes is similar.</strong> Once we have selected the solid to mesh,
we choose ‚ÄúExtrusion 3D‚Äù as the meshing algorithm and no hypothesis needs to be associated.
However, we have to provide the 1D algorithm and hypothesis to define
how the mesh extrusion should behave.</p>

<p>We select ‚ÄúWire Discretisation‚Äù as the 1D algorithm, and the previous local length
used for the 2D sub-meshes as the hypothesis.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_3d_submesh_parameters.png" alt="Hybrid 3D submesh parameters"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_1d_submesh_parameters.png" alt="Hybrid 1D submesh parameters"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>3D submesh parameters</em></center></td>
<td><center><em>1D submesh parameters</em></center></td>
</tr>
</tbody>
</table>

<p>We repeat this for the 2 other solids. The mesh tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_tree.PNG" alt="Salome hybrid mesh tree"></p>

<p><strong>Before computing the mesh, we need to tell Salome in which order the sub-meshes
should be computed.</strong> To avoid meshing conflict while extruding, it is best in
our case, to fully mesh solid 1 before meshing the driving surface of solid 2
and solid 3. We have to right click on the mesh and select ‚ÄúChange sub-mesh Priority‚Äù.
The meshing order should be the following:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_order.PNG" alt="Salome hybrid mesh tree"></p>

<p>After ‚Ä¶</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sesamx.io/blog/3d_mesh_with_free_tools/">https://www.sesamx.io/blog/3d_mesh_with_free_tools/</a></em></p>]]>
            </description>
            <link>https://www.sesamx.io/blog/3d_mesh_with_free_tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060942</guid>
            <pubDate>Wed, 11 Nov 2020 18:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing leaky logs: how to find a bug and ensure it never returns]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060456">thread link</a>) | @pabloest
<br/>
November 11, 2020 | https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><blockquote>
<p><strong>TL;DR</strong> I lay out a case for moving security enforcement into the hands
of developers. I show how I and another developer at r2c successfully identified data
leakage in our logs, fixed the issue, and prevented it from happening in the
future. We did this <em>in a matter of hours, without assistance from our AppSec team</em>.</p>
</blockquote>
<h2>Introduction</h2>
<p>As a developer and engineering manager, I‚Äôve become obsessed with finding ways
to rapidly solve security issues across the engineering organization without ever
needing to fully involve our security team.</p>
<p>Why is this important? I see multiple benefits:</p>
<ul>
<li>Fixing security issues is <em>fast</em>. So fast, in fact, that we can solve them in
minutes after identifying them, without security issues languishing for days
or weeks. In previous roles, I've seen internally known security issues lie
open with only obscurity protecting my organization from fallout.</li>
<li>When developers can solve security issues easily themselves, it frees the
security team to focus on ‚Äúbig picture‚Äù security. I want security engineers
to be thinking how to choose frameworks, set up tools, help with secure
architecture, and build defense-in-depth‚Äînot finding my last XSS mistake.</li>
</ul>
<p>I call this concept ‚Äúself-service DevSec‚Äù.</p>
<p>In the rest of this blog post, I'll walk through a security bug we encountered
during the day-to-day course of regular development work. I'll discuss how we
discovered the issue, and how, within just a few hours, fixed the security
issue, and used Semgrep to prevent the bug from reoccurring.</p>
<p>Here's the story:</p>
<h2>Story</h2>
<p>Last month, I was debugging a Flask web-app authentication workflow with
Clara McCreery, another engineer at r2c. Like many engineers faced with
a confusing debugging problem, one of our first steps was to throw the web-app
into debug logging.</p>
<p>Specifically, we wanted to know what was going on with our database operations,
so we set our ORM (in this case, we use SQLAlchemy) into INFO-level logging with:</p>
<div data-language="py"><pre><code>logging<span>.</span>getLogger<span>(</span><span>"sqlalchemy.engine.base.Engine"</span><span>)</span><span>.</span>setLevel<span>(</span>logging<span>.</span>INFO<span>)</span></code></pre></div>
<p>This configures SQLAlchemy to log all SQL statements, together with passed
parameters. Let's look at some of the output we saw:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 11:50:01] "POST /api/auth/authenticate HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
</span><span>INFO<span>:</span><span>sqlalchemy.engine.base.Engine:{'token_1': </span></span><span><span>$</span><span>2a<span>$10</span><span>$KVsyW1jjKn</span>.pvkVi3w9Rn.1mwnZFd7F2SFveGDG8flIhbe.MoJH4G, <span>'param_1'</span><span>:</span> <span>1</span><span>}</span></span></span></code></pre></div>
<p>...Uh-oh.</p>
<p>We definitely shouldn‚Äôt be logging tokens (even if they're securely hashed).
(In this example the actual token value has been changed to protect
the innocent.)</p>
<h2>Let‚Äôs make a plan</h2>
<p>At this point we‚Äôve identified a security issue, and we want to stomp it out
while preserving our ability to inspect logs. Our plan:</p>
<ol>
<li>Mitigate the immediate security issue.</li>
<li>Find a permanent solution to the problem that‚Äôs future proof. A permanent
solution means a baked-in change to our systems. Ideally this solution is
automated and seamless across our entire organization.</li>
<li>Add a mechanism to enforce our solution‚Äôs use organization-wide.</li>
</ol>
<p>In the rest of this post, I‚Äôll walk you through how we addressed each step.
Notably, we were able to accomplish this entire flow in a couple hours, without
engaging the security team at all.</p>
<h3>1. Mitigation</h3>
<p>Mitigation here was fairly straightforward, as we already knew the root cause
of our problem. We can quickly revert our logging change. Then we can do
a quick audit of our logs to ensure that only development test tokens were
leaked.</p>
<h3>2. The permanent solution</h3>
<p>How do we prevent SQLAlchemy from logging sensitive data?</p>
<p><em>A valiant attempt</em></p>
<p>Step 1 was to read the docs. A quick web search of ‚Äúsqlalchemy hide parameters
in engine logging‚Äù linked us to the SQLAlchemy <a href="https://docs.sqlalchemy.org/en/13/core/engines.html" target="_blank" rel="noopener">Engine
documentation</a>. A detailed
read later, we found the <code>hide_parameters</code> flag, which prevents the logging
framework from emitting <em>any</em> parameters in logs or exceptions.</p>
<p>While this certainly would prevent our security issue, it was too blunt of a hammer
for us: we wanted to know (for example) database IDs, and the like, for debugging.</p>
<p><em>The real solution</em></p>
<p>We then inspected the relevant SQLAlchemy <a href="https://github.com/sqlalchemy/sqlalchemy/tree/master/lib/sqlalchemy" target="_blank" rel="noopener">source
code</a>. The
relevant code is in <code>sqlalchemy/engine/base.py</code>:</p>
<div data-language="py"><pre><code>    <span>if</span> self<span>.</span>_echo<span>:</span>
        self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>statement<span>)</span>
        <span>if</span> <span>not</span> self<span>.</span>engine<span>.</span>hide_parameters<span>:</span>
            self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>
                <span>"%r"</span><span>,</span>
                sql_util<span>.</span>_repr_params<span>(</span>
                    parameters<span>,</span> batches<span>=</span><span>10</span><span>,</span> ismulti<span>=</span>context<span>.</span>executemany
                <span>)</span><span>,</span>
            <span>)</span></code></pre></div>
<p><code>sql_util._repr_params</code>, in turn, runs:</p>
<div data-language="py"><pre><code><span>def</span> <span>_repr_params</span><span>(</span>self<span>,</span> params<span>,</span> typ<span>)</span><span>:</span>
    trunc <span>=</span> self<span>.</span>trunc
    <span>if</span> typ <span>is</span> self<span>.</span>_DICT<span>:</span>
        <span>return</span> <span>"{%s}"</span> <span>%</span> <span>(</span>
            <span>", "</span><span>.</span>join<span>(</span>
                <span>"%r: %s"</span> <span>%</span> <span>(</span>key<span>,</span> trunc<span>(</span>value<span>)</span><span>)</span>
                <span>for</span> key<span>,</span> value <span>in</span> params<span>.</span>items<span>(</span><span>)</span>
            <span>)</span>
        <span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>Investigating <code>trunc</code>, we found that it converts the parameter value by
truncating the parameter‚Äôs <code>repr</code> to a maximum number of characters.</p>
<p>This meant that we should override the <code>repr</code> method of the parameter object to
prevent sensitive logging.</p>
<p>At this point, like good engineers, we took the lazy route: stand on your
peers‚Äô shoulders. I found <a href="https://github.com/sqlalchemy/sqlalchemy/issues/4806" target="_blank" rel="noopener">this GitHub
issue</a>, where <a href="https://techspot.zzzeek.org/" target="_blank" rel="noopener">Mike
Bayer</a> had already posted a nice solution.</p>
<p>Some shameless copying later (and adding some types to make <code>mypy</code> happy), we
had <a href="https://gist.github.com/nbrahms/2fee940f4d87f09ffc3823be5a334cf3" target="_blank" rel="noopener">this
Gist</a>. The
key code is:</p>
<div data-language="py"><pre><code><span>class</span> <span>ObfuscatedString</span><span>(</span>types<span>.</span>TypeDecorator<span>)</span><span>:</span>
    <span>"""
    String column type for use with SQLAlchemy models whose
    content should not appear in logs or exceptions
    """</span>

    impl <span>=</span> types<span>.</span>String

    <span>class</span> <span>Repr</span><span>(</span><span>str</span><span>)</span><span>:</span>
        <span>def</span> <span>__repr__</span><span>(</span>self<span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
            <span>return</span> <span>"********"</span>

    <span>def</span> <span>process_bind_param</span><span>(</span>self<span>,</span> value<span>:</span> Optional<span>[</span><span>str</span><span>]</span><span>,</span> dialect<span>:</span> Any<span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span>Repr<span>]</span><span>:</span>
        <span>return</span> self<span>.</span>Repr<span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>

    <span>def</span> <span>process_result_value</span><span>(</span>
        self<span>,</span> value<span>:</span> Optional<span>[</span>Repr<span>]</span><span>,</span> dialect<span>:</span> Any
    <span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span><span>str</span><span>]</span><span>:</span>
        <span>return</span> <span>str</span><span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>


<span>setattr</span><span>(</span>db<span>,</span> <span>"ObfuscatedString"</span><span>,</span> ObfuscatedString<span>)</span></code></pre></div>
<p>What does this code accomplish? It replaces our original <code>str</code> parameters
with a new <code>ObfuscatedString.Repr</code> parameter. When logged (or when emitted
into an exception message), the string is replaced by our <code>********</code>
obfuscation sentinel. Since the parameter is still bound as a raw string (via
<code>impl = types.String</code>), the correct value is still inserted and selected from
the database.</p>
<p>To use this new column type, we set our <code>token</code>‚Äôs column type:</p>
<div data-language="py"><pre><code><span>class</span> <span>Token</span><span>(</span>db<span>.</span>Model<span>)</span><span>:</span>
    <span>.</span><span>.</span><span>.</span>
    token <span>=</span> db<span>.</span>Column<span>(</span>db<span>.</span>ObfuscatedString<span>,</span> <span>.</span><span>.</span><span>.</span><span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>We then re-enabled INFO logging, and checked that we were properly obfuscating
text:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 13:48:55] "GET /api/agent/deployments/1/policies HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
INFO:sqlalchemy.engine.base.Engine:{'token_1': ********, 'param_1': 1}</span></code></pre></div>
<p>For completeness, we also validated in our development database console that the
correct values were stored and retrieved.</p>
<p>Great success! üö¢ Ship it.</p>
<h3>3. Enforcement</h3>
<p>It was tempting to rest on our laurels here. We had solved our security issue for
the time being, and we could get back to debugging our original auth issue.</p>
<p>But we wanted to guarantee that <em>we would never see this issue again</em>. How would we do
this?</p>
<p>Here are some ideas that I‚Äôm sure we‚Äôve all encountered before:</p>
<ol>
<li>Block all commits to SQLAlchemy models on security review!</li>
<li>Host a yearly security training for all devs, including the pitfalls of
logging sensitive data!</li>
<li>Audit logs weekly!</li>
<li>File an issue with your SAST provider, demanding they add checks to catch
sensitively logged data!</li>
</ol>
<p>If there is a central take-away from this blog post, it is this: these are not
ideal solutions:</p>
<ol>
<li>Blocking commits introduces needless friction into the development
process, slows development velocity, and needlessly distracts the security
team.</li>
<li>Security trainings are an important component to a security program, and
necessary to keep developers aware of evolving security threats, but humans
have fallible memory, and we can forget things we've heard months or even
days in the past.</li>
<li>Regular audits, like blocking commits, introduce a heavy workload on an
almost certainly overloaded security team.</li>
<li>Your SAST provider will certainly welcome your suggestion, but you will be
beholden to their software release cycle, and may not see checks be
available for months; furthermore, if your issue is domain-specific, it may
not even make sense for a check to be implemented within a generalist product.</li>
</ol>
<p>Fortunately, Semgrep gave us a simple solution here: Define an
<em>invariant</em> in your code, and <em>enforce</em> it using a Semgrep scan on every CI
run.</p>
<p>At r2c, we use GitHub Actions to run Semgrep on every merge request. We define
what checks Semgrep should run using <em>a managed policy</em>, a list of rules and
notification settings managed by <a href="https://semgrep.dev/" target="_blank" rel="noopener">semgrep.dev</a>.</p>
<p>To guarantee our code against future issues, I went to
<a href="https://semgrep.dev/editor" target="_blank" rel="noopener">semgrep.dev/editor</a> and wrote <a href="https://semgrep.dev/s/nbrahms:obfuscate-sensitive-string-columns-2" target="_blank" rel="noopener">a quick rule</a>
to detect potential insecurely logged SQLAlchemy columns.</p>
<p>Here's the rule definition in Semgrep's YAML definition language:</p>
<div data-language="yaml"><pre><code><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> obfuscate<span>-</span>sensitive<span>-</span>string<span>-</span>columns
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>|</span><span>
        $COLUMN = db.Column(db.String, ...)</span>
    <span>-</span> <span>metavariable-regex</span><span>:</span>
        <span>metavariable</span><span>:</span> $COLUMN
        <span>regex</span><span>:</span> <span>'.*(?&lt;![A-Za-z])(token|key|email|secret)(?![A-RT-Za-rt-z]).*'</span>
  <span>message</span><span>:</span> <span>|</span><span>
    '$COLUMN' may expose sensitive information in logs and exceptions. Use
    'db.ObfuscatedString' instead of 'db.String'.</span>
  <span>severity</span><span>:</span> WARNING</code></pre></div>
<p>What does this rule do? Let‚Äôs break it down:</p>
<ul>
<li><code>id</code>: We give our rule a concise descriptive ID for easy reference by any developer who
sees it pop up in their editor or CI output.</li>
<li>
<p><code>patterns</code>: This is composed of two parts:</p>
<ul>
<li><code>pattern</code>: This expression tells Semgrep to ‚Ä¶</li></ul></li></ul></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060456</guid>
            <pubDate>Wed, 11 Nov 2020 17:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doomsday prepping ‚Äì Disaster planning for less crazy folk (2016)]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 111 (<a href="https://news.ycombinator.com/item?id=25060418">thread link</a>) | @VBprogrammer
<br/>
November 11, 2020 | https://lcamtuf.coredump.cx/prep/ | <a href="https://web.archive.org/web/*/https://lcamtuf.coredump.cx/prep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

 

<a name="1"></a>
<h2>1. Introduction <span>[<a href="#1">link</a>]</span></h2>

<p>
The prepper culture begs to be taken with a grain of salt. In a sense, it has
all the makings of a doomsday cult: a tribe of unkempt misfits who hoard gold
bullion, study herbalism, and preach about the imminent collapse of our society.
</p>

<p>
Today, we see such worries as absurd. It's not that life-altering disasters are
rare: every year, we hear about millions of people displaced by wildfires, earthquakes,
hurricanes, or floods. Heck, not a decade goes by without at least one first-class
democracy lapsing into armed conflict or fiscal disarray. But having grown up in a period
of unprecedented prosperity and calm, we take our way of life for granted - and find
it difficult to believe that an episode of bad weather or a currency crisis could
upend our lives for good.
</p>

<p>
I suspect that we dismiss such hazards not only because they seem surreal, but also because
worrying about them makes us feel helpless and lost. What's more, we follow the same instincts
to tune out far more pedestrian and avoidable risks; for example, 
most of us don't plan ahead for losing a job, for dealing with a week-long water outage, or
for surviving the night if our home goes up in smoke.
</p>

<p>
For many, the singular strategy for dealing with such dangers is to pray for the
government to bail us out. But no matter if our elected officials prefer to school us with
passages from
<a href="https://smile.amazon.com/dp/0156334607">Milton
Friedman</a> or from
<a href="https://smile.amazon.com/dp/0486477487" title="I'm sorry... I'm really sorry!">Thomas
Piketty</a>, the hard truth is that no state can provide a robust safety net for all
of life's likely contingencies; in most places, government-run social programs are severely deficient in funding, in
efficiency, and in scope. Large-scale disasters pit us against even worse odds; from New Orleans in 2005 to
Fukushima in 2011, there are countless stories of people left behind due to political dysfunction, poorly
allocated resources, or lost paperwork.
</p>

<p>
And so, the purpose of this guide is to combat the mindset of learned helplessness by
promoting simple, level-headed, personal preparedness techniques that are easy to
implement, don't cost much, and will probably help you cope with whatever life throws your way.
</p>

<p>
Oh, one thing: in contrast to most other docs of its kind, this page an
unadulterated labor of love; there are no affiliate links, paid product placements, or ads anywhere in the guide.
</p>

<a name="2"></a>
<h2>2. Mapping out the unknown <span>[<a href="#2">link</a>]</span></h2>

<p>
Effective preparedness can be simple, but it has to be rooted in an honest and
systematic review of the risks you are likely to face. Plenty of excited newcomers begin
by shopping for ballistic vests and night vision goggles; they would be better
served by grabbing a fire extinguisher, some bottled water, and then putting the rest of
their money in a rainy-day fund.
</p>

<p>
To maintain sanity while trying to enumerate risks, I found that it's best to focus on
broad outcomes instead of trying to track down every single way for things to go south.
Say, it should not matter if you are laid off because of a downsizing, because
your new boss hates you, or because they finally catch you stealing paperclips. The
outcome is the same: you are out of a job and urgently need a way to pay your bills.
</p>

<p>
Another insidious distraction is the desire to immediately figure out how to respond to all the scenarios
we end up dreaming of. Let's save that for later; by prematurely focusing on the second half of the
problem, we may end up glossing over some of the less tractable scenarios - or make
haphazard assumptions that will cloud our judgment in other ways.
</p>

<p>
I also found that to come up with a rational threat model, we need to think of "risk" as a product of
both the probability and the consequences of a given event. By that metric, stubbed toes
and zombie outbreaks are equally uninteresting; one of them has nearly zero significance,
the other, nearly zero odds.
</p>

<p>
What else? Ah, right: the final piece of advice I have is to keep things uncomplicated. There are
popular doomsday predictions that deal with cutting-edge particle physics, god-like computer
hackers, vast government conspiracies, or extraterrestrial messages hidden in pop songs. I suppose
we can't <i>really</i> rule that stuff out, but historical data suggests that there's a lot more
merit in worrying about falling off a ladder or getting hit by a car.
</p>

<p>
All right! With these caveats in mind, let's go over some canonical scenarios that are worth thinking about.
</p>

<a name="2.1"></a>
<h3>2.1. Problem space #1: Small-scale events <span>[<a href="#2.1">link</a>]</span></h3>

<p>
It's always fun to speculate about solar flares and supervolcanoes; it's far more mind-numbing to
seriously evaluate the consequences of backed up sewage or burst water mains. But in reality,
such unglamorous, small-scale incidents are far more likely to disrupt and reshape our
lives.
</p>

<p>
Broadly speaking, disastrous outcomes of such humdrum contingencies can be divided into
several groups:
</p>

<ul>

<li>
<p>
<b>Insolvency.</b>
  If a person over the age of 40 tells you that they have never lost a job, they are
  pretty lucky (or lying). Yet, the risk is seldom taken seriously; many middle-class,
  single-income families would be in deep trouble if it ever took them more than 2-3 months
  to find a new, equally well-paying gig.
</p>

</li><li>
<p>
<b>Disrupted access to water, food, energy, or transportation.</b>
  Substantial and prolonged outages happen everywhere; many of us will experience
  at least one at some point in our lives. A week without electricity may be just
  inconvenient and scary, especially in a high-rise or
  in a seedy neighborhood; but even a single hot day without potable water is really
  bad news.
</p>

</li><li>
<p>
<b>Loss of shelter.</b>
  Every year, there are over 350,000 house fires in the United States. Such accidents
  usually aren't deadly - but if you are unlucky, they can leave you stranded in the middle
  of the night in your PJs, with no documents or credit cards in hand.
</p>

</li><li>
<p>
<b>Unintentional injury.</b>
  Largely preventable and predictable incidents - such as falls, vehicle collisions, and poisonings -
  account for some 40 million ER visits annually. And lest you say people are simply too
  quick to rush to the hospital, said incidents also result in about 100,000 US
  deaths every year.
</p>

</li><li>
<p>
<b>Intentionally inflicted harm.</b>
  Violent crime is essentially <i>normal</i> almost everywhere in the world.
  In the US in the 90s, your lifetime likelihood of victimization was
  estimated to be around 80%; the odds of suffering criminal injury hovered at 40%. More recent
  research is hard to come by - but rest assured, life-threatening encounters remain a very real risk.
</p>

</li><li>
<p>
<b>Debilitating illness or death.</b>
  It's going to get you; maybe next week, maybe in 50 years. We can't really predict the day,
  but we can understand and meaningfully manage the impact it will have on those who depend on us -
  say, our stay-at-home partners or young kids.
</p>

</li></ul>

<p>
All in all, the risks discussed in this section have three defining characteristics: they are relatively
likely to happen; are strikingly easy to mitigate (we'll get into that soon); and tend to be so
unglamorous that they seldom make the cut in any "serious" guide to emergency preparedness.
</p>

<a name="2.2"></a>
<h3>2.2. Problem space #2: Mass calamities <span>[<a href="#2.2">link</a>]</span></h3>

<p>
If an errant backhoe took out the utilities for your block, you would probably head to the
grocery store to pick up bottled water (and use their restrooms, too). But if a
once-in-a-century storm damaged major roads and left half the city without running water, your
options wouldn't be as clear-cut.
</p>


<p>
That's why we have to look at larger-scale emergencies through somewhat different lens, taking into
account their likely magnitude, duration, and the nature of the forces at play. Some of the
plausible scenarios to think about include:
</p>

<ul>

<li>
<p>
<b>Natural disasters.</b>
  Common examples include floods, hurricanes, earthquakes, wildfires, and heatwaves. In some
  regions, such events are very rare; in others, they are almost guaranteed every decade or two.
</p>

</li><li>
<p>
<b>Industrial accidents.</b>
  Many people live in the proximity of heavy industries - say, refineries, freight railroads, or power plants.
  Depending on the type of industrial facilities nearby, you may want to evaluate the potential
  consequences of upwind and upstream explosions or chemical spills.
</p>

</li><li>
<p>
<b>Social unrest.</b>
  Riots are a distinct risk in many urban and suburban areas around the world. When angry mobs
  take it to the streets, widespread arson and violent crime are not unheard of, sometimes going
  on for days or weeks.
</p>

</li><li>
<p>
<b>Economic crises.</b>
  All highly developed countries go through cyclic recessions and periods of high unemployment;
  the US had about ten big ones in the past 100 years alone. Sometimes, such events
  are accompanied by bank runs and collapses of financial institutions; other times,
  they involve hyperinflation, product rationing, and currency controls.
</p>

</li><li>
<p>
<b>Pandemic.</b>
  It's been a while since the highly developed world experienced a devastating outbreak, but it
  may be premature to flat out dismiss the risk. In 1918, an unusual strain of flu managed to kill 75
  million people. Few years later, a mysterious sleeping sickness - probably also of viral origin -
  swept the globe, crippling millions, some for life. We aren't necessarily better prepared
  for similar events today.
</p>

</li><li>
<p>
<b>Terrorism or conventional war.</b>
  We think we would see it coming - but history shows that such events tend to catch nations
  off guard. These phenomena are noteworthy not only because of their immediate death toll,
  which can be relatively low - but because of the far-reaching and long-term socioeconomic
  disruption they can cause.
</p>

</li></ul>

<p>
Most of us will probably not get tangled up in a large-scale disaster of any sort, but it
is only wise to hedge your bets. There are countless examples to demonstrate that such events
happen often and can strike close to home - say:
</p>

<ul>

<li>
<p>
The EU debt crisis, from 2009 onward. A series of events that led to staggering unemployment rates
in Greece, deposit confiscations in Cyprus, and uncertain prospects for the entire
eurozone.
</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lcamtuf.coredump.cx/prep/">https://lcamtuf.coredump.cx/prep/</a></em></p>]]>
            </description>
            <link>https://lcamtuf.coredump.cx/prep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060418</guid>
            <pubDate>Wed, 11 Nov 2020 17:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advance Electromagnetism Notes (Site)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060248">thread link</a>) | @E-Reverance
<br/>
November 11, 2020 | https://andrealommen.github.io/PHY309/lectures | <a href="https://web.archive.org/web/*/https://andrealommen.github.io/PHY309/lectures">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <h3 id="for-reference">For reference</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/derivatives">All the Fundamental Theorems Together</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwell">Maxwell‚Äôs Equations</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/minus_signs">Minus Signs</a><br></p>
<h3 id="chapter-1-vector-analysis">Chapter 1: Vector Analysis</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/grad">Gradients Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/div">Divergence Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/curl">Stokes‚Äô Theorem (Curl)</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/dirac">Dirac Delta Function</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentials">Potentials and Boundary Conditions</a><br></p>
<h3 id="chapter-2-electrostatics">Chapter 2: Electrostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt2">Andrea‚Äôs Crash Course in Chapter 2</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/electric">Electric Field</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/divcurlE">Divergence and Curl of Electric Field, Gauss‚Äôs Law</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/PotentialWorkEnergy">Potential, Work, Energy</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/conductors">Boundary Conditions and Conductors</a><br></p>
<h3 id="chapter-3-potentials">Chapter 3: Potentials</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt3">Andrea‚Äôs Crash Course in Chapter 3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/laplace">Laplace‚Äôs Equation and the Method of Images</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/separation">Separation of Variables</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/multipole">Multipole Expansion </a><br></p>
<h3 id="chapter-4-electric-fields-in-matter">Chapter 4: Electric Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt4">Andrea‚Äôs Crash Course in Chapter 4</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/debrief">Debrief HW3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/displacement">Displacement</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/boundaryD">Boundary Values in the Presence of a Dielectric</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/SolutionToInClassDielectricCylinderProblem.pdf">Full solution to the Dielectric Cylinder Problem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/final_words_displacement">Final Words (Rant?) on Displacement</a><br></p>
<h3 id="one-third-of-the-way-through-the-course-we-reflect">One-third of the way through the course, we reflect‚Ä¶</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/CumulativeSummary1">Summary of Course so Far</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Survey.html">Survey Results</a><br></p>
<h3 id="first-exam">First Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/firstexamformat">What will be the format of the 1st exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_1st">Practice Problems for 1st exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/firstexam">First Exam</a><br></p>
<h3 id="chapter-5-magnetostatics">Chapter 5: Magnetostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt5">Andrea‚Äôs Crash Course in Chapter 5</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/lorentz">Lorentz and Biot-Savart</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/ampere">Ampere‚Äôs Law and the Vector Potential</a><br></p>
<h3 id="chapter-6-magnetic-fields-in-matter">Chapter 6: Magnetic Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt6">Andrea‚Äôs Crash Course in Chapter 6</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/magnetized_matter">Magnetization and the Field of a Magnetized Object</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/auxiliary">The Auxiliary Field</a><br></p>
<h3 id="chapter-7-electrodynamics">Chapter 7: Electrodynamics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt7">Andrea‚Äôs Crash Course in Chapter 7</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/induction">Electromotive Force and Induction</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwellChapt7">Maxwell‚Äôs Equations</a><br></p>
<h3 id="chapter-8-griffiths-calls-it-conservation-laws-at-this-point-we-only-picked-up-the-continuity-equation-and-saved-the-rest-for-after-chapter-9">Chapter 8: Griffiths calls it Conservation laws, at this point we only picked up the Continuity Equation and saved the rest for after Chapter 9</h3>
<p>(We‚Äôre kind of picking up Chapter 8 along the way‚Ä¶)<br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt8">Andrea‚Äôs Crash Course in Chapter 8</a><br></p>
<h3 id="chapter-9-electromagnetic-waves">Chapter 9: Electromagnetic Waves</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt9">Andrea‚Äôs Crash Course in Chapter 9</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/light">Light!!!!!</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization of Waves in Linear and Conducting Media</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/reflection">Boundary Conditions, Reflection and Transmission</a><br></p>
<h3 id="second-exam">Second Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/secondexamreview">Review for the second exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexamformat">What will be the format of the 2nd exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_2nd">Practice Problems for 2nd exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexam">Second Exam</a><br></p>
<h3 id="poynting-vector-energy-transmission-coefficient-parts-of-chapters-8-and-9">Poynting Vector, Energy, Transmission coefficient (parts of chapters 8 and 9)</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/quarterwaveplate">In a quarter wave plate, can we really assume the transmission coefficients are the same?</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/poynting">Poynting Theorem, Poynting Vector, Energy, Momentum</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/transmission">Poynting Theorem in EM Waves, Transmission and Reflection Coefficients</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/plasma">Waves in a Tenuous Plasma, Dispersion</a> <br></p>
<h3 id="chapter-10-potentials-and-fields">Chapter 10: Potentials and Fields</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Andrea‚Äôs Crash Course in Chapter 10</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentialformulation">The Potential Formulation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/deferred">The Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/leinard">Leinard-Wiechert Potential</a> <br></p>
<h3 id="chapter-11-radiation">Chapter 11: Radiation</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Andrea‚Äôs Crash Course in Chapter 11</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/radiation">Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/dipole">Dipole Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/point">Radiation from a Point Charge</a> <br></p>
<h3 id="the-final-week-looking-backwards-and-forwards">The Final Week: Looking backwards and forwards</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Chapter 10 Review (emphasis Gauge and Deferred) Plus Relativity, Chapt 12</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPt2">Chapter 10 Review cont‚Äôd including Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Pancake breakfast party, and Review Chapter 11.  We‚Äôll do a questionnaire here to get your thoughts about the class</a></p>
<h3 id="the-final-exam">The Final Exam</h3>
<p>You may look at the following whenever you want.  It explains the format of the exam and what kind of problems
to expect.
<a href="https://andrealommen.github.io/PHY309/lectures/finalexamformat">Format of the Final Exam</a><br></p>

<p>When you‚Äôre ready to take the exam please click <a href="https://andrealommen.github.io/PHY309/lectures/finalexam">here.</a></p>

  </div>


</article>


      </div>
    </div></div>]]>
            </description>
            <link>https://andrealommen.github.io/PHY309/lectures</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060248</guid>
            <pubDate>Wed, 11 Nov 2020 17:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Futhark Work on Apple Silicon?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060172">thread link</a>) | @Athas
<br/>
November 11, 2020 | https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on November 11, 2020
    
        by Troels Henriksen
    
</p>

<p>Apple is coming out with computers that are basically ARM64, <a href="https://en.wikipedia.org/wiki/Think_different">but with a different ABI than existing ARM64 for some reason</a>. They call the architecture <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_Silicon">Apple Silicon</a>, which is a wonderful term that will undoubtedly never become dated or insufficiently precise.</p>
<p>Anyway, you see various posts such <a href="https://developer.r-project.org/Blog/public/2020/11/02/will-r-work-on-apple-silicon/">Will R Work on Apple Silicon?</a> where language developers answer whether their language will work on these new machines. Since these machines will support transparent emulation of x86, the simple answer is <em>yes</em>. Apple‚Äôs emulation was quite good during the PPC-to-x86 transition, so this is trustworthy. Of course, emulation is never going to be as fast as native compilation. For R, the problem is that they depend on some Fortran code, and there is <a href="https://developer.apple.com/forums/thread/651476">not yet a Fortran compiler available for Apple Silicon</a>.</p>
<p>Well, I can confirm that Futhark depends on absolutely no Fortran. Futhark compiles to C (or Python), and does not care about the specific target architecture. Therefore, Futhark programs should run fine on Apple Silicon. The bigger problem is that <a href="https://www.extremetech.com/computing/270902-apple-defends-killing-opengl-opencl-as-developers-threaten-revolt">Apple has deprecated OpenCL</a>, and <a href="https://www.provideocoalition.com/officially-official-nvidia-drops-cuda-support-for-macos/">does not support CUDA at all</a> due to being grumpy with NVIDIA, so there may eventually be no way to run Futhark <em>on a GPU</em> on macOS. It is unlikely that we will find the time to add a backend for Apple‚Äôs <a href="https://developer.apple.com/metal/">proprietary Metal API</a> that is supported <em>absolutely nowhere else</em>, but it‚Äôs possible that we‚Äôll finish Futhark‚Äôs embryonic Vulkan backend. While macOS does not come bundled with Vulkan, <a href="https://github.com/KhronosGroup/MoltenVK">even Apple probably cannot hold back this eruption</a>.</p>
<p>And of course, the Futhark multi-core backend should run well on any Unix-like system.</p>


    </div></div>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060172</guid>
            <pubDate>Wed, 11 Nov 2020 17:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Minimal 3D creative coding tool ‚Äì control 8√ó8√ó8 dots with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060146">thread link</a>) | @doersino
<br/>
November 11, 2020 | https://doersino.github.io/tixyz/ | <a href="https://web.archive.org/web/*/https://doersino.github.io/tixyz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://doersino.github.io/tixyz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060146</guid>
            <pubDate>Wed, 11 Nov 2020 17:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at how LinkedIn exfiltrates extension data from their users (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060089">thread link</a>) | @coreyprophitt
<br/>
November 11, 2020 | https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users | <a href="https://web.archive.org/web/*/https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
          <p><img src="https://prophitt.me/assets/images/posts/linkedins-gambit.svg" width="300" height="300"></p><div>
            
            <p><time datetime="2020/11/05T00:00:00Z">Published on November 5th, 2020</time>
          </p></div>
        </div>

        <p><span>√Ç¬∑</span><span>√Ç¬∑</span><span>√Ç¬∑</span></p>

        <h2>What did I find?</h2>
        <p>
          LinkedIn is actively spraying their users' browser with web requests and dom queries in an attempt to determine
          if certain browser extensions are installed. The data is then exfiltrated back to LinkedIn.
        </p>
        <p>
          It is not clear what the data is used for or how it is used by LinkedIn. However, it is clear LinkedIn is
          targeting certain sales and recruiting tools. It is also common knowledge in the sales and recruiting
          communities that LinkedIn restricts or outright bans accounts based on the use of unapproved tools.
        </p>
        <p>
          LinkedIn is within their right to detect malicious user behavior and take action. However, the means they are
          employing are problematic for a number of reasons:
          </p><ol>
            <li>
              LinkedIn doesn't verify you are actually using the extension, they only check if the extension is currently
              installed and/or enabled.
            </li>
            <li>
              A number of the tools LinkedIn does not allow have legitimate uses and can be used on public web pages.
            </li>
            <li>
              The exfiltrated data could be further used for nefarious things such as browser finger printing.
            </li>
          </ol>
        

        <p>
          Furthermore, the methods employed by LinkedIn to detect extensions take advantage of developer oversights and
          browser extension limitations. This comes across as shady to me.
        </p>

        <h2>Unraveling the Mystery</h2>
        <p>
          I was initially turned on to LinkedIn's data exfiltration when I noticed a large number of failed web requests while visiting
          a LinkedIn profile. Initially, I thought my adblocker was blocking network requests. However, upon a closer look I noticed the
          web requests were not being sent across the web. They were actually being sent locally, to the browser itself. This can be
          seen clearly when viewing the network request's path. The paths were all being made using Chrome's own extension protocol. All
          requests began with <strong>chrome-extension://</strong>.
        </p>
        <p>
          For the uninitiated, the Chrome extension protocol is used to make web requests directly to an installed browser extension.
          Typically, this is used by the extension itself to retrieve resources or assets. However, any resources listed in an extension's
          manifest under the <strong>"web_accessible_resources"</strong> key are available to all web page contexts. Ironically, this
          section of the manifest was designed to minimize browser fingerprinting and protect the privacy of the extension user. Here's
          an excerpt directly from <a target="_blank" rel="noopener noreferrer" href="https://developer.chrome.com/extensions/manifest/web_accessible_resources">
          Google's own documentation</a> regarding the web accessible resources:
        </p>

        <blockquote>
         Prior to manifest version 2 all resources within an extension could be accessed from any page on the web. This allowed a malicious website to fingerprint the extensions that a user has installed or exploit vulnerabilities (for example XSS bugs) within installed extensions. Limiting availability to only resources which are explicitly intended to be web accessible serves to both minimize the available attack surface and protect the privacy of users.
        </blockquote>

        <p>
         Unfortunately, Google's changes only minimized the attack surface and did not prevent browser fingerprinting or privacy violations.
         It is this very issue that is leveraged by LinkedIn to identify installed extensions.
        </p>

        <p>
          My curiosity got the best of me and I set out to learn more about how LinkedIn was performing the scan and what they were doing
          with the data.
        </p>

        <h2>Eeny, Meeny, Miny, Moe</h2>
        <p>
          The sheer number of Chrome extension web requests performed by LinkedIn were staggering. I began to wonder how they were storing
          all of the extension information in order to make those web requests. The hunt began.
        </p>
        <p>
          Initially, I jotted down a few of the unique extension ids in hopes of finding references to them. I looked for any reference
          to the ids within LinkedIn's web responses but I had no luck. I looked within LinkedIn's web resources and code, but again I had no
          luck. Another idea crossed my mind; <i>Maybe they were hiding the extension information in their cookies or local storage?</i>
        </p>
        <p>
          My hunch led me to LinkedIn's local storage and a curious key, <strong>C_C_M</strong>. The value for the key was a large,
          seemingly random set of characters seen below:
        </p><pre><code>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‚Ä¶</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</a></em></p>]]>
            </description>
            <link>https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060089</guid>
            <pubDate>Wed, 11 Nov 2020 16:58:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xilinx-Samsung SmartSSD Computational Storage Drive Launched]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25059946">thread link</a>) | @blopeur
<br/>
November 11, 2020 | https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg" data-caption="Smartssd Pr 1120x560"><img width="696" height="461" src="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-400x265.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-634x420.jpg 634w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Smartssd Pr 1120x560" title="Smartssd Pr 1120x560"></a><figcaption>Smartssd Pr 1120x560</figcaption></figure></div>
            <!-- content --><p>Computational storage is a small but growing segment of the market. To address this, the Samsung SmartSSD is being launched with a Xilinx Kintex FPGA inside to bring computational storage capabilities in a standard form factor. In this article, we are going to discuss how Xilinx and Samsung are delivering a computational storage platform.<span id="more-48283"></span></p>
<h2>Xilinx-Samsung SmartSSD Background</h2>
<p>First, why computational storage. One of the big drivers is that moving data, at high speeds, across systems can use a lot of power and consumes bandwidth. With computational storage, data can be processed without bringing it back to the main CPU.</p>
<figure id="attachment_48289" aria-describedby="caption-attachment-48289"><a href="https://www.servethehome.com/?attachment_id=48289" rel="attachment wp-att-48289"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png" alt="Xilinx SmartSSD Computational Storage Demand" width="1511" height="825" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png 1511w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-800x437.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-696x380.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-1068x583.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-769x420.png 769w" sizes="(max-width: 1511px) 100vw, 1511px"></a><figcaption id="caption-attachment-48289">Xilinx SmartSSD Computational Storage Demand</figcaption></figure>
<p>Part of the other driver here is that Xilinx sees computational storage as becoming mainstream, projected to be 5% of the market in only a few years. For its part, Xilinx is covering a number of different types of accelerators aside form the Samsung SmartSSD including those from Pliops, ScaleFlux, and BittWare.</p>
<figure id="attachment_48288" aria-describedby="caption-attachment-48288"><a href="https://www.servethehome.com/?attachment_id=48288" rel="attachment wp-att-48288"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png" alt="Xilinx SmartSSD Computational Storage Becoming Mainstream" width="1481" height="781" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png 1481w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-400x211.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-800x422.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-696x367.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-1068x563.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-796x420.png 796w" sizes="(max-width: 1481px) 100vw, 1481px"></a><figcaption id="caption-attachment-48288">Xilinx SmartSSD Computational Storage Becoming Mainstream</figcaption></figure>
<p>The basic Samsung SmartSSD has two main sets of components. One is basically a 4TB Samsung V-NAND SSD. This includes a NAND controller, and we are told DRAM for the controller to use as well. The second part of the solution is a Xilinx Kintex FPGA with its own 4GB of memory.</p>
<figure id="attachment_48285" aria-describedby="caption-attachment-48285"><a href="https://www.servethehome.com/?attachment_id=48285" rel="attachment wp-att-48285"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png" alt="Samsung Xilinx SmartSSD Internal Components" width="1263" height="783" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png 1263w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-400x248.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-800x496.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-696x431.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-1068x662.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-677x420.png 677w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-356x220.png 356w" sizes="(max-width: 1263px) 100vw, 1263px"></a><figcaption id="caption-attachment-48285">Samsung Xilinx SmartSSD Internal Components</figcaption></figure>
<p>The basic flow is that commands can be issued to either the SSD or the FPGA portion of the drive and processing can occur at the FPGA instead of going back to the host system.</p>
<figure id="attachment_48286" aria-describedby="caption-attachment-48286"><a href="https://www.servethehome.com/?attachment_id=48286" rel="attachment wp-att-48286"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png" alt="Samsung Xilinx SmartSSD Internal Operation" width="1456" height="836" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png 1456w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-400x230.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-800x459.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-696x400.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-1068x613.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-731x420.png 731w" sizes="(max-width: 1456px) 100vw, 1456px"></a><figcaption id="caption-attachment-48286">Samsung Xilinx SmartSSD Internal Operation</figcaption></figure>
<p>We are going to show an example later but a common question will be how are these programmed. One can use a standard storage stack or the OpenCL stack for computational storage aspects.</p>
<figure id="attachment_48291" aria-describedby="caption-attachment-48291"><a href="https://www.servethehome.com/?attachment_id=48291" rel="attachment wp-att-48291"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png" alt="Xilinx SmartSSD IP Runtime Stack" width="1470" height="723" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png 1470w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-400x197.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-800x393.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-696x342.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-1068x525.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-854x420.png 854w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-324x160.png 324w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-533x261.png 533w" sizes="(max-width: 1470px) 100vw, 1470px"></a><figcaption id="caption-attachment-48291">Xilinx SmartSSD IP Runtime Stack</figcaption></figure>
<p>As one would expect with a FPGA, there is a tie in with partner IP solutions as well as those that Xilinx and Samsung will have.</p>
<figure id="attachment_48290" aria-describedby="caption-attachment-48290"><a href="https://www.servethehome.com/?attachment_id=48290" rel="attachment wp-att-48290"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png" alt="Xilinx SmartSSD IP Development" width="1487" height="727" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png 1487w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-400x196.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-800x391.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-696x340.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-1068x522.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-859x420.png 859w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-533x261.png 533w" sizes="(max-width: 1487px) 100vw, 1487px"></a><figcaption id="caption-attachment-48290">Xilinx SmartSSD IP Development</figcaption></figure>
<p>The Xilinx Storage Services (XSS) are offloads available for the platform. These include compression and crypto offloads.</p>
<figure id="attachment_48292" aria-describedby="caption-attachment-48292"><a href="https://www.servethehome.com/?attachment_id=48292" rel="attachment wp-att-48292"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png" alt="Xilinx SmartSSD IP Xilinx Storage Services" width="1531" height="786" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png 1531w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-400x205.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-800x411.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-696x357.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-1068x548.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-818x420.png 818w" sizes="(max-width: 1531px) 100vw, 1531px"></a><figcaption id="caption-attachment-48292">Xilinx SmartSSD IP Xilinx Storage Services</figcaption></figure>
<p>Taking the compression in VDO as an example, the following slides have the basic flow:</p>
<figure id="attachment_48294" aria-describedby="caption-attachment-48294"><a href="https://www.servethehome.com/?attachment_id=48294" rel="attachment wp-att-48294"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png" alt="Xilinx SmartSSD VDO 1" width="1379" height="780" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png 1379w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-400x226.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-800x453.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-696x394.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-1068x604.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-743x420.png 743w" sizes="(max-width: 1379px) 100vw, 1379px"></a><figcaption id="caption-attachment-48294">Xilinx SmartSSD VDO 1</figcaption></figure>
<p>For reads, the FPGA is used to decompress data at the SmartSSD. By putting the compression on the SSD, Xilinx says it can get better compression ratios.</p>
<figure id="attachment_48295" aria-describedby="caption-attachment-48295"><a href="https://www.servethehome.com/?attachment_id=48295" rel="attachment wp-att-48295"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png" alt="Xilinx SmartSSD VDO 2" width="1447" height="784" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png 1447w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-400x217.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-800x433.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-696x377.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-775x420.png 775w" sizes="(max-width: 1447px) 100vw, 1447px"></a><figcaption id="caption-attachment-48295">Xilinx SmartSSD VDO 2</figcaption></figure>
<p>In terms of examples, we wanted to highlight one from Lewis Rhodes Labs where they are doing NPUSearch using computational storage. Effectively here the SmartSSDs are being used to scale out the number of accelerators with the number of SSDs. An application can send requests to the storage, data can be evaluated at the drives, and only results passed back to the main system.</p>
<figure id="attachment_48293" aria-describedby="caption-attachment-48293"><a href="https://www.servethehome.com/?attachment_id=48293" rel="attachment wp-att-48293"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png" alt="Xilinx SmartSSD Lewis Rhodes Labs Search" width="1538" height="837" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png 1538w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-800x435.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1536x836.png 1536w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-696x379.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-772x420.png 772w" sizes="(max-width: 1538px) 100vw, 1538px"></a><figcaption id="caption-attachment-48293">Xilinx SmartSSD Lewis Rhodes Labs Search</figcaption></figure>
<p>Since many of our readers will have noticed this, we asked about the PCIe Gen3 and we were told that there is a roadmap to the future.</p>
<h2>Final Words</h2>
<p>For STH readers, an immediate question is going to be why computational storage? Part of this model is that accelerators are tied to storage. For accelerator companies, this is great. Many of our readers though are going to ask about why not use DPUs instead. If you missed it&nbsp;<a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">What is a DPU A Data Processing Unit Quick Primer</a> is a good resource there. We asked since if the only goal is offload, and the SmartSSD is in many ways two devices that are co-packaged, then it could make sense to offload to a bigger chip. We were told that it is less expensive to use a smaller accelerator on each drive than to scale to a larger accelerator. This is one area that we know there is a lot of momentum behind each model in the data center. It will be interesting to see which ultimately wins.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059946</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Miniselect: Practical and Generic Selection Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059942">thread link</a>) | @cristaloleg
<br/>
November 11, 2020 | https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-555">

	

	
	<div>
		
<p>Today I present a big effort from my side to publish <a href="https://github.com/danlark1/miniselect">miniselect</a> ‚Äî generic C++ library to support multiple selection and partial sorting algorithms. It is already <a href="https://github.com/ClickHouse/ClickHouse/pull/16825">used</a> in <a href="https://clickhouse.tech/">ClickHouse</a> with huge performance benefits. Exact benchmarks and results will be later in this post and now let‚Äôs tell some stories about how it all arose. I publish this library under Boost License and any contributions are highly welcome.</p>



<h2>It all started with sorting</h2>



<p>While reading lots of articles, papers, and posts from Hacker News, I found it pretty funny each several months new ‚Äúshiny‚Äù, ‚Äúfastest‚Äù, ‚Äúgeneric‚Äù sorting algorithms to come or remembered from old papers such as the recent paper on <a href="https://blog.acolyer.org/2020/10/19/the-case-for-a-learned-sorting-algorithm/">learned sorting</a>, <a href="https://sortingsearching.com/2020/06/06/kirkpatrick-reisch.html">Kirkpatrick-Reisch</a> sort or <a href="https://news.ycombinator.com/item?id=14661659">pdqsort</a>. It is that we are essentially 65+ years into writing sorting algorithms, and we still find improvements. Shouldn‚Äôt sorting items be a ‚Äúsolved‚Äù problem by now? Unfortunately, not. New hardware features come, we find that sorting numbers can be actually done faster than best comparison <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)"> time complexity and we still find improvements in sorting algorithms like avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches in partitions</a> and trying to find good pivots as pdqsort does. Also, there are many open questions in that area as ‚Äúwhat is the minimum number of comparisons needed?‚Äù.</p>



<p>Huge competition is still going on in sorting algorithms and I believe we are not near the optimal sorting and learned sorting looks like the next step. But it uses the fundamental fact that no one expects sorting to be completed in a couple of passes and we can understand something about data during first array passes. We will understand why it matters later.</p>



<p>My favorite general sorting is <a href="https://github.com/orlp/pdqsort">pdqsort</a>, it proves to be currently the best general sorting algorithm and it shows a significant boost over all standard sorts that are provided in C++. It is also <a href="https://docs.rs/pdqsort/1.0.3/pdqsort/">used</a> in Rust.</p>



<h2>Selection and Partial Sorting</h2>



<p>Nearly a couple of months ago I started thinking about a slightly different approach when it comes to sorting ‚Äî partial sorting algorithms. It means that you don‚Äôt need to sort all <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements but only find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> smallest and sort them. For example, it is widely used in SQL queries when you do <code>ORDER BY LIMIT N</code> and <code>N</code> is often small, from 1-10 to ideally couple of thousands, bigger values still happen but rare. And, oh god, how little engineering and theoretical research has been done there compared to full sorting algorithms. In fact, the question of specifically finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th order statistics when <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is small is open and no good solution is presented. Also, partial sorting is quite easy to obtain after that, you need to sort the first <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> elements by some sorting algorithm to get optimal <img src="https://s0.wp.com/latex.php?latex=O%28n+%2B+k+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n + k \log k)" title="O(n + k \log k)"> comparisons and we will look at only one example when it is not the case. Yes, there are a bunch of median algorithms that can be generalized to find the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. So, what are they? Yeah, you may know some of them but let‚Äôs revise, it is useful to know your enemies.</p>



<h3>QuickSelect</h3>



<p>This is almost the very first algorithm for finding the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element, just do like <a href="https://en.wikipedia.org/wiki/Quicksort">QuickSort</a> but don‚Äôt go recursively in two directions, that‚Äôs it. Pick middle or even random element and partition by this element, see in which of two parts <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is located, update the one of the borders, voila, after maximum of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> partitions you will find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. Good news that on average it takes <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"> comparisons if we pick random pivot. That is because if we define <img src="https://s0.wp.com/latex.php?latex=C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n, k)" title="C(n, k)"> is the expected number of comparisons for finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements and <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%3D+%5Cmax_%7B1%7D%5E%7Bn%7D+C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) = \max_{1}^{n} C(n, k)" title="C(n) = \max_{1}^{n} C(n, k)">, then during one stage we do <img src="https://s0.wp.com/latex.php?latex=n+-+1&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - 1" title="n - 1"> comparisons and uniformly pick any pivot, then even if we pick the biggest part on each step</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+n+-+1+%2B+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bn%2F2%7D%5E%7Bn+-+1%7D+C%28i%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)" title="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))" title="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))"></p>



<p>If assuming by induction that <img src="https://s0.wp.com/latex.php?latex=C%28i%29+%5Cleq+4i&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(i) \leq 4i" title="C(i) \leq 4i"> with an obvious induction base, we get</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29+%5Cleq+n+-+1+%2B+4%283n%2F4%29+%3C+4n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n" title="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n"> </p>



<p>Bad news is that the worst case will still be <img src="https://s0.wp.com/latex.php?latex=O%28n%5E2%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n^2)" title="O(n^2)"> if we are unfortunate and always pick the biggest element as a pivot, thus partitioning .</p>



<p>In that sense that algorithm provides lots of pivot ‚Äústrategies‚Äù that are used nowadays, for example, picking pivot as a <img src="https://s0.wp.com/latex.php?latex=n%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/2" title="n/2"> element of the array or picking pivot from 3 random elements . Or do like <code>std::nth_element</code> from libcxx ‚Äî choose the middle out out of <img src="https://s0.wp.com/latex.php?latex=A%5B0%5D%2C+A%5Bn%2F2%5D%2C+A%5Bn+-+1%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A[0], A[n/2], A[n - 1]" title="A[0], A[n/2], A[n - 1]">.</p>



<p>I decided to visualize all algorithms I am going to talk about today, so quickselect with a median of 3 strategy on random input looks something like this:</p>



<figure><img data-attachment-id="579" data-permalink="https://danlark.org/nth-element-clang-2020-11-09_11-18-38/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-clang-2020-11-09_11.18.38" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=1024" alt=""><figcaption>nth_element in libcxx, median of 3 strategies</figcaption></figure>



<p>And random pivot out of 3 elements works similar</p>



<figure><img data-attachment-id="581" data-permalink="https://danlark.org/median-of-3-random-2020-11-09_11-06-02/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-3-random-2020-11-09_11.06.02" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=1024" alt=""><figcaption>Finding median in median of 3 random algorithm</figcaption></figure>



<p>For a strategy like <a href="https://github.com/llvm/llvm-project/blob/3ed89b51da38f081fedb57727076262abb81d149/libcxx/include/algorithm#L5159">libcxx</a> (C++ llvm standard library) does, there are quadratic counterexamples that are pretty easy to detect, such patterns also appear in real data. The counterexample looks like that:</p>



<figure><div>
<div id="gist106376435">
    <div>
      <div>
        

      </div>
      
    </div>
</div>

</div></figure>



<figure><img data-attachment-id="584" data-permalink="https://danlark.org/nth_element_clang_median_3_killer-2020-11-10_22-55-30/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth_element_clang_median_3_killer-2020-11-10_22.55.30" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=1024" alt=""><figcaption>std::nth_element in libcxx for Medianof3Killer</figcaption></figure>



<p>This is definitely quadratic. By the way, this is perfectly ok with the C++ standard wording as it says:</p>



<figure><img data-attachment-id="587" data-permalink="https://danlark.org/2020-11-10-230126_795x63_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png" data-orig-size="795,63" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-230126_795x63_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=795" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png 795w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=768 768w" sizes="(max-width: 795px) 100vw, 795px"><figcaption><a href="https://eel.is/c++draft/alg.nth.element#5">https://eel.is/c++draft/alg.nth.element#5</a></figcaption></figure>



<h2>Median of Medians</h2>



<p>For a long time, computer scientists thought that it is impossible to find medians in worst-case linear time, however, Blum, Floyd, Pratt, Rivest, Tarjan came up with BFPRT algorithm or like sometimes it is called, median of medians algorithm.</p>



<p>Median of medians algorithm: Given array <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A" title="A"> of size <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> and integer <img src="https://s0.wp.com/latex.php?latex=k+%5Cleq+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k \leq n" title="k \leq n">,</p>



<ol><li>Group the array into <img src="https://s0.wp.com/latex.php?latex=n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/5" title="n/5"> groups of size 5 and find the median of each group. (For simplicity, we will ignore integrality issues.)</li><li>Recursively, find the true median of the medians. Call this <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">.</li><li>Use <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> as a pivot to partition the array.</li><li>Recurse on the appropriate piece.</li></ol>



<p>When we find the median <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> of <img src="https://s0.wp.com/latex.php?latex=g+%3D+n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g = n/5" title="g = n/5"> groups, at least <img src="https://s0.wp.com/latex.php?latex=g%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g/2" title="g/2"> of them have at least 3 out of 5 elements that are smaller or equal than <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">, that said the biggest out of 2 partitioned chunks have size <img src="https://s0.wp.com/latex.php?latex=7n%2F10&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="7n/10" title="7n/10"> and we have the reccurence</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+cn+%2B+C%28n%2F5%29+%2B+C%287n%2F10%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq cn + C(n/5) + C(7n/10)" title="C(n) \leq cn + C(n/5) + C(7n/10)"></p>



<p>If we appropriately build the recurse tree we will see that</p>



<figure><img data-attachment-id="589" data-permalink="https://danlark.org/2020-11-10-232345_1330x458_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png" data-orig-size="1330,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-232345_1330x458_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png 1330w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This is the geometric series with <img src="https://s0.wp.com/latex.php?latex=cn%281+%2B+9%2F10+%2B+%289%2F10%29%5E2+%2B+%289%2F10%29%5E3+%2B+%5Cldots+...%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)" title="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)"> which gives us the result <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+10+c+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq 10 c n" title="C(n) \leq 10 c n">.</p>



<p>Actually, this constant 10 is really big. For example, if we look a bit closer, <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> is at least 1 because we need to partition the array, then finding median out of 5 elements cannot be done in less than 6 comparisons (can be proven by only brute-forcing) and in 6 comparisons it can be done in the following way</p>



<ol><li>Use three comparisons and shuffle around the numbers so that <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B2%5D%2C+a%5B4%5D+%3C+a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[2], a[4] < a[5]" title="a[1] < a[2], a[4] < a[5]">, and <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[4]" title="a[1] < a[4]">.</li><li>If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[2]" title="a[3] > a[2]">, then the problem is fairly easy. If <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2] < a[4]" title="a[2] < a[4]">, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">. If not, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">.</li><li>So <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3C+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] < a[2]" title="a[3] < a[2]">. If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[4]" title="a[3] > a[4]">, then the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">. Otherwise, the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">.</li></ol>



<p>So that maximum <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> can be <img src="https://s0.wp.com/latex.php?latex=11%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="11/5" title="11/5"> and it gives us the upper bound <img src="https://s0.wp.com/latex.php?latex=22n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="22n" title="22n"> comparisons which looks like it can be achieved. Some other tricks can be done in place to achieve a bit lower constants like <img src="https://s0.wp.com/latex.php?latex=18n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="18n" title="18n"> (for example, sorting arrays of 5 and comparing less afterwards). In practice, the constant is really big and you can see it from the following demonstration which was even fastened because it took quite a few seconds:</p>



<figure><img data-attachment-id="593" data-permalink="https://danlark.org/median-of-medians-2020-11-09_11-04-33/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-medians-2020-11-09_11.04.33" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=1024" alt=""><figcaption>Median of medians for random input</figcaption></figure>



<h2>HeapSelect</h2>



<p>Another approach to finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element is to create a <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> on an array of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and push other <img src="https://s0.wp.com/latex.php?latex=n+-+k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - k" title="n - k"> elements into this heap. C++ <code>std::partial_sort</code> works that way (with additional heap sorting of the first heap). It shows good results for very small <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and random/ascending arrays, however starts to significantly degrade with growing <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and becomes impractical. Best case <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)">, worst <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">.</p>



<figure><img data-attachment-id="596" data-permalink="https://danlark.org/partial_sort-2020-11-09_12-28-40/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="partial_sort-2020-11-09_12.28.40" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=1024" alt=""><figcaption>std::partial_sort, two stages, first HeapSelect then heap sort of the first half, accelerated for speed</figcaption></figure>



<h2>IntroSelect</h2>



<p>As the previous algorithm is not very much practical and QuickSelect is really good on average, in 1997 <a href="http://www.cs.rpi.edu/~musser/gp/introsort.ps">‚ÄúIntrospective Sorting and Selection Algorithms‚Äù</a>  from David Musser came out with a sorting algorithm called ‚ÄúIntroSelect‚Äù. </p>



<p>IntroSelect works by optimistically starting out with QuickSelect and only switching to MedianOfMedians if it recurses too many times without making sufficient progress. Simply limiting the recursion to constant depth is not good enough, since this would make the algorithm switch on all sufficiently large arrays. Musser discusses a couple of simple approaches:</p>







<p>This algorithm came into <a href="https://github.com/gcc-mirror/gcc/blob/e0af865ab9d9d5b6b3ac7fdde26cf9bbf635b6b4/libstdc%2B%2B-v3/include/bits/stl_algo.h#L4748">libstdcxx</a> and guess which strategy was chosen? Correct, none of them. Instead, they try <img src="https://s0.wp.com/latex.php?latex=2%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="2\log n" title="2\log n"> QuickSelect steps and if not successful, fallback to HeapSelect algorithm. So, worst case <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"></p>



<figure><img data-attachment-id="598" data-permalink="https://danlark.org/nth-element-gcc-2020-11-09_11-06-37/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-gcc-2020-11-09_11.06.37" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=1024" alt=""><figcaption>std::nth_element in libstdcxx, ‚ÄúIntroSelect‚Äù</figcaption></figure>



<h2>PDQSelect</h2>



<p>Now that most of the known algorithms come to an end üòà, we can start looking into something special and extraordinary. And the first one to look at is pdqselect which comes pretty straightforward from <a href="https://github.com/orlp/pdqsort">pdqsort</a>, the algorithm is basically QuickSelect but with some interesting ideas on how to choose an appropriate pivot:</p>



<ol><li>If there are <img src="https://s0.wp.com/latex.php?latex=n+%3C+24&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n < 24" title="n < 24"> elements, use <a href="https://en.wikipedia.org/wiki/Insertion_sort">insertion sort</a> to partition or even sort them. As insertion sort is really fast for a small amount of elements, it is reasonable</li><li>If it is more, choose <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> ‚Äî pivot:<ol><li>If there are less or equal than 128 elements, choose pseudomedian (or ‚Äúninther‚Äù, or median of medians which are all them same) of the following 3 groups:<ol><li>begin, mid, end</li><li>begin + 1, mid ‚Äì 1, end ‚Äì 1</li><li>begin + 2, mid + 1, end ‚Äì 2</li></ol></li><li>If there are more than 128 elements, choose median of 3 from begin, mid, end</li></ol></li><li>Partition the array by the chosen pivot with avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches</a>:<ol><li>The partition is called bad if it splits less than <img src="https://s0.wp.com/latex.php?latex=1%2F8n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="1/8n" title="1/8n"> elements</li><li>If the total number of bad partitions exceeds <img src="https://s0.wp.com/latex.php?latex=%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\log n" title="\log n">, use <code>std::nth_element</code> or any other fallback algorithm and return</li><li>Otherwise, try to defeat some patterns in the partition by (sizes are l_size and r_size respectively):<ol><li>Swapping begin, begin + l_size / 4</li><li>Swapping p ‚Äì 1 and p ‚Äì l_size / 4</li><li>And if the number of elements is more than 128<ol><li>begin + 1, begin + l_size / 4 + 1</li><li>begin + 2, begin + l_size / 4 + 2</li><li>p ‚Äì 2, p ‚Äì l_size / 4 + 1</li><li>p ‚Äì 3, p ‚Äì l_size / 4 + 2</li></ol></li><li>Do the same with the right partition</li></ol></li></ol></li><li>Choose the right partition part and repeat like in QuickSelect</li></ol>



<figure><img data-attachment-id="605" data-permalink="https://danlark.org/pdqselect-2020-11-09_11-03-23/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pdqselect-2020-11-09_11.03.23" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=1024" alt=""><figcaption>pdqselect on random input</figcaption></figure>



<h2>Media‚Ä¶</h2></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059942</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is It Time to Modernize the PostgreSQL Core Team?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059852">thread link</a>) | @ahachete
<br/>
November 11, 2020 | https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    
<p>The PostgreSQL Community is large, diverse and global. There are users, enthusiasts, developers, contributors, advocates and commercial entities from around the world. All of them working in a loosely collaborative fashion to grow and make PostgreSQL succeed.</p>
<p>The Postgres Core Team is considered to be the steering committee for the Community. The definition of the group responsibilities can be <a href="https://www.postgresql.org/developer/core/">found here</a>. The core team members are listed on the <a href="https://www.postgresql.org/community/contributors/">Contributor Profiles</a> page.</p>
<p>On September 30th EnterpriseDB acquired 2ndQuadrant. At the time of the acquisition there were five members in Core; two of them were EnterpriseDB employees and another one a 2ndQuadrant employee. This meant that 60% of the Core members would be employed by EnterpriseDB. On October 20th, in an effort to diffuse concerns about a single commercial entity having majority control, the <a href="https://www.postgresql.org/about/news/statement-from-the-postgresql-core-team-on-the-edb-acquisition-of-2ndquadrant-2094/">Core Team announced</a> that this is an issue that they would be addressing:</p>
<p>‚Äú<em>There has long been an unwritten rule that there should be no more than 50% of the membership of the Core Team working for the same company</em>‚Äù</p>
<p>This rule was enacted back in the days of the <a href="https://www.postgresql.org/message-id/39181CCD.99531ADA@greatbridge.com">Great Bridge</a>. Core addressed the unwritten rule by appointing on November 2nd <a href="https://www.postgresql.org/about/news/new-postgresql-core-team-members-2103/">two new members: Andres Freund and Jonathan Katz</a>. This change in Core reduced the proportion of EnterpriseDB members to three out of seven. <strong>Fundaci√≥n PostgreSQL</strong> would like to extend a very warm welcome to Andres and Jonathan. They are both well known and long time community contributors.</p>
<p>The addition of the new members allowed Core to be compliant with the 50% rule. However: was this organizational change the best choice? Was it the only change that could have been implemented? Could we have looked at the culture of our global community and used this opportunity to strengthen our ties?</p>
<p>Here are some facts about Core‚Äôs structure and membership:</p>
<ul>
<li><strong>Company influence</strong>:
<ul>
<li>Core has switched from having 40% of its members from a single company to now having 43% from a single company and 71% from two companies.</li>
<li>100% of the members are from only 4 companies.</li>
</ul>
</li>
<li><strong>Diversity</strong>:
<ul>
<li>100% of the current Core team members are white men.</li>
<li>All of the Core members are either US or European. No other region is represented.</li>
<li>All but one Core member work for US companies.</li>
</ul>
</li>
<li><strong>Democracy:</strong>
<ul>
<li>Core members are only appointed by existing Core members. In contrast, the ‚Äú<a href="https://www.postgresql.org/community/recognition/#npos">Recognised Postgres Nonprofit Organisations</a>‚Äù (created and enforced by Core) has as a requirement that the ‚Äú<em>board of directors MUST be elected by the membership</em>‚Äù. These rules were, in turn, created by Core itself.</li>
<li>Core members serve for an <em>unlimited</em> term. In contrast, the same Community recognition rules above also require that ‚Äú<em>Lifetime directorships MUST NOT be allowed</em>‚Äù. Four of the current Core members <a href="https://web.archive.org/web/20051023004218/http://www.postgresql.org/developer/bios">have been serving in the Core team for more than 15 years</a>.</li>
</ul>
</li>
<li><strong>Transparency</strong>:
<ul>
<li>The election process, candidate selection, selection criteria, etc are all secret.</li>
<li>Core Team meeting minutes are secret.</li>
<li>Core team policies are enacted by declaration, without involvement of the global community.</li>
</ul>
</li>
</ul>
<p>Facts aside, there are some organizational concerns that may require some further analysis.</p>
<p>In the PostgreSQL distributed community, the <a href="https://www.postgresql.org/developer/core/">Core Team</a> acts as the <em>de facto</em> ‚Äúcentral authority‚Äù for the project. The <a href="https://www.postgres.ca/">Postgres Association of Canada</a> (‚ÄúCA‚Äù, in short), acts as its legal arm, holding assets (including intellectual property, like domain names and trademarks).</p>
<p>However, this presents an interesting dichotomy: Core makes decisions, but if these require a legal entity to be executed, they are executed by CA. Which has its own board of directors, that needs to approve them. What if they don‚Äôt? What if they don‚Äôt follow Core? Similarly, how is Core accountable, if it is not backed directly by a legal entity? Because of this, are there any potential liabilities faced directly by their members, as individuals? And what happens if CA‚Äôs Board goes haywire?</p>
<p>Other mature and successful open source projects, while distributed as Postgres and built from the contributions of people and organizations all around the world, are nowadays backed by clear and strong legal and organizational structure. Take for example the <a href="https://www.apache.org/foundation/">Apache Foundation</a>, or the <a href="https://www.fsf.org/working-together/fiscal-sponsorship">Free Software Foundation</a>. Or the <a href="https://www.cncf.io/">Cloud Native Computing Foundation (CNCF)</a>, which is a Charter of the Linux Foundation. Its structure <a href="https://www.cncf.io/blog/2019/12/06/cncf-toc-governance-structure-elections-2020/">has three main bodies</a>:</p>
<p>‚Äú<em>A <strong>Governing Board (GB)</strong> that is responsible for marketing, budget and other business oversight decisions for the CNCF, a <strong>Technical Oversight Committee (TOC)</strong> that is responsible for defining and maintaining the technical vision, and an <strong>End User Community (EUC)</strong> that is responsible for providing feedback from companies and startups to help improve the overall experience for the cloud native ecosystem</em>‚Äù</p>
<p>The <a href="https://www.cncf.io/people/governing-board/">Governing Board has currently 24 members</a>, and their <a href="https://www.cncf.io/about/governing-board-meeting-minutes/">meeting minutes are public</a> (they are not alone: MariaDB Foundation <a href="https://mariadb.org/bodminutes/2020-10-21/">is now publishing their board meetings too</a>); the <a href="https://www.cncf.io/people/technical-oversight-committee/">Technical Committee consists of 11 members and 77 contributors</a>; the <a href="https://docs.google.com/presentation/d/194SyKdHL7ws_DBOdbrXdowEJi54kIzDdDK_h-6Ag0uo/edit#slide=id.g9ffb40d42b_0_161">End User Community has more than 150 companies</a>; furthermore, there are dozens of <a href="https://www.cncf.io/people/ambassadors/">ambassadors</a>; and also dozens of <a href="https://www.cncf.io/people/staff/">staff</a> members. While possibly operating at a different scale than PostgreSQL, they all contribute, in different manners, to the steering, development and vision of the CNCF.</p>
<p>What do you think? <strong>Is PostgreSQL Core today what the PostgreSQL Community needs, or is it time to modernize its processes, structure and governance?</strong> If you think it is the latter, please leave your comments below. I hope this post serves as the starting point for a broader and constructive discussion that can serve as feedback to Core. Let‚Äôs ensure the best future for our beloved open source database!</p>

                </div>
                
                    
                
            </div>
        </div>
    </div>
</section></div>]]>
            </description>
            <link>https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059852</guid>
            <pubDate>Wed, 11 Nov 2020 16:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are Package Registries Holding Open-Source Hostage?]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25059755">thread link</a>) | @aviaviavi
<br/>
November 11, 2020 | https://about.scarf.sh/post/package-registries-and-open-source | <a href="https://web.archive.org/web/*/https://about.scarf.sh/post/package-registries-and-open-source">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>A few days ago, I received an email from Docker about a change I already knew was coming:<em>‚Äç</em></p><blockquote><em>Docker will begin enforcing rate limits on container pulls for Anonymous and Free users.</em><br></blockquote><p>To many, this came as no surprise. For years, <a href="http://hub.docker.com/">Docker Hub</a> has offered free hosting of container images, which typically range in size from a few megabytes to many gigabytes. Docker workflows as a result use a <em>lot</em> of bandwidth, and that bandwidth costs money.<br></p><p>Should we OSS (open-source software)&nbsp;developers have to think about the business and financial models of the platforms we host our software on? In a perfect world, we wouldn't have to‚Äîbut in the real world we very much do. The incentives between OSS maintainers and the registries they use are often misaligned.&nbsp;<br></p><p>Docker Hub, <a href="http://npmjs.com/">npm</a>, and other comparable registries are incentivized to create lock-in, even if it makes the product experience worse for their users and customers. This is especially true of the for-profit companies behind the registries, but we see similar issues from many of the not-for-profit registries. </p><p>Maintainers, on the other hand, are incentivized to choose the best product for their needs at the lowest cost, which depends on being able to switch providers when a better service comes on the market.&nbsp;<br></p><p>This situation is fundamentally at odds with the today's package management ecosystem, where immutability is paramount in order to achieve stability. We avoid breaking things at all costs, on principle, since OSS packages are the nuts and bolts of the software ecosystem, the internet, and thus society itself.<br></p><h6><strong>Mechanics of registry lock-in</strong><br></h6><p>The registry where you host your packages and containers might be free today, but if that changes later, as is the case now with Docker, you and your users might be stuck paying whatever price the vendor chooses to set. Your users might even agree to access your package without the rate limit, but<strong> </strong><em>you</em> will not be seeing any of that revenue. Access to your open-source software was effectively just sold for a profit, and you, the author of that software, were cut out of the transaction.<br></p><p>While you could in theory just host your software somewhere else, can you really do that without breaking things for your current users? If you maintain and distribute a popular Docker image, switching the package registry is likely difficult.<br></p><p>Currently, any image on Docker Hub is installable as:<br></p><div><pre><code>$ docker run org-name/image-name</code></pre></div><p><em>‚Äç</em>If you decide later you actually want to move your container hosting somewhere else - let's say <a href="https://cloud.google.com/container-registry" target="_blank">Google Container Registry</a> for this example - the Docker client is reasonable and lets you pull down images by their URL:<br></p><div><pre><code>$ docker run gcr.io/org-name/image-name</code></pre></div><p><em>‚Äç</em>The problem here is that once you've changed the URL to your images, all of your existing users will stop getting updates! Even worse, this can break builds or pipelines for your users whenever they hit the new rate limits, which are not under your control. </p><p>At the point where your container has a sizable user-base all going through one of the existing container registries, your lock-in is substantial. Moving platforms will be painful. The crux of the problem here is that <em>you</em> don't own the distribution channel. The registry is the&nbsp; first place the web traffic goes, and everything that happens after that is at <em>the registry vendor‚Äôs</em><strong> </strong>discretion and to their advantage, not yours.<br></p><h6><strong>Effects of registry lock-in</strong><br></h6><p>Some might respond: <em>"This still seems like more of a theoretical problem than a practical one."</em><br></p><p>There are several practical downstream effects of the misaligned incentive structures to open-source package hosting. One major effect of registry lock-in is that maintainers cannot access their usage data. The data that registries naturally collect from package downloads can be quite useful to maintainers in a myriad of ways, yet registries typically don't share anything beyond a download count. </p><p>Registries know where the downloads are coming from, the devices, the package versions, which other packages are installed alongside, and a whole lot more. Little to none that information is shared with maintainers. Thus, maintainers are effectively locked out from observing the usage traffic.&nbsp;<br></p><p>Why is this the case? It's not because developers don't ask for it (<a href="https://github.com/npm/npm/issues/279">https://github.com/npm/npm/issues/279</a>). It's because the registries have no incentive to do so. It would cost the registries money to build and maintain the features to provide this data. Some registries even claim that exposing this data publicly would incentivize maintainers to game the system. Meanwhile, the extreme levels of inertia in software distribution keep maintainers locked in. </p><p>The registries' demonstrated distrust of maintainers seems counterproductive in a space where there's opportunity to work together cooperatively. If registry incentives were aligned accordingly, a registry like npm, for instance, would be in a great position to empower maintainers to leverage their own distribution data to deliver the best software possible.<br></p><p>What makes npm‚Äôs particular scenario even worse is that they've made it so difficult to use a registry that is<em> not</em> npm. There's no way to pull a single package from an alternate registry without switching to that registry. Which makes it quite impossible to actually publish a widely used JavaScript package without putting it on npm.&nbsp;<br></p><p>Contrast this scenario to Docker: Docker Hub creates different tradeoffs that both help and harm OSS maintainers. They've loosened their grip on OSS maintainers by making it user-friendly to pull containers down from alternative registries besides Docker Hub. However, even if you switch away from Docker Hub, you're still jumping from one company to another. This is because, at the end of the day, the registries‚Äînot the maintainers‚Äîown the distribution URL. The power imbalance continues.<br></p><p>My argument is not intended to dismiss the efforts of the registries as a whole. Package registries serve an essential role in software distribution, and have collectively serviced billions upon billions of package downloads. They‚Äôve made it easy for anyone in the world to interact with open-source, and as a result have helped push open-source forward. Astonishingly, they have, for most part, remained free to use! But as software continues to eat the world and the distribution of that software becomes more important, conflicting interests in this space become increasingly problematic.<br></p><h6><strong>Looking forward</strong><br></h6><p>How do we solve this? Ultimately, package registries need to align their incentives with those of maintainers. Registries should build products maintainers <em>want</em> to use rather than products they <em>have</em> to use.&nbsp;The entire OSS&nbsp;community can benefit. <br></p><p>Part of this means registries must be more intentional about giving maintainers back control over the distribution of their own software, even when it means the maintainers could take their packages elsewhere. As a community, we should be empowering maintainers to do their best work rather than constraining them to work within a specific&nbsp; platform or framework.&nbsp;<br></p><p>For the health of the open source ecosystem, it's critical to ensure that maintainers are not locked out from accessing the data about their own software distribution. Maintainers must be able to make data-informed decisions and treat distribution data as something that rightfully belongs to them, instead of just the registry providers.<br></p><p>Unfortunately, the current software distribution model works to cut maintainers out, making all downstream actions more difficult and strictly less informed. When we as a community decide to better align ourselves with open-source maintainers and build platforms to empower them, the result will be better software for the entire ecosystem.</p><p>Scarf is working on new tooling to address these problems, so stay tuned! Follow <a href="https://twitter.com/scarf_oss" target="_blank">@scarf_oss</a> on Twitter or subscribe below for periodic updates.<br></p></div></div></div></div>]]>
            </description>
            <link>https://about.scarf.sh/post/package-registries-and-open-source</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059755</guid>
            <pubDate>Wed, 11 Nov 2020 16:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to the Scrypt Hash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059496">thread link</a>) | @lanecwagner
<br/>
November 11, 2020 | https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Scrypt is a slow-by-design <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a> or more accurately, a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">KDF</a> function. Simply put, the purpose of the Scrypt hash is to take some input data, and create a fingerprint of that data, but to do it very slowly. A common use-case is to take a password and create an n-bit private key, which is much longer and more secure. Here at <a href="https://app.qvault.io/">Qvault,</a> we use a similar KDF for securing user passwords.</p>



<p>For example, let‚Äôs pretend your password is <code>password1234</code>. By using Scrypt, we can extend that deterministically into a 256-bit key:</p>



<pre><code>password1234 -&gt; 
AwEEDA4HCwQFAA8DAwwHDQwPDwUOBwoOCQACAgUJBQ0JAAYNBAMCDQ4JCQgLDwcGDQMDDgMKAQsNBAkLAwsACA==</code></pre>



<p>That long 256-bit key can now be used as a private key to encrypt and decrypt data. For example, it could be the key in an <a href="https://qvault.io/2020/01/02/very-basic-intro-to-aes-256-cipher/">AES-256</a> cipher.</p>



<h2>Why Not Encrypt With The Password Directly?</h2>



<p>Most encryption algorithms, including AES-256, require that a key of sufficient length is used. By hashing the password, we can derive a longer, more secure, fixed-size key.</p>



<p>Furthermore, using a KDF like Scrypt provides additional benefits over a traditional hash function like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a>:</p>



<ul><li>Computationally expensive and slow</li><li>Memory intensive (potentially several gigabytes of RAM is used to execute the hash)</li></ul>



<p>Often times <a href="https://qvault.io/2020/02/11/how-do-brute-force-attackers-know-they-found-the-key/">brute-force attackers</a> will try to break encryption by guessing passwords over and over until they get it right. AES-256 and SHA-2 are fast, so an attacker would be able to guess many passwords per second. By using a slow hashing function like Scrypt to derive a key, we can force the attacker to waste more resources trying to break in.</p>



<h2>Scrypt Step-by-Step</h2>



<p>Scrypt can be visualized by some psuedo-code:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	// we'll get to this
}</code></pre>



<p>Let‚Äôs go through the steps of converting those inputs into the desired <code>derivedKey</code></p>



<h3>1 ‚Äì Define Blocksize</h3>



<pre><code lang="go">const blockSize = 128 * blockSizeFactor</code></pre>



<h3>2 ‚Äì Generate Initial Salt</h3>



<p>Scrypt uses <a aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/PBKDF2" target="_blank" rel="noreferrer noopener nofollow">PBKDF2</a> as a child key-derivation function. We use it to generate an initial salt. <code>PBKDF2</code> has the following signature:</p>



<pre><code lang="go">func PBKDF2(
	prf,
	password,
	salt,
	numIterations,
	desiredKeyLen
) derivedKey {}</code></pre>



<p>We use it as follows:</p>



<pre><code lang="go">const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)</code></pre>



<h3>3 ‚Äì Mix Salt</h3>



<p>Next, we mix the salt. We split <code>initialSalt</code> into <code>splitSalt</code>, which is a 2D array of bytes. Each sub-array contains 1024 bytes</p>



<pre><code lang="go">splitSalt := [][1024]byte(initialSalt)
for i, block := range splitSalt {
	newBlock := roMix(block, costFactor)
	splitSalt[i] = newBlock
}</code></pre>



<p>Where <code>roMix</code> is the following function:</p>



<pre><code lang="go">func roMix(block, iterations){
	v := []
	x := block
	for i := 0; i &lt; iterations; i++ {
		v[i] = x
		x = blockMix(x)
	}
	for i := 0; i &lt; iterations; i++ {
		j := integerify(x) % iterations
		x = blockMix(x ^ v[j])
	}
	return x
}</code></pre>



<p><code>integerify</code> is defined by <a aria-label=" (opens in a new tab)" href="https://tools.ietf.org/html/rfc7914" target="_blank" rel="noreferrer noopener nofollow">RFC-7914</a> and <code>blockMix</code> is:</p>



<pre><code lang="go">func blockMix(block){
	r := len(block) / 128
	// split block into an array of 2r 64-byte chunks
	chunks := get2r64ByteChunks()

	x := chunks[len(chunks)-1]
	y := []
	for i := 0; i &lt; len(chunks); i++{
		x = salsa20-8(x ^ chunks[i])
		y[i] = x
	}
	return [y[0], y[2], ...y[2r-2], y[1], y[3], ...y[2r-1]]
}</code></pre>



<p><code>salsa20-8</code> is the 8-round version of the algorithm defined <a href="https://en.wikipedia.org/wiki/Salsa20" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">here</a>.</p>



<h3>4 ‚Äì Finalize Salt</h3>



<p>Now <code>splitSalt</code> has been mixed in such a computationally exhausting way that we will call it an <code>expensiveSalt</code>. Expensive salt will be a single array of bytes, so we need to concatenate all the subarrays in <code>splitSalt</code>.</p>



<pre><code lang="go">expensiveSalt := append([], splitSalt...)</code></pre>



<h3>5 ‚Äì Return Final KDF</h3>



<pre><code lang="go">return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)</code></pre>



<p>The final pseudocode for our top level function is as follows:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	const blockSize = 128 * blockSizeFactor

	const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)

	splitSalt := [][1024]byte(initialSalt)
	for i, block := range splitSalt {
		newBlock := roMix(block, costFactor)
		splitSalt[i] = newBlock
	}

	expensiveSalt := append([], splitSalt...)

	return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)
}</code></pre>



<p>Or, if you prefer, the pseudocode as defined by <a href="https://en.wikipedia.org/wiki/Scrypt" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">Wikipedia</a>:</p>



<pre><code lang="">Function scrypt
   Inputs:
      Passphrase:                Bytes    string of characters to be hashed
      Salt:                      Bytes    random salt
      CostFactor (N):            Integer  CPU/memory cost parameter - Must be a power of 2 (e.g. 1024)
      BlockSizeFactor (r):       Integer  blocksize parameter (8 is commonly used)
      ParallelizationFactor (p): Integer  Parallelization parameter. (1..232-1 * hLen/MFlen)
      DesiredKeyLen:             Integer  Desired key length in bytes
   Output:
      DerivedKey:                Bytes    array of bytes, DesiredKeyLen long

   Step 1. Generate expensive salt
   blockSize ‚Üê 128*BlockSizeFactor  //Length (in bytes) of the SMix mixing function output (e.g. 128*8 = 1024 bytes)

   Use PBKDF2 to generate initial 128*BlockSizeFactor*p bytes of data (e.g. 128*8*3 = 3072 bytes)
   Treat the result as an array of p elements, each entry being blocksize bytes (e.g. 3 elements, each 1024 bytes)
   [B0...Bp‚àí1] ‚Üê PBKDF2HMAC-SHA256(Passphrase, Salt, 1, blockSize*ParallelizationFactor)

   Mix each block in B Costfactor times using ROMix function (each block can be mixed in parallel)
   for i ‚Üê 0 to p-1 do
      Bi ‚Üê ROMix(Bi, CostFactor)

   All the elements of B is our new "expensive" salt
   expensiveSalt ‚Üê B0‚à•B1‚à•B2‚à• ... ‚à•Bp-1  //where ‚à• is concatenation
 
   Step 2. Use PBKDF2 to generate the desired number of bytes, but using the expensive salt we just generated
   return PBKDF2HMAC-SHA256(Passphrase, expensiveSalt, 1, DesiredKeyLen);</code></pre>




		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059496</guid>
            <pubDate>Wed, 11 Nov 2020 16:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mental Models for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059450">thread link</a>) | @laybak
<br/>
November 11, 2020 | https://informedpm.com/posts/mental-models | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/mental-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>It is trendy to talk about mental models these days, especially in the tech industry. But really, it's just a fancy way of saying "useful ways of thinking".</span></p> <p><span>In this post, I present a collection of mental models that are most relevant to the work of product managers. Some of these are borrowed from other disciplines. And they can be valuable additions to your toolbox for dealing with complexity.</span></p> <p><span>I intend for these to be jumping-off points for further thinking and learning. And not an exhaustive list. For a general introduction to mental models, here is a </span> <a href="https://fs.blog/mental-models/" target="_blank"><span>useful article by Farnam Street</span></a> <span>.</span></p> <p><span>Let's get started.</span></p>  <p><h2><span>Part 1: Learning </span></h2></p> <p><h3><span>Ensemble of Models</span></h3></p> <p><span>All models are wrong because they simplify. They omit details. For this reason, we should not rely on any single model. Instead, a many-model approach allows you to explain more and avoid blindspots. This works because the wrongness in each model tends to cancel out.</span></p> <p><span>Charlie Munger, an investor who popularized mental models, advocates combining them in a "latticework of models". And in machine learning, </span> <a href="https://en.wikipedia.org/wiki/Ensemble_learning" target="_blank"><span>ensemble methods</span></a> <span> can be an effective approach. </span></p> <p><span>This is useful when considering the diverse perspectives and opinions of your stakeholders.</span></p>  <p><h3><span>Learning by Doing</span></h3></p> <p><span>Which mental models matter in which circumstances? Knowing that is the hard part. </span></p> <p><span>A lot of skills and knowledge are implicit. They are hard to codify, or even articulate. You won't find them in neatly packaged books or elegant theories. </span></p> <p><span>But you can hone your judgment by maintaining contact with reality. You can put in iterations, and let your learning compound over time.</span></p>  <p><h3><span>Bayesian Updating</span></h3></p> <p><span>We get new information all the time. Feedback from a customer, changes in the industry, unforeseen challenges etc.</span></p> <p><span>Bayes' theorem provides a mathematical approach to weigh the old hypothesis (the "prior", initial belief) and new evidence. Bayesian inference is widely applicable in many areas, including AI and machine learning. Fun fact, it is also effective for </span> <a href="https://en.wikipedia.org/wiki/Bayesian_search_theory" target="_blank"><span>finding missing aircrafts</span></a> <span>.</span></p> <p><span>Here is an engaging introductory video on the topic.</span></p> <div><p><iframe src="https://www.youtube.com/embed/HZGCoVF3YvM?title=0&amp;byline=0&amp;portrait=0" frameborder="0"></iframe></p></div>  <p><h3><span>Process vs Outcome</span></h3></p> <p><span>It is tempting to judge our decisions by the outcome. But good decisions can lead to bad outcomes. And vice versa.</span></p> <p><span>Having a good process with a good outcome is ideal. Whereas a bad process with a good outcome is just gambling with blind luck.</span></p> <p><span>One way to calibrate your decisions over time is to document your decisions in a </span> <a href="https://fs.blog/2014/02/decision-journal/" target="_blank"><span>decision journal</span></a> <span>. Good things to write down include the context for the decision, alternatives and the range of outcomes, what you expect to happen, and how you feel mentally and physically.</span></p>  <p><h3><span>Dumb Idea Paradox</span></h3></p> <p><span>Many of the big success stories sounded stupid. Red Bull is an expensive drink that tastes disgusting. Snapchat is an app for sending disappearing photos. </span></p> <p><span>In the book </span> <a href="https://www.amazon.com/Loonshots-Nurture-Diseases-Transform-Industries-ebook/dp/B07D2BKVQR" target="_blank"><span>Loonshots</span></a> <span>, Safe Bahcall gave examples of brilliant ideas that had to survive "the Three Deaths" before finally succeeding. He wrote, "In the real world, ideas are ridiculed, experiments fail, budgets are cut, and good people are fired for stupid reasons." Andrew Chen also wrote about this in </span> <a href="https://andrewchen.co/dumb-idea-paradox/" target="_blank"><span>Dumb Idea Paradox</span></a> <span>.</span></p>  <p><h3><span>Satisficing</span></h3></p> <p><span>We make decisions in a world of uncertainty, with incomplete and imperfect information. Certainty is an illusion. It is better to be vaguely right than precisely wrong. </span></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Satisficing" target="_blank"><span>Satisficing</span></a> <span> (satisfy + suffice), introduced by&nbsp;</span> <a href="https://en.wikipedia.org/wiki/Herbert_A._Simon" target="_blank"><span>Herbert A. Simon</span></a> <span>, is about making decisions that are not perfect, but good enough. You can satisfice either by finding optimal solutions for a simplified world, or satisfactory solutions for a realistic one.</span></p>  <p><h2><span>Part 2: Collaboration &amp; Execution</span></h2></p> <p><h3><span>Maker's Schedule. Manager's Schedule</span></h3></p> <p><span>Context switching is costly, especially for creative work. In </span> <a href="http://www.paulgraham.com/makersschedule.html" target="_blank"><span>Paul Graham's popular essay</span></a> <span>, he discussed the cost of meetings and interruptions:</span></p> <p><em>"When you're operating on the maker's schedule, meetings are a disaster. A single meeting can blow a whole afternoon, by breaking it into two pieces each too small to do anything hard in."</em></p> <p><span>It is important to recognize the nature of different types of work. This way we can get more focused time for deep work, for ourselves and for our team.</span></p>  <p><h3><span>Working Memory and Cognitive Load</span></h3></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Working_memory" target="_blank"><span>Working memory</span></a> <span> is basically </span> <em>"how much stuff you can think about at the same time"</em> <span>. Each of us has a limited capacity. The "</span> <a href="https://en.wikipedia.org/wiki/The_Magical_Number_Seven%2C_Plus_or_Minus_Two" target="_blank"><span>magic number</span></a> <span>" of objects an average human can hold in short-term memory is 7, plus or minus 2.</span></p> <p><span>In the workplace, there is a lot of information to process. And the sheer load can quickly overwhelm our working memory.</span></p> <p><span>This calls for building a system to work around this. It could mean regular follow-ups, reminders, repetition, and good note-taking and documentation.</span></p>  <p><h3><span>Circle of Competence</span></h3></p> <p><span>Ôªø</span> <a href="https://en.wikipedia.org/wiki/Circle_of_competence" target="_blank"><span>Circle of competence</span></a> <span> is a mental model developed by Warren Buffett and Charlie Munger. Here's how Buffett summarized it:</span></p> <p><em>"Know your circle of competence, and stick within it. The size of that circle is not very important; knowing its boundaries, however, is vital."</em></p> <p><span>Being clear about what you know and what you think you know can keep your hubris in check. It can also help you identify blind spots and areas of improvement. </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/circle-of-competence.png"></p>  <p><h3><span>Batch Processing</span></h3></p> <p><span>Instead of completing tasks in the order that they come, you can often save time by grouping similar tasks together. It reduces costly context switching and interrupts by consolidating repetitive tasks that are not time-sensitive.</span></p> <p><span>This approach can be helpful in answering emails, reading news articles, processing customer feedback etc. As an added benefit, once you batch the tasks, they also tend to be easier to delegate or automate.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/batch-processing.png"></p>  <p><h3><span>Incentives</span></h3></p> <p><span>All living creatures respond to incentives. That is, the proverbial carrot and stick. Behaviours that are rewarded are reinforced.</span></p> <p><span>Knowing this helps us understand the true motivation of our partners, stakeholders, and even customers. This allows us to influence without direct power.</span></p>  <p><h3><span>Goodhart's Law</span></h3></p> <p><span>It is important to consider incentives when deciding measurements of success and metrics to focus on. </span></p> <p><span>Goodhart's Law was named after the economist Charles Goodhart. The general version, phrased by anthropologist Marilyn Strathern, states that "</span> <em>When a measure becomes a target, it ceases to be a good measure</em> <span>."
to be a good measure." </span></p> <p><span>It is possible that some stakeholders can "game the system" and artificially inflate metrics in ways that don't reflect customer value.</span></p> <p><span>We need to be careful about what to measure and consider the incentives of the individual stakeholders. </span></p>  <p><h3><span>Persuasion</span></h3></p> <p><span>To make change happen, persuasion is essential. I have compiled the models, principles, and tactics on this topic in a </span> <a href="https://informedpm.com/posts/persuasion-product-manager" target="_blank"><span>separate post</span></a> <span>. </span></p>  <p><h2><span>Part 3: Systems Thinking</span></h2></p> <p><span>Product managers routinely deal with complex systems. A product is a system of features, stakeholders, processes, customers, other players in the market, changing industry and economic trends etc.</span></p> <p><span>A system is more than the sum of its parts. Systems thinking allows us to better understand the interconnections of the different parts.</span></p>  <p><h3><span>Feedback Loops</span></h3></p> <p><span>A feedback loop is a closed chain of causal connections formed by routing an output of a system back as an input. </span></p> <p><span>Different feedback structures can produce drastically different behaviours. Balancing feedback loops lead to stability or an equilibrium. Whereas reinforcing feedback loops lead to exponential growth or collapses. </span></p> <p><span>Understanding the structure of the system helps us understand its behaviours.</span></p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/General_Feedback_Loop.svg/330px-General_Feedback_Loop.svg.png"></p>  <p><h3><span>Flywheel</span></h3></p> <p><span>The "</span> <a href="https://www.jimcollins.com/article_topics/articles/the-flywheel-effect.html" target="_blank"><span>flywheel effect</span></a> <span>" is a concept developed by researcher Jim Collins. It is a special kind of feedback loop (positive/reinforcing). Push the flywheel. Accelerate momentum. Then repeat.</span></p> <p><span>It is said that Bezos considered Amazon's application of the flywheel concept to be its "secret sauce". </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/Amazon%20flywheel.png"></p>  <p><h3><span>Non-Linearity</span></h3></p> <p><span>A linear relationship between two variables can be drawn on a chart with a straight line. In a non-linear relationship, the cause does not produce a proportional effect.     </span></p> <p><span>In a linear system, twice the push can produce twice the response. But in a nonlinear system, twice the push can produce the response squared, a sixth, or no response at all.</span></p> <p><span>For example, doubling the team headcount may yield 1.2X the output. Tripling the price may yield 10X the revenue. </span></p> <p><span>Many relationships in systems are non-linear. This is often a source of surprise. Beware of the trap of assuming (though more intuitive) linear relationships. </span></p>  <p><h3><span>Leverage Points </span></h3></p> <p><span>To get more of a desired outcome, we may have to change the structure of a system. There are leverage points in all systems, where the efforts you apply can yield disproportionate results. For instance, identifying and resolving a bottleneck in a process can be a force multiplier for your efforts.</span></p> <p><span>But as systems scientist </span> <a href="https://en.wikipedia.org/wiki/Donella_Meadows" target="_blank"><span>Donella Meadows</span></a> <span> pointed out, leverage points are often counter-intuitive. And there is no cheap way to mastering the art of identifying leverage points. Though in her book </span> <a href="https://www.amazon.com/Thinking-Systems-Primer-Donella-Meadows/dp/1603580557" target="_blank"><span>Thinking in Systems</span></a> <span>, she proposed a ranked list of leverage point candidates based on her experience. </span></p>  <p><h3><span>Second and Higher Order Effects</span></h3></p> <p><span>First-order effects are the direct consequences of an action. They tend to be immediate. They tend to be obvious. They tend to be static. Thinking in first-order effects often a dangerous over-simplification.</span></p> <p><span>In real life, each agent in the system can respond to changes. Second (and higher) order effects include the effects of subsequent actions. </span></p> <p><span>An example of first-order thinking would be to assume that introducing a new feature will lead to more users coming. Higher-order effects would include increasing technical complexity internally, cluttering and degrading the overall UX, competitors responding by copying the feature or launching a new product etc.</span></p>  <p><h2><span>Part 4: Strategy &amp; Planning</span></h2></p> <p><h3><span>Inversion</span></h3></p> <p><span>Inversion as a thinking tool turns the problem upside down. </span></p> <p><span>Instead of always starting at the beginning, sometimes it is beneficial to start at the end. This thinking can be useful in planning, where we start with the end goal and work backward. For instance, at Amazon, there is a practice of writing a ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://informedpm.com/posts/mental-models">https://informedpm.com/posts/mental-models</a></em></p>]]>
            </description>
            <link>https://informedpm.com/posts/mental-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059450</guid>
            <pubDate>Wed, 11 Nov 2020 16:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TypeScript splits the atom A first look at TS 4.1's new template literal types]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059336">thread link</a>) | @danvk
<br/>
November 11, 2020 | https://effectivetypescript.com/2020/11/05/template-literal-types/ | <a href="https://web.archive.org/web/*/https://effectivetypescript.com/2020/11/05/template-literal-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><img src="https://effectivetypescript.com/images/split-atom.png" width="324" height="298" alt="Splitting a string type"></p><p>TypeScript's type system has grown steadily more powerful over the past five years, allowing you to precisely type more and more patterns in JavaScript. The upcoming <a href="https://github.com/microsoft/TypeScript/issues/40124" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/40124', event);">TypeScript 4.1 release</a> includes a particularly exciting new <a href="https://github.com/microsoft/TypeScript/pull/40336" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/pull/40336', event);">addition</a> to the type system: <em>template literal types</em>.</p>
<p>Template literal types solve a <a href="https://github.com/microsoft/TypeScript/issues/12754" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/12754', event);">long-standing gap</a> in TypeScript's type system and, as I'll argue at the end of the post, they solve it in a particularly <em>TypeScripty</em> way.</p>
<p>To understand template literal types, let's start with a seemingly simple question: what can't you type?</p>
<h2 id="The-limits-of-type-safety-in-TypeScript"><a href="#The-limits-of-type-safety-in-TypeScript" title="The limits of type safety in TypeScript"></a>The limits of type safety in TypeScript</h2><p>My standard example of a pattern you <em>couldn't</em> type has always been the <code>camelCase</code> function, which maps something like <code>"foo_bar"</code> ‚Üí <code>"fooBar"</code>. It's easy to implement in JavaScript using a regular expression:</p>
<figure><div><pre><code><span><span>function</span> <span>camelCase</span>(<span>term</span>) </span>{<br>  <span>return</span> term.replace(<span>/_([a-z])/g</span>, <span><span>m</span> =&gt;</span> m[<span>1</span>].toUpperCase());<br>}<br></code></pre></div></figure>

<p>This function is trivial to <em>simply</em> type:</p>
<figure><div><pre><code><span>declare</span> <span><span>function</span> <span>camelCase</span>(<span>term: <span>string</span></span>): <span>string</span></span>;<br></code></pre></div></figure>

<p>So that's not quite what I'm getting at. Ideally you'd like to be able to use this to convert objects with <code>snake_cased</code> properties (like you'd get from a database) into one with <code>camelCased</code> properties (like you typically use in JS/TS). In other words, what should the return type of this function be to make the following code type check (or not) as you'd expect?</p>
<figure><div><pre><code><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>) </span>{<br>  <span>const</span> out: <span>any</span> = {};<br>  <span>for</span> (<span>const</span> [k, v] of <span>Object</span>.entries(obj)) {<br>    out[camelCase(k)] = v;<br>  }<br>  <span>return</span> out;<br>}<p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;  </p></code></pre></div></figure>

<p>Prior to TypeScript 4.1 (now a release candidate) this just wasn't possible. The reason was that string literal types like <code>"foo_bar"</code> were "atomic" in the sense that you couldn't observe any structure inside of them. They were indivisible. But clearly there <em>is</em> structure in strings. Just look at <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods" target="_blank" rel="noopener" onclick="return trackOutboundLink('the limits of type safety in typescript', 'https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods', event);">all the methods</a> on <code>String.prototype</code>.</p>
<p>Enter: TypeScript 4.1!</p>
<h2 id="TypeScript-splits-the-atom"><a href="#TypeScript-splits-the-atom" title="TypeScript splits the atom"></a>TypeScript splits the atom</h2><p>TypeScript 4.1 introduce a few features that make it possible to precisely type the <code>objectToCamel</code> function:</p>
<ol>
<li><em>Template literal types</em> This is the key advance. Template literal types allow you to find structure inside string literal types and create infinite, strict subsets of <code>string</code> (think "strings starting with <code>on</code>").</li>
<li><em>Key Remapping in Mapped Types</em> While it was possible to change the keys in an object before using tricks like <a href="https://effectivetypescript.com/2020/05/12/unionize-objectify/">Unionize and Objectify</a>, this new feature makes it much more straightforward.</li>
</ol>
<p>Let's use these two features to implement <code>objectToCamel</code>.</p>
<p>First, let's look at template literal types. They look like ES template literals:</p>
<figure><div><pre><code><span>type</span> OnString = <span>`on<span>${<span>string</span>}</span>`</span>;<br><span>const</span> onClick: OnString = <span>'onClick'</span>;<br><span>const</span> handleClick: OnString = <span>'handleClick'</span>;<br>   <br></code></pre></div></figure>

<p>This lets you create a type for "strings starting with <code>on</code>." Before TypeScript 4.1, you either had <code>string</code> or an enumerated union of string literal types (<code>"a" | "b" | "c"</code>). Now you can define structured subsets of <code>string</code>.</p>
<p>Here are a few other patterns:</p>
<figure><div><pre><code><span>type</span> IdNum = <span>`id<span>${<span>number</span>}</span>`</span>;<br><span>const</span> id1: IdNum = <span>'id123'</span>;  <br><span>const</span> id2: IdNum = <span>'idABC'</span>;   <p><span>type</span> Digit = <span>'0'</span> | <span>'1'</span> | <span>'2'</span> | <span>'3'</span> | <span>'4'</span> |<br>             <span>'5'</span> | <span>'6'</span> | <span>'7'</span> | <span>'8'</span> | <span>'9'</span>;<br><span>type</span> ThreeDigitNum = <span>`<span>${Digit}</span><span>${Digit}</span><span>${Digit}</span>`</span>;</p></code></pre></div></figure>

<p>What makes this really powerful is that you can use the <a href="https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/', event);"><code>infer</code> keyword</a> in a template literal type to do pattern matching:</p>
<figure><div><pre><code><span>type</span> ToCamel1&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;Tail&gt;}</span>`</span><br>    : S;<p><span>type</span> T = ToCamel1&lt;<span>'foo_bar'</span>&gt;;  </p></code></pre></div></figure>

<p>The conditional matches string literal types of the form <code>"head_tail"</code>. The "<code>_</code>" acts as a delimiter to split the string. Because <a href="https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types', event);">conditional types distribute over unions</a>, this also works for union types:</p>
<figure><div><pre><code><span>type</span> TU = ToCamel1&lt;<span>'first_name'</span> | <span>'last_name'</span>&gt;;<br><br></code></pre></div></figure>

<p>There's a big issue, though. What if there's two <code>_</code>s in the string literal type?</p>
<figure><div><pre><code><span>type</span> T2 = ToCamel1&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>We can't stop after the first "<code>_</code>", we need to keep going. We can do this by making the type recursive:</p>
<figure><div><pre><code><span>type</span> ToCamel&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;ToCamel&lt;Tail&gt;&gt;}</span>`</span><br>    : S;<br><span>type</span> T0 = ToCamel&lt;<span>'foo'</span>&gt;;  <br><span>type</span> T1 = ToCamel&lt;<span>'foo_bar'</span>&gt;;  <br><span>type</span> T2 = ToCamel&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>The recursive bit is where we call <code>ToCamel&lt;Tail&gt;</code>.</p>
<p>Pretty neat! Now let's put it all together.</p>
<h2 id="A-typed-objectToCamel"><a href="#A-typed-objectToCamel" title="A typed objectToCamel"></a>A typed objectToCamel</h2><p>Recall that a <a href="https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8', event);">mapped type</a> in TypeScript looks and works something like this:</p>
<figure><div><pre><code><span>interface</span> Vector {<br>  x: <span>number</span>;<br>  y: <span>number</span>;<br>}<br><span>type</span> Promisify&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T]: <span>Promise</span>&lt;T[K]&gt;  <br>};<br><span>type</span> VectorPromise = Promisify&lt;Vector&gt;;<br><br></code></pre></div></figure>

<p>The <code>keyof T</code> here produces a union of string literal types (<code>"x" | "y"</code>) and the mapped type produces an object type from this given a way to produce the values (the <code>Promise&lt;T[K]&gt;</code>). But the keys are set by the union. You can't change them.</p>
<p>With Key Remapping, you can add an <code>as</code> clause to the key in a mapped type to change things around. This works particularly well with template literal types:</p>
<figure><div><pre><code><span>interface</span> Student {<br>  name: <span>string</span>;<br>  age: <span>number</span>;<br>}<br><span>type</span> Evented&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> <span>`<span>${K &amp; <span>string</span>}</span>Changed`</span>]: <span>(<span>val: T[K]</span>) =&gt;</span> <span>void</span>;<br>}<br><span>type</span> StudentEvents = Evented&lt;Student&gt;;<br><br><br><br><br></code></pre></div></figure>

<p>(The <code>&amp; string</code> is there for technical reasons that I don't want to get into.)</p>
<p>Using this, we can plug in our <code>ToCamel</code> generic to put it all together:</p>
<figure><div><pre><code><span>type</span> ObjectToCamel&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> ToCamel&lt;K&gt;]: T[K]<br>};<p><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>): <span>ObjectToCamel</span>&lt;<span>T</span>&gt; </span>{<br>  <br>}</p><p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;<br>                <br>                </p></code></pre></div></figure>

<p>Here's a <a href="https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA', event);">complete playground</a>.</p>
<h2 id="What-can-should-you-do-with-template-literal-types"><a href="#What-can-should-you-do-with-template-literal-types" title="What can should you do with template literal types?"></a>What <del>can</del> should you do with template literal types?</h2><p>After template literal types landed, the TypeScript Twittersphere went crazy. I shared a use case around <a href="https://expressjs.com/en/guide/routing.html" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://expressjs.com/en/guide/routing.html', event);">express</a>, which quickly became the most popular tweet I've ever posted:</p>
<blockquote><p lang="en" dir="ltr">Another use of <a href="https://twitter.com/typescript?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/typescript?ref_src=twsrc%5Etfw', event);">@TypeScript</a> 4.1's template literal types: extracting the URL parameters from an express route. Pretty amazing you can do this in the type system! <a href="https://t.co/gfZQy70whg" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/gfZQy70whg', event);">https://t.co/gfZQy70whg</a> <a href="https://t.co/aEyfMwjjqX" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/aEyfMwjjqX', event);">pic.twitter.com/aEyfMwjjqX</a></p>‚Äî Dan Vanderkam (@danvdk) <a href="https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw', event);">September 4, 2020</a></blockquote> 

<p>A <a href="https://twitter.com/buildsghost/status/1301976526603206657" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/buildsghost/status/1301976526603206657', event);">JSON parser</a> made the rounds and then someone <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">implemented a full SQL engine</a> in the type system. Hacker news <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">was impressed</a>.</p>
<p>As with any new tool, it will take some time for the community to figure out the best ways to use it. Here are a few ideas. We'll see how they pan out!</p>
<ul>
<li><p>Dotted access: <strong>easy win</strong></p>
<p>Lodash allows you to write <a href="https://stackoverflow.com/a/43395675/388951" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://stackoverflow.com/a/43395675/388951', event);">"iteratee" expressions</a> like <code>xs.map('a.b.c')</code>, which is roughly the same as <code>xs.map(x =&gt; x.a.b.c)</code>. Template literal types will make it possible for this sort of API to be typed.</p>
<p>I've never been a big fan of this style. I'd prefer to write <code>x =&gt; x.a.b.c</code>. But perhaps some of this is just bias from not being able to type these properly in the past. Using string literals for enums, for example, is frowned upon in Java as unsafe, <a href="https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code', event);">stringly typed</a>, code. But it turns out to be fine in TypeScript because the type system is rich enough to capture it. So we'll see!</p>
</li>
<li><p>Parsing routes: <strong>huge win!</strong></p>
<p>See my tweet above. Parsing <code>{userId: string}</code> out of <code>/users/:userId</code> will be a big win for express users.</p>
<p>Going the other direction is also compelling. In a server I use at work, we issue API calls via something like <code>get('/users/:userId', {userId: 'id'})</code>. We have types defined for the parameters for each route. But now we can just let TypeScript infer them to ensure that nothing will ever get out of sync.</p>
<p>Similar considerations apply to routes with <a href="https://reactrouter.com/web/example/url-params" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://reactrouter.com/web/example/url-params', event);">react-router</a>.</p>
</li>
<li><p>Better types for <code>querySelector</code> / <code>querySelectorAll</code>: <strong>nice win</strong></p>
<p>The <a href="https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349', event);">DOM typings</a> are clever enough to infer a subtype of <code>Element</code> here:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input'</span>);<br><br></code></pre></div></figure>

<p>But once you add anything more complex to the selector, you lose this:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input.my-class'</span>);<br><br></code></pre></div></figure>

<p>With template literal types, it will be possible to fix this. I wouldn't be surprised if it becomes common practice to replace calls to <code>getElementById</code> with equivalent calls to <code>querySelector</code>:</p>
<figure><div><pre><code><span>const</span> el1 = <span>document</span>.getElementById(<span>'foo'</span>);<br><br><span>const</span> div = <span>document</span>.querySelector(<span>'div#foo'</span>);<br><br></code></pre></div></figure>

<p>This will no doubt require me to rewrite Item 55 of <a href="https://amzn.to/38s1oCK" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://amzn.to/38s1oCK', event);"><em>Effective TypeScript</em></a> ("Understand the DOM hierarchy"). Oh well!</p>
</li>
<li><p>Parsing options in <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a> or <a href="https://github.com/docopt/docopt.coffee" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/docopt/docopt.coffee', event);">docopt</a>: <strong>a small win</strong></p>
<p>With <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a>, you define your command line tool's arguments using something like this:</p>
<figure><div><pre><code>program<br>  .option(<span>'-d, --debug'</span>, <span>'output extra debugging'</span>)<br>  .option(<span>'-s, --small'</span>, <span>'small pizza size'</span>)<br>program.parse(process.argv);<br><span>console</span>.log(program.debug, program.small);<br></code></pre></div></figure>

<p>Setting aside the mutation style, which is hard to model in TypeScript, template literal types should make it possible to extract the parameter names from the calls to <code>.option</code>.</p>
</li>
<li><p>Parsing SQL or GraphQL: <strong>I could go either way!</strong></p>
<p>The <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">ts-sql</a> demo <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">raised some eyebrows</a>, but it also made a real point about the power of template literal types. Given a TypeScript version of your database schema (which can be generated using <a href="https://github.com/PSYT/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/PSYT/schemats', event);">schemats</a> or <a href="https://github.com/danvk/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/danvk/schemats', event);">pg-to-ts</a>), it should be possible to infer result types for a SQL query:</p>
<figure><div><pre><code><span>import</span> {Schema} <span>from</span> <span>'./dbschema'</span>;<p><span>async</span> <span><span>function</span> <span>getStudentsByAge</span>(<span>db: Pool, age: <span>number</span></span>) </span>{<br>  <span>const</span> result = <span>await</span> db.query&lt;Schema&gt;(<span>`</span><br><span>  SELECT first_name, last_name FROM students</span><br><span>  WHERE age = $1;</span><br><span>  `</span>, [age]);  <br>  <span>return</span> result.rows;<br>  <br>}</p></code></pre></div></figure>

<p>This seems potentially amazing, but also perhaps brittle. You'd have to work in the subset of SQL that your types understood: presumably you wouldn't want to implement all of <a href="https://en.wikipedia.org/wiki/PL/pgSQL" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://en.wikipedia.org/wiki/PL/pgSQL', event);">PL/pgSQL</a> in the type system. But I could imagine getting a large class of queries, including joins, to work.</p>
<p>So I'm on the fence on this one! Similar considerations apply to GraphQL queries, which would be a bit easier to join with a schema in the type system than raw SQL.</p>
</li>
</ul>
<p>Template literal types open up many new doors for TypeScript library authors and should improve the overall experience of using TypeScript for everyone by capturing more JavaScript patterns in the type system.</p>
<p>I'd like to conclude by pointing out that this is a very <em>TypeScripty</em> solution to this problem. ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://effectivetypescript.com/2020/11/05/template-literal-types/">https://effectivetypescript.com/2020/11/05/template-literal-types/</a></em></p>]]>
            </description>
            <link>https://effectivetypescript.com/2020/11/05/template-literal-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059336</guid>
            <pubDate>Wed, 11 Nov 2020 15:52:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ZX Spectrum 8-Bit Chiptune Music Collection: AY-3-8910, Beeper, Digital]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059328">thread link</a>) | @elvis70
<br/>
November 11, 2020 | https://zxart.ee/eng/music/ | <a href="https://web.archive.org/web/*/https://zxart.ee/eng/music/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zxart.ee/eng/music/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059328</guid>
            <pubDate>Wed, 11 Nov 2020 15:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the Webmention.io API]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059318">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/ | <a href="https://web.archive.org/web/*/https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
    <header>
      <p>Fetching my IndieWeb mentions with HTTPie and Requests</p><section>
      <p><time datetime="2020-11-10T00:00:00+00:00">
            <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">
              Tuesday, 10 November, 2020
            </a>
          </time>‚Äî by
          <br>
        <a href="https://randomgeekery.org/post">Post</a>
        ‚Äî <a href="https://randomgeekery.org/categories/tools/">Tools</a>
      
      
      
        ‚Äî
        
          <a href="https://randomgeekery.org/tags/python">Python</a>
        
          <a href="https://randomgeekery.org/tags/indieweb">IndieWeb</a>
        
          <a href="https://randomgeekery.org/tags/fixing-my-site">fixing my site</a>
        
          <a href="https://randomgeekery.org/tags/site">Site</a>
        
      <br>
        Around 1,300 words, or 6 minutes of reading</p><section><p>Part 1 of 1 in the
              <a href="https://randomgeekery.org/series/fixing-my-webmentions">fixing my webmentions</a> series.</p>
          <dl></dl></section>
        

        
        
<nav>
  <section>
    <header>
      
      Previous Post
    </header>
    
      <p>
        <a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">Tangling code from Hugo content with Raku</a>
      </p>
      
    
  </section>
  <section>
    <header>
      Next Post
      
    </header>
    
      <p><em>You are reading the newest post</em></p>
    
  </section>
</nav>

      </section>
  
  
  
    
  

  <figure>
    <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg">
      <img src="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg" alt="A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.">
    </a><figcaption>A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.</figcaption></figure>


    </header>
    <section>

      <p>So I hosed a local copy of my mentions feed the other month.
What‚Äôs my ‚Äúmentions feed,‚Äù I hear you wondering?</p>
<p>Whenever somebody shares a reaction to something here ‚Äî like, reshare, reply, mention ‚Äî that reaction gets sent to <a href="https://webmention.io/">Webmention.io</a>.
There are more moving parts than that, of course.
<a href="https://brid.gy/">Bridgy</a> aggregates reactions to my announcement toots and tweets and sends those to Webmention.
It shows in my mentions feed as a reaction to site content when someone reacts to a relevant tweet.</p>
<p><em>Sometimes</em> folks even post mentions, replies, and reactions directly to the Webmention endpoint.
Mostly it‚Äôs just social media reactions, though.</p>
<p>The <a href="https://github.com/aaronpk/webmention.io#api">Webmention.io API</a> lets me gather all of these reactions.</p>
<p>Let‚Äôs acquaint ourselves with the important parts of this API.
You‚Äôll need your API token, which can be found in the Webmention <a href="https://webmention.io/settings">Settings</a> once you sign up.</p>
<h2 id="reading-the-feed-with-httpie">Reading the feed with HTTPie</h2>
<p>I‚Äôll use <a href="https://httpie.io/">HTTPie</a> for my little exploration.
I like the way it works.</p>
<h3 id="getting-recent-reactions">Getting recent reactions</h3>
<p>We mainly care about the mentions endpoint.
Hand it your domain and API token, and it will send you the 20 most recent responses for your site.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span>
</code></pre></div><p>HTTPie‚Äôs double-equals <code>==</code> syntax means ‚Äúmake a query string,‚Äù so I end up with something like this:</p>
<div><pre><code data-lang="text">https://webmention.io/api/mentions.jf2?domain=randomgeekery.org&amp;token=xxxxx
</code></pre></div><p>When <code>http</code> fetches that URL, I get back a <a href="https://www.w3.org/TR/jf2/">JF2</a> feed that looks something like this.</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Jumpei KAWAMI"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"text"</span><span>:</span> <span>"I wrote a note:\n\nI added this note from org mode‚Ä¶"</span>
            <span>},</span>
            <span>"published"</span><span>:</span> <span>"2020-10-25T23:32:25+00:00"</span><span>,</span>
            <span>"repost-of"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw/status/1320508544601509889"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>887739</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"repost-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-10-26T04:07:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/repost/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span>
        <span>},</span>
        <span>‚ãÆ</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>What‚Äôs JF2?
It‚Äôs obviously JSON.
Maybe something to do with <a href="https://jsonfeed.org/">JSON Feed</a>?
Similar, but no.
JF2 is a JSON format for IndieWeb‚Äôs <a href="http://microformats.org/wiki/microformats2">microformats2</a>.
The mnemonic I‚Äôve been trying to drill into my head is ‚ÄúJSON (micro)Formats 2.‚Äù</p>
<p>It‚Äôs not a very good mnemonic.</p>
<p>Each entry summarizes the reaction, including which of my posts they were reacting to.
That‚Äôs kind of important.
Most recently, Twitter user <a href="https://twitter.com/junkw">junkw</a> retweeted my announcement about <a href="https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/">adding a note from Org mode</a>.</p>
<div>
  <p>Note</p><p>

  There‚Äôs also a <code>.json</code> endpoint for every feed that presents a different structure for mentions.
I prefer it, because it contains fewer <code>wm-*</code> fields.
But the documentation uses JF2, so that‚Äôs what I‚Äôll do.</p></div>

<h3 id="checking-for-new-reactions">Checking for new reactions</h3>
<p>Maybe I‚Äôm checking again later and only want to see the <em>new</em> reactions.
I request mentions received since the value of the <code>wm-received</code> field in the last entry I have.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Well, yeah.
That makes sense.
I don‚Äôt get the kind of traffic where you‚Äôd expect fresh reactions every time you check.</p>
<h3 id="fetching-the-oldest-reactions-first">Fetching the oldest reactions first</h3>
<p>As I mentioned at the start, my site is a little broken.
I need to rebuild the full list of reactions so my <a href="https://randomgeekery.org/tags/hugo">Hugo</a> site can work with a complete record.
To do that, I should probably start from the oldest mentions and work my way forward.</p>
<p>Rather than the default <code>sort-dir</code> of <code>down</code>, I specify <code>up</code>.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Steve Scaffidi"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy‚Ä¶"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy‚Ä¶"</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-02-18T03:11:58+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium/status/1229604443651526656"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>757935</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-02-18T22:32:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Aww, my first site reply.
From <a href="https://twitter.com/hercynium">hercynium</a>.</p>
<p>I only get 20 results by default, though.
Here.
Let‚Äôs make <a href="https://stedolan.github.io/jq/">jq</a> show us.
Here‚Äôs a default page.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> sort-dir<span>==</span>up <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>20
</code></pre><h3 id="handling-result-pagination">Handling result pagination</h3>
<p>I can specify how many responses I want in each response with the <code>per-page</code> parameter.
With <code>per-page</code> set to 100, I get a hundred entries.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> per-page<span>==</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>100
</code></pre><p>Of course, if there aren‚Äôt a hundred entries to fill the page, I only get what‚Äôs available.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span> per-page<span>=</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>0
</code></pre><p>The <code>page</code> parameter ‚Äî which starts at zero ‚Äî lets me step through the feed in batches.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up <span>\
</span><span></span>  <span>page</span><span>==</span><span>1</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"brian wisti"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/‚Ä¶"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"‚Ä¶"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"‚Ä¶"</span><span>,</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-03-10T06:24:45+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti/status/1237263101482823681"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>766993</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-03-10T06:38:55Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/‚Ä¶"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span>
        <span>},</span>
        <span>‚ãÆ</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Right.
That‚Äôs Bridgy catching a Twitter thread.
At least I can see the full conversation from my site.
Or I wil once I‚Äôm done fixing everything.</p>
<h3 id="bonus-checking-for-reactions-to-a-specific-post">Bonus: checking for reactions to a specific post</h3>
<p>I could get a JF2 feed for specific URLs on my site if I was so inclined.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>target</span><span>==</span>https://randomgeekery.org
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>""</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>""</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>""</span>
            <span>},</span>
            <span>"mention-of"</span><span>:</span> <span>"https://randomgeekery.org"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>null</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>796241</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"mention-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-05-14T11:25:47Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>I deal with my site reactions in bulk so they can be incorporated in the Hugo build.
This could be handy for JavaScript-driven update on reactions since the site was last built and pushed, though.</p>
<h2 id="rebuilding-the-local-mentions-file">Rebuilding the local mentions file</h2>
<p>Now I want to take what I learned about the API to build a local copy of my site‚Äôs mention history.
Let‚Äôs step away from HTTPie and the command line before I try something dangerous.</p>
<p>The <a href="https://requests.readthedocs.io/en/master/">requests</a> library for <a href="https://randomgeekery.org/tags/python">Python</a> can help me build one list of Webmentions.</p>
<div><pre><code data-lang="python"><span>import</span> <span>json</span>
<span>import</span> <span>os</span>
<span>import</span> <span>time</span>

<span>import</span> <span>requests</span>

<span>def</span> <span>rebuild_full_feed</span><span>(</span><span>domain</span><span>:</span> <span>str</span><span>,</span> <span>token</span><span>:</span> <span>str</span><span>,</span> <span>target_file</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>endpoint</span> <span>=</span> <span>"https://webmention.io/api/mentions.jf2"</span>
    <span>page_size</span> <span>=</span> <span>100</span>
    <span>all_entries</span> <span>=</span> <span>[]</span>
    <span>page_index</span> ‚Ä¶</code></pre></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</a></em></p>]]>
            </description>
            <link>https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059318</guid>
            <pubDate>Wed, 11 Nov 2020 15:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instacart Web Performance Audit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059265">thread link</a>) | @toddgardner
<br/>
November 11, 2020 | https://requestmetrics.com/web-performance/performance-profiling-instacart | <a href="https://web.archive.org/web/*/https://requestmetrics.com/web-performance/performance-profiling-instacart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Grocery shopping is tedious and time consuming.  In search of a more streamlined experience, I decided to try Instacart.  Unfortunately, using their site is <em>also</em> tedious and time consuming.</p>

<!--more-->

<h2 id="common-actions-take-too-long">Common Actions Take Too Long</h2>
<p>In the video you‚Äôll see I attempt to visit the landing page of my local grocery store and, after that loads, do a search for <em>yogurt</em>.</p>

<figure>
    <video controls="" muted="" preload="metadata">
        <source src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-load-and-search.mp4" type="video/mp4">
    </video>
    <figcaption>Visiting a grocery store homepage and searching for items.</figcaption>
</figure>

<p>Over <strong>25</strong> seconds to perform a single load and search.  Just loading the Cub Foods ‚Äústorefront‚Äù page took <strong>14</strong> seconds and <strong>154</strong> requests.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-total-stats.png" alt="Loading a single storefront">
    <figcaption>Network stats for loading a single storefront in Instacart.</figcaption>
</figure>

<p>On the plus side there were some very nice placeholder graphics that set the mood while I waited.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-placeholder.png" alt="Placeholder graphics for days">
</figure>

<h3 id="when-its-not-javascripts-fault">When it‚Äôs not JavaScript‚Äôs Fault</h3>
<p>Usually when I look at ‚Äúmodern‚Äù websites the main performance culprit is JavaScript.  Too many scripts doing too much rendering.  While Instacart <em>does</em> have too much JavaScript, they have a bigger problem: <strong>the server</strong>.</p>

<h4 id="the-initial-page-load-is-slow">The Initial Page Load is Slow</h4>
<p>Instacart uses some combination of server and client rendering.  On the one hand, it‚Äôs great that they don‚Äôt just load a blank page with a big spinner in the middle and wait for 20MB of JavaScript to load.</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-page.png" alt="3 seconds to load the basic page skeleton">
</figure>
<p>On the other hand it took <strong>3</strong> seconds to get the single page layout skeleton back.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-skeleton.png" alt="Just a basic SPA template">
    <figcaption>Three seconds for some placeholder template HTML is a bit long.</figcaption>
</figure>

<p>The images to populate the placeholder template took another few seconds:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-image.png" alt="4 seconds for a background image">
</figure>

<p>If you notice the first segment of the URL after the Cloudfront domain is <code>/156x/</code>. These endpoints will return custom sized images and that first segment is the requested dimensions.  You can change that segment to <code>/300x/</code>, for example, and you‚Äôll get a bigger image that maintains aspect ratio (it will be 300px wide by whatever the height should be to keep the ratio).  You can also specify a height if you want a different effect:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-custom-image-size.png" alt="Custom images sizes are great, but costly for performance">
</figure>

<p>Cool, but this is almost certainly part of the reason loading uncached images is so slow. The origin behind Cloudfront is doing a lot of work to make a custom image and send it over the wire on-demand.</p>

<p>In all fairness, these images have the proper cache response headers, so subsequent page loads will have the images served from the browser memory cache.  But that first hit is very slow.</p>

<h4 id="the-api-is-slow-too">The API is Slow Too</h4>
<p>It isn‚Äôt just the page load and images that are slow.  The servers responding to API requests are taking their time as well.  Some of the calls to populate data on the page took over <strong>5</strong> seconds!</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-api.png" alt="Several API calls took over 5 seconds">
</figure>

<p>One of the endpoints shown here fetches coupon information.  In the initial loading video you can see the coupon section is particularly slow to render.  Even though there is content loaded below the fold, the user has no idea since the placeholders are still shown for the coupon section until that call returns.</p>

<h4 id="placeholders-are-nice-but-faster-endpoints-are-better">Placeholders are Nice But Faster Endpoints are Better</h4>

<p>This is where the hybrid rendering model falls apart a bit.  There is a lot of dynamic content being rendered post page load.  And since the API is slow the user is getting even more placeholders.</p>

<p>As the user scrolls down the page there are on-demand API calls made to show products from each grocery department.  These calls can take upwards of 2 seconds each.  And there‚Äôs a lot of them.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-department.png" alt="On-demand API calls to load additional products are slow.">
</figure>

<p>For each one we get more placeholder graphics until the server returns its response:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-more-placeholders.png" alt="Placeholders are cool, but speed would be better.">
</figure>

<p>Placeholders do a nice job of minimizing jank or <a href="https://requestmetrics.com/web-performance/cumulative-layout-shift">cumulative layout shift</a> but they are a poor substitute for the actual content.  Paradoxically I find they can also make a site feel slower since the UI is changing out from under the user so frequently.</p>

<h3 id="maybe-instacart-doesnt-think-it-has-a-performance-problem">Maybe Instacart Doesn‚Äôt Think It Has a Performance Problem?</h3>
<p>There‚Äôs a <a href="https://tech.instacart.com/building-instacarts-view-model-api-part-1-why-view-model-4362f64ffd2a">few articles</a> on <a href="https://tech.instacart.com/scaling-at-instacart-distributing-data-across-multiple-postgres-databases-with-rails-13b1e4eba202">the Instacart engineering blog</a> discussing the back-end technical implementation of the site.  In both the linked articles they discuss ‚Äúimproved performance‚Äù and the existing ‚Äúhealthy performance‚Äù of the site.  Perhaps the main problem is they don‚Äôt think there‚Äôs a performance issue to fix?</p>

<p>Most modern technical stacks are capable of serving pages and API calls in sub-second time if that‚Äôs the company‚Äôs goal.  I suspect in this case they have limited resources and other priorities.  Maybe things are better in the phone app, but I think I‚Äôll stick with going to the grocery store for now, it‚Äôs faster.</p>

</div></div>]]>
            </description>
            <link>https://requestmetrics.com/web-performance/performance-profiling-instacart</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059265</guid>
            <pubDate>Wed, 11 Nov 2020 15:44:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25059205">thread link</a>) | @jessems
<br/>
November 11, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>. I've come to beleive a goal of preserving user privacy is often inherently in tension with the goal of advancing user productivity.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which ‚Äî crucially ‚Äî includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has found adopters in anyone from principled libertarians to journalists and human rights activitists whose lives may depend on their conversations remaining unwiretapped.</p><h2>Early privacy-preserving software was too difficult to use</h2><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most salient reason, however, seems to be that to this day, it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG was the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><h2>Surveillance capitalist companies will not encrypt your data, because they rely on being able to read it</h2><p>One such email provider, Gmail by Google, gained millions of users by offering a free plan. Their initial monetization strategy was scanning your emails and serving you personalized ads. Although they've stopped personalizing the ads, they're still scanning your email's contents to serve you a better experience across their services. Similarly, Facebook tracks what you do to shape your experience and keep you glued (they would say 'engaged') to their platform.</p><p>What unites platforms like Google and Facebook, is described by Professor Shoshana Zuboff as ‚Äú<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>‚Äù. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. You might be the user, but you're not the customer ‚Äî the advertisers are.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><h2>Data is also collected to improve the service</h2><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By offering this as a paid service, Google exposes itself to a different incentive, one where the customer and the user are now one and the same.</p><p>Even if you're both the user and the customer, your data is still being harvested. This data might not feed into personalized ads (because that‚Äôs no longer the primary business model) but rather into improving your experience. But as a business user, when does your experience improve? And as a service provider, how do you know what improves the experience?</p><h2>Improvements are productivity gains</h2><p>There's an inclination to think of improvements as things that help you do the thing you want to do quicker, better and/or with less frustration. We can go one step further and borrow some of the thinking used in economics and treat productivity simply as the ratio between outputs (salaries and corporate profits) and inputs (hours worked). Productivity increases if inputs can be decreased (for equal outputs) or outputs can be increased (for equal inputs). What's more, we would expect this quantity to improve along with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task (decreased input), all other things being equal, we‚Äôll end up seeing those gains reflected in our outputs.</p><h2>Productivity gains are discovered, not planned</h2><p>What exactly are the things that increase efficiency? Here's where it gets tricky. In the realm of knowledge work, we don't always know where the gains will come from ‚Äî that is, before they are made. We are still discovering new ways in which we can be more productive and especially so in the domain of collaborative productivity. An illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this potential existed wasn't at all  obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn‚Äôt obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>Although there's some inherent uncertainty about what the productivity gains will look like (and where to look for them), there's no uncertainty about whether they will be made at all. If one thing can be counted on, it's the tech industry's relentless march towards higher productivity. The big tech platforms know this and don't shy away from investing heavily in innovation (discovery) in that direction.</p><h2>Productivity gains are unlocked by harvesting data</h2><p>Although there is some inherent tension between preserving privacy vs. allowing for a multiplayer mode like Figma, we can find even stronger tensions when it comes to harvesting data in favor of productivity gains.</p><p>A search feature relies on indexing your data. A recommendation feature relies on mining your browsing history. An autocomplete feature relies on what you (or other users) typed before.</p><p>All these potential features which are made possible through harvesting your user data are not available to privacy-preserving products. The user data isn't readable to them ‚Äî and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><h2>The productivity gap between privacy-preserving and non-preserving services</h2><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there‚Äôs a gap between the two ‚Äî and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059205</guid>
            <pubDate>Wed, 11 Nov 2020 15:37:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25059009">thread link</a>) | @lettergram
<br/>
November 11, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I‚Äôm am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it‚Äôs possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes‚Äô favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it‚Äôs so wide spread or there‚Äôs a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It‚Äôs also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden‚Äôs up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a ‚Äúsoftware bug‚Äù in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they‚Äôve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on ‚Äúhow to distract GOP poll watchers‚Äù</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I‚Äôm not sure I believe all the claims.</p>
<p>However, I think it‚Äôs very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it‚Äôs important we identify fraud and / or improve the process so this doesn‚Äôt happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this‚Ä¶</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I‚Äôm not convinced this wont lead to violence. I‚Äôm concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059009</guid>
            <pubDate>Wed, 11 Nov 2020 15:14:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058805">thread link</a>) | @wojtekmach
<br/>
November 11, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> Jos√© Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard ‚Äúyou may not need Redis with Elixir‚Äù. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir‚Äôs different features against Redis‚Äô capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won‚Äôt receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now ‚Äî the ‚Äúwho‚Äù may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let‚Äôs consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let‚Äôs say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that‚Äôs 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir‚Äôs clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn‚Äôt require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang‚Äôs unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let‚Äôs start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let‚Äôs consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let‚Äôs continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that ‚Äúyou should avoid blocking the main thread‚Äù. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won‚Äôt block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058805</guid>
            <pubDate>Wed, 11 Nov 2020 14:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systematically removing code]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25058632">thread link</a>) | @jerodsanto
<br/>
November 11, 2020 | https://thepugautomatic.com/2020/11/systematically-removing-code/ | <a href="https://web.archive.org/web/*/https://thepugautomatic.com/2020/11/systematically-removing-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><hgroup><p><span>Written November 8, 2020. <span>Tagged <a href="https://thepugautomatic.com/tag/methodology">Methodology</a>.</span></span></p></hgroup><div><p>It's easy to miss things when removing code, leaving behind unused methods, templates, CSS classes or translation keys. (Especially in a dynamic language like Ruby, without a compiler to help you spot dead code.)</p><p>I avoid this by removing code systematically, line by line, depth-first.</p><p>This is one of those things that seems obvious when you do it, but in my experience, many people do it haphazardly.</p><p>Say we wanted to remove the "item box" from this page:</p><p>page.html.erb</p><pre><code><span><span><span>&lt;</span>p</span><span>&gt;</span></span>Welcome to my page!<span><span><span>&lt;/</span>p</span><span>&gt;</span></span><p><span><span>&lt;%=</span> render<span>(</span><span>"item_box"</span><span>,</span> item<span>:</span> item<span>)</span> <span>%&gt;</span></span></p></code></pre><p>_item_box.html.erb</p><pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>box box--fancy<span>"</span></span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>So our end goal is to remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line.</p><p>First, we search the project to check that <code>_item_box.html.erb</code> isn't used somewhere else, or referenced in docs that we'll need to update. It isn't, so we're OK to remove it ‚Äì but before we do that, we must go through it line by line.</p><p>The first line is <code>&lt;div class="box box--fancy"&gt;</code>. So we search the project for these two CSS classes, checking if they're in use somewhere else. If not, we remove them from the CSS files.</p><p>We go deeper if required ‚Äì perhaps the CSS for <code>.box--fancy</code> uses a CSS variable. Then we check if that variable is in use elsewhere. <a href="https://thepugautomatic.com/2014/03/stacked-vim-searches-down-cold/">Stacked searches in Vim</a> are helpful here.</p><p>Once we've checked a line in the file, we delete that line. This helps us keep track of what we've already checked.</p><p>So after we've checked and removed that line, we're left with</p><p>_item_box.html.erb</p><pre><code>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>And we continue this way, line by line. Is the <code>item.title</code> used elsewhere? If not, we should probably remove it, too. What about <code>format_description</code>, <code>item.description</code>, the <code>my.translation.key</code> translation key?</p><p>Again, we go deeper if required, not removing the <code>format_description</code> method until we've gone through <em>it</em> line by line.</p><p>When we've looked at every line in <code>_item_box.html.erb</code> and deleted them as we went, the file will be empty, and we can start popping the stack.</p><p>We remove the empty <code>_item_box.html.erb</code> file.</p><p>And we can finally remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line, fairly confident that we didn't leave dead code behind.</p><p>This probably sounds more tedious than it is. It tends to be quick work, and you can take shortcuts ‚Äì removing a swathe of lines that don't reference anything else, or that only call methods that you know are used elsewhere.</p></div></section></div><div><p>Content and design ¬© <a href="https://henrik.nyh.se/">Henrik Nyh</a> (<a href="https://twitter.com/henrik">@henrik</a>). Code is under a <a href="http://en.wikipedia.org/wiki/MIT_License">MIT License</a> unless otherwise stated.</p><p>Pug art by <a href="https://johannaost.com/">Johanna √ñst</a>; other graphics are under a <a href="http://creativecommons.org/licenses/by/3.0/">CC BY License</a>.</p><p>Powered by <a href="https://11ty.dev/">Eleventy</a>.</p></div></div>]]>
            </description>
            <link>https://thepugautomatic.com/2020/11/systematically-removing-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058632</guid>
            <pubDate>Wed, 11 Nov 2020 14:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Linear Algebra for Applied Machine Learning with Python]]>
            </title>
            <description>
<![CDATA[
Score 380 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25058619">thread link</a>) | @Anon84
<br/>
November 11, 2020 | https://pabloinsente.github.io/intro-linear-algebra | <a href="https://web.archive.org/web/*/https://pabloinsente.github.io/intro-linear-algebra">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        
<!-- https://docs.mathjax.org/en/latest/configuration.html#local-config-files -->




<article>
  <h2>Introduction to Linear Algebra for Applied Machine Learning with Python</h2>
  <time datetime="2020-05-26T00:00:00+00:00">26 May 2020</time>
  

  

<p>Linear algebra is to machine learning as flour to bakery: <strong>every machine learning model is based in linear algebra, as every cake is based in flour</strong>. It is not the only ingredient, of course. Machine learning models need vector calculus, probability, and optimization, as cakes need sugar, eggs, and butter. Applied machine learning, like bakery, is essentially about combining these mathematical ingredients in clever ways to create useful (tasty?) models.</p>

<p>This document contains <strong>introductory level linear algebra notes for applied machine learning</strong>. It is meant as a reference rather than a comprehensive review. If you ever get confused by matrix multiplication, don‚Äôt remember what was the $L_2$ norm, or the conditions for linear independence, this can serve as a quick reference. It also a good introduction for people that don‚Äôt need a deep understanding of linear algebra, but still want to learn about the fundamentals to read about machine learning or to use pre-packaged machine learning solutions. Further, it is a good source for people that learned linear algebra a while ago and need a refresher.</p>

<p>These notes are based in a series of (mostly) freely available textbooks, video lectures, and classes I‚Äôve read, watched and taken in the past. If you want to obtain a deeper understanding or to find exercises for each topic, you may want to consult those sources directly.</p>

<p><strong>Free resources</strong>:</p>

<ul>
  <li><strong>Mathematics for Machine Learning</strong> by Deisenroth, Faisal, and Ong. 1st Ed. <a href="https://mml-book.github.io/">Book link</a>.</li>
  <li><strong>Introduction to Applied Linear Algebra</strong> by Boyd and Vandenberghe. 1sr Ed. <a href="http://vmls-book.stanford.edu/">Book link</a></li>
  <li><strong>Linear Algebra Ch. in Deep Learning</strong> by Goodfellow, Bengio, and Courville. 1st Ed. <a href="https://www.deeplearningbook.org/contents/linear_algebra.html">Chapter link</a>.</li>
  <li><strong>Linear Algebra Ch. in Dive into Deep Learning</strong> by Zhang, Lipton, Li, And Smola. <a href="https://d2l.ai/chapter_preliminaries/linear-algebra.html">Chapter link</a>.</li>
  <li><strong>Prof. Pavel Grinfeld‚Äôs Linear Algebra Lectures</strong> at Lemma. <a href="https://www.lem.ma/books/AIApowDnjlDDQrp-uOZVow/landing">Videos link</a>.</li>
  <li><strong>Prof. Gilbert Strang‚Äôs Linear Algebra Lectures</strong> at MIT. <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/">Videos link</a>.</li>
  <li><strong>Salman Khan‚Äôs Linear Algebra Lectures</strong> at Khan Academy. <a href="https://www.khanacademy.org/math/linear-algebra">Videos link</a>.</li>
  <li><strong>3blue1brown‚Äôs Linear Algebra Series</strong> at YouTube. <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Videos link</a>.</li>
</ul>

<p><strong>Not-free resources</strong>:</p>

<ul>
  <li><strong>Introduction to Linear Algebra</strong> by Gilbert Strang. 5th Ed. <a href="https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/0980232775">Book link</a>.</li>
  <li><strong>No Bullshit Guide to Linear Algebra</strong> by Ivan Savov. 2nd Ed. <a href="https://www.amazon.com/No-bullshit-guide-linear-algebra/dp/0992001021">Book Link</a>.</li>
</ul>

<p>I‚Äôve consulted all these resources at one point or another. Pavel Grinfeld‚Äôs lectures are my absolute favorites. Salman Khan‚Äôs lectures are really good for absolute beginners (they are long though). The famous 3blue1brown series in linear algebra is delightful to watch and to get a solid high-level view of linear algebra.</p>

<p>If you have to pic one book, I‚Äôd pic <strong>Boyd‚Äôs and Vandenberghe‚Äôs Intro to applied linear algebra</strong>, as it is the most beginner friendly book on linear algebra I‚Äôve encounter. Every aspect of the notation is clearly explained and pretty much all the key content for applied machine learning is covered. The Linear Algebra Chapter in Goodfellow et al is a nice and concise introduction, but it may require some previous exposure to linear algebra concepts. Deisenroth et all book is probably the best and most comprehensive source for linear algebra for machine learning I‚Äôve found, although it assumes that you are good at reading math (and at math more generally). Savov‚Äôs book it‚Äôs also great for beginners but requires time to digest. Professor Strang lectures are great too but I won‚Äôt recommend it for absolute beginners.</p>

<p>I‚Äôll do my best to keep notation consistent. Nevertheless, learning to adjust to changing or inconsistent notation is a useful skill, since most authors will use their own preferred notation, and everyone seems to think that its/his/her own notation is better.</p>

<p>To make everything more dynamic and practical, I‚Äôll introduce bits of Python code to exemplify each mathematical operation (when possible) with <code>NumPy</code>, which is the facto standard package for scientific computing in Python.</p>

<p>Finally, keep in mind this is created by a non-mathematician for (mostly) non-mathematicians. I wrote this as if I were talking to myself or a dear friend, which explains why my writing is sometimes conversational and informal.</p>

<p>If you find any mistake in notes feel free to reach me out at pcaceres@wisc.edu and to https://pablocaceres.org/ so I can correct the issue.</p>



<p><strong>Note:</strong> <em>underlined sections</em> are the newest sections and/or corrected ones.</p>

<p><strong><a href="#preliminary-concepts">Preliminary concepts</a></strong>:</p>
<ul>
  <li><a href="#sets">Sets</a></li>
  <li><a href="#belonging-and-inclusion">Belonging and inclusion</a></li>
  <li><a href="#set-specification">Set specification</a></li>
  <li><a href="#ordered-pairs">Ordered pairs</a></li>
  <li><a href="#relations">Relations</a></li>
  <li><a href="#functions">Functions</a></li>
</ul>

<p><strong><a href="#vectors">Vectors</a></strong>:</p>
<ul>
  <li><a href="#types-of-vectors">Types of vectors</a>
    <ul>
      <li><a href="#geometric-vectors">Geometric vectors</a></li>
      <li><a href="#polynomials">Polynomials</a></li>
      <li><a href="#elements-of-r">Elements of R</a></li>
    </ul>
  </li>
  <li><a href="#zero-vector-unit-vector-and-sparse-vector">Zero vector, unit vector, and sparse vector</a></li>
  <li><a href="#vector-dimensions-and-coordinate-system">Vector dimensions and coordinate system</a></li>
  <li><a href="#basic-vector-operations">Basic vector operations</a>
    <ul>
      <li><a href="#vector-vector-addition">Vector-vector addition</a></li>
      <li><a href="#vector-scalar-multiplication">Vector-scalar multiplication</a></li>
      <li><a href="#linear-combinations-of-vectors">Linear combinations of vectors</a></li>
      <li><a href="#vector-vector-multiplication-dot-product">Vector-vector multiplication: dot product</a></li>
    </ul>
  </li>
  <li><a href="#vector-space-span-and-subspace">Vector space, span, and subspace</a>
    <ul>
      <li><a href="#vector-space">Vector space</a></li>
      <li><a href="#vector-span">Vector span</a></li>
      <li><a href="#vector-subspaces">Vector subspaces</a></li>
    </ul>
  </li>
  <li><a href="#linear-dependence-and-independence">Linear dependence and independence</a></li>
  <li><a href="#vector-null-space">Vector null space</a></li>
  <li><a href="#vector-norms">Vector norms</a>
    <ul>
      <li><a href="#euclidean-norm">Euclidean norm: $L_2$</a></li>
      <li><a href="#manhattan-norm">Manhattan norm: $L_1$</a></li>
      <li><a href="#max-norm">Max norm: $L_\infty$</a></li>
    </ul>
  </li>
  <li><a href="#vector-inner-product-length-and-distance">Vector inner product, length, and distance</a></li>
  <li><a href="#vector-angles-and-orthogonality">Vector angles and orthogonality</a></li>
  <li><a href="#systems-of-linear-equations">Systems of linear equations</a></li>
</ul>

<p><strong><a href="#matrices">Matrices</a></strong>:</p>

<ul>
  <li><a href="#basic-matrix-operations">Basic matrix operations</a>
    <ul>
      <li><a href="#matrix-matrix-addition">Matrix-matrix addition</a></li>
      <li><a href="#matrix-scalar-multiplication">Matrix-scalar multiplication</a></li>
      <li><a href="#matrix-vector-multiplication-dot-product">Matrix-vector multiplication: dot product</a></li>
      <li><a href="#matrix-matrix-multiplication">Matrix-matrix multiplication</a></li>
      <li><a href="#matrix-identity">Matrix identity</a></li>
      <li><a href="#matrix-inverse">Matrix inverse</a></li>
      <li><a href="#matrix-transpose">Matrix transpose</a></li>
      <li><a href="#hadamard-product">Hadamard product</a></li>
    </ul>
  </li>
  <li><a href="#special-matrices">Special matrices</a>
    <ul>
      <li><a href="#rectangular-matrix">Rectangular matrix</a></li>
      <li><a href="#square-matrix">Square matrix</a></li>
      <li><a href="#diagonal-matrix">Diagonal matrix</a></li>
      <li><a href="#upper-triangular-matrix">Upper triangular matrix</a></li>
      <li><a href="#lower-triangular-matrix">Lower triangular matrix</a></li>
      <li><a href="#symmetric-matrix">Symmetric matrix</a></li>
      <li><a href="#identity-matrix">Identity matrix</a></li>
      <li><a href="#scalar-matrix">Scalar matrix</a></li>
      <li><a href="#null-or-zero-matrix">Null or zero matrix</a></li>
      <li><a href="#echelon-matrix">Echelon matrix</a></li>
      <li><a href="#antidiagonal-matrix">Antidiagonal matrix</a></li>
      <li><a href="#design-matrix">Design matrix</a></li>
    </ul>
  </li>
  <li><a href="#matrices-as-systems-of-linear-equations">Matrices as systems of linear equations</a></li>
  <li><a href="#the-four-fundamental-matrix-subsapces">The four fundamental matrix subsapces</a>
    <ul>
      <li><a href="#the-column-space">The column space</a></li>
      <li><a href="#the-row-space">The row space</a></li>
      <li><a href="#the-null-space">The null space</a></li>
      <li><a href="#the-null-space-of-the-transpose">The null space of the transpose</a></li>
    </ul>
  </li>
  <li><a href="#solving-systems-of-linear-equations-with-matrices">Solving systems of linear equations with matrices</a>
    <ul>
      <li><a href="#gaussian-elimination">Gaussian Elimination</a></li>
      <li><a href="#gauss-jordan-elimination">Gauss-Jordan Elimination</a></li>
    </ul>
  </li>
  <li><a href="#matrix-basis-and-rank">Matrix basis and rank</a></li>
  <li><a href="#matrix-norm">Matrix norm</a></li>
</ul>

<p><strong><a href="#linear-and-affine-mappings">Linear and affine mappings</a></strong>:</p>

<ul>
  <li><a href="#linear-mappings">Linear mappings</a></li>
  <li><a href="#examples-of-linear-mappings">Examples of linear mappings</a>
    <ul>
      <li><a href="#negation-matrix">Negation matrix</a></li>
      <li><a href="#reversal-matrix">Reversal matrix</a></li>
    </ul>
  </li>
  <li><a href="#examples-of-nonlinear-mappings">Examples of nonlinear mappings</a>
    <ul>
      <li><a href="#norms">Norms</a></li>
      <li><a href="#translation">Translation</a></li>
    </ul>
  </li>
  <li><a href="#affine-mappings">Affine mappings</a>
    <ul>
      <li><a href="#affine-combination-of-vectors">Affine combination of vectors</a></li>
      <li><a href="#affine-span">Affine span</a></li>
      <li><a href="#affine-space-and-subspace">Affine space and subspace</a></li>
      <li><a href="#affine-mappings-using-the-augmented-matrix">Affine mappings using the augmented matrix</a></li>
    </ul>
  </li>
  <li><a href="#special-linear-mappings">Special linear mappings</a>
    <ul>
      <li><a href="#scaling">Scaling</a></li>
      <li><a href="#reflection">Reflection</a></li>
      <li><a href="#shear">Shear</a></li>
      <li><a href="#rotation">Rotation</a></li>
    </ul>
  </li>
  <li><a href="#projections">Projections</a>
    <ul>
      <li><a href="#projections-onto-lines">Projections onto lines</a></li>
      <li><a href="#projections-onto-general-subspaces">Projections onto general subspaces</a></li>
      <li><a href="#projections-as-approximate-solutions-to-systems-of-linear-equations">Projections as approximate solutions to systems of linear equations</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#matrix-decompositions">Matrix decompositions</a></strong>:</p>
<ul>
  <li><a href="#lu-decomposition">LU decomposition</a>
    <ul>
      <li><a href="#elementary-matrices">Elementary matrices</a></li>
      <li><a href="#the-inverse-of-elementary-matrices">The inverse of elementary matrices</a></li>
      <li><a href="#lu-decomposition-as-gaussian-elimination">LU decomposition as Gaussian Elimination</a></li>
      <li><a href="#lu-decomposition-with-pivoting">LU decomposition with pivoting</a></li>
    </ul>
  </li>
  <li><a href="#qr-decomposition">QR decomposition</a>
    <ul>
      <li><a href="#orthonormal-basis">Orthonormal basis</a></li>
      <li><a href="#orthonormal-basis-transpose">Orthonormal basis transpose</a></li>
      <li><a href="#gram-schmidt-orthogonalization">Gram-Schmidt Orthogonalization </a></li>
      <li><a href="#qr-decomposition-as-gram-schmidt-orthogonalization">QR decomposition as Gram-Schmidt Orthogonalization</a></li>
    </ul>
  </li>
  <li><a href="#determinant">Determinant</a>
    <ul>
      <li><a href="#determinant-as-measures-of-volume">Determinant as measures of volume</a></li>
      <li><a href="#the-2-x-2-determinant">The 2X2 determinant</a></li>
      <li><a href="#the-n-x-n-determinant">The NXN determinant</a></li>
      <li><a href="#determinants-as-scaling-factors">Determinants as scaling factors</a></li>
      <li><a href="#the-importance-of-determinants">The importance of determinants</a></li>
    </ul>
  </li>
  <li><a href="#eigenthings">Eigenthings</a>
    <ul>
      <li><a href="#change-of-basis">Change of basis</a></li>
      <li><a href="#eigenvectors-eigenvalues-and-eigenspaces">Eigenvectors, Eigenvalues, and Eigenspaces</a></li>
      <li><a href="#trace-and-determinant-with-eigenvalues">Trace and determinant with eigenvalues</a></li>
      <li><a href="#eigendecomposition">Eigendecomposition</a></li>
      <li><a href="#eigenbasis-are-a-good-basis">Eigenbasis are a good basis</a></li>
      <li><a href="#geometric-interpretation-of-eigendecomposition">Geometric interpretation of Eigendecomposition</a></li>
      <li><a href="#the-problem-with-eigendecomposition">The problem with Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#singular-value-decomposition">Singular Value Decomposition</a>:
    <ul>
      <li><a href="#singular-value-decomposition-theorem">Singular Value Decomposition Theorem</a></li>
      <li><a href="#singular-value-decomposition-computation">Singular Value Decomposition computation</a></li>
      <li><a href="#geometric-interpretation-of-the-singular-value-decomposition">Geometric interpretation of the Singular Value Decomposition</a></li>
      <li><a href="#singular-value-decomposition-vs-eigendecomposition">Singular Value Decomposition vs Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#matrix-approximation">Matrix Approximation</a>:
    <ul>
      <li><a href="#best-rank-k-approximation-with-svd">Best rank-k approximation with SVD</a></li>
      <li><a href="#best-low-rank-approximation-as-a-minimization-problem">Best low-rank approximation as a minimization problem</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#epilogue">Epilogue</a></strong></p>



<p>While writing about linear mappings, I realized the importance of having a basic understanding of a few concepts before approaching the study of linear algebra. If you are like me, you may not have formal mathematical training beyond high school. If so, I encourage you to read this section and spent some time wrapping your head around these concepts before going over the linear algebra content (otherwise, you might prefer to skip this part). I believe that reviewing these concepts is of great help to understand the <em>notation</em>, which in my experience is one of the main barriers to understand mathematics for nonmathematicians: we are <em>non</em>native speakers, so we are continuously building up our vocabulary. I‚Äôll keep this section very short, as is not the focus of this mini-course.</p>

<p>For this section, my notes are based on readings of:</p>

<ul>
  <li><strong>Geometric transformations (Vol. 1)</strong> (1966) by Modenov &amp; Parkhomenko</li>
  <li><strong>Naive Set Theory</strong> (1960) by P.R. Halmos</li>
  <li><strong>Abstract Algebra: Theory and Applications</strong> (2016) by Judson &amp; Beeer. <a href="http://abstract.pugetsound.edu/download/aata-20160809.pdf">Book link</a></li>
</ul>

<h2 id="sets">Sets</h2>

<p>Sets are one of the most fundamental concepts in mathematics. They are so fundamental that they are not defined in terms of anything else. On the contrary, other branches of mathematics are defined in terms of sets, including linear algebra. Put simply, <strong>sets are well-defined collections of objects</strong>. Such objects are called <strong>elements or members</strong> of the set. The crew of a ship, a caravan of camels, and the LA Lakers roster, are all examples of sets. The captain of the ship, the first camel in the caravan, and LeBron James are all examples of ‚Äúmembers‚Äù or ‚Äúelements‚Äù of their corresponding sets. We denote a set with an upper case italic letter as $\textit{A}$. In the context of linear algebra, we say that a line is a set of points, and the set of all lines in the plane is a set of sets. Similarly, we can say that <em>vectors</em> are sets of points, and <em>matrices</em> sets of vectors.</p>

<h2 id="belonging-and-inclusion">Belonging and inclusion</h2>

<p>We build sets using the notion of <strong>belonging</strong>. We denote that $a$ <em>belongs</em> (or is an <em>element</em> or <em>member</em> of) to $\textit{A}$ with the Greek letter epsilon as:</p>



<p>Another important idea is <strong>inclusion</strong>, which allow us to build <em>subsets</em>. Consider sets $\textit{A}$ and $\textit{B}$. When every element of $\textit{A}$ is an element of $\textit{B}$, we say that $\textit{A}$ is a <em>subset</em> of $\textit{B}$, or that $\textit{B}$ <em>includes</em> $\textit{A}$. The notation is:</p>



<p>or</p>



<p>Belonging and inclusion are derived from <strong>axion of extension</strong>: <em>two sets are equal if and only if they have the same elements</em>. This axiom may sound trivially obvious but is necessary to make belonging and ‚Ä¶</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pabloinsente.github.io/intro-linear-algebra">https://pabloinsente.github.io/intro-linear-algebra</a></em></p>]]>
            </description>
            <link>https://pabloinsente.github.io/intro-linear-algebra</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058619</guid>
            <pubDate>Wed, 11 Nov 2020 14:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What mother never told you about VM service (1983) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058543">thread link</a>) | @fanf2
<br/>
November 11, 2020 | http://www.leeandmelindavarian.com/Melinda/tutorial.pdf | <a href="https://web.archive.org/web/*/http://www.leeandmelindavarian.com/Melinda/tutorial.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.leeandmelindavarian.com/Melinda/tutorial.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058543</guid>
            <pubDate>Wed, 11 Nov 2020 14:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058502">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://matklad.github.io//2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io//2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that ‚ÄúSmalltalk IDE is the best we‚Äôve ever had‚Äù.</p>
<p>Note that ‚Äúsemantic understanding‚Äù is mostly unrelated to the traditional interpretation of ‚ÄúIDE‚Äù as <em>Integrated</em> Development Environment.
I personally don‚Äôt feel that the ‚ÄúIntegrated‚Äù bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there‚Äôs an ample room for improvement for the integration bits.
For me, <strong>I</strong> in ‚Äú<strong>I</strong>DE‚Äù stands for ‚Äúintelligent‚Äù, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
‚ÄúUnix and command line can do anything an IDE can do‚Äù is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It‚Äôs <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like ‚Äúsometimes I type vim, sometimes I type vi, they are sufficiently similar‚Äù.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It‚Äôs the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim‚Äôs text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you‚Äôll get the ‚Äúassists‚Äù system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; ‚Äúswap arguments‚Äù, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don‚Äôt ‚Äúopen a file‚Äù.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often‚Äâ‚Äî‚Äâyou don‚Äôt need bookmarks if you can just find things.</p>
<p>For me, there‚Äôs one aspect of traditional editors which is typically not matched in IDEs out of the box‚Äâ‚Äî‚Äâbasic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim‚Äôs <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for ‚Äúgo to symbol by fuzzy name‚Äù functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough‚Äâ‚Äî‚Äâit made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE‚Äôs guesses.</p>
<p>There‚Äôs C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don‚Äôt know why it didn‚Äôt happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There‚Äôs a saying that you can‚Äôt write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript‚Ä¶‚Äã
Well, you first need to build n alternative language for which you can actually implement and an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io//2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058502</guid>
            <pubDate>Wed, 11 Nov 2020 14:09:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$200k in sales from a $6k advertisement]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 102 (<a href="https://news.ycombinator.com/item?id=25058363">thread link</a>) | @mildlyclassic
<br/>
November 11, 2020 | https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad | <a href="https://web.archive.org/web/*/https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <div>
        <div>
          <div>


          
            <table>
                <thead>
                  <tr>
                    <th>
                      Metric
                    </th>
                    <th>
                      Count
                    </th>
                  </tr>
                </thead>
                <tbody>
                <tr data-href="#!">
                    <td>
                      Time period
                    </td>
                    <td>
                      Aug 17,2020 - Aug 24,2020
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Visitors
                    </td>
                    <td>
                      7,200
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Emails
                    </td>
                    <td>
                      45
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Video calls
                    </td>
                    <td>
                      30
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Units sold</strong>
                    </td>
                    <td>
                      <b>10</b>
                    </td>
                  </tr>   
                  <tr data-href="#!">
                    <td>
                      <strong>Unit price</strong>
                    </td>
                    <td>
                      <b>$20,000</b>
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Total revenue from DF</strong>
                    </td>
                    <td>
                      <b>$200,000</b>
                    </td>
                  </tr>
                  
                </tbody>
              </table>
              
              
          <ul>
              <li>
                Build cheap broadband distribution technology.
              </li>
              <li>
                Prove the tech works by connecting 1M people in one city.
              </li>
              <li>
                Deploy across 1,000 cities in India
              </li>
            </ul>

            

            <p>
                Our goal at <a href="https://www.wifidabba.com/">Wifi Dabba</a> is to lower the cost of broadband access in India. We use lasers instead of underground fiber as our core network and commodity components to dramatically lower the cost of deploying a broadband network.
            
                We've been running a beta network in Bengaluru, India for the last 9 months serving thousands of live customers. We're now ready to deploy a city wide network and provide cheap internet access to a million people.
            </p>

            <iframe width="100%" height="450" src="https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1" srcdoc="<style>*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}</style><a href=https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1><img width='100%' style='min-height:250px;' src='https://img.youtube.com/vi/LwVWJXBNQg8/hqdefault.jpg' alt='Wifi Dabba overview'><span>‚ñ∂</span></a>" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="Wifi Dabba overview"></iframe>

            
            <p>
              A core tenet of the Wifi Dabba network is distributed ownership. We believe that ownership of the internet should be in the hands of as many people as possible. If the cost of broadband tech drops, then more people can help pay for the cost of the network.
              And if you're one of the people paying for the distribution, we believe you should get revenue in return.
            </p>

            <p>
              We've divided the city of Bengaluru into 100 regions called PoPs. Anyone can buy a region and get a share in the revenue from those subscribers. 
            </p>

            <p>
              The Wifi Dabba franchise model:
            </p>

            <ul>
              <li>
                <strong>$20,000</strong> to purchase a 4sqkm. PoP.
              </li>
              <li>
                <strong>Minimum guaranteed revenue</strong> Paid quarterly with a 6 year rev share agreement.
              </li>
              <li>
                <strong>Fully managed service</strong> Be an absentee landlord
              </li>
            </ul>

            

            <p>
              <span>We've sold 40 as of the time of writing this.</span>
              <br>
              
              Wifi Dabba is insanely lucky for the amount of public support we have as a company. We regularly get phone calls, emails and even people dropping by our office just to tell us they like our service. Over the last 3 years we've received dozens of emails from people requesting franchises or other types of partnerships.
              We're incredibly humbled and thankful for this support on a daily basis.
            </p>

            
            <p>
              We believe there is a large group of people that care about the future of the internet and would be willing to put their money where their mouths are. As long as the price and the level of risk involved is reasonable.
              Our gut told us that this group would most likely be people that have seen success in the technology business as engineers, operators and entreprenuers.
            </p>

            
            <p>
              We've had our heads down over the last three years building and testing our network stack. Publicity or notariety has never been high on our list. 
              We've begun ramping up our social media efforts but it was clear that to kickstart our outreach, we had to do a little bit of advertising.
            </p>

            
            
              <p><img src="https://www.wifidabba.com/images/df-venn.png" height="300" width="330" alt="...">
                <br>
              </p>
            <p>
              <a href="https://www.daringfireball.net/">Daringfireball.net</a> is a great blog authored by <a href="https://en.wikipedia.org/wiki/John_Gruber">John Gruber</a> who is also the creator of <a href="https://daringfireball.net/projects/markdown/">Markdown</a>.
              DF was a natural choice for us as we've been readers of the blog for a long while and we knew from experience that DF readers would fit our target market rather well. Given the high quality of John's writing and insights into the industry, we felt that there would be a large pool of senior tech veterans that would be interested in Wifi Dabba among DF's audience.
            </p>

            <p>
                The sponsorship cost us $6,500 and ran for the week starting Aug 17, 2020 and we got:
                </p><ul>
                <li>
                  A display ad in the sidebar on every page of the site, all week long.
                </li>
                <li>
                  A post from the sponsor in the RSS feed at the start of the week. Us, the sponsor, got to address Daring Fireball‚Äôs most dedicated readers directly.
                </li>
                <li>
                  At the end of the week, John also posts an item thanking and linking to the feed sponsor.
                </li>
              </ul>
            

            <p>
                Stats about DF readership
                </p><ul>
                <li>
                Typical weekday web page views: 80,000‚Äì100,000.
                </li>
                <li>
                Estimated monthly web page views: 2.5 million.
                </li>
                <li>
                Estimated Daring Fireball RSS feed subscribers: Over 200,000.
                </li>
                <li>
                Twitter followers on the @daringfireball  account: Over 92,000.
                </li>
              </ul>
            
            

            
            <p>
                We created two variants of our message. Designed in bold colours to stand out against DF's dark theme. These creatives rotated randomly.
                We decided to focus on the technology because of the nature of the audience and hoped that the website did a good job of explaining the product.  
                </p><p><img src="https://www.wifidabba.com/images/df-ads.png" width="100%" alt="Buy internet POP">
                </p>
            

            
            <div>
                <p><strong>Click Ad -&gt; Browse site -&gt; Setup a call</strong></p><p>

                We expected visitors to click on the ad in DF and land on our homepage. Once on our site, we hoped that visitors would check out our videos as well as browse through a few pages.
                If they liked what they saw, we had a prominent buy button on the front page which led to a page to setup a video call.
            </p></div>

            <p>
                It's worth noting here that we knew going in that a large percentage of DF's audience would be using Ad-blockers. Nothing wrong with that, we use ad-blockers ourselves.
            </p>

            <p>
              Furthermore, we made a deliberate choice to add a high friction call to action and contact process. In order to purchase a PoP, a visitor would be directed to a calendar managed by calendly that would help them setup a call with someone from our team at a convenient time.
            </p>
            <p><a href="https://wifidabba.com/buy">
              <img width="100%" src="https://www.wifidabba.com/images/df-buy.png" alt="Setup Call">
            </a></p><p>
              The reason for this is that we knew DF would deliver a few hundred visitors a day to our site. We're a small team and our core focus is deploying the network, not necessarily sales and our goal is to sell the PoPs to people that are really excited a lot about our idea and show a high level of interest.
              The $20,000 price point of our product + the high friction of the contact process + users that are OK with ads = A high signal to noise ratio from DF visitors. 
              We'd love to hear any feedback on what you think about this.
            </p>

            
              

              <p>
                Our thesis turned out to be pretty spot on. Senior engineers from Google, Apple and a host of other technology companies purchased the PoPs.
                The actual sales process turned out to be fairly quick and straight forward. Most of the people that purchased the PoPs did so within a period of 48 hours of having the call.
              </p>

              



          </div>
        </div>
    </div>
    </section></div>]]>
            </description>
            <link>https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058363</guid>
            <pubDate>Wed, 11 Nov 2020 13:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executing GraphQL Queries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058361">thread link</a>) | @chmaynard
<br/>
November 11, 2020 | https://jemma.dev/blog/executing-graphql-queries | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/executing-graphql-queries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://graphql.org/">GraphQL</a> is surging in popularity as a preferred choice for APIs over REST APIs. One of the reasons many companies cite for converting their APIs from REST to GraphQL is its ease of use. If you know JSON, GraphQL is incredibly intuitive. And there are helpful tools like <a href="https://github.com/graphql/graphiql">GraphiQL</a>, an in browser GraphQL IDE.</p>

<p>Even with its usability, there are still a few pointers which are helpful to learning GraphQL. GitHub implemented their <a href="https://developer.github.com/v4/">API v4</a> using GraphQL. Let‚Äôs work through an example using <a href="https://developer.github.com/v4/explorer/">GitHub‚Äôs GraphiQL explorer</a> to hit the GitHub API as a way to learn some basic GraphQL:</p>

<h3 id="graphiql-keyboard-shortcuts">GraphiQL Keyboard Shortcuts</h3>

<p>Before we start, take a look at these keyboard shortcuts I frequently use when working in the GraphiQL IDE:</p>

<ul>
  <li>Auto Complete: Ctrl-Space (or Option-Space)</li>
  <li>Run query: Ctrl-Enter</li>
  <li>Format query: Ctrl-Shift-P</li>
</ul>

<h3 id="githubs-graphiql-explorer">GitHub‚Äôs GraphiQL Explorer</h3>

<p>When you open up <a href="https://developer.github.com/v4/explorer/">GitHub‚Äôs GraphiQL explorer</a>, you‚Äôll see three panes. The top left is a query editor for our GraphQL query to GitHub‚Äôs API; bottom left is for query variables; and the right side will display query results when we hit the API.</p>

<p>After signing in with your GitHub account details, Hit play (Ctrl-Enter) on the query which GitHub autofills! You‚Äôll see your login displayed on the right side of the screen. The first item to note here is that the result mirrors the syntax and format of the query. This is a big part of what makes GraphQL so intuitive! The API responses mirror the API requests.</p>

<h3 id="reading-the-docs">Reading the Docs</h3>

<p>Towards the right of the GraphiQL explorer, there‚Äôs a <code>&lt; Docs</code> button. Toggle it! (This is not to be confused with the topbar menu <code>Docs</code> dropdown.) The <code>&lt; Docs</code> will toggle a little interface which tells us what to expect in our queries, and helps us when we use incorrect syntax. It will let us search by type.</p>

<p>Your first question, though, might be, how will we know the type of our data? In GraphQL, we can use <code>__typename</code> on any data to get its type. For instance, we can edit the query we just wrote:</p>

<div><div><pre><code>query <span>{</span>
  viewer <span>{</span>
    __typename
  <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>and we‚Äôll see that <code>viewer</code> has the type <code>"User"</code>. If we now search the docs for <code>"User"</code>, we‚Äôll see there are many <code>"Fields"</code> on user which we can explore. Try adding a few fields to your initial query.</p>

<h3 id="user">User</h3>

<p>Well, there must also be other <code>"User"</code>s we can access instead of just ourselves. Let‚Äôs try it! Replace <code>viewer</code> in the query from above with <code>user</code>. When we run this snippet, we‚Äôll see an error:</p>

<div><div><pre><code>query <span>{</span>
  user <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The error will appear on our right pane. The error message tells us our problem, <code>"Field 'user' is missing required arguments: login"</code> Ah! We haven‚Äôt told GraphQL <em>which</em> user we‚Äôre interested in. As it suggests, let‚Äôs pass in a user‚Äôs login. <a href="https://github.com/torvalds">Linus Torvalds</a> created git, so he seems like an appropriate user to play with. His login is <code>torvalds</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Neat. On the right side of your screen you should see that he‚Äôs had a GitHub account since 2011.</p>

<h3 id="connections">Connections</h3>

<p>When looking at the <code>User</code> docs, you might have noticed a type suffixed with <code>"Connection"</code>, for instance, <code>followers</code> has type <code>"FollowerConnection"</code>.</p>

<p>In GraphQL, <code>User</code> is a <code>Node</code>. Nodes have edges, and lists of these edges are called <code>Connections</code>. A <code>Connection</code> is a way to see all nodes that are connected to a certain node in a specific way. In our case, we‚Äôre looking for all <code>followers</code> nodes which are connected to Linus Torvalds. (See <a href="https://www.apollographql.com/blog/explaining-graphql-connections-c48b7c3d6976/">this Apollo blog post</a> for further reading about connections.)</p>

<p>If we try typing <code>followers</code> in the query, GraphiQL will give us an indication of an error. Hovering, we can read the error message, saying that <code>followers</code> must have a selection of subfields. This is where GraphiQL is incredibly helpful. Hit run (Ctrl-enter) after typing <code>followers</code>, and GraphiQL will autocomplete what its asking for:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>GraphiQL has auto-filled in the <code>edges</code>, <code>node</code> and <code>id</code> field on <code>followers</code> as defaults to give us some data about Linus‚Äô followers. This makes sense given what we know about edges and nodes: followers has <code>edges</code> and each of these is a <code>node</code>.</p>

<p>But, if we look to the right side of our screen, we‚Äôll see we have an error instead of results. The type <code>"MISSING_PAGINATION_BOUNDARIES"</code> and message <code>"You must provide a 'first' or 'last' value to properly paginate the 'followers' connection."</code> are both helpful here.</p>

<p>One of GraphQL‚Äôs real features is that it never returns more data than you ask it for. That said, we must tell it exactly how much data we want, by using (as prompted), the <code>first</code> or <code>last</code> field to limit the number of followers we‚Äôre asking for. Let‚Äôs look at Linus‚Äô last 5 followers:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This worked! But the <code>id</code>s aren‚Äôt particularly informative. We can see the type of <code>followers</code> by again using <code>__typename</code>. Or, we can use Ctrl-space to autoprompt some fields we might be interested in. Instead of the <code>id</code> field on a <code>node</code>, let‚Äôs look at <code>name</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          name
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Aha, we can see the name of a few of Linus‚Äô followers. But, exactly how popular is he? For that, we can use the <code>totalCount</code> field under <code>followers</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As of the writing of this post, he has 124,812 followers. Notably, <code>totalCount</code> was <em>not</em> limited by our pagination. This is because it is only returning a single value, not a series of values.</p>

<h3 id="query-variables">Query Variables</h3>

<p>Reading this, you might have been curious how many followers a different user has. For that, we could replace <code>"torvalds"</code> with a different user‚Äôs login. Or, we could learn about Query Variables!</p>

<p>This is the last remaining pane (on the bottom left) which we haven‚Äôt touched yet.</p>

<p>We first need to declare the argument within our query. GraphQL requires a type here. We‚Äôll need to declare it in two places. The first is passing it into the query itself. The syntax is <code>query ($variable_name:type!) { ...</code> In our case, we want to pass a <code>login</code> of type <code>String</code>, so <code>query ($login:String!) {...</code>. Secondly, we want this to be our user‚Äôs login. So we can replace <code>torvalds</code> with <code>$login</code> as follows:</p>

<div><div><pre><code>query <span>(</span><span>$login</span>:String!<span>)</span> <span>{</span>
  user<span>(</span>login: <span>$login</span><span>)</span> <span>{</span>
    name
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
     totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>If we run this, our error message tells us that <code>"Variable $login of type String! was provided invalid value"</code>! Ah! We still didn‚Äôt use our bottom left ‚ÄúQuery Variables‚Äù pane. Let‚Äôs fill it in. Again, we can use the Ctrl-space to help us out: <code>{"login": "jemmaissroff"}</code>. If we now hit run, we‚Äôll see (among other things) that I have <em>significantly</em> fewer followers than Linus Torvalds.</p>

<h3 id="tldr">TL;DR</h3>

<p>For those short on time or attention:</p>

<ul>
  <li>GraphQL query results mirror JSON, making them easy to parse, write and reason about</li>
  <li><a href="https://github.com/graphql/graphiql">GraphiQL</a> is a helpful GraphQL IDE</li>
  <li><code>__typename</code> gives the type of an item, helpful for reading the docs</li>
  <li>Some queries have required arguments to limit the scope of a search, like <code>login</code> for user</li>
  <li>Pagination is a feature of GraphQL, requiring us to limit our queries, sometimes using <code>first</code> or <code>last</code></li>
  <li>Query variables must have a type and be named in the query declaration</li>
  <li>Query variables then can be used throughout the query itself by referencing the name in the declaration</li>
</ul>

<p>For an example of a queries which uses a few additional features of GraphQL, check out the queries I wrote <a href="https://github.com/jemmaissroff/find_github_email/blob/main/lib/find_github_email/queries.rb">here</a> for a Ruby gem to <a href="https://github.com/jemmaissroff/find_github_email">find GitHub users‚Äô emails</a>.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/executing-graphql-queries</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058361</guid>
            <pubDate>Wed, 11 Nov 2020 13:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NodeJVM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058252">thread link</a>) | @mooreds
<br/>
November 11, 2020 | https://mikehearn.github.io/nodejvm/ | <a href="https://web.archive.org/web/*/https://mikehearn.github.io/nodejvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/mikehearn/nodejvm/edit/master/docs/index.md" title="Edit this page">Óèâ</a>
                
                
                
<p>This repository demonstrates how to use NodeJS/npm modules directly from Java and Kotlin. Why is it useful:</p>
<ul>
<li>Gain access to unique JavaScript modules, like the Dat peer to peer file sharing framework shown in the samples.</li>
<li>Combine your existing NodeJS and Java servers together, eliminating the overheads of REST, serialisation, two separate
  virtual machines. Simplify your microservices architecture into being a polyglot architecture instead.</li>
<li>Use it to start porting NodeJS apps to the JVM world and languages, incrementally, one chunk at a time, whilst always
  having a runnable app. Or do the reverse.</li>
</ul>
<h2 id="how-does-it-work">How does it work?<a href="#how-does-it-work" title="Permanent link">¬∂</a></h2>
<p><a href="https://www.graalvm.org/">GraalVM</a> is a modified version of OpenJDK that includes the cutting edge Graal and Truffle compiler infrastructure.
It provides an advanced JavaScript engine that has competitive performance with V8, and also a modified version of
NodeJS 10 that swaps out V8 for this enhanced JVM. In this way you can fuse together NodeJS and the JVM, allowing apps
to smoothly access both worlds simultaneously with full JIT compilation.</p>
<h2 id="known-limitations">Known limitations<a href="#known-limitations" title="Permanent link">¬∂</a></h2>
<p>NodeJS really wants to load module files from the filesystem and nowhere else, so your Java app will need a <code>node_modules</code>
directory from where it's started. There are tricks to work around this and allow bundling of JS into JAR files as
libraries, but nothing done at the moment.</p>
<p>GraalVM uses NodeJS 10, not the latest versions.</p>
<p>You change <code>java</code> on the command line to <code>nodejvm</code> and that's all it needs, but many tools and IDEs expect the java
launcher to always be called <code>java</code>.  </p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://mikehearn.github.io/nodejvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058252</guid>
            <pubDate>Wed, 11 Nov 2020 13:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Defense of GnuPG]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058064">thread link</a>) | @m3rcury
<br/>
November 11, 2020 | https://www.oyd.org.tr/en/articles/defense-of-gpg/ | <a href="https://web.archive.org/web/*/https://www.oyd.org.tr/en/articles/defense-of-gpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>
    
     
      
    <p>For several years, there has been an uprasing against GPG. Every now and then someone writes up a blog post and condemn OpenPGP and it‚Äôs implementations for being too hard to use or too easy to mess up. The GPG side is mostly silent. So, this article is in defence of GPG.</p>
<p>Main points made against GPG can be listed like this:</p>
<ol start="0">
<li>GPG is too complicated for ‚Äúnormal‚Äù users</li>
<li>Because GPG is too complicated, it‚Äôs userbase is minuscule</li>
<li>Email is inherently impossible to secure so don‚Äôt even bother encrypting it. Just abandon GPG</li>
<li>Nobody bothers to read emails of ‚Äúnormal‚Äù people so don‚Äôt encrypt</li>
<li>TLS has done much more for email security than GPG</li>
<li>GPG is error prone and security wise it is dangerous for people to use it when actual security is needed</li>
<li>For various reasons, only cryptonerds use it and take pride on GPG so it is lame</li>
<li>GPG‚Äôs trust model (web of trust) is broken and only cryptonerds are keeping it alive</li>
<li>GPG is old</li>
<li>There are better [insert anything involving app like crypto tool] why bother with GPG</li>
<li>GPG crypto has [Insert any long term RSA based cryptography‚Äôs short comings and trust problems] why not use modern crypto</li>
</ol>
<p>During these discussion, these point are mostly assumed to be true;</p>
<ol start="0">
<li>People are stupid and lazy so are the users of encryption tools</li>
<li>Since users are stupid and lazy tools should be designed keeping that in mind</li>
<li>Designing for stupid and lazy requires stripping people from anything than needed(i.e freedom)</li>
<li>If security is not absolute it is worthless</li>
<li>If privacy is not absolute, anonymity is worthless</li>
<li>If your adversary cannot compromise  of your security then there is no need for GPG even for privacy</li>
</ol>
<h2 id="whats-the-problem">What‚Äôs The Problem</h2>
<p>We name periods of human history by their defining property. That property is mainly what drives human society and culture at that current age. The iron age was shaped by the superiority of iron as a material for weapons and agricultural tools. Today‚Äôs digitally shaped age is called <a href="https://www.schneier.com/essays/archives/2012/11/when_it_comes_to_sec.html">digital feudalism</a> and it governs our lives. Just like regular feudalism the resources of society is controlled by few, generated by many and the feudal lords of ours claim their right to their thrones through their infrastructure.</p>
<p>We as users are fueling the rise of the digital technologies but handful of companies are controlling and profiting from it. Just like peasants of the middle ages, you are seen as basic people who cannot understand the complex life that only a few selected elites can. It is what you are asusmed to be: simple people who wants simple things, like ‚Äúapps‚Äù that will give you what you assumed to need and nothing more. It is the same old condescending view of serfs, now given to you by companies, ignorant and arrogant developers and overall by capitalism.</p>
<p>Today saying ‚Äúwhat do I understand about computers‚Äù is equivalent to saying ‚ÄúI don‚Äôt know how to light a fire‚Äù in stone age! Just because someone might be feeding you back in those days did not mean that you could survive on your own. The same applies to current digital age. Just because someone is doing <strong>stuff</strong> for you does not ensure your digital survival. There was no easy way to light a fire back then and there will be no ‚Äúpress this button‚Äù easy way to take back the power in the digital age. Whoever claims people <strong>want</strong> or <strong>need</strong> only simple stupid apps and whoever denies the fact that we are living in digital feudalism are building a dystopian future where few elite unprecedentedly controls the future. Self determination is never given by anyone but can only be taken by everyone!</p>
<p>This ideology that ‚Äúpeople are stupid‚Äù and ‚Äúpeople want easy(read:stupid)‚Äù things dominates today‚Äôs end user software development. Good UX does not equal to simple. The real meaning in these expressions is: ‚Äúyou are too stupid to take responsibility for your self and to understand what‚Äôs going on, so we as technological elites will take care of you‚Äù. This is what‚Äôs the base of almost all GPG related criticism. GPG is too hard for people!</p>
<p>PGP, the preceder of GPG, was conceived in 1991 and this era was shaped by hackers. Not the hackers that main stream media shows in black hoods and authorities around the world paint as people with no moral boundaries. Hackers are the people who playfully expanded what is available to what is possible. This attitude brought general public; personal computers, GNU/Linux operating system that are now powering almost every backbone in the world, 3D printers etc. PGP was shaped by the empowerment of that era, not the ‚Äúthere is an app for that‚Äù era of today which is shaped by multi-billion dollar cooperation built upon the cultural and technological accumulation of hackers.</p>
<p>That brings us to the point: GPG is hard for people, but so were the general purpose computers around 20 years ago. Everything requires individual dedication and determination to learn and maintain. What happened with computers is that some people capitalised on the opportunity, poured money into devices and after hundreds of hours long R&amp;D those computers became ‚Äúeasy‚Äù. The outcome of that process was loss of the right to fix, more enclosed and restricted user environments and computers that works against us! So those who invested in computers can profit from their investment.</p>
<p>The same problem also exists for encryption. There was no real incentive for capitalists to invest in publicly accessible encryption. Solid encryption would make reaching data possible only for the user who owns it and this would be counter intuitive to the interest of capitalism. But today there is an incentive: people are afraid of what our digital world has become. They are afraid of their <a href="https://en.wikipedia.org/wiki/Global_surveillance_disclosures_(2013%E2%80%93present)">government‚Äôs abuse of power</a>, they are afraid of <a href="https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold">companies taking advantage of their lives</a>, they are afraid that their <a href="https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal">involment in democracy will be lost</a>. People are afraid and there is no better time to sell something. That‚Äôs why Apple is now selling <a href="https://en.wikipedia.org/wiki/FBI%E2%80%93Apple_encryption_dispute">privacy as a product</a> and that is why every communication service regardless their privacy invasive tendencies are <a href="https://faq.whatsapp.com/en/android/28030015/">promoting encryption</a>. What is missing is that people are still an object in this case. Whoever holds the key holds the future and there is no alternative to GPG that gives the user the best self determination!</p>
<p>So, how is GPG doing while the craze to own next killer encryption app continiue? <a href="https://en.wikipedia.org/wiki/Werner_Koch"><strong>Werner Koch</strong></a>, is the single person maintaining GPG. He was almost about to give up on GPG for <a href="https://www.propublica.org/article/the-worlds-email-encryption-software-relies-on-one-guy-who-is-going-broke">economic reasons</a> when the <a href="https://en.wikipedia.org/wiki/Edward_Snowden">Snowden incident</a> has chanced his decision. The world‚Äôs whole server infrastructure security and personal freedom rests on his shoulder and he had to ask for help. It is a huge difference in investment/impact ratio when compared to every other encryption tool. GPG exist by determination and not through capital pressure.</p>
<p>In every ‚ÄúGPG is dead‚Äù cry almost always includes some <strong>killer</strong> new technology that makes more <strong>sense</strong> than GPG. Let‚Äôs talk about them for a while.</p>
<h2 id="signal">Signal</h2>
<p>A big hit in secure instant messaging. Signal is build upon proprietary software Textsecure and RedPhone that had been once developed by <a href="https://en.wikipedia.org/wiki/Moxie_Marlinspike">Moxie Merlinspike</a> and his co-founder Stuart Anderson. Signal Protocol utilizing <a href="https://en.wikipedia.org/wiki/Double_Ratchet_Algorithm">double ratchet</a> encryption is a game changer for modern connectivity and implemented in [several applications[(https://signal.org/blog/whatsapp-complete/). Signal applications and server code is free software but <a href="https://oyd.org.tr/en/articles/stop-saying-freedom-is-a-private-matter/">their developers and business model is not</a>. It is <a href="#https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">yet another walled garden with no federation</a> and <a href="https://moxie.org/blog/gpg-and-me/">claiming GPG is dead</a>.</p>
<h2 id="matrix-protocol">Matrix Protocol</h2>
<p><a href="https://en.wikipedia.org/wiki/Matrix_(protocol)">Matrix protocol</a> is an open standard for general communication needs. Like <a href="https://en.wikipedia.org/wiki/Xmpp">XMPP -Extensible Messaging and Presence Protocol-</a> it is designed to be implemented widely and serve various modern needs of communication. End-to-end encryption is falling behind and there are still implementation problems but if everything goes well Matrix Protocol could be a modern free future for communication. The only problem is that Matrix Protocol is still an instant communication system and the cryptography behind it is specialized only for that purpose.</p>
<h2 id="insert-any-app-or-protocol">[Insert Any App or Protocol]</h2>
<p>Almost all have some of these short comings:</p>
<ul>
<li>Walled Gardens with no federation</li>
<li>Non-free dependencies</li>
<li>Single purpose</li>
<li>Symmetrical communication while e-mail being asymmetrical</li>
<li>Opaque key generation and management</li>
</ul>
<p>Modern messaging softwares do have merits that are desirable such as <a href="https://en.wikipedia.org/wiki/Forward_secrecy">forward secrecy</a>, <a href="https://en.wikipedia.org/wiki/Elliptic_curve_cryptography">recent algorithms with shorter keys</a>(read: not necessarily more secure) and more frictionless key management(which heavily depends on central key servers and personal data). All these merits are, to some degree, desireable for GPG too but those tool‚Äôs have different design requirements than GPG. GPG can and will become better at most points. When the case is single person against a multi-billion dollar industry, this should not count as a fair trial.</p>
<p>What GPG is offering in exchange is <strong>freedom</strong>, not just another ‚Äúapp‚Äù that walls it‚Äôs users in and here is why:</p>
<h2 id="gpg-giving-you-the-total-control-of-your-key-and-identity">GPG giving you the TOTAL control of your key and identity</h2>
<p>This primary point is so important, the rest seems moot. GPG is the most liberating piece of software EVER. What GPG is capable of and how it is implemented almost always secondary to the fact that <strong>you</strong> as the user in need of cryptography <strong>control</strong> the key. You can export it, expand it, change it, renew it, <a href="https://github.com/intra2net/paperbackup">print it on paper</a>, revoke it. The fact that you own and control your key actually makes it possible for you to build your identity around that key. This is almost like being your own certificate authority and issuing your certificates as you please.</p>
<p>This comes with the trust problem of cryptopgraphy. If anyone can generate a key with any metadata, then who is deciding on a particular key belong to an individual. The answer is <strong>no one</strong> and <strong>everyone</strong>. <a href="https://en.wikipedia.org/wiki/Web_of_trust">Web of trust</a> is an answer to this question for most part. You basically sign keys of people who you know and the people who trust you, trusts your friends.</p>
<p>This implementation is <a href="https://web.archive.org/web/20131009142806/https://www.rubygems-openpgp-ca.org/blog/theres-trust-and-then-theres-trust-and-then-theres-trust.html">considered broken</a> by a lot of people and there is a natural down side of making your social network public. That being said building trust ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.oyd.org.tr/en/articles/defense-of-gpg/">https://www.oyd.org.tr/en/articles/defense-of-gpg/</a></em></p>]]>
            </description>
            <link>https://www.oyd.org.tr/en/articles/defense-of-gpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058064</guid>
            <pubDate>Wed, 11 Nov 2020 13:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058039">thread link</a>) | @pavehawk2007
<br/>
November 11, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM‚Äìwith what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, ‚Äúhey, here‚Äôs the RAM that we‚Äôre going to use to store pixel information.‚Äù</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn‚Äôt strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don‚Äôt want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won‚Äôt rehash the general virtio protocol. However, the device-specific structures are a bit different, so we‚Äôll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we‚Äôre going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you‚Äôre a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren‚Äôt pure white. Instead, you can see bits of red, blue, and green. That‚Äôs because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920√ó1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640√ó480, which only requires \(640\times 480\times 4=1,228,800\) bytes‚Äìa bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I‚Äôll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 ‚ÄúGPU Device‚Äù. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another‚Äì4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I‚Äôll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we‚Äôre really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	‚Ä¶</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058039</guid>
            <pubDate>Wed, 11 Nov 2020 13:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of connections between politicians and orgs awarded gov contracts]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25057931">thread link</a>) | @roxanneonhacker
<br/>
November 11, 2020 | https://sophieehill.shinyapps.io/my-little-crony/ | <a href="https://web.archive.org/web/*/https://sophieehill.shinyapps.io/my-little-crony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
          A visualization of the connections between
          <strong>Tory politicians</strong>
          and
          <strong>companies being awarded government contracts during the pandemic,</strong>
          based on reporting by
          <a href="https://www.opendemocracy.net/en/dark-money-investigations/">openDemocracy,</a>
          <a href="https://bylinetimes.com/">Byline Times,</a>
          and more.
        </p>
    </div></div>]]>
            </description>
            <link>https://sophieehill.shinyapps.io/my-little-crony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057931</guid>
            <pubDate>Wed, 11 Nov 2020 12:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced System-on-Chip Design Lecture Notes]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25057889">thread link</a>) | @allending
<br/>
November 11, 2020 | https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/ | <a href="https://web.archive.org/web/*/https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057889</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[92% efficacy of Sputnik V Covid-19 vaccine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057881">thread link</a>) | @pama
<br/>
November 11, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li><i>The Sputnik V vaccine efficacy amounted to 92% (calculation based on the 20 confirmed COVID-19 cases split between vaccinated individuals and those who received the placebo). Currently 40,000 volunteers are taking part in double-blind, randomized, placebo-controlled Phase III of Sputnik V clinical trials, out of which over 20,000 have been vaccinated with the first dose of the vaccine and more than 16,000 with both the first and second doses of the vaccine. </i></li>
<li><i>Efficacy was demonstrated on the basis of a first interim analysis obtained 21 days after the first injection. </i></li>
<li><i>There were no unexpected adverse events during the trials. Monitoring of the participants is ongoing. </i></li>
<li><i>The world‚Äôs first registration of COVID-19 vaccine, done in Russia on the 11th of August under the emergency use authorization mechanism, enables the Russian Federation to administer the vaccine outside of the clinical trials to volunteers such as medics and other high-risk groups. Trials conducted under the civil use of the vaccine in Russia (not being a part of clinical trials) based on the monitoring of additional 10,000 vaccinated confirmed vaccine efficacy at a rate of over 90%. </i></li>
<li><i>The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report. </i></li>
<li><i>Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, UAE, Venezuela and other countries, as well as Phase II-III ‚Äì in India. </i></li>
<li><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that had proven safe and effective with no long-term side effects in more than 250 clinical trials globally conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). More than 100,000 people have received approved and registered drugs based on the human adenoviral vectors. </i></li>
<li><i>The uniqueness of the Russian vaccine is in using two different human adenoviral vectors that enable to provide strong and long-term immune response after the second injection.</i> </li>
</ul>
<p>
<b>Moscow, 11.11.2020</b> ‚Äì The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia‚Äôs sovereign wealth fund), announce that the Sputnik V vaccine, the world's first registered vaccine against coronavirus (registered on the 11th of August under the emergency use authorization mechanism) created on the well-studied platform of human adenoviral vectors, demonstrated high efficacy. The confirmation is based on the first interim data from the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia involving 40,000 volunteers.
</p>
<p>
The trials evaluated efficacy among over 16,000 volunteers who received the vaccine or placebo 21 days after the first injection. As a result of a statistical analysis of 20 confirmed cases of coronavirus, the case split between vaccinated individuals and those who received the placebo indicates that the Sputnik V vaccine had an efficacy rate of 92% after the second dose.
</p>
<p>
Separately, in September the vaccine was first administered to a group of volunteers from the ‚Äúred zones‚Äù of Russian hospitals. The observation of additional 10,000 vaccinated volunteers representing medics and other high-risk groups under the civil use of the vaccine out of clinical trials also confirmed the vaccine‚Äôs efficacy rate of over 90 percent.
</p>
<p>
The data received will be published by Gamaleya&nbsp;Center researchers in one of the world‚Äôs leading peer-reviewed medical academic journals following an independent valuation of the data by leading epidemiology experts. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
<p>
As of November 11, as part of the clinical trials in Russia‚Äôs 29 medical centers, more than 20,000 volunteers were vaccinated with first dose and over 16,000 volunteers with the first and the second dose of the vaccine.
</p>
<p>
In addition, as of November 11, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection site, flu-like syndrome including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analysed by the Independent Monitoring Committee comprising of leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involving active participation of Moscow‚Äôs Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
Observation of study participants will continue for six months after which the final report will be presented. Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India. A separate detailed study of the vaccine‚Äôs safety and immunogenicity for elderly people is being conducted.
</p>
<p>
The research data will be provided by RDIF to the national regulators of countries interested in purchasing the Russian vaccine in order to streamline the registration process.
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation: </b><br>
‚ÄúThe use of the vaccine and the results of clinical trials demonstrate that it is an efficient solution to stop the spread of coronavirus infection, –∞ preventive healthcare tool, and this is the most successful path to defeat the pandemic.‚Äù
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director: </b><br>
‚ÄúThe publication of the interim results of the post-registration clinical trials that convincingly demonstrate Sputnik V vaccine‚Äôs efficacy gives way to mass vaccination in Russia against COVID-19 in the coming weeks. Thanks to the production scale up at new manufacturing sites, Sputnik V vaccine will soon be available for a wider population. This will break the current trend and lead to an eventual decrease in COVID-19 infection rates, first in Russia, then globally.‚Äù
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director: </b><br>
‚ÄúPositive interim results of Phase III give reasons to expect a successful outcome of Sputnik V clinical trials. We will continue to process and analyse all the data and look to the future with optimism, expecting that results of our work will help end the pandemic sooner.‚Äù
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund: </b><br>
‚ÄúSputnik V is the first registered vaccine against COVID-19 in the world, the vaccine is based on safe and effective platform of human adenoviral vectors. More and more countries are recognizing the human adenoviral vector platform and plan to include these vaccines, as the most studied and known, in their respective national vaccine portfolio. I would also like to stress the importance of international cooperation and close partnership among vaccine-developing states. Vaccines should be above politics. The world needs a diversified portfolio of high-quality vaccines with Sputnik V, based on the well-tested human adenoviral vector platform, being an important element of it.‚Äù
</p>
<p>
The safety of vaccines based on human adenoviruses was confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world‚Äôs leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from over 50 countries. The vaccine supplies for the global market will be produced by RDIF‚Äôs international partners in India, Brazil, China, South Korea and other countries. The existing RDIF contracts with international partners enable the production of 500 million doses of the Sputnik V vaccine outside Russia annually. RDIF is now considering additional requests from a number of countries and companies to further increase its foreign production capacities.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia‚Äôs Health Ministry and became the world‚Äôs first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="http://" target="_blank">sputnikvaccine.com</a><a target="_blank" href="http://"></a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF) </b>is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF‚Äôs management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects with foreign partners totaling more than RUB1.9 trillion and covering 95% of the regions of the Russian Federation. RDIF portfolio companies employ more than 800,000 people and generate revenues which ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057881</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Richard Feynman and How to Learn Anything Well]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057821">thread link</a>) | @stanrivers
<br/>
November 11, 2020 | https://www.butwhatfor.com/feynman-technique/ | <a href="https://web.archive.org/web/*/https://www.butwhatfor.com/feynman-technique/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Disclosure: Links to Amazon are generally affiliated links. As an Amazon Associate, we earn from qualifying purchases, meaning a commission may be generated on purchased items.</p><div>
<div>
<div>
<div>
<p><strong><a href="https://www.butwhatfor.com/richard-feynman/">Richard P. Feynman </a></strong> (1918 ‚Äì 1988) was an American theoretical physicist often referred to as ‚ÄúThe Great Explainer‚Äù due to his ability to make complex topics understandable. While he won the Nobel Price in Physics in 1965 for his work developing quantum electrodynamics, today he is also famous for his forays into bongo drum playing, Tuvan throat singing, and safe cracking.</p>
<div>
<figure>
<p><a href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" target="_blank" rel="noopener noreferrer"><br>
<img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" alt="" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg&quot;,&quot;height&quot;:315,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:53211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}"><br>
</a></p>
</figure>
</div>
<p data-pm-context="[]">It is 1941 and you have a problem. While you haven‚Äôt yet gotten around to defining quantum electrodynamics or even started your work helping design the atomic bomb, you are nearing the end of your second year of graduate school. This means you have an exam soon.</p>
<p>That‚Äôs OK though. You know what to do. After all, you have made it this far already. You just do what you always do ‚Äì you pull out a notebook. And not just any notebook, but one especially well-prepared for the task at hand. Namely, a blank one.</p>
<p>A fitting title is needed for the first page. You think for a moment, smiling to yourself as you creatively run through all the options you could pick. But, alas, none of them seem right. You opt for the tried-and-true but never worn out choice. You write it down.</p>
<p>You are Richard P. Feynman, arguably the brightest young physics mind in the United States at the time, and you have just written ‚ÄúNotebook Of Things I Don‚Äôt Know About‚Äù on the title page.</p>
<p><em>Note: For more on Richard Feynman, check out <a href="https://amzn.to/36pgDxt">Genius: The Life and Science of Richard Feynman, </a>the definitive biography by James Gleick, or Feynman‚Äôs autobiographical writings in<a href="https://amzn.to/35krIk7"> ‚ÄúSurely You‚Äôre Joking, Mr. Feynman!‚Äù</a></em></p>
<h4>The Feynman Learning Technique</h4>
<p>Feynman realized early on that people can trick themselves into believing they understand something more deeply than they truly do. This self-delusion often comes from an earnest effort focused on learning the wrong thing ‚Äì learning the name of something as opposed to that which it truly is.</p>
<blockquote><p>The next Monday we were playing in a field, and a kid said to me, ‚ÄúWhat‚Äôs that bird? Do you know the name of that bird?‚Äù I said, ‚ÄúI haven‚Äôt the slightest idea.‚Äù He said, ‚ÄúWell, it is a brown‚Äëthroated thrush.‚Äù He said, ‚ÄúYour father doesn‚Äôt teach you anything.‚Äù</p>

<p>But my father had already taught me about the names of birds. Once we walked, and he said, ‚ÄúThat is a brown-throated thrush. In German it is called the Pfleegel fl√ºgel. In Chinese it is called Keewontong. In Japanese a Towhatowharra‚Äù, and so on.</p>

<p>And when you know all the names of that bird in every language, you know nothing, know absolutely nothing, about the bird‚Ä¶ So I had learned already that names don‚Äôt constitute knowledge‚Ä¶</p>

<p>We have to learn that these are the kinds of disciplines in the field of science that you have to learn ‚Äì to know when you know, and when you don‚Äôt know, and what it is you know, and what it is you don‚Äôt know.</p>

<p>You‚Äôve got to be very careful not to confuse yourself.</p></blockquote>
<p>Understanding this, Feynman was very careful to not delude himself into a superficial understanding of important topics. He developed a more holistic, multidisciplinary approach to learning that served him well throughout his career. While never specifically stated by Feynman as a set technique with steps, Feynman loved sharing with others enough that we can piece together his teachings, along with stories of his life, to better understand how he naturally approached learning anything new.</p>
<p>The combination of ideas, which many different authors outline slightly differently but are holistically the same, is known as <em>The Feynman Learning Technique</em>.</p>
<p>So how does this technique actually work?</p>
<h4>Step 1: Whatever you are trying to learn, take a stab at learning it</h4>
<p>The way that Feynman learned and internalized new ideas was to first attack them head on the old fashioned way ‚Äì by reading and thinking through them. The key emphasis in that sentence is on the word <em>thinking</em>. Famously, Feynman would read the abstract of a scientific paper, and before reading any further, attempt to solve the stated problem. Only then would he read through the rest of the paper. He was focused on mentally wrestling with an idea as opposed to letting someone else walk him to the final answer.</p>
<p>So the first step in the process is to pick something that you need (or better yet, desire) to learn and spend time with the new idea until you have internalized it to the best of your ability.</p>
<p>Now, you might aptly question, ‚ÄúWhat is this <em>hogwash</em>? Step 1 of this supposed wonderfully useful learning technique is to learn something? I‚Äôm out.‚Äù</p>
<p>Stop your <em>swining</em> and don‚Äôt worry ‚Äì there is more to it than that. Which brings us to the second step.</p>
<h4>Step 2: Write everything down, in as simple a way as possible, as if you were preparing a lecture for an inquisitive child</h4>
<p>This is where the notebook comes in. Open it. Close everything else.</p>
<p>From memory, write down everything you can about what you are trying to learn as if you were preparing to teach it to someone else. Preferably, pretend you are planning to teach the topic to a child ‚Äì the more you can simplify your language and the ideas, the more likely you are to find areas where you are hiding behind the name of something as opposed to true understanding.</p>
<blockquote><p>Test it this way: You say, ‚ÄúWithout using the new word which you have just learned, try to rephrase what you have just learned in your own language. Without using the word ‚Äòenergy,‚Äô tell me what you know now about the dog‚Äôs motion.‚Äù You cannot. So you learned nothing about science. That may be all right. You may not want to learn something about science right away.</p>

<p>You have to learn definitions. But for the very first lesson, is that not possibly destructive?</p></blockquote>
<p>At this point, you will probably notice that there are things that you are missing or don‚Äôt remember as well as you thought you did. Write those items down ‚Äì make a list of all the things you don‚Äôt know.</p>
<p>Now open everything back up and search out the answers to those items. Get to a point where you feel like you have conveyed what is required for your theoretical student to deeply understand the topic.</p>

<h4>Step 3: Ask questions as if you were a child to identify gaps in your understanding</h4>
<p data-pm-context="[]">Now you need to channel your inner child. Feynman‚Äôs neverending child-like curiosity is often viewed as the core, natural foundation that differentiated Feynman from other equally intelligent individuals. As children are wont to do, <a href="https://www.butwhatfor.com/invert-always-invert-avoid-failure-to-succeed/">start questioning every line you have written down</a>.</p>
<p>If we take a concept ‚Äì for example, the calculation of <a href="https://www.investopedia.com/terms/n/npv.asp">net present value</a>. Why do we discount cash received in the future? How do you choose a discount rate? Can the rate change between people? Should it change over time? Can you use a different discount rate in different periods? How many years of cash do you think about? How do you determine what those cash numbers will be in the future? What happens if cash is negative in the future? And so on.</p>
<p>If you are seeking Feynman-level understanding, it is not enough to merely know the math formula as that is akin to just knowing the name of something. You need to understand the information qualitatively and quantitatively supporting the formula ‚Äì only then should you feel confident in your understanding.</p>
<p>As you write out these new questions, you‚Äôll find you can answer some of these. Maybe even most of these. However, at some point, you will run out of answers for the incessant child ‚Äì write all these things down as items you ‚Äúdon‚Äôt know about.‚Äù Then go find the answers to these new topics.</p>
<p>By doing this, you are strengthening the foundation upon which your primary new learnings are ingrained in your head.</p>
<blockquote><p>But the problem, you see, when you ask&nbsp;<em>why</em>&nbsp;something happens, how does a person answer why something happens? For example, Aunt Minnie is in the hospital. <em>Why?</em> Because she went out, slipped on the ice, and broke her hip. That satisfies people. It satisfies, but it wouldn‚Äôt satisfy someone who came from another planet and who knew nothing about why when you break your hip do you go to the hospital‚Ä¶</p>

<p>And you begin to get a very interesting understanding of the world and all its complications. If you try to follow anything up, you go deeper and deeper in various directions. For example, if you go, ‚Äú<em>Why did she slip on the ice?‚Äù</em> Well, ice is slippery. Everybody knows that, no problem. But you ask&nbsp;<em>why is ice slippery?</em>&nbsp;That‚Äôs kinda curious. Ice is extremely slippery. It‚Äôs very interesting. <em>You say, how does it work?</em> You could either say, ‚ÄúI‚Äôm satisfied that you‚Äôve answered me. Ice is slippery; that explains it,‚Äù or you could go on and say, ‚Äú<em>Why is ice slippery?‚Äù</em> and then you‚Äôre involved with something, because there aren‚Äôt many things as slippery as ice‚Ä¶</p>

<p><em>A solid that‚Äôs so slippery?</em> Because it is, in the case of ice, when you stand on it (they say) momentarily the pressure melts the ice a little bit so you get a sort of instantaneous water surface on which you‚Äôre slipping. W<em>hy on ice and not on other things?</em> Because water expands when it freezes, so the pressure tries to undo the expansion and melts it. It‚Äôs capable of melting, but other substances get cracked when they‚Äôre freezing, and when you push them they‚Äôre satisfied to be solid.</p>

<p><em>Why does water expand when it freezes and other substances don‚Äôt?</em> I‚Äôm not answering your question, but I‚Äôm telling you how difficult the&nbsp;<em>why&nbsp;</em>question is. You have to know what it is that you‚Äôre permitted to understand and allow to be understood and known, and what it is you‚Äôre not. You‚Äôll notice, in this example, that the more I ask why, the deeper a thing is, the more interesting it gets. We could even go further and say, ‚Äú<em>Why did she fall down when she slipped?‚Äù</em> It has to do with gravity, involves all the planets and everything else. Nevermind! It goes on and on.</p></blockquote>

<h4>Step 4: Repeat step 3 until the questioning adds no incremental value</h4>
<p data-pm-context="[]">Now you iterate with yourself. After you have written down the ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.butwhatfor.com/feynman-technique/">https://www.butwhatfor.com/feynman-technique/</a></em></p>]]>
            </description>
            <link>https://www.butwhatfor.com/feynman-technique/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057821</guid>
            <pubDate>Wed, 11 Nov 2020 12:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardly Working with Cloudflare Workers]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25057709">thread link</a>) | @malthejorgensen
<br/>
November 11, 2020 | https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers | <a href="https://web.archive.org/web/*/https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- Possible titles:
Cloudflare workers are hard to work with
Working with Cloudflare Workers
Hardly working with Cloudflare Workers
-->

<p><em>Note: The team behind Notifly also runs <a href="https://www.eduflow.com/">Eduflow</a> and <a href="https://www.peergrade.io/">Peergrade</a>.</em></p>

<h2 id="introduction">Introduction</h2>

<p>This is the story of me trying to replace a simple NGINX reverse proxy (plus some basic redirects) with a Cloudflare Worker.</p>

<p>Our old landing page is a Wordpress blog hosted on WPEngine. Historically, this has always been set up behind an NGINX reverse proxy serving at <a href="http://peergrade.io/">peergrade.io</a> and <a href="http://www.peergrade.io/">www.peergrade.io</a>. The reverse proxy was needed for doing various redirects outside of Wordpress and doing some cookie trickery to redirect to <a href="http://app.peergrade.io/">app.peergrade.io</a> if the session cookie for the app was present.</p>

<p>The reverse proxy is hosted on DigitalOcean and is the only thing we have hosted there, so I wanted to get rid of it. We already use Cloudflare and so I thought ‚Äúthis would be a good test to try out Cloudflare Workers‚Äù. And less infrastructure is better, right?</p>

<h2 id="the-good-parts">The good parts</h2>

<p>Getting set up with <code>wrangler</code> ‚Äì the CLI for Cloudflare Workers ‚Äì was a breeze. It gives you a webpack setup out of the box which allowed me to install NPM packages and use them without any extra work on my part. I eventually downgraded to a setup without webpack (called ‚Äújavascript‚Äù in <code>wrangler</code>) ‚Äì since I ended up not needing any packages.</p>

<p>The vanilla Javascript setup allows you to ‚Äúlive edit‚Äù the worker at <code>https://dash.cloudflare.com/&lt;account-id&gt;/workers/edit/&lt;worker-slug&gt;</code></p>

<p>Here you can edit and run the updated script without saving and deploying the worker, allowing for a very fast and easy ‚Äúedit-compile-run‚Äù loop.</p>

<p>Another cool thing is that you can change the URL in the small ‚Äúbrowser‚Äù on the page to your liking ‚Äì this is very useful for testing out proxies and other things that depend on the domain name or precise URL being sent to the worker. The debugger part of the UI is also incredibly useful but does have a tendency to disconnect from time to time.</p>

<h2 id="page-rules-vs-workers">Page Rules vs. Workers</h2>

<p>In a classic setup you‚Äôll usually have a couple of redirects alongside your reverse proxy ‚Äì and so do we. We use <a href="http://www.peergrade.io/">www.peergrade.io</a> as our canonical domain so we redirect peergrade.io to www.peergrade.io and we redirect http:// to https://.</p>

<p>This can be set up easily in Cloudflare by adding a couple of redirects in your Page Rules.</p>

<p>However, redirects from page rules are applied after any worker on the same URL. Since my worker‚Äôs default action is to reverse proxy, the redirect page rule will never be hit.</p>

<p>Annoyingly, this isn‚Äôt clearly described in the docs and you‚Äôll have to find <a href="https://community.cloudflare.com/t/cf-workers-and-rate-limiting-firewall-rules-bot-management/132164/3">this forum post</a> from the official Cloudflare forum to know that.
The post notes that ‚Äú<em>security-related ones will run before [workers]</em>‚Äù ‚Äì but which ones are those? (All respect to Kenton Varda who wrote the post and is the main architect behind Cloudflare Workers. Cloudflare Workers <em>are</em> very very cool, but they are also a bit more quirky than I‚Äôd like at the moment)</p>

<p>In order to preserve these redirects, I‚Äôll have to manually write them in the worker code (or relay the URLs that need to redirect to Cloudflare itself ‚Äì which is basically the same amount of code).</p>

<!-- 
- An aside:

    Apparently *Always Use HTTPS* is such a "security-related" page rule, even though it's basically an http:// to https:// redirect. Cloudflare even admits to that [in the docs](https://support.cloudflare.com/hc/en-us/articles/204144518-SSL-FAQ#h_a61bfdef-08dd-40f8-8888-7edd8e40d156). 

    Cloudflare Page Rules allows you to set up multiple rules for a single URL-pattern, but then only allows you to use that pattern once. However, *Always Use HTTPS* is special and doesn't allow any other rules once it's used on a URL-pattern. This means if you want *Automatic HTTPS Rewrites* on top of *Always Use HTTPS* you have to specify 2 rules:

    1. www.peergrade.io ‚Äì *Always Use HTTPS*
    2. [https://www.peergrade.io](https://www.peergrade.io) ‚Äì *Automatic HTTPS Rewrites*
-->

<p>The same thing goes for cache rules. I had previously been using a page rule to aggressively cache static assets and user-uploaded content served from Wordpress. That now has to be written inside the worker as well.</p>

<p>Page rules have an internal ordering that you can set. Rules that match the given URL are executed in order ‚Äì so that if two redirect rules match the URL, the first one in the ordering will be used. It would be <em>really nice</em> if workers could be added to the same list ‚Äì that would mean I could put the redirects and cache rules before my worker and much more easily handle this scenario. <em>In principle</em> this would be easy if all the built-in page rules were reimplemented as workers, but there‚Äôs probably legacy behaviors and tie-ins to the rest of the stack that makes that impossible or at least non-trivial. (Still hoping for a future update on this ü§ûüèª)</p>

<h2 id="the-reverse-proxy">The reverse proxy</h2>

<p>Back to the main task at hand ‚Äì we‚Äôre implementing a simple reverse proxy and that happens to be <a href="https://developers.cloudflare.com/workers/examples/bulk-origin-proxy">one of the examples</a> in the Cloudflare Worker docs. However, getting it set up myself I quickly ran into issues with redirect loops and cases where my origin would redirect for seemingly no reason. To be fair, proxying can be tricky to get right since it‚Äôs hard to test properly before rollout, and on top of that you have DNS propagation and caching, which means there might be timing issues. But even with that, it seemed extra tricky with Cloudflare Workers.</p>

<p>On closer inspection, the example from the Cloudflare docs seems to defy reasoning. The incoming request in the example must have the header <code>Host: google.yourdomain.com</code> in order for it to match the Google entry in <code>ORIGINS</code>. I was able to confirm as much by inspecting the incoming request in the Cloudflare worker debugger. That incoming request is then relayed directly to <code>www.google.com</code>. Let‚Äôs try that ourselves:</p>

<div><div><pre><code>curl -H 'Host: google.yourdomain.com' https://www.google.com
</code></pre></div></div>

<p>The response we get is a 404 page (which makes sense since the host doesn‚Äôt match). However, the Cloudflare worker doesn‚Äôt get a 404 ‚Äì it renders the familiar Google search frontpage. Something must be happening behind the scenes. That something is what I call ‚ÄúThe Web Platform‚Äù part of Cloudflare Workers.</p>

<h2 id="the-web-platform">The Web Platform</h2>

<p>Cloudflare Workers uses Chrome‚Äôs V8 as its execution engine and this also sets the context in which your script is run.</p>

<p>The available API is a very small subset of <a href="https://platform.html5.org/">The Web Platform</a> (the Javascript API available in modern browsers) ‚Äì specifically Ecmascript/Javascript itself, plus <code>Fetch</code>, <code>URL</code>, and <code>Blob</code>. I believe Cloudflare chose this API because it melds well with V8, but also because web devs will be familiar with those APIs. But how familiar are you <em>really</em> with <code>fetch</code>, <code>Request</code>, and <code>Response</code>? (all part of the <code>Fetch</code>-spec)<br>
I don‚Äôt think I actually knew the <code>Request</code> and <code>Response</code>-objects in any detail before using Cloudflare Workers ‚Äì having gotten along just fine with variations of</p>

<div><div><pre><code>fetch('http://example.org', { options }).then((r) =&gt; r.json())
</code></pre></div></div>

<p>plus some error handling on top for many years.</p>

<p>When working with Workers what you‚Äôll mostly be doing is to manipulate the incoming <code>Request</code>-object  and pass it on to <code>fetch</code>, or manipulate the outgoing <code>Response</code>-object and passing that on to Cloudflare‚Äôs handler. Have you ever manually created a <code>Request</code>-object in the browser? I haven‚Äôt. The reason this gets complicated is the fact that the spec for <code>fetch</code> itself is very ‚Äúloose‚Äù. For example, <code>fetch</code> can take either a <code>Request</code>-object or a simple Javascript object that just looks a lot like a <code>Request</code>-object as its argument ‚Äì and it not really clear what differences between the two are.
<code>fetch</code> also allows passing a <code>Request</code>-objects as both its first and second argument <code>fetch(Request(...), Request(...))</code> ‚Äì good luck trying to figure out what that does!</p>

<p>If we go back to the example from the Cloudflare docs ‚Äì what‚Äôs going on ‚Äúbehind the scenes‚Äù in our proxy example from earlier is that you can‚Äôt change the <code>Host</code>-header when doing a <code>fetch</code>. This makes a lot of security sense in the browser where <code>fetch</code> normally lives, but it‚Äôs quite normal behavior for a reverse proxy and actually something I was doing in my NGINX setup in order to have WPEngine respond with the right content. It‚Äôs not a behavior you‚Äôve ever needed or thought about when using <code>fetch</code> in the browser.
The server is just a very different environment than the browser. The browser Javascript API is not built with server functionality in mind, and it ends up being a hamstring when working with Cloudflare Workers.</p>

<h2 id="maybe-maybe-maybe">Maybe, maybe, maybe‚Ä¶?</h2>

<p>A bunch of forum posts on community.cloudflare.com talk about this issue</p>

<ul>
  <li><strong>Only available on the Enterprise plan?</strong> <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/2">This forum post</a> describes that setting the <code>Host</code> -header in workers is not possible. Followed up with <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/5">a later answer</a> that it‚Äôs possible but only for Enterprise accounts.
 <a href="https://community.cloudflare.com/t/reverse-proxy-using-page-rules/47836/16">This other post</a> says the same.</li>
  <li><strong>Kenton Varda to the rescue</strong> In response to <a href="https://community.cloudflare.com/t/not-possible-to-override-the-host-header-on-workers-requests/13077/7">this post</a> Kenton Varda actually extends Cloudflare Workers with the <code>cf.resolveOverride</code>-flag on the <code>Request</code>-object,
which should allow at least part of the reverse proxy setup to work.
Unfortunately, to explain the new feature the post just links to the top-level URL of the documentation for Cloudflare Workers ‚Äì which currently doesn‚Äôt
describe how  <code>cf.resolveOverride</code> works and how to use it.</li>
  <li><strong>The missing documentation</strong> <a href="https://community.cloudflare.com/t/different-hostname-with-same-origin-in-workers/16662/12">This older post</a> seemingly cites documentation that no longer exists! :(<br>
 I have been unable to find any meaningful documentation of <code>cf.resolveOverride</code> outside of the community forum, and I was unable to have it allow me to switch the <code>Host</code>-header.</li>
</ul>

<h2 id="the-final-nail-in-the-coffin">The final nail in the coffin</h2>

<p>For a brief moment I actually thought my setup was working, but it only ‚Äúlooked‚Äù like it was working due to the following sequence of events:</p>

<ul>
  <li>A request for <code>www.peergrade.io</code> would hit the worker</li>
  <li>The worker would then do a request to <code>peergrade.wpengine.com</code></li>
  <li>Wordpress/WPEngine would then respond with a redirect to <code>www.peergrade.io</code> since the <code>Host</code>-header is incorrect</li>
  <li>Cloudflare by default then follows that redirect and makes a new request to <code>www.peergrade.io</code>.
Since Cloudflare is the host of <code>www.peergrade.io</code> you‚Äôd think we‚Äôd hit infinite recursion here.
But magically, it doesn‚Äôt just enter the worker script again ‚Äì it knows (somehow) it has to go further down the Cloudflare stack.
Since the DNS A-record in Cloudflare still had the IP of the DigitalOcean instance, that final fetch would simply fetch the page from the old proxy server which worked as it always had ü§¶üèª</li>
</ul>

<!--
Another example of this "familiar but unfamiliar" API is when I was trying to inspect the session cookie: I had to do a base64 decode into a `Uint8Array` (in order to do a zlib decompression). The function available for decoding base64 is `atob` which you may know from the browser.

However, in order to get the actual binary data you'll have to do this Javascript incantation:

```jsx
const weirdstr = atob(cookiestr);
const bytearray = new Uint8Array(new ArrayBuffer(weirdstr.length));

for (let i = 0; i < weirdstr.length; i++) {
  bytearray[i] = weirdstr.charCodeAt(i);
}
```

Again, this isn't Cloudflare's fault per se, but they're inheriting a bad choice from The Web Platform where they could have done something else. That bad choice becomes accentuated by the fact that most workers need to implement something that is basically backend or proxy server behavior, which by now you can see The Web Platform really isn't set up for. 

Similarly, you'll inherit this weird quirk directly from the browser Javascript engine:

```jsx
console.log(btoa('Ê±âÂ≠ó'))
// The above raises a DOMException in your Cloudflare Worker with the
// following message:
// "btoa() can only operate on characters in the Latin1 (ISO/IEC 8859-1) range."
```

Yes yes, there's some sense to this ‚Äì Javascript strings are UTF-16 and that's why this example doesn't work. But take a look at Node.js where `btoa` and `atob` are not available ‚Äì Node.js has a much better answer to many of these problems.

Lastly, since many things are iterables or DOM-objects, you won't get anything useful out of console logging `request.headers`, `request.headers.keys()`, `request.headers.values()`, `request.headers.entries()`. This wouldn't be a problem if the `request`-object was fully inspectable in the debugger but nothing shows up when you open up `request.headers`.
The solution to this is just `console.log([...request.headers])`.
-->

<h2 id="conclusion">Conclusion</h2>

<p>Overall, Cloudflare Workers are really cool and the tooling around them is pretty great. But I do feel like it was an unfortunate choice to adopt The Web Platform
instead of using parts of the Node standard library or a different, more server-oriented API. Lastly, while the documentation feels fairly complete and fleshed out ‚Äì the fact
that the answers on the forum tell 2-3 different stories about whether it‚Äôs possible to change the <code>Host</code>-header means that it‚Äôs something that is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</a></em></p>]]>
            </description>
            <link>https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057709</guid>
            <pubDate>Wed, 11 Nov 2020 12:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf ‚Äì 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057456">thread link</a>) | @ProfDreamer
<br/>
November 11, 2020 | https://emacsconf.org/2020/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p>EmacsConf 2020 | Online Conference | <strong>November 28 and 29, 2020</strong><br>
<a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a><br>
<a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> | <a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> | <a href="https://emacsconf.org/2020/planning/">Planning</a> |
<a href="https://emacsconf.org/conduct/">Code of Conduct</a></p>

<p>EmacsConf is the conference about the joy of Emacs, Emacs Lisp, and
memorizing key sequences.</p>

<p>We are holding EmacsConf 2020 as a virtual (online) conference again
this year, especially now, given the current state of the world with
the ongoing global pandemic. We remain fully committed to freedom, and
we will continue using our infrastructure and streaming setup
consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free software</a>, much like the last
EmacsConf. Check out the <a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> and
<a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> for more details.</p>

<h2>Watching</h2>

<p>On November 28 and 29 you will be able to watch the livestreams via
<a href="https://live.emacsconf.org/">https://live.emacsconf.org</a>, which also has details on how to watch the
streams using media players that support streaming (like mpv and VLC).</p>

<p>We'll record the conference and post the videos and links on the
individual talk pages. In the meantime, please enjoy
<a href="https://emacsconf.org/2019/talks/">last year's talks</a>.</p>

<h2>Participating</h2>

<p>For audience questions specifically, we will be experimenting with
using a collaboratively-editable Etherpad as the primary means of
collecting audience questions. We will be posting a link to the pad
closer to the event. If, however, you are unable to access the pad to
add your question(s), we will still try to take questions from our
questions-specific IRC channel (<code>#emacsconf-questions</code> on
<code>chat.freenode.net</code>), and ask one or two volunteers to kindly add
questions from that channel to the pad on behalf of folks who are not
able to or prefer not to use the web-based questions pad.</p>

<p>Come hang out with us in <code>#emacsconf</code> on <code>chat.freenode.net</code>.  You can
join the chat using <a href="ircs://chat.freenode.net:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser, a self-hosted instance
of <a href="https://thelounge.chat/">The Lounge</a> free software web IRC client for EmacsConf.</p>

<h2>Updates</h2>

<p>Be sure to subscribe to our mailing list
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a> for discussion and
announcements about the conference.</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057456</guid>
            <pubDate>Wed, 11 Nov 2020 11:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Write Unit Tests for Logging]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25057372">thread link</a>) | @JanVanRyswyck
<br/>
November 11, 2020 | https://principal-it.eu/2020/11/unit-tests-for-logging/ | <a href="https://web.archive.org/web/*/https://principal-it.eu/2020/11/unit-tests-for-logging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<h2>
						How To Write Unit Tests For Logging
					</h2>
					<p><span>
						November 11, 2020
					</span>
				</p></div>

				
<p>Once in a while I get asked the question whether one should write <a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">solitary tests</a> for 
logging functionality. My answer to this question is the typical consultant answer: ‚ÄúIt depends‚Äù. In essence, logging 
is an infrastructure concern. The end result is log data that is being written to a resource which is external to 
an application. Usually the generated data ends up in a file, a database or it might even end up in a cloud service.</p>

<p>Because logging crosses the process boundary of an application, it is more useful to write 
<a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">sociable tests</a> to verify this particular functionality. It doesn‚Äôt make sense to 
use solitary tests in this particular case.</p>

<p>That being said, there are situations where business requirements explicitly state that logging should be a part of the 
interface of an application. In this situation, the intent of logging should be expressed explicitly by the code which 
in turn should also be exercised by solitary tests. The excellent book 
<a href="https://bit.ly/tdd-goos2" target="blank" rel="noopener noreferrer nofollow">Growing Object Oriented Software 
Guided By Tests</a>, written by Steve Freeman and Nat Pryce, mentions that there are generally two separate types of 
logging:</p>

<ul>
  <li>Support logging</li>
  <li>Diagnostic logging</li>
</ul>

<p>A support log contains messages that are intended for those that perform operational activities. These messages are used 
to determine whether the system behaves correctly or not. The log level for these messages is usually of type <em>error</em> 
or <em>info</em>.</p>

<p>A diagnostic log on the other hand holds messages that are targeted towards software developers. These messages provide 
valuable insights into the details of a running system. The log level for these messages is usually of type <em>debug</em> or 
<em>trace</em>.</p>

<p>Given these two types of logging, the basic idea is that code which expresses the intent of support logging should be 
exercised by solitary tests. Code statements that initiate diagnostic logging are usually not covered by tests.</p>

<p>Let‚Äôs have a look at an example that demonstrates both support and diagnostic logging in action.</p>

<pre><code>public class ExpenseSheetController : Controller
{
    private readonly ICommandHandler&lt;CreateExpenseSheet&gt; _commandHandler;
    private readonly ISupportNotifier _supportNotifier;

    public ExpenseSheetController(ICommandHandler&lt;CreateExpenseSheet&gt; commandHandler,
                                  ISupportNotifier supportNotifier)
    {
        _commandHandler = commandHandler;
        _supportNotifier = supportNotifier;
    }
    
    [HttpPost]
    [ServiceFilter(typeof(PerformanceTracing))]
    public IActionResult Create(CreateExpenseSheetFormModel formModel)
    {
        try
        {
            var command = new CreateExpenseSheet(Guid.NewGuid(), formModel.EmployeeId);
            _commandHandler.Handle(command);
        }
        catch(Exception ex)
        {
            _supportNotifier.ErrorDuringExpenseSheetCreation(ex, formModel.EmployeeId);
            return BadRequest();
        }
        
        _supportNotifier.ExpenseSheetCreated(formModel.EmployeeId);
        return Ok();
    }
}
</code></pre>

<p>Here we have the implementation of a controller that can receive a request for creating a new expense sheet. Notice that 
the constructor of this controller class expects an instance of the <em>ISupportNotifier</em> interface. This dependency is 
being used by the implementation of the <em>Create</em> method for logging an error when an exception occurs. It is also used 
for logging when an expense sheet has been successfully created.</p>

<p>This is how the implementation of the <em>SupportNotifier</em> looks like.</p>

<pre><code>public class SupportNotifier : ISupportNotifier
{
    private readonly ILogger&lt;SupportNotifier&gt; _logger;

    public SupportNotifier(ILogger&lt;SupportNotifier&gt; logger)
    {
        _logger = logger;
    }
    
    public void ExpenseSheetCreated(Guid employeeId)
    {
        _logger.LogInformation("Expense sheet created for employee with ID '{employeeId}'.");
    }

    public void ErrorDuringExpenseSheetCreation(Exception ex, Guid employeeId)
    {
        _logger.LogError(ex, $"Unable to create a new expense sheet for employee with ID '{employeeId}'");
    }
}
</code></pre>

<p>This code demonstrates that support logging uses log levels <em>error</em> or <em>info</em> depending on the context. Verifying the
code of the <em>SupportNotifier</em> class itself can be done by using sociable tests. It‚Äôs not a good idea to write
solitary tests for the <em>SupportNotifier</em> class. This would imply that a test double should be used as an instance of 
<em>ILogger</em>. As we already touched on in a <a href="https://principal-it.eu/2020/05/test-double-heuristics/">previous blog post</a>, it‚Äôs much better to 
avoid using test doubles for types that you don‚Äôt own. In this particular case it would even be quite hard to do as 
the <em>Logxx</em> methods of <em>ILogger</em> are actually extension methods and not regular methods.</p>

<p>Let‚Äôs have a look at the tests for the <em>ExpenseSheetController</em>.</p>

<pre><code>[Specification]
public class When_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();

        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }

    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support()
    {
        _supportNotifier.Received()
            .ExpenseSheetCreated(new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699"));
    }

    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
}

[Specification]
public class When_an_error_occurs_while_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();
        _exception = new InvalidOperationException("Meltdown");
        
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        commandHandler.WhenForAnyArgs(ch =&gt; ch.Handle(null))
            .Throw(_exception);
        
        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }
    
    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support_that_a_new_expense_sheet_has_been_created()
    {
        _supportNotifier.Received()
            .ErrorDuringExpenseSheetCreation(_exception, 
                new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB"));
    }
    
    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
    private Exception _exception;
}
</code></pre>

<p>These tests verify whether support logging occurs when an expense sheet has been created or when an exception gets 
raised. This way we express the intent of the operational requirements.</p>

<p>Notice that controller method has been decorated with a <em>ServiceFilter</em> attribute.</p>

<pre><code>[HttpPost]
[ServiceFilter(typeof(PerformanceTracing))]
public IActionResult Create(CreateExpenseSheetFormModel formModel)
{
    ...
}
</code></pre>

<p>By applying this attribute, the <em>PerformanceTracing</em> action filter is being registered to surround the execution of the 
controller method. Let‚Äôs have a look at the implementation of this action filter.</p>

<pre><code>public class PerformanceTracing : ActionFilterAttribute
{
    private readonly ILogger&lt;PerformanceTracing&gt; _logger;
    private readonly Stopwatch _stopWatch;

    public PerformanceTracing(ILogger&lt;PerformanceTracing&gt; logger)
    {
        _logger = logger;
        _stopWatch = new Stopwatch();
    }

    public override void OnActionExecuting(ActionExecutingContext context)
    {
        _stopWatch.Start();
    }

    public override void OnActionExecuted(ActionExecutedContext context)
    {
        _stopWatch.Stop();

        var controllerName = context.Controller.GetType().Name;
        var controllerActionName = context.ActionDescriptor.DisplayName;
        
        _logger.LogTrace($"Action '{controllerActionName}' of controller {controllerName} executed in " + 
            $"{_stopWatch.ElapsedMilliseconds} ms.");
    }
}
</code></pre>

<p>This implementation is a nice example of diagnostic logging. The action filter measures the execution time of a 
controller method and logs the result. Notice that we‚Äôre injecting the <em>ILogger</em> interface directly into the constructor.
By registering the <em>PerformanceTracing</em> action filter using the <em>ServiceFilter</em> attribute, we ensure that an instance 
of <em>ILogger</em> gets resolved and properly injected. We didn‚Äôt provide any tests for this implementation.</p>

<p>I think it‚Äôs useful to consider support logging and diagnostic logging as two separate concepts, even though they quite 
often use the same mechanisms under the hood.</p>


				<p>
						<em>
							If you and your team want to learn more about how to <u>write maintainable unit tests</u>
							and <u>get the most out of TDD practices</u>, make sure to have look at our
							<a href="https://principal-it.eu/training.html">trainings and workshops</a> or checkout
							the <a href="https://principal-it.eu/books.html">books section</a>. Feel free to reach
							out at <span>info@principal-it.be</span>.
						</em>
					</p>

				

				

				
			</div></div>]]>
            </description>
            <link>https://principal-it.eu/2020/11/unit-tests-for-logging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057372</guid>
            <pubDate>Wed, 11 Nov 2020 11:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Telegram Bot with Azure Functions and Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057328">thread link</a>) | @qpbp_user
<br/>
November 11, 2020 | http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/ | <a href="https://web.archive.org/web/*/http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><ul><li><a href="#introduction">Introduction</a></li><li><a href="#flow-review">Flow Review</a></li><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</a></li><li><a href="#folder-structure">Folder structure</a></li><li><a href="#run-function-locally">Run function locally</a></li><li><a href="#implement-the-bot">Implement the bot</a></li><li><a href="#running-bot-locally">Running bot locally</a></li><li><a href="#deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</a></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="introduction">Introduction</h2><p>In this tutorial, we will create an Azure Function with a simple Telegram Bot (Echo Bot). We will test it locally and then deploy it to Azure Portal. It means our bot will work only at the moment when someone is using it. So the function will be triggered only when someone is sending a message to a bot.</p><h2 id="flow-review">Flow Review</h2><ol><li>The user sends any message to Telegram Bot</li><li>Telegram sends requests via Webhook to our Azure Function</li><li>Azure Function replies to Webhook with a copied message</li></ol><h2 id="prerequisites">Prerequisites</h2><ul><li>node.js - v10.16.2</li><li>npm - v6.14.5</li><li>telegraf - v3.38.0</li><li>ngrok - v2.3.35</li><li>Azure subscribtion</li><li>you need to install <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions">Azure Functions extension</a> to Visual Studio Code</li></ul><h2 id="create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</h2><ol><li><p>click on Azure Icon in Visual Studio Code</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.48.39-1024x885.png" alt="Azure Icon in VSC"></p></li><li><p>login under your Azure subscription</p></li><li><p>click on ‚ÄúCreate Function Icon‚Äù</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.51.16.png" alt="Create Function Icon"></p></li><li><p>you will be asked to use an existing project or create a new. Let‚Äôs create a new:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.54.40-1024x281.png" alt="Create a new project"></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.13-1024x589.png" alt="Create new project folder"></p></li><li><p>select the function template. We will use <strong>HTTP trigger</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.36-1024x607.png" alt="Choose a Function Template"></p></li><li><p>provide a function name and select Enter:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.16-1024x213.png" alt="Enter the name of the function"></p></li><li><p>please provide a <strong>Function</strong> key for a <strong>Function authorization</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.27-1024x280.png" alt="Function Authorization level"></p></li><li><p>penultimate step. Select how you would like to open a project. We will use the current window:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.39-1024x291.png" alt="How to open a function project in Visual Studio Code"></p></li><li><p>you will be redirected to the <strong>default HTTP trigger function with Javascript code</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.57.02-1024x618.png" alt="The default function Code"></p></li><li><p>now this function will appear in Azure Functions section:</p></li></ol><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.23.30-1024x340.png" alt="Newly created function"></p><h2 id="folder-structure">Folder structure</h2><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.29.34-300x256.png" alt="Function Folder Structure"></p><ul><li><strong>package.json</strong> - metadata relevant to the Node.js project</li><li><strong>proxies.json</strong> - you can modify requests and responses from function</li><li><strong>host.json</strong> - metadata file relevant to the Azure project. It‚Äôs a global configuration for all functions in an application</li><li><strong>azure-bot-cloud-function</strong> - it‚Äôs our function folder. Each function has a separate folder with code file (.js in our case) and function.json. Function.json it‚Äôs a <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-expressions-patterns">binding configuration file</a>.</li></ul><h2 id="run-function-locally">Run function locally</h2><ol><li><p>Select Run -&gt; Start Debugging in Visual Studio Code menu</p></li><li><p>If you have no Azure Functions Core Tools locally, you need to install them on this step. The instruction can be found in <a href="https://github.com/Azure/azure-functions-core-tools#installing">Azure repo:</a></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-20.48.48-1024x127.png" alt="Install Azure Function Core Tools"></p></li><li><p>You should see how the NPM tasks will executing and finally get a link to the working function:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.08.28-1024x601.png" alt="Link to the local Azure function"></p></li><li><p>Let‚Äôs open our function in the browser:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.20.46-1024x274.png" alt="Azure Function is working locally"></p><p>As you see, the function responds to us with the behavior by default. Also, you can simply run the function using the <strong>func start</strong> command.</p></li></ol><h2 id="implement-the-bot">Implement the bot</h2><p>For work with Telegram API, we will use the most popular library for Node.js - <a href="https://github.com/telegraf/telegraf">Telegraf.js</a>. We need to install it in the project folder:</p><div><pre><code data-lang="bash">npm install telegraf --save
</code></pre></div><p>Please make sure the <code>package.json</code> has Telegraf after the running previous command.</p><p>Because Telegram will send webhook requests to our bot, we need to make an external HTTPS URL. For this purpose we can use <a href="https://ngrok.com/">ngrok library</a>:</p><p>If all is good, we can go to <code>function-folder&gt;/index.js</code> and create a simple Echo-bot:</p><div><pre><code data-lang="javascript"><span>const</span> <span>Telegraf</span> <span>=</span> <span>require</span>(<span>'telegraf'</span>)
<span>const</span> { <span>TELEGRAM_BOT_TOKEN</span>, <span>WEBHOOK_ADDRESS</span> } <span>=</span> <span>process</span>.<span>env</span>

<span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>TELEGRAM_BOT_TOKEN</span>, {<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> }})

<span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>WEBHOOK_ADDRESS</span>)
<span>bot</span>.<span>on</span>(<span>'message'</span>, (<span>ctx</span>) =&gt; <span>ctx</span>.<span>telegram</span>.<span>sendCopy</span>(<span>ctx</span>.<span>chat</span>.<span>id</span>, <span>ctx</span>.<span>message</span>))

<span>module</span>.<span>exports</span> <span>=</span> <span>async</span> <span>function</span> (<span>context</span>, <span>req</span>) {
	<span>return</span> <span>bot</span>.<span>handleUpdate</span>(<span>req</span>.<span>body</span>, <span>context</span>.<span>res</span>)
}
</code></pre></div><p>You can take <code>TELEGRAM_BOT_TOKEN</code> value from <a href="https://telegram.me/BotFather">BotFather bot</a>. The <code>WEBHOOK_ADDRESS</code> will contain a link to the Azure Function. We will talk about this variable later. Our bot will work in Webhook mode - it‚Äôs a more preferable way to run Telegram bot. The Telegram will automatically inform our bot about all updates. In the polling mechanism, our bot needs to frequently ask Telegram about updates, so it requires non-stop work for our bot (most cases).</p><h2 id="running-bot-locally">Running bot locally</h2><p>To run this bot locally we need to create a public address using ngrok. By default, the local Azure function is running on port <code>7071</code>. We can use the following combination in the terminal to create a public URL:</p><p>In the terminal you will get your HTTPS link for testing Webhook:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.29.42-1024x400.png" alt="HTTPS public URL using ngrok"></p><p>Copy the ngrok-created link and add the route to the function. Something similar to this:</p><div><pre><code data-lang="javascript"><span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>'https://&lt;random-value&gt;.ngrok.io/api/azure-bot-cloud-function'</span>)
</code></pre></div><p>Also, don‚Äôt forget to pass a real Telegram token to the Telegraf constructor:</p><div><pre><code data-lang="javascript"><span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>'some-token-value'</span>, {
	<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> },
})
</code></pre></div><p>It‚Äôs very dirty, but for a quick test it‚Äôs OK, so please remember to remove all real keys from the code.</p><p>Then you can run a function just using the simple command:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.49.14-1024x709.png" alt="Azure Functions is running locally"></p><p>Good job! Now open your bot in Telegram and send any message. Our bot should copy it and resend to you:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.41.16.png" alt="Echo-Bot example"></p><h2 id="deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</h2><p>To deploy Azure Function we just need to click on this button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.52.40-1024x730.png" alt="Deploy Azure Function"></p><p>Then choose your resource and press ‚ÄúDeploy‚Äù. The process will be started:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.53.55-1024x406.png" alt="The process of deploying Azure Function"></p><p>After successful deployment, we need to go to Azure Portal and update <strong>WEBHOOK_ADDRESS</strong> and <strong>TELEGRAM_BOT_TOKEN</strong> variables with real values.</p><p>To get a real function URL, go to ‚ÄúFunctions‚Äù, then choose your Azure Function and press ‚ÄúGet Function Url‚Äù button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.05.24-1024x275.png" alt="How to get Azure Function URL"></p><p>We need to copy this value and paste to Application Settings along with Telegram Token:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.59.12-1024x343.png" alt="Application Settings in Azure"></p><p>After adding our secret keys, press ‚ÄúSave‚Äù and restart our application:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.09.41-1024x424.png" alt="Restart Azure application"></p><p>That‚Äôs all. Our bot should work in the cloud and you can track all function executions in real-time:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.13.07-1024x325.png" alt="Azure Dashboard"></p><p>Each function execution means that our bot handled 1 single message.</p><h2 id="conclusion">Conclusion</h2><p>In this tutorial, we have created an Azure Function with a simple Echo-Bot for Telegram. Azure Functions its a cool way to host your bots. You will be chargeable by the simple formula - (Memory size)X(Execution time in ms)X(Executions per month) and also remember that the first 400,000 GB/s of execution and 1,000,000 executions are free. If you need to estimate your pricing costs you can use <a href="https://azure.microsoft.com/en-us/pricing/calculator/">this pricing calculator</a>.</p><p>P.s. don‚Äôt forget to delete/clean/stop all resources.</p><p><a href="https://disqus.com/">comments powered by </a></p></div></div></section></div>]]>
            </description>
            <link>http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057328</guid>
            <pubDate>Wed, 11 Nov 2020 10:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging the Kernel with QEMU]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057309">thread link</a>) | @__rompy
<br/>
November 11, 2020 | https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html | <a href="https://web.archive.org/web/*/https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4480419177723293408">
<p>Hi folks, in this post I'm going to walk through how to setup the linux kernel for debugging. I will also demonstrate that the setup works by setting a break-point to a test driver I wrote myself. All the code will be available from my gitlab, all the links to my gitlab will be re-posted at the end.&nbsp;</p><p>The setup I describe here re-uses some parts of the syzkaller setup, and for good reason later on in the post series I will break into a tutorial for the syzkaller tool as well. So lets get on with it.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/s1109/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" imageanchor="1"><img data-original-height="625" data-original-width="1109" height="360" src="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/w640-h360/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" width="640"></a></td></tr><tr><td>Screenshot of a successful debug session with full debug symbols for the kernel! We can even see the call to start_kernel and a frame before that as well!<br></td></tr></tbody></table><br>&nbsp;<h2>The Process</h2><p>Okay so we want to study kernel exploitation but given that the kernel isn't something totally accessible in userspace, its not as convenient to debug as userpace stuff, we need a bit of a run up before we can actually poke and prod the kernel to figure out how to write our exploits. So there's a number of important steps to how we get this done, here's what we're going to do:</p><ol><li>Build a kernel</li><li>Build an image</li><li>Launch the virtual machine&nbsp;</li><li>Attach and setup the debugger</li><li>Building, loading and debugging a test module <br></li></ol><p>We also need to be able to build our kernel because there may be build options that are important to configure in order to control exploit protection or include modules and functionality to the kernel when needed. <br></p><h2>Building a Kernel</h2><p>Okay so before we get going with launching our Qemu instances and debugging modules we need an environment. For convenience sake I'm working off of a fresh Ubuntu 18.04.5 LTS machine. I'll document the processes from fresh install to first successful kernel build.</p><p>To start we need to make sure we have everything we need to build a kernel:</p><p><span>$<b>sudo apt-get update</b></span></p><p><span>$<b>sudo apt-get upgrade </b><br></span></p><p><span>$<b>sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison qemu-system-x86</b></span></p><p>Next we obviously need a kernel so lets download a brand new kernel:</p><p><span>$<b>wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz</b><br>--2020-11-10 23:00:26--&nbsp; https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz<br>Resolving cdn.kernel.org (cdn.kernel.org)... 151.101.225.176, 2a04:4e42:35::432<br>Connecting to cdn.kernel.org (cdn.kernel.org)|151.101.225.176|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 115538096 (110M) [application/x-xz]<br>Saving to: ‚Äòlinux-5.9.7.tar.xz‚Äô<p>linux-5.9.7.tar.xz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 42%[=============&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]&nbsp; 46.79M&nbsp; 3.08MB/s&nbsp;&nbsp;&nbsp; eta 23s&nbsp;&nbsp; &nbsp;</p></span></p><p><span>... <br></span></p><p><span>$<b>tar -xf linux-5.9.7.tar.xz</b></span></p><p>We're just a couple steps from sending the final build commands, before we get to that lets make sure the kernel config is ready to rock. Because we're working on a Linux host we can simply swipe the .config for the virtual machine's Ubuntu kernel like so:</p><p><span>$<b>cp /boot/config-5.4.0-52-generic .config</b></span></p><p>We then need to select some options that make debugging and exploit dev a little easier. First thing we need is to merge some options for making the kernel easier to run in a virtual machine:</p><p><span>$<b>make kvmconfig</b></span></p><p><span>Using .config as base<br>Merging ./kernel/configs/kvm_guest.config<br>#<br># merged configuration written to .config (needs make)<br>#</span></p><p><span>...</span></p><p>Great, now we need to enable some options for debug symbols, kaslr and other awesome things. So open the <span>.config</span> somewhere in a text editor and make sure you either add or modify the file so these options are set:</p><p><span>CONFIG_KCOV=y<br>CONFIG_DEBUG_INFO=y<br>CONFIG_KASAN=y<br>CONFIG_KASAN_INLINE=y<br>CONFIG_CONFIGFS_FS=y<br>CONFIG_SECURITYFS=y </span><br><span><span># CONFIG_RANDOMIZE_BASE is not set<br></span></span></p><p>Cool now we need to make sure the config is ready to go for a build:</p><p><span>$<b>make savedefconfig</b></span></p><p><span>$<b>make -j4</b></span></p><p><span>&nbsp;...</span></p><p>Now you should grab some coffee, play a startcraft2 game because this may take a while. Okay so if your build worked you should have an object file in the following location:</p><p><span>[kernel_dir]/arch/x86_64/boot/bzImage</span>&nbsp;</p><h2>Build an image</h2><p>We're going to build an image for this kernel so we might as well plop a "image" directory in this folder:</p><p><span>$<b>mkdir [kernel_dir]/image/</b></span></p><p>Once you're kernel is build we need to start thinking about how to build a file system for this. Here I'm going to cheat and steal some tips from the syzkaller folks. We need to first download syzkaller, as follows:</p><p><span>$<b>git clone https://github.com/google/syzkaller.git</b></span></p><p><span>Cloning into 'syzkaller'...<br>remote: Enumerating objects: 1, done.<br>remote: Counting objects: 100% (1/1), done.<br>...<br></span></p><p>Move back to the kernel build and setup an image:</p><p><span>$<b>cd [kernel_dir]/image/</b></span></p><p><span>$<b>cp [syzkaller_dir]/tools/create_image.sh .</b></span></p><p>Okay so we can now create an image, all we need to do is simply invoke create_image.sh:</p><p><span>$<b>./create_image.sh&nbsp;</b></span></p><p><span>+ DIR=chroot<br>+ PREINSTALL_PKGS=openssh-server,curl,tar,gcc,libc6-dev,time,strace,sudo,less,psmisc,selinux-utils,policycoreutils,checkpolicy,selinux-policy-default,firmware-atheros,python,xrdp,g++,make,libtool,autoconf,nasm<br>+ '[' -z ']'<br>+ ADD_PACKAGE=make,sysbench,git,vim,tmux,usbutils,tcpdump</span></p><p><span>...</span><br></p><p>If that worked you should have the following in your folder:</p><p><span>$<b>ls</b>&nbsp;</span></p><p><span>chroot/</span></p><p><span>create-image.sh</span></p><p><span>stretch.id_rsa</span></p><p><span>stretch.id_rsa.pub</span></p><p><span>stretch.img</span><br></p><h2>Launch the virtual machine <br></h2><p>Now we can launch qemu with all the goodies in place:</p><p><span>qemu-system-x86_64 \<br>&nbsp; -kernel <b>../arch/boot/x86_64/bzImage</b> \<br>&nbsp; -append "console=ttyS0 root=/dev/sda earlyprintk=serial nokaslr"\<br>&nbsp; -hda <b>./stretch.img</b> \<br>&nbsp; -net user,hostfwd=tcp::10021-:22 -net nic \<br>&nbsp; -enable-kvm \<br>&nbsp; -nographic \<br>&nbsp; -m 2G \<br>&nbsp; -s \<br>&nbsp; -S \<br>&nbsp; -smp 2 \<br>&nbsp; -pidfile vm.pid \<br>&nbsp; 2&gt;&amp;1 | tee vm.log</span></p><p><span>...</span></p><p><br>The <span>-s</span> is a shorthand for <span>-gdb tcp::1234</span>, which means the gdbserver will be hosted at port 1234. -S tells qemu not to start the cpu automatically, this gives us a chance to set a breakpoint before the kernel starts executing. </p><p>So that's the image running smoothly, lets setup our debugging environment.</p><h2>Attach and setup the debugger<br></h2><p>We can then attach a gdb debugger to the qemu instance as follows. On another terminal, separate from the one running your qemu instance, start up gdb and issue the following commands:</p><p><span>$<b>cd [kernel_dir]/image/ </b><br></span></p><p><span>$<b>gdb ../vmlinux<br></b></span></p><p><span>Reading symbols from ../vmlinux...</span></p><p><span>(gdb)<b> target remote :1234<br></b></span></p><p><span>Remote debugging using :1234<br>0x000000000000fff0 in exception_stacks ()<br></span></p><p><span>(gdb) <b>c</b></span></p><p>We give the "c" command to continue execution. We can now set some of our own breakpoints. As part of the tutorial I've included a custom IOCTL driver and app code (code that invokes the ioctl from userspace), i thought this would be nifty since it shows full ability to develope and debug a driver, something crucial to hunting down modern bugs and exploit development. Anyway lets code and build our own module.</p><h2>Building, Loading and debugging a test module<br></h2><p>Okay so we need to make a test ioctl driver, so lets head over the to kernel source directory and make a new folder in the /driver/ subfolder:</p><p><span>$</span><b><span>cd&nbsp; [kernel_dir]/drivers/</span></b></p><p><span>$</span><b><span>mkdir debug_driver/</span></b></p><p><span>$</span><b><span>cd debug_driver/ <br></span></b></p><p><span>$</span><b><span>touch debug_driver.c</span></b></p><p><span>$</span><b><span>touch debug_driver_app.c</span></b></p><p><span>$</span><b><span>touch Makefile</span></b></p><p>The code for <span>debug_driver.c</span> and <span>debug_driver_app.c </span>as we well as the <span>Makefile</span> are available at this repo <a href="https://gitlab.com/k3170makan/linux-kernel-exploit-development">https://gitlab.com/k3170makan/linux-kernel-exploit-development</a>. All you need to do is download the repo and stick this in its own folder under <span>[kernel_dir]/drivers/</span>. To build the module the we need to set the "M" variable in the kernel make script:</p><p><span>$<b>cd [kernel_dir]; make -C . M=drivers/debug_driver/</b></span></p><p><span>make: Entering directory '/home/kh3m/Research/Kernel/debug_image/linux-5.5.3'<br>&nbsp; AR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; drivers/debug_driver//built-in.a<br>&nbsp; CC [M]&nbsp; drivers/debug_driver//debug_driver.o</span></p><p><span>...</span></p><p>Now we need to get this module on our qemu host somehow, I do this the hard way, I'm sure there's all sorts of nifty ways to scp files onto the qemu host but I actually just re-create the image after copying the drivers to a folder to be baked into the start up filesystem. First we need to edit create-image.sh so it includes everything in a folder we specify, that way we can just dump stuff in the folder and run create-image.sh whenever we want those files on a live instance.</p><p>So before create-image.sh builds the disk image on line 129, stick this in there:</p><p>++ <span>sudo cp -r ./add/* $DIR/home/.</span><br></p><p>now we make a "add" folder and stick the kernel module and app code in there:</p><p><span>$<b> cd [kernel_dir]/image/</b></span></p><p><span>$ <b>mkdir add/</b></span></p><p><span>$ <b>cd add/</b></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver.ko .</b><br></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver_app.c .</b></span></p><p><span>$ <b>./create-image.sh</b> </span></p><p>Okay so we have a module, we have a symbol file debug_driver.ko, with stuff we need to set breakpoints. Lets load the module into the kernel, then check where it gets loaded before we actually set the breakpoint:</p><p><span>root@syzkaller:$ <b>cd /home/</b></span></p><p><span>root@syzkaller:$ insmod debug_driver.ko</span></p><p><span> [&nbsp;&nbsp; 32.792570] audit: type=1400 audit(1605058227.605:7): avc:&nbsp; denied&nbsp; { module_load } for&nbsp; pid=249 comm="insmod" path="/home/debug_driver.ko" dev="sda" ino=21253 scontext=system_u:system_r:kernel_t:s0 1<br>[&nbsp;&nbsp; 32.793766] debug_driver: loading out-of-tree module taints kernel.<br>[&nbsp;&nbsp; 32.800394] [debug_driver] loaded! <br>[&nbsp;&nbsp; 32.800826] [debug_driver] device registered successfully<br>[&nbsp;&nbsp; 32.802298] [debug_driver] device has been successfully created <b><br></b></span></p><p>Before we can debug it properly we need to know where it is loaded in kernel memory:</p><p><span>root@syzkaller:/home# <b>cat /proc/modules</b> <br>debug_driver 16384 0 - Live <b>0xffffffffa0000000</b> (O)</span></p><p>Okay lets now set our breakpoint and load the symbol file using the base address of the module:</p><div><p><span>&nbsp;(gdb) <b>add-symbol-file ../drivers/debug_driver/debug_driver.ko&nbsp; 0xffffffffa0000000</b><br>add symbol table from file "../drivers/debug_driver/debug_driver.ko" at<br>&nbsp;&nbsp; &nbsp;.text_addr = 0xffffffffa0000000<br>(y or n) <b>y</b><br>Reading symbols from ../drivers/debug_driver/debug_driver.ko...<br>(gdb) <b>break dev_read</b><br>Breakpoint 1 at <b>0xffffffffa0000010: file drivers/debug_driver//debug_driver.c</b>, line 81.<br>(gdb) c</span></p></div><p>Cool lets execute the driver program so we can trigger the code we want:</p><p><span>root@syzkaller:$ <b>gcc -o debug_driver_app.elf debug_driver_app.c<br></b></span></p><p><span><span>root@syzkaller:/home# <b>./debug_driver_app.elf </b><br>Usage: ./debug_driver_app.elf [message to write] [read length] <br></span></span></p><p><span><span>root@syzkaller:</span>$ <b>./debug_driver_app.elf "hello" 10</b></span></p><p><span>[&nbsp; 160.083320] [debug_driver] message successfully copied message =&gt; [hello]<br>[&nbsp; 160.083326] [debug_driver] buffer copied to message holder<br>[debug_driv‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</a></em></p>]]>
            </description>
            <link>https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057309</guid>
            <pubDate>Wed, 11 Nov 2020 10:53:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why electronic voting is dangerous]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057302">thread link</a>) | @ian_starts
<br/>
November 11, 2020 | https://blog.iankok.com/risk-electronic-voting | <a href="https://web.archive.org/web/*/https://blog.iankok.com/risk-electronic-voting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>With the 2020 US elections having mail in ballots,
I found myself wondering if a digital solution would be safer, more reliable and easier. As usual the answer isn't straightforward. </p>
<p>In this post I'll talk you through some possible solutions and their potential downsides.</p>
<p>I will mostly focus on Dutch elections, seeing as I can provide the best insights, and most arguments are easily
transferable to other nations.</p>
<h2>Requirements</h2>
<p>If we would develop a voting system from scratch it would need to have some features that protect our rights and make
sure the elected ruler is the one the people really wanted (questionable if that's the case with current electoral systems, but that's for another time).</p>
<ol>
<li><strong>Accuracy</strong> - are all the votes counted, do they represent the will o' the people?</li>
<li><strong>Anonymity</strong> - very difficult this one. We don't want the votes to be signed, that would leave opportunities for
coercion and intimidation. However, we do need to verify that the voter is eligible to vote (or a real person at all for that matter).</li>
<li><strong>Verifiability</strong> - we need to be able to verify if the process went correctly.</li>
<li><strong>Speed</strong> - it would be useful if votes would be counted quicker. </li>
</ol>
<p>A big problem with anonymity and verifiability is that making votes anonymous makes them difficult to verify.</p>
<p>If we had a database with all the people who voted, and their cast vote, verifiability would be tackled. However, it wouldn't be anonymous.</p>
<h2>e-voting vs i-voting</h2>
<p>When discussing electronic voting there are essentially two things at play. </p>
<ol>
<li><strong>e-voting</strong> - voting on a machine on location. Like 35 municipalities did in the Netherlands between roughly 1970 and 2007.</li>
<li><strong>i-voting</strong> - voting online using a device connected to the internet.</li>
</ol>
<p>e-voting is usually seen as the easier one. You can tackle anonymity by submitting anonymous votes, and verify it
manually with a passport check before entering the voting booth.</p>
<p>i-voting is much more difficult, because you can't have the manual check.</p>
<h2>We can protect our back accounts, so how hard can protecting votes be, right?</h2>
<p>Well, unless you're part of a secret society with unlimited wealth, chances are your bank account is not a very interesting target.</p>
<p>The scale of an election is massive. The decision made there has so much influence,
that it's an incredibly high value target.</p>
<blockquote>
<p>Most hackers aren't hardcore geeks typing away on their kali linux distro. It's usually a game of
influencing people, leaked data or a weak password. This can be summarised as the <em>human error</em>.</p>
</blockquote>
<p>It's much more likely hackers will pour resources into hacking an election than a bank account.</p>
<h2>e-voting</h2>
<p>e-voting seems like a pretty good idea. it's pretty straight forward on an abstract level: keep everything the same, only make the counting digital.</p>
<p>Too bad it's an oversimplification. It's impossible for most voters to check how the system works internally.
Even if the voters were all programmers, the source code doesn't have to be open-source. There's no rule against making the source code private. </p>
<p>So basically, it's a black box which we have to trust with one of the most important things in a democracy, and impossible for any voter to check the process.</p>
<p>This fear is backed by a <a href="https://www.bundesverfassungsgericht.de/SharedDocs/Pressemitteilungen/EN/2009/bvg09-019.html">2009 decision</a> by the Federal Constitutional Court of Germany:</p>
<blockquote>
<p>The use of voting machines which electronically record the voters‚Äô votes and electronically ascertain the election
result only meets the constitutional requirements if the essential steps of the voting and of the ascertainment of the
result can be examined reliably and without any specialist knowledge of the subject.  </p>
</blockquote>
<p>Beside these 'lack of control' fears, a lot of systems have failed miserably over the years.</p>
<p>The lack of pen-testing (inviting good-guy hackers to attack your system and check for vulnerabilities) makes it very hard to pinpoint exact failures, but here's a curated list of found problems in the US:</p>
<ul>
<li>2003 ‚Äì In Fairfax, new voting machines either didn‚Äôt work, or would lose the voter‚Äôs choice after a few moments.</li>
<li>2003 ‚Äì The State of Maryland found that the Diebold Election Systems, Inc. (now rebranded as Premier Election Solutions) AccuVote-TS system ‚Äúas implemented in policy, procedure, and technology, is at high risk of compromise.‚Äù</li>
<li>2002-2006 ‚Äì During this period, Election Systems and Software, the US‚Äôs leading voting machine manufacture was shipping some of its systems with remote access software, making them vulnerable to hacking.  </li>
<li>2006 ‚Äì Researchers from the Voting Systems Technology Assessment Advisory Board (VSTAAB) and the University of California corroborated previous research that found various Diebold voting machines can have the votes on their memory cards tampered with in a way that cannot be detected. They found a number of other security vulnerabilities as well.</li>
<li>2006 ‚Äì Princeton researchers studied the Diebold AccuVote-TS and found that it was vulnerable to a range of serious attacks. These included the possibility of malware installation which could be used to alter the vote.</li>
<li>2015 ‚Äì The Virginia Information Technologies Agency assessed the WinVote machine, which is manufactured by Advanced Voting Solutions. The agency recommended discontinuing the use of these machines after they found a range of serious flaws such as weak passwords, outdated security protocols, and insufficient system hardening.</li>
<li>2018 ‚Äì At DEFCON, J. Alex Halderman showed that Diebold AccuVote TSX voting machines could be manipulated remotely in a mock election. The same vulnerable machines were being used in 18 different states. After the event, a 50 page report was released, detailing vulnerabilities in Election Systems &amp; Software‚Äôs M650 machine and the Diebold AccuVote TSX. Together, these machines are used in as many as 23 states.</li>
<li>2018 ‚Äì Some voters in Texas allege that the Hart InterCivic‚Äôs eSlate machine was switching their vote to another candidate in the state‚Äôs election for senator.</li>
</ul>
<p>And of course a Dutch problem:</p>
<ul>
<li>2007 - It was possible to read and analyse the Electromagnetic radiation of voting machines from dozens of meters away. This caused the anonymity to be completely compromised.</li>
</ul>
<p>Side-note; this was known before an election took place. Still, parts of the election were held with the voting machines,
causing the Dutch government to be sued, losing, and going back to paper ballots.</p>
<p>So yeah, e-voting; not perfect.</p>
<h2>Hopes for e-voting</h2>
<p>More recently there has been talk of re-instating e-voting with some big adaptations. </p>
<p>The new version would basically be a computer with a printer. You can cast your vote in a voting booth with no
connectivity to the web. The voting machine would print your vote on a piece of paper, which you can then check for errors and deposit in the voting box.
These printed votes are easily read by a central computer, making counting them a lot easier and quicker.</p>
<p>Though this seems like an interesting concept, it's also doesn't have a lot of benefits over paper ballots. As the software axiom goes "keep it simple, stupid",
this doesn't really comply.</p>
<h2>i-voting</h2>
<p>I-voting, also known as remote e-voting, is casting your vote from the comfort of your own couch.
The only country which implemented such a system is Estonia. With tech giants migrating more of your life to the internet,
it seems that it's only logical to move to i-voting. Let's take a look at Estonia. How their system works,
what the vulnerabilities are, and whether we should follow suit.</p>
<h3>How it works</h3>
<p>Estonia's i-voting system builds on their ID card. This ID card is also a smart card and allows owners to digitally
sign documents and facilitates secure authentication. This already laid infrastructure makes it possible to tackle one of our demands; <strong>verifiability</strong>.</p>
<p>The i-voting system is available in an early voting period (sixth day to fourth day prior to Election Day). You can
change your vote an unlimited amount of times in that timeframe. You can also overwrite your vote by going to a
polling station, invalidating your i-vote.</p>
<p>When this new voting method was first introduced, the president Arnold R√º√ºtel challenged i-voting, claiming breach of the principle of equality of voting.
The president brought a petition against the e-voting provisions to Estonian Supreme Court but lost. R√º√ºtel was mostly
popular amongst the still Russian speaking elderly minority. About 1.9% voted online in the
<a href="https://archive.is/20120713045721/http://news.com.com/Estonia+pulls+off+nationwide+Net+voting/2100-1028_3-5898115.html">2005 election</a>.
This has increased over the years to <a href="https://rk2019.valimised.ee/en/voting-result/voting-result-main.html">43.8% in 2019</a>.</p>
<p>Estonia also open-sourced much of their source code to make the system as transparent as possible. They haven't
released everything (annoying some critics). Most notably, all the client side code is missing (more in that later).</p>
<p>One of the biggest things going for i-voting is potentially increasing voter turnout, however that
claim has been <a href="https://core.ac.uk/download/pdf/95665595.pdf">mostly invalidated.</a></p>
<h3>Vulnerabilities</h3>
<p>One peer <a href="https://estoniaevoting.org/findings/paper/">reviewed research paper</a> claims the researchers could be able to
breach the system, change votes and vote totals, and erase any evidence of their actions if they could install
malware on the election servers. Now of course, it's basically impossible to breach the security of election servers.
However, circling back to human error; what if someone is bribed, careless, or just malicious? The stakes are immense,
and these edge cases can not be ignored.</p>
<p>Another gaping security hole is the personal device of the voter. This may be the weakest link in the chain.
The system is quite robust after the ballot has been cast. However, sending that ballot is not trivial. </p>
<p>It's easy to write a fake web client (hence the hidden source code. That would make it too easy),
tricking people into thinking they've already voted. Or a piece of malware, sending a different vote than you typed.</p>
<p>The Estonian National Electoral parried these criticisms, <a href="http://vvk.ee/valimiste-korraldamine/vvk-uudised/vabariigi-valimiskomisjoni-vastulause-the-guardianis-ilmunud-artiklile">claiming</a>
they "give us no reason to suspend online balloting". The purported vulnerabilities were said to be either not feasible in reality or already accounted for in the design of the e-voting system.</p>
<p>The Estonian Information System Authority also responded. Claiming the criticisms as a political, rather ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.iankok.com/risk-electronic-voting">https://blog.iankok.com/risk-electronic-voting</a></em></p>]]>
            </description>
            <link>https://blog.iankok.com/risk-electronic-voting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057302</guid>
            <pubDate>Wed, 11 Nov 2020 10:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Choosing Boring Tech]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057240">thread link</a>) | @amzans
<br/>
November 11, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I‚Äôm often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn‚Äôt matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It‚Äôs an illusion that makes us feel like we‚Äôre fully in control of what makes or breaks the product.</p><p>Don‚Äôt get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you‚Äôre actually building, and sooner or later your business will hit this wall.</p><p>I‚Äôm not saying that software doesn‚Äôt matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you‚Äôre trying to solve and the resources you have at hand. There‚Äôs no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as ‚Äúpicking old technologies over newer ones‚Äù, but it doesn‚Äôt necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you‚Äôre trying to make a decision to increase the odds that your product or business will succeed, it‚Äôs worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it‚Äôs about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I‚Äôm happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I‚Äôd rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what‚Äôs important here, it‚Äôs more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That‚Äôs why I wouldn‚Äôt bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I‚Äôm being serious). But that‚Äôs for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It‚Äôs a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear‚Äôs tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057240</guid>
            <pubDate>Wed, 11 Nov 2020 10:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Option Hacking the Tektronix TDS 420A]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25057162">thread link</a>) | @segfaultbuserr
<br/>
November 11, 2020 | https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html | <a href="https://web.archive.org/web/*/https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Previous installments in this series: <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html">In the Lab - Tektronix TDS 420A Oscilloscope</a>, 
 <a href="https://tomverbeure.github.io/2020/06/27/Tektronix-TDS420A-Remote-Control-over-GPIB.html">Tektronix TDS 420A Remote Control over GPIB</a>, 
 <a href="https://tomverbeure.github.io/2020/07/02/Extracting-the-Tektronix-TDS420A-Firmware.html">Extracting the Tektronix TDS 420A Firmware</a>, 
 <a href="https://tomverbeure.github.io/2020/07/03/TDS420A-Serial-Debug-Console-Symbol-Table-Ghidra.html">A Tektronix TDS 420A, a Serial Debug Console, a Symbol Table, and Ghidra</a></em></p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#how-a-tds400-oscilloscope-manages-hardware-features" id="markdown-toc-how-a-tds400-oscilloscope-manages-hardware-features">How a TDS400 Oscilloscope Manages Hardware Features</a></li>
  <li><a href="#the-key-to-enabling-option-05---video-triggering" id="markdown-toc-the-key-to-enabling-option-05---video-triggering">The Key to Enabling Option 05 - Video Triggering</a></li>
  <li><a href="#the-key-to-enabling-option-2f---advanced-dsp-math" id="markdown-toc-the-key-to-enabling-option-2f---advanced-dsp-math">The Key to Enabling Option 2F - Advanced DSP Math</a></li>
  <li><a href="#options-05-and-2f-enabled" id="markdown-toc-options-05-and-2f-enabled">Options 05 and 2F Enabled!</a></li>
  <li><a href="#option-1m---120k-sample-points---a-different-story" id="markdown-toc-option-1m---120k-sample-points---a-different-story">Option 1M - 120K Sample Points - A Different Story</a></li>
  <li><a href="#in-search-of-the-missing-memory" id="markdown-toc-in-search-of-the-missing-memory">In Search of the Missing Memory</a></li>
  <li><a href="#success-at-last" id="markdown-toc-success-at-last">Success at Last!</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>



<p>I wrote <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html#the-tektronix-tds-420a-in-brief">earlier</a>
about the optional features of TDS 400 series of oscilloscopes:</p>

<ul>
  <li>Option 05: Video Trigger</li>
  <li>Option 13: RS-232/Centronics Hardcopy Interface</li>
  <li>Option 1F: File System/Floppy</li>
  <li>Option 2F: Advanced DSP Math</li>
  <li>Option 1M: 120k waveform sample points</li>
</ul>

<p>Most scopes, including mine, come with options 13 and 1F, but the remaining ones are less common.</p>

<p>The video triggering and advanced DSP math options are pure firmware functions, but even 
the 120k sample points option seemed like something that could be enabled with a software hack, since
the signal acquisition board has the 512KB of RAM available to store the data.</p>

<p>Here, I‚Äôll describe how the TDS 400 series manages option enablement, and
how you can hack the scope into getting them to work.</p>



<p>Using Ghidra and the debug console, I figured out how the scope manages hardware
features: it has a function called <code>hwAccountantQuery</code> that has a single
parameter which I‚Äôll call the ‚Äòfeature ID‚Äô.</p>

<p><code>hwAccountantQuery</code> will return an integer value for that feature ID. These values
can be boolean in nature (‚ÄúIs a certain feature present or not‚Äù) or can be the
amount of DSP memory etc.</p>

<p>Here‚Äôs a very non-exhaustive list of codes that I‚Äôve been able to identify:</p>

<div><div><pre><code>0x20d: number of scope channels
0x20f: size of acquisition RAM
0x216: ProbeD2MemSize
0x248: CPU clock period
0x255: InstrumentNameStringPtr
0x271: hwProbeSpecialDiagModeActive
0x2a0: hwProbeSpecialDiagLoopCount
0x2a1: hwProbeSpecialDaigSeqId
0x2b8: 30000 points -&gt; value when 1M option is not possible
0x2bf: TDS420A
0x2d2: RS232 Debug uart present
0x317: MathPak      -&gt; this is the advanced DSP math function
0x461: Floppy drive present
0x537: flashRomDateStringPtr
0x54c: TDS410A
0x560: TDS430A
0x700: hwProbeTvTrigPresent
</code></pre></div></div>

<p><code>hwAccountantQuery</code> calls <code>hwAccountantGetValue</code>. The first part of that function looks liks this:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwAccountantGetValue.png" alt="hwAccountantGetValue"></p>

<p>It‚Äôs a large <code>if-then-else</code> or <code>case</code> statement that calls a dedicated function for a particular
feature ID.</p>



<p>Did you see <code>_hwProbeTvTrigPresent()</code>? That‚Äôs the function that checks
if the video triggering feature should be enabled:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTvTrigPresent.png" alt="hwProbeTvTrigPresent"></p>

<p>And there we have it! To enable ‚ÄúOption 05 - Video Triggering‚Äù, all you need to do
is store a non-zero value in non-volatile RAM location 7!</p>

<p><em>This is not a shocking new discovery: plenty of online sources already mentioned this,
but it‚Äôs great to confirm it from first principles, by going to the source.</em></p>



<p>Internally, the Advanced Math DSP is called ‚ÄúMathPak‚Äù. Just like for video triggering, 
the <code>hwAccountGetValue</code> function issues a call to <code>hwProbeMathPakPresent()</code>:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeMathPakPresent.png" alt="hwProbeMathPakPresent"></p>

<p>Option 2F simply relies on a non-zero value in NVRAM location 9!</p>



<p>It‚Äôs now just a matter of issuing the following 2 commands on the debug console:</p>

<div><div><pre><code>libManagerWordAtPut 0x50007, 1
libManagerWordAtPut 0x50009, 1
</code></pre></div></div>

<p>My scope booted up with this image:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/options_05_and_2f_enabled.jpg" alt="Options 05 and 2F enabled"></p>

<p>Success! I‚Äôm now the proud owner of a scope that supports an entirely obsolete video triggering
mode, and a FFT math option!</p>

<p>Video Triggering Menu:
<img src="https://tomverbeure.github.io/assets/tds420a/video_triggering_features.jpg" alt="Video triggering features"></p>

<p>Live FFT of a 1kHz square wave:
<img src="https://tomverbeure.github.io/assets/tds420a/fft.jpg" alt="FFT"></p>



<p>Unfortunately, the <code>case</code> statement is only a small part of the <code>hwAccountGetValue</code> function: most
feature checking functions are performed by looping through an array of structs that
have the feature ID and a function pointer to the checking function. It‚Äôs a bit harder to figure 
out in Ghidra, but we already know that the function names to enable options start with <code>hwProbe</code>.</p>

<p>With Ghidra, we can filter on this, and that gives the <code>hwProbe1MOption</code> and the 
<code>hwProbe1MPresent</code> functions.</p>

<p><code>hwProbe1MPresent</code> looks very familiar:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MPresent.png" alt="hwProbe1MPresent"></p>

<p>Just like for the 05 and 2F options, we need to set a specific byte in the
NVRAM:</p>

<div><div><pre><code>libManagerWordAtPut 0x50006, 1
</code></pre></div></div>

<p><code>hwProbe1MOption</code> is a different story:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MOption.png" alt="hwProbe1MOption"></p>

<p>When you run <code>hwProbe1MOption</code> on the command line, the function returns a 0.</p>

<p>Feature IDs 0x216 and 0x20f are also part of the array of structs. They call the functions
<code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> respectively.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTable.png" alt="hwProbe table"></p>

<p><code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> both run a test to check the amount of RAM that 
is populated on the board.</p>

<p>When you run these query commands on the debug console, you get:</p>

<div><div><pre><code>hwAccountantQuery(0x216)    
262143
hwAccountantQuery(0x20f)    
131071
</code></pre></div></div>

<p>It‚Äôs now clear why option 1M doesn‚Äôt get enabled after changing the NVRAM value: 
feature ID 0x20f is fine (131071/0x1ffff is larger than 0x1fffe), but feature ID 0x216 is not 
(262143/0x3ffff is smaller than 0xffffe).</p>

<p>Whatever it is used for, the amount of ‚ÄúD2‚Äù memory in the scope is too small.</p>



<p>This finally gave me the crucial hint to start looking at other PCBs inside the scope and
try to find if there‚Äôs a place with empty footprints for RAM chips.</p>

<p>I call this the DSP PCB. Luckily, it‚Äôs a board that‚Äôs easy to remove from the chassis, without 
fragile flex cables or connectors.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_pcb.jpg" alt="DSP PCB"></p>

<p>Look at those 6 beautiful, unused footprints!</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/ram_footprints_closeup.jpg" alt="RAM footprints closeup"></p>

<p>The RAM chips are M5M51008 with a 100ns speed rating, made by Mitsubishi LSI.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_datasheet.jpg" alt="Memory Datasheet"></p>

<p>Surprisingly, Digikey still carries these parts: they‚Äôre now made by Rochester
Electronics, and only available in 70ns or 55ns version, but faster is better,
so that shouldn‚Äôt be a problem.</p>

<p>They‚Äôre cheap too at just $2.56 a piece.</p>

<p>The only issue is a minimum order quantity of 100 parts. $256 for a feature
on a 25 years old $190 oscilloscope is a bit too much! Luckily, the parts
are available at various Chinese chip brokers: I was able to buy them at 
<a href="https://utsource.net/">UTSource</a> for just $1.81 a piece. Even when buying 10 
of them (for redundancy), shipping was the biggest part of the cost:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_order.png" alt="Memory Order"></p>

<p><em>Once ordered, UTSource let me know that these parts were refurbished‚Ä¶</em></p>

<p>A few days later, the parts arrived at my front door, ready to be populated
on the DSP board:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_board_before_surgery.jpg" alt="DSP Board Before Surgery"></p>

<p>Note how I did not disconnect the battery that‚Äôs wired to the board: it‚Äôs used to
permanently provide power to those 4 RAMs chips on the left that are encased into 
some transparant polymer gu. Removing the battery will result in lost calibration
data (or so they say.)</p>

<p>I used a regular soldering iron instead of a hot air gun to attach the 6 RAMs:
there was enough solder on the pads and I‚Äôm most comfortable doing it that way.
Afterwards I Ohm‚Äôed out most of the pins, and I‚Äôm glad I did because
there were some open connections.</p>

<p>The end result isn‚Äôt perfect, but it‚Äôs good enough:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/rams_populated.jpg" alt="RAMs Populated"></p>



<p>With the RAM populated, it‚Äôs time to power on the scope and check the result
of the enhancement surgery!</p>

<p>The scope bootup screen looks good:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/option_1m_enabled.jpg" alt="Option 1M enabled"></p>

<p>And this formerly grayed out 12000 points menu option is now available:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/120k_points.jpg" alt="120K Points"></p>

<p>Victory at Last!</p>



<p>The TDS 420A is an old oscilloscope, and even with those 3 new options enabled, it‚Äôs
far inferior to my Siglent 2304X or even my HP 54825A (Windows 95!) loaner.</p>

<p>120K sample points is obviously better than 30K, but it still pales in comparison
to the 140M sample points of the Siglent.</p>

<p>So what then was the point of this whole exercise?</p>

<p>I got a close up view of oscilloscope internals, I learned Ghidra from scratch and
applied it on a real, non-trival project, I added RAM to a 25 year old oscilloscope 
and it worked, I spent tons of late night hours decoding firmware, and 
I had an unreasonable amount of fun doing so.</p>

<p>I even started to appreciate the Tektronix user interface a little bit!</p>

<p>It was time well spent.</p>

<p>For now, the scope will remain on my bench while I start adding Tektronix support 
in glscopeclient. That was the whole point of acquiring the scope to being with!</p>

<p>And if it turns out that it‚Äôs really too limited for my use, I can always
sell it back on eBay, this time with 3 additional features enabled.</p>



<ul>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/hacking-my-tds460a-to-have-options-1m2f/">Hacking my TDS460A to have options 1M/2F?</a></p>
  </li>
  <li>
    <p><a href="https://forum.tek.com/viewtopic.php?t=140268">TDS420 Options Possible?</a></p>
  </li>
  <li>
    <p><a href="http://videohifi17.rssing.com/chan-62314146/all_p49.html">Upgrade Tektronix: FFT analyzer</a></p>

    <p>Story about upgrading the CPU board from 8MB to 16MB on a TDS420 (not the 420A?) and then FFT in the
  NVRAM.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=iJt2O5zaLRE">Enabling FFT option in Tektronix TDS 540A oscilloscope</a></p>

    <p>Not very useful for 420A owners: enables FFT by copying NVRAM EEPROM.</p>
  </li>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/tds420-with-lost-options/msg2032465/?PHPSESSID=021nnvu02ca549sh5le7s9r8i5#msg2032465">TDS420 with lost options</a></p>

    <p>Specific comment about how to enable options on the 420A over GPIB. I wasn‚Äôt able to get this to 
  work for some reason.</p>
  </li>
  <li>
    <p><a href="http://www.ko4bb.com/getsimple/index.php?id=enable-tds754d-options">Enable TDS754D Options using GPIB</a></p>

    <p>Another one about using GPIB.</p>
  </li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057162</guid>
            <pubDate>Wed, 11 Nov 2020 10:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forming Professional Dev Team Habits]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057078">thread link</a>) | @morchen
<br/>
November 11, 2020 | https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>How does your workplace cultivate an environment of team development? How do you make sure your engineers have time for creative ideas and professional development, all the while meeting sprints, deadlines and deliverables? While branded photogenic team building activities are common in many tech companies ‚Äî especially with rapidly growing teams, this strategy fails to help grow together as professionals and misses the aim in the long run.</p>
<p>For long, I‚Äôve been toying with such questions, asking myself ‚Äî how can companies keep ‚Äúthe fun bits‚Äù, but also cultivate purpose and a culture of self and team professional development. In this post you‚Äôll find the pilot we‚Äôre launching at Swimm: the main goals of such a pilot and why we believe in it, as well as the execution strategy. We will follow-up and share our experiences in future posts.</p>
<h3><strong>The Why: Delivering Code Excellence</strong></h3>
<p><strong>Professionalism</strong>. First, we want to create a culture where all of our team members learn new things, on an ongoing basis. To become professionals, we need to keep learning all the time. To stay happy and challenged at work we need access to resources, and need our managers to invest in our development.</p>
<p><strong>Innovation</strong>. Second, reviewing together new topics and brainstorming on how they can be integrated into our products will provide new ideas and make us constantly rethink our current approaches.</p>
<p>While thinking about a way to achieve these goals, I was looking for best practice, study cases and models that worked well or gloriously failed in other places in the tech industry. Specifically, I was inspired by <a href="https://medium.com/@Idan.Bassuk/a-proven-methodology-for-becoming-an-a-i-expert-32d43887cb1e">this post</a> by Idan Bassuk from <strong>Aidoc</strong>. I contacted Idan and he was very kind to answer all my questions. I learned that they‚Äôve been continuing their ‚ÄúDeep Snips‚Äù (where one of their team members learns a subject and presents it to the team) for the past 3 years, and that he still believes this method helps achieve its goals. I learned from their experience that many of their talks resulted in actual impact to their products. This gave me confidence that this method can indeed have a meaningful impact, and I was now more eager than before to put this to the test.</p>
<h3><strong>The How: Swimminars X 2 Weeks</strong></h3>
<p><strong>Swimminars.</strong> Every other week, one of our engineers will get to learn something new that they wish to dive deeper into and learn. It can be about anything at all, as long as it‚Äôs technological, and can be applied to our product(s), even if not in the foreseeable future. Then, the engineer will give a lecture, sharing their research and new knowledge with the team. After every session, we will also publish a blog post, summarising the lecture for our community or new hires to use if they wish.</p>
<p><strong>Technicalities</strong>. We plan to divide the session into two parts ‚Äî the first will be technical, an in-depth overview of the relevant subject (will be covered on our blog posts). The second part will include holding internal discussions on the possible utilisation, adoption and impacts of the topic on our product(s). Are we already relying on some of this knowledge? Can it help us tackle a current or future issue? Perhaps we need to consider implementing it now?</p>
<p>During the two weeks of the engineer‚Äôs turn, (s)he gets as much time as needed to learn the subject and prepare the lecture. This will be prioritised over other tasks, and we assume it will take between one and two days. This is a huge commitment ‚Äî with all the tasks that we have as a startup, every day is precious. Still, we decided that the impact we are hoping for is so valuable that it‚Äôs worth the price, and that we are willing to make the experiment.</p>
<h3><strong>Piloting: Managing Expectations</strong></h3>
<p><strong>Risks</strong>. Yet, as always, it‚Äôs easier said than done. Indeed this can go wrong in different ways ‚Äî time management vs efficiency, getting to a high level of interesting presentations and useful technological insight, or getting every one‚Äôs voice heard on the team in a manner that compliments them. It‚Äôs a learning on the go activity. So we‚Äôre up for a team challenge.</p>
<p><strong>Upsides</strong>. For the duration of our team pilot, every other week, the entire dev team will get to learn something new while taking turns deepening knowledge, improving writing and presentation skills and becoming experts within the team on their Swimminar topics. This team exercise will provide each engineer individually and the team as whole, positive experiences of success. We hope.</p>
<p>I will be the first to give a Swimminar ‚Äî specifically, on <strong>git internals</strong>. How it goes from there, only time will tell. We promise to report back on how this experiment is working for us. Stay tuned.</p>
<p><em>Swimm is a tool helping engineers contribute to any codebase faster and better with automatically generated hints and codebase insight.</em></p>
<p><em>Omer Rosenbaum, Swimm‚Äôs Chief Technology Officer. Cyber training expert and Founder of Checkpoint Security Academy. Author of <a href="https://data.cyber.org.il/networks/networks.pdf">Computer Networks (in Hebrew)</a>. Visit My <a href="https://www.youtube.com/watch?v=79jlgESHzKQ&amp;list=PL9lx0DXCC4BMS7dB7vsrKI5wzFyVIk2Kg">YouTube Channel</a>.</em></p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057078</guid>
            <pubDate>Wed, 11 Nov 2020 10:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bdshemu: Bitdefender shellcode emulator]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25057062">thread link</a>) | @mdontu
<br/>
November 11, 2020 | https://hvmi.github.io/blog/2020/11/11/bdshemu.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/11/bdshemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Detecting exploits is one of the major strengths of Hypervisor Memory Introspection (HVMI). The ability to monitor guest physical memory pages against different kinds of accesses, such as write or execute, allows HVMI to impose restrictions on critical memory regions: for example, stack or heap pages can be marked as being non-executable at the EPT level, so when an exploit manages to gain arbitrary code execution, the introspection logic would step in and block the execution of the shellcode.</p>

<p>In theory, intercepting execution attempts from memory regions such as the stack or the heap should be enough to prevent most of the exploits. Real life is often more complicated, and there are many cases where legit software uses techniques that may resemble on attack - Just In Time compilation (JIT) in browsers is one good example. In addition, an attacker may store its payload in other memory regions, outside the stack or the heap, so a method of discerning good code from bad code is useful.</p>

<p>We will talk in this blog post about the Bitdefender Shellcode Emulator, or <a href="https://github.com/bitdefender/bddisasm">bdshemu</a> for short. bdshemu is a library capable of emulating basic x86  instructions (in all modes - 16, 32 and 64 bit), while observing shellcode-like behavior. Legitimate code, such as JIT code, will look different compared to a traditional shellcode, so this is what bdshemu is trying to determine: whether the emulated code behaves like a shellcode or not.</p>

<h2 id="bdshemu-overview">bdshemu Overview</h2>

<p>bdshemu is a library written in C, and is part of the bddisasm project (and of course, it makes use of bddisasm for instruction decoding). The bdshemu library is built to emulate x86 code only, so it has no support for API calls. In fact, the emulation environment is highly restricted and stripped down, and there are only two memory regions available:</p>

<ul>
  <li>The page(s) containing the emulated code;</li>
  <li>The stack;</li>
</ul>

<p>Both of these memory regions are virtualized, meaning that they are in fact copies of the actual memory being emulated, so modifications made to them don‚Äôt affect the actual system state. Any access made by the emulated code outside of these two areas (which we will call the shellcode and the stack, respectively) will trigger immediate emulation termination. For example, an API call will automatically cause a branch outside the shellcode region, thus terminating emulation. However, in bdshemu, all we care about is instruction-level behavior of the code, which is enough to tell us whether the code is malicious or not.</p>

<p>While bdshemu provides the main infrastructure for detecting shellcodes inside a guest operating-system, it is worth noting that this is not the only way HVMI determines that execution of a certain page is malicious - two other important indicators are used:</p>

<ul>
  <li>The executed page is located on the stack - this is common with stack-based vulnerabilities;</li>
  <li>The stack is pivoted - when a page is first executed and the <code>RSP</code> register points outside the normal stack allocated for the thread;</li>
</ul>

<p>These two indicators are enough on their own to trigger an exploit detection. If these are not triggered, bdshemu is used to take a good look at the executed code, and decide if it should be blocked or not.</p>

<h2 id="bdshemu-architecture">bdshemu Architecture</h2>

<p>bdshemu is created as a standalone C library, and it only depends on bddisasm. Working with bdshemu is fairly simple, as just like bddisasm, it is a single-API library:</p>
<div><div><pre><code><span>SHEMU_STATUS</span>
<span>ShemuEmulate</span><span>(</span>
    <span>SHEMU_CONTEXT</span> <span>*</span><span>Context</span>
    <span>);</span>
</code></pre></div></div>

<p>The emulator expects a single <code>SHEMU_CONTEXT</code> argument, containing all the needed information in order to emulate the suspicious code. This context is split in two sections - input parameters and output parameters. The input parameters must be supplied by the caller, and they contain information such as the code to be emulated, or initial register values. The output parameters contain information such as what shellcode indicators bdshemu detected. All these fields are well documented in the source-code.</p>

<p>Initially, the context is filled in with the following main information (please note that emulation outcome may change depending on the value of the provided registers and stack):</p>

<ul>
  <li>Input registers, such as segments, general purpose registers, MMX and SSE registers; they can be left 0, if they are not known, or if they are irrelevant;</li>
  <li>Input code, which is the actual code to be emulated;</li>
  <li>Input stack, which can contain actual stack contents, or can be left 0;</li>
  <li>Environment info, such as mode (32 or 64 bit), or ring (0, 1, 2 or 3);</li>
  <li>Control parameters, such as minimum stack-string length, minimum NOP sled length or the maximum number of instructions that should be emulated;</li>
</ul>

<p>The main output parameter is the <code>Flags</code> field, which contains a list of shellcode indicators detected during the emulation. Generally, a non-zero value of this field strongly suggests that the emulate code is, in fact, a shellcode.</p>

<p>bdshemu is built as a plain, quick and simple x86 instruction emulator: since it only works with the shellcode itself and a small virtual stack, it doesn‚Äôt have to emulate any architectural specifics - interrupts or exceptions, descriptor tables, page-tables, etc. In addition, since we only deal with the shellcode and stack memory, bdshemu does not do memory access checks, since it doesn‚Äôt even allow accesses to other addresses. The only state apart from the registers that can be accessed is the shellcode itself and the stack, and both are copies of the actual memory contents - the system state is never modified during the emulation, only the provided <code>SHEMU_CONTEXT</code> is. This makes bdshemu extremely fast, simple, and lets us focus on its main purpose: detecting shellcodes.</p>

<p>As far as instruction support goes, bdshemu supports all the basic x86 instructions, such as branches, arithmetic, logic, shift, bit manipulation, multiplication/divison, stack access and data transfer instructions. In addition, it also has support for other instructions, such as some basic MMX or AVX instructions - <code>PUNPCKLBW</code> or <code>VPBROADCAST</code> are two good examples.</p>

<h2 id="bdshemu-detection-techniques">bdshemu Detection Techniques</h2>

<p>In order to determine whether an emulated piece of code behaves like a shellcode, there are several indicators bdshemu uses.</p>

<h3 id="nop-sled">NOP Sled</h3>

<p>This is the classic presentation of shellcodes; since the exact entry point of the shellcode when gaining code execution may be unknown, attackers usually prepend a long sequence of <code>NOP</code> instructions, encoding <code>0x90</code>. The parameters for the NOP-sled length can be controlled when calling the emulator, via the <code>NopThreshold</code> context field. The default value is <code>SHEMU_DEFAULT_NOP_THRESHOLD</code>, which is <code>75</code>, meaning that minimum 75% of all the emulated instruction must be <code>NOP</code>.</p>

<h3 id="rip-load">RIP Load</h3>

<p>Shellcodes are designed to work correctly no matter what address they‚Äôre loaded at. This means that the shellcode has to determine, dynamically, during runtime, the address it was loaded at, so absolute addressing can be replaced with some form of relative addressing. This is typically achieved by retrieving the value of the instruction pointer using well-known techniques:</p>

<ul>
  <li><code>CALL $+5/POP ebp</code> - executing these two instructions will result in the value of the instruction pointer being stored in the <code>ebp</code> register; data can then be accessed inside the shellcode using offsets relative to the <code>ebp</code> value;</li>
  <li><code>FNOP/FNSTENV [esp-0xc]/POP edi</code> - the first instruction is any FPU instruction (not necessarily <code>FNOP</code>), and the second instruction, <code>FNSTENV</code> saves the FPU environment on the stack; the third instruction will retrieve the <code>FPU Instruction Pointer</code> from <code>esp-0xc</code>, which is part of the FPU environment, and contains the address of the last FPU executed - in our case, <code>FNOP</code>; from there on, addressing relative to the <code>edi</code> can be used to access shellcode data;</li>
</ul>

<p>Internally, bdshemu keeps track of all the instances of the instruction pointer being saved on the stack. Later loading that instruction pointer from the stack in any way will result in triggering this detection. Due to the way bdshemu keeps track of the saved instruction pointers, it doesn‚Äôt matter when, where or how the shellcode attempts to load the RIP in a register and use it, bdshemu will always trigger a detection.</p>

<p>In 64 bit, RIP-relative addressing can be used directly, since the instruction encoding allows it. However, surprisingly, a large number of shellcodes still use a classic method of retrieving the instruction pointer (generally the <code>CALL/POP</code> technique), which is somehow weird, but it probably indicated that 32 bit shellcodes were ported to 64 bit with minimal modifications.</p>

<h3 id="write-self">Write Self</h3>

<p>Most often, shellcodes come in encoded or encrypted forms, in order to avoid certain bad characters (for example, <code>0x00</code> in a shellcode that should resemble a string may break the exploit) or to avoid detection by security technologies (for example, AV scanners). This means that during runtime, the shellcode must decode itself (usually in-place), by modifying its own contents, and then executing the plain-text code. Typical methods of decoding involve <code>XOR</code> or <code>ADD</code> based decryption algorithms.</p>

<p>Certainly, bdshemu follows this kind of behavior, and keeps track internally of each modified byte inside the shellcode. Whenever the suspected shellcode writes any portion of itself, and then it executes it, the self-write detection will be triggered.</p>

<h3 id="tib-access">TIB Access</h3>

<p>Once a shellcode has gained code execution, it needs to locate several functions inside various modules, in order to carry its actual payload (for example, downloading a file, or creating a process). On Windows, the most common way of doing this is by parsing the user-mode loader structures, in order to locate the addresses where the required modules were loaded, and then locate the needed functions inside these modules. The sequence of structures the shellcode will access is:</p>

<ol>
  <li>The Thread Environment Block (<code>TEB</code>), which is located at <code>fs:[0]</code> (32 bit thread) or <code>gs:[0]</code> (64 bit thread);</li>
  <li>The Process Environment Block (<code>PEB</code>), which is located at <code>TEB+0x30</code> (32 bit) or <code>TEB+0x60</code> (64 bit)</li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/11/bdshemu.html">https://hvmi.github.io/blog/2020/11/11/bdshemu.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/11/bdshemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057062</guid>
            <pubDate>Wed, 11 Nov 2020 10:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keyboardio Atreus: Yeah or Meh?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056988">thread link</a>) | @liveweird
<br/>
November 11, 2020 | https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5faba45f5480d10039a1a829">
	

	<section>
		<p>I've bought another mechanical keyboard (technically - I've backed <a href="https://www.kickstarter.com/projects/keyboardio/atreus">the Kickstarter campaign</a>). Feel free to call me an addict - I don't mind. It's my 4th and all three that I already have work well until now, so I have no valid reason to complain about them. Why waste money then (as they were not cheap - we're talking about an expenditure of 130+ USD per keyboard)?</p><p>The truth is, I use more than one computer (on a daily basis). Desktop PC powered by Windows 10, my private development machine (macOS), and the one provided by the company I currently cooperate with (Ubuntu 20). That means constant switching between very different keyboards and layouts. MacBook Pro's keyboard is pure rubbish (even the refined scissor 2020 model), Lenovo Thinkpad's one is a bit better but still very far from typing experience achievable only for mechanical keyboards, my desktop keyboard is fine but freakin' huge.</p><p>That's why I've decided that what I really need is a reliable mechanical keyboard <strong>I could carry with me easily</strong> and plug anywhere I want.</p><p>Sounds easy, but there are objective obstacles. Mechanical keyboards are generally large and heavy. Both Das Keyboards I own are 100% out of the question here. I have an 88 WASD keyboard as well, but even w/o a numerical keypad, it's too big to carry in the backpack.</p><p>Atreus to the rescue.</p><p>The brand "Atreus" is not new. If you're into mechanical keyboards, you've probably heard about <a href="https://atreus.technomancy.us/">Classic Atreus</a> - as it's available since 2014. The concept was very simple - to create a mechanical keyboard that is fully optimized for natural palms position, so you have all the keys within reach w/o making any move. That also means minimizing the number of keycaps by doing some crazy optimizations (more about that later).</p><p>The keyboard I've ordered is a product of cooperation of <strong>Atreus</strong> and <strong>Keyboardio</strong> - a refreshed, minimalistic version of Classic Atreus with few slight improvements aimed to make it even more compact and apply the lessons from previous models (e.g., adjust the keys in the very center area). You can read more about it (incl. specs and design decisions) <a href="https://shop.keyboard.io/products/keyboardio-atreus">here</a>.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus_top.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg 900w" sizes="(min-width: 720px) 720px"></figure><p>I've ordered a blank model (no symbols on the top of keycaps) with <strong>Kailh BOX White switches</strong> and the dedicated case. It's the first model with Kailh switches I've ever tried. The white ones are clicky and have very early tactile feedback. I'm not going to delay that message - the switches turned out to be <u>AWESOME</u>. The typing experience is extremely satisfying (IMHO better than Cherry MX Clear or Gamma Zulu ones). It does require some (reasonable) force, but in exchange, you get the subliminal certainty (the one that doesn't involve conscious thinking) of whether you pressed the button effectively (once) or not.</p><p>OK, good switches are important, but what about the layout? If you've used previous models of Atreus before, you won't be surprised - the changes are subtle but not revolutionary. If you had no prior experience with Atreus, it may be a real shocker.</p><p>First of all, the keyboard has only <strong>44 keycaps</strong> (yay). The space bar is of the size of any other keycap. There are three modes - black, blue, and red (officially named: default, fun, and upper). Default is ... well, default. Fun is active when you <u>hold</u> the 'Fun' button (3rd from the left in the bottom row of the right part of the keyboard) and upper is <u>switched on</u> by (pressing, you don't need to hold them) <strong>Fun</strong> &amp; <strong>Esc</strong> combo.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus.png 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png 680w"></figure><p>Some "standard" keys are entirely missing (e.g., <strong>Caps Lock</strong>), some have very un-intuitive positions (<strong>Escape</strong>, <strong>Tab</strong>, <strong>Backspace</strong>). You can read about the layout on the official page (linked above), so I'm not going to describe all the nuances - I'd like to focus on the impressions instead: how does it work? Is it easy to get used to? Convenient? How does it work for typical development keystrokes/routines?</p><p>It ... depends.</p><p>It didn't take me much time to get used to typing texts (articles, blog posts, e-mails) - the layout is a bit skewed, but still: it's QWERTY. The most mistakes I was making were in the 3rd row (<strong>'b'</strong>, <strong>'c'</strong> and <strong>'m'</strong>). However, getting accustomed to control/function keys is an entirely different kind of story:</p><ul><li><strong>Backspace</strong>/<strong>Space</strong> tandem is very different to what you know but once you try it, it gets very intuitive</li><li><strong>Ctrl</strong> and <strong>Alt</strong> are well within reach, but they force you to change your mechanical habits - that will take time</li><li><strong>Tab</strong>'s positioning is the most surprising - it's probably the least reachable keycap on the board</li><li>Having <strong>Delete</strong> in the red (upper) mode means that you're pretty much restricted to using <strong>Backspace</strong></li><li>All kinds of parenthesis (in the blue mode) require memorization from scratch</li><li>TBH I don't use red mode at all - it's just too much of a hassle (that means no <strong>PageUp</strong>, <strong>PageDown</strong>, <strong>F1 </strong>... <strong>F12 </strong>keys - but TBH I've used them very rarely anyway)</li></ul><hr><p><em>A side-note: I don't use Vim, I've also recently gave up on Spacemacs. Last months for codecrafting I've used mainly SublimeText + TabNine (80%) and Visual Studio Code (20%).</em></p><p>After two weeks of using Atreus, it feels like I'm still <u>terribly slow</u> - quite fluent, can manage without a cheatsheet, but still - just painfully slooow. The new automations (you don't need to think about) are not (yet) there, and the old ones got rusty already (when I try to use Das Keyboard occasionally). Ahh, yeah - I've mentioned the printed cheat sheet - it comes in the box with the keyboard, it's laminated, and it's a hell of help - especially in the first few days. A decent idea - kudos for that.</p><p>To be honest, I think that those few weeks are still too little to make a proper judgment, so let's consider it an early review and revisit in few months time.</p><p>IMHO, Atreus delivers what it promises. </p><p>It's compact and lightweight indeed. The quality (of manufacturing) is flawless - sharp, raw, minimalistic, yet beautiful.</p><p>Overall, it's my 2nd favorite of all mech keyboards I've ever used (runner up only to the <a href="https://www.wasdkeyboards.com/wasd-v3-88-key-iso-custom-mechanical-keyboard.html">Cherry MX Clear 88-key WASD</a>), and that says a lot. Yes, this position has been earned mainly by the outstanding switches and the unquestionable mobility, but it's not that I classify the layout as a con. It does require time to adjust your habits, but it's hard to name even a single, irrevocably bad design decision (in terms of positioning or spacing) - with <strong>Tab</strong> positioning being the most controversial one.</p><p>Btw. if you don't like any particular key position, there's a dedicated piece of software (Chrysalis: <a href="https://github.com/keyboardio/Chrysalis">https://github.com/keyboardio/Chrysalis</a>) you can use to conveniently remap it (in the end: I didn't remap any single key).</p><p>It should be stated very clearly - IMHO, this keyboard is <strong><u>much better suited for typists</u></strong> than e.g., developers (or gamers), but even for a typist, it will take several weeks to get used to it and regain a proper pace of typing. What does it mean 'proper pace'? Is it possible to get as effective as with a standard IBM Model M layout?</p><p>Opinions vary.</p><p>Personally, I don't think so, but please keep in mind that this is not a 105-cap but 44-cap keyboard - some efficiency is intended to be sacrificed for the compactness. Consider carefully the scenarios you'd like to use it for, before, not after buying.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056988</guid>
            <pubDate>Wed, 11 Nov 2020 09:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container Queries are coming to Chromium]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056551">thread link</a>) | @LorenzA
<br/>
November 11, 2020 | https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com | <a href="https://web.archive.org/web/*/https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div id="primary">
<main id="main">
<article id="post-25159">

<div>
<p><img loading="lazy" src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" alt="" width="2024" height="880" srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w" sizes="(max-width: 2024px) 100vw, 2024px" data-old-src="https://www.bram.us/wordpress/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" data-srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w"></p>
<p>Just <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">announced</a> on the Chromium mailing list is an <a href="https://www.chromium.org/blink/launching-features">‚ÄúIntent to Prototype‚Äù</a> Container Queries, which is quite exciting news üéâ</p>
<details>
<summary>ü§î Container Queries?</summary>
<p>Container Queries allow authors to style elements according to the size of a container. This is similar to a @media query, except that it evaluates against a container instead of the viewport.</p>
</details>
<p>The experimental implementation will follow <a href="https://gist.github.com/mirisuzanne/748169312f110d6246e092945673b16e">Miriam Suzanne‚Äôs proposal</a>, which looks like this:</p>
<pre><code>main,
aside {
  contain: size; /* (1) Create an implicit "container root" or "containment context" */
}

.media-object {
  display: grid;
  gap: 1em;
}

@container (max-width: 45em) { /* (2) When the nearest `contain: size` ancestor has a max-width of 45em ‚Ä¶ */
  .media-object { /* ‚Ä¶ apply these rules onto .media-object */
    grid-template: 'img content' auto / auto 1fr;
  }
}</code></pre>
<p>Using <code>contain: size</code> <em>(1)</em> will create an implicit ‚Äúcontainer root‚Äù or ‚Äúcontainment context‚Äù on that element. Elements contained inside it can then have container queries applied onto them, by use of a new at-rule <code>@container (<em>&lt;container-media-query&gt;</em>)</code> <em>(2)</em>. The target selector and CSS rules to apply in that case are nested within the <code>@container</code> at-rule, just like we already do with other at-rules.</p>
<p>In the example above extra rules will be applied to <code>.media-object</code> whenever its nearest ancestor with size containment set ‚Äî such as <code>&lt;main&gt;</code> or <code>&lt;aside&gt;</code> ‚Äî has a <code>max-width</code> of <code>45em</code>.</p>
<p>~</p>
<p>A <a href="https://github.com/dbaron/container-queries-implementability#proposal">previous version of this proposal by L. David Baron</a> required a context selector to be set, but that has been dropped here. The <code>@container</code> rule from Miriam‚Äôs version will work in any containment context <em>(read: the nearest parent element that has <code>contain: size</code> set)</em>. The syntax might still change, but that‚Äôs irrelevant to the prototype which is to be implemented:</p>
<blockquote><p>This is not at all finalized, but the underlying problems we need to solve in Blink are (mostly) the same regardless of how the feature is accessed, so we‚Äôll for now use this proposal as the temporary syntax.</p></blockquote>
<p>~</p>
<p><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">Intent to Prototype: Container Queries ‚Üí</a><br><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1145970">Chrome Tracking Bug ‚Üí</a></p>
<div>
<p><b>Did this help you out? Like what you see?<br>Thank me with a coffee.</b></p><p>I don't do this for profit but a small one-time donation would always put a smile on my face. Thanks!</p>
<p><a href="https://www.paypal.me/bramus/3EUR">‚òïÔ∏è Buy me a Coffee <em>(‚Ç¨3)</em></a></p>
</div>
</div>

<div>

<p>
Bramus is a Freelance Web Developer from Belgium. From the moment he discovered view-source at the age of 14 <em>(way back in 1997)</em>, he fell in love with the web and has been tinkering with it ever since <i><a href="https://www.bram.us/about">(more ‚Ä¶)</a></i> <a href="https://www.bram.us/author/bramus/" rel="author">
View more posts </a>
</p>
</div>
</article>
<nav role="navigation" aria-label="Posts">
<h2>Post navigation</h2>

</nav>

</main>
</div>
</div></div>]]>
            </description>
            <link>https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056551</guid>
            <pubDate>Wed, 11 Nov 2020 08:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to C# basics: Difference between ‚Äú=‚Äù and ‚Äú{ get; } =‚Äù for properties]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056344">thread link</a>) | @cincura_net
<br/>
November 10, 2020 | https://www.tabsoverspaces.com/id/233844 | <a href="https://web.archive.org/web/*/https://www.tabsoverspaces.com/id/233844">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<h3>Back to C# basics: Difference between "=&gt;" and "{ get; } =" for properties <a href="https://www.tabsoverspaces.com/id/233844" rel="bookmark nofollow" title="Permalink"><span aria-label="Permalink"></span></a></h3>
	<p>
	<span aria-label="Published"></span> 11 Nov 2020
	<span></span>
	<span aria-label="Time to read"></span> 1 mins
	<span></span>
	<span aria-label="Tags"></span> .NET
</p>
<p>I recently realized, the difference between <code>=&gt;</code> and <code>{ get; } =</code> for properties might not be as known as everybody thinks, based on code I saw multiple times.</p>
<!-- excerpt --> 
<p>Here‚Äôs an example code.</p>
<pre><code>public class C
{
	public Foo A { get; } = new Foo();
	public Foo B =&gt; new Foo();
}
</code></pre>
<p>Is it the same or is it not? The answer is, it‚Äôs not the same. The <code>A</code> property is property with <em>getter</em> only (aka read only or immutable property). When <code>C</code> instance is created a new instance of <code>Foo</code> is assigned to the property and will be returned from now on. The <code>B</code> property defines also only <em>getter</em>, but this time the <em>getter</em> contains the <code>new Foo();</code> as it‚Äôs body, aka returning new instance of <code>Foo</code> every time you access <code>B</code>.</p>
<p>Putting it into barebone C#, it would look like this.</p>
<pre><code>public class C
{
	readonly Foo _a = new Foo();
	
	public Foo A
	{
		get { return _a; }
	}

	public Foo B
	{
		get { return new Foo(); }
	}
}
</code></pre>
<p>Makes sense?</p>

</article><article>
	<p>
		<a href="https://www.tabsoverspaces.com/about"><img src="https://www.tabsoverspaces.com/assets/bio_image.png" alt="Profile Picture"></a>
		Ji≈ô√≠ ƒåinƒçura is an independent developer focusing on data and business layers, language constructs, parallelism and databases. Specifically Entity Framework, asynchronous and parallel programming, cloud and Azure. He's Microsoft Most Valuable Professional and you can read his articles, guides, tips and tricks at www.tabsoverspaces.com.
	</p>
</article></div>]]>
            </description>
            <link>https://www.tabsoverspaces.com/id/233844</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056344</guid>
            <pubDate>Wed, 11 Nov 2020 07:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cell Signaling Technologies ‚Äì Detailed 3D model of human cells]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25055908">thread link</a>) | @ozten
<br/>
November 10, 2020 | http://www.digizyme.com/cst_landscapes.html | <a href="https://web.archive.org/web/*/http://www.digizyme.com/cst_landscapes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="u6389-bw">
     <div id="u6389"><!-- column -->
      <div id="u6389_align_to_page">
       <!-- m_editable region-id="editable-static-tag-U6264-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p><span id="u6264">Cell Signaling Technologies</span></p>
       <!-- /m_editable -->
       <!-- m_editable region-id="editable-static-tag-U6399-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p>Molecular Landscapes</p>
       <!-- /m_editable -->
       
       
       
      </div>
     </div>
    </div></div>]]>
            </description>
            <link>http://www.digizyme.com/cst_landscapes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055908</guid>
            <pubDate>Wed, 11 Nov 2020 06:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dive into BPF: a list of reading material]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055866">thread link</a>) | @moks
<br/>
November 10, 2020 | https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/ | <a href="https://web.archive.org/web/*/https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<ul id="markdown-toc">
  <li><a href="#what-is-bpf" id="markdown-toc-what-is-bpf">What is BPF?</a></li>
  <li><a href="#dive-into-the-bytecode" id="markdown-toc-dive-into-the-bytecode">Dive into the bytecode</a></li>
  <li><a href="#resources" id="markdown-toc-resources">Resources</a>    <ul>
      <li><a href="#generic-presentations" id="markdown-toc-generic-presentations">Generic presentations</a>        <ul>
          <li><a href="#about-bpf" id="markdown-toc-about-bpf">About BPF</a></li>
          <li><a href="#about-xdp" id="markdown-toc-about-xdp">About XDP</a></li>
          <li><a href="#about-other-components-related-or-based-on-ebpf" id="markdown-toc-about-other-components-related-or-based-on-ebpf">About other components related or based on eBPF</a></li>
        </ul>
      </li>
      <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a>        <ul>
          <li><a href="#about-bpf-1" id="markdown-toc-about-bpf-1">About BPF</a></li>
          <li><a href="#about-tc" id="markdown-toc-about-tc">About tc</a></li>
          <li><a href="#about-xdp-1" id="markdown-toc-about-xdp-1">About XDP</a></li>
          <li><a href="#about-flow-dissectors" id="markdown-toc-about-flow-dissectors">About flow dissectors</a></li>
          <li><a href="#about-p4-and-bpf" id="markdown-toc-about-p4-and-bpf">About P4 and BPF</a></li>
        </ul>
      </li>
      <li><a href="#tutorials" id="markdown-toc-tutorials">Tutorials</a></li>
      <li><a href="#examples" id="markdown-toc-examples">Examples</a>        <ul>
          <li><a href="#from-the-kernel" id="markdown-toc-from-the-kernel">From the kernel</a></li>
          <li><a href="#from-package-iproute2" id="markdown-toc-from-package-iproute2">From package iproute2</a></li>
          <li><a href="#from-bcc-set-of-tools" id="markdown-toc-from-bcc-set-of-tools">From bcc set of tools</a></li>
          <li><a href="#other-examples" id="markdown-toc-other-examples">Other examples</a></li>
          <li><a href="#manual-pages" id="markdown-toc-manual-pages">Manual pages</a></li>
        </ul>
      </li>
      <li><a href="#the-code" id="markdown-toc-the-code">The code</a>        <ul>
          <li><a href="#bpf-code-in-the-kernel" id="markdown-toc-bpf-code-in-the-kernel">BPF code in the kernel</a></li>
          <li><a href="#xdp-hooks-code" id="markdown-toc-xdp-hooks-code">XDP hooks code</a></li>
          <li><a href="#bpf-logic-in-bcc" id="markdown-toc-bpf-logic-in-bcc">BPF logic in bcc</a></li>
          <li><a href="#code-to-manage-bpf-with-tc" id="markdown-toc-code-to-manage-bpf-with-tc">Code to manage BPF with tc</a></li>
          <li><a href="#bpf-utilities" id="markdown-toc-bpf-utilities">BPF utilities</a></li>
          <li><a href="#other-interesting-chunks" id="markdown-toc-other-interesting-chunks">Other interesting chunks</a></li>
          <li><a href="#llvm-backend" id="markdown-toc-llvm-backend">LLVM backend</a></li>
          <li><a href="#running-in-userspace" id="markdown-toc-running-in-userspace">Running in userspace</a></li>
          <li><a href="#commit-logs" id="markdown-toc-commit-logs">Commit logs</a></li>
        </ul>
      </li>
      <li><a href="#troubleshooting" id="markdown-toc-troubleshooting">Troubleshooting</a>        <ul>
          <li><a href="#errors-at-compilation-time" id="markdown-toc-errors-at-compilation-time">Errors at compilation time</a></li>
          <li><a href="#errors-at-load-and-run-time" id="markdown-toc-errors-at-load-and-run-time">Errors at load and run time</a></li>
        </ul>
      </li>
      <li><a href="#and-still-more" id="markdown-toc-and-still-more">And still more!</a></li>
    </ul>
  </li>
</ul>

<p><em>~ <a href="https://github.com/qmonnet/whirl-offload/commits/gh-pages/_posts/2016-09-01-dive-into-bpf.md">Updated</a> 2019-01-10 ~</em></p>



<p>BPF, as in <strong>B</strong>erkeley <strong>P</strong>acket <strong>F</strong>ilter, was initially conceived in 1992
so as to provide a way to filter packets and to avoid useless packet copies
from kernel to userspace. It initially consisted in a simple bytecode that is
injected from userspace into the kernel, where it is checked by a verifier‚Äîto
prevent kernel crashes or security issues‚Äîand attached to a socket, then run on
each received packet. It was ported to Linux a couple of years later, and used
for a small number of applications (tcpdump for example). The simplicity of the
language as well as the existence of an in-kernel Just-In-Time (JIT) compiling
machine for BPF were factors for the excellent performances of this tool.</p>

<p>Then in 2013, Alexei Starovoitov completely reshaped it, started to add new
functionalities and to improve the performances of BPF. This new version is
designated as eBPF (for ‚Äúextended BPF‚Äù), while the former becomes cBPF
(‚Äúclassic‚Äù BPF). New features such as maps and tail calls appeared. The JIT
machines were rewritten. The new language is even closer to native machine
language than cBPF was. And also, new attach points in the kernel have been
created.</p>

<p>Thanks to those new hooks, eBPF programs can be designed for a variety of use
cases, that divide into two fields of applications. One of them is the domain
of kernel tracing and event monitoring. BPF programs can be attached to kprobes
and they compare with other tracing methods, with many advantages (and
sometimes some drawbacks).</p>

<p>The other application domain remains network programming. In addition to socket
filter, eBPF programs can be attached to tc (Linux traffic control tool)
ingress or egress interfaces and perform a variety of packet processing tasks,
in an efficient way. This opens new perspectives in the domain.</p>

<p>And eBPF performances are further leveraged through the technologies developed
for the IO Visor project: new hooks have also been added for XDP (‚ÄúeXpress Data
Path‚Äù), a new fast path recently added to the kernel. XDP works in conjunction
with the Linux stack, and relies on BPF to perform very fast packet processing.</p>

<p>Even some projects such as P4, Open vSwitch,
<a href="http://openvswitch.org/pipermail/ovs-dev/2014-October/047421.html">consider</a>
or started to approach BPF. Some others, such as CETH, Cilium, are entirely
based on it. BPF is buzzing, so we can expect a lot of tools and projects to
orbit around it soon‚Ä¶</p>



<p>As for me: some of my work (including for
<a href="https://qmonnet.github.io/whirl-offload/2016/07/15/beba-research-project/">BEBA</a>)
is closely related to eBPF, and several future articles on this site will focus
on this topic. Logically, I wanted to somehow introduce BPF on this blog before
going down to the details‚ÄîI mean, a real introduction, more developed on BPF
functionalities that the brief abstract provided in first section: What are BPF
maps? Tail calls? What do the internals look like? And so on. But there are a
lot of presentations on this topic available on the web already, and I do not
wish to create ‚Äúyet another BPF introduction‚Äù that would come as a duplicate of
existing documents.</p>

<p>So instead, here is what we will do. After all, I spent some time reading and
learning about BPF, and while doing so, I gathered a fair amount of material
about BPF: introductions, documentation, but also tutorials or examples. There
is a lot to read, but in order to read it, one has to <em>find</em> it first.
Therefore, as an attempt to help people who wish to learn and use BPF, the
present article introduces a list of resources. These are various kinds of
readings, that hopefully will help you dive into the mechanics of this kernel
bytecode.</p>



<figure>
  <img src="https://qmonnet.github.io/whirl-offload/img/icons/pic.svg">
</figure>

<h2 id="generic-presentations">Generic presentations</h2>

<p>The documents linked below provide a generic overview of BPF, or of some
closely related topics. If you are very new to BPF, you can try picking a
couple of presentation among the first ones and reading the ones you like most.
If you know eBPF already, you probably want to target specific topics instead,
lower down in the list.</p>

<h3 id="about-bpf">About BPF</h3>

<p>Generic presentations about eBPF:</p>

<ul>
  <li>
    <p><a href="https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/"><em>A brief introduction to XDP and eBPF</em></a>
(Diego Pino Garc√≠a, January 2019): <br>
An excellent and accessible introduction providing context, history, and
details about the functioning of eBPF.</p>
  </li>
  <li>
    <p><a href="https://www.redhat.com/en/blog/introduction-ebpf-red-hat-enterprise-linux-7"><em>Introduction to eBPF in Red Hat Enterprise Linux 7</em></a>
(Stanislav Kozina, January 2019): <br>
Focusing on the eBPF features arriving in Red Hat.</p>
  </li>
  <li>
    <p><a href="http://fulvio.frisso.net/files/18HPSR%20-%20eBPF.pdf"><em>Toward Flexible and Efficient In-Kernel Network Function Chaining with IO Visor</em></a>
(Fulvio Risso, HPSR 2018, Bucharest, June 2018): <br>
A generic introduction to BPF, XDP, IO Visor, bcc and other components.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/740157/"><em>A thorough introduction to eBPF</em></a>
(Matt Flemming, on LWN.net, December 2017): <br>
A well-written and accessible introduction providing an overview of eBPF
subsystem components.</p>
  </li>
  <li>
    <p><a href="http://schd.ws/hosted_files/ossna2017/da/BPFandXDP.pdf"><em>Making the Kernel‚Äôs Networking Data Path Programmable with BPF and XDP</em></a>
(Daniel Borkmann, OSSNA17, Los Angeles, September 2017):<br>
One of the best set of slides available to understand quickly all the basics about eBPF and XDP (mostly for network processing).</p>
  </li>
  <li>
    <p><a href="https://speakerdeck.com/tuxology/the-bsd-packet-filter">The BSD Packet Filter</a>
(Suchakra Sharma, June 2017): <br>
A very nice introduction, mostly about the tracing aspects.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/bpf-tracing-and-more"><em>BPF: tracing and more</em></a>
(Brendan Gregg, January 2017):<br>
Mostly about the tracing use cases.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/linux-bpf-superpowers"><em>Linux BPF Superpowers</em></a>
(Brendan Gregg, March 2016):<br>
With a first part on the use of <strong>flame graphs</strong>.</p>
  </li>
  <li>
    <p><a href="https://www.socallinuxexpo.org/sites/default/files/presentations/Room%20211%20-%20IOVisor%20-%20SCaLE%2014x.pdf"><em>IO Visor</em></a>
(Brenden Blanco, SCaLE 14x, January 2016):<br>
Also introduces <strong>IO Visor project</strong>.</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/ebpf_on_the_mainframe_lcon_2015.pdf"><em>eBPF on the Mainframe</em></a>
(Michael Holzheu, LinuxCon, Dublin, October 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/tracing-linux-ezannoni-linuxcon-ja-2015_0.pdf"><em>New (and Exciting!) Developments in Linux Tracing</em></a>
(Elena Zannoni, LinuxCon, Japan, 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/bpf_collabsummit_2015feb20.pdf"><em>BPF ‚Äî in-kernel virtual machine</em></a>
(Alexei Starovoitov, February 2015):<br>
Presentation by the author of eBPF.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/603983/"><em>Extending extended BPF</em></a>
(Jonathan Corbet, July 2014)</p>
  </li>
</ul>

<p><strong>BPF internals</strong>:</p>

<ul>
  <li>Daniel Borkmann has been doing an amazing work to present <strong>the internals</strong> of eBPF, in particular about <strong>its use with tc</strong>, through several talks and papers.
    <ul>
      <li><a href="http://netdevconf.org/1.2/session.html?daniel-borkmann"><em>Advanced programmability and recent updates with tc‚Äôs cls_bpf</em></a>
(netdev 1.2, Tokyo, October 2016):<br>
Daniel provides details on eBPF, its use for tunneling and encapsulation,
direct packet access, and other features.</li>
      <li><a href="http://netdevconf.org/1.2/slides/oct5/07_tcws_daniel_borkmann_2016_tcws.pdf"><em>cls_bpf/eBPF updates since netdev 1.1</em></a>
(netdev 1.2, Tokyo, October 2016, part of
<a href="http://netdevconf.org/1.2/session.html?jamal-tc-workshop">this tc workshop</a>)</li>
      <li><a href="http://www.netdevconf.org/1.1/proceedings/slides/borkmann-tc-classifier-cls-bpf.pdf"><em>On getting tc classifier fully programmable with cls_bpf</em></a>
(netdev 1.1, Sevilla, February 2016):<br>
After introducing eBPF, this presentation provides insights on many
internal BPF mechanisms (map management, tail calls, verifier). A
must-read! For the most ambitious,
<a href="http://www.netdevconf.org/1.1/proceedings/papers/On-getting-tc-classifier-fully-programmable-with-cls-bpf.pdf">the full paper is available here</a>.</li>
      <li><a href="https://archive.fosdem.org/2016/schedule/event/ebpf/attachments/slides/1159/export/events/attachments/ebpf/slides/1159/ebpf.pdf"><em>Linux tc and eBPF</em></a>
(fosdem16, Brussels, Belgium, January 2016)</li>
      <li><a href="https://fosdem.org/2017/schedule/event/ebpf_xdp/"><em>eBPF and XDP walkthrough and recent updates</em></a>
(fosdem17, Brussels, Belgium, February 2017)</li>
    </ul>

    <p>These presentations are probably one of the best sources of documentation to
understand the design and implementation of internal mechanisms of eBPF.</p>
  </li>
</ul>

<p>The <a href="https://www.iovisor.org/resources/blog"><strong>IO Visor blog</strong></a> has some
interesting technical articles about BPF. Some of them contain a bit of
marketing talks.</p>

<p>As of early 2019, there are more and more presentations being done around
multiple aspects of BPF. One nice example is
<a href="http://vger.kernel.org/lpc-bpf.html">the BPF track</a> that was held in parallel
to the Linux Plumbers Conference in late 2018 (and should be held again on
coming years), where lots of topics related to eBPF development or use cases
were presented.</p>

<p><strong>Kernel tracing</strong>: summing up all existing methods, including BPF:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/vh21/meet-cutebetweenebpfandtracing"><em>Meet-cute between eBPF and Kerne Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Kprobes, uprobes, ftrace</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/vh21/linux-kernel-tracing"><em>Linux Kernel Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Systemtap, Kernelshark, trace-cmd, LTTng, perf-tool, ftrace, hist-trigger,
perf, function tracer, tracepoint, kprobe/uprobe‚Ä¶</p>
  </li>
</ul>

<p>Regarding <strong>event tracing and monitoring</strong>, Brendan Gregg uses eBPF a lot and
does an excellent job at documenting some of his use cases. If you are in
kernel tracing, you should see his blog articles related to eBPF or to flame
graphs. Most of it are accessible
<a href="http://www.brendangregg.com/blog/2016-03-05/linux-bpf-superpowers.html">from this article</a>
or by browsing his blog.</p>

<p>Introducing BPF, but also presenting <strong>generic concepts of Linux networking</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linux-networking-explained"><em>Linux Networking Explained</em></a>
(Thomas Graf, LinuxCon, Toronto, August 2016)</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linuxcon-2015-linux-kernel-networking-walkthrough"><em>Kernel Networking Walkthrough</em></a>
(Thomas Graf, LinuxCon, Seattle, August 2015)</p>
  </li>
</ul>

<p><strong>Hardware offload</strong>:</p>

<ul>
  <li>eBPF with tc or XDP supports hardware offload, starting with Linux kernel
version 4.9 and introduced by Netronome. Here is a presentation about this
feature:<br>
<a href="http://netdevconf.org/1.2/session.html?jakub-kicinski">eBPF/XDP hardware offload to SmartNICs</a>
(Jakub Kicinski and Nic Viljoen, netdev 1.2, Tokyo, October 2016)</li>
  <li>An updated version was presented on year later:<br>
<a href="https://www.netdevconf.org/2.2/session.html?viljoen-xdpoffload-talk">Comprehensive XDP offload‚ÄîHandling the edge cases</a>
(Jakub Kicinski and Nic Viljoen, netdev 2.2, Seoul, November 2017)</li>
  <li>I presented a shorter but updated version at FOSDEM 2018:<br>
<a href="https://fosdem.org/2018/schedule/event/xdp/">The Challenges of XDP Hardware Offload</a>
(Quentin Monnet, FOSDEM‚Äô18, Brussels, February 2018)</li>
</ul>

<p>About <strong>cBPF</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.tcpdump.org/papers/bpf-usenix93.pdf"><em>The BSD Packet Filter: A New Architecture for User-level Packet Capture</em></a>
(Steven McCanne and Van Jacobson, 1992):<br>
The original paper about (classic) BPF.</p>
  </li>
  <li>
    <p><a href="http://www.gsp.com/cgi-bin/man.cgi?topic=bpf">The FreeBSD manual page about BPF</a>
is a useful resource to understand cBPF programs.</p>
  </li>
  <li>
    <p>Daniel Borkmann realized at least two presentations on cBPF,
<a href="http://borkmann.ch/talks/2013_devconf.pdf">one in 2013 on mmap, BPF and Netsniff-NG</a>, and
<a href="http://borkmann.ch/talks/2014_devconf.pdf">a very complete one in 2014 on tc and cls_bpf</a>.</p>
  </li>
  <li>
    <p>On Cloudflare‚Äôs blog, Marek Majkowski presented his
<a href="https://blog.cloudflare.com/introducing-the-bpf-tools/">use of BPF bytecode with the <code>xt_bpf</code> module for <strong>iptables</strong></a>.
It is worth mentioning that eBPF is also supported by this module, starting
with Linux kernel 4.10 (I do not know of ‚Ä¶</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</a></em></p>]]>
            </description>
            <link>https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055866</guid>
            <pubDate>Wed, 11 Nov 2020 05:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal epistemology, free speech, and tech companies]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055742">thread link</a>) | @jseliger
<br/>
November 10, 2020 | https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies | <a href="https://web.archive.org/web/*/https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
						<p>The NYT describes ‚Äú<a href="https://www.nytimes.com/2020/10/13/magazine/free-speech.html">The Problem of Free Speech in an Age of Disinformation</a>, and in response Hacker News commenter <a href="https://news.ycombinator.com/item?id=24813749">throwaway13337</a> says, in part, ‚ÄúIt‚Äôs not unchecked free speech. Instead, it‚Äôs unchecked curation by media and social media companies with the goal of engagement.‚Äù There‚Äôs some truth to the idea that social media companies have evolved to seek engagement, rather than truth, but I think the social media companies are reflecting a deeper human tendency. I wrote back to throwaway13337: ‚ÄúTry teaching non-elite undergrads, and particularly assignments that require some sense of epistemology, and you‚Äôll discover that the vast majority of people have pretty poor personal epistemic hygiene‚Äîit‚Äôs not much required in most people, most of the time, in most jobs.‚Äù</p>
<p>From what I can tell, we evolved to form tribes, not to be ‚Äúright:‚Äù Jonathan‚Äôs Haidt‚Äôs <a href="https://jakeseliger.com/2012/03/25/jonathan-haidts-the-righteous-mind-and-what-were-really-arguing-about/"><em>The Righteous Mind: Why Good People Are Divided by Politics and Religion</em></a> deals with this topic well and at length, and I‚Äôve not seen any substantial rebuttals of it. We don‚Äôt naturally take to tracking the question, ‚ÄúHow do I know what I know?‚Äù Instead, we naturally seem to want to find ‚Äúfacts‚Äù or ideas that support our preexisting views. In the HN comment thread, someone asked for specific examples of poor undergrad epistemic hygiene, and while I‚Äôd prefer not to get super specific for reasons of privacy, I‚Äôve had many conversations that take the following form: ‚ÄúHow do you know article x is accurate?‚Äù ‚ÄúGoogle told me.‚Äù ‚ÄúHow does Google work?‚Äù ‚ÄúI don‚Äôt know.‚Äù ‚ÄúWhat does it take to make a claim on the Internet.‚Äù ‚ÄúUm. A phone, I guess?‚Äù A lot of people‚Äîmaybe most‚Äîwill uncritically take as fact whatever happens to be served up by Google (it‚Äôs always Google and never Duck Duck Go or Bing), and most undergrads whose work I‚Äôve read will, again uncritically, accept clickbait sites and similar as accurate. Part of the reason for this reasoning is that undergrads‚Äôs lives are minimally affected by being wrong or incomplete about some claim done in a short assignment that‚Äôs being imposed by some annoying professor toff standing between them and their degree.</p>
<p>The gap between elite information discourse and everyday information discourse, even among college students, who may be more sophisticated than their peer equivalents, is vast‚Äîso vast that I don‚Äôt think most journalists (who mostly talk to other journalists and to experts) and to other people who work with information, data, and ideas really truly understand it. We‚Äôre all living in bubbles. I don‚Äôt think I did, either, before I saw the epistemic hygiene most undergrads practice, or don‚Äôt practice. This is not a ‚Äúkids these days‚Äù rant, either: many of them have never really been taught to ask themselves, ‚ÄúHow do I know what I know?‚Äù Many have never really learned anything about the scientific method. It‚Äôs not happening much in most non-elite schools, so where are they going to get epistemic hygiene from?</p>
<p>The United States alone has 320 million people in it. Table DP02 in the Census at data.census.gov estimates that 20.3% of the population age 25 and older has a college bachelor‚Äôs degree, and 12.8% have a graduate or professional degree. Before someone objects, let me admit that a college degree is far from a perfect proxy for epistemic hygiene or general knowledge, and some high school dropouts perform much better at cognition, meta cognition, statistical reasoning, and so forth, than do some people with graduate degrees. With that said, though, a college degree is probably a decent approximation for baseline abstract reasoning skills and epistemic hygiene.</p>
<p>Almost anyone who wants a megaphone in the form of one of the many social media platforms available now has one. The number of people motivated by questions like ‚ÄúWhat is really true, and how do I discern what is really true? How do I enable myself to get countervailing data and information into my view, or worldview, or worldviews?‚Äù is not zero, again obviously, but it‚Äôs not a huge part of the population. And many very ‚Äúsmart‚Äù people in an IQ sense use their intelligence to build better rationalizations, rather than to seek truth (and I may be among the rationalizers: I‚Äôm not trying to exclude myself from that category).</p>
<p>Until relatively recently, almost everyone with a media megaphone had some kind of training or interest in epistemology, even they didn‚Äôt call it ‚Äúepistemology.‚Äù Editors would ask, ‚ÄúHow do you know that?‚Äù or ‚ÄúWho told you that?‚Äù or that sort of thing. Professors have systems that are supposed to encourage greater-than-average epistemic hygiene (again: these systems were not and are not perfect, and nothing I have written so far implies that they were or are).</p>
<p>Most people don‚Äôt care about the question, ‚ÄúHow do you know what you know?‚Äù and they‚Äôll be fairly surprised if it‚Äôs asked, implicitly or explicitly. Some people are intrigued by it but most aren‚Äôt, and view questions about sources and knowledge to be a hindrance. This is less likely to be true of people who aspire to be researchers or work in other knowledge-related professions, but that describes only a small percentage of undergraduates, particularly at non-elite schools. And the ‚Äúelite schools‚Äù thing drives a lot of the media discourse around education. One of the things I like about Professor X‚Äôs book <a href="https://jakeseliger.com/2011/06/10/summary-judgement-in-the-basement-of-the-ivory-tower-confessions-of-an-accidental-academic-professor-x/"><em>In the Basement of the Ivory Tower</em></a> is how it functions as a corrective to that discourse.</p>
<p>For most people, floating a factually incorrect conspiracy theory online isn‚Äôt going to negatively affect their lives. If someone is a nurse and gives a patient a wrong medication or incorrect medication, that person is not going to be a nurse for long. If the nurse states or repeats a factually incorrect political or social idea online, particularly but not exclusively under a pseudonym, that nurse‚Äôs life likely won‚Äôt be affected. There‚Äôs no truth feedback loop. The same is true for someone working in, say, construction, or engineering, or many other fields. The person is free to state things that are factually incorrect, or incomplete, or misleading, and doing so isn‚Äôt going to have many negative consequences. Maybe it will have some positive consequences: one way to show that you‚Äôre really on team x is to state or repeat falsehoods that show you‚Äôre on team x, rather than on team ‚ÄúWhat is really true?‚Äù</p>
<p>I don‚Äôt want to get into daily political discourse, since that tends to raise defenses and elicit anger, but the last eight months have demonstrated many people‚Äôs problems with epistemology, and in a way that can have immediate, negative personal consequences‚Äîbut not for everyone.</p>
<p><a href="https://www.pewresearch.org/fact-tank/2019/09/26/who-doesnt-read-books-in-america/">Pew Research data indicate that a quarter of US adults didn‚Äôt read a book in 2018</a>; this is consistent with <a href="https://www.newyorker.com/magazine/2007/12/24/twilight-of-the-books">other data</a> indicating that about half of US adults read zero or one books per year. Again, yes, there are surely many individuals who read other materials and have excellent epistemic hygiene, but this is a reasonable mass proxy, given the demands that reading makes on us.</p>
<p>Many people driving the (relatively) elite discourse don‚Äôt realize how many people are not only not like them, but wildly not like them, along numerous metrics. It may also be that <a href="http://www.arnoldkling.com/blog/gossip-at-scale/">we don‚Äôt know how to deal with gossip at scale</a>. Interpersonal gossip is all about personal stories, while many problems at scale are best understood through data‚Äîbut the number of people deeply interested in data and data‚Äôs veracity is small. And elite discourse has some of its own possible epistemic falsehoods, or at least uncertainties, embedded within it: some of the populist rhetoric against elites is rooted in truth.</p>
<p>We are all caught in our bubble, and the universe of people is almost unimaginably larger than the number of people in our bubble. If you got this far, you‚Äôre probably in a nerd bubble: usually, anything involving the word ‚Äúepistemology‚Äù sends people to sleep or, alternately, scurrying for something like ‚ÄúYou won‚Äôt believe what this celebrity wore/said/did‚Äù instead. Almost no one wants to consider epistemology; to do so as a hobby is rare. One person‚Äôs disinformation is another person‚Äôs teambuilding. If you think the preceding sentence is in favor of disinformation, by the way, it‚Äôs not.</p>
					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055742</guid>
            <pubDate>Wed, 11 Nov 2020 05:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business ideas (from my first million podcast)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055308">thread link</a>) | @micropoet
<br/>
November 10, 2020 | https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553 | <a href="https://web.archive.org/web/*/https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055308</guid>
            <pubDate>Wed, 11 Nov 2020 03:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning a New Language While Browsing the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055257">thread link</a>) | @rahulchowdhury
<br/>
November 10, 2020 | https://hulry.com/toucan-learn-language/ | <a href="https://web.archive.org/web/*/https://hulry.com/toucan-learn-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
<p>Around 2015, I picked up a hobby of learning a new language ‚Äî Spanish.</p>



<p>However, after a few months of dedicated learning time, I couldn‚Äôt get myself to stick to the hobby.</p>



<p>I had other things to work on, and learning a language was not my priority.</p>



<p>But things have changed now.</p>



<p>In this post, I‚Äôll talk about how I‚Äôm learning a bit of Spanish every single day using a new language learning tool called <a href="https://jointoucan.com/" target="_blank" rel="noreferrer noopener">Toucan</a>.</p>



<p>Let‚Äôs get started with:</p>



<h2>My experience with various language-learning apps</h2>



<p>I started my Spanish learning journey with the most popular language-learning app ‚Äî <a href="https://www.duolingo.com/" target="_blank" rel="noreferrer noopener nofollow">Duolingo</a>.</p>



<p>While it was fun initially, I soon found myself missing practice days.</p>



<p>As time passed by, the gap widened. And soon enough, I stopped my Spanish sessions.</p>



<p>In the last few years, I‚Äôve tried to rekindle the Spanish spark in me and continue learning with Duolingo. Still, I never succeeded in sticking to the classes.</p>



<p>Then came <a href="https://www.babbel.com/" target="_blank" rel="noreferrer noopener nofollow">Babbel</a>.</p>



<p>While I must say that Babbel has a better course in terms of learning proper grammar and dialects, it had the same problem as Duolingo:</p>



<p>It was hard for me to dedicate time from my schedule for learning sessions.</p>



<p>My only motivation for learning Spanish was to expand my skill set.</p>



<p>Since I‚Äôm not moving to a Spanish speaking country anytime soon, I didn‚Äôt feel the need to prioritise this hobby.</p>



<p>But then:</p>



<p>A few months ago, I spotted a new <a href="https://chrome.google.com/webstore/detail/toucan/lokjgaehpcnlmkebpmjiofccpklbmoci" target="_blank" rel="noreferrer noopener nofollow">Chrome extension called Toucan</a>. Around the same time, a similar extension launched called <a href="https://www.usefluent.co/" target="_blank" rel="noreferrer noopener">Fluent</a>.</p>



<p>The key selling point of these new extensions was to learn a new language while browsing the web.</p>



<p>You don‚Äôt need to dedicate time for picking up a new language. Club the learning sessions, along with activities we do every day ‚Äî browsing the web and reading articles online.</p>



<p>After a quick test ride, here‚Äôs:</p>



<h2>Why I find language learning extensions interesting</h2>



<p>The first and most immense value ‚Äî habit bundling.</p>



<p>I had previously talked about how I <a href="https://hulry.com/building-podcasts-habit/" target="_blank" rel="noreferrer noopener">clubbed my habit</a> of making tea every morning with listening to podcasts.</p>



<p>I saw a similar opportunity with these browser extensions.</p>



<p>The biggest hurdle for me in learning Spanish was making time for classes.</p>



<p>Now:</p>



<p>I don‚Äôt need to dedicate time out of my daily routine to learn a new language.</p>



<p>I browse and read lots of articles online. With Toucan or Fluent, I can learn and practice Spanish every time I read stuff online.</p>



<p>Here‚Äôs:</p>



<h2>How Toucan and Fluent work</h2>



<p>Install Toucan or Fluent, and browse the web as you‚Äôd typically do.</p>



<p>These extensions will translate and highlight some words from the page content into the language you‚Äôve chosen.</p>



<p>Hovering over the highlighted word will bring up a popup card like this:</p>



<div><figure><img data-attachment-id="943" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-demo/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1646%2C742&amp;ssl=1" data-orig-size="1646,742" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-demo" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1024%2C462&amp;ssl=1" loading="lazy" width="1024" height="462" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1" alt="Toucan translating and showing up a word on Instapaper." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating and showing up a word on Instapaper.</figcaption></figure></div>



<p>Pretty neat. Right?</p>



<p>Apart from the convenience, another thing I like is that the translations are beautifully blended into the content.</p>



<p>For example, from the above screenshot, you can see Toucan seamlessly translated and blended the English word ‚Äúevent‚Äù into its Spanish counterpart ‚Äî evento.</p>



<p>While reading an article, I can see a mixture of English and the language I want to learn.</p>



<p>To know more about the translated word, I can hover on it and Toucan will show me the word in English, with its definition.</p>



<p>I‚Äôve tried both Toucan and Fluent on multiple websites, and they seem to blend in translations flawlessly with the page‚Äôs design.</p>



<p>Here‚Äôs an article on Forbes with Toucan translations:</p>



<div><figure><img data-attachment-id="947" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-forbes/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1474%2C814&amp;ssl=1" data-orig-size="1474,814" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-forbes" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=300%2C166&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1024%2C565&amp;ssl=1" loading="lazy" width="1024" height="565" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1" alt="Toucan translating words from an article on Forbes." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating words from an article on Forbes.</figcaption></figure></div>



<p>Now:</p>



<p>Fluent, however, has a more targeted highlighting than Toucan. </p>



<p>If you‚Äôre using Fluent, it‚Äôll highlight words with different colour based on gender.</p>



<div><figure><img data-attachment-id="983" data-permalink="https://hulry.com/toucan-learn-language/fluent-colour-highlights/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1596%2C508&amp;ssl=1" data-orig-size="1596,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-colour-highlights" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=300%2C95&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1024%2C326&amp;ssl=1" loading="lazy" width="1024" height="326" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1" alt="Fluent highlighting words with a different colour." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fluent highlighting words with a different colour.</figcaption></figure></div>



<p>In the paragraph shown above, Fluent highlighted the word ‚Äúderrame‚Äù with a yellow tint (because it‚Äôs masculine), and ‚Äúincluso‚Äù with a neutral grey-ish colour (because it‚Äôs gender-neutral).</p>



<p>That said, here are:</p>



<h2>Some features in Toucan that caught my attention</h2>



<p>Trying out both extensions, I chose to stick with Toucan, mainly due to a couple of subtle features.</p>



<p>The first being:</p>



<h3>Word definitions</h3>



<p>Toucan shows up the definition of a translated word on the hovercard that shows up.</p>



<div><figure><img data-attachment-id="952" data-permalink="https://hulry.com/toucan-learn-language/toucan-word-definition/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1524%2C632&amp;ssl=1" data-orig-size="1524,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-word-definition" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=300%2C124&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1024%2C425&amp;ssl=1" loading="lazy" width="1024" height="425" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1" alt="Toucan showing a word's definition." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan showing a word‚Äôs definition.</figcaption></figure></div>



<p>As a non-native English speaker, this feature is helpful to me. </p>



<p>If I don‚Äôt know the meaning of the translated word, I can read the definition on the card.</p>



<p>There‚Äôs one caveat though:</p>



<p>Right now, not all words show up a definition. However, the number of words without a description is low.</p>



<p>Also, the team at Toucan promised they are continuously working on adding more words and definitions to the tool.</p>



<p>Therefore, this caveat should no longer exist pretty soon.</p>



<p>Another feature I found helpful is:</p>



<h3>The ability to mark a word as learnt</h3>



<p>The Toucan hovercard has a little checkmark which lets me mark a word as learnt, like this:</p>



<div><figure><img data-attachment-id="958" data-permalink="https://hulry.com/toucan-learn-language/touch-mark-word-done/" data-orig-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="touch-mark-word-done" data-image-description="" data-medium-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?resize=840%2C526&amp;ssl=1" alt="Marking a word as known in Toucan." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Marking a word as known in Toucan.</figcaption></figure></div>



<p>What this does is it prevents the word from getting translated in future articles or content.</p>



<p>Since I had taken a couple of Spanish lessons in the past, I marked a handful of words as ‚ÄúI know this‚Äù and Toucan will leave those words in the source language ‚Äî English, for me.</p>



<p>Also:</p>



<p>The Toucan team is working on some recommendation magic for this feature.</p>



<p>For example:</p>



<p>Marking the word ‚Äúcoffee‚Äù as learnt will set Toucan to translate tricky words like ‚Äúhot coffee‚Äù or ‚Äúnice coffee‚Äù in your future reads.</p>



<p>This is how I‚Äôll be able to calibrate Toucan to show up more complicated words as I progress in my Spanish learning journey. </p>



<p>Now:</p>



<p>Everyone learns at a different pace.</p>



<p>To make it easy to progress comfortably, Toucan allows me to:</p>



<h3>Select language packs for translation</h3>



<p>Instead of being bombarded with a giant index of Spanish words, Toucan allows me to <a href="https://jointoucan.com/dashboard" target="_blank" rel="noreferrer noopener nofollow">select language packs</a> on the dashboard:</p>



<div><figure><img data-attachment-id="962" data-permalink="https://hulry.com/toucan-learn-language/toucan-language-packs/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1860%2C1182&amp;ssl=1" data-orig-size="1860,1182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-language-packs" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=300%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1024%2C651&amp;ssl=1" loading="lazy" width="1024" height="651" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1" alt="Selecting language packs in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Selecting language packs in Toucan.</figcaption></figure></div>



<p>Each language pack has a set of words that Toucan will search for in an article or web page content and translate.</p>



<p>For example, choosing the language pack ‚ÄúGet Around the City‚Äù will set Toucan to translate the following English words in the collection to their Spanish counterparts:</p>



<div><figure><img data-attachment-id="964" data-permalink="https://hulry.com/toucan-learn-language/toucan-get-around-city-pack/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1420%2C834&amp;ssl=1" data-orig-size="1420,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-get-around-city-pack" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1" alt="Toucan's &quot;Get Around the City&quot; language pack." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan‚Äôs ‚ÄúGet Around the City‚Äù language pack.</figcaption></figure></div>



<p>This feature is beneficial for beginners because we can choose a handful of language packs and start learning.</p>



<p>Once we have mastered the words in the selected packs, we can remove them from our list and move on to more advanced packs.</p>



<p>So, overall, Toucan seems to be a useful tool for learning a language.</p>



<p>But, here‚Äôs a burning question:</p>



<h2>Can language extensions be a distraction?</h2>



<p>It depends on the translation density set for the extension.</p>



<p>For example, in Toucan, we can control the number of translations on a page with the following setting:</p>



<div><figure><img data-attachment-id="967" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-frequency/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1600%2C1158&amp;ssl=1" data-orig-size="1600,1158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-frequency" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=300%2C217&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1024%2C741&amp;ssl=1" loading="lazy" width="1024" height="741" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1" alt="Choosing a translation density in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Choosing a translation density in Toucan.</figcaption></figure></div>



<p>Choosing ‚ÄúMany‚Äù will set Toucan to replace and highlight a substantial number of words on the page with their translated counterparts.</p>



<p>I tried this setting for some time, and I found it somewhat distracting because there were a ton of words highlighted in the page fighting for my attention.</p>



<p>To take it easy and progress gradually, I started with the setting ‚ÄúLess‚Äù.</p>



<p>With ‚ÄúLess‚Äù, I get around 5‚Äì7 words translated in an article of 4‚Äì5 min read time.</p>



<p>Also:</p>



<p>With ‚ÄúLess‚Äù translations are distributed evenly in the article. Thus, the highlights don‚Äôt steal my attention from the content.</p>



<p>I can naturally spot a highlight as I read through the content, and hover on the translated word for the meaning.</p>



<p>Here‚Äôs what I recommend:</p>



<p>Start with ‚ÄúLess‚Äù ‚Üí As you become comfortable with the translations ‚Üí Move to ‚ÄúMore‚Äù.</p>



<p>With a gradual transition, it‚Äôll be easier to stick to this extension and interpret it as a tool instead of a distraction.</p>



<p>Similar to Toucan, Fluent also shows up an option to choose how many words you‚Äôd like to see translated:</p>



<div><figure><img data-attachment-id="992" data-permalink="https://hulry.com/toucan-learn-language/fluent-set-word-density/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1584%2C662&amp;ssl=1" data-orig-size="1584,662" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-set-word-density" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1024%2C428&amp;ssl=1" loading="lazy" width="1024" height="428" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1" alt="Setting a translation density on Fluent." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Setting a translation density on Fluent.</figcaption></figure></div>



<p>Establishing the fact that these extensions are a tool rather than a distraction, here‚Äôs another critical question:</p>



<h2>Are there any privacy concerns?</h2>



<p>Privacy is a significant factor in an extension like this since we‚Äôre giving the extension full access to whatever we browse.</p>



<p>Both <a href="https://jointoucan.com/privacy" target="_blank" rel="noreferrer noopener nofollow">Toucan</a> and <a href="https://www.usefluent.co/privacy" target="_blank" rel="noreferrer noopener nofollow">Fluent</a> have addressed this concern with a friendly privacy policy.</p>



<p>Here‚Äôs a gist:</p>



<ul><li>They don‚Äôt sell user data for ads.</li><li>The extensions don‚Äôt store any browsing history.</li><li>They only store the translated words in a browsing session to keep track of your learning progress.</li></ul>



<p>But:</p>



<p>With a free product, there will always be privacy concerns, no matter how clean it‚Äôs privacy policy might be. The business needs to make money.</p>



<p>Here‚Äôs how Toucan generates revenue right now:</p>



<ul><li><strong>Premium memberships.</strong> Toucan offers a premium membership which unlocks a couple of advanced learning packs.</li><li><strong>Own a word.</strong> With Toucan, you can <a href="https://jointoucan.com/own-the-word/claim" target="_blank" rel="noreferrer noopener nofollow">own a word</a> for <strong>$0.99/week</strong>. This means that if I own the word ‚Äúproductivity‚Äù, then every time someone hovers over the translated word for ‚Äúproductivity‚Äù, they‚Äôll see my name and website at the bottom of the card. Consider it a form of advertisement without the use of your browsing history.</li></ul>



<p>That said:</p>



<p>I would still recommend you turn off Toucan on sensitive websites like your email inbox, banking sites, etc.</p>



<p>Here‚Äôs how you can do it:</p>



<div><figure><img data-attachment-id="975" data-permalink="https://hulry.com/toucan-learn-language/turn-off-toucan/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="turn-off-toucan" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?resize=840%2C526&amp;ssl=1" alt="Turning off Toucan translations on a specific website." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Turning off Toucan translations on a specific website.</figcaption></figure></div>



<p>Once Toucan is turned off for a particular website, the extension will never read any data from any page of the website.</p>



<p>Here are some of the websites where I have disabled Toucan:</p>



<ul><li>HEY email</li><li>Dropbox</li><li>Gmail</li><li>Banking websites I use</li><li>WordPress</li><li>Notion</li></ul>



<p>It‚Äôs always wise to fine-tune privacy settings so that we don‚Äôt leak any of our data to a company who might use it to their advantage.</p>



<p>Now that we talked about Toucan‚Äôs premium subscription, let‚Äôs see:</p>



<h2>Whether premium is worth the money</h2>



<p>Right now, the only selling point of ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hulry.com/toucan-learn-language/">https://hulry.com/toucan-learn-language/</a></em></p>]]>
            </description>
            <link>https://hulry.com/toucan-learn-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055257</guid>
            <pubDate>Wed, 11 Nov 2020 03:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Value for People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055070">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Minh Pham. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I want to start off by saying Congrats and Good job. If you‚Äôre reading this, it‚Äôs likely you know how to code ‚Äì and even if you‚Äôre still working on getting that first job, that means you have one of the most desirable skill sets in the world today. I congratulate you because getting here took work. You weren‚Äôt born with this knowledge, and even if you felt like it came naturally, it was still a journey of discovery, learning, and practice that got you where you are today.</p>



<p>As you look towards your first job ‚Äì I want to offer you a single piece of advice that may act as your career‚Äôs guiding north star:</p>



<p><strong>Create Value for People.</strong></p>



<p>When you have the power to create anything, you begin to realize the importance isn‚Äôt on the code you‚Äôre writing but rather why you‚Äôre writing it in the first place. What value are you creating through your skill? This is why companies hire people like yourself. They are seeking out individuals who can ultimately deliver value to their customers, particularly through software. As you mature, you will realize that much of engineering has little to do with how fancy your solution is, and instead has everything to do with what problem it solves for the user. Once you accept this, you‚Äôll begin to see that discussions of tech choice and code structure rarely matters outside the context of what business value it represents.</p>



<p>This is where your focus should stay.</p>



<p>Obsessions with patterns and algorithms don‚Äôt serve anyone‚Äôs mission by themselves. Ignore the constant pressure to assert yourself through syntactic cleverness and obscure trivia. These things don‚Äôt matter. These things don‚Äôt drive value for anyone. No matter how many ‚Äúexperienced‚Äù engineers tell you these are important, I promise you no company hires people simply for them to recite principles and algorithms.</p>



<p>While coding might be your latest skill set, it is by no means an engineer‚Äôs only skillset. Remember that at the end of the day, it doesn‚Äôt matter if your code is ugly, fancy, verbose or concise ‚Äì the value you create matters. Strive to be an excellent communicator, a quality teammate, and an outstanding human. These attributes will guide your engineering efforts to ensure you bring value.</p>



<p>No matter where your career goes, if you focus on creating value for people, opportunities will never be in short supply. Desire for specific skills may rise and fall, but people will always look to those who can create value.</p>



<p>With that, I wish you the best of luck and may our journeys cross again,</p>



<p>Minh Pham</p>



<p><em><a href="https://www.linkedin.com/in/miniseagoat/">Minh Pham</a> believes you should lead how you want to be led. This has been the guiding principle of his career since he started. As an Engineer, he always wished he had someone who would guide him ‚Äì telling him what‚Äôs important, what he has to work on, and what he should ignore. Having gone through all that and then some, Minh now looks to be the positive influence he wishes he had.</em></p>



<p><em>As a manager, Minh‚Äôs greatest passion was teaching people the skills to create and drive the careers they want to have. Now as a career coach, he works to show people they have the power to build the life they want.</em></p>



<p><em>Minh believes anyone can do it ‚Äì and he promises it doesn‚Äôt involve linked lists or graph traversals.</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-11-09T09:27:00-07:00">November 9, 2020</time><time datetime="2020-10-23T21:27:22-06:00">October 23, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055070</guid>
            <pubDate>Wed, 11 Nov 2020 03:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Helped me be more Productive as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054231">thread link</a>) | @strikingloo
<br/>
November 10, 2020 | https://www.datastuff.tech/programming/productivity-software-developer-student/ | <a href="https://web.archive.org/web/*/https://www.datastuff.tech/programming/productivity-software-developer-student/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-884" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@strikingloo">
<meta name="twitter:title" content="How I Stay Productive as a Software Developer">
<meta name="twitter:description" content="Imagine getting more stuff done, more effectively, in less time.">
<meta name="twitter:image" content="https://cdn.pixabay.com/photo/2020/11/04/19/22/windmill-5713337_1280.jpg">
<p>Imagine getting more stuff done, more effectively, in less time. That is how I will define productivity for the rest of this piece.</p>
<p>I‚Äôve been reading a lot of productivity articles, tips, tricks and Twitter threads. In a way, doing so is the worst kind of procrastination, entropy for entropy‚Äôs sake. But every once in a while you‚Äôll glean some gold nugget among the rubble, and it will all be worth it.</p>
<p>This is my attempt at recollecting what nuggets I found. On each section I will:</p>
<ul><li>Cite sources I found interesting or relevant.</li><li>Mention whether the methods have worked for me and what exact impact they‚Äôve had.</li></ul>
<p>I will add a big caveat though: I think every person‚Äôs optimal productivity engine should be different. Thus, all of this advice should be taken, tested, and left to rot if it doesn‚Äôt work for you. And that pretty much applies to all other posts of this kind, in any blog ever, in my opinion.</p>
<p>Without further ado, here are the things I‚Äôve seen actually work to make me get more stuff done, or stay less stressed.</p>
<h2>Reduce cognitive load</h2>
<p>Cognitive load is a beautiful term. It roughly means ‚ÄúHow full is your mind‚Äôs RAM?‚Äù. </p>
<p>Whenever you‚Äôre thinking of the next 5 things you have to do, your groceries list, and whether you left the stove on, you‚Äôre carrying cognitive load.</p>
<p>It should be evident, but cognitive load stresses you out. Reducing it can help you better focus on your task.</p>
<p>Here‚Äôs what has worked for me on this account:</p>
<ul><li>Keep a clean room, office and desk<sup><a href="#fn1">1</a></sup>. You shouldn‚Äôt have trouble finding anything you use often, and the things you use the most often should be very easy to reach. This also applies to your filesystem, bookmarks system, etc. If you know you‚Äôll want to check a certain link again in the future, bookmark it under an intuitive path. Don‚Äôt find yourself looking for it through your twitter feed.</li><li>If something‚Äôs on your mind and it‚Äôs not useful to keep thinking of it, <strong>write it down and forget it</strong>. You can look it up later. </li></ul>
<p>Take this article, for instance: instead of pestering myself thinking ‚ÄòYou have to write that article!‚Äô I just added an item on my Trello backlog that said ‚Äòarticle on productivity‚Äô and forgot about it until I had free time again and checked.</p>
<p>My own setup for task tracking is a combination of Trello for daily/weekly tasks and a Google sheet for long term stuff -like a deferred backlog- but really, every person has their own perfect combination of tools and processes. Find your own. </p>
<p>I know many people who prefer physical post-its, or a board. I‚Äôd rather get the portability of a browser app and the tracking for future reference. This is especially good if you also practice journaling, because then it‚Äôs just ‚ÄúWhat did I do today? Oh ok I‚Äôll check today‚Äôs cards‚Äù. Still, your mileage will vary, so try many things and see what works best for you.</p>
<h2>Keep productive habits</h2>
<blockquote><p>‚Ä¶Watch your actions, they become your habits; watch your habits, they become your character; watch your character, it becomes your destiny.‚Äù</p><cite><em>‚Äï&nbsp;</em><strong>Lao Tzu</strong></cite></blockquote>
<p>Some people recommend this book called ‚ÄúAtomic Habits‚Äù. I won‚Äôt lie, I haven‚Äôt read it. But I read a good summary on reddit and agree with most of it, thought I was already kind of doing most of what it talks about.</p>
<p>The gist of it is: don‚Äôt try to build productivity on its own, build systems that incentivize you to be productive.</p>
<p>Some people use pomodoros, others prefer to put on noise-blocking headphones; I personally prefer to hide my cell phone until I have got enough stuff done. </p>
<p>My technique for this is simple: every month, (or use whatever time frame works for you), I decide which routines I will keep.</p>
<p>Right now for instance, my routines are:</p>
<ul><li>Exercise 4 times a week.</li><li>Do everything I have to for work and school, obviously.</li><li>Journal every night</li><li>2 hours of Japanese study every day</li></ul>
<p>The painful side of having a very clear set of goals and habits is: you‚Äôre extremely accountable to them. Is the day ending and you haven‚Äôt done your daily study session? You better get down to it right now. </p>
<p>In my case, my own conscience is a harsh enough mistress, but if you are not that hard on yourself when your to-do lists have uncrossed items, you may want to try something like </p>
<ul><li>Asking your SO to make passive aggressive remarks to you if you don‚Äôt finish your tasks.</li><li>Reward yourself with something sweet.</li><li>Going full monk-mode and forfeiting cell phone time until everything is done.</li></ul>
<p>Now for the flip side: you‚Äôre accountable for your tasks, yes, but you also set them. So whenever you define what your habits will be, don‚Äôt overestimate yourself. It‚Äôs better to have realistic, achievable goals that fall a bit short of your <em>maximum effort</em>, than it is to overstep, burn out or just not build the habits because you can‚Äôt keep up with them. </p>
<p>Did you underestimate your time management skills and now you‚Äôre doing everything you planned for <em>and</em> then get a lot of free time anyway? Cool! You get to feel productive <em>and</em> have free time. </p>
<p>You definitely don‚Äôt want to optimize for minimum free time. It sounds obvious, but I‚Äôve caught myself and others doing this without realizing it.</p>
<p>The devil doesn‚Äôt always make work with idle hands.</p>
<p>Another thing about incentives: this ties to the ‚Äúunclutter‚Äù rule I mentioned earlier, but do try to turn everything around you into a big <strong>habit-keeping engine</strong>. </p>
<p>For instance, if your goal is to read a book every week, have your book on sight and within arm‚Äôs reach at all times. Carry it on your suitcase/backpack, take it out instead of your cell phone when you want to procrastinate, etc. </p>
<p>You‚Äôll be surprised by how much stuff you get done when <strong>everything around you is making you do it</strong>.</p>
<p>For a small guide on creating habits that I found interesting (though maybe more complicated than necessary) see <a href="https://www.lesswrong.com/posts/vE7Z2JTDo5BHsCp4T/instrumental-rationality-4-2-creating-habits">creating habits</a>.</p>
<h2>Don‚Äôt use your head for things a PC was made for</h2>
<p>Really though, remember what I said about cognitive load? Defining daily goals is not cool if you end up spending 5 minutes every hour thinking ‚Äúok what comes next? I already crossed my Chinese practice and my Economics lecture, what was the next item?‚Äù. </p>
<p>You want whatever system you build to be maintainable in the long run, so you should make it as easy to consult as possible, and not depend on a very fallible piece of architecture (your head).</p>
<p>So keep everything written down, on a nice .txt file, a Google doc, a sheet, etc. Use whatever you like, but not your head. Really it‚Äôs that simple, and it works. </p>
<p>(Aside: I am not going into detail into different tools or task tracking systems because honestly? There are like 20 different articles on this topic posted on HackerNews every week, and they‚Äôre all the same).</p>
<h2>Effective Note Taking</h2>
<p>This is all I have to say about note taking.</p>
<p>I am not a very note taking inclined person. I started this particular habit this year, and even though it <em>feels</em> productive, I don‚Äôt feel like I can quite say it has actually made me perform better yet.</p>
<p>So my first tip on this will be: <strong>don‚Äôt take notes if you don‚Äôt think it will be worth it</strong>. Some people retain information better when they take notes, I am not one of those people but if you are, then that piece of advice doesn‚Äôt apply to you. Remember when I said systems needed to be custom?</p>
<p>I also say this because I see there‚Äôs this trend in the internet of ‚Äúwrite everything down, take all the notes!‚Äù and I think we‚Äôre tending towards an excessive ‚Äúpro-notes-taking‚Äù bias, which may be unwarranted.</p>
<p>Secondly: if you are not writing everything down, how do you decide what should be kept? Well, I‚Äôm open to better ideas, but in my case I optimize for (estimated) <strong>future searchability</strong>: is what I just read, heard or watched something I am <strong>likely to think of in the future</strong>? And maybe I will want to recall it exactly and won‚Äôt be able to? Well then, into the notes it goes.</p>
<p>Note that it doesn‚Äôt need to be a relevant piece of information per se. I take notes about interesting history facts, anime trivia and weird Japanese words, not because they‚Äôll come up in my final exams (fingers crossed) or, gods forbid, my job. I keep those quotes and facts around because they may come up in conversation.</p>
<p>Generally though, I think the category that makes the best notes is ‚Äúthings that I am likely to forget and look up again in the future, but I don‚Äôt care to learn by heart right now‚Äù. </p>
<p>This includes things like very specific facts about a domain, convoluted bash commands that you put into a script to not have to remember again (but want to persist somewhere else in case you want them on a different pc), or syntax details in a programming language.</p>
<p>I will be reading an article and think ‚Äúoh, $FRIEND_X surely would find this very funny‚Äù and just write it down. And then I may send it to them through IM, but let‚Äôs be honest I could forget‚Ä¶ until I reread my notes in the future.</p>
<p>Oh, the topic of rereading notes. This one is a tricky bit I haven‚Äôt mastered yet, and I am also open to suggestions in this area. Personally, I only reread notes on technical topics whenever they come up and I want to refresh my memory, and any other topic if I am thinking of it.</p>
<p>I know some people like to go through all of their notes every X time and they say it improves their creativity and gets the writing juices flowing. I am not super concerned about my creativity or writing right now (in case my one year posting-gap didn‚Äôt make that clear), but I will definitely experiment with that in the future (and write about it if I get any relevant results).</p>
<p>Lastly, I‚Äôve recently been using a <strong>personal wiki</strong> for some of my notes (only the polished, public-facing ones), and it‚Äôs really cool, but it just reinforces point one: I feel like part of why I use a personal wiki is just that it feels nice, and I haven‚Äôt yet seen a lot of improvement over a simple Evernote or Google Docs. Maybe it‚Äôs a matter of scale and the effects won‚Äôt be apparent until a few years in? We will see.</p>
<h2>Anki and SRS for studying and productivity.</h2>
<blockquote><p><strong>Anki makes memory a choice</strong>, rather than a haphazard event, to be left to chance.</p><cite>Michal ‚Ä¶</cite></blockquote></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datastuff.tech/programming/productivity-software-developer-student/">https://www.datastuff.tech/programming/productivity-software-developer-student/</a></em></p>]]>
            </description>
            <link>https://www.datastuff.tech/programming/productivity-software-developer-student/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054231</guid>
            <pubDate>Wed, 11 Nov 2020 00:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PilferShush Jammer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054222">thread link</a>) | @karlzt
<br/>
November 10, 2020 | https://www.cityfreqs.com.au/pilfer.php | <a href="https://web.archive.org/web/*/https://www.cityfreqs.com.au/pilfer.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
            Basic information about how the SDKs code function. They start with a call to the Android/Java API that deals with audio recording and playback. From there with a buffer array full of some audio data, it can then be sent to a native code library that is also installed as part of the SDK. These libraries handle the more CPU intensive work such as sifting through the data using various common methods (Goertzel et al) to find audio signals of interest. 
            </p><p>
            This first section shows some of the Android/Java function calls and parameters used.
            </p><p>
							<strong>alphonso</strong>
              <br>
              ALPHONSO_VERSION = "2.0.46";
              </p><pre>    private static final int RECORDER_AUDIO_BYTES_PER_SEC = 16000;
    private static final int RECORDER_AUDIO_ENCODING = 2;
    private static final int RECORDER_BIG_BUFFER_MULTIPLIER = 16;
    private static final int RECORDER_CHANNELS = 16;
    private static final int RECORDER_SAMPLERATE_44100 = 44100;
    private static final int RECORDER_SAMPLERATE_8000 = 8000;
    private static final int RECORDER_SMALL_BUFFER_MULTIPLIER = 4;
    public static final byte ACR_SHIFT_186 = (byte) 0;
    public static final byte ACR_SHIFT_93 = (byte) 1;
    public static final int ACR_SPLIT = 2;</pre>

              <p><strong>bitsound</strong>
              <br>
              VERSION_NAME = "v4.2.2"
              </p><pre>    public void a(int i) {
      try {
        this.d = new AudioRecord(6, this.b, 16, 2, i);
        if (this.d.getState() == 1) {
          try {
            this.d.startRecording();
            if (this.d.getRecordingState() != 3) {
              b.c(a, "Audio recording startDetection fail");
              this.d.release();
              this.e = false;
              return;
            }
            a(this.d);
            this.e = true;
            return;</pre>
            
              <p><strong>cifrasoft</strong>
              <br>
              VERSION_NAME = "1.0.3"
              </p><pre>    public static final int AUDIO_BUFFER_SIZE_MULTIPLIER = 4;
    public static final int AUDIO_THREAD_STOP_TIMEOUT = 3000;
    public static final int MAX_EMPTY_AUDIO_BUFFER_SEQUENTIAL_READS = 10;
    this.SAMPLE_RATE = 44100;</pre>
    
              <pre>    private int readAudioData(int currentPcmOffset, byte[] pcm) {
      AudioRecordService.handler.sendEmptyMessageDelayed(1, 3000);
      int result = this.mAudioRecord.read(pcm, currentPcmOffset * 2, this.bufferLength * 2);
      AudioRecordService.handler.removeMessages(1);
      return result;
    }</pre>

              <p><strong>copsonic</strong>
              <br>
              CORE_VERSION = "SonicAuth_CORE_v1.2.2.1";
              </p><pre>    "signalType": "ULTRASONIC_TONES",
    "content" : {
        "frequencies" : [ [18000, 20000, "TwoTones"] ]

    "signalType": "ZADOFF_CHU",
    "content": {
      "config": {
        "samplingFreq": 44100,
        "minFreq": 18000,
        "maxFreq": 19850,
        "filterRolloff": 0.5,
        "totalSignalTime": 0.3,
        "nMsgSymbols": 2,
        "filterSpan": 8
      },
      "set": {
        "centralFreq": 18925,
        "nElemSamples": 36,
        "nSymbolElems": 181</pre>

              <p><strong>dv (dov-e)</strong>
              <br>
              VERSION_NAME = "1.1.7"
              </p><pre>    private void recorderWork() {
      if (this.recordingActive) {
        int bytesReadNumber = this.myRecorder.read(this.myBuffer, 0, this.myBuffer.length);
        if (this.recordingActive) {
          DVSDK.getInstance().DVCRxAudioSamplesProcessEvent(this.myBuffer, 0, bytesReadNumber / 2);
        }
      }
    }</pre>
    
              <p><strong>fanpictor</strong>
              <br>
              VERSION_NAME = "3.2.3"
              </p><pre>    enum FNPFrequencyBand {
      Default,
      Low,
      High
    }
              </pre>

              <p><strong>fidzup</strong></p><pre>    a. this.frequency = paramBasicAudioAnalyzerConfig.frequency;   // 19000.0f
    b. this.samplingFrequency = paramBasicAudioAnalyzerConfig.samplingRate;    // 44100.0f
    c. this.windowSize = paramBasicAudioAnalyzerConfig.windowSize;   // 0x200 (512)
    d. /* pulseDuration = 69.66f */
    e. this.pulseWidth = Math.round(paramBasicAudioAnalyzerConfig.pulseDuration * (this.samplingFrequency / 1000.0F));
    f. this.pulseRatio = paramBasicAudioAnalyzerConfig.pulseRatio;   // 32.0f
    /* signalSize = 0x20 (32)
    g. this.signalPeriodPulses = paramBasicAudioAnalyzerConfig.signalSize;
    h. this.bitCounts = paramBasicAudioAnalyzerConfig.bitcounts;   // 0xb (11)</pre>         
            <pre>    paramf.a = 19000.0F;            
    paramf.b = 44100.0F;            
    paramf.c = 512;                 
    paramf.d = 69.66F;              
    paramf.e = 0.33333334F;         
    paramf.f = ((int)(paramf.d * 32.0F * 3.2F)); // 7133.184
    paramf.g = 32;                 
    paramf.h = new int[] { 15, 17, 19, 13, 11, 21, 23, 9, 7, 25, 27 };</pre>             

              <p><strong>fluzo</strong>
              <br>
              VERSION = "1.3.001"</p><pre>    this.p = jSONObject.getInt("frame_length_milliseconds");
    this.q = jSONObject.getInt("frame_step_milliseconds");
    this.r = (float) jSONObject.getDouble("preemphasis_coefficient");
    this.s = jSONObject.getInt("num_filters");
    this.t = jSONObject.getInt("num_coefficients");
    this.u = jSONObject.getInt("derivative_window_size");</pre>
    
              <p><strong>instreamatic</strong>
              <br>
              VERSION_NAME = "7.16.0"</p><pre>    private static final int BUFFER_SECONDS = 5;
    private static int DESIRED_SAMPLE_RATE = 16000;</pre>
 
              <p><strong>lisnr</strong>
              <br>
              VERSION_NAME = "5.0.1.1";
              </p><pre>    // LisnrIDTone          
    public long calculateToneDuration() {
        return ((long) (((double) (this.lastIteration + 1)) * 2.72d)) * 1000;
    }
    // LisnrTextTone
    public long calculateToneDuration() {
        return (long) (((this.text.length() * 6) * 40) + 1280);
    }
    // LisnrDataTone
    public long calculateToneDuration() {
        return (long) (((this.data.length * 6) * 40) + 1280);
    }
    AudioRecord audioRecord = new AudioRecord(0, d, 16, 2, 131072);</pre>  

              <pre>    ArrayAudioPlayer.this.audioOutput = new AudioTrack(3, ArrayAudioPlayer.this.samplerate, 4, 2, 16000, 1);
    ArrayAudioPlayer.this.audioOutput.play();
    int written = 0;
    while (!ArrayAudioPlayer.this.threadShouldStop) {
      try {
        if (ArrayAudioPlayer.this.buffer.getBufferLeftToRead() &gt; 0) {
          int size = ArrayAudioPlayer.this.buffer.getBufferLeftToRead();
          written += size;
          ArrayAudioPlayer.this.audioOutput.write(ArrayAudioPlayer.this.buffer.readFromBuffer(size), 0, size);
          } else {
            ArrayAudioPlayer.this.threadShouldStop = true;
          }
        } catch (IOException e) {
          e.printStackTrace();
        }</pre>
        
              <p><strong>moodmedia</strong>
              <br>
              getVersion() = "1.2.1";
              </p><pre>    b = new AudioRecord(5, 44100, 16, 2, Math.max(AudioRecord.getMinBufferSize(44100, 16, 2) * 4, 32768));
    this.b = Type.SONIC;
    this.b = Type.ULTRASONIC;
    if (num.intValue() == 44100 || num.intValue() == 48000)
    this.j.setName("Demodulator");
    this.k.setName("Decoder");
    this.l.setName("HitCounter");
              </pre>
 
              <p><strong>prontoly (sonarax)</strong>
              <br>
              VERSION_NAME = "4.2.0";
             </p><pre>    contentValues.put("time", cVar.a);
    contentValues.put("type", cVar.b.name());
    contentValues.put(NotificationCompat.CATEGORY_EVENT, cVar.c);
    contentValues.put("communication_type", cVar.d);
    contentValues.put("sample_rate", cVar.e);
    contentValues.put("range_mode", cVar.f);
    contentValues.put("data", cVar.g);
    contentValues.put("duration", cVar.h);
    contentValues.put("count", cVar.i);
    contentValues.put("volume", cVar.j);</pre>
    
              <p><strong>realitymine</strong>
              <br>
              getSdkVersion = "5.1.6";
              </p><pre>    this.e = AudioRecord.getMinBufferSize(44100, 16, 2);
    int i = this.e;
    this.d = new byte[i];
    this.c = new AudioRecord(1, 44100, 16, 2, i);</pre>

              <p><strong>redbricklane (zapr)</strong>
              <br>
              SDK_VERSION = "3.3.0";
              </p><pre>    AudioRecord localAudioRecord = new AudioRecord(1, 8000, 16, 2, 122880);
    if (localAudioRecord.getState() == 1) {
      this.logger.write_log("Recorder initialized", "finger_print_manager");
      this.logger.write_log("Recording started", "finger_print_manager");
      localAudioRecord.startRecording();</pre>

              <p><strong>runacr</strong>
              <br>
              release = "1.0.4"
              </p><pre>    int minBufferSize = AudioRecord.getMinBufferSize(11025, 16, 2);
    this.K = new AudioRecord(6, 11025, 16, 2, minBufferSize * 10);</pre>

              <p><strong>shopkick</strong></p><pre>    .field bitDetectThreshold:Ljava/lang/Double;
    .field carrierThreshold:Ljava/lang/Double;
    .field detectThreshold:Ljava/lang/Double;
    .field frFactors:Ljava/lang/String;
    .field gapInSamplesBetweenLowFreqAndCalibration:Ljava/lang/Integer;
    .field maxFracOfAvgForOne:Ljava/lang/Double;
    .field maxIntermediates:Ljava/lang/Integer;
    .field minCarriers:Ljava/lang/Integer;
    .field noiseThreshold:Ljava/lang/Double;
    .field numPrefixBitsRequired:Ljava/lang/Integer;
    .field numSamplesToCalibrateWith:Ljava/lang/Integer;
    .field presenceDetectMinBits:Ljava/lang/Integer;
    .field presenceNarrowBandDetectThreshold:Ljava/lang/Double;
    .field presenceStrengthRatioThreshold:Ljava/lang/Double;
    .field presenceWideBandDetectThreshold:Ljava/lang/Double;
    .field useErrorCorrection:Ljava/lang/Boolean;
    .field wideBandPresenceDetectEnabled:Ljava/lang/Boolean;
    .field highPassFilterType:Ljava/lang/Integer;</pre>
              <pre>    Java_com_shopkick_app_presence_NativePresencePipeline_setDopplerCorrectionEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setHighPassFilterEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setWideBandDetectEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setNumPrefixBitsRequiredParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setPresenceDetectNarrowBandDetectThresholdFCParam
    ‚Ä¶</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cityfreqs.com.au/pilfer.php">https://www.cityfreqs.com.au/pilfer.php</a></em></p>]]>
            </description>
            <link>https://www.cityfreqs.com.au/pilfer.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054222</guid>
            <pubDate>Wed, 11 Nov 2020 00:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eddie's Ink Chip Hack (2002)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054177">thread link</a>) | @userbinator
<br/>
November 10, 2020 | http://www.eddiem.com/photo/CIS/inkchip/chip.html | <a href="https://web.archive.org/web/*/http://www.eddiem.com/photo/CIS/inkchip/chip.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/cis.htm">My CIS page.</a></p></td>
<th>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/inkchip.JPG" name="Graphic2" width="401" height="400"></p></th>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/printer/chipreset/resetchip.html">Part
				2 build your own reseter</a></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><strong>What is a Intellidge ink chip.</strong><span size="5"><br>
</span>Epson fit
				small circuit boards to most of their ink cartridges. These
				record the amount of ink that is estimated to be in the
				cartridge. I read that the official epson line is that it is for
				the customers benefit and not an anti-refill device. Whether you
				believe this or not they are a bloody nuisance to anyone wanting
				to refill the cartridges or use bulk ink. It also stops people
				using old cartridges full of solvent for cleaning the heads.
				Another problem was early printer models didn't check if the
				cartridge had been changed while power was on. This was good if
				you wanted to trick the printer into copying a ‚Äúfull‚Äù
				chip to and empty one, however the reverse was also true and you
				could easily copy and ‚Äúempty‚Äù one into your full
				one.<br>
They are just a small memory device holds 32 bytes of
				data, they do not measure real ink level and nor does the
				printer. The printer reads the chips on startup, estimates
				(sometimes badly) how much ink should have been used and writes
				this back at shutdown. They hold other data as well.<br>
So epson
				go to the trouble of fitting chips to cartridges and building all
				the extra sockets, wiring, electronics and software into the
				printer so you can use the computer to see the predicted level
				and it can stop you printing if it think you've used enough ink.
				High-end Canon's on the other hand make the inks tank clear so
				you can see and have optical sensor to detect emptiness. This
				make a lot more sense ‚Äì unless you are making an
				anti-refill device that is. Canon almost got my business this
				time but nobody I could find has run pigment in them ‚Äì too
				risky.<br>
To get around the chip problems someone usually end up
				producing read-only chip which always read full (for use with
				CIS) and chip reseters for those who want to refill. These are
				not available for 2100p at the time of writing as far as I can
				tell.<br>
Before ordering my 2100p I did my homework and it seemed
				fairly likely a chip reseter would become available at some point
				and read-only chips as well. I was also cocky enough to think I
				could crack it myself and I have. It didn't go quite as expected
				though.<br>
<strong>What do I want to do?</strong><br>
I want the easiest way
				to fool the printer into believing it has full cartridges present
				so I can build my CIS.<br>
<strong>What did I expect?</strong><br>
A logical
				interface for Intellidge is i2c (i squared c) or TWI (two wire
				interface). Then the chip could just be some standard i2c eeprom.
				The Intellidge have too many pads for this but I was hopeful.
				After that would could SPI or microwire ‚Äì again this could
				use off the shelf parts. If the chips were micro-controllers then
				plain asynchronous serial would be my choice.<br>
<strong>I had a
				look.</strong><br>
To do this I use a AVR mega323 micro, I declined
				offers of logic analyzers being a homebrew type of guy. The 323
				has 2K of internal ram which is enough for some minimalist data
				logging. It was about $50AUS in parts ($30US) to make. I wired a
				cartridge to bring the signals out and took a quick look with a
				voltmeter.<br>
<strong>Nothing!</strong><br>
There was nothing there. I
				expected some power but no, the chips are only powered briefly
				when the are accessed. I used leds to get a rough idea what was
				what and hooked up the micro via resistors to give some degree of
				protection to the printer if I screwed up. The code in the micro
				was written is assembler and captured data sent via rs232 to my
				PC where I wrote a delphi program to display and process the
				data.</p></td></tr>
<tr>
<td colspan="3">
</td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/fastendsml.gif" name="Graphic5" width="615" height="213"></a><br>
<a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html">Click
				here for more traces.</a></p>
<p lang="en-GB">This is the sort of thing I got. No
				protocol I ever seen. Obviously synchronous with bi-directional
				data, very short format. I was confused a little by how short it
				was - because I expect much better precision for the ink
				level.<br>
The traces seem to be.<br>
Top ‚Äì some sort of sync
				line, this always goes low before the start of transmission.<br>
Next
				‚Äì power this goes low (off) between chip reads at printer
				startup but stays high during the shutdown ‚Äì when data is
				written to the chip.<br>
Next ‚Äì the clock, data is read of
				the rising edge and changed on the falling.<br>
Bottom ‚Äì
				bi-directional data, the first 4 bits are always from printer to
				the chip, the rest depend on whether it is a read or write. LSB
				first (left).</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Convert to binary and some patterns emerge.<br>
It
				was not real obvious how the chips were addressed or which bits
				encoded ink levels. Some more data when some ink had been used
				made it easier.</p>
<p lang="en-GB">Below is one chip being read at startup, there
				are 7 accesses one for each chip. Only 3 block have data ‚Äì
				the other chips must be hooked to different data lines.</p>
<div lang="en-GB"><p><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/strtbinary.gif" name="Graphic6" width="818" height="45"></p></div></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Below is the complete shutdown stream. Again we
				can only see 3 chips from here.</p>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/endbinary.gif" name="Graphic7" width="297" height="199"><br clear="left">
After
				printing a few bits near the beginning of the bit stream did
				change. It looks to me like the first 3 bits are the chip address
				the next is a write bit then the ink level, I get the feeling
				there aren't many bits used to encode it (later looks like 6).<br>
So
				‚Äì the top one shows 252 bits of data being read out of the
				chip.<br>
The first part of the shutdown shows just the ink level
				being read out, this is to check the same chip is there.<br>
The
				second part is the ink-level and some other stuff (printer serial
				number maybe) being written into the chip. Seeing I didn't use
				any ink the bit-stream is identical to the read except for bit 3
				‚Äì presumably the write bit.</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><span size="5"><br>
Tuesday
				24 Sept 2002. I fooled the printer.</span></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/spoofed.gif" name="Graphic8" width="381" height="363"><span size="3">The
				interesting thing about this screen grab is the black cartridge
				is really only two thirds full. I spoofed the printer by pulling
				the serial data line low during the time the ink level bits are
				being clocked out of the ink chip.<br>
This is means 6 bits
				starting at the 5'th bit in the stream.</span></p>
<p lang="en-GB"><span size="3">The first 3 bits appear to be the
				chip address, I guess the next is a read/write select. I used a
				AVR mega323 to detect the start of the serial transmission look
				for the address of chip1+read (black apparently) then pull data
				low for 6 clock edges. </span></p>
<p lang="en-GB"><span size="3">I'm sure I can reset 3 of the chips
				by tapping into chip1 signal. Reseting the rest will mean tapping
				into at least one more. </span></p>
<p lang="en-GB"><span size="3">The current set up is for
				experimentation only ‚Äì it is not ‚Äúthe real thing‚Äù.</span></p>
<p lang="en-GB"><span size="3">Shorting the data to ground may be a
				bit drastic but it is only for a very brief time. I hoped the
				data line would be open collector but this doesn't seem to be the
				case.</span></p></td></tr></div></div>]]>
            </description>
            <link>http://www.eddiem.com/photo/CIS/inkchip/chip.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054177</guid>
            <pubDate>Wed, 11 Nov 2020 00:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nadia Eghbal on working (and writing) in public]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053962">thread link</a>) | @jger15
<br/>
November 10, 2020 | https://www.thepullrequest.com/p/nadia-eghbal | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/nadia-eghbal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg&quot;,&quot;height&quot;:1200,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:399616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>                                                                                              Portrait by <a href="https://www.katiasobolski.com/">Katia Sobolski</a>.</em></p><p><strong>Nadia Eghbal is uniquely positioned to write about open source having spent almost two years in developer relations at the Alexandrian library of open source, GitHub. She then spent two years continuing her quasi-anthropological study of open source at Protocol Labs, and now works in writer relations at Substack (host of this publication). Her new book is <a href="https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/">Working in Public: The Making and Maintenance of Open Source Software</a>, which like her career trajectory, starts in open source software but ends up grappling with larger issues of creators in an unbundled digital economy. </strong><em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement">The Pull Request</a></strong></em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement"> review is here</a>.</strong></p><p><em>AGM: My naive mental model of open-source was this almost communitarian kibbutz model. And yet, the big lesson from your book is that that‚Äôs not really how it works. </em></p><p>NE: Part of the reason why I wrote this book was because I feel like we've had this communitarian kibbutz kind of model, which you've identified, is the prevailing model that people understand in open source and that gets frequently talked about. And I think that narrative has kind of been owned by the likes of [Richard] Stallman or Eric Raymond or anyone who kind of remembers those early days of open source. And that model definitely still exists within the matrix of different community models. The ‚Äòclubs‚Äô are kind of like that, where everyone is rolling up their sleeves and there's lots of different active contributors. And then we also have  the ‚Äòfederations‚Äô that are kinda like the really big open source projects that we're used to thinking about like Linux, but then there‚Äôs the rise of the ‚Äòstadium‚Äô model that is, I think, much newer.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png&quot;,&quot;height&quot;:408,&quot;width&quot;:934,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57769,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>The Eghbal model of open-source communities (referenced copiously here), whose contours are readily applicable more broadly.</em></p><p>If you look at what's happened to open source for the past 20 years, at some point demand outpaced supply and the amount of context that anyone can really have around any one open source project‚Äîbecause every developer is relying on like hundreds of different projects‚Äîit's not really possible to become this roll-up-your-sleeves member of every single project. And so, yeah, I think the governance does look really different and it‚Äôs specifically something that I didn't want to bang people over the head about it in the book. But I think a stadium model lends itself a little bit more to that kind authoritarian model and there‚Äôs less the kind of governance issues that we see in like a federation where people are like <em>this is a democracy!</em> and everyone is gonna ask everyone for opinions and stuff even if you might only have one or a few contributors. The contributors [in a stadium] are kind of just making the decisions and I think they should feel comfortable leaning into that. Even though right now I think a lot of them feel uncomfortable doing that because they keep being told that open source is supposed to this super participatory thing.</p><p><em>AGM: And you think that it doesn't necessarily have to be.</em></p><p>NE: I think the tension in one of these stadium models is where you do have a lot of users. And then you have some of these casual contributors who are opening issues, making feature requests or just lost, and you are kind of sorting through all that volume from people that you don't know. In my view, it's kind of like, well, I don't understand why should that person have a say in your project, if they've never looked at it before, and they're just kind of coming in for the first time and you're the core developer of the project. </p><p>There is a set of rhetoric in open source that says every person is a contributor, and anyone who kind of comes in, you should treat them as a contributor and like invest in them and all this stuff, but I don't feel like we would do that for anything else. If you had a hobby meetup kind of group with you and your friends and someone came in once and then was like <em>I think we should runs a group like this</em>, you'd be like: W<em>ho are you?</em> <em>This is this is our thing. </em>I think I want people to feel more comfortable saying that. And there's obvious parallels between that and the Internet at large right now.</p><p><em>AGM: You took the words right out of my mouth. In the book, you‚Äôve got a long riff on the <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons</a>. Not that I want to turn this interview into a Facebook thing, because having worked there and spent part of my career on it, it's like the last thing I want to talk about‚Ä¶but I do think it's somewhat relevant in that, Twitter or Facebook, is it actually the public forum and a commons? Can Zuck or Jack run it as you suggest? Can they run it like [Guido] van Rossum does Python, as officially-titled Benevolent Dictator For Life? In some sense that‚Äôs actually better? </em></p><p>NE: Yeah. Well, I don't think Facebook is a commons anymore, just by sheer size that we‚Äôre dealing with. One of the things that I'm trying to do in the book is go back through Elinor Ostrom‚Äôs definition of a commons and saying, okay, she makes the argument that we can avoid this tragedy of the commons by having people self govern. But she has very specific rules that she's laid out around what actually qualifies something as a commons, so we can self govern in a healthy way, assuming these conditions hold and a lot of those conditions have to do with having clear membership boundaries and very high context for your interactions with each other. And so if you think just about Facebook being 2.6 billion people or however many people are on Facebook now, it's impossible that literally multiple billions of people all have that kind of context for each other. I think of Facebook as being this substrate that fosters a bunch of smaller communities. You might have Facebook Messenger which resembles more like the group chats or the ‚Äòclub‚Äô-style communities. You might have the ‚Äòstadium‚Äô type situations that are more like one person broadcasting out to a group of people and you might have Facebook groups which could be like either ‚Äòclubs‚Äô or ‚Äòfederations‚Äô depending how big they are. You actually have a permutation of lots of different types of communities that are across the entire platform. But I think having that kind of vocabulary can help us figure out, what does it actually mean to develop governance for any of these platforms? It's the same thing with Twitter also. I don't see a world where we have one policy or a certain set of guidelines. </p><p><em>AGM: That‚Äôs a somewhat shocking statement.</em></p><p>NE: Yeah, it's so it's funny that that‚Äôs controversial. Part of what I was trying to do in the book is saying like, okay, let's not like talk about social media, let's just talk about this other weird thing called open source. And let's look at the dynamics there and how that's evolved for 20 years. Can you depersonalize this a little bit and if you agree with me that these things seem to be happening in open source. And stacking this up against other economic frameworks we've had in the past, like the commons, and it doesn't seem to hold here, then can we take that conclusion and transfer it back over somewhere else‚Ä¶</p><p><em>AGM: Okay, that's the vibe I got from your book that you were trying to actually talk about the rest of it. So it's good to know that I wasn't over-reading into it. </em></p><p>NE: I was trying to be sensible about it. </p><p><em>AGM: Do you think the push on Facebook for content moderation, and Twitter, is a fool's errand? You know how Kevin Roose and Charles Warzel of </em>The Times<em> and that whole whiny mob that's constantly trying to get them to moderate everything. You think that's probably not the way forward?</em></p><p>NE: It seems beyond not just gonna happen, it seems actively wrong to me. It‚Äôs as though we're asking another country to govern the United States or something. I'm trying to look at where do those governance boundaries start and who should be moderating themselves or not, and just the thought that you would have a sort of widespread platform governance on some of these issues just seems, yeah, morally wrong to me.</p><p><em>AGM: Are you a free-speech absolutist, Nadia, that rarest of breeds?</em></p><p>NE: I'm not super public about my politics, but then I don‚Äôt mind poking my head out a little bit around it and publishing the book was kind of part of this for me because, to be totally frank, there are these democratic kind of ideals and these like communist-y ideals that we are holding about both the Internet and open source which are driving me crazy and, I'm trying to point out, you know, that's not always the case. And sometimes it's about one person who was doing a lot of things and we're just like couching it in a group cooperative. Yeah, I don't really know what my politics are, but I definitely err as far to that side as possible, as I think is reasonable. I do think this kind of moderation stuff, no one really has the answer to it. And so I'm not gonna sit here and be like, <em>I know how to fix it!</em> No one knows how to fix Facebook. Or any of these platforms. There's there's some humility that should be in place there, but I know what I stand for and what I'm aiming for.</p><p><em>AGM: I dislike looking always at the extreme example. But you know, Balaji [Srinivasan] had this whole dust-up with Taylor Lorenz and he's constantly getting into fights with these media people. And it's weird because he's often so right in so many ways, and he's good at getting attention. But somehow he hasn't parlayed into a mainstream following. </em></p><p>NE: I do feel like we need to have institutions a little bit in order to reinforce that. Well, I don't know if that's true or not, because people do follow like Elon Musk or Joe Rogan, or whatever. So that does exist. But I feel it would be so nice that if we had a publication that we could be proud of, that people would read outside of tech. There's no legible symbols for someone else to kind of follow. Like it's even weird that the most popular tech figures are not always the most popular figures actually in tech. Like Mark Cuban ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/nadia-eghbal">https://www.thepullrequest.com/p/nadia-eghbal</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/nadia-eghbal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053962</guid>
            <pubDate>Wed, 11 Nov 2020 00:16:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053892">thread link</a>) | @shihn
<br/>
November 10, 2020 | https://shihn.ca/posts/2020/voting-systems/ | <a href="https://web.archive.org/web/*/https://shihn.ca/posts/2020/voting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<h2>Introduction</h2>
<p>We encounter voting in some form around us all the time. We rate our Uber drivers, they rate us back. We up-vote and down-vote posts and trolls on Reddit. We give stars to movies and restaurants. We vote on who gets kicked out of our favorite reality television show. We vote for Presidents.</p>
<p>All these voting systems seem a bit different from one another, but one thing that's definitely common among them ‚Äî we will find ways to complain about them. The way a voting system is designed can make an <em>election</em> trivial or really complicated in nature. In fact, sometimes, the winner of an election may be determined by the rules of the voting system and not the intent of the voters (electoral college anyone?). In this post I try to explore the core of different voting systems and wonder if there is a perfect voting system.</p>
<p>Here I am going to use the word <em>election</em> to define an event or a goal that requires voting. An election doesn't have to be political in nature.</p>
<p><em>Note and Acknowledgement: This blog post is influenced by the chapter on voting systems in video games in the book Power-Up by Matthew Lane.</em></p>
<h2>Plurality Voting</h2>
<p>This is the simplest form of voting. Most political elections in the United States are done using this form of voting. It's quite simple ‚Äî every voter casts a vote for their favorite candidate. The candidate with the most number of votes wins.</p>
<p>Let's look at an example that we will continue to use in this post. We ask 100 people to vote for their favorite flavor of ice cream. The candidates are <em>Vanilla</em>, <em>Chocolate</em>, and <em>Strawberry</em>. Here's the result:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry</td>
<td>15</td>
</tr>
</tbody>
</table>
<p><strong>Vanilla has won!</strong> Now if you stare at the numbers a bit, you will find some downsides in declaring Vanilla the winner in this election of the flavors.</p>
<p>An obvious one is that more votes were cast for a flavor that is not the winning flavor. You could also argue that no flavor should win because none of them reached a majority.</p>
<p>Here Strawberry is acting as a <strong>spoiler</strong> ‚Äî similar to how third-party candidates in US elections can be considered spoilers. Maybe we should have a <strong><em>run-off election</em></strong> where only Vanilla and Chocolate are considered. Perhaps more people favor Chocolate over Vanilla when Strawberry is out of the picture. (The US state of Georgia has rules akin to this. In the 2020 elections for the senate seats in Georgia, none of the candidates achieved a majority. So run-off elections will be held in January of 2021 with the top two candidates).</p>
<p>The essence of the Plurality voting system is that it does not capture the full spectrum of voters' preferences. If someone voted for Strawberry, it does not tell us how they feel about Vanilla or Chocolate.</p>
<p>This system does not truly determine the <em>'will of the people'</em>, unless.... there are only two candidates. One of the candidates is guaranteed to receive a majority, barring a tie. So if it were truly a <em>two-party system</em> some of the flaws of this system do not matter any more.</p>
<h2>Ranked Choice Voting</h2>
<p>Since the Plurality based system does not capture the full spectrum of the voter's preferences, we should probably ask for more information from the voters. What if we asked the voters to rank all the candidates, rather than cast a ballot for their favorite?</p>
<p>Let's look at the example we've been working with. We asked the 100 people to rank the candidate flavors. Here's the result:</p>
<table>
<thead>
<tr>
<th>1st</th>
<th>2nd</th>
<th>3rd</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>Strawberry</td>
<td>Chocolate</td>
<td>45</td>
</tr>
<tr>
<td>Strawberry</td>
<td>Chocolate</td>
<td>Vanilla</td>
<td>15</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Strawberry</td>
<td>Vanilla</td>
<td>30</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Vanilla</td>
<td>Strawberry</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>All of the 45 people who voted for Vanilla had Strawberry as the second choice. All 15 people who voted for Strawberry, had Chocolate as their second choice. Of the 40 people who voted for Chocolate, 30 preferred Strawberry over Vanilla, and 10 preferred Vanilla. So, which flavor won? There are multiple ways to interpret this data. Let's look at a couple üëá</p>
<h2>Borda Count</h2>
<p>In this system for <code>n</code> candidates, each first-place vote receives <code>n</code> points. Second-place receives <code>n-1</code> points, and so on. The candidate with the most points wins.</p>
<p>Let's compute the points in our example. Vanilla received 45 first places, 10 second places, and 45 third places. So the score for Vanilla is <code>45n + 10(n-1) + 45(n-2)</code>. Here, <code>n</code> is <code>3</code>, giving Vanilla a score of <code>200</code>. Here's the final tally:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Points</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>200</td>
</tr>
<tr>
<td>Chocolate</td>
<td>195</td>
</tr>
<tr>
<td>Strawberry</td>
<td>205</td>
</tr>
</tbody>
</table>
<p><strong>Strawberry has won!</strong> Strawberry, which had the fewest votes in the Plurality voting system, has the most points in the Borda ranking system. Totally ridiculous, isn't it? Well maybe, but maybe not. Strawberry did receive the fewest third-place votes. And 75% of the people had Strawberry as their second choice.  Perhaps Strawberry does deserve to win!</p>
<h2>Instant Runoff Voting</h2>
<p>Let's take a look at a different model of interpreting the ranked voting data. In an Instant Runoff, the candidate with the fewest first-place votes is eliminated, and its votes are distributed to the second choice. This is then repeated until we have one candidate left standing.</p>
<p>Some consider this model of iterative elimination a bit confusing and thereby not practical. But it's getting wide adoption, including in political elections (San Francisco and Oakland city elections, for example). It is also used to decide the winner of the Best Picture Academy Award.</p>
<p>Let's apply this to our current example.</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry (eliminated)</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Strawberry is eliminated. Since all Strawberry voters preferred Chocolate over Vanilla, Chocolate gets Strawberry's 15 votes. Chocolate now has 55 votes, a majority. <strong>Chocolate has won!</strong></p>
<h2>Quick Recap</h2>
<p>We have discussed three systems so far, and in our example, we have had three different winners for the same election. You may decide subjectively that one of these systems may be better for the use case you have in mind, or you might think as I did at first: <strong>It's all pointless!</strong></p>
<h2>The Impossibility</h2>
<p>There is a concept in decision theory called the <strong><a href="https://en.wikipedia.org/wiki/Independence_of_irrelevant_alternatives">Independence of Irrelevant Alternatives (IIA)</a></strong> which states a voter's preference between two choices <code>x</code> and <code>y</code>, should not depend on any other choices.</p>
<p>This seems like a simple and a good rule to live by and our election systems should live by them as well. Sadly, all the systems we have looked at so far do not abide by this rule.</p>
<p>Let's look at the Plurality system - From the rankings we know that all of Strawberry voters prefer Chocolate over Vanilla. If the choice of Strawberry was not there, Chocolate would have won with 55 votes. But with Strawberry present, Vanilla wins with 45 votes.</p>
<p>For the Borda system, Chocolate is the spoiler. With Chocolate in the picture, Strawberry wins. Without Chocolate, Vanilla wins 55-45.</p>
<p>In the Instant Runoff, Chocolate wins when Vanilla is present but Strawberry wins 60-40 if Vanilla is not.</p>
<h3>Arrow's Impossibility Theorem</h3>
<p>In decision theory, here are some good things to have in an election or any voting system.</p>
<ul>
<li>Independence of Irrelevant Alternatives: which we have discussed and failed to account for so far.</li>
<li>Nondictatorship: Output should not be based on one individual, the wishes of multiple voters should be taken into consideration.</li>
<li>Pareto Efficiency (Unanimity): should have a notion of <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">unanimity</a> ‚Äî If every voter prefers candidate A over candidate B, candidate A should win.</li>
<li>Unrestricted Domain: Voting must account for all individual preferences.</li>
<li>Ordering:  Each individual should be able to order the choices in any way.</li>
</ul>
<p>All good rules, don't you think? Let's create the ultimate voting system! But here comes <a href="https://en.wikipedia.org/wiki/Kenneth_Arrow">Kenneth Arrow</a> to shatter our hopes.</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Arrow's_impossibility_theorem">Arrow's Impossibility Theorem</a> states that in all cases where preferences are ranked, it is impossible to formulate a social ordering without violating one of these rules.</strong></p>
<p>In other words, any democracy that satisfies Unanimity and the Independence of Irrelevant Alternatives, must be a dictatorship! *<em>insert dramatic sound effects</em>*</p>
<p>So yeah, we will always find things to argue about in an election. üòí</p>
<h2>Dodging the Impossibility</h2>
<p>Since every system is flawed, is it the end of this essay? Unfortunately for you, I, like many of you, noticed this one clause in Arrow's impossibility theorem which provides a way for us to escape this gravity well.</p>
<p>The theorem assumes that we are dealing with a ranked choice voting system. Let's just not rank our candidates. üí°</p>
<p>Here I would remind you, that we're trying to look at voting systems in general, not just political elections.</p>
<p>We have implemented non rank based systems in Software numerous times. Think Netflix, Yelp, Reddit, Tinder. The key as you may have guessed is rating, and not ranking (Tinder being a more specific type of rating - approval voting, which I'll discuss later). A voting system based on rating is usually called <strong>Score Voting</strong>.</p>
<h2>Score Voting</h2>
<p>The idea behind score voting is that you give each candidate a score in one or many categories. This score is independent of the score the other candidates receive. Think Diving and Gymnastics in the Olympics. The judges rate each athlete based on form, routine, landings. One with the highest total score wins.</p>
<p>But is this system better? That's subjective but we know it lets us escape the impossibility mathematically, and yet conform to independence, unanimity and nondictatorship rules.</p>
<h2>Approval Voting</h2>
<p>There's a simpler form or Score Voting - Approval Voting. Think of it as a binary version of the score voting. Each person can give a candidate a score of <code>0</code> or <code>1</code>. In other words one can approve or disapprove any number of candidates.</p>
<p>This is similar to how people vote on dating apps like Tinder. They give prospects a score of <code>1</code> by swiping right, and a score of <code>0</code> by swiping left.</p>
<h2>Strategizing the Ranked Vote</h2>
<p>One key advantage for Score Voting and Approval Voting is that it never hurts to vote for your favorite candidate. It may seem obvious and trivial but it's not always satisfied by voting systems. For example, it is common in political elections for people to not vote for the third-party candidate even though the third-party candidate may be the voter's first ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shihn.ca/posts/2020/voting-systems/">https://shihn.ca/posts/2020/voting-systems/</a></em></p>]]>
            </description>
            <link>https://shihn.ca/posts/2020/voting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053892</guid>
            <pubDate>Wed, 11 Nov 2020 00:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exodus of Silicon Valley]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25052818">thread link</a>) | @Reedx
<br/>
November 10, 2020 | https://breakingground.us/exodus/ | <a href="https://web.archive.org/web/*/https://breakingground.us/exodus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4180">
					
					
					
					
					<div>
					<p>On the day the sun didn‚Äôt rise in San Francisco, the early warning signs came through the screen. The 6:30 a.m. Zoom always requires unnatural light, making the outlines of faces fuzzy. The natural morning light, combined with the ‚ÄúTouch Up My Appearance‚Äù feature on 2020‚Äôs preferred video conferencing system, hides the marks of age and sleeplessness that most of us seek to mask. But by 9:00, the fluorescent light was still dominating the screen, and the darkness outside our windows had turned to infernal orange.</p>
<p>The scientific explanation for our sunless day in September is pretty dull. The clouds of soot from the largest California wildfire in history intermixed with the Bay Area‚Äôs perennial fog, turning the usual sepia hue of dirty global cities into an apocalyptic blood-orange sky. Though Twitter blamed the hellscape on far more menacing forces, the direct cause of our Blade Runner Day was mostly carbon clinging to the blue-light hues while letting the red pierce through.</p>
<p>If we were more like ancient peoples, many joked, we would assume the gods were enraged. We‚Äôd be running for the hills to escape their wrath, or at least head straight for our prepper bunkers. That we are unlike ancient people is actually the only myth, as this is exactly the exodus that is happening in Silicon Valley right now‚Äîand will continue for the next few years as true believers deliver themselves from this promised land.</p>
<p><a href="https://breakingground.us/from-ashes/">It‚Äôs time to build</a>, yes. But it‚Äôs also time to leave.</p>
<p>The battle over tech‚Äôs supremacy has been waged and all of our premonitions came true: We wanted flying cars and got vertical take-off innovation hubs from every car maker in America. Software has not only eaten the world, but feasted on your screen-weary eyes. It has swallowed your children, your church, your bank, and your politics, and somehow it all feels inevitable. That these feats of human progress‚Äîof instant connectivity in a now homebound world‚Äîbecame the scapegoat of our time is another symptom of the era‚Äôs end, cueing the quiet exodus of builders who had bigger aspirations than the same-day shipping that keeps our households afloat.</p>
<p>Now, Silicon Valley is witnessing a reckoning, but it‚Äôs not the long-awaited one predicted by the New York press, or the antitrust bonanza that Washington longs for because too many people seem satisfied getting their news from Facebook. The reckoning is more of a realization that tech exceeded expectations and somehow squandered the fruit of its own garden, and that a city on a hill that could have supported so much innovation was not Florence in the Renaissance nor the Athenian Academy with MacBooks. Rather, it became a government-sponsored needle exchange, a haven for the homeless and forgotten that put government‚Äôs paralysis on display downtown on Market Street.</p>
<blockquote><p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p></blockquote>
<p>San Francisco had four times as many deaths from overdose this year as it did from the COVID-19 virus.</p>
<p>2020 is not the great reckoning predicted in the book of Revelation, despite the fires, the plagues, and the wailing on Twitter. It is the resignation and determination of Exodus, of a dogged people packing up U-Hauls and fleeing this frontier state to seek an even newer, more eternal world.</p>
<p>* * *</p>
<p>The computer revolution of the late twentieth century has yet to be named as an epoch, but we can assume that nomenclature will begin in the coming years, alongside the battle for what it all really meant.</p>
<p>What we now call our ‚Äútechnological age‚Äù was supposed to be a full-throated and enduring argument for the future, not unlike previous epochs in history that pushed art, science, philosophy, and religion forward in dizzying ways that run counter to ordinary time. The Enlightenment. The Renaissance. The French Revolution. These movements now sit as categories on our bookshelves with clear beginnings and ends, and more importantly, clear hubs and cities of frenetic building that drove the ethos forward. Many books assume that contemporary critics or philosophers were blissfully ignorant to the unraveling of their revolutions, but we should not assume that contemporaries did not feel the same twilight setting. The figurative orange skies always creep in before dawn.</p>


<p>Which brings us to the supposed death of Silicon Valley, a fate that has long been predicted but with data now finally catching up. San Francisco apartment rents in 2020 have deflated by 20 percent after an up-up-and-away decade that made the city truly unlivable. Home inventory has reached a fifteen-year high in a city blighted by restrictive housing policy that makes construction cranes as miraculous as stumbling upon a burning bush. The growth in online sales-tax collection, according to the <em>San Francisco Chronicle</em>, is the lowest of all counties in the state of California. And public tech companies, such as Pinterest, paid upwards of $90 million to break its lease in downtown San Francisco. Some would argue this is a clear end to Bay Area tech dominance, while others would point to the many new unicorns that popped up this year despite the once-in-a-century pandemic. No one‚Äôs living here, yet somehow the companies are still growing.</p>
<p>Silicon Valley doesn‚Äôt really have cultural critics to weigh in on whether this era is officially over, but we do have venture capitalists. And our Nostradomuses are telling us that change is afoot.</p>
<p><em>Do we really need this office? The founders all have left.</em></p>
<p><em>Their entire partnership is now living in Montana. It‚Äôs only a two-hour flight away!</em></p>
<p><em>Denver seems like a good option, but Reno has no state income tax.</em></p>
<p>The weirdness of this exodus is that it is not driven by fear. Technologists weren‚Äôt <em>really </em>driven out by plague or fire or San Francisco‚Äôs insatiable need for higher tax revenue. Those ills were always apparent, and yet people stayed to carry the torch.</p>
<p>The exodus of tech‚Äôs true believers may be that the covenant is finally fulfilled. That when America‚Äîalong with the rest of the world‚Äîmet their darkest hour and turned inward, the technology that was long ridiculed as frivolous or dangerous led us to relative normalcy. The Zooms. The Tiger Kings. The Signal chats. The Slack jokes. An election news cycle that plowed ruthlessly forward on Twitter. Though inconvenient, mothers and fathers set their children in front of screens to occupy them for <em>just</em> long enough to survive a terrible year. And maybe, just maybe, the same-day-shipping racket that made Jeff Bezos the richest man alive was actually a feat of human genius that held the country together when public infrastructure and the social fabric were fraying at the seams. Perhaps our lowly software revolution was actually the fruition of a long-held California dream, when the physical world forced us inside and virtual life prevailed.</p>
<blockquote><p>Silicon Valley is no longer a place, they‚Äôll say. It‚Äôs a way of being, of building, and the latest embodiment of belief in human progress. And it‚Äôs spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p></blockquote>
<p>For that triumph, the nerds can now smell the impending scapegoating of their success. And like so many of history‚Äôs prophets and heretics, those who believe most fervently in the promise of technology are beginning their long march away from the Valley.</p>
<p>And they will substitute the virtual world for the physical space that once defined this movement. Silicon Valley is no longer a place, they‚Äôll say. It‚Äôs a way of being, of building, and the latest embodiment of belief in human progress. And it‚Äôs spreading faster than the viruses and the wildfires and the apocalyptic threats that mire our physical world.</p>
<p>Silicon Valley is over. The exodus is just beginning.</p>
					</div> <!-- .entry-content -->

				
				</article></div>]]>
            </description>
            <link>https://breakingground.us/exodus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052818</guid>
            <pubDate>Tue, 10 Nov 2020 22:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top 10 Most Important SQL Commands to Know]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052742">thread link</a>) | @jackmcclelland
<br/>
November 10, 2020 | https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <figure><img src="https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/SQL-Cheat-Sheet.png 600w, https://blog.arctype.com/content/images/size/w1000/2020/11/SQL-Cheat-Sheet.png 1000w, https://blog.arctype.com/content/images/2020/11/SQL-Cheat-Sheet.png 1440w"></figure><p>As companies and organizations find themselves dealing with rapidly increasing amounts of data, there's a growing need for developers to effectively use databases to handle this data. SQL, which stands for Structured Query Language, is a programming language that helps manage data stored in relational databases (a popular type of database).</p><p>SQL commands can help a developer create tables, add and modify data in these tables, search the database, and more. This article will cover a list of ten basic SQL commands that are essential to know for developers working with SQL. You'll find for each SQL command a code snipped and brief description of what the code runs.</p><p>Whether you're a beginner or a pro at SQL, consider trying out <a href="http://arctype.com/"><strong>Arctype</strong></a>, a redesigned SQL client for PostgreSQL and MySQL developers and teams. It's free, fast, and easy-to-use: <a href="http://arctype.com/" rel="noopener noreferrer">http://arctype.com/</a></p><p>Let's get right into it! Here are ten basic building blocks of SQL programming.</p><hr><!--kg-card-begin: markdown--><h2 id="createtable">CREATE TABLE</h2>
<pre><code>CREATE TABLE table_name (
  column_1 datatype_1, 
  column_2 datatype_2, 
  column_3 datatype_3
);
</code></pre>
<!--kg-card-end: markdown--><p>This command allows you to create a new database or table; the example above adds a new table with a title and column names.</p><!--kg-card-begin: markdown--><h2 id="altertable">ALTER TABLE</h2>
<pre><code>ALTER TABLE table_name 
ADD column_name datatype;
</code></pre>
<!--kg-card-end: markdown--><p>Run this command to modify (add, drop, rename, etc) the structure (not the data) in your database; the example above adds a new column to a table with a specified datatype.</p><!--kg-card-begin: markdown--><h2 id="delete">DELETE</h2>
<pre><code>DELETE FROM table_name
WHERE some_condition = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command can delete data from your table based on conditions specified with the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="drop">DROP</h2>
<p><code>DROP TABLE table_name;</code></p>
<!--kg-card-end: markdown--><p>Similar to the create command, DROP deletes a database or table. Be careful when using this command ‚Äì the code above will delete your whole table, including all data, indexes, and more.</p><!--kg-card-begin: markdown--><p><code>ALTER TABLE table_name DROP COLUMN column_name;</code></p>
<!--kg-card-end: markdown--><p>The ALTER TABLE and DROP statement above will remove a specific column from a table.</p><!--kg-card-begin: markdown--><h2 id="insertinto">INSERT INTO</h2>
<pre><code>INSERT INTO table_name (column_1, column_2, column_3) 
VALUES (value_1, value_2, value_3);
</code></pre>
<!--kg-card-end: markdown--><p>To add new records to your table, use the INSERT INTO command. You can use this command on one or more rows.</p><!--kg-card-begin: markdown--><h2 id="select">SELECT</h2>
<pre><code>SELECT column_name 
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Every query begins with SELECT; this is how you grab data from your database. It's the most fundamental SQL query. After the SELECT command, you can use the keyword FROM to specify a table, the keyword WHERE to select with conditions, and the keyword ORDER BY to sort your results.</p><!--kg-card-begin: markdown--><h2 id="update">UPDATE</h2>
<pre><code>UPDATE table_name
SET some_column = some_value
WHERE some_column = some_value;
</code></pre>
<!--kg-card-end: markdown--><p>This command lets you edit data in your table by updating data based on conditions specified after the WHERE keyword.</p><!--kg-card-begin: markdown--><h2 id="as">AS</h2>
<pre><code>SELECT column_name AS 'Alias'
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>The AS keyword allows you to use a temporary alias when referring to a column or table.</p><!--kg-card-begin: markdown--><h2 id="count">COUNT</h2>
<pre><code>SELECT COUNT(column_name)
FROM table_name;
</code></pre>
<!--kg-card-end: markdown--><p>Use the COUNT() function to add up the number of rows where the specified column is not NULL.</p><!--kg-card-begin: markdown--><h2 id="between">BETWEEN</h2>
<pre><code>SELECT column_name(s)
FROM table_name
WHERE column_name BETWEEN value_1 AND value_2;
</code></pre>
<!--kg-card-end: markdown--><p>This operator filters the results to be within a specified range (numbers, text, dates, etc).</p><hr><p>These building blocks will get you started programming with SQL, which is a great language useful and definitely worth learning in 2020. Check out the <a href="https://insights.stackoverflow.com/survey/2020">StackOverflow Developers Survey 2020</a>, where 65k developers answered questions about the programming languages and tools they run: SQL was top three in the most popular technologies question!</p><figure><img src="https://blog.arctype.com/content/images/2020/11/devdev.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2020/11/devdev.png 600w, https://blog.arctype.com/content/images/2020/11/devdev.png 900w" sizes="(min-width: 720px) 720px"><figcaption>If you're curious you can check out the rest of the results of the survey here at the URL here: <a href="https://insights.stackoverflow.com/survey/2020" rel="noopener noreferrer">https://insights.stackoverflow.com/survey/2020</a></figcaption></figure><p>Database programming languages are popular and have active developer communities, and are becoming increasingly important as organizations seek to process the thousands of terabytes of data generated each day. If you're working with databases in SQL or are planning on doing so, check out the newly-designed <a href="http://arctype.com/"><strong>Arctype</strong></a> SQL client. It's faster and easier-to-use than many of the clients out there right now and is designed with your needs in mind as a modern developer.</p><p>Thanks for checking out my article covering these ten basic SQL commands! Let me know if you have any questions, or would like me to write a follow-up post with more intermediate SQL commands to check out. Happy coding!</p>
            </div></div>]]>
            </description>
            <link>https://blog.arctype.com/sql-cheat-sheet-top-10-most-important-sql-commands-to-know/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052742</guid>
            <pubDate>Tue, 10 Nov 2020 22:12:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantopian's open-source investment dream died]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25052699">thread link</a>) | @ugwigr
<br/>
November 10, 2020 | https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p>Back in 2011, John Fawcett and Jean Bredeche had the dream of democratizing investing. They envisioned a platform that would make quantitative analysis and investment accessible and understandable for anyone who was keen to give it a try, kicking down doors for the everyman that had mostly been open to hedge funds or super-rich angel investors until that point.</p>
<p>Quantopian was launched off the back of that dream. A platform that taught users about quant investment and gave them a platform to write and save their own code, Quantopian was supposed to be the first crowd-sourced hedge fund. For years, users iterated on each other‚Äôs code as a community developed on the platform, full of users with and without financial backgrounds. These users would pit their algorithms against one-another, and Quantopian would go on to use the winning equations to manage investor assets, giving the winners some returns.&nbsp;</p>
<p>Fawcett and Bredeche would go on to raise $48.8 million for Quantopian in the meantime. In 2016, Steven Cohen announced that he would be teaming up with Quantopian to the tune of $250 million, relying on some of the user models Quantopian managed and investing in Quantopian itself.</p>
<p><span>In February, the first cracks in the city wall took hold. For at least two years, Fawcett said in </span><a href="https://www.bizjournals.com/boston/news/2020/02/20/fintech-firm-quantopian-is-returning-investors.html"><span>an interview</span></a><span>, Quantopian‚Äôs low-risk, market-neutral strategy model hadn‚Äôt been yielding results. Fawcett and Bedeche announced that the company would be returning investor money and switching strategies in an attempt to keep things afloat, </span><a href="https://www.quantopian.com/posts/quantopian-strategic-pivot"><span>asking that users</span></a><span> now develop models beyond the market-neutral ones the company had relied on for years.</span></p>
<p>Now, the dream is dead.</p>
<p><span>This week, Quantopian </span><a href="https://www.quantopian.com/posts/quantopians-community-services-are-closing"><span>abruptly announced</span></a><span> that it would be shutting down its community services and that users would lose access to all their materials if not saved locally by November 14. No reason was given for the shutdown.&nbsp;</span><span>Quants across the finance community expressed equal parts shock and disappointment that Quantopian had </span><a href="https://www.linkedin.com/posts/dr-tom-starke-a0a9a3b3_tribute-to-quantopian-activity-6728150978325045248-Lrsf/"><span>come crashing down</span></a><span>.&nbsp;</span></p>
<p>‚ÄúOur mission was to break open quant finance and make it accessible to everyone,‚Äù Fawcett wrote in a blog post on Quantopian‚Äôs website. "You helped realize this mission and came together to form the biggest community of quants the world has ever seen. For that, I am extremely proud and grateful. I sincerely hope that Quantopian is just one milestone in your journey through quantitative finance.‚Äù</p>
<p>The announcement was met with mixed reception. Some users gave tearful goodbyes to the platform and expressed interest in crowdfunding the site, while others expressed outrage at the seemingly abrupt decision.&nbsp;</p>
<hr>
<blockquote>
<h2>"Was there a heads-up so we could retrieve our results? backtests? :("</h2>
</blockquote>

<blockquote>
<h2>"My god no. is there any way to save the quantopian community site ??? why is this site closing down???"</h2>
<h2>"0-day notice! Are you kidding me &gt; where is all the code ???"</h2>
</blockquote>
<hr>
<p>Fawcett gave no answers. Users wondered the extent to which Quantopian would disappear; would the lectures and learning resources be preserved online somewhere? Would they be able to recover assets of theirs which had already been taken down? Where would they go to chat and organize with other quants and finance junkies?&nbsp;</p>
<p>The name Quantopian gave itself proved to be an ominous foreshadowing of its eventual fate. All utopias must fall, and Quantopian‚Äôs democratic dream had turned to sand and fallen through users' fingers before they could come to grips with what was happening.&nbsp;</p>
<p><span>In 2020, Quantopian‚Äôs dream of ‚Äúdemocratizing finance‚Äù isn‚Äôt unique. Trading app Robinhood touts </span><a href="https://robinhood.com/us/en/support/articles/our-mission/#:~:text=Robinhood's%20mission%20is%20to%20democratize,for%20newcomers%20and%20experts%20alike."><span>the exact same mission</span></a><span>, and it‚Äôs trying to pick up where Quantopian left off. Yesterday, Fawcett announced that Quantopian and Robinhood would be </span><a href="https://www.quantopian.com/posts/were-joining-robinhood"><span>coming together</span></a><span> in what he described as a natural fit for the two companies.&nbsp;</span></p>
<p><span>‚Äú</span><span>Quantopian has always stood for greater access and deeper education, so we are fundamentally aligned with Robinhood‚Äôs mission to democratize finance for all,‚Äù Fawcett wrote. ‚ÄúOur merry band of Quantopians should fit right in as we work together to further expand access to financial information and education, and inspire greater participation in the financial markets.‚Äù</span></p>
<p>Fawcett offered little details as to how this deal would take form, but one thing was clear: the Quantopian of old would no longer exist.</p>
<p>These platforms are more than the sum of their parts, and Quantopian‚Äôs community structure ‚Äî the factor which most makes it unmistakably itself ‚Äî will not be preserved by Robinhood.&nbsp;</p>
<p>Robinhood has grown to considerable size and been downloaded by an ever-increasing number of users during the COVID-19 pandemic who are using it to invest and, hopefully, make a little extra money during trying times. Or, if they‚Äôre lucky enough, make it big.&nbsp;</p>
<p><span>But although Robinhood shares the same mission as Quantopian at first glance, it is propped up on something much uglier than Quantopian ever was. Robinhood lacks a community element, and what implementations it has tried have had </span><a href="https://fortune.com/2020/08/10/robinhood-popularity-data-robintrack-stock-market-trading-tracker/"><span>disastrous impacts</span></a><span>. A read through the replies to Quantopian‚Äôs shutdown announcement reveal the deep histories users had on the platform.</span></p>
<p>‚ÄúWithin a few months after joining in 2016, I'd learned Python, programmed all of my Excel-based strategies, entered and won Contest 22, [and] started live trading in IB,‚Äù user Roman Parker wrote. ‚ÄúWith no relevant degree or experience, I was interviewing at large NYC funds. Q was changing my life.‚Äù</p>
<hr>
<blockquote>
<h2>"Never in my life have i seen a place where so many smart people were willing to share so much information with me without expecting anything in return. I am and will forever be grateful for what you have done for me." ‚Äî Quantopian user Mattias Lamonte</h2>
</blockquote>

<hr>
<p>The communities that have sprouted up around Robinhood‚Äôs success are much darker. Communities like r/wallstreetbets and viral videos like the infamous ‚Äú<a href="https://www.youtube.com/watch?v=A-tNkuYV4_Q">wsb yolo</a>,‚Äù which shows a man losing tens of thousands of dollars on the app in real time, keep sincerity at an arm‚Äôs length and sustain themselves with desperate humor. Though the output of Quantopian‚Äôs community was ultimately gobbled up by Quantopian itself and its investors, what Quantopian provided to its users was collaboration and experience. Robinhood‚Äôs frenzy is about who can win big, and who can lose bigger.</p>
<p><span>Even if the business end couldn‚Äôt keep itself afloat, the utopia existed, for a time, for the site‚Äôs users, many of whom had their lives and careers changed by Quantopian‚Äôs open platform and its catalog of resources. Today, other services like Quantiacs and QuantConnect operate off similar models to Quantopian‚Äôs. The first to do something isn‚Äôt always the best to do it, and perhaps one of these companies will perfect what Quantopian initially set out to do.</span></p>
<p>These lives wouldn't have been impacted if Quantopian had not put out the rallying call, but ultimately, users didn't need Quantopian as much as Quantopian needed them.&nbsp;Quantopian gave them the first rocks and sticks, and the community used it to build cities. In the end, it was the failure of the company itself, not those who used its tools, to deliver on the promise that attracted such a large community to begin with.</p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/how-quantopian-died-shut-down-quant-investment-robinhood/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052699</guid>
            <pubDate>Tue, 10 Nov 2020 22:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Birth of Unix with Brian Kernighan [audio]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052605">thread link</a>) | @spinningslate
<br/>
November 10, 2020 | https://corecursive.com/brian-kernighan-unix-bell-labs1/ | <a href="https://web.archive.org/web/*/https://corecursive.com/brian-kernighan-unix-bell-labs1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>When you work on your computer, there are so many things you take for granted: operating systems, programming languages, they all have to come from somewhere. </span></p><p><span>In the late 1960s and 1970s, that somewhere was Bell Labs, and the operating system they were building was UNIX. </span></p><p><span>They were building more than just an operating system though. They were building a way to work with computers that had never existed before.&nbsp; </span></p><p><span>In today‚Äôs episode I talk to Brian Kernighan about the history of Unix.</span></p><p><span>‚ÄúIf you wanted, you could go sit in your office and think deep thoughts or program, or write on your own blackboard or whatever, but then come back to the common space when you wanted to.‚Äú ‚Äì Brian Kernighan </span></p><p><span>‚ÄúI found it easier to program when I was trying to figure out the logic for myself rather than trying to figure out where in the infinite stack of documentation was the function I needed. So for me, programming is more like creating something rather than looking it up, and too much of today‚Äôs programming is more like looking it up.‚Äù ‚Äì Brian Kernighan </span></p><p><span>‚ÄúIf what I find challenging or hard or whatever is also something that other people find hard or challenging or whatever, then if I do something that will improve my lot, I‚Äôm perhaps improving their lot at the same time.‚Äù ‚Äì Brian Kernighan</span></p><p><span><strong>Links:</strong></span></p><p><a href="https://www.cs.princeton.edu/people/profile/bwk" target="_blank" rel="noopener noreferrer">Brian‚Äôs Homepage</a></p><p><a href="https://www.amazon.com/dp/1695978552" target="_blank" rel="noopener noreferrer">Book: Unix: A History and a Memoir</a></p></div></div>]]>
            </description>
            <link>https://corecursive.com/brian-kernighan-unix-bell-labs1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052605</guid>
            <pubDate>Tue, 10 Nov 2020 22:01:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boring Tech Is More Fun]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25052491">thread link</a>) | @amzans
<br/>
November 10, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I‚Äôm often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn‚Äôt matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It‚Äôs an illusion that makes us feel like we‚Äôre fully in control of what makes or breaks the product.</p><p>Don‚Äôt get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you‚Äôre actually building, and sooner or later your business will hit this wall.</p><p>I‚Äôm not saying that software doesn‚Äôt matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you‚Äôre trying to solve and the resources you have at hand. There‚Äôs no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as ‚Äúpicking old technologies over newer ones‚Äù, but it doesn‚Äôt necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you‚Äôre trying to make a decision to increase the odds that your product or business will succeed, it‚Äôs worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it‚Äôs about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I‚Äôm happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I‚Äôd rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what‚Äôs important here, it‚Äôs more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That‚Äôs why I wouldn‚Äôt bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I‚Äôm being serious). But that‚Äôs for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It‚Äôs a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear‚Äôs tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25052491</guid>
            <pubDate>Tue, 10 Nov 2020 21:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051897">thread link</a>) | @csomar
<br/>
November 10, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven‚Äôt been using Rust for production much; maybe a bit more than a year. The static type checks means I‚Äôm getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn‚Äôt have a running syslog service by default.</p>

<p>Now that‚Äôs fine, the program functioned correctly. But I don‚Äôt care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let‚Äôs take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don‚Äôt want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that‚Äôs it. This code now compiles and runs correctly. If syslog is running, it‚Äôll write logs to syslog and the terminal. Otherwise, it‚Äôll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it‚Äôs perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>132</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>132</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051897</guid>
            <pubDate>Tue, 10 Nov 2020 21:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Messenger App Tutorial with Phoenix LiveView]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051678">thread link</a>) | @szsoppa
<br/>
November 10, 2020 | https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1 | <a href="https://web.archive.org/web/*/https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In a series of articles <strong>(don't forget to <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a>!)</strong>, we'll convince you that Phoenix LiveView will revolutionize the way you create reactive UIs!</p>
<h2>Why Phoenix?</h2>
<p>The thing about Elixir, on top of Erlang/OTP, is that it offers a great mix of making life easy and being a scalable and reliable platform that will not let you down when your estimated traffic of 4000 users becomes 4,000,000 users.</p>
<p><strong>Phoenix Framework</strong> is Elixir's answer to the never-ending question of how to build rich web applications, and it's got a lot of tools that make the job easy - one of the latest being <strong>Phoenix LiveView</strong>.</p>
<p>Long story short, <strong>LiveView is a tool that lets an Elixir developer create reactive UIs without writing a single line of JS code</strong>. Which is great, given that many Elixir developers do not exactly consider themselves fluent at JS, or - just like myself - are not exactly in love with JS.</p>
<h2>Lessons learnt from reactive UI libraries</h2>
<p>Many JavaScript frameworks, both contemporary and not-so-contemporary ones, rely on manipulating the page's DOM for dynamic content updates.</p>
<p>Historically, for instance, developers using BackboneJS would define a <code>Backbone.View</code> to represent an <em>atomic chunk of user interface</em>, behind which there's a <code>Backbone.Model</code>, encapsulating the business logic of data.</p>
<p>Backbone remained unopinionated about how views were to be rendered, so it had no built-in tools to make the re-rendering of views on model changes efficient - the whole structure of a view had to be built from scratch and replaced, which tended to yield inefficient views.</p>
<p>In contrast, modern frameworks such as ReactJS or Vue.js don't care about how the data model layer works at all (loosely coupled data stores such as Redux are often used for this) - but they have a <strong>virtual DOM</strong> concept - long story short, a pattern of incrementally upgrading only those elements that need to be changed, based on changes in the state of particular components and their children.</p>
<p><strong>The challenge, though, is pretty much down to how to exchange data between the UI and the backend.</strong> You will usually need to implement a JSON API or a GraphQL service, or perhaps you could develop a WebSocket-based solution using Phoenix Channels.</p>
<p>Either way, the <a href="https://en.wikipedia.org/wiki/Pareto_principle" target="_blank">Pareto 80/20 principle</a> will imminently catch you, and when you get to the 20% of work needed to finish off your message-passing code, it'll soon become a <em>framework within a framework</em>.</p>
<h2>Why, where &amp; how LiveView excels</h2>
<p>Phoenix LiveView's concept is both groundbreaking and familiar, in different ways.</p>
<p>It is familiar in that it lets you define UI elements as nestable components composed of pure HTML markup, and it builds upon the experience of reactive UI frameworks in implementing mechanisms that calculate diffs between consecutive UI states to ensure efficient updates.</p>
<p>It is groundbreaking in the way it maintains the states of components and manages their updates - <strong>in Phoenix LiveView, components are stateful on the server, and their events and updates are communicated via a bidirectional WebSocket connection</strong>.</p>
<p><strong>Phoenix LiveView is built on top of Elixir processes and Phoenix Channels</strong> - every LiveView instance is a BEAM process, acting very much like a <a href="https://hexdocs.pm/elixir/GenServer.html" target="_blank">GenServer</a>, receiving messages and updating its state.</p>
<p>While modern JS frameworks such as React have server-side rendering capabilities, it is usually not convenient to do this in a non-NodeJS backend server. Rendering content via JavaScript often results in SEO issues, and some trickery is needed for search engines to index the page correctly. <strong>In Phoenix LiveView, the initial render is static as in the classic HTML request-response cycle</strong>, so you'll get good <a href="https://developers.google.com/web/tools/lighthouse" target="_blank">Lighthouse scores</a> and it won't hurt your SEO.</p>
<p>Erlang easily maintains thousands of processes concurrently, and Phoenix authors have even <a href="https://phoenixframework.org/blog/the-road-to-2-million-websocket-connections" target="_blank">managed to make it handle 2 million WebSocket connections</a> on a single (albeit pretty strong) machine. With the server using Elixir's strengths to manage LiveView states, <strong>the client-side logic can be thin and simple</strong>.</p>
<p>In fact, as stated in the introduction, <strong>in most LiveView-powered apps you won't write a single line of JS code</strong>. In many cases, when interacting with an element whose update is supposed to fetch data for a new UI state from the server, the workflow using a reactive JS framework would be:</p>
<ol>
<li>Handle the element's <code>change</code> event
</li>
<li>Send a request to the server containing the actual changes
</li>
<li>Receive response and update state store based on response data
</li>
<li>Let the view layer re-render the changed DOM elements
</li>
</ol>
<p>This involves annotating HTML elements so that they can be identified by JS code, writing browser-side scripts to handle the element's state change event, send a payload to the server, which processes the request as part of a Phoenix controller action.</p>
<p><strong>With Phoenix LiveView, you only write HTML and Elixir code, with the JS part being handled by a script bundled with the LiveView package.</strong></p>
<h2>Phoenix LiveView basic usage</h2>
<p>The basic idea behind Phoenix LiveView is very simple and straightforward. <strong>Be sure to <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a> to learn more!</strong></p>
<p>LiveView is an Elixir behaviour, and your most basic LiveView definition will consist of two callback implementations:</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:render/1" target="_blank"><code>render/1</code></a> function, containing the template of how your component is represented in HTML, with elements of the component's state interpolated. This is much like defining an ordinary view. The special <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#sigil_L/2" target="_blank"><code>~L</code> sigil</a> is used to interpolate <code>assigns</code> into your EEx syntax, and convert it into an HTML-safe structure.
</li>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:mount/2" target="_blank"><code>mount/2</code></a> function, wiring up socket assigns and establishing the LiveView's initial state.
</li>
</ul>
<pre><code>  <span><span>defmodule</span> <span>YourappWeb.CounterLive</span></span> <span>do</span>
    <span>use</span> Phoenix.LiveView

    <span><span>def</span> <span>render</span></span>(assigns) <span>do</span>
      ~L<span>""</span><span>"
      &lt;a href='#' phx-click='increment'&gt;
        I was clicked &lt;%= @counter %&gt; times!
      &lt;/a&gt;
      "</span><span>""</span>
    <span>end</span>

    <span><span>def</span> <span>mount</span></span>(params, socket) <span>do</span>
      {<span>:ok</span>, assign(socket, <span>:counter</span>, <span>0</span>)}
    <span>end</span>
  <span>end</span></code></pre>
<p>However, the whole fun of using LiveView is managing its state, and the next two callbacks will come in handy.</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:handle_event/3" target="_blank"><code>handle_event/3</code></a> function, handling events coming <strong>from the browser</strong>. Noticed the <code>phx-click</code> attribute in our template's link? This is the name of an event that will be transported to the LiveView process via WebSockets. We'll define a function clause that will match to the event's name.
</li>
</ul>
<pre><code>  <span><span>def</span> <span>handle_event</span></span>(<span>"increment"</span>, params, %{<span>assigns:</span> %{<span>counter:</span> counter}} = socket) <span>do</span>
    {<span>:noreply</span>, assign(socket, <span>:counter</span>, counter + <span>1</span>)}
  <span>end</span></code></pre>
<p>  It will mutate the LiveView's state to have a new, incremented value of the counter, and the <code>render/1</code> function will be called with the new assigns.</p>
<p>  The second argument, here named <code>params</code>, is of special interest as well, because - in the case of a <code>phx-click</code> event - it contains the event's metadata:</p>
<pre><code>  %{
    <span>"altKey"</span> =&gt; <span>false</span>,
    <span>"ctrlKey"</span> =&gt; <span>false</span>,
    <span>"metaKey"</span> =&gt; <span>false</span>,
    <span>"pageX"</span> =&gt; <span>399</span>,
    <span>"pageY"</span> =&gt; <span>197</span>,
    <span>"screenX"</span> =&gt; <span>399</span>,
    <span>"screenY"</span> =&gt; <span>558</span>,
    <span>"shiftKey"</span> =&gt; <span>false</span>,
    <span>"x"</span> =&gt; <span>399</span>,
    <span>"y"</span> =&gt; <span>197</span>
  }</code></pre>
<p>  We trust that you won't now hesitate to try it out with a <code>&lt;form&gt;</code> tag and a <code>phx-change</code> attribute to see what event metadata are passed when a form element's value is changed. Either way, <strong>we'll explore this in more detail in later episodes of this tutorial - stay tuned and <a href="#c-newsletter" target="_blank">subscribe to our newsletter</a> so that you don't miss out</strong>!</p>
<ul>
<li>A <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#c:handle_info/2" target="_blank"><code>handle_info/2</code></a> callback, handling events coming from <strong>anywhere but the browser</strong>. This means events sent from external sources <em>(remember a LiveView is just an Elixir process, so you can do whatever's needed in order for it to receive messages!)</em>, or events sent from the LiveView to itself. For instance, it takes this to increment the counter every 5 seconds:
</li>
</ul>
<pre><code>  <span><span>def</span> <span>mount</span></span>(params, socket) <span>do</span>
    if connected?(socket), <span>do:</span> <span>:timer</span>.send_interval(<span>5000</span>, <span>self</span>(), <span>:increment</span>)

    {<span>:ok</span>, assign(socket, <span>:counter</span>, <span>0</span>)}
  <span>end</span>

  <span><span>def</span> <span>handle_info</span></span>(<span>:increment</span>, %{<span>assigns:</span> %{<span>counter:</span> counter}} = socket) <span>do</span>
    {<span>:noreply</span>, socket |&gt; assign(<span>:counter</span>, counter + <span>1</span>)}
  <span>end</span></code></pre>
<p>  To reduce code repetition, you could make <code>handle_event/3</code> send a message to <code>self()</code> that triggers the same <code>handle_info/2</code> routine.</p>
<p>You can now access your LiveView as a standalone route - to do this, put this in your <code>router.ex</code>:</p>
<pre><code><span>import</span> Phoenix.LiveView.Router

scope <span>"/"</span>, YourappWeb <span>do</span>
 live <span>"/counter"</span>, CounterLive
<span>end</span></code></pre>
<p>...or render the LiveView within any other template:</p>
<pre><code>&lt;%= Phoenix.LiveView.live_render(<span>@conn</span>, YourappWeb.CounterLive) %&gt;</code></pre>
<h2>The Curious Messenger Roadmap<a name="series" target="_blank"></a></h2>
<p>We'll make you familiar with how to wield the Phoenix LiveView sword, and you'll build a fully-fledged Messenger replacement, which will make you (almost) forget about any other instant messaging app you had ever used before...</p>
<p>Phoenix LiveView is obviously only part of the story, and there's a lot more ground that we'll cover. We'll do a few episodes, each of which touches a different set of concerns that we'll have to consider when designing the app.</p>
<ul>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-2" target="_blank">At the beginning, we'll bootstrap the app and install all needed dependencies, design the app's database and context structure, with all of the app's business logic in mind.</a>
</li>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-3" target="_blank">Then we'll implement the app's user authentication feature using Pow, a great library integrating all the tools you need to let users sign up and log into the application. Next, we'll go on to implement the actual awesome Curious Messenger features, and here's where most of the <strong>Phoenix LiveView</strong> magic will shine. We'll show you how to create a live-updated view of your contact list and of each of your conversations.</a>
</li>
<li><a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-4" target="_blank">Obviously, we'll also elaborate on what can go wrong when using LiveView, because the worst assumption one can make is that people's network connections are perfect. We'll see for ourselves that Phoenix LiveView is not the Holy Grail of reactive UI building solutions and that this approach has several shortcomings that need to be kept in mind.</a>
</li>
<li>Finally, we'll fine-tune the Curious Messenger app, adding some customizable settings and push notifications <em>(did we actually say there'll be no JS? We lied.)</em> so that you never miss out on any message from ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1">https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1</a></em></p>]]>
            </description>
            <link>https://curiosum.dev/blog/elixir-phoenix-liveview-messenger-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051678</guid>
            <pubDate>Tue, 10 Nov 2020 20:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Flaws of ‚ÄúSubscription Fatigue‚Äù, ‚ÄúSVOD Fatigue‚Äù, and the ‚ÄúStreaming Wars‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25051292">thread link</a>) | @bschne
<br/>
November 10, 2020 | https://www.matthewball.vc/all/misnomers | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/misnomers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-96dbb3b03808a860d80e"><div><p>When we consider the state of tech-media in 2020, there are a few common narratives. The most inescapable is the ‚ÄúStreaming Wars‚Äù. In November, I argued that <a href="https://www.matthewball.vc/all/minedmedia">this term was a misnomer</a>. Digital/streaming/OTT video is really just <em>a</em> battle in a much larger war: the ‚Äúecosystem war‚Äù. And for the most part, this war is fought asymmetrically. Apple and Amazon both sell digital media devices, third-party media content, and their own original content, for example. However, Apple isn‚Äôt an e-retailer nor a diversified enterprise cloud services provider, and Amazon doesn‚Äôt even have a smartphone, personal computer, watch or non-video app store. I‚Äôll come back to this idea, but understanding the differences between these companies and their motivations is helpful when considering two other popular phases that are unhelpful at best and misleading at worst: ‚Äúsubscription fatigue‚Äù and ‚ÄúSVOD fatigue‚Äù.</p><p><strong>‚ÄúSubscription Fatigue‚Äù</strong></p><p>The ‚Äúsubscription economy‚Äù, by definition, presumes that the overall ‚Äúeconomy‚Äù ‚Äì from products, to services, content, transportation, labor and more ‚Äì is shifting over to ‚Äúsubscriptions‚Äù. Thus, to claim that consumers have ‚Äúsubscription fatigue‚Äù is to say that they have ‚Äúspending fatigue‚Äù.</p><p>As always, most consumers will say they wish they spent less money, bought fewer things, and enjoyed lower prices. However, it makes little sense to say that the decision to buy TV subscriptions, radio subscriptions, toothbrush subscriptions, video gaming subscriptions, dog food subscriptions, car subscriptions, or productivity software subscriptions should drive ‚Äúsubscription fatigue‚Äù or mean each subscription competes with one another. For decades, consumers have bought TV, music, toothbrushes, video games, dog food, cars and Microsoft Office. What‚Äôs new is that they all have similar models ‚Äì digitally-based, predominantly D2C subscriptions. This changes nothing about the individual value or baseline need for them.</p><p>Of course, the ‚Äúsubscription economy‚Äù does mean that step one of a recession will be to ‚Äúre-evaluate all subscriptions‚Äù. However, this does not mean subscription <em>fatigue</em> should be considered a real ‚Äúthing‚Äù, let alone a defining element of modern-day competition. Furthermore, payment model ‚Äì upfront v. recurring, subscription v. √° la carte, online v. offline ‚Äì is irrelevant to what‚Äôs ‚Äúre-evaluated‚Äù and not. Some subscriptions are ‚Äúnecessities‚Äù, like toilet paper, while others are concerned with discretionary spend, such as Office 365 or Netflix or Tinder. This latter group isn‚Äôt competitive because they‚Äôre ‚Äúsubscriptions‚Äù, but because there is, as always, finite spending money for non-essential items. </p><p>To this end, it‚Äôs important to highlight subscriptions are often a <em>preferred</em> buying path for consumers. Most would rather (or can only afford) $10 a month for a multi-year license to Microsoft Office for $300. Subscriptions also meaningfully reduce the cognitive burden of repeat decision making. No longer do you need to ‚Äútrack‚Äù your toothbrush for wear, risk ‚Äúrunning out‚Äù of toilet paper and then be forced to overpay for a small-volume purchase, or need to scan and hoard coupons to ensure a great deal. Similarly, many consumers would rather marginally overpay for an all-you-can-eat subscription than optimize for specific tiers of use. In fact, most of us have caustic responses to per unit pricing, often to the point of irrationality (e.g. $40 for 35 loads of laundry detergent v. $1.00 per load). Amazon Prime is based on the <em>need</em> to get shipping fees out of the way once, versus fight them over and over and over and over, even if the effective shipping cost went up for a consumer, or the lack of shipping costs led to unnecessary purchases.</p><p>The rise of fully flexible monthly commitments also means that consumers no longer have to worry about having made a bad decision and being stuck with it. In this sense, every subscription is still √° la carte, but unlike in the analog era, the default outcome of ‚Äúdoing nothing‚Äù is to keep getting value you enjoy rather than running out of a thing you need. </p><p><em>(Note that none of this means that a digital subscription business is a ‚Äúgood‚Äù one. Many sub-categories of CPGs and foodstuffs, not to mention music or fitness equipment, weren‚Äôt good business before the shift to subscription. The fact they shifted to subscriptions doesn‚Äôt inherently change this, just as it doesn‚Äôt mean they suddenly compete with all other subscriptions).</em></p><p><strong>‚ÄúSVOD Fatigue‚Äù</strong></p><p>Of course, the nuances of ‚Äúsubscription fatigue‚Äù is separate from the question of ‚ÄúSubscription <em>VOD</em> fatigue‚Äù. It is obvious consumers don‚Äôt need 20 Netflixes. However, they‚Äôre not being asked to buy 20 Netflixes. It‚Äôs wrong to treat Fox Nation, Netflix, ESPN, and Twitch as competitors, let alone interchangeable ‚Äúunits of SVOD‚Äù. They serve very different functions and offer very different content. Just as Spotify and the <em>New York Times</em> and Amazon Prime shipping each do.</p><p>Amazon and Apple TV+, meanwhile, aren‚Äôt Netflixes ‚Äì not in monetization, content volumes, or strategy. Now, if Amazon or Apple‚Äôs SVOD services can monetize so dramatically better through the Prime and iOS ecosystem than Netflix can via direct consumer spend and a singular focus, they can, in theory, ‚Äúkill‚Äù Netflix ‚Äì should they so choose ‚Äì but that has nothing to do with SVOD fatigue nor the number of viable SVODs.</p><p>The question of SVOD fatigue isn‚Äôt about ‚Äúhow many SVODs will the average household have‚Äù. It‚Äôs really about ‚Äúhow many different roles are there to be played in video‚Äù. And the answer here is mostly path dependent ‚Äì it depends on the innovation, risk taking, and discovery that happens in the marketplace, as well as timing. No one knew ‚Äúlive streaming video games‚Äù was an opportunity until Twitch, for example. And while Twitch likely steals <em>time</em> away from the video ecosystem, the viability of the Twitch subscription doesn‚Äôt mean that the number of viable OTT services has reduced.</p><p><strong>The Question</strong></p><p>All of which is to say what matters in SVOD is simple and not unique to SVOD: <span>A service will succeed if (1) it addresses a real, outstanding customer want/need; (2) at an appropriate price or value to the consumer; and (3) while generating sustainable economics</span>. </p><p>Quibi is a good example here. The company believes that there is an outstanding need for a new type of content, focused on a different time and place, under a different viewing behavior and focused on a specific audience. If it is right, and it can build up a defensible leadership position before other players replicate it, a new subscription will be possible and it doesn‚Äôt matter how many SVODs a customer already has (just as whether they have NYT or Spotify doesn‚Äôt matter). But of course, if you ask consumers ‚Äúdo you wish you had fewer subscriptions‚Äù or ‚Äúfewer SVODs‚Äù, they will say yes ‚Äì especially if they don‚Äôt really know what the new ‚Äúthing‚Äù is. Note, too, that Pay-TV studies have been promising that 10%‚Äì30% of subscribers will cancel each year. They never do‚Ä¶ because enough value remains. </p><p>More broadly, this three-point framework is well established (it actually has nothing to do with video). Over the past forty years, we have seen countless examples of ‚Äúnetworks‚Äù launching into hyper-saturated marketplaces with hyper-specific but unproven (and often openly derided) theses regarding outstanding consumer wants and needs. Almost all of these have succeeded. In fact, they usually spawned several direct competitors ‚Äì showing that the unmet want was even larger than originally anticipated. &nbsp;</p><p>For example‚Ä¶</p><ul data-rte-list="default"><li><p><em>1972: HBO launched a network focused on the most valuable TV time, Sunday night, with an unprecedented monetization model (√° la carte consumer spend and no advertising), and focused only on reruns of Hollywood movies. It was ultimately bought by 25% of TV homes, became the most profitable network in the world and the market leader in quality. And this was despite the launches of Showtime (1976), Starz (1994) and Epix (2009).</em></p></li><li><p><em>1977: Nickelodeon launched 24/7 content only for kids. No longer was kids content relegated just to afternoon and Sunday morning blocks. In the 2000s, Nickelodeon became the most watched cable network, despite having spun-off several other Nick-branded channels and seen the launch of The Disney Channel in 1983.</em></p></li><li><p><em>1979: ESPN launched a 24/7 sports channel, ultimately with the highest programming budget in the world. In 2019, it brought in more than $2.5B in profits, with an annual revenue of roughly $9B. In 2009, Fox launched its own suite of 24/7 Fox-branded sports networks.</em></p></li><li><p><em>1980: CNN launched a 24/7 news channel. Today, it generates an estimated $800MM a year in cash flow on $2B in revenue, and several other 24/7 networks exist.</em></p></li><li><p><em>1981: MTV launched a 24/7 music video and culture channel that focused only on young audiences. The result was the first new Hollywood film/TV conglomerate in decades. Within years, MTV had launched several other 24/7 networks, while competitors launched even more focused versions, such as CMT.</em></p></li><li><p><em>1983: BET launched a 24/7 network focused on black American audiences. In 2001, the company was sold to Viacom for $3B. Several other black-focused networks exist today. </em></p></li><li><p><em>1996: Fox News launched a 24/7 news channel‚Ä¶ only for half of news watchers. It now generates more than $1.5B in cash on $2.5B+ revenue</em></p></li></ul><p>Of course, this sort of logic can be used to justify faulty assumptions around what opportunity exists, where, how large it might be, how durable it is, etc. In addition, these specifics gaps were open because of technological limitations. A network like ABC could only air one thing at a time ‚Äì and therefore there were structural impediments to serving ‚Äúeveryone‚Äù. Netflix, meanwhile, can air anything, at any time, to every viewer, and on an individual basis.</p><p>But the crucial point here is that it‚Äôs wrong to think about the ‚Äúnumber‚Äù of subscription video services, just as it was wrong to think about how ‚Äúmany‚Äù networks were in the cable bundle in 1980, 1985, 1990, and so on. In fact, it‚Äôs incredibly close ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/misnomers">https://www.matthewball.vc/all/misnomers</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/misnomers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051292</guid>
            <pubDate>Tue, 10 Nov 2020 20:18:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large-Scale Geo-Replicated Conflict-Free Replicated Data Types [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25051115">thread link</a>) | @simonebrunozzi
<br/>
November 10, 2020 | https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf | <a href="https://web.archive.org/web/*/https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gsd.inesc-id.pt/~ler/reports/carlosbartolomeu-midterm.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25051115</guid>
            <pubDate>Tue, 10 Nov 2020 20:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Middle Management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050928">thread link</a>) | @duck
<br/>
November 10, 2020 | https://boz.com/articles/middle-management | <a href="https://web.archive.org/web/*/https://boz.com/articles/middle-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p>There is an old saying in business that people don‚Äôt leave a job, they leave a
manager. I have found this to be generally accurate. But in my experience the
next most likely person to influence them isn‚Äôt their manager‚Äôs manager. It
is the CEO. </p>
<p>One reason I think middle managers so often feel like they are in no-man‚Äôs
land is because, well, they are. This is a chart I made up of how valuable a
connection is from each person to the various levels of management above
them.</p>
<p><img src="https://boz.com/middle-management.png" alt="horseshoe chart"></p>
<p>The ennui many middle managers feel at the trough of this diagram is
understandable. To the team you are the voice of management. But to
management you are the voice of the team. When I was at the nadir of this
chart in my own career it was the closest I came to leaving Facebook.</p>
<p>Eventually I managed to sort out a few strategies that helped me genuinely
enjoy middle management.</p>
<p>First, take pride in your job as the central link in the chain. Be an
efficient conduit of information in both directions. Don‚Äôt create any
friction in either direction unless you are sure you have unique value to
add. Too many middle managers create a layer for themselves when it isn‚Äôt
necessary which slows things down and is a form of value add disease.</p>
<p>Second, use this opportunity to sharpen your skills managing managers and
information flows. Those will be your core responsibilities for the rest of
your career from this point forward. </p>
<p>With those basic responsibilities sorted, you will find that this position in
the value chain allows you to identify opportunities nobody else sees. While
employees and senior leadership align on the work, you are effectively left to
operate the machinery by which work gets done. You have purview over the
processes that enable communication, escalation, and decision making. </p>
<p>As you advance in your career these things start to become obfuscated as
people push them below the surface to cater more to you. But they are always
there, as a hidden form of gravity that you will recognize if you invest the
time now. When teams slow down or drift from their mission, this is where the
problem is. When scope creeps or execution lags this is usually the first
place to look. I think this is one reason managers who were developed
internally often outperform those who arrived on top of an organization. It
helps if the machinery of progress isn‚Äôt entirely an abstraction.</p></section></div></div>]]>
            </description>
            <link>https://boz.com/articles/middle-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050928</guid>
            <pubDate>Tue, 10 Nov 2020 19:55:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 questions for writing]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050838">thread link</a>) | @flreln
<br/>
November 10, 2020 | https://vasilishynkarenka.com/8questions/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/8questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/11/angelina-litvin-K3uOmmlQmOo-unsplash.jpg" alt="8 questions for writing">
            </figure>

            <section>
                <div>
                    <p>You cannot write productively if you do not have a plan.</p><p>That‚Äôs why most people struggle with writing: they have an idea to communicate but no specific plan of action to express their thought. As a result, they either procrastinate and never begin writing in the first place, or they hit writer‚Äôs block and spend hours staring at a blinking cursor on the top of a blank page.</p><p>The reason why people don‚Äôt plan writing is counterintuitive. They <em>think</em> they know how to write because they know the alphabet. But just like learning how to drive Toyota Prius in the suburbs doesn‚Äôt make you Michael Schumacher on track, knowing how to write symbols doesn‚Äôt make you a professional writer. You need to learn the skill.</p><p>The secret to good writing, as to any kind of knowledge work, is deliberate planning. If you do not have a plan, writing becomes a mysterious process you do only when you‚Äôre inspired. But if you document what you‚Äôre going to do, writing turns into a professional act with less opportunity for sloth. And the best way to plan writing is to ask questions.</p><p>If you think about something proactively, you run two mental processes at once. First, you keep the subject of your thought in your working memory. And second, you actively search through your mind for the object of interest. That‚Äôs a problem, given how much effort it takes to stay focused on a task.</p><p>But if you present yourself with a question, you change that. When you write the question down and look at it, you stay focused for longer. You benefit from your sensory channels to stay engaged, and you also run one mental process instead of two.</p><p>That‚Äôs why I‚Äôve built a simple routine of asking myself a set of questions about what I‚Äôm planning to write. I apply it whenever I experience an itch like, ‚ÄúOh, I could write an article about this!‚Äù After running the process for two months, I‚Äôve empirically discovered how important it is to capture the idea right at the moment when it‚Äôs being formed. If I don‚Äôt turn my thought into an objective artifact that I can revisit later, I lose it.</p><p>Here are five reasons why questions work so well for writing:</p><ol><li>Good questions are like an advanced Google Search query to your mind. They have high suggestive value because the parameters that you pass to a question light up relevant areas of memory for you. If you do not have a question in mind and just roam through ideas, you‚Äôre like a first-time Google user who blindly presses ‚ÄúI‚Äôm Feeling Lucky‚Äù all the time.</li><li>Questions exist in the physical world. When you write a question down, you can get back to it later and think about it again. If you do not write your thought down, it will fly away from your unstable working memory, and you may never get into the same situation that triggered that thought in the first place. As it‚Äôs tough to trace back the system one thinking [1], you‚Äôre way better off writing things down.</li><li>Questions are discovery satellites for new knowledge. The best thing about questions is that you can ask yourself something you do not yet know. When you write down a problem with no answer, you may revisit it later and add new information as you develop more understanding. More interesting and less obvious is that asking yourself questions for which you have no answers triggers curiosity and programs your subconscious to think about it in the background.</li><li>Questions convince yourself that your work is important. This may sound trivial at first, but I‚Äôve discovered that if I don‚Äôt have a decent argument why what I‚Äôm writing is important, I produce bad writing or get stuck in writer‚Äôs block. And it‚Äôs way easier to stay convinced that what you‚Äôre doing matters if you documented the reasons on paper ‚Äì you can get back to your questions and get inspired when things get tough.</li><li>Questions help you avoid obvious mistakes. In many professions, checklists are a must. If you‚Äôre a pilot or a surgeon, you spend years mastering simple procedures because you don‚Äôt have time to do system two thinking when you have a problem in the field. You need to have already thought. I believe writers benefit from checklists even more because writing is considered to be a creative act, and most creative tasks usually benefit from systemic approaches and vice versa.</li></ol><p>Below are the questions I routinely ask myself when I‚Äôm profiling an idea.</p><h2 id="1-why-do-i-want-to-write-this-article">1. Why do I want to write this article?</h2><p>When you answer that question, you will discover the <em>actual</em> problem that you want to solve with the piece. Often, the problem will be different from the original idea of the article. If you have experience with the topic, you‚Äôll likely see a better solution, a different angle of attack you can use to solve a reader‚Äôs problem.</p><p>For example, when I started <a href="https://vasilishynkarenka.com/learning/">my work on learning</a>, the original idea was to produce a theoretical piece describing the research that I‚Äôve done. But when I answered the first question, I realized that my work aims to help a reader improve their learning process, and the best way to do that would be to write a description of my own process and embed principles into it of preaching theories.</p><p>The answer will often contradict the initial idea that you‚Äôve come up with. That‚Äôs fine ‚Äì just update the idea. What you must avoid doing is continuing with the initial plan if you‚Äôve clearly discovered a better one after answering the question. Even if you already have the draft done, you must rewrite the whole thing because your job as a writer is to not waste reader‚Äôs time.</p><p>Here‚Äôs how I defined the ‚Äúwhy‚Äù for this work:</p><blockquote>Q: Why do I want to write this article?<br>A: I want to help people improve their writing process by adding a simple routine of asking questions.</blockquote><p>The ‚Äúwhy‚Äù question is also a test for abstractions. If you do not have a concise answer, you will find yourself attempting to write an all-covering piece. Avoid that mistake and define the purpose of the work first.</p><p>If you cannot answer the question, do not write this article.</p><h2 id="2-what-do-i-want-to-write-about">2. What do I want to write about?</h2><p>The answer to the question determines the subject of your article. The subject is what the article is about, the broader topic of the work [2]. For example:</p><ul><li>‚ÄúI wanna write about productivity.‚Äù</li><li>‚ÄúI want to write about learning.‚Äù</li><li>‚ÄúI want to write a post about habits.‚Äù</li></ul><p>Here‚Äôs my subject for this post:</p><blockquote>Q: What do I want to write about?<br>A: I want to write about the writing process.</blockquote><p>When you answer the second question, you will grasp the category of knowledge you‚Äôre dealing with and enrich your writing.</p><p>Categories are a form of abstraction that we use to deal with complexity. Imagine a fridge. What I just did is I put some mental image in your head. But the refrigerator that you see is not some specific fridge, like the one you have in the kitchen, although it might be close. The fridge‚Äôs image in your head is an abstract fridge that combines details of fridges you have seen in the past. That‚Äôs what a category is.</p><p>The most value of categories comes from enrichment. When you see a new, tall, metallic rectangular object with two sections and a handle, you can‚Äôt help but guess it‚Äôs a fridge, because its properties match with the properties of fridges you have seen before. But you not only deduce the category of the unknown object based on how its features compare with the category representation that you know. You also <em>enrich</em> the concrete object with the features you expect an item of this category to have. In the fridge that you imagined, you‚Äôd expect to have some shelves inside, maybe a pack of eggs, or a cold bottle of Guiness. Without knowing it for sure, you pre-suppose to find this stuff in a new fridge that you see because of enrichment.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/11/alexandru-acea-cVTC0gEOx8E-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@alexacea?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexandru Acea</a> on <a href="https://unsplash.com/s/photos/fridge?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</figcaption></figure><p>Once you understand the category of your work, you will be able to pull different ideas from the category level to enrich your article and better serve the reader. For example, suppose you‚Äôre writing a piece on fitness habits. In that case, you may jump to the category level and understand that fitness is about fitness habits <em>and</em> nutrition, <em>and</em> sleep. You could also level up to the habits category and see if there‚Äôs anything to pull from there ‚Äì any similarities between building a habit of jogging and learning to play the piano? And if you have something to say on those things and it fits the context of your work, you can enrich your work.</p><p>The process of jumping between categories may sound complicated. I‚Äôd recommend taking a piece of paper and a pen to draw things when you‚Äôre getting started. The paper will make it easier to see the category literally ‚Äúabove‚Äù the object because of spatial cognition [3], and you will discover other objects from that category (i.e., nutrition, sleep) because of the white space effect when your mind fills in the missing details for you.</p><p>With experience, the process of jumping across categories of knowledge, and looking at a thing from different angles becomes automatic. It integrates into your perception so well that you don‚Äôt even notice it happening. Like a chess grandmaster, you just <em>know</em> a good move.</p><h2 id="3-what-do-i-want-to-say-about-the-subject">3. What do I want to say about the subject?</h2><p>The third question determines your theme. The theme is what you have to say about the subject you‚Äôre writing about. For example, here‚Äôs a subject-theme pair for this work:</p><p>Subject:</p><blockquote>Q: What do I want to write about? <br>A: I want to write about the writing process.</blockquote><p>Theme:</p><blockquote>Q: What do I want to say about the subject?<br>A: I want to convince my reader that asking yourself simple questions about an article helps a) flesh out the idea better and b) notice more ideas for writing. To make the process easier, one could use shortcuts and think of an article as a set of blocks rather than one big monolithic piece.</blockquote><p>The purpose of selecting your theme is to limit what you‚Äôre writing about and outline a course of work. As you may have noticed, there are many things one can say about the writing process. If I attempted to write a piece on the ‚Äúwriting process‚Äù as ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/8questions/">https://vasilishynkarenka.com/8questions/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/8questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050838</guid>
            <pubDate>Tue, 10 Nov 2020 19:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draft Array API Standard Released for Public Comment]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25050558">thread link</a>) | @travisoliphant
<br/>
November 10, 2020 | https://data-apis.org/blog/array_api_standard_release/ | <a href="https://web.archive.org/web/*/https://data-apis.org/blog/array_api_standard_release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post" itemprop="articleBody">
    
    <p>Array and tensor libraries - from NumPy, TensorFlow and PyTorch to Dask, JAX,
MXNet and beyond - could benefit greatly from a uniform API for creating and
working with multi-dimensional arrays (a.k.a tensors), as we discussed in
<a href="https://data-apis.org/blog/announcing_the_consortium/">our previous blog post</a>.
Today we‚Äôre pleased to announce a first version of our array API standard
(<a href="https://data-apis.github.io/array-api/latest">document</a>,
<a href="https://github.com/data-apis/array-api/">repo</a>) for review by the
wider community. Getting to this point took slightly longer than we had
initially announced because, well, it‚Äôs 2020 and hence nothing quite goes
according to plan.</p>
<p>The current status of the standard is that it is a coherent story (or at
least, we hope it is) that gives readers enough context about goals and scope
to understand and review the design decisions already taken and APIs it
contains. However, <em>it is not yet complete and we can still change direction
and make significant changes based on community feedback</em>. This is important
‚Äî no one likes a ‚Äútake it or leave it‚Äù approach, and more eyes can make the
final result better. There‚Äôs still a few TODOs in places, and a couple of key
sections to be finished. The most important of those are the API for device
support, and the Python API for the
<a href="https://data-apis.github.io/array-api/latest/design_topics/data_interchange.html">data interchange protocol</a>
(proposed to be based on <a href="https://github.com/dmlc/dlpack">DLPack</a>).</p>
<p>It is worth repeating the main goal of this standard: make it easier to
switch from one array library to another one, or to support multiple array
libraries as compute backends in downstream packages. We‚Äôd also like to
emphasize that if some functionality is <em>not</em> present in the API standard,
that does <em>not</em> mean it‚Äôs unimportant, or that we‚Äôre asking existing array
libraries to deprecate it. Instead it simply means that that functionality at
present isn‚Äôt supported - likely due to it not being present in all or most
current array libraries, or not being used widely enough to have been
included so far. The <a href="https://data-apis.github.io/array-api/latest/use_cases.html">use cases section</a>
of the standard may provide more insight into important goals.</p>
<h2 id="some-key-design-topics">Some key design topics</h2>
<p>Two topics stood out so far in terms of complexity and choices that were hard
to make in such a way that they‚Äôd work well for all existing libraries:
mutability &amp; copy/view behaviour, and dtype casting rules.</p>
<h5 id="the-standard-will-contain-common-mutable-operations-such-as-slice-assignment-but-will-generally-avoid-in-place-mutation-in-apis-like-the-out-keyword">The standard will contain common mutable operations such as slice assignment, but will generally avoid in-place mutation in APIs like the <code>out</code> keyword</h5>
<p>NumPy, PyTorch, CuPy and MXNet provide strided arrays, and rely heavily on
mutating values in existing arrays and on the concept of a ‚Äúview‚Äù for
performance. TensorFlow, JAX and Dask on the other hand have no or limited
support, given that they rely on an execution graph and/or JIT compiler which
provides constraints on how much mutability can be supported. The design
decisions described <a href="https://data-apis.github.io/array-api/latest/design_topics/copies_views_and_mutation.html">here</a>
will allow the most heavily used types of mutability - inplace operators,
item assignment and slice assignment - to be retained, while avoiding the use
of the <code>out=</code> keyword which is problematic to support for some libraries and
arguably a suboptimal API to begin with.</p>
<p>For libraries like SciPy and scikit-learn, the supported features are essential.
Code like this, from scikit-learn‚Äôs <code>ForestClassifier</code>:</p>
<div><pre><code data-lang="python"><span>for</span> <span>k</span> <span>in</span> <span>range</span><span>(</span><span>self</span><span>.</span><span>n_outputs_</span><span>):</span>
    <span>predictions</span><span>[</span><span>k</span><span>][</span><span>unsampled_indices</span><span>,</span> <span>:]</span> <span>+=</span> <span>p_estimator</span><span>[</span><span>k</span><span>]</span>
</code></pre></div><p>or this, from SciPy‚Äôs <code>optimize.linprog</code>:</p>
<div><pre><code data-lang="python"><span>r</span> <span>=</span> <span>b</span> <span>-</span> <span>A</span><span>@x</span>
<span>A</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>=</span> <span>-</span><span>A</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span>
<span>b</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>=</span> <span>-</span><span>b</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span>
<span>r</span><span>[</span><span>r</span> <span>&lt;</span> <span>0</span><span>]</span> <span>*=</span> <span>-</span><span>1</span>
</code></pre></div><p>is quite common and we see it as fundamental to how users work with array libraries.
<code>out=</code> is less essential though, and leaving it out is important for JAX,
TensorFlow, Dask, and future libraries designed on immutable data structures.</p>
<h5 id="casting-rules-for-mixed-type-families-will-not-be-specified-and-are-implementation-specific">Casting rules for mixed type families will not be specified and are implementation specific</h5>
<p>Casting rules are relatively straightforward when all involved dtypes are of
the same kind (e.g. all integer), but when mixing for example integers and
floats it quickly becomes clear that array libraries don‚Äôt agree with each
other. One may get exceptions, or dtypes with different precision. Therefore
we had to make the choice to leave the rules for ‚Äúmixed kind dtype casting‚Äù
undefined - when users want to write portable code, they should avoid this
situation or use explicit casts to obtain the same results from different
array libraries. An example as simple as this one:</p>
<div><pre><code data-lang="python"><span>x</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span>  <span># will be integer</span>
<span>y</span> <span>=</span> <span>np</span><span>.</span><span>ones</span><span>(</span><span>5</span><span>,</span> <span>dtype</span><span>=</span><span>float16</span><span>)</span>
<span>(</span><span>x</span> <span>*</span> <span>y</span><span>)</span><span>.</span><span>dtype</span>
</code></pre></div><p>will show the issue. NumPy will produce <code>float64</code> here, PyTorch will produce
<code>float16</code>, and TensorFlow will raise <code>InvalidArgumentError</code> because it does not
support mixing integer and float dtypes.</p>
<p>See <a href="https://data-apis.github.io/array-api/latest/API_specification/type_promotion.html">this section of the standard</a>
for more details on casting rules.</p>
<h2 id="a-portable-test-suite">A portable test suite</h2>
<p>With the array API standard document we are also working on a
<a href="https://github.com/data-apis/array-api-tests">test suite</a>. This test suite
will be implemented with Pytest and Hypothesis, and won‚Äôt rely on any
particular array implementation, and is meant to test compliance with the API
standard.</p>
<p>It is still very much a work-in-progress, but the aim is to complete it by
the time the community review of the API standard wraps up. However, the
community is encouraged to check out the current work on the test suite on
<a href="https://github.com/data-apis/array-api-tests">GitHub</a> and try it out and
comment on it. The
<a href="https://github.com/data-apis/array-api-tests/blob/master/README.md">README</a>
in the test suite repo contains more information on how to run it and
contribute to it.</p>
<p>The test suite will be runnable with any existing library. This can be done
by specifying the array implementation namespace to be tested via an
environment variable:</p>
<div><pre><code data-lang="bash">$ <span>ARRAY_API_TESTS_MODULE</span><span>=</span>jax.numpy pytest
</code></pre></div><p>The test suite will also support vendoring so that array libraries can easily
include it in their own test suites.</p>
<p>The result of running the test suite will be an overview of the level of
compliance with the standard. We expect it will take time for libraries to
get to 100%; anything less shouldn‚Äôt just mean ‚Äúfail‚Äù, 98% would be a major
step towards portable code compared to today.</p>
<h2 id="people--projects">People &amp; projects</h2>
<p>So who was involved in getting the API standard to this point, and which
libraries do we hope will adopt this standard? The answer to the latter is
‚Äúall existing and new array and tensor libraries with a Python API‚Äù. As for
who was involved, we were lucky to get contributions from creators and senior
maintainers of almost every project of interest - here‚Äôs a brief description:</p>
<ul>
<li>NumPy: Stephan Hoyer and Ralf Gommers are both long-time NumPy maintainers.
In addition we got to consult regularly with Travis Oliphant, creator of
NumPy, on the history behind some decisions made early on in NumPy‚Äôs life.</li>
<li>TensorFlow: Alexandre Passos was a technical lead on the TensorFlow team,
and has been heavily involved until a few weeks ago. Paige Bailey is the
product manager for TensorFlow APIs at Google Research. Edward Loper and
Ashish Agarwal, TensorFlow maintainers, replaced Alexandre recently as
Consortium members.</li>
<li>PyTorch: Adam Paszke is one of the co-creators of PyTorch. Ralf Gommers
leads a team of engineers contributing to PyTorch.</li>
<li>MXNet: Sheng Zha is a long-time MXNet maintainer. Markus Weimer is an
Apache PMC member and mentor for the MXNet incubation process into the
Apache Foundation.</li>
<li>JAX: Stephan Hoyer and Adam Paszke are two maintainers of JAX.</li>
<li>XArray: Stephan Hoyer is one of the co-creators, and still a maintainer, of Xarray.</li>
<li>Dask: Tom Augspurger is a senior Dask maintainer.</li>
<li>CuPy: we have no active participant from CuPy. However we have talked to
the CuPy team at Preferred Networks, who are supportive of the goals and
committed to following NumPy‚Äôs lead on APIs.</li>
<li>ONNX: Sheng Zha is an ONNX Steering Committee member.</li>
</ul>
<p>Many other people have made contributions so far, including the Consortium
members listed at <a href="https://github.com/data-apis/governance">https://github.com/data-apis/governance</a>.</p>
<h2 id="next-steps-to-a-first-complete-standard">Next steps to a first complete standard</h2>
<p>We are now looking for feedback from the wider community, and in particular
maintainers of array libraries. For each of those libraries, a Consortium
member involved in the library will be soliciting feedback from their own
project. We‚Äôd like to get to the point where it‚Äôs clear for each library that
there are no blockers to adoption and that the overall shape of the API
standard is considered valuable enough to support.</p>
<p>In addition, given that this API standard is completely new and drafting
something like it hasn‚Äôt been attempted before in this community, we‚Äôd love
to get meta feedback - is anything missing or in need of shaping in the
standard document, the goal and scope, ways to participate, or any other such
topic?</p>
<p>To provide feedback on the array API standard, please open issues or pull
requests on <a href="https://github.com/data-apis/array-api">https://github.com/data-apis/array-api</a>. For larger discussions
and meta-feedback, please open GitHub Discussion topics at
<a href="https://github.com/data-apis/consortium-feedback/discussions">https://github.com/data-apis/consortium-feedback/discussions</a>.</p>


</div></div>]]>
            </description>
            <link>https://data-apis.org/blog/array_api_standard_release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050558</guid>
            <pubDate>Tue, 10 Nov 2020 19:33:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Benefits of Being a Stoic]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25050456">thread link</a>) | @davefreiburger
<br/>
November 10, 2020 | https://gradually.co/the-benefits-of-being-a-stoic/ | <a href="https://web.archive.org/web/*/https://gradually.co/the-benefits-of-being-a-stoic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-893">
				<!-- <a href="https://gradually.co/the-benefits-of-being-a-stoic/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              																			<p>								Wisdom								</p><!-- end cat-wrap -->
						<p><span>&nbsp; ‚Ä¢&nbsp; </span>
						<span>Benefits of Being a Stoic</span>
						<span> &nbsp;‚Ä¢&nbsp; </span>
						<span>
							November 10, 2020						</span>

						<img width="640" height="340" src="https://gradually.co/wp-content/uploads/2020/11/GD24-Wisdom.gif" alt="" loading="lazy"></p><div>

																					<div>
								<p><a href="https://linkmix.co/1611480" target="_blank">
									[Image source: Eric Gerlach/Giphy]								</a></p><h5>
									<a href="http://nautil.us/issue/92/frontiers/the-joys-of-being-a-stoic" target="_blank">
										The Joys of Being a Stoic									</a>
									 &nbsp;by Massimo Pigliucci									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>‚ÄúIf there is nothing you can do about a particular situation, why beat yourself up about it?‚Äù ‚Äî Massimo Pigliucci</span></li>
<li><span>Stoicism shouldn‚Äôt be about suppressing your emotions. Moreso, Stoicism is about adjusting your unhealthy emotions (anger) to a more mindful embrace of healthier ones (joy).&nbsp;</span></li>
<li><span>Stoicism receives a great deal of pushback regarding the negative effects of not acknowledging pain and the silent endurance and lack of emotion.&nbsp;</span></li>
<li><span>Massimo quotes Epictetus (Greek Philosopher), ‚ÄúSome things are within our power, while others are not. Within our power are opinion, motivation, desire, aversion, and, in a word, whatever is of our own doing; not within our power are our body, our property, reputation, office, and, in a word, whatever is not of our own doing.‚Äù&nbsp;</span></li>
<li><span>Massimo adds, ‚Äú‚Ä¶the idea is to internalize our goals: Instead of focusing, as it comes natural, on outcomes, let‚Äôs pay attention to our intentions and efforts. The Stoics think that the only truly good thing for us is our own character, and that therefore the only truly bad things are whatever may undermine our character. Everything else (including health, wealth, reputation, etc.) has value, but does not define who we are.‚Äù</span></li>
<li><span>The four virtues:</span></li>
</ul>
<ol>
<li>
<ol>
<li><i><span>Practical wisdom</span></i><span> ‚Äî the knowledge of what is truly good or bad for me. Will this undermine my character or not?&nbsp;</span></li>
<li><i><span>Courage</span></i><span> ‚Äî doing something that frightens us.</span></li>
<li><i><span>Justice</span></i><span> ‚Äî as treating other people, like my coworker, fairly and with respect.</span></li>
<li><i><span>Temperance</span></i><span> ‚Äî we should do things in the right measure, neither too much nor too little.&nbsp;</span></li>
</ol>
</li>
</ol>
<ul>
<li><span>‚ÄúApply the dichotomy of control and the four virtues to everything you do and, as Epictetus promises, you will never be unhappy. You will be free, and you will live a life truly worth living.‚Äù ‚Äî Massimo Pigliucci</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>Massimo mentions that the four virtues help us form a sort of moral compass. Allowing people to navigate the world and weather the storm of whatever that‚Äôs thrown at us. Moral compass or not, Stoicism or not, knowing your own virtues that help you navigate the world seems like an exercise worth doing. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!-- </a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/the-benefits-of-being-a-stoic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25050456</guid>
            <pubDate>Tue, 10 Nov 2020 19:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important Open Source projects should not use GitHub]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049619">thread link</a>) | @rolph
<br/>
November 10, 2020 | https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html | <a href="https://web.archive.org/web/*/https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Published on <span id="pubdate">2020-10-23</span>. Modified on <span id="moddate">2020-10-25</span>.</p>
<p>Thousands of the worlds best Open Source projects are still hosting their code repositories on GitHub. Since Microsoft has purchased GitHub this has become a serious problem.</p>
<p><b>Update 2020-10-25:</b> This is not directly related as it could happen on other hosting platforms as well, but just a few hours after I wrote this the youtube-dl repository was taken down from GitHub by RIAA due to a <a href="https://github.com/ytdl-org/youtube-dl/">DMCA request</a>.</p>
<p>It is no news that <a href="https://en.wikipedia.org/wiki/GitHub#Acquisition_by_Microsoft">Microsoft purchased GitHub in 2018</a>, everyone knows that. Yet despite that fact thousands of the worlds most important Open Source projects continue to host their code on GitHub. People seem to have forgotten just how rotten Microsoft really is and how dangerous that situation is.</p>
<p>It is not so much the fact that many projects host their projects on GitHub, it is the fact that many projects haven't secured the code outside of GitHub! They rely fully on GitHub to maintain and protect the code.</p>
<p>Microsoft is very actively purchasing important projects related to Open Source and in April 2020 it was announced that they had now also acquired <a href="https://en.wikipedia.org/wiki/Npm_(software)">npm</a>, a JavaScript packaging vendor, for an undisclosed sum of money.</p>
<p>Perhaps the younger generation don't know anything about the past "evils" of Microsoft and naively believe that Microsoft is now the good friend to Open Source, but the truth is that all these acquisitions of Open Source projects is a business tactic that is put in place to improve Microsoft's loosing position to Open Source. It is a matter of control.</p>
<p>Just yesterday <a href="https://www.minecraft.net/en-us/article/java-edition-moving-house">Microsoft announced</a> that Minecraft will require a Microsoft account to play in 2021 and that owners of the classic version will be forced to migrate.</p>
<p>While this is not related to Open Source, it is a really good example of how bad it can get if Microsoft sometime in the future decides that projects on GitHub are required to do something which goes against these projects interests.</p>
<p>I will not name any names, because that is not important, but how in the world can any Open Source project that regards their code base as valuable not make sure that they have a completely up to date copy of every single line of code outside of GitHub!?</p>
<p>Some project developers only keep parts on the code in personal repositories, others haven't even got a backup but trust fully that GitHub will always have a working and current release of the latests commits.</p>
<p>For years people have warned about the position GitHub had in the world of Open Source because it concentrates too much of the power to make or break the community in a single entity. Having Microsoft behind the steering wheel makes the situation a thousand times worse.</p>
<p>Nobody in their right mind would ever have imagined uploading Open Source code to Microsoft servers just a decade ago. Microsoft where the archenemy of Open Source in the nineties and they deployed all kinds of dirty tactics to keep other operating systems out of the market, especially dirty tactics against Linux. In the early 2000s the then CEO Steve Ballmer said, <q>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.</q> And for many years they tried to gain control over Linux and manipulated the market in different ways in order to "crush the competition". When they realized they couldn't do that and that the battle was lost, they deployed a new tactic in which they instead try to make money of Linux, which is what that are doing now in a lot of areas, and which is why they seem "friendlier" to the Open Source community.</p>
<p>I myself do have some code residing on GitHub, but of course I also have multiple up-to-date clones and backups elsewhere. However, having the worlds largest repository of important Open Source code reside in the hands of Microsoft is just madness. Why haven't all the major projects migrated? Running a self-hosting Git server isn't that difficult and there even exists several solutions that are pretty solid.</p>
<p>More and more of all the good stuff about Open Source and community driven development and sharing of resources, code and experience is slowly getting either gobbled up or ruined and massacred by big corporations or economically based foundations. Why is it that as soon as money enters into the picture so many things are turned into "crap"? Of course, greed is the answer, but an even more important question than that is: Why is it that we have stopped caring?</p>
<p>Large projects should self-host their repositories in order to stay completely independent, but some alternative solutions to the more popular services such as GitHub, GitLab and BitBucket does exist (not an exhaustive list):</p>
<ul>
<li><a href="https://codeberg.org/">Codeberg</a><br>Codeberg is a registered German non-profit organization and I think it is the best alternative. Codeberg does not depend on external services. No third party cookies, no tracking. Hosted in the EU.<br>Relevant discussion on <a href="https://news.ycombinator.com/item?id=22795930">Hacker News</a>. Relevant <a href="https://codeberg.org/codeberg/org/src/branch/master/PrivacyPolicy.md">Privacy Policy</a></li>
<li><a href="https://notabug.org/">NotABug</a><br>NotABug.org is run by <a href="https://peers.community/">Peers</a>, a group of people interested in free software and free society. It is mostly for small projects though. Relevant <a href="https://notabug.org/tos">Privacy Policy</a>.</li>
<li><a href="https://sourcehut.org/">sourcehut</a><br>sourcehut is currently considered alpha and it is not going to stay free, but it does not have any tracking or advertising. All features work without JavaScript. Relevant <a href="https://man.sr.ht/privacy.md">Privacy Policy</a>. Relevant discussion on <a href="https://news.ycombinator.com/item?id=23030489">Hacker News</a>. After signing up you get the following message: <q>Payment is optional during the alpha, but be aware that it will become mandatory later. This service is funded by its users, not by investors.</q></li>
</ul>
<p>A few good solutions for self-hosting (not an exhaustive list):</p>
<ul>
<li><a href="https://gogs.io/">Gogs</a> - old discussion at <a href="https://news.ycombinator.com/item?id=11374003">Hacker News</a></li>
<li><a href="https://gitea.io/en-US/">Gitea</a> a community-managed fork of Gogs - discussed at <a href="https://news.ycombinator.com/item?id=17006503">Hacker News</a></li>
<li><a href="https://github.com/theonedev/onedev">OneDev</a> - discussed at <a href="https://news.ycombinator.com/item?id=22081419">Hacker News</a></li>
</ul>
<p>Other relevant reading: <a href="https://jacquesmattheij.com/what-is-wrong-with-microsoft-buying-github/">What is wrong with Microsoft buying GitHub</a></p>
</article></div>]]>
            </description>
            <link>https://www.unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049619</guid>
            <pubDate>Tue, 10 Nov 2020 18:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Innocent badgers behind ‚Äúawful‚Äù and ‚Äúdisgusting‚Äù looting of Viking graves]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049599">thread link</a>) | @Bologo
<br/>
November 10, 2020 | https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4973" role="main"><div><div><div><p>On November 4, various media reported on the looting of Viking graves in the Norwegian town of <a href="https://en.wikipedia.org/wiki/Oppdal">Oppdal</a>. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>Malevolent grave robbers had allegedly ravaged a sacred Viking burial ground. Local newspapers attributed the misdeed to wanton vandals, greedy thieves, or both. The intruders had apparently drilled deep holes into 17 of the Viking graves.</p><p>‚ÄúIt‚Äôs awful!‚Äù <a href="https://www.adressa.no/nyheter/trondelag/2020/11/06/Anmeldte-vikinggrav-plyndring-i-Oppdal-n%C3%A5-har-saken-tatt-en-uventet-vending-22955618.ece">said Thora Nyborg</a>, a curator at the NTNU University Museum in Trondheim, according to local newspaper <em>OPP </em>(paywalled link <a href="https://opp.no/2020/11/nyheter/vikinggraver-plyndret-i-hostmorket/">here</a>). ‚ÄúMany organic objects have been lost, and more objects might be lost now that air has been allowed into the graves.‚Äù</p><p>Archaeology website AncientPages.com <a href="https://www.ancientpages.com/2020/11/06/disgusting-vandalism-and-looting-of-viking-graves-in-norway/">called the vandalism ‚Äúdisgusting.</a>‚Äù And commenters on the Facebook page The Heathen Underground <a href="https://www.facebook.com/heathenunderground/photos/pb.728159570530461.-2207520000../3763552250324496/?type=3&amp;eid=ARAk94RGYvhaVzFmr5C9yKMCmQ32q4-ZklASGYAnOI05bhST6Muv28ZWrAJzOp3mR3HLyVKKIZUIXIxy">said it was all ‚Äúvery sad.‚Äù</a></p><h2>Looting of Viking graves a blessedly rare event</h2><p>Their indignation was understandable. After all, the <a href="https://www.visitnorway.com/listings/the-burial-site-at-vang/204434/">Vang burial site</a>, and its more than 800 burial mounds, is Northern Europe‚Äôs largest remaining burial site from the Iron Age. As such, it is a site of major historical importance.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>The local newspaper <em>OPP </em>even suggested that the holes, which were of varying depths, <a href="https://opp.no/2020/11/nyheter/vikinggraver-plyndret-i-hostmorket/">had been dug using a special drill</a> (paywalled link), indicating a wicked degree of cunning on the part of the graverobbers.</p><p>Furthermore, except for an isolated case in 2014, there had been no looting at this major Viking burial ground since the 19th century.</p><h2>Badgers behind the looting of Viking graves</h2><p>But on November 6, events took a different turn. The <a href="https://www.psychnewsdaily.com/300-cocaine-packages-wash-ashore-on-dutch-beach-drug-tourists-look-for-more/">police</a> had suddenly closed the case, said Sjur Vammervold, a cultural consultant for the municipality of Oppdal.</p><p>The reason was that the suspect turned out to be impossible to prosecute. ‚ÄúIt seems that a badger was behind it,‚Äù <a href="https://www.dagbladet.no/kultur/gravplyndrer-avslort/73037518">Vammervold told local newspaper <em>Dagbladet</em></a>.<span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>‚ÄúAt least now we know that people weren‚Äôt responsible,‚Äù he said. ‚ÄúThe badger is quite innocent, and probably had no plans to rob any graves,‚Äù he added.</p><p>Vammervold said that while the badger hypothesis has not yet been proven, at this point it seems the most likely explanation.</p><p>‚ÄúBased on how badgers dig holes, they are probably behind this,‚Äù he said of the short legged <a href="https://www.psychnewsdaily.com/category/animal-psychology/" target="_blank" rel="noreferrer noopener">animals</a>.</p><p>Most of the burial sites at Vang date from the Late Iron Age (400 ‚Äì 1050 AD), which includes the <a href="https://en.wikipedia.org/wiki/Viking_Age">Viking Age</a> (793 ‚Äì 1066 AD). Archaeologists have made many important discoveries there.</p><hr><p><strong>Photo credit: </strong><a href="https://pixabay.com/users/andyballard-1141862/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2030975">andy ballard</a>&nbsp;via&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2030975">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/innocent-badgers-behind-awful-and-disgusting-looting-of-viking-graves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049599</guid>
            <pubDate>Tue, 10 Nov 2020 18:50:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meet the world's first Kafka data catalog]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25049235">thread link</a>) | @lefterisdvr
<br/>
November 10, 2020 | https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From data stagnating in warehouses to a growing number of real-time applications, in this article we explain why we need a new class of Data Catalogs: this time for real-time data.&nbsp;</p><p>The 2010s brought us organizations <i>‚Äúdoing big data‚Äù</i>. Teams were encouraged to dump it into a data lake and leave it for others to harvest.&nbsp;</p><p>But data lakes soon became data swamps. There were no best practices, no visibility into service levels or quality of data, no data contracts, no naming conventions or standardizations.&nbsp;</p><p>Just as quickly as data had arrived, it was impossible to find or trust.&nbsp;</p><p>If you were mature you might have deployed an enterprise Data Catalog that discovered data across your data stores. If you were less mature this would have been a manual process of documentation.&nbsp;</p><p>Either way, this wouldn‚Äôt prepare you for what was to come in the world of data and <a href="https://lenses.io/dataops/">DataOps</a>.&nbsp;</p><h3>

New streaming data, same problem, bigger stakes</h3><p>
As a developer or data engineer, you still have a problem finding data. Answering simple questions such as: Where do I have customer data? How about surnames and phone numbers or credit cards?&nbsp;</p><p>Why is this?&nbsp;</p><p>It‚Äôs because the challenge to catalog data got harder. Data isn‚Äôt sitting in data warehouses any longer. It‚Äôs streaming. And it is data generated by applications run within engineering, not business teams. </p><p>A lot of applications.</p><p>Engineering teams haven‚Äôt got time nor can they be expected to follow traditional data governance practices.</p><p>And yet, if there is no way to know what data there is across different teams and how to find it - it may as well not exist.</p><p>Much of DataOps is about self-service to remove friction from delivery. Pure luck in speaking to the right person at the right time or endless back-and-forths to understand what data exists, how it looks, etc isn't right. </p><p>This won‚Äôt work in 2020.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1tMpPZhid4mgL7MmbBaKiQ/e3b84596b166d1eba6bd5b303c891726/dataops-workspace.png" alt="DataOps container for your data platform"></p><p>For real-time data, there is no alternative but to automate the data management processes. This includes the discovery of data entities, data lineage, classification and quality.&nbsp;</p><p>Automation will mean teams are free to develop new data-intensive applications without centralized data governance or manual procedures.&nbsp; What data is generated can be immediately socialized across a business for other teams to benefit from.</p><h3>Commandments of Cataloguing data
</h3><p>Metadata is Queen. </p><p>If you can collect it from your different data infrastructure and applications you‚Äôre on the right path. Then to make it valuable you need to serve this information in the right measure, and you can start to answer the right questions:&nbsp;</p><ul><li><p> <!-- -->What data exists and its profile?</p></li><li><p> <!-- -->What is its quality?</p></li><li><p> <!-- -->What service levels can I expect?</p></li><li><p> <!-- -->What is its data provenance?</p></li><li><p> <!-- -->How might other services be impacted?</p></li><li><p> <!-- -->How compliant is it?</p></li></ul><p>Being able to answer these sorts of questions is fundamentally important to the success of real-time data projects.&nbsp;</p><p>Gartner agrees:<i> </i></p><p><i>‚ÄúBy 2021, organizations that offer a curated catalog of internal and external data to diverse users will realize twice the business value from their data and analytics investments than those that do not‚Äù</i></p><p><b><i>Source: Augmented Data Catalogs: Now an Enterprise Must-Have for Data and Analytics Leaders,‚Äù Ehtisham Zaidi &amp; Guido de Simoni, Sept.12, 2019</i></b>

</p><h3>Enter the Lenses real-time Data Catalog
</h3><p>Lenses.io delivers the first and only <a href="https://lenses.io/usecases/discover">Data Catalog for streaming data</a>.</p><p><img src="https://downloads.ctfassets.net/tnuaj0t7r912/3wE5igSRxlgeTTNk7Qy4zc/6cfe43a2e8a7d7ef49c29b02d4d462c0/lenses.io_4.0_real_time_data_catalog.gif" alt="Lenses.io - Real time data catalog for Apache Kafka"></p><p>
It's an easy, secure and intuitive way to identify your data:</p><ul><li><p> <!-- -->It works in real-time</p></li><li><p> <!-- -->It continuously and automatically identifies all your streaming data</p></li><li><p> <!-- -->It works across any data serialization format</p></li><li><p> <!-- -->It enables your team to mask and protect all <a href="https://help.lenses.io/using-lenses/data/data-policies/">sensitive data</a>.</p></li></ul><p><img src="https://images.ctfassets.net/tnuaj0t7r912/7BkMWioUDyPJTjE08BZ25P/f8bf542b6892bc0551133aeac7ae6a66/lenses.io_4.0_data_policies.gif" alt="lenses.io 4.0 data policies - data masking for Apache Kafka"></p><p>Lenses not only provides a Google Search experience over streaming data, but also a Google Maps experience. </p><p>In addition to monitoring your pipelines (Kafka Connect, Flink, Spark Streaming etc.) and your microservices<b>,</b> Lenses will highlight which applications are consuming or producing such ‚Äúsensitive‚Äù data.</p><p>Next, we‚Äôll explain the thought process and key principles behind our real-time Data Catalog.</p><h3>Like Google but for Apache Kafka metadata

</h3><p>Building a real-time Data Catalog was a natural progression for our team. We‚Äôve been giving visibility into Apache Kafka environments and applications that run on Kafka for years.&nbsp;&nbsp;</p><p>This was mainly developed to help engineers gain insight into their Kafka streams. Very useful when it came to debugging applications and inspecting message payload with SQL, partitioning information, overseeing infrastructure health or viewing consumer lag.</p><h3>It all starts with SQL
</h3><p>The SQL engine to explore topic data is particularly important. </p><p>To understand the data and its structure we connected to an AVRO schema registry or deserialized proprietary messages. This meant we had visibility into the metadata and payload of all data sitting in Kafka.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3H4HgRJRB2kIecDBxWrloU/be23f75b16a743698c0224577526af79/_Blog_-Data-Catalog---4.0-release---Alternative.jpg" alt="Lenses.io data catalog for Apache Kafka architecture"></p><p>
Last year we extended the capabilities to explore data in Elasticsearch with the same SQL engine and built a framework to connect to multiple different data stores in the future: Postgres, Redis, Cassandra.&nbsp;</p><p>We also register stream processing applications that run on our <a href="https://docs.lenses.io/4.0/sql/">streaming SQL engine</a> over Kubernetes.&nbsp;&nbsp;</p><p>We allow developers to register their external applications either as a REST endpoint or with a client for JVM-based applications.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/VoX7OrBtso7pnE7dh66T5/d773f7955ba1d66ca978402f26ae8eb9/lenses-api-docs-external-apps.png" alt="Lenses API docs external apps"></p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3iy2qCN9vTVzNpf5rDkwV6/6b1caba28603be4dc8680fc8f5670a01/topology-client-properties.png" alt="topology-client-properties"></p><p>This builds us an App Catalog and a Topology of all the dependencies between different flows and applications. Allowing us to build the data lineage of different data sets.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1tYvPfHqG2xHjfo7NfpVZ1/7394b4b2e3f409c1c12ff8c07b85fde6/_Blog_-Data-Catalog---4.0-release---Alternative_01.jpg" alt="Apache Kafka pipeline topology and data lineage lenses.io"></p><p>It also allows us to answer a few important questions:</p><ul><li><p> <!-- -->What applications generated this data?</p></li><li><p> <!-- -->How much can I trust the quality of the data and at what service levels?</p></li><li><p> <!-- -->What downstream applications consume this data to understand service disruption impact?</p></li></ul><p>The Topology, App Catalog and SQL Engine therefore give us the ability to maintain a metadata catalog of data flowing across a data platform.&nbsp;</p><p>Most importantly, this data is updated automatically and in real-time. </p><p>As engineering teams develop a new product, whether it be a consumer-facing microservice application or data processing pipeline, the data and topology will be discovered automatically, including payload and all metadata.&nbsp;&nbsp;</p><p>Or if an application writes to an Elasticsearch index, that too will automatically be picked up.</p><p>No need to manually maintain a catalog.&nbsp;</p><p>This information can then be presented and found in a free-text search fashion a la Google:&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/6xN1yqyFKhCyNTlik17Vb/caa0832fc2c1061daf9767bfd3823b73/image__25_.png" alt="Lenses.io - real time data catalog - searching metadata in Apache Kafka and Elasticsearch"></p><p>The catalog is protected with the same unified namespace-based security model that protects all data access in Lenses.&nbsp;</p><p>It opens up new use cases around how data can be accessed and drastically reduces the time or the duplicate effort compared to current methods of finding data.&nbsp;</p><p>Here are two examples.&nbsp;</p><h3>1. Scoping a new project
</h3><p>A business analyst is able to scope the feasibility of a new innovative stock management application by exploring what data can be used across multiple different lines of business, including service levels, quality and compliance requirements.</p><p>The analyst starts typing keywords such as <i>stock*</i> to find all metadata (indexes, documentation, field names, streamings) and generating applications that match.&nbsp;</p><p>They can drill down to the payload to explore the data or view in the context of a topology to understand upstream and downstream applications connected to the data. An analyst can only view data they have been granted access to, and/or may have certain sensitive fields masked in accordance with compliance requirements.&nbsp;</p><h3>2. Data access audit</h3><p>
An auditor needs to explore all data entities holding possible password information. </p><p>The auditor saves themselves weeks of data gathering and manual reporting by searching <i>pass*</i> to find all entities. They validate the Lenses user group namespaces for these entities to understand which users have access and understands the applications processing this information via a Topology.&nbsp;</p><p>This same process can help meet any number of compliance controls including GDPR, HIPPA, SOX, SEC and PCI.&nbsp;</p><p>You can try out these use cases (or your own) by exploring our real-time data catalog for free in a sandbox environment at <a href="https://portal.lenses.io/">portal.lenses.io</a> or see all deployment options at <a href="https://lenses.io/start">lenses.io/start</a></p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25049235</guid>
            <pubDate>Tue, 10 Nov 2020 18:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rev.ng decompiler nightly builds have been released]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048645">thread link</a>) | @agiantleap
<br/>
November 10, 2020 | https://rev.ng/blog/the-road-ahead/post.html | <a href="https://web.archive.org/web/*/https://rev.ng/blog/the-road-ahead/post.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<p>In this blog post we will briefly describe today's release, provide an overview of the components of rev.ng and introduce you the next steps the rev.ng project intends to take towards the 1.0 release.</p>
<p>We are inviting small groups of people to get access to nightly builds.
If you already registered, be patient and monitor our <a href="https://twitter.com/_revng">Twitter account</a>. Otherwise, <a href="https://rev.ng/register-for-nightly.html">register now</a>.</p>
<h2>Nightly builds release</h2>
<p>Today, we start releasing nightly builds of all the rev.ng components including <code>revng</code> (binary lifter and translator), <code>revng-c</code> (the decompiler) and <code>cold-revng</code> (the user interface).</p>
<p>rev.ng is an ambitious project which took the long route in several aspects.
We think this will prove to be a winning strategy to build an innovative product.</p>
<p>We're now starting to see the end of the tunnel that leads us to become a mature tool for binary analysis, but we're not there yet.
Nightly builds are our way to invite you to join us along the last mile of the journey.</p>
<h3>What to expect</h3>
<p>rev.ng can currently handle binaries compiled for Linux targeting x86-64, i386, ARM, AArch64, MIPS and SystemZ.
Here's a few things you can do with the current release.</p>
<h4>1. Try out the UI using test files</h4>
<p>The package we distribute includes a set of pre-lifted files.
You can open them in the UI right away.</p>
<div><pre><span></span><span>EXAMPLES</span><span>=</span>root/share/revng/qa/tests/runtime/x86_64/abi-enforced-for-decompilation
./revng ui <span>$EXAMPLES</span>/calc.bc
</pre></div>
<video controls="controls" width="945">
<source src="https://rev.ng/downloads/calc.mp4" type="video/mp4">
</video>
          
          
            <h4>2. Lift, translate and run ls</h4>
<p>You can also give a try to the binary translator.
For instance, you can lift <a href="https://rev.ng/downloads/ls-ubuntu-16.04"><code>ls</code></a> to LLVM IR, recompile it, and run it again:</p>
<div><pre><span></span>wget <span>'https://rev.ng/downloads/ls-ubuntu-16.04'</span>
chmod +x ls-ubuntu-16.04
./ls-ubuntu-16.04 --color<span>=</span>always -lhn
./revng translate ls-ubuntu-16.04
./ls-ubuntu-16.04.translated --color<span>=</span>always -lhn
</pre></div>

<p>Please note that translation support for non-x86-64 input architectures is working but has some limitations.</p>
<h4>3. Decompile ls</h4>
<p>The rev.ng UI also provides a wizard for decompilation.</p>
<video controls="controls" width="945">
<source src="https://rev.ng/downloads/ls.mp4" type="video/mp4">
</video><h3>What not to expect</h3>
<p>The builds are to be considered unstable and under heavy development, therefore keep in mind to:</p>
<ol>
<li>read the <code>README.md</code>
</li>
<li>perform frequent updates</li>
<li>expect suboptimal decompiled code and crashes</li>
<li>report anything unexpected/slow</li>
<li>expect rapid improvements</li>
</ol>
<p>For those, who have access to the nightly builds, the <a href="https://github.com/revng/help">revng/help</a> repository will contain a shortlist of known issues we're working on.</p>
<h2>Overview of the rev.ng components</h2>
<p>rev.ng is divided in several components, some of them are open source.</p>
<p>Let's start with the ones we forked from existing projects:</p>
<ul>
<li>
<code>qemu</code>: our fork provides a dynamic library able to produce tiny code instructions from a raw sequence of bytes.</li>
<li>
<code>llvm</code>: our LLVM 10 fork with minor changes.</li>
<li>
<code>qtcreator</code>: the base of our UI.</li>
</ul>
<p>The following projects are the open source parts of the rev.ng project:</p>
<ul>
<li>
<code>revng</code>. The core of rev.ng: the binary lifter and translator. Given a binary program, it lifts to tiny code instructions and then to LLVM IR. Produces an LLVM module, and, optionally recompiles it.</li>
<li>
<code>orchestra</code>. Our almighty meta-build system. It handles all the dependencies for you, fetches them from our binary archives or builds them from source. Don't try to build rev.ng by yourself, use <code>orchestra</code>.</li>
<li>
<code>revng-qa</code>. A repository for our test programs.</li>
</ul>
<p>The following projects will be released under a commercial license and are currently released as binaries only:</p>
<ul>
<li>
<code>revng-c</code>. Takes <code>revng</code> output and decompiles it to C.</li>
<li>
<code>caliban</code>. A project providing an API to perform high-level actions on binaries, on top of which the UI and, in the future, our scripting engine are built.</li>
<li>
<code>cold-revng</code>. The UI, a QtCreator plugin.</li>
</ul>
<h2>Roadmap towards the release</h2>
<p>In the following, we report a list of tasks to accomplish and components to develop/finalize in order to get to the final release.
You can expect one or more blog posts or some other form of publication for each item.</p>
<ul>
<li>
 Release the nightly builds</li>
<li>
 Create a <a href="https://github.com/revng/help">GitHub repository</a> to support nightly builds' users</li>
<li>
 Completely move the development of open source projects to GitHub</li>
<li>Requirements for tagging the beta:<ul>
<li>
 CFG combing</li>
<li>
 Improved ABI Analysis</li>
<li>
 Type Shrinking Analysis</li>
<li>
 Data Layout Analysis</li>
<li>
 Value Manipulation Analysis</li>
<li>
 Define a <em>data model</em> for the analyzed program and how to change it</li>
<li>
 Identify libraries using strings (BigMatch)</li>
<li>
 Full PE/COFF and Mach-O support</li>
</ul>
</li>
<li>Requirements for tagging the 1.0 release:<ul>
<li>
 Improve UI/UX</li>
<li>
 Python scripting engine</li>
<li>
 Windows and macOS port</li>
<li>
 Import C headers and debug information</li>
<li>
 Compatibility layer</li>
<li>
 Support for packers/self-modifying code</li>
<li>
 Support remote processing</li>
</ul>
</li>
</ul>
<h2>Conclusions</h2>
<p>We'd like to thank everyone who is participating in the nightly builds programme.
Your feedback will help us along the way towards the final release.</p>
<p>Releasing nightly builds, along with switching to a fully open air development of the open source components, is part of our effort to spread the word and collect feedback.
Our ultimate goal is to build a robust community to engage with and to grow a flourishing ecosystem of software based on rev.ng binary analysis framework.</p>
<p>Also, a shout-out to all those who put their hard work in order to make this first public release finally possible, in particular Pietro, <a href="https://twitter.com/carpikes">Alain</a>, <a href="https://twitter.com/fcremo">fcremo</a> and Andrea, but also all the others who contributed to spot bugs and share their opinions.</p>
<p>We hope you're excited as we are.
Enjoy!</p>
          
        </div></div>]]>
            </description>
            <link>https://rev.ng/blog/the-road-ahead/post.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048645</guid>
            <pubDate>Tue, 10 Nov 2020 17:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linus Torvalds' Home Office [YouTube]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048457">thread link</a>) | @bojanvidanovic
<br/>
November 10, 2020 | https://devandgear.com/posts/linus-torvalds-home-office/ | <a href="https://web.archive.org/web/*/https://devandgear.com/posts/linus-torvalds-home-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>When it comes to computer setups, there is one that always comes to my mind,
the setup of Linus Torvalds in the famous YouTube video <strong>‚ÄúLinus Torvalds Guided
Tour of His Home Office‚Äù</strong>. The video is from 2014 with almost 300k views, and
his home office probably changed until now, but interestingly it gives
a glimpse of how one of the most influential figures in the open-source
community works.</p>
<p>One would have imagined multiple <a href="http://localhost:1314/products/categories/monitors/">monitors</a> connected together, with a bunch of
computers, and everything perfectly organized. But that‚Äôs not a case here,
Linus getting done his work on a medium-sized Dell monitor set on a walking
desk. I wasn‚Äôt expecting to see a walking desk, they are very rare to be seen,
but in theory, they are healthier than a standing desk that keeps you in
a static position. If you already own a standing desk, you can add a walking
pad to it like this <a href="https://amzn.to/38t9Ll8">one</a>, and make it a walking desk. Aside from that everything
else seems pretty normal, a clean productive space.</p>
<p>That is one side of the office, the other side of his office is a bit messy
with a bunch of hardware stacked one on top of each other, which he admits it‚Äôs
probably best to burn.</p>
<p>I‚Äôd like to see the evolution of Linus‚Äôs office, but if you don‚Äôt know he is
a very reserved person, so it will be hard. Anyway, if you haven‚Äôt seen the
video, here is the link and enjoy it.</p>



        </div></div>]]>
            </description>
            <link>https://devandgear.com/posts/linus-torvalds-home-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048457</guid>
            <pubDate>Tue, 10 Nov 2020 17:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnout can exacerbate work stress, further promoting a vicious circle]]>
            </title>
            <description>
<![CDATA[
Score 300 | Comments 201 (<a href="https://news.ycombinator.com/item?id=25048455">thread link</a>) | @rustoo
<br/>
November 10, 2020 | https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php | <a href="https://web.archive.org/web/*/https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <!-- Hier kommen Imagescroller und ZGN, sowie... -->
            <!-- Offene Universit√§t Scroller --><!-- Default Row -->
            <!-- Spaltenlayout gem√§√ü Einstellungen f√ºr option_schalter_linke_spalte, option_schalter_rechte_spalte -->
            <!-- Ende linke Spalte -->
            <article id="spaltemitte">
               <!-- Beginn Inhalt Spalte Mitte -->
               <!-- Index√ºberschrift:  -->
               <h3>
                  Work stress and burnout are mutually reinforcing / Surprisingly, the effect of work stress on burnout is much smaller than the effect of burnout on work stress
               </h3>
               <p>
                  10 November 2020
               </p>
               <p>
                  Stress and overload in the workplace are increasing worldwide and are often considered a cause of burnout. Indeed, a new study shows that work stress and burnout are mutually reinforcing. However, contrary to popular belief, burnout has a much greater impact on work stress than vice versa. "This means that the more severe a person's burnout becomes, the more stressed they will feel at work, such as being under time pressure, for example," said Professor Christian Dormann of Johannes Gutenberg University Mainz (JGU). Employees suffering from burnout should be timely provided with adequate support in order to break the vicious circle between work stress and burnout.
               </p>
               <p>
                  Symptoms of burnout include exhaustion, cynicism, and reduced performance. "The most important burnout symptom is the feeling of total exhaustion ‚Äì to the extent that it cannot be remedied by normal recovery phases of an evening, a weekend, or even a vacation," said Dormann. "To protect themselves from further exhaustion, some try to build a psychological distance to their work, that is, they alienate themselves from their work as well as the people associated with it and become more cynical," added Dr. Christina Guthier. She conducted the study as part of her doctoral thesis in Dormann's research group and was awarded with the dissertation prize of the Alfred Teves Foundation in 2020. The study has recently been published in <em>Psychological Bulletin</em>.
               </p>
               <p>
                  For the joint publication with Professor Christian Dormann and Professor Manuel V√∂lkle of Humboldt-Universit√§t zu Berlin, Christina Guthier evaluated 48 longitudinal studies of burnout and work stress comprising 26,319 participants. The average age in the initial survey was about 42 years, 44 percent of the respondents were men. The longitudinal studies from 1986 to 2019 came from various countries, including predominantly European countries as well as Israel, the USA, Canada, Mexico, South Africa, Australia, China, and Taiwan.
               </p>
               <h4>
                  Stopping the downward spiral and reducing the effect of burnout on work stress
               </h4>
               <p>
                  The results challenge, or at least relativize, the common perception that work stress is the driving force behind burnout. "Burnout can be triggered by a work situation, but that is not always the case," Dormann pointed out. Once burnout begins, it develops only very gradually, building up slowly over time. Ultimately it leads to work being increasingly perceived as stressful: The amount of work is too much, time is too short, and work stress is too great. "When exhausted, the ability to cope with stress usually decreases. As a result, even smaller tasks can be perceived as significantly more strenuous," explained Guthier, the first author of the article. "We expected an effect of burnout on work stress; the strength of the effect was very surprising," she noted. The effect of burnout on perceived work stress can be somewhat mitigated if employees have more control over their own work and receive support from colleagues or superiors.
               </p>
               <p>
                  According to Dormann, a new research area is emerging on the basis of this unique data because the strong boomerang effect of burnout on work stress has not yet been investigated. Key questions that need to be addressed are: how can the effects of burnout on perceived work stress be reduced and how can the development of this vicious circle be prevented? Dormann and Guthier suggest that the place to start is with management behavior. Employees should have the opportunity to give feedback on their work stress at any time and be appreciated. Last but not least, proper recovery could also help to stop the downward spiral.
               </p><!-- Ende Inhalt Spalte Mitte -->
            </article>            <!--Ende-->
                     </div></div>]]>
            </description>
            <link>https://www.uni-mainz.de/presse/aktuell/12451_ENG_HTML.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048455</guid>
            <pubDate>Tue, 10 Nov 2020 17:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avo's Ultimate Tracking Plan Template (With Downloadable Worksheet)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25048395">thread link</a>) | @kelseyfecho
<br/>
November 10, 2020 | https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet | <a href="https://web.archive.org/web/*/https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We talked in depth about <em>why</em> you need a tracking plan in our<a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"> definitive guide to tracking plans</a>; now, we‚Äôll break down the awesome tracking plan template we created for you, so you‚Äôre ready to implement better product analytics via your tool of choice (possibly Avo üòâ).</p><p>But before we dive in, here‚Äôs a quick refresher on what a tracking plan is (you may recognize this from our<a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"> definitive guide to tracking plans</a>):</p><p><em>A tracking plan is a document that defines the key stages of your customer life cycle and codifies a single source of truth for the data that supports it. It helps you standardize your data management and capture better and cleaner data.</em></p><p>As part of your tracking plan, you‚Äôll need to outline the events and properties relevant to your goals, explain where in your codebase tracking code should be placed, and provide context for why you‚Äôre tracking what you are.</p><p>While each of the elements of your tracking plan will be as unique to your business as your product is to your market, you can save admin time up front by using a tracking plan template. There are dozens floating around the internet, so we went ahead and created our üéâUltimate Tracking Plan Template üéâ that pulls together the 10 elements you absolutely must have. Use this template to spend less time researching how to make your tracking plan and more time using it.</p><h2><strong>What makes a good tracking plan?</strong></h2><p>Your tracking plan should include events and properties that help you understand your customers‚Äô behavior and measure progress through your sales funnel and customer journeys so you can see how well your features are meeting customer needs. It shouldn‚Äôt aim to measure every drop of data under the sun‚Äîjust those that are most important to you.</p><p><em>For the full breakdown of how to find the events and properties that mirror your customer journey, check out</em><a href="https://www.avo.app/blog/our-definitive-guide-to-tracking-plans"><em> our full guide on tracking plans</em></a><em>, and then meet us back here.</em></p><p>To get a full picture of your customers‚Äô behaviors and experiences, you‚Äôll need a mix of both <strong>qualitative metrics</strong> (the kind that reflect user sentiment) and <strong>quantitative metrics</strong> (the kind that reflect user actions).</p><p>Your tracking plan will focus on quantitative metrics. That's because it's possible to objectively measure whether an action happened. But it‚Äôs equally important that your sales and product teams reach out to customers and users via surveys, social media, and reviews to get qualitative data to complement your tracking plan.</p><h2><strong>The 10 key elements of your tracking plan</strong></h2><p>We have a lot of experience helping folks build killer tracking plans (and we‚Äôve seen a lot of great examples of tracking plans from other companies, too). When we sat down and pulled from our experience‚Äîand the experiences of others‚Äîwe noticed there were <strong>10 key elements</strong> that every great tracking plan included.</p><h3><strong>1. KPIs</strong></h3><figure id="w-node-530d128e532a-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8da57e1d363a3d9b0b_zFsYVY341ROFEJtzHTqKjGUl5B--qn1HOpQJveWLNR_qPh-UsdTVUqGCRatRYI8S9Y4z4ZM3U7bm__KHLqPCOEYSYsO-dvIwiyB57Y4sU1_D481F9IvaSCLtb9v687GfNMss5BvN.png" alt=""></p></figure><p>‚Äç</p><p>Each event you track should tie directly to a business-end key performance indicator (KPIs) that affects your success, so you can easily reference the tie-in between metrics tracked and their real-world value.</p><p>These KPIs will change depending on your company maturity, product, and business strategy, but here are some examples:</p><ul role="list"><li>Signup funnel&nbsp;</li><li>Retention from signup to playing game&nbsp;</li><li>Monthly new signups&nbsp;</li></ul><p>This first section is what will give any business-end stakeholders the context they need to understand how the tracking plan ties into a wider strategy.</p><h3><strong>2. Event categories</strong></h3><figure id="w-node-4acb0f34daaa-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d25d6db8b075c10f4_DU2hKDTJVw5geaQSvCWdZyykuvO9nbgj3zRVCYZgG8Lv3eAKNBRShY9_R0XpxJ7hY0KcAPgHKukstUyxK-n7mC_UQxJ622J3GsS01LFzSXbnwPWfZHkuQzvcdYcsKibJImCc9_us.png" alt=""></p></figure><p>‚Äç</p><p>Your tracking plan should break down events tracked by macro category‚Äîtypically reflecting the different kinds of KPIs you‚Äôve set‚Äîso you can keep track of each segment of customer success.</p><p>Like all things on this list, the kinds of events you‚Äôll track will depend on your goals and use case, but here are a few examples:</p><ul role="list"><li>Authentication&nbsp;</li><li>Gameplay</li><li>Tournaments&nbsp;</li><li>Navigation</li></ul><p>Once you‚Äôve set the broad categories of events you care about, you can drill down and decide on the specific events and properties within each category.</p><h3><strong>3. Event names</strong></h3><figure id="w-node-187250f1dc30-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8fd082e416a91e7b79_TcJUo78HcU3SgDp2OEbWGP1kUdEwnKRCNvMBKYg3wctbFjMTcyr37VzBXFtiVQWmIzikz_XIAvHu1iL17HcPDyLiWG7H_R6DDMCDUPGrvJsQ1cShwvQ6qauCwydT-pFzwUMWaAKM.png" alt=""></p></figure><p>‚Äç</p><p>Your tracking plan should include one row for each event name (each of which will have rows for child properties). Additionally, each of your events should be <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#a-namenaming-conventionsa-naming-conventions-for-events-and-properties">named in a consistent way</a> that‚Äôs in line with your agreed-on naming schema. This structure makes it easy for anyone to quickly scan and understand what events you‚Äôre tracking.</p><p>Your event names will depend on the kinds of events you‚Äôre tracking and on your naming schema. Within the categories we outlined above, some possible event names could include the following:</p><ul role="list"><li>Signup Started&nbsp;</li><li>Signup Completed&nbsp;</li><li>Login Completed&nbsp;</li><li>Game Started&nbsp;</li><li>Game Completed&nbsp;</li></ul><p>Note how each of these event names shares the same tense (past tense) and capitalization. This isn‚Äôt just to make your template look pretty; it makes everything easier to understand.</p><h3><strong>4. Event description</strong></h3><figure id="w-node-1dc7d6600a1b-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8e862fad531128fb1f_tHQLNeHbz4xZgGQ3UDyoKeIlRgTnEAInfIqB5SPwyCVGMzW8Is3gsevwEqNtDkAoBbEBFjggi_w5pBtynvHVoB1a16Hr9qE1EGK1uGG-zs0g3pTwRCeDDNhmWt_ZEK0yFUaBGhAk.png" alt=""></p></figure><p>‚Äç</p><p>Your tracking plan should include a clear description for each event, including the event source (where the action is taking place) and <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#a-namedescriptionsa-descriptions-for-events-and-properties">any additional context of when and why the event happens</a>. That makes it easy for anyone looking at your template to quickly understand what the event is tracking.</p><p>Your event descriptions should be no longer than one or two sentences and should clearly and concisely explain what it is you‚Äôre measuring (and when). Let‚Äôs assume that we‚Äôre measuring the event ‚ÄúGame Completed.‚Äù Our description for this event might be:</p><p><em>Event sent when a user has successfully completed a game.&nbsp;</em></p><p>Creating consistent descriptions for each of your events will make it easy for anyone using your tracking plan to gain the context they need to interpret your data.</p><h3><strong>5. Properties</strong></h3><figure id="w-node-333264b27c1d-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee33289892753ad21_3EYStOV5VQlQYeGzMJPyMOp8QzHD8qKyZdFUxZp4ZAmQBmsKtm5gRQ-X1wUejDhl0AQRr2yjQ8F9uv4-0v-WDSn3lJJ5irFTq_c-S229dgHG8M9ts_0w0vdaSl4WAc4VMHbXMyIe.png" alt=""></p></figure><p>‚Äç</p><p>For each event, you should include a full breakdown of its attached properties, with one row per property‚Äîagain, all named consistently‚Äîso you can easily see which properties are being tracked for a given customer action.</p><p><em>Bonus: You should also define your property groups (these can be spaced across event groups) so you can easily see what kind of user behaviors you‚Äôre tracking.</em></p><p>It can be easy to let <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#properties">naming conventions for properties</a> slide, but ensuring that each property follows your schema will prevent data collection and compilation errors down the road. Let‚Äôs say we‚Äôre measuring gameplay events, particularly the ‚ÄúGame Completed‚Äù event we identified above. We might track the following properties:</p><ul role="list"><li>Game Mode&nbsp;</li><li>Game Count&nbsp;</li></ul><p>Each of these properties will tell us whether or not a specific user action was completed (e.g., ‚ÄúGame Mode‚Äù tells us the mode of the game the user played and ‚ÄúGame Count‚Äù tells us how many games the user has completed).&nbsp;&nbsp;</p><h3><strong>6. Property description</strong></h3><figure id="w-node-7f23661ce86e-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8dda8f2787d81a87d7_SRKyGBFh80amOWqLYm4bzJbJVTRc8dPooGC5elZjp7LEHi4ATelWDMowhRa3Jx0RdpBp68K52pDCGMe6smASuB6iYRY0gTZ1klOETv6ue1imXwlaJkmpuLJyd_AYaq2jfgNAcKEd.png" alt=""></p></figure><p>‚Äç</p><p>Your tracking plan should include a clear description for each property so that any user can understand what the property is tracking and where the data is coming from.</p><p>Just like your event descriptions, your property descriptions should fill a column to the right of your property names and <a href="https://www.avo.app/docs/best-practices/defining-descriptive-events-and-properties#properties-1">clearly and concisely describe what each property measures</a>.</p><p>For example, if we‚Äôre tracking how many games players complete during their session, we may track a property called ‚ÄúGame Count‚Äù. Our description of this property might look something like this:</p><p><em>The number of games a player has completed when this event is sent. Including the game that was just completed on Game Completed.&nbsp;</em></p><p>This extra context will help anyone looking at your tracking plan make sense of all your properties.</p><h3><strong>7. Property value types</strong></h3><figure id="w-node-a7b247d39bb4-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d4c3a92f224aa4e6d_P3Be8oQWJnz8WdmT5_PSPQpWy7JYNkUaweT8IWfUYFgC1Q7-zXGDT9kMMAKYc8Uo4g3K1E9F_4rhTIBRdSM_-wcGvRH2H_Sm7F3YhG-stRmHQU4jtRpScWITAVLZzg00buHIrHz8.png" alt=""></p></figure><p>‚Äç</p><p>Each property within your tracking plan will collect a different data type. These types should be explicitly laid out so developers implement across codepaths and platforms consistently. This also helps your data analysts know what to expect from the tracking analytics code output.&nbsp;</p><p>This is one of the few sections of your tracking plan that will not greatly vary. Instead, the data in this column should include these common data types:</p><ul role="list"><li>int</li><li>floating-point number</li><li>boolean</li><li>string</li><li>datetime</li><li>a list of any of the data types above&nbsp;</li></ul><p>When you formally identify these data types for each of your events and properties, you help your developers avoid coding errors that will impact data compilation down the line.</p><h3><strong>8. Platforms</strong></h3><figure id="w-node-27beb698434d-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8d3e80f7aef4929f6c_uE8HThZK-UHSz_XorkNrq5sj8lGQP5dYoD4Tr4jWi33Ky80JvVP_6wti3UGVtB1K4F2760jlQbO9zeYsK9CwjN94Yu-J93rG7TpLDpWKGWAy03pkK3tnB24ITLqB2vjPxz5-3u2W.png" alt=""></p></figure><p>‚Äç</p><p>For each property, you should note what platform the data is coming from so you can keep track of which applications contribute what information to your dataset.</p><p>This will depend on the development platforms you use and how your codebase is structured. But here‚Äôs a general outline of some of the platforms you may need to think about:</p><ul role="list"><li><strong>For web: </strong>JavaScript, TypeScript or Reason</li><li><strong>For mobile (generally): </strong>React Native or Expo or Flutter for iOS and Android apps</li><li><strong>For mobile (Android): </strong>Java or Kotlin&nbsp;</li><li><strong>For mobile (iOS):</strong>Swift or Objective C&nbsp;</li><li><strong>For backend: </strong>one or more backend sources (depending on number of programming languages and micro services)&nbsp;</li><li><strong>For game engines: </strong>Unity</li></ul><p>Including this breakdown of platforms that contribute data to your app will ensure that developers know where to implement tracking analytics across the board, and you won‚Äôt forget about any key components of your product.</p><h3><strong>9. Status</strong></h3><figure id="w-node-1697c41ba975-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee332892c4253ad22_Kjv8rek4cO-Y02kJmcgee0I4Wm5Qy2WxefQzbBeqQCf3nuMUA8hYuAKJUYL7Oi2Dpx-5VBZP88VKAWdwnxGdvugItvH_SoBxIOHrdTTofdp35s9GE_gqsGI-6qXl77A2pJn1Ahnh.png" alt=""></p></figure><p>‚Äç</p><p>This is a really important one: Your tracking plan must indicate the status of each step of tracking analytics implementation. This ensures that your team--and your tracking plan stakeholders--have a clear understanding of what work has been completed, what needs review, and what is in testing.&nbsp;</p><p>For example, let‚Äôs say you‚Äôre tracking events and properties related to your login authentication method. You‚Äôll need to note when that analytics code is ready for review and testing so your developers know that it‚Äôs not ready to ship, and don‚Äôt prematurely launch what could be a buggy bit of code.&nbsp;</p><h3><strong>10. Code snippet</strong></h3><figure id="w-node-9cafc5601453-cc6e1d3b"><p><img src="https://assets.website-files.com/5ec440af46599341a9a10225/5f988e8ee3ef37d419b6f69b_sBOY_kvaTx5H_ds77RHPB7lR0xEDQ1MZL4SAWDVD5ICI4O8FvrD30dNhnEfq8Xv7_1B3HOclQUWqkXmuE6RquaNN3YLNxcOSTa4jNGV4gNcLxwEZz-cg_eYd9FNk_amDfkjxjR9N.png" alt=""></p></figure><p>‚Äç</p><p>Finally, your tracking plan should include your tracking code for each event and property that needs to be tracked so that your developers can easily place it into the correct spot without naming-convention or syntax errors.</p><p>If you‚Äôre doing this manually with a spreadsheet alone‚Äîinstead of using a tool, like Avo, that can house your implementation code and send it directly to developers‚Äîthis section can get a little lengthy.</p><p>By explicitly giving the code for each property, you reduce the likelihood of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet">https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet</a></em></p>]]>
            </description>
            <link>https://www.avo.app/blog/avos-ultimate-tracking-plan-template-w-downloadable-worksheet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048395</guid>
            <pubDate>Tue, 10 Nov 2020 17:21:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka a More Accurate Perspective on Pulsar Performance]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25048083">thread link</a>) | @addisonj
<br/>
November 10, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25048083</guid>
            <pubDate>Tue, 10 Nov 2020 16:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Gods on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 326 | Comments 161 (<a href="https://news.ycombinator.com/item?id=25047838">thread link</a>) | @ivm
<br/>
November 10, 2020 | https://www.riknieu.com/the-gods-on-hackernews/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/the-gods-on-hackernews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tank_ghisletti?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Francisco Ghisletti</a> on <a href="https://unsplash.com/s/photos/greek-gods?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>(This post is mostly fun and tongue-in-cheek, please contain your indignation.)</p><p>Every so often I encounter a comment on HackerNews that involuntarily makes my jaw drop, head shake and eyes water. It's usually concerning what some on HackerNews consider a 'worthwhile' amount of money you can earn as an solopreneur or maker VS being an employee. </p><p>Obviously, it's probably a small minority of the silent masses who scroll through HN daily who have these views, but comments like the following, or a variant of it comes up so often I can't help but feel that a decent part of the community is <em>ridiculously</em> out of touch with the rest of humanity. </p><p>Behold.</p><!--kg-card-begin: html--><blockquote><p lang="und" dir="ltr">üòÇ <a href="https://t.co/mg1UFHxp08">https://t.co/mg1UFHxp08</a></p>‚Äî Pete from No CS Degree (@petecodes) <a href="https://twitter.com/petecodes/status/1326144308706209798?ref_src=twsrc%5Etfw">November 10, 2020</a></blockquote> <!--kg-card-end: html--><p>$1000 per month from a side project is considered meh. üò≥ üôÉ</p><p>And here's another from the same day,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/soundslikealot.png"></figure><p>And from the same user a few scrolls later,</p><figure><img src="https://www.riknieu.com/content/images/2020/11/FANG.png"></figure><p>My god. Look, the commenter had the self awareness to bring up regional cost of living and that not everyone can work at the FAMANGs of the world, but really? Getting $3.7 million dollars for just 7 years of work is, like, a bad deal?</p><p>To consider making $500K pa as a doable, realistic salary to be taken into account when deciding between starting a company or just seeking a job... Like us millennials say, "I can't. Even." </p><p>That annual salary far outstrips what I can reasonably expect to earn in a decade, and I'm a developer working for a fintech startup with a good couple of years under my belt. For most people in the world, $500K pa is a <em><strong>preposterous</strong></em> amount of money. </p><p>I'm too lazy to go dig up more examples, but I'm sure you'll find some more gems like these if you go digging around on past threads.</p><p>This kind of poo-pooing of what most - and I'm talking 90% of the US population, never mind the rest of the world! - would consider rather large amounts of money is incredibly mind-blowing and makes my head spin.</p><p>Now I'm sure that in commenters like the above's worlds, that kind of money is indeed average and peanuts, but I wanted to write this article for myself and the rest of us to just try and deal. </p><p>I'm trying to make sense of the fact that I'm on this forum, interacting with people everyday, talking about current events and issues, that make more money per year than I can even imagine. In a way we're peers, but more realistically they're like the gods of Olympus who occasionally slum it with the rest of us.</p><p>So if you're like me, and you consider even a $1000 as lot of money, let's look at this as average mortals should.</p><h2 id="1-1000pm-is-a-flippen-lot">1) $1000pm is a flippen lot</h2><p>Let's go with the $1000 pm example, because figures like $3.6 million is, to be frank, in the realms of La-La land for me and almost everyone I know personally. </p><p>And let's - for the sake of simplicity - assume that you can take home 60% of that revenue as net earnings. And that the project doesn't take up more free time with maintenance and support issues than you can handle on your own. That's $600 per month. Extra. From a thing on the side. </p><p>I realise that I live in one of those cheap, unappealing parts of the world, but that kinda money would easily cover me and my family's rent every month, and then some. Do you realise how much of a mental weight that can take off a persons shoulders? To know rent is covered over and above your day-job earnings?</p><p>Away with your $1000-is-not-worth-it malarky!</p><h2 id="2-making-money-with-your-own-products-is-hard-">2) Making money with your own products is HARD.</h2><p>Take a look at <a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">this post</a> by <a href="https://twitter.com/mccrmx">Chris McCormick</a>, titled "<a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174">Holy heck this is hard</a>". </p><p>When he last checked, 12 solo founders out of 17207 made more than $10K MRR. Only 54 products made more than $2000pm. I don't think I need to express that in ratios for you to see the probability of making a profitable project.</p><p>Starting a product and <em>actually earning money from it</em> is hard. Insanely hard. Hell, if you manage to make even $100pm from a side project you've got my respect. You've got me beat by a lot!</p><p>When I see makers on IndieHackers or Twitter celebrate $100 in sales I get genuinely excited for them. It's really an incredible feat. Bravo to them, I wish them luck and more success in the future.</p><h2 id="that-1000-per-month-can-grow">That $1000 per month can grow</h2><p>Another thing to consider is that earning a $1000 pm means your project is basically validated and ready to explode. With work, you could probably scale it to much higher multiples. </p><p>Sure, the money it makes is negligible to the higher beings in Silicon Valley, but for us regular plebs that's a <em>strong</em> signal that your project potentially has legs. It might even be a project you could sell for $3.7 million dollars in 7 years time, if you put the work in and get a little lucky.</p><h2 id="ya-but-rik-cost-of-living">Ya, but Rik, cost of living</h2><p>Sure, things cost more in the States. And more so in SanFran. But I can't just up and go live in the States. Nor pretty much anywhere else in the First World. A heck of a lot of the people frequenting HN, TW and IH on a daily basis could probably not either.</p><p>So for people like us, it's inspiring to read about some rando making a $1000 pm, on their own, independently. It gives us hope that some dude in Alabama could start a thing and sell it for more money than we could expect to earn in a lifetime as a salaried employee. Because maybe that means we could too.</p><p>Because they used the same tools we have access too(except for Stripe üòù). They had access to the same markets we could reach. </p><p>And they make the kinds of money with those tools that could buy people like us freedom. Freedom from being chained to a job, freedom from financial stress, and possibly even the freedom to move our families to better places in the world. Places that others just get born in.</p><p>So when you see smarmy comments on HackerNews new putting down the success of others, take a step back and realise, it's not meant for you. It's not personal. </p><p>These are merely the musings of a few lucky, privileged gods, reflecting on the toils of the mortals.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. üëá</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/the-gods-on-hackernews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047838</guid>
            <pubDate>Tue, 10 Nov 2020 16:34:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of the youtube-dl project]]>
            </title>
            <description>
<![CDATA[
Score 542 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25047818">thread link</a>) | @rg3
<br/>
November 10, 2020 | https://rg3.name/202011071352.html | <a href="https://web.archive.org/web/*/https://rg3.name/202011071352.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<h3><a href="https://rg3.name/202011071352.html">Origins of the youtube-dl project</a></h3>
<p>Posted on <time>2020-11-07T13:52Z</time>. Updated on <time>2020-11-10T16:28Z</time>.</p>


<p>As you may know, as of the time this text is being written <a href="https://github.com/ytdl-org/youtube-dl">youtube-dl‚Äôs repository at GitHub</a> is blocked due to a <a href="https://github.com/github/dmca/blob/master/2020/10/2020-10-23-RIAA.md">DMCA takedown letter</a> received by GitHub on behalf of the RIAA. While I cannot comment on the current maintainers' plans or ongoing discussions, in light of the claims made in that letter I thought it would be valuable to put in writing the first years of youtube-dl as the project creator and initial maintainer.</p>
<div>
<h4 id="_copper_thieves">Copper thieves</h4>
<p>All good stories need at least a villain so I have arbitrarily chosen copper thieves as the villains of the story that set in motion what youtube-dl is today. Back in 2006 I was living in a town 5 to 10 kilometers away from <a href="https://en.wikipedia.org/wiki/Avil%C3%A9s">Avil√©s</a>, which is itself a small city or town in northern Spain. While people in Avil√©s enjoyed some nice infrastructures and services, including cable and ADSL Internet access, the area I lived in lacked those advantages. I was too far away from the telephone exchange to enjoy ADSL and copper thieves had been stealing copper wires along the way to it for years, causing telephone service outages from time to time and making the telephone company replace those wires with weaker and thinner wires, knowing they would likely be stolen again. This had been going on for several years at that point.</p>
<p>This meant my only choice for home Internet access so far had been a dial-up connection and a <a href="https://en.wikipedia.org/wiki/Modem#Standardized_56k_(V.90/V.92)">56k V.90 modem</a>. In fact, connection quality was so poor I had to limit the modem to 33.6 kbps mode so the connection would be at least stable. Actual download speeds rarely surpassed 4 KB/sec. <a href="https://en.wikipedia.org/wiki/YouTube">YouTube</a> was gaining popularity then to the point it was purchased by Google at the end of that year.</p>
</div>
<div>
<h4 id="_up_all_night_to_get_some_bits">Up all night to get some bits</h4>
<p>Watching any YouTube video on the kind of connection I described above was certainly painful, as you can imagine. Any video that was moderately big would take ages to download. For example, a short 10 MB video would take, if you do the math, 40 minutes to download, making streaming impossible. A longer and higher-quality video would take several hours and render the connection unusable for other purposes while you waited for it to be available, not to mention the possibility of the connection being interrupted and having to start the download process again. Now imagine liking a specific video a lot after watching it and wanting to watch it a second or third time. Going through that process again was almost an act of masochism.</p>
<p>This situation made me interested in the possibility of downloading the videos I was trying to watch: if the video was interesting, having a copy meant I could watch it several times easily. Also, if the downloader was any good, maybe the download process could be resumed if the connection was interrupted, as it frequently was.</p>
<p>At the time, there were other solutions to download videos from YouTube, including a quite popular <a href="https://addons.mozilla.org/en-US/firefox/addon/greasemonkey/">Greasemonkey</a> script. By pure chance, none of the few I tested were working when I did, so I decided to explore the possibility of creating my own tool. And that is, more or less, how youtube-dl was born. I made it a command-line program so it would be easy to use for me and wrote it in Python because it was easy thanks to its extensive standard library, with the nice side effect that it would be platform independent.</p>
</div>
<div>
<h4 id="_an_ethereal_start">An Ethereal start</h4>
<p>The initial version of the program only worked for YouTube videos. It had almost no internal design whatsoever because it was not needed. It did what it had to do as a simple script that proceeded straight to the point. Line count was merely 223, with only 143 being actual lines of code, 44 for comments and 36 of them blank. The name was chosen out of pure convenience: youtube-dl was an obvious name, hard to forget, and it could be intuitively typed as ‚ÄúY-O-U-TAB‚Äù in my terminal.</p>
<p>Having been using Linux for several years at that point, I decided to publish the program under a free software license (MIT for those first versions) just in case someone could find it useful. Back then, GitHub did not exist and we had to ‚Äúmake do‚Äù with <a href="https://en.wikipedia.org/wiki/SourceForge">SourceForge</a>, which had a bit of a tedious form that you needed to fill to create a new project. So, instead of going to SourceForge, I quickly published it under <a href="https://web.archive.org/web/20060812055952/http://www.arrakis.es/~rggi3/youtube-dl/">the web space that my Internet provider gave me</a>. While not usual today, it was common for ISPs to give you an email address and some web space you could upload stuff to using FTP. That way, you could have your own personal website on the net. The first ever version made public was 2006.08.08, although I probably had been using the program for a few weeks at that point.</p>
<p>To create the program, I studied what the web browser was doing when watching a YouTube video using Firefox. If I recall correctly, Firefox didn‚Äôt yet have the development tools it has today to analyze network activity. Connections were mostly HTTP and <a href="https://en.wikipedia.org/wiki/Wireshark">Wireshark</a>, known as ‚ÄúEthereal‚Äù up to that year, proved invaluable to inspect the network traffic coming in and out of my box when loading a YouTube video. I wrote youtube-dl with the specific goal of doing the same things the web browser was doing to retrieve the video. It even sent out a User-Agent string that was verbatim copied from Firefox for Linux, as a way to make sure the site would send the program the same version of video web pages that were used to study what the web browser was doing.</p>
<p>In addition, YouTube used <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Adobe Flash</a> back then for the player. Videos were served as Flash Video files (FLV), and this all meant a proprietary plugin was required to watch them on the browser (many will remember the dreaded <code>libflashplayer.so</code> library), which would have made any browser development tools useless. This proprietary plugin was a constant source of security advisories and problems. I used a Firefox extension called <a href="https://en.wikipedia.org/wiki/Flashblock">Flashblock</a> that prevented the plugin from being loaded by default and replaced embedded content using the plugin, in web pages, with placeholder elements containing a clickable icon so content would be loaded only on demand and the plugin library was not used unless requested by the user.</p>
<p>Flashblock had two nice side effects apart from making the browsing experience more secure. On the one hand, it removed a lot of noisy and obnoxious ads from many web pages, which could also be a source of security problems when served by third parties. On the other hand, it eased analyzing how videos were being downloaded by the video player. I would wait until the video page had finished downloading completely and then start logging traffic with Wireshark just before clicking on the embedded video player placeholder icon, allowing it to load. This way, the only traffic to analyze was related to the plugin downloading the video player application and the application itself downloading the video.</p>
<p>It‚Äôs also worth noting the Flash Player plugin back then <a href="https://www.nirsoft.net/articles/copy_flash_flv_temp_file.html">was already downloading a copy of those videos to your hard drive</a> (they were stored in <code>/tmp</code> under Linux) and many users relied on that functionality to keep a copy of them without using additional tools. youtube-dl was simply more convenient because it could retrieve the video title and name the file more appropriately in an automated way, for example.</p>
</div>
<div>
<h4 id="_ahh_fresh_meat">Ahh, fresh meat!</h4>
<p>The Flash Player plugin was eventually <a href="https://www.omgubuntu.co.uk/2010/09/saving-flash-videos-in-linux-tmp-no-longer-works">modified so videos wouldn‚Äôt be so easily available to grab</a>. One of the first measures was to <a href="https://en.wikipedia.org/wiki/Unlink_(Unix)">unlink</a> the video file after creating it, so the i-node would still exist and be available to the process using it (until it was closed) while keeping the file invisible from the file system point of view. It was still possible to grab the file by using the <code>/proc</code> file system to examine file descriptors used by the browser process, but with every one of those small steps youtube-dl turned to be more and more convenient.</p>
<p>As many free and open source enthusiasts back then, I used <a href="https://en.wikipedia.org/wiki/Freecode">Freshmeat</a> to subscribe to new releases of projects I was interested in. When I created youtube-dl, I also created a project entry for it in that website so users could easily get notifications of new releases and a change log listing new features, fixes and improvements. Freshmeat could also be browsed to find new and interesting projects and its front page contained the latest updates, which usually amounted to only a few dozens a day. It‚Äôs only my guess that‚Äôs the way <a href="https://en.wikipedia.org/wiki/Joe_Barr">Joe Barr</a> (rest in peace), an editor for <a href="https://en.wikipedia.org/wiki/Linux.com">linux.com</a>, found out about the program and decided to write <a href="https://www.linux.com/news/cli-magic-enhance-your-youtube-viewing-pleasure/">an article about it</a> back in 2006. Linux.com was a bit different then and I think it was one of the frequently-visited sites for Linux enthusiasts together with other classics like <a href="https://en.wikipedia.org/wiki/Slashdot">Slashdot</a> or <a href="https://en.wikipedia.org/wiki/LWN.net">Linux Weekly News</a>. At least, it was for me.</p>
<p>From that point on, youtube-dl‚Äôs popularity started to grow and I started getting some emails from time to time to thank me for creating and maintaining the program.</p>
</div>
<div>
<h4 id="_measuring_buckets_of_bits">Measuring buckets of bits</h4>
<p>Fast forward to the year 2008. youtube-dl‚Äôs popularity had kept growing slowly and users frequently asked me to create similar programs to download from more sites, a request I had conceded a few times. It was at that point that I decided to rewrite the program from scratch and make it support multiple video sites natively. I had some simple ideas that would separate the program internals into several pieces. To simplify the most important parts: one would be the file downloader, common for every website, and another one would be the information extractors: objects (classes) that would contain code specific to a video site. When given a URL or pseudo-URL, the information extractors would be queried to know which one could handle that type of URL and then requested to extract information about that video or list of videos, with the primary goal of obtaining the video URL or a list of video URLs with available formats, together with some other metadata like the video titles, for example.</p>
<p>I also took the chance to switch version control systems and change where the project would be hosted. ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rg3.name/202011071352.html">https://rg3.name/202011071352.html</a></em></p>]]>
            </description>
            <link>https://rg3.name/202011071352.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047818</guid>
            <pubDate>Tue, 10 Nov 2020 16:33:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jack Ma's Bund Finance Summit Speech]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25047544">thread link</a>) | @ceohockey60
<br/>
November 10, 2020 | https://interconnected.blog/jack-ma-bund-finance-summit-speech/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/jack-ma-bund-finance-summit-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!-- social share icon -->
                    

                    <p><em>I don‚Äôt normally do any translation, because Interconnected is focused on original work and thinking. But I felt compelled to provide an English version of Jack Ma‚Äôs speech on October 24 at the Bund Finance Summit in Shanghai, because mainstream media coverage of the speech and the subsequent cancellation of Ant Group‚Äôs IPO has been lacking and simplistic. The speech is worth reading in its entirety to have a deeper understanding the full picture. Below is my unofficial translation of the speech </em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>based on a Chinese transcript</em></a><em>, with minor edits for clarity and speechifying. To read my deep dive analysis on the speech and its broader context, please check out: "<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">Jack Ma, P2P Lending, Responsibility, Legacy</a>"</em></p><p><em>ÊàëÈÄöÂ∏∏‰∏çÂÅö‰ªª‰ΩïÁøªËØëÂ∑•‰ΩúÔºåÂõ†‰∏∫„Ää‰∫íËÅî„Äã‰∏ìÊ≥®‰∫éÂéüÂàõ‰ΩúÂìÅÂíåÊÄùËÄÉ„ÄÇ‰ΩÜÊàëËßâÂæóÊúâÂøÖË¶ÅÊèê‰æõÈ©¨‰∫ë10Êúà24Êó•Âú®‰∏äÊµ∑Â§ñÊª©ÈáëËûçÂ≥∞‰ºö‰∏äÁöÑÊºîËÆ≤ÁöÑ‰∏Ä‰∏™Ëã±ÊñáÁâàÔºåÂ∞ΩÁÆ°Âè™ÊòØÊàë‰∏™‰∫∫ÈùûÂÆòÊñπÁöÑÁøªËØëÔºåÂõ†‰∏∫‰∏ªÊµÅÂ™í‰ΩìÂØπÊºîËÆ≤ÂíåÈöèÂêéËöÇËöÅÈõÜÂõ¢ÂèñÊ∂à‰∏äÂ∏ÇÁöÑÊä•ÈÅìÂ§™Ê¨†Áº∫ÔºåËøá‰∫éÁÆÄÂçïÂåñ„ÄÇÊï¥Â•óÊºîËÆ≤ÂÄºÂæó‰∏ÄËØªÊù•Êõ¥Ê∑±Â±ÇÁöÑ‰∫ÜËß£Êï¥‰∏™‰∫ãÊÉÖÔºåÂèØ‰ª•Âú®</em><a href="https://sfl.global/news_post/mayunshanghaiwaitanjinrongluntanyanjiangquanwenwushanjian/"><em>ËøôÈáåÁúãÂÖ®Êñá</em></a><em>ÔºåÂú®</em><a href="https://finance.sina.com.cn/chanjing/gsnews/2020-10-28/doc-iiznctkc8161643.shtml"><em>ËøôÈáåÁúãËßÜÈ¢ë</em></a><em>„ÄÇÊÉ≥ÁúãÊàëÂØπËøôÂ•óÊºîËÆ≤ÂíåÊúâÂÖ≥Â§ßËßÇÊôØÁöÑÊ∑±Â∫¶ÂàÜÊûêÔºåËØ∑ËØª„Ää<a href="https://interconnected.blog/jack-ma-p2p-lending-responsibility-legacy/">È©¨‰∫ëÔºåP2PÂÄüË¥∑ÔºåË¥£‰ªªÔºåÁïôÁªôÁ§æ‰ºöÁöÑÈÅó‰∫ß</a>„Äã</em></p><hr><p>Thank you for inviting me to this Summit. I am delighted to have this opportunity to learn, discuss, and exchange ideas together with you. In 2013, also in Shanghai, I came to the Lujiazui Finance Summit and shared some ‚Äúpie in the sky‚Äù views about Internet-powered finance. Seven years later, today I'm back in Shanghai as an unofficial non-professional person here at the Bund Finance Summit, hoping to share more ideas for you to ponder.</p><p>Actually, I was quite torn about whether to speak here today. But I think there is one thing that is incumbent upon this group of people, and that is the responsibility to think about the future, because although the world has left us many opportunities for development, there are really only one or two critical opportunities. This is a most critical moment.</p><p>So I come here to share some of my own thoughts and views, which are the result of our own practical experience in the last 16 years, plus discussions and research I have had with scholars, experts, and practitioners from all over the world, during the period when I was honored to be the co-chair of the UN High-Level Panel on Digital Cooperation and an advocate for the UN Sustainable Development Goals (SDGs).</p><p>I‚Äôm basically retired at this point, so I thought I'd speak freely at this unofficial forum and share the non-professional views of a non-professional person. Fortunately, I've discovered that many professionals no longer speak about their professions anymore.</p><p>I have three points of view for you to consider. They may be immature, incorrect, or laughable. Just give them a listen, if they make no sense, just forget about them.</p><p>The first point of view is we have some inertia in our thinking, like we always feel that in order to keep pace with international standards, we must do what developed countries like Europe and the United States have done. If we don‚Äôt have something they have, the so-called ‚Äúblank spot‚Äù, we must fill those blank spots domestically. Filling these spots has become the goal to pursue.</p><p>I have always felt that, given this year's situation, the phrase to ‚Äúfill the blank spot‚Äù is problematic. Just because Europe and the United States have something does not mean that thing is always advanced and worth having ourselves. In fact, today, we should not be concerned about what things to align with, which country's standard to adapt to, what blank spots to fill. Today, we have to think about how to align with the future, how to adapt to the future‚Äôs standard, how to fill the future‚Äôs blank spots. We have to figure out what the future will be, and what we really want to do, and then look at how others do it. If we always repeat the language of others, discuss topics defined by others, we will not only be lost in the present, but also miss the future.</p><p>After World War II, the world needed to restore economic prosperity. The establishment of the Bretton Woods system was an enormous catalyst to the global economy. Later, after the Asian financial crisis occurred, the Basel Accords talked about risk control, which has been gaining more and more attention, to the point that it became an operational standard for risk control. Now the trend is, the world is talking more and more just about risk control, not development. Very few people talk about where the opportunities are for young people, for developing countries.</p><p>This, in fact, is the root cause of many of the world's problems today. We also see today that the Basel Accords have put great limitations on Europe‚Äôs ability to innovate as a whole, for example, in digital finance.</p><p>Basel, more like a seniors club, is about solving the problem of an aging financial system that has been operating for decades, and Europe‚Äôs aging system is extremely complex. But the problem in China is the opposite: it is not a problem of systemic financial risk, because China's financial sector basically doesn‚Äôt have a system. Its risk is actually a "lack of financial system."</p><p>China's financial sector, like other developing countries that have just grown up, is a young industry that does not have a mature ecosystem and is not fully moving. China has many big banks. They are more like big rivers or arteries in our body‚Äôs circulatory system, but today we need more lakes, ponds, streams and tributaries, all kinds of swamps. Without these parts of the ecosystem, we will die when we are flooded, and die when we are in a drought. So, today we are a country that bears the risk of lacking a healthy financial system, and we need to build a healthy financial system, not worry about financial systemic risks.</p><p>They are like two completely different diseases, like Alzheimer's disease and polio. Both look similar at first glance but are two totally different illnesses. If a child takes Alzheimer's medication, he or she will not only get the old person‚Äôs disease, but a lot of other strange diseases as well.</p><p>The Basel Accords is designed to treat the diseases of the elderly with an aging system and over-complexity, and what we have to think about is what can we learn from the elderly? You must remember, older people and younger people care about different issues. Younger people care about whether there are schools, older people care about whether there are hospitals.</p><p>So, the way the world is changing this year is fascinating and very fast. Last night in Shanghai, we decided on the pricing of Ant‚Äôs IPO. This is the largest listing ever priced in the history of the entire human race, and the pricing happened in a place other than New York City. This was unthinkable five years ago, even three years ago, but miracles happen.</p><p>Second, innovation must come at a price, and our generation must take on that responsibility.</p><p>President Xi once said, "success does not have to come from me." I understand this phrase to be about a sense of responsibility. It‚Äôs about taking responsibility for the future, for tomorrow, for the next generation. Many of the world's problems today, including China's, can only be solved by innovation. However, for real innovation to happen, no one will show you the way, and someone must shoulder that responsibility, because innovation is bound to make mistakes. But the question is not how not to make mistakes, but whether we can perfect and correct them after making mistakes and persistently innovate. To make risk-free innovation is to stifle innovation, and there is no risk-free innovation in this world. There is no such thing as risk-free innovation. Oftentimes, managing risk down to zero is the biggest risk.</p><p>When the battle of Red Cliff was fought, I believe Cao Cao‚Äôs act of connecting all the ships together was the first instance of an aircraft carrier, in China and the world, but after a fire burned it all down, for a thousand years, the Chinese people didn't dare to think about it again. Once they thought about that fire, who still wanted to make a bigger ship, who could still have this kind of system-level thinking?</p><p>Seven or eight years ago, also in Shanghai, I mentioned this concept of Internet-powered finance. We have always emphasized that Internet-powered finance must have three core elements: first, it must have rich data; second, it must have risk control technology based on rich big data; and third, it must have a credit-based system built on big data.</p><p>Using these three criteria to evaluate, we can see that P2P is not Internet-powered finance at all, but today we cannot negate the innovation that the Internet has brought to finance just because of P2P. In fact, let's think about it, how can there be thousands of Internet-powered finance companies in China within a few years? Shouldn't we examine what gave birth to thousands of ‚ÄúInternet-powered finance‚Äù, the so-called P2P companies?</p><p>Today, it's really difficult to regulate ourselves; it's hard to conduct regulation everywhere around the globe. Innovation mainly comes from the marketplace, innovation comes from the grassroots, innovation comes from young people. Regulatory challenges are getting bigger and bigger. In fact, <em>jian </em>[editor's note: English word is ‚Äúsupervision‚Äù, the first character in the word for ‚Äúregulation‚Äù in Chinese] and <em>guan </em>[editor's note: English word is ‚Äúmanagement‚Äù, the second character in the word for ‚Äúregulation‚Äù in Chinese] are two different things. "Supervision" means watching you as you develop and paying attention to your development. ‚ÄúManagement‚Äù means intervening when there is a problem or when there is a foreseeable problem.</p><p>We are very good at ‚Äúmanagement‚Äù, but our ‚Äúsupervision‚Äù ability is sorely lacking.</p><p>Good innovation is not afraid of regulation, but is afraid of being subjected to yesterday's way to regulate. We cannot use the way to manage a railway station to manage an airport. We cannot use yesterday's way to manage the future.</p><p>"Supervision" and "management" are not the same, ‚Äúpolicies‚Äù and ‚Äúdocuments‚Äù are also not the same. This isn‚Äôt allowed, that isn‚Äôt allowed, those are all called ‚Äúdocuments‚Äù. Policy ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/jack-ma-bund-finance-summit-speech/">https://interconnected.blog/jack-ma-bund-finance-summit-speech/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/jack-ma-bund-finance-summit-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047544</guid>
            <pubDate>Tue, 10 Nov 2020 16:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C source-to-source compiler enhancement from within]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25047169">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://hal.inria.fr/hal-02998412 | <a href="https://web.archive.org/web/*/https://hal.inria.fr/hal-02998412">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p><strong>Abstract</strong> : We show how locally replaceable code snippets can be used to easily
  specify and prototype compiler and language enhancements for the
  C language that work by local source-to-source
  transformation.
  A toolbox implements the feature and provides many directives that
  can be used for compile time configuration and tuning, code
  unrolling, compile time expression evaluation and program
  modularization.
  The tool is also easily extensible by simple filters that can be
  programmed with any suitable text processing framework.                    </p>
                                </div><p><small>
                https://hal.inria.fr/hal-02998412<br>
                Contributeur : <a rel="nofollow" href="https://hal.inria.fr/search/index/q/*/contributorId_i/105206" target="_blank">Jens Gustedt</a>                        &lt;<a href="" id="link5faf2a2e158f3"></a>&gt;
                        <br>Soumis le : mardi 10 novembre 2020 - 15:02:12<br>Derni√É¬®re modification le : mercredi 11 novembre 2020 - 03:36:16</small>
        </p></div>]]>
            </description>
            <link>https://hal.inria.fr/hal-02998412</link>
            <guid isPermaLink="false">hacker-news-small-sites-25047169</guid>
            <pubDate>Tue, 10 Nov 2020 15:42:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Pulsar and Kafka ‚Äì The Full Benchmark Report]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046908">thread link</a>) | @tuhaihe
<br/>
November 10, 2020 | https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report | <a href="https://web.archive.org/web/*/https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://streamnative.io/blog/tech/2020-11-09-benchmark-pulsar-kafka-performance-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046908</guid>
            <pubDate>Tue, 10 Nov 2020 15:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Mass Effect not require admin rights, or how not to write a boolean check]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046894">thread link</a>) | @zdw
<br/>
November 10, 2020 | https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/ | <a href="https://web.archive.org/web/*/https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Hi all, it‚Äôs me again, your favorite modder who publishes a single research blog post a year. Welcome to my new blog, where I will also post maybe once a year! I got fed up with blogger‚Äôs endless unfixed bugs. I‚Äôm going to leave the content there though for historical sake.</p>
<p>I just finished a hardcore crunch to ship ALOT Installer V4, which is a complete rewrite of ALOT Installer. ALOT Installer is the Mass Effect modding scene‚Äôs main texture installation tool, built on top of aquadran‚Äôs MassEffectModder program, which can be used to install textures in a more advanced fashion. In V4 of ALOT Installer, I split the main ‚Äòcore‚Äô features into a cross-platform .NET Core library so I can also write a frontend that works on Linux. But that‚Äôs not why I‚Äôm here today ‚Äì I‚Äôm here to follow up on how I fixed Mass Effect on PC to not require elevation for good.</p>
<h2>Mass Effect on PC: About what you‚Äôd be expect from a mid 2000‚Äôs console port</h2>
<p>For those of you not in the know, Mass Effect came out on PC back in 2008, and was ported from the Xbox 360 by a studio named Demiurge, who also developed Pinnacle Station for Mass Effect. It‚Äôs‚Ä¶ a really meh port that has not aged very well. It‚Äôs passable as a game but it has a lot of problems, even when it came out. Particle LODs not working properly, texture LODs being read backwards, ini settings being randomly reset to their defaults, the problems are pretty numerous, just to name a few. But nothing completely game breaking.</p>
<p>Well, kind of. There is one, but it‚Äôs not specifically due to Mass Effect. The big issue is that Mass Effect requires administrator rights to run, because Demiurge seems to have assumed everyone would run the game as administrator ‚Äì which <em>might</em> have been OK if the game was only really developed when Windows XP existed, but Windows Vista had already been out for over a year by the time the game had released. Even back then though, Windows XP had a concept of LUA (Least User Access) with separated user accounts. For more information on this, you should check out the original post I wrote, <a href="https://www.me3tweaks.com/blog/modding/why-mass-effect-requires-administrator-rights-and-how-we-fixed-origin-not-running-it/">Why Mass Effect on PC requires administrator</a>. It describes a lot of backstory to this post.</p>
<h2>Oh boy, PhysX, my favorite physics library!</h2>
<figure id="attachment_67" aria-describedby="caption-attachment-67"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/ageialogo1.gif" alt="" width="236" height="134"><figcaption id="caption-attachment-67">I may have a slight beef with this SDK.</figcaption></figure><p>
Mass Effect for PC runs on a lightly modified version of Unreal Engine 3, which appears to be dated around late 2006. According to some former BioWare developers, this version of Unreal Engine was not very mature yet, to put it lightly. According to some stories from these developers, it was really difficult to work with because Epic Games was focused on Gears of War and not dedicating much time to their partners who were also using the engine.</p>
<p>Unreal Engine 3 uses PhysX for physics interactions, so Epic Games built a dll that interfaces PhysX to Unreal Engine data formats through a file named PhysXLoader.dll, which loads the PhysX libraries from both parties. PhysX is a physics simulation library that was acquired by AGEIA Technologies in the mid 2000s before AGEIA was sold to Nvidia in early 2008. If you remember Physics Processing Unit cards, or PPU, they were using PhysX before Nvidia promptly killed that idea.</p>
<figure id="attachment_66" aria-describedby="caption-attachment-66"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png" alt="" width="360" height="136" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25.png 360w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-300x113.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-07_19h50_25-250x94.png 250w" sizes="(max-width: 360px) 100vw, 360px"><figcaption id="caption-attachment-66">PhysXLoader.dll, PhysXCore.dll, and NxCooking.dll make up the PhysX dlls for Mass Effect.</figcaption></figure>
<p>All three Mass Effect games use PhysX, but Mass Effect 2 and Mass Effect 3 use the system‚Äôs install of PhysX, while Mass Effect uses the local game‚Äôs PhysX. Mass Effect 2 and Mass Effect 3 also use the ‚Äòmodern‚Äô version of PhysX, rather than the legacy one that was shipped by AGEIA. Nvidia changed some paths under the hood when it took over, which separates Legacy out from it‚Äôs ‚Äòmodern‚Äô versions. </p>
<p>But that doesn‚Äôt seem to stop Legacy PhysX‚Äôs uninstaller from deleting modern PhysX‚Äôs files/registry keys, so during the course of testing this fix, my other copies of Mass Effect 2/3 didn‚Äôt work, even after installing the ‚Äòmodern‚Äô PhysX redistributable. It‚Äôs really annoying how BioWare couldn‚Äôt just ship a 8MB library with the game ‚Äì they already shipped the installer for PhysX with the game, so it‚Äôs not like it saved space!</p>
<p>But anyways‚Ä¶</p>
<h2>The issue with Epic Games‚Äô PhysXLoader.dll is that it can load PhysXCore.dll locally, or from the system‚Äôs installed version</h2>
<p>Err‚Ä¶ wait, how is that an issue? Can‚Äôt you just load the local dll, and if that doesn‚Äôt exist, load the system one? How is that an issue exactly?</p>
<figure id="attachment_73" aria-describedby="caption-attachment-73"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg" alt="OH BOY HERE WE GO" width="294" height="294" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1.jpg 294w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-150x150.jpg 150w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-48x48.jpg 48w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-250x250.jpg 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/4929c5241f6f230614d6454092c699fe1-180x180.jpg 180w" sizes="(max-width: 294px) 100vw, 294px"><figcaption id="caption-attachment-73">You won‚Äôt believe how many facepalms there were as I making this fix.</figcaption></figure><p>
On boot, Mass Effect writes two values to the Windows HKEY_LOCAL_MACHINE registry:</p>
<blockquote><p>REG_BINARY HKLM\SOFTWARE\AGEIA Technologies enableLocalPhysXCore [mac address, 6 bytes]<br>
REG_DWORD HKLM\SOFTWARE\AGEIA Technologies EpicLocalDllHack [1]</p></blockquote>
<p>*Mass Effect is a 32-bit program, so on 64-bit systems it goes into HKLM\SOFTWARE\WOW6432Node\AGEIA Technologies instead, if you‚Äôre looking for yourself.</p>
<p>Remember these registry values, they‚Äôre going to be important later!</p>
<p>These registry values are why Mass Effect requires administrative permissions. In my previous blog post linked above, we explored why these writings were enough to make Microsoft put Mass Effect into it‚Äôs compatibility database, which forces it to run as admin when matching on certain executable criteria, which we worked around by modifying the executable criteria to no longer match. </p>
<p>We have to modify the executable to enable Large Address Aware, so the game could load higher resolution textures without running out of memory, so there was no way to avoid breaking the signature. This in turn caused Origin to no longer run the game as it would not elevate games without a valid EA signature. But if the game cannot write these registry keys on boot, the game may crash‚Ä¶ </p>
<p>So it‚Äôs already a big fun chain of problems, but we worked around Mass Effect needing administrative rights by simply giving the user account permissions to that specific AGEIA Technologies registry key. This would let the game process write the values it needed, and would we could go on our merry way. I assumed the game crashed because it was denied write permissions and Demiurge couldn‚Äôt be bothered to write a try/catch around the registry writing code.</p>
<h2>You probably shouldn‚Äôt name your registry values as a hack if you want me to think this is a good idea</h2>
<p>Our solution to this problem did not change Mass Effect‚Äôs behavior ‚Äì the values it wanted to write to the registry were going to be written one way or another, so we were just letting it do the thing it‚Äôs always done, just without administrative rights. There wasn‚Äôt really any change in application behavior.</p>
<figure id="attachment_81" aria-describedby="caption-attachment-81"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png" alt="" width="362" height="154" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59.png 362w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-300x128.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/2020-11-01_12h55_59-250x106.png 250w" sizes="(max-width: 362px) 100vw, 362px"><figcaption id="caption-attachment-81">The two registry values that Mass Effect writes.</figcaption></figure>
<p>mirh, a moderator for <a href="https://www.pcgamingwiki.com/wiki/Home">PC Gaming Wiki</a>, sounded the alarm for years that somehow we were breaking other games in ALOT Installer ‚Äì even though our application didn‚Äôt actually change how Mass Effect was behaving writing these values, so there‚Äôs no way our change would break other games.</p>
<p>After many months, he wrote a fairly detailed reason why ALOT Installer (when, in reality, it was Mass Effect) is breaking other games: <b>enableLocalPhysXCore</b> being in the registry <em>is used by other games using Epic Game‚Äôs PhysXLoader.dll.</em> When I was writing V4 of ALOT Installer, I told mirh I would take a more serious look into his idea of a solution that would not break other games, even though at the time I did not really understand how a registry key with the system‚Äôs MAC address would break other games ‚Äì or why it even used a MAC address to begin with.</p>
<p>mirh seems to have determined this enableLocalPhysXCore lets Mass Effect use the local directory‚Äôs PhysXCore.dll/NxCooking.dll, instead of loading the one from the installed PhysX redistributable. Mass Effect doesn‚Äôt install the PhysX redistributable, so it could not rely on it existing, so it needed to use the local libraries.</p>
<p>Hope you‚Äôre strapped in because this is where it gets really dumb: </p>
<h4>The MAC address stored in in the registry by MassEffect.exe is read by PhysXLoader.dll and compared against your system‚Äôs MAC address to determine if it should load the local directory‚Äôs PhysX libraries or the system‚Äôs.</h4>
<p>Which MAC address? </p>
<h3>¬Ø\_(„ÉÑ)_/¬Ø</h3>
<p>So the way Mass Effect works:</p>
<ol>
<li>Very early in the boot process of MassEffect.exe, your MAC address is read and written to the registry as enableLocalPhysXCore (along with EpicLocalDllHack)</li>
<li>MassEffect.exe loads PhysXLoader.dll</li>
<li>PhysXLoader.dll reads the value of enableLocalPhysXCore and compares your system‚Äôs MAC address against it</li>
<li>If it matches, it uses the local folder‚Äôs PhysX, if not, it uses the system‚Äôs redistributable version of PhysX</li>
</ol>
<p>Yes, you read that right.</p>
<p>It turns out that other games, such as Mirror‚Äôs Edge, have a PhysXLoader.dll that also reads these values (as they‚Äôre based on the same code), <em>but they don‚Äôt include local PhysX libraries</em>. So those games boot up, see enableLocalPhysXCore, and try to load the local library, which fails, and the game doesn‚Äôt start. This information is second hand from mirh ‚Äì I have not tested other games broken by this registry value.</p>
<p>Normally that value wouldn‚Äôt exist, and it should use the system PhysX. This behavior can be tested in Mass Effect by denying it write permissions to the registry key, deleting the values, and having Legacy PhysX installed ‚Äì it will use the system libraries instead. If system PhysX is not installed, the application will not boot ‚Äì this is why we originally had to let Mass Effect write these keys, otherwise it could appear that the installer broke Mass Effect, when it actually was a terrible implementation by Epic Games.</p>
<figure id="attachment_157" aria-describedby="caption-attachment-157"><img loading="lazy" src="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png" alt="Facepalm" width="782" height="433" srcset="https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1.png 782w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-300x166.png 300w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-768x425.png 768w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-250x138.png 250w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-550x305.png 550w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-325x180.png 325w, https://www.me3tweaks.com/blog/wp-content/uploads/2020/11/Facepalm-PNG-File1-542x300.png 542w" sizes="(max-width: 782px) 100vw, 782px"><figcaption id="caption-attachment-157">It‚Äôs hard to imagine any possible scenario where this was a good idea.</figcaption></figure><p>
If you‚Äôre interfacing with a library that has exports you can call to initialize/load the PhysX SDK‚Ä¶ couldn‚Äôt you just, you know, pass a boolean to tell it to locally load? Why does it not locally look to begin with? And what‚Äôs up with the MAC address? Why is this in the registry, where it behaves LIKE A GLOBAL SETTING??? </p>
<p>All of these seem like terrible design decisions ‚Äì and after disassembling the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/">https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</a></em></p>]]>
            </description>
            <link>https://www.me3tweaks.com/blog/modding/making-me1-not-require-admin-rights-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046894</guid>
            <pubDate>Tue, 10 Nov 2020 15:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homegrown KDP doubling crystal for Nd:YAG laser]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046806">thread link</a>) | @buescher
<br/>
November 10, 2020 | http://www.milankarakas.org/pub/KDP/HomegrownKDP.html | <a href="https://web.archive.org/web/*/http://www.milankarakas.org/pub/KDP/HomegrownKDP.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><span>

<p>
Long time ago I had idea to add a doubling crystal to my
Nd:YAG laser to get green output. But the problem is
that I have no idea which one to buy. There is many
choices, but no simple guide which one will be
appropriate for such Q-switched Nd:YAG laser. I have
another Nd:YAG laser without Q-switch, and this
complicates things a bit more if I want to get doubled
frequency from that laser too.

</p><p>
I heard of KDP (chemical formula
KH<sub>2</sub>PO<sub>4</sub>), and I have that chemical
for hydroponic use, but did not believe that it is
possible to grow decent crystal for SHG (Second Harmonic
Generation). Since my school days, I know how to grow
crystals with jar, chemical and just fiber. This type of
growing crystals give only heap of crystals bond
together, for which I not believe that it is possible to
use as a SHG.

</p><p>
Just by accident, I watched video on YouTube about
growing another type of crystal, so called
‚Äòalum‚Äô, and there is explanation how to get
single seeded crystal. Aside that, I saw another video
where they grow KDP crystal for NIF (National Ignition
Facility). Second video looks too complicated to me, so
I decided to follow procedure for growing alum crystal,
but with KH<sub>2</sub>PO<sub>4</sub> chemical. Result
was disappointing. I got many crystals aside from the
seeded one, and mostly bonded together. I tried re-seed
bigger one, but it lead to even worst situation.

</p><p>
After few attempts I gave up. What I get is hundreds of
small crystals, for what I believed that there is no
even smallest chance to get frequency doubling, or
making other harmonics (THG, FHG, etc.). I tried to find
information on the internet about whether someone got
homegrown KDP crystal and use it as SHG. There is no
results. Only result I got is about purchasing such
crystals, but price is... huh... &nbsp; :-p

</p><p> In private conversation with my friend
<a href="http://www.jarrodkinsey.com/">
Jarrod Kinsey</a>
he pushed me to try to put some small crystal at the
output beam from the Nd:YAG laser anyway. I argued that
this is not possible and that for such frequency
doubling it is required special cut of the crystal,
precision aligning, polarized laser, and so on.

</p><p>
Later on, I wanted to check what is necessary to get
proper angle, but all I got is many offers for buying
finished crystals with instructions how to use. At few
pages they mentioned some angles, but also many other
data, for what at this time I have no idea what they
means. Until today I am not sure about many of that, but
I am much more close to understanding it.

</p><p>
Laser is there, crystals are there, but also many
questions too. Finally, I got courage to try it. During
preparing for this test, I had all the time idea how to
tell him that it failed, and that he is wrong. Also, I
remember conversation with another friend,
<a href="http://www.jossresearch.org/">
Jon Singer,</a>
a long time ago about this subject, before my attempt to
grow crystals. He mentioned to me that this may be
difficult too, but not impossible. He also mentioned
that it is worth to try to grow crystals;
‚ÄúWhat‚Äôs to lose?‚Äù

</p><p>
With all of that on my mind, and with serious doubt, I
wear safety goggles and fire my laser with focusing lens
onto small KDP crystal. I had no idea where to point
that focus. I tried few times with different angles, and
WOW! Green light popped right out of the crystal. At
first very weak, but at that moment, my excitement
increased my perception of such intensity to the
extreme. By slightly changing angle, I got even more
green light out.

</p><p>
It took me a while until cool down my mind and realized
what I got. Then I reported to my friends on the
<a href="https://mail.neurotica.com/mailman/listinfo/lasers">
Lasers -- Laser and high-energy physics hacking </a>
mailing list, who congratulated me for this achievement.

<br>

</p>
<p>
At third picture from the left, there is glued crystal
at approximately 42¬∞ to the incoming beam. Note that
I am not sure of the exact angle, because incoming beam
is focused, which produce cone of light. Such cone is
not so good, and part of the incoming energy is wasted.
I tried to use binocular as a beam shrinker. Instead of
3 mm beam, my attempt is to narrow it to about 0.3 mm
(if binocular has magnification 8x, then reversed should
narrow or shrink beam to very narrow beam. Such narrow
beam has high divergence, but at short distance it is
okay. After beam pass crystal, it will be good to use
beam expander to back to the original beam diameter, or
to expand beam even more to achieve lower divergence.
But I forgot that in binocular are glued two lenses
together to correct chromatic aberration. Here is how it
looks after a few laser pulses:

<br>

</p>

<div><p>
There is glue, or optical cement between that two lenses.
It seems that some glues/cements don‚Äôt like IR (infra
red) radiation. I noticed that at first, there is only
burning spot, but as room temperature changes, one of
two lenses made different expansion rate and produce
crack.

</p></div>
<p>
I am mentioned birefringence which is visible on the
green spot. By slightly adjusting (rotating) angle, that
two groups of spots becomes one. When collimating to the
infinite, such phenomena is less visible, because both
spots make one small spot, slightly elliptic.

</p><p>
My both Nd:YAG lasers are non-polarized. For that reason
I use so called ‚ÄòType II‚Äô phase matching. Since I
am ‚Äònewbie‚Äô in that field, on the Internet you may
find some nice article(s) about phase matching. One of
them is:
</p>

<a href="http://ilphotonics.com/CD/Crystech-Crystals/Non_Linear_Crystals/nlo.pdf">
http://ilphotonics.com/CD/Crystech-Crystals/Non_Linear_Crystals/nlo.pdf</a>

<p>
And another document:

</p>
<a href="http://www.quantumtech.com/apps/916.pdf">http://www.quantumtech.com/apps/916.pdf</a>

<p> Citation from page 5:

</p><p>*4.

</p><p>
‚ÄúWhen the cell is mounted horizontally in an optical
mount, the screw (for filling the fluid) should face the
ceiling. The polarization for the input beam should make
and angle of 45¬∞ with respect to the horizontal or
vertical plane. Slight Rotation and/or angular
adjustment is required to obtain optimum efficiency.‚Äù

</p><p>
*5.

</p><p>
"Type II process is more efficient because the
acceptance angle is wider, making alignment and thermal
control less critical than Type I process, especially
for doubling 1060nm. For tripling two orthogonally
polarized beams, this process is attractive if the
crystal is cut at the proper angle for tripling. The
distance between the doubler and tripler should be as
small as possible for best efficiency. Two orthogonally
polarized beams should make an angle of 45¬∞ when the
cell is oriented as in instruction *4." [End of
citation]

</p><p>
I tried tripling Nd:YAG laser, but since my laser is not
polarized, and because there is huge amount of white
light from flashlamp, can‚Äôt be sure whether I got 355 nm
(THG) in UV range. For tripling frequency, there must be
actually two crystals. One after another, carefully
oriented, aligned and so on. Too much complicated for me
at this moment.

</p><p>
One of the beauty for such wide acceptance angle is for
beginners like me. Even when holding KDP crystal in
hand, one may be able to adjust close to the proper
angle, so that there is at least some green light.
Further adjusting is then easier, because it increase or
decrease intensity of doubled frequency very gently. Not
so sharp like Phase I matching. I tried that too, but it
works bad for non-polarized lasers.

</p><p>
Another good thing is that even completely fogged
crystal produce some green light. Not much, but crystal
glow green anyway. There is almost no output beam (no
visible spot), just diffuse green glowing. Even most
clear crystal produce some fluorescence which is
consequence of change in refraction indexes. I am not
completely sure how and why, because in relatively short
period read so much documents, and this matter is very
complex.

</p><p>
Such fluorescence can bee seen in clear crystals, so
that one may see the path of the laser beam.

</p><p>
In one document (can‚Äôt remember which one), they said
that fine powder can produce SHG too, but with helps of
PMT (Photo Multiplier Tube). This means that random
oriented small crystals, many of them will be
accidentally oriented close to the proper angle, so that
they can make frequency doubling. At that way, they get
very dim green light which can be seen only with aid of
PMT.

</p><div><p>
About conversion efficiency. I have no instruments for
measuring efficiency, and suppose that in my case,
efficiency of conversion is low. In one of my post to
the lasers mailing list, I mentioned that it is possible
to put KDP crystal intracavity for lasers which has not
Q-switch. On that way, one may get greater efficiency by
counting on standing waves inside laser resonator, But
this is very problematic if laser is not polarized.  My
friend Douglas Little tried it and got some green light
out too. But after few shots, one or both HR mirrors,
got optical damage. Standing wave become stronger and
stronger each time passes lasing media. Just one part is
‚Äòextracted‚Äô and converted into harmonic. It will be good
that conversion efficiency is high, so that both laser
mirrors are HR, but one of them with added high
reflectance for 532 nm. If both HR mirrors are for 1064
nm, then doubled frequency will exit at both end of the
Nd:YAG doubled laser.

</p></div><div><p>
About making seed crystals. You may use an old method of
growing crystals as a start for growing small KDP
crystals for seeds.

</p></div> 

<div><p>
An old method with string may give you bad result, so
consider alternative method, which is also simple.
</p></div> 
<p>
If you are lucky enough, and get big crystal, after
cutting to proper size and angle for SHG or THG use,
rest of the crystal may serve as seed crystal. Chose
part which is clear. Shape it and put it as a seed. Or,
if big crystal not met quality requirement, at least one
part of such crystal may serve as a seed crystal. Mostly
clear part is pyramidal part of the KDP crystal.
Prismatic part may be with inclusions, bubbles, water
pockets, and other defects.

</p><p>
I have no chance to get enough big crystal yet. For such
growing of near perfect crystals, it require more or
less sophisticated apparatus, ultra pure water, well
prepared solution etc. I use ‚Äôindustrial grade‚Äô
KH<sub>2</sub>PO<sub>4</sub>, which bought in hydroponic
store. It is marked as MKP 0-52-34. The problem with
that chemical is that there is small amount of</p></span></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.milankarakas.org/pub/KDP/HomegrownKDP.html">http://www.milankarakas.org/pub/KDP/HomegrownKDP.html</a></em></p>]]>
            </description>
            <link>http://www.milankarakas.org/pub/KDP/HomegrownKDP.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046806</guid>
            <pubDate>Tue, 10 Nov 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading, Wisely ‚Äì How I'm Using Readwise to Improve My Learning]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25046762">thread link</a>) | @ggnall
<br/>
November 10, 2020 | https://www.grahamgnall.com/blog/2020/11/9/reading-wisely | <a href="https://web.archive.org/web/*/https://www.grahamgnall.com/blog/2020/11/9/reading-wisely">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-9da5bc9359b1bdaa3cf4"><div><p>Readwise is a utility that‚Äôs changed the way I read. I'm thoroughly enjoying it and I recommend it to anyone looking to improve their learning. You can sign up for a trial here:</p>
<p><a href="https://readwise.io/">Readwise - plain link</a></p>
<p><a href="https://t.co/3y8bAXryW7?amp=1">Readwise - my referral link</a></p>
<h2 id="about">About</h2>
<p>Readwise is an app (browser extension, web app, mobile app) that organizes information from the books you read. The app relies on learning techniques like <a href="https://en.wikipedia.org/wiki/Spaced_repetition">spaced repetition</a> to train your memory on your reading highlights and annotations.</p>
<h2 id="benefits">Benefits</h2>
<p><strong>Retention</strong></p>
<p>Readwise makes it easy to retain information you‚Äôve read and deemed important in the past. I try to read constantly, but when I look at my <a href="https://www.grahamgnall.com/books">Books</a> list, there are plenty of subjects that are blurry or shockingly, missing altogether from my memory. I‚Äôve been a Kindle device/app enthusiast and previously built my own scripts to export and organize my highlights. It was fun, but I ended up spending more time writing the so-called automation than actually reviewing the highlights. Readwise handles all of the syncing automatically from all your ebooks and articles, and even supports input from physical books. Its Daily Readwise review feature is a daily, randomized feed of highlights that surfaces old and new content to train on.</p>
<p><strong>Making New Connections</strong></p>
<p>There is a thrilling feeling when your mind makes connections between two seemingly disparate topics. This is foundational in my belief in <a href="https://www.grahamgnall.com/blog/2014/7/9/learn-disciplines-not-skills-startups-for-liberal-arts-majors">liberal arts education</a> and it's applications. The simple act of viewing highlights from multiple, unrelated books in the Daily Readwise allows your brain to play with these concepts on the same plane. Readwise‚Äôs tagging feature allows you to group highlights about the same topic or theme, so you can build your knowledge base with more examples and perspectives. Both of these features aid in constructing, expanding, and applying mental models to the world, or what Charlie Munger called a <a href="https://fs.blog/great-talks/a-lesson-on-worldly-wisdom/">‚Äúlatticework‚Äù</a> of models from different disciplines.</p>
<h2 id="how-i-use-it">How I Use It</h2>
<p><strong>Set Up</strong></p>
<p>I mostly use the core Readwise syncing sources:</p>
<ol>
<li>Kindle - automated</li>
<li>Pocket - automated</li>
<li>Non-kindle ebooks - semi-automated, requires one manual step when I finish a book</li>
<li>Physical books - manual, but with highly reliable OCR.</li>
</ol>
<p>There are also other a growing number of non-traditional sources like Twitter threads and podcast annotations. I haven‚Äôt tried them out yet, but they look promising.</p>
<p>The default settings are thoughtfully done to maximize your learning right out of the box (e.g. 5 daily items, mix of old and new highlights). You can get really granular configuring these settings, down to the book/article level. So far, I‚Äôve only used this to filter out certain things, like definitions from a Javascript textbook I read in 2012. </p>
<p><strong>Developing a Review Habit</strong> </p>
<p>The best product experiences create new habits and rituals around them, for a positive result. Readwise has created a few distinct habits for me. I look forward to my Daily Readwise and it‚Äôs one of the few things I let myself do on my phone when waking up. This takes less than a minute and is easy to implement. I never have to schedule in time for this and I never miss it.</p>
<p>Readwise sits on my home screen and I‚Äôve started to open it whenever I need a ‚Äúfeed fix‚Äù. It takes my boredom trigger and offers something more valuable than a dopamine hit. Sometimes I‚Äôll do a few cycles of 5 items before calling it quits and going back to whatever I was supposed to be doing. </p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_44801"><div><p><strong>Developing Better Reading Habits</strong></p>
<p>Readwise has also changed the way I read. I now look for insights that I want to extract and return to later far more deliberately. I‚Äôve found that even for books I abandon, if I was able to pull a single interesting idea out of it, I got some value out of it. This has reduced the guilt of putting down a book that can‚Äôt hold my attention. Or in the case of many business books, lets me extract the primary bits in the beginning without slogging through the filler.</p>
<p>The same applies to how I approach articles. I now view all types of text as holding information I can extract for my own purposes. I'm excited to uncover items to clip and have been delighted by the easy inputs into Readwise, including: highlighting directly in my browser, copy/pasting text from a mobile app, or taking an image of a physical book or magazine. This lets me jot things down, like book recommendations, without having to leave the text and pick them up later. </p>
<p><strong>Organizing Information</strong></p>
<p>I‚Äôve always liked the idea of linking ideas together and this was lacking in my homegrown version of this tool. In addition to notes, you can also add freeform tags to your highlights. This makes it easy to view all your highlights that relate to theme like <code>writing</code> or <code>decision-making</code>. I use this feature to learn about a specific topic. I‚Äôm very interested in learning about the routines and processes of interesting creators, and I‚Äôve started to aggregate tags for <code>routine</code> and <code>process</code> for instance. </p>
<p>I use the Daily Review to tag anything that fits into my ongoing areas of interest.</p>
</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1604956577898_10298"><p>The free-form search is also a great way to pull in notes on a specific topic. Feeling homesick recently, I typed in ‚Äúnew york‚Äù and saw some highlights that made me smile:</p></div><div data-block-type="44" id="block-yui_3_17_2_1_1604955485534_70588"><div><h2 id="last-word">Last Word</h2>
<p>I was happy to drop my hacky version for a simple, easy, and well-designed product. It's helping me to create better habits and reinvigorating my reading pracitce.</p>
<p>I'm training myself to spend on well-designed software products so that such things can exist. Unfortunately paid apps are still a boundary for many - and hopefully the COVID trend of increased subscription spending will change that. For me, the $8.99 / month is well worth the increased utility from books I‚Äôve already purchased (usually for the low Amazon set price of $9.99). I‚Äôm sure this was intentional: get more out of your books for less than the already low price of a book a month. Better yet, it makes me <em>excited</em> to buy and read more books.</p>
<p>Of course, if you want to apply these lessons to a self-hosted system you can. You can scrape (pun intended) together your own version by parsing the Kindle Cloud Reader (and other reading apps) to a database (including no-code databases in Notion, Airtable, and even Google Sheets) and building out the necessary views. Or you can keep it lo-fi. I‚Äôve heard of several non-fiction authors using a index card based version of Readwise, where they group passages from different sources by them. I wouldn‚Äôt be surprised if this tradition influenced Readwise's card ui and tag features. </p>
<p>And then you <em>could</em> always take it further. While many in the <em>organized thinking</em> movement (or <a href="https://twitter.com/cultroam?lang=en">roamcult</a>) are using Readwise‚Äôs Notion and Roam exports to develop fully mapped information on <em>everything</em>, I find the Readwise experience to be fully satisfactory on its own.</p>
</div></div></div>]]>
            </description>
            <link>https://www.grahamgnall.com/blog/2020/11/9/reading-wisely</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046762</guid>
            <pubDate>Tue, 10 Nov 2020 15:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everyone Talks About Insecure Randomness, but Nobody Does Anything About It]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046519">thread link</a>) | @airza
<br/>
November 10, 2020 | https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html | <a href="https://web.archive.org/web/*/https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<section>
		
		<p>In which I take a crack at pointing a neural network at random noise, and achieve 95+% predictive bitwise accuracy against my hated foe in this world, Xorshift128.</p>
		<blockquote><p>"Any one who considers arithmetical methods of producing random digits is, of course, in a state of sin."</p></blockquote>
	</section>
	<section>
		<h2>What exactly are you up to here?</h2>
		<p>The motivation for this blog was a secure code review a few years ago, when looking at a client's email token generation<label for="1"></label><span>I don't actually work as an RNN jockey for work- I'm a security consultant. </span>. Frankly, I don't remember what their code looked like at <i>all</i>, but it probably looked something like this:</p>
		<figure><pre><code data-lang="python"><span>"""gotta make a token and send it to the client!"""</span>
<span>very_random_number</span> <span>=</span> <span>get_random_number</span><span>()</span>
<span>two_factor_token</span> <span>=</span> <span>convert_representation</span><span>(</span><span>very_random_number</span><span>)</span>
<span>send_email</span><span>(</span><span>"Your two factor authentication token is:"</span>
	<span>+</span><span>two_factor_token</span><span>,</span><span>user_email</span><span>)</span>
<span>save_token_to_user</span><span>(</span><span>user_id</span><span>,</span><span>two_factor_token</span><span>)</span>
		</code></pre></figure>
		<p>Code like this undergirds the security of much of the internet. A user wants to reset their password, so they enter their email. We generate a secret code and send it to their email; opening the link in the email proves that the requestor is legitimate. Sometimes we text codes like this to users when they try to login to their banks; this type of association between a random number and a user is also the backbone of a huge chunk of cookie-based authentication.</p><p>Is this code secure?  Well, it depends. Naturally, we might attack the email component (as emails are sometimes sent unencrypted, whoops) or we might attack the association between the data (maybe the token and the email are derived from attacker controlled data or whatever). The quality of the random number generation here matters as well, at least in theory: some random number generators are predictable, while others are provably difficult to attack. If we could predict this, it would be super bad- we'd just trigger the email to the victim, somehow predict the RNG, and be on our way. On the other hand, even if we are able to 'predict' this, we are still in trouble: there is no obvious way to go about it without prior knowledge of what <i>convert_representation</i> is up to.</p>
		<p>I think machine learning provides the bridge here. The thought has hung in my mind for a few years, in fact; I've picked the brains of everyone I know remotely related to the field, and I've even hired some people to take a crack at it. So far, I haven't seen any prior literature suggesting that it's been possible or done, and nobody was really sure how to approach it. Finally, thanks to a generous grant from the Phil Brass Weird Ideas Foundation<label for="2"></label><span>AKA <a href="https://www.directdefense.com/">DirectDefense</a> who was happy to sponsor this research while I was not busy bug hunting for them! </span> I was able to take a few weeks to think about it methodically.</p>
		<p>The rest of this blog is structured in a pretty straightforward way: I talk about how numbers are generated at random in a computer, then talk about how to transform that notion of randomness into a learnable problem<label for="3"></label><span>A basic knowledge of machine learning, and especially gradient descent will be helpful for understanding some of my thought process through this blog. </span>. Not surprisingly, I will then solve that problem, and propose a roadmap for how to continue chipping away at the distance between my current progress and a usable attack.</p>
	</section>
	<section>
		<h2>Our Constant State of Sin</h2>
		<p>Computers, these fucked up little rocks we have forced to think, are gambling creatures. Despite the rigid constraints that we have imposed on them, we sometimes instead demand them to be fickle beyond our own capabilities, to choose a number more wildly than any human dare dream. For example, by invoking <code>Xorshift128</code>, a rather stylishly named fellow, you can choose a number between zero and about four billion (<code>2**32</code>, to be precise), which is a number that, while you do not often have a reason to choose at random, is at least a number whose neighbors you encounter at least occasionally. More excitingly, you can invoke this function a staggering <code>2**128</code> times<label for="4"></label><span>More or less the number of atoms in every living person on earth. </span> before you encounter a repetition in its pattern of randomness.</p>
		<p><i>But how?</i> I hear you cry. That is to say, A particular problem arises here, the one I think Von Neumann was referring to above: programming a computer is the art of telling it exactly what you want it to do, more or less in advance, and telling it exactly what random stuff to come up with, <i>in advance</i>, both defeats the purpose of the program in the first place and also poses fascinating logical challenges at the programming level. Certainly you do not have time to roll four billion of <i>anything</i>, and even if you did, writing each of those numbers down in some way would be a miserable use of time and hard disk space. On the other hand, cycling through just a few of the available numbers also sounds wrong; if you cycle through just a few hundred of the integers between 0 and 2**32, you're not really providing a lot of randomness.</p>
		<p>We will set aside the question of what randomness really <i>is</i> and think about it from a programming perspective. We can define a Random Number Generator (RNG) as something that outputs a sequence of numbers. In order to make sure that they are as random as possible, we're also going to introduce something new: <i>state</i>. The state gets passed into this RNG function, and in addition to outputting a random-ish number, it is going to output <i>new</i> state- this state will be as big or bigger (usually much bigger) than the output. Then we're just going to feed this output state <i>back</i> into the RNG to generate the next number in the sequence- and that's going to give us new state, which will let us continue this for quite a while. One point of confusion is that sometimes the output is <i>also</i> used as the state<label for="5"></label><span>Astute readers will wonder: where does the original state come from? Fascinatingly, movement of the mouse, entries into the keyboard, and other minutiae of computer operation are used to generate a very small amount of randomness- that is, at some level the start comes from the simple uncertainty of everyday computer use. There isn't a lot of randomness available here, so the RNG serves to <i>stretch</i> it out over a longer period of time. </span>.</p>
		<p>To take this into the concrete, we will consider an RNG, the <b>Middle-square method</b>. Relatively ancient by RNG standards, it was invented by Von Neumann sometime in the 1940s, when he was busy inventing almost everything else. A number of <code>N</code> digits is squared, and the <code>N/2</code> middle digits of the result are taken both as the <i>output</i> as well as the <i>state</i> to square for the next iteration. The simplest case, n=2, works as follows: we start with 43, square it to produce 1849, and then take the middle two digits to get our result, 84. This 84 is also our new state, so next time we're fiending for the results of a d100, we square it again, 7056, taking the middle to get 5, our output and our new state. Okay, so next is 25, which we'll call 0025, which gives us 2, which gives us 0004, translated as 0...</p>
		<p>Uh oh. We seem to have run into a dead end here. 0 squared is of course 0. These numbers are not looking so random anymore. In fact, the behavior is pretty bad no matter what number you begin with. The figure below lists all the states/outputs showing that the tendency to degrade towards cycles is pretty unavoidable.</p>
		<figure>
			<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" height="100%" viewBox="-307 -5 300 450">
 <title>Middle square method 2 digits</title>
 <desc></desc>
 
 <defs>
  <path id="arrow" d="M 9.5,0 H 14 m -2,-2 l 2,2 l -2,2"></path>
  <g id="loop1">
   <path d="M 9,0 V 10 H 0"></path>
   <use xlink:href="#arrow" transform="translate(0,19) rotate(-90)"></use>
  </g>
  <g id="loop2">
   <path d="M 9,0 V -10 H -20"></path>
   <use xlink:href="#arrow" transform="translate(-20,-19) rotate(90)"></use>
  </g>
 </defs>
 <g font-family="sans-serif" font-size="10" font-weight="bold" text-anchor="middle" stroke-linejoin="round" stroke-linecap="round" stroke="none" fill="none">
  <rect x="-4999" y="-4999" width="9999" height="9999"></rect>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">00</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#loop1" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">01</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">04</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="0" dy="0.7ex" transform="scale(0.75,1)">07</text><path d="M 5,  0 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="10" dy="0.7ex" transform="scale(0.75,1)">71</text><path d="M 5, 10 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">02</text><path d="M 5, 20 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">05</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">84</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">29</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">36</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">19</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">14</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">12</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">11</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">46</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-240,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">92</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">77</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-280,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">76</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="20" dy="0.7ex" transform="scale(0.75,1)">42</text><path d="M 5, 20 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-300,0)"><text x="0" y="30" dy="0.7ex" transform="scale(0.75,1)">69</text><path d="M 5, 30 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-260,0)"><text x="0" y="40" dy="0.7ex" transform="scale(0.75,1)">89</text><path d="M 5, 40 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="50" dy="0.7ex" transform="scale(0.75,1)">37</text><path d="M 5, 50 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="60" dy="0.7ex" transform="scale(0.75,1)">58</text><path d="M 5, 60 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="70" dy="0.7ex" transform="scale(0.75,1)">43</text><path d="M 5, 70 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">62</text><path d="M 5, 80 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">25</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">16</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">13</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">56</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="80" dy="0.7ex" transform="scale(0.75,1)">81</text><path d="M 5, 80 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="90" dy="0.7ex" transform="scale(0.75,1)">87</text><path d="M 5, 90 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">68</text><path d="M 5,100 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="100" dy="0.7ex" transform="scale(0.75,1)">41</text><path d="M 5,100 H 9 V 100"></path><use xlink:href="#arrow" transform="translate(0,100)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="110" dy="0.7ex" transform="scale(0.75,1)">75</text><path d="M 5,110 H 9 V  80"></path><use xlink:href="#arrow" transform="translate(0, 80)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">32</text><path d="M 5,120 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">18</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">72</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="120" dy="0.7ex" transform="scale(0.75,1)">27</text><path d="M 5,120 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="130" dy="0.7ex" transform="scale(0.75,1)">61</text><path d="M 5,130 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="140" dy="0.7ex" transform="scale(0.75,1)">82</text><path d="M 5,140 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="150" dy="0.7ex" transform="scale(0.75,1)">73</text><path d="M 5,150 H 9 V 120"></path><use xlink:href="#arrow" transform="translate(0,120)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="160" dy="0.7ex" transform="scale(0.75,1)">45</text><path d="M 5,160 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="170" dy="0.7ex" transform="scale(0.75,1)">55</text><path d="M 5,170 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="180" dy="0.7ex" transform="scale(0.75,1)">95</text><path d="M 5,180 H 9 V  20"></path><use xlink:href="#arrow" transform="translate(0, 20)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">03</text><path d="M 5,190 H 9 V   0"></path><use xlink:href="#arrow" transform="translate(0,  0)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">06</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">08</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">09</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">64</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">93</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">44</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">21</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-200,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">96</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="190" dy="0.7ex" transform="scale(0.75,1)">31</text><path d="M 5,190 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-220,0)"><text x="0" y="200" dy="0.7ex" transform="scale(0.75,1)">63</text><path d="M 5,200 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-180,0)"><text x="0" y="210" dy="0.7ex" transform="scale(0.75,1)">38</text><path d="M 5,210 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="220" dy="0.7ex" transform="scale(0.75,1)">33</text><path d="M 5,220 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">78</text><path d="M 5,230 H 9 V 190"></path><use xlink:href="#arrow" transform="translate(0,190)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">28</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="230" dy="0.7ex" transform="scale(0.75,1)">17</text><path d="M 5,230 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">91</text><path d="M 5,240 H 9 V 230"></path><use xlink:href="#arrow" transform="translate(0,230)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="240" dy="0.7ex" transform="scale(0.75,1)">54</text><path d="M 5,240 H 9 V 240"></path><use xlink:href="#arrow" transform="translate(0,240)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">10</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#loop1" transform="translate(0,250)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">90</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">30</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">48</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">22</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">15</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="250" dy="0.7ex" transform="scale(0.75,1)">34</text><path d="M 5,250 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">35</text><path d="M 5,260 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="260" dy="0.7ex" transform="scale(0.75,1)">66</text><path d="M 5,260 H 9 V 260"></path><use xlink:href="#arrow" transform="translate(0,260)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="270" dy="0.7ex" transform="scale(0.75,1)">65</text><path d="M 5,270 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="280" dy="0.7ex" transform="scale(0.75,1)">85</text><path d="M 5,280 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="290" dy="0.7ex" transform="scale(0.75,1)">59</text><path d="M 5,290 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">67</text><path d="M 5,300 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="300" dy="0.7ex" transform="scale(0.75,1)">26</text><path d="M 5,300 H 9 V 300"></path><use xlink:href="#arrow" transform="translate(0,300)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">70</text><path d="M 5,310 H 9 V 250"></path><use xlink:href="#arrow" transform="translate(0,250)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">52</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="310" dy="0.7ex" transform="scale(0.75,1)">23</text><path d="M 5,310 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">39</text><path d="M 5,320 H 9 V 310"></path><use xlink:href="#arrow" transform="translate(0,310)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="320" dy="0.7ex" transform="scale(0.75,1)">86</text><path d="M 5,320 H 9 V 320"></path><use xlink:href="#arrow" transform="translate(0,320)"></use></g>
  </g>
  <g>
   <g transform="translate(-20 ,0)"><text x="0" y="330" dy="0.7ex" transform="scale(0.75,1)">50</text><path d="M 5,330 H 9 V 330"></path><use xlink:href="#loop1" transform="translate(0,330)"></use></g>
  </g>
  <g transform="translate(0,10)">
   <g transform="translate(-20 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">60</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#loop1" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">40</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">20</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">47</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-100,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">74</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-120,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">88</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-140,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">83</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-160,0)"><text x="0" y="340" dy="0.7ex" transform="scale(0.75,1)">94</text><path d="M 5,340 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="350" dy="0.7ex" transform="scale(0.75,1)">49</text><path d="M 5,350 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">80</text><path d="M 5,360 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="360" dy="0.7ex" transform="scale(0.75,1)">53</text><path d="M 5,360 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-80 ,0)"><text x="0" y="370" dy="0.7ex" transform="scale(0.75,1)">99</text><path d="M 5,370 H 9 V 360"></path><use xlink:href="#arrow" transform="translate(0,360)"></use></g>
   <g transform="translate(-60 ,0)"><text x="0" y="380" dy="0.7ex" transform="scale(0.75,1)">97</text><path d="M 5,380 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="390" dy="0.7ex" transform="scale(0.75,1)">51</text><path d="M 5,390 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="400" dy="0.7ex" transform="scale(0.75,1)">98</text><path d="M 5,400 H 9 V 340"></path><use xlink:href="#arrow" transform="translate(0,340)"></use></g>
  </g>
  <g transform="translate(0,20)">
   <g transform="translate(-20 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">24</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#loop2" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="410" dy="0.7ex" transform="scale(0.75,1)">57</text><path d="M 5,410 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
   <g transform="translate(-40 ,0)"><text x="0" y="420" dy="0.7ex" transform="scale(0.75,1)">79</text><path d="M 5,420 H 9 V 410"></path><use xlink:href="#arrow" transform="translate(0,410)"></use></g>
  </g>
 </g>
</svg>

			<label for="mn-demo">‚äï</label>
			
			<span>
				<i>Directed graph of all 100 2-digit pseudorandom numbers obtained using the middle-square method</i>, by CMG Lee.
			</span>
		</figure>
		<p>Performance for the version with 4 digits of state is better; the average length of time before being trapped in a cycle is after 43 outputs<label for="6"></label><span>Another useful property of these RNGs is that it is pretty obvious when they are starting to break down- among the 10000 numbers the 4-digit version can output, only <i><code>0, 9600, 1600, 5600, 8100, 100, 4100, 2916, 2500, 3009, 5030, 3600, 7600, 3792, 2100, 6100, 540</code></i> immediately lead to decay. </span>. That code looks something like this, just so you get the idea:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>"""The version with a 4 digit state/output
	not to be confused with the one above, that
	has two."""</span>

	<span>#e.g. 1234**2-&gt;1522756
</span>	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> 

	<span>#1522756 -&gt; 01522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span> <span>%</span> <span>square</span>

	<span>#01522756 -&gt; 5227
</span>	<span>next_state</span> <span>=</span> <span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>20</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>You can see in the above example that the state and the output are identical, but there is no particular reason this has to be the case. For example, we could have the state be the inner four numbers, with the output being the <i>outer</i> four numbers:</p>
		<figure><pre><code data-lang="python"><span>def</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>):</span>
	<span>square</span> <span>=</span> <span>state</span><span>**</span><span>2</span> <span># e.g. 1234**2-&gt;1522756
</span>	<span>formattedSquare</span> <span>=</span> <span>"%08d"</span><span>%</span><span>square</span>
	<span>output</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>0</span><span>:</span><span>2</span><span>]</span><span>+</span><span>formattedSquare</span><span>[</span><span>6</span><span>:])</span>
	<span>next_state</span> <span>=</span> <span>int</span><span>(</span><span>formattedSquare</span><span>[</span><span>2</span><span>:</span><span>6</span><span>])</span>
	<span>return</span> <span>(</span><span>next_state</span><span>,</span><span>output</span><span>)</span>
<span>state</span> <span>=</span> <span>1234</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>40</span><span>):</span>
	<span>state</span><span>,</span><span>output</span> <span>=</span> <span>much_better_von_neumann_generator</span><span>(</span><span>state</span><span>)</span>
	<span>print</span><span>(</span><span>output</span><span>)</span>
		</code></pre></figure>
		<p>This RNG is also not quite ready for prime time, but the relationship between the output and state is already harder to guess. However, they are clearly <i>interconnected</i> in some causal sense, a fact we will return to in a bit. For now, we are starting to see a few important tensions in the design of RNGs already:</p>
		<ul>
			<li><b>Unpredictability</b> ‚Äì Increasing the number of digits in the output/state increases the unpredictability of the output. Sometimes less adroitly designed algorithms (like the one above) will eventually degenerate to some kind of undesirable low-randomness state, but most ones in use in computers simply will iterate through their entire state in some order before returning to the original one. Among the generators that look superficially okay, there are a lot of mathematically interesting ways to verify this intuition: we can count the number of bits to make sure it is evenly distributed; we can figure out if the runs of ones and zeros look OK, and a ‚Ä¶</li></ul></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html">https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</a></em></p>]]>
            </description>
            <link>https://www.airza.net/2020/11/09/everyone-talks-about-insecure-randomness-but-nobody-does-anything-about-it.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046519</guid>
            <pubDate>Tue, 10 Nov 2020 14:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The state of JavaScript at the end of 2020]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046293">thread link</a>) | @milo_im
<br/>
November 10, 2020 | https://www.ideamotive.co/javascript-business-guide | <a href="https://web.archive.org/web/*/https://www.ideamotive.co/javascript-business-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
           <p><span id="hs_cos_wrapper_pillarPage_content" data-hs-cos-general-type="widget_container" data-hs-cos-type="widget_container"><p id="hs_cos_wrapper_widget_1603280203415" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>00</span>
        
        
          <span>State of JavaScript in 2020 [INFOGRAPHIC]</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1603200140243" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p><img src="https://www.ideamotive.co/hs-fs/hubfs/Pillar%20JS/JavaScript%20in%202020%20C%20(4).png?width=1439&amp;quality=low" alt="JavaScript in 2020 C (4)"></p>

    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603280336294" data-hs-cos-general-type="widget" data-hs-cos-type="module">









  <div>
    <p> Share the infographic in social media </p>
    
  </div>


</div>
<p id="hs_cos_wrapper_widget_1601646578122" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    
      <h2>
        
          <span>01</span>
        
        
          <span>What is JavaScript?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601646616007" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>You might have heard that ‚ÄúJavaScript is everywhere.‚Äù Which is where exactly?&nbsp;&nbsp;</p>
<p>According to <a href="https://w3techs.com/technologies/details/cp-javascript" rel="noopener" target="_blank">Web3Techs</a> ‚Äî on over 96% of all websites. Google, LinkedIn, Yahoo, YouTube, eBay, Amazon, you name it. There‚Äôs JavaScript all over the place.&nbsp;</p>
<p>Created in 1995 by Brendan Eich, JavaScript is a scripting language used to build and manage dynamic web content, such as multimedia, interactive forms, animations, photo slideshows, calendars, autocomplete suggestions, and much more.</p>
<p>JS is one of the three core technologies of frontend web development, along with HTML and CSS. While HTML is a markup language responsible for giving the structure to a website, and CSS is a language used to apply styles to HTML content, JavaScript is responsible for creating and managing dynamic, interactive website elements.</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069795205" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        Who is the JavaScript creator?
      </h3>
    
    
      <div>
        <p>Born in 1961, <a href="https://www.linkedin.com/in/brendaneich/" rel="noopener" target="_blank"><span>Brendan Eich</span></a> is an American technologist, software engineer, and keynote speaker. After joining Netscape Communications in 1995, Eich created a language to support the browser. It was designed based on Java‚Äôs syntax and standard library, and with object names that corresponded to Java classes.&nbsp;</p>
<p>In 1998, Eich co-founded the Mozilla project, ultimately leading to the creation of the Mozilla Foundation, which later became <a href="https://www.mozilla.org/en-US/foundation/moco/" rel="noopener" target="_blank"><span>Mozilla Corporation</span></a>. After leaving Mozilla, Eich set up another company, <a href="https://brave.com/" rel="noopener" target="_blank"><span>Brave Software</span></a>, developing a privacy-oriented browser combined with a blockchain-based digital advertising platform.</p>
      </div>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601646749682" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>Is JavaScript a programming language?</h3>
<p>Yes! As the name implies ‚Äî JavaScript is a <em>scripting language</em>. Traditionally, scripting languages are executed one line at a time by an interpreter, so a computer program that directly executes the written instructions. This stands in opposition to <em>compiled languages</em>, such as C++, for instance, which must run through a compiler before they can be translated into binary code.&nbsp;</p>
<p>Currently, it is possible to run JS with a just-in-time compiler, too. It compiles the code on the fly and caches the result to speed up the subsequent runs. Still, JavaScript remains a scripting language.</p>
<p>&nbsp;As a programming language, JavaScript is:</p>
<ul>
<li><strong>High-level</strong> ‚Äì high-level languages resemble natural languages or mathematical notation, which helps simplify programming, including code updates and extensions.</li>
<li><strong>Dynamic </strong>‚Äì as a dynamic language, JS uses dynamically-written code to quickly implement functionality to an application, in a way that enhances programming efficiency.</li>
<li><strong>Prototype-based </strong>‚Äì JavaScript‚Äôs structure is based on prototypical objects, which can be cloned and reused as templates to build new objects. Prototypes also enable building associations between objects in JS. Copying and modifying objects are more direct than in class-based languages such as Java, which simplifies coding and reduces the programmer‚Äôs cognitive load.</li>
<li><strong>Multi-paradigm </strong>‚Äì JS supports event-driven, functional, and imperative programming styles, which makes it a multi-paradigm language. This results in its flexibility and enables different approaches to development.&nbsp;</li>
</ul>
<h3>Is JavaScript open source?</h3>
<p>Open source applies to software, and JS is a programming language, so no, JS is not open source. However, it‚Äôs an open standard that conforms to <a href="https://www.ecma-international.org/ecma-262/" rel="noopener" target="_blank"><span>ECMAScript</span></a> specification. Anyone can use it to develop their own implementations.&nbsp;</p>
<p>For JS to produce any output, we need <a href="https://en.wikipedia.org/wiki/Interpreter_(computing)" rel="noopener" target="_blank"><span>interpreter engines</span></a>, each of which is subject to its own license agreement. For example, <a href="https://v8.dev/" rel="noopener" target="_blank"><span>Google‚Äôs V8</span></a>, <a href="https://github.com/facebook/hermes" rel="noopener" target="_blank"><span>Facebook‚Äôs Hermes</span></a>, or <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Projects/Rhino" rel="noopener" target="_blank"><span>Mozilla‚Äôs Rhino</span></a>, they are all open source. By contrast, <a href="https://jerryscript.net/" rel="noopener" target="_blank"><span>Jerryscript</span></a> is licensed under the Apache License.</p>
<h3>The difference between JavaScript library and framework</h3>
<p>While interpreters are essential to generate JS output, frameworks and libraries are optional but highly recommended. These are <strong>prewritten components that your JavaScript team can use to build robust, highly-performant code faster</strong>. They offer significant advantages to your business, too, from reducing code size and complexity to speeding up the deployment of your project.&nbsp;</p>
<p>Sometimes, e.g., in the case of React, it‚Äôs hard to categorically determine whether a given resource is a framework or a library. Nevertheless, in theory, the two notions are distinct.</p>
<p><strong><img src="https://www.ideamotive.co/hubfs/The%20difference%20between%20JavaScript%20library%20and%20framework%20(2).png" alt="The difference between JavaScript library and framework (2)"></strong></p>
<h4>Framework</h4>
<p>A <strong>framework </strong>is a software platform that lays the groundwork for programmers to develop applications. You can compare it to a house plan or blueprint that needs to be populated with input before the construction begins.&nbsp;</p>
<p>Same with a software framework; it is pre-equipped with code for predefined classes, workflows, and functions, but needs specific details to be supplied by the programmer before it can run a complete code.&nbsp;</p>
<p>Popular JS frameworks include Angular, Bootstrap, and Vue.js.</p>
<p><strong>Jump to </strong><a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener"><strong><span>this section</span></strong></a><strong> to learn more about JS frameworks.&nbsp;</strong></p>
<h4>Library</h4>
<p>A <strong>library</strong>, like a framework, refers to a reusable piece of code; however, libraries are usually focused on delivering a specific functionality/component, and give developers greater freedom over the code structure than frameworks. Coming back to the house metaphor: libraries can be compared to ready-made pieces of furniture or appliances that we choose to make our home complete.&nbsp;</p>
<p>The main difference between a library and a framework is that a library contains snippets of ready-made code that needs to be still arranged by the developer into a workflow. Frameworks, on the other hand, are in charge of running workflows. Additionally, one framework can utilize multiple libraries.</p>
<p>There are dozens of JS libraries available, with DOJO, jQuery, and React topping popularity charts.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1602069971226" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
    
      <p>While most JavaScript developers rely on specific frameworks and libraries, some of them also build applications using the so-called ‚ÄúVanilla JavaScript,‚Äù i.e., pure JS code without any additional resources. However, this approach is infrequent.</p>
    
  </div>

</div>
<div id="hs_cos_wrapper_widget_1601647248048" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>How does JavaScript work?</h3>
<p>JavaScript is primarily used in the form of<strong> client-side JavaScript</strong>. This means it is typically running on client devices (laptops, smartphones, PCs, and others) communicated with the network.&nbsp;</p>
<p>In the client-side context, scripts execute directly in the browser, which results in faster processing and immediate response to the user‚Äôs requests. Because of the speed and more lightweight script processing on the client side, this model is preferred to implement dynamic, interactive web content and handle user interactions.</p>
<p>An extended version of JS allows it to be run on the server side, with backend access to files, databases, and servers. In this context, JS code is created similarly to C, Java, or any other server-side language.</p>
<p><strong>Server-side JavaScript</strong> can be applied to handle logging in, manage personal information and preferences, and fetch specific files or data as requested by the user. <a href="https://nodejs.org/" rel="noopener" target="_blank"><span>NodeJS</span></a> is commonly used as a runtime environment to execute JavaScript code outside a web browser</p>
<p><strong>See also section <a href="https://www.ideamotive.co/javascript-business-guide#the-most-popular-javascript-frameworks" rel="noopener">The most popular JavaScript frameworks</a>.</strong></p>
<p>Currently, JS is the only commonly-recognized client-side language for browsers apart from WebAssembly, which is rather to be seen as a complementary technology. Alternative solutions like Java applets, Silverlight, or ActiveX, have all been discontinued by now.&nbsp;</p>
    </div>
  </section>

</div>
<div id="hs_cos_wrapper_widget_1603785890114" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <div id="">
    
      <h3>
        What is the difference between Java and JavaScript?
      </h3>
    
    
      <p>We‚Äôve seen it happen too many times... A job posting for JavaScript talent with a ‚ÄúJava Developer‚Äù header. A few years ago, the confusion between the two languages was so common it became anecdotal. Today, it seems to be a thing of the past.The two languages could not be further from the same thing. Still, just in case you (or your HR department) need a little recap, here are the core differences between Java and JS:</p>
    
  </div>

</div>

<div id="hs_cos_wrapper_widget_1601896662232" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <h3>What can you build with JavaScript?</h3>
<p>Originally, JavaScript was conceived to add interactivity into static browser pages. While today, it is still mostly used to enrich websites with animated, lively components, its capabilities also cover the creation of:</p>
<ul>
<li>Robust web and server applications</li>
<li>Stunning business presentations</li>
<li>Interactive gaming platforms</li>
<li>Multi-functional mobile apps</li>
<li>Smart device applications&nbsp;</li>
</ul>
<p><strong><br>For more details</strong><a href="https://www.ideamotive.co/javascript-business-guide#what-is-javascript-used-for" rel="noopener"><strong><span> jump to the next chapter</span></strong></a></p>
<h3><span>How is JavaScript different from TypeScript?</span></h3>
<p>If you already have some grasp of JavaScript, you might have stumbled upon <a href="https://www.typescriptlang.org/" rel="noopener" target="_blank"><span>TypeScript</span></a>. A superset of JS, TypeScript is a modern programming language developed and maintained by Microsoft. It was publicly released in 2012 as a tool for the development of large applications in JS (‚ÄúJavaScript that scales‚Äù ‚Äî states the official slogan). TypeScript simplifies JavaScript code, making it easier to read and debug, and at the same time, it expands on JS capabilities.</p>
<p><strong>See also: </strong><a href="https://www.ideamotive.co/javascript-business-guide#javascript-vs-typescript" rel="noopener"><strong><span>JavaScript vs. TypeScript</span></strong></a></p>
    </div>
  </section>

</div>
<p id="hs_cos_wrapper_widget_1601896842863" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="what-is-javascript-used-for">
    
      <h2>
        
          <span>02</span>
        
        
          <span>What is JavaScript used for?</span>
        
      </h2>
    
  </section>

</p>
<div id="hs_cos_wrapper_widget_1601896857056" data-hs-cos-general-type="widget" data-hs-cos-type="module">


  <section id="">
    <div>
      <p>In the introduction, we have already covered some of the key JavaScript applications. Here, we will add some more details about each use of the language.</p>
<h3>Adding interactive website components</h3>
<p>JavaScript was made to create and control dynamic website content, and this task remains its primary application. A vast majority of developers use JS to enhance Internet web pages with interactive features such as:</p>
<ul>
<li>dynamic forms</li>
<li>animated graphics</li>
<li>autocomplete suggestions</li>
<li>photo slideshows</li>
</ul>
<p>If we said that everyone uses JS on their website, this wouldn‚Äôt be much of an overstatement. JS powers over 90% of all global sites, including those of ‚Ä¶</p></div></section></div></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ideamotive.co/javascript-business-guide">https://www.ideamotive.co/javascript-business-guide</a></em></p>]]>
            </description>
            <link>https://www.ideamotive.co/javascript-business-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046293</guid>
            <pubDate>Tue, 10 Nov 2020 14:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue 3.0 Components Library]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046142">thread link</a>) | @quatro444
<br/>
November 10, 2020 | https://quatrochan.github.io/Equal/ | <a href="https://web.archive.org/web/*/https://quatrochan.github.io/Equal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quatrochan.github.io/Equal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046142</guid>
            <pubDate>Tue, 10 Nov 2020 14:17:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU has plans for a European Internet with a firewall [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25046096">thread link</a>) | @MaKey
<br/>
November 10, 2020 | https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39 | <a href="https://web.archive.org/web/*/https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.europarl.europa.eu/RegData/etudes/STUD/2020/648784/IPOL_STU(2020)648784_EN.pdf#page=39</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046096</guid>
            <pubDate>Tue, 10 Nov 2020 14:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitdefender: UPX Unpacking Featuring Ten Memory Corruptions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25046084">thread link</a>) | @landave
<br/>
November 10, 2020 | https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/ | <a href="https://web.archive.org/web/*/https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>This post breaks the two-year silence of this blog, showcasing a selection of memory corruption vulnerabilities in Bitdefender‚Äôs anti-virus engine.</p>
<h2 id="introduction">Introduction</h2>
<p>The goal of binary packing is to compress or obfuscate a binary, usually to save space/bandwidth or to evade malware analysis.
A packed binary typically contains a compressed/obfuscated data payload. When the binary is executed, a loader decompresses this payload and then jumps to the actual entry point of the (inner) binary.
Most anti-virus engines support binary unpacking at least for packers (such as <a href="https://upx.github.io/">UPX</a>) that are very popular and that are also used by non-malware software.</p>
<p>This blog post is about UPX unpacking of PE binaries in the Bitdefender core engine. The main steps in UPX unpacking of PE binary files are the following:</p>
<ol>
<li>Detect the loader from the entry point</li>
<li>Find the compressed data payload and extract it</li>
<li>Unfilter the extracted code</li>
<li>Rebuild various structures (such as the import table, the relocation table, the export table, and the resources)</li>
</ol>
<p>The following vulnerabilities are presented in the control-flow order of the UPX unpacker.</p>
<p><strong>Disclaimer</strong>: In the following, decompiled code from Bitdefender‚Äôs core engine is presented.
The naming of variables, fields, and macros is heavily inspired by the <a href="https://github.com/upx/">original UPX</a>. For some snippets, a reference to the original function is added for comparison. It is likely that some types are incorrect.</p>

<p>After the UPX loader has been detected, the Bitdefender engine tries to detect whether the loader applies a specific kind of deobfuscation to the compressed data payload before extracting it. The (de)obfuscation is very simple, making only use of the three operations ADD, XOR, and ROTATE_LEFT.
If this deobfuscation is detected, then the engine iterates through the corresponding instructions of the loader and parses them with their operands in order to be able to deobfuscate the data as well. This looks as follows:</p>
<div><pre><code data-lang="cpp"><span>int32_t</span> operation[<span>16</span>]; <span>// on the stack
</span><span></span><span>int32_t</span> operand[<span>16</span>]; <span>// on the stack
</span><span></span><span>int</span> i <span>=</span> <span>0</span>;
<span>int</span> pos <span>=</span> <span>0</span>;
<span>do</span> {
  <span>bool</span> op_XOR_or_ADD <span>=</span> <span>false</span>;
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0x81u</span>
    <span>&amp;&amp;</span> (loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x34</span>  <span>||</span> loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x4</span>)) {
      operation[i] <span>=</span> (loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>0x34</span>) <span>?</span> <span>OP_XOR</span> : OP_ADD;
      operand[i] <span>=</span> <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>loaderdata[pos <span>+</span> <span>3</span>];
<span>      <span>++</span>i;
</span>      pos <span>+=</span> <span>7</span>;
      op_XOR_or_ADD <span>=</span> <span>true</span>;
    }
  }
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0xC1u</span> <span>&amp;&amp;</span> loaderdata[pos <span>+</span> <span>1</span>] <span>==</span> <span>4</span>) {
    operation[i] <span>=</span> OP_ROTATE_LEFT;
    operand[i] <span>=</span> loaderdata[pos <span>+</span> <span>3</span>];
<span>    <span>++</span>i;
</span>    pos <span>+=</span> <span>4</span>;
<span>    <span>if</span> (i <span>==</span> <span>16</span>) <span>break</span>;
</span>    <span>continue</span>;
  }
  <span>if</span> (op_XOR_or_ADD) {
<span>    <span>if</span> (i <span>==</span> <span>16</span>) <span>break</span>;
</span>    <span>continue</span>;
  }
  <span>if</span> (loaderdata[pos] <span>==</span> <span>0xE2u</span>) { <span>/* omitted: apply collected operations */</span> }
  pos <span>+=</span> <span>2</span>;
} <span>while</span> (pos <span>+</span> SOME_SLACK <span>&lt;</span> loaderdata_end);
</code></pre></div><p>Observe how the bound-check on the index variable <code>i</code> is performed. As the buffer <code>loaderdata</code> is fully attacker-controlled, it is easy to verify that we can increase the index variable <code>i</code> by two before running into one of the checks <code>i == 16</code>. In particular, we can increase <code>i</code> from 15 to 17, after which we can overwrite the stack with completely arbitrary data.</p>
<div><pre><code data-lang="python">(<span>10</span>ec<span>.</span><span>12</span>dc): Break instruction exception <span>-</span> code <span>80000003</span> (first chance)
<span>00000000</span><span>`</span><span>0601</span>fe42 cc              <span>int</span>     <span>3</span>
</code></pre></div><p>The debug break is due to the stack canary which we have overwritten. If we continue, we see that the return fails because the stack is corrupted.</p>
<div><pre><code data-lang="python"><span>0</span>:<span>000</span><span>&gt;</span> g
(<span>10</span>ec<span>.</span><span>12</span>dc): Access violation <span>-</span> code c0000005 (first chance)
First chance exceptions are reported before <span>any</span> exception handling<span>.</span>
This exception may be expected <span>and</span> handled<span>.</span>
<span>00000000</span><span>`</span><span>06006603</span> c3              ret

<span>0</span>:<span>000</span><span>&gt;</span> dd rsp
<span>00000000</span><span>`</span><span>0014</span>ed98  deadbeef deadbeef deadbeef deadbeef
<span>00000000</span><span>`</span><span>0014</span>eda8  deadbeef deadbeef deadbeef deadbeef
</code></pre></div>
<p>The collected operations (for the deobfuscation shown in //1//) are applied to the payload buffer at an attacker-controlled offset <code>write_offset</code>.
Obviously, this offsets needs to be checked before writing to it. There are two checks on <code>write_offset</code>. The first is</p>
<div><pre><code data-lang="cpp"><span>if</span> (write_offset <span>&lt;=</span> extractobj<span>-&gt;</span>dword10 <span>+</span> <span>3</span>) 
</code></pre></div><p>and the second one is</p>
<div><pre><code data-lang="cpp"><span>if</span> (loaderdata[pos] <span>==</span> <span>0xE2u</span>) {
  <span>if</span> (write_offset <span>&gt;=</span> extractobj<span>-&gt;</span>dword10 <span>-</span> <span>3</span>)
</code></pre></div><p>Both checks test against the field <code>dword10</code>. The field <code>dword10</code>, sitting on the calling functions‚Äôs stack frame, is never initialized. This makes the bound check useless and introduces a fully attacker-controlled heap buffer overflow.</p>

<p>After the extraction, the engine attempts to deobfuscate the extracted data with a static XOR key.</p>
<div><pre><code data-lang="cpp"><span>for</span>(<span>int</span> i<span>=</span><span>0</span>; i<span>&lt;</span><span>0x300</span>; i<span>++</span>) {
  <span>if</span> (<span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>entrypoint_data[i] <span>==</span> <span>0x4243484B</span>) {
    <span>int32_t</span> j <span>=</span> i <span>+</span> <span>0x4A</span>;
    <span>uint8_t</span> xor_key <span>=</span> entrypoint_data[j]; <span>// attacker-controlled
</span><span></span>    <span>int32_t</span> xor_len <span>=</span> <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>entrypoint_data[j <span>-</span> <span>7</span>]; <span>// attacker-controlled
</span><span></span>    <span>if</span> (xor_len <span>&gt;</span> packer<span>-&gt;</span>set_to_size_of_rawdata) <span>return</span> j; <span>// &lt;-- wrong bound check
</span><span></span>    <span>for</span>(<span>int32_t</span> k<span>=</span><span>0</span>; k<span>&lt;</span>xor_len; k<span>++</span>) {
<span>      packer<span>-&gt;</span>extracted_data[k] <span>^=</span> xor_key; <span>// &lt;-- oob write
</span></span><span></span>    }
    <span>*</span>info_string <span>=</span> <span>"encrypted"</span>;
  }
}
</code></pre></div><p>The bound check is completely wrong. It should check against the size of the extracted data buffer. Instead, it checks against a value that is previously set to the raw data size of the section we extracted the data from. Those two sizes have nothing to do with each other. In particular, one can be much smaller than the other, or vice-versa.</p>
<p>As the function does not return after the first deobfuscation run, the memory corruption can be triggered up to 0x300 times in a row.
This allows us to bypass the limitation that in a single deobfuscation run we always XOR with the same byte. We would simply XOR as follows:</p>
<div><pre><code data-lang="cpp">First run (i<span>=</span><span>0</span>)<span>:</span>  XOR with B0 B0 B0 B0 B0 B0 B0
Second run (i<span>=</span><span>1</span>)<span>:</span> XOR with B1 B1 B1 B1 B1
Third run (i<span>=</span><span>2</span>)<span>:</span>  XOR with B2 B2
</code></pre></div><p>Overall, we then have XORed with C0 C0 C1 C1 C1 C2 C2 for completely arbitrary C0, C1, and C2. We can essentially XOR with such a pattern of almost arbitrary length, and switch the byte at most 0x300 times.</p>
<p>Needless to say, this vulnerability is a useful exploitation primitive as it enables very powerful memory corruptions: XORing allows us to modify selectively only certain parts of data, leaving other parts (for example heap metadata or critical objects) untouched.</p>
<h2 id="4-heap-buffer-overflow-in-the-filters">//4//: Heap Buffer Overflow in the Filters</h2>
<p>A filter is a simple transformation on binary code (say, x86-64 code) that is applied before compression, with the goal to make the code more compressible. After we have decompressed the data, we need to revert this filtering.
Bitdefender supports about 15 different filters. Here is one of them (filter 0x11):</p>
<div><pre><code data-lang="cpp"><span>int32_t</span> bytes_to_filter <span>=</span> <span>/* omitted. is guaranteed not to be oob. */</span>; 
<span>int</span> i <span>=</span> <span>0</span>;
<span>while</span> (<span>1</span>) {
  <span>do</span> {
    <span>if</span> (<span>--</span>bytes_to_filter <span>&lt;</span> <span>0</span>) <span>break</span>;
  } <span>while</span> (extracted_data[i<span>++</span>] <span>!=</span> <span>0xE8u</span>);
  <span>if</span> (bytes_to_filter <span>&lt;</span> <span>0</span>) <span>break</span>;
  <span>*</span>(<span>int32_t</span> <span>*</span>)<span>&amp;</span>extracted_data[i] <span>-=</span> i; <span>// &lt;-- oob write
</span><span></span>  i <span>+=</span> <span>4</span>;
}
</code></pre></div><p>The problem is that <code>bytes_to_filter</code> is only updated when <code>i</code> is incremented by one, but not when it is later incremented by four.</p>
<p>Of the 15 filters, about 8 seem to be affected by such a heap buffer overflow. I treated them all together as one bug (after all, it is not unlikely that they share code).</p>
<h2 id="5-heap-buffer-overflow-when-rebuilding-imports">//5//: Heap Buffer Overflow when Rebuilding Imports</h2>
<p>The following memory corruption occurs in a loop of the function PeFile::rebuildImports (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">PeFile::rebuildImports</a>). It looks like this:</p>
<div><pre><code data-lang="cpp"><span>this</span><span>-&gt;</span>im<span>-&gt;</span>iat <span>=</span> <span>this</span><span>-&gt;</span>iatoffs;
<span>this</span><span>-&gt;</span>newiat <span>=</span> <span>&amp;</span>extract_obj<span>-&gt;</span>extracted_data[<span>this</span><span>-&gt;</span>iatoffs <span>-</span> (<span>uint64_t</span>)(<span>uint32_t</span>)pefile<span>-&gt;</span>rvamin];
<span>while</span> (<span>*</span>p) {
  <span>if</span> (<span>*</span>p <span>==</span> <span>1</span>) {
    ilen <span>=</span> strlen(<span>++</span>p) <span>+</span> <span>1</span>;
    <span>if</span> (<span>this</span><span>-&gt;</span>inamespos) {
      <span>if</span> (ptr_diff(<span>this</span><span>-&gt;</span>importednames,<span>this</span><span>-&gt;</span>importednames_start) <span>&amp;</span> <span>1</span>) <span>--</span><span>this</span><span>-&gt;</span>importednames;
<span>      memcpy(<span>this</span><span>-&gt;</span>importednames <span>+</span> <span>2</span>, p, ilen); <span>// &lt;-- memory corruption
</span></span><span></span>      <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ptr_diff(<span>this</span><span>-&gt;</span>importednames,extract_obj<span>-&gt;</span>extracted_data <span>-</span> pefile<span>-&gt;</span>rvamin);
      <span>this</span><span>-&gt;</span>importednames <span>+=</span> ilen <span>+</span> <span>2</span>;
      p <span>+=</span> ilen;
    }
    <span>else</span> {
      <span>//omitted, see below //5//
</span><span></span>    }
  }
  <span>else</span> <span>if</span> (<span>*</span>p <span>==</span> <span>0xFFu</span>) {
    p <span>+=</span> <span>3</span>;
    <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ord_mask <span>+</span> <span>*</span>(<span>uint16_t</span> <span>*</span>)(p <span>+</span> <span>1</span>);
  }
  <span>else</span> {
    <span>// omitted
</span><span></span>  }
  <span>++</span><span>this</span><span>-&gt;</span>newiat;
}
</code></pre></div><p>The length <code>ilen</code> that is passed to memcpy is completely attacker-controlled and thus needs to be checked. Observe that the <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2847">original UPX</a> does a checked omemcpy at this place.</p>
<h2 id="6-another-heap-buffer-overflow-when-rebuilding-imports">//6//: Another Heap Buffer Overflow when Rebuilding Imports</h2>
<p>In the same loop of the function PeFile::rebuildImports (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">PeFile::rebuildImports</a>), there is another memory corruption:</p>
<div><pre><code data-lang="cpp"><span>this</span><span>-&gt;</span>im<span>-&gt;</span>iat <span>=</span> <span>this</span><span>-&gt;</span>iatoffs;
<span>this</span><span>-&gt;</span>newiat <span>=</span> <span>&amp;</span>extract_obj<span>-&gt;</span>extracted_data[<span>this</span><span>-&gt;</span>iatoffs <span>-</span> (<span>uint64_t</span>)(<span>uint32_t</span>)pefile<span>-&gt;</span>rvamin];
<span>while</span> (<span>*</span>p) {
  <span>if</span> (<span>*</span>p <span>==</span> <span>1</span>) {
    ilen <span>=</span> strlen(<span>++</span>p) <span>+</span> <span>1</span>;
    <span>if</span> (<span>this</span><span>-&gt;</span>inamespos) {
      <span>//omitted, see above //5//
</span><span></span>    }
    <span>else</span> {
      extracted_data <span>=</span> extract_obj<span>-&gt;</span>extracted_data;
      dst_ptr <span>=</span> (extracted_data <span>-</span> pefile<span>-&gt;</span>rvamin) <span>+</span> (<span>*</span><span>this</span><span>-&gt;</span>newiat <span>+</span> <span>2</span>);
      <span>if</span> (dst_ptr <span>&lt;</span> extracted_data) <span>return</span> <span>0</span>;
      extracted_data_end <span>=</span> <span>&amp;</span>extracted_data[extract_obj<span>-&gt;</span>extractbuffer_bytes_written];
      <span>if</span> (dst_ptr <span>&gt;</span> extracted_data_end <span>||</span> <span>&amp;</span>dst_ptr[ilen <span>+</span> <span>1</span>] <span>&gt;</span> extracted_data_end) <span>return</span> <span>0</span>;
<span>      strcpy(dst_ptr,p); <span>// &lt;-- memory corruption
</span></span><span></span>      p <span>+=</span> ilen;
    }
  }
  <span>else</span> <span>if</span> (<span>*</span>p <span>==</span> <span>0xFFu</span>) {
    p <span>+=</span> <span>3</span>;
    <span>*</span><span>this</span><span>-&gt;</span>newiat <span>=</span> ord_mask <span>+</span> <span>*</span>(<span>uint16_t</span> <span>*</span>)(p <span>+</span> <span>1</span>);
  }
  <span>else</span> {
    <span>// omitted
</span><span></span>  }
  <span>++</span><span>this</span><span>-&gt;</span>newiat;
}
</code></pre></div><p>The problem is that the strings <code>dst_ptr</code> and <code>p</code> can overlap, so we overwrite the string that we called strlen() on earlier.
This can turn a terminating null-byte into a non-null byte and when strcpy() is called, the string is longer than expected, overflowing the buffer.</p>
<p>A possible fix is to replace the <code>strcpy(dst_ptr,p)</code> with <code>memmove(dst_ptr,p,ilen)</code>.</p>
<p>It looks like <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/pefile.cpp#L2832">original UPX</a> is affected as well. The two commits <a href="https://github.com/upx/upx/commit/14992260c60b8d6677a677a9cdfae98b11353df7">14992260</a> and <a href="https://github.com/upx/upx/commit/1faaba8f4ce56eb5df8ce24bb4f04d665b87b4fa">1faaba8f</a> are an attempt to fix the problem in the devel branch of UPX.</p>
<h2 id="7-heap-buffer-overflow-when-unoptimizing-the-relocation-table">//7//: Heap Buffer Overflow when Unoptimizing the Relocation Table</h2>
<p>Another memory corruption is in the function Packer::unoptimizeReloc (cf. <a href="https://github.com/upx/upx/blob/d7ba31cab8ce8d95d2c10e88d2ec787ac52005ef/src/packer.cpp#L990">Packer::unoptimizeReloc</a>):</p>
<div><pre><code data-lang="cpp"><span>for</span> (<span>uint8_t</span> <span>*</span> p <span>=</span> <span>*</span>in; <span>*</span>p; p<span>++</span>, relocn<span>++</span>) {
  <span>if</span> (<span>*</span>p <span>&gt;=</span> <span>0xF0u</span>) {
    <span>if</span> (<span>*</span>p <span>==</span> <span>0xF0u</span> <span>&amp;&amp;</span> <span>!*</span>(<span>uint16_t</span> <span>*</span>)(‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/">https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/</a></em></p>]]>
            </description>
            <link>https://landave.io/2020/11/bitdefender-upx-unpacking-featuring-ten-memory-corruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25046084</guid>
            <pubDate>Tue, 10 Nov 2020 14:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hands on with: MeiliSearch ‚Äì A next generation search engine for modern web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25045927">thread link</a>) | @piterrro
<br/>
November 10, 2020 | https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web | <a href="https://web.archive.org/web/*/https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <div>
                            <p><strong>In this post, I‚Äôm gonna review the Meilisearch repository which describes itself as a ‚ÄúLightning Fast, Ultra Relevant and Typo-Tolerant Search Engine‚Äù. There were couple of things that caught my eye with this project...</strong></p>

<h3>Quick intro: What is the ‚ÄúHands on with X‚Äù series?</h3>
<p>This is a series of blog posts in which we focus on open source technologies encountered in the course of our research for new development projects or while browsing latest news from a development environment which is close to our minds in our day to day work. One day I realized that my Github account is full of starred repositories containing interesting tools, databases, libraries and other cutting-edge technologies that seem to be very interesting for me. I was alway staring at them on Github for later review but never got a chance to really use them. That‚Äôs when the idea for this blog post series was born. I was having a feeling that a lot of users are in the same situation, they starred a repository because they might have used it in the future and was curious how it works, but never got a chance to do that. So for the next couple of posts I‚Äôm gonna focus on reviewing and using interesting and popular repositories I‚Äôve found on Github for the past couple of years.
</p>



<h3 id="h">Table of contents</h3>
<ul>
    <li><a href="#h2"> - Motivations for reviewing Meilisearch</a></li>
    <li><a href="#h3"> - Github repository and Readme</a></li>
    <li><a href="#h4"> - The data set for testing purposes</a></li>
    <li><a href="#h5"> - Kicking it off - Download binary and start the server</a></li>
    <li><a href="#h6"> - Prepare the data to be ingested</a></li>
    <li><a href="#h7"> - Indexing first collection</a></li>
    <li><a href="#h8"> - Indexing speed</a></li>
    <li><a href="#h9"> - Making search queries</a></li>
    <li><a href="#h10"> - Frontend integration</a></li>
    <li><a href="#h11"> - Would I recommend MeiliSearch?</a></li>
    <li><a href="#h12"> - Conclusions</a></li>
</ul>
<hr>

<h3 id="h2">Motivations for reviewing Meilisearch</h3>
<p><strong>Its search engine</strong>. I‚Äôm not a heavy user of search engines in my day-to-day projects. I know Elasticsearch and Spinx are among the most popular ones. I also have some experience with TSvector in Postgresql which allowed to create simple ‚Äúsearch engine features‚Äù within Postgresql database. But that's it, so I‚Äôm curious how that new Meilisearch project accommodates itself in this long-inhabited environment.</p>

<p><strong>Its written in Rust</strong> which is interesting so that Rust is very close to bare metal. It‚Äôs also a new technology and most of the search engines we have are written in C++ or Java. I feel that a new perspective from a totally new language might be worth a try.</p>

<p>Since it‚Äôs Rust, it compiles to a single binary and it's portable, so that means no more long hours of building a project which would make deploying along with any other project a breeze.</p>

<p><strong>It claims to have ‚Äúsearch as-you-type experience‚Äù</strong> which means that it is able to return results so fast that it returns results for EVERY keystroke. Interesting given the fact that the Readme file doesn‚Äôt contain information about reference dataset authors used to support that claim. Of course it is not possible for a dataset of any size and for smaller data sets it's trivial, so I wanted to learn how long Meilisearch is able to support that claim, given that I‚Äôll be using a bigger than usual dataset.
</p>

<h3 id="h3">Github repository and Readme</h3>
<p>The url address of Github repository is <a href="https://github.com/meilisearch/MeiliSearch">https://github.com/meilisearch/MeiliSearch</a>. As of the beggining of the September 2020, the repository has over 9k stars and over 30 contributors. The commits are pushed more or less weekly. The tool seem to have small community around it so its definitely not a dead project. In addition Meili raised 1,5M euros in their first funding round (<a href="https://blog.meilisearch.com/meili-fundraise/">https://blog.meilisearch.com/meili-fundraise/</a>) which shows that they are determined to develop the product and compete with big players, which is what they also claim on their website, they want to be an alternative to search engine APIs like Algolia.</p>
<p>What is more important for us - developers is the documentation and its clarity. The readme page is short and compact, with only relevant information which is a plus, because they also have a full blown documentation hosted as a separate website at <a href="https://docs.meilisearch.com/">https://docs.meilisearch.com/</a>.</p>
<p>The readme contains all of the basic informations need to start using the engine which means it has recipes for building from source as well as downloading a compiled binary or using a docker image. In addition there are examples how to index a first collection and make queries. All that is compact enough so that following it step by step should take no more than 10-15 minutes to complete.</p>
<p>The documentation contains description of the main concepts that were used when building the engine as well as advanced guides starting from installation and configuration up to the most advanced features of the engine. It is well written but after reading it I was left with a feeling that it is still immature project with a long road ahead of it.</p>




<h3 id="h4">The data set for testing purposes</h3>
<p>Of course testing the search engine with a small data set doesn‚Äôt make much sense since today‚Äôs hardware capabilities allows to easily keep in memory datasets weighing a couple hundreds of megabytes. So I took a different approach, I decided to find a data set that consists mostly of text and would be useful in real world examples. My choice went to Kaggle dataset: Cornell University arXiv index (<a href="https://www.kaggle.com/Cornell-University/arxiv">https://www.kaggle.com/Cornell-University/</a>). As per Wikipedia, arXiv is an open-access repository of electronic preprints (known as e-prints) approved for posting after moderation, but not full peer review. It consists of scientific papers in the fields of mathematics, physics, astronomy, electrical engineering, computer science, quantitative biology, statistics, mathematical finance and economics, which can be accessed online. The dataset hosted on Kaggle is just a friction of the whole arXiv and it contains an index of publications with information like: author, title, category and short excerpt. The dataset format is JSON and weights about 2.7gb all you need to do to download it and unzip.</p>

<h3 id="h5">Kicking it off - Download binary and start the server</h3>
<p>Now that I have a data set we can start testing MeiliSearch. The installation is pretty straightforward, I used a ready to use bash script (of course I reviewed the script in the first place as I know these bash installations are basically an attack vector).</p>
<pre><code>$ curl -L https://install.meilisearch.com | sh
$ ./meilisearch
Server is listening on: http://127.0.0.1:7700</code></pre>
<p>That was very smooth, it went well without any problems, point for Meilisearch.</p>


<h3 id="h6">Prepare the data to be ingested</h3>
<p>In order to search the data we have to create an index first (think of it as a database table) and ingest the data to it in a Meilisearch instance. For index creation I used:</p>
<pre><code>curl -i -X POST 'http://127.0.0.1:7700/indexes' --data '{ "name": "arxiv", "uid": "arxiv" }'</code></pre>
<p>After the command completed I tried to feed the index with raw data, but there are couple of constraints to the format. First thing is that the file must be less than 10 megabytes and second is that the JSON should actually be a JSON array where each element is a separate document identified by unique id field. I tried to use good old split, awk, sed unix tools in the first place, but after some time I gave up and switched to Node.js. </p>
<p>You can check the whole script below. Its not very sophisticated but it does the job.
</p>




<h3 id="h7">Indexing first collection</h3>
<p>The script above does basically two things. It first reads the file contents line by line and builds a payload containing about 1000 documents. It then sends the payload to MeiliSearch, in return we get an ‚ÄúupdateId‚Äù which is an identifier that we can later use to ask our MeiliSearch instance whether the indexation operation for that batch finished. If the indexation batch is finished, then we can resume the file consumption, assemble another data batch and send it to MeiliSearch. And here comes the first surprise, as the documentation doesn‚Äôt clearly lay that out and I had to figure it (how it works). It seems that MeiliSearch has an internal queue that is able to accept any number of data payloads for ingesting and it processes this queue at its own pace. Makes sense to me, but as it turned out later, it‚Äôs not so lovely.
</p>

<h3 id="h8">Indexing speed</h3>
<p>Buffering incoming data has a lot of advantages, having that buffer you are able to not overwhelm your processing units with work, while still maintaining the work pace. In addition you can scale your work capacity by adding more workers, that‚Äôs when the buffers shine, because you can quickly consume additional data by throwing more resources at it. Unfortunately MeiliSearch indexing queue is processed only by one worker even on a multi-core CPU. That means, you can throw a lot of data for indexing at it but it will basically take the same amount of time, if you would do it one payload at a time. </p>
<p>It actually gets worse as the indexation time increases as your data set size increases. That is not a bad thing as long as the growth is linear and it's not too significant. Unfortunately again with MeiliSearch it's exactly the opposite. The indexation time grows exponentially and even with small data sets it gets to a point where indexing 3gb of data would take unknown time (from my calculations). I was having high hopes downloading a 2.7gb data set and trying to index it with MeiliSearch, unfortunately I was only able to index 115mb (yes, megabytes) which is about 80 000 lines from the file. Just to give you the context, the first 20 000 items were indexed in less than 1 minute, another 20 000 items took about 4 minutes. Reaching 88 000 items took 10 minutes and arXiv data set has almost 1 800 000 items. </p>

<p>That being said, the indexation time is too long and I didn‚Äôt want to spend the next few days waiting for it to finish. I did spend some more time trying to find how to speed up the indexing process, I looked through the documentation and Issues on Github, unfortunately I was not the only one that had that problem. This issue: <a href="https://github.com/meilisearch/MeiliSearch/issues/876">https://github.com/meilisearch/MeiliSearch/issues/876</a> highlights it. Until the indexing process can be paralleled at least in ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web">https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web</a></em></p>]]>
            </description>
            <link>https://codefibershq.com/blog/hands-on-meilisearch-a-next-generation-search-engine-for-modern-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045927</guid>
            <pubDate>Tue, 10 Nov 2020 13:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kraftwerk song performed with 5 Arduinos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045818">thread link</a>) | @alanjay
<br/>
November 10, 2020 | https://marquisdegeek.com/music_kraftwerk01 | <a href="https://web.archive.org/web/*/https://marquisdegeek.com/music_kraftwerk01">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://marquisdegeek.com/music_kraftwerk01</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045818</guid>
            <pubDate>Tue, 10 Nov 2020 13:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aesthetics over Usability ‚Äì Google's New App Icons]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25045441">thread link</a>) | @moeminm
<br/>
November 10, 2020 | https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605012940954/mO5AoN3Ie.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605011290156/BFSvCYtdr.png?auto=format&amp;q=60" alt="Google-Workspace-Icons-bad.png"></p>
<p>Google's new app icons are, well, a massive disappointment. They are so bad, there's a <a target="_blank" href="https://restoreoldicons.xyz/">Chrome extension</a> that you can download to restore the old icons. Design changes are always met with some sort of backlash, that's understandable, people don't like change. Facebook's desktop redesign, Instagram's icon redesign, Macbook's touchbar, etc. The problem here; however, revolves around usability, and that's when user feedback should be seriously taken into consideration.</p>
<p>Aside from the icon's shapes, there is nothing else distinguishable about them. They are all made from a palette of four colors; blue, green, yellow, and red. There's a reason why people hate them, and it's not colors, it's usability. </p>
<p>Browsing through the internet, here are some common complaints:</p>
<blockquote>
<p>I had to manually change every Google app icon on my Android phone. I had trouble finding the Maps icon even though it is in the same place. All the new icons look similar to Google drive icon.</p>
</blockquote>
<p>The complaints all revolve around not being to <em>find</em> the apps they want to launch.</p>
<blockquote>
<p>Bring back the old version. Like the new icons aren't even close. They're so unrecognizable that when I go search for them, I forget what I'm looking for before I get to them. It takes me 3 tries to create new events in my calendar or check my email lol</p>
</blockquote>
<p>I believe this comment summarizes why this change rolled out and is live</p>
<blockquote>
<p>To me, this is a symptom of a large company with lots of internal politics and friction, where it is not safe for a designer to push back and say "no, this is not a good idea" to their manager.</p>
<p>Or, even more likely, someone did, and were forced to execute anyway.</p>
</blockquote>
<p>Unfortunately, this is the current state of UX and Design in a lot of companies. Stakeholders are ultimately the one making decisions despite being met with proven statistics from designers. </p>
<p>I also feel like this is a great lesson to any aspiring designer that working for FANG companies isn't always rainbows and sunshine. I can't be sure why these icons rolled out, if it actually was internal politics or not, but it <strong>does</strong> happen. It isn't always about working for FANG companies, but working for a company that aligns with your values. </p>
<p>See you in another Google rebrand. </p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/aesthetics-over-usability-googles-new-app-icons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045441</guid>
            <pubDate>Tue, 10 Nov 2020 12:59:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bidirectional Scrolling: Why Not Both?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25045390">thread link</a>) | @bradley_taunt
<br/>
November 10, 2020 | https://uglyduck.ca/bidirectional-scrolling/ | <a href="https://web.archive.org/web/*/https://uglyduck.ca/bidirectional-scrolling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <section>
        
          <p><time datetime="2020-11-09T00:00:00+00:00">November 9, 2020</time></p>
        
        
        
          <p><em>Discussing the design decisions of bidirectional scrolling in regards to performance</em></p>
        
        <p>I recently came across Adam Silver‚Äôs post <a href="https://adamsilver.io/articles/bidirectional-scrolling-whats-not-to-like/">about the merits and pitfalls of bidirectional scrolling</a> and found myself conflicted with the design arguments put forth in the article. It‚Äôs a very good article overall, and I suggest giving it a read before digging deeper into my post here.</p>

<h2 id="the-premise">The Premise</h2>

<p>The original article argues that displaying page content via horizontal scrolling (and therefore slightly hiding interactive content) creates a few major issues:</p>

<ul>
  <li>it increases the chance users won‚Äôt see it</li>
  <li>there‚Äôs a greater reliance on digital literacy</li>
  <li>it‚Äôs generally more labour intensive for users</li>
</ul>

<p>Adam also makes a solid statement here:</p>

<blockquote>
  <p>Having to scroll down and across in a zig zag fashion can be tiresome, especially for people with motor impairments.</p>
</blockquote>

<p>But I don‚Äôt believe these issues create a need to completely remove the horizontal ‚Äúscrolling‚Äù design altogether. You can still implement the <code>See All Items</code> category link, while allowing the horizontal content to load in <em>dynamically</em>. Balance is always key.</p>

<h2 id="not-all-at-once-please">Not All At Once, Please!</h2>

<p>So what exactly do I mean by <em>dynamically</em> loading in horizontal content?</p>

<ul>
  <li>The user is shown the top 4 items in a given category</li>
  <li>From there, the user can use the <code>See All Items</code> link to jump into a full category page</li>
  <li>If they so desire, they can begin scroll horizontally in a given category row
    <ul>
      <li>Once they reach the end of the row, 4 more items will load in automatically to expand the list</li>
      <li>To avoid a never-ending list, it might be best to limit total row items to ~20 items. At this point the UI could prompt the user to <code>View All Items</code> in that category.</li>
    </ul>
  </li>
</ul>

<p>By loading the row content in piece-by-piece, initial loads for users will be faster and subsequent list items will load quickly as well (since they would limit to a set default - in this case only 4).</p>

<h2 id="final-improvements">Final Improvements</h2>

<p>Below you can find a quick, static version of this concept. Here you can see the horizontal list items, along with their corresponding <code>See All Items</code> links. You‚Äôll have to use your imagination for how new items would load once you each the end of a horizontal row. (I‚Äôm too lazy to spend extra time building out that functionality for a hypothetical blog post)</p>

<p data-height="844" data-theme-id="dark" data-default-tab="result" data-user="bradleytaunt" data-slug-hash="pobxpXz" data-pen-title="Bidirectional Scrolling CSS">
  <span>See the Pen <a href="https://codepen.io/bradleytaunt/pen/pobxpXz">
  Bidirectional Scrolling CSS</a> by Bradley Taunt (<a href="https://codepen.io/bradleytaunt">@bradleytaunt</a>)
  on <a href="https://codepen.io/">CodePen</a>.</span>
</p>



        
<br>

      </section>
    </div></div>]]>
            </description>
            <link>https://uglyduck.ca/bidirectional-scrolling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25045390</guid>
            <pubDate>Tue, 10 Nov 2020 12:52:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Micro 3.0 is a platform for cloud native development]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25044604">thread link</a>) | @asim
<br/>
November 10, 2020 | https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html | <a href="https://web.archive.org/web/*/https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      
      
      

      <p>This is the official announcement for the release of Micro 3.0 better known as M3O - a platform for cloud native development. 
Our 3.0 release is a major refactor and consolidation of the existing tooling into something that addresses the entire workflow 
of build, run, manage and consume all from the developers perspective.</p>

<p>Read on to learn more or go straight to the <a href="https://github.com/micro/micro/releases/latest">latest release</a>. 
Head to <a href="https://m3o.com/">m3o.com</a> for the hosted offering.</p>

<h2 id="overview">Overview</h2>

<p>Micro focuses on developer productivity for the backend. It‚Äôs clear that the Cloud has become infinitely more complex 
over the past few years. Micro attempts to create order out of that chaos by distilling it all down to a handful of 
primitives for distributed systems development.</p>

<p>Why should you care? If you‚Äôre reading this you‚Äôve no doubt encountered the tedious nature of infrastructure management, 
wrangling a kubernetes cluster on AWS or the thousands of things you need to do to cobble together a platform before 
starting to build a product. We think we‚Äôve nailed the solution for that just as Android did for Mobile. Keep reading 
if you want to find out more.</p>

<h2 id="quick-flashback">Quick Flashback</h2>

<p>Micro started out as a <a href="https://micro.mu/blog/2016/03/20/micro.html">toolkit for microservices</a> development, 
incorporating an api gateway, web dashboard and cli to interact with services built using a Go RPC framework. 
Back then it felt like getting anyone to buy into PaaS again was going to be a losing battle. So we chose 
to write single purpose tools around an RPC framework thinking it might allow people to adopt it piece by piece 
until they saw the need for a platform. It was really straight forward right until it wasn‚Äôt.</p>

<p>There was a simple Go framework plus some surrounding 
components to query and interact with them, but like any long lived project, the complexity grew as we 
tried to solve for that platform experience that just couldn‚Äôt be done with a swiss army knife. The repo 
exploded with a number of independent libraries. To the creator its obvious what these are all for but to 
the user there is nothing but cognitive overload.</p>

<p>In 2019 we went through a <a href="https://micro.mu/blog/2019/06/10/the-great-consolidation.html">consolidation</a> of all those libraries 
which helped tremendously but there was still always one outstanding question. What‚Äôs the difference between 
<a href="https://github.com/micro/micro">micro</a> and <a href="https://github.com/micro/go-micro">go-micro</a>? It‚Äôs a good 
question and one we‚Äôve covered before. We saw go-micro as a framework and micro as a toolkit but these 
words were basically empty and meaningless because multiple projects working in coordination really need a 
crisp story that makes sense and we didn‚Äôt have one.</p>

<p>In 2020 we‚Äôre looking to rectify that but let‚Äôs first let‚Äôs talk about platforms.</p>

<h2 id="paas-in-2020">PaaS in 2020</h2>

<p>5 years ago the world exploded with a proliferation of ‚Äúcloud native‚Äù tooling as containers and 
container orchestration took centre stage. More specifically, Docker and Kubernetes redefined the 
technology landscape along with a more conscious move towards building software in the cloud.</p>

<p>Micro took a forward looking view even as far back as 2015. It was clear distributed systems and cloud native 
was going to become the dominant model for backend services development over the coming years but, what wasn‚Äôt clear 
is just how long we‚Äôd spend wrangling all sorts tools like docker, kubernetes, grpc, istio and everything else. 
It felt like we were rebuilding the stack and weren‚Äôt really ready to talk about development aspects of it all.</p>

<p>In fact at that time, people mostly wanted to kick the tyres on all these tools and piece something together. 
Running kubernetes yourself became all the rage and even using service mesh as the holy grail for solving 
all your distributed systems problems. Many of us have come to realise while all of this tech is fun 
it‚Äôs not actually solving development problems.</p>

<p>We‚Äôve gotten to the point of managed kubernetes and even things like Google Cloud Run or DigitalOcean App 
Platform, but none of these things are helping with a development model for a cloud native era. Our 
frustrations with the existing developer experience have grown and Micro felt like something that 
could solve for all that, but only if we took a drastic step to overhaul it.</p>

<p>We think PaaS 3.0 is not just about running your container or even your source code but something that 
encapsulates the entire developer experience including a model for writing code for the cloud. Based on that 
Micro 3.0 aka M3O is a platform for cloud native development.</p>

<h2 id="what-even-is-cloud-native">What even is Cloud Native?</h2>

<p>What is cloud native? What does it mean to build for the cloud? What is a cloud service?</p>

<p>Cloud native is basically a descriptive term for something that was built to run in the cloud. That‚Äôs it. It‚Äôs not 
magic, it might sound like a buzzword, but the reality is it simply means, that piece of software was built 
to run in the cloud. How does that differ from the way we used to build before? Well the idea behind the cloud 
is that its ephemeral, scalable and everything can be accessed via an API.</p>

<p>Our expectation for services running in the cloud is that they‚Äôre mostly stateless, leveraging external services 
for the persistence, that they are identified by name rather than IP address and they themselves provide an 
API that can be consumed by multiple clients such as web, mobile and cli or other services.</p>

<p>Cloud native applications are horizontally scalable and operate within domain boundaries that divide them as 
separate apps which communicate over the network via their APIs rather than as one monolithic entity. 
We think cloud services require a fundamentally different approach to software creation and why Micro 3.0 
was designed with this in mind.</p>

<h2 id="micro-30-aka-m3o">Micro 3.0 aka M3O</h2>

<p>Micro 3.0 (M3O) reimagines Micro as a platform for cloud native development. What does that mean? Well we think of 
it as PaaS 3.0, a complete solution for source to running and beyond. Micro has moved from just being a Go 
framework to incorporating a standalone server and hosted platform. Our hosted offering is called 
<a href="https://m3o.com/">M3O</a>, a hat tip to Micro 3.0 or M[icr]o, whichever way you want to see it.</p>

<p>Another way to think about it. What Git is to GitHub, Micro is to the M3O platform. Let‚Äôs dig into it.</p>

<p>Micro 3.0 includes the following.</p>

<h3 id="server">Server</h3>

<p>The server is our abstraction for cloud infrastructure and underlying systems you might need for writing 
distributed systems. The server encapsulates all of these concerns as gRPC services which you can 
query via any language. The goal here is to say developers don‚Äôt really need to be thinking about infrastructure 
but what they do need is design patterns and primitives for building distributed systems.</p>

<p><img src="https://micro.mu/images/micro-3.0.png"></p>

<p>The server includes the following:</p>

<ul>
  <li>
    <p><strong>Authentication</strong>: Auth whether its authentication or authorization is part of the system. Create JWT tokens, define access rules, use one system to govern everything in a simple and straight forward manner. Whether it‚Äôs for a user or a service.</p>
  </li>
  <li>
    <p><strong>Configuration</strong>: Dynamic config management allows you to store relevant config that needs to be updated without having to restart services. Throw API keys and business logic related configuration into the secure config service and let your services pick up the changes.</p>
  </li>
  <li>
    <p><strong>Key-Value Storage</strong>: We‚Äôre focused on best practices for microservices development which means keeping services mostly stateless. To do this we‚Äôre providing persistent storage on the platform. Key-Value allows you to rapidly write code and store data in the format you care about.</p>
  </li>
  <li>
    <p><strong>Event Streaming</strong>: Distributed systems are fundamentally in need of an event driven architecture to breakdown the tight dependencies between them. Using event streaming and pubsub allows you to publish and subscribe to relevant events async.</p>
  </li>
  <li>
    <p><strong>Service Registry</strong>: Micro and M3O bake in service discovery so you can browse a directory of services to explore your service APIs and enable you to query services by name. Micro is all about microservices and multi-service development.</p>
  </li>
  <li>
    <p><strong>Service Network</strong>: Because you don‚Äôt want to have to resolve those service names to addresses and deal with the load balancing aspect, the server bakes in a ‚Äúservice mesh‚Äù which will handle your inter-service requests (as gRPC) and route to the 
appropriate instance.</p>
  </li>
  <li>
    <p><strong>Identity Proxy</strong>: We include a separate identity proxy for external requests using gRPC via the CLI and other means. This enables you to query from your local machine or anywhere else using valid auth credentials and have it seamlessly work as if 
you were in the platform itself.</p>
  </li>
  <li>
    <p><strong>API Gateway</strong>: Finally there‚Äôs an API gateway that automatically exposes your services to the outside world over HTTP. Internally writing service to service using gRPC makes sense, but at the end of the day we want to build APIs consumed from clients via HTTP.</p>
  </li>
</ul>

<h3 id="clients">Clients</h3>

<p>The server provides inter-service communication and two means of external communication with a HTTP API and gRPC proxy but that 
experience is made much better when there‚Äôs user experience on the client side that works. Right now we‚Äôve got two ways of doing this.</p>

<ul>
  <li>
    <p><strong>Command Line</strong>: The CLI provides a convenient and simple way to talk to the server via gRPC requests through the proxy. 
The most convenient commands are builtin but every service you write also gets beautiful dynamic generated commands 
for each endpoint.</p>
  </li>
  <li>
    <p><strong>gRPC SDKs</strong>: Every service in the server is accessible via gRPC. We‚Äôre code generating clients for the server itself 
so you can access them from any language. What this enables is a wide array of experiences on the client side without 
having to handcraft libraries for each language.</p>
  </li>
  <li>
    <p><strong>Web Interface</strong>: Coming soon is a dynamically generated web interface that creates a simple query mechanism through a 
browser for any of your services. We‚Äôve got a http api, gRPC proxy and command line interface but feel like the browser 
could use some love too.</p>
  </li>
</ul>

<h3 id="framework">Framework</h3>

<p>One thing we really understood from our time working on go-micro was that the developer experience ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html">https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</a></em></p>]]>
            </description>
            <link>https://micro.mu/blog/2020/11/05/micro-v3-aka-m3o.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044604</guid>
            <pubDate>Tue, 10 Nov 2020 11:00:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to revert HP printer‚Äôs ban on 3rd-party ink cartridges]]>
            </title>
            <description>
<![CDATA[
Score 411 | Comments 253 (<a href="https://news.ycombinator.com/item?id=25044597">thread link</a>) | @kdeldycke
<br/>
November 10, 2020 | https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/ | <a href="https://web.archive.org/web/*/https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
     <p>
      Hewlett
      <span>
       &amp;
      </span>
      Packard, the founders, had great lessons to teach us (managers in high-tech) about culture. I even
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management/commit/de3e64647c911f78a37b3e54c7e46197acb061e1">
       quoted them
      </a>
      in my
      <a href="https://github.com/kdeldycke/awesome-engineering-team-management#readme">
       awesome list on engineering team management
      </a>
      .&nbsp;üë®‚Äçüíº
     </p>
     <p>
      <span>
       HP
      </span>
      Inc., the company, sucks. At least their
      <a href="https://news.ycombinator.com/item?id=25045024">
       printer division‚Äôs business model
      </a>
      . They recently pushed a
      <strong>
       firmware update to ban third-party compatible toner cartridges
      </strong>
      .&nbsp;üíî
     </p>
     <p>
      The timeline is&nbsp;straightforward:
     </p>
     <ul>
      <li>
       <p>
        2020, March: general lockdown. ü¶† I need a home office.
        <span>
         SO
        </span>
        is a scientist and spend her time printing papers for review. Got her an
        <a href="https://amzn.com/B073R2WVKB/?tag=kevideld-20">
         <span>
          HP
         </span>
         Color LaserJet M254dw
        </a>
        to keep her productive workflow (
        <a href="https://en.wikipedia.org/wiki/Publish_or_perish">
         publish or perish!
        </a>
        ).
       </p>
      </li>
      <li>
       <p>
        2020, October:
        <span>
         HP
        </span>
        release a new firmware (versioned
        <code>
         20201021
        </code>
        ).
       </p>
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20201021-firmware.jpg">
     </p>
     <ul>
      <li>
       2020, November: my printer auto-upgrade. I‚Äôm welcomed with this
       <em>
        Supply Problem
        <a href="https://en.wikipedia.org/wiki/Screen_of_death">
         Screen of Death
        </a>
       </em>
       :
      </li>
     </ul>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-supply-problem-screen-of-death.jpg">
     </p>
     <p>
      I can‚Äôt print anymore.&nbsp;ü§Ø
     </p>
     <p>
      Eight months. My printer worked for only 8 months.&nbsp;üò§
     </p>
     <p>
      <span>
       OK
      </span>
      . It‚Äôs my fault. I should have spent more money buying certified‚Ñ¢ gear.&nbsp;üòë
     </p>
     <p>
      <img alt="" src="https://comdoc.com/wp-content/uploads/2019/01/copier-printer-meme-03.jpg">
     </p>
     <p>
      The solution is to travel back in time when things were working just great, and downgrade to the previous&nbsp;firmware.
     </p>
     <h2 id="disable-auto-upgrade">
      Disable Auto-Upgrade
      <a href="#disable-auto-upgrade" title="Permanent link">
       ¬∂
      </a>
     </h2>
     <p>
      We will start by stopping this madness for good, and prevent the printer from downloading a firmware behind our&nbsp;back.
     </p>
     <p>
      In the control panel, go to
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       LaserJet Update
      </code>
      &gt;
      <code>
       Manage Updates
      </code>
      :
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-manage-updates-menu.jpg">
     </p>
     <p>
      Then set these&nbsp;options:
     </p>
     <ul>
      <li>
       Allow Downgrade:
       <code>
        Yes
       </code>
      </li>
      <li>
       Check Automatically:
       <code>
        Off
       </code>
      </li>
      <li>
       Prompt Before Install:
       <code>
        Always Prompt
       </code>
      </li>
      <li>
       Allow Updates:
       <code>
        No
       </code>
      </li>
     </ul>
     <p>
      I‚Äôm quite surprised downgrades are allowed. ü§î It seems out of character. Therefor, with my
      <em>
       Evil Product Manager
      </em>
      hat, I advise
      <span>
       HP
      </span>
      to monetize this feature under a monthly Enterprise Subscription of sort.&nbsp;üòà
     </p>
     <h2 id="download-old-firmware">
      Download Old Firmware
      <a href="#download-old-firmware" title="Permanent link">
       ¬∂
      </a>
     </h2>
     <p>
      I got lucky and found the previous
      <code>
       20200612
      </code>
      firmware referenced in
      <a href="https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf">
       <code>
        https://ftp.hp.com/pub/networking/software/pfirmware/pfirmware.glf
       </code>
      </a>
      .
     </p>
     <p>
      There you‚Äôll get a direct link to the
      <code>
       .rfu
      </code>
      file (Remote Firmware Update):
      <a href="http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       <code>
        http://ftp.hp.com/pub/networking/software/pfirmware/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      And just in case it disappear from its original location, here is a
      <a href="https://kevin.deldycke.com/uploads/2020/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu">
       copy of
       <code>
        HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
       </code>
      </a>
      .
     </p>
     <p>
      The checksum of that file&nbsp;is:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> sha256sum ./HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
<span data-linenos="2 "></span><span>91c7f51ceba2386f3b94dcb9da20c669ab10b1ee3a9b1e1f742c40091920188e</span>
</code></pre>
     </div>
     <h2 id="downgrade-firmware">
      Downgrade Firmware
      <a href="#downgrade-firmware" title="Permanent link">
       ¬∂
      </a>
     </h2>
     <p>
      Once you get the
      <code>
       .rfu
      </code>
      file, list all your printers from a macOS&nbsp;terminal:
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpstat -p -d
<span data-linenos="2 "></span><span>printer HP_Color_LaserJet_M254dw_0 is idle.  enabled since Fri Nov  6 17:47:06 2020</span>
<span data-linenos="3 "></span><span>system default destination: HP_Color_LaserJet_M254dw_0</span>
</code></pre>
     </div>
     <p>
      And run the firmware downgrade
      <span>
       CLI
      </span>
      :
     </p>
     <div>
      <pre><span></span><code><span data-linenos="1 "></span><span>$</span> lpr -P HP_Color_LaserJet_M254dw_0 /Users/kde/Downloads/HP_Color_LaserJet_Pro_M254_dw_Printer_series_20200612.rfu
</code></pre>
     </div>
     <p>
      Nothing gets printed to the&nbsp;console.
     </p>
     <p>
      I don‚Äôt know what happens here but it seems the
      <code>
       .rfu
      </code>
      file is pushed to the printer‚Äôs queue and then gets consumed as any other printable document. See,
      <a href="https://www.jsof-tech.com/unpacking-hp-firmware-updates-part-1/">
       the
       <span>
        RFU
       </span>
       file format is a matryoshka doll
      </a>
      embedding printing commands, encoded data and raw
      <span>
       NAND
      </span>
      code.
     </p>
     <p>
      After a minute  or two, the printers reboots and upgrades&nbsp;itself:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-firmware-updating.jpg">
     </p>
     <p>
      And we‚Äôre back in business!&nbsp;ü•≥
     </p>
     <p>
      A detour via
      <code>
       Setup
      </code>
      &gt;
      <code>
       Service
      </code>
      &gt;
      <code>
       Firmware Datecode
      </code>
      menu confirm we‚Äôre running the the previous&nbsp;firmware:
     </p>
     <p>
      <img alt="" src="https://kevin.deldycke.com/uploads/2020/hp-laserjet-printer-20200612-firmware.jpg">
     </p>
     <h2 id="printer-security">
      Printer Security
      <a href="#printer-security" title="Permanent link">
       ¬∂
      </a>
     </h2>
     <p>
      In my research for this article, I found out about
      <a href="https://github.com/RUB-NDS/PRET">
       <span>
        PRET
       </span>
       , a printer exploitation toolkit
      </a>
      . It‚Äôs a brilliant tool, in a malignant way. It allows for pen-testing and hacking, using the same vectors as the firmware update.&nbsp;ü§´
     </p>
     <p>
      I‚Äôll probably play with it in the future. For fun, but also to try enhance the security of the printer. In the mean time, I guess a password is the bare minimum. And if my printer get kidnapped by a cyber gang, I now have a way to restore my printer‚Äôs firmware!&nbsp;üò¨
     </p>
     <h3>
      Related content
     </h3>
     
     
    </div></div>]]>
            </description>
            <link>https://kevin.deldycke.com/2020/11/revert-hp-printer-ban-on-third-party-ink-cartridges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044597</guid>
            <pubDate>Tue, 10 Nov 2020 10:59:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The myriad meanings of pwd in Unix systems]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25044131">thread link</a>) | @quyleanh
<br/>
November 10, 2020 | https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Last week I ran a poll on Twitter to see what people considered with respect to the meaning of ‚Äòpwd‚Äô in Unix and Linux systems. The results were varied, for perhaps good reason.</em></p>

<p>At the end of Oct 2020 I ran a <a href="https://twitter.com/qmacro/status/1322567992551624705">brief poll on Twitter</a>, on which 82 people voted. Here‚Äôs that poll, and the results. They‚Äôre quite mixed, which at first might seem surprising. But there are reasons for that, as we‚Äôll find out.</p>

<p><img src="https://qmacro.org/content/images/2020/11/twitter-poll-pwd.png" alt="Poll on Twitter: &quot;Fun Saturday afternoon shell poll. In Unix (and Linux), what do you think the P in $PWD (or pwd) stand for?&quot;"></p>

<p><strong>Print working directory</strong></p>

<p>The most popular option was ‚Äúprint working directory‚Äù. At first sight it seems logical: ‚Äúprint out the current working directory, i.e. where I am right now‚Äù. Moreover, the description in various versions of the manual for <code>pwd</code> help to drive home that notion. Typically we see sentences like ‚Äú<a href="https://linux.die.net/man/1/pwd">print name of current/working directory</a>‚Äù or ‚Äú<a href="https://www.mankier.com/1/pwd">print the current directory</a>‚Äù.</p>

<p>But there are lots of commands that print stuff, and are described in that way too. Take the <code>id</code> command. Here‚Äôs what one man page says: ‚Äú<a href="https://man7.org/linux/man-pages/man1/id.1.html">print real and effective user and group IDs</a>‚Äù. There‚Äôs ‚Äúprint‚Äù again. But the command isn‚Äôt <code>pid</code>, it‚Äôs <code>id</code>. When you think about it, many, many commands in Unix send information to STDOUT, i.e. to the terminal. That‚Äôs sort of the point of many of them.</p>

<p>This time arguably only superficially definitive, it would seem, the Wikipedia entry states, on the <a href="https://en.wikipedia.org/wiki/Pwd">page for <code>pwd</code></a>: ‚Äúthe pwd command (print working directory) writes the full pathname of the current working directory to the standard output‚Äù. As if to underline the hopeful authority of this statement, there are five (!) footnotes that supposedly link to resources that back this up.</p>

<p>Unfortunately, the first footnote points to a Wayback Machine copy of the <a href="https://web.archive.org/web/20050520231659/http://cm.bell-labs.com/7thEdMan/v7vol1.pdf">UNIX PROGRAMMERS MANUAL - Seventh Edition, Volume 1 - January, 1979</a>, wherein there are actually zero references to <code>pwd</code> being short for ‚Äúprint working directory‚Äù:</p>

<p><img src="https://qmacro.org/content/images/2020/11/programmers-manual-pwd.png" alt="excerpt from UNIX PROGRAMMERS MANUAL on pwd"></p>

<p>I don‚Äôt know about you, but this historic document carries more weight for me than other sources I‚Äôve come across, and it only serves here to undermine the credibility of the Wikipedia entry.</p>

<p>The rest of the footnote links seem dubious at best, except for the one pointing to the <a href="https://www.gnu.org/software/coreutils/manual/coreutils.html#pwd-invocation">GNU Coreutils manual on pwd</a> which has it as ‚Äúprint working directory‚Äù. But everything else I‚Äôve seen so far makes me think that this is a misunderstanding that has spread for obvious and innocent reasons. In addition, the one footnote in the Wikipedia page that is not used to back this claim up is a pointer to <a href="https://pubs.opengroup.org/onlinepubs/9699919799/utilities/pwd.html">The Open Group Base Specifications Issue 7, 2018 edition‚Äôs information on pwd</a>, which almost seems like it‚Äôs actually avoiding using the word ‚Äúprint‚Äù at all: ‚Äúreturn working directory name‚Äù ‚Ä¶ ‚ÄúThe pwd utility shall write to standard output an absolute pathname of the current working directory, which does not contain the filenames dot or dot-dot.‚Äù. Very specific, very not-print.</p>

<p>So I‚Äôm thinking that ‚Äúprint working directory‚Äù isn‚Äôt what <code>pwd</code> stands for. In fact, ‚Äúprint working directory‚Äù may be common to some man pages, but on this macOS machine, with its <a href="https://en.wikipedia.org/wiki/Berkeley_Software_Distribution">BSD</a> heritage, we have, instead: ‚Äúpwd ‚Äì return working directory name‚Äù. Moreover, it goes on to say ‚ÄúThe pwd utility writes the absolute pathname of the current working directory to the standard output‚Äù.</p>

<p><strong>Pathname of working directory</strong></p>

<p>So perhaps it really is ‚Äúpathname of working directory‚Äù. That would, at least to me, make more sense. Not only does it eschew the redundancy of ‚Äúprint‚Äù, it also is more specific about the output - if I‚Äôm in <code>/home/dja/</code> for example, then invoking pwd will tell me that, i.e. where I am, including the whole path, and not just <code>dja</code>:</p>



<p><strong>Process working directory</strong></p>

<p>As for the other options, I do favour ‚Äúprocess working directory‚Äù, mostly because it makes a lot of sense to me; every process in Unix has the concept of a current working directory, and that‚Äôs exactly what I‚Äôm asking for when I‚Äôm in my shell process and enter <code>pwd</code> - there‚Äôs a part in the video <a href="https://youtu.be/hgFBRZmwpSM?t=165">Unix terminals and shells</a> that explains this very well.</p>

<p>I‚Äôd love to be able to point to some old Unix sources that definitively explain the answer, but unfortunately that search has come up with very little - the <code>pwd</code> source in both the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V5/usr/source/s2/pwd.c">5th</a> and <a href="https://github.com/yisooan/unix-v6/blob/master/source/s2/pwd.c">6th</a> Editions of Unix shed no light on this whatsoever.</p>

<p><strong>Present working directory</strong></p>

<p>What about ‚Äúpresent working directory‚Äù? Well, that option seems to have legs, in the form of the Korn shell. While <a href="https://northstar-www.dartmouth.edu/doc/solaris-forte/ipe-help/dbx/dbx88cc.html">one source</a> implies that the answer might well be ‚Äúpathname of current working directory‚Äù, in that <code>pwd</code> just emits the value of the <code>$PWD</code> environment variable (and a variable called ‚Äúprint working directory‚Äù makes no sense at all) ‚Ä¶ it would seem that in ksh-land, at least, ‚Äúpresent working directory‚Äù is what <code>pwd</code> represents. Take, for example, the <a href="https://osr507doc.xinuos.com/en/man/html.C/ksh.C.html">ksh man page</a> which states ‚ÄúPWD - The present working directory set by the cd command‚Äù.</p>

<p>There‚Äôs a ton of discussion, both direct and indirect, on this very question. Take for example these two entries in the Unix &amp; Linux Stack Exchange forum: <a href="https://unix.stackexchange.com/questions/399026/etymology-of-pwd">Etymology of $PWD</a> and <a href="https://unix.stackexchange.com/questions/174990/what-is-pwd-vs-current-working-directory">What is $PWD? (vs current working directory)</a>. Of course, perhaps the definitive answer will never be found, as computing history is nothing if not varied and prone to forking.</p>

<p><strong>Multics and print_wdir</strong></p>

<p>Talking of history, we could go further back to pre-Unix roots, in the form of Multics, which indirectly gave rise to Unix (originally ‚ÄúUnics‚Äù). In the <a href="https://multicians.org/multics-commands.html">list of Multics Commands</a>, we see, nestled amongst other similarly named commands, something that jumps out at us:</p>

<div><div><pre><code>print_mail (pm)	display mail in a mailbox
print_messages (pm)	display interactive messages in a mailbox
print_motd (pmotd)	display message of the day (source)
print_proc_auth (ppa)	display process's sensitivity level and compartments
print_request_types (prt)	display list of I/O daemon request types
print_search_paths (psp)	display search paths
print_search_rules (psr)	display ready messages
print_wdir (pwd)	display working directory
</code></pre></div></div>

<p>There‚Äôs <code>pwd</code>, and in fact, just like its sibling <code>pmotd</code>, for example, which is short for <code>print_motd</code>, it‚Äôs short for <code>print_wdir</code>. Now, given the context of the original poll being set to Unix and Linux, perhaps we must discount this information. But as someone who is fascinated with Unix history in general - how can I?</p>

<p>I guess there are few things to conclude. The history is rich and diverse, and maybe we‚Äôll never know for sure. Perhaps, in fact, the answer will depend on whom we ask. In the grand scheme of things, it doesn‚Äôt really matter ‚Ä¶ but to those who delight in minutiae, it‚Äôs a fun topic worth exploring.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2020/11/08/the-meaning-of-pwd-in-unix-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044131</guid>
            <pubDate>Tue, 10 Nov 2020 09:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Automation Part 4: Who made it, why, and in what context?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25044097">thread link</a>) | @nonoesp
<br/>
November 10, 2020 | https://sketch.nono.ma/who-made-it-why-and-in-what-context | <a href="https://web.archive.org/web/*/https://sketch.nono.ma/who-made-it-why-and-in-what-context">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <div>

    
          <svg data-name="sketch.nono.ma" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 153"><defs></defs><title>Sketch.Nono.MA</title><path d="M182.51,57.42v1.29a8.6,8.6,0,0,0,.48,3.47,1.85,1.85,0,0,0,1.82,1c1.34,0,2-1.05,2-3.14a8,8,0,0,0-.12-1.42,6.27,6.27,0,0,0-.44-1.38,11.32,11.32,0,0,0-.84-1.52c-.36-.54-.81-1.17-1.36-1.9l-2.22-3.23c-.71-1-1.3-1.92-1.77-2.72a18.44,18.44,0,0,1-1.13-2.28,10,10,0,0,1-.61-2,11.93,11.93,0,0,1-.17-2,6.9,6.9,0,0,1,1.79-5,6.43,6.43,0,0,1,4.84-1.85,6,6,0,0,1,3.86,1.23,5.77,5.77,0,0,1,2,3.43c.06.28.11.53.14.74a6.16,6.16,0,0,1,.07.69c0,.25,0,.57,0,1v1.57l-4.4.43c0-.83,0-1.42,0-1.79a6.37,6.37,0,0,0-.12-1.07c-.16-1.33-.78-2-1.86-2-1.24,0-1.86,1-1.86,3a9.55,9.55,0,0,0,.07,1.26,4.32,4.32,0,0,0,.39,1.21,16.05,16.05,0,0,0,1,1.66l1.77,2.66,2.27,3.23a21.45,21.45,0,0,1,2.4,4.58,12.66,12.66,0,0,1,.84,4.34,6.61,6.61,0,0,1-1.7,4.89,6.53,6.53,0,0,1-4.85,1.71,6.34,6.34,0,0,1-6.55-4.73,14.33,14.33,0,0,1-.29-3.26v-.83a8.51,8.51,0,0,1,.05-.88Z"></path><path d="M211.28,66.84h-4.69l-3.33-15L201.32,57v9.8h-4.54V35.11h4.54V47.05l4.4-11.94h4.6l-4.07,10.71Z"></path><path d="M226.51,35.11V39.3h-6.38v8.8h4.45v4.18h-4.45V62.65h6.77v4.19H215.59V35.11Z"></path><path d="M234.59,39.3h-4.21V35.11h13.15V39.3h-4.4V66.84h-4.54Z"></path><path d="M259.92,55.52c0,.85.06,1.51.08,2s0,.91,0,1.36q0,8.46-6.53,8.46-6.33,0-6.33-7.61V42.25q0-7.61,6.33-7.61Q260,34.64,260,43V44a13.8,13.8,0,0,1-.1,1.45h-4.54a12,12,0,0,0,.09-1.21v-1a10.26,10.26,0,0,0-.4-3.54,1.54,1.54,0,0,0-1.58-.93,1.44,1.44,0,0,0-1.43.69,6.93,6.93,0,0,0-.36,2.77V59.67a6.93,6.93,0,0,0,.36,2.77,1.44,1.44,0,0,0,1.43.69,1.56,1.56,0,0,0,1.56-.88,9,9,0,0,0,.42-3.36c0-.53,0-1,0-1.49s0-1.09-.07-1.88Z"></path><path d="M270.13,52.28V66.84h-4.55V35.07h4.55v13h3.57v-13h4.55V66.84H273.7V52.28Z"></path><path d="M283.91,62.08h4.54v4.76h-4.54Z"></path><path d="M309.34,66.84h-4.55l-5.22-16.65V66.84H295V35.11h3.85l5.91,18.7V35.11h4.55Z"></path><path d="M328.34,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM323.8,41.38a3.47,3.47,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.51,3.51,0,0,0,.42,2,2,2,0,0,0,2.81,0,3.33,3.33,0,0,0,.45-2Z"></path><path d="M348.84,66.84H344.3l-5.23-16.65V66.84h-4.54V35.11h3.85l5.92,18.7V35.11h4.54Z"></path><path d="M367.84,58.75c0,1,0,1.73,0,2.33s-.08,1.12-.14,1.55a4.63,4.63,0,0,1-.29,1.09,7.46,7.46,0,0,1-.53,1,5.56,5.56,0,0,1-2.25,1.92,7.4,7.4,0,0,1-6.24,0,5.56,5.56,0,0,1-2.25-1.92,7.46,7.46,0,0,1-.53-1,5.11,5.11,0,0,1-.31-1.09,10.43,10.43,0,0,1-.15-1.55c0-.6,0-1.38,0-2.33V43.15c0-.95,0-1.73,0-2.33a10.28,10.28,0,0,1,.15-1.54,5.21,5.21,0,0,1,.31-1.1,7.39,7.39,0,0,1,.53-1,5.63,5.63,0,0,1,2.25-1.88,7.4,7.4,0,0,1,6.24,0,5.63,5.63,0,0,1,2.25,1.88,7.39,7.39,0,0,1,.53,1,4.72,4.72,0,0,1,.29,1.1c.06.42.11.94.14,1.54s0,1.38,0,2.33ZM363.3,41.38a3.38,3.38,0,0,0-.43-2,1.6,1.6,0,0,0-1.41-.6,1.62,1.62,0,0,0-1.39.6,3.29,3.29,0,0,0-.45,2V60.57a3.42,3.42,0,0,0,.43,2,1.62,1.62,0,0,0,1.41.59,1.64,1.64,0,0,0,1.39-.59,3.33,3.33,0,0,0,.45-2Z"></path><path d="M374.37,62.08h4.55v4.76h-4.55Z"></path><path d="M397.19,35.11h5.42V66.84h-3.87V44.44L395,66.84H393l-3.77-22.4v22.4h-3.77V35.11h5.32L394,50.9Z"></path><path d="M412.62,66.84h-4.36l4.4-31.73h5.81l4.2,31.73h-4.4l-.82-7.14h-4.06Zm2.8-26-1.55,14.7H417Z"></path><path d="M96.84,97.69c-1.56,0-2.5.76-2.5,1.8s1.21,1.63,2.34,1.9l1.3.32c2.08.5,4,1.59,4.06,4s-1.93,4.09-5.24,4.09-5.26-1.54-5.36-4.29H93.9c.1,1.45,1.31,2.15,2.88,2.15s2.75-.79,2.76-2-1-1.53-2.48-1.91l-1.58-.41c-2.27-.58-3.68-1.72-3.68-3.71,0-2.44,2.17-4.07,5.07-4.07s4.93,1.65,5,4H99.44C99.32,98.38,98.33,97.69,96.84,97.69Z"></path><path d="M103.78,95.76h2.44v7.61h.17l3.73-4.16H113l-4,4.47,4.25,5.89h-2.93l-3.16-4.43-.9,1v3.48h-2.44Z"></path><path d="M113.33,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C115.24,109.77,113.33,107.7,113.33,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M129.83,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.26-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M131,104.43c0-3.16,1.91-5.35,5-5.35,2.53,0,4.28,1.47,4.45,3.72H138a2,2,0,0,0-2.09-1.75c-1.5,0-2.51,1.25-2.51,3.34s1,3.39,2.51,3.39A2,2,0,0,0,138,106h2.33c-.18,2.2-1.84,3.74-4.44,3.74C132.82,109.77,131,107.57,131,104.43Z"></path><path d="M144.42,109.57H142V95.76h2.39V101h.12a3,3,0,0,1,3.09-1.89c2.15,0,3.56,1.39,3.56,3.9v6.59H148.7v-6.22a2,2,0,0,0-2-2.21,2.15,2.15,0,0,0-2.24,2.36Z"></path><path d="M152.8,104.45c0-3.19,1.94-5.37,4.91-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C154.71,109.77,152.8,107.7,152.8,104.45Zm7.3-1a2.3,2.3,0,0,0-2.36-2.43,2.49,2.49,0,0,0-2.51,2.43Z"></path><path d="M170.09,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.15-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.69-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M178,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.57-.22,2.57-.93v0c0-1-.62-1.59-1.76-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42h-.08a3.21,3.21,0,0,1-3,1.63C179.52,109.78,178,108.7,178,106.66Zm6.5-.8v-1.23a7.34,7.34,0,0,1-2.24.51c-1.09.15-1.9.55-1.9,1.48s.72,1.37,1.74,1.37A2.21,2.21,0,0,0,184.53,105.86Z"></path><path d="M191.5,109.57h-2.45V99.21h2.34V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59H195.7v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M199.83,104.41c0-3.46,1.89-5.33,4.28-5.33a3.08,3.08,0,0,1,3,1.84h.1V95.76h2.45v13.81h-2.4v-1.63h-.15a3.13,3.13,0,0,1-3,1.81C201.66,109.75,199.83,107.82,199.83,104.41Zm7.39,0c0-2-.86-3.31-2.44-3.31s-2.46,1.38-2.46,3.31.85,3.36,2.46,3.36S207.22,106.4,207.22,104.39Z"></path><path d="M222.15,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.9,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.45-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M231.42,101.1h-2v5.36c0,1,.49,1.2,1.11,1.2a3.12,3.12,0,0,0,.71-.1l.41,1.91a4.8,4.8,0,0,1-1.43.24c-1.84.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21h1.47V96.73h2.44v2.48h2Z"></path><path d="M232.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S232.53,107.64,232.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S240,106.32,240,104.43Z"></path><path d="M244.15,99.21h2.36v1.73h.11a2.6,2.6,0,0,1,2.56-1.88,5.79,5.79,0,0,1,.87.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.33,2.24v6.09h-2.44Z"></path><path d="M251.11,96.42a1.42,1.42,0,1,1,1.42,1.32A1.38,1.38,0,0,1,251.11,96.42Zm.19,2.79h2.44v10.36H251.3Z"></path><path d="M255.43,104.45c0-3.19,1.94-5.37,4.9-5.37,2.55,0,4.74,1.6,4.74,5.23v.75h-7.22a2.55,2.55,0,0,0,2.64,2.81,2.17,2.17,0,0,0,2.2-1.33l2.28.25c-.44,1.8-2.09,3-4.51,3C257.34,109.77,255.43,107.7,255.43,104.45Zm7.3-1a2.31,2.31,0,0,0-2.36-2.43,2.48,2.48,0,0,0-2.51,2.43Z"></path><path d="M272.72,102.19a1.82,1.82,0,0,0-1.91-1.29c-1,0-1.8.48-1.79,1.18s.41,1,1.46,1.21l1.77.37c2,.43,2.91,1.33,2.92,2.81,0,2-1.84,3.3-4.43,3.3s-4.14-1.12-4.44-3l2.38-.23a1.85,1.85,0,0,0,2.05,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.39-1.18l-1.77-.37c-2-.41-2.92-1.41-2.91-2.92,0-1.92,1.69-3.14,4.18-3.14s3.84,1.12,4.17,2.87Z"></path><path d="M281.25,95.76h2.44v5.16h.1a3.09,3.09,0,0,1,3-1.84c2.4,0,4.28,1.87,4.28,5.33s-1.83,5.34-4.27,5.34a3.14,3.14,0,0,1-3-1.81h-.14v1.63h-2.4Zm4.83,12c1.61,0,2.46-1.42,2.46-3.36s-.83-3.31-2.46-3.31-2.44,1.3-2.44,3.31S284.52,107.75,286.08,107.75Z"></path><path d="M292.27,113.33l.57-2c1.07.31,1.77.22,2.23-.92l.25-.66-3.76-10.58h2.59l2.39,7.83h.1l2.4-7.83h2.59l-4.18,11.71a3.65,3.65,0,0,1-3.64,2.68A4.33,4.33,0,0,1,292.27,113.33Z"></path><path d="M318.74,109.57h-2.23l-6.5-9.41h-.12v9.41h-2.5V95.76h2.24l6.5,9.41h.12V95.76h2.49Z"></path><path d="M320.53,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S320.53,107.64,320.53,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S328,106.32,328,104.43Z"></path><path d="M334.59,109.57h-2.44V99.21h2.33V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.56,1.41,3.55,3.9v6.59H338.8v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M342.91,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.92,5.34-5,5.34S342.91,107.64,342.91,104.43Zm7.45,0c0-1.9-.82-3.42-2.48-3.42s-2.5,1.52-2.5,3.42.83,3.39,2.5,3.39S350.36,106.32,350.36,104.43Z"></path><path d="M362,95.76l4.1,10h.16l4.1-10h3.06v13.81h-2.4v-9.49h-.13l-3.81,9.45h-1.8l-3.81-9.47h-.13v9.51H359V95.76Z"></path><path d="M375.47,106.66c0-2.33,1.92-2.93,3.93-3.15,1.83-.19,2.56-.22,2.56-.93v0c0-1-.62-1.59-1.75-1.59a2.06,2.06,0,0,0-2.12,1.31l-2.28-.32c.54-1.89,2.21-2.86,4.39-2.86,2,0,4.21.82,4.21,3.56v6.93h-2.35v-1.42H382a3.21,3.21,0,0,1-3,1.63C377,109.78,375.47,108.7,375.47,106.66Zm6.5-.8v-1.23a7.41,7.41,0,0,1-2.24.51c-1.09.15-1.91.55-1.91,1.48s.73,1.37,1.75,1.37A2.21,2.21,0,0,0,382,105.86Z"></path><path d="M386.49,99.21h2.37v1.73H389a2.58,2.58,0,0,1,2.55-1.88,5.92,5.92,0,0,1,.88.07v2.25a4.54,4.54,0,0,0-1.13-.14,2.21,2.21,0,0,0-2.34,2.24v6.09h-2.44Z"></path><path d="M399.47,101.1h-2.05v5.36c0,1,.5,1.2,1.11,1.2a3.33,3.33,0,0,0,.72-.1l.41,1.91a4.88,4.88,0,0,1-1.44.24c-1.83.06-3.25-.9-3.24-2.85V101.1h-1.47V99.21H395V96.73h2.44v2.48h2.05Z"></path><path d="M401.13,99.21h2.45v10.36h-2.45Zm1.8-4.44h2.39l-2.07,3.08h-1.83Z"></path><path d="M408.15,109.57h-2.44V99.21H408V101h.12a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21,2.12,2.12,0,0,0-2.19,2.36Z"></path><path d="M416.47,104.45c0-3.19,1.93-5.37,4.9-5.37,2.55,0,4.73,1.6,4.73,5.23v.75h-7.21a2.55,2.55,0,0,0,2.64,2.81,2.16,2.16,0,0,0,2.19-1.33l2.28.25c-.43,1.8-2.09,3-4.5,3C418.38,109.77,416.47,107.7,416.47,104.45Zm7.29-1A2.3,2.3,0,0,0,421.4,101a2.5,2.5,0,0,0-2.51,2.43Z"></path><path d="M427.66,108l5.34-6.7v-.08h-5.17v-2H436v1.67l-5.09,6.58v.09h5.26v2h-8.5Z"></path><path d="M441.63,109.57l4.87-13.81h3.08l4.87,13.81h-2.67l-1.14-3.4h-5.2l-1.14,3.4Zm8.33-5.41-1.87-5.57H448l-1.87,5.57Z"></path><path d="M458.24,109.57h-2.45V95.76h2.45Z"></path><path d="M459.92,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S459.92,107.64,459.92,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.5,1.52-2.5,3.42.82,3.39,2.5,3.39S467.37,106.32,467.37,104.43Z"></path><path d="M474,109.57h-2.44V99.21h2.33V101H474a3.11,3.11,0,0,1,3.09-1.89c2.14,0,3.55,1.41,3.55,3.9v6.59h-2.44v-6.22a2,2,0,0,0-2-2.21A2.12,2.12,0,0,0,474,103.5Z"></path><path d="M488.7,102.19a1.81,1.81,0,0,0-1.91-1.29c-1,0-1.79.48-1.78,1.18s.41,1,1.46,1.21l1.77.37c1.95.43,2.91,1.33,2.91,2.81,0,2-1.83,3.3-4.42,3.3s-4.14-1.12-4.45-3l2.38-.23a1.86,1.86,0,0,0,2.06,1.41c1.16,0,1.93-.53,1.93-1.24s-.44-1-1.4-1.18l-1.76-.37c-2-.41-2.92-1.41-2.92-2.92,0-1.92,1.7-3.14,4.19-3.14s3.83,1.12,4.17,2.87Z"></path><path d="M492.35,104.43c0-3.21,1.93-5.35,5-5.35s5,2.14,5,5.35-1.93,5.34-5,5.34S492.35,107.64,492.35,104.43Zm7.45,0c0-1.9-.82-3.42-2.47-3.42s-2.51,1.52-2.51,3.42.83,3.39,2.51,3.39S499.8,106.32,499.8,104.43Z"></path></svg>
    
    

            <p><img src="https://nono.imgix.net/img/u/sketch-191102-cordoba-las-ramblas-alfar-torres-ferreras-ceramic-artisan.jpg?auto=format%2Ccompress&amp;ixlib=php-3.3.0&amp;w=2500"></p>

    <p>Andy Warhol's artworks have sold for millions of dollars. His most famous works‚Äîthink of Campbell's Soup Cans (1962) and Marylin Diptych (1962)‚Äîare limited edition paintings. Campbell's Soup Cans' piece consists of 32 images produced over five months<sup id="fnref:wikipedia-warhol-andy"><a href="#fn:wikipedia-warhol-andy" role="doc-noteref">1</a></sup>, and Marilyn Monroe's artwork consists of 50 portraits.<sup id="fnref:wikipedia-warhol-marilyn"><a href="#fn:wikipedia-warhol-marilyn" role="doc-noteref">2</a></sup></p>
<p>After hand-painting thirty-two soup cans by hand, Warhol moved to photo-silkscreen, a printmaking technique originally invented for commercial use that allowed Warhol and other artists to create reproductions of the same artwork using a silkscreen.<sup id="fnref:warhol-moma-learning"><a href="#fn:warhol-moma-learning" role="doc-noteref">3</a></sup></p>
<p>Warhol painted the soup cans with acrylic paint. Each canvas corresponded to a soup variety sold by Campbell's back in the 1960s.</p>
<p>Screen printing speeds up the reproduction of an artwork. Once the silkscreen is ready, colors are applied, one by one, using a squeegee to push the ink through the mesh screen<sup id="fnref:dickblick-screen-printing"><a href="#fn:dickblick-screen-printing" role="doc-noteref">4</a></sup>, either by hand or automatically with a machine, a process being used at the time to mass-produce advertisements.<sup id="fnref:warhol-moma-learning__2"><a href="#fn:warhol-moma-learning" role="doc-noteref">3</a></sup></p>
<p>"I don't think art should be only for the select few," Warhol claimed, "I think it should be for the mass of the American people."</p>
<p>Nowadays, we could argue this vision is a reality. Large corporations and artisans deploy a wide range of mediums to automate what used to be done by hand, producing goods en masse, lessening their price and uniqueness while improving its quality and availability. You can buy a ready-to-hang print of Vang Goh's&nbsp;<em>The Starry Night</em>&nbsp;at IKEA for $49.99 while the Museum of Modern Art in Midtown Manhattan shields and exhibits the original painting.</p>
<p>Contrary to his statement, Warhol created artwork for the selected few that could pay for it. In 2007, a 1964&nbsp;<em>Large Campbell's Soup Can</em>&nbsp;sold for $7.4 million, and&nbsp;<em>Silver Car Crash</em>&nbsp;sold for $105.4 million in 2013.</p>
<p>Aesthetics and taste aside, it's all about the story behind each piece.</p>
<p>Who made it, why, and in what context?</p>
<!-- References -->



  </div>



  </div><div>
      <p><img src="https://nono.imgix.net/folio/images/veil.gif" data-src="https://nono.imgix.net/img/u/sketch-nono-ma-logo.svg"></p>
<hr>
<p>
My sketches and stories, in&nbsp;your&nbsp;inbox.
</p>

<p><span>One email per week. No spam ever.</span></p>

<p><img src="https://sketch.nono.ma/img/u/profile-nono-ma-sketch.jpg" alt="Pencil sketch of Nono Mart√≠nez Alonso.">
</p>


      </div></div>]]>
            </description>
            <link>https://sketch.nono.ma/who-made-it-why-and-in-what-context</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044097</guid>
            <pubDate>Tue, 10 Nov 2020 09:24:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Low Hanging Fruits in Front End Performance Optimization]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044079">thread link</a>) | @pawurb
<br/>
November 10, 2020 | https://pawelurbanek.com/frontend-performance-optimization | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/frontend-performance-optimization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title="Web apps frontend performance is represented by grapes Photo by Amos Bar-Zeev on Unsplash" alt="Web apps frontend performance is represented by grapes Photo by Amos Bar-Zeev on Unsplash" data-src="https://pawelurbanek.com/assets/frontend-optimization-fruits-6ff2f8bc957fe4e1142ab67c3a460ce9dc962eba5b1dc2f10c5125292c558b37.jpg" src="https://pawelurbanek.com/assets/frontend-optimization-fruits-thumb-90ff9c113ed86f833b4e2fa0bbe34e130f2ee5871d3b08aa033fe1e1cbc0e7ad.jpg">
    </p>
  

  

  

  <p>I conduct Rails performance audits for a living. Clients usually approach me with a request to speed up the backend, i.e., optimize the bottleneck API endpoint or tune the database queries. After the initial research, it often turns out that tweaking the frontend will make a better impact on the perceivable performance than fine-tuning the backend.</p>

<p>In this blog post, I describe the often-overlooked techniques that can significantly improve your web app‚Äôs overall performance.</p>

<p>These tips apply to all the web technologies like Ruby on Rails, NodeJS, Python Django, or Elixir Phoenix. It does not matter if you render an HTML or serve an API consumed by the JavaScript SPA framework. It all comes down to transferring bytes over the HTTP protocol. Frontend performance optimization is all about making this process as efficient as possible.</p>

<h2 id="why-is-frontend-performance-critical-for-your-websites-success">Why is frontend performance critical for your website‚Äôs success?</h2>

<p>I guess that developers often disregard the frontend performance because it doesn‚Äôt directly affect the infrastructure costs. Rendering the unoptimized website is offloaded to the visitor‚Äôs desktop or mobile device and cannot be measured using backend monitoring tools.</p>

<p>Developers usually work on top-notch desktop computers with a high-speed internet connection. They do not experience poor performance themselves. The UX of visiting your landing page on a 15 inch Mac Book Pro with a fiber connection cannot be compared to an old Android device on a shaky 3G network.</p>

<p>A typical web app issues dozens of requests on initial load. Only a few are backend-related, i.e., website HTML, API calls, etc. The majority of requests are static assets, JavaScript libraries, images. Fine-tuning the frontend-related requests will give a much greater return than shaving a couple of hundered milliseconds off a database query.</p>

<p>Google Bot measures the performance of your website, and it directly affects the SEO rating. Since <a href="https://developers.google.com/search/mobile-sites/mobile-first-indexing" target="_blank" rel="noopener noreferrer">July 2019</a>, Google Bot is using a <em>‚ÄúMobile first‚Äù</em> approach to assessing your website.</p>

<p>You might not care about frying the CPU and wasting the bandwidth of your mobile users. Maybe landing a sweet spot in Google search results should convince you to focus on your frontend performance?</p>

<h2 id="test-in-your-clients-shoes">Test in your client‚Äôs shoes</h2>

<p><em>‚ÄúIf you want to write fast websites, use slow internet.‚Äù</em>.</p>

<p>You should regularly throttle the internet speed during the development process to experience first-hand how your app will behave for most users.</p>

<p>On macOS, you can use the <a href="https://nshipster.com/network-link-conditioner/" target="_blank" rel="noopener noreferrer">Network Link Conditioner</a> to do it:</p>

<p><img alt="Simulate mobile network on a desktop computer" title="Simulate mobile network on a desktop computer" loading="lazy" src="https://pawelurbanek.com/assets/3g-network-performance-4273c3bd62edbdaddfdc36d7dad126747f3d69804a7ce8c1227cd8f96ff0a1ed.png"></p>

<p>Also, both Firefox and Chrome developer tools offer the option to throttle the internet speed in the <strong>Network</strong> tab:</p>

<p><img alt="Chrome network throttle setting" title="Chrome network throttle setting" loading="lazy" src="https://pawelurbanek.com/assets/chrome-network-throttle-ed2b0e3cb5163dbf3d6fe89601bd32c072af9a2b7146e82d8004f8e536ca208d.png"></p>

<p>Chrome network throttle</p>

<p><img alt="Firefox network throttle setting" title="Firefox network throttle setting" loading="lazy" src="https://pawelurbanek.com/assets/firefox-network-throttle-d11d6b54034fff903c4cc721f05a66747904fd72d3d9760ab7f1141491875434.png"></p>

<p>Firefox network throttle</p>


<p>Maybe the internal demos of the new features should also be done on the throttled network? Everyone in the company should have the chance to see how the app really works for most users.</p>

<h2 id="reconnaissance">Reconnaissance</h2>

<p>Discovering frontend issues is usually more straightforward than backend ones. You don‚Äôt even need admin access to the website. By definition, the frontend issues are in the <em>frontend</em>. You can scan and diagnose every website out there. I use the following tools to perform the initial scan:</p>

<p><a href="https://www.fastorslow.com/" target="_blank" rel="noopener noreferrer">FastOrSlow</a></p>

<p><a href="https://www.webpagetest.org/" target="_blank" rel="noopener noreferrer">WebPageTest</a></p>

<p><a href="https://developers.google.com/speed/pagespeed/insights/" target="_blank" rel="noopener noreferrer">Google PageSpeed Insights</a></p>

<p><a href="https://github.com/GoogleChrome/lighthouse" target="_blank" rel="noopener noreferrer">GoogleChrome lighthouse</a></p>

<p>There‚Äôs no reason why ANY website shouldn‚Äôt score top on each of those tools. Read on if your score is anywhere below 90%.</p>

<p><img alt="Abot for Slack FastOrSlow score" title="Abot for Slack FastOrSlow score" loading="lazy" src="https://pawelurbanek.com/assets/abot-fastorslow-28336ad9b7b74849a6a1d85a1ad269be81dd6288a960ee3b3ecbe69e6cf6b6a7.png"></p>

<p><img alt="Abot for Slack WebPageTest score" title="Abot for Slack WebPageTest score" loading="lazy" src="https://pawelurbanek.com/assets/abot-webpagetest-e33807bf28e738ced4aa16f48cdf17e44836a986b283aca9d673c8504ff045fa.png"></p>

<p><img alt="Abot for Slack Google speed score" title="Abot for Slack FastOrSlow score" loading="lazy" src="https://pawelurbanek.com/assets/abot-googlespeed-03d18ebbc637cce72357f44e3ed65e1cf60062e633df52bafc2eb178e0cca7ac.png"></p>

<p>The <a href="https://abot.app/" target="_blank">Abot landing page</a> is a dynamic Rails website getting top performance rating</p>





<h2 id="client-side-caching">Client-side caching</h2>

<p>Correctly configuring client-side caching is the most critical frontend optimization. I‚Äôve seen it misconfigured in multiple production apps so far. <a href="https://github.com/webpack/webpack" target="_blank" rel="noopener noreferrer">Webpack</a> comes with a great mechanism to easily leverage client-side caching, i.e., <em>MD5 digest</em>. The production assets generation process must be configured to append the <em>MD5 digest</em> tag to the filename.</p>

<p>It means that in the production environment, the <code>application.js</code> file becomes <code>application-5bf4f97...95c2147.js</code>. The random suffix is generated based on the file contents, so it is guaranteed to change if the file changes. You must add the correct <code>cache-control</code> header to make sure that once downloaded, the file will persist in the browser cache:</p>

<figure><pre><code data-lang="bash">cache-control: public, max-age<span>=</span>31536000, immutable</code></pre></figure>

<p>The <code>immutable</code> parameter ensures that cache is not cleared when the user explicitly refreshes the website on the Chrome browser.</p>

<p>If you‚Äôre using NGINX as reverse proxy you can use the following directive:</p>

<figure><pre><code data-lang="nginx"><span>location</span> <span>~</span><span>*</span> <span>\</span><span>.(?:ico|css|js|gif|jpe?g|png|woff2)</span>$ <span>{</span>
  <span>add_header</span> <span>Cache-Control</span> <span>"public,</span> <span>max-age=31536000,</span> <span>immutable"</span><span>;</span>
  <span>try_files</span> <span>$uri</span> <span>=</span><span>404</span><span>;</span>
<span>}</span></code></pre></figure>

<p>I‚Äôve seen many apps using <code>Etag</code> and <code>Last-Modified</code> headers instead of <code>Cache-Control</code>. <code>Etag</code> is also generated based on the file contents, but the client has to talk to the server to confirm that the cached version is still correct. It means that on every page visit, the browser has to issue a request to validate its cache contents and wait for <code>304 Not Modified</code> response. This  completely unnecessary network roundtrip can be avoided if you add a <code>Cache-Control</code> header.</p>

<h2 id="limit-bandwidth-usage">Limit bandwidth usage</h2>

<p>Nowadays, websites are just MASSIVE. It often takes multiple MBs to render a static landing page. Let me point out the most common mistakes that affect it and how they can be resolved.</p>

<h3 id="compress-and-resize-images">Compress and resize images</h3>

<p>There‚Äôs no excuse for serving uncompressed images on your website. You must make sure to process all your images with tools like <a href="https://compressor.io/" target="_blank" rel="noopener noreferrer">Compressor.io</a>. There‚Äôs often no perceivable difference for images processed with <strong>Lossy</strong> compression, and it usually means ~70% size reduction.</p>

<p>Resizing an image to the size that it actually needs is often overlooked. To check it, visit your website using Firefox on a large desktop screen, right-click the image, and select <strong>View image info</strong>. You‚Äôll see what dimensions the image needs vs. how large it is now:</p>

<p><img alt="Checking real image" title="Checking real image" loading="lazy" src="https://pawelurbanek.com/assets/real-image-size-524abe8437774180a233461deb8ada35092fda22cee4b3dfe85c0d0ad2e757b8.png"></p>

<p>Make sure first to resize the image and only then compress it. Otherwise, you might lose quality.</p>

<h3 id="defer-images-loading">Defer images loading</h3>

<p>You should defer the loading of the images that are not visible in the initial viewport. During the initial load, dozens of requests are competing for network throughput. Delaying the transfer of unnecessary images will leave more resources for necessary assets like CSS stylesheets etc.</p>

<p>There‚Äôs <a href="https://github.com/aFarkas/lazysizes" target="_blank" rel="noopener noreferrer">plenty</a> of <a href="https://github.com/tuupola/lazyload" target="_blank" rel="noopener noreferrer">different</a> <a href="https://github.com/vvo/lazyload" target="_blank" rel="noopener noreferrer">JavaScript libraries</a> that offer this feature. Including them means additional bandwidth usage, so I prefer to keep things simple and use a native <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/img#attr-loading" target="_blank" rel="noopener noreferrer"><code>loading='lazy'</code></a> HTML attribute.</p>

<p>It has decent <a href="https://caniuse.com/loading-lazy-attr" target="_blank" rel="noopener noreferrer">browser support</a>. Have a look at how it affected one of my blog posts:</p>

<p><img alt="Checking real image " title="Checking real image " loading="lazy" src="https://pawelurbanek.com/assets/before-lazy-images-a0e8cdb9099f3d5a348f853f4f222b67149aa058e59ecd29d2d5338be81cd8c0.png"></p>

<p>Without lazy loaded images</p>

<p><img alt="Checking real image " title="Checking real image " loading="lazy" src="https://pawelurbanek.com/assets/after-lazy-images-836f1781a9b7bf56cd8883a0ad0d252f52223f74b856e7e994ecef1d52efd029.png"></p>

<p>Lazy loading for images enabled</p>



<p>As you can see, adding <code>loading='lazy'</code> to all the images reduced ten requests and over <em>250kb</em> of transfer on the initial load. That‚Äôs a massive deal for slower internet connections!</p>

<h3 id="enough-with-the-gifs-already">Enough with the GIFs already‚Ä¶</h3>

<p>GIFs are HUGE! I understand you want to showcase a fancy UI on your landing page, but maybe you could use a lazy-loaded movie clip instead? <em>10MB</em> GIF can be converted to <em>250kb</em> mp4 file‚Ä¶ Twitter automatically changes <em>GIF</em> images to <em>mp4</em> files, so I‚Äôd trust them on this one.</p>

<h3 id="cherry-pick-and-measure-dependencies-size">Cherry-pick and measure dependencies size</h3>

<p>Many frontend libraries offer a modular approach to including them in your application. For example, <a href="https://getbootstrap.com/docs/3.4/customize/" target="_blank" rel="noopener noreferrer">Bootstrap</a> allows you to customize the build to include only the components you need.</p>

<p>Some popular libraries have lightweight alternatives. Since recently, <a href="https://twitter.com/addyosmani/status/1304676118822174721" target="_blank" rel="noopener noreferrer">ChromeDevTools suggests them</a>, so make sure to use it for your application.</p>

<h3 id="reconsider-3rd-party-dependencies">Reconsider 3rd party dependencies</h3>

<p>Overusing externally hosted 3rd party JavaScript libraries is the simplest way to kill the performance of your website.</p>

<p>Dropping in yet another <code>&lt;script src="..."&gt;</code> tag might not seem like a big deal. It‚Äôs easy to forget that one script can result in a cascade of requests, each including more resources. Here‚Äôs the cost of embedding sample 3rd party JavaScript libraries:</p>

<table>
  <tbody><tr>
    <th></th>
    <th>Requests</th>
    <th>Bandwidth (total/gzipped)</th>
  </tr>
  <tr>
    <td><a href="https://www.google.com/analytics/" target="_blank" rel="noopener noreferrer">Google Analytics</a></td>
    <td>4</td>
    <td>104.09 KB / 40.37 KB</td>
  </tr>
  <tr>
    <td><a href="https://simpleanalytics.com/" target="_blank" rel="noopener noreferrer">Simple Analytics</a></td>
    <td>2</td>
    <td>5.29 KB / 3.12 KB</td>
  </tr>
  <tr>
    <td><a href="https://developer.twitter.com/en/docs/twitter-for-websites/follow-button/overview.html" target="_blank" rel="noopener noreferrer">Twitter button</a></td>
    <td>8</td>
    <td>173.68 KB / 59.30 KB</td>
  </tr>
  <tr>
    <td><a href="https://disqus.com/" target="_blank" rel="noopener noreferrer">Disqus</a></td>
    <td>26</td>
    <td>862.55 KB / 271.48 KB</td>
  </tr>
  <tr>
    <td><a href="https://commento.io/" target="_blank" rel="noopener noreferrer">Commento.io</a></td>
    <td>5</td>
    <td>64.73 KB / 19.25 KB</td>
  </tr>
</tbody></table>



<p>The only 3rd party JavaScript dependency I use for this blog is <a href="https://commento.io/" target="_blank" rel="noopener noreferrer">Commento.io</a> for comments. It‚Äôs over <strong>10x</strong> lighter than its alternative Disqus.</p>

<p>I‚Äôve switched from using Google Analytics to SimpleAnalytics long ago. Recently I‚Äôve decided I don‚Äôt need to track the visitors of this blog at all. Summary visit stats from Cloudflare are enough for me.</p>

<p><img alt="CloudFlare visits stats" title="CloudFlare visits stats" loading="lazy" src="https://pawelurbanek.com/assets/cloudflare-total-stats-2af208b0332a799e70e0aaa5495ef01c05c12ccc24514110accd3a4005817863.png"></p>

<p>All the tracking I need. No JavaScript dependencies required</p>


<p>Including 3rd party libraries from external sources often reduces your ability to set correct caching headers, thus hurting your performance score.</p>

<p>You should always look for the most straightforward tool that meets your requirements and only resort to using 3rd party if you cannot develop the lightweight solution yourself.</p>

<h2 id="http-2">HTTP 2</h2>

<p><em>HTTP 2</em> offers massive performance improvement over <em>HTTP 1.1</em> for loading static assets. Headers are compressed to reduce bandwidth. Even more important is that multiple assets can be loaded in parallel over a single HTTP connection.</p>

<p>It might not be critical for API calls, but for static assets, you should enable <em>HTTP 2</em> and expect serious performance gains.</p>

<p>How to do it depends on your infrastructure. If you‚Äôre using custom infrastructure with NGINX reverse proxy, you can check out <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-nginx-with-http-2-support-on-ubuntu-18-04" target="_blank" rel="noopener noreferrer">this tutorial</a>.</p>

<p>If you‚Äôre using Heroku, you‚Äôre out of luck because currently, it <a href="https://help.heroku.com/JAOCNZ25/does-heroku-have-plans-to-support-http-2" target="_blank" rel="noopener noreferrer">does not support HTTP 2</a>. The simplest way to add HTTP 2 support for Heroku is to proxy your traffic through <a href="https://pawelurbanek.com/cloudflare.com/" target="_blank" rel="noopener noreferrer">Cloudflare</a>.</p>

<p>If you don‚Äôt want to move your application to Cloudflare‚Äôs DNS, you can always use a custom domain just for serving assets from their CDN.</p>

<h2 id="physical-server-location-and-cdn">Physical server location and CDN</h2>

<p>The usage of CDN (<em>Content Delivery Network</em>) is critical if your user base is spread across the globe. Correctly configured CDN will cache static assets on the edge locations, significantly reducing the request‚Äôs duration. We‚Äôre talking like <em>50ms</em> vs. <em>800ms</em> (<strong>16x</strong> ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/frontend-performance-optimization">https://pawelurbanek.com/frontend-performance-optimization</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/frontend-performance-optimization</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044079</guid>
            <pubDate>Tue, 10 Nov 2020 09:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software development: should we stop? Maybe we should]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044031">thread link</a>) | @enz
<br/>
November 10, 2020 | http://blog.spencermounta.in/2020/should-we-stop/index.html | <a href="https://web.archive.org/web/*/http://blog.spencermounta.in/2020/should-we-stop/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://blog.spencermounta.in/2020/should-we-stop/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044031</guid>
            <pubDate>Tue, 10 Nov 2020 09:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Awful Edge Case in Bash's Set -e]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044030">thread link</a>) | @jbrot
<br/>
November 10, 2020 | http://jbrot.com/blog/dash_e_problems.html | <a href="https://web.archive.org/web/*/http://jbrot.com/blog/dash_e_problems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <header>
                
                
            </header>

            <p>
            The last six months, I've been building out the automated testing infrastructure at a start up.
            Our infrastructure is mostly in Python, but writing Bash scripts is inevitable.
            At the end of the day, automated testing is all about running commands in a row‚Äîand Bash is the right tool for the job.
            </p>

            <p>
            There are a <a href="https://mywiki.wooledge.org/BashPitfalls">whole</a> <a href="https://github.com/anordal/shellharden/blob/master/how_to_do_things_safely_in_bash.md">bunch</a> <a href="https://sipb.mit.edu/doc/safe-shell/">of</a> <a href="https://wizardzines.com/comics/bash-errors/">articles</a> about how to write safe Bash scripts, and the standard advice is to add <code>set -euo pipefail</code> to make your scripts "safe."
            In this article, I'm going to describe one edge case where <code>set -e</code> completely fails to work.
            </p>

            <h2> Background </h2>

            <p>
            Suppose we have two projects in a git repo, say MyLibrary and MyApplication, where MyApplication depends on MyLibrary. And suppose each project provides a script <code>test.sh</code> that looks something like this:
            </p>

<pre><code>#!/bin/bash

set -e

./configure
make

python fancy_test_driver.py tests/first_tests
python fancy_test_driver.py --option-1 tests/second_tests
python fancy_test_driver.py --option-2 tests/third_tests
</code></pre>

            <p>
            This is a pretty reasonable script.
            We can now require that all changes pass both <code>my_library/test.sh</code> and <code>my_application/test.sh</code> before being merged.
            </p>

            <p>
            As time goes on, the amount of tests (and projects!) can spiral out of control.
            Eventually, someone (me) gets tasked with trying to optimize things.
            One obvious thing to do is to abort early.
            If MyLibrary fails testing, we don't need to bother with testing MyApplication.
            </p>

            <p>
            Of course, the developers who used to get errors from both projects aren't very happy about this change.
            Now passing the <code>test.sh</code> scripts is like peeling an onion: you resolve the first layer of errors only to find more errors lurking underneath‚Äîhidden by the early abort.
            However, there's a middle ground.
            We can test MyApplication only if MyLibrary fails while running test cases.
            If MyLibrary fails during compilation, continuing on is pointless since MyApplication depends on MyLibrary.
            </p>

            <p>
            So how do we distinguish when <code>test.sh</code> fails during compilation from when it fails during testing?
            Exit codes, naturally:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE

python fancy_test_driver.py tests/first_tests
python fancy_test_driver.py --option-1 tests/second_tests
python fancy_test_driver.py --option-2 tests/third_tests
</code></pre>

            <p>
            And we're done!
            An exit code of 0 means we passed the tests, an exit code of 79 means compilation failure (no need to test further projects), and any other exit code means we failed in testing‚Äîso we can continue testing the other projects.
            </p>

            <h2> Finding the Problem </h2>

            <p>
            The above solution works fine when we only have two lines that need the special exit code.
            However, it quickly becomes unwieldly when it needs to be applied to more lines:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

pushd codegen_tool1 || exit $COMPILE_FAILURE_CODE
./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE
./codegen_tool1 || exit $COMPILE_FAILURE_CODE
popd || exit $COMPILE_FAILURE_CODE

pushd codegen_tool2 || exit $COMPILE_FAILURE_CODE
./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE
./codegen_tool2 || exit $COMPILE_FAILURE_CODE
popd || exit $COMPILE_FAILURE_CODE

./configure || exit $COMPILE_FAILURE_CODE
make || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            Gross!
            Clearly, we should factor out the <code>|| exit $COMPILE_FAILURE_CODE</code> line and have it apply to all of our lines at once.
            We can easily do this by creating a separate <code>build.sh</code> script:
            </p>

<pre><code>#!/bin/bash

set -e

pushd codegen_tool1
./configure
make
./codegen_tool1
popd

# snip

./configure
make
</code></pre>

            <p>
            And then adjusting <code>test.sh</code> to just have:
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

./build.sh || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            And this, too, works great!
            But wait!
            Why even use a second script?
            Can't we do the exact same thing with a subshell?
            </p>

<pre><code>#!/bin/bash

set -e

COMPILE_FAILURE_CODE=79

(
    pushd codegen_tool1
    ./configure
    make
    ./codegen_tool1
    popd

    # snip

    ./configure
    make
) || exit $COMPILE_FAILURE_CODE

# Run some tests...
</code></pre>

            <p>
            <strong>No!</strong>
            This subshell implementation is dangerously broken.
            The rest of this article will explore how and why the subshell code does not function as expected.
            </p>

            <h2> There's a Problem? </h2>

            <p>
            Let's run some simple bash programs and see what happens.
            First, we'll confirm <code>set -e</code> works as expected.
            </p>

<pre><samp>$ cat script1.sh
#!/bin/bash
echo "Statement 1"
(exit 3)
echo "Statement 2"

$ echo "$?"
0

#!/bin/bash
set -e
echo "Statement 1"
(exit 3)
echo "Statement 2"

$ ./script2.sh
Statement 1

$ echo "$?"
3
</samp></pre>

            <p>
            Yep, that's what we expected.
            Without <code>set -e</code> Bash ran every statement, and with <code>set -e</code> Bash stopped after the first non-zero exit code.
            What if we put our statements in a subshell?
            </p>

<pre><samp>$ cat script3.sh
#!/bin/bash
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)

$ ./script3.sh
Statement 1
Statement 2

$ echo "$?"
0

$ cat ./script4.sh
#!/bin/bash
set -e
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)

$ ./script4.sh
Statement 1

$ echo "$?"
3
</samp></pre>

        <p>
        And again, that's what we expected.
        The subshell made no difference.
        Note that <code>set -e</code> does propagate into the subshell.
        Alright. What if we mask the subshell's exit code?
        </p>

<pre><samp>$ cat script5.sh
#!/bin/bash
set -e
(
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script5.sh
Statement 1
Statement 2

$ echo "$?"
0
</samp></pre>

        <p>And again everything works as...</p>

        <h2> Wait, what? </h2>

        <p>Okay. Maybe <code>set -e</code> doesn't propagate?</p>

<pre><samp>$ cat script6.sh
#!/bin/bash
set -e
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script6.sh
Statement 1
Statement 2

$ echo "$?"
0

$ cat script7.sh
#!/bin/bash
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
) || exit 9

$ ./script7.sh
Statement 1
Statement 2

$ echo "$?"
0
</samp></pre>

        <p>
        Nope. Still doesn't work.
        Even if we just have <code>set -e</code> in the subshell and not in the outer script, it doesn't work.
        </p>

        <h2>So what's going on?</h2>

        <p>
        Well, if we dig into the Bash man page, we find this excerpt about <code>set -e</code>:
        </p>

        <blockquote>
              Exit  immediately  if a pipeline (which may consist of a single simple command), a list, or a compound command (see SHELL GRAMMAR above), exits with a non-zero status.
              The shell does not exit if the  command  that  fails  is part  of  the command list immediately following a while or until keyword, part of the test following the if or elif reserved  words, <em>part of any command executed in a &amp;&amp; or || list except the command following the final &amp;&amp; or ||,</em> any command in a pipeline but the last, or if the command's return value is being inverted with !.
        </blockquote>

        <p>
        So, the spec says that if you're using <code>&amp;&amp;</code> or <code>||</code>, only the last command's exit code can cause the shell to exit.
        This makes sense, because you expect  <code>command_1 || command_2</code> to execute <code>command_2</code> if <code>command_1</code> fails.
        Without this exception, it would be very hard to have any logical statements when <code>-e</code> is set.
        </p>

        <p>
        The behavior we just witnessed is, therefore, Working as Intended‚Ñ¢.
        When we try to mask the subshell's exit code, we put the subshell at the start of an <code>||</code> list.
        So, the subshell's exit code will not cause an exit despite <code>-e</code> being set.
        But, every single command inside the subshell is <em>also</em> considered part of the <code>||</code> list, and thus no exit code anywhere in the subshell can cause the subshell to exit.
        It's as if <code>set +e</code> is being run implicitly in the subshell‚Äîonly, as we've seen, we can't override it with an explicit <code>set -e</code> in the subshell.
        </p>

        <p>
        Is there anything we can do to fix this?
        Well, you're probably better off with one of the approaches I presented earlier.
        If you need to stay inside the same shell script, the solution with <code>trap</code> below is probably what you want.
        And if you truly need to use a subshell, I was able to come up with this mess:
        </p>

<pre><samp>$ cat script8.sh
#!/bin/bash
set -e
echo "Some stuff with -e set"

set +e
(
    set -e
    echo "Statement 1"
    (exit 3)
    echo "Statement 2"
)
[[ $? -ne 0 ]] &amp;&amp; exit 9
set -e

echo "More code with -e set (unreachable)"

$ ./script8.sh
Some stuff with -e set
Statement 1

$ echo "$?"
9
</samp></pre>

        <h3>Bonus Solution</h3>

        <p>
        I ended up using <code>trap</code> for error masking:
        </p>

<pre><samp>$ cat script9.sh
#!/bin/bash

set -e

trap 'exit 9' ERR

echo "Statement 1"
(exit 3)
echo "Statement 2"

trap - ERR

$ ./script9.sh
Statement 1

$ echo "$?"
9
</samp></pre>

        <p>
        The nice part about this solution is it allows you to stick with just one script (useful if you need to use functions), and the logic is straightforward.
        This option can be harder to make work if you're already using <code>trap ERR</code> for cleanup, though.
        </p>

        </article></div>]]>
            </description>
            <link>http://jbrot.com/blog/dash_e_problems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044030</guid>
            <pubDate>Tue, 10 Nov 2020 09:09:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Become Covid Savvy in 10 Steps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25044022">thread link</a>) | @datashrimp
<br/>
November 10, 2020 | https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/ | <a href="https://web.archive.org/web/*/https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://adsp.ai/articles/how-to-become-covid-savvy-in-10-steps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25044022</guid>
            <pubDate>Tue, 10 Nov 2020 09:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Productivity Guide: All You Need to Know to Be Efficient]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043892">thread link</a>) | @iuliangulea
<br/>
November 10, 2020 | https://iuliangulea.com/productivity/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://iuliangulea.com/images/productivity.png" alt="Productivity"></p><h2 id="productivity-definition">Productivity Definition</h2><blockquote><p>Productivity is a measure of the efficiency of a person to perform a specific task.</p></blockquote><p>We often think it is a state of constant efficiency that allows us to do everything faster and better, but this is wrong. <em>Productivity is a measurement per individual task.</em></p><p>If you try to measure productivity as the number of tasks you accomplish daily, you still have to count in each individual assignment, which endorses the idea that productivity is a measurement per task.</p><h2 id="productivity-from-within-and-without">Productivity From Within And Without</h2><p>There are different strategies for productivity, and all those strategies can be classified into two main categories: <strong>external productivity</strong> and <strong>internal productivity.</strong></p><p><strong>External productivity</strong> is what usually people put their emphasis on. Also, it is what all those products, apps, and services promise to deliver. External productivity is all about automation, better tools, frameworks, software, and anything that allows you to perform your work better and faster. It has a significant potential to improve your performance by taking advantage of technology and advanced tools.</p><p><strong>Internal productivity,</strong> on the other hand, is often overlooked. Unlike the external one, internal productivity is all about your cognitive and physical performance, about your ability to focus, sustain your attention on the task at hand, manage your energy, and, generally speaking, understand how your body and mind works.</p><h2 id="gaining-productivity-expertise--the-pyramid-of-mastery">Gaining Productivity Expertise ‚Äî The Pyramid Of Mastery</h2><p><img src="https://iuliangulea.com/images/the-pyramid-of-mastery/the-pyramid-of-mastery-1.png" alt="Pyramid of Mastery"></p><p><a href="https://iuliangulea.com/pyramid-of-mastery/">The Pyramid of Mastery</a> is a model that defines any domain in terms of 4 categories:</p><p><strong>Elements</strong> are the fundamental building blocks that make up a domain. In productivity, elements are abstract: focus, attention, working memory, sensory channels, etc.</p><p><strong>Rules</strong> are the laws by which the elements interact with each other and general principles that govern a domain. Some rules are: goal-directed attention is easily distracted, senses have a different throughput, working memory cannot perform two tasks simultaneously (hence multitasking is a myth), etc.</p><p><strong>Tools</strong> are the instruments that help you operate with the Elements and Rules. The majority of productivity tools nowadays are software apps. One of the best productivity tools is pen and paper.</p><p><strong>Frameworks</strong> are a combination of the previous layers. A Framework is a layer of abstraction that hides the underlying fundamentals behind a friendly facade that is easy to use to achieve a specific goal. Some frameworks in productivity are office suites and various productivity methods (e.g., <a href="https://en.wikipedia.org/wiki/Pareto_principle">80/20 Rule</a>, <a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method">The Eisenhower Method</a>, and others).</p><p>All four layers together allow you to be an expert in your field. Leave one out, and there will always be something you do not fully understand. And when you don‚Äôt understand something, you cannot be fully efficient at it.</p><p>If you would like to find out more about how the Pyramid of Mastery applies to the field of productivity, I wrote a separate <a href="https://iuliangulea.com/pyramid-of-mastery/productivity/">article</a> on that topic.</p><h2 id="productivity-approaches">Productivity Approaches</h2><p>Generally speaking, you can be more productive by taking one or several of the following approaches:</p><p><strong>1. Delegate/Outsource the task.</strong> This approach is the most efficient from the time standpoint as it frees all your time and allows you to focus on other tasks. Although it is limited in how much you can delegate/outsource, it is crucial to keep in mind that you can and need to delegate.</p><p><strong>2. Automate the task.</strong> If you cannot delegate/outsource, think about whether your work on a task can be either fully or partially automated. There are lots of services, products, and programs that can do the work for you in a broad range of areas. If their cost is smaller than the value of the time you can save using them, then do it.</p><p><strong>3. Use better tools and learn them well.</strong> If automation is also not an option, then it means <em>you</em> need to do it. Having good tools is crucial if you want to be productive. A thorough understanding of their functions can make a big difference. In the case of software, learn its features and the shortcuts of the most frequently used functionality by you.</p><p><strong>4. Understand cognitive processes and learn what works best for you.</strong> Whenever we need to perform mental work, understanding <em>how</em> our <a href="https://iuliangulea.com/human-senses/">senses</a>, <a href="https://iuliangulea.com/attention/">attention</a>, <a href="https://iuliangulea.com/working-memory/">working memory</a>, and other relevant processes work can make a huge difference. As a plant flourishes, when the conditions are right, our brains can be incredibly performant whenever we offer them the right environment in which they can function.</p><h2 id="my-top-productivity-strategies">My Top Productivity Strategies</h2><p><strong>The Rule Of Threes.</strong> This is a meta strategy I came up with some time ago that help me make the right decisions when it comes to taking on new opportunities. No matter how productive you are, if you have too much on your plate, your attention and energy will split into too many places, and that will affect your productivity. The rule is simple: at any one point in time, I should have no more than three ongoing projects, and by an ongoing project, I mean any work that spans for longer than one week. Having more than that will scatter your energy and attention to the detriment of effectiveness.</p><p><strong>Plan Your Day In Advance.</strong> It is much easier to follow a predefined list of steps rather than having only the destination in mind and think about your next course of action after each task. The 10‚Äì15 minutes spent in the evening to decide and prioritize what you will work on will save you plenty of energy and time the following day.</p><h2 id="more-productivity-tips-for-every-day">More Productivity Tips For Every Day</h2><p><strong>1. Reduce Distractions As Much As Possible.</strong> If there is something that can distract you, sooner or later, it will distract you. Therefore, if you want to keep focused for a longer time, remove as many distractions as you can. This includes visual distractions on your table and screen (yes, those Facebook and Twitter tabs are hooking your attention pretty easy, aren‚Äôt they?), audial distractions (buy yourself a good pair of noise-canceling headphones), and other types of disturbances that distract you regularly.</p><p><strong>2. Put Your Phone Away.</strong> Although it is also a distraction, this tip deserves a separate mention. Put your phone on silent mode and away from your sight (not in your pocket). All those sounds (including notifications, calls, etc.) and flashes are nothing else than stimuli that have their primary goal to grab your attention and distract you from the thing you are focused on. It is also essential to put the phone away, as having it in your area of sight will also urge you to grab it when you see it on the table.</p><p><strong>3. Split Your Tasks Into Manageable Chunks.</strong> If an assignment is too big for you to comprehend, consider splitting it into several smaller subtasks until you get them of a size that you can easily accomplish. A positive side-effect of this is that smaller tasks provide a sense of progress, positively affecting your overall state and mood.</p><p><strong>4. Use Good Tools And Learn Them Properly.</strong> If you use software tools, learn the shortcuts of the programs you work in as it will save you dozens of hours within a year. If you use physical tools, buy high-quality tools, as they will pay off multiple times.</p><p><strong>5. Your Energy Is More Important Than The Allocated Time.</strong> Time Management is overrated. It‚Äôs not that timing your tasks is not essential, but <em>time is absolute.</em> It is independent of anything. Consider your energy levels when planning your tasks. Your energy is what matters when working on a job. You can spend 2 hours banging your head against something in the evening when you are tired and then complete that task in 30 minutes the next morning. Know when you are more productive and work on the most important tasks then.</p><p><strong>6. Use Visual Aids.</strong> A pen and a piece of paper are sometimes the best, simple, and most efficient productivity tools you can use. If the task you are working on relies on manipulating multiple pieces of information at a time, write them on paper or draw a diagram. That will free up resources necessary to store them in your working memory so that you can focus on processing and manipulating them instead. This will also involve your visual sense, allowing you to make more potentially relevant connections between ideas.</p><h2 id="all-productivity-articles">All Productivity Articles</h2><p>These are all articles I have written on productivity. Enjoy!</p><ul><li><a href="https://iuliangulea.com/keyboard-shortcuts/">6 Shortcuts That Save Me 62 Hours Each Year</a></li><li><a href="https://iuliangulea.com/pyramid-of-mastery/productivity/">The Ultimate Productivity Guide ‚Äî Scientifically Proven Techniques To Get Things Done</a></li><li><a href="https://iuliangulea.com/attention/">The Dual Nature Of Attention ‚Äî 5 Ways To Stay Less Distracted And Be More Productive</a></li><li><a href="https://iuliangulea.com/working-memory/">How People Learn ‚Äî Working Memory And The 3 Basic Rules Of Productivity</a></li><li><a href="https://iuliangulea.com/the-most-substantial-word/">Your Name ‚Äî The Most Substantial Word</a></li><li><a href="https://iuliangulea.com/how-i-automated-things/">How I Saved 14 Hours Of Working Time Each Month</a></li><li><a href="https://iuliangulea.com/one-percent-rule/">The One Percent Rule - How Tiny Changes Can Bring Big Results</a></li><li><a href="https://iuliangulea.com/team-processes-what/">Increase Your Team‚Äôs Productivity by Establishing Processes - Part III</a></li><li><a href="https://iuliangulea.com/team-processes-how/">Increase Your Team‚Äôs Productivity by Establishing Processes - Part II</a></li><li><a href="https://iuliangulea.com/team-processes-why/">Increase Your Team‚Äôs Productivity by Establishing Processes - Part I</a></li></ul><hr></div></div>]]>
            </description>
            <link>https://iuliangulea.com/productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043892</guid>
            <pubDate>Tue, 10 Nov 2020 08:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how I git]]>
            </title>
            <description>
<![CDATA[
Score 228 | Comments 135 (<a href="https://news.ycombinator.com/item?id=25043731">thread link</a>) | @ingve
<br/>
November 10, 2020 | https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Every now and then I get questions on how to work with git in a smooth way when developing, bug-fixing or extending curl ‚Äì or how I do it. After all, I <a href="https://daniel.haxx.se/blog/2020/10/26/working-open-source/" data-type="post" data-id="14901">work on open source full time</a> which means I have very frequent interactions with git (and GitHub). Simply put, I work with git all day long. Ordinary days, I issue git commands several hundred times.</p>



<p>I have a very simple approach and way of working with git in curl. This is how it works.</p>



<h2>command line</h2>



<p>I use git almost exclusively from the command line in a terminal. To help me see which branch I‚Äôm working in, I have this little bash helper script.</p>



<pre>brname () {
  a=$(<code>git rev-parse --abbrev-ref HEAD 2&gt;/dev/null</code>)
  if [ -n "$a" ]; then
    echo " [$a]"
  else
    echo ""
  fi
}
PS1="\u@\h:\w\$(brname)$ "</pre>



<p>That gives me a prompt that shows username, host name, the current working directory and the current checked out git branch.</p>



<p>In addition: I use Debian‚Äôs <a href="https://salsa.debian.org/debian/bash-completion/-/blob/master/README.md">bash command line completion</a> for git which is also really handy. It allows me to use tab to complete things like git commands and branch names. </p>



<h2>git config</h2>



<p>I of course also have my customized <code>~/.gitconfig</code> file to provide me with some convenient aliases and settings. My most commonly used git aliases are:</p>


<pre title="">st = status --short -uno
ci = commit
ca = commit --amend
caa = commit -a --amend
br = branch
co = checkout
df = diff
lg = log -p --pretty=fuller --abbrev-commit
lgg = log --pretty=fuller --abbrev-commit --stat
up = pull --rebase
latest = log @^{/RELEASE-NOTES:.synced}..
</pre>


<p>The ‚Äòlatest‚Äô one is for listing all changes done to curl since the most recent RELEASE-NOTES ‚Äúsync‚Äù. The others should hopefully be rather self-explanatory.</p>



<p>The config also sets <code>gpgsign = true</code>, enables mailmap and a few other things.</p>



<h2>master is clean and working</h2>



<p>The main curl development is done in the single <a href="https://github.com/curl/curl">curl/curl</a> git repository (primarily hosted on GitHub). We keep the master branch the bleeding edge development tree and we work hard to always keep that working and functional. We do our releases off the master branch when that day comes (every eight weeks) and we provide ‚Äú<a href="https://curl.haxx.se/snapshots/">daily snapshots</a>‚Äù from that branch, put together ‚Äì yeah ‚Äì daily.</p>



<p>When merging fixes and features into master, we avoid merge commits and use rebases and fast-forward as much as possible. This makes the branch very easy to browse, understand and work with ‚Äì as it is 100% linear.</p>



<h2>Work on a fix or feature</h2>



<p>When I start something new, like work on a bug or trying out someone‚Äôs patch or similar, I first create a local branch off master and work in that. That is, I don‚Äôt work directly in the master branch. Branches are easy and quick to do and there‚Äôs no reason to shy away from having loads of them!</p>



<p>I typically name the branch prefixed with my GitHub user name, so that when I push them to the server it is noticeable who is the creator (and I can use the same branch name locally as I do remotely).</p>



<pre>$ git checkout -b bagder/my-new-stuff-or-bugfix</pre>



<p>Once I‚Äôve reached somewhere, I commit to the branch. It can then end up one or more commits before I consider myself ‚Äúdone for now‚Äù with what I was set out to do.</p>



<p>I try not to leave the tree with any uncommitted changes ‚Äì like if I take off for the day or even just leave for food or an extended break. This puts the repository in a state that allows me to easily switch over to another branch  when I get back ‚Äì should I feel the need to. Plus, it‚Äôs better to commit and explain the change <em>before</em> the break rather than having to recall the details again when coming back.</p>



<h2>Never stash</h2>



<p>‚Äúgit stash‚Äù is therefore not a command I ever use. I rather create a new branch and commit the (temporary?) work in there as a potential new line of work.</p>



<h2>Show it off and get reviews</h2>



<p>Yes I am the lead developer of the project but I still maintain the same work flow as everyone else. All changes, except the most minuscule ones, are done as pull requests on GitHub.</p>



<p>When I‚Äôm happy with the functionality in my local branch. When the bug seems to be fixed or the feature seems to be doing what it‚Äôs supposed to do and the test suite runs fine locally.</p>



<p>I then clean up the commit series with ‚Äú<code>git rebase -i</code>‚Äù (or if it is a single commit I can instead use just ‚Äú<code>git commit --amend</code>‚Äú).</p>



<p>The commit series should be a set of logical changes that are related to this change and not any more than necessary, but kept separate if they are separate. Each commit also gets its own proper commit message. Unrelated changes should be split out into its own separate branch and subsequent separate pull request.</p>



<pre>git push origin bagder/my-new-stuff-or-bugfix</pre>



<h2>Make the push a pull request</h2>



<p>On GitHub, I then make the newly pushed branch into a <a href="https://github.com/curl/curl/pulls">pull request</a> (aka ‚Äúa PR‚Äù). It will then become visible in the list of pull requests on the site for the curl source repository, it will be announced in the #curl IRC channel and everyone who follows the repository on GitHub will be notified accordingly.</p>



<p>Perhaps most importantly, a pull request kicks of a flood of CI jobs that will build and test the code in numerous different combinations and on several platforms, and the results of those tests will trickle in over the coming hours. When I write this, we have around 90 different CI jobs ‚Äì per pull request ‚Äì and something like 8 different code analyzers will scrutinize the change to see if there‚Äôs any obvious flaws in there.</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png"><img loading="lazy" width="2686" height="1510" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-05-curl-Project-status-dashboard.png" alt=""></a><figcaption>CI jobs per platform over time. Graph snapped on November 5, 2020</figcaption></figure>



<h2>A branch in the actual curl/curl repo</h2>



<p>Most contributors who would work on curl would not do like me and make the branch in the curl repository itself, but would rather do them in their own forked version instead. The difference isn‚Äôt that big and I <em>could</em> of course also do it that way.</p>



<h2>After push, switch branch</h2>



<p>As it will take some time to get the full CI results from the PR to come in (generally a few hours), I switch over to the next branch with work on my agenda. On a normal work-day I can easily move over ten different branches, polish them and submit updates in their respective pull-requests.</p>



<p>I can go back to the&nbsp;master branch again with ‚Äò<code>git checkout master</code>‚Äò and there I can ‚Äú<code>git pull</code>‚Äù to get everything from upstream ‚Äì like when my fellow developers have pushed stuff in the mean time.</p>



<h2>PR comments or CI alerts</h2>



<p>If a reviewer or a CI job find a mistake in one of my PRs, that becomes visible on GitHub and I get to work to handle it. To either fix the bug or discuss with the reviewer what the better approach might be.</p>



<p>Unfortunately, flaky CI jobs is a part of life so very often there ends up one or two red markers in the list of CI jobs that can be ignored as the test failures in them are there due to problems in the setup and not because of actual mistakes in the PR‚Ä¶</p>



<p>To get back to my branch for that PR again, I ‚Äú<code>git checkout bagder/my-new-stuff-or-bugfix</code>‚Äú, and fix the issues.</p>



<p>I normally start out by doing follow-up commits that repair the immediate mistake and push them on the branch:</p>



<pre>git push origin <code>bagder/my-new-stuff-or-bugfix</code></pre>



<p>If the number of fixup commits gets large, or if the follow-up fixes aren‚Äôt small, I usually end up doing a squash to reduce the number of commits into a smaller, simpler set, and then force-push them to the branch.</p>



<p>The reason for that is to make the patch series easy to review, read and understand. When a commit series has too many commits that changes the previous commits, it becomes hard to review.</p>



<h2>Ripe to merge?</h2>



<p>When the pull request is ripe for merging (independently of who authored it), I switch over to the master branch again and I merge the pull request‚Äôs commits into it. In special cases I cherry-pick specific commits from the branch instead. When all the stuff has been yanked into master properly that should be there, I push the changes to the remote.</p>



<p>Usually, and especially if the pull request wasn‚Äôt done by me, I also go over the commit messages and polish them somewhat before I push everything. Commit messages should follow our style and mention not only which PR that it closes but also which issue it fixes and properly give credit to the bug reporter and all the helpers ‚Äì using the right syntax so that our automatic tools can pick them up correctly!</p>



<p>As already mentioned above, I merge fast-forward or rebased into master. No merge commits.</p>



<h2>Never merge with GitHub!</h2>



<p>There‚Äôs a button GitHub that says ‚Äúrebase and merge‚Äù that could theoretically be used for merging pull requests. I <em>never</em> use that (and if I could, I‚Äôd disable/hide it). The reasons are simply:</p>



<ol><li>I don‚Äôt feel that I have the proper control of the commit message(s)</li><li>I can‚Äôt select to squash a subset of the commits, only all or nothing</li><li>I often want to cleanup the author parts too before push, which the UI doesn‚Äôt allow</li></ol>



<p>The downside with not using the merge button is that the message in the  PR says ‚Äúclosed by [hash]‚Äù instead of ‚Äúmerged in‚Ä¶‚Äù which causes confusion to a fair amount of users who don‚Äôt realize it means that it actually means the same thing! I consider this is a (long-standing) GitHub UX flaw.</p>



<h2>Post merge</h2>



<p>If the branch has nothing to be kept around more, I delete the local branch again with ‚Äú<code>git branch -d [name]</code>‚Äù and I remove it remotely too since it was completely merged there‚Äôs no reason to keep the work version left.</p>



<p>At any given point in time, I have some 20-30 different local branches alive using this approach so things I work on over time all live in their own branches and also submissions from various people that haven‚Äôt been merged into master yet exist in branches of various maturity levels. Out of those local branches, the number of concurrent pull requests I have in progress can be somewhere between just a few up to ten, twelve something.</p>



<h2>RELEASE-NOTES</h2>



<p>Not strictly related, but in order to keep interested people informed about what‚Äôs happening in the tree, we sync the <a href="https://github.com/curl/curl/blob/master/RELEASE-NOTES">RELEASE-NOTES</a> file every once in a while. Maybe every 5-7 days or so. It ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/">https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/09/this-is-how-i-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043731</guid>
            <pubDate>Tue, 10 Nov 2020 08:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Event, 18th Nov: Building a Notion Website Live]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25043693">thread link</a>) | @saviorand
<br/>
November 9, 2020 | http://optemization.com/how-to-build-notion-website | <a href="https://web.archive.org/web/*/http://optemization.com/how-to-build-notion-website">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-how-to-build-notion-website"><div id="block-128d927961c546d8870b1a51a5579a93"><picture><source srcset="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/67b219ac-6de7-482c-b615-91d148315e54.png?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-d2269dc812f14b90932490290a797437"><span id="d2269dc812f14b90932490290a797437"></span><span><span>üñ•Ô∏è You can do websites on Notion?</span></span></h2><blockquote id="block-2d6de681f9a04563af1656151a4a72ac"><span><span>If you spend anytime on #productivity Twitter or r/Notion you know that building websites on Notion, is the new normal :)  Thanks to projects like Super and Fruition, Notion pages can turn into real websites, with custom domains, analytics, and styling!

My new teammate Valentine, just shared a </span><span><a target="_blank" rel="noopener noreferrer" href="https://optemization.com/notion-landing-page-guide">comprehensive guide</a></span><span> on how to build your own Notion website. 

However, this stuff is really visual, so we thought it'd be super fun to host an </span><span><strong>event where we conceptualize, design and ship a Notion website LIVE</strong></span><span>! 

So two things: RSVP below and tell us what kind of website do you want to build!</span></span></blockquote><h2 id="block-1b34e201f6484d4680c97fe88b965d4c"><span id="1b34e201f6484d4680c97fe88b965d4c"></span><span><span>üñãÔ∏è Sign Up</span></span></h2><h2 id="block-b67496c5fc8b4bdcb04d5891dc6baf0b"><span id="b67496c5fc8b4bdcb04d5891dc6baf0b"></span><span><span>üòÉ Are you excited?</span></span></h2><div id="block-c91d2a953127494f86a21d77c34339ea"><div id="block-f2134537e8d04052915c6399871b09eb"><blockquote id="block-7d5a84aa13624e43ba7e69fbac453dea"><span><span>Share the event on the ze twitter üôè</span></span></blockquote></div></div></article></div></div></div>]]>
            </description>
            <link>http://optemization.com/how-to-build-notion-website</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043693</guid>
            <pubDate>Tue, 10 Nov 2020 07:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020 Haskell Is Ready for Prime Time]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25043675">thread link</a>) | @_query
<br/>
November 9, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There‚Äôs been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it‚Äôs ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That‚Äôs how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It‚Äôs really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it‚Äôs highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it‚Äôs finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there‚Äôs now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it‚Äôs finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043675</guid>
            <pubDate>Tue, 10 Nov 2020 07:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why's (Poignant) Guide to Ruby (2004)]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 143 (<a href="https://news.ycombinator.com/item?id=25043544">thread link</a>) | @creolabs
<br/>
November 9, 2020 | https://poignant.guide/book/chapter-2.html | <a href="https://web.archive.org/web/*/https://poignant.guide/book/chapter-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<h2>1. Opening This Book</h2>

<p>Pretend that you‚Äôve opened this book (although you probably <em>have</em> opened this
book), just to find a huge onion right in the middle crease of the book. (The
manufacturer of the book has included the onion at my request.)</p>

<p>So you‚Äôre like, ‚ÄúWow, this book comes with an onion!‚Äù (Even if you don‚Äôt
particularly like onions, I‚Äôm sure you can appreciate the logistics of shipping
any sort of produce discreetly inside of an alleged programming manual.)</p>

<p>Then you ask yourself, ‚ÄúWait a minute. I thought this was a book on Ruby, the
incredible new programming language from Japan. And although I can appreciate
the logistics of shipping any sort of produce discreetly inside of an alleged
programming manual: Why an onion? What am I supposed to do with it?‚Äù</p>

<p>No. Please don‚Äôt puzzle over it. You don‚Äôt need to do anything with the onion.
Set the onion aside and let <em>it</em> do something with <em>you</em>.</p>

<p>I‚Äôll be straight with you. I want you to cry. To weep. To whimper sweetly. This
book is a <strong>poignant</strong> guide to Ruby. That means code so beautiful that tears
are shed. That means gallant tales and somber truths that have you waking up the
next morning in the arms of this book. Hugging it tightly to you all the day
long. If necessary, fashion a makeshift hip holster for <em>Why‚Äôs (Poignant) Guide
to Ruby</em>, so you can always have this book‚Äôs tender companionship.</p>

<p>You really must sob once. Or at least sniffle. And if not, then the onion will
make it all happen for you.</p>





<h2>2. The Dog Story</h2>

<p>So try this first bit of poignancy on for size:</p>

<p>One day I was walking down one of those busy roads covered with car dealerships
(this was shortly after my wedding was called off) and I found an orphaned dog
on the road. A woolly, black dog with greenish red eyes. I was kind of feeling
like an orphan myself, so I took a couple balloons that were tied to a pole at
the dealership and I relocated them to the dog‚Äôs collar. Then, I decided he
would be my dog. I named him Bigelow.</p>

<p>We set off to get some Milkbones for Bigelow and, afterwards, head over to my
place, where we could sit in recliners and listen to Gorky‚Äôs Zygotic Mynci. Oh,
and we‚Äôd also need to stop by a thrift store and get Bigelow his own recliner.</p>

<p>But Bigelow hadn‚Äôt accepted me as his master. So five minutes later, the stupid
dog took a different crosswalk than I did and I never caught up. So whereas he
had previously only been lost once, he was now lost twice. I slowed my pace
towards the life of Milkbones and an extra recliner. I had a dog for five
minutes.</p>

<p>Stupid Benedict Arnold of a dog. I sat on a city bench and threw pine cones at a
statue of three sheep crossing a bridge. After that, I wept for hours. The tears
just came. Now there‚Äôs a little something poignant to get you started.</p>

<p>I wonder where he went with all those balloons. That crazy dog must have looked
like a party with legs.</p>

<p>It wasn‚Äôt much later that I pulled my own Bigelow. I printed out a bunch of
pages on Ruby. Articles found around the Web. I scanned through them on a train
ride home one day. I flipped through them for five minutes and then gave up. Not
impressed.</p>

<p>I sat, staring out the window at the world, a life-sized blender mixing graffiti
and iron smelts before my eyes. <em>This world‚Äôs too big for such a a little
language</em>, I thought. <em>Poor little thing doesn‚Äôt stand a chance. Doesn‚Äôt have
legs to stand on. Doesn‚Äôt have arms to swim.</em></p>

<p>And yet, there I was. One little man on a flimsy little train (and I even still
had a baby tooth to lose at the time) out of billions of people living on a
floating blue rock. How can I knock Ruby? Who‚Äôs to say that I‚Äôm not going to
happen to choke on my cell phone and die later that evening. Why‚Äôs dead, Ruby
lives on.</p>

<p>The gravestone:</p>

<blockquote>
  <p>What‚Äôs in his trachea? Oh, look, a Nokia!</p>
</blockquote>

<p>Just my luck. Finally get to have a good, long sleep underground, only to be
constantly disturbed by <em>Pachelbel‚Äôs Canon</em> going off in my stomach.</p>



<h2>3. The Red Sun Rises</h2>

<p>So, now you‚Äôre wondering why I changed my mind about Ruby. The quick answer is:
we clicked.</p>

<p>Like when you meet Somebody in college and they look like somebody who used to
hit you in the face with paintbrushes when you were a kid. And so, impulsively,
you conclude that this new Somebody is likely a non-friend. You wince at their
hair. You hang up phones loudly during crucial moments in their anecdotes. You
use your pogo stick right there where they are trying to walk!</p>

<p>Six months later, somehow, you and Somebody are sitting at a fountain having a
perfectly good chat. Their face doesn‚Äôt look so much like that childhood
nemesis. You‚Äôve met the Good Twin. You clicked.</p>

<p>So whereas I should probably be pounding your teeth in with hype about Ruby and
the tightly-knit cadre of pertinent acronyms that accompany it everywhere
(whetting the collective whistles of your bosses and their bosses‚Äô bosses),
instead I will just let you coast. I‚Äôll let you free-fall through some code,
interjecting occasionally with my own heartfelt experiences. It‚Äôll be quite
easy, quite natural.</p>

<p>I should offer you some sort of motivation, though. So, Smotchkkiss, I‚Äôm going
to give my three best reasons to learn Ruby and be done with it.</p>

<ol>
  <li>
    <p><strong>Brain health.</strong></p>

    <p>Vitamin R. Goes straight to the head. Ruby will teach you to <em>express</em> your
ideas through a computer. You will be writing stories for a machine.</p>

    <p>Creative skills, people. Deduction. Reason. Nodding intelligently. The
language will become a tool for you to better connect your mind to the world.
I‚Äôve noticed that many experienced users of Ruby seem to be clear thinkers and
objective. (In contrast to: heavily biased and coarse.)</p>
  </li>
  <li>
    <p><strong>One man on one island.</strong></p>

    <p>Ruby was born in Japan. Which is freaky. Japan is not known for its
software. And since programming languages are largely written in English, who
would suspect a language to come from Japan?</p>

    <p>And yet, here we have Ruby. Against the odds, Yukihiro Matsumoto created
Ruby on February 24, 1993. For the past ten years, he has steadily brought Ruby
to a global audience. It‚Äôs triumphant and noble and all that. Support diversity.
Help us tilt the earth just a bit.</p>
  </li>
  <li>
    <p><strong>Free.</strong></p>

    <p>Using Ruby costs nothing. The code to Ruby itself is open for all of the
world to inhale/exhale. Heck, this book is free. It‚Äôs all part of a great, big
giveaway that should have some big hitch to it.</p>

    <p>You‚Äôd think we‚Äôd make you buy vacuums or timeshare or fake Monets. You‚Äôd
think there‚Äôd be a 90 minute presentation where the owner of the company comes
out at the end and knuckles you into sealing the deal.</p>

    <p>Nope, free.</p>
  </li>
</ol>

<p>With that, it‚Äôs time for the book to begin. You can now get out your highlighter
and start dragging it along each captivating word from this sentence on. I think
I have enough hairspray and funny money on my person to keep me sustained until
the final page.</p>



<h2>4. How Books Start</h2>

<p>Now, if you ever have read a book, you know that no book can properly start
without an exorbitant amount of synergy. Yes, synergy. Maybe you didn‚Äôt know
this. Synergy means that you and I are supposed to cooperate to make this a
great reading experience.</p>

<p>We start off the book by getting along well in the Introduction. This
togetherness, this <strong>synergy</strong>, propels us through the book, with me guiding you
on your way. You give me a reassuring nod or snicker to indicate your progress.</p>

<p>I‚Äôm Peter Pan holding your hand. Come on, Wendy! Second star to the right and on
till morning.</p>

<p>One problem here. I don‚Äôt get along well with people. I don‚Äôt hold hands very
well.</p>

<p>Any of my staff will tell you. At the Opening Ceremonies of This Book (a catered
event with stadium seating), I discovered that the cucumber sandwiches weren‚Äôt
served in tea towels. As a result, the butter hadn‚Äôt set with the cucumbers
right‚Ä¶ Anyways, I made a big scene and set fire to some of the advertising
trucks outside. I smashed this spotlight to pieces and so on. I had this loud
maniacal laughing thing going on deep into that night. It was a real mess.</p>

<p>But, since I don‚Äôt get along well with people, I hadn‚Äôt invited anyone but
myself to the Opening Ceremonies of This Book. So it wasn‚Äôt really that
embarrassing. I kept it under wraps and no one found out about the whole ordeal.</p>

<p>So you‚Äôve got to know that <strong>synergy</strong> doesn‚Äôt actually mean <strong>synergy</strong> in this
book. I can‚Äôt do normal <strong>synergy</strong>. No, in this book, <strong>synergy</strong> means
<strong>cartoon foxes</strong>. What I‚Äôm saying is: this book will be starting off with an
exorbitant amount of <strong>cartoon foxes</strong>.</p>

<p>And I will be counting on you to turn them into <strong>synergy</strong>.</p>


      <p>
      <a href="https://poignant.guide/book/chapter-3.html">Turn page.</a>
      </p>
    </div></div>]]>
            </description>
            <link>https://poignant.guide/book/chapter-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25043544</guid>
            <pubDate>Tue, 10 Nov 2020 07:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AppleCrate II: A New Apple II-Based Parallel Computer (2015)]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25042551">thread link</a>) | @aresant
<br/>
November 9, 2020 | http://michaeljmahon.com/AppleCrateII.html | <a href="https://web.archive.org/web/*/http://michaeljmahon.com/AppleCrateII.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<b><span face="Arial, helvetica" size="4"><p>AppleCrate II:  A New Apple II-Based Parallel Computer</p>
</span><span face="Arial, helvetica" size="2"><p>
Michael J. Mahon ‚Äì July 26, 2008<br>
Revised ‚Äì September 23, 2015</p>

<p><img src="http://michaeljmahon.com/CrateII.jpg" width="500" height="612"></p>

</span><span face="Arial, helvetica"><p>Introduction</p>
</span></b><span face="Arial, helvetica" size="2"><p>
In 2004 I built the first <a href="http://michaeljmahon.com/Applecrate.html">AppleCrate</a>, an 8-board system, as an inexpensive, easy to program
vehicle for experiments in parallel programming‚Äîa kind of "blade server" for the Apple II, if
you will!  AppleCrate I (at the time I didn't realize that it was number "I" ;-) was great fun, and it
enabled some very interesting experiments, but over time I discovered some of its shortcomings.</p>

<p>First and foremost, since the boards were supported by only two edges and not clamped in place, it
was relatively fragile and hard to transport.  Second, I had come across situations in which more
than 8 slave processors would have been useful.  Third, my arrangement for collecting audio signals
synthesized by the slaves was quite makeshift and delivered sound with lots of digital "hash"
as background noise.  And finally, the original AppleCrate made no provision for plugging I/O cards
into any of its boards, so it had to be hosted by a separate Apple II, adding to the problem of
transporting it for demonstrations.</p>

<p>The AppleCrate II is designed to be significantly improved in all of the areas that were
problems for the AppleCrate I.</p>

<b></b></span><b><span face="Arial, helvetica"><p>Description</p>
</span></b><span face="Arial, helvetica" size="2">

<p>The AppleCrate II is made from 17 Enhanced Apple //e main boards.  (Fifteen of these boards were
obtained in the same eBay auction that netted the eight unenhanced boards for the original AppleCrate.)
Because they are enhanced ROMs, the original NadaNet boot ROM code would not fit and a new
boot protocol had to be developed, as described below.</p>

<p>Instead of mounting the cards vertically in a frame, as in the original, I decided to mount them
horizontally in a stack secured with standoffs‚Äî3/4" long hexagonal rods, each with a screw protruding from
one end and a tapped hole in the other.  The AppleCrate II has nine "columns" of these standoffs‚Äîsix
metal columns at the back and corners of the boards and three nylon columns interior to the boards
to add stiffness, as shown in the photo below at the 2-board construction stage:</p>

<p><img src="http://michaeljmahon.com/TwoBoards.jpg" width="800" height="554"></p>

<p>This "hi-rise" construction makes the "stack" quite rigid and sturdy, while eliminating the need
for a space-consuming exoskeleton.  It also has the advantage of leaving the top board unobstructed
so that I/O cards can be plugged in, allowing it to serve as the host machine for the AppleCrate.  (In fact,
I used 17 boards so that the top board can serve as master and leave 16 slave machines for parallel
programs.)</p>

<p>The Pushbutton 1 input and Annunciator 1 output bus wires and the AN2-to-PB2 GETID daisy chain wires are connected to
machined-pin sockets inserted into the 16-pin game port connector.  These connections support <a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a>,
which is the only signal connection between the boards.  The network adapter (described below) is shown
with its mounting bracket under what will be the third board.  The power bus card is supported by a
similar angle bracket, and the standoffs immediately beneath them are filed down to accomodate the
bracket thickness.</p>

<p>The boards are powered by a PC AT power supply.  The average power consumed by an Apple //e
board is about 4.2 watts, so the whole 17-board crate consumes only about 70 watts in total,
and both the AppleCrate and the power supply run only a few degrees above ambient temperature.</p>

<p>I decided to use #12 copper bus wires
to distribute power to all boards (visible on the right side of the first photo).  I would have preferred
a connectorized approach, but I could not come up with a connector scheme with a
reasonable mating/unmating force.  As a result, I decided to go with soldered power connections.
(It's a good thing that Apple //e's are so reliable, since replacing one in the middle of the
stack would be relatively difficult!)</p>

<p>The top board is used as the "master" machine with I/O cards and an external keyboard plugged into it.
The Master boots the 16 slave Apples in the AppleCrate II and uses them to run parallel programs.
Once they have been booted and started, they can run independently of the master‚Äîthough they are clearly
I/O-constrained!</p>

<b></b></span><b><span face="Arial, helvetica"><p>Indicators</p>
</span></b><span face="Arial, helvetica" size="2">

<p>It has proven useful to have some real-time indication of each board's activity.  The stock board contains a
red "power" LED (at the right) and a red "speaker" LED at the left.  Both are easily visible from the back of the
boards (the "front" of the AppleCrate).  The function of the power LED is fixed, but the speaker LED is usable
as an indicator that software running on the board can operate, just by toggling the speaker.  For example,
printing a "beep"‚ÄîCHR$(07)‚Äîcauses the speaker LED to flash for 0.1 second, and can be used to indicate some
condition in the software.  (The speaker LED will not light when a speaker is installed, but AppleCrate
boards have no speakers attached.)</p>

<p>Although the Applecrate network interface described below incorporates an LED to show global network activity,
it is very useful to be able to see when any particular board is sending on the network.  This need is met by
using the PDL 3 timer to "stretch" each packet send operation into a visible flash of a green rectangular LED.</p>

<p><img src="http://michaeljmahon.com/SendLED.jpg" width="762" height="263"></p>

<p>These photos show the modification made to the 558 timer chip, in which a 267-ohm resistor (just what I
had handy‚Äîany value between 220 and 560 ohms is fine) is connected
between pins 5 and 8, and the "send" signalling LED is connected between pin 8 and ground, with pin 8 going to the
anode.  The rectangular LED is carefully pressed between the cassette input and output jacks.  On some boards,
the jacks were so close together that it was necessary to "shave" the upper plastic swage on the side of the input
jack with an Exacto knife to make room for the LED to press fit between them.  (Note that in these photos the red
wire connected to the anode of the LED has not yet been soldered.)</p>

</span><b><span face="Arial, helvetica"><p>Network Boot in NadaNet 3.x</p>
</span></b><span face="Arial, helvetica" size="2">

<p>Since AppleCrate machines have no I/O capabilities other than
the network, they must be booted from the network.  This requires that the ROMs on the boards be replaced with
EPROMs containing modified RESET code to perform the network boot.</p>

<p>As with the AppleCrate I, replacement of the self-test code was the easiest path, since it is self-contained,
contiguous, and is executed upon power-on reset if no keyboard is connected.  However, the Enhanced //e ROM contains
only $200 bytes of self-test code, just half the size of the unenhanced //e self-test, requiring a new
design for the network boot.</p>

<p>The AppleCrate I used an "active" boot protocol, in which each board enabled by the "GETID daisy chain" (connected from
AN2 of the previous machine to PB2 of the current machine) continuously sent GETID requests to ID 1, until it was assigned
a permanent ID and received a NadaNet boot image.  The complexity of this protocol, requiring both sending and receiving
packets over the network, resulted in a boot ROM requirement of almost $400 bytes‚Äîwhich fit in an <b>Unenhanced</b> //e ROM.</p>

<p>Since the <b>Enhanced</b> //e ROM has only $200 bytes available, a new "passive" boot protocol had to be devised.
The <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">new ROM code</a> continuously monitors the network for a broadcast BOOTREQ control packet
containing  the load address and length of the immediately following boot code data.  When the boot image has been correctly
read from the network, control is passed to its starting address.  This passive boot code only needs to <b>read</b> packets from the
net, and so occupies just $190 bytes, which comfortably fits in place of the Enhanced //e ROM self-test code at $C600.</p>

<p>The new boot protocol capitalizes on the fact that boot code is sent as a broadcast transaction, so the
machines being booted do not need IDs to receive boot code.  A page of "second-stage boot" code is added at the
front of the slave machine boot image.  This code is given control immediately after the boot image is received, and,
when enabled by the "GETID daisy chain", it sends a GETID request to the machine that &amp;BOOTed it, making use of the
code in the full NadaNet boot image to do so (see the BOOT2 code in the <a href="http://michaeljmahon.com/NADA.CRATE.pdf">NADA.CRATE</a>
listing for details).</p>

<p>The GETID daisy chain functions just as it did in the AppleCrate I.  The "first" machine is permanently enabled
by connecting its PB2 to ground.  AN2 of each machine is connected
to PB2 of the "next" machine.  The second-stage boot code running in each machine initially sets its AN2.
Then it waits until it sees its PB2 go low, enabling it to send its GETID request.  When its GETID is successful
it drops its AN2, enabling the next machine.  Then it clears its video display, writes a banner showing the
machine ID, and enters its server loop.</p>

<p>This results in permanent
IDs being assigned in the fixed order of the physical daisy chain, while allowing all ROMs to be identical.
An LED on the AppleCrate II NadaNet adapter board is wired to the last machine's AN2, so that when the last
machine drops its AN2, the red LED extinguishes, signalling that all machines have booted successfully.</p>

<p>When a network-booting machine is reset, it first checks the network state.  If the network is low (ZERO),
it performs a cold start.  If the network is being held high (ONE), it checks page 3 to see if it is being cold started or warm reset.  If it is
a warm reset, it re-enters its Server loop.  If it is a cold start, it initializes and enters the ROM boot code, again waiting
for a BOOTREQ packet.  (This approach has the advantage of reliably forcing a reboot on a power cycle, while
still permitting boards to be warm reset while holding the network high.)</p>

<p>As of NadaNet 3.1, all AppleCrate boot ROMs must be <a href="http://michaeljmahon.com/PASSIVEBOOT.ROM.pdf">NadaNet 3.x capable</a>.</p>

</span><b><span face="Arial, helvetica"><p>AppleCrate II NadaNet Interface</p>
</span></b><span face="Arial, helvetica" size="2">
<p><a href="http://michaeljmahon.com/NadaNet.html">NadaNet</a> is a TTL-level serial network in which logic high is represented by a voltage greater than +2 volts
and logic low is represented by a voltage less than +0.7 volts.  The fanout capability of a TTL annunciator output
is sufficient to  drive a dozen or so TTL pushbutton inputs if they are not otherwise ‚Ä¶</p></span></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://michaeljmahon.com/AppleCrateII.html">http://michaeljmahon.com/AppleCrateII.html</a></em></p>]]>
            </description>
            <link>http://michaeljmahon.com/AppleCrateII.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042551</guid>
            <pubDate>Tue, 10 Nov 2020 03:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Kills Cname Cloaking on iOS/iPadOS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25042374">thread link</a>) | @fenier
<br/>
November 9, 2020 | https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/ | <a href="https://web.archive.org/web/*/https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cunderwood.dev/2020/11/06/using-cnames-to-bypass-itp-has-been-put-to-torch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042374</guid>
            <pubDate>Tue, 10 Nov 2020 02:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networking for Introverts]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042288">thread link</a>) | @davefreiburger
<br/>
November 9, 2020 | https://gradually.co/how-to-network-as-an-introvert/ | <a href="https://web.archive.org/web/*/https://gradually.co/how-to-network-as-an-introvert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gradually.co/how-to-network-as-an-introvert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042288</guid>
            <pubDate>Tue, 10 Nov 2020 02:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1984 by George Orwell [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25042280">thread link</a>) | @bra-ket
<br/>
November 9, 2020 | https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf | <a href="https://web.archive.org/web/*/https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://snewd.com/wp-content/uploads/2020/01/1984-George-Orwell.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042280</guid>
            <pubDate>Tue, 10 Nov 2020 02:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Practices for Writing Clean Interfaces in Go]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25042085">thread link</a>) | @lanecwagner
<br/>
November 9, 2020 | https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://qvault.io/2020/03/15/best-practices-for-writing-clean-interfaces-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25042085</guid>
            <pubDate>Tue, 10 Nov 2020 01:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking an election fraud claim using open data and Dolt]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25041998">thread link</a>) | @proverbialbunny
<br/>
November 9, 2020 | https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-11-09-debunking-election-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041998</guid>
            <pubDate>Tue, 10 Nov 2020 01:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Try Design Thinking]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25041961">thread link</a>) | @gbasin
<br/>
November 9, 2020 | https://garybasin.com/try-design-thinking/ | <a href="https://web.archive.org/web/*/https://garybasin.com/try-design-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2081">
	<img width="362" height="410" src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C410&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-lazy-src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C410&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">	<div>
		<!-- .entry-header -->

		<div>
			
<p>It‚Äôs 9pm, you‚Äôre at your friend‚Äôs house, and the show you‚Äôre watching ends. You scramble to change the channel but you can‚Äôt figure out the remote. You stare at dozens of buttons with no clue where to start. <strong>Doesn‚Äôt it make you feel stupid?</strong> Some experimentation might get you somewhere, but it‚Äôs not easy. Why can‚Äôt you figure it out?</p>



<p>In these situations, we often blame ourselves. We‚Äôre not smart, patient, or capable enough. This conclusion is incorrect ‚è§ <strong>product design is the direct cause of the stress</strong>.</p>



<p>This realization won‚Äôt help you with your frustrating remote experience. However, it does emphasize the importance of user experience design. <strong>We can redesign experiences to create new feelings</strong>.</p>



<p>Next time you‚Äôre confronted with a bad user experience, <a href="https://twitter.com/garybasin/status/1324908038524899329">spend some time brainstorming better designs</a>. You never know where your experiments will take you.</p>



<div><figure><img loading="lazy" width="362" height="950" src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C950&amp;ssl=1" alt="" srcset="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?w=362&amp;ssl=1 362w, https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=114%2C300&amp;ssl=1 114w" sizes="(max-width: 362px) 100vw, 362px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?w=362&amp;ssl=1 362w, https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=114%2C300&amp;ssl=1 114w" data-lazy-src="https://i1.wp.com/garybasin.com/wp-content/uploads/2020/11/remote-1.png?resize=362%2C950&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>




					</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</div>

	
</article></div>]]>
            </description>
            <link>https://garybasin.com/try-design-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041961</guid>
            <pubDate>Tue, 10 Nov 2020 01:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing my phone battery with a cheap AliExpress knock-off]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25041894">thread link</a>) | @flotwig
<br/>
November 9, 2020 | https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html | <a href="https://web.archive.org/web/*/https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>This is a story of one man√¢‚Ç¨‚Ñ¢s quest for power.</p> <p>I purchased my current phone, a OnePlus 5T, in 2017. This summer, after about two and a half years of ownership, I noticed that it was no longer holding a charge all day. Frequently, the phone would reach 0% and shut off, right in the middle of tracking an evening bike ride or watching Netflix while cooking dinner. Although cell phone battery wear is a well-known issue, I got tired of it pretty quickly.</p> <p>I used the <a href="https://play.google.com/store/apps/details?id=com.digibites.accubattery&amp;hl=en_US&amp;gl=US">AccuBattery</a> app for about two months to try and get a handle on my battery health. It measured my phone√¢‚Ç¨‚Ñ¢s amperage draw during the day and used that to estimate that of the 3300 milliamp-hour (mAh) capacity that my battery originally offered, only about 2400 mAh of capacity remained - only about 75% of the battery√¢‚Ç¨‚Ñ¢s original health:</p> <p><img src="https://zach.bloomqu.ist/assets/battery/oem-capacity.png" alt="Screenshot of AccuBattery app for OEM battery capacity"></p> <p>This answered the question of √¢‚Ç¨≈ìwhy does it feel like my phone is shutting off so quickly?√¢‚Ç¨ÔøΩ pretty clearly. Now, it was up to me to get a replacement battery.</p> <h3 id="attempting-to-get-a-genuine-battery">Attempting to get a genuine battery</h3> <p>My first thought was that I could simply order the OEM OnePlus 5T battery somewhere online. Why not? I found a page on the OnePlus website where prices are listed for replacement parts. The USA page was down at the time of this writing, but the <a href="https://www.oneplus.in/support/pricing/detail?code=7">India support page</a> lists a OnePlus 5T OEM battery replacement as being about $15.</p> <p>This seemed acceptable to me. My first thought was to email OnePlus support asking how to purchase the battery. Unfortunately, according to the service rep, they do not ship or sell OEM batteries without service:</p> <blockquote> <p>We would like to inform you that we do not ship or sell the accessories in any parts of the world, and all the repairs are carried out by our Authorized service centers only. So if you wish to get the device repaired, you can send it to the OnePlus authorized service center and get the same repaired.</p> </blockquote> <p>This is in line with what other OnePlus customers have reported - nobody, as far as I can tell, has ever been able to source OEM batteries from OnePlus, leaving DIY customers like myself to try and find knock-offs elsewhere.</p> <p>I would√¢‚Ç¨‚Ñ¢ve sent my phone in for repairs, but after I received the above email, I had such a long and terrible customer support experience trying to arrange the repair that by the end of it, I no longer trusted OnePlus to reliably service and return my phone. This lack of trust was reinforced by horror stories from other OnePlus customers - one customer√¢‚Ç¨‚Ñ¢s phone was <a href="https://www.reddit.com/r/oneplus/comments/eleckw/sent_my_oneplus_5_to_fort_worth_tx_for_repair_no/">lost by the Fort Worth, TX service center</a>, another√¢‚Ç¨‚Ñ¢s was <a href="https://www.reddit.com/r/oneplus/comments/depgkg/oneplus_lost_my_coworkers_phone_during_repair_at/">lost and took 4 weeks before being returned</a>, and yet another customer had <a href="https://www.reddit.com/r/oneplus/comments/jke2kd/sent_my_op3t_for_a_battery_replacement_oneplus/">their phone held hostage unless they agreed to repairing EVERYTHING instead of just getting the battery replaced</a>. These stories, combined with my awful customer support experience, convinced me that sending my phone in would be a truly bad idea.</p> <h3 id="buying-an-aftermarket-battery">Buying an aftermarket battery</h3> <p>Many people on the /r/oneplus5t subreddit have recommended purchasing a <a href="https://www.ifixit.com/Store/Android/OnePlus-5-5T-Replacement-Battery/IF330-018?o=2">replacement battery from iFixit</a>, but I felt like iFixit was simply selling cheap Chinese batteries with a nice label on them. I mean, if OnePlus can fix it for $15, why does the iFixit battery cost $30, if not for marketing?</p> <p>So, I hit up eBay and AliExpress, and eventually found the [sic] √¢‚Ç¨≈ìSpecail Mobilephone Parts Store√¢‚Ç¨ÔøΩ, where they offer a <a href="https://web.archive.org/web/20201109223630/https://www.aliexpress.com/item/4000438352423.html">√¢‚Ç¨≈ì4650 mAh√¢‚Ç¨ÔøΩ √¢‚Ç¨≈ìPerfect business battery√¢‚Ç¨ÔøΩ</a> for the OnePlus 5T. With slogans like <a href="https://zach.bloomqu.ist/assets/battery/giant-energy-huge-capacity.webp">√¢‚Ç¨≈ìGiant energy; huge capacity√¢‚Ç¨ÔøΩ</a>, <a href="https://zach.bloomqu.ist/assets/battery/safety-does-not-explode.webp">√¢‚Ç¨≈ìSafety does not explode√¢‚Ç¨ÔøΩ</a>, and <a href="https://zach.bloomqu.ist/assets/battery/ensure-qualified-and-safe-to-use.webp">√¢‚Ç¨≈ìEnsure qualified and safe to use√¢‚Ç¨ÔøΩ</a>, I felt confident that my $11.87 was going to a good place. I placed the order and, about 3 weeks later, I received the battery in my mailbox.</p> <h3 id="battery-physics-101">Battery Physics 101</h3> <p><img src="https://zach.bloomqu.ist/assets/battery/oem-and-aftermarket.jpg" alt="Photo of the OEM battery and the aftermarket battery side-by-side"> <small>The OEM battery (left) and the aftermarket battery installed (right).</small></p> <p>The first thing I noticed about the replacement battery was that the capacity was even HIGHER than what I ordered. The OnePlus 5T OEM battery is rated at 3300 mAh capacity, the AliExpress product page advertised a battery with 4650 mAh capacity, and the label on the battery I received claimed an astounding <em>5350 mAh</em> capacity - 162% of the OEM capacity. Clearly, I had gotten a great deal!</p> <p>The second thing I noticed was that the aftermarket battery was significantly lighter than the OEM battery. So much lighter that I weighed the batteries out of curiosity. The OEM OnePlus 5T battery weighed 47.0g. The aftermarket OnePlus 5T battery weighed 38.7g, or about 17% less.</p> <p>It√¢‚Ç¨‚Ñ¢s amazing that Da Da Xiong was able to achieve 162% capacity with 17% less weight. Too amazing to be true, in fact.</p> <p>Via Wikipedia, I learned that the <a href="https://en.wikipedia.org/wiki/Specific_energy">specific energy</a> of a lithium-ion polymer battery can be up to <a href="https://en.wikipedia.org/wiki/Lithium-ion_battery">265 watt-hours per kilogram (Wh/kg)</a>. The nominal voltage of the lithium-ion polymer batteries here is about 3.8V. We can use <a href="https://en.wikipedia.org/wiki/Ohm%27s_law">Ohm√¢‚Ç¨‚Ñ¢s law</a> to calculate the maximum possible capacity of each battery based on weight, assuming that each battery is always supplying the nominal 3.8V.</p> <p>Let√¢‚Ç¨‚Ñ¢s start by calculating the maximum possible Amp-hours (Ah) per kilogram (kg) for a Li-ion poly battery at 3.8V, using Ohm√¢‚Ç¨‚Ñ¢s law:</p> <div><div><pre><code>265 Wh/kg / 3.8 V = 69 Ah/kg
</code></pre></div></div> <p>Now, we can calculate the maximum physically possible capacity for each battery by multiplying this number by the weights of each battery:</p> <div><div><pre><code>OEM battery:          .047 kg * 69 Ah/kg = 3.2 Ah = 3200 mAh
Aftermarket battery: .0387 kg * 69 Ah/kg = 2.6 Ah = 2600 mAh
</code></pre></div></div> <p>The astute reader might be wondering why this estimate for the maximum capacity of the OEM battery (3200 mAh) is less than the capacity OnePlus advertises (3300 mAh). Why is this? Well, it√¢‚Ç¨‚Ñ¢s because the assumption we made - that each battery is always supplying the nominal 3.8V - is false. The voltage output of a Li-ion poly battery <a href="https://learn.adafruit.com/li-ion-and-lipoly-batteries/voltages">drops over time</a>, so the calculation shown is only a lower bound approximation of each battery√¢‚Ç¨‚Ñ¢s maximum capacity.</p> <p>I don√¢‚Ç¨‚Ñ¢t have information about the exact chemical composition of these batteries, nor the voltage charts, nor do I know what the upper and lower voltage limits are on the OnePlus 5T charging circuit. However, if we estimate that the voltage drops from 3.8V to 3.0V in a linear fashion (<code>V = 3.8 - .8t, 0 &lt;= t &lt;= 1</code>), we can use integration to arrive at approximately 3600 mAh maximum capacity for the OEM battery and 2900 mAh maximum capacity for the aftermarket battery.</p> <p>Even without exact numbers, these calculations demonstrate that <em>something</em> is fishy about the Da Da Xiong battery√¢‚Ç¨‚Ñ¢s mAh claims.</p> <h3 id="real-world-usage">Real-world usage</h3> <p>Anyways, I didn√¢‚Ç¨‚Ñ¢t buy this shady AliExpress battery just so that I could do a bunch of math. I purchased it to restore my phone√¢‚Ç¨‚Ñ¢s ability to last all day, and it has definitely succeeded at that. From a qualitative perspective, I now have enough juice to keep my phone√¢‚Ç¨‚Ñ¢s battery fueled all day until I can recharge it at night.</p> <p>From a quantitative perspective, AccuBattery reports that the aftermarket battery has an estimated 3360 mAh capacity, which about matches the capacity of the OEM battery:</p> <p><img src="https://zach.bloomqu.ist/assets/battery/aftermarket-capacity.png" alt="Screenshot of AccuBattery app for aftermarket battery capacity"></p> <p>However, what AccuBattery fails to account for is the fact that once the aftermarket battery reaches 15%, the battery percentage begins to free-fall until it reaches 0% and shuts off. It seems like 15% on the aftermarket battery is equivalent to 1% on the OEM battery. I think this is because the Android OS cannot correctly estimate the battery√¢‚Ç¨‚Ñ¢s remaining charge because it has different voltage characteristics than the OEM battery, but it doesn√¢‚Ç¨‚Ñ¢t really bother me, I just have to make sure that to charge the phone at 15% instead of 1%. This seems to be an extremely common experience with DIY battery replacements - even folks using the iFixit battery run in to this issue.</p> <p>If we take 15% off of AccuBattery√¢‚Ç¨‚Ñ¢s estimated capacity, we get 2856 mAh, which is really really close to what a brand new OnePlus 5T reports - AccuBattery estimates the OEM battery as having ~3000 mAh capacity when it is brand new. That about matches my experience - with the Da Da Xiong battery, the phone is staying alive longer, almost like when it was new.</p> <h3 id="conclusions">Conclusions</h3> <ul> <li>Random Chinese batteries do not work as advertised - they will not magically double your phone√¢‚Ç¨‚Ñ¢s battery capacity.</li> <li>However, random Chinese batteries work <em>almost as well</em> as brand new OEM batteries, but your battery percentage will forever be miscalibrated.</li> <li>Never trust OnePlus customer service.</li> </ul> </div></div>]]>
            </description>
            <link>https://zach.bloomqu.ist/blog/2020/11/aftermarket-cell-phone-battery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25041894</guid>
            <pubDate>Tue, 10 Nov 2020 01:14:15 GMT</pubDate>
        </item>
    </channel>
</rss>
