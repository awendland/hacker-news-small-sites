<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 22 Sep 2020 12:30:48 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 22 Sep 2020 12:30:48 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Making Skeletonised Leaves]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24532709">thread link</a>) | @arbol
<br/>
September 20, 2020 | https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/ | <a href="https://web.archive.org/web/*/https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1332">

	

	
			<figure>
				<img width="992" height="1331" src="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=992" alt="" loading="lazy" srcset="https://adq454703481.files.wordpress.com/2020/09/dried.jpg 992w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=768 768w" sizes="(max-width: 992px) 100vw, 992px" data-attachment-id="1333" data-permalink="https://blog.lidskialf.net/dried/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried.jpg?w=763">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>I decided I wanted to try making some skeletonised leaves. So I did some Googling and decided to try <a href="https://penguinbaybiology.org/make-clear-leaf-view-vein-structure/">this</a> approach.</p>



<p>We went out in the evening and gathered some leaves from the local  Shrubbery. Totally not suspicious üôÇ</p>



<figure><img data-attachment-id="1343" data-permalink="https://blog.lidskialf.net/leaves/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203574&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;909&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="leaves" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/leaves.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>I bought some Sodium Hydroxide and a cheap steel pot from ebay. Note: it must <strong>not</strong> be Aluminium as the Sodium Hydroxide will react with Aluminium!</p>



<figure><img data-attachment-id="1336" data-permalink="https://blog.lidskialf.net/ingredients/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381793&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;543&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="ingredients" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/ingredients.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Although Sodium Hydroxide isn‚Äôt a deadly poison, you really don‚Äôt want it on your skin or in your eyes, so gloves/goggles are a necessity for safety. Hmm, I should really look into some sort of cheap lab coat as well to protect my clothes for this sorta stuff:</p>



<figure><img data-attachment-id="1339" data-permalink="https://blog.lidskialf.net/safety/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600381856&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;634&quot;,&quot;shutter_speed&quot;:&quot;0.03&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="safety" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/safety.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I scaled up the proportions to 1L of (Edinburgh) tap water and 30G of Sodium Hydroxide powder. I put them in the pot, brought it to the boil and added the leaves. </p>



<p>For fun I also tested the pH of the solution with my new pH paper (also from Ebay/China). Its about a 14, so pretty alkaline!</p>



<figure><img data-attachment-id="1340" data-permalink="https://blog.lidskialf.net/phpaper/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600203853&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;108&quot;,&quot;shutter_speed&quot;:&quot;0.04001&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="phpaper" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/phpaper.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>The instructions suggested boiling for about two hours, but it appears to depend on the leaves you choose. I checked on it every 20 minutes or so, and pulled leaves out as they became ready. </p>



<p>To process them, I had the following set up next to the pot:</p>



<ul><li>Tray 1: Plain tap water to wash off the Sodium Hydroxide.</li><li>Tray 2: Some ‚ÄúOrdinary Household Bleach‚Äù (aka Sodium Hypochlorite) to bleach any remaining colour out.</li><li>Tray 3: More plain tap water to wash off the bleach.</li><li>A sheet of alumunium foil to put the leaves on to dry out.</li></ul>



<p>After all of them were processed, I ended up with this:</p>



<figure><img data-attachment-id="1345" data-permalink="https://blog.lidskialf.net/drying/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg" data-orig-size="1331,998" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600212131&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;104&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="drying" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300" data-large-file="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=900" src="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=1024 1024w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=150 150w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=300 300w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/drying.jpg 1331w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The next morning I was able to unpeel the more robust leaves, yielding me these:</p>



<figure><img data-attachment-id="1346" data-permalink="https://blog.lidskialf.net/dried-1/" data-orig-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg" data-orig-size="992,1331" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1600352312&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;211&quot;,&quot;shutter_speed&quot;:&quot;0.010013&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dried-1" data-image-description="" data-medium-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224" data-large-file="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" src="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763" alt="" srcset="https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=763 763w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=112 112w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=224 224w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg?w=768 768w, https://adq454703481.files.wordpress.com/2020/09/dried-1.jpg 992w" sizes="(max-width: 763px) 100vw, 763px"></figure>



<p>Observations</p>



<ul><li>You need to use <em>robust</em> leaves from trees. I tried some nettle leaves, but they quickly turned to mush. Some of the tree leaves appeared to process fine, but turned out to be way too delicate to remove from the foil after drying: definitely depends on the species. There may be a better way to dry them, will think on it.</li><li>Only process one species of leaf at a time, otherwise you constantly have to check each one in the pot, which means you‚Äôre disturbing them more to check.</li><li>Make sure to check on the water level! I <em>almost</em> boiled it dry.</li><li>Its fiddly! During processing, you have to <em>carefully</em> unroll the leaves by hand while wearing gloves to get them flat prior to drying.</li><li>I tried processing a dried up Oak leaf since theoretically it should be closer to being skeletonised: it didn‚Äôt seem to work very well (you can see the unsuccessful result on the aluminium foil photo).</li></ul>



<p>What Next?</p>



<p>They‚Äôre definitely more robust than I expected, but they‚Äôre still quite delicate. I fancy trying dying them and embedding them into some transparent resin next.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.lidskialf.net/2020/09/17/making-skeletonised-leaves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532709</guid>
            <pubDate>Sun, 20 Sep 2020 08:35:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is macOS under the biggest malware attack ever?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24532184">thread link</a>) | @todsacerdoti
<br/>
September 19, 2020 | https://reverse.put.as/2020/09/17/evilquest-revisited/ | <a href="https://web.archive.org/web/*/https://reverse.put.as/2020/09/17/evilquest-revisited/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p>No. I just clickbaited you but don‚Äôt leave yet, keep reading for something fun!</p>
<p>A couple of days ago I found something curious on <a href="https://www.virustotal.com/gui/">VirusTotal</a>. There were more than 40 thousand binaries with the same size in a single day. That seemed very odd so I loaded two random binaries and compared their contents. The only difference was on strings section.</p>
<p>VirusTotal detections were very low (two to three) and identified the samples as EvilQuest/ThiefQuest malware.</p>
<p>To prove that all the binaries were the same except for strings, I wrote a quick <a href="https://github.com/gdbinit/evilquest_stats">Mach-O stats</a> utility in <a href="https://golang.org/">Go</a> (yes, 2020 is this crazy!) to hash the code and strings sections separately. The hypothesis is that the code section would have the same hash for all the samples, and the strings section would have a unique hash for each sample. The output confirmed that this was indeed the case - same code, different strings.</p>
<p>Running this program against 206091 binaries totalling 34GB of data:</p>
<div><pre><code data-lang="bash">Mach-O Stats
<span>(</span>c<span>)</span> <span>2020</span> Pedro Vilaca. All Rights Reserved
 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| <span>(</span>206091/206091, <span>1563</span> it/s<span>)</span> <span>[</span>2m11s:0s<span>]</span>
__text map
cd87dfd659fc2334ccc59093c1f41ba9abf4c88046d438ddd8bc2d82f55859d7 <span>206091</span>
</code></pre></div><p>Given that the strings are encrypted/obfuscated, my first idea was that this could be a new version with mutated versions being used in different sources. Doesn‚Äôt make that much sense given that the code was the same but given that EvilQuest has ransomware features, this could be for example different BitCoin wallets for each sample.</p>
<p>Now it was time to load one of the samples into a disassembler and give a look at its contents. Assuming that the VirusTotal detections were correct even if too low, I grabbed the <a href="https://objective-see.com/downloads/malware/EvilOSX.zip">known sample</a> of EvilQuest. This sample contains debugging symbols so it‚Äôs very easy to navigate since most function names are explicit about their intents. The new sample fixed that mistake and had that information removed.</p>
<p>Before bringing the heavy diffing guns such as <a href="https://www.zynamics.com/software.html">BinDiff</a> and <a href="http://diaphora.re/">Diaphora</a> I like to give a look around to feel what‚Äôs going on. In this case the code had differences but was very similar. I could see what were clearly obfuscated/encrypted strings like in the original sample. So, I tried to find those functions using the symbols from the first sample. That was fast and easy and confirmed that the code was related (either from the same author or someone reusing it - attribution is hard :P).</p>
<p>Scott Knight released a <a href="https://github.com/carbonblack/tau-tools/tree/master/malware_specific/ThiefQuest">script</a> to decrypt/encrypt the original samples strings, but it doesn‚Äôt work with the new samples. It makes sense given that there are keys and tables that could have changed, and also what appears to be a new type of obfuscated/encrypted string format.</p>
<div><pre><code data-lang="plaintext">000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053
</code></pre></div><p>The new strings type appears to always starts with <strong>000Bg{</strong>.</p>
<p>Learning a new programming language is easier when you have things to do with it, so I decided to write a <a href="https://github.com/gdbinit/evilquest_deobfuscator">decrypter/deobfuscator</a> in Go. In hindsight it wasn‚Äôt a smart decision because it‚Äôs kind of ugly to deal with buffers in Go and much easier in C (or I don‚Äôt know yet the best way to do it in Go).</p>
<div><pre><code data-lang="bash">$ ./evilquest_deobfuscator -s <span>"000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053"</span>
EvilQuest String Deobfuscator
<span>(</span>c<span>)</span> <span>2020</span> Pedro Vilaca. All Rights Reserved
000Bg<span>{</span>0000090nQ4XL1qPsnl1ZjpKX0lkFoa0000053 -&gt; rb+
</code></pre></div><p>Meanwhile, the next day there were again more than 40 thousand new samples with the same size. Confirmed again that the only difference was in strings. While reversing and writing the strings decrypter I noticed that the hash of the sample I was using was modified. That generated a brain click and I went to bed thinking that this wasn‚Äôt a big malware campaign (very sad!) because it didn‚Äôt make sense with so many samples but it could be a VirusTotal issue. VirusTotal sandbox just got trapped into an analysis loop. This idea was reinforced by the fact that the sample had been submitted from the <strong>ZZ</strong> country code, meaning unknown origin. Connecting these two ideas reinforced my belief that this was the right path.</p>
<p>After I finished the <a href="https://github.com/gdbinit/evilquest_deobfuscator">strings decrypter</a> I could verify that my unique samples campaign hypothesis wasn‚Äôt valid. The strings were all the same, just encrypted/obfuscated with different keys.</p>
<p>So, the next step was to verify the code to see what was happening there. This was very easy to find since it‚Äôs the first thing the sample does.</p>
<p>At the entrypoint we can observe the mutation function being called first with <code>argv[0]</code> as its argument.</p>
<div><pre><code data-lang="plaintext">000000010001A8D0         public start
000000010001A8D0 start   proc near
(...)
000000010001A8D0         push    rbp
000000010001A8D1         mov     rbp, rsp
000000010001A8D4         sub     rsp, 2F0h
000000010001A8DB         mov     rax, cs:___stack_chk_guard_ptr
000000010001A8E2         mov     rax, [rax]
000000010001A8E5         mov     [rbp+var_8], rax
000000010001A8E9         mov     [rbp+var_94], 0
000000010001A8F3         mov     [rbp+var_98], edi
000000010001A8F9         mov     [rbp+var_A0], rsi
000000010001A900         mov     rax, [rbp+var_A0]
000000010001A907         mov     rdi, [rax]      ; argv[0]
000000010001A90A         call    fg_open_and_reencrypt_cstrings ; binary self modifies here
(...)
</code></pre></div><p>Next follows opening the executable itself with <code>rb+</code> mode (reading and writing). Fun enough there is a memory leak because the decrypted string buffer is malloc‚Äôed in the decryptor function. One of the differences from this sample versus the previous is the increased usage of dynamically allocated memory, increasing the potential for memory leaks. There are a lot more memory leaks all over the code. Xcode Instruments has a nice leak detector (<em>hint, hint</em>).</p>
<div><pre><code data-lang="plaintext">000000010001A840 fg_open_and_reencrypt_cstrings proc near
000000010001A840                                         ; CODE XREF: start+3A‚Üìp
000000010001A840
000000010001A840 var_24          = dword ptr -24h
000000010001A840 __filename      = qword ptr -20h
000000010001A840 FILE_pointer    = qword ptr -18h
000000010001A840 var_10          = qword ptr -10h
000000010001A840 var_4           = dword ptr -4
000000010001A840
000000010001A840         push    rbp
000000010001A841         mov     rbp, rsp
000000010001A844         sub     rsp, 30h
000000010001A848         mov     [rbp+var_10], rdi
000000010001A84C         mov     rdi, [rbp+var_10]
000000010001A850         lea     rax, a000bg0000090nq_18 ; "000Bg{0000090nQ4XL1qPsnl1ZjpKX0lkFoa000"...
000000010001A857         mov     [rbp+__filename], rdi
000000010001A85B         mov     rdi, rax
000000010001A85E         call    fg_decrypt_0000Bg_string ; decrypt/decode string
000000010001A863         mov     rdi, [rbp+__filename]
000000010001A867         mov     rsi, rax  ; "rb+"
000000010001A867                           ; memleak here since the returned ptr was calloc'ed
000000010001A86A         call    _fopen
000000010001A86F         mov     [rbp+FILE_pointer], rax
000000010001A873         cmp     [rbp+FILE_pointer], 0
000000010001A878         jz      loc_10001A890
000000010001A87E         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A882         call    _ftrylockfile
000000010001A887         cmp     eax, 0
000000010001A88A         jz      loc_10001A89C
000000010001A890
000000010001A890 loc_10001A890:            ; CODE XREF: fg_open_and_reencrypt_cstrings+38‚Üëj
000000010001A890         mov     [rbp+var_4], 0FFFFFFFFh
000000010001A897         jmp     loc_10001A8C1
000000010001A89C ; ---------------------------------------------------------------------------
000000010001A89C
000000010001A89C loc_10001A89C:            ; CODE XREF: fg_open_and_reencrypt_cstrings+4A‚Üëj
000000010001A89C         mov     rdi, [rbp+FILE_pointer] ; FILE* handle
000000010001A8A0         call    fg_reencrypt_cstrings
000000010001A8A5         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A8A9         call    _funlockfile
000000010001A8AE         mov     rdi, [rbp+FILE_pointer] ; FILE *
000000010001A8B2         call    _fclose
000000010001A8B7         mov     [rbp+var_4], 0
000000010001A8BE         mov     [rbp+var_24], eax
000000010001A8C1
000000010001A8C1 loc_10001A8C1:            ; CODE XREF: fg_open_and_reencrypt_cstrings+57‚Üëj
000000010001A8C1         mov     eax, [rbp+var_4]
000000010001A8C4         add     rsp, 30h
000000010001A8C8         pop     rbp
000000010001A8C9         retn
000000010001A8C9 fg_open_and_reencrypt_cstrings endp
</code></pre></div><p>The <code>fg_reencrypt_cstrings</code> function is previous listing is where the mutation occurs.
The function will find the <code>__cstring</code> section and iterate over its contents, decrypting and encrypting the strings, and write back to the binary. The original binary is already modified when it returns from <code>fg_open_and_reencrypt_cstrings</code> .</p>
<div><pre><code data-lang="c">(...)
<span>for</span> ( j <span>=</span> <span>0</span>; j <span>&lt;</span> sg<span>-&gt;</span>nsects; <span>++</span>j ) {
    v12 <span>=</span> (<span>__int64</span>)sub_100006580(a1, v17, <span>80LL</span>);
    <span>// obfuscated string is "__cstring"
</span><span></span>    v2 <span>=</span> fg_decrypt_0000Bg_string(<span>"000Bg{00000H0nQ4XL1qPsnl3oBkir1CDCUq3Z{iy|22B2MZ0000073"</span>);
    <span>if</span> ( <span>!</span>strcmp((<span>const</span> <span>char</span> <span>*</span>)v12, v2) ) {
        v11 <span>=</span> (<span>__int64</span>)sub_100006580(a1, <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>*</span>(_QWORD <span>*</span>)(v12 <span>+</span> <span>40</span>));
        v10 <span>=</span> <span>0LL</span>;
        v9 <span>=</span> <span>0LL</span>;
        v8 <span>=</span> <span>0</span>;
        fseek(a1, <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>0</span>);
        <span>while</span> ( (<span>unsigned</span> <span>__int64</span>)v8 <span>&lt;</span> <span>*</span>(_QWORD <span>*</span>)(v12 <span>+</span> <span>40</span>) ) {
            <span>if</span> ( <span>*</span>(_BYTE <span>*</span>)(v11 <span>+</span> v8) ) {
                <span>++</span>v9;
            }
            <span>else</span> <span>if</span> ( v9 ) {
                v7 <span>=</span> (<span>char</span> <span>*</span>)calloc(<span>1uLL</span>, v9 <span>+</span> <span>1</span>);
                __memcpy_chk(v7, v10 <span>+</span> v11, v9, <span>-</span><span>1LL</span>);
                v6 <span>=</span> fg_decrypt_0000Bg_string(v7);
                __s <span>=</span> (<span>char</span> <span>*</span>)fg_encrypt_0000Bg_string(v6);
                <span>if</span> ( v7 <span>!=</span> v6 ) {
                    v3 <span>=</span> strlen(__s);
                    <span>if</span> ( v3 <span>==</span> strlen(v7) ) {
                        fseek(a1, v10 <span>+</span> <span>*</span>(<span>unsigned</span> <span>int</span> <span>*</span>)(v12 <span>+</span> <span>48</span>), <span>0</span>);
                        fwrite(__s, <span>1uLL</span>, v9, a1);
                        free(v6);
                    }
                }
                free(v7);
                free(__s);
                v10 <span>+=</span> v9 <span>+</span> <span>1</span>;
                v9 <span>=</span> <span>0LL</span>;
            }
            <span>else</span> {
           ‚Ä¶</code></pre></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reverse.put.as/2020/09/17/evilquest-revisited/">https://reverse.put.as/2020/09/17/evilquest-revisited/</a></em></p>]]>
            </description>
            <link>https://reverse.put.as/2020/09/17/evilquest-revisited/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24532184</guid>
            <pubDate>Sun, 20 Sep 2020 06:02:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startups are a complex multivariable equation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24531852">thread link</a>) | @grwthckrmstr
<br/>
September 19, 2020 | https://www.preetamnath.com/blog/startups-multivariable-equation | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/startups-multivariable-equation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Launching a startup and building it into a successful business requires a multidisciplinary skillset. Because startups are a complex <a href="https://en.wikipedia.org/wiki/Multivariable_calculus" target="_blank">multivariable equation</a>.</p><p>You have moving target, which is somewhat in sight but not really. You‚Äôre wearing glasses but objects at a great distance are blurry.&nbsp;</p><p>The multivariable equation looks something like this</p><ul role="list"><li>understanding the market and finding a gap</li><li>coming up with a product thesis to solve the customer‚Äôs needs</li><li>finding the right distribution channels that are profitable</li><li>discovering pockets of places to find the initial set of customers</li><li>positioning the solution with the right messaging</li><li>creating the right business model and pricing structure</li><li>building competitive differentiation to fight off competition</li><li>having a founding team that has the right skillset for all the problems listed above and the million others that aren‚Äôt</li></ul><figure id="w-node-2bc32fdcbb34-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f66be2bf4382616b86f3dba_startup%20complex%20multivariable%20equation%20photo.jpg" loading="lazy" alt=""></p><figcaption><em>Photo by </em><a href="https://unsplash.com/@barkiple?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank"><em>John Barkiple</em></a></figcaption></figure><p>There‚Äôs a million reasons a startup might fail. And you cannot control those million factors of chaos.</p><p>But you can piece together parts of this equation (via discovery) and solve them one by one. Solving a piece of the equation reduces your chances of crash and burn, i.e. increases your chances of success.</p><p>The factors I‚Äôve listed above are some of the more well understood parts of this equation, and ones that you can actually control and influence.</p><p>However, it doesn‚Äôt matter if you get only solve a few parts of the equation, because one or two wrong answers such as distribution channels or business model might be enough to kill your business. That‚Äôs what runway (frugality, burn rate, funding, customer revenue) is for.</p><p>Even if you get all the above factors right, it takes a lot of time and effort for your business to take off, to build up momentum and achieve <a href="https://www.preetamnath.com/blog/momentum-escape-velocity" target="_blank">escape velocity</a>.</p><p>It boils down to - Can you solve your startup's multivariable equation before you run out of runway?</p><figure id="w-node-c061837fdebd-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f66c1f176b8944f5e9c79f3_startup%20runway.jpg" loading="lazy" alt=""></p><figcaption><em>Photo by </em><a href="https://unsplash.com/@jmoncasi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank"><em>Jordi Moncasi</em></a><a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"></a></figcaption></figure><p>This is why a lot of successful businesses don‚Äôt do something entirely new and from the ground up. They take something existing and working and improve parts of the equation. </p><p>Zoom took WebEx and made the product delightfully easy to use.</p><p>And similarly, a lot of businesses are copycats. They copy something existing and improve upon it slightly and meaningfully. One can argue that <a href="https://invertedpassion.com/copying-ideas-is-highly-underrated/" target="_blank">copying ideas</a> is highly underrated. </p><p>Instagram Stories is basically Snapchat‚Äôs innovation, but they won because the distribution piece of the equation was far ahead.</p><p>Zoom and Instagram simply picked a multivariable equation where some of the unknowns were already solved for.</p></div></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/startups-multivariable-equation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531852</guid>
            <pubDate>Sun, 20 Sep 2020 04:15:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Era of Regulatory Grift: TikTok-Oracle, NXP-Qualcomm, Arm-Nvidia]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531657">thread link</a>) | @ceohockey60
<br/>
September 19, 2020 | https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>The dictionary definition of the word ‚Äúgrift‚Äù is as follows: ‚Äú<a href="https://www.merriam-webster.com/dictionary/grift">to acquire money or property illicitly</a>‚Äù. It may be a strong word, but also more or less encapsulates the regulatory ethos that‚Äôs governing cross-border technology businesses these days.</p><p>The TikTok-Oracle deal flaunts this grifting ethos, but it‚Äôs just the latest example of a series of haphazard regulatory actions mired in geopolitical brinkmanship -- a trend that may implicate deals with much larger impact, like the pending Nvidia acquisition of Arm.</p><h2 id="tiktok-oracle">TikTok-Oracle</h2><p>There are still many missing details to the TikTok-Oracle deal, and Trump <a href="https://uk.reuters.com/article/us-usa-tiktok-oracle/trump-raises-questions-about-tiktok-oracle-deal-if-bytedance-ties-remain-idUKKBN2672KD">may not approve the deal</a>. But in the grand scheme of things, many of these details are no longer important, because the spirit of the entire TikTok ‚Äúsoap opera‚Äù is cemented: a <strong>regulatory grift </strong>by the Trump administration that enriches its political donor (Larry Ellison), strengthens its campaign message (anti-China, job creation), while doing next to nothing to protect Americans from either intrusive data collection or foreign influence.</p><p>Let‚Äôs look at each of these malfeasances.</p><p><strong><em>What Oracle gets.</em></strong> TikTok‚Äôs immediate business value accrues to Oracle Cloud to the tune of possibly <a href="https://www.theinformation.com/articles/with-tiktok-deal-oracle-could-gain-billion-dollar-cloud-customer?utm_content=article-4850&amp;utm_campaign=article_email&amp;utm_source=sg&amp;utm_medium=email">$1 billion in annual revenue</a> in the coming years, as it desperately tries to catch up to AWS and Azure. The Oracle brand may also get a boost from this young, cool consumer product, even though Oracle has no experience running such a product. Since I‚Äôve written in detail about TikTok‚Äôs business value in ‚Äú<a href="https://interconnected.blog/what-is-tiktok-worth-to-whom-and-why/"><strong>What is TikTok Worth to Whom and Why?</strong></a>‚Äù, I won‚Äôt repeat myself here. <strong>One element I did not discuss so explicitly is how valuable TikTok‚Äôs user data is to the Oracle data broker business.</strong></p><p>In a nutshell, a data broker sells data to third parties mostly for marketing or advertisement purposes. Oracle‚Äôs data broker businesses are euphemistically called <a href="https://www.oracle.com/cx/marketing/">Oracle CX Marketing</a> and <a href="https://www.oracle.com/data-cloud/">Oracle Data Cloud</a>. Having the treasure trove of data that TikTok has already collected is perhaps an even more immediate business boost to Oracle than getting the product‚Äôs workload onto its cloud. Ironically (or perhaps appropriately), the person who called out the privacy violations of data brokers like Oracle, Equifax, and others is <a href="https://www.linkedin.com/in/michael-beckerman-9b750a58/"><strong>Michael Berkerman</strong></a><strong>, who is currently TikTok US‚Äôs Head of Public Policy</strong>. He did so last year as the then President and CEO of the Internet Association in <a href="https://www.foxnews.com/opinion/michael-beckerman-why-do-we-need-a-federal-privacy-law-ask-the-data-brokers-selling-your-private-information">an OpEd published on Fox News</a> -- a ‚Äúmedia‚Äù outlet that the President of the United States most certainly pays attention to. I wonder how long Berkerman will be sticking around, if at all, after the TikTok-Oracle deal closes.</p><p>Lastly, Oracle will likely get a <a href="https://www.ft.com/content/58eb7c26-2154-477f-af19-19157ae29261">minority stake in TikTok</a> with ByteDance still being the majority shareholder. This piece of equity in one of the most valuable private tech companies in the world -- trading at a $140 billion valuation in the secondary market earlier this year -- is something that Oracle would have no business getting in a normal investing situation. Not a bad deal <a href="https://www.businessinsider.com/oracle-billionaire-larry-ellison-is-fundraising-for-donald-trump-2020-2">for hosting a single fundraiser</a>.</p><p><strong><em>What the Trump campaign gets.</em> </strong>Being more ‚Äúanti-China‚Äù than Biden and going after the Vice President‚Äôs son‚Äôs business dealings in China has been a messaging tentpole of the Trump re-election campaign. It can now claim credit for acting tough and forcing a marquee Chinese tech company to ‚Äúsurrender‚Äù its crown jewel product to America, while accomplishing none of those things, because TikTok‚Äôs core technology is staying with ByteDance in China.</p><p>The Oracle bid also apparently includes a ‚Äú<strong>20,000 new jobs‚Äù </strong>commitment -- a typical public relations promise with no legally binding effect. Being ‚Äúanti‚Äù-China while ‚Äúcreating‚Äù jobs is a strong one-two punch as we approach the final stretch of the 2020 election season, so much so that Secretary Mnuchin couldn't wait to sell the 20,000 jobs message on CNBC the day after Oracle‚Äôs winning bid was made public, <em>even though</em> the deal hasn‚Äôt been approved or finalized yet.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/ZPRPswu2Cyc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>TikTok US‚Äôs current payroll is about 1,400 people. <strong>That would be an almost 20x increase in headcount.</strong> Theoretically possible? Sure. Practical and sensible? Hardly.</p><p><em><strong>What the American people get.</strong> </em>Nothing, except that they still get to watch cool dance videos and <a href="https://www.tiktok.com/@rosssmith/video/6797540353730743557">grandmas do this</a> on their phones. We have no new information or answer to any of the three legitimate concerns surrounding TikTok:</p><ul><li>Does it send data to China?</li><li>Is its user data collection practices proper?</li><li>Is it being used as a tool for foreign influence?</li></ul><p>To be clear, there <em>are</em> regulatory tools based on technology at our disposal to answer these questions, <strong>with or without Oracle</strong>. I‚Äôve laid them out in detail in ‚Äú<a href="https://interconnected.blog/a-framework-to-dis-trust-and-verify-tiktok/"><strong>A Framework to (Dis)trust and Verify TikTok</strong></a>‚Äù. Unfortunately, it‚Äôs clear as day that the Trump administration is only interested in the political messaging benefits of TikTok-Oracle, not doing the actual work that is required to protect the interests of the American people.</p><p><strong>There is another winner that we should all take note of: <em>Chinese regulators.</em></strong></p><p>Chinese regulators typically use their power to force technology and IP transfers from foreign entities to domestic companies via joint-ventures or outright acquisitions -- <strong>another form of regulatory grift</strong>. This TikTok-Oracle deal is the first time to my knowledge, where Chinese regulators use their power to protect a home-grown technology from being <em>transferred out</em> to a foreign entity.</p><p>This win has just as much to do with exerting their regulatory power as the sucker on the other side of the negotiation table. This dynamic isn‚Äôt new, if we look at the failed NXP-Qualcomm acquisition in 2018.</p><h2 id="nxp-qualcomm">NXP-Qualcomm</h2><p>Qualcomm‚Äôs attempt to buy the Dutch semiconductor maker, NXP, for $44 billion was abandoned, because it could not get approval from Chinese regulators. This occurred during the previous height of tension when the U.S. and China were tossing retaliatory trade tariffs at each other like a couple of teenage boys in a backyard snowball fight.</p><p>The Chinese regulators did not disapprove of the deal and asked for changes to gain approval, which would‚Äôve been a good faith move. <strong>They just ignored it and let the deadline pass.</strong> This is after Secretary Mnuchin and his Commerce Department counterpart, Wilbur Ross, lobbied the Chinese Vice Minister, Liu He, and Ambassador to the US, Cui Tiankai, to approve the deal. The backdrop of this lobbying was Trump easing the penalties on the Chinese telecom equipment maker, ZTE, for violating U.S. sanction rules with regard to Iran and North Korea -- hoping for some reciprocity and dealmaking.</p><p>This foolish hope did not pan out. Instead, Qualcomm, America‚Äôs national champion in the race to 5G, had to fork up a <a href="https://www.wsj.com/articles/qualcomm-plans-to-abandon-nxp-deal-1532549728">$2 billion cancellation fee to NXP and increase its stock buyback program from $10 to $30 billion</a> to appease its shareholders. What‚Äôs more, this turn of events showed Chinese regulators that given the <strong>interconnected nature of the global economy</strong>, particularly technology businesses, they have far-reaching authority and leverage to shape deals, events, and technology acquisition vis-a-vis <strong>a tough-talking, weak-acting </strong>Trump administration. It is a key reversal in fortune, when a large swath of China‚Äôs technology sector, particularly Huawei, has been hammered by U.S. sanctions.</p><p>Qualcomm-NXP was a defensive play -- not approving a deal. TikTok-Oracle is a proactive play -- not losing control of domestic technology. <strong>There‚Äôs now an opportunity for even more aggressive ‚Äúregulatory grift‚Äù: Arm-Nvidia.</strong></p><h2 id="arm-nvidia">Arm-Nvidia</h2><p>It‚Äôs hard to comprehend the long-term impact that Nvidia‚Äôs $40 billion acquisition of Arm will have on the future of technology. One thing is certain though: it‚Äôs way more important than TikTok and Oracle, separately and combined.</p><p>We shouldn‚Äôt assume the Arm-Nvidia deal will be closed as expected given all the corporate governance issues with Arm‚Äôs China operation. Arm China‚Äôs CEO, Allen Wu, has been fired by the board for various acts of conflicts of interest and double dealing, <a href="https://www.zdnet.com/article/arms-fired-china-jv-head-refuses-to-leave-company-reps-banned-from-company-premises/">yet refuses to leave</a>. Arm‚Äôs CEO, Simon Segars, is trying to assure the public that the mess <a href="https://www.yicaiglobal.com/news/chip-designer-arm-to-solve-chinese-jv-management-issue-before-nvidia-buyout">will be cleaned up </a>in order to not endanger the sale, but he‚Äôs not in a position of leverage, now that the deal is public and the expectations are high. (Nvidia‚Äôs market cap increased by $17.5 billion the day after the deal was announced.)</p><p>Furthermore, the Arm China division is a joint-venture where 51% of the entity is owned by a consortium of these three funds:</p><ul><li><a href="https://en.wikipedia.org/wiki/China_Investment_Corporation">China Investment Corporation</a> (China‚Äôs sovereign wealth fund)</li><li><a href="https://en.wikipedia.org/wiki/Silk_Road_Fund">Silk Road Fund</a> (a state-owned fund focused on projects related to the Belt &amp; Road Initiative)</li><li><a href="https://en.wikipedia.org/wiki/Temasek_Holdings">Temasek Holding</a> (Singapore‚Äôs sovereign wealth fund)</li></ul><p>The other 49% is owned by Softbank via Arm. The joint venture structure is par for the course for any foreign technology company doing business in China. But such a tight ownership by state-owned funds means Chinese regulators (and Singaporean regulators for that matter) have strong jurisdictional power over the deal from the get-go. NXP-Qualcomm‚Äôs legal hook was a tenuous nexus. TikTok-Oracle‚Äôs hook was established by <a href="https://en.pingwest.com/a/7657">an eleventh hour change</a> to the government‚Äôs technology ‚Äúentity list‚Äù. Arm-Nvidia doesn‚Äôt need any extra work for regulators to aggressively insert themselves into the picture.</p><p>What will the Chinese regulators do is hard to tell at this moment. However, given the fact that Arm‚Äôs chip design IP has a 95% global market share in mobile devices and is <a href="https://www.zdnet.com/article/aws-graviton2-what-it-means-for-arm-in-the-data-center-cloud-enterprise-aws/">making inroads into cloud data centers</a> as well, <strong>it‚Äôs likely that China will either veto the deal (like NXP-Qualcomm) or try to keep any semiconductor IP that Arm China has even a tangential connection to</strong>. Some Chinese tech media <a href="https://mp.weixin.qq.com/s/W8nhj6udDTdr54ui7_0RIQ">are already speculating about a veto</a>. Using this opportunity to acquire some key technology also makes sense, because by <em>not</em> doing so, China runs the monumental risk of having the entire Arm ecosystem be subject to U.S. sanctions after it becomes a property of Nvidia. An ‚Äú<strong>Arm sanction</strong>‚Äù would cripple China‚Äôs entire mobile technology sector, where domestic chip design options barely exist and the open source option, RISC-V, still ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/">https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/era-of-regulatory-grift-tiktok-oracle-nxp-qualcomm-arm-nvidia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531657</guid>
            <pubDate>Sun, 20 Sep 2020 03:08:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prodigal Techbro]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24531490">thread link</a>) | @cyunker
<br/>
September 19, 2020 | https://conversationalist.org/2020/03/05/the-prodigal-techbro/ | <a href="https://web.archive.org/web/*/https://conversationalist.org/2020/03/05/the-prodigal-techbro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

               <div>


                  <p><em>The tech executive turned data justice warrior is celebrated as a truth-telling hero, but there‚Äôs something a bit too smooth about this narrative arc.</em></p><div><p><img src="https://conversationalist.org/wp-content/uploads/2020/03/Tristan-Harris.jpg" alt="" srcset="https://conversationalist.org/wp-content/uploads/2020/03/Tristan-Harris.jpg 799w, https://conversationalist.org/wp-content/uploads/2020/03/Tristan-Harris-300x200.jpg 300w, https://conversationalist.org/wp-content/uploads/2020/03/Tristan-Harris-768x512.jpg 768w" sizes="(max-width: 640px) 100vw, 640px"></p><p><span>Credit: Stuart Isett/Fortune</span><span></span></p></div>
<p>A few months ago, I was contacted by a senior executive who was about to leave a marketing firm. He got in touch because I‚Äôve worked on the non-profit side of tech for a long time, with lots of volunteering on digital and human rights. He wanted to ‚Äògive back‚Äô. Could I put him in touch with digital rights activists? Sure. We met for coffee and I made some introductions. It was a perfectly lovely interaction with a perfectly lovely man. Perhaps he will do some good, sharing his expertise with the people working to save democracy and our private lives from the surveillance capitalism machine of his former employers. The way I rationalized helping him was: firstly, it‚Äôs nice to be nice; and secondly, movements are made of people who start off far apart but converge on a destination. And isn‚Äôt it an unqualified good when an insider decides to do the right thing, however late?</p>
<p>The Prodigal Son is a New Testament parable about two sons. One stays home to work the farm. The other cashes in his inheritance and gambles it away. When the gambler comes home, his father slaughters the fattened calf to celebrate, leaving the virtuous, hard-working brother to complain that all these years he wasn‚Äôt even given a small goat to share with his friends. His father replies that the prodigal son ‚Äòwas dead, now he‚Äôs alive; lost, now he‚Äôs found‚Äô. Cue party streamers. It‚Äôs a touching story of redemption, with a massive payload of moral hazard. It‚Äôs about coming home, saying sorry, being joyfully forgiven and starting again. Most of us would love to star in it, but few of us will be given the chance.</p>
<p>The Prodigal Tech Bro is a similar story, about tech executives who experience a sort of religious awakening. They suddenly see their former employers as toxic, and reinvent themselves as experts on taming the tech giants. They were lost and are now found. They are warmly welcomed home to the center of our discourse with invitations to write opeds for major newspapers, for think tank funding, book deals and TED talks. These guys ‚Äì and yes, they are all guys ‚Äì are generally thoughtful and well-meaning, and I wish them well. But I question why they seize so much attention and are awarded scarce resources, and why they‚Äôre given not just a second chance, but also the mantle of moral and expert authority.</p>
<p>I‚Äôm glad that Roger McNamee, the early Facebook investor, has <a href="https://www.theguardian.com/world/2020/feb/29/rebecca-solnit-younger-feminists-shift-understanding-give-new-tools">testified to the U.S. Congress</a> about Facebook‚Äôs wildly self-interested near-silence about its amplification of Russian disinformation during the 2016 presidential election. I‚Äôm thrilled that Google‚Äôs ex-‚Äòdesign ethicist‚Äô, Tristan Harris, ‚Äú<a href="https://www.theguardian.com/world/2020/feb/29/rebecca-solnit-younger-feminists-shift-understanding-give-new-tools">the </a><em>closest thing Silicon Valley has to a conscience,</em>‚Äú(startlingly faint praise) now runs a Center for Humane Technology, exposing the mind-hacking tricks of his former employer. I even <a href="https://www.youtube.com/watch?v=3hSrUaSNFSY&amp;t=2309s">spoke</a> ‚Äîcritically but, I hope, warmly‚Äîat the book launch of James Williams, another ex-Googler turned attention evangelist, who ‚Äú<a href="https://en.wikipedia.org/wiki/Center_for_Humane_Technology">co-founded the movement</a>‚Äùof awareness of designed-in addiction. I wish all these guys well. I also wish that the many, exhausted activists who didn‚Äôt take money from Google or Facebook could have even a quarter of the attention, status and authority the Prodigal Techbro assumes is his birth-right.</p>
<p>Today, when the tide of public opinion on Big Tech is finally turning, the brothers (and sisters) who worked hard in the field all those years aren‚Äôt even invited to the party. No fattened calf for you, my all but unemployable tech activist. The moral hazard is clear; why would anyone do the right thing from the beginning when they can take the money, have their fun, and then, when the wind changes, convert their status and relative wealth into special pleading and a whole new career?</p>
<p>Just half an hour flipping through my contacts produced half a dozen friends and acquaintances who didn‚Äôt require a ‚Äòroad to Damascus‚Äô conversion to see what was wrong with big tech or the ways governments abuse it. Nighat Dad runs the <a href="https://digitalrightsfoundation.pk/">Digital Rights Foundation in Pakistan</a>, defending online freedom of expression and privacy for women, minorities and dissidents. That‚Äôs real courage. <a href="https://privacyinternational.org/people/95/gus-hosein">Gus Hosein</a> has worked in tech and human rights for over 20 years, runs Privacy International, the UK-based non-profit, and is the most visionary thinker I know on how to shake up our assumptions about why things are as they are.&nbsp; <a href="https://biancawylie.com/">Bianca Wylie </a>founded the volunteer-run Open Data Institute Toronto, and works on open data, citizen privacy and civic engagement. The ‚Äú<a href="https://www.citylab.com/life/2018/12/bianca-wylie-interview-toronto-quayside-protest-criticism/574477/">Jane Jacobs of the Smart Cities Age</a>,‚Äù she‚Äôs been a key figure in opening up and slowing down Alphabet‚Äôs Sidewalk Labs juggernaut in Toronto. Aral Balkan runs <a href="https://small-tech.org/">Small Technology Foundation </a>and works on both the tools and the policies to resist surveillance capitalism. Unafraid of being unpopular, even with other activists, Balkan freely hammers rights organizations or conferences for taking big tech‚Äôs sponsorship money while criticizing the companies‚Äô practices. In the western Balkans, <a href="https://hvale.me/">hvale vale</a><a href="#_ftn10" name="_ftnref10"></a> works tirelessly and cheerfully on women‚Äôs rights, sexual rights and the political and practical path to a feminist internet. <a href="https://en.wikipedia.org/wiki/Robin_Gross">Robin Gross</a>, &nbsp;a Californian intellectual property lawyer, could have put her persistence and sheer pizazz to work defending big entertainment companies, but instead she‚Äôs worked for decades against the copyright maximalism that strangles artists‚Äô creativity and does nothing to increase their incomes. I would love to hear their voices amplified, not (just) the voices of those who took a decade and more to work out the rottenness at the core of big tech.</p>
<p>Ex-Google lobbyist Ross Lajeunesse left the company in 2019 over its censored search engine for China and also because of homophobic, sexist and racist work practices. He‚Äôs now running for a Democratic senate nomination, and recently wrote a classic of the ‚Äòscales have fallen from my eyes‚Äô genre, called ‚ÄúI Was Google‚Äôs Head of International Relations. <a href="https://medium.com/@rossformaine/i-was-googles-head-of-international-relations-here-s-why-i-left-49313d23065">Here‚Äôs Why I Left</a>.‚Äù Its lede is <em>‚ÄúThe company‚Äôs motto used to be ‚ÄúDon‚Äôt be evil.‚Äù Things have changed.‚Äù</em></p>
<p>Really? Has Google really changed? Lajeunesse joined in 2008, years into Google‚Äôs multi-billion dollar <a href="https://www.bloomberg.com/news/articles/2010-10-21/google-2-4-rate-shows-how-60-billion-u-s-revenue-lost-to-tax-loopholes">tax avoidance</a>, <a href="https://www.cnet.com/news/google-hit-with-job-discrimination-lawsuit/">sexist labor practices</a> and <a href="http://news.bbc.co.uk/2/hi/technology/6740075.stm">privacy hostility</a> and continued to work there through the years of <a href="https://www.bbc.co.uk/news/technology-40406542">antitrust fines</a>, misuse of <a href="https://www.bbc.com/news/technology-40406542">personal health data</a>, <a href="https://www.cnet.com/news/judge-rejects-324-5m-wage-fixing-settlement-struck-by-apple-google-others/">wage fixing</a>, and financially <a href="https://www.nytimes.com/2017/08/30/us/politics/eric-schmidt-google-new-america.html">pressuring think tanks</a>. Google didn‚Äôt change. It just started treating some of its insiders like it already treated outsiders. That only looks like radical change if you‚Äôve never thought too hard about what you are doing and to whom.</p>
<p>One hundred thousand people work for Google/Alphabet; some of them have much more power than others. The point isn‚Äôt whether Lajeunesse is or isn‚Äôt culpable for the many acts of the enormous company he represented‚Äîas its chief lobbyist in Asia for several years‚Äîit‚Äôs that of all the people who spent the decade of 2010-20 working thanklessly to expose and reduce the firm‚Äôs monopolistic abuse and assault on global privacy, it‚Äôs the ex-lobbyist who gets our attention now.</p>
<p>We all need second chances. Even if we don‚Äôt need those fresh starts ourselves, we want to live in a world where people have a reason to do better. But the prodigal tech bro‚Äôs redemption arc is so quick and smooth it‚Äôs barely a road bump. That‚Äôs because we keep skipping the most important part of the prodigal son story‚Äîwhere he hits rock bottom. In the original parable, the prodigal son wakes up in a pig sty, starving, and realizes his father‚Äôs servants now live better than he does. He resolves to go home to the people and place he did not value or respect before. He will beg to be one of his father‚Äôs servants. He accepts his complete loss of status. But instead of chastising and punishing his prodigal son, the rejoicing father greets him joyfully and heads off the apology with a huge party. It‚Äôs a great metaphor for how to run a religion, but a lousy way to run everything else.</p>
<p>Prodigal tech bro stories skip straight from the past, when they were part of something that‚Äîsurprise!‚Äîturned out to be bad, to the present, where they are now a moral authority on how to do good, but without the transitional moments of revelation and remorse. &nbsp;But the bit where you say you got things wrong and people were hurt? That‚Äôs the most important part. It‚Äôs why these corporatized reinventions feel so slick and tinny, and why so many of the comments on Lajeunesse‚Äôs <a href="https://medium.com/@rossformaine/i-was-googles-head-of-international-relations-here-s-why-i-left-49313d23065">train wreck post</a> on Medium were critical. The journey feels fake. These ‚ÄòI was lost but now I‚Äôm found, please come to my TED talk‚Äô accounts typically miss most of the actual journey, yet claim the moral authority of one who‚Äôs ‚Äòbeen there‚Äô but came back. It‚Äôs a teleportation machine, but for ethics.</p>
<p>(While we‚Äôre thinking about the neatly elided parts of the prodigal tech bro story, let‚Äôs dwell for one moment on the deletion of the entire stories of so many women and people of color barely given a first chance in Silicon Valley, let alone multiple reinventions.)</p>
<p>The only thing more fungible than cold, hard cash is privilege. The prodigal tech bro doesn‚Äôt so much take an off-ramp from the relatively high status and well-paid job he left when the scales fell from his eyes, as zoom up an on-ramp into a new sector that accepts the reputational currency he has accumulated. He‚Äôs not joining the resistance. He‚Äôs launching a new kind of start-up using his industry contacts for seed-funding in return for some reputation-laundering.</p>
<p>So what? Sure, it‚Äôs a little galling, but where‚Äôs the harm?</p>
<p>Allowing people who share responsibility for our tech dystopia to keep control of the narrative means we never get to the bottom of how and why we got here, and we artificially narrow the possibilities for where we go next. And centering people who were insiders before and claim to be leading the outsiders ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://conversationalist.org/2020/03/05/the-prodigal-techbro/">https://conversationalist.org/2020/03/05/the-prodigal-techbro/</a></em></p>]]>
            </description>
            <link>https://conversationalist.org/2020/03/05/the-prodigal-techbro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531490</guid>
            <pubDate>Sun, 20 Sep 2020 02:06:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Apple Notes Protobuf]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531472">thread link</a>) | @todsacerdoti
<br/>
September 19, 2020 | https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/ | <a href="https://web.archive.org/web/*/https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"> <p><strong>TL;DR</strong>: This post explains portions of two protobufs used by Apple, one for the Note format itself and another for embedded objects. More importantly, it explains how you can figure out the structure of protobufs.</p> <!--more--> <h2 id="background">Background</h2> <p>Previous entries in this series covered how to deal with <a href="https://ciofecaforensics.com/2020/01/10/apple-notes-revisited/">Apple Notes</a> and the <a href="https://ciofecaforensics.com/2020/01/13/apple-notes-revisited-easy-embedded-objects/">embedded objects</a> in them, including <a href="https://ciofecaforensics.com/2020/01/14/apple-notes-revisited-embedded-tables/">embedded tables</a> and <a href="https://ciofecaforensics.com/2020/01/20/apple-notes-revisited-galleries/">galleries</a>. Throughout these posts, I have referred to the fact that Apple uses protocol buffers (protobufs) to store the information for both notes and the embedded objects within them. What I have not yet done is actually provide the .proto file that was used to generate the Ruby output, or explained how you can develop the same on your app of interest. If you only care about the first part of that, you can view the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/notestore.proto">.proto file</a> or the <a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser/blob/master/proto/protobuf_config.py">config</a> I use for <a href="https://github.com/jmendeth/protobuf-inspector">protobuf-inspector</a>. Both of these files are just a start to pull out the important parts for processing and can certainly be improved.</p> <p>As with previous entries, I want to make sure I give credit where it is due. After pulling apart the Note protobuf and while I was trying to figure out the table protobuf, I came across <a href="https://github.com/dunhamsteve">dunhamsteve‚Äôs</a> work. As a result, I went back and modified some of my naming to better align to what he had <a href="https://github.com/dunhamsteve/notesutils/blob/master/notes.md">published</a> and added in some fields like version which I did not have the data to discover.</p> <h2 id="what-is-a-protocol-buffer">What is a Protocol Buffer?</h2> <p>To quote directly from <a href="https://developers.google.com/protocol-buffers">the source</a>,</p> <blockquote> <p>Protocol buffers are Google‚Äôs language-neutral, platform-neutral, extensible mechanism for serializing structured data ‚Äì think XML, but smaller, faster, and simpler. You define how you want your data to be structured once, then you can use special generated source code to easily write and read your structured data to and from a variety of data streams and using a variety of languages.</p> </blockquote> <p>What does that mean? It means a protocol buffer is a way you can write a specification for your data and use it in many projects and languages with one command. The end result is source code for whatever language you are writing in. For example, <a href="https://github.com/sballin/alfred-search-notes-app/blob/master/search/proto/notestore.pb.go">Sean Ballinger‚Äôs Alfred Search Notes App</a> used my <code>notestore.proto</code> file to compile to Go instead of Ruby to interact with Notes on MacOS. When you use it in your program, the data which you save will be a raw data stream which won‚Äôt look like much, but will be intelligable to any code with that protobuf definition.</p> <p>The definition is generally a <code>.proto</code> file which would look something like:</p> <figure><pre><code data-lang="protobuf"><span>syntax</span> <span>=</span> <span>"proto2"</span><span>;</span>

<span>// Represents an attachment (embedded object)</span>
<span>message</span> <span>AttachmentInfo</span> <span>{</span>
   <span>optional</span> <span>string</span> <span>attachment_identifier</span> <span>=</span> <span>1</span><span>;</span>
   <span>optional</span> <span>string</span> <span>type_uti</span> <span>=</span> <span>2</span><span>;</span>
<span>}</span></code></pre></figure> <p>This definition would have just one message type (AttachmentInfo), with two fields (attachment_identifier and type_uti), both optional. This is using the <code>proto2</code> syntax.</p> <h2 id="why-care-about-protobufs">Why Care About Protobufs</h2> <p>Protobufs are everywhere, especially if you happen to be working with or looking at Google-based systems, such as Android. Apple also uses a lot of them in iOS, and for people that have to support both operating systems, using a protobuf makes the pain of maintaining two different code bases slightly less annoying because you can compile the same definition to different languages. If you are in forensics, you may come across something that looks like it isn‚Äôt plaintext and discover that you‚Äôre actually looking at a protobuf. When it comes specifically to Apple Notes, protobufs are used both for the Note itself and the attachments.</p> <h2 id="how-to-use-a-proto-file">How to Use a .proto file</h2> <p>Assuming you have a <code>.proto</code> file, either from building one yourself or from finding one from your favorite application, you can compile it to your target language using <a href="https://github.com/protocolbuffers/protobuf/releases">protoc</a>. The resulting file can then be included in your project using whatever that language‚Äôs include statement is to create the necessary classes for the data. For example, when writing Apple Cloud Notes Parser in Ruby, I used <code>protoc --ruby_out=. ./proto/notestore.proto</code> to compile it and then <code>require_relative 'notestore_pb.rb'</code> in my code to include it.</p> <p>If I wanted instead to add in support for python, I would only have to make this change: <code>protoc --ruby_out=. --python_out=. ./proto/notestore.proto</code></p> <h2 id="how-can-you-find-a-protobuf-definition-file">How Can You Find a Protobuf Definition File?</h2> <p>If you come up against a protobuf in an application you are looking at, you might be able to find the <code>.proto</code> protobuf definition file in the application itself or somewhere on the forensic image. I ended up going through an iOS 13 forensic image earlier this year and found that Apple still had some of theirs on disk:</p> <figure><pre><code data-lang="shell"><span>[</span>notta@cuppa iOS13_logical]<span>$ </span>find | <span>grep</span> <span>'\.proto$'</span>
./System/Library/Frameworks/MultipeerConnectivity.framework/MultipeerConnectivity.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievementsBackCompat.proto
./System/Library/PrivateFrameworks/ActivityAchievements.framework/ActivityAchievements.proto
./System/Library/PrivateFrameworks/CoreLocationProtobuf.framework/Support/Harvest/CLPCollectionRequest.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDatabaseCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingDomainCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingInvitationCodables.proto
./System/Library/PrivateFrameworks/ActivitySharing.framework/ActivitySharingCloudKitCodables.proto
./System/Library/PrivateFrameworks/CloudKitCode.framework/RecordTransport.proto
./System/Library/PrivateFrameworks/RemoteMediaServices.framework/RemoteMediaServices.proto
./System/Library/PrivateFrameworks/CoreDuet.framework/knowledge.proto
./System/Library/PrivateFrameworks/HealthDaemon.framework/Statistics.proto
./System/Library/PrivateFrameworks/AVConference.framework/VCCallInfoBlob.proto
./System/Library/PrivateFrameworks/AVConference.framework/captions.proto</code></pre></figure> <p>Some of these are <em>really</em> interesting when you look at them, particularly if you care about their location data and pairing. You don‚Äôt even have to have an iOS forensic image sitting around as all of the same files are included in your copy of MacOS 10.15.6, as well, if you run <code>sudo find /System/ -iname "*.proto"</code>. I am not including any interesting snippets of those because they are copyrighted by Apple and I would explicitly note that none are related to Apple Notes or the contents of this post.</p> <p>In general, you should not expect to find these definitions sitting around since the definition file isn‚Äôt needed once the code is generated. For more open source applications, you might be interested in some <a href="https://www.google.com/search?q=ext%3Aproto++AND+inurl%3Aproto+AND+message+AND+proto2">Google Dorks</a>, especially when looking at Android artifacts, as you might still find them.</p> <h2 id="how-can-you-rebuild-the-protobuf">How Can You Rebuild The Protobuf?</h2> <p>But what if you can‚Äôt find the definition file, how can you rebuild it yourself? This was the most interesting part of rewriting Apple Cloud Notes Parser as I had no knowledge of how Apple typically represents data, nor protobufs, so it was a fun learning adventure.</p> <p>If you have nothing else, the <code>protoc --decode-raw</code> command can give you an intial look at what is in the data, however this amounts to not much more than pretty printing a JSON object, it doesn‚Äôt do a great job of telling you you what might be in there. I made heavy use of mildsunrise‚Äôs <a href="https://github.com/mildsunrise/protobuf-inspector">protobuf-inspector</a> which at least makes an attempt to tell you what you might be looking at. Another benefit to using this is that it lets you incrementally build up your own definition by editing a file named <code>protobuf_config.py</code> in the protobuf-insepctor folder.</p> <p>For example, below is the output from protobuf-inspector when I ran it on the Gunzipped contents of one of the first notes in my test database.</p> <figure><pre><code data-lang="python"><span>[</span><span>notta</span><span>@</span><span>cuppa</span> <span>protobuf</span><span>-</span><span>inspector</span><span>]</span><span>$</span> <span>python3</span> <span>main</span><span>.</span><span>py</span> <span>&lt;</span> <span>~/</span><span>note_18</span><span>.</span><span>blob</span> 
<span>root</span><span>:</span>
    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
        <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
        <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
            <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>"Pure blob title"</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>2</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>8</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>3</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>4</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>14</span><span>)</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>10</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>,</span> <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>)</span>
                <span>5</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
            <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
                <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                <span>3</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span>
                    <span>2</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>4294967295</span>
            <span>4</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                    <span>1</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>bytes</span> <span>(</span><span>16</span><span>)</span>
                        <span>0000</span>   <span>EE</span> <span>FE</span> <span>10</span> <span>DA</span> <span>5</span><span>A</span> <span>79</span> <span>43</span> <span>25</span> <span>88</span> <span>BA</span> <span>6</span><span>D</span> <span>CA</span> <span>E2</span> <span>E9</span> <span>B7</span> <span>EC</span>                          <span>....</span><span>ZyC</span><span>%</span><span>..</span><span>m</span><span>.....</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>24</span><span>)</span>
                    <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>9</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
                <span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>5</span>
                <span>2</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>(</span><span>1</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>0</span><span>,</span> <span>3</span> <span>&lt;</span><span>varint</span><span>&gt;</span> <span>=</span> <span>1</span><span>)</span>
            <span>5</span> <span>&lt;</span><span>chunk</span><span>&gt;</span> <span>=</span> <span>message</span><span>:</span>
          ‚Ä¶</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/">https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</a></em></p>]]>
            </description>
            <link>https://ciofecaforensics.com/2020/09/18/apple-notes-revisited-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531472</guid>
            <pubDate>Sun, 20 Sep 2020 02:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Do Neobanks Make Money?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24531372">thread link</a>) | @michaelm244
<br/>
September 19, 2020 | https://blog.mattheakis.com/how_do_neobanks_make_money/ | <a href="https://web.archive.org/web/*/https://blog.mattheakis.com/how_do_neobanks_make_money/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
  
  <time datetime="2020-09-15T06:52:31+00:00">15 Sep 2020</time>
  <p>Neobanks are on a tear and users are loving them. Neobanks are online-only banks, typically funded by venture capital, that piggy-back on top of an existing institution‚Äôs banking license and offer a way for customers to store/spend money. Examples include Revolut, Nubank, Chime, Simple, N26, and more. They have a real shot at becoming the mainstream banking choice for customers over the next decade. Nubank, the most popular neobank in Brazil, recently <a href="https://www.reuters.com/article/us-nubank-brazil-growth/brazilian-fintech-nubank-has-grown-to-15-million-users-ceo-idUSKBN1WQ26C" target="_blank">announced</a> that they have 15 million customers. For reference, Wells Fargo has <a href="https://google.com/" target="_blank">22 million active users</a> on its mobile app. Neobanks are a rising force and key in understanding where the financial services industry is headed.</p>

<p>But how do these neobanks make money? The imprecise answer of ‚Äúthey make money when you swipe their card‚Äù doesn‚Äôt tell you much. In this post, I‚Äôll concretely show how the mechanics of a neobank‚Äôs business model works.</p>

<p>Let‚Äôs take a look at <a href="https://www.chime.com/" target="_blank">Chime</a>, the largest consumer neobank in the US. Chime‚Äôs core offering is a debit card alongside checking and savings accounts. They have nifty features like the ability to receive your paycheck two days early, no overdraft fees, and 100% mobile banking. With 60% of Americans not being able to cover a surprise $1,000 expense, a 2-day advance on a paycheck can be a huge relief for managing expenses. And the nixing of overdraft fees is a massive help for the <a href="https://www.pymnts.com/news/banking/2018/banking-overdraft-fees-cfbp-credit-unions/" target="_blank">US consumers paying a mind-boggling $34 billion/year</a> in overdraft fees. These differentiated features have led to Chime amassing <a href="https://techcrunch.com/2019/09/04/chime-now-has-5-million-customers-and-introduces-overdraft-alternative/" target="_blank">5 million customers</a> and <a href="https://www.businessinsider.com/chime-set-to-quadruple-revenue-in-2019-2019-11" target="_blank">$200 million in annualized revenue</a>.</p>

<p><strong>A neobank like Chime primarily makes money in two ways:</strong></p>

<ol>
  <li>Interchange revenue paid by payment processors (e.g., Stripe) when they process a payment for a Chime card</li>
  <li>Collecting interest from users‚Äô deposits</li>
</ol>

<p>Although some neobanks have different revenue streams (e.g., Wealthfront charges users roboadvisor fees as a percentage of the total value of assets stored with them), interchange and deposits interest are the two largest and most common revenue streams for neobanks. These are also some of the largest revenue streams for big banks (lending though typically being the largest).</p>

<h3 id="interchange"><strong>Interchange</strong></h3>

<p>Interchange revenue is money that a card issuer (such as Chime) receives when someone swipes their card. Interchange is paid by the merchant through payment processing fees. The merchant is the party accepting a card payment in return for goods/services (e.g., your local supermarket). As an example, if a merchant uses <a href="https://stripe.com/" target="_blank">Stripe</a> for payment processing and is paying the standard <a href="https://stripe.com/pricing" target="_blank">2.9%</a> in transaction fees, Stripe will use a portion of that 2.9% to pay the card issuer.</p>

<h2><img src="https://www.helcim.com/pictures/credit-card-processing-flow-152858808066.jpg" alt="card_process"></h2>

<p>Image Credit: <a href="https://www.helcim.com/article/how-credit-card-processing-works/" target="_blank">Helcim</a></p>

<p>The specific amount paid to the card issuer depends on a number of factors and it varies for every transaction. The most important factors are:</p>

<ul>
  <li>Whether the card is debit or credit
    <ul>
      <li>Credit is significantly higher interchange</li>
    </ul>
  </li>
  <li>Whether the card has specific rewards/perks
    <ul>
      <li><a href="https://usa.visa.com/pay-with-visa/cards/visa-credit-cards/visa-infinite-credit-cards.html" target="_blank">Visa Infinite</a> (many rewards/perks) has a higher interchange rate than the standard Visa card</li>
    </ul>
  </li>
  <li>The type of the merchant for a given transaction
    <ul>
      <li>Hotels have some of the highest interchange rates</li>
    </ul>
  </li>
</ul>

<p>Ultimately the card network (e.g., Visa) decides what the interchange rates are. The key equation for an interchange revenue stream is:</p>

<p><i>avg. interchange rate * total transaction volume</i></p>

<p>In Chime‚Äôs case, their cards are on the Visa network so Visa decides how much interchange they receive. The Visa interchange rates, along with Chime‚Äôs specific rates, are <a href="https://usa.visa.com/dam/VCOM/download/merchants/visa-usa-interchange-reimbursement-fees.pdf" target="_blank">public</a> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. Depending on the type of merchant and transaction, Chime earns between 0.8% - 1.9% of a transaction‚Äôs amount, Although it‚Äôs impossible to know the exact amount of interchange Chime receives without knowing the distribution of Chime users‚Äô spending, a reasonable guess based on aggregate consumer spending would put Chime‚Äôs average interchange rate at 1.25%<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. This means that Chime receives around 1.25% of _all spending on their cards_. Not bad! There are still a handful of costs that Chime has to pay per transaction:</p>

<ul>
  <li>Intermediary card processors
    <ul>
      <li>Example: Chime uses <a href="https://www.galileo-ft.com/" target="_blank">Galileo</a>, which likely charges them anywhere from 0.05% - 0.4% of transaction volume</li>
    </ul>
  </li>
  <li>Fraud: if a customer loses their card and a thief spends money on it, Chime may have to cover the cost
    <ul>
      <li>Note: keep in mind that since Chime is offering debit cards, not credit cards, there is no risk of the customer not paying back Chime for transactions</li>
    </ul>
  </li>
  <li>Server costs: the server that has to process a transaction</li>
</ul>

<p>Even with these costs, Chime is still making a handsome profit per transaction. Being the card issuer, as they are here, is a very high-margin business.</p>

<h3 id="deposits-interest"><strong>Deposits Interest</strong></h3>

<p>Interest revenue is earned by a depository institution investing customer funds in low-risk securities. The depository institution typically also pays the customer for keeping their deposits at the institution. The key equation for profitability of this revenue stream is:</p>

<p><i>(% interest earned - % interest paid to depositor) * deposits amount</i></p>

<p>The <em>% interest earned</em> for neobanks is typically equal to the <a href="https://fred.stlouisfed.org/series/FEDFUNDS" target="_blank">effective federal funds rate</a>. Because the federal funds rate is constantly shifting, the profitability of this revenue stream for neobanks is constantly shifting. This is why neobanks frequently change the interest rate offered to depositors (see <a href="https://blog.wealthfront.com/category/product-news/" target="_blank">Wealthfront‚Äôs blog</a> as an example). This is a stark contrast to big banks however. A key benefit of a banking charter is that banks can lend out a multiple of their deposits as loans (e.g., mortgages, business loans). This amount is referred to as net interest margin, and is typically much higher than the federal funds rate - <a href="https://www.investopedia.com/ask/answers/061715/what-net-interest-margin-typical-bank.asp" target="_blank">it was 3.3% on average for banks in 2018</a>. The _% interest paid to depositor* is how much the depositor earns by storing their funds with the institution, and is set by the depository institution. For the recent wave of high-yield accounts offered by neobanks, they‚Äôve set <em>% interest paid to depositor</em> essentially equal to *% interest earned_, making this revenue stream‚Äôs profitability close to zero. The typical rationale is for the high-yield account to draw in consumers for other higher-margin products such as debit/credit cards or loans.</p>

<p>In Chime‚Äôs case, <em>% interest earned</em> (the federal funds rate) is 0.09% at the time of writing (Sept. 2020), and <a href="https://chime.zendesk.com/hc/en-us/articles/221487887-What-do-I-need-to-know-about-the-Chime-Savings-Account-" target="_blank"><em>% interest paid to depositor</em></a> is 1.00%. This means that Chime is actually losing money on their deposit account product, and likely using it as a <a href="https://en.wikipedia.org/wiki/Loss_leader" target="_blank">loss leader</a> for the debit card, which has far higher profit margins. Also note that Chime only gives depositors 1% in interest for funds in their savings account. For any funds in the checking account (which over all customers may be larger), no interest is given.</p>

<p>These are the two main revenue streams for the majority of neobanks, but there are also others such as <a href="https://en.wikipedia.org/wiki/Cross-selling" target="_blank">cross-selling</a>, <a href="https://www.svmcards.com/" target="_blank">reward redemption referrals</a>, and new ones being created by startups. Hopefully this has given you a grasp of the basics, let me know if you have any thoughts/questions below!</p>




  <br>
  
  
  
</article>

      </div></div>]]>
            </description>
            <link>https://blog.mattheakis.com/how_do_neobanks_make_money/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24531372</guid>
            <pubDate>Sun, 20 Sep 2020 01:29:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bug Could Let Attackers Hijack Firefox for Android via Wi-Fi Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530986">thread link</a>) | @assineproff
<br/>
September 19, 2020 | http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/ | <a href="https://web.archive.org/web/*/http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tps_slideContainer_1237"><div>

<p>Dear Android users, if you use the Firefox web browser on your smartphones, make sure it has been updated to version 80 or the latest available version on the Google Play Store.</p>

<p>ESET security researcher Lukas Stefanko yesterday&nbsp;<a href="https://twitter.com/LukasStefanko/status/1307013106615418883" target="_blank" rel="noopener noreferrer">tweeted</a>&nbsp;an alert demonstrating the exploitation of a recently disclosed high-risk remote command execution vulnerability affecting the Firefox app for Android.</p>

<p>Discovered originally by Australian security researcher&nbsp;<a href="https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/red-team-tech-notes/-/tree/master/firefox-android-2020" target="_blank" rel="noopener noreferrer">Chris Moberly</a>, the vulnerability resides in the SSDP engine of the browser that can be exploited by an attacker to target Android smartphones connected to the same Wi-Fi network as the attacker, with Firefox app installed.</p>
<p>SSDP, stands for Simple Service Discovery Protocol, is a UDP based protocol that is a part of UPnP for finding other devices on a network. In Android, Firefox periodically sends out SSDP discovery messages to other devices connected to the same network, looking for second-screen devices to cast.</p>
<p>Any device on the local network can respond to these broadcasts and provide a location to obtain detailed information on a UPnP device, after which, Firefox attempts to access that location, expecting to find an XML file conforming to the UPnP specifications.</p>

<p>According to the vulnerability report Moberly submitted to the Firefox team, the SSDP engine of the victims‚Äô Firefox browsers can be tricked into triggering an Android intent by simply replacing location of the XML file in the response packets with a specially crafted message pointing to an Android intent URI.</p>
<p>For this, an attacker connected to a targeted Wi-Fi network can run a malicious SSDP server on his/her device and trigger intent-based commands on nearby Android devices through Firefox‚Äîwithout requiring any interaction from the victims.</p>
<p>Activities allowed by the intent also includes automatically launching the browser and open any defined URL, which, according to the researchers, is sufficient to trick victims into providing their credentials, install malicious apps, and other malicious activities based on the surrounding scenarios.</p>
<p>‚ÄúThe target simply has to have the Firefox application running on their phone. They do not need to access any malicious websites or click any malicious links. No attacker-in-the-middle or malicious app installation is required. They can simply be sipping coffee while on a cafe‚Äôs Wi-Fi, and their device will start launching application URIs under the attacker‚Äôs control,‚Äù Moberly said.</p>

<p>‚Äúit could have been used in a way similar to phishing attacks where a malicious site is forced onto the target without their knowledge in the hopes they would enter some sensitive info or agree to install a malicious application.‚Äù</p>
<p>Moberly reported this vulnerability to the Firefox team a few weeks back, which the browser maker has now patched in the Firefox for Android versions 80 and later.</p>
<p>Moberly has also released a&nbsp;<a href="https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/red-team-tech-notes/-/blob/master/firefox-android-2020/ffssdp.py" target="_blank" rel="noopener noreferrer">proof-of-concept exploit</a>&nbsp;to the public that Stefanko used to demonstrate the issue in the above video against three devices connected to the same network.</p>

</div></div></div>]]>
            </description>
            <link>http://tech.thewebgangs.com/a-bug-could-let-attackers-hijack-firefox-for-android-via-wi-fi-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530986</guid>
            <pubDate>Sat, 19 Sep 2020 23:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SCons Is Still Slow]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24530845">thread link</a>) | @luu
<br/>
September 19, 2020 | https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/ | <a href="https://web.archive.org/web/*/https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					
					<!-- .entry-header -->

											<div>
							<p>A while back I posted a series of articles exploring the scalability of SCons, a popular Python-based build tool.  In a nutshell, my experiments showed that <b>SCons exhibits roughly quadratic growth in build runtimes as the number of targets increases</b>:</p>
<ul>
<li><a href="https://blog.melski.net/2011/05/23/why-is-scons-so-slow/">Why is SCons so slow?</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/03/08/how-scalable-is-scons/">How scalable is SCons?</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/07/21/a-second-look-at-scons-performance/">A second look at SCons performance</a></li>
<li><a href="http://www.electric-cloud.com/blog/2010/08/11/the-last-word-on-scons-performance/">The last word on SCons performance</a></li>
</ul>
<p>
Recently Dirk Baechle attempted to rebut my findings in an entry on the SCons wiki:  <a href="http://scons.org/wiki/WhySconsIsNotSlow">Why SCons is not slow</a>.  I thought Dirk made some credible suggestions that could explain my results, and he did some smart things in his effort to invalidate my results.  Unfortunately, his methods were flawed and his conclusions are invalid.  My original results still stand: <b>SCons really is slow.</b>  In the sections that follow I‚Äôll share my own updated benchmarks and show where Dirk‚Äôs analysis went wrong.</p>
<h3>Test setup</h3>
<p>
As before, I used <a href="https://github.com/emelski/scons_bench/blob/master/genscons.pl">genscons.pl</a> to generate sample builds ranging from 2,000 to 50,000 targets.  However, my test system was much beefier this time:</p>
<table>
<tbody><tr>
<th></th>
<th>2013</th>
<th>2010</th>
</tr>
<tr>
<th>OS</th>
<td>Linux Mint 14 (kernel version 3.5.0-17-generic)</td>
<td>RedHat Desktop 3 (kernel version 2.4.21-58.ELsmp)</td>
</tr>
<tr>
<th>CPU</th>
<td>Quad 1.7GHz Intel Core i7, hyperthreaded</td>
<td>Dual 2.4GHz Intel Xeon, hyperthreaded</td>
</tr>
<tr>
<th>RAM</th>
<td>16 GB</td>
<td>2 GB</td>
</tr>
<tr>
<th>HD</th>
<td>SSD</td>
<td>(unknown)</td>
</tr><tr>
<th>SCons</th>
<td>2.3.0</td>
<td>1.2.0.r3842</td>
</tr>
<tr>
<th>Python</th>
<td>2.7.3 (system default)</td>
<td>2.6.2</td>
</tr>
</tbody></table>
<p>
Before running the tests, I rebooted the system to ensure there were no rogue processes consuming memory or CPU.  I also forced the CPU cores into ‚Äúperformance‚Äù mode to ensure that they ran at their full 1.7GHz speed, rather than at the lower 933MHz they switch to when idle.</p>
<h3>Revisiting the original benchmark</h3>
<p>
I think Dirk had two credible theories to explain the results I obtained in my original tests.  First, Dirk wondered if those results may have been the result of <i>virtual memory swapping</i> ‚Äî my original test system had relatively little RAM, and SCons itself uses a lot of memory.  It‚Äôs plausible that physical memory was exhausted, forcing the OS to swap memory to disk.  As Dirk said, ‚Äúthis would explain the increase of build times‚Äù ‚Äî you bet it would!  I don‚Äôt remember seeing any indication of memory swapping when I ran these tests originally, but to be honest it was nearly 4 years ago and perhaps my memory is not reliable.  To eliminate this possibility, I ran the tests on a system with 16 GB RAM this time.  During the tests I ran <span><span face="Courier New">vmstat 5</span></span>, which collects memory and swap usage information at five second intervals, and captured the result in a log.</p>
<p>
Next, he suggested that I skewed the results by directing SCons to inherit the ambient environment, rather than using SCons‚Äô default ‚Äúsanitized‚Äù environment.  That is, he felt I should have used <span><span face="Courier New">env = Environment()</span></span> rather than <span><span face="Courier New">env = Environment(ENV = os.environ)</span></span>.  To ensure that this was not a factor, I modified the tests so that they did not inherit the environment.  At the same time, I substituted <span><span face="Courier New">echo</span></span> for the compiler and other commands, in order to make the tests faster.  Besides, I‚Äôm not interested in benchmarking the compiler ‚Äî just SCons!  Here‚Äôs what my <span><span face="Courier New">Environment</span></span> declaration looks like now:</p>
<pre title="">env = Environment(CC = 'echo', AR = 'echo', RANLIB = 'echo')
</pre>
<p>With these changes in place I reran my benchmarks.  As expected, there was no change in the outcome.  There is no doubt:  <b>SCons does <i>not</i> scale linearly</b>.  Instead the growth is <i>polynomial</i>, following an n<sup>1.85</sup> curve.  And thanks to the the <a href="https://github.com/emelski/scons_bench/blob/master/logs/2.3.0/001/50000.vmstat">vmstat output</a> we can be certain that there was absolutely no swapping affecting the benchmarks.  Here‚Äôs a graph of the results, including an n<sup>1.85</sup> curve for comparison ‚Äî notice that you can barely see that curve because it matches the observed data so well!</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_full.png"><img data-attachment-id="1040" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_full/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_full.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_full.png?w=640&amp;h=384" alt="SCons full build runtime - click for larger view" srcset="https://emelski.files.wordpress.com/2013/12/scons_full.png 500w, https://emelski.files.wordpress.com/2013/12/scons_full.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_full.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
For comparison, I used the SCons build log to make a shell script that executes the same series of <span><span face="Courier New">echo</span></span> commands.  At 50,000 targets, the shell script ran in 1.097s.  You read that right:  <b>1.097s</b>.  Granted, the shell script doesn‚Äôt do stuff like up-to-date checks, etc., but still ‚Äî of the 3,759s average SCons runtime, 3,758s ‚Äî 99.97% ‚Äî is SCons overhead.</p>
<p>
I also created a non-recursive Makefile that ‚Äúbuilds‚Äù the same targets with the same <span><span face="Courier New">echo</span></span> commands.  This is a more realistic comparison to SCons ‚Äî after all, nobody would dream of actually controlling a build with a straight-line shell script, but lots of people would use GNU make to do it.  With 50,000 targets, GNU make ran for <b>82.469s</b> ‚Äî more than 45 times faster than SCons.</p>
<h3>What is linear scaling?</h3>
<p>
If the performance problems are so obvious, why did Dirk fail to see them?  Here‚Äôs a graph made from his test results:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_baechle.png"><img data-attachment-id="1038" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_baechle/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime, via D. Baechle" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=640&amp;h=640" alt="SCons full build runtime, via D. Baechle - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_baechle.png 500w, https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_baechle.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
Dirk says that this <a href="http://scons.org/wiki/WhySconsIsNotSlow#Linear_scaling">demonstrates ‚ÄúSCons‚Äô linear scaling‚Äù</a>.  I find this statement baffling, because his data clearly shows that <i>SCons does not scale linearly</i>.  It‚Äôs simple, really:  <i>linear scaling</i> just means that the build time increases by the same amount for each new target you add, regardless of how many targets you already have.  Put another way, it means that the difference in build time between 1,000 targets and 2,000 targets is <i>exactly the same</i> as the difference between 10,000 and 11,000 targets, or between 30,000 and 31,000 targets.  Or, put yet another way, it means that when you plot the build time versus the number of targets, you should get a straight line with <i>no change in slope at any point</i>.  Now you tell me:  does that describe Dirk‚Äôs graph?</p>
<p>
Here‚Äôs another version of that graph, this time augmented with a couple additional lines that show what the plot would look like if SCons were truly scaling linearly.  The first projection is based on the original graph from 2,500 to 4,500 targets ‚Äî that is, if we assume that SCons scales linearly and that the increase in build time between 2,500 and 4,500 targets is representative of the cost to add 2,000 more targets, then this line shows us how we should expect the build time to increase.  Similarly, the second projection is based on the original graph between 4,500 and 8,500 targets.  You can easily see that the actual data does not match either projection.  Furthermore you can see that the slope of these projections is <i>increasing</i>:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png"><img data-attachment-id="1039" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_baechle_augmented/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build runtime with linear projections, via D. Baechle" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=640&amp;h=640" alt="SCons full build runtime with linear projections, via D. Baechle - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png 500w, https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_baechle_augmented.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
This shows the importance of testing at large scale when you‚Äôre trying to characterize the scalability of a system from empirical data.  It can be difficult to differentiate polynomial from logarithmic or linear at low scales, especially once you incorporate the constant factors ‚Äî polynomial algorithms can sometimes even give <i>better</i> absolute performance for small inputs than linear algorithms!  It‚Äôs not until you plot enough data points at large enough values, as I‚Äôve done, that it becomes easy to see and identify the curve.</p>
<h3>What does profiling tell us?</h3>
<p>
Next, Dirk reran some of his tests under a profiler, on the very reasonable assumption that if there was a performance problem to be found, it would manifest in the profiling data ‚Äî surely at least one function would demonstrate a larger-than-expected growth in runtime.  Dirk only shared profiling data for two runs, both incremental builds, at 8,500 and 16,500 targets.  That‚Äôs unfortunate for a couple reasons.  First, the performance problem is less apparent on incremental builds than on full builds.  Second, with only two datapoints it is literally not possible to determine whether growth is linear or polynomial.  The results of Dirk‚Äôs profiling was negative:  he found no ‚Äúsignificant difference or increase‚Äù in any function.</p>
<p>
Fortunately it‚Äôs easy to run this experiment myself.  Dirk used <a href="http://docs.python.org/2/library/profile.html">cProfile</a>, which is built-in to Python.  To profile a Python script you can inject cProfile from the command-line, like this: <span><span face="Courier New">python -m cProfile scons</span></span>.  Just before Python exits, cProfile dumps timing data for every function invoked during the run.  I ran several full builds with the profiler enabled, from 2,000 to 20,000 targets.  Then I sorted the profiling data by function internal time (time spent in the function exclusively, not in its descendents).  <i>In every run</i>, the same two functions appeared at the top of the list:  <span><span face="Courier New">posix.waitpid</span></span> and <span><span face="Courier New">posix.fork</span></span>.  To be honest this was a surprise to me ‚Äî previously I believed the problem was in SCons‚Äô Taskmaster implementation.  But I can‚Äôt really argue with the data.  It makes sense that SCons would spend most of its time running and waiting for child processes to execute, and even that the amount of time spent in these functions would increase as the number of child processes increases.  But look at the growth in runtimes in these two functions:</p>
<p>
<a href="https://emelski.files.wordpress.com/2013/12/scons_profiler.png"><img data-attachment-id="1041" data-permalink="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/scons_profiler/#main" data-orig-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png" data-orig-size="500,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="SCons full build function time, top two functions" data-image-description="" data-medium-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=300" data-large-file="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=500" src="https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=640&amp;h=640" alt="SCons full build function time, top two functions - click for full size" srcset="https://emelski.files.wordpress.com/2013/12/scons_profiler.png 500w, https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=150&amp;h=150 150w, https://emelski.files.wordpress.com/2013/12/scons_profiler.png?w=300&amp;h=300 300w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>
Like the overall build time, these curves are obviously non-linear.  Armed with this knowledge, I went back to Dirk‚Äôs profiling data.  To my surprise, <i>posix.waitpid and posix.fork don‚Äôt even appear in Dirk‚Äôs data</i>.  On closer inspection, his data seems to include only a subset of all functions ‚Äî about 600 functions, whereas <a href="https://github.com/emelski/scons_bench/blob/master/logs/2.3.0_profiling/001/20000.prof">my profiling data</a> contains more than 1,500.  I cannot explain this ‚Äî perhaps Dirk filtered the results to exclude functions that are part of the Python library, assuming that the problem must be in SCons‚Äô own code rather than in the library on which it is built.</p>
<p>
This demonstrates a second fundamental principle of performance analysis:  make sure that you consider <i>all</i> the data.  Programmers‚Äô intuition about performance problems is notoriously bad ‚Äî even mine! ‚Äî which is why it‚Äôs important to measure before acting.  But measuring won‚Äôt help if you‚Äôre missing critical data or if you discard part of the data before doing any analysis.</p>
<h3>Conclusions</h3>
<p>
On the surface, performance analysis seems like it should be simple:  start a timer, run some code, stop the timer.  Done correctly, performance analysis can illuminate the dark corners of your application‚Äôs performance.  Done incorrectly ‚Äî and there are <i>many</i> ways to do it incorrectly ‚Äî it can lead you on a wild goose chase and cause you to squander resources fixing the wrong problems.</p>
<p>
Dirk Baechle had good intentions when he set out to analyze SCons performance, but he made some mistakes in his process that led him to an erroneous conclusion.  First, he didn‚Äôt run enough ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/">https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/</a></em></p>]]>
            </description>
            <link>https://blog.melski.net/2013/12/11/update-scons-is-still-really-slow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530845</guid>
            <pubDate>Sat, 19 Sep 2020 22:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculus in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530760">thread link</a>) | @Lukas1994
<br/>
September 19, 2020 | https://www.causal.app/blog/calculus-in-saas | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/calculus-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a>‚Äç</p><p>I have been studying the SaaS model in depth for almost 7 years now. Since the day <a href="https://alexoppenheimer.substack.com/p/harry-2d5d1af6bf">Harry Weller</a> walked into my office with a stack of materials and told me to study it and then SaaS build models and bring them to portfolio companies, I don't think a day has gone by where I have not thought about the conceptual and operational nuances of the recurring revenue business model.</p><p>Somewhere around mid 2015 I had my "aha" moment in my research when I tied my academic training in mechanical engineering to the startup business models I was building: it's all calculus. The integral-derivative relationship applies incredibly well to the ARR and Recognized Revenue relationship. Making this connection between engineering math and financial math gave me a feeling that only a true nerd could appreciate: the joy of putting integral symbols and accounting terms on the same slide.</p><p>The simplest way to illustrate this mathematical parallel is with a car:</p><figure id="w-node-2abd43418357-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b33c9e3271323643b3d_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F42d5ef92-52d9-49fe-8be7-16028bee1ff4_884x306.png" alt=""></p></figure><p>If a car is moving at 60mph, then in one hour it will travel 60 miles (assuming its speed does not change). That is the definition of "miles per hour." ARR is very similar: if a company is "moving" at $10M ARR, then in one year it will recognize $10M of revenue (assuming everything stays consistent). Recognized revenue is the distance, ARR is the speed. It's critical to recognize that ARR is a rate at a specific point in time used to imply something (here, expected recognized revenue in the future period).</p><p>For the more accounting oriented, another analogy can be made to the balance sheet:</p><figure id="w-node-9fc87f218c80-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b3392b0138c4e64006b_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F6c06ddcc-de3e-4d96-960a-22b4b39e334e_842x455.png" alt=""></p></figure><p>While revenue is the top line metric on the income statement, ARR works more like a balance sheet metric: it is taken at a single point in time rather than over a period of time. This can make income statements confusing and misaligned - another example of the divergence of accounting in economics in subscription businesses.</p><p>Now back to calculus... if the ARR function was actually a mathematical equation, you could integrate it. If y = 10x where y = ARR and x = time in months, then after two months ARR = $20. After 12 months, ARR = $120 (assuming we start from $0 of ARR). So at the end of a year, the business has grown from $0 to $120 in ARR. But what is the recognized revenue? The complex answer is that it's the integral of 10x from 0 to 12 months. (Apologies in advance if this triggers a high school calculus flashback.)</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b337d3c7911d7362b81_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Ff7fcb57f-644b-490c-bfa8-6d0c986d2fda_305x80.png" alt=""></p></figure><p>You could also chart this out and see that it is a right triangle with the area of 1/2*base*height. Where the base is 12 months and the height is $120: $1,440/2 = $720).</p><p>Pretty cool relationship and calculation conceptually, but in real businesses ARR growth doesn't fit a simple equation (or any equation at all), so it's not inherently practical to start breaking out the power rule and your old textbooks to predict ARR growth.</p><p>If we switch back to the car analogy, it takes on a little more of a nuanced meaning. Just like a business doesn't grow on a smooth curve, car speeds do not either. Just like the gas pedal makes the car go faster and the brake pedal &amp; friction make it go slower, so too in a SaaS company, <a href="https://alexoppenheimer.substack.com/p/thin-slicing-arr">the new sales are making the speed/ARR increase and the churned customers are making the speed/ARR decrease</a>. I will dive into more details in later posts, but the goal in a car is to go as far and fast as you can while burning the least amount of fuel. So too in a SaaS company, the goal is to have the highest ARR you can, recognize the most revenue and burn the least cash. You can think about SaaS Magic Number like the fuel efficiency of a SaaS business - looking forward to diving into why this is actually helpful in building a company.</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/calculus-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530760</guid>
            <pubDate>Sat, 19 Sep 2020 22:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bevy 0.2]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24530698">thread link</a>) | @_cart
<br/>
September 19, 2020 | https://bevyengine.org/news/bevy-0-2/ | <a href="https://web.archive.org/web/*/https://bevyengine.org/news/bevy-0-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://bevyengine.org/news/bevy-0-2/matching_squares.png"></p>
      
    
  </div><div><p>A month after the initial Bevy release, and thanks to <strong>87</strong> contributors, <strong>174</strong> pull requests, and our <a href="https://github.com/sponsors/cart"><strong>generous sponsors</strong></a>, I'm happy to announce the <strong>Bevy 0.2</strong> release on <a href="https://crates.io/crates/bevy">crates.io</a>!</p>
<p>For those who don't know, Bevy is a refreshingly simple data-driven game engine built in Rust. You can check out <a href="https://bevyengine.org/learn/book/getting-started/">Quick Start Guide</a> to get started. Bevy is also free and open source forever! You can grab the full <a href="https://github.com/bevyengine/bevy">source code</a> on GitHub.</p>
<p>Here are some of the highlights from this release:</p>
<h2 id="async-task-system">Async Task System</h2>

<p>Bevy uses multi-threading throughout the engine: ECS scheduling, asset loading, rendering, etc. Before this release it used <a href="https://github.com/rayon-rs/rayon">Rayon</a> for almost all of these tasks. Rayon is nice because it is generally as simple as calling <code>some_list.par_iter().for_each(|x| do_something(x))</code>. Rayon then automatically breaks the <code>for_each</code> into tasks and runs them on as many cores as it can. Rayon is a great choice if you want to easily parallelize code, but it has the downside of being pretty cpu-hungry.</p>
<p>Bevy (and a number of other rust game engines and ecs frameworks using rayon) have received feedback that they were overly cpu hungry / usage was not proportional to "real" work done.</p>
<p>We decided to resolve this problem by building a custom async-friendly task system, which enables the creation of context-specific task pools. For example, you might have separate pools for compute, IO, networking, etc. This also gives us the flexibility to load balance work appropriately according to work type and/or priority. The cpu usage wins have been huge:</p>
<h3 id="total-combined-percent-cpu-usage-8-core-machine-smaller-is-better">Total Combined Percent CPU Usage - 8 Core Machine (smaller is better)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy_tasks_1.svg" alt="threading cpu usage 8 core"></p>
<h3 id="total-combined-percent-cpu-usage-32-core-machine-smaller-is-better">Total Combined Percent CPU Usage - 32 Core Machine (smaller is better)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy_tasks_2.svg" alt="threading cpu usage 32 core"></p>
<h2 id="initial-web-platform-support">Initial Web Platform Support</h2>
<p>authors: @smokku</p>
<p>(A subset of) Bevy now runs on the web using WebAssembly/WASM! Specifically, Bevy apps can run Bevy ECS schedules, react to input events, create an empty canvas (using winit), and a few other things. This is a huge first step, but it is important to call out that there are still a number of missing pieces, such as 2D/3D rendering, multi-threading, and sound. </p>
<p>Those limitations haven't stopped @mrk-its from building the first WASM Bevy game!</p>
<h3 id="bevy-robbo-playable-here"><a href="https://github.com/mrk-its/bevy-robbo">bevy-robbo</a> (<a href="https://s3.eu-central-1.amazonaws.com/mrk-public/bevy-robbo/index.html">playable here</a>)</h3>
<p><img src="https://bevyengine.org/news/bevy-0-2/bevy-robbo.png" alt="bevy-robbo"></p>
<p>They use Bevy for game logic and cleverly work around the render limitations by passing ASCII art game state from <a href="https://github.com/mrk-its/bevy-robbo/blob/master/src/systems/js_render.rs">this Bevy system</a> to <a href="https://github.com/mrk-its/bevy-robbo/blob/master/assets/render.js">this JavaScript function</a>. </p>
<p>You can play around with some Bevy WASM examples by <a href="https://github.com/bevyengine/bevy/tree/master/examples#wasm">following the instructions here</a>.</p>
<h2 id="parallel-queries">Parallel Queries</h2>
<p>authors: @GrantMoyer</p>
<p>Bevy ECS Queries are a flexible way to retrieve data from the Entity Component System. Systems that <em>use</em> queries already run in parallel, but before this change the queries themselves could not be <em>iterated</em> in parallel. <strong>Bevy 0.2</strong> adds the ability to easily iterate queries in parallel:</p>
<pre><code><span>fn </span><span>system</span><span>(</span><span>pool</span><span>: </span><span>Res</span><span>&lt;</span><span>ComputeTaskPool</span><span>&gt;</span><span>, </span><span>mut </span><span>query</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> Transform</span><span>&gt;) {</span><span>
    query</span><span>.</span><span>iter</span><span>().</span><span>par_iter</span><span>(</span><span>32</span><span>).</span><span>for_each</span><span>(&amp;</span><span>pool</span><span>, |</span><span>mut </span><span>transform</span><span>| {</span><span>
      transform</span><span>.</span><span>translate</span><span>(</span><span>Vec3</span><span>::</span><span>new</span><span>(</span><span>1.0</span><span>, </span><span>0.0</span><span>, </span><span>0.0</span><span>));
    });
}
</span></code></pre>
<p>This provides a nice functional api (similar to Rayon) that runs on top of the new <code>bevy_tasks</code> system. It breaks the query up into 32 "batches" and runs each batch as a different task in the bevy task system. </p>
<h2 id="transform-system-rewrite">Transform System Rewrite</h2>
<p>authors: @MarekLg</p>
<pre><code><span>// old
</span><span>fn </span><span>system</span><span>(</span><span>translation</span><span>: &amp;</span><span>Translation, </span><span>rotation</span><span>: &amp;</span><span>Rotation, </span><span>scale</span><span>: &amp;</span><span>Scale</span><span>) {
  </span><span>println!</span><span>("</span><span>{} {} {}</span><span>",</span><span> translation</span><span>.</span><span>0</span><span>,</span><span> rotation</span><span>.</span><span>0</span><span>,</span><span> scale</span><span>.</span><span>0</span><span>);
}

</span><span>// new
</span><span>fn </span><span>system</span><span>(</span><span>transform</span><span>: &amp;</span><span>Transform</span><span>) {
  </span><span>println!</span><span>("</span><span>{} {} {}</span><span>",</span><span> transform</span><span>.</span><span>translation</span><span>(),</span><span> transform</span><span>.</span><span>rotation</span><span>(),</span><span> transform</span><span>.</span><span>scale</span><span>());
}
</span></code></pre>
<p>Bevy's old transform system used separate <code>Translation</code>, <code>Rotation</code>, and <code>Scale</code> components as the "source of truth". Users modified with these components in their systems, after which they were synced to a <code>LocalTransform</code> component, which was in turn synced to a global <code>Transform</code> component, taking hierarchy into account. This was nice for a couple of reasons:</p>
<ul>
<li>Slightly more cache efficient to retrieve individual components like <code>Translation</code> (because less data needs to be accessed)</li>
<li>Theoretically more parallel-friendly. Systems that only access <code>Translation</code> won't block systems accessing <code>Rotation</code>.</li>
</ul>
<p>However this approach also has some pretty serious downsides:</p>
<ul>
<li>The "individual components" are the source of truth, so <code>LocalTransform</code> is out of date when user systems are running. If an up to date "full transform" is needed, it must be manually constructed by accessing all three components.</li>
<li>Very hard to reason about. There are 5 components users need to think about and they all interact with each other differently.</li>
<li>Setting a Transform to a specific matrix value (ex: <code>Mat4::look_at()</code>) was extremely cumbersome, and the value would be immediately overwritten unless the user explicitly disabled component syncing.</li>
</ul>
<p>Given these issues, we decided to move to a single unified local-to-parent <code>Transform</code> component as the source of truth, and a computed <code>GlobalTransform</code> component for world-space transforms. We think this api will be much easier to use and to reason about. <a href="https://gist.github.com/joeante/79d25ec3a0e86436e53eb74f3ac82c0c">Unity is also considering a similar Transform rework for their ECS</a> and a lot of discussion on this topic happened in this <a href="https://community.amethyst.rs/t/legion-transform-design-discussion">Amethyst Forum Thread</a>.</p>
<h2 id="joystick-gamepad-input">Joystick/Gamepad Input</h2>
<p>authors: @simpuid</p>
<p>The Bevy Input plugin now has cross-platform support for most controllers thanks to the <a href="https://gitlab.com/gilrs-project/gilrs">gilrs</a> library!</p>
<pre><code><span>fn </span><span>button_system</span><span>(</span><span>gamepads</span><span>: </span><span>Res</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>Gamepad</span><span>&gt;&gt;</span><span>, </span><span>button_input</span><span>: </span><span>Res</span><span>&lt;</span><span>Input</span><span>&lt;</span><span>GamepadButton</span><span>&gt;&gt;) {
    </span><span>for</span><span> gamepad </span><span>in</span><span> gamepads</span><span>.</span><span>iter</span><span>() {
        </span><span>if</span><span> button_input</span><span>.</span><span>just_pressed</span><span>(</span><span>GamepadButton</span><span>(*</span><span>gamepad</span><span>, </span><span>GamepadButtonType</span><span>::</span><span>RightTrigger</span><span>)) {
            </span><span>println!</span><span>("</span><span>Pressed right trigger!</span><span>");
        }
    }
}
</span></code></pre><h2 id="bevy-ecs-performance-improvements">Bevy ECS Performance Improvements</h2>
<p>authors: @cart</p>
<h3 id="generational-entity-ids">Generational Entity IDs</h3>
<p>We changed Entity IDs from being random UUIDs to incrementing generational indices. Random UUIDs were nice because they could be created anywhere, were unique across game runs, and could be safely persisted to files or reused across networks. I was really hoping we could make them work, but they ended up being too slow relative to the alternatives. The randomness had a measurable cost and entity locations had to be looked up using a hash map.</p>
<p>By moving to generational indices (we use the hecs implementation), we can directly use entity ids as array indices, which makes entity location lookups lightning fast.</p>
<h3 id="read-only-queries">Read Only Queries</h3>
<p>I implemented "read only" traits for queries that don't mutate anything. This allows us to guarantee that a query won't mutate anything.</p>
<h3 id="removed-locking-from-world-apis">Removed locking from World apis</h3>
<p>This gives us a really nice speed boost. We can do this safely due to a combination of the new "read only queries" and changing World mutation apis to be a mutable World borrow.</p>
<p>This is not yet enabled for <code>Queries</code> in systems because a system could have multiple <code>Queries</code>, which could be simultaneously accessed in a way that doesn't make mutable access unique. I think thats a solve-able problem, but it will take a bit more work. Fortunately "for-each" systems don't have any collision risk, so we now use lock-less queries there.</p>
<h3 id="direct-component-lookup-in-nanoseconds-smaller-is-better">Direct component lookup (in nanoseconds, smaller is better)</h3>
<p>As a result of these optimizations, direct component lookup is <em>much</em> faster than it used to be:</p>
<p><img src="https://bevyengine.org/news/bevy-0-2/get_component.svg" alt="get_component graph"></p>
<p>Note that this benchmark used <code>world.get::&lt;T&gt;(entity)</code>. <code>query.get::&lt;T&gt;(entity)</code> should have results similar to the <code>hecs</code> results because it still uses a lock. Eventually I'm hoping that we can remove locks from system queries too.</p>
<h2 id="change-log">Change Log</h2>
<h3 id="added">Added</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/384">Task System for Bevy</a>
<ul>
<li>Replaces rayon with a custom designed task system that consists of several "TaskPools".</li>
<li>Exports <code>IOTaskPool</code>, <code>ComputePool</code>, and <code>AsyncComputePool</code> in <code>bevy_tasks</code> crate.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/292">Parallel queries for distributing work over with the <code>ParallelIterator</code> trait.</a>
<ul>
<li>e.g. <code>query.iter().par_iter(batch_size).for_each(/* ... */)</code></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/280">Added gamepad support using Gilrs</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/503">Implement WASM support for bevy_winit</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/506">Create winit canvas under WebAssembly</a> </li>
<li><a href="https://github.com/bevyengine/bevy/pull/496">Implement single threaded task scheduler for WebAssembly</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/271">Support for binary glTF (.glb).</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/358">Support for <code>Or</code> in ECS queries.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/339">Added methods <code>unload()</code> and <code>unload_sync()</code> on <code>SceneSpawner</code> for unloading scenes.</a>.</li>
<li><a href="https://github.com/bevyengine/bevy/pull/145">Custom rodio source for audio.</a>
<ul>
<li><code>AudioOuput</code> is now able to play anything <code>Decodable</code>.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/362"><code>Color::hex</code></a> for creating <code>Color</code> from string hex values.
<ul>
<li>Accepts the forms RGB, RGBA, RRGGBB, and RRGGBBAA.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/381"><code>Color::rgb_u8</code> and <code>Color::rgba_u8</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/396">Added <code>bevy_render::pass::ClearColor</code> to prelude.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/430"><code>SpriteResizeMode</code> may choose how <code>Sprite</code> resizing should be handled. <code>Automatic</code> by default.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/428">Added methods on <code>Input&lt;T&gt;</code></a> for iterator access to keys.
<ul>
<li><code>get_pressed()</code>, <code>get_just_pressed()</code>, <code>get_just_released()</code></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/270">Derived <code>Copy</code> for <code>MouseScrollUnit</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/390">Derived <code>Clone</code> for UI component bundles.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/332">Some examples of documentation</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/451">Update docs for Updated, Changed and Mutated</a></li>
<li>Tips for faster builds on macOS: <a href="https://github.com/bevyengine/bevy/pull/312">#312</a>, <a href="https://github.com/bevyengine/bevy/pull/314">#314</a>, <a href="https://github.com/bevyengine/bevy/pull/433">#433</a></li>
<li>Added and documented cargo features
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/249">Created document <code>docs/cargo_features.md</code>.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/249">Added features for x11 and wayland display servers.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/363">and added a feature to disable libloading.</a> (helpful for WASM support)</li>
</ul>
</li>
<li>Added more instructions for Linux dependencies
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/275">Arch / Manjaro</a>, <a href="https://github.com/bevyengine/bevy/pull/290">NixOS</a>, <a href="https://github.com/bevyengine/bevy/pull/463">Ubuntu</a> and <a href="https://github.com/bevyengine/bevy/pull/331">Solus</a></li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/491">Provide shell.nix for easier compiling with nix-shell</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/505">Add <code>AppBuilder::add_startup_stage_|before/after</code></a></li>
</ul>
<h3 id="changed">Changed</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/374">Transform rewrite</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/504">Use generational entity ids and other optimizations</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/417">Optimize transform systems to only run on changes.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/323">Send an AssetEvent when modifying using <code>get_id_mut</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/332">Rename <code>Assets::get_id_mut</code> -&gt; <code>Assets::get_with_id_mut</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/183">Support multiline text in <code>DrawableText</code></a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/324">iOS: use shaderc-rs for glsl to spirv compilation</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/304">Changed the default node size to Auto instead of Undefined to match the Stretch implementation.</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/478">Load assets from root path when loading directly</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/485">Add <code>render</code> feature</a>, which makes the entire render pipeline optional.</li>
</ul>
<h3 id="fixed">Fixed</h3>
<ul>
<li><a href="https://github.com/bevyengine/bevy/pull/361">Properly track added and removed RenderResources in RenderResourcesNode.</a>
<ul>
<li>Fixes issues where entities vanished or changed color when new entities were spawned/despawned.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/385">Fixed sprite clipping at same depth</a>
<ul>
<li>Transparent sprites should no longer clip.</li>
</ul>
</li>
<li><a href="https://github.com/bevyengine/bevy/pull/345">Check asset path existence</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/376">Fixed deadlock in hot asset reloading</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/394">Fixed hot asset reloading on Windows</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/406">Allow glTFs to be loaded that don't have uvs and normals</a></li>
<li><a href="https://github.com/bevyengine/bevy/pull/383">Fixed archetypes_generation being ‚Ä¶</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bevyengine.org/news/bevy-0-2/">https://bevyengine.org/news/bevy-0-2/</a></em></p>]]>
            </description>
            <link>https://bevyengine.org/news/bevy-0-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530698</guid>
            <pubDate>Sat, 19 Sep 2020 22:21:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Provisioning an App Service on Azure Using Terraform with AzureDevOps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530366">thread link</a>) | @lokethien
<br/>
September 19, 2020 | https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/ | <a href="https://web.archive.org/web/*/https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>
  
  <div><p>Part of a good DevOps routine is to have the infrastructure as code. This way you can utilize a high level of control with source control. You can also effortlessly spin up another identical environment.</p>

<h2 id="terraform">Terraform</h2>

<p>If you have a sizable project that has a lot of resources or a DevOps enthusiast, it may be smart to keep it in source control.</p>

<p>Terraform is Hashicorp‚Äôs solution for <em>IaC</em>. The configuration language of choice is HcL (Hashicorp configuration language). Please do not fear learning a new language. HcL is highly enjoyable and simple to learn. It‚Äôs also multi-cloud so you can learn Terraform once and use it to provision resources on AWS, Azure, and Google Cloud.</p>

<p>The Azure provider is relatively mature and it‚Äôs in constant development. It‚Äôs open-source so if you are having issues, you can always create an issue on their repository. If you absolutely cannot do what you want to do using Terraform, you could always use ARM templates in Terraform or even CLI commands. So let‚Äôs go through the tutorial of using it in Azure with CI/CD using Azure DevOps.</p>

<h2 id="recipe">Recipe</h2>

<h3 id="1-install-terraform-extension">1. Install Terraform extension</h3>

<p>In this tutorial, I will use an extension to AzureDevOps that will enable us to run Terraform in our build pipeline. Get it <a href="https://marketplace.visualstudio.com/items?itemName=ms-devlabs.custom-terraform-tasks">here</a> and install it in your organization.</p>

<h3 id="2-create-project-on-azuredevops">2. Create project on AzureDevOps</h3>

<p>Before you start creating a pipeline, you should have a project ready on AzureDevOps. Remember that the service <code>Pipelines</code> needs to be on (can be turned on in settings -&gt; overview) and <code>Repos</code> as well.</p>

<p>After that, you should create a repository and clone it to your desktop. Since the pipeline will include two stages; develop and master, it is smart to create a branch <code>develop</code> out from <code>master</code>.</p>

<h3 id="3-set-up-a-service-connection">3. Set-up a service connection</h3>

<p>A service connection enables you to hook-up the AzureDevOps project to the magical fairy-cloud of Azure. Create it by going to <code>Project settings</code> ‚Üí <code>Service connections</code> and hit new service connection from the top right corner. There you select <code>Azure Resource Manager</code> and then you can use <code>Service principal (automatic)</code> as the authentication method.</p>

<p><img src="https://www.andreasrein.net/images/06-app-service-terraform/azure-devops-service-connection.png"></p>

<p>You then select the scope but remember that if you want Terraform to be able to create resource groups, you should leave the <code>Resource group</code> select as unselected. Pick a short and sweet name, create and you are good to go. I distinguish between the development environment and the production environment in this tutorial and, you should preferably do that too. If you do so, you can use two different subscriptions.</p>

<h3 id="4-install-terraform">4. Install Terraform</h3>

<p>Download Terraform <a href="https://www.terraform.io/downloads.html">here</a>, zip it out and put it somewhere on your disk. Remember to add it to your system‚Äôs <code>PATH</code>.</p>

<h3 id="5-write-infrastructure-code">5. Write infrastructure code</h3>

<p>The fun begins after you have successfully installed Terraform. You can finally start writing deliberate infrastructure code in HcL so warm your fingers up and let‚Äôs start by getting your editor ready. If you are using Visual Studio Code, I highly recommend the excellent plugin <a href="https://marketplace.visualstudio.com/items?itemName=mauve.terraform">Terraform</a>.</p>

<p>So create these files:</p>

<ul>
<li>variables.tf</li>
<li>variables/dev.tfvars</li>
<li>variables/prod.tfvars</li>
<li>main.tf</li>
</ul>

<p><em>Terraform can be highly modular but for the purpose of this guide, I have decided to keep it as simple as possible.</em></p>

<h4 id="variables-tf">variables.tf</h4>

<p><code>variables.tf</code> is the home of all the variables but not the values themselves. The values can be found in the environment specific .tfvars files.</p>

<pre><code># General
variable "resource_group_name" {
  description = "The name of the resource group"
}

variable "location" {
  description = "The Azure region in which all resources should be created"
}

# App Service
variable "app_service_plan_name" {
  description = "The name of the app service plan for the backend"
}

variable "app_service_name" {
  description = "The name of the app service for the backend"
}

# Application Insights
variable "application_insights_name" {
  description = "The name of the application insights resource"
}
</code></pre>

<h4 id="variables-dev-tfvars">variables/dev.tfvars</h4>

<p><code>variables/</code> is the folder with the environment specific variable values. The example uses an homegrown Azure resources naming convention. Go with what you like as long as you keep it consistent.</p>

<pre><code>resource_group_name                       = "rg-terraform-dev"
location                                  = "West Europe"
app_service_plan_name_backend             = "azappp-terraform-dev"
app_service_name_backend                  = "azapp-terraform-dev"
application_insights_name                 = "appi-terraform-dev"
</code></pre>

<h4 id="variables-prod-tfvars">variables/prod.tfvars</h4>

<pre><code>resource_group_name                       = "rg-terraform-prod"
location                                  = "West Europe"
app_service_plan_name_backend             = "azappp-terraform-prod"
app_service_name_backend                  = "azapp-terraform-prod"
application_insights_name                 = "appi-terraform-prod"
</code></pre>

<h4 id="main-tf">main.tf</h4>

<p><code>main.tf</code> is where the infrastructure code resides. The Azure Provider is well documented and it can be found <a href="https://www.terraform.io/docs/providers/azurerm/">here</a>.</p>

<pre><code>/*
* Provider block defines which provider they require
*/

provider "azurerm" {
  version = "=2.26.0"
  features {}
}

terraform {
  backend "azurerm" {}
}

/*
* Resource Group
*/
resource "azurerm_resource_group" "this" {
  name     = var.resource_group_name
  location = var.location
}

/*
* App Service Plan
*/
resource "azurerm_app_service_plan" "this" {
  name                = var.app_service_plan_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  kind                = "Windows"

  sku {
    tier = "Standard"
    size = "S1"
  }
}

/*
* App Service
*/
resource "azurerm_app_service" "this" {
  name                = var.app_service_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  app_service_plan_id = azurerm_app_service_plan.this.id

  site_config {
    websockets_enabled = true
  }

  app_settings = {
    "APPINSIGHTS_INSTRUMENTATIONKEY"      = "${azurerm_application_insights.this.instrumentation_key}"
    "APPINSIGHTS_PORTALINFO"              = "ASP.NET"
    "APPINSIGHTS_PROFILERFEATURE_VERSION" = "1.0.0"
    "WEBSITE_HTTPLOGGING_RETENTION_DAYS"  = "35"
  }
}

/*
* Application Insights
*/
resource "azurerm_application_insights" "this" {
  name                = var.application_insights_name
  location            = azurerm_resource_group.this.location
  resource_group_name = azurerm_resource_group.this.name
  application_type    = "web"
}
</code></pre>

<h3 id="6-create-storage-account-for-state-files">6. Create storage account for state files</h3>

<p>Terraform relies on a state file so it can know what has been done and so forth. The Terraform extension will use a storage account in Azure that we define. So go to your Azure portal and create these resources or use your existing ones.</p>

<ul>
<li>Resource Group: rg-terraform-demo</li>
<li>Storage Account: stterraformdemo</li>
<li>Storage Container: terraform</li>
</ul>

<p>The resource naming is completely optional since they are inside the azure-pipelines.yml file. Remember to double-check the state file resources in <code>azure-pipelines.yml</code>.</p>

<h3 id="7-write-build-pipeline">7. Write build pipeline</h3>

<p>The infrastructure is defined and ready to be deployed on Azure but before we can do that, we would have to define the AzureDevOps build pipeline.</p>

<p>In this example, I will use a deployment template so we can keep it clean in the main azure-pipelines file and reuse it later.</p>

<p>So create these files:</p>

<ul>
<li>azure-pipelines.yml</li>
<li>azure-pipelines-deployment-template.yml</li>
</ul>

<h4 id="azure-pipelines-yml">azure-pipelines.yml</h4>

<p>The two stages, <code>DeployDev</code> and <code>DeployProd</code> is identical apart from the variables passed in the template and that the <code>DeployProd</code> only triggers from the <code>master</code> branch.</p>

<pre><code># Set how the build pipeline triggers
trigger:
  branches:
    include:
      - develop
      - master

# Just say its gonna trigger on pull requests too
pr:
  branches:
    include:
      - develop
      - master

variables:
  # Name of the pipeline. Defaults to the AzureDevOps project name but it can be changed.
  - name: pipelineName
    value: TerraformDemo
  # Name of the resource group where the state file lies
  - name: tfStateRgName
    value: rg-terraform-demo
  # Name of the storage account for the state file
  - name: tfStateStName
    value: stterraformdemo
  # Name of the container for the state file
  - name: tfStateCtrName
    value: terraform

stages:
- stage: DeployDev
  displayName: Deploy Dev
  jobs:
  - template: azure-pipelines-deployment-template.yml
    parameters:
      environment: 'Dev'
      pipelineName: ${{variables.pipelineName}}
      backendServiceName: AzureDev
      tfStateRgName: ${{variables.tfStateRgName}}
      tfStateStName: ${{variables.tfStateStName}}
      tfStateCtrName: ${{variables.tfStateCtrName}}

- stage: DeployProd
  displayName: Deploy Prod
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))
  jobs:
  - template: azure-pipelines-deployment-template.yml
    parameters:
      environment: 'Prod'
      pipelineName: '${{variables.pipelineName}}'
      backendServiceName: AzureProd
      tfStateRgName: '${{variables.tfStateRgName}}'
      tfStateStName: '${{variables.tfStateStName}}'
      tfStateCtrName: '${{variables.tfStateCtrName}}'
</code></pre>

<h4 id="azure-pipelines-deployment-template-yml">azure-pipelines-deployment-template.yml</h4>

<pre><code>parameters:
- name: 'environment'
  type: 'string'
  displayName: 'The name of the environment'

- name: 'pipelineName'
  type: 'string'
  displayName: 'The name of the pipeline'

- name: 'backendServiceName'
  type: 'string'
  displayName: 'The name of the backend service'

- name: 'tfStateRgName'
  type: 'string'
  displayName: 'The name of the az resource group where the tf state file should be'

- name: 'tfStateStName'
  type: 'string'
  displayName: 'The name of the az storage account where the tf state file should be'

- name: 'tfStateCtrName'
  type: 'string'
  displayName: 'The name of the az storage account container where the tf state should be'

jobs:
  - job: Deploy
    displayName: Deploy ${{parameters.environment}}
    continueOnError: false
    pool:
      name: 'Azure Pipelines'
      vmImage: 'windows-latest'
    steps:
    - task: ‚Ä¶</code></pre></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/">https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/</a></em></p>]]>
            </description>
            <link>https://www.andreasrein.net/posts/app-service-terraform-azure-azuredevops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530366</guid>
            <pubDate>Sat, 19 Sep 2020 21:16:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My Python Notebook Driven Book on Evolutionary Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24530288">thread link</a>) | @DataCrayon
<br/>
September 19, 2020 | https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<div>

<p>Evolutionary Algorithms (<em>EAs</em>) are a fascinating class of algorithms for meta-heuristic optimisation. There exist many books on the topic of EAs, ranging from their theory to practice. The first book I read on the topic was <em>Genetic algorithms in search, optimization, and machine learning</em> by David E. Goldberg (1989), and to this day I still recommend it to new students in the field.</p>

</div>
</div>
</div><div>

<div>
<p>However, there is a re-occurring difficulty when my students are starting out in the field, <em>"how do I move from theory to practice?"</em>. Most books will have some chapters dedicated to applications of EAs, but what's missing is an up-to-date book dedicated to using modern technology and concepts.</p>
</div>
</div><div>

<div>
<div>
<p>When writing this book, I had to answer some difficult questions:</p>
<ul>
<li>What programming language will my examples be written in?</li>
<li>What software libraries will I use?</li>
<li>How do I structure the chapters and sections, do I lead entirely by example or do I dedicate some parts to the theory?</li>
<li>Do I focus on single-objective EAs or multi-objective EAs?</li>
</ul>
<p>Nevertheless, the decisions had to be made. I selected Python as the programming language simply due to its rise in popularity (in 2019), and this was only a difficult choice because there is a wealth of resources written for MATLAB. Of the resources written in MATLAB, it is a shame to not be able to use PlatEMO, which is a well-maintained open-source platform for Evolutionary Multi-objective Optimisation. In its place, when a software library is needed, I will turn to Platypus, which provides optimisation algorithms and analysis tools for multi-objective optimisation.</p>
<p>For the structure of the chapters and sections, I have decided to lead entirely by example. There will be code to demonstrate every concept used, and I will show how we can implement algorithms from their mathematical representation. In these cases, I will focus on the readability of the implementations rather than their performance.</p>
<p>Finally, I will focus on multi-objective EAs as this represents the majority of real-world problems. However, single-objective EAs will make an appearance to highlight the differences between the two.</p>

</div>
</div>
</div><div>

<div>
<p>Perhaps the most difficult question to answer is <em>where do we start?</em> There is so much to cover, and many potential starting points. For this book, I will start with a definition of objective functions, and illustrate the relationship between what we call the problem space and the objective space. With this approach, I hope there will be a clear understanding of what the various operators within an EA are affecting.</p>
</div>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530288</guid>
            <pubDate>Sat, 19 Sep 2020 21:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can TikTok be banned from US based Android devices?]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24530155">thread link</a>) | @bluegopher
<br/>
September 19, 2020 | https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      Legal questions aside, let's explore the technical possibilities.
    </p><div>

<p>Let‚Äôs be very clear here. I am not a fan of TikTok. I had the misfortune of coming across it when it was still called Musically and I had to explain to a little girl that she, unlike her friends, was not allowed to dance for strangers. That ruined an otherwise perfect evening.</p>

<p>I‚Äôm also not a fan of Donald Trump(et). It‚Äôs safe to assume that he threatens to shut down TikTok for all the wrong reasons, but if he manages to pull through, it will be a benefit for mankind. So, is it actually technically possible to get TikTok and WeChat banned in the US?</p>

<h2 id="removing-apps-from-google-play">Removing apps from Google Play</h2>

<p>Story time (you can skip ahead two paragraphs for an obvious revelation)!</p>

<p>I once wrote a pretty silly slot machine game for Android. It was as a coding exercise and failed in pretty much every aspect except being recognized for what it actually wasn‚Äôt: a real gambling app.
</p><figure>
  <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/pocketbandit.png">
    <img src="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/pocketbandit.png">
  </a>
  
  <figcaption>Pocket Bandit: pretty (, colorful,) boring</figcaption>
  
</figure><p>
                             
                             
All you could do was to bet one to three coins, then pull the lever and watch the reels spin. You started with a fixed amount of credit and the laws of probability dictated that you‚Äôd eventually go bankrupt. Once that happened, you could simply restarted the ‚Äúgame‚Äù and had a full purse again. No <em>wait x hours or pay $$$ to continue playing</em> bullshit. No way of winning anything either. In other words: the most boring one-armed bandit ever. Not even suitable for detoxing a gambling addict. I had somehow managed to put in all the mechanics of a classical slot machine except the one (winning/loosing) that was responsible for producing the excitement.</p>

<p>Well, there‚Äôs no rule that states, you can‚Äôt publish rubbish on Google Play. Much to my surprise though, there is a rule that says, you can‚Äôt publish gambling apps in some Arab countries without governmental approval. So, one fateful morning, I received a mail from Google telling me that my app had been pulled from Play in those countries. I was pissed. Not because the world needed my app. Not because some Arabs were now deprived of the most dull entertainment, only I could provide. I was pissed because someone had obviously only spent the time of looking at the screenshots to determine that this was a gambling app, but hadn‚Äôt bothered to reason how you were suppose to spend (real) money in an app that doesn‚Äôt even request network permission. It felt unjustified. Like a downvote driven in with the banhammer. Someone with the attention span of a puppy had the power of Thor.</p>

<p>There was no point in appealing. After all, the game was crap, but the incident was a nice reminder on how fragile businesses, build on apps are. Somewhere, someone with too little time to be thorough can simply nuke them without prior warning. Needless to say, that in time, the same  kind of sloppiness resulted in more of my apps being pulled ‚Ä¶</p>

<p>So, what‚Äôs the take away from my story?</p>

<p>Geo fencing has always been a core feature of Play and Google never really went out of its way to stand up for developers. Sure, my apps are small fries compared to behemoths like TikTok, but then again, they aren‚Äôt direct competitors to youtube either. Let‚Äôs keep that in mind in case anyone has high hopes for Google putting up a fight.</p>

<h2 id="what-about-sideloading">What about sideloading?</h2>

<p>Who needs Play anyway? Android is not IOS, we can simply download the APK off the web and install it ourselves, right? Eh well, no. It‚Äôs not that simple. Bytedance swallowed Google‚Äôs Cool Aid and switched to App Bundles/Dynamic Delivery in order to reduce the size of their app. So instead of a single, one size fits all APK, you get a bunch of individual files. In case of TikTok v17.6.3 and depending on your device, the list might look like this:</p>

<ul>
<li>com.zhiliaoapp.musically-2021706030.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.armeabi_v7a.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.en.apk</li>
<li>com.zhiliaoapp.musically-2021706030_config.xhdpi.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_creationtool_so.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_creationtool_so.config.armeabi_v7a.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_fusing.apk</li>
<li>com.zhiliaoapp.musically-2021706030_df_photomovie.apk</li>
</ul>

<p>Split APKs cannot be sideloaded (easily). On plain Android, there‚Äôs simply no user interface for telling the packagemanager that you want it to install an app from several connected files (<a href="https://raccoon.onyxbits.de/blog/merge-split-apk/">after all, making sideloading difficult was/is the whole idea behind App Bundles</a>). You need extra tools (e.g. ADB) for that. But let‚Äôs be brutally honest here, if you are in the target audience of TikTok, then you are probably missing a brain cell or two (out of a total of two) and won‚Äôt be able to use them.</p>

<div>
  
  <p><span>Fun fact</span>
  
  
App Bundles have a build in security flaw. Traditional APKs cannot be modified by the Playstore. App Bundles can. For rogue government agencies, this provides the option of pushing hacked app updates to </p><u>selected</u><p> individuals. For that reason, <b>no</b> app in the "communications" category should ever use App Bundles as a distribution format. Imagine that! Coincidentally, Trump was actually right when calling TikTok a security issue. Cheers ByteDance!

</p></div>
                             
                             

<p>So, why doesn‚Äôt ByteDance simply host a traditional APK on the TikTok website then?</p>

<p>Two reasons actually</p>

<ol>
<li>Self hosting your app means, people will download the self hosted version (duh!), even if they could get it from the Playstore. As a result, the Playstore version sees less downloads, less reviews and less ratings which may eventually lead to it spiraling down in the rankings (ever wondered why all youtubers end their videos with the magic mantra ‚Äúlike and subscribe, hit the bell and give me a thumbs up‚Äù? Same mechanic there). This, by the way was the leverage, Google used to monopolize the app store market on Android: you are free to host elsewhere, but if your competitors solely host with us, they will eventually outrank you.</li>
<li>ByteDance not only drank the Google Cool aid, but also coughed it up and swallowed it again. Part of their revenue is in-app purchases. Those don‚Äôt work with sideloaded APKs. They could, of course, implement their own <abbr title="In App Purchase">IAP</abbr>, but that‚Äôs something <a href="https://raccoon.onyxbits.de/blog/2020081401/">Epic tried with Fortnite</a> recently‚Ä¶</li>
</ol>

<h2 id="removing-existing-tiktok-installations-from-devices">Removing existing TikTok installations from devices</h2>

<p>Buckle up, this may come as a surprise or as a confirmation of your fears!</p>

<p>Did you ever notice the big green ‚Äúinstall‚Äù button on the Google Play website? With it, you can conveniently browse the store on your PC and send apps to your phone for installation.</p>

<figure>
  <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/googleplay-tiktok.png">
    <img src="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/googleplay-tiktok.png">
  </a>
  
  <figcaption>Screencap: The install button on the Play website is sort off a remnant from the old days when 320x480 screens where the norm and you'd rather browse the androidmarket (as it was called back then) on your PC.</figcaption>
  
</figure>
                             
                             

<p>This is done via ‚ÄúPush messages‚Äù. Which is just a modern way of saying that your phone wakes up every couple of minutes in order to waste battery and bandwidth on checking if there are any new ads you should see. It also checks if there are any app updates or pending installs (from the green button) while it is at it, just so you have a reason not to disable the <del>spy</del> playstore app when you don‚Äôt need it. The relevant <a href="https://developers.google.com/protocol-buffers/">message structure</a> looks like this:</p>

<div><pre><code data-lang="protobuf"><span>message</span> <span>Notification</span> {<span>
</span><span></span>  <span>optional</span> <span>int32</span> notificationType <span>=</span> <span>1</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> timestamp <span>=</span> <span>3</span>;<span>
</span><span></span>  <span>optional</span> Docid docid <span>=</span> <span>4</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> docTitle <span>=</span> <span>5</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> userEmail <span>=</span> <span>6</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppNotificationData appData <span>=</span> <span>7</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppDeliveryData appDeliveryData <span>=</span> <span>8</span>;<span>
</span><span></span>  <span>optional</span> PurchaseRemovalData purchaseRemovalData <span>=</span> <span>9</span>;<span>
</span><span></span>  <span>optional</span> UserNotificationData userNotificationData <span>=</span> <span>10</span>;<span>
</span><span></span>  <span>//optional InAppNotificationData inAppNotificationData = 11;
</span><span></span>  <span>//optional PurchaseDeclinedData purchaseDeclinedData = 12;
</span><span></span>  <span>optional</span> <span>string</span> notificationId <span>=</span> <span>13</span>;<span>
</span><span></span>  <span>optional</span> LibraryUpdate libraryUpdate <span>=</span> <span>14</span>;<span>
</span><span></span>  <span>optional</span> LibraryDirtyData libraryDirtyData <span>=</span> <span>15</span>;<span>
</span><span></span>}<span>
</span><span>
</span><span></span><span>message</span> <span>AndroidAppDeliveryData</span> {<span>
</span><span></span>  <span>optional</span> <span>int64</span> downloadSize <span>=</span> <span>1</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> signature <span>=</span> <span>2</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> downloadUrl <span>=</span> <span>3</span>;<span>
</span><span></span>  <span>repeated</span> AppFileMetadata additionalFile <span>=</span> <span>4</span>;<span>
</span><span></span>  <span>repeated</span> HttpCookie downloadAuthCookie <span>=</span> <span>5</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> forwardLocked <span>=</span> <span>6</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> refundTimeout <span>=</span> <span>7</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> serverInitiated <span>=</span> <span>8</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> postInstallRefundWindowMillis <span>=</span> <span>9</span>;<span>
</span><span></span>  <span>optional</span> <span>bool</span> immediateStartNeeded <span>=</span> <span>10</span>;<span>
</span><span></span>  <span>optional</span> AndroidAppPatchData patchData <span>=</span> <span>11</span>;<span>
</span><span></span>  <span>optional</span> EncryptionParams encryptionParams <span>=</span> <span>12</span>;<span>
</span><span></span>  <span>optional</span> <span>string</span> gzippedDownloadUrl <span>=</span> <span>13</span>;<span>
</span><span></span>  <span>optional</span> <span>int64</span> gzippedDownloadSize <span>=</span> <span>14</span>;<span>
</span><span></span>  <span>repeated</span> SplitDeliveryData splitDeliveryData <span>=</span> <span>15</span>;<span>
</span><span></span>  <span>optional</span> <span>int32</span> installLocation <span>=</span> <span>16</span>;<span>
</span><span></span>}<span>
</span><span>
</span><span></span><span>message</span> <span>PurchaseRemovalData</span> {<span>
</span><span></span>  <span>optional</span> <span>bool</span> malicious <span>=</span> <span>1</span>;<span>
</span><span></span>}</code></pre></div>

<p>A request to delete an app from a device looks like this:</p>

<div><pre><code data-lang="protobuf">notificationType<span>:</span> <span>2</span><span>
</span><span></span>docid {<span>
</span><span></span>  backendDocId<span>:</span> <span>"com.zhiliaoapp.musically"</span><span>
</span><span></span>}<span>
</span><span></span>purchaseRemovalData {<span>
</span><span></span>  malicious<span>:</span> <span>true</span><span>
</span><span></span>}</code></pre></div>

<p>Note that the malicious flag is purely cosmetic. The only thing Play has to send is the package name of the app and the notificationType 2. The app gets deleted, even if it wasn‚Äôt installed via Play.</p>

<h2 id="blocking-tiktok-in-the-usa">Blocking TikTok in the USA</h2>

<p>Let‚Äôs say you are an existing TikTok user and a US citizen. Let‚Äôs say, after reading the above, you disable the Playstore client, so Google can‚Äôt delete apps from your phone. What are they going to do then? Tell your ISP to firewall the TikTok servers (I heard, China has the tech for that. Maybe they‚Äôll share‚Ä¶)? Well, curiously, there‚Äôs a much simpler solution. Did I already mention that ByteDance drank the Google Coolaid to the last drip? Let‚Äôs use an <a href="https://raccoon.onyxbits.de/">apk downloader</a> to request the <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/com_zhiliaoapp_musically.json">Google Playstore entry for the TikTok app</a>. Here‚Äôs an excerpt:</p>

<div><pre><code data-lang="json"><span>"dependency"</span><span>:</span> [{
          <span>"packageName"</span>: <span>"com.google.android.gms"</span>,
          <span>"minVersionCode"</span>: <span>12451000</span>,
          <span>"skipPermissions"</span>: <span>true</span>,
          <span>"deferredInstallAllowed"</span>: <span>false</span>
        }]</code></pre></div>

<p>The <code>com.google.android.gms</code>package is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/">https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/</a></em></p>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/trump-ban-tiktok-wechat-usa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24530155</guid>
            <pubDate>Sat, 19 Sep 2020 20:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effective ML (and F#)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529774">thread link</a>) | @jasim
<br/>
September 19, 2020 | http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp | <a href="https://web.archive.org/web/*/http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
  <p>
    This is a summary of <a href="http://twitter.com/#!/yminsky">Yaron Minsky</a>'s nine pieces of advice from the <a href="http://vimeo.com/14313378">Effective ML</a> video. Since ML is a predecessor of F#, most of the advice applies to F# as well.
  </p>
  <p>
    <strong>1. Favor readers over writers (10:20)</strong>. There're systematic differences in opinion between those who spent their time reading code and those who spent it writing code. Whenever there's a difference in opinion between these two groups, the readers are always right and the writers are always wrong. The readers will always push in the direction of clarity and simplicity and the ability to change behavior easily. At least if you're building software that's going to last.
  </p>
  <p>
    <strong>2. Create uniform interfaces (12:15)</strong>. Always create an interface to your code to make it easier on the reader. When you build interfaces, you should have standards that apply uniformly across your code base to build solid expectations. Those who use your code should know what to provide and what to expect when interfacing with your codebase.
  </p>
  <p>
    <strong>3. Make illegal states unrepresentable (18:03)</strong>. Use the type system as a tool to enforce invariants on the code you write. Choose your data types such that states that are illegal don't show up as legal states in the program. Take this code representing various connection information as an example. It keeps track of relevant information in a fairly readable manner:
  </p>
  <pre>type connection_state =
  | Connecting
  | Connected
  | Disconnected

type connection_info = {
    state:             connection_state
    server:            IPAddress
    last_ping_time:    DateTime option
    last_ping_id:      int option
    session_id:        string option
    when_initiated:    DateTime option
    when_disconnected: DateTime option
}</pre>
  <p>On the surface these types look reasonable, but there're some tricky invariants that need to hold about the data. For instance, if you have a last_ping_time, you should probably also have a last_ping_id and vice versa. And the session_id and when_initiated probably only makes sense when you're connected. Similarly, when_disconnected only makes sense if you've been disconnected.</p>
  <p>The key is that there's nothing about the types that help you enforce all these invariants. A better approach would be to refactor the connection_info into a series of types where the invariants would be inherent in the types themselves rather than being implicit in the logic surrounding the types:</p>
  <pre>type connecting = { when_initiated: DateTime }
type connected = { last_ping: (DateTime * int) option
                   session_id: string }
type disconnected = { when_connected: DateTime }

type connection_state =
  | Connecting of connecting
  | Connected of connected
  | Disconnected of disconnected

type connection_info = {
    state: connection_state
    server: IPAddress
}</pre>
  <p>server remains in connection_info because it applies to any of the states. The other information have been grouped together with the state it related to. The different connection_states are no longer merely a simple enumerated type but each of the different tags have content. Note also how the last_ping is now both the last_ping_time and last_ping_id. Either both are present, and grouped together, or not.</p>
  <p>
    <strong>4. Code for exhaustiveness (28:33)</strong>. This one is closely related to making illegal states unrepresentable in that you should write your code aiming at exhaustiveness guarantees. For instance, when you have a match statement, the compiler will warn you if the match isn't exhaustive. The key benefit is as a refactoring tool because it guides changes in the code base. Don't use the match all because it means that if you expand on the discriminated union the compiler will not warn you.
  </p>
  <p>
    <strong>5. Open few modules (34:08)</strong>. When you open a module, it makes your code a bit shorter, and that's great for the guy who wrote the code, but not the guy reading it. Now you can no longer just look at the code and tell where the value came from. In F#, with Visual Studio integration and IntelliSense, this is less of a problem. But the key advice is to respect the cognitive limitation of the people reading the code. If you want people to remember something, make them remember only for a short period of time.
  </p>
  <p>
    <strong>6. Make common errors obvious (38:10)</strong>. Use exceptions for exceptional conditions is what people often tell you. But whether something is a common case depends on context. For instance, in one context it's an error if an element isn't in a list, whereas in others it's perfectly acceptable. For your API it may depend on the caller if a case is exceptional or not. To better support the caller, you could create two versions depending on how you want to communicate an error:
  </p>
  <pre>val hd : 'T list -&gt; 'T option
val hd_exn : 'T list -&gt; 'T</pre>
  <p>Now you can tell from the name of the function weather it throws an exception or not. For people reading the code it makes it easier to understand the error behavior of the code.</p>
  <p>
    <strong>7. Avoid boilerplate (40:52)</strong>. Avoid repeating the same code, or almost the same code, in multiple places. Boilerplate appears, in general, because people have a cut and paste template they use to do almost the same thing in multiple spots and because their language isn't good enough to encode what they want to do in a clean way. You want to get rid of boilerplate because the structure you're repeating is there for a reason, and your code evolves. At that point you're not going to remember all the places where the repetition shows up. It also goes back to readability. It's hard to convince people to read code if it's dull. And nothing is duller than boilerplate, even though the code is critical.
  </p>
  <p>Interestingly, reducing boilerplate doesn't always make code less verbose. The goal isn't to make the code shorter but to separate out which parts of the code is the same and which parts vary.</p>
  <p>
    <strong>8. Avoid complex type hackery (45:30)</strong>. The enemy of good code, of correctness, isn't dynamic guarantees, properties about the code that cannot be proved at compile time, but complexity. Refrain from making your code more complex (using <a href="http://mlton.org/PhantomType">phantom types</a>, for instance), just so you can have the type system verify additional properties of the code.
  </p>
  <p>
    <strong>9. Don't be puritanical about purity (47:10)</strong>. Avoiding side-effect is generally worth striving for, because code without side-effects tends to be easier to reason about. But sometimes it's also just easier to code with side-effects. There may even be performance reasons for allowing side-effects so don't be embarrassed about it. In reality, programs don't just compute things, they do things like write files, send messages, and so on. All this doing involves side-effects. Again, remember that the enemy of correctness is complexity. Don't jump through hoops to make your code too complex just to make it pure.
  </p>
</div></div>]]>
            </description>
            <link>http://bugfree.dk/blog/2012/06/24/effective-ml-and-fsharp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529774</guid>
            <pubDate>Sat, 19 Sep 2020 19:17:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Django validate passwords?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529740">thread link</a>) | @rangerranvir
<br/>
September 19, 2020 | https://ranvir.xyz/blog/how-does-django-validate-passwords/ | <a href="https://web.archive.org/web/*/https://ranvir.xyz/blog/how-does-django-validate-passwords/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><img data-src="https://i.ibb.co/n3YzYyF/Main-Images-4-1.png" alt="How does Django validate passwords" title="How does Django validate passwords" src="https://i.ibb.co/n3YzYyF/Main-Images-4-1.png">
</p><p>
A few days ago, I was working on one of my old Django projects. It was running an old version of Django and I wanted to keep it updated with the latest changes of the framework.</p>
<p>
So to check the <a href="https://ranvir.xyz/blog/django-admin-tips-and-tricks/">admin site</a>, I tried to create the superuser after connection to the local database.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>createsuperuser</span>
</code></pre></div></div>

<p>
When I passed a password similar to the username it failed saying, <code>The password is too similar to the username.</code></p>
<p><img data-src="https://i.ibb.co/94D2x9G/Screenshot-2020-09-19-at-1-32-17-AM.png" alt="The password is too similar to the username" title="The password is too similar to the username" src="https://i.ibb.co/94D2x9G/Screenshot-2020-09-19-at-1-32-17-AM.png">
</p><p>
This error triggered me to check the working behind this password validation feature.</p><p>
The first thing that I looked into was the <code>manage.py</code> file itself which in turn was importing and executing a method called, <code>execute_from_command_line</code>.</p><p>
I traced it back and found a package <code>commands</code> containing everything that I wanted to know. This directory had two files.</p>
<div><div><pre><code><span>1.</span> <span>createsuperuser</span><span>.</span><span>py</span>
<span>2.</span> <span>changepassword</span><span>.</span><span>py</span>
</code></pre></div></div>
<h2 id="the-changepassword-command">The changepassword command</h2><p>
Since I had never used/ heard about the <code>changepassword</code> command, I thought of trying it first and to my great pleasure, it worked. You have to pass the username as the first argument.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>changepassword</span> <span>username</span>
</code></pre></div></div>
<p><img data-src="https://i.ibb.co/YRfMkYW/Screenshot-2020-09-19-at-3-10-09-AM.png" alt="python manage.py changepassword" title="python manage.py changepassword" src="https://i.ibb.co/YRfMkYW/Screenshot-2020-09-19-at-3-10-09-AM.png">
</p><p>
Sometimes you find gold when you read the code, right? √∞≈∏ÀúÔøΩ</p><p>
Now let√¢‚Ç¨‚Ñ¢s get back to the business and look into the <code>createsuperuser</code> command class in more detail.</p>
<h2 id="fetching-the-correct-database">Fetching the correct database</h2><p>
If you have been using Django for some time, you would know that Django allows you to change a lot of things depending upon the settings you define.</p><p>
This also includes using some random model as your base User model. This is the first thing that the superuser creation <code>__init__</code> constructor method checks for.</p>
<h2 id="creating-the-superuser-without-interaction">Creating the superuser without interaction</h2><p>
You can use a version of the command that allows you to create the superuser without any interaction.</p>
<div><div><pre><code><span>python</span> <span>manage</span><span>.</span><span>py</span> <span>createsuperuser</span> <span>--</span><span>username</span> <span>ranvir</span> <span>--</span><span>email</span> <span>abc</span><span>@</span><span>abc</span><span>.</span><span>com</span> <span>--</span><span>no</span><span>-</span><span>input</span>
</code></pre></div></div>
<p><img data-src="https://i.ibb.co/LJtHHq5/Screenshot-2020-09-19-at-3-17-49-AM.png" alt="python manage.py createsuperuser no-input" title="python manage.py createsuperuser no-input" src="https://i.ibb.co/LJtHHq5/Screenshot-2020-09-19-at-3-17-49-AM.png">
</p><p>
Although the user created using this process will have no password. We can create the password either using the <code>changepassword</code> command or the admin panel.</p>
<h2 id="required-fields-and-interactive-mode">Required fields and interactive mode</h2><p>
For the default <code>User</code> model, <code>email</code> is the only required field but you can change that by changing your <code>REQUIRED_FIELD</code> setting as well.</p><p>
In the interactive mode( which is the default mode as well), the first thing that the prompt asks you to fill, is the username.</p><p>

Django tries to smartly suggest the current system username as the default username. (Just Wow)</p>
<p><img data-src="https://i.ibb.co/pr1Z1Qw/Screenshot-2020-09-19-at-2-14-46-AM.png" alt="django suggest the current system username" title="django suggest the current system username" src="https://i.ibb.co/pr1Z1Qw/Screenshot-2020-09-19-at-2-14-46-AM.png">
</p><p>
It won√¢‚Ç¨‚Ñ¢t suggest the system username if it is already taken. (That√¢‚Ç¨‚Ñ¢s AI for me √∞≈∏Àú‚Äö)</p>
<p><img data-src="https://i.ibb.co/r3YxbKL/Screenshot-2020-09-19-at-2-15-41-AM.png" alt="django doens't suggest the current system username if already taken" title="django doens't suggest the current system username if already taken" src="https://i.ibb.co/r3YxbKL/Screenshot-2020-09-19-at-2-15-41-AM.png">
</p><p>
After the username, you have to fill in the required field which is the email field for the default User model.</p><p>
Finally, you have to fill in the password field.</p>
<h2 id="the-validate-password-method">The validate password method</h2><p>
Sorry for keeping you waiting this long before jumping onto the real reason behind the post.</p><p>
The <code>validatepassword</code> is the function that is used to validate the password provided by the user.</p><p>
Again, we can configure all these validators as well, if these different password validation doesn√¢‚Ç¨‚Ñ¢t work for you, go forward and remove the classes from your settings file.</p><p>
These are the default validators.</p>
<div><div><pre><code><span>AUTH_PASSWORD_VALIDATORS</span> <span>=</span> <span>[</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.UserAttributeSimilarityValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.MinimumLengthValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.CommonPasswordValidator'</span><span>,</span>
    <span>},</span>
    <span>{</span>
        <span>'NAME'</span><span>:</span> <span>'django.contrib.auth.password_validation.NumericPasswordValidator'</span><span>,</span>
    <span>},</span>
<span>]</span>
</code></pre></div></div><p>
If we use the default validators, then the password,</p>
<ol>
<li>Should not be similar to <code>username</code>, <code>first_name</code>, <code>last_name</code> and <code>email</code>. It also checks for the similarity using <a href="https://docs.python.org/2.4/lib/sequence-matcher.html">SequenceMatcher</a>. It should be less than 0.7 similar which you can customize. (Told you, it√¢‚Ç¨‚Ñ¢s AI)</li>
<li>Should be greater than 8 characters.</li>
<li>Should not be in the list of common passwords. The list of common passwords is in the file, <code>common-passwords.txt.gz</code>. It contains a list of around 20000 common passwords which you should not use.</li>
<li>Should not contain all numeric characters.</li>
</ol><p>
I would suggest keeping the basic configuration intact for the password handling. You can use your own validations on top of it as well.</p><p>
So, that√¢‚Ç¨‚Ñ¢s it for this time. Till next time.</p>
</div></div>]]>
            </description>
            <link>https://ranvir.xyz/blog/how-does-django-validate-passwords/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529740</guid>
            <pubDate>Sat, 19 Sep 2020 19:11:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pachyderm vs. Airflow]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529683">thread link</a>) | @ishcheklein
<br/>
September 19, 2020 | https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/ | <a href="https://web.archive.org/web/*/https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p>If you do a lot of data pipelining, you‚Äôve probably heard a lot about Airflow by now. I gave a talk
about it a while back at a meetup, and wrote a blog post about it. The gist of my pitch for Airflow
was essentially <em>‚ÄúLook, it‚Äôs so much better than cron.‚Äù</em></p>

<p>Fast-forward a year or two, and my team is using Pachyderm now. This post is about why I wanted to try Pachyderm,
what I love about it, some things that can be improved about it, and some of the tricks you‚Äôll need to know if you want to start using it.</p>

<p><em>Note: I am not in any way being paid by Pachyderm.</em></p>

<hr>



<ul>
<li><p>Designed for a machine learning model workflow, but can also handle regular data pipelining
(including cron-style scheduling). This is incredibly reassuring to me, because Airflow is kind of the other way around.</p></li>

<li><p>Scalability (parallelization support). I haven‚Äôt done much with this yet, but it‚Äôs also reassuring to know it‚Äôs there,
since we‚Äôre a rapidly growing company, and I‚Äôm sure our data needs are going to continue to expand.</p></li>

<li><p>Data and code provenance tracking are built-in.</p></li>
</ul>

<p><em>What that means:</em> It‚Äôs easy to figure out what version
 of your code was running at any given time, and on what data. This is critical if you‚Äôre iterating on
 code for ETL processes or models, or tracking a model that‚Äôs going to evolve over time based on what data it has seen.</p>

<ul>
<li>The egress feature and built-in feed-forward are amazingly elegant.<br></li>
</ul>

<p>Feed-forward (I don‚Äôt know what they call it, that‚Äôs just what I call it) means
you can have one pipeline read from the output of another, and trigger off of that directly.</p>

<p>In Airflow, for comparison, you had to configure this with messaging and it was kind of clunky
(and originally there was no push, only pull, so you were always polling for <em>is that thing done yet?</em>).</p>

<p>In Pachyderm, it‚Äôs an extremely simple configuration.</p>

<p>Egress means you don‚Äôt have to write a plugin to do something as basic as push your data to s3. Pachyderm already
knows how to do that for you (see below for an example of how this is specified in a pipeline).</p>

<p>There‚Äôs also an easy way to tell it to re-process as much data as you want (*except for cron inputs, but they‚Äôre
going to fix that).</p>

<ul>
<li>Not having to clean up the fallout from runaway backfills</li>
</ul>

<p>Runaway backfill in Airflow made our server fall down more than once whenever anybody
forgot to update the start date or name of their DAG. This was a built-in default setting that we couldn‚Äôt change,
where Airflow would try to backfill any missing data to the beginning of time
(1970, of course), and celery would get overloaded.</p>

<p>We tried numerous approaches to make it impossible to do this
by accident, including having tests for checking that the start_date for a revised DAG
was always after the date of the latest changes.</p>

<p>It was the bane of my Airflow existence. Clearing the celery cache
and getting it to restart, and then backfill what we <em>actually</em> wanted was always a time-consuming process, including
kicking the web server again and getting everything back online.</p>

<ul>
<li>Smart re-tries by default (and this is configurable).</li>
</ul>

<p>Having retries at all was a big advantage of Airflow over basic cron, especially since it‚Äôs modular, so you can
have different re-try settings for each step of an ETL pipeline.</p>

<p>Having said that, this was a also kind of a pain to deal with in Airflow, because
if somebody set a ridiculous number of retries, or a backfill job was failing,
it could easily become a blocker for unrelated pipelines just by
gunking up the celery queue with tons of re-tries for something that was
 already failing (see above re: runaway backfill).</p>

<p>With Airflow, we were always having to guess about how many
retries to do, and how much back-off to add in between tries.</p>

<p>Pachyderm‚Äôs defaults for this are completely reasonable
(3 retries, with increasing delay in between each try).</p>

<p>If you get the enterprise version (which is cheap for an enterprise product):</p>

<ul>
<li><p>It‚Äôs more secure than Airflow, with built-in encryption (There‚Äôs also no risk of exposing
passwords by printing all the logs to a webpage that anyone can see, the way Airflow did by default.)</p></li>

<li><p>Really responsive and smart team, and a growing community of users</p></li>

<li><p>Nice dashboard to go with the CLI tool</p></li>

<li><p>Finally, if you don‚Äôt like writing DAGs in Airflow, and are considering one of the myriad (!) new tools
to simplify that for you, this is even simpler than that. (And in my opinion, makes a lot more sense.)</p></li>
</ul>

<p>And here‚Äôs an example of a full ETL process with 3 pipeline steps:</p>

<p><strong>1. Get the data from an api</strong></p>

<pre><code>{
    "pipeline": {
       "name": "api_to_s3_pipeline"
    },

    "transform": {
       "cmd": ["python3", "get_requests.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_api_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "cron": {
            "name": "api_daily_job",
            "spec": "16 6 * * *",
            "repo": "api_to_s3"
         }
    },
    "egress": {"URL": "s3://mys3bucket/"},
    "enable_stats": true,
    "job_timeout": 10m
}
</code></pre>

<p><strong>2. Process the data with pyspark on kubernetes</strong></p>

<pre><code>{
    "pipeline": {
       "name": "pyspark_pipeline"
    },

    "transform": {
       "cmd": ["python3", "pyspark_processsing.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_pyspark_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "atom": {
            "name": "pyspark_daily_job",
            "repo": "pyspark_daily_job",
            "glob: "/*/*/*/"
         }
    },
    "egress": {"URL": "s3://my-pyspark-bucket/"},
    "enable_stats": true,
    "job_timeout": 120m
}
</code></pre>

<p><strong>3. Load the data to Redshift</strong></p>

<pre><code>{
    "pipeline": {
       "name": "load_to_redshift_pipeline"
    },

    "transform": {
       "cmd": ["python3", "load_to_redshift.py"],
       "image": "pathto.ecr.region.aws.com/mydockerregistry:my_psycopg2_image_v1",
       "image_pull_secrets": ["regcred"]
    },
    "input":{
        "atom": {
            "name": "daily_load_job",
            "repo": "daily_load_job",
            "glob: "daily_*.gz"
         }
    },
    "enable_stats": true,
    "job_timeout": 125m
}
</code></pre>

<p>Also, they just got Series A funding, so they‚Äôre going to be around for a while.</p>

<hr>



<p>This was my first time using kubernetes, never mind suddenly being in charge of it (!).</p>

<p>Fair warning: Minikube is deceptively easy to set up and use for very basic testing. If this is all you do with
kubernetes, you‚Äôll think Kubernetes very simple.</p>

<p>Kubernetes itself
isn‚Äôt that hard to deploy if you know what needs to be configured, but I really didn‚Äôt
know any of that when I started. I ran into some weird issues where the kubernetes control script
<code>kubectl</code> didn‚Äôt set the permissions correctly on some of the config files. (Shoutout to Sean Jezewski for helping me
troubleshoot unintuitive stuff like that.)</p>

<p>In case you‚Äôre wondering, as did almost everyone I spoke to while I was doing this,
EKS on AWS is not really ready for prime-time yet.</p>

<p>I ended up relying on a script that the Pachyderm guys wrote to deploy Kubernetes
directly on EC2, and just adapted that for our needs.</p>

<p>Things that are great about deploying in the cloud:</p>

<ul>
<li><p>Encapsulation is your friend. It‚Äôs so much easier when you have complete control of the environment, and there‚Äôs no mystery
about what packages are available or what the paths are.</p></li>

<li><p>Scaling becomes relatively easy. Just split your data and run more jobs in parallel.</p></li>
</ul>

<p>Things to remember about deploying in the cloud:</p>

<ul>
<li><p>Logging is your friend. You won‚Äôt be able to debug with print statements on a remote, headless machine. Some of my
teammates didn‚Äôt quite understand this until they actually did it. Good logging makes it trivially easy to figure out what went wrong.</p></li>

<li><p>Versioning is your friend. Kubernetes won‚Äôt pull the container unless it knows it needs to, so you have to keep renaming your container
if you want to test changes. It‚Äôs kind of a pain, but it‚Äôs simple enough to
just make it part of the workflow (and our next step is to have Jenkins do this for us as part of our
CICD workflow).</p></li>

<li><p>Having to rebuild the container and version it and push it up each time does a couple of things:</p></li>
</ul>

<p>a) Testing is even more important. It‚Äôs a lot nicer if you can do enough testing that after a few bug fixes you‚Äôre on version 4, rather than
(as one of my early pipelines is) version 16.</p>

<p>b) It can be a little bit more annoying to push bug fixes/updates (especially without a CICD system
to build and deploy the containers for you)</p>

<hr>



<ul>
<li>People steered us away from EKS, so then setting up our own kubernetes cluster without a
devops person (!) was challenging, mostly because of</li>

<li><p>AWS permissions issues, including but not limited to:</p>

<p>a) giving the cluster the ability to run queries on the RDS database in the same account</p>

<p>b) creating a separate VPC for Redshift so I could create a peering connection for that (see separate post)</p>

<p>c) giving the cluster the ability to access s3 buckets</p>

<p>d) giving my team access to the docker registries on ECS</p>

<p>e) stupid things like legacy s3 bucket region restrictions that are (or should be?)
going away any minute now(?), but EC2 still cares about, which generate completely
uninformative AccessDenied errors</p></li>

<li><p>Figuring out the workflow for deploying and debugging. This was a little weird at first, but once I got the hang of it,
actually very easy (more on that below)</p></li>

<li><p>Setting up a docker registry and using that (and we don‚Äôt have Jenkins handling that for us yet)</p></li>

<li><p>Managing two clusters on two separate accounts, and switching between them (learning in hard mode is not
always twice as fun as just learning!)</p></li>

<li><p>There is a built-in outlet to connect Pachyderm up with Prometheus, but no built-in monitoring means we‚Äôre doing it downstream
(i.e with automated email alerts sent from Looker if something fails) or manually checking via the
CLI or dashboard view. I have been using the CLI thus far, but now that we have more than a few pipelines
going on one cluster, the dashboard is starting to make more sense.</p></li>

<li><p>Understanding how the ‚Ä¶</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/">https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/</a></em></p>]]>
            </description>
            <link>https://szeitlin.github.io/posts/engineering/pachyderm-vs-airflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529683</guid>
            <pubDate>Sat, 19 Sep 2020 19:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On fast navigation in the command line]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529677">thread link</a>) | @kkoncevicius
<br/>
September 19, 2020 | http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/ | <a href="https://web.archive.org/web/*/http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>A small list of methods for fast file system navigation from the command line.
While I tried all of them and finally settled on a minimal approach described at the end, the article doesn‚Äôt advocate for one method over the others.
Different users have different needs and should choose the approach most suitable in their circumstances.</p>

<h2 id="spring">Spring</h2>

<p>At the beginning, just after learning to use the command line, my terminal navigation included a lot of <code>cd</code> and a lot of <code>ls</code>.
I jumped around folders, learned shortcuts like, <code>cd ~</code>, <code>cd -</code>, and started becoming familiar with the shell.
Having multi-argument commands for quick file manipulation felt powerful and fresh, or so I remember.</p>

<p>After going to command line you no longer have to open folders in a graphical window manager, scan their names, use <code>&lt;ctrl + mouse click&gt;</code> to select them, and then drag the mouse to move those selected folders to another place.
You do <code>'mv pattern* place/'</code> instead.
All is nice.</p>

<p>But there was one problem.</p>

<h2 id="summer">Summer</h2>

<p>Along the way I started organizing my folders using a structure like this:</p>

<pre><code>‚îî‚îÄ‚îÄ work
    ‚îú‚îÄ‚îÄ bitbucket
    ‚îÇ   ‚îî‚îÄ‚îÄ user1
    ‚îÇ       ‚îú‚îÄ‚îÄ repo1
    ‚îÇ       ‚îî‚îÄ‚îÄ repo2
    ‚îú‚îÄ‚îÄ github
    ‚îÇ   ‚îú‚îÄ‚îÄ user1
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo1
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repo2
    ‚îÇ   ‚îú‚îÄ‚îÄ user2
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo1
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repo2
    ‚îÇ   ‚îú‚îÄ‚îÄ user3
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo1
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo2
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo3
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repo4
    ‚îÇ   ‚îî‚îÄ‚îÄ user4
    ‚îÇ       ‚îî‚îÄ‚îÄ repo1
    ‚îú‚îÄ‚îÄ teaching
    ‚îÇ   ‚îú‚îÄ‚îÄ class1
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lecture1
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lecture2
    ‚îÇ   ‚îî‚îÄ‚îÄ class2
    ‚îÇ       ‚îú‚îÄ‚îÄ lecture1
    ‚îÇ       ‚îî‚îÄ‚îÄ lecture2
    ‚îú‚îÄ‚îÄ‚îÄ clients
    ‚îÇ   ‚îú‚îÄ‚îÄ client1
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project1
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project2
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ project3
    ‚îÇ   ‚îú‚îÄ‚îÄ client2
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project1
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project2
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ project3
    ‚îÇ   ‚îî‚îÄ‚îÄ client3
    ‚îÇ      ‚îî‚îÄ‚îÄ project1
    ‚îî‚îÄ‚îÄ‚îÄ ...
</code></pre>

<p>I often had to go in and out of various project folders and my <code>cd</code> + <code>ls</code> navigation became tedious.
Reaching a project involved navigating a big tree of directories.
On top of that a lot of directories had similar names which got in the way of tab completion.
This is where I found ‚Äúz‚Äù - a command line utility that tracks your most visited folders based on frequency and recency<a href="#fn:1" id="fnref:1" title="see footnote"><sup>‚ó¶</sup></a>.</p>

<p>‚Äúz‚Äù keeps a database of your most frequently used folders and allows to quickly jump to these folders even if you don‚Äôt remember their full name.
Instead of doing a lot of <code>cd</code> + <code>&lt;tab&gt;</code> all you have to do is type <code>'z proj'</code> and <code>z</code> will take you to your most frequently/recently accessed folder that has <code>proj</code> somewhere in its name.
It takes a short amount of time for ‚Äúz‚Äù to learn about your most visited places but after that it becomes quick and convenient.</p>

<p>But there was one problem.</p>

<h2 id="autumn">Autumn</h2>

<p>‚Äúz‚Äù didn‚Äôt always take me where I wanted to be.
It worked, I would say, around 95% of the time or more.
But those other times it took me to an unrelated directory and distracted from the work at hand forcing to navigate my way back using the old <code>cd</code>.
Moreover, sometimes I moved and renamed various folders which likely contributed to its disorientation.</p>

<p>After this experience I decided that the terminal should be dumb and deterministic without any fuzziness or smart guessing.
And here I found <code>marks</code> - a short and sweet command line script for keeping manual directory bookmarks.<a href="#fn:2" id="fnref:2" title="see footnote"><sup>‚ó¶</sup></a>
It consisted of 4 tiny functions: one for creating a mark, one for removing, one for listing all the marks, and one for jumping to the bookmarked folder:</p>

<pre><code>export MARKPATH=$HOME/.marks

function mark {
  mkdir -p "$MARKPATH"; ln -s "$(pwd)" "$MARKPATH/$1"
}

function unmark {
  rm -i "$MARKPATH/$1"
}

function marks {
  ls -l "$MARKPATH" | sed 's/  / /g' | cut -d' ' -f9- | sed 's/ -/\t-/g' &amp;&amp; echo
}

function jump {
  cd -P "$MARKPATH/$1" 2&gt;/dev/null || echo "No such mark: $1"
}
</code></pre>

<p>As well as a function generating completion suggestions after pressing <code>&lt;tab&gt;</code>:</p>

<pre><code>_completemarks() {
  local curw=${COMP_WORDS[COMP_CWORD]}
  local wordlist=$(find $MARKPATH -type l -printf "%f\n")
    COMPREPLY=($(compgen -W '${wordlist[@]}' -- "$curw"))
    return 0
}

complete -F _completemarks jump unmark
</code></pre>

<p>The workflow of marks is manual but convenient.
You have to go into the directory you want to bookmark and execute the <code>mark</code> command followed by the custom name, like <code>'mark myproject'</code>.
After that you can quickly jump back to this bookmarked folder using <code>'jump myproject'</code> and when the bookmark is no longer relevant you can get rid of it with <code>'unmark myproject'</code>.</p>

<p>With this approach the user is in control.
There is no secret smart behaviour which means no auto-magic and no surprises.
And after moving a project to another place the bookmark can be easily adjusted to point to its new location immediately, without waiting for a hidden automatic process to update its location, frequency, and recency.</p>

<p>But there was one problem.</p>

<h2 id="winter">Winter</h2>

<p>Neither of those <code>jump</code> nor <code>z</code> commands could take me everywhere I needed to go.
So the typical workflow would start with jumping to a project via the <code>jump</code> command but then switching to the old navigation via <code>cd</code> once inside it.
Which meant that for navigating the file system I always had to keep using both: <code>jump</code> and <code>cd</code>.
And having two distinct commands for doing the same thing felt a bit weird.
This is where I learned about the <code>$CDPATH</code><a href="#fn:3" id="fnref:3" title="see footnote"><sup>‚ó¶</sup></a> variable and rolled out my own solution.</p>

<p>All you have to do is add this to your .bashrc:</p>

<pre><code>export CDPATH=.:~/.marks/
</code></pre>

<p>Then, to add a bookmark called <code>@name</code> pointing to a <code>"dir"</code> directory:</p>

<pre><code>ln -sr dir ~/.marks/@name
</code></pre>

<p>To delete a bookmark:</p>

<pre><code>rm ~/.marks/@name
</code></pre>

<p>To jump to its location:</p>

<pre><code>cd @name
</code></pre>

<p>And to list all available bookmarks:</p>

<pre><code>cd @&lt;tab&gt;
</code></pre>

<p>The <code>$CDPATH</code> solution works best when all the bookmarks are started with a special symbol which in my case was <code>@</code>.
This solves a couple of problems.
One, the bookmarked directories, if prefixed with <code>@</code> symbol, will not interfere with directories in the current folder.
Second, all the available bookmarks will be displayed by typing <code>'cd @&lt;tab&gt;'</code>.
And third, all bookmarks are now part of <code>cd</code> and so they gain tab completion for free.
You can even use tab completion for jumping directly to folders nested within bookmarks by doing <code>'cd @bookmark/subfolder/'</code>.</p>

<p>Using this method you no longer have to maintain a short list of custom bookmark functions and their autocompletion in your .bashrc.
And command for ‚Äúchange directory‚Äù can always be done with the same old and familiar <code>cd</code> command, independant of context.</p>

<p>But there was one problem.</p>

<h2 id="springagain">Spring again</h2>

<p>After working with the <code>$CDPATH</code> approach for a while I began noticing something peculiar.
At no point in time did I have a list with a dozen or more bookmarks.
Instead I found myself constantly going to the same 2 or 3 projects, finishing them, removing them from <code>~/.marks/</code> folder, adding new ones, and repeating the cycle again.
Why would someone keep bookmarks for 3 directories?</p>

<p>This time, instead of changing the command, I tried to do something different and changed the folder structure.
My projects moved from the state of being relevant to being archived so why not create an archive directory and organize folders based not on their name or type but on state?
Thus the <code>"zzz"</code> folder was born.
And now my project structure looks something like this:</p>

<pre><code>‚îî‚îÄ‚îÄ work
    ‚îú‚îÄ‚îÄ active_project1
    ‚îú‚îÄ‚îÄ active_project2
    ‚îî‚îÄ‚îÄ zzz
        ‚îú‚îÄ‚îÄ bitbucket
        ‚îÇ   ‚îî‚îÄ‚îÄ user1
        ‚îÇ       ‚îú‚îÄ‚îÄ repo1
        ‚îÇ       ‚îî‚îÄ‚îÄ repo2
        ‚îú‚îÄ‚îÄ github
        ‚îÇ   ‚îú‚îÄ‚îÄ user1
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo1
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repo2
        ‚îÇ   ‚îú‚îÄ‚îÄ user2
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo1
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repo2
        ‚îÇ   ‚îú‚îÄ‚îÄ user3
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo1
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo2
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repo3
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repo4
        ‚îÇ   ‚îî‚îÄ‚îÄ user4
        ‚îÇ       ‚îî‚îÄ‚îÄ repo1
        ‚îú‚îÄ‚îÄ teaching
        ‚îÇ   ‚îú‚îÄ‚îÄ class1
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lecture1
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lecture2
        ‚îÇ   ‚îî‚îÄ‚îÄ class2
        ‚îÇ       ‚îú‚îÄ‚îÄ lecture1
        ‚îÇ       ‚îî‚îÄ‚îÄ lecture2
        ‚îú‚îÄ‚îÄ‚îÄ clients
        ‚îÇ   ‚îú‚îÄ‚îÄ client1
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project1
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project2
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ project3
        ‚îÇ   ‚îú‚îÄ‚îÄ client2
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project1
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ project2
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ project3
        ‚îÇ   ‚îî‚îÄ‚îÄ client3
        ‚îÇ      ‚îî‚îÄ‚îÄ project1
        ‚îî‚îÄ‚îÄ‚îÄ ...
</code></pre>

<p>With this structure the bookmarking systems no longer provide big benefits as most frequent and recent folders are always under ~/work/some_project.
And since at any timepoint only a few of them are visible the tab completion will do its job: <code>'cd ~/w&lt;tab&gt;/s&lt;tab&gt;'</code>.</p>

<p>The name <code>"zzz"</code> might seem strange but is convenient: the letters ‚Äúzzz‚Äù symbolically mark the projects within as being in a ‚Äúsleeping‚Äù state while the 3 ‚Äúz‚Äù letters in a row make sure that this folder is always placed at the very end of your active project list.
A nice folder structure is still maintained in the archive but for the ease of access all active folders are layed flat under the <code>~/work/</code> directory.
When the project is paused or completed it is moved to its place within the <code>"zzz"</code> hierarchy, maintaining the previous structure.
There is one extra benefit - contents of the <code>"work"</code> directory act as a reminder about all the projects that are in progress.
If necessary a to-do list with concrete details might be placed at the same level.</p>

<p>And just like that, like a newbie, I navigate the file system with <code>cd</code> and <code>ls</code> again.</p>






</div>]]>
            </description>
            <link>http://karolis.koncevicius.lt/posts/fast_navigation_in_terminal_coming_full_cirlce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529677</guid>
            <pubDate>Sat, 19 Sep 2020 19:00:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Financial Status Template]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24529631">thread link</a>) | @jrdi
<br/>
September 19, 2020 | https://jordivillar.com/financial-status/ | <a href="https://web.archive.org/web/*/https://jordivillar.com/financial-status/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><a href="https://bit.ly/2Fm374g">The Financial Status Template</a><svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M16.5 13V18.5H6.5V8.5H12" stroke="#4A5568"></path> <path d="M10 15L18.5 6.5" stroke="#4A5568"></path> <path d="M14 6.5H18.5V11" stroke="#4A5568"></path></svg></h2><h3>How to stay on top of your personal finances.</h3><p>Staying on top of your <stron>personal finances</stron> can be challenging, tedious, and even discouraging, but for most people this process is a necessary evil. Spending more than you earn is a sure way to bury yourself in debt, and not being careful about precisely where <strong>your money is going</strong> can leave you struggling to pay for the day-to-day necessites.</p><p>During the last year, I have been <strong>tracking my personal finances</strong> on a monthly basis. Nothing too complicated but useful with <strong>insightful visualizations</strong>, allowing you to evaluate your financial status at-a-glance.</p><figure><a href="https://bit.ly/2Fm374g"><img src="https://i.ibb.co/1sRmTpJ/Screenshot-2020-09-19-at-13-43-31.png" alt="The Financial Status Template"></a></figure><p>I share similar personal finances insights in Twitter, you can <a href="https://twitter.com/jrdi">follow me there</a> as I continue to document my journey.</p></div></div></div>]]>
            </description>
            <link>https://jordivillar.com/financial-status/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529631</guid>
            <pubDate>Sat, 19 Sep 2020 18:51:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Quit a $500K Job at Amazon to Work for Myself (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24529590">thread link</a>) | @jkchu
<br/>
September 19, 2020 | https://danielvassallo.com/only-intrinsic-motivation-lasts/ | <a href="https://web.archive.org/web/*/https://danielvassallo.com/only-intrinsic-motivation-lasts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-92">
			<!-- .entry-header -->
	<div>
		
<h2>Why I Quit a $500K Job at Amazon to Work for Myself</h2>



<p>Last week I left my cushy job at Amazon after 8 years. Despite getting rewarded repeatedly with promotions, compensation, recognition, and praise, I wasn‚Äôt motivated enough to do another year.</p>



<p>I spent my entire time in AWS building tools for developers. I liked that field so much that I would have been satisfied working in it for the rest of my life.</p>



<p>I joined Amazon as an entry level developer. Within 3.5 years I had been promoted twice to a senior engineer, and I was practically guaranteed another promotion to principal engineer this year if I had stayed. My potential at the company was high, I was told.</p>



<p>My esteem within the company grew along the years and I was regarded an expert and a leader in my field. People looked up to me and respected me.</p>



<p>I made $75K in my first year and that gradually grew to $511K by my last year. I could have made another $1M if I stayed another couple of years.</p>



<p>My work‚Äìlife balance was good too, despite Amazon‚Äôs reputation. I didn‚Äôt need to prove myself anymore, and I could get everything done in 40 hours a week. My team worked from home one day a week, and I rarely opened my laptop at night or weekends.</p>



<p>Also, the people I worked with were exceptional. I had three managers in total, and all were generous people with lots of empathy. I‚Äôm very grateful to everyone I worked with.</p>



<p>Everything was going well and getting better. But despite all this, my motivation to go to work each morning was decreasing‚Äîalmost in an inverse trend to my career and income growth.</p>



<figure><img loading="lazy" width="1024" height="576" src="https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1024%2C576&amp;ssl=1" alt="Rewards up, motivation down." srcset="https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?resize=1100%2C619&amp;ssl=1 1100w, https://i0.wp.com/danielvassallo.com/wp-content/uploads/2019/02/rewards_motivation-2340812862-1549830899929.png?w=1801&amp;ssl=1 1801w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Rewards up, motivation down.</figcaption></figure>



<p>It would have been foolish of me to expect my motivation to start increasing if I got yet another promotion, or another compensation bump, or another big project. But there was something else that was trending down with my motivation. It was my freedom.</p>



<h3>The Motivation Decline</h3>



<p>For the first couple of years my motivation was off the charts. I was mostly working with another person on an internal tool, and there was very little scrutiny around it. It was a time where I had a lot of independence in choosing how to work and what to work on‚Äîat least relative to more recent years.  It was just me and the other person improving this thing, talking to users, releasing updates, testing it, and everything else. Whatever we felt was important, we generally got to do. We did the best work we could for its own sake and we were mostly self-directed.</p>



<p>The last couple of years, however, were quite different. I was leading the most important project in the history of my department, with many stakeholders and complex goals. What I could do was always bounded by my ability to convince all the people involved that it was the best way to navigate our goals. </p>



<p>I was always going to be working on somebody else‚Äôs terms at Amazon. The terms were simple in the beginning (keep fixing the thing), but kept getting more complicated as the years passed by (maximize all goals; satisfy all stakeholders). Then there were other restrictions inherent to working in a large organization about how to do the work, what work to do, what goals to set, and what business was worth pursuing. This situation was squeezing me into doing things that I‚Äôd rather not do, and vice versa.</p>



<h3 id="mce_19">Finding New Motivation</h3>



<p>What kind of work would I do if I had to do it forever? Not something that I did until I reached some milestone (an exit), but something that I would consider satisfactory if I continued to do it until I‚Äôm 80. What is out there that I could do that would make me excited waking up every day for the next 45 years that could also earn me enough money to cover my expenses? Is that too unambitious? I don‚Äôt think so. Because there are two types of drivers that get me out of bed in the morning.</p>



<p>One comes from the outside in the form of a carrot or a stick. For instance, I‚Äôm not automatically driven to do my tax returns every April, but I make sure I do because I don‚Äôt want to go to prison. Or I might not want to work on something I dislike, but I do so anyway because I may need to pay the bills, or want to buy a fancy car. These are the extrinsic motivators.</p>



<p>The other comes from within. This is what drives me to do things when there isn‚Äôt a carrot or a stick. Hobbies are one activity driven by this. But what I was looking for was something that I could do for a living that was also driven by this type of motivation: the intrinsic kind.</p>



<p>Back to the question of whether this is too unambitious. See, I realized that extrinsic motivation doesn‚Äôt last. Whenever I got promoted, it felt good for a week, and then it was as over. When I first hit $100K income, I would take a peek at my W2 for a few days admiring the six digits, but then it wore off. When I hit $200K, $300K, $400K, and $500K, it was the same thing. I would be delusional to think that earning $1M, or $10M would suddenly make it different. And I feel the same with every other extrinsic reward or material possession. Getting them feels good for a while, but this wears off quickly.</p>



<p>The things that don‚Äôt wear off are those that I‚Äôve been doing since I was a kid, when nothing was forcing me to do them. Things such as writing code, selling my creations, charting my own path, calling it like I saw it. I know my strengths, and I know what motivates me, so why not do this all the time? I‚Äôm lucky to live in a time where I can do something independently in my area of expertise without requiring large amounts of capital or outside investors. So that‚Äôs what I‚Äôm doing.</p>



<h3>What‚Äôs Next?</h3>



<p>I‚Äôm going all in on independence, and I‚Äôm going to try to make a living with my own bare hands starting from nothing. I don‚Äôt expect to only do things that I like, but it will be on my terms. My target is to cover my family‚Äôs expenses before I run out of savings while doing something that intrinsically motivates me. What more would I ever want to be satisfied with my work?</p>



<p>If you liked this article, check out:</p>



<ul><li><a href="https://danielvassallo.com/from-employee-to-bootstrapper/">How I set myself up financially before I took the plunge</a>.</li><li><a rel="noreferrer noopener" aria-label="And obviously about what I‚Äôll be doing for a living (opens in a new tab)" href="http://danielvassallo.com/#doing" target="_blank">And what I‚Äôm doing now for a living</a>.</li></ul>



<p>Now that I can use Twitter without being subject to Amazon‚Äôs social media policy, you can <a href="https://twitter.com/dvassallo">follow me there</a> as I continue to document my journey.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://danielvassallo.com/only-intrinsic-motivation-lasts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529590</guid>
            <pubDate>Sat, 19 Sep 2020 18:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Cruel Deception ‚Äì RAF Pilot Remains Discovered in North Korea]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529345">thread link</a>) | @Hansig_jw
<br/>
September 19, 2020 | https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><strong>A cruel</strong> <strong>deception</strong> ‚Äì <strong>RAF pilot</strong> <strong>remains</strong> discovered in <strong>North Korea</strong> is a story that once I had the full details of the aftermath several years later, quite frankly left me speechless and angry.</p><p>In early 2004, I was contacted at the embassy in Pyongyang by David Hinton, the brother of an RAF pilot who had been shot down in 1952 over North Korea during the Korean war. He said he had been working for several years trying to garner as much information from a variety of primary sources as to the fate of his brother.√Ç&nbsp; He said he now had in his possession most of the details of the shoot down supplied by eyewitness United States Air Force (USAF) pilots and map coordinates of the site of the crash (which he later sent to me).</p><p>He then expressed a wish to be able to visit North Korea and hopefully, finally discover the fate of his brother. Could we help?</p><p>The background was that the pilot, Flt Lt Desmond Hinton, who received the Distinguished Flying Cross in World War II for shooting down two Japanese fighters had bailed out of his burning F84e Thunderjet whilst carrying out a strafing mission north east of Pyongyang on 2 January 1952. At the time, Flt Lt Hinton was one of a number of RAF pilots who were attached to and flying with the USAF. Despite enquiries after the war and with no further information as to his fate forthcoming, Flt Lt Hinton was subsequently officially listed as missing in action.</p><div id="gallery-1"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/thumbnail-1/#main"><img width="400" height="311" src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" alt="Flt Lt Hinton North Korea" aria-describedby="gallery-1-980" data-lazy-srcset="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?resize=300%2C233&amp;ssl=1 300w" data-lazy-sizes="(max-width: 400px) 100vw, 400px" data-lazy-src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-1-980"> Flt Lt Hinton with USAF colleagues -Photo David Hinton</figcaption></figure></div><p>I knew that this was going to be a tall order to try and carry out. The Korean War itself was and still is a huge propaganda tool for the Kim dynasty. So requesting assistance in finding a hated enemy, albeit a fallen one, was perhaps a request too far.</p><p>But surprisingly, no.</p><p>Permission was granted for me to meet with the North Korean military and at the initial meeting, I provided them with all the research material sent to me by David Hinton and they said they would investigate.</p><p><em><strong>The</strong><strong> process of making this project happen, working with the North Korean military, I have covered in a previous post</strong></em> <a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/">British Diplomat Works With North Korean Military </a></p><p>Against all expectations, the military did get back to me shortly afterwards with some quite startling news. Based on the information I had given them, they had identified the crash site which was close to a village called Kuso-ri/Gueso-ri situated near to what is currently the main airport for Pyongyang.</p><p>They had spoken with villagers including two elders who had witnessed the shoot down. Flt Lt Hinton had indeed ejected but his parachute failed and he was killed on impact. The villagers had then interred him in an unmarked grave in a field adjacent to the village. An exact location had been identified and human bones and fragments of uniform and aircraft had been uncovered. <em><strong>This scenario is somewhat similar to my previous post</strong> </em><a href="https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/">Tragic RAF Pilot√¢‚Ç¨‚Ñ¢s Secret Grave Discovered In Albania</a></p><p>With this discovery, events moved quickly. A visa for David to enter North Korea was fast tracked and he duly arrived hopeful for some form of final closure. During his visit, he was treated as an honoured guest by the North Koreans and enjoyed the rare distinction of being accompanied throughout his visit by a senior Korean People‚Äôs Army officer, Colonel Kwak Chol-hui, who was at that time Director of Negotiations for Remains at the armistice site at Panmunjom.</p><p>So, on the day appointed to visit the village to view the grave, we arrived early and were met by the Colonel and both witnesses who then led us to the gravesite which was a short distance away.</p><p>The grave consisted simply of a mound of earth surrounded by a white picket fence, without any inscription. It lay close to a narrow footpath on a hillside 200 meters from the road.</p><p>David was introduced at the grave to the two witnesses to Desmond‚Äôs crash, a Mr Ri and Mr Han, local villagers who were only 13-years old at the time of the incident but who still appeared to have perfect recollections of the event. Perhaps a little too perfect and too detailed I thought at the time. But, maybe it was just me being a tad too cynical.</p><p>David then gave a short speech at the grave, thanking Colonel Kwak and the British embassy for making his visit possible, while the head of the village promised to tend the grave and paint the fence regularly.</p><p>We spent about 2 hours in the village and at the gravesite before it was time to leave. We said farewell to the Colonel and the witnesses and set off back to Pyongyang and David left North Korea the next day.</p><p>Upon his return to the UK, he was kind enough to send me copies of the many photographs he had taken that day and which I still have.</p><p>I learnt later that in 2011, a casket containing the bones of Flt Lt Hinton had been passed with great ceremony to the then British ambassador to North Korea for repatriation and presumably for burial at the UN Korean War cemetery in Busan, South Korea.</p><p><strong>And here the story would have finally ended. But no!</strong></p><p>The British Daily Mail ran a story on 17th June 2018 that was a shocker to me. It was revealed that subsequent DNA testing carried out on the bones after the repatriation identified them not as those of Flt Lieutenant Hinton but those of an animal!</p><p>According to the paper, family members were informed but the media was kept in the dark for fear of damaging relations between North Korea and the UK. Don‚Äôt you just love political machinations!</p><p>The paper then went on to quote the source as the memoirs of Mr Thae Yong-Ho, a North Korean diplomat who was Deputy North Korean Ambassador to the UK at the time and who defected to South Korea in 2016.</p><p>It also came as North Korean dictator Kim Jong Un had agreed with US President Donald Trump at their Singapore summit that all remains of US servicemen who died in the Korean War would now be returned.</p><p>Interestingly, the New York Times ran a story on 1st August 2018 detailing how difficult it had been to identify remains of American MIA‚Äôs handed over by the North Koreans to the US as a result of the Agreement with the paper also quoting the Hinton DNA story.</p><p>Mr Thae maintained that the Hinton episode was a case of crass incompetence. He also stated that Britain did protest but North Korean officials countered by saying they lacked the proper equipment to distinguish human from animal bones.</p><p>To this day, I cannot believe how stupid the North Koreans behaved in this matter. They must have known that DNA would be carried out on the bones.√Ç&nbsp; If so, why did they release them?</p><p>A country that has a nuclear programme, the ability to launch missiles and a sophisticated scientific infrastructure coming out with such a lame excuse just didn‚Äôt hold water.</p><p>I might add that at the time of the Hinton project, Mr Thae was well known to the embassy in Pyongyang, both professionally and socially. He was an experienced diplomat at the Ministry of Foreign Affairs where as part of his portfolio, he was in charge of the UK desk, hence the contacts. So, he would have been well aware (and probably involved behind the scenes) in what developed.</p><p>So what should have been a positive North Korean story about the discovery and dignified burial of a fallen RAF pilot and the assistance given to a close relative to enable him to pay his last respects, in the end turned out to be nothing but a cruel and wicked deception.</p><p><em><strong>Sources:</strong></em></p><p>https://www.dailymail.co.uk/news/article-5852503/Remains-RAF-hero-shot-North-Korea-2011-turns-animal-bones.html</p><p>‚ÄúCryptography From the Third-<wbr>Floor Secretariat√¢‚Ç¨ÔøΩ 2018 Thae Yong-Ho</p><div heateor-sss-data-href="https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/"><p>Spread the love</p><ul><li><a data-pin-lang="en_US" href="https://www.pinterest.com/pin/create/button/?url=https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/" data-pin-count="false" data-pin-do="buttonPin" data-pin-config="beside"><img src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845"></a></li></ul></div></div></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/a-cruel-deception-raf-pilots-remains-discovered-in-north-korea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529345</guid>
            <pubDate>Sat, 19 Sep 2020 18:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Discussion of Li-Meng Yan's Paper on SARS-CoV-2]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24529261">thread link</a>) | @akvadrako
<br/>
September 19, 2020 | https://www.randombio.com/ratg132.html | <a href="https://web.archive.org/web/*/https://www.randombio.com/ratg132.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- change font to prevent FauI coming out as Faul -->
<section>

<p>
<span> <img src="https://www.randombio.com/O40gray-gray.png" alt="O" title="O"></span>
n September 14 2020, Li-Meng Yan, a dissident Chinese virologist, along with three
colleagues, posted an article at <a href="https://zenodo.org/record/4028830">zenodo.org</a>
<sup>[1]</sup> claiming to prove that SARS-CoV-2 was artificially created. Twitter 
canceled the author's account two days later and political activists vociferously 
attacked the paper on political grounds. It is clear that many people don't want to 
hear her evidence. But the issue is extremely important. If the virus was produced 
in an experiment and accidentally released, as this paper claims, it means the Wuhan 
Institute of Virology is in dire need of upgrades to their virus-handling procedures 
to prevent it from happening again.
</p><p>
My background is 30 years as a researcher in protein biochemistry using biophysical 
techniques and molecular biology, including design, cloning, and expression of 
recombinant proteins, to study protein function and structure. Here's a brief
summary of the argument put forward in the paper along with my comments.
</p><p>
<i>Update, Sep 20 2020</i>: I've expanded the comments to describe the evidence they
would need to make their case more convincing.
</p><hr><p>
<b>Claim 1:</b> 
   ‚Äú[the sequences of] RaTG13, RmYN02, and several pangolin viruses recently
   published are highly suspicious and likely fraudulent.‚Äù
   ‚ÄúThe RaTG13 virus is excluded from this analysis given the strong evidence 
   suggesting that its sequence may have been fabricated and the virus does not exist 
   in nature.‚Äù
</p><p>
<b>Comment:</b>
   RaTG13 was published by Shi Zhengli at the same time as the SARS-CoV-2 sequence. 
   In 2013 Shi also published a partial gene segment of RaBtCoV/4991, which is identical 
   to RaTG13, but it is incomplete. The authors say that the WIV took this partial
   sequence and fraudulently added the remainder to exculpate themselves, trying
   to make it appear that RaTG13 was a pre-existing virus. 
</p><p>
   Evidence in favor of this claim is that Shi <i>et al.</i> made no mention of 
   RaBtCoV/4991 in their 2020 paper. But unless someone wants to claim that 4991 
   was also fabricated, RaBtCoV/4991 had to come from somewhere, which is to say it is 
   a real virus. So Claim 1 doesn't make sense. 
</p><p>
<b>What is needed:</b>
   To prove this the authors would have to find another virus that is 100% identical 
   with the published partial RaBtCoV/4991 sequence but which differs from RaTG13. 
</p><hr><p>

<b>Claim 2:</b> 
   The WIV could have used transgenic hACE2 transgenic mice to improve the virus's
   ability to bind to its receptor. ‚ÄúThis animal model 
   has been established during the study of SARS-CoV and has been available in the 
   Jackson Laboratory [a commercial supplier of transgenic mice] for many years.‚Äù
   However, hACE2 mice are ‚Äúnot a good model to reflect the virus' transmissibility
   and associated clinical symptoms in humans.‚Äù If they had used golden Syrian
   hamster instead, the authors say, ‚Äúthe highly contagious nature of SARS-CoV-2 
   would be extremely evident‚Äù and they could have released accurate information.
</p><p>
<b>Comment:</b> 
   This is a good point. If true, it would tend to exculpate the Chinese researchers.
   But we already know many techniques they could have used. No one was claiming 
   that making the virus was impossible. 
</p><p>
<b>What is needed:</b> 
   Sending live animals to another country requires tons of paperwork. They would need
   Jax's sales records or government export records (which might be available via a
   FOIA request). 
</p><hr><p>
<b>Claim 3:</b> 
   The paper provides a flow chart for how the virus could have been constructed.
   ‚ÄúTwo restriction sites are present at either end of the RBM [receptor-binding
   motif] of SARS-CoV-2, providing convenience for replacing the RBM within the spike 
   gene.‚Äù
</p><p>
<b>Comment:</b> 
   The spike protein consists of two parts: S1, which binds to the receptor, and S2,
   which fuses the viral and cellular membranes. The point where the subunits are joined 
   is called the S1/S2 site. Proteolysis of this site is essential for infection.
   The RBM is the part of S1 that binds to the receptor. A common technique is 
   to take functional domains out of one protein and put them into another. The easiest 
   way to do this is by finding (or creating) restriction sites in the DNA that allow 
   you to cut the DNA in a specific place.
</p><p>
   The flow chart is quite reasonable, but again no one doubted that artificially 
   creating the virus is possible. So describing how someone could have done it
   doesn't tell us much; any competent molecular biologist could come up with
   a similar scheme.
</p><p>
   The article makes a big deal about the presence of restriction sites on the S1/S2 
   sequence, including an <code>EcoRI</code> site and a <code>BstEII</code> site. 
   But this does not indicate engineering. Many restriction sites occur naturally by 
   chance. Their presence is not unusual, but they are a major inconvenience for those 
   of us who try to clone DNA‚Äîmany restriction sites we might wish to use are 
   ruled out by the presence of another one in an inconvenient location. The 
   probability of finding one of over a thousand known 
   <a href="http://rebase.neb.com/rebase/rebase.html">restriction sites</a> at an 
   arbitrary location in a 3800 base sequence by chance is very high.
</p><p>
<b>What is needed:</b> 
   To prove this convincingly, the authors would need to find an authentic copy 
   of the original virus sequence without the restriction sites to show what the virus 
   was like before the supposed change was made. 
</p><hr><p>
<b>Claim 4:</b> 
   The furin cleavage site contains rare codons, an unusual sequence not shared by other 
   lineage B betacoronaviruses, and a <code>FauI</code> restriction site. It 
   could not have been introduced by evolution, say the authors, and the probability 
   of successful homologous recombination ever occurring among the ancestors of these 
   viruses is low. ‚ÄúA  <code>FauI</code> restriction site is formulated by the codon choices 
   here, suggesting the possibility that the restriction fragment length polymorphism,
   a technique that a WIV lab is proficient at, could have been involved.‚Äù
   The authors suggest that the <code>FauI</code> site was added to monitor the presence
   of the furin-cleavage site.
</p><p>
<b>Comment:</b> 
   The furin cleavage site is known to increase the tropism of the virus, and it is 
   now known that the virus even infects the brain, but there is little evidence so
   far that it increases pathogenicity. There is as yet no good explanation for the 
   presence of the furin cleavage site. 
</p><p>
   It might make sense for a virus creator to put a restriction site in the middle of
   the furin cleavage site to make sure it didn't disappear. RFLP analysis is a simple 
   technique and any molecular biology lab could handle it easily. However, as mentioned,
   restriction sites pop up randomly all the time, so finding one proves little.
</p><p>
<b>What is needed:</b> 
   The <code>FauI</code> restriction site is a red herring. To prove that the furin cleavage
   site was added, the authors would have to find a trail of evidence showing step
   by step how the sequence was manipulated from whatever virus the WIV started from.
   It would also be helpful to have data showing that furin cleavage increases 
   pathogenicity. This is plausible but it needs to be shown experimentally.
</p><hr><p>
<b>Claim 5:</b> 
   WIV most likely used ZC45 and ZXC21, not RaTG13, to create SARS-CoV-2 because RaTG13 is 
   not real. The reasoning behind this claim is that the S1 sequence of SARS-CoV-2 
   is quite similar to these other viruses except for the receptor-binding motif and 
   furin-cleavage sites. Also, two other proteins on these viruses, the Orf8 protein 
   and E protein, are 94.2% and 100% identical to SARS-CoV-2.
</p><p>
<b>Comment:</b> 
   This is indeed strange but so far circumstantial.
</p><p>
<b>What is needed:</b> 
   The authors need to prove that RaTG13 is not real. They claim to have evidence,
   and I look forward to seeing it,  but to be convincing it would have to be more 
   than the discovery of mysterious unexplained features in the DNA sequence.
</p><hr><p>
The authors say they plan to prove that RaTG13 is fabricated in a follow-up report. 
If they can do this, it would be solid evidence of consciousness of guilt on the part 
of WIV researchers. However, the current paper doesn't say very much more than what 
other bloggers have already revealed.
</p><p>
It would be premature to draw any conclusion about the origins of the virus from this
paper. The authors have set for themselves a difficult and possibly impossible task: 
finding a signature of intel¬≠ligent design in a virus is much like what the 
creationists have been doing without success for years. 
</p><p>
But what is not premature is that social media giants deciding for us what is 
true and what is false may turn out to be as big a threat as the virus. It is unfair 
and unscientific to dismiss ideas that one doesn't want to hear as ‚Äúconspiracy 
theories‚Äù as many people are doing. 
</p><hr><p>
1. Yan LM, Kang S, Guan J, Hu S (2020). Unusual Features of the SARS-CoV-2 
Genome Suggesting Sophisticated Laboratory Modification Rather Than Natural 
Evolution and Delineation of Its Probable Synthetic Route.
https://zenodo.org/record/4028830
</p><hr><p>
<i>
sep 16 2020, 6:52 pm (Updated Sep 20 2020)
</i>
</p>
</section>
</div></div>]]>
            </description>
            <link>https://www.randombio.com/ratg132.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529261</guid>
            <pubDate>Sat, 19 Sep 2020 17:57:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meeting everyone on a new team]]>
            </title>
            <description>
<![CDATA[
Score 194 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24529176">thread link</a>) | @craigkerstiens
<br/>
September 19, 2020 | https://www.annashipman.co.uk/jfdi/meeting-everyone.html | <a href="https://web.archive.org/web/*/https://www.annashipman.co.uk/jfdi/meeting-everyone.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="meeting-everyone">
    
    <date>17 September 2020</date>
      <p>When I joined the Financial Times as Technical Director for FT.com, I inherited a team of around 50 engineers. One of the first things I did was meet each of them for a one-to-one. I was initially resistant, but it was extremely valuable, I‚Äôm glad I did it, and I would definitely do it again in a future role.</p>

<h2 id="my-mentors-advice-about-the-content-of-the-meeting">My mentor‚Äôs advice about the content of the meeting</h2>

<p>The idea was suggested to me by a mentor, who‚Äôd been advised to do it by <em>his</em> mentor, a Rear Admiral, who said this was something you should do whenever you have a team of fewer than 150 people. My mentor gave me some tips:</p>

<ul>
  <li>Be clear about whether you will take action or whether this is for information only.</li>
  <li>This should mostly be about listening ‚Äì you should talk for maybe 5 minutes and they should talk for 25.</li>
  <li>It‚Äôs to find out what‚Äôs going well and what‚Äôs not going well.</li>
  <li>It‚Äôs informal, but make sure it‚Äôs in an enclosed meeting room so that people feel they can speak freely.</li>
  <li>Sometimes it will be quite boring, sometimes you may just learn a lot about someone‚Äôs family or hobbies, but that is useful from a getting to know people/relationship-building perspective and it means that you know some things about that person.</li>
  <li>Aim is to get a bit about their background, their priorities and their pressures.</li>
</ul>

<h2 id="making-time-was-hard">Making time was hard</h2>

<p>I was initially resistant because of the time commmitment. With a team of ~50, that‚Äôs a lot of hours, and I was also working four days a week so each meeting takes up a greater proportion of time. However, once I‚Äôd made the decision to do this and announced my intention, it was important to me to follow through, so I made sure to make time.</p>

<p>I scheduled four of these 1:1s a week, starting with the people reporting directly to me and then on down the management chain.</p>

<h2 id="i-ran-each-meeting-in-the-same-way">I ran each meeting in the same way</h2>

<p>Firstly I ran through everything I planned to cover, and then stepped through it.</p>


<ul>
  <li>I am asking the same questions to everyone</li>
  <li>This is information for me only to get an idea of themes and how things are going; I‚Äôm not explicitly planning to take action on anything we discuss, so if something comes up that I need to take action on, let‚Äôs make sure we discuss that after this meeting</li>
  <li>This is confidential. If you say something about someone else I‚Äôm not going to go and tell them. I may report on ‚Äòwhat people are saying‚Äô, but I‚Äôll say ‚Äòthe engineers feel‚Äô or ‚Äòan engineer said‚Äô; I won‚Äôt say ‚Äú[Your name] said‚Ä¶‚Äù</li>
</ul>

<h3 id="what-were-going-to-discuss">What we‚Äôre going to discuss</h3>

<ul>
  <li>First I‚Äôll introduce myself, and tell you a bit about my background</li>
  <li>Then, if you like, I‚Äôd love you to tell me a bit about yourself ‚Äì as much or as little as you feel like sharing</li>
  <li>Then we‚Äôll discuss the following questions:</li>
</ul>

<ol>
  <li>What do you think the most important things we should be doing over the next year?</li>
  <li>What will get in the way of us doing that?</li>
  <li>What‚Äôs going well, i.e. what should we make sure we don‚Äôt change?</li>
  <li>Is there anything you think I should know about?</li>
</ol>

<h2 id="is-there-anything-i-should-know-about">Is there anything I should know about?</h2>

<p>When I asked this question I talked a bit about why I was asking. I explained that I might not necessarily see or know things that may seem apparent to them, and while they should always feel able to bring things to me, now was a good opportunity to do so. It was an opportunity to make sure I‚Äôve heard what‚Äôs important to you, what things should change and what things should stay the same.</p>

<p>This question always elicited very interesting responses, from organisational issues, to personal information people felt it was valuable for me to know about them.</p>

<h2 id="i-told-them-what-i-was-planning-to-ask-in-advance">I told them what I was planning to ask in advance</h2>

<p>I put all the information in the meeting invite.</p>

<div>
<p>I mentioned that I wanted to have a chat with everyone on FT.com to understand how things are going, does this time suit you for this?</p>

<p>The meeting agenda is the same for everyone; a quick intro and then the following questions (I'll go through this in the meeting too):</p>

<ul>
<li>What do you think the most important things we should be doing over the next year?</li>
<li>What will get in the way of us doing that?</li>
<li>What‚Äôs going well, i.e. what should we make sure we don‚Äôt change?</li>
<li>Is there anything you think I should know about?</li>
</ul>

<p>Thanks,</p>
<p>Anna</p>
</div>

<p>Some people did not read the meeting invite and came with no idea what the meeting was about. Some people had fully prepared and written notes that they then read out to me. Actually people having prepared sometimes was less useful, because sometimes it led the conversation to solutions rather than problems. However it was great that people had really given it some thought.</p>

<h2 id="making-notes-felt-too-much-like-a-promise">Making notes felt too much like a promise</h2>

<p>Each meeting was half an hour. In the very first one, I made notes in a notebook, but I realised that created an implicit commitment that I was going to take action on everything that was said, even though I had said it was information only.</p>

<p>However, I do not have a very good memory, so for all the subsequent ones I made a few notes after each meeting of key themes. This meant I couldn‚Äôt do more than two in a row or go straight into another meeting, so it made scheduling slightly harder. These days, people are much more aware of the shorter meeting approach so if doing this again, I‚Äôd go for the ‚Äòtherapy hour‚Äô ‚Äì 25 minutes for conversation then 5 minutes for me to make the notes.</p>

<h2 id="introducing-myself">Introducing myself</h2>

<p>In my intro, I gave a potted career history. Starting from my degree in philosophy, and my first career in <a href="https://www.barringtonstoke.co.uk/">children‚Äôs book publishing</a>, through teaching myself to code, my <a href="https://www.hw.ac.uk/study/uk/postgraduate/information-technology-software-systems.htm">masters in Software Systems</a> and then my 15+ year career in programming, infrastructure and operations, technical architecture, and my previous role as <a href="https://www.annashipman.co.uk/jfdi/a-year-in-the-life-os-lead.html">Open Source lead</a>. I also talked about what appealed to me about the job as Technical Director at the FT.</p>

<p>I said roughly the same thing to everyone. I don‚Äôt normally introduce myself and give my background, but in this case I thought that as a new Tech Director most of them would not be working closely with me, and I would not be contributing code, so it was worth giving my credentials.</p>

<p>My mentor had suggested I also say something personal. I think he intended something like ‚Äúmarried with two children‚Äù (or whatever), but instead, I tried to give a different kind of personal detail, something about my interests. I tried to come up with a different one for each conversation, for example something about my <a href="https://twitter.com/annashipman/status/1043917006477643777">cross-stitch hobby</a>.</p>

<p>This part was the hardest part for me, because prior to this I had generally enjoyed keeping a clear boundary between work stuff and personal stuff, so that definitely didn‚Äôt cover talking about cross-stitch, or my home life, on a first meeting. However, I had been trying to bring more of my personal self to work, and this part of the intro did lead to some really interesting conversations and I think helped make a better connection.</p>

<p>Of course, these days, when we are all at home, my personal life is in meetings with me, so it‚Äôs good I‚Äôd already started on that journey!</p>

<p>Giving so much information in my introduction also allowed the other person to introduce themselves how they wanted. Some talked career history, some focused on their hobbies, others were really open about their lives and aspirations.</p>

<h2 id="i-am-so-glad-i-did-this">I am so glad I did this</h2>

<p>My mentor was wrong about one thing ‚Äì&nbsp;none of the conversations were boring.</p>

<p>In my first few months in the new job, I often felt really stretched for time, but I never regretted a single one of these meetings; it was always extremely interesting, my team are brilliant and it was great to meet them one on one, and each conversation always contained some valuable information.</p>

<p>There were two very valuable things about this for me.</p>

<p>The first was getting an idea of what change was needed. These meetings gave me a brilliant insight that wasn‚Äôt available elsewhere. Patterns started emerging very quickly, and formed the basis of our <a href="https://medium.com/ft-product-technology/the-difficult-teenage-years-setting-tech-strategy-after-a-launch-7f42eb94a424">tech strategy</a>.</p>

<p>The second was building relationships. A lot of the people I had 1:1s with I would not have come into contact with during the course of the ordinary working week. It would have taken time to meet everyone at socials, and it wouldn‚Äôt have been the same quality of conversation. I still feel, two years on, that I know a bit about all the people I had those conversations with, which has felt to me like a good foundation for our subsequent conversations.</p>

<p>It was also good, as someone who is a bit shy, to have names to faces quite quickly and people to say hello to when walking round the office.</p>

<h2 id="was-it-useful-for-my-team">Was it useful for my team?</h2>

<p>About a year later, I asked some of the people with whom I‚Äôd had these conversations whether they‚Äôd been useful (in an anonymous form).</p>

<p>All of the people who responded said they found the conversation valuable, and some of their comments were:</p>

<ul>
  <li>‚ÄúIt broke down barriers and helped me feel less intimidated about approaching you, whether to talk about work or just to have a general chit chat. You are a very busy person who I wouldn‚Äôt ever work with directly so it was good to feel that you knew I existed.‚Äù</li>
  <li>‚ÄúThere is hardly any opportunity for me to talk to people in higher position like you except when the team has a big problem. The 1:1 was really casual and I felt really comfortable talking to you. It was a good time to know what kind of person you are. If we didn‚Äôt do the 1:1, the answer of the question below ‚ÄúDo you feel able to raise issues with me?‚Äù would be ‚ÄúNo‚Äù.‚Äù</li>
  <li>‚ÄúWe sat down when you first started and it was nice to get some one-to-one time because it‚Äôs not often you get to do that with a Technical Director. It was nice to raise issues but for me, it was more of an opportunity to understand if I could trust you in the future with raising issues. Raising issues can be difficult and scary so it‚Äôs important to know if the person you are raising them to is receptive.‚Äù</li>
  <li>‚ÄúIt really showed that you cared about us as humans, and how we fit with the rest of the team. It was also a great opportunity to get to know you‚Äù</li>
  <li>‚ÄúI think often of that conversation‚Äù</li>
</ul>

<h2 id="did-it-make-them-feel-more-able-to-raise-issues-with-me">Did it make them feel more able to raise issues with me?</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.annashipman.co.uk/jfdi/meeting-everyone.html">https://www.annashipman.co.uk/jfdi/meeting-everyone.html</a></em></p>]]>
            </description>
            <link>https://www.annashipman.co.uk/jfdi/meeting-everyone.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529176</guid>
            <pubDate>Sat, 19 Sep 2020 17:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reasons Your Growth Startup Is Hiring Too Junior]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24529137">thread link</a>) | @svmanager
<br/>
September 19, 2020 | https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Growth startups often find themselves lacking senior team members as they scale. The problems that arise from this are plentiful, including things like:</p>
<ul>
  <li>Requiring heroics to fix things</li>
  <li>Penalizing junior team members for failure to meet responsibilities well above their pay grade.</li>
  <li>Building technology that doesn‚Äôt scale</li>
</ul>

<p>Here‚Äôs some reasons why companies get into this situation.</p>

<h2 id="reason-1-habit">Reason 1: Habit</h2>

<p>When you‚Äôre a tiny startup budgets are extremely lean and products don‚Äôt have a lot of users. In that environment companies often prioritize breadth of functionality (see what works) and getting that via several (more affordable) junior team members guided by a smaller group of senior team members.</p>

<p>Problems arise if that strategy exists past market fit. The add-a-junior-to-do-more strategy implodes as the team grows too large for the senior staff to manage closely and the technical challenges start to look more daunting.</p>

<h2 id="reason-2-hubris">Reason 2: Hubris</h2>

<p>Sometimes people recognize the problems are getting more difficult but still don‚Äôt hire more seniors. This can often be chalked up to hubris - surely I can just direct a bunch of juniors to execute on the genius solutions I come up with for all our problems. The problem here is that you‚Äôre not a genius and even if you were that strategy doesn‚Äôt scale.</p>

<h2 id="reason-3-fear">Reason 3: Fear</h2>

<p>The flip side of hubris is fear. New senior staff can look like a threat to the power of existing senior staff. You might have to choose between doing what‚Äôs right for the company and retaining certain kinds of power. The answer there is simple - it‚Äôs better to be part of something great than the owner of something that fails.</p>

<p>A different play on this theme is junior teammates fearing that new senior teammates will take away some of their opportunities. It‚Äôs possible, sure. But more often the opportunities they will take over are the ones juniors would have had trouble succeeding in.</p>

<p>In a growing company with reasonably difficult challenges, good seniors will do more to expand the set of opportunities than shrink them. And good senior talent will help juniors via mentorship and guidance.</p>

<h2 id="reason-4-money-issues">Reason 4: Money Issues</h2>

<p>Money issues play out in a couple ways.</p>

<p>First, the cost of senior talent can subconsciously make you concerned about the remaining budget for yourself. I haven‚Äôt seen this played out directly and blatantly, but it‚Äôs another version of the fear game - assuming compensation is a zero sum game leads to weird incentives.</p>

<p>Second, it‚Äôs easy to think 2 juniors are better than one senior. As you read about the myth of the 10x engineer you might find yourself thinking this way. Let‚Äôs talk more about how this is a misconception in reason 5‚Ä¶</p>

<h2 id="reason-5-miscalculation-of-necessary-skills-for-right-now">Reason 5: Miscalculation of Necessary Skills For Right Now</h2>

<p>As referenced earlier, problems get much harder when you add significant growth to a platform. It‚Äôs not uncommon to underestimate the challenges at hand. In reality, even simple products at massive scale need significant senior leadership to ensure they are being built and operated effectively. Trying to replace the leadership of senior talent with a volume of junior talent is a sure-fire way to screw this up.</p>

<h2 id="reason-6-miscalculation-of-necessary-skills-in-the-future">Reason 6: Miscalculation of Necessary Skills In the Future</h2>

<p>To make things more difficult, you don‚Äôt just have to hire for right now, you have to hire for 2 or more years in the future. The senior talent you hire now must seed the leadership ranks you need in the future. Especially in product and engineering, you can‚Äôt just hire everyone you need when you need them. For starters, the job market would laugh at that sort of just-in-time attempt at hiring. But also, these roles require much more detailed understanding of the systems at play, so you need to have people with intimate knowledge developed in advance.</p>

<p>Think of it this way - look at whatever company you‚Äôre trying to be like in 5 years. Look at their team. If you don‚Äôt start hiring towards something like that team sooner rather than later you‚Äôll never be that company.</p>

<h2 id="reason-7-arguments-about-what-seniors-need">Reason 7: Arguments About What-Seniors-Need</h2>

<p>Another reason people hire too junior is thinking around senior talent needing explicit areas of responsibility that don‚Äôt overlap. This is the ‚Äúone alpha‚Äù theory - that senior talent can‚Äôt collaborate productively and need their own pack. There might be some nuggets of truth here, but most of it is nonsense. That‚Äôs like NASA saying they couldn‚Äôt have smart people work together on getting to the moon because these great scientists need their own domains.</p>

<p>Ultimately you have to look at the problems you‚Äôre solving. If they are truly challenging they can support a number of seniors. If they aren‚Äôt you‚Äôll probably have trouble hiring and retaining more than a few.</p>

<h2 id="conclusion">Conclusion</h2>

<p>There‚Äôs a lot of reasons why you might hire too junior as your company grows. Know them and hire intentionally.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/09/11/Hiring-Too-Junior.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24529137</guid>
            <pubDate>Sat, 19 Sep 2020 17:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twister OS: Make Raspberry Pi Look Like Windows or macOS]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24528732">thread link</a>) | @yboris
<br/>
September 19, 2020 | https://twisteros.com/index.html | <a href="https://web.archive.org/web/*/https://twisteros.com/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Twister OS 2020 | <a href="https://discord.gg/Fh8sjmu" target="_blank">Join our Discord!</a></p></div></div>]]>
            </description>
            <link>https://twisteros.com/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24528732</guid>
            <pubDate>Sat, 19 Sep 2020 16:50:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmark of popular graph/network packages]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526881">thread link</a>) | @dvfjsdhgfv
<br/>
September 19, 2020 | https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/ | <a href="https://web.archive.org/web/*/https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        



<p><strong>This post is superseded by an <a href="https://www.timlrx.com/2020/05/10/benchmark-of-popular-graph-network-packages-v2/">updated benchmark</a></strong></p>
<p>In this post I benchmark the performance of 5 popular graph/network packages. This was inspired by two questions I had:</p>
<ol>
<li><p>Recently, I have been working with large networks (millions of vertices and edges) and often wonder what is the best currently available package/tool that would scale well and handle large scale network analysis tasks. Having tried out a few (networkx in Python and igraph in R) but on different problems, I thought it would be nice to have a head to head comparison.</p></li>
<li><p>Running large scale computations is also much easier nowadays with the availability of virtual machines that could be easily spinned up thanks to the growth of cloud computing. I think the trend of powerful single machines will eliminate a lot of the need for enterprise clusters so it will be interesting to see how far we can push a single machine using optimised algorithms.<a href="#fn1" id="fnref1"><sup>1</sup></a></p></li>
</ol>
<p>To replicate the benchmark study and for the full codes, please refer to <a href="https://github.com/timlrx/graph-benchmarks">my github repository</a>. Instructions on how to setup and install the packages are also located in the repository.</p>
<div id="setup">
<h2>Setup</h2>
<p>The benchmark was carried out using a Google Compute n1-standard-16 instance (16vCPU Haswell 2.3GHz, 60 GB memory). I compare 5 different packages:</p>
<ul>
<li><a href="https://graph-tool.skewed.de/">graph-tool</a></li>
<li><a href="https://igraph.org/redirect.html">igraph</a></li>
<li><a href="https://networkit.github.io/">networkit</a></li>
<li><a href="https://networkx.github.io/">networkx</a></li>
<li><a href="https://snap.stanford.edu/snappy/">snap</a></li>
</ul>
<p>Networkx is written in Python while the other four packages are based on C / C++ but have Python APIs. Igraph has a R and Mathematica binding as well but to be consistent the following benchmark was based on the Python one. The other 3 libraries (snap, networkit and graph-tool) have an additional emphasis on performance with multi-processing capabilities built in.</p>
<p>Selecting what tasks to compare on is not really a trivial task with each package offering various tools and capabilities. In the end, I decided to focus on 5 specific problems:</p>
<ul>
<li>loading the data</li>
<li>single source shortest path</li>
<li>page rank</li>
<li>k-core decomposition</li>
<li>strongly connected components</li>
</ul>
<p>Loading is more of an I/O task while the other 4 are common graph algorithms. Disclaimer: I try as much as possible to specify the same parameters for each algorithm but differences in API across the packages could translate to actual differences in how the algorithm is run and the final output.</p>
<p><span>13/12/2019 Edit: Some of the observed differences in performance might be a result of different stopping criteria used - see algorithms for more information.</span></p>
<p>3 datasets from the <a href="https://snap.stanford.edu/data/index.html">Stanford Large Network Dataset Collection</a> were used in the exercise:</p>
<ul>
<li><a href="https://snap.stanford.edu/data/amazon0302.html">amazon</a>, 262k nodes, 1.2m edges</li>
<li><a href="https://snap.stanford.edu/data/web-Google.html">google</a>, 875k nodes, 5.1m edges</li>
<li><a href="https://snap.stanford.edu/data/soc-Pokec.html">pokec</a>, 1.6m nodes, 30.6m edges</li>
</ul>
<p>While it is the easiest to rank the packages based on the run-time of the algorithms, it is only one of the many considerations of what makes a good package. I try to offer a more subjective view based on my experience with these packages.</p>
</div>

<div id="results">
<h2>Results</h2>
<p>All timings reported are normalised to reflect the run time for a single run of the task.</p>
<p>Networkx is much slower than any of the other libraries. Across all computation tasks and for all datasets it is around 10 times slower than the <em>slowest</em> library.<a href="#fn2" id="fnref2"><sup>2</sup></a> For example, it took 67s to run the single source shortest path problem on the Pokec dataset compared to 6.8s for networkit (the next slowest). Page rank took more than 10 minutes to run compared to 1 minute for igraph. Hence, I left it out of the comparison plots.</p>
<p>Here are the run times of the remaining four packages:</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/b13c3d06c53af36cafd2b861d21948ee7613dd3a/3c0f3/post/2019-05-05-benchmark-of-popular-graph-network-packages_files/figure-html/plot_all-1.png" width="672"></p>
<p>Full results can be seen from the table below:</p>
<table>
<thead>
<tr>
<th>
dataset
</th>
<th>
Algorithm
</th>
<th>
graph-tool
</th>
<th>
igraph
</th>
<th>
networkit
</th>
<th>
networkx
</th>
<th>
snap
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Amazon
</td>
<td>
connected components
</td>
<td>
0.09
</td>
<td>
0.48
</td>
<td>
0.21
</td>
<td>
5.94
</td>
<td>
0.40
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
k-core
</td>
<td>
0.11
</td>
<td>
0.33
</td>
<td>
0.01
</td>
<td>
8.62
</td>
<td>
0.42
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
loading
</td>
<td>
5.00
</td>
<td>
0.79
</td>
<td>
3.27
</td>
<td>
9.96
</td>
<td>
1.90
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
page rank
</td>
<td>
0.05
</td>
<td>
1.59
</td>
<td>
0.01
</td>
<td>
25.71
</td>
<td>
0.90
</td>
</tr>
<tr>
<td>
Amazon
</td>
<td>
shortest path
</td>
<td>
0.06
</td>
<td>
0.12
</td>
<td>
0.32
</td>
<td>
3.31
</td>
<td>
0.14
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
connected components
</td>
<td>
0.32
</td>
<td>
2.23
</td>
<td>
0.65
</td>
<td>
21.71
</td>
<td>
2.02
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
k-core
</td>
<td>
0.57
</td>
<td>
1.68
</td>
<td>
0.06
</td>
<td>
153.21
</td>
<td>
1.57
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
loading
</td>
<td>
67.27
</td>
<td>
5.51
</td>
<td>
17.94
</td>
<td>
39.69
</td>
<td>
9.03
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
page rank
</td>
<td>
0.76
</td>
<td>
5.24
</td>
<td>
0.12
</td>
<td>
106.49
</td>
<td>
4.16
</td>
</tr>
<tr>
<td>
Google
</td>
<td>
shortest path
</td>
<td>
0.20
</td>
<td>
0.69
</td>
<td>
0.98
</td>
<td>
12.33
</td>
<td>
0.30
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
connected components
</td>
<td>
1.35
</td>
<td>
17.75
</td>
<td>
4.69
</td>
<td>
108.07
</td>
<td>
15.28
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
k-core
</td>
<td>
5.73
</td>
<td>
10.87
</td>
<td>
0.34
</td>
<td>
649.81
</td>
<td>
8.87
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
loading
</td>
<td>
119.57
</td>
<td>
34.53
</td>
<td>
157.61
</td>
<td>
237.72
</td>
<td>
59.75
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
page rank
</td>
<td>
1.74
</td>
<td>
59.55
</td>
<td>
0.20
</td>
<td>
611.24
</td>
<td>
19.52
</td>
</tr>
<tr>
<td>
Pokec
</td>
<td>
shortest path
</td>
<td>
0.86
</td>
<td>
0.87
</td>
<td>
6.87
</td>
<td>
67.15
</td>
<td>
3.09
</td>
</tr>
</tbody>
</table>
<div id="io">
<h3>I/O</h3>
<p>Looking at the plots above, graph-tool and networkit loads data much more slowly than the other two libraries. I was reading the datasets as a tab delimited file and graph-tool basically uses a Python code to parse the input. The other 3 packages should be using C libraries to read the files which result in better performance.<a href="#fn3" id="fnref3"><sup>3</sup></a></p>
</div>
<div id="algorithms">
<h3>Algorithms</h3>
<p>Networkit and graph-tool takes the top spot in most of the tests with graph-tool having the shortest run time for the single source shortest path and connected components problems and networkit winning the race for k-core and page rank.</p>
<p>When networkit is fast, it is extremely fast. On the pokec dataset it takes just 0.2s to run the page rank algorithm (graph-tool: 1.7s, igraph: 59.6s, snap: 19.5s). For the k-core decomposition it is also 10 times faster than all other competitors or 2000 times networkx. That is consistent with the findings of their research paper where they claim that using some of the latest state of the art algorithms led to their processing speed being faster by an order of magnitude. However, for the shortest path problem (not analysed in their paper) it lags behind all other packages.<a href="#fn4" id="fnref4"><sup>4</sup></a></p>
<p><span>13/12/2019 Edit: Matthew Galati from SAS pointed out that for the pagerank algorithm, networkit (as of version 6.0) uses L2 norm as a stopping criteria while other packages use the L1 norm. This means that it is doing fewer iterations and the speed is somewhat artificial. Thanks Matthew!</span></p>
<p>graph-tool is the most steady performer and achieves very impressive performance across all four tasks. With openMP support it betters igraph and snap across all tasks. It is 3 to 10+ times faster than those two packages.</p>
<p>igraph and snap achieves mostly similar performance across all tasks with a slight edge towards snap. This is also consistent with snap‚Äôs research findings.</p>
</div>
<div id="other-considerations">
<h3>Other Considerations</h3>
<p>There are also other important considerations when making a switch from networkx or igraph to one graph-tool or networkit.</p>
<p><strong>Packages</strong><br>
First, the algorithms available differ quite significantly across the packages. Users interested in switching to one of these packages should read the documentation on the list of features available. For example, while they all contain the basic tools needed to manipulate networks, graph-tool does not have the more usual modular clustering tools but has additional functionalities on statistical inference on graphs using stochastic block models.</p>
<p>Visualising networks is also an important part of the analytical tool chain. Igraph implements quite a few layout algorithms and renders them using the cairo library. Snap supports graphviz while graph-tool supports both graphviz and cairo. Networkit takes a different approach and relies on networkx to draw while also providing support and integration with Gephi via its streaming plugin.</p>
<p><strong>API</strong><br>
Moving away from native Python or R means that the syntax for the packages can sometimes be quite convoluted. I compare the syntax for the shortest path problem below. Writing it in networkx would look something like this:</p>
<pre><code>nx.shortest_path_length(g, nodeid)</code></pre>
<p>igraph:</p>
<pre><code>g.shortest_paths([g.vs[node_index]])</code></pre>
<p>graph-tool:</p>
<pre><code>shortest_distance(g, g.vertex(node_index))</code></pre>
<p>networkit:</p>
<pre><code>distance.BFS(g, node_index).run()</code></pre>
<p>snap:</p>
<pre><code>NIdToDistH = snap.TIntH()
snap.GetShortPath(g, node_index, NIdToDistH, True)</code></pre>
<p>Of all, I find snap‚Äôs the most cumbersome since one has to define an additional variable (with the correct variable type) to store the results before running it. Running more advanced functions on graph-tool and networkit also requires a user to pre-define variables with the correct type to store results.<a href="#fn5" id="fnref5"><sup>5</sup></a></p>
<p><strong>Support and Documentation</strong><br>
User support and documentation is really important when one wants to use the project in an actual project setting. Networkx is by far the winner in this category with more than 4k github stars and lots of issues documented in github and stackoverflow. Igraph fairs decently as well with more than a thousand stars across its different modules.</p>
<p>graph-tool and networkit has much smaller followings though the creators seem relatively responsive to user issues and the packages are in active development.</p>
<p>snap was last updated on July 2018 but still supports only Python 2.7.x versions.</p>
</div>
<div id="conclusion">
<h3>Conclusion</h3>
<p>Overall, I am pleasantly surprised at the performance of the libraries especially graph-tool and networkit and plan to play around with them further. The fact that they breeze through the Pokec dataset is a good sign, but it will be interesting to find out what is the limit before computation becomes slow or memory issues start appearing.</p>
<p>As for recommendations on which package people should learn, I think picking up networkx is still important as it makes network science very accessible with a wide range of tools and capabilities. If analysis starts being too slow (and maybe that‚Äôs why you are here) then I will suggest taking a look at graph-tool or networkit to see if they contain the necessary algorithms for your needs.</p>
</div>
</div>



        
          
        

        

        
      </article>

      
        
      


      

    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://www.timlrx.com/2019/05/05/benchmark-of-popular-graph-network-packages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526881</guid>
            <pubDate>Sat, 19 Sep 2020 12:09:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Rust is not a mature programming language]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24526861">thread link</a>) | @DarkCrusader2
<br/>
September 19, 2020 | https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/ | <a href="https://web.archive.org/web/*/https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>While I have nothing against Rust as such and keep writing my pet project in Rust, there are still some deficiencies I find preventing Rust from being a proper programming language. Here I‚Äôd like to present them and explain why I deem them as such even if not all of them have any impact on me.<br>
<span id="more-1971"></span></p>
<h3>Rust language problems</h3>
<p>First and foremost, <strong>Rust does not have a formal language specification</strong> and by that I mean that while some bits like grammar and objects are explained, there are no formal rules to describe what language features can and cannot be. If you‚Äôve ever looked at ISO C standard you‚Äôve seen that almost any entity there has three or four parts in the description: formal syntax, constraints (i.e. what is not allowed or what can‚Äôt be done with it), semantics (i.e. what it does, how it impacts the program, what implementation caveats are there), and there may be some examples to illustrate the points. The best close equivalent in Rust is <a href="https://doc.rust-lang.org/reference/" rel="noopener noreferrer" target="_blank">The Rust Reference</a> and e.g. structure there is described in the following way: syntax (no objections there), definition in a form of ‚ÄúA struct is a nominal struct type defined with the keyword <code>struct</code>.‚Äù, examples, a brief mention of empty (or unit-like) structures in the middle of examples, and ‚ÄúThe precise memory layout of a struct is not specified.‚Äù at the end. I understand that adding new features is more important than documenting them but this is lame.</p>
<p>A proper mature language (with 1.0 in its version) should have a formal specification that should be useful both for people developing compilers and the programmers trying to understand certain intricacies of the language and why it does not work as expected (more on that later). For example, for that <code>struct</code> definition I find lacking at least these: mentioning that you can have <code>impl</code> for it (even a reference would do‚Äîeven if you have to repeat it for every type), split off tuples into a separate entry because it‚Äôs very different syntactically and raises a question why you have anonymous tuples and not anonymous structs (which you also can‚Äôt find from the documentation), and of course create proper layout so that rather important information (about memory layout for example) is not lost among examples.</p>
<p>And now to the specific problems I encounter quite often and I don‚Äôt know whether I understand it wrong or the compiler understands it wrong. And since there‚Äôs no formal specification I can‚Äôt tell which one it is (even if the former is most probable).</p>
<p><strong>Function/method calling convention.</strong> Here‚Äôs a simple example:</p>
<blockquote><p>
struct Foo { a: i32 }<br>
impl Foo { fn bar(&amp;mut self, val: i32) { self.a = val + 42; } }<br>
fn main() {<br>
&nbsp; let mut foo = Foo { a: 0 };<br>
&nbsp; foo.bar(foo.a);<br>
}
</p></blockquote>
<p>For now this won‚Äôt compile because of the borrowing but shouldn‚Äôt the compiler be smart enough to create a copy of <code>foo.a</code> before call? I‚Äôm not sure but IIRC current implementation first mutably borrows object for the call and only then tries to borrow the arguments. Is it really so and if yes, why? <em>Update:</em> I‚Äôm told that newer versions of the compiler handle it just fine but the question still stands (was it just a compiler problem or the call definition has been changed?).</p>
<p>The other thing is the old C caveat of function arguments evaluation. Here‚Äôs a simple example:</p>
<blockquote><p>
let mut iter = ‚Äúabc‚Äù.chars();<br>
foo(iter.next().unwrap(), iter.next().unwrap(), iter.next().unwrap());
</p></blockquote>
<p>So would it be <code>foo('a','b','c')</code> or <code>foo('c','b','a')</code> call. In C it‚Äôs undefined because it depends on how arguments are passed on the current platform (consider yourself lucky if you don‚Äôt remember <code>__pascal</code> or <code>__stdcall</code>). In Rust it‚Äôs undefined because there‚Äôs no formal specification to tell you even that much. And it would be even worse if you consider that you may use the same source for indexing the caller object like <code>handler[iter.next().unwrap() as usize].process(iter.next().unwrap());</code> in some theoretical bytecode handler (of course it‚Äôs a horrible way to write code and you should use named temporary variables but it should illustrate the problem).</p>
<p>And another source of annoyance for me is <strong>traits</strong>. I have almost no problems with owning/lifetime/borrowing concepts but traits get me almost every time. I‚Äôm vaguely aware that the answer to why the following problems exist is ‚Äúbecause traits are implemented as a call table‚Äù but again, <em>should</em> they be implemented like that and what should be the constraints on them (after all the original object should be somehow linked to the trait pointer). So when you have a supertrait (i.e. <code>trait Foo: Bar</code>) you can‚Äôt easily cast it for subtrait (e.g. <code>&amp;Foo -&gt; &amp;Bar</code>) without writing a lot of boilerplate code. And even worse if you convert an object into <code>Box&lt;trait&gt;</code> there‚Äôs no way to get the original object back (still in boxed form of course; I remember seeing a special crate that implements a lot of boilerplate code in order to get a mutable reference though). To reiterate: the problem is not me being stupid but rather the lack of formal description on how it‚Äôs done and why what I want is so hard. Then I‚Äôd probably at least be able to realize how I should change my code to work around the limitations.</p>
<h3><code>rustc</code> problems</h3>
<p>No, I‚Äôm not going to talk about compilation speed. It‚Äôs certainly a nuisance but not a problem per se. Here I want to point rather theoretical problems that a mature language should not have. And having just one compiler is one of those problems (call that problem zero).</p>
<p>First of all, <strong>bootstrapping process</strong> is laughably bad. I realize that it‚Äôs never too easy but if you call yourself a systems programming language you should be able to bootstrap a compiler in a sane amount of steps. For instance, IIRC <code>Guix</code> has the following bootstrapping process for C compiler: simple C complier in Scheme (for which you can often write an implementation in assembly by hand) compiles TCC, TCC compiles GCC 2.95, GCC 2.95 compiles GCC 3.7, GCC 3.7 compiles GCC 4.9. For <code>rustc</code> you should either start with the original compiler written in OCaml and compile every following version with the previous one (i.e. 1.17 with 1.16) or cheat by using <code>mrustc</code> written in C++ which can compile Rust 1.19 or 1.29 (without borrow checks), then compile 1.30 with 1.29, 1.31 with 1.30 etc etc. The problem here is that you cannot skip versions and e.g. compile <code>rustc 1.46</code> with <code>rustc 1.36</code> (I‚Äôd be happy to learn that I‚Äôm wrong). IMO you should have maybe an ineffective compiler but written in a dialect that much older compiler should understand i.e. <code>rustc 1.0</code> should be able to compile a compiler for 1.10, which can be used to compile 1.20 and so forth. Of course it‚Äôs a huge waste of resources for rather theoretical problem but it may prove beneficial for compiler design itself.</p>
<p>Then there‚Äôs <strong>LLVM dependency.</strong> I understand that <code>LLVM</code> provides many advantages (like no need to worry about code generation for many platforms and optimising it) but it gives some disadvantages too. First, you don‚Äôt have a really self-hosting compiler (a theoretical problem but still a thing worth thinking about; also consider that you have to rely on a framework developed mostly by large corporations mostly in their own interests). Second, you‚Äôre limited by what it does e.g. I read complaints about debug builds being too slow mostly because of LLVM backend. And I suspect it still can‚Äôt do certain kinds of memory-related optimisations because it was designed with C++ compiler in mind which still has certain quirks regarding multiple memory access (plus IIRC there was one LLVM bug triggered by an infinite loop in Rust code that‚Äôs perfectly valid there but not according to C++ rules). I‚Äôm aware that <code>cranelift</code> exists (and Rust front-end for <code>GCC</code>) so hopefully this will be improved.</p>
<p>And finally there‚Äôs a thing related to the previous problem. Rust has poor <strong>support for assembly</strong>. Of course not so many people need standalone assembly and not inline one (which is still lacking but <code>asm!</code> is almost there) but languages oriented for systems programming support compiling assembly in addition to the higher-language code so it would be <em>proper</em> to support assembly files even with not so rich preprocessor syntax as GAS has. Fiddling with <code>build.rs</code> to invoke an external assembler is possible but not nice at all.</p>
<h3>Other Rust language problems</h3>
<p>There‚Äôs also one problem with Rust <code>std</code> library that I should mention too. It‚Äôs useless for interfacing OS. Now if I want to do something natural to any UNIX system I need to at least import <code>libc</code> crate <del datetime="2020-09-19T03:32:25+00:00">and link against an external libc</del> (it‚Äôs part of the runtime anyway). One solution would be that crate I heard of that wanted to translate <code>musl</code> into Rust so you can at least eliminate the linking step. But the proper solution would be to support at least OS-specific syscall() in <code>std</code> crate as many interesting libc functions are just a wrapper over it (like <code>open()</code>/<code>write()</code>/<code>ioctl()</code>; Windows is a different beast so I don‚Äôt mind if it‚Äôs <code>std::os::unix::syscall</code> and not something more common).</p>
<hr>
<p>I‚Äôm not a Rust language architect and I‚Äôm extremely unlikely to become one but I have an opinion on what Rust lacks in order to become a proper mature language really fit for systems development (three things essentially: being fully self-hosted, having a specification, and being able to interface low-level stuff without resorting to C compiler or assembler). Hopefully this will be rectified despite the lack of Mozilla.</p>

								
				<p>
					<small>
												This entry was posted on Friday, September 18th, 2020 at 2:03 pm and is filed under <a href="https://codecs.multimedia.cx/category/rust/" rel="category tag">Rust</a>, <a href="https://codecs.multimedia.cx/category/useless-rants/" rel="category tag">Useless Rants</a>.						You can follow any responses to this entry through the <a href="https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/feed/">RSS 2.0</a> feed. 

													You can <a href="#respond">leave a response</a>, or <a href="https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/trackback/" rel="trackback">trackback</a> from your own site.
						
					</small>
				</p>

			</div></div>]]>
            </description>
            <link>https://codecs.multimedia.cx/2020/09/why-rust-is-not-a-mature-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526861</guid>
            <pubDate>Sat, 19 Sep 2020 12:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Philosophers in an influence graph with PageRank scores]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526402">thread link</a>) | @jonersRochen
<br/>
September 19, 2020 | https://s4n0i.github.io/schoolofathens/ | <a href="https://web.archive.org/web/*/https://s4n0i.github.io/schoolofathens/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Each node represents a philosopher. Nodes are linked if one philosopher was an influence to the other.
                The size of a node represents the overall influence of a philosopher on the network.</p><p>
                
                Click on a philosopher's node to get more info about them. You can also interact with the graph by dragging nodes, panning and zooming.
            </p></div></div>]]>
            </description>
            <link>https://s4n0i.github.io/schoolofathens/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526402</guid>
            <pubDate>Sat, 19 Sep 2020 10:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a scraper that finds the Best Remote Jobs Every Week on the web]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24526323">thread link</a>) | @xoelop
<br/>
September 19, 2020 | https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/ | <a href="https://web.archive.org/web/*/https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Hey everyone!</p><p>I'm <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">Xoel</a>, the creator of <a href="https://noicejobs.com/" rel="noopener noreferrer">NoiceJobs.com</a>. On this blog, we'll post the best remote jobs found every week, scraped, aggregated and curated from pretty much all job boards in the Internet.</p><p>For example...</p><ul> <li> üëâ üèù <a target="blank" href="https://bit.ly/2RxVom5">Senior Software Developer</a> at <b>Jupiter</b>
<br>
<b>$70,000 - $120,000 USD + Equity depending on experience</b>
<br> üè° Hiring in EU, Canada, US, Mexico, Central &amp; South America, Rest of Europe  <p>‚Ä¢ We're looking for someone to help <strong>build and support new features</strong> as we scale out the product and company. You will be primarily working with <strong>React, React Native, Node.js</strong>, and <strong>GraphQL</strong>.<br>‚Ä¢ We're looking for someone who is particularly interested in creating systems within the constraints of a <strong>start-up</strong>.<br>‚Ä¢ And finally: we're <strong>bootstrapped</strong>, so far, <strong>building a sustainable business we all want to work at</strong>.</p>
<br> üì® Wanna get an intro with Rich, CTO at Jupiter? <a href="https://airtable.com/shrzoNF0Lcz50u9oh?prefill_open_for_offers=TRUE%20&amp;prefill_extra_info_reported=I%27m%20interested%20in%20the%20Senior%20Software%20Developer%20position%20at%20Jupiter.%0A%0AThis%20is%20why%20I%20think%20I%27m%20a%20great%20candidate%20for%20this%20position%3A" target="_blank" rel="noopener noreferrer">Join NoiceJobs</a> if you haven't yet or <a href="https://blog.noicejobs.com/cdn-cgi/l/email-protection#51293e343d113f3e3832343b3e33227f323e3c6e2224333b3432256c183f25233e746361373e2374636125393474636102343f383e23746361023e372526302334746361153427343d3e213423746361213e223825383e3f74636130257463611b242138253423" target="_blank" rel="noopener noreferrer">email us</a> if you're a member already.
<br> </li> </ul>
<p> Wanna promote your job on NoiceJobs? <a href="#hiring">Check this out</a> </p><p>This post will make it easier to navigate the blog and all the different categories. Jump to...</p><ul> <li> <a href="#Engineering">üñ• Best Remote Engineering jobs found this week</a> </li> <li> <a href="#Product">üñº Best Remote Product jobs found this week</a> </li> <li> <a href="#Business">üíµ Best Remote Business jobs found this week</a> </li> <li> <a href="#Other">üíº Best Other Remote jobs found this week</a> </li> </ul>
<p>BTW: now you can also get these jobs every week <a href="#newsletter">via email!</a></p><h2 id="-best-remote-engineering-jobs-found-this-week">üñ• Best Remote Engineering jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-cto-26-tech-lead-remote-jobs-between-sep-11-and-sep-18/">CTO &amp; Tech Lead jobs</a><br><a href="https://blog.noicejobs.com/best-senior-engineering-manager-remote-jobs-between-sep-11-and-sep-18/">Engineering Manager jobs</a><br><a href="https://blog.noicejobs.com/best-senior-fullstack-remote-jobs-between-sep-11-and-sep-18/">Fullstack jobs</a><br><a href="https://blog.noicejobs.com/best-senior-frontend-remote-jobs-between-sep-11-and-sep-18/">Frontend jobs</a><br><a href="https://blog.noicejobs.com/best-senior-backend-remote-jobs-between-sep-11-and-sep-18/">Backend jobs</a><br><a href="https://blog.noicejobs.com/best-senior-sre-26-devops-remote-jobs-between-sep-11-and-sep-18/">SRE &amp; Devops jobs</a><br><a href="https://blog.noicejobs.com/best-senior-infosec-remote-jobs-between-sep-11-and-sep-18/">Infosec jobs</a><br><a href="https://blog.noicejobs.com/best-senior-mobile-remote-jobs-between-sep-11-and-sep-18/">Mobile jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ios-remote-jobs-between-sep-11-and-sep-18/">iOS jobs</a><br><a href="https://blog.noicejobs.com/best-senior-android-remote-jobs-between-sep-11-and-sep-18/">Android jobs</a><br><a href="https://blog.noicejobs.com/best-senior-python-remote-jobs-between-sep-11-and-sep-18/">Python jobs</a><br><a href="https://blog.noicejobs.com/best-senior-javascript-remote-jobs-between-sep-11-and-sep-18/">Javascript jobs</a><br><a href="https://blog.noicejobs.com/best-senior-java-remote-jobs-between-sep-11-and-sep-18/">Java jobs</a><br><a href="https://blog.noicejobs.com/best-senior-rails-ruby-remote-jobs-between-sep-11-and-sep-18-2/">Rails/Ruby jobs</a><br><a href="https://blog.noicejobs.com/best-senior-go-remote-jobs-between-sep-11-and-sep-18/">Go jobs</a><br><a href="https://blog.noicejobs.com/best-senior-rust-remote-jobs-between-sep-11-and-sep-18/">Rust jobs</a><br><a href="https://blog.noicejobs.com/best-senior-php-remote-jobs-between-sep-11-and-sep-18/">PHP jobs</a><br><a href="https://blog.noicejobs.com/best-senior-wordpress-remote-jobs-between-sep-11-and-sep-18/">Wordpress jobs</a><br><a href="https://blog.noicejobs.com/best-senior-qa-remote-jobs-between-sep-11-and-sep-18/">QA jobs</a><br><a href="https://blog.noicejobs.com/best-senior-solutions-architect-remote-jobs-between-sep-11-and-sep-18/">Solutions Architect jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-science-26-ml-remote-jobs-between-sep-11-and-sep-18-2/">Data Science &amp; ML jobs</a><br><a href="https://blog.noicejobs.com/best-senior-nlp-26-nlg-remote-jobs-between-sep-11-and-sep-18-2/">NLP &amp; NLG jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-engineering-26-big-data-remote-jobs-between-sep-11-and-sep-18-2/">Data Engineering &amp; Big Data jobs</a><br><a href="https://blog.noicejobs.com/best-senior-shopify-remote-jobs-between-sep-11-and-sep-18/">Shopify jobs</a><br><a href="https://blog.noicejobs.com/best-senior-gis-remote-jobs-between-sep-11-and-sep-18/">GIS jobs</a><br><a href="https://blog.noicejobs.com/best-senior-react-remote-jobs-between-sep-11-and-sep-18/">React jobs</a><br><a href="https://blog.noicejobs.com/best-senior-vue-remote-jobs-between-sep-11-and-sep-18/">Vue jobs</a><br><a href="https://blog.noicejobs.com/best-devrel-remote-jobs-found-between-sep-02-and-sep-09/">DevRel jobs</a><br><a href="https://blog.noicejobs.com/best-senior-game-dev-26-design-remote-jobs-between-sep-11-and-sep-18-2/">Game Dev &amp; Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-haskell-remote-jobs-between-sep-11-and-sep-18/">Haskell jobs</a><br><a href="https://blog.noicejobs.com/best-senior-scala-remote-jobs-between-sep-11-and-sep-18/">Scala jobs</a><br><a href="https://blog.noicejobs.com/best-generalist-remote-jobs-between-sep-11-and-sep-18/">Generalist jobs</a><br><a href="https://blog.noicejobs.com/best-senior-c-2b-2b-remote-jobs-between-sep-11-and-sep-18-2/">C++ jobs</a><br><a href="https://blog.noicejobs.com/best-senior-net-remote-jobs-between-sep-11-and-sep-18-2/">.NET jobs</a><br></p><h2 id="-best-remote-product-jobs-found-this-week">üñº Best Remote Product jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-cpo-remote-jobs-between-sep-11-and-sep-18/">CPO jobs</a><br><a href="https://blog.noicejobs.com/best-senior-product-manager-remote-jobs-between-sep-11-and-sep-18/">Product Manager jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ux-26-product-design-remote-jobs-between-sep-11-and-sep-18/">UX &amp; Product Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ui-design-remote-jobs-between-sep-11-and-sep-18/">UI Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-art-26-visual-design-remote-jobs-between-sep-11-and-sep-18/">Art &amp; Visual Design jobs</a><br><a href="https://blog.noicejobs.com/best-senior-copywriting-remote-jobs-between-sep-11-and-sep-18/">Copywriting jobs</a><br><a href="https://blog.noicejobs.com/best-senior-video-editing-remote-jobs-between-sep-11-and-sep-18/">Video Editing jobs</a><br></p><h2 id="-best-remote-business-jobs-found-this-week">üíµ Best Remote Business jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-sales-remote-jobs-between-sep-11-and-sep-18/">Sales jobs</a><br><a href="https://blog.noicejobs.com/best-senior-sdr-remote-jobs-between-sep-11-and-sep-18/">SDR jobs</a><br><a href="https://blog.noicejobs.com/best-senior-legal-remote-jobs-between-sep-11-and-sep-18/">Legal jobs</a><br><a href="https://blog.noicejobs.com/best-senior-operations-remote-jobs-between-sep-11-and-sep-18/">Operations jobs</a><br><a href="https://blog.noicejobs.com/best-senior-customer-support-remote-jobs-between-sep-11-and-sep-18/">Customer Support jobs</a><br><a href="https://blog.noicejobs.com/best-senior-seo-2c-sem-remote-jobs-between-sep-11-and-sep-18/">SEO, SEM jobs</a><br><a href="https://blog.noicejobs.com/best-senior-marketing-remote-jobs-between-sep-11-and-sep-18/">Marketing jobs</a><br><a href="https://blog.noicejobs.com/best-senior-growth-remote-jobs-between-sep-11-and-sep-18/">Growth jobs</a><br><a href="https://blog.noicejobs.com/best-senior-agile-scrum-remote-jobs-between-sep-11-and-sep-18-2/">Agile/Scrum jobs</a><br><a href="https://blog.noicejobs.com/best-senior-data-business-analyst-remote-jobs-between-sep-11-and-sep-18-2/">Data/Business Analyst jobs</a><br><a href="https://blog.noicejobs.com/best-senior-finance-26-investing-remote-jobs-between-sep-11-and-sep-18-2/">Finance &amp; Investing jobs</a><br><a href="https://blog.noicejobs.com/best-senior-accounting-26-bookkeping-remote-jobs-between-sep-11-and-sep-18-2/">Accounting &amp; Bookkeping jobs</a><br><a href="https://blog.noicejobs.com/best-senior-ecommerce-remote-jobs-between-sep-11-and-sep-18/">Ecommerce jobs</a><br><a href="https://blog.noicejobs.com/best-senior-social-media-remote-jobs-between-sep-11-and-sep-18/">Social Media jobs</a><br></p><h2 id="-best-other-remote-jobs-found-this-week">üíº Best Other Remote jobs found this week</h2><p><a href="https://blog.noicejobs.com/best-senior-software-contract-26-freelance-remote-jobs-between-sep-11-and-sep-18/">Software Contract &amp; Freelance jobs</a><br><a href="https://blog.noicejobs.com/best-senior-software-part-time-remote-jobs-between-sep-11-and-sep-18/">Software Part-time jobs</a><br><a href="https://blog.noicejobs.com/best-junior-remote-jobs-between-sep-11-and-sep-18/">Junior jobs</a><br></p>
<h2>üì© Get these jobs as weekly newsletters</h2>

<h2 id="hiring"> Are you hiring remotely?
</h2>
<p> üì£ If so, you can now <a href="https://airtable.com/shreWkzRKtq6oQFiK" target="_blank" rel="noopener noreferrer">post a job on NoiceJobs</a> to reach up to thousands of talented remote workers.
</p>
<p> Some numbers on NoiceJobs' audience:
</p>
<ul> <li> More than <b>3000 subscribers</b> on our <a href="https://t.me/noicejobs" target="_blank" rel="noopener noreferrer">Telegram channels</a> </li> <li> <b>Hundreds of people registered</b> on NoiceJobs and get these posts weekly </li> <li> This blog (launched on September 9) had <b><span id="pageviews"></span> page views</b> in the last month (verified by <a href="https://referral.simpleanalytics.com/xoel" target="_blank" rel="noopener noreferrer">Simple Analytics</a>). </li> <li> Our traffic analytics are 100% open. <a href="https://simpleanalytics.com/blog.noicejobs.com" target="_blank" rel="noopener noreferrer">Check them out here üëÄ</a> and see our pageviews in the graph below </li>
</ul>
<div> <p> A cool graph with our visits would go here, but ad blockers don't like the Simple Analytics embed. Disable yours if you'd like to view it :) </p>
</div>
<h3 id="that-s-it-">That's it!</h3><p>I also share jobs like these in these <a href="https://t.me/NoiceJobs">Telegram channels</a>. More than 3,000 people are subscribed to them.</p><p>Have a good weekend!</p><p>Xoel - <a href="https://twitter.com/xoelipedes" rel="noopener noreferrer">I'm on Twitter too. Say hi!</a></p>
</div>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.noicejobs.com/best-remote-jobs-in-the-world-between-sep-11-and-sep-18/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526323</guid>
            <pubDate>Sat, 19 Sep 2020 09:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Way to Find Clients for Your IT Consulting Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24526274">thread link</a>) | @kureikain
<br/>
September 19, 2020 | https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/ | <a href="https://web.archive.org/web/*/https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-197">

    

	<div>

		
<p>As an experienced software engineer or IT professional, you have spent many years building up your expertise and your skill-set. You‚Äôve built many solutions and you have solved many problems for clients of various sizes. You have finally decided to turn your expertise into a proper business and escape the rat race once and for all. </p>



<p>Perhaps you‚Äôve even put a team together and have managed to secure a client or two with some decent projects. Everything is looking promising. </p>



<p>Except you run into a little problem. </p>



<p>You have NO idea how to get more clients. </p>



<p>The B2B sales process for technology products and services is complicated, it requires reaching out to the right people who are in a position to make a decision and navigating a complex sales cycle, and you don‚Äôt even know where to begin. In fact, you hate this part You really really do. You‚Äôre a technology person after all. You‚Äôre brilliant at what you do. Surely you shouldn‚Äôt have to engage in low-life scummy sales tactics to find clients. You really hate this part. </p>



<p>But you have a business now, so you try. You send out some cold e-mails. You pitch some people on LinkedIn. You spend some money on social media ads, and it just goes down a drain. And then‚Ä¶. nothing. Zero. You have NO new clients. You‚Äôre in a rut. You begin to panic.</p>



<hr>



<p>But there is good news. </p>



<p>Let‚Äôs take a step back. Whenever you find yourself in a rut, always take a step back. Take a few deep breaths, calm yourself down for a moment, and try to get more general. Try to look at the big picture. You have to put the problems aside for a moment so you can clear your mind and take a fresh look.</p>



<p>The good news is that there is a clear path to what you want.</p>



<p>In fact, you already have the components in place.</p>



<p>The first step is to realise that your professional career so far has given you a valuable competitive advantage.</p>



<p>You now know certain things and can do certain things that very few people on the planet know or can do. </p>



<p>The second step is to realise there is demand for these special skills and knowledge you possess.</p>



<p>There are business owners, managers, decision makers, leaders who are, right now, in need of what you know and what you can do for them. More importantly, many of them have both the willingness and the ability to compensate you generously if you can help them solve specific challenges they are currently facing, or specific goals they are currently committed to achieving.</p>



<p>The third step is to realise that you already have direct access to most of these people. It‚Äôs called LinkedIn (or, more broadly, social media).</p>



<p>As you can see, I was not being wishy-washy when I said the components are already in place. All 3 of the above are indeed already in place.</p>



<p>The path to what you want is through aligning yourself ‚Äì your internal beliefs, your presentation and the messaging you put out ‚Äì so you position yourself to be the natural choice for those seeking your expertise.</p>



<p>And yes, you do have to learn to sell. But this doesn‚Äôt have to be so intimidating and you certainly don‚Äôt have to feel like a low-life doing this. So take another deep breath, and allow yourself to get friendly with sales for a moment. Soon you will be best friends ‚Äì better than you know. </p>



<p>I‚Äôll give you a blueprint to follow, right here in this post. And in the future I‚Äôll go into many more details, but this here should be more than enough to get you started. You shouldn‚Äôt need ANYTHING else, don‚Äôt get yourself overwhelmed. It‚Äôs actually very simple and even easy. </p>



<p>First I‚Äôll tell you what NOT to do. </p>



<p>Then I‚Äôll give you a few basic steps to follow.</p>



<hr>



<p>First and foremost ‚Äì DO NOT go hire anyone to do this for you. Trust me on this one. No one can market or sell your product for you before you‚Äôve mastered this process yourself first. You MUST learn to sell your own products and services, there is no way around it. What‚Äôs more ‚Äì no one can do it better than you. You KNOW what you‚Äôre good at. You KNOW what you‚Äôve been able to do for other clients before. You KNOW what problems you‚Äôve been able to solve. You‚Äôve SEEN people and businesses struggle and make wrong decisions and regret them and you KNOW how to do this right. You know how to do it better. No one else can communicate this better than you. No one can be more convincing. No one can connect with your future clients better than you. </p>



<p>Second, avoid paid advertising before you‚Äôve learned how to generate high-ticket sales without it. Paid ads are an amplifier. If you‚Äôre making zero sales right now, the result of putting lots and lots of money in paid ads will be lots and lots of money multiplied by zero. Don‚Äôt waste your time and money doing this. I‚Äôve been there. It ain‚Äôt pretty. </p>



<p>Repeat after me: Paid ads and sales people are for scaling only. Once you‚Äôve got your offer and your messaging down to a proven working system, you can then pay for ads and hire sales people to go 10x or 100x bigger. But you are not ready for this. Delay this phase as long as possible. When the time comes, you will know it. </p>



<p>Finally, for the love kittens, please don‚Äôt go spamming people left and right with your offer. Don‚Äôt send e-mails. Don‚Äôt talk to strangers on messenger. Don‚Äôt call them on the phone. Don‚Äôt ask for appointments. Just don‚Äôt, ok? Don‚Äôt do it. No one likes that. It won‚Äôt get you anywhere. </p>



<p>There IS a better way.</p>



<hr>



<p>So here is what to do.</p>



<p>You can get started today, easily. And you can see results quickly, without spending a fortune on anyone or anything.</p>



<p>Your biggest problem right now is obscurity. No one knows you exist. Simple as that.</p>



<p>To start getting more sales, you have to get out there where relevant people can see you so that A) they know you exist and B) you get an opportunity to speak directly to their current pains and frustrations.</p>



<p>As tacky as it sounds, social media turns out to be useful for this.</p>



<p>I‚Äôve found that LinkedIn can be pretty great for B2B sales ‚Äì but I‚Äôve also seen people get good results with high-ticket sales on Facebook as well. (Once again, though ‚Äì DO NOT just go spamming people on LinkedIn! Keep calm and read on.)</p>



<p>There is a structure and sequence to the approach. You have to do things in the right order  and you have to get through some things first, but it‚Äôs easy, there‚Äôs no big expenses involved, and you can start getting results in weeks or even days if you do this right.</p>



<p>The first steps go like this:</p>



<ol><li>Get as much clarity as you can on who your ideal clients are and what your main offer is. I think you already have a good idea about this, but always worth thinking harder about it and putting it in writing for yourself and your team. Make sure to think about your ideal client as A PERSON, even if we‚Äôre talking billion-dollar corporations here. At the end of the day someone has to make a decision and write a check.</li><li>Prime your LinkedIn profile. Make it look professional. Use the tag-line to speak directly to your ideal buyer (this requires some creativity and it‚Äôs a bit of a process ‚Äì don‚Äôt be afraid to keep changing it, but once you find something that works, stick with it.) Use the longer ‚ÄúAbout‚Äù section to do more of the same. You have to basically turn that into a mini sales letter. Don‚Äôt go into many technical details ‚Äì always write as if it‚Äôs coming out of your ideal client‚Äôs head. Think of their situation, their current struggles and challenges, the urgency of the problem, and how you can relieve that. Talk about what they will gain from working with you and the amount of time, effort and money they will save.</li><li>Start adding very targeted connections ‚Äì on a daily basis. If you wish, you can pay for LinkedIn‚Äôs Sales Navigator, but I‚Äôve found that the basic search works good enough for me. Every day run a search for people who may be in a position to make decisions about your offer (or go through your LinkedIn network recommendations) and just send out connection requests to 5 ‚Äì 10 people each day day (but don‚Äôt go crazy and start adding everyone indiscriminately.) You can add a little personalisation note, but I‚Äôm not sure it makes much of a difference with most people. Your profile (and especially the tag-line) should be able to speak for itself. There are people who use LinkedIn for networking and they will usually accept your connection request. Then there are people who don‚Äôt like connecting with strangers and they will ignore you. Don‚Äôt make a big deal out of it, don‚Äôt take it personally, just stick to the process and turn it into a habit.</li><li>While you are growing your network, start making more regular posts. You should aim for once a day, on average. You can do more (but not much more) or less (but not much less). In your posts, you can do a number of different things, but the whole point is to imagine you are speaking directly to your ideal clients. Don‚Äôt be too sales-y all the time, just speak from your expertise and experience. Talk about their problems and your solution to them. Talk about what you‚Äôve done for other similar clients and the specific benefits they‚Äôve experienced. Talk especially about saving time ‚Äì that‚Äôs a big one. </li><li>Don‚Äôt be discouraged if you get little to no interactions with your posts at first! This DOESN‚ÄôT mean people aren‚Äôt reading your content. Many people (especially busy people) will not react to your content, but if it‚Äôs relevant they WILL read it. When people do start interacting with your posts, feel free to start conversations with them. Keep the conversation exploratory and see how you can be of service. If you can get them on the phone, even better. Just keep this in mind: your first job is NOT to try to sell them anything. It‚Äôs to understand whether or not you‚Äôre a good fit for working together and to genuinely give them the advice that‚Äôs best for them. If this happens to mean working with you, great ‚Äì don‚Äôt be shy about it either. </li><li>Once every few weeks, make a post with a very direct offer, ‚Ä¶</li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/">https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/</a></em></p>]]>
            </description>
            <link>https://corebrief.com/2020/09/09/a-better-way-to-find-clients-for-your-it-consulting-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24526274</guid>
            <pubDate>Sat, 19 Sep 2020 09:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How attractive is your website? Check using Visual Mind AI]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 160 (<a href="https://news.ycombinator.com/item?id=24525995">thread link</a>) | @myraahio
<br/>
September 19, 2020 | https://myraah.io/visualmind | <a href="https://web.archive.org/web/*/https://myraah.io/visualmind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              
              <h4>Visual rank of your website is as important as your SEO rank.</h4>
              <p>Users make lasting judgments about a website‚Äôs appeal within a split second.  This first impression is influential enough to later affect their opinions of a site‚Äôs usability and trustworthiness.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind ?</h4>
              <p>Visual Mind is an AI engine specifically designed for understanding and scoring visual appearance of a website. Visual Mind has analyzed over a million websites to achieve an accuracy rate of over 97%.</p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
              
              <h4>What is Visual Mind Score and why it matters ?</h4>
              <p>For too long, aesthetics of a website has been dismissed as a superficial concern. That is a mistake. As latest research demonstrates ( See recommended ref) , the visual appeal of a website is tied up with far weightier issues, such as functionality and trustworthiness.</p>
              <p>Have you ‚Äúfast-tested‚Äù your website? Remember, you have only fifty milliseconds to impress your visitors. Flash your website to people for a very short period of time and then ask for their opinion. That is the opinion that matters.</p>
              <p>Visual Mind score ‚Äì provides you with a qualitative score about that first impression. It can help you evaluate your website aesthetics and make improvements.</p>
              <p><a href="https://myraah.io/index.php/visualmind">Check Your VM SCORE</a></p>
            </div>
          </div> <!-- col -->
        </div><div>
          <div>
            <div>
				<h4>Want to explore more ‚Äì we recommend</h4>
              <p>A.  Bauerly, M., and Liu, Y. Effects of Symmetry and Number of Compositional Elements on Interface and Design Aesthetics. Int. Journal of Human-Computer Interaction 3 (2008).</p>
              <p>B. Cyr, D. Modeling Website Design across Cultures: Relationships to Trust, Satisfaction and E-loyalty. Journal of Management Information Systems 24, 4 (2008)</p>
              <p>C. Everard, A., and Galletta, D. How presentation flaws affect perceived site quality, trust, and intention to purchase from an online store. Journal of Management Information Systems 22, 3 (2006)</p>
              <p>D. Geissler, G., Zinkhan, G., and Watson, R. The Influence of Home Page Complexity on Consumer Attention, Attitudes, and Purchase Intent. Journal of Advertising 35, 2 (2006)</p>
              <p>E. Hall, R. H., and Hanna, P. The Impact of Web Page Text-background Colour Combinations on Readability,Retention, Aesthetics and Behavioural Intention. Behaviour &amp; Information Technology 23, 3 (2004)</p>
              <p>G. Lindgaard, G., Fernandes, G., Dudek, C., and Brown, J. Attention Web Designers: You Have 50 Milliseconds to Make a Good First Impression! Behaviour &amp; Information Technology 25, 2 (2006)</p>
              <p>H. Michailidou, E., Harper, S., and Bechhofer, S. Visual Complexity and Aesthetic Perception of Web Pages. Proc. Design of Communication (2008)</p>
              <p>I. Tuch, A. N., Bargas-Avila, J. A., and Opwis, K. Symmetry and Aesthetics in Website Design: It‚Äôs a Man‚Äôs Business. Computers in Human Behavior 26, 6 (2010)</p>
              
			</div>
          </div> <!-- col -->
        </div></div>]]>
            </description>
            <link>https://myraah.io/visualmind</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525995</guid>
            <pubDate>Sat, 19 Sep 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CrazyFast Crystal based 88x31 visitor counter img generator brought back to 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525873">thread link</a>) | @gcds
<br/>
September 19, 2020 | https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/ | <a href="https://web.archive.org/web/*/https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1502570149819-b2260483d302?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Evening Project: A Crystal based super fast visitor counter">
            </figure>

            <section>
                <div>
                    <p>I have taken this week's holidays with the plan that the Overkill Workbench materials would be delivered today, but in the end, it will be delivered on Sunday, so I have a lot of free time on my hands.</p><p>Yesterday, while talking with some friends, I remembered old good &lt;2008 websites, portals, and how we created them; one of the most prominent features I loved about that period was 88x31, and 120x60 sized Ad's/Counters and other goodies. It was always a fight between website authors fighting for a higher number of page visits and similar metrics. Nowadays, everything is hidden and typical, only seen by webmasters on Google Analytics and similar tools.</p><p>So today's my evening project is <a href="https://crystal-lang.org/">Crystal</a> language-based 88x31 website visitor counter image rendered entirely in <a href="https://crystal-lang.org/">Crystal</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-60.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-60.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-60.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-60.png 1600w, https://www.techprowd.com/content/images/2020/09/image-60.png 1754w" sizes="(min-width: 720px) 720px"></figure><h2 id="requirements-">Requirements:</h2><ul><li>A single endpoint would return 88x31 sized png with numbers</li><li>Provide two numbers, one unique visitor count, and other total visits.</li><li>Do not depend on external libraries for image generation.</li><li>Use the least amount of resources like memory and disk space. (Maybe one day my blog will be viral, who knows)</li><li>Most important, be as fast as possible!</li></ul><h2 id="architecture-">Architecture:</h2><p>The plan is to run the crystal internal HTTP server without any overhangs and host it on Heroku free plan.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-61.png" alt=""></figure><p>Store user identifiers in Redis for uniqueness measurement and fast lookup (Remember we need speed)</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source.gif" alt=""></figure><p>I found a shard (Crystal libraries are called shards) for image rendering, which can generate a PNG image using raw X, Y pixel information no external libraries used.</p><figure><a href="https://github.com/stumpycr/stumpy_png"><div><p>stumpycr/stumpy_png</p><p>Read/Write PNG images in pure Crystal. Contribute to stumpycr/stumpy_png development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>GitHub</span></p></div><p><img src="https://avatars0.githubusercontent.com/u/27729351?s=400&amp;v=4"></p></a></figure><p>For Redis client, I am going to use this shard:</p><figure><a href="https://github.com/stefanwille/crystal-redis"><div><p>stefanwille/crystal-redis</p><p>Full featured Redis client for Crystal. Contribute to stefanwille/crystal-redis development by creating an account on GitHub.</p><p><img src="https://github.githubassets.com/favicons/favicon.svg"><span>stefanwille</span><span>GitHub</span></p></div><p><img src="https://avatars2.githubusercontent.com/u/331756?s=400&amp;v=4"></p></a></figure><h2 id="step-1-rendering-image">Step 1: Rendering image</h2><p>As I have chosen image size to be 88x31, I need to try to fit two numbers. Total visits - Every load counts and Unique Visitors - Number of unique visitors.</p><p>I have drawn some sample representation I imagine in Photoshop:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-62.png" alt=""></figure><p>It looks tiny on my 4K monitor, but back in 2005, it looked huge on my 1024x768 monitor.</p><p>One of the problems now that I am not using external libraries is that I have no simple way to render text on the image. That's not a big deal, remembering practices I used for Graphical LCD/OLED on embedded electronic projects. I will create an array of Tuples of 3 uint8 integers of each pixel information in a 7x10 array for each number.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-64.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-64.png 600w, https://www.techprowd.com/content/images/2020/09/image-64.png 800w" sizes="(min-width: 720px) 720px"></figure><p>To make each number in array format, I need to generate 7x10 images of each number. Then using the <a href="https://javl.github.io/image2cpp/">https://javl.github.io/image2cpp/</a> tool, I generated arrays for each character.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x939393%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x404141%252C%25200xa4a4a4%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x787879%252C%25200x6e6f6f%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xababab%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x212222%252C%25200xababab%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x646465%252C%25200xb3b3b3%252C%25200x939393%252C%25200xababab%252C%25200x828282%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x212222%252C%25200x4d4e4e%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D"><img src="https://www.techprowd.com/content/images/2020/09/carbon--19-.png" alt="carbon--19-"></a></p>
<!--kg-card-end: markdown--><p>Now that I have pixel data of each character, I can finally create a whole image.</p><p>Knowing the array's exact size, in our case, it's 7x10; we can loop through the array and fill in all pixels referenced from a given position.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%253A%253ACharacters%250A%2520%2520%2520%2520CHARACTER_WIDTH%2520%253D%25207%250A%2520%2520%2520%2520CHARACTER_HEIGHT%2520%253D%252010%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520TWO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x828282%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200xababab%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x323233%252C%25200x646465%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x404141%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x646465%252C%25200x939393%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x8b8b8b%252C%25200x787879%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x404141%252C%25200x939393%252C%25200x404141%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x9b9c9c%252C%25200x212222%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200xb3b3b3%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ONE%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x4d4e4e%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x323233%252C%25200x9b9c9c%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200x939393%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x6e6f6f%252C%25200x6e6f6f%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x0a0b0c%250A%2520%2520%2520%2520%255D%2520%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520ZERO%2520%253D%2520%255B%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x0a0b0c%252C%25200x59595a%252C%25200x6e6f6f%252C%25200x646465%252C%25200x212222%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200x787879%252C%25200xa4a4a4%252C%25200x6e6f6f%252C%25200x939393%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x0a0b0c%252C%25200xb3b3b3%252C%25200x323233%252C%25200x0a0b0c%252C%25200x0a0b0c%252C%25200xa4a4a4%252C%25200x4d4e4e%252C%2520%250A%2520%2520%2520%2520%2520%2520%2520%25200x4d4e4e%252C%25200x9b9c9c%252C%25200x0a0b0c%252C%2520"><img src="https://www.techprowd.com/content/images/2020/09/carbon--20-.png" alt="carbon--20-"></a></p>
<!--kg-card-end: markdown--><p>After trying out <code>VisitorCounter::Characters.render_character</code> function I was able to see it working correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-65.png" alt=""></figure><p>Now it's time to wrap it all and make the main function, which would generate and return generated image as <code>IO::Memory</code> buffer.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/carbon--21--1.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/carbon--21--1.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/carbon--21--1.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/carbon--21--1.png 1600w, https://www.techprowd.com/content/images/2020/09/carbon--21--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><p>To make more usable, I added this image generator to a simple HTTP server and returned random numbers generated in response.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Ainclude%2520StumpyPNG%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Aserver%2520%253D%2520HTTP%253A%253AServer.new%2520do%2520%257Ccontext%257C%250A%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%250A%2520%2520image%2520%253D%2520VisitorCounter%253A%253AImageGenerator.generate(%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520%2520%2520Random.new.rand(1..99999999)%252C%250A%2520%2520)%250A%250A%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520IO.copy(image%252C%2520context.response)%250Aend%250A%250Aaddress%2520%253D%2520server.bind_tcp%25208080%250Aputs%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250Aserver.listen%250A"><img src="https://www.techprowd.com/content/images/2020/09/carbon--22-.png" alt="carbon--22-"></a></p>
<!--kg-card-end: markdown--><p>After running this code and going to <code>http://127.0.0.1:8080</code> I received generated image with random numbers.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-66.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-66.png 600w, https://www.techprowd.com/content/images/2020/09/image-66.png 612w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-67.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-67.png 600w, https://www.techprowd.com/content/images/2020/09/image-67.png 612w"></figure><p>Now we can move on to a more exciting part, which is counting visitors.</p><h2 id="step-2-counting-visitors">Step 2: Counting Visitors</h2><p>To count visitors first, we need some kind of unique value. In this project, I am going to use the IP address of the client. As I plan to host this on Heroku, I know that IP will only be IPv4, so I can safely convert the IP address from 127.0.0.1 to its bytes equivalent by merging all 4 x Int8 parts of IP this way it will take less space in Redis memory 4 bytes instead of 15 bytes.</p><p>This is a function which extracts IP address from request. As I mentioned before, this will be hosted on Heroku, so the client IP address will be available in the HTTP header <code>X-Forwarded-For</code> as a load balancer will replace the client IP address with its own.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520extract_ip(request)%250A%2520%2520%2520%2520ip%2520%253D%2520request.headers%255B%2522X-Forwarded-For%2522%255D%253F%250A%2520%2520%2520%2520if%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520case%2520remote_address%2520%253D%2520request.remote_address%250A%2520%2520%2520%2520%2520%2520%2520%2520when%2520Socket%253A%253AIPAddress%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520remote_address.address%250A%2520%2520%2520%2520%2520%2520%2520%2520else%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip%2520%253D%2520nil%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520unless%2520ip.nil%253F%250A%2520%2520%2520%2520%2520%2520a%252C%2520b%252C%2520c%252C%2520d%2520%253D%2520ip.split(%27.%27)%250A%250A%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520Slice(UInt8).new(4)%250A%2520%2520%2520%2520%2520%2520ip_address%255B0%255D%2520%253D%2520a.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B1%255D%2520%253D%2520b.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B2%255D%2520%253D%2520c.to_u8%250A%2520%2520%2520%2520%2520%2520ip_address%255B3%255D%2520%253D%2520d.to_u8%250A%250A%2520%2520%2520%2520%2520%2520return%2520String.new(ip_address)%250A%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520nil%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--25-.png" alt="carbon--25-"></a></p>
<!--kg-card-end: markdown--><p>If the IP address is not available for some reason, I will skip this visit from a unique visit count and just increase the total visit count.</p><p>Now wrapping everything into <code>WebHandler</code>, which will nicely integrate into HTTP Server, we should have a working counter.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=module%2520VisitorCounter%250A%2520%2520%2520%2520class%2520WebHandler%250A%2520%2520%2520%2520%2520%2520%2520%2520include%2520HTTP%253A%253AHandler%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_OFFSET_KEY%2520%253D%2520%2522UNIQUE_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_OFFSET_KEY%2520%253D%2520%2522TOTAL_VISITS_OFFSET%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520TOTAL_VISITS_KEY%2520%253D%2520%2522TOTAL_VISITS%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520UNIQUE_VISITS_KEY%2520%253D%2520%2522UNIQUE_VISITS%2522%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520initialize(redis%2520%253A%2520Redis%253A%253APooledClient)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis%2520%253D%2520redis%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520def%2520call(context)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers%255B%2522Server%2522%255D%2520%253D%2520%2522Techprowd%2520Visitor%2520Counter%2520v1.0%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520context.request.method%2520%253D%253D%2520%2522GET%2522%2520%257C%257C%2520context.request.method%2520%253D%253D%2520%2522HEAD%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.status_code%2520%253D%2520405%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.headers.add(%2522Allow%2522%252C%2520%2522GET%252C%2520HEAD%2522)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520context.request.path.not_nil!%2520!%253D%2520%2522%252F%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520call_next(context)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520ip_address%2520%253D%2520extract_ip(context.request)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520unless%2520ip_address.nil%253F%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_total_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520increase_unique_visits(ip_address)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520image%2520%253D%2520ImageGenerator.generate(%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_total_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520get_unique_visits()%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520)%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_type%2520%253D%2520%2522image%252Fpng%2522%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520context.response.content_length%2520%253D%2520image.size%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520IO.copy(image%252C%2520context.response)%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520increase_unique_visits(ip)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520if%2520%2540redis.exists(ip)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(ip%252C%25201)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(UNIQUE_VISITS_KEY).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_unique_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(UNIQUE_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520private%2520def%2520get_total_visits%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520(%2540redis.get(TOTAL_VISITS_KEY)%2520%257C%257C%2520%25220%2522).to_i%250A%2520%2520%2520%2520%2520%2520%2520%2520end%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--35-.png" alt="carbon--35-"></a></p>
<!--kg-card-end: markdown--><p>The main file code should look like this right now:</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=require%2520%2522stumpy_png%2522%250Arequire%2520%2522http%252Fserver%2522%250Arequire%2520%2522http%252Fserver%252Fhandlers%252F*%2522%250Arequire%2520%2522redis%2522%250A%250Arequire%2520%2522.%252Fvisitor_counter%252F*%2522%250A%250Ainclude%2520StumpyPNG%250A%250Amodule%2520VisitorCounter%250A%2520%2520VERSION%2520%253D%2520%25220.1.0%2522%250A%250A%2520%2520ENV%255B%2522PORT%2522%255D%2520%257C%257C%253D%2520%25228080%2522%250A%2520%2520ENV%255B%2522REDIS_URL%2522%255D%2520%257C%257C%253D%2520%2522redis%253A%252F%252F127.0.0.1%252F%2522%250A%250A%2520%2520redis%2520%253D%2520Redis%253A%253APooledClient.new(url%253A%2520ENV%255B%2522REDIS_URL%2522%255D)%250A%250A%2520%2520server%2520%253D%2520HTTP%253A%253AServer.new(%255B%250A%2520%2520%2520%2520HTTP%253A%253AErrorHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ALogHandler.new%252C%250A%2520%2520%2520%2520HTTP%253A%253ACompressHandler.new%252C%250A%2520%2520%2520%2520VisitorCounter%253A%253AWebHandler.new(redis)%252C%250A%2520%2520%255D)%250A%250A%2520%2520address%2520%253D%2520server.bind_tcp%2520%25220.0.0.0%2522%252CENV%255B%2522PORT%2522%255D.to_i%250A%2520%2520puts%2520%2522Listening%2520on%2520http%253A%252F%252F%2523%257Baddress%257D%2522%250A%2520%2520server.listen%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--31-.png" alt="carbon--31-"></a></p>
<!--kg-card-end: markdown--><p>Running the main code now we should see the counter working as expected:</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-80.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-80.png 600w, https://www.techprowd.com/content/images/2020/09/image-80.png 801w"></figure><figure><img src="https://www.techprowd.com/content/images/2020/09/image-79.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-79.png 600w, https://www.techprowd.com/content/images/2020/09/image-79.png 612w"></figure><p>Notice the response times of the web request! It's around 1ms per request! That's crazy fast... But wait, it's not built correctly.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-81.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-81.png 600w, https://www.techprowd.com/content/images/2020/09/image-81.png 829w"></figure><p>Now that's what I call FAST!</p><figure><img src="https://www.techprowd.com/content/images/2020/09/source-1.gif" alt=""></figure><p>Just one issue... While running Apache benchmarks, I noticed that the total visit counter is increasing at every request, which is right, but it can be easily abused. We need to rate-limit the total visit counter so that a single IP address can have only one visit per X amount of time.</p><p>Easy, he said! Remember, we are using Redis for our storage, and Redis has a Keys with Expiration feature. Which is precisely what we need.</p><!--kg-card-begin: markdown--><p><a href="https://carbon.now.sh/?bg=rgba(171%2C%20184%2C%20195%2C%201)&amp;t=seti&amp;wt=none&amp;l=crystal&amp;ds=true&amp;dsyoff=20px&amp;dsblur=68px&amp;wc=true&amp;wa=true&amp;pv=56px&amp;ph=56px&amp;ln=false&amp;fl=1&amp;fm=Hack&amp;fs=14px&amp;lh=133%25&amp;si=false&amp;es=2x&amp;wm=false&amp;code=private%2520def%2520increase_total_visits(ip)%250A%2520%2520%2520%2520if%2520%2540redis.exists(%2522!%2523%257Bip%257D%2522)%2520%253D%253D%25200%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.incr(TOTAL_VISITS_KEY).to_i%250A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2540redis.set(%2522!%2523%257Bip%257D%2522%252C%25201%252C%2520RATE_LIMIT_SECONDS)%250A%2520%2520%2520%2520end%250Aend"><img src="https://www.techprowd.com/content/images/2020/09/carbon--37-.png" alt="carbon--37-"></a></p>
<!--kg-card-end: markdown--><p>This way now only increases total visits only when the rate limit timeout will be reached; in this code, it's 5 seconds, but I am going to set something like 1 minute in production.</p><p>Now that we have our application working as we expect. We should deploy our application. I am going to follow the official <a href="https://crystal-lang.org/2016/05/26/heroku-buildpack.html">Crystal guide for Heroku deployment</a>.</p><figure><img src="https://www.techprowd.com/content/images/2020/09/image-82.png" alt="" srcset="https://www.techprowd.com/content/images/size/w600/2020/09/image-82.png 600w, https://www.techprowd.com/content/images/size/w1000/2020/09/image-82.png 1000w, https://www.techprowd.com/content/images/size/w1600/2020/09/image-82.png 1600w, https://www.techprowd.com/content/images/2020/09/image-82.png 1676w" sizes="(min-width: 1200px) 1200px"></figure><p>After easy set up and install now we have an working counter running on heroku.</p><p><a href="https://immense-beyond-23382.herokuapp.com/">https://immense-beyond-23382.herokuapp.com/</a></p><!--kg-card-begin: html--><p><img src="https://immense-beyond-23382.herokuapp.com/"></p><!--kg-card-end: html--><h2 id="conclusion">Conclusion</h2><p>The fully working source code is available on my <a href="https://www.patreon.com/posts/41771991">Patreon account</a> for all pledgers. I will try to add this small counter to this Ghost template as I really loved the idea of this small counter 15 years ago.</p><p>Don't forget to subscribe to the newsletters down bellow. Every new article will be delivered in a friendly email, readable format straight into your mailbox!</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to techprowd</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.techprowd.com/evening-project-a-crystal-based-super-fast-visitor-counter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525873</guid>
            <pubDate>Sat, 19 Sep 2020 07:43:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My first 15000 curl commits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525665">thread link</a>) | @dosshell
<br/>
September 18, 2020 | https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I‚Äôve long maintained that <strong>persistence</strong> is one of the main qualities you need in order to succeed with your (software) project. In order to manage to ship a product that truly conquers the world. By continuously and never-ending keeping at it: polishing away flaws and adding good features. On and on and on.</p>



<p>Today marks the day when I landed my 15,000th commit in the <a href="https://github.com/curl/curl">master branch in curl‚Äôs git repository</a> ‚Äì and we don‚Äôt do merge commits so this number doesn‚Äôt include such. Funnily enough, <a href="https://github.com/curl/curl/graphs/contributors">GitHub can‚Äôt count</a> and shows a marginally lower number.</p>



<figure><img loading="lazy" width="844" height="116" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits.png 844w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-450x62.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-200x27.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/15000-commits-768x106.png 768w" sizes="(max-width: 844px) 100vw, 844px"></figure>



<p>This is of course a totally meaningless number and I‚Äôm only mentioning it here because it‚Äôs even and an opportunity for me to celebrate something. To cross off an imaginary milestone. This is not even a year since we passed <a href="https://daniel.haxx.se/blog/2019/11/29/curl-25000-commits/" data-type="post" data-id="12859">25,000 total number of commits</a>. Another meaningless number.</p>



<p>15,000 commits equals 57% of all commits done in curl so far and it makes me the only committer in the curl project with over 10% of the commits.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#daniel-vs-rest"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard1-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>The curl git history starts on December 29 1999, so the first 19 months of commits from the early curl history are lost. 15,000 commits over this period equals a little less than 2 commits per day on average. I reached 10,000 commits  in December 2011, so the latest 5,000 commits were done at a slower pace than the first 10,000.</p>



<p>I estimate that I‚Äôve spent more than 15,000 hours working on curl over this period, so it would mean that I spend more than one hour of ‚Äúcurl time‚Äù per commit on average. According to <a href="https://curl.haxx.se/gitstats/authors.html">gitstats</a>, these 15,000 commits were done on 4,271 different days.</p>



<p>We also have other curl repositories that aren‚Äôt included in this commit number. For example, I have done over 4,400 commits in curl‚Äôs website repository.</p>



<p>With these my first 15,000 commits I‚Äôve added 627,000 lines and removed 425,000, making an average commit adding 42 and removing 28 lines. (Feels pretty big but I figure the really large ones skew the average.)</p>



<p>The largest time gap ever between two of my commits in the curl tree is almost 35 days back in June 2000. If we limit the check to ‚Äúmodern times‚Äù, as in 2010 or later, there was a 19 day gap in July 2015. I <em>do</em> take vacations, but I usually keep up with the most important curl development even during those.</p>



<p>On average it is one commit done by me every 12.1 hours. Every 15.9 hours since 2010. </p>



<p>I‚Äôve been working <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">full time on curl since early 2019</a>, up until then it was a spare time project only for me. Development with pull-requests and CI and things that verify a lot of the work <em>before</em> merge is a recent thing so one explanation for a slightly higher commit frequency in the past is that we then needed more ‚Äúoops‚Äù commits to rectify mistakes. These days, most of them are done in the PR branches that are squashed when subsequently merged into master. Fewer commits with higher quality.</p>



<h2>curl committers</h2>



<p>We have merged commits authored by over 833 authors into the curl master repository.  Out of these, 537 landed only a single commit (so far).</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#authors"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard2-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 48 authors who ever wrote 10 or more commits within the same year. 20 of us committed that amount of commits during more than one year.</p>



<figure><a href="https://curl.haxx.se/dashboard1.html#coreteam-per-year"><img loading="lazy" width="1200" height="675" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1200x675.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-450x253.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-200x113.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-768x432.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-1536x864.png 1536w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-curl-Project-status-dashboard3-2048x1152.png 2048w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>



<p>We are 9 authors who wrote more than 1% of the commits each.</p>



<p>We are 5 authors who ever wrote 10 or more commits within the same year in 10 or more years.</p>



<p>Our second-most committer (by commit count) has not merged a commit for over seven years.</p>



<p>To reach curl‚Äôs top-100 committers list right now, you only need to land 6 commits.</p>



<h2>can I keep it up?</h2>



<p>I intend to stick around in the curl project going forward as well. If things just are this great and life remains fine, I hope that I will be maintaining roughly this commit speed for years to come. My prediction is therefore that it will take longer than another twenty years to reach 30,000 commits.</p>



<p>I‚Äôve worked on curl and its precursors for almost <em>twenty-four years</em>. In another twenty-four years I will be well into my retirement years. At some point I will probably not be fit to shoulder this job anymore!</p>



<p>I have never planned long ahead before and I won‚Äôt start now. I will instead keep focused on keeping curl top quality, an exemplary open source project and a welcoming environment for newcomers and oldies alike. I will continue to make sure the project is able to function totally independently if I‚Äôm present or not.</p>



<h2>The 15,000th commit?</h2>



<p>So what exactly did I change in the project when I merged my 15,000th ever change into the branch?</p>



<p>It was a pretty boring and <a href="https://github.com/curl/curl/commit/559ed3ca2545c56a9acc4e805970434f657bd691">non-spectacular one</a>. I removed a document (<code>RESOURCES</code>) from the docs/ folder as that has been a bit forgotten and now is just completely outdated. There‚Äôs a much better page for this provided on the web site: <a href="https://curl.haxx.se/rfc/">https://curl.haxx.se/rfc/</a></p>



<h2>Celebrations!</h2>



<p>I of coursed asked my twitter friends a few days ago on how this occasion is best celebrated:</p>



<figure><a href="https://twitter.com/bagder/status/1302345161272418307"><img loading="lazy" width="825" height="493" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish.png 825w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-450x269.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-200x120.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2020/09/Screenshot_2020-09-15-Twitter-Publish-768x459.png 768w" sizes="(max-width: 825px) 100vw, 825px"></a></figure>



<p>I showed these results to my wife. She approved.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/18/my-first-15000-curl-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525665</guid>
            <pubDate>Sat, 19 Sep 2020 06:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small Computing and the Security Mindset]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525475">thread link</a>) | @zdw
<br/>
September 18, 2020 | http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html | <a href="https://web.archive.org/web/*/http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

</header>
<section data-field="subtitle">
The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting‚Ä¶
</section>
<section data-field="body">
<section name="3648"><div><div><h3 name="8f02" id="8f02">Small Computing and the Security&nbsp;Mindset</h3><p name="3181" id="3181">The story of modern computing is the story of the big-computing mindset (scale, centralization, elitism, and paternalism) infecting everything it touches as programming becomes more of a profession than a craft. In the process, it creates edifices of practices‚Ää‚Äî‚Ääuseful in big-computing situations‚Ää‚Äî‚Ääthat get unthinkingly applied outside of their appropriate bounds, forcing small-computing projects into the strictures of big-computing design. One major domain where we must begin to think critically about the big- vs small-computing distinction is security.</p><p name="46d1" id="46d1">Small-computing systems ought to be secure. After all, they are our most personal environments! They are our diaries and our artworks and our dream journals! But computer security, as it has become professionalized, has become more and more focused on big-computing environments, and good security practices in those environments are inimical to the basic tenets of small computing.</p><p name="369b" id="369b">In a big-computing environment, valuable secrets (like credit card numbers) and desirable powers (like the ability to tweet on behalf of the president) are kept on a set of machines owned by a single entity (the corporation) on behalf of the ostensible owners of that information and power (particular end-users) and protected from illegitimate access (hacking/cracking) by an elite set of professionals (software engineers, ops teams, security consultants) who use their monopoly on legitimate access to certain power (superuser &amp; administrator privileges, commit access) to construct laws (security policies) that prohibit as many not-explicitly-allowed operations as possible. Because the adversaries are many, with infinite time and energy, and because the treasure is valuable, and because laws always have unseen loopholes, these elite professionals construct layers upon layers of rules to limit not only what users (legitimate or illegitimate) can do, but what kind of feedback they can receive.</p><p name="c145" id="c145">This mentality has even made its way into language design: Java (and C++) have a rudimentary form of access control where members can be marked private, and good style in these languages is to mark all member data as private and write accessor functions, ostensibly in order to perform validity checks on proposed modification. This boilerplate is added rather than doing the sensible thing and creating custom metatables such that assignments are implicitly passed through an integrity check (as may be done in Python and Lua). Of course, such checks are rarely implemented, and they cannot distinguish between ‚Äòauthorized‚Äô and ‚Äòunauthorized‚Äô calling-classes anyhow‚Ää‚Äî‚Ääwhile C++ has ‚Äòfriend classes‚Äô that can modify private data directly, and both support using inheritance hierarchies to control data access, there is no granularity smaller than kin/friend versus outsider, so these access controls are borderline useless for everything besides the ad-hoc plugging failures of the type system and increasing the line count of codebases.</p><p name="c4c2" id="c4c2">Systems that require big-computing style security exist. Problems that are best suited to those systems also exist‚Ää‚Äî‚Ääyour bank ought to not only have big-computing style security, but ought to have substantially better security than it has. But, this model is not really sensible in many of the places it is used. For instance, Google Docs (which simulates a word processor with some limited support for simultaneous editing by multiple users) is locked into this model only because it is client-server, and a hypothetical local-first or peer-to-peer version should not be so professionalized and stratified; Microsoft Word, being a local application, has no legitimate excuse (though the real reason, as with most big-computing systems, is that unnecessary centralization is a very effective way to squeeze money out of users who don‚Äôt know any better).</p><p name="d95a" id="d95a">When I use Google Docs, I can modify the javascript running on my browser, modify the cookies being sent to the server, and modify URL parameters. If I do something wrong, I will get an entirely unhelpful error message from inside the black box of the remote server. This is because, by failing to fall precisely in line with the Alphabet Corporation‚Äôs desired behavior, I have become an adversary, and adversaries cannot be given information that might help them do whatever they might want to do (since some of the things they might want to do is get, for instance, the credit card numbers of everyone who has ever bought an advertisement). Of course, Google engineers writing and maintaining Google Docs face the same situation. Outside of an adversarial situation, investigating a poorly-understood piece of code by poking it and interpreting error messages is called debugging, and part of the small computing ethos is that users should not be prevented from debugging.</p><p name="05d7" id="05d7">The difference between big computing and small computing is, in essence, that in small computing, the user is never an adversary. This is because the running code is owned and controlled by the user. This goes beyond open source / free software (where the developer is no adversary, but the developer is an elite professional often working on behalf of a corporation inside a firewall, performing work that may well be detrimental to those who actually need to interact with its effects).</p><p name="bd41" id="bd41">What kinds of structures befit a small-computing system in an environment where networking exists, and what security models are appropriate for these structures?</p><p name="8df4" id="8df4">For one thing, a multi-user client-server model makes no sense. In a client-server model, whoever controls the single server functionally controls all clients. There is, therefore, incentive to hoard power by locking vital functionalities away on the shared server, making every client dependent‚Ää‚Äî‚Ääslowed by latency when online, shit out of luck when offline, and always under threat of sudden unilateral changes in policy or protocol.</p><p name="d853" id="d853">Instead, we should look to peer to peer systems: direct for real-time communication, and offline-first store-and-forward schemes for everything else. Asymmetric encryption for key exchange and for signing still make sense here, as does hash-based content addressing for storage. Secure Scuttlebutt and IPFS are good models for what small-computing-oriented network technologies of the future might look like: fully distributed, yet resistant to the kinds of threats that regularly take down federated systems like ActivityPub and IRC, because all nodes are equal and all nodes replicate for each other (under cryptographically-enforced anti-spoofing measures).</p><p name="32c0" id="32c0">What does a threat model for small-computing infrastructure look like?</p><p name="2535" id="2535">Well, unlike in big-computing systems, a small-computing system does not (typically) have large numbers of highly motivated dedicated attackers. Fuzzy Bear isn‚Äôt APTing your grandma‚Äôs laptop, because your grandma‚Äôs laptop has nothing on it but christmas MIDIs and questionable nudes. Our threat is really from folks doing large-scale automated sweeps for low-hanging fruit. So, small-computing threat modeling looks like everyday opsec: use encryption, don‚Äôt give strangers direct access to private spaces and limit the spaces they do have access to, distinguish between sensitive and non-sensitive data, and protect the integrity of the system from outsiders. Protect the network-facing portion of your machine, while maximizing your own access to it.</p><p name="aa5a" id="aa5a">In this context, technologies we absolutely do not need are: passwords, SSO, certificate authority hierarchies, name servers and host files, NAT firewalls, code signing, chroot jails, memory layout randomizers, executable symbol stripping, single-application containers, daemons running as ‚Äònobody‚Äô, web APIs for wrapping the web APIs around your web APIs, friend classes, and sudo.</p><p name="9477" id="9477">Technologies we might want to look into: distributed hash tables, chord routing, merkel trees, functional languages, JIT, fast copy-on-write, network-aware cache eviction policies, split-brain countermeasures, transitive blocking, store and forward, message passing, microversioning, journaling, and image-based environments.</p></div></div></section>
</section>
</article></div>]]>
            </description>
            <link>http://www.lord-enki.net/medium-backup/2020-09-18_Small-Computing-and-the-Security-Mindset-821dfb512aa7.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525475</guid>
            <pubDate>Sat, 19 Sep 2020 05:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Vector Spaces to Periodic Functions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525383">thread link</a>) | @susam
<br/>
September 18, 2020 | https://susam.in/blog/from-vector-spaces-to-periodic-functions/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/from-vector-spaces-to-periodic-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 30 Jan 2019</p>
<h2 id="vector-spaces"><a href="#vector-spaces">Vector Spaces</a></h2>
<p>
A fascinating result that appears in linear algebra is the fact that the
set of real numbers \( \mathbb{R} \) is a vector space over the set of
rational numbers \( \mathbb{Q}. \) This may appear surprising at first
but it is easy to show that it is indeed so by checking that all eight
axioms of vector spaces hold good:
</p>

<ol>
  <li>
    <p>
      Commutativity of vector addition:<br>
      \( x + y = y + x \) for all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Associativity of vector addition:<br>
      \( x + (y + z) = (x + y) + z \) for all \( x, y, z \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive identity vector:<br>
      We have \( 0 \in \mathbb{R} \) such that \( x + 0 = x \) for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of additive inverse vectors:<br>
      There exists \( -x \in \mathbb{R} \) for all \( x \in \mathbb{R}.
      \)
    </p>
  </li>
  <li>
    <p>
      Associativity of scalar multiplication:<br>
      \( a(bx) = (ab)x \) for all \( a, b \in \mathbb{Q} \) and for all
      \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over vector addition:<br>
      \( a(x + y) = ax + by \) for all \( a \in \mathbb{Q} \) and for
      all \( x, y \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Distributivity of scalar multiplication over scalar addition:<br>
      \( (a + b)x = ax + bx \) for all \( a, b \in \mathbb{Q} \) and for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
  <li>
    <p>
      Existence of scalar multiplicative identity:<br>
      We have \( 1 \in \mathbb{Q} \) such that \( 1 \cdot x = x \) for
      all \( x \in \mathbb{R}. \)
    </p>
  </li>
</ol>
<p>
  This shows that the set of real numbers \( \mathbb{R} \) forms a
  vector space over the field of rational numbers \( \mathbb{Q}. \)
  Another quick way to arrive at this fact is to observe that \(
  \mathbb{Q} \subseteq \mathbb{R}, \) that is, \( \mathbb{Q} \) is a
  subfield of \( \mathbb{R}. \) Any field is a vector space over any of
  its subfields, so \( \mathbb{R} \) must be a vector space over \(
  \mathbb{Q}. \)
</p>


<h2 id="problem"><a href="#problem">Problem</a></h2>

<p>
Here is an interesting problem related to vector spaces that I came
across recently:
</p>

<div>
<p>
Define two periodic functions \( f \) and \( g \) from \( \mathbb{R} \)
to \( \mathbb{R} \) such that their sum \( f + g \) is the identity
function. The axiom of choice is allowed.
</p>
<p>
A function \( f \) is periodic if there exists \( p \gt 0 \) such that
\( f(x + p) = f(x) \) for all \( x \) in the domain.
</p>
</div>

<p>
<em>
If you want to think about this problem, this is a good time to pause
and think about it. There are spoilers ahead.
</em>
</p>


<h2 id="solution"><a href="#solution">Solution</a></h2>

<p>
The axiom of choice is equivalent to the statement that every vector
space has a basis. Since the set of real numbers \( \mathbb{R} \) is a
vector space over the set of rational numbers \( \mathbb{Q}, \) there
must be a basis \( \mathcal{H} \subseteq \mathbb{R} \) such that every
real number \( x \) can be written uniquely as a finite linear
combination of elements of \( \mathcal{H} \) with rational coefficients,
that is,
\[
  x = \sum_{a \in \mathcal{H}} x_a a
\]
where each \( x_a \in \mathbb{Q} \) and \( \{ a \in \mathcal{H} \mid x_a
\ne 0 \} \) is finite. The set \( \mathcal{H} \) is also known as the
Hamel basis.
</p>

<p>
We know that \( b_a = 0 \) for distinct \( a, b \in \mathcal{H} \)
because \( a \) and \( b \) are basis vectors.
</p>

<p>
In the above expansion of \( x, \) each \( x_a \) is a rational number
that appears as the coefficient of the basis vector \( a. \) Therefore
\( (x + y)_{a} = x_a + y_a \) for all \( x, y \in \mathbb{R}. \) Thus \(
(x + b)_{a} = x_a + b_a = x_a + 0 = x_a. \) This shows that a function
\( f(x) = x_a \) is a periodic function with period \( b \) for any \( b
\in \mathcal{H} \setminus \{a\}. \)
</p>

<p>
Let us define two functions:
\begin{align*}
  f(x) &amp; = \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a,
  &amp;
  g(x) &amp; = x_b b.
\end{align*}
where \( b \in \mathcal{H} \) and \( x \in \mathbb{R}. \) Let us
choose \( c \in \mathcal{H} \) such that \( c \ne b. \) Then \( f(x) \)
is a periodic function with period \( b \) and \( g(x) \) is a periodic
function with period \( c. \) Further,
\[
  f(x) + g(x)
  = \left( \sum_{a \in \mathcal{H} \setminus \{ b \}} x_a a \right) + x_b b
  = \sum_{a \in \mathcal{H}} x_a a
  = x.
\]
Thus \( f(x) \) and \( g(x) \) are two periodic functions such that
their sum is the identity function.
</p>


<h2 id="references"><a href="#references">References</a></h2>
<ul>
  <li>
    <a href="https://mathworld.wolfram.com/VectorSpace.html">Vector
    Space</a> (by Eric W. Weisstein)
  </li>
  <li>
    <a href="https://web.archive.org/web/20141026224511/https://drexel28.wordpress.com/2010/10/22/the-dimension-of-r-over-q/">The
    Dimension of R over Q</a> (by Alex Youcis)
  </li>
  <li>
    <a href="https://mathblag.wordpress.com/2013/09/01/sums-of-periodic-functions/">Sums
  of Periodic Functions</a> (by David Radcliffe)
  </li>
</ul>



</div></div>]]>
            </description>
            <link>https://susam.in/blog/from-vector-spaces-to-periodic-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525383</guid>
            <pubDate>Sat, 19 Sep 2020 05:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hand-Optimizing VLIW Assembly Language as a Game]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24525372">thread link</a>) | @luu
<br/>
September 18, 2020 | http://silverspaceship.com/hovalaag/ | <a href="https://web.archive.org/web/*/http://silverspaceship.com/hovalaag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://silverspaceship.com/hovalaag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525372</guid>
            <pubDate>Sat, 19 Sep 2020 05:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review of Pinephone PostmarketOS CE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24525210">thread link</a>) | @vidak
<br/>
September 18, 2020 | https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini | <a href="https://web.archive.org/web/*/https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div><p>The version of the Pinephone that I am reviewing is the postmarketOS</p><p>Community Edition (CE).</p><p>My first impression of the Pinephone after I unboxed the device was</p><p>very good. I enjoyed the feeling of the weight of the Pinephone in my</p><p>hand, and the overall build quality of the system still impresses</p><p>me. It is my opinion that the PINE64 hardware development and</p><p>manufacturing process is very solid. For what I paid, which was about</p><p>AUD$200 all up, I believe I have received hardware that is superior</p><p>than a phone that I could have bought from a retail store in my city</p><p>for the same price.</p><p>The screen is glossy, and the capacitive touch screen (this is a</p><p>question fellow smolnet citizen Shufei wanted answered in some detail)</p><p>responds well.</p><p>I was, however, disappointed with the stock postmarketOS software that</p><p>came flashed on the eMMC. The Software Centre was a particular</p><p>disappointment. It, by default, only showed the currently installed</p><p>software, and it was not possible to browse any other software which</p><p>was not already installed.</p><p>Also, the camera application that came installed by default, 'Cheese',</p><p>did not allow the camera to function.</p><p>I attempted to install Plasma Mobile using the command line, following</p><p>these instructions:</p><p>But it ended up completely wrecking the function of the</p><p>phone. Installing the package that the wiki article recommended did</p><p>not update LightDM, and I ended up soft-bricking the phone while</p><p>fiddling with the LightDM configuration in order to stop the phone</p><p>from (still) booting into phosh, and not Plasma Mobile.</p><p>It also disabled cell data functionality, and ended up messing with a</p><p>lot of the guts of the Linux installation. So I do not recommend</p><p>attempting to switch to Plasma Mobile on the Pinephone from inside an</p><p>already-existing postmarketOS installation. I recommend getting a</p><p>Plasma Mobile system image, and flashing that from the start if you</p><p>wish to experiment with different user interfaces.</p><div><p><span> ##</span></p><h2>Linux Software Distributions</h2></div><p>There is a great many Linux distributions available for the</p><p>Pinephone. The following link to the PINE64 wiki contains a</p><p>more-or-less exhaustive list of each of them:</p><p>The Linux distributions that I tested out are:</p><div><p><span>###</span></p><h3>postmarketOS (phosh UI)</h3></div><p>I enjoyed this system image because it came with a wizard for</p><p>NetworkManager which enabled me to make sure cell data worked most</p><p>consistently. However, the power consumption of this image was</p><p>prohibitively high, and it caused the phone to run very hot. When the</p><p>battery was at 10% charge, rebooting the phone would cause the last of</p><p>this precious charge to be used up, and the phone would run completely</p><p>out of power.</p><p>This image was basically a desktop UI, and did not have many, if any</p><p>mobile UI configurations present. It was rather fun to see the</p><p>Pinephone boot into a full GNOME desktop environment. I imagine if you</p><p>had a bigger screen connected to the Pinephone, you would be quite</p><p>impressed with what this phone could pull off.</p><div><p><span>###</span></p><h3>postmarketOS (Plasma Mobile)</h3></div><p>Slow and buggy, really.</p><p>This distribution has a major problem at the moment: the unlock/power</p><p>button is not properly debounced, and it makes it virtually impossible</p><p>sometimes to unlock the phone. Otherwise, this distribution is very,</p><p>very impressive, and I would actually like to switch to it, because</p><p>cell data works best for Optus on Ubuntu Touch.</p><p>This distribution could indeed be a daily driver for someone if they</p><p>could sort out the button debouncing problem.</p><p>This is a Linux-based operating system that uses a closed-source</p><p>UI. It was so glossy and locked-down in terms of configurability that</p><p>I was turned off using it. It has a great tutorial for teaching you</p><p>the gestures you need to learn in order to use the touch screen.</p><p>I did like the fact that it organised all your contacts and messages</p><p>into interesting metaphors, and it ran reasonably quickly, but there</p><p>is no way of configuring the UI beyond what how it arrives to you.</p><p>This image was fairly slow to run on the Pinephone, but in my opinion</p><p>it is the absolute best demonstration of KDE Plasma Mobile. It was</p><p>very visually impressive, and the menus were full-featured and</p><p>informative. It did not, however, support phone calls or SMS.</p><p>This is my current choice of Linux distribution for the phone. It has</p><p>a software centre full of different and interesting programs,</p><p>including Transmission (torrent client) and GIMP (!!! I have yet to</p><p>install this to see how or if it works well, but the fact that it is</p><p>possible to at least _run_ GIMP in some capacity on the Pinephone</p><p>would like like running Adobe Photoshop on a Samsung Galaxy).</p><p>This is merely anecdotal, and I have not performed any scientific</p><p>tests to work out if this is true, but the latest September 2020</p><p>stable release of this image seems to have the best power settings of</p><p>any of the other distributions for this phone.</p><p>I hesitate to give an estimate of exactly how long this phone will</p><p>last on a single charge, given normal use. But, I finished charging</p><p>this phone at 0700HRS this morning, and, with no other charge, it is now</p><p>on 50% charge, and the current time is 1230HRS. I think I have put the</p><p>phone through a little heavier use than I do normally, this morning,</p><p>however.</p><p>Virtually all of the functions of the phone are enabled without any</p><p>configuration in Mobian.</p><p>I highly recommend flashing the following system image to an SD card</p><p>so you can try out all the major Linux distributions for your phone:</p><p>It contains 13 different distributions, and it is trivial to switch</p><p>between each of them through the main boot menu.</p><p>I have rung a few people on the phone, and, assuming you have a</p><p>distribution flashed on the phone that supports phonecalls (like the</p><p>one I am currently using, Mobian), there should be absolutely no issue</p><p>using this fundamental feature of the Pinephone.</p><p>For the most part, the cell data modem in the Pinephone works well for</p><p>me. There is a fairly large problem with my use of the Pinephone with</p><p>its cell data, however.</p><p>I live in Australia, and the mobile phone carrier that I use is</p><p>Optus. The setup(s) that work for me with my Pinephone, running</p><p>Mobian, is:</p><p>&gt; Name: 1</p><p>&gt; APN: yesinternet</p><p>&gt; Name: Optus Yes Internet</p><p>&gt; APN: yesinternet</p><p>After about 3 or 4 hours after I boot up the phone, the cell data</p><p>stops working, and the Network Mode in the 'Mobile' submenu of</p><p>Settings changes from</p><p>&gt; 2G, 3G, 4G (Preferred)</p><p>to just</p><p>&gt; 2G, 3G, 4G</p><p>This issue is fixed for another 3 or 4 hours by rebooting the phone,</p><p>which does not actually take that long (about 10 to 15 seconds), but</p><p>it is a hassle to be cut off from mobile data if you forget about your</p><p>phone.</p><p>These two links help shed light on exactly what is happening with the</p><p>Pinephone when it tries to remain connected to the Optus network:</p><p>(A forum post. Someone using a similar, if not identical mobile data</p><p>modem as the Pinephone in Australia, with the Optus network)</p><p>(A Github post which familiarises the reader with the concepts and</p><p>command line tools involved in using Linux with 4G LTE modems on</p><p>Debian and Ubuntu)</p><p>The issue with the Pinephone is explained the forum thread (the first</p><p>link). The issue is that there are at least two modes for the Quectel</p><p>EG25 modem that the Pinephone uses, only one of which seems to be</p><p>supported by Optus. The two modes are QMI and MBIM. Optus, I assume,</p><p>only supoprts MBIM:</p><p>https://forum.gl-inet.com/t/using-rooter-on-the-gl-x750/8983/8 Forum post</p><p>The relevant sentence from the above forum post is:</p><p>&gt; Also, MBIM is buggy for Quectel modems even in OpenWRT 19.07</p><p>&gt; (snapshot), mostly sometimes modem ‚Äúfreezes‚Äù and I need to restart.</p><p>The issue that the original poster was having with this modem is</p><p>explained in the same post:</p><p>&gt; The reason is exactly this: user.notice Create Connection:</p><p>&gt; WDA-GET-DATA-FORMAT is ‚Äúraw-ip‚Äù </p><p>&gt; When you use a modem over QMI and the data-format is ‚Äúraw-ip‚Äù the</p><p>&gt; system needs to know that modem is on ‚Äúraw-ip‚Äù, without that,</p><p>&gt; interface doesn‚Äôt get an IP address.</p><p>When I was using the postmarketOS version of phosh, the NetworkManager</p><p>program started a wizard which contained a lot more options about how</p><p>to configure the Pinephone's Quectel LTE modem. One activity I would</p><p>like to carry out is learning how to start this wizard from within</p><p>Mobian. I wish to keep Mobian as the primary operating system for the</p><p>Pinephone just because its Software Centre has such an amazing</p><p>quantity and quality of different programs, and the postmarketOS</p><p>Centre requires you to manually search for the programs you want, in</p><p>order for them to show up at all inside the Centre.</p><p>The GPS seems to function perfectly fine inside the default Mobian</p><p>maps program. It can show you, with reasonable accuracy (although not</p><p>to the same accuracy as, say, a proprietary maps application) exactly</p><p>where you are. I think the accuracy of the GPS on the Pinephone is</p><p>somewhere in the region of 10 square metres.</p><p>The main issue with the GPS, however, is that it does not currently</p><p>link in with the Perth public transport system. I cannot use this</p><p>program to plan public transport journeys. But I believe I should be</p><p>able to take care of this problem by either (a) adding data to</p><p>OpenStreetMap, or (b) using a web browser, where I should be able to</p><p>access the Transperth public transport trip planner webpage.</p><p>This is a feature that works without a hitch in Mobian. I was</p><p>surprised to see myself receiving SMS messages unexpectedly from</p><p>friends as I left the phone in my pocket and forgot about it.</p><p>The camera application in Mobian works. However it has a refresh rate</p><p>of around 1 FPS. The quality is passable. This is not an issue for me</p><p>because, philosophically, phone cameras should not replace the</p><p>function of proper dedicated photographic devices. Will this camera</p><p>take reasonable photos? Yes. What is the comparison of the quality of</p><p>the photos? I would venture a guess that it is about as good as a</p><p>cheap action camera, like a GoPro knock-off.</p><div><p><span> ##</span></p><h2>Flashing Different Operating Systems</h2></div><p>Compared to the arduous process that one has to go through in order to</p><p>change operating systems on an Android phone, the Pinephone is very</p><p>easy to flash. You can flash data onto both an SD card, or the phone's</p><p>internal eMMC.</p><p>For flashing an SD card, the process is as ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini">https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</a></em></p>]]>
            </description>
            <link>https://proxy.vulpes.one/gemini/tanelorn.city/~vidak/pinephone/pinephone-review.gemini</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525210</guid>
            <pubDate>Sat, 19 Sep 2020 04:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Dive into K-pop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24525108">thread link</a>) | @eswat
<br/>
September 18, 2020 | https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-719">

	
	<!-- .entry-header -->


			<div>

			<p><img src="https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/8dedad4c-ee57-46fd-91a2-32cbb9a652d1/d97l7vh-b56d2b05-419a-4aa2-90c9-1f7a87db1968.jpg/v1/fill/w_1024,h_725,q_75,strp/my_first_kpop_collage_by_rainbowcandleofjoy_d97l7vh-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NzI1IiwicGF0aCI6IlwvZlwvOGRlZGFkNGMtZWU1Ny00NmZkLTkxYTItMzJjYmI5YTY1MmQxXC9kOTdsN3ZoLWI1NmQyYjA1LTQxOWEtNGFhMi05MGM5LTFmN2E4N2RiMTk2OC5qcGciLCJ3aWR0aCI6Ijw9MTAyNCJ9XV0sImF1ZCI6WyJ1cm46c2VydmljZTppbWFnZS5vcGVyYXRpb25zIl19.Py2kzajyzSvCd5CFWXNFSOW5m_rgR6UJMXllQj3dy18" alt="KPOP Collections: Kpop Groups Collage"></p>
<p>Prior to last month, I knew next to nothing about K-pop (Korean popular music) besides having heard a few songs in passing and the rumors of the industry‚Äôs infamous elements, most notably a string of high profile suicides over the last few years. As an American with no connection to music or South Korean culture, I wondered if I was getting an accurate picture of the industry or if I was being misled by the most lurid and morbid elements eagerly conveyed by the media.</p>
<p>So I decided to do a deep dive down the internet rabbit hole of K-pop to understand what it is, how it works, and what I think about it. For anything that‚Äôs not my personal opinion or that goes beyond basic historical knowledge, I‚Äôll cite my sources, which are a mixture of news articles, academic articles, YouTube videos, and some content aggregators like Wikipedia and Statista. I welcome any corrections or criticisms on inaccurate sources or things I didn‚Äôt understand.</p>
<p>I‚Äôll warn you upfront ‚Äì this essay is over 30,000 words long. It is the largest post I have made on dormin.org besides my novel. Since I sympathize with anyone who doesn‚Äôt want to make such a large time investment into a subject of passing curiosity, I will present my key findings here divided between the five <strong>parts</strong> of the essay. If you‚Äôre not sure if you want to read everything, you can jump to any individual part and understand it without reading the other sections.</p>

<h3><a href="#Basics"><strong><u>Part 1</u> ‚Äì <u>The Basics</u></strong></a></h3>
<ul>
<li>‚ÄúK-pop‚Äù is both a genre of music and an entire industry which ‚Äúmanufacturers‚Äù performers and their performance output (music, dance routines, shows, merchandise, etc.) in a highly systematized top-down manner</li>
<li>The global popularity of K-pop is extraordinary considering the relatively small population of South Korea, and the relatively small size of K-pop production companies</li>
</ul>
<h3><a href="#Product"><strong><u>Part 2</u> ‚Äì <u>The Product</u></strong></a></h3>
<ul>
<li>K-pop‚Äôs industrial/corporate structure represents a Korean (and East-Asian) cultural alternative to Western pop and broader music production</li>
<li>K-pop stars and bands are manufactured and controlled by production companies in the same manner Western athletes are trained and traded by sports teams.</li>
<li>K-pop stars are crafted into idealized portrays of individuals by East Asian cultural standards</li>
</ul>
<h3><a href="#Fans"><strong><u>Part 3</u> ‚Äì <u>The Fans</u></strong></a></h3>
<ul>
<li>K-pop fandom is both more intense on average than Western fandom, and has a larger percentage of unhealthily obsessive fans</li>
<li>K-pop fandom is based on a parasocial relationship between fans and stars</li>
<li>K-pop stars are forced to abide by extremely restrictive behavioral norms to appease production companies and fans</li>
</ul>
<h3><a href="#Process"><strong><u>Part 4</u>‚Äì <u>The Process</u></strong></a></h3>
<ul>
<li>Trying to become a K-pop star is a terrible idea by any rational cost-benefit analysis</li>
<li>The process by which production companies train K-pop stars is abusive and depends on the ignorance of children/teenagers and clueless and/or malicious parents</li>
<li>Even after making it through the extraordinarily difficult audition and training process, the vast majority of K-pop stars will have short careers and earn little or possibly <em>no</em> money</li>
</ul>
<h3><a href="#Machine"><strong><u>Part 5</u> ‚Äì <u>The Machine</u></strong></a></h3>
<ul>
<li>K-pop is an extremely centralized, hierarchical industry, where structural, business, and creative decisions are almost entirely made by corporate management, rather than the performers</li>
<li>Raw creativity in the music production process is largely outsourced to Westerners who write, produce, and choreograph the music</li>
<li>The K-pop industry is subsidized and supported by the South Korean government, if not implicitly or explicitly directed, as a conscious form of soft power projection and social control.</li>
</ul>
<p>As you can tell, I came away from my research with a negative view of K-pop. I don‚Äôt think it‚Äôs the worst thing in the world, but I find its fandom to be unhealthy and its production process to be exploitative. That being said, there are undoubtedly many tremendous talents in the K-pop world and the cultural power of K-pop is remarkable. I‚Äôll give my summarized thoughts on K-pop as a whole at the conclusion of the essay.<br>
<a name="Basics"></a></p>
<hr>
<p><img src="https://www.rollingstone.com/wp-content/uploads/2018/08/BTS-kpop-takeover-the-world.jpg" alt="How K-Pop Conquered the West - Rolling Stone"></p>
<h2><strong><u>Part 1</u> ‚Äì <u>The Basics</u></strong></h2>
<h3><strong>What is K-pop?</strong></h3>
<p>‚ÄúK-pop‚Äù refers to a genre of music and the industry which creates it. Both are based out of South Korea and particularly Seoul.</p>
<h3><strong>What is K-pop music?</strong></h3>
<p>K-pop is an offshoot of 90s Western pop with heavy influences from synthetics and hip hop. Lyrics are mostly Korean, but with English words and sometimes other languages thrown in. K-pop is usually sung by mono-gendered bands with members aged from their mid-teens to late 20s. Such bands typically resemble the structure and appearance of American boy bands from the 90s and 2000s (ie. NSYNC). As a representative K-pop sample, check out ‚ÄúDNA‚Äù by BTS:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/MBdVXkSdhwU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Properly understood, ‚ÄúK-pop music‚Äù is inseparable from ‚ÄúK-pop performance.‚Äù The music itself is one component of a larger presentation which includes dance choreography, music videos, fashion, and the personas of bands and individual band members. Though these elements are also present in Western music, they are far more important to K-pop music. K-pop fandom is considered the appreciation of all these aspects as an integrated whole.</p>
<h3><strong>What are the Origins of K-pop?</strong></h3>
<p>The Western influence on Korean music began in the 1940s with the American occupation of much of the Korean peninsula after its liberation from Imperial Japan. With the outbreak of the Korean War in the early 1950s, further American presence was added, with over 300,000 US troops at the peak.<a href="#_edn1" name="_ednref1">[1]</a> After the war, the American military stayed at dozens<a href="#_edn2" name="_ednref2">[2]</a> of bases throughout South Korea as a permanent fixture of the country. Over the decades, these soldiers imported American culture and media, including American music. Presently, there are still 20,000 US soldiers in South Korea.<a href="#_edn3" name="_ednref3">[3]</a></p>
<p>The early Western musical influence in South Korea was based on folk and hippie music in the 60s and 70s, and then evolved into sappy ballads in the 80s. These genres merged with traditional Korean music to form a small, localized music industry. Creative expansion was restrained by the South Korean government‚Äôs censorship and restrictions on movement in and out of the country. In the 1970s, the government banned American rock music and Korean offshoots for their connotations with drug use.<a href="#_edn4" name="_ednref4">[4]</a> Until 1983, South Korean citizens were banned from traveling abroad for tourism, and the last restrictions weren‚Äôt lifted until 1988 (year of the Seoul Summer Olympics).<a href="#_edn5" name="_ednref5">[5]</a></p>
<p>Korean music had a revolution in the early 1990s with the three-member band, Seo Taiji and the Boys. Founded in 1992, the Boys debuted on a South Korean television talent show and received the lowest ratings of the night.<a href="#_edn6" name="_ednref6">[6]</a> Unexpectedly, their premiere song was a huge hit and launched the band to fame. The Boys soon became the first successful Korean rap group and redefined the Korean music industry. Leader Seo Taiji was a rare experimenter in a country still emerging from isolation and relative cultural stagnancy. Prior to forming the Boys, he had been part of an indie heavy metal band.<a href="#_edn7" name="_ednref7">[7]</a></p>
<p>Through their music, style, and appearance, Seo Taiji and the Boys inadvertently became the first K-Pop band. While their music was more hip hop-based, the Boys pioneered the mixture of Western pop and hip hop presented with intense, highly-choreographed dance routines within a refined aesthetic theme.<a href="#_edn8" name="_ednref8">[8]</a> For a sample, see here:</p>
<p><span><iframe width="760" height="428" src="https://www.youtube.com/embed/IRFfPZQeJuo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Seo Taiji and the Boys disbanded in 1996. But by the end of its short career, mimicking boy bands had sprung up throughout South Korea. These bands were picked up by a new wave of music production companies which would become the basis of the K-pop industry. They looked to Japan and its well established ‚ÄúJ-pop‚Äù industry as a template for the sustained production of popular musical talent. Thus, while the Boys were independent, experimental, and subversive, the bands created in their wake were more institutionalized, sanitized, and formed by top-down design.</p>
<h3><strong>How Big is K-pop?</strong></h3>
<p>In 2017, the entire K-pop industry produced $5 billion in revenue.<a href="#_edn9" name="_ednref9">[9]</a> For the closest American comparison I can find ‚Äì in 2019, American <em>record labels</em> earned $8.7 billion in revenue.<a href="#_edn10" name="_ednref10">[10]</a> Unfortunately, I can‚Äôt find numbers for total music industry revenue in the US, so this isn‚Äôt quite a fair comparison. The two might be difficult to compare due to diverging industry structures;&nbsp; for instance, in South Korea, $1.2 billion of its 2017 revenues came from karaoke sales, only $250 million less than its digital music sales<a href="#_edn11" name="_ednref11">[11]</a></p>
<p>Nevertheless, considering that South Korea has less than 1/6<sup>th</sup> the US population and 1/14<sup>th</sup> the GDP, that‚Äôs pretty damn impressive.</p>
<p>Also of note, in 2019, South Korea was the 6<sup>th</sup> largest music market in the world, ahead of China and behind France.<a href="#_edn12" name="_ednref12">[12]</a> In 2017, South Korea exported $513 million worth of music and imported only $14 million worth, which is an extremely strong indicator of the country‚Äôs preference for K-pop over Western pop.<a href="#_edn13" name="_ednref13">[13]</a></p>
<p>BTS (AKA Bangtan Boys) is the most popular K-pop band in the world today and ever. According to the 2019 IFPI Global Music Report, BTS was the 7<sup>th</sup> most listened to artist in the world, and had the 3<sup>rd</sup> most popular album globally. Despite Spotify not streaming in South Korea, BTS was its second most popular artist in 2019.<a href="#_edn14" name="_ednref14">[14]</a></p>
<p>Perhaps more relevantly, a 2017 Hyundai Research Institute report claimed that BTS alone was worth $3.6 billion to the South Korean economy annually when accounting for adjacent economic activity and tourism. Supposedly 1/13th of all tourists to South Korea in 2017 came because of BTS.<a href="#_edn15" name="_ednref15">[15]</a> A 2019 report from Hollywood Reporter brought the figure up $4.65 billion.<a href="#_edn16" name="_ednref16">[16]</a></p>
<h3><strong>How Big is K-pop in America?</strong></h3>
<p>I can‚Äôt find firm figures, but the general consensus is that K-pop has been blowing up in the US since at least 2017, with articles about the genre‚Äôs American explosion popping up in the <em>New York Times</em>,<a href="#_edn17" name="_ednref17">[17]</a> <em>NPR</em>,<a href="#_edn18" name="_ednref18">[18]</a> the <em>Guardian</em>,<a href="#_edn19" name="_ednref19"><em><strong>[19]</strong></em></a> etc. From 2015 to 2019, demand for K-pop concert tickets increased 1,900% in the US.<a href="#_edn20" name="_ednref20">[20]</a> This growth seems to be largely thanks to BTS, which is about 5X more popular than Blackpink, the second most popular ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/">https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</a></em></p>]]>
            </description>
            <link>https://dormin.org/2020/09/06/a-deep-dive-into-k-pop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24525108</guid>
            <pubDate>Sat, 19 Sep 2020 04:36:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. bans WeChat, TikTok, citing national security reasons]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 180 (<a href="https://news.ycombinator.com/item?id=24524662">thread link</a>) | @empressplay
<br/>
September 18, 2020 | https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5729631.1600444028!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1263681818.jpg"></p></div><figcaption>U.S. business transactions with the Chinese-owned social apps WeChat and TikTok are to be banned, starting Sunday.<!-- --> <!-- -->(Cindy Ord/Getty Images)</figcaption></figure><p><span><p>The U.S. Commerce Department has issued an order that will bar people in the United States from downloading Chinese-owned messaging app WeChat and video-sharing app TikTok, starting Sunday.</p>  <p>Commerce officials said the ban on new U.S. downloads of TikTok could be still rescinded by President Donald Trump before it takes effect late Sunday as TikTok owner ByteDance races to clinch an agreement over the fate of its U.S. operations.</p>  <p>ByteDance has been in talks with Oracle Corp and others to create a new company, TikTok Global, which&nbsp;aims to address U.S. concerns about the security of its users' data. ByteDance still needs Trump's approval to stave off a U.S. ban.</p>  <p>Commerce officials said they will not bar additional technical transactions for TikTok until Nov. 12, which gives the company additional time to see if ByteDance can reach a deal for its U.S. operations. "The basic TikTok will stay intact until Nov. 12," Commerce Secretary Wilbur Ross told Fox Business Network.</p>  <p>The department said the actions will "protect users in the U.S. by eliminating access to these applications and significantly reducing their functionality."</p>  <p>U.S. Commerce Department officials said they were taking the extraordinary step because of the risks the apps' data collection poses. China and the companies have denied U.S. user data is collected for spying.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1205295609.jpg 300w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1205295609.jpg 460w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1205295609.jpg 620w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg 780w,https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1205295609.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729318.1600434343!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1205295609.jpg"></p></div><figcaption>U.S. Secretary of Commerce Wilbur Ross said the ban on Tik Tok and WeChat will combat China's 'malicious collection of American citizens' personal data.'<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Ross said in a written statement "we have taken significant action to combat China's malicious collection of American citizens' personal data, while promoting our national values, democratic rules-based norms, and aggressive enforcement of U.S. laws and regulations."</p>  <p>"We disagree with the decision from the Commerce Department, and are disappointed that it stands to block new app downloads from Sunday and ban use of the TikTok app in the U.S. from Nov. 12," the company said in a statement. "We will continue to challenge the unjust executive order, which was enacted without due process and threatens to deprive the American people and small businesses across the U.S. of a significant platform for both a voice and livelihoods."</p>  <p>The Commerce Department order will "de-platform" the two apps in the U.S. and bar Apple Inc's app store, Alphabet Inc's Google Play and others from offering the apps on any platform "that can be reached from within the United States," a senior Commerce official told Reuters.</p>  <p>The order will not ban U.S. companies from doing business&nbsp;on WeChat outside the United States, which will be welcome news to U.S. firms like Walmart and Starbucks that use WeChat's embedded "mini-app"&nbsp;programs to facilitate transactions and engage consumers in China, officials said.</p>    <p>The order will not bar transactions with WeChat-owner Tencent Holdings' other businesses, including its online gaming operations, and will not prohibit Apple, Google or others from offering TikTok or WeChat apps anywhere outside the United States.</p>  <p>The bans are in response to a pair of executive orders issued by Trump on Aug.&nbsp;6 that gave the Commerce Department 45 days to determine what transactions to block from the apps he deemed pose a national security threat. That deadline expires on Sunday.</p>  <h2>'Untrusted'&nbsp;Chinese apps</h2>  <p>The Trump administration has ramped up efforts to purge "untrusted" Chinese apps from U.S. digital networks and has called TikTok and WeChat&nbsp;"significant threats."</p>  <p>TikTok has 100 million users in the United States and is especially popular among younger Americans.</p>  <p>WeChat has had an average of 19 million daily active users in the United States, analytics firm&nbsp;Apptopia said in early August. It is popular among Chinese students, ex-pats and some Americans who have personal or business relationships in China.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1228542119.jpg 300w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1228542119.jpg 460w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1228542119.jpg 620w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg 780w,https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1228542119.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729307.1600433977!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1228542119.jpg"></p></div><figcaption>People walk past the headquarters of ByteDance, the parent company of TikTok, in Beijing.<!-- --> <!-- -->(Greg Baker/AFP/Getty Images)</figcaption></figure></span></p>  <p>WeChat is an all-in-one mobile app that combines services similar to Facebook, WhatsApp, Instagram and Venmo. The app is an essential part of daily life for many in China and boasts more than 1 billion users.</p>  <p>The Commerce Department will not seek to compel people in the United States to remove the apps or stop using them but will not allow updates or new downloads. "We are aiming at a top corporate level. We're not going to go out after the individual users," one Commerce official said.</p>  <p>Over time, officials said, the lack of updates will degrade the apps' usability.</p>  <p>"The expectation is that people will find alternative ways to do these actions," a senior official said. "We expect the market to act and there will be more secure apps that will fill in these gaps that Americans can trust and that the United States government won't have to take similar actions against."</p>    <p>The Commerce Department is also barring additional technical transactions with WeChat starting Sunday that will significantly reduce the usability and functionality of the app in the United States.</p>  <p>The order bars data hosting within the United States for WeChat, content delivery services and networks that can increase functionality and internet transit or peering services.</p>  <p>"What immediately is going to happen is users are going to experience a lag or lack of functionality," a senior Commerce official said of WeChat users. "It may still be usable but it is not going to be as functional as it was." There may be sporadic outages as well, the official said.</p>  <p>Commerce will bar the same set of technical transactions for TikTok, but that will not take effect until Nov. 12 to give the company additional time to see if ByteDance can reach a deal for its U.S. operations. The official said TikTok U.S. users would not see "a major difference" in the app's performance until Nov. 12.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/1273236956.jpg 300w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/1273236956.jpg 460w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/1273236956.jpg 620w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg 780w,https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/1273236956.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729309.1600434154!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/1273236956.jpg"></p></div><figcaption>U.S. President Donald Trump could still rescind the download ban before it comes into effect Sunday. <!-- --> <!-- -->(Scott Olson/Getty Images)</figcaption></figure></span></p>  <p>Commerce will not penalize people who use TikTok or WeChat in the United States.</p>  <p>The order does not bar data storage within the United States for WeChat or TikTok.</p>  <p>Some Americans may find workarounds. There is nothing that would bar an American from travelling to a foreign country and downloading either app, or potentially using a virtual private network and a desktop client, officials conceded.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/u-s-bans-wechat-tiktok-1.5729249</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524662</guid>
            <pubDate>Sat, 19 Sep 2020 03:15:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monitoring My Home Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24524433">thread link</a>) | @mr-karan
<br/>
September 18, 2020 | https://mrkaran.dev/posts/isp-monitoring/ | <a href="https://web.archive.org/web/*/https://mrkaran.dev/posts/isp-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p>I like monitoring <em>stuff</em>. That‚Äôs what I do at work and when my home ISP started giving me random problems and I decided it would be nice to monitor my home network as well. There are a couple of ways to go around this, a very popular and OSS solution is <a href="https://oss.oetiker.ch/smokeping/">SmokePing</a>. SmokePing is written in Perl and is used to visualise network latencies. It‚Äôs quite a great solution but for my current stack which involves Prometheus and Grafana, it meant I had to deploy a standalone tool separate from my monitoring stack - something which I wanted to avoid.</p>

<p><img src="https://oss.oetiker.ch/smokeping/doc/reading_detail.png" alt="SmokePing Graphs"></p>

<p>So, I looked for other solutions and luckily happened to stumble upon <a href="https://twitter.com/oddtazz">oddtazz</a> in one of the common Telegram groups where he shared his solution for the above: Telegraf ICMP <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping">plugin</a> and Grafana. This is exactly what I‚Äôve been looking for but for some reason, I had wrongly assumed Telegraf needs InfluxDB to store the data. Googling a bit more, I found Telegraf <a href="https://github.com/influxdata/telegraf/blob/release-1.15/plugins/outputs/prometheus_client/README.md">supports</a> Prometheus format (amongst a huge list of others!) but this wasn‚Äôt so clear in their docs.</p>

<p>I decided to run a Telegraf agent in my RPi connected to my home router over LAN and scrape metrics using Prometheus and visualise graphs in Grafana! For the non-patient readers, here‚Äôs what my dashboard looks like!:</p>

<p><img src="https://mrkaran.dev/images/ISP-Monitoring-Grafana2.png" alt="image"></p>

<p><img src="https://mrkaran.dev/images/ISP-Monitoring-Grafana1.png" alt="image"></p>

<h2 id="setup">Setup</h2>

<p>To get started, we need to download <a href="https://github.com/influxdata/telegraf">Telegraf</a> and configure the <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ping">Ping</a> plugin. Telegraf has the concept of <strong>Plugins</strong> for Input, Output, Aggregating and Processing. What this basically means is that you can configure multiple input plugins like DNS, ICMP, HTTP and export the data of these plugins in a format of your choice with Output plugins.
This makes Telegraf extermely extensible, you could write a plugin (in Go) of your choice if you fancy that as well!</p>

<p>Here‚Äôs what my <code>telegraf.conf</code> looks like:</p>
<div><pre><code data-lang="toml"><span># Input plugins</span>

<span># Ping plugin</span>
[[<span>inputs</span>.<span>ping</span>]]
<span>urls</span> = [<span>"mrkaran.dev"</span>, <span>"tailscale.mrkaran.dev"</span>, <span>"floyd.mrkaran.dev"</span>, <span>"1.1.1.1"</span>, <span>"kite.zerodha.com"</span>, <span>"google.com"</span>, <span>"reddit.com"</span>, <span>"twitter.com"</span>, <span>"amazon.in"</span>, <span>"zerodha.com"</span>]
<span>count</span> = <span>4</span>
<span>ping_interval</span> = <span>1.0</span>
<span>timeout</span> = <span>2.0</span>

<span># DNS plugin</span>
[[<span>inputs</span>.<span>dns_query</span>]]
  <span>servers</span> = [<span>"100.101.134.59"</span>]
  <span>domains</span> = [<span>"mrkaran.dev"</span>, <span>"tailscale.mrkaran.dev"</span>, <span>"floyd.mrkaran.dev"</span>, <span>"1.1.1.1"</span>, <span>"kite.zerodha.com"</span>, <span>"google.com"</span>, <span>"reddit.com"</span>, <span>"twitter.com"</span>, <span>"amazon.in"</span>, <span>"zerodha.com"</span>]

<span># Output format plugins</span>
[[<span>outputs</span>.<span>prometheus_client</span>]]
  <span>listen</span> = <span>":9283"</span>
  <span>metric_version</span> = <span>2</span></code></pre></div>
<p>Firstly, so nice to see an <em>Ops</em> tool <strong>not</strong> using <code>YAML</code>. Kudos to Telegraf for that. I‚Äôd love to see other tools follow suit.</p>

<p>Getting back to the configuration part, <code>input.plugin</code> is a list of plugins that can be configured and I have configured the Ping and DNS plugin in my config. The <code>output</code> is in Prometheus format so it can be scraped and ingested by Prometheus‚Äô time-series DB.</p>

<h3 id="running-telegraf">Running Telegraf</h3>

<p>With the above config in place, let‚Äôs try running the agent and see what metrics we get. I am using <a href="https://hub.docker.com/_/telegraf/">official</a> Docker image to run the agent with the following config:</p>
<div><pre><code data-lang="sh">docker run --name telegraf-agent --restart always -d -p <span>9283</span>:9283 -v <span>$PWD</span>/telegraf.conf:/etc/telegraf/telegraf.conf:ro telegraf</code></pre></div>
<p>After running the above command, you should be able to see the metrics at <code>localhost:9283/metrics</code></p>
<div><pre><code data-lang="sh">$ curl localhost:9283/metrics | head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  <span>0</span>     <span>0</span>    <span>0</span>     <span>0</span>    <span>0</span>     <span>0</span>      <span>0</span>      <span>0</span> --:--:-- --:--:-- --:--:--     <span>0</span><span># HELP dns_query_query_time_ms Telegraf collected metric</span>
<span># TYPE dns_query_query_time_ms untyped</span>
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"amazon.in"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>124</span>.096472
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"google.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>136</span>.793673
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"kite.zerodha.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>122</span>.780946
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"mrkaran.dev"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>137</span>.915851
dns_query_query_time_ms{<span>dc</span>=<span>"floyd"</span>,domain=<span>"twitter.com"</span>,host=<span>"work"</span>,rack=<span>"work"</span>,rcode=<span>"NOERROR"</span>,record_type=<span>"NS"</span>,result=<span>"success"</span>,server=<span>"100.101.134.59"</span>} <span>111</span>.097483</code></pre></div>
<p>Perfect! Now, we‚Äôre all set to configure Prometheus to scrape the metrics from this target. In order to do that you need to add a new <a href="https://prometheus.io/docs/concepts/jobs_instances/">Job</a>:</p>
<div><pre><code data-lang="yml">- job_name: <span>"ispmonitor"</span>
  scrape_interval: 60s
  static_configs:
    - targets: [<span>"100.94.241.54:9283"</span>] <span># RPi telegraf Agent</span></code></pre></div>
<p>In the above config, I am plugging my Tailscale IP assigned to my RPi on the port where Telegraf agent is bound to. This is one of the <strong>many</strong> reasons why Tailscale is so bloody awesome! I can connect different components in my network to each other without setting up any particular firewall rules, exposing ports on a case by case basis.</p>

<p><strong>Sidenote</strong>: If you haven‚Äôt read Tailscale‚Äôs <strong>amazing</strong> <a href="https://tailscale.com/blog/how-nat-traversal-works/">NAT Traversal blog post</a>, do yourself a favour and check it out after you finish reading this one ofcourse!</p>

<p>Anyway, coming back to our Prometheus setup, we can see the metrics being ingested:</p>

<p><img src="https://mrkaran.dev/images/Prometheus-Telegraf-Ingest.png" alt="image"></p>

<h2 id="show-me-the-graphs">Show me the graphs</h2>

<p>Now comes the exciting bit ‚Äì making <strong>pretty</strong> graphs. First, let‚Äôs discuss what‚Äôs the most important data I can extract out of <code>Ping</code> and <code>DNS</code> plugins. These plugins export decent amount of data, but a good rule of thumb while making dashboards is to optimise signal v/s noise ratio. We‚Äôll do that by filtering out only the metrics that we care for.</p>

<p>Let‚Äôs checkout all the metrics exported by <code>Ping</code> plugin:</p>
<div><pre><code data-lang="sh">$ curl localhost:9283/metrics | grep ping | grep TYPE
<span># TYPE ping_average_response_ms untyped</span>
<span># TYPE ping_maximum_response_ms untyped</span>
<span># TYPE ping_minimum_response_ms untyped</span>
<span># TYPE ping_packets_received untyped</span>
<span># TYPE ping_packets_transmitted untyped</span>
<span># TYPE ping_percent_packet_loss untyped</span>
<span># TYPE ping_result_code untyped</span>
<span># TYPE ping_standard_deviation_ms untyped</span>
<span># TYPE ping_ttl untyped</span></code></pre></div>
<p>Perfect! So, from the above list of metrics, the most important ones for us are:</p>

<ul>
<li><code>ping_average_response_ms</code>: Avg RTT for a packet</li>
<li><code>ping_maximum_response_ms</code>: Max RTT for a packet</li>
<li><code>ping_percent_packet_loss</code>: % of packets lost on the way</li>
</ul>

<p>With just the above 3 metrics, we can answer questions like:</p>

<ul>
<li><strong>Is my ISP suffering an outage?</strong></li>
</ul>

<p>If yes, <code>ping_percent_packet_loss</code> should be unusually higher than normal. This usually happens when the ISP has routing is borked and that causes the packet to be routed in a less optimized way and as a side effect packet loss becomes one of the key metrics to measure here.</p>

<ul>
<li><strong>Is the upstream down?</strong></li>
</ul>

<p>If yes, <code>ping_average_response_ms</code> over a recent window should be higher than a window compared to a previous time range when things were fine and dandy. This can either mean 2 things: Either your ISP isn‚Äôt routing correctly to the said upstream or the CDN/Region where your upstream is faced an outage. This is quite a handy metric for me to monitor!</p>

<p>How many times have your friends complained ‚Äú<code>xyz.com</code> isn‚Äôt working for me‚Äù and when you try to load, it‚Äôs fine from your end? There are a lot of actors at play but <code>ping</code> is usually the most simple and quickest way to detect whether an issue persists or not. Of course, this doesn‚Äôt work for hosts which block ICMP packets altogether. They are not rare either, like <code>netflix.com</code> and <code>github.com</code> both block ICMP probes for example. For my use case, this wasn‚Äôt a major issue as I was able to still probe a decent amount of upstreams all over the world.</p>

<p>With that out of the way, let‚Äôs break the dashboard into different components and see what goes behind them.</p>

<h3 id="ping-response-panel">Ping Response Panel</h3>

<p><img src="https://mrkaran.dev/images/ping-row-panel3.png" alt=""></p>

<p>To plot this, simply choose a <code>Stat</code> visualisation with the query <code>ping_average_response_ms{url="$url"}</code>. Repeat this panel for the variable <code>$url</code> and you should be able to generate a nice row view like this.</p>

<p>Additonally you can choose Thresholds and the Unit to be displayed in the panel with these options.</p>

<p><img src="https://mrkaran.dev/images/ping-row-panel1.png" alt="">
<img src="https://mrkaran.dev/images/ping-row-panel2.png" alt=""></p>

<h3 id="ping-response-time-graph">Ping Response Time Graph</h3>

<p>The next graph is interesting, it lets me visualise the avg, min, max ping response time as well as the % packet loss plotted on the Y2 (right Y) axis.</p>

<p><img src="https://mrkaran.dev/images/floyd-ping.png" alt=""></p>

<h3 id="availability-panel">Availability Panel</h3>

<p>An interesting query to calculate uptime (just in the context whether the upstream is reachable) is:</p>
<div><pre>100 - avg_over_time(ping_percent_packet_loss[2m])</pre></div>
<p>Since I scrape metrics at an interval of <code>1m</code>(in order to not ping too frequently and disrupt my actual browsing experience), in this query I am averaging the data points for the metric <code>ping_percent_packet_loss</code> in a <code>[2m]</code> window.</p>

<p><img src="https://mrkaran.dev/images/ping-availability.png" alt=""></p>

<h3 id="dns-response-time-graph">DNS Response Time Graph</h3>

<p>We can similarly query the DNS response time by visualising the average response time for a DNS query. This might be useful only to people self-hosting their DNS servers.</p>

<p><img src="https://mrkaran.dev/images/telegraf-dns.png" alt=""></p>

<h2 id="conclusion">Conclusion</h2>

<p>So with a pretty simple and minimal OSS solution, I was able to setup monitoring for my home network! Over the last few days whenever my ISP had slightest of trouble, I can correlate it with my metrics! I mean I still can‚Äôt do anything about it cause the other person on ISP‚Äôs customer support is ‚ÄúDid you try rebooting your router‚Äù  ‚Äì the quintessential solution to all tech problems. Wish we could reboot this entire damn 2020 as well, but one could hope!</p>

<p>Shoot me for any questions on my Twitter <a href="https://twitter.com/mrkaran_">@mrkaran_</a> :)</p>

<p>Fin!</p>

			</div></div>]]>
            </description>
            <link>https://mrkaran.dev/posts/isp-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524433</guid>
            <pubDate>Sat, 19 Sep 2020 02:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24524046">thread link</a>) | @pietromenna
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I‚Äôll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I‚Äôm also starting to be disappointed by some of its negative aspects. While it doesn‚Äôt prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I‚Äôd like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we‚Äôll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as ‚Äúfoolish‚Äù does not end well.</p>
<p>While I disagree with the tone here, I‚Äôd like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it‚Äôs outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the ‚Äúflyweight‚Äù design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let‚Äôs get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn‚Äôt the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn‚Äôt. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let‚Äôs remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let‚Äôs not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father‚Äôs tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it‚Äôs directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don‚Äôt think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer ‚Äúcomposition over inheritance‚Äù. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you‚Äôre done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don‚Äôt see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: ‚ÄúDefine a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically‚Äù. Now, if we take a look at some modern technologies, doesn‚Äôt this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I‚Äôm not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I‚Äôm merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section ‚ÄúWhat to Expect from Design Patterns‚Äù, page 351:</p>
<blockquote>
<p>It‚Äôs possible to argue that this book hasn‚Äôt accomplished much. After all, it doesn‚Äôt present any algorithms or programming techniques that haven‚Äôt been used before. [‚Ä¶] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can‚Äôt offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don‚Äôt study design patterns in software, we won‚Äôt be able to improve them, and it‚Äôll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24524046</guid>
            <pubDate>Sat, 19 Sep 2020 01:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Test Machine Learning Code and Systems]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24523930">thread link</a>) | @7d7n
<br/>
September 18, 2020 | https://eugeneyan.com/writing/testing-ml/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/testing-ml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Two weeks ago, <a href="https://twitter.com/jeremyjordan" target="_blank">Jeremy</a> wrote a great post on <a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">Effective Testing for Machine Learning Systems</a>. He distinguished between traditional software tests and machine learning (ML) tests; software tests check the <strong>written logic</strong> while ML tests check the <strong>learned logic</strong>.</p>

<p>ML tests can be further split into <strong>testing</strong> and <strong>evaluation</strong>. We‚Äôre familiar with ML <strong>evaluation</strong> where we train a model and evaluate its performance on an unseen validation set; this is done via metrics (e.g., accuracy, <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" target="_blank">Area under Curve of Receiver Operating Characteristic (AUC ROC)</a>) and visuals (e.g., <a href="https://eugeneyan.com/writing/recommender-systems-baseline-pytorch/#implementation-2-matrix-factorization-with-bias" target="_blank">precision-recall curve</a>).</p>

<p>On the other hand, ML <strong>testing</strong> involves checks on model behaviour. <strong>Pre-train tests</strong>‚Äîwhich can be run without trained parameters‚Äîcheck if our <em>written logic</em> is correct. For example, is classification probability between 0 to 1? <strong>Post-train tests</strong> check if the <em>learned logic</em> is expected. For example, on the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>, we should expect females to have a higher survival probability (relative to males).</p>

<p><img src="https://eugeneyan.com/assets/testing-ml-flow.jpg" title="Workflow for testing machine learning" alt="Workflow for testing machine learning"></p>
<p>Workflow for testing machine learning (<a href="https://www.jeremyjordan.me/testing-ml/" target="_blank">source</a>)</p>

<p>Taken together, here‚Äôs how the workflow might look like. To complement this, we‚Äôll implement a machine learning model and run the following tests on it:</p>
<ul>
  <li><a href="#pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</a></li>
  <li><a href="#post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</a></li>
  <li><a href="#model-evaluation-to-ensure-satisfactory-performance">Evaluation to ensure satisfactory model performance</a></li>
</ul>

<blockquote>
  <p>Follow along with the code in this Github repository: <a href="https://github.com/eugeneyan/testing-ml" target="_blank"><code>testing-ml</code></a></p>
</blockquote>

<h2 id="setting-up-the-context-algorithm-and-data">Setting up the context (algorithm and data)</h2>

<p>Before we can do ML testing, we‚Äôll need an <strong>algorithm and some data</strong>. Our algorithm will be a <a href="https://numpy.org/" target="_blank"><code>numpy</code></a> implementation of <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py" target="_blank"><code>DecisionTree</code></a> which predicts a probability for binary classification. (<a href="#try-it-for-yourself-and-break-something">Extensions to make it support regression welcome!</a>).</p>

<p>To run our tests, we‚Äôll use the <a href="https://www.kaggle.com/c/titanic/data" target="_blank">Titanic dataset</a>. This tiny data set (~900 rows, 10 features) makes for fast testing (when model training is involved) and allows us to iterate quickly. (As part of performance evaluation, we run <code>fit()</code> and <code>predict()</code> hundreds of times to get the 99th percentile timing.) The simplicity and familiarity of the data also makes it easier to discuss the post-train (i.e., learned logic) tests.</p>

<div><div><pre><code>+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
| PassengerId | Survived | Pclass | Name                                    | Sex    | Age | SibSp | Parch | Ticket    |    Fare | Cabin | Embarked |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------|
|           1 |        0 |      3 | Braund, Mr. Owen Harris                 | male   |  22 |     1 |     0 | A/5 21171 |    7.25 | nan   | S        |
|           2 |        1 |      1 | Cumings, Mrs. John Bradley (Florence... | female |  38 |     1 |     0 | PC 17599  | 71.2833 | C85   | C        |
|           3 |        1 |      3 | Heikkinen, Miss. Laina                  | female |  26 |     0 |     0 | STON/O2.  |   7.925 | nan   | S        |
|           4 |        1 |      1 | Futrelle, Mrs. Jacques Heath (Lily M... | female |  35 |     1 |     0 | 113803    |    53.1 | C123  | S        |
|           5 |        0 |      3 | Allen, Mr. William Henry                | male   |  35 |     0 |     0 | 373450    |    8.05 | nan   | S        |
|           6 |        0 |      3 | Moran, Mr. James                        | male   | nan |     0 |     0 | 330877    |  8.4583 | nan   | Q        |
|           7 |        0 |      1 | McCarthy, Mr. Timothy J                 | male   |  54 |     0 |     0 | 17463     | 51.8625 | E46   | S        |
|           8 |        0 |      3 | Palsson, Master. Gosta Leonard          | male   |   2 |     3 |     1 | 349909    |  21.075 | nan   | S        |
|           9 |        1 |      3 | Johnson, Mrs. Oscar W (Elisabeth Vil... | female |  27 |     0 |     2 | 347742    | 11.1333 | nan   | S        |
|          10 |        1 |      2 | Nasser, Mrs. Nicholas (Adele Achem)     | female |  14 |     1 |     0 | 237736    | 30.0708 | nan   | C        |
+ ------------+----------+--------+-----------------------------------------+--------+-----+-------+-------+-----------+---------+-------+----------+
</code></pre></div></div>
<p>If you're unfamiliar with the Titanic dataset, here's how it looks like (scroll to the right).</p>

<h2 id="adopting-testing-habits-from-software-engineering">Adopting testing habits from software engineering</h2>

<p>We‚Äôll adopt some good habits from software engineering. We won‚Äôt go through them in detail here though it was previously covered in another <a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/" target="_blank">post</a>:</p>
<ul>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#write-some-unit-tests-theyre-our-safety-harness" target="_blank">Unit test</a> fixture reuse, exceptions testing, etc with <a href="https://docs.pytest.org/en/latest/" target="_blank"><code>pytest</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-coverage-how-extensive-are-our-tests" target="_blank">Code coverage</a> with <a href="https://coverage.readthedocs.io/en/coverage-5.2.1/" target="_blank"><code>Coverage.py</code></a> and <a href="https://pytest-cov.readthedocs.io/en/latest/" target="_blank"><code>pytest-cov</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#lint-to-ensure-consistency-across-projects" target="_blank">Linting</a> to ensure code consistency with <a href="https://www.pylint.org/" target="_blank"><code>pylint</code></a></li>
  <li><a href="https://eugeneyan.com/writing/setting-up-python-project-for-automation-and-collaboration/#check-for-type-errors-to-prevent-them" target="_blank">Type checking</a> to verify type correctness with <a href="http://mypy-lang.org/" target="_blank"><code>mypy</code></a></li>
</ul>

<p>(Note: The tests below won‚Äôt include type hints though the <a href="https://github.com/eugeneyan/testing-ml/blob/master/src/tree/decision_tree.py#L16" target="_blank">implementation code</a> does.)</p>

<h2 id="pre-train-tests-to-ensure-correct-implementation">Pre-train tests to ensure correct implementation</h2>

<p>In pre-train tests, we want to <strong>catch errors in our implementation</strong> (i.e., written logic) before training an erroneous model. We can run these tests without a fully trained model.</p>

<p>First, we‚Äôll test our functions of <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity" target="_blank">Gini impurity</a> and <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#Information_gain" target="_blank">Gini gain</a>. These will be used to <a href="https://en.wikipedia.org/wiki/Decision_tree_learning#General" target="_blank">split the data</a> and grow our decision tree.</p>

<div><div><pre><code><span>def</span> <span>test_gini_impurity</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.219</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.375</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.469</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_impurity</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.500</span>


<span>def</span> <span>test_gini_gain</span><span>():</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.5</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.125</span>
    <span>assert</span> <span>round</span><span>(</span><span>gini_gain</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[[</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>]]),</span> <span>3</span><span>)</span> <span>==</span> <span>0.0</span>
</code></pre></div></div>

<p>Next, we‚Äôll check if the model prediction shape is expected. We should have the same number of rows as the input features.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_shape</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>pred_train</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as training labels.'</span>
    <span>assert</span> <span>pred_test</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X_test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],),</span> <span>'DecisionTree output should be same as testing labels.'</span>
</code></pre></div></div>

<p>We‚Äôll also want to check the output ranges. Given that we‚Äôre predicting probabilities, we should expect the output to range from 0 to 1 inclusive.</p>

<div><div><pre><code><span>def</span> <span>test_dt_output_range</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>X_test</span><span>,</span> <span>y_test</span> <span>=</span> <span>dummy_titanic</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
    <span>pred_train</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
    <span>pred_test</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_test</span><span>)</span>

    <span>assert</span> <span>(</span><span>pred_train</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_train</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
    <span>assert</span> <span>(</span><span>pred_test</span> <span>&lt;=</span> <span>1</span><span>).</span><span>all</span><span>()</span> <span>&amp;</span> <span>(</span><span>pred_test</span> <span>&gt;=</span> <span>0</span><span>).</span><span>all</span><span>(),</span> <span>'Decision tree output should range from 0 to 1 inclusive'</span>
</code></pre></div></div>

<p>Here, we‚Äôll check for test set leakage (i.e., duplicate rows in train/test splits) by concatenating train and test data, dropping duplicates, and checking the number of rows. (Note: Other leakages include <a href="https://www.fast.ai/2017/11/13/validation-sets/#time-series" target="_blank">temporal leaks</a> and <a href="https://en.wikipedia.org/wiki/Leakage_(machine_learning)#Feature_leakage" target="_blank">feature leaks</a>; we won‚Äôt cover them here.)</p>

<div><div><pre><code><span>def</span> <span>test_data_leak_in_test_data</span><span>(</span><span>dummy_titanic_df</span><span>):</span>
    <span>train</span><span>,</span> <span>test</span> <span>=</span> <span>dummy_titanic_df</span>

    <span>concat_df</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>train</span><span>,</span> <span>test</span><span>])</span>
    <span>concat_df</span><span>.</span><span>drop_duplicates</span><span>(</span><span>inplace</span><span>=</span><span>True</span><span>)</span>

    <span>assert</span> <span>concat_df</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>==</span> <span>train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span> <span>+</span> <span>test</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
</code></pre></div></div>

<p>Given perfectly separable data and unlimited depth, our decision tree should be able to ‚Äúmemorise‚Äù the training data and <em><a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank">overfit</a> completely</em>. In other words, if we train <em>and</em> evaluate on the training data, we should get 100% accuracy. (Note: the Titanic data isn‚Äôt perfectly separable so we‚Äôll create a small data sample for this.)</p>

<div><div><pre><code><span>@</span><span>pytest</span><span>.</span><span>fixture</span>
<span>def</span> <span>dummy_feats_and_labels</span><span>():</span>
    <span>feats</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([[</span><span>0.7057</span><span>,</span> <span>-</span><span>5.4981</span><span>,</span> <span>8.3368</span><span>,</span> <span>-</span><span>2.8715</span><span>],</span>
                      <span>[</span><span>2.4391</span><span>,</span> <span>6.4417</span><span>,</span> <span>-</span><span>0.80743</span><span>,</span> <span>-</span><span>0.69139</span><span>],</span>
                      <span>[</span><span>-</span><span>0.2062</span><span>,</span> <span>9.2207</span><span>,</span> <span>-</span><span>3.7044</span><span>,</span> <span>-</span><span>6.8103</span><span>],</span>
                      <span>[</span><span>4.2586</span><span>,</span> <span>11.2962</span><span>,</span> <span>-</span><span>4.0943</span><span>,</span> <span>-</span><span>4.3457</span><span>],</span>
                      <span>[</span><span>-</span><span>2.343</span><span>,</span> <span>12.9516</span><span>,</span> <span>3.3285</span><span>,</span> <span>-</span><span>5.9426</span><span>],</span>
                      <span>[</span><span>-</span><span>2.0545</span><span>,</span> <span>-</span><span>10.8679</span><span>,</span> <span>9.4926</span><span>,</span> <span>-</span><span>1.4116</span><span>],</span>
                      <span>[</span><span>2.2279</span><span>,</span> <span>4.0951</span><span>,</span> <span>-</span><span>4.8037</span><span>,</span> <span>-</span><span>2.1112</span><span>],</span>
                      <span>[</span><span>-</span><span>6.1632</span><span>,</span> <span>8.7096</span><span>,</span> <span>-</span><span>0.21621</span><span>,</span> <span>-</span><span>3.6345</span><span>],</span>
                      <span>[</span><span>0.52374</span><span>,</span> <span>3.644</span><span>,</span> <span>-</span><span>4.0746</span><span>,</span> <span>-</span><span>1.9909</span><span>],</span>
                      <span>[</span><span>1.5077</span><span>,</span> <span>1.9596</span><span>,</span> <span>-</span><span>3.0584</span><span>,</span> <span>-</span><span>0.12243</span><span>]</span>
                      <span>])</span>
    <span>labels</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>])</span>
    <span>return</span> <span>feats</span><span>,</span> <span>labels</span>

<span>def</span> <span>test_dt_overfit</span><span>(</span><span>dummy_feats_and_labels</span><span>):</span>
    <span>feats</span><span>,</span> <span>labels</span> <span>=</span> <span>dummy_feats_and_labels</span>
    <span>dt</span> <span>=</span> <span>DecisionTree</span><span>()</span>
    <span>dt</span><span>.</span><span>fit</span><span>(</span><span>feats</span><span>,</span> <span>labels</span><span>)</span>
    <span>pred</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>dt</span><span>.</span><span>predict</span><span>(</span><span>feats</span><span>))</span>

    <span>assert</span> <span>np</span><span>.</span><span>array_equal</span><span>(</span><span>labels</span><span>,</span> <span>pred</span><span>),</span> <span>'DecisionTree should fit data perfectly and prediction should == labels.'</span>
</code></pre></div></div>

<p>Lastly, we check if increasing tree depth leads to increased accuracy and AUC ROC on <em>training</em> data (though it‚Äôll overfit and perform poorly on <em>validation</em> data). In the test below, we fit trees of depth one to 10 and ensure training accuracy and AUC increases consistently.</p>

<div><div><pre><code><span>def</span> <span>test_dt_increase_acc</span><span>(</span><span>dummy_titanic</span><span>):</span>
    <span>X_train</span><span>,</span> <span>y_train</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>dummy_titanic</span>

    <span>acc_list</span> <span>=</span> <span>[]</span>
    <span>auc_list</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>depth</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>10</span><span>):</span>
        <span>dt</span> <span>=</span> <span>DecisionTree</span><span>(</span><span>depth_limit</span><span>=</span><span>depth</span><span>)</span>
        <span>dt</span><span>.</span><span>fit</span><span>(</span><span>X_train</span><span>,</span> <span>y_train</span><span>)</span>
        <span>pred</span> <span>=</span> <span>dt</span><span>.</span><span>predict</span><span>(</span><span>X_train</span><span>)</span>
        <span>pred_binary</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>pred</span><span>)</span>
        <span>acc_list</span><span>.</span><span>append</span><span>(</span><span>accuracy_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred_binary</span><span>))</span>
        <span>auc_list</span><span>.</span><span>append</span><span>(</span><span>roc_auc_score</span><span>(</span><span>y_train</span><span>,</span> <span>pred</span><span>))</span>

    <span>assert</span> <span>sorted</span><span>(</span><span>acc_list</span><span>)</span> <span>==</span> <span>acc_list</span><span>,</span> <span>'Accuracy should increase as tree depth increases.'</span>
    <span>assert</span> <span>sorted</span><span>(</span><span>auc_list</span><span>)</span> <span>==</span> <span>auc_list</span><span>,</span> <span>'AUC ROC should increase as tree depth increases.'</span>
</code></pre></div></div>

<h2 id="post-train-tests-to-ensure-expected-learned-behaviour">Post-train tests to ensure expected learned behaviour</h2>

<p>In post-train tests, we want to <strong>check if the model is behaving ‚Ä¶</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/testing-ml/">https://eugeneyan.com/writing/testing-ml/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/testing-ml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24523930</guid>
            <pubDate>Sat, 19 Sep 2020 01:23:15 GMT</pubDate>
        </item>
    </channel>
</rss>
