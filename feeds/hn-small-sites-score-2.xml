<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 06 Nov 2020 16:39:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 06 Nov 2020 16:39:45 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Biden Will Win Nevada by 1%]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996787">thread link</a>) | @marcacohen
<br/>
November 5, 2020 | https://mco.dev/biden-will-win-nevada-by-1/ | <a href="https://web.archive.org/web/*/https://mco.dev/biden-will-win-nevada-by-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
            <div>
              <p>Nevada has 86% of its votes reported and won’t announce additional results until later today. But it’s pretty easy to crunch the numbers because it has only 22 counties.</p>
<p>Nearly all of those counties are red except for Clark and Washoe, which are by far the largest in population. All you have to do is extrapolate the remaining votes, on a per county basis, to break the same way the existing votes have gone.</p>
<p>One pitfall here is timing bias, i.e., the later counted votes within a county may be distributed differently than those counted earlier. That’s quite possible if they are comprised of a differently distributed category (e.g. mail-in vs. in-person, early vs. later received absentee ballots, etc.).</p>
<p>According to the New York Times, “Remaining votes include mail ballots received on Election Day, those that will arrive over the next week and provisional ballots.". So they’ll likely skew a bit but it’s not obvious in which direction. And 86% is a pretty good sample size.</p>
<p>The calculation below does this simple per-county extrapolation. My projected shares of the total may be off a bit due to excluding the effect of the two other party candidates, but the relative difference should be the same: Biden will win Nevada by about 1%.</p>
<br>

              
            </div>
          </div></div>]]>
            </description>
            <link>https://mco.dev/biden-will-win-nevada-by-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996787</guid>
            <pubDate>Thu, 05 Nov 2020 09:26:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding from scratch after a cease and desist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996671">thread link</a>) | @khuknows
<br/>
November 5, 2020 | https://rocketgems.com/blog/goodbye-uimovement/ | <a href="https://web.archive.org/web/*/https://rocketgems.com/blog/goodbye-uimovement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
            
                <p>The story of why I had to rebuild an established site from scratch and how things are going since making the switch</p>
            
        </div>
        
    </div><div>
        <div>
            <p>Five years ago, <a href="https://www.producthunt.com/posts/ui-movement" target="_blank">I launched a little side project called UI Movement</a> which was a newsletter that featured five design animations every week. It's since grown in scope and popularity until the newsletter had close to 30,000 subscribers and the site was getting ~350,000 page views per month.</p><p>The featured designs came from various external sources, but one was by far the most popular. It made sense because that source was super well known amongst designers and it’s where they go to share their work.</p><p>The legal team from that website sent me a cease and desist for UI Movement a couple of months ago. Even though the featured designs always included attribution and links back to the original, they were clearly not happy that UI Movement was featuring content from their site. The email was a bit of a shock, but deep down I knew it could happen at any moment. Running a “curation” type site like UI Movement with most of the content coming from one source was always a risk.</p><p>I thought about making minor changes and hoping it would be enough, but decided to take a different approach.</p><p>The truth is, UI Movement is no longer a big part of my business and it was more of a passion project/hobby that I was slowly losing interest in. I was getting tired of featuring over-the-top design animations that would never make it into production or would be quite annoying for users if they did. While I still see value in finding inspiration from unrealistic designs, I wasn’t enjoying the process of curating them anymore.</p><p>Instead of shutting UI Movement down or making a few small tweaks, I decided to start from scratch and make a UI design inspiration site I could get excited about.</p><p>The end result is that UI Movement became <a href="https://screenlane.com/" target="_blank">Screenlane</a>: A site that features web &amp; mobile screenshots from live products for UI design inspiration. No more unrealistic prototypes. Admittedly, not the most innovative idea, but I believe I can get Screenlane to the point where it's providing as much or more value than UI Movement.</p><p>Screenlane has been live for ~3 weeks and I thought it would be a good time to share some numbers. This was more than a redesign or a rebrand with a domain change. It's all new content, a new domain, brand, and website. I had no idea what to expect.</p><p>Here are the numbers so far:<br></p><h2>The newsletter</h2><p>When the announcement email was sent, the newsletter had 29,662 subscribers. It now has 29,250 subscribers (a decrease of 412).</p><p>The announcement email included a big “unsubscribe” button after an explanation of the change and why it happened.<br></p><p>Since then, a couple more weekly newsletters have been sent and they both briefly mentioned the change. I'm hoping the number of unsubscribes will level off over time. 128 people have subscribed since the change, which is promising.</p><h2>Website traffic</h2><p>Traffic has dropped from ~15,000 users &amp; ~82,000 page views per week to ~8,000 users and ~38,000 page views per week.</p><p><img src="https://rocketgems.com/media/django-summernote/2020-11-04/a00341d1-3aaf-45d0-9a8e-728d22043ed9.png"><br></p><p>Traffic from <b>uimovement.com</b> is redirected to <b>screenlane.com?ref=uimovement</b>, which helps me track the trend of how much of the traffic is still attempting to go to UI Movement. I also submitted a "change of address" notice to Google through the&nbsp;Search Console.&nbsp;</p><h2><span>Reactions from subscribers</span></h2><p>I rarely heard from UI Movement subscribers until this change. At least half a dozen people have been in touch to let me know how how sad they are that UI Movement is essentially dead and how much value they got from it. A few people also shared some words of encouragement about the direction I've taken with Screenlane. It was both surprising and awesome to hear from subscribers. Honestly, I didn't expect as many people to be disappointed by the demise of UI Movement. I now feel a bit more pressure to make Screenlane great.</p><p>Overall, the decrease in newsletter subscribers is reasonably small, the drop in traffic is substantial, and the overall response to Screenlane is positive. I'm fairly happy with how things are going &amp; it will be interesting to see if I can stop the downward trend and start growing the traffic &amp; newsletter again.</p><p>It's been quite fun to make such a drastic change without worrying too much about the outcome. This whole situation would have been much worse if UI Movement was a significant part of the business or still drove a lot of traffic to <a href="https://pageflows.com/" target="_blank">Page Flows</a>.</p>
            
            
        </div>
    </div></div>]]>
            </description>
            <link>https://rocketgems.com/blog/goodbye-uimovement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996671</guid>
            <pubDate>Thu, 05 Nov 2020 08:57:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abortion Is Wrong: Steelmanning a Position I Do Not Hold]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996518">thread link</a>) | @taylorlunt
<br/>
November 5, 2020 | https://taylor.gl/blog/10/ | <a href="https://web.archive.org/web/*/https://taylor.gl/blog/10/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
    <div>
      
<p>
<a href="https://taylor.gl/">Home</a>

  
  
  <a href="https://taylor.gl/"> </a>

  
  
  »
  
  <a href="https://taylor.gl/blog/"> Blog</a>

</p>

<p><span>
  Reading time: 13 minutes.

  Written in 2020.
</span></p>

<p>Religious conservatives grasp at straws when trying to justify their pro-life (anti-abortion) position, usually appealing to either religious doctrine or the idea that abortion is “killing a baby” and killing is wrong. The logical faults with these arguments are obvious, but I see the arguments of religious individuals who are horrified with abortion as a desperate attempt to justify their correct intuition — correct, because abortion is wrong. It is the killing of a defenseless creature we ought to protect. Even most pro-choice people admit abortion is a last resort and unwanted pregnancies should be avoided. This conceeds the unethical nature of abortion, and simply states it is overcome by other factors. This means where you fall on the pro-choice/pro-life debate is a subjective question of how you balance these factors, not “anti-science” as some claim. I address several of these factors in this article, and I also outline several often-ignored reasons why abortion is wrong, and they’re hopefully more sophisticated than the usual religious tripe you’ve heard before. Note that these are all arguments for why abortion is ethically wrong and should be avoided, not an argument that we should make abortion illegal, which is a bad idea and doesn’t even make abortion less common, only more dangerous.</p>
<h3 id="common-pro-choice-arguments">Common pro-choice arguments</h3>
<p>Many pro-choice arguments are flawed in that they can be applied equally to justify abortion and (post-birth) infanticide. An MIT pro-choice student group made the argument that “unwanted life can be worse than no life at all,” implying the right of a child to a mother who wants them and who is prepared for motherhood, financially and otherwise. Lack of such preparation of the mother is apparently grounds for killing the fetus, because death is better than a bad life. So why not kill a three-month-old baby whose mother is poor, or doesn’t care for them much? Would it not, too, be a form of euthanasia? More selfish are the arguments for the woman’s right not to be a mother and instead to be able to have a career or whatever, which could as easily justify infanticide. Don’t want to kill your chances at a career? Kill your baby instead!</p>
<p>The same MIT student group argues: why should a woman have to “face all consequences from something she did not do alone”? Another argument for the killing of a <span>fetus<span>or baby</span></span> based on inconvenience to the mother, but this time with a hint of the common pro-choice accusation of misogyny: this is just men telling women what to do with their bodies, and if men could get pregnant, then abortion would have been legal a long time ago. (Nevermind the fact that women have been able to vote since 1920 in the United States.) But this argument also falls with the comparison to infanticide. Men can’t get pregnant, but they can have children, and many of them don’t want children. Many men would find it convenient to get rid of their children so they don’t have to pay child support. So why is infanticide illegal? Perhaps because the desires of the parent are outweighed by the rights of the child.</p>
<p>Anyone who has seen a newborn baby knows how undeveloped they are, and the distinction between a baby <span>right before birth and right after<span>or right before ’viability’ and right after, if you prefer</span></span> is similar to the distinction between magma and lava — that is, it’s basically the same thing but in a different location. This means nearly every pro-choice argument can be applied equally to justify infanticide, rendering it useless. The exception is the argument of the bodily autonomy of the mother: the fetus has no right to the body of the mother. Apparently this bodily autonomy of the mother extends to the right to cut up the fetus and suck its body parts out with a hose, or the right to crush the skull of the fetus, or the right to poison the fetus to death — all common methods of abortion. If the fetus were simply removed in a fashion similar to birth, and allowed to die of natural causes, this argument may apply, but otherwise a double standard exists between the bodily autonomy of the mother and the bodily autonomy of the fetus. In any case, the argument for bodily autonomy is weak: the fetus didn’t ask to be created, and the mother created it anyway, so she should be responsible for it. The tenancy agreement of the fetus was made implicitly on conception.</p>
<h3 id="sympathy-arguments">Sympathy arguments</h3>
<p>We don’t eat <span>dog or cat<span>or dogs or cats, if you prefer to avoid the mass nouns and see them as individuals</span></span> because it would be abhorant to us to eat creatures which would remind us of creatures we love, even though, for example, pigs are at least as cognitively sophisticated. But pigs are gross and roll in the mud, so it’s okay to eat them. Eating them won’t break anyone’s hearts unless their hearts were already bleeding. Similarly to our aversion to caticide and dogicide, we should avoid abortion because feticide reminds us of infanticide. Even if you are not killing a real baby, you’re making people feel on a visceral level that you are, which is suffering in its own right. This is not a hypothetical argument: at least a third of people in the United States think abortion should be illegal in all cases. Such people are horrified by abortion. Even if it does not actually involve killing babies, these people think it does, and their hearts break in sympathy.</p>
<h3 id="slippery-slope-arguments">Slippery slope arguments</h3>
<p>Abortion is the first step on the road to the destruction of the sanctity of human life. Human life must be sacred, not for religious or spiritual reasons, but because we are humans and therefore want the value of human life to be enshrined in the law. (One reason why suicide is illegal in some places.) Because of the similarity morally between late-term abortions and early infancy infanticide, there is a slippery slope to infanticide. But more generally, allowing humans to kill other humans always makes human life cheaper.</p>
<p>Abortion can also lead to eugenics. Parents can screen their fetuses for certain <span>traits<span>such as sex</span></span>, and abort if the they don’t like what they find. This logic has made female infanticide in China not uncommon, so it’s easy to see how it could cause abortion, too. One of the problems is that parental screening of fetuses need not be logical. It will be more likely to be determined by what is <span>fashionable<span>sex in China</span></span> and what is determined to be desirable given the social and political climate. </p>
<p>If people become much less likely to have autistic babies, then those who do have autism will have less resources, be less understood by society, and be more likely to face discrimination. If the gender ratio becomes to imbalanced, the problems are obvious. And any narrow form of selection can lead to loss of genetic diversity in the population. But beyond just the utilitarian argument against eugenics via abortion, I think it’s a bit sad that we think some babies just aren’t good enough to be born.</p>
<p>By permitting abortion, we tell mothers they are free to abdicate their motherhood. If you don’t want to be a mother, it’s okay, you don’t have to be a mother. This is an unhealthy message which may persist in the minds of women once they do decide to have a baby. If motherhood is not a responsibility, but a choice, then mothers will be more likely to neglect their children or give up their older child for adoption when things get tough. The same basically applies to fatherhood. If a man’s first reaction to hearing that he got a woman pregnant is to plead with her to get an abortion, then he has been trained to run away from fatherhood and not take the role seriously. This is good for nobody.</p>
<h3 id="abortion-is-a-bad-decision">Abortion is a bad decision</h3>
<p>In general, people are not taking the role of parenthood serously anymore. People would use abortion to put off parenthood until a more convenient time, but we know from positive psychology that building a family is going to have a much greater positive impact on your happiness than trying to advance your career or lounge around for another decade. And procrastinating parenthood may lead to not being able to see your grandchildren grow up, or your children “make it” in the world. So why do people routinely make the wrong choice in Western society? Abortion plays a role. It makes it easy not to see parenthood as a responsibility and as a core part of the human experience, but rather as more of a hobby, which some may be interested in, and other people might try bowling instead. If abortion should be illegal, it should be to stop mothers from shooting themselves <span>in the foot<span>not to mention shooting the fetus in the head</span></span>. </p>
<h3 id="risk">Risk</h3>
<p>They say the risks of abortion are less than the risks of childbirth, and science confirms this: one study showed the risk of death from giving birth is 14 times higher than from abortion. This is given as an argument in favor of the pro-choice position. The problem with this argument is that it’s a false comparison; many mothers who get abortions now end up having children later anyway, so the risk is actually <span>additive<span>abortion now + birth later vs. birth now</span></span>. When a woman undergoes multiple abortions, the subsequent abortions are also progressively less safe, and can lead to, for example, Asherman syndrome, which can cause pain and infertility. A 2015 review also found a link between abortion and future issues with pregnancy including premature birth and low birth weight. With the risks of abortion alone, it may be unethical to perform abortions — at least in some cases, such as when the mother has already had one or more abortions.</p>
<p>There are also societal health risks to abortion beyond the health of the <span>mother<span>and child…</span></span>. The kinds of reckless people who have unprotected sex and need abortions are also the kinds of reckless people who spread <span>STIs<span>the infections formerly known as STDs</span></span>, and it’s better if they settle down and become parents rather than continuing to spread disease. …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://taylor.gl/blog/10/">https://taylor.gl/blog/10/</a></em></p>]]>
            </description>
            <link>https://taylor.gl/blog/10/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996518</guid>
            <pubDate>Thu, 05 Nov 2020 08:17:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bddisasm: The Bitdefender x86 Disassembler]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996492">thread link</a>) | @signa11
<br/>
November 5, 2020 | https://hvmi.github.io/blog/2020/11/04/bddisasm.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/04/bddisasm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Hypervisor Memory Introspection (HVMI) relies on analyzing memory accesses in order to determine whether they are legitimate or not. For example, by analyzing the old memory value and the newly stored value, HVMI can decide whether to allow the modification or not. This, however, introduces the complication of needing to do an in-depth analysis of each instruction that modifies protected memory. Unlike a RISC architecture, x86 has a large number of instructions that may access memory in a complicated, read-modify-write (RMW) manner, and using complicated addressing schemes.
In order to simplify instruction decoding and analysis, a dedicated x86 instruction decoder has been created, capable of providing full instruction information, and thus alleviating the HVMI module from needing to know x86 instructions format. This blog post will detail some bddisasm internals, how to work with it, while highlighting why it is a critical part of HVMI. In addition, we will go through some particularities of x86 instruction encoding. The main bddisasm project is located <a href="https://github.com/bitdefender/bddisasm">here</a>, and the documentation can be accessed <a href="https://bddisasm.readthedocs.io/">here</a>.</p>

<h2 id="bddisasm-overview">bddisasm Overview</h2>

<p>bddisasm is a standalone library, written in C, with some Python used for internal decoder-tables generation. The library is built to be fast, while providing as much information about the decoded instructions as possible - this is important, because other projects using bddisasm can rely on it to provide complete and accurate information about instructions. When considering other decoding libraries, there are only some which are similar in features:</p>

<ul>
  <li><a href="https://intelxed.github.io/">Intel Xed</a>, which is written and maintained by Intel, thus somehow making it the standard x86 decoder; while not the fastest, it provides rich information about the decoded instructions;</li>
  <li><a href="https://github.com/aquynh/capstone">Capstone</a>, which is basically a collection of decoders for multiple architectures;</li>
  <li><a href="https://github.com/zyantific/zydis">ZyDis</a>, which is comparable to Xed as far as features go, and lightweight (however, when bddisasm was created internally, ZyDis did not exist yet);</li>
</ul>

<p>Other decoders written in other languages, such as Rust or C#, or disassembler (which only provide a textual output of the instruction, without providing actual decoded instruction information) were not considered. Given that Xed and Capstone seemed rather difficult to work with at that time, we decided to create a lightweight decoder of our own, with the following objectives in mind:</p>

<ul>
  <li>Lightweight - written entirely in C, with no external dependencies, no memory allocated, and thread-safe by design;</li>
  <li>Fast - while we needed a decoder capable of providing as much information as possible about instructions, we still considered speed an important factor;</li>
  <li>Resilient - the decoder should be able to handle all kinds of malformed instructions, as well as valid instructions containing redundant prefixes, or encodings which are not typical;</li>
  <li>Complete - the decoder must support all existing x86 instructions, including AVX; moreover, extending the support to new instructions should be as simple as possible;</li>
  <li>Easy to work with - single-header file, single-API library, which provides all possible information in the output decoded instruction, without the need to call additional functions in order to extract information from the decoded instruction;</li>
</ul>

<p>We will not get into a comparison between bddisasm and other decoding libraries, and we will keep the focus of this blog post on how to work with bddisasm and how useful it is in HVMI.</p>

<h2 id="working-with-bddisasm">Working With bddisasm</h2>

<p>Working with the decoding library is easy: include the <code>bddisasm.h</code> header file, link with the <code>bddisasm.lib</code> (Windows) or <code>libbddisasm.a</code> (Linux), and call the decoding API! bddisasm uses a single-API decoding scheme, where the <code>NdDecode</code> APIs provide an output <code>INSTRUX</code> structure containing all the possible information about the instruction. The only thing not included in the <code>INSTRUX</code> structure is the textual disassembly of the instruction, which has to be generated separately using the <code>NdToText</code> API. A typical usage scenario might be the following:</p>

<div><div><pre><code><span>#include "bddisasm/bddisasm.h"
</span>
<span>int</span> <span>main</span><span>()</span>
<span>{</span>
     <span>INSTRUX</span> <span>ix</span><span>;</span>
     <span>unsigned</span> <span>char</span> <span>ins</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>{</span> <span>0x33</span><span>,</span> <span>0xC0</span> <span>};</span>
     <span>NDSTATUS</span> <span>status</span><span>;</span>

     <span>status</span> <span>=</span> <span>NdDecodeEx</span><span>(</span><span>&amp;</span><span>ix</span><span>,</span> <span>ins</span><span>,</span> <span>sizeof</span><span>(</span><span>ins</span><span>),</span> <span>ND_CODE_64</span><span>,</span> <span>ND_DATA_64</span><span>);</span>
     <span>if</span> <span>(</span><span>!</span><span>ND_SUCCESS</span><span>(</span><span>status</span><span>))</span>
     <span>{</span>
         <span>printf</span><span>(</span><span>"Decoding failed with error 0x%08x!</span><span>\n</span><span>"</span><span>,</span> <span>status</span><span>);</span>
         <span>return</span> <span>-</span><span>1</span><span>;</span>
     <span>}</span>

     <span>printf</span><span>(</span><span>"Decoded instruction with length %d!</span><span>\n</span><span>"</span><span>,</span> <span>ix</span><span>.</span><span>Length</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<h3 id="decoded-instruction-information">Decoded Instruction Information</h3>

<p>Note that the output <code>INSTRUX ix</code> structure will contain <em>all</em> the information about the decoded instruction. A comprehensive list about what kind of information you can find:</p>

<ul>
  <li>Raw information about the instruction, such as prefixes, opcodes, modrm, SIB, displacement, immediate fields;</li>
  <li>Information about operand size, address size, vector length;</li>
  <li>Decoded prefix information, such as whether the instruction uses lock, is repeated, is xacquire/xrelease enabled or CET tracked;</li>
  <li>Length information, including about the instruction itself and different fields of the instruction, such as immediate fields or displacement;</li>
  <li>Offset information about each constituent field of the instruction (position of each field inside the instruction);</li>
  <li>Individual RFLAGS flags access mode: modified, tested, set, cleared and undefined;</li>
  <li>FPU flags access for <code>C0</code>, <code>C1</code>, <code>C2</code> and <code>C3</code> flags;</li>
  <li>AVX information, such as instruction exception class, tuple type, and rounding mode;</li>
  <li>Instruction category (example: CALL, RET, ARITH, LOGIC, etc.);</li>
  <li>Instruction set (example: I86, I64, MMX, SSE4, etc.);</li>
  <li>CPUID feature flag, which indicates the leaf and subleaf that must be queried, together with the register and bit which indicates support for that particular instruction;</li>
  <li>Valid operating modes for the instruction (example: real, protected, long, VMX root, etc.);</li>
  <li>Valid prefixes for the instruction (example: REP, LOCK, etc.);</li>
  <li>Valid decorators for AVX instructions (example: masking, broadcast, rounding, etc.);</li>
  <li>Instruction Mnemonic;</li>
  <li>Operand information, including: operand type, size, access (read, conditional read, write, conditional write) and details;</li>
  <li>Full memory operand details: segment, base, index, scale, compressed displacement, stack, string, bitbase, VSIB, etc.);</li>
  <li>Implicit operands information: registers, implicit memory locations, etc.</li>
</ul>

<p>Examples on how different kind if info can be extracted from <code>INSTRUX</code> can be found on the <a href="https://bddisasm.readthedocs.io/en/latest/">official documentation page</a>.</p>

<h3 id="textual-disassembly">Textual Disassembly</h3>

<p>Using the <code>NdToText</code> function, one can convert a decoded <code>INSTRUX</code> to a textual disassembly that can be printed. The <code>NdToText</code> function only supports Intel style syntax, so the following instruction <code>33C0</code> would be decoded as <code>XOR       eax, eax</code>, and <code>4833C0</code> would be decoded as <code>XOR       rax, rax</code>. Typical usage of the <code>NdToText</code> function is:</p>
<div><div><pre><code>    <span>// Create the text disassembly for this instruction.</span>
    <span>char</span> <span>text</span><span>[</span><span>ND_MIN_BUF_SIZE</span><span>];</span>

    <span>NdToText</span><span>(</span><span>&amp;</span><span>ix</span><span>,</span> <span>0</span><span>,</span> <span>sizeof</span><span>(</span><span>text</span><span>),</span> <span>text</span><span>);</span>

    <span>printf</span><span>(</span><span>"Instruction: %s</span><span>\n</span><span>"</span><span>,</span> <span>text</span><span>);</span>
</code></pre></div></div>

<h2 id="bddisasm-in-hvmi">bddisasm in HVMI</h2>

<p>bddisasm is a critical part of the HVMI technology. As mentioned, decoding and analyzing instructions is important, since the vast majority of events HVMI is dealing with are EPT violations (memory-referencing instructions).</p>

<p>One of the first things HVMI does when an EPT violation takes place is to decode the offending instruction. Since accessing guest memory is usually slow (as it involves translating the guest linear address to a guest physical address, and mapping each physical page in the process - both page-tables and the actual page), once an instruction is decoded, it gets cached internally. Subsequent accesses from the same instruction pointer would yield an already decoded, cached instruction, thus speeding up this process (of course, caching instructions also implies that the pages containing them have to be monitored for modifications, in order to invalidate the cache if an instruction is modified).</p>

<p>Once the instruction has been decoded, HVMI will dissect it in order to determine each memory location accessed. This is important, because one instruction may directly, or indirectly, access multiple memory locations, and we have to analyze each access before allowing the instruction to continue. Since bddisasm provides full operand information (including implicit operands), HVMI will basically iterate through all the instruction operands, and check if they’re memory. For each memory operand, it would then make sure that it accesses a region of memory that is not monitored by HVMI. Examples of instructions that access multiple addresses might include:</p>

<ul>
  <li><code>CALL [mem]</code> - it reads the <code>[mem]</code> operand, and it writes the stack; it may also access the shadow stack, if CET Shadow Stack is enabled;</li>
  <li><code>MOVS</code> - it reads memory from <code>[rsi]</code>, and writes memory to <code>[rdi]</code>;</li>
  <li>AVX instruction using VSIB addressing - multiple addresses may be accessed by a VSIB operand such as <code>[rax+xmm0*8]</code>;</li>
  <li>MPX instructions <code>BNDLDX</code> and <code>BNDSTX</code>, which access the bounds tables;</li>
</ul>

<p>There are also some events (mostly asynchronous) which may cause EPT violations, even if the current instruction does not do any kind of memory access; such events include:</p>

<ul>
  <li>Delivery of interrupts or exceptions, which will read the Interrupt Descriptor Table (IDT), and will write the interrupt frame on the stack;</li>
  <li>Accesses inside the Global Descriptor Table (GDT), as part of a descriptor load;</li>
  <li>Access inside the Task State Segment (TSS) as part of a task switch or interrupt delivery;</li>
  <li>Accesses inside page-tables, as part of page-walks (although these are distinctively indicated using a dedicated bit inside the VMCS EPT violation exit qualification);</li>
  <li>Other memory accesses, such as Processor Trace induced accesses, Branch Trace Stores accesses, etc.</li>
</ul>

<p>These types of events are not included in the <code>INSTRUX</code> structure, as they may occur in an asynchronous manner, during normal instruction execution.</p>

<p>Once the faulting instruction has been decoded, it gets analyzed by multiple modules inside Introcore, in order to determine whether it is a legitimate modification (this is used …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/04/bddisasm.html">https://hvmi.github.io/blog/2020/11/04/bddisasm.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/04/bddisasm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996492</guid>
            <pubDate>Thu, 05 Nov 2020 08:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Who are all those people in your (engineering) organization?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996321">thread link</a>) | @liveweird
<br/>
November 4, 2020 | https://no-kill-switch.ghost.io/who-are-all-those-people-in-your-engineering-organization/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/who-are-all-those-people-in-your-engineering-organization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5fa31d109b10c10039cc3e57">
	

	<section>
		<p>Categorization, classification, segmentation - we, human beings, love labeling things and separating them into buckets. I am not an exception, and as someone who builds &amp; develops engineering teams, I have a habit of classifying ... <strong>engineers</strong>. Of course, there are many ways of doing that: by seniority, by area of expertise, by the type of products built. But what about categorizing the engineers by <u>their (unofficial) role in getting sh... stuff done</u>?</p><p>You've probably heard about the <em>'mercenaries VS missionaries'</em> distinction, but what I mean is something far more elaborate and detailed. And what is more, my goal is not only to present the essential engineer species I distinguish but also to clarify what happens (to the organization) if any particular group is underrepresented or even missing completely.</p><p>Here we go:</p><ol><li><strong>paratroopers </strong>- geniuses who hack through, carve the path, disrupt, break the unbreakable, and act far behind the front-lines - they may be 100% anti-social, live in their own world, not able to communicate and collaborate, but they'll do work no one else is capable of</li><li><strong>lifeguards</strong> - relentless firefighters, ones who are there always to save the day, because they genuinely care - whatever happens, they won't let it go underwater (even if they lack skill, they compensate with energy, sense of duty and commitment)</li><li><strong>sages</strong> - the only ones present who are here long enough to understand how things work and why (what was the original intent, concept, vision); they preserve the knowledge about the solution (usually because they played a significant role in its creation), w/o them it's just black magic and horror</li><li><strong>evangelists</strong> - ones with the mission, who genuinely believe in what the organization is doing - that it has a real meaning worth fighting for; they are here because they think this is an unique place where they can make a real difference (for clients, society, our common future, etc.)</li><li><strong>conductors</strong> - ones who tame the chaos, effectively orchestrate others to achieve more and move further, and have enough balls to make tough, out-of-script decisions when no-one else is eager to; they have a gift of simplifying and clarifying things, usually accompanied with a skill of visualizing the work</li><li><strong>binders</strong> - individuals who make others gel together, as something greater than the sum of the individuals; thanks to them, people feel like they really belong (to something unique and special) and make real bonds with co-workers</li><li><strong>wrestlers</strong> - ones who do the heavy lifting, make the difference, are always in the first row, never afraid of challenges and obstacles (but need to be directed by someone else); they set the standards high as the objective experts in their particular field (usually technical)</li><li><strong>cannon fodder</strong> - those who do not play any major role, but probably would like to (at some point) - for now: flexible 'task pushers' &amp; gap-fillers who tend to do 80% of all work; some have true potential, some are just useful, some have stalled their promising career</li><li><strong>deadwood</strong> - people who bring less value than they consume - many of them just DGAF &amp; require constant babysitting (don't mistake it with coaching/mentoring, please), but some just lack skills or are misfits in that particular context; deadwood can be very absorbing, decrease the overall productivity &amp; deteriorate any positive traits in the company's culture</li></ol><p>To be clear, these are roles, not positions - a single individual can easily qualify as a combination of some of these (e.g. a sage who is also a conductor), but not every combination makes sense (and hence exists in the wild, of course).</p><p>What happens if your team loses all ...</p><ul><li>... <strong>paratroopers</strong> - frankly ... opinions vary; on the one hand, they can spur the innovation for the whole organization and cause real break-throughs, but betting on individuals who are brilliant but nearly impossible to cooperate with doesn't sound like a sustainable strategy for gaining a competitive edge ...</li><li>... <strong>lifeguards</strong> - you're balancing on the edge of an abyss - if things go awry, there'll be no-one to save the day - no-one will feel obliged to fix the issue; people don't CARE anymore and find it completely normal (<em>"it's just a job, after all"</em>, <em>"we work 40h/week in this country"</em>, <em>"but why me?"</em>)</li><li>... <strong>sages</strong> - there's a high chance no-one will notice: for months or even (!) years, because no-one will admit the issue openly; but people will keep going workarounds/short-cuts (because goals have to be met anyway), tangling even more dependencies, breaking boundaries, obfuscating the past design decisions - the solution drifts from complicated towards complex or even chaos (Cynefin-wise)</li><li>... <strong>evangelists</strong> - it's much harder to keep a more profound sense of purpose - intrinsic motivations are more likely to dry out, what either drives people out (of the organization) or directs them towards more shallow (and temporary) motivations (which is a short-term strategy)</li><li>... <strong>conductors</strong> - everything engulfs either on chaos or in helpless stasis (or alternately in both of them), the team is not capable of anything that requires coordination/synchronization</li><li>... <strong>binders</strong> - people work together, but in separation, instead of acting as a team, they resemble an ensemble of 1-head-only "teams", each one with its own agenda, responsibility, commitments; it doesn't mean people won't help each other if needed, but that's just accidental support, not a true synergy</li><li>... <strong>wrestlers</strong> - there's no-one to set a proper tempo/standards, the mediocrity reigns and expectation threshold deteriorates; it's perceived as OK to be 'average' while it's uncool and anti-social to step ahead and express any ambition</li></ul><p><strong>Cannon fodder</strong> and <strong>deadwood </strong>should be considered separately: the former because it's quite unlikely you'll be running out of them and the latter due to the fact that you should do your best to identify and get rid of them promptly.</p><p>Forgetting temporarily about the <strong>paratroopers</strong> (each of them is unique and it's hard to find a common denominator for them), the groups above can be conveniently aggregated into two <em>"master categories"</em>:</p><ol><li><strong>lifeguards</strong>, <strong>sages </strong>and <strong>evangelists </strong>are roles <u>specific to your organization</u> - someone who was a sage in X obviously won't start with enough org-specific knowledge to immediately become a sage in Y; it also means that growing those roles takes time, effort and mentoring - if you're caught off-guard and lose such an individual unprepared, the reasonable replacement may be a huge issue (or even - impossible (!)); the organization stripped of its lifeguards, sages and evangelists is <u>purely vegetative</u> - frequently w/o realizing that</li><li><strong>conductors</strong>, <strong>binders</strong> and <strong>wrestlers</strong> are <u>generic roles</u>, based on individual traits and/or experience - being talented/skilled in one or more of those roles massively increases your value in the job market - every sensible employer looks for such talent, so such people are always in high demand</li></ol><hr><p>It's a good moment to summarize the thought train of this blog post. IMHO the essence of conscious, long-term team building (which is a key responsibility of every Engineering Leader/Manager) is to:</p><ul><li>for <strong>lifeguards</strong>, <strong>sages</strong> and <strong>evangelists</strong> you need to <u>control the outflow</u> - the risk is losing skills/knowledge/attitude that is very hard to replace; act by shadowing, pairing, doubling positions</li><li>for <strong>conductors</strong>, <strong>binders </strong>and <strong>wrestlers</strong> you need to <u>secure the steady, healthy (&amp; regular) inflow</u> - the risk is finding out one day that all your teams consist of cannon fodder - people who expect to be led, taught, directed, but not (YET) capable to play any major role</li><li>and for <strong>paratroopers</strong> - you need to consider individually whether your organization can effectively utilize such a sophisticated "weapon" for its own advantage, w/o actually hurting itself</li></ul><hr><p>P.S. Two groups I've considered but finally excluded from the least are <em>"leaders"</em> and<em> "gardeners"</em> (ones who help other grow) - for different reasons; when it comes to leaders I think that the "leadership" aspect is covered by the 3 organization-specific groups (lifeguards, sages, evangelists), and even if I find a "gardener" a very important role long-term, its impact on short-term GSD is limited.</p><p>P.S.S. Do you agree with the choice of those roles? Can you match them to key people in your engineering organization? Or maybe you have different categories you'd like to share? Feel free to let me know in the comments below - truly appreciated.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/who-are-all-those-people-in-your-engineering-organization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996321</guid>
            <pubDate>Thu, 05 Nov 2020 07:30:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eurodeputy on hunger strike to demand a tax on financial markets]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996320">thread link</a>) | @paulintrognon
<br/>
November 4, 2020 | https://www.politico.eu/article/senior-french-mep-goes-on-hunger-strike-to-protest-against-budget/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/senior-french-mep-goes-on-hunger-strike-to-protest-against-budget/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>A senior French MEP has gone on hunger strike to demand the EU introduce a tax on financial markets and to protest against budget plans that downgraded programs on health, research and climate change. </p>
<p>“My goal is not to die but to avoid millions of deaths,” Pierre Larrouturou&nbsp;told POLITICO. “If there’s no financing, there is no agreement.”&nbsp;</p>
<p>In July, European leaders agreed on a historic&nbsp;<a href="https://www.politico.eu/article/eu-leaders-reach-deal-on-coronavirus-recovery-fund/">€1.82 trillion budget&nbsp;</a>and&nbsp;coronavirus recovery package and laid out a path to add new bloc-wide sources of revenue to finance the EU budget, including a levy based on non-recycled plastic.&nbsp;But the <a rel="noreferrer noopener" href="https://www.politico.eu/article/sidelined-on-recovery-parliament-plans-battle-over-eu-budget/" target="_blank">European Parliament is unhappy with several aspects of the deal,</a> notably the lack of a strong mechanism to punish rule of law breaches by national capitals and cuts to some programs. </p>

<p>MEPs also want a definitive timetable for the introduction of a financial transaction tax —&nbsp;something the European Commission first proposed in 2011. Larrouturou said the tax, which advocates say would ensure that the financial sector contributes more fairly to tax revenues,&nbsp;would bring in €50 billion a year.</p>
<p>The French MEP, part of the socialist group in the Parliament, said he had his sights set on a meeting of EU finance ministers&nbsp;in December where he wants agreement to establish a financial transaction tax in 2024. &nbsp;</p>
<p>“There is something obscene in saying that there is no money for health, hospitals and climate when financial markets have never been at such a high level,” said Larrouturou, who as the rapporteur for the EU's 2021 annual budget is responsible for shepherding key legislation through Parliament.</p>
<p>He&nbsp;blamed the Council — as well as his own country, France — for blocking a proposal that has been on the table for years and would help economies to repay their debt.&nbsp;EU capitals have consistently resisted the introduction of such EU-wide revenue raising mechanisms&nbsp;to keep direct control over taxation.</p>
<p>The MEP&nbsp;also warned that a financial transaction tax would help countries avoid a tough recession in 2024 because “the landing will be brutal.”&nbsp;</p>
<p>“Those countries who say 'no' to the [financial transaction tax] — it means they prefer to help traders and tax voters,” he added.&nbsp;</p>

<p>The Parliament must give its&nbsp;consent to the EU's multi-year budget running from 2021 to 2027, while the Council will also need to sign off on the final budget numbers.</p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/senior-french-mep-goes-on-hunger-strike-to-protest-against-budget/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996320</guid>
            <pubDate>Thu, 05 Nov 2020 07:29:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kotlin for Interviews – Part 4: Iteration]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996247">thread link</a>) | @joannawyka
<br/>
November 4, 2020 | https://blog.kotlin-academy.com/kotlin-for-interviews-part-4-iteration-b176dee4f1ae | <a href="https://web.archive.org/web/*/https://blog.kotlin-academy.com/kotlin-for-interviews-part-4-iteration-b176dee4f1ae">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@sherryyuan?source=post_page-----b176dee4f1ae--------------------------------" rel="noopener"><img alt="Sherry Yuan" src="https://miro.medium.com/fit/c/96/96/1*vPHsbna8rWXF2trnsf3w3Q.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12000/0*RsUKPdGuGwhKpAbu" width="6000" height="4000" srcset="https://miro.medium.com/max/552/0*RsUKPdGuGwhKpAbu 276w, https://miro.medium.com/max/1104/0*RsUKPdGuGwhKpAbu 552w, https://miro.medium.com/max/1280/0*RsUKPdGuGwhKpAbu 640w, https://miro.medium.com/max/1400/0*RsUKPdGuGwhKpAbu 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*RsUKPdGuGwhKpAbu?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@danielcgold?utm_source=medium&amp;utm_medium=referral" rel="noopener">Dan Gold</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="1ea5">This is Part 4 of Kotlin for Interviews, a series where I go over Kotlin functions and code snippets that came up often during my Android interview prep. also compiled a cheatsheet that covers all 5 parts of this series, which you can find <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-cheatsheet-88a9831e9d55">here</a>.</p><p id="9fbc">You can find Part 1, Common Data Types, <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-part-1-common-data-types-886ea1e40645">here</a>.</p><p id="b016">This part covers:</p><ul><li id="cd5a"><a href="#9ca3" rel="noopener">Refresher on Range</a></li><li id="b63e"><a href="#d553" rel="noopener">1D arrays/lists</a></li><li id="60a0"><a href="#74be" rel="noopener">2D arrays/lists</a></li><li id="a969"><a href="#c4a8" rel="noopener">Maps</a></li><li id="9e50"><a href="#739b" rel="noopener">PriorityQueues</a></li></ul><p id="a6e9">Many interview problems require some kind of iteration, be it manipulating an input array or using a map to store information, so I’ll go over different ways of iterating over some common data structures.</p><p id="087e">A <code>Range</code> in Kotlin is a sequence of values defined by a start value, an end value, and a step. The step, or distance between two values, has a default value of 1. The one you’ll encounter the most often is <code>IntRange</code>, but you can use <code>LongRange</code> and <code>CharRange</code> as well.</p><ul><li id="34da"><code>forEach()</code> performs the given action on each element in the collection. This is the iteration method I use most often in normal projects, but didn’t use as often in interviews because 1) <code>forEach()</code> will throw a <code>ConcurrentModificationException</code> if you try to modify the collection while iterating through it, and 2) a lot of interview problems require taking the index into account as well.</li><li id="bba2"><code>forEachIndexed()</code> is like <code>forEach()</code>, except you also have access to the element’s index inside the lambda, which you often need in interview problems.</li></ul><pre><span id="871c"><em>// Print elements at even indices.</em><br><strong>list.forEachIndexed { index, element -&gt; <br>    if (index % 2 == 0) println("$element")<br>}</strong></span></pre><ul><li id="bdcd"><code><em>..</em></code>, aka <code>rangeTo()</code>, can be used in the form of <code>for(i in a..b)</code> to create then iterate through a <code>Range</code>. The range would include both the start (<code>a</code>) and end (<code>b</code>) elements, so if you want to use it to iterate through a list/array, you should either write it as <code>for (i in 0..list.size-1)</code> or use <code>until</code> instead. Even though it’s most often used with <code>Int</code>s, you can iterate over <code>Char</code>s as well.</li></ul><pre><span id="6a58"><em>// Iterate and print from i = 0 to i = 100</em><br><strong>for (i in 0..100) { println(i) }</strong></span><span id="dcbf"><em>// Iterate from i = 0 to i = list.size-1</em><br><strong>for (i in 0..list.size-1) { println(list[i]) }</strong></span><span id="c139"><em>// Iterate and print 'a', 'b', 'c', 'd'</em><br><strong>for (i in 'a'..'d') { println(i) }</strong></span></pre><ul><li id="8576"><code>downTo()</code> works like <code>..</code>, except each iteration goes down a step rather than up one.</li></ul><pre><span id="71b8"><em>// Iterate and print from i = 100 to i = 0</em><br><strong>for (i in 100 downTo 0) { println(i) }</strong></span></pre><ul><li id="85ed"><code>step()</code> lets you specify the change in values between each iteration.</li></ul><pre><span id="1f26"><em>// Iterate and print 1, 3, 5, 7</em><br><strong>for (i in 1..8 step 2) { println(i) }</strong></span><span id="9534"><em>// Iterate and print 8, 5, 2<br></em><strong>for (i in 8 downTo 1 step 3) { println(i) }</strong></span></pre><ul><li id="db3e"><code>until()</code> includes the start element, but not the end element. It’s my preferred way of iterating through a collection’s indices, because if you use the list’s size as the end you don’t have to worry about indices being out of bounds.</li></ul><pre><span id="83af"><em>// Iterate and print from i = 0 to i = 99</em><br><strong>for (i in 0 until 100) { println(i) }</strong></span><span id="246d"><em>// Iterate and print elements from i = 0 to i = list.size-1</em><br><strong>for (i in 0 until list.size) { println(list[i]) }</strong></span></pre><ul><li id="9e00"><code>indices</code> returns an <code>IntRange</code> representing a collection’s valid indices, and can be used similarly to <code>until()</code>.</li></ul><pre><span id="6c95"><strong>val list = listOf('a', 'b', 'c')<br>println(list.indices)</strong> <em>// Prints 0..2</em><br><em>// Iterate and print elements from i = 0 to i = 2<br></em><strong>for (i in list.indices) { println(list[i]) }</strong></span></pre><ul><li id="ef55"><code>repeat()</code><em> </em>executes the given function action the specified number of times.</li></ul><pre><span id="83f5"><em>// Print "Hello" 100 times</em><br><strong>repeat(100) {<br>    println("Hello")<br>}</strong></span></pre><p id="49a2">This is something you don’t see that often in real projects, but appears all the time in interview problems — grids, mazes, graphs, and more may all be represented using a 2D array.</p><p id="c7a7">Here’s my preferred way to iterate through a 2D array or list using <code>until</code>:</p><pre><span id="90c0"><strong>if (grid.isEmpty()) return<br>for (i in 0 until grid.size) {<br>    for (j in 0 until grid[0].size) {<br>        println(grid[i][j])<br>    }<br>}</strong></span></pre><p id="0137">Alternatively, you can use <code>indices</code>:</p><pre><span id="f0db"><strong>if (grid.isEmpty()) return<br>for (i in grid.indices) {<br>    for (j in 0 until grid[0].size) {<br>        println(grid[i][j])<br>    }<br>}</strong></span></pre><p id="accc">Maps are also common in interview problems, especially as a good way to store information when a list isn’t enough.</p><p id="bec6">If you need to iterate through key-value pairs, you can either use a <code>for</code> loop or a <code>forEach</code> loop. This is up to personal preference.</p><pre><span id="75ad"><em>// Iterate through entries using a for-loop</em><br><strong>for ((key, value) in map) {<br>    println("$key = $value")<br>}</strong></span><span id="7b25"><em>// Iterate through entries using forEach()</em><br><strong>map.forEach { (key, value) -&gt; println("$key = $value") }</strong></span></pre><p id="bb64">If you only need to iterate through the keys, you can use the <code>keys</code> val to get a <code>Set</code> of all the keys in the map, and iterate through those.</p><pre><span id="227a"><strong>map.keys.forEach { println(it) }</strong></span></pre><p id="d489">Similarly, if you only need to iterate through the values, the <code>values</code> val will return a <code>Set</code> of all the values in the map.</p><pre><span id="989f"><strong>map.values.forEach { println(it) }</strong></span></pre><p id="6d5a"><code>PriorityQueue</code>s are helpful for when you want elements to be processed based on their priority. They’re often used in interview problems that ask for K-th largest, K-th smallest, top K frequent, etc. I covered them in more detail in Part 1, but here’s a reminder of what iterating through one looks like.</p><pre><span id="d1cb"><strong>val pq = PriorityQueue&lt;Int&gt;(listOf(2, 1, 3))</strong><br><em>// pq will be empty after 3 iterations</em><br><strong>while(pq.isNotEmpty()) {<br>    println(pq.poll()) </strong><em>// prints 1, then 2, then 3</em><strong><br>}</strong></span></pre><p id="eb71">That’s it for part 4! Here’s the <a rel="noopener" href="https://blog.kotlin-academy.com/kotlin-for-interviews-cheatsheet-88a9831e9d55">link to the cheatsheet</a> covering all 5 parts again.</p></div></div></section></div>]]>
            </description>
            <link>https://blog.kotlin-academy.com/kotlin-for-interviews-part-4-iteration-b176dee4f1ae</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996247</guid>
            <pubDate>Thu, 05 Nov 2020 07:11:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What 4chan thinks of HN (2014)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996090">thread link</a>) | @ffpip
<br/>
November 4, 2020 | https://rbt.asia/g/thread/41920845 | <a href="https://web.archive.org/web/*/https://rbt.asia/g/thread/41920845">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rbt.asia/g/thread/41920845</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996090</guid>
            <pubDate>Thu, 05 Nov 2020 06:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monitor Network Usage in Linux]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24996009">thread link</a>) | @bhupesh
<br/>
November 4, 2020 | https://bhupesh-v.github.io/monitor-network-usage-stats-in-linux/ | <a href="https://web.archive.org/web/*/https://bhupesh-v.github.io/monitor-network-usage-stats-in-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>The amount of data sent (uploaded) &amp; received (downloaded) can be found out
using the following bash script.</p>

<div><div><pre><code>
netu<span>()</span> <span>{</span>
    <span># [net]work [u]sage: check network usage stats</span>

    <span>net_device</span><span>=</span><span>$(</span>ip route | <span>awk</span> <span>'/via/ {print $5}'</span><span>)</span>
    <span>TRANSMITTED</span><span>=</span><span>$(</span>ifconfig <span>"</span><span>$net_device</span><span>"</span> | <span>awk</span> <span>'/TX packets/ {print $6$7}'</span><span>)</span>
    <span>RECEIVED</span><span>=</span><span>$(</span>ifconfig <span>"</span><span>$net_device</span><span>"</span> | <span>awk</span> <span>'/RX packets/ {print $6$7}'</span><span>)</span>

    <span>printf</span> <span>"%s</span><span>\n</span><span>"</span> <span>"</span><span>$(</span>tput bold<span>)</span><span>🔼 TRANSMITTED </span><span>$(</span>tput sgr0<span>)</span><span>: </span><span>$TRANSMITTED</span><span>"</span>
    <span>printf</span> <span>"%s</span><span>\n</span><span>"</span> <span>"</span><span>$(</span>tput bold<span>)</span><span>🔽 RECEIVED    </span><span>$(</span>tput sgr0<span>)</span><span>: </span><span>$RECEIVED</span><span>"</span>
<span>}</span>

</code></pre></div></div>

<ul>
  <li>Only works per session, i.e stats are gathered once you power up your PC (or login) and are lost when you shutdown.</li>
  <li>Good to have if you have limited data availability &amp; want to monitor your data usage.</li>
</ul>

<p>Let’s just review on what utilities we used here.</p>

<h2 id="ip"><code>ip</code></h2>

<p>Our first step is to find your default networking device (i.e the default networking interface) and its name.</p>

<div><div><pre><code>default via 192.168.42.129 dev enp0s20u4u1 proto dhcp metric 100 
169.254.0.0/16 dev enp0s20u4u1 scope <span>link </span>metric 1000 
192.168.42.0/24 dev enp0s20u4u1 proto kernel scope <span>link </span>src 192.168.42.149 metric 100
</code></pre></div></div>

<p>The first line of output lists our default network interface (the string followed by your PC name, mine is <code>dev</code>). The interface name will be different in your case.</p>

<h2 id="ifconfig"><code>ifconfig</code></h2>

<p>This is a good old tool used by network professionals to configure a network interface. <code>ifconfig $net_device</code> will display the status of our default net device.</p>

<div><div><pre><code><span>$ </span>ifconfig enp0s20u4u1
enp0s20u4u1: <span>flags</span><span>=</span>4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 192.168.42.149  netmask 255.255.255.0  broadcast 192.168.42.255
        inet6 fe80::d464:9bdb:2b16:b27  prefixlen 64  scopeid 0x20&lt;<span>link</span><span>&gt;</span>
        inet6 2405:204:322e:53d:18ef:6496:fbb7:9309  prefixlen 64  scopeid 0x0&lt;global&gt;
        inet6 2405:204:322e:53d:93c3:cff8:8680:78bb  prefixlen 64  scopeid 0x0&lt;global&gt;
        ether 96:a3:91:8e:68:de  txqueuelen 1000  <span>(</span>Ethernet<span>)</span>
  <span>--</span><span>&gt;</span>   RX packets 19334  bytes 14292555 <span>(</span>14.2 MB<span>)</span>
        RX errors 0  dropped 0  overruns 0  frame 0
  <span>--</span><span>&gt;</span>   TX packets 16514  bytes 3008589 <span>(</span>3.0 MB<span>)</span>
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
</code></pre></div></div>

<p>You see the <code>RX</code> and <code>TX</code> packets? Yup that’s our stats. Now we will use <code>awk</code> to extract those packet infos.</p>

<h2 id="awk"><code>awk</code></h2>

<p>AWK is a pattern scanning language, generally used for data manipulation needs.</p>

<p>Now, this is not a tutorial about awk but let’s just understand our use-case here. A simple awk statement might look like this.</p>

<div><div><pre><code><span>awk</span> <span>'/pattern/ { action }'</span>
</code></pre></div></div>

<p>So in our case, we want to look for <em>pattern</em> which matches <code>TX packets</code>.</p>

<div><div><pre><code><span>$ </span>ifconfig enp0s20u4u1 |  <span>awk</span> <span>'/TX packets/'</span>
        TX packets 18554  bytes 3411366 <span>(</span>3.4 MB<span>)</span>
</code></pre></div></div>

<p>Meh, this doesn’t look good. We want that human-readable format <code>3.4MB</code>. One thing which excites me is that we can access/read each individual field (or word or record) in that line. Each word can then be printed using <code>print $&lt;field-no&gt;</code> (an <a href="http://kirste.userpage.fu-berlin.de/chemnet/use/info/gawk/gawk_9.html#SEC87"><em>action</em></a>)</p>

<picture>
	<img alt="awk fields when using ifconfig command in linux" src="https://drive.google.com/uc?export=view&amp;id=1Zx4J4VdcufOlCGEjClrG-vdFbmdYEBhj">
	<figcaption>I know the last two rows are f**ked up. Maybe its a bug ?</figcaption>
</picture>

<p>Now we just print both the <code>$6</code> and <code>$7</code> fields.</p>

<div><div><pre><code><span>$ </span>ifconfig enp0s20u4u1 |  <span>awk</span> <span>'/TX packets/ { print $6$7 }'</span>
<span>(</span>5.7MB<span>)</span>
</code></pre></div></div>

<h3 id="demo-">Demo 🍲</h3>

<p><img src="https://user-images.githubusercontent.com/34342551/97838566-75e6c780-1d06-11eb-86ae-6b3f562969a1.png" alt="netu-monitor-network-data-usage"></p>

<p>And of course, you can <code>watch</code> this script to get real-time feedback as well.</p>



<blockquote>
  <p><strong>Homework</strong>: Figure out how to make this data persist.</p>
</blockquote>

<p>Also, have you ever been a class monitor in your school? I was once in 9th grade :)</p>

  </div></div>]]>
            </description>
            <link>https://bhupesh-v.github.io/monitor-network-usage-stats-in-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24996009</guid>
            <pubDate>Thu, 05 Nov 2020 06:03:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Committing Suicide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24995761">thread link</a>) | @lettergram
<br/>
November 4, 2020 | https://austingwalters.com/on-committing-suicide/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/on-committing-suicide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3389">

<div>
<p>Those that know me, know that I am both bold and resolute. I stand by my thoughts / comments, yet I attempt to keep an open mind, analyze a situation, self-reflect on any biases, and integrate feedback. I even go so far as to analyze my confidence level, see <a href="https://predictionbook.com/" target="_blank" rel="noopener noreferrer">predictionbook.com</a>.</p>
<p>With that in mind. I want to share how utterly angry and helpless I feel —</p>
<p>I can’t share my true thoughts, hell my analysis, of the current political situation in the U.S. Although I have written on it countless times, I end up deleting the posts.</p>
<p>Why?</p>
<p>It’s not safe to share thoughts.</p>
<h2>State of Affairs</h2>
<p>Today, sharing one’s opinion can cost you your livelihood, your ability to communicate, and more.</p>
<p>Historically, that was always true, perhaps more-so. We’re now returning to the status quo — repression.</p>
<p>Today’s flavor of repression is one where offending someone randomly across the globe, can cost you your job. That person may not have a standing in your community and may not have a relationship with your employer. However, they can amplify their voice, tweet your employer, and your employer (scared out of its mind by the current situation) will terminate you. That is the state of affairs today. It doesn’t matter if you’re correct or innocent. It doesn’t even matter if 99.9% of people aren’t offended by what you said — we are now in a world of “<a href="https://en.wikipedia.org/wiki/Online_shaming#Cancellation" target="_blank" rel="noopener noreferrer">cancel culture</a>“.</p>
<h2>Finding Middle Ground</h2>
<p>In the United States in 2020, we have two paths. One path leads to an ever more left-leaning populous “uprising”; the other path leads to an ever more right-leaning populous “uprising”. I don’t see an alternative, outside of some quite-frankly comical alternatives (e.g. President Mitt Romney, with VP Bernie Sanders).</p>
<p>One way or another, I lose. No one is speaking up for my beliefs or representing me.</p>
<p>I sense I’m not alone. Everyone I speak to left or right, hates the current state of affairs. Most of us even agree on <em>why</em> we distrust the system. Unfortunately, we can’t elect someone to fix the system. Neither Trump, nor Biden, nor Bernie, nor anyone on the ballot accurately represents or even inspires us.</p>
<p>By and large, I believe this is due to the “absolute” nature of our current social strife. Take the question:</p>
<blockquote><p>Why can’t I be anti-vaccine and pro-choice?</p></blockquote>
<p>You would suspect everyone would agree that we “own” our bodies. If that were true, then you would effectively have to be pro-choice AND support people’s right to choose what to put in their bodies; body ownership is the middle ground. I wish we could coalesce around the middle ground, then compromise on edge cases, enabling progress.</p>
<p>Take another example:</p>
<blockquote><p>Why don’t we do firearms training in schools?</p></blockquote>
<p>It’s an honest question — we’ve had the 2nd amendment for hundreds of years. Similar to driving a car, we should train our youth to handle firearms. I suspect we all know the reason this is not occurring — because a significant portion of the United States is fearful of firearms.</p>
<p>From the evidence, the fear is unjustified. We have evidence that with a good training program and robust mental evaluation process, firearms by-and-large are safe for society. <a href="https://en.wikipedia.org/wiki/Firearms_regulation_in_Switzerland" target="_blank" rel="noopener noreferrer">See Switzerland</a>:</p>
<blockquote><p>Swiss males grow up expecting to undergo basic military training, usually at age 20 in the recruit school..</p>
<p>…Prior to 2007, members of the Swiss Militia were supplied with 50 rounds of ammunition for their military weapon in a sealed ammo box that was regularly audited by the government…</p>
<p>…Every person with a Swiss citizenship, aged 10 years or older, can take part at any federal ranges and will be able to shoot for free with the ordinance rifle…</p>
<p>…In 2016, there were 187 attempted and 45 completed homicides, for a homicide rate of 0.50 per 100,000 population, giving Switzerland one of the lowest homicide rates in the world…</p></blockquote>
<p>Further, firearms are already widely available (<a href="https://en.wikipedia.org/wiki/Estimated_number_of_civilian_guns_per_capita_by_country" target="_blank" rel="noopener noreferrer">300+ million guns in the U.S.</a>) &amp; availability enshrined in law.</p>
<p>Sorrowfully, evidence doesn’t matter here; fear guides many. Yoda has some insights here:</p>
<blockquote><p><span data-parade-type="promoarea" data-parade-location-types="promoarea" data-parade-location-ids="article" data-parade-views="false" data-parade-touches="false" data-parade-clicks="false" data-parade-mouseovers="false">Fear is the path to the dark side. Fear leads to anger. Anger leads to hate. Hate leads to suffering.</span></p>
<p>— George Lucas (Yoda)</p></blockquote>
<h2>The False Dichotomy</h2>
<p>I don’t agree with the left or the right on many things in United States politics. In fact, I find most of the arguments a false dichotomy, designed to garner votes. To share one’s full thoughts would cause either or both sides to lash out, even though evidence may support the claims / musings.</p>
<p>Regretfully, this leaves me and many others out of the public discourse. While most of us have heard,</p>
<blockquote><p>The only thing necessary for the triumph of evil is for good men to do nothing.</p>
<p>— Edmund Burke (attributed)</p></blockquote>
<p>It’s not quite that simple and I prefer another sentiment:</p>
<blockquote><p>A man dies when he refuses to stand up for that which is right. A man dies when he refuses to stand up for justice. A man dies when he refuses to take a stand for that which is true.</p>
<p>— Martin Luther King Jr.</p></blockquote>
<center><br>
<iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/0On19DRA2fU?start=88" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"><span style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" data-mce-type="bookmark" class="lazy lazy-hidden mce_SELRES_start">﻿</span></iframe></center><p>Truthfully, we’re all being held hostage. I am very confident few people fully agree with either side in this political theater. We have extremists on either side shouting and being amplified by social media. In truth, the vast majority of us don’t agree [fully] with either extreme. Most of us, want to “live and let live” — that’s the American way. We’re a country founded on our hatred for taxes and the desire to live free from persecution. Please, please.. Don’t let that change.</p>
<p>It’s easy to decide “what’s right” when you look at it through that lens — am I persecuting others or increasing taxes (arguably a form of persecution)? If either are true, likely we should reconsider our stance.</p>
<h2>The Chaos</h2>
<p>Today, we are edging towards chaos. We all feel it. Riots, job loss, deadly diseases, [trade] wars, homelessness… We need leadership that can unite us.</p>
<p>Unfortunately, many of our would-be leaders have opted out or have been pushed out of this system. They’ve become engineers, scientists, bloggers — too scared to share their opinions (<a href="https://en.wikipedia.org/wiki/Slate_Star_Codex" target="_blank" rel="noopener noreferrer">even shutting down</a>). To hold a nuanced opinion different from the “socially accepted” by one group or another will get you “canceled”. In this case, “canceled” can mean anything from losing your job, to losing financial platforms/instruments (i.e. PayPal, VISA, YouTube revenue, etc.), to receiving threats on your life.</p>
<p>We have an ongoing pandemic, with millions in the United States likely about to perish, the economy collapsing, and we still cannot escape the politics.</p>
<p>I’m not hopeful.</p>
<p>I have so many musings, stories, and analyses I’d like to share, but neither facts nor my opinions matter.</p>
<p>Let’s be honest —</p>
<ul>
<li>I’m a white, cisgender, straight, male</li>
<li>I work as a technical manager in a research group, at a bank</li>
<li>I’m socially liberal in many ways and conservative in others</li>
<li>I grew up lower-middle class; now, I’m upper-middle class</li>
<li>I don’t attribute myself to any political party</li>
</ul>
<p>A large number of people dismiss or overlook me because of my background. Those who don’t outright dismiss me are also not likely to support my interest(s).</p>
<h2>Meritocracy or Bust</h2>
<p>What scares me is that I am a father and I am fearful for my children’s future. I was raised with the understanding that America is a meritocracy. Regardless of your race, gender, or creed, you should have the ability to make a life in the United States,<strong><em> to build a future for your children</em></strong>. Sadly, I don’t see the same core mission today. None of the political parties or the government at large appears forward-looking, for the children. Perhaps, that’s because of a <a href="https://www.cdc.gov/nchs/nvss/births.htm" target="_blank" rel="noopener noreferrer">declining birthrate</a>, I’m not sure.</p>
<p>As someone with children, I’m pleading for a group to come together to challenge the current status quo and equitably look to improve our society. We do have systemic problems that need to be fixed. Compromises will need to be made, but I don’t believe we need sacrifices from anyone.</p>
<p>The racism and sexism needs to stop. I suspect, most of us (though, not all) want a meritocracy, a hierarchy based on merit. Unfortunately, what’s being propagated is a hierarchy based on race, sex and orientation — the under-privileged. It’s clear from the countless stories we see in the news. I am sure you are tired of the racism, as am I. That’s probably true regardless of which side of the political spectrum you fall.</p>
<p><em>No one’s</em> value to society should be assessed by their race, gender or creed. A person’s value should be based off what they have to offer to a given group, organization, or society. We can rally around that idea (that we’re all equal, differentiated on merit) and work to improve. It’s a middle ground we can [mostly] agree on. From there, we can fix the injustices.</p>
<p>What horrifies me, is that even to express that <em>“we’re all equal” </em>is a challenge to this new socio-economic hierarchy. <em>No one</em> is representing me or has my family’s best interests in mind. Realistically, I don’t expect anyone to have <em>my family’s interests</em> in mind, but I don’t want my potential / rights eroded.</p>
<p>Due to this political tug of war, both sides of the political spectrum want to diminish our rights; they’re only bickering over which rights to diminish. Let’s stop this tug of war and come together.</p>
<p>If we don’t come together, soon enough we won’t have a democracy, or frankly, a future to build for.</p>
<h2>In the Words of John Adams…</h2>
<blockquote><p>Remember, democracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide. It is in vain to say that democracy is less vain, less proud, less selfish, less ambitious, or less avaricious than aristocracy or monarchy. It is not true, in fact, and nowhere appears in history. Those passions are the same in all men, under all forms of simple government, and when unchecked, produce the same effects of fraud, violence, and cruelty. When clear prospects are opened before vanity, pride, avarice, or ambition, for their easy gratification, it is hard for the most considerate philosophers and the most conscientious moralists to resist the temptation. Individuals have conquered themselves. Nations and large bodies of men, never.</p>
<p>— …</p></blockquote></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/on-committing-suicide/">https://austingwalters.com/on-committing-suicide/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/on-committing-suicide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24995761</guid>
            <pubDate>Thu, 05 Nov 2020 04:52:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Account Takeover via IDOR in Starbucks Singapore]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24995657">thread link</a>) | @eshanaswar
<br/>
November 4, 2020 | http://www.kamilonurozkaleli.com/posts/starbucks-singapore-account-takeover/ | <a href="https://web.archive.org/web/*/http://www.kamilonurozkaleli.com/posts/starbucks-singapore-account-takeover/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<h3 id="recon"><strong>Recon</strong></h3>
<p>While browsing Starbucks Singapore, I noticed a page loaded with content from a 3rd party site. Let’s call this site <em>example.com</em> in order not to disclose it. When I did some research on this site, I saw the same login page on <em>card.starbucks.com.sg</em> in the directory example.com/starbucks, and at this point I had two possibilities.</p>
<ol>
<li>This application can be an environment where current developments of <em>card.starbucks.com.sg</em> are made and tested.</li>
<li>Or it may have been used as an old test environment and is in an idle state.</li>
</ol>
<p>Both possibilities increased the probability of a bug here, but the main problem is that I did not know whether a bug I will find here would affect the production environment. To understand this, I created a user account at card.starbucks.com.sg and tried to log into example.com/starbucks with this account. BINGO! I was able to successfully login with the account I just created. Both applications seemed to be using the same authentication mechanism.</p>
<p><img src="http://www.kamilonurozkaleli.com/images/starbucks-1.png" alt="Scheme-1, both applications are using same database table."></p>
<h3 id="exploitation"><strong>Exploitation</strong></h3>
<p>From this point I browsed example.com/starbucks and discovered an endpoint which does not exist in the production app. The POST data this endpoint received was as follows.</p>
<p><code>email=hacker@hacker.com</code></p>
<p>When I write the email address of the account I want to takeover in the email parameter here and send a request, I saw the partial information of the account belonging to that email address on my profile page. I could not fully takeover the account yet, and my password change request was not successful due to the invalid CSRF token generated in this application.</p>
<p>To get around this, I copied the PHPSESSID cookie value from example.com/starbucks to card.starbucks.com.sg and BOOM! I was able to see all the information belongs to victim in the production environment, the valid CSRF tokens generated here allowed me to change the password and I was able to completely takeover an account whose e-mail address I know.</p>
<h3 id="impact"><strong>Impact</strong></h3>
<p>Except for seeing all personal information belonging to users and completely taking over the accounts, if there is a loaded credit in the user account, these credits can be spent in Starbucks stores via the mobile application.</p>
<h3 id="multiplying-the-reward"><strong>Multiplying the Reward</strong></h3>
<p>I came across two other test environments on example.com. Let’s call them <em>example.com/starbucks2</em> and <em>example.com/starbucks3</em>. With my account at card.starbucks.com.sg, I was not able to login to either test environment. example.com/starbucks2 did not allow me to create a new account, so I tried my luck at example.com/starbucks3 and successfully created a new account. Things get a little complicated here, I will try to explain it as simply as possible.</p>
<p>I think the applications example.com/starbucks2 and example.com/starbucks3 were using test tables, so users in production could not login in these applications.</p>
<p>With the account I created at example.com/starbucks3, I was able to log in to example.com/starbucks2, but not card.starbucks.com.sg. However, the PHPSESSID I copied from example.com/starbucks2 was valid on card.starbucks.com.sg and I could use that account. Considering all the scenarios, I created a chain here as follows:</p>
<ol>
<li>Create a dummy account with the victim’s email address at example.com/starbucks3. (Add to testusers table.)</li>
<li>At example.com/starbucks2, associate the account for that email with your own account via the same endpoint. (Associate the PHPSESSID with the email in the testusers table.)</li>
<li>Copy the PHPSESSID to card.starbucks.com.sg and takeover. (Takeover the real account of the same email address in the production users table.)</li>
</ol>
<p><img src="http://www.kamilonurozkaleli.com/images/starbucks-2.png" alt="Scheme-2, relations between applicaitons and tables."></p>
<p>May 17th - Report Submitted<br>
May 18th - Triaged<br>
May 20th - Rewarded $4000 bounty<br>
Jun 17th - Rewarded $2000 bounty as 1.5x multiplier</p>

		</div></div>]]>
            </description>
            <link>http://www.kamilonurozkaleli.com/posts/starbucks-singapore-account-takeover/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24995657</guid>
            <pubDate>Thu, 05 Nov 2020 04:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Httpy – Let's build a (nano) HTTP client]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24995571">thread link</a>) | @mhasbini
<br/>
November 4, 2020 | https://mhasbini.com/blog/lets-build-an-http-client.html | <a href="https://web.archive.org/web/*/https://mhasbini.com/blog/lets-build-an-http-client.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<h2>What?</h2>

<p>
  Continuing with the same theme as the previous post (<a href="https://mhasbini.com/blog/lets-build-a-web-framework.html" target="_blank">Let's build a (nano) web framework</a>), in this post we'll be bulding a nano http client similar to <a href="https://github.com/urllib3/urllib3" target="_blank">urllib3</a>.
</p>


<h2>Introducing httpy</h2>

<p>
  The http client will be built using Python. Here's the usage we're aiming to get:
</p>

    <pre><code><span>import</span> httpy

req <span>=</span> httpy<span>.</span>get<span>(</span><span>'http://httpbin.org/robots.txt'</span><span>)</span>

req<span>.</span>status 
req<span>.</span>data </code></pre>


<p>
    To achieve this, we need to build:

    </p><ol>
        <li><b>URL parser</b>: This will allow us to get from the string <code>http://httpbin.org/robots.txt</code> to know what the scheme, host &amp; path are.</li>
        <li><b>Communication function</b>: This will send the HTTP request and get the raw response.</li>
        <li><b>HTTP response parser</b>: This will allow us to parse the raw HTTP response to get the response status and the page content.</li>
    </ol>

<h3>How deep are we gonna go?</h3>

<p>
  We're going to basing our work on Python's <a href="https://docs.python.org/3/library/socket.html" target="_blank"><code>socket</code></a> and <a href="https://github.com/pyparsing/pyparsing/" target="_blank">pyparsing</a> libraries.
</p>

<h3>Compromises</h3>

<p>
  As this is experiment is to get an mvp, these are the compromises for this library:
</p>

<ul>
    <li>Only work with HTTP</li>
    <li>URL's format is only a subset.</li>
    <li>Only IPV4</li>
</ul>

<h2>URL parser</h2>

<p>
    The usage will be:

    </p><pre><code><span>try</span><span>:</span>
    host<span>,</span> port<span>,</span> path <span>=</span> parse_url<span>(</span><span>'http://httpbin.org/robots.txt'</span><span>)</span>
<span>except</span> ValueError <span>as</span> e<span>:</span>
    <span>print</span><span>(</span>e<span>)</span>
    exit<span>(</span><span>)</span></code></pre>



<p>
    Let's start by having a couple of test cases. I'm going to use <a href="https://docs.python.org/3/library/doctest.html" target="_blank">doctest</a> for the examples.

    </p><pre><code><span>def</span> <span>parse_url</span><span>(</span>url<span>)</span><span>:</span>
    <span>"""Pase url based on this format:

    http://host[:port]path[?query][#fragment]

    &gt;&gt;&gt; parse_url('http://httpbin.org/')
    ('httpbin.org', 80, '/')
    &gt;&gt;&gt; parse_url('http://httpbin.org/robots.txt')
    ('httpbin.org', 80, '/robots.txt')
    &gt;&gt;&gt; parse_url('http://test:1234/lorem?a=b#c')
    ('test', 1234, '/lorem?a=b')
    &gt;&gt;&gt; parse_url('https://mhasbini.com/')
    Traceback (most recent call last):
        ...
    ValueError: Invalid URL
    &gt;&gt;&gt; parse_url('httpmhasbini.com')
    Traceback (most recent call last):
        ...
    ValueError: Invalid URL
    """</span>

    <span>return</span> <span>""</span></code></pre>



<p>
    We can define a context-free grammar to parse the url based on the specified format.

    I opted to use <a href="https://github.com/pyparsing/pyparsing/" target="_blank">pyparsing</a> to achieve this.

    The grammar is as follow:

    </p><pre><code><span>import</span> pyparsing <span>as</span> pp

host_pp <span>=</span> pp<span>.</span>Word<span>(</span>pp<span>.</span>alphanums <span>+</span> <span>'.'</span> <span>+</span> pp<span>.</span>alphas<span>)</span><span>.</span>setResultsName<span>(</span><span>'host'</span><span>)</span>
port_pp <span>=</span> pp<span>.</span>pyparsing_common<span>.</span>signed_integer<span>.</span>setResultsName<span>(</span><span>'port'</span><span>)</span>
path_pp <span>=</span> pp<span>.</span>Combine<span>(</span><span>'/'</span> <span>+</span> pp<span>.</span>Optional<span>(</span>pp<span>.</span>Word<span>(</span>pp<span>.</span>srange<span>(</span><span>"[a-zA-Z0-9.-_~!$&amp;'()*+,;=:@]"</span><span>)</span><span>)</span><span>)</span><span>)</span><span>.</span>setResultsName<span>(</span><span>'path'</span><span>)</span>
fragment_pp <span>=</span> pp<span>.</span>Optional<span>(</span><span>'#'</span> <span>+</span> pp<span>.</span>Word<span>(</span>pp<span>.</span>srange<span>(</span><span>"[a-zA-Z0-9/?"</span><span>)</span><span>)</span><span>)</span><span>.</span>setResultsName<span>(</span><span>'fragment'</span><span>)</span></code></pre>



<p>
    This is a simple implementation that only supports http and don't adhear completely to the syntax specified in <a href="https://tools.ietf.org/html/rfc3986" target="_blank">rfc3986</a> but is good enough for our mvp.
</p>

<p>
    What's left is to compine these two parts while capturing parsing exceptions and returing the values in the correct format:

    </p><pre><code><span>import</span> pyparsing <span>as</span> pp

<span>def</span> <span>parse_url</span><span>(</span>url<span>)</span><span>:</span>
    <span>"""Pase url based on this format:

    http://[host[:port]]path[?query][#fragment]

    &gt;&gt;&gt; parse_url('http://httpbin.org/')
    ('httpbin.org', 80, '/')
    &gt;&gt;&gt; parse_url('http://httpbin.org/robots.txt')
    ('httpbin.org', 80, '/robots.txt')
    &gt;&gt;&gt; parse_url('http://test:1234/lorem?a=b#c')
    ('test', 1234, '/lorem?a=b')
    &gt;&gt;&gt; parse_url('https://mhasbini.com/')
    Traceback (most recent call last):
        ...
    ValueError: Invalid URL
    &gt;&gt;&gt; parse_url('httpmhasbini.com')
    Traceback (most recent call last):
        ...
    ValueError: Invalid URL
    """</span>

    host_pp <span>=</span> pp<span>.</span>Word<span>(</span>pp<span>.</span>alphanums <span>+</span> <span>'.'</span> <span>+</span> pp<span>.</span>alphas<span>)</span><span>.</span>setResultsName<span>(</span><span>'host'</span><span>)</span>
    port_pp <span>=</span> pp<span>.</span>pyparsing_common<span>.</span>signed_integer<span>.</span>setResultsName<span>(</span><span>'port'</span><span>)</span>
    path_pp <span>=</span> pp<span>.</span>Combine<span>(</span><span>'/'</span> <span>+</span> pp<span>.</span>Optional<span>(</span>pp<span>.</span>Word<span>(</span>pp<span>.</span>srange<span>(</span><span>"[a-zA-Z0-9.-_~!$&amp;'()*+,;=:@]"</span><span>)</span><span>)</span><span>)</span><span>)</span><span>.</span>setResultsName<span>(</span><span>'path'</span><span>)</span>
    fragment_pp <span>=</span> pp<span>.</span>Optional<span>(</span><span>'#'</span> <span>+</span> pp<span>.</span>Word<span>(</span>pp<span>.</span>srange<span>(</span><span>"[a-zA-Z0-9/?"</span><span>)</span><span>)</span><span>)</span><span>.</span>setResultsName<span>(</span><span>'fragment'</span><span>)</span>

    syntax_pp <span>=</span> <span>'http://'</span> <span>+</span> host_pp <span>+</span> pp<span>.</span>Optional<span>(</span><span>':'</span> <span>+</span> port_pp<span>)</span> <span>+</span> path_pp <span>+</span> fragment_pp

    <span>try</span><span>:</span>
        result <span>=</span> syntax_pp<span>.</span>parseString<span>(</span>url<span>)</span>        
    <span>except</span> pp<span>.</span>ParseException<span>:</span>
        <span>raise</span> ValueError<span>(</span><span>'Invalid URL'</span><span>)</span>

    <span>return</span> result<span>.</span>get<span>(</span><span>'host'</span><span>)</span><span>,</span> result<span>.</span>get<span>(</span><span>'port'</span><span>,</span> <span>80</span><span>)</span><span>,</span> result<span>.</span>get<span>(</span><span>'path'</span><span>)</span></code></pre>



<h2>Communication function</h2>

<p>
    This is the main part of the library, the usage will be:

    </p><pre><code><span>try</span><span>:</span>
    raw_response <span>=</span> get<span>(</span>host<span>,</span> port<span>,</span> path<span>)</span>
<span>except</span> ConnectionError <span>as</span> e<span>:</span>
    <span>print</span><span>(</span>e<span>)</span>
    exit<span>(</span><span>)</span></code></pre>



<p>
    As usual, we start with defining a couple of test cases:

    </p><pre><code><span>def</span> <span>get</span><span>(</span>host<span>,</span> port<span>,</span> path<span>)</span><span>:</span>
    <span>"""Open connection and send GET HTTP request and return raw response

    &gt;&gt;&gt; get('httpbin.org', 80, '/robots.txt') # doctest:+ELLIPSIS
    'HTTP/1.1 200 OK\\r\\nDate: ...\\r\\nContent-Type: text/plain\\r\\nContent-Length: 30\\r\\nConnection: close\\r\\nServer: gunicorn/19.9.0\\r\\nAccess-Control-Allow-Origin: *\\r\\nAccess-Control-Allow-Credentials: true\\r\\n\\r\\nUser-agent: *\\nDisallow: /deny\\n'
    &gt;&gt;&gt; get('mhasbini.com', 1234, '/robots.txt')
    Traceback (most recent call last):
        ...
    tt2.ConnectionError: [Errno 113] No route to host
    """</span>

    <span>.</span><span>.</span><span>.</span></code></pre>



<p>
    To execute this logic, we need to:
    </p><ol>
        <li>Construct the request hearder.</li>
        <li>Open socket and send the request: We'll use <code>socket.AF_INET</code> family because we're only supporting ipv4 and <code>code.SOCK_STREAM</code> type because we're using TCP.</li>
        <li>Read the response a chunk at a time and then return it.</li>
    </ol>



<p>
    Putting the above requirements into code:

    </p><pre><code><span>import</span> socket

<span>class</span> <span>ConnectionError</span><span>(</span>OSError<span>)</span><span>:</span>
    <span>"""Raised when a socket connection fail for any reason"""</span>
    <span>pass</span>

<span>def</span> <span>get</span><span>(</span>host<span>,</span> port<span>,</span> path<span>)</span><span>:</span>
    <span>"""Open connection and send GET HTTP request and return raw response

    &gt;&gt;&gt; get('httpbin.org', 80, '/robots.txt') # doctest:+ELLIPSIS
    'HTTP/1.1 200 OK\\r\\nDate: ...\\r\\nContent-Type: text/plain\\r\\nContent-Length: 30\\r\\nConnection: close\\r\\nServer: gunicorn/19.9.0\\r\\nAccess-Control-Allow-Origin: *\\r\\nAccess-Control-Allow-Credentials: true\\r\\n\\r\\nUser-agent: *\\nDisallow: /deny\\n'
    &gt;&gt;&gt; get('mhasbini.com', 1234, '/robots.txt')
    Traceback (most recent call last):
        ...
    tt2.ConnectionError: [Errno 113] No route to host
    """</span>

    
    request_m  <span>=</span> <span><span>f'GET </span><span><span>{</span>path<span>}</span></span><span> HTTP/1.1\r\n'</span></span>
    request_m <span>+=</span> <span><span>f'Host: </span><span><span>{</span>host<span>}</span></span><span>:</span><span><span>{</span>port<span>}</span></span><span>\r\n'</span></span>
    request_m <span>+=</span> <span>'Connection: close\r\n'</span>
    request_m <span>+=</span> <span>'\r\n'</span>

    <span>try</span><span>:</span>
        
        
        sock <span>=</span> socket<span>.</span>socket<span>(</span>socket<span>.</span>AF_INET<span>,</span> socket<span>.</span>SOCK_STREAM<span>)</span>
        sock<span>.</span>connect<span>(</span><span>(</span>host<span>,</span> port<span>)</span><span>)</span>
        sock<span>.</span>sendall<span>(</span>request_m<span>.</span>encode<span>(</span><span>)</span><span>)</span>

        
        data <span>=</span> <span>b''</span>
        <span>while</span> <span>True</span><span>:</span>
            _buffer <span>=</span> sock<span>.</span>recv<span>(</span><span>1024</span><span>)</span>

            <span>if</span> <span>not</span> _buffer<span>:</span>
                <span>break</span>

            data <span>+=</span> _buffer

        sock<span>.</span>close<span>(</span><span>)</span>

        <span>return</span> <span>repr</span><span>(</span>data<span>.</span>decode<span>(</span><span>)</span><span>)</span>
    <span>except</span> OSError <span>as</span> e<span>:</span>
        <span>raise</span> ConnectionError<span>(</span><span>str</span><span>(</span>e<span>)</span><span>)</span> <span>from</span> <span>None</span></code></pre>



<h2>HTTP response parser</h2>

<p>
    This is the final step where we take the raw response from the function above and parse it to get the status code and the response body. The API is as follow:
</p>

    <pre><code>status<span>,</span> body <span>=</span> parse_response<span>(</span>response<span>)</span></code></pre>


<p>Example of responses:</p>

    <pre><code><span>HTTP/1.1 <span>200 OK</span></span>
 Thu, 05 Nov 2020 00:05:19 GMT
 text/plain
 30
 close
 gunicorn/19.9.0
 *
 true

 *
 /deny</code></pre>


    <pre><code><span>HTTP/1.1 <span>404 NOT FOUND</span></span>
 Thu, 05 Nov 2020 00:05:46 GMT
 text/html
 233
 close
 gunicorn/19.9.0
 *
 true<span>

<span>&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN"&gt;</span>
<span><span><span>&lt;</span>title</span><span>&gt;</span></span>404 Not Found<span><span><span>&lt;/</span>title</span><span>&gt;</span></span>
<span><span><span>&lt;</span>h1</span><span>&gt;</span></span>Not Found<span><span><span>&lt;/</span>h1</span><span>&gt;</span></span>
<span><span><span>&lt;</span>p</span><span>&gt;</span></span>The requested URL was not found on the server.  If you entered the URL manually please check your spelling and try again.<span><span><span>&lt;/</span>p</span><span>&gt;</span></span></span></code></pre>



<p>
    We start by defining test cases:
</p>

    <pre><code><span>def</span> <span>parse_response</span><span>(</span>raw_response<span>)</span><span>:</span>
    <span>"""Parse raw http response and return status code and body.

    &gt;&gt;&gt; parse_response('HTTP/1.1 200 OK\\r\\nDate: Thu, 05 Nov 2020 03:22:48 GMT\\r\\nContent-Type: text/plain\\r\\nContent-Length: 30\\r\\nConnection: close\\r\\nServer: gunicorn/19.9.0\\r\\nAccess-Control-Allow-Origin: *\\r\\nAccess-Control-Allow-Credentials: true\\r\\n\\r\\nUser-agent: *\\nDisallow: /deny\\n')
    (200, 'User-agent: *\\nDisallow: /deny')
    &gt;&gt;&gt; parse_response('lorem ipsum')
    Traceback (most recent call last):
        ...
    ValueError: Invalid raw response
    """</span>

    <span>.</span><span>.</span><span>.</span></code></pre>


<p>
    The headers and the body are seperated by <code>\r\n\r\n</code> so we parse it as follow:
</p>

    <pre><code>DELIMITER <span>=</span> <span>'\\r\\n\\r\\n'</span>

status_pp <span>=</span> pp<span>.</span>pyparsing_common<span>.</span>signed_integer<span>.</span>setResultsName<span>(</span><span>'status'</span><span>)</span>
body_pp <span>=</span> pp<span>.</span>Suppress<span>(</span>DELIMITER<span>)</span> <span>+</span> pp<span>.</span>Regex<span>(</span><span>r'(.*?)$'</span><span>)</span><span>.</span>setResultsName<span>(</span><span>'body'</span><span>)</span>

response_pp <span>=</span> pp<span>.</span>LineStart<span>(</span><span>)</span> <span>+</span> <span>'HTTP/1.1'</span> <span>+</span> status_pp <span>+</span> pp<span>.</span>SkipTo<span>(</span>DELIMITER<span>)</span> <span>+</span>  body_pp</code></pre>


<p>
    Putting it together:
</p>

    <pre><code><span>import</span> pyparsing <span>as</span> pp

<span>def</span> <span>parse_response</span><span>(</span>raw_response<span>)</span><span>:</span>
    <span>"""Parse raw http response and return status code and body.

    &gt;&gt;&gt; parse_response('HTTP/1.1 200 OK\\r\\nDate: Thu, 05 Nov 2020 03:22:48 GMT\\r\\nContent-Type: text/plain\\r\\nContent-Length: 30\\r\\nConnection: close\\r\\nServer: gunicorn/19.9.0\\r\\nAccess-Control-Allow-Origin: *\\r\\nAccess-Control-Allow-Credentials: true\\r\\n\\r\\nUser-agent: *\\nDisallow: /deny\\n')
    (200, 'User-agent: *\\nDisallow: /deny')
    &gt;&gt;&gt; parse_response('lorem ipsum')
    Traceback (most recent call last):
        ...
    ValueError: Invalid raw response
    """</span>

    DELIMITER <span>=</span> <span>'\r\n\r\n'</span>

    status_pp <span>=</span> pp<span>.</span>pyparsing_common<span>.</span>signed_integer<span>.</span>setResultsName<span>(</span><span>'status'</span><span>)</span>
    body_pp <span>=</span> pp<span>.</span>SkipTo<span>(</span>pp<span>.</span>Regex<span>(</span><span>r'$'</span><span>)</span><span>)</span><span>.</span>setResultsName<span>(</span><span>'body'</span><span>)</span>

    response_pp <span>=</span> pp<span>.</span>LineStart<span>(</span><span>)</span> <span>+</span> <span>'HTTP/1.1'</span> <span>+</span> status_pp <span>+</span> pp<span>.</span>SkipTo<span>(</span>DELIMITER<span>)</span> <span>+</span> body_pp <span>+</span> pp<span>.</span>LineEnd<span>(</span><span>)</span>

    <span>try</span><span>:</span>
        result <span>=</span> response_pp<span>.</span>parseString<span>(</span>raw_response<span>)</span>
    <span>except</span> pp<span>.</span>ParseException<span>:</span>
        <span>raise</span> ValueError<span>(</span><span>'Invalid raw response'</span><span>)</span>

    <span>return</span> result<span>.</span>get<span>(</span><span>'status'</span><span>)</span><span>,</span> result<span>.</span>get<span>(</span><span>'body'</span><span>)</span></code></pre>



<h2>Plugging everything together</h2>

<p>
    This is the final step where we plug everything together and some syntactic sugar.
</p>


<b>httpy.py</b>

    <pre><code><span>from</span> parsers <span>import</span> parse_url<span>,</span> parse_response
<span>from</span> request_helper <span>import</span> get <span>as</span> raw_get

<span>class</span> <span>Result</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> status<span>,</span> data<span>)</span><span>:</span>
        self<span>.</span>status <span>=</span> status
        self<span>.</span>data <span>=</span> data

<span>def</span> <span>get</span><span>(</span>url<span>)</span><span>:</span>
    <span>return</span> Result<span>(</span><span>*</span>parse_response<span>(</span>raw_get<span>(</span><span>*</span>parse_url<span>(</span>url<span>)</span><span>)</span><span>)</span><span>)</span></code></pre>


<p>
And we have our demo working! 🎉
</p>
    <pre><code><span>import</span> httpy

req <span>=</span> httpy<span>.</span>get<span>(</span><span>'http://httpbin.org/robots.txt'</span><span>)</span>

req<span>.</span>status 
req<span>.</span>data </code></pre>



<h2>Conclusion</h2>

<p>The full source code is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mhasbini.com/blog/lets-build-an-http-client.html">https://mhasbini.com/blog/lets-build-an-http-client.html</a></em></p>]]>
            </description>
            <link>https://mhasbini.com/blog/lets-build-an-http-client.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24995571</guid>
            <pubDate>Thu, 05 Nov 2020 04:04:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Linux Commands HandBook]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24995352">thread link</a>) | @ekianjo
<br/>
November 4, 2020 | https://openbootcamps.com/the-linux-commands-handbook/ | <a href="https://web.archive.org/web/*/https://openbootcamps.com/the-linux-commands-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <!--kg-card-begin: markdown-->
<p>The Linux Commands Handbook follows the 80/20 rule: you’ll learn 80% of a topic in around 20% of the time you spend studying it.</p>
<p>I find that this approach gives you a well-rounded overview.</p>
<p>This handbook does not try to cover everything under the sun related to Linux and its commands. It focuses on the small core commands that you will use the 80% or 90% of the time, and tries to simplify the usage of the more complex ones.</p>
<p>All these commands work on Linux, macOS, WSL, and anywhere you have a UNIX environment.</p>
<p>I hope the contents of this handbook will help you achieve what you want: <strong>getting comfortable with Linux</strong>.</p>
<p><a target="_blank" href="https://flaviocopes.com/page/linux-commands-handbook/" rel="noopener noreferrer">Click here to download this handbook in PDF / ePUB / Mobi format</a>.</p>
<p>Enjoy!</p>

<h2 id="summary">Summary</h2>

<h2 id="introductiontolinuxandshells">Introduction to Linux and shells</h2>
<h3 id="whatislinux">What is Linux?</h3>
<p>Linux is an operating system, like macOS or Windows.</p>
<p>It is also the most popular Open Source operating system, and it gives you a lot of freedom.</p>
<p>It powers the vast majority of the servers that compose the Internet. It’s the base upon which everything is built. But not just that. Android is based on (a modified version of) Linux.</p>
<p>The Linux “core” (called a <em>kernel</em>) was born in 1991 in Finland, and it has come a really long way from its humble beginnings. It went on to be the kernel of the GNU Operating System, creating the duo GNU/Linux.</p>
<p>There’s one thing about Linux that corporations like Microsoft, Apple, and Google will never be able to offer: the freedom to do whatever you want with your computer.</p>
<p>They’re actually going in the opposite direction, building walled gardens, especially on the mobile side.</p>
<p>Linux is the ultimate freedom.</p>
<p>It is developed by volunteers, some paid by companies that rely on it, some independently. But there’s no single commercial company that can dictate what goes into Linux, or the project’s priorities.</p>
<p>You can also use Linux as your day to day computer. I use macOS because I really enjoy the applications and design (and I also used to be an iOS and Mac apps developer). But before using macOS I used Linux as my main computer Operating System.</p>
<p>No one can dictate which apps you can run, or “call home” with apps that track you, your position, and more.</p>
<p>Linux is also special because there’s not just “one Linux”, like is the case with Windows or macOS. Instead, we have <strong>distributions</strong>.</p>
<p>A “distro” is made by a company or organization and packages the Linux core with additional programs and tooling.</p>
<p>For example you have Debian, Red Hat, and Ubuntu, probably the most popular distributions.</p>
<p>But many, many more exist. You can create your own distribution, too. But most likely you’ll use a popular one that has lots of users and a community of people around it. This lets you do what you need to do without losing too much time reinventing the wheel and figuring out answers to common problems.</p>
<p>Some desktop computers and laptops ship with Linux preinstalled. Or you can install it on your Windows-based computer, or on a Mac.</p>
<p>But you don’t need to disrupt your existing computer just to get an idea of how Linux works.</p>
<p>I don’t have a Linux computer.</p>
<p>If you use a Mac, you just need to know that under the hood macOS is a UNIX Operating System. It shares a lot of the same ideas and software that a GNU/Linux system uses, because GNU/Linux is a free alternative to UNIX.</p>
<blockquote>
<p><a target="_blank" href="https://en.wikipedia.org/wiki/Unix" rel="noopener noreferrer">UNIX</a> is an umbrella term that groups many operating systems used in big corporations and institutions, starting from the 70’s</p>
</blockquote>
<p>The macOS terminal gives you access to the same exact commands I’ll describe in the rest of this handbook.</p>
<p>Microsoft has an official <a target="_blank" href="https://docs.microsoft.com/en-us/windows/wsl/install-win10" rel="noopener noreferrer">Windows Subsystem for Linux</a> which you can (and should!) install on Windows. This will give you the ability to run Linux in a very easy way on your PC.</p>
<p>But the vast majority of the time you will run a Linux computer in the cloud via a VPS (Virtual Private Server) like DigitalOcean.</p>
<h3 id="whatisashell">What is a shell?</h3>
<p>A shell is a command interpreter that exposes an interface to the user to work with the underlying operating system.</p>
<p>It allows you to execute operations using text and commands, and it provides users advanced features like being able to create scripts.</p>
<p>This is important: shells let you perform things in a more optimized way than a GUI (Graphical User Interface) could ever possibly let you do. Command line tools can offer many different configuration options without being too complex to use.</p>
<p>There are many different kind of shells. This post focuses on Unix shells, the ones that you will find commonly on Linux and macOS computers.</p>
<p>Many different kind of shells were created for those systems over time, and a few of them dominate the space: Bash, Csh, Zsh, Fish and many more!</p>
<p>All shells originate from the Bourne Shell, called <code>sh</code>. “Bourne” because its creator was Steve Bourne.</p>
<p>Bash means <em>Bourne-again shell</em>. <code>sh</code> was proprietary and not open source, and Bash was created in 1989 to create a free alternative for the GNU project and the Free Software Foundation. Since projects had to pay to use the Bourne shell, Bash became very popular.</p>
<p>If you use a Mac, try opening your Mac terminal. By default it runs ZSH (or, pre-Catalina, Bash).</p>
<p>You can set up your system to run any kind of shell – for example I use the Fish shell.</p>
<p>Each single shell has its own unique features and advanced usage, but they all share a common functionality: they can let you execute programs, and they can be programmed.</p>
<p>In the rest of this handbook we’ll see in detail the most common commands you will use.</p>

<h2 id="the-man-command">The <code>man</code> command</h2>
<p>The first command I’ll introduce will help you understand all the other commands.</p>
<p>Every time I don’t know how to use a command, I type <code>man &lt;command&gt;</code> to get the manual:</p>
<figure><img src="https://i1.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screen-Shot-2020-07-04-at-18.42.40.png?ssl=1" alt="" srcset="https://www.freecodecamp.org/news/content/images/size/w600/2020/10/Screen-Shot-2020-07-04-at-18.42.40.png 600w, https://www.freecodecamp.org/news/content/images/size/w1000/2020/10/Screen-Shot-2020-07-04-at-18.42.40.png 1000w, https://i1.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screen-Shot-2020-07-04-at-18.42.40.png?ssl=1 1188w" data-recalc-dims="1" data-lazy-srcset="https://www.freecodecamp.org/news/content/images/size/w600/2020/10/Screen-Shot-2020-07-04-at-18.42.40.png 600w, https://www.freecodecamp.org/news/content/images/size/w1000/2020/10/Screen-Shot-2020-07-04-at-18.42.40.png 1000w, https://i1.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screen-Shot-2020-07-04-at-18.42.40.png?ssl=1 1188w" data-lazy-src="https://i1.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screen-Shot-2020-07-04-at-18.42.40.png?ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>This is a man (from <em>_manual_</em>) page. Man pages are an essential tool to learn as a developer. They contain so much information that sometimes it’s almost too much.<br>The above screenshot is just 1 of 14 screens of explanation for the <code>ls</code> command.</p>
<p>Most of the time when I need to learn a command quickly I use this site called <strong>tldr pages</strong>: <a target="_blank" href="https://tldr.sh/" rel="noopener noreferrer">https://tldr.sh</a>. It’s a command you can install, which you then run like this: <code>tldr &lt;command&gt;</code>. It gives you a very quick overview of a command, with some handy examples of common usage scenarios:</p>
<figure><img src="https://i0.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screen-Shot-2020-09-07-at-07.35.41.png?ssl=1" alt="" srcset="https://www.freecodecamp.org/news/content/images/size/w600/2020/10/Screen-Shot-2020-09-07-at-07.35.41.png 600w, https://www.freecodecamp.org/news/content/images/size/w1000/2020/10/Screen-Shot-2020-09-07-at-07.35.41.png 1000w, https://i0.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screen-Shot-2020-09-07-at-07.35.41.png?ssl=1 1002w" data-recalc-dims="1" data-lazy-srcset="https://www.freecodecamp.org/news/content/images/size/w600/2020/10/Screen-Shot-2020-09-07-at-07.35.41.png 600w, https://www.freecodecamp.org/news/content/images/size/w1000/2020/10/Screen-Shot-2020-09-07-at-07.35.41.png 1000w, https://i0.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screen-Shot-2020-09-07-at-07.35.41.png?ssl=1 1002w" data-lazy-src="https://i0.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screen-Shot-2020-09-07-at-07.35.41.png?ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>This is not a substitute for <code>man</code>, but a handy tool to avoid losing yourself in the huge amount of information present in a <code>man</code> page. Then you can use the <code>man</code> page to explore all the different options and parameters you can use on a command.</p>
<h2 id="the-ls-command">The <code>ls</code> command</h2>

<p>Inside a folder you can list all the files that the folder contains using the <code>ls</code> command:</p>
<pre><code>ls
</code></pre>
<p>If you add a folder name or path, it will print that folder’s contents:</p>
<pre><code>ls /bin
</code></pre>
<p><img src="https://i2.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screenshot-2019-02-09-at-18.50.14.png?ssl=1" alt="Screenshot-2019-02-09-at-18.50.14" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screenshot-2019-02-09-at-18.50.14.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p><code>ls</code> accepts a lot of options. One of my favorite combinations is <code>-al</code>. Try it:</p>
<pre><code>ls -al /bin
</code></pre>
<p><img src="https://i0.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screenshot-2019-02-09-at-18.49.52.png?ssl=1" alt="Screenshot-2019-02-09-at-18.49.52" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/www.freecodecamp.org/news/content/images/2020/10/Screenshot-2019-02-09-at-18.49.52.png?ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Compared to the plain <code>ls</code> command, this returns much more information.</p>
<p>You have, from left to right:</p>
<ul>
<li>the file permissions (and if your system supports ACLs, you get an ACL flag as well)</li>
<li>the number of links to that file</li>
<li>the owner of the file</li>
<li>the group of the file</li>
<li>the file size in bytes</li>
<li>the file’s last modified datetime</li>
<li>the file name</li>
</ul>
<p>This set of data is generated by the <code>l</code> option. The <code>a</code> option instead also shows the hidden files.</p>
<p>Hidden files are files that start with a dot (<code>.</code>).</p>

<h2 id="thecdcommand">The <code>cd</code> command</h2>
<p>Once you have a folder, you can move into it using the <code>cd</code> command. <code>cd</code> means <strong>c</strong>hange <strong>d</strong>irectory. You invoke it specifying a folder to move into. You can specify a folder name, or an entire path.</p>
<p>Example:</p>
<pre><code>mkdir fruits
cd fruits
</code></pre>
<p>Now you are in the <code>fruits</code> folder.</p>
<p>You can use the <code>..</code> special path to indicate the parent folder:</p>
<pre><code>cd .. #back to the home folder
</code></pre>
<p>The # character indicates the start of the comment, which lasts for the entire line after it’s found.</p>
<p>You can use it to form a path:</p>
<pre><code>mkdir fruits
mkdir cars
cd fruits
cd ../cars
</code></pre>
<p>There is another special path indicator which is <code>.</code>, and indicates the <strong>current</strong> folder.</p>
<p>You can also use absolute paths, which start from the root folder <code>/</code>:</p>
<pre><code>cd /etc
</code></pre>

<h2 id="the-pwd-command">The <code>pwd</code> command</h2>

<p>Whenever you feel lost in the filesystem, call the <code>pwd</code> command to know where you are:</p>
<pre><code>pwd
</code></pre>
<p>It will print the current folder path.</p>

<h2 id="the-mkdir-command">The <code>mkdir</code> command</h2>

<p>You create folders using the <code>mkdir</code> command:</p>
<pre><code>mkdir fruits
</code></pre>
<p>You can create multiple folders with one command:</p>
<pre><code>mkdir dogs cars
</code></pre>
<p>You can also create multiple nested folders by adding the <code>-p</code> option:</p>
<pre><code>mkdir -p fruits/apples
</code></pre>
<p>Options in UNIX commands commonly take this form. You add them right after the command name, and they change how the command behaves. You can often combine multiple options, too.</p>
<p>You can find which options a command supports by typing <code>man &lt;commandname&gt;</code>. Try now with <code>man mkdir</code> for example (press the <code>q</code> key to esc the man page). Man pages are the amazing built-in help for UNIX.</p>

<h2 id="the-rmdir-command">The <code>rmdir</code> command</h2>

<p>Just as you can create a folder using <code>mkdir</code>, you can delete a folder using <code>rmdir</code>:</p>
<pre><code>mkdir fruits
rmdir fruits
</code></pre>
<p>You can also delete multiple folders at once:</p>
<pre><code>mkdir fruits cars
rmdir fruits cars
</code></pre>
<p>The folder you delete must be empty.</p>
<p>To delete folders with files in them, we’ll use the more generic <code>rm</code> command which deletes files and folders, using the <code>-rf</code> option:</p>
<pre><code>rm -rf fruits cars
</code></pre>
<p>Be careful as this command does not ask for confirmation and it will immediately remove anything you ask it to remove.</p>
<p>There is no <strong>bin</strong> when removing files from the command line, and recovering lost files can be hard.</p>

<h2 id="the-mv-command">The <code>mv</code> command</h2>

<p>Once you have a file, you can move it around using the <code>mv</code> command. You specify the file current path, and its new path:</p>
<pre><code>touch test
mv pear new_pear
</code></pre>
<p>The <code>pear</code> file is now moved to <code>new_pear</code>. This is how you <strong>rename</strong> files and folders.</p>
<p>If the last parameter is a folder, the file located at the first parameter path is going to be moved into that folder. In this case, you can specify a list of files and they will all be moved in the folder path identified by the last parameter:</p>
<pre><code>touch pear
touch apple
mkdir fruits
mv pear apple fruits #pear and apple moved to the fruits folder
</code></pre>

<h2 id="the-cp-command">The <code>cp</code> command</h2>

<p>You can copy a file using the <code>cp</code> command:</p>
<pre><code>touch test
cp apple another_apple
</code></pre>
<p>To copy folders you need to add the <code>-r</code> option to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openbootcamps.com/the-linux-commands-handbook/">https://openbootcamps.com/the-linux-commands-handbook/</a></em></p>]]>
            </description>
            <link>https://openbootcamps.com/the-linux-commands-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24995352</guid>
            <pubDate>Thu, 05 Nov 2020 03:19:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Native vs. Hybrid Apps: Which Route to Take?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24995168">thread link</a>) | @allending
<br/>
November 4, 2020 | https://blog.snappymob.com/native-vs-hybrid-apps-which-route-to-take | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/native-vs-hybrid-apps-which-route-to-take">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>If you’re thinking of developing an app, and you’ve consulted the internet on it, you’ve most probably noticed that these two terminologies pop up a lot — Native and Hybrid. What do they mean? How are they different? Which would be better for the nature of your business?</p>
<!--more--><p>Let’s tackle all these burning questions today.&nbsp;</p>
<p>This is how we’ll do it: We’ll define the terms, distinguish them, and then study which piece fits into your priorities and business goals better.&nbsp;</p>
<h2><strong>Understanding What They Are</strong></h2>
<p>Before getting into the nitty gritty, let’s lay down a quick overview of these terminologies.&nbsp;</p>
<h3><strong>Native Apps</strong></h3>
<p>As long as you have a basic understanding of apps, you’d know that smartphones run on either iOS or Android platforms, right? Easy. Basically, native applications are developed specifically for a particular mobile operating system using a software development kit like Java for Android, and Objective-C or Swift for iOS.</p>
<p>The end result of a native app often “feels right” because users have the ability to interact with features in the mobile device’s operating system like GPS, camera, microphone, contact list etc. Given its mature ecosystem, native apps definitely have the advantage of faster performance compared to hybrid apps. Being consistent and similar with other native apps, users will generally learn to navigate your app faster.</p>
<p>At least 80% of the apps on your smartphone are built on native development kits. Take Instagram or your favourite mobile game for an example — these apps that depend on HD graphics and smooth user experience definitely perform better as native apps.</p>
<h3><strong>Hybrid Apps</strong></h3>
<p>Hybrid apps, on the other hands, are basically web apps within an app. They’re built with Javascript, HTML, and CSS and run in a simplified browser (or, webview) on what looks and feels like a native app.&nbsp;</p>
<p>Hybrid apps are typically easier and require less time to develop, compared to native apps. They also require less maintenance and are easier to scale. Most companies opt for hybrid development because they can get the app to market fast, as the apps can be built on a single codebase and released onto multiple platforms quick and easy.</p>
<p><span><strong>Defining Your Goals</strong></span></p>
<p>When it comes to deciding which route to take, there are no cookie cutter, one-size-fits-all answers. There are a few things you will need to consider to weigh your odds — user experience, time to market, app performance, and maintenance. Your personal preferences for these factors make the compass that will point you to the right direction.</p>

<span><img src="https://blog.snappymob.com/hs-fs/hubfs/user%20experience.jpg?width=600&amp;name=user%20experience.jpg" alt="user experience" width="600" srcset="https://blog.snappymob.com/hs-fs/hubfs/user%20experience.jpg?width=300&amp;name=user%20experience.jpg 300w, https://blog.snappymob.com/hs-fs/hubfs/user%20experience.jpg?width=600&amp;name=user%20experience.jpg 600w, https://blog.snappymob.com/hs-fs/hubfs/user%20experience.jpg?width=900&amp;name=user%20experience.jpg 900w, https://blog.snappymob.com/hs-fs/hubfs/user%20experience.jpg?width=1200&amp;name=user%20experience.jpg 1200w, https://blog.snappymob.com/hs-fs/hubfs/user%20experience.jpg?width=1500&amp;name=user%20experience.jpg 1500w, https://blog.snappymob.com/hs-fs/hubfs/user%20experience.jpg?width=1800&amp;name=user%20experience.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px"></span>

<h3><strong>User Experience</strong></h3>
<p>User experience has always been the top factor of an app’s success in user retention. In this millennial age, smartphones have become very personal devices for everyone. We carry them everywhere we go, from the moment we get out of bed to the moment right before we get back into bed. Having a responsive and reliable device that allows us to easily obtain the information we need at any time is one of the reasons why it’s so important to us.</p>
<p><a href="https://buildfire.com/app-statistics/#:~:text=Even%20though%20the%20average%20person,t%20get%20used%20every%20month."><span>Buildfire’s statistics</span></a> on mobile usage indicates that, even though the average person uses 25 apps per month, 96% of the time spent on their devices is split across only 10 apps. What is the reason? Yes, you know it. People are downloading apps, but they’re not using them. As a matter of fact, 75% of apps are used only once after being downloaded, and then within the snap of a finger — users churn.</p>
<p>So, let's link it back to why choosing the technology you build your app on is crucial. Psychologically, users' needs are pretty simple. They buy a new device, spend some time learning to navigate, learn about its features, and they’re done. They don’t want to have to solve a new maze everytime they download a new app.&nbsp;</p>
<p>So with that in mind, the important question to ask yourself before building an app is this: How do I make my app easy to navigate and avoid having users feel like they’re in a maze? The answer is simple — by creating a seamless experience with the platform’s extensive style guide from controls to visuals.</p>
<p>Since native apps are developed for and to be consistent with the ecosystem within the specific operating systems, you can rest assured that user experience won’t be compromised.</p>
<p>Hybrid however, is a risk for user experience, even with the most brilliant UX designs. The difference in style guidelines on hybrid apps could interfere with the success of your application.</p>
<h3><strong>Time To Market</strong></h3>
<p>If time is a major concern, then hybrid apps might be the best solution for you. If you have 6 months or more to spare, however, opt for native solutions.&nbsp;</p>
<p>If your goal right now is to get your product to market as quickly as possible, and you’re willing to sacrifice performance and user experience, go hybrid. Hybrid apps have a shorter development time as the app is built on a single source code and can be released onto multiple platforms.</p>
<p>It’s also a good idea to start with hybrid if you’re testing the viability of your project. After seeing positive feedback, perhaps you can confidently switch to native to penetrate a bigger market.&nbsp;</p>

<img src="https://blog.snappymob.com/hs-fs/hubfs/app%20performance.jpg?width=600&amp;name=app%20performance.jpg" alt="app performance" width="600" srcset="https://blog.snappymob.com/hs-fs/hubfs/app%20performance.jpg?width=300&amp;name=app%20performance.jpg 300w, https://blog.snappymob.com/hs-fs/hubfs/app%20performance.jpg?width=600&amp;name=app%20performance.jpg 600w, https://blog.snappymob.com/hs-fs/hubfs/app%20performance.jpg?width=900&amp;name=app%20performance.jpg 900w, https://blog.snappymob.com/hs-fs/hubfs/app%20performance.jpg?width=1200&amp;name=app%20performance.jpg 1200w, https://blog.snappymob.com/hs-fs/hubfs/app%20performance.jpg?width=1500&amp;name=app%20performance.jpg 1500w, https://blog.snappymob.com/hs-fs/hubfs/app%20performance.jpg?width=1800&amp;name=app%20performance.jpg 1800w" sizes="(max-width: 600px) 100vw, 600px">

<h3><strong>App Performance</strong></h3>
<p>After all that’s said, it’s pretty obvious that native would win this category. Native apps are faster and more seamless in the sense that when a user navigates through the app, all its contents, visuals and structure readily fit on their device.</p>
<p>As for hybrid, content and data are loaded from the server. How might this affect performance? When servers are taken into account, we need to consider the number of requests being made to a server, or, how many people are trying to reach that server. The higher the traffic, the slower the performance of your app.&nbsp;</p>
<h3><strong>App Updates</strong></h3>
<p>When it comes to tech and product development, there’s no such thing as bug-free software that never needs updates. Development teams will always find room for improvement. So the difference lies in the frequency of your updates and what actions are required from your users to acquire the updates. This will all have an impact on how well your app is received.</p>
<p>Hybrid apps don't require users to update through app stores. Once the update is applied on the page that is loaded from the server, users who navigate through the app can instantly see the update.</p>
<p>Native app users, on the other hand, will need to go through the app stores for updates before they see the changes. This won’t be any extra work for those who have automatic updates enabled on their devices, but what about those who don’t? Will frequent updates frustrate them and affect their perception of your app? This will be something for you to consider.</p>
<h2><strong>Next Step For You</strong></h2>
<p>When it comes to deciding which technology to build your application on, both native and hybrid have their respective advantages and disadvantages. What you need to do is weigh the pros and cons, and decide what risks you’re willing or unwilling to take. If your business is on a tight deadline and going hybrid is your only option, just be aware of the tradeoffs that you are putting on the line.&nbsp;</p>
<p>Essentially, it’s no question that native apps make a bigger impact in the long run. Your initial investment will definitely be higher, but the end result of better user experience and performance might be worth taking the leap for.&nbsp;</p>
<p>Have a ground-breaking idea that you’re eager to bring to life? We’re here to help! <a href="http://snappymob.com/contact"><span>Contact us</span></a> and we’ll talk about your next big app.</p></span></p><p><label>app development</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/native-vs-hybrid-apps-which-route-to-take</link>
            <guid isPermaLink="false">hacker-news-small-sites-24995168</guid>
            <pubDate>Thu, 05 Nov 2020 02:34:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Journey to a Curl Domain]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24995139">thread link</a>) | @sohkamyung
<br/>
November 4, 2020 | https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Good things come to those who wait?</p>



<p>When I created and started hosting the first websites for curl I didn’t care about the URL or domain names used for them, but after a few years I started to think that maybe it would be cool to register a curl domain for its home. By then it was too late to find an available name under a “sensible” top-level domain and since then I’ve been on the lookout for one.</p>



<h2>Yeah, I host it</h2>



<p>So yes, I’ve administrated every machine that has ever hosted the curl web site going all the way back to the time before we called the tool curl. I’m also doing most of the edits and polish of the web content, even though I’m crap at web stuff like CSS and design. So yeah, I consider it my job to care for the site and make sure it runs smooth and that it has a proper (domain) name.</p>



<h2>www.fts.frontec.se</h2>



<p>The first ever curl web page was hosted on “<code>www.fts.frontec.se/~dast/curl</code>” in the late 1990s (<a href="https://web.archive.org/web/19981202234521/http://www.fts.frontec.se/%7Edast/curl/">snapshot</a>). I worked for the company with that domain name at the time and ~dast was the location for my own personal web content.</p>



<h2>curl.haxx.nu</h2>



<p>The curl website moved to its first “own home”, with curl.haxx.nu in August 1999 (<a href="https://web.archive.org/web/19991013093821/http://curl.haxx.nu/">snapshot</a>) when we registered our first domain and the .nu top-level domain was available to us when .se wasn’t.</p>



<h2>curl.haxx.se</h2>



<p>We switched from curl.haxx.nu to curl.haxx.se in the summer of 2000 (when finally were allowed to register our name in the .se TLD) (<a href="https://web.archive.org/web/20001017164421/https://curl.haxx.se/">snapshot</a>).</p>



<p>The name “haxx” in the domain has been the reason for many discussions and occasional concerns from users and overzealous blocking-scripts over the years. I’ve kept the curl site on that domain since it is the name of one of the primary <a href="https://curl.haxx.se/sponsors.html">curl sponsors</a> and partly because I want to teach the world that a particular word in a domain is not a marker for badness or something like that. And of course because we have not bought or been provided a better alternative.</p>



<p><a href="https://www.haxx.se/">Haxx</a> is still the name of the company I co-founded back in 1997 so I’m also the admin of the domain.</p>



<h2>curl.se</h2>



<p>I’ve looked for and contacted owners of curl under many different TLDs over the years but most have never responded and none has been open for giving up their domains. I’ve always had an extra attention put on <code>curl.se</code> because it is in the Swedish TLD, the same one we have for Haxx and where I live.</p>



<h2>The curling background</h2>



<p>The first record on archive.org of anyone using the domain <code>curl.se</code> for web content is dated <a href="https://web.archive.org/web/20030830002347/http://www.curl.se/">August 2003</a> when the Swedish curling team “Härnösands CK” used it. They used the domain and website for a few years under this name. It can be noted that it was team <a href="https://en.wikipedia.org/wiki/Anette_Norberg">Anette Norberg</a>, which subsequently won two Olympic gold medals in the sport.</p>



<p>In September 2007 the site was renamed, still being about the sport curling but with the name “the curling girls” in Swedish (<em>curlingtjejerna</em>) which remained there for just 1.5 years until it changed again. “curling team Folksam” then populated the site with contents about the sport and that team until they let the domain expire in 2012. (Out of these three different curling oriented sites, the first one is the only one that still seems to be around but now of course on another domain.)</p>



<h2>Ads</h2>



<p>In early August 2012 the domain was registered to a new owner. I can’t remember why, but I missed the chance to get the domain then.</p>



<p>August 28 2012 marks the first date when curl.se is recorded to suddenly host a bunch of links to casino, bingo and gambling sites. It seems that whoever bought the domain wanted to surf on the good name and possible incoming links built up from the previous owners. For several years this crap was what the website showed. I doubt very many users ever were charmed by the content nor clicked on many links. It was ugly and over-packed with no real content but links and ads.</p>



<p>The last archive.org capture of the ad-filled site was done on October 2nd 2016. Since then, there’s been no web content on the domain that I’ve found. But the domain registration kept getting renewed.</p>



<h2>Failed to purchase</h2>



<p>In August 2019, I noticed that the domain was about to expire, and I figured it could be a sign that the owner was not too interested in keeping it anymore. I contacted the owner via a registrar and offered to buy it. The single only response I ever got was that my monetary offer was “too low”. I tried to up my bid, but I never got any further responses from the owner and then after a while I noticed that the domain registration was again renewed for another year. I went back to waiting.</p>



<h2>Expired again</h2>



<p>In September 2020 the domain was again up for expiration and I contacted the owner again, this time asking for a price for which they would be willing to sell the domain. Again no response, but this time the domain actually went all the way to expiry and deletion, which eventually made it available “on the market” for everyone interested to compete for the purchase.</p>



<p>I entered the race with the help of a registrar that would attempt to buy the name when it got released. When this happens, when a domain name is “released”, it becomes a race between all the potential buyers who want the domain. It is a 4-letter domain that is an English word and easy pronounceable. I knew there was a big risk others would also be trying to get it.</p>



<p>In the early morning of October 19th 2020, the curl.se domain was released and in the race of getting the purchase… I lost. Someone else got the domain before me. I was sad. For a while, until I got the good news…</p>



<h2>Donated!</h2>



<p>It turned out my friend <strong>Bartek Tatkowski</strong> had snatched the domain! After getting all the administrative things in order, Bartek graciously donated the domain to me and 15:00 on October 30 2020 I could enter my own name servers into the dedicated inputs fields for the domain, and configure it properly in our master and secondary DNS servers.</p>



<h2>curl.se is the new home</h2>



<p>Starting on November 4, 2020 <strong>curl.se is the new official home</strong> site for the curl project. The <code>curl.haxx.se</code> name will of course remain working for a long time more and I figure we can basically never shut it down as there are so many references to it spread out over the world. I intend to eventually provide redirects for most things from the old name to the new.</p>



<div><figure><a href="https://www.fastly.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-1200x630.png" alt="" width="190" height="100" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-200x105.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-450x236.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-768x403.png 768w" sizes="(max-width: 190px) 100vw, 190px"></a></figure></div>



<p>What about a www prefix? The jury is still out how or if we should use that or not. The initial update of the site (November 4) uses a www.curl.se host name in links but I’ve not done any automatic redirects to or from that. As the site is CDNed, and we can’t use CNAMEs on the apex domain (curl.se), we instead use anycast IPs for it – the net difference to users should be zero. (Fastly is a generous sponsor of the curl project.)</p>



<p>I also happen to own <code>libcurl.se</code> since a few years back and I’ll make sure using this name also takes you to the right place.</p>



<h2>Why not curl.dev?</h2>



<p>People repeatedly ask me. Names in the .dev domains are <em>expensive</em>. Registering <code>curl.dev</code> goes for 400 USD right now. <code>curl.se</code> costs 10 USD/year. I see little to no reason to participate in that business and I don’t think spending donated money on such a venture is a responsible use of our funds.</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/truthseeker08-2411480/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1923005">truthseeker08</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1923005">Pixabay</a>. Domain by Bartek Tatkowski.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24995139</guid>
            <pubDate>Thu, 05 Nov 2020 02:27:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Source Code Leak]]>
            </title>
            <description>
<![CDATA[
Score 719 | Comments 258 (<a href="https://news.ycombinator.com/item?id=24994746">thread link</a>) | @resynth1943
<br/>
November 4, 2020 | https://resynth1943.net/articles/github-source-code-leak/ | <a href="https://web.archive.org/web/*/https://resynth1943.net/articles/github-source-code-leak/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="content">
		
		<p>What do Microsoft <i>really</i> think about open-source?</p>

		<p>The entire source code for the code hosting service used by developers, <a href="http://github.com/">GitHub.com</a>, has just been leaked to the public.</p>
<p>In a suspicious <a href="https://web.archive.org/web/20201104050026if_/https://github.com/github/dmca/tree/565ece486c7c1652754d7b6d2b5ed9cb4097f9d5">commit</a> to the <a href="https://github.com/github/dmca">official GitHub DMCA repository</a>, an unknown individual uploaded the confidential source code, impersonating Nat Friedman using a bug in GitHub's application.</p>
<p>At the heart of open-source, GitHub has long been criticised for keeping its source code private. The platform hosts millions of open-source projects, and critics say GitHub's position is somewhat hypocritical.</p>
<p>However, this raises questions around the security of GitHub's source code, and whether or not GitHub have anything to lose, if they do plan to release the source code in a public setting.</p>
<p>Some worry this will damage the overall security of GitHub, and this may be true. Commonly, closed-source applications perform "security by obscurity". This means the source code is hidden, with the intention of concealing security risks.</p>
<p>Since Microsoft's <a href="https://www.theverge.com/2018/10/26/17954714/microsoft-github-deal-acquisition-complete">acquisition of GitHub</a> in 2018, Microsoft have repeatedly emphasised their "love" for open-source. We have seen this through repeated commercial advertisements, which aim to place Microsoft at the forefront of open-source development.</p>
<p>Some users, such as Drew DeVault, suggest Microsoft is attempting to <a href="https://drewdevault.com/2020/08/27/Microsoft-plays-their-hand.html">centralise open-source</a>. Through closed-source applications, and proprietary extensions to Git, GitHub is seen as a platform that tries to <em>contain</em> open-source. An example of this is when <a href="https://www.theverge.com/2020/6/29/21306674/github-down-errors-outage-june-2020">GitHub went offline for two hours</a>, leaving thousands of open-source projects inaccessible and unusable.</p>
<p>GitHub is, in many ways, the Google of open-source development.</p>
<p>Perhaps GitHub as 12 years late in finally revealing their source code to the public; and maybe this is just what we need. <a href="https://mastodon.tedomum.net/@resynth1943">What do you think?</a></p>


		<!-- Doing a little experiment here. -->
		<p aria-disabled="true">resynth1943.article</p>
	</div></div>]]>
            </description>
            <link>https://resynth1943.net/articles/github-source-code-leak/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24994746</guid>
            <pubDate>Thu, 05 Nov 2020 01:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IPv6 Is a Total Nightmare – This Is Why]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24994587">thread link</a>) | @whereistimbo
<br/>
November 4, 2020 | https://teknikaldomain.me/post/ipv6-is-a-total-nightmare/ | <a href="https://web.archive.org/web/*/https://teknikaldomain.me/post/ipv6-is-a-total-nightmare/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<div>


<p>So this is just going to be a total rant.
IPv6 is, in theory, a solution to many things, including the dwindling IPv4 address space.
IPv6 was a draft in 1997(!), and became a real <em>Internet Standard</em> in 2017.
And, quite frankly, it’s one of those things that just adds too much hassle for not enough benefit.</p>

<p>Okay, yes, IPv6’s address space is <em><strong>massive.</strong></em>
IPv4 uses 32-bit addresses, allowing for 4,294,967,296 total addresses.
IPv6 uses 128-bit addresses, meaning… 340,282,366,920,938,463,463,374,607,431,768,211,456 addresses.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>
The entire v4 space could fit into the v6 space $7.922816251426434 \times 10^{28}$ times over.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>
The default allocation to people, a <code>/64</code>, meaning the first half of the addresses is fixed and the entire second half is the part unique to the network, means that most people have 18,446,744,073,709,551,616 addresses to play with at home.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>
Compared to v4, where <em>most</em> networks are around <code>/24</code>, meaning the first three groupings are fixed, you get… 254 addresses.
Again, context, a standard <code>/64</code> allocation can, <em>again</em>, fit the entire v4 address space inside itself 4,294,967,296 times. (Yes, that’s the number of addresses <em>in</em> the IPv4 address space. That’s what happens when you divide a power by half of that power.)</p>
<p>IPv4 addresses are, well, sparse, given that most high-level authorities have already run out of addresses, but because CIDR and NAT are a thing, we’ve really started compacting down our usage.
<em>My entire house</em> of easily over 60 IPs takes up… 2, according to the rest of the world.</p>
<h2 id="allocation-issues">Allocation Issues</h2>
<p>One thing that people have criticized IPv4 for is that the allocations are just horrible.
For example, <em>anything</em> starting with <code>127</code> is <code>localhost</code>.
normally this is <code>127.0.0.1</code>, but anything from <code>127.0.0.0</code> to <code>127.255.255.255</code> all mean the <strong>exact same thing.</strong>
That’s 16,777,216 addresses all <em>literally for <code>localhost</code>.</em>
By numbers, 0.39% of the address space, but just keep this in mind.</p>
<p>Similarly, anything starting with a <code>0</code>, is effectively “current network” (only valid as source), again, another 16 million addresses.</p>
<p>There’s also multiple blocks for private networks, <code>10.0.0.0/8</code>, <code>172.16.0.0/12</code>, and <code>192.168.0.0/16</code>.
In total, 17,891,328 addresses.</p>
<p>Compared to IPv6, yes, IPv6 is much better… in theory.
There’s only <em>one</em> loopback address, <code>::1</code>.
At the same time… <code>fc00::/7</code> (26,58,455,991,569,831,745,807,614,120,560,689,152 addresses) is the private address space (more on that later), <code>fe80::/10</code> (332,306,998,946,228,968,225,951,765,070,086,144 addresses) is the <em>local</em> address space, and <code>ff00::/8</code> (1,329,227,995,784,915,872,903,807,060,280,344,576 addresses.) is multicast.
yes, do you see a recurring pattern?
Even though the entire “special” address assignments are exactly 1.271% of the entire IPv6 address space, we’re still allocating <strong>giant</strong> swathes of addresses.
History repeats itself, you can see that <em>right here.</em></p>
<p>And I will admit, that multicast in IPv6 is special since some bits in the address are special flags, and one form of multicast actually includes a response node’s address, so it’s not <em>just</em> an arbitrary number, but… come on, that’s a little uncalled for, having <em>that much</em> space.</p>

<p>We all know what an IPv4 address looks like, right?
Four dotted-decimal grouping in the range from 0–255.
For example, <code>192.168.5.225</code>.
IPv6 uses <em>eight</em> groupings of four <em>hex</em> digits, colon-separated.
For example, <code>2607:f0d0:1002:0051:0000:0000:0000:0004</code>.
That’s… very unweildy, so we have a few shortening rules.
Any zeros that <em>lead</em> the droup can be dropped, giving us this: <code>2607:f0d0:1002:51:0:0:0:4</code>.
And since <em>that</em> is still repetitive, you can replace <em>exactly one</em> sequence of <em>more than one group</em> of all zeros with an empty: <code>2607:f0d0:1002:51::4</code>.
For the record this is why the loopback address is <code>::1</code>.
The full address is <code>0000:0000:0000:0000:0000:0000:0000:0001</code>.
Even with those methods, they’re still <em>much</em> longer, harder to remember, and harder to even say than IPv4 addresses.</p>
<h2 id="urls">URLs</h2>
<p>And remember that this address violates the URL spec, since the <code>:</code> character is specifically to be used to separate the <em>host</em> portion (e.g., <code>google.com</code>) from the <em>port</em> to connect to (assuming nonstandard).
As an example, I can reach my torrent client via <code>http://192.168.5.43:9091</code>.
See that <code>:</code> there?
Because Transmission listens on port 9091, not port 80.
How do we fix this?
Well, by breaking it again, naturally.
To connect to a raw IPv6 address, you wrap it in square brackets.
To connect to <code>2607:f0d0:1002:51::4</code> directly, that’s <code>http://[2607:f0d0:1002:51::4]/</code>
<strong>Why is this a thing?!</strong>.</p>
<h2 id="dns">DNS</h2>
<p>okay, admittedly, IPv6 kinda relies on DNS since… just about everything uses DNS, and of course, actual names are more memorable than 32 hexadecimal digits, but DNS isn’t magic.
Unless you have your own DNS server (actually not that hard) that’s configured, you’re still manually typing addresses.
Of course if you have, say, pfSense managing your network, every static DHCP lease will be registered in DNS, but it has to take a DHCP lease.
And if this device doesn’t… well, I hope you don’t mind typing that out by hand to connect so you can configure it.</p>
<p>Even better, rDNS.
rDNS, or Reverse DNS, is where a DNS query is performed <em>with an IP address</em> that returns the hostname associated, in a <code>PTR</code> record.
For example, the IPv4 that <code>google.com</code> resolves to, <code>216.58.192.142</code>, can be queried as <code>142.192.58.216.in-addr.arpa</code> to get it’s “real” name, a <code>PTR</code> record for <code>ord36s01-in-f142.1e100.net</code>.
With <code>dig</code>, specifying a <code>-x</code> and then the IP will convert it to the correct format.
And if you look close, the query name is the IP, backwards, with <code>in-addr.arpa</code> at the front.
It’s backwards because of the hierarchical nature of DNS, which runs right to left, the opposite of IPs.
Of course, there’s also rDNS for IPv6:</p>
<div><pre><code data-lang="plaintext">$ dig -x 2607:f0d0:1002:51::4

; &lt;&lt;&gt;&gt; DiG 9.11.3-1ubuntu1.12-Ubuntu &lt;&lt;&gt;&gt; -x 2607:f0d0:1002:51::4
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 22821
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 65494
;; QUESTION SECTION:
;4.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1.5.0.0.2.0.0.1.0.d.0.f.7.0.6.2.ip6.arpa. IN PTR

;; ANSWER SECTION:
4.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1.5.0.0.2.0.0.1.0.d.0.f.7.0.6.2.ip6.arpa. 3600 IN PTR 4000.0000.0000.0000.1500.2001.0d0f.7062.ip6.static.sl-reverse.com.

;; Query time: 731 msec
;; SERVER: 127.0.0.53#53(127.0.0.53)
;; WHEN: Sun Aug 30 00:52:50 EDT 2020
;; MSG SIZE  rcvd: 180
</code></pre></div><p>That is <em><strong>insane.</strong></em>
The IPv6 rDNS <abbr title="Top Level Domain">TLD</abbr>
is just <code>ip6.arpa</code>, and the IP part is…
every single hex digit, reversed.</p>
<div><pre><code data-lang="plaintext">2607f0d0100200510000000000000004
4000000000000000150020010d0f7062
</code></pre></div>
<p>One of the core pillars of IPv6 is that most of the processing of traffic should happen at the endpoints — routers don’t do much besides read, and forward, with very little actual data processing.
The IPv6 header while being <em>gargantuan</em> in comparison (because the giant addresses), is also much simpler.
A fixed version code (6), the traffic class (<abbr title="Differentiated Services">DiffServ</abbr>
+ <abbr title="Explicit Congestion Notification">ECN</abbr>
), a <em>flow label</em> which is effectively a random value that’s constant for every packet that’s part of the same logical connection, length, type of next header, and a TTL (then addresses, obviously).
That is <em>it</em>.
The IPv4 header contains 13 fields plus optional sections, and the IPv6 header contains a flat 8.
Of course, you may actually need other details, and that’s where the <em>next header</em> field comes in.
Instead of packing all sorts of options into the standard, global header, IPv6 uses additional header <em>extensions</em> that can get tacked on one after another to provide that information, say for fragmentation or IPsec.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>
The value in the next header field identifies what’s going to come next, and the final header in the line will use this field to indicate the contained protocol, be it TCP, UDP, or something else.</p>
<p>Also note there’s no checksum anymore.
I mean, just about every device uses Ethernet, which has a Frame Check Sequence (FCS), UDP has a checksum option, TCP has a required checksum…
If we want to simply packet processing, drop the sum.
And really, it does make sense, in a way.
Even without that one, that means that most programs have two checksums: the Ethernet FCS as the frame gets transmitted point to point, and the transport layer checksum, making sure the entire packet is still valid.
Also, the IPv4 checksum also included the TTL (max number of hops in the path before the packet is dropped), meaning that at <em>every stop</em> along the way, the checksum had to be recalculated.</p>
<p>As a final point, this also does bring a change to another protocol: UDP.
With IPv4, the UDP checksum field can (and often would) be left blank as all zeros, meaning “no checksum”.
In IPv6, this is now disallowed, and a all zero checksum will still be checked… and then found invalid.
All UDP packets over IPv6 <em>must</em> have a valid checksum calculated.</p>

<p>So every link between devices has an MTU, the Maximum Transmission Unit.
For normal Ethernet links, minus the frame overhead, this is 1500 bytes.
If your equipment supports jumbo frames, that’s closer to 9000 bytes.
Well not all links are equal.
Some devices might have a high-MTU link on one end, and a lower MTU link on the other.
For example, my router might support jumbo frames internally, but the WAN side doesn’t allow that.
To deal with, this, we have <em>fragmentation</em>.</p>
<p>If a router is unable to forward a frame due to MTU differences, it will, if allowed, split the packet into multiple chunks, using the More Fragments flag and the Fragment Offset field of the IPv4 header, and send the packet in multiple frames piece by piece, which the other end can reassemble.
Note that I said “if allowed.”
There is a Don’t Fragment flag in the IPv4 header, and if this is set by the sending device, a router that cannot support a packet of that size will send back an <abbr title="Internet Control Message Protocol">ICMP</abbr>
“packet too big” message which bounces back along the chain.
Any node in the network path can perform this, meaning that for sending data, the only MTU you care about is the MTU of the device you’re directly connected …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://teknikaldomain.me/post/ipv6-is-a-total-nightmare/">https://teknikaldomain.me/post/ipv6-is-a-total-nightmare/</a></em></p>]]>
            </description>
            <link>https://teknikaldomain.me/post/ipv6-is-a-total-nightmare/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24994587</guid>
            <pubDate>Thu, 05 Nov 2020 00:37:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anatomy of a Binary Executable]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24994522">thread link</a>) | @WalterSobchak
<br/>
November 4, 2020 | https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/ | <a href="https://web.archive.org/web/*/https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <div>
                <h3>Anatomy of a Binary Executable</h3>
                
                    <p><em></em>
                        <span>Wed, Nov 4, 2020</span>
                        <em></em>
                        <span>23-minute read</span>
                    </p>
                
            </div>

            <p>Even though I’ve developed software for a number of years now, there’s one question that has always been in the back of my mind and I haven’t had the time or patience to really answer, until now: <strong>What <em>is</em> a binary executable anyways?</strong></p>
<p>For this example, I wrote a brutally simple Rust program that includes a function “<code>sum</code>” to add two integers together, and am invoking it from <code>main()</code>:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>main</span>() {
    println<span>!</span>(<span>"{}"</span>, sum(<span>5</span>, <span>8</span>));
}

<span>pub</span> <span>fn</span> <span>sum</span>(a: <span>i32</span>, b: <span>i32</span>) -&gt; <span>i32</span> {
    a <span>+</span> b
}
</code></pre></div><p>My Rust code is always structured the <a href="https://doc.rust-lang.org/cargo/guide/project-layout.html">“cargo way”</a>, so I can compile my program by running <code>cargo build</code>, and this will produce a binary for me within the <code>target/debug/</code> directory. I have named my crate <code>rbin</code>, so this is the name of the binary that is created at this location:</p>
<div><pre><code data-lang="bash">~$ cargo build
   Compiling rbin v0.1.0 <span>(</span>/home/mierdin/Code/rbin<span>)</span>
    Finished dev <span>[</span>unoptimized + debuginfo<span>]</span> target<span>(</span>s<span>)</span> in 0.15s

~$ ls -lha target/debug/rbin
-rwxrwxr-x <span>2</span> mierdin mierdin 3.1M Nov  <span>3</span> 22:46 target/debug/rbin
</code></pre></div><p>These days, it’s really easy to take such questions for granted, but if you’re curious, you may be asking:</p>
<blockquote>
<p>“But what <strong>is</strong> that file?”</p>
</blockquote>
<p>I mean we all generally know that it’s an “executable”, in that we run it and our program happens. But what does that mean? What is contained in that file that means our computer automatically just <strong>knows</strong> how to run it? And how is it possible that a program with 7 lines of code can take up over 3 megabytes of disk space?!?</p>
<p>It turns out that in order to create an executable for this ridiculously simple program, the Rust compiler must include quite a bit of additional software to make it possible.</p>

<p>Well, it turns out there is a widely accepted format for these things, called the <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">“Executable and Linkable Format”</a>, or ELF!</p>
<blockquote>
<p>Note that I won’t be comprehensively covering ELF here (there are plenty of other resources, many of which I’ll link to) - rather this is an exploration of what goes into a Rust binary with the simplest, default settings, and some observations about what seems interesting to me.</p>
</blockquote>
<p>ELF is a well-known, popular format, especially in the world of Linux, but there are plenty of others. <a href="https://en.wikipedia.org/wiki/Comparison_of_executable_file_formats">Operating systems like Windows and macOS each have their own format</a>, which is a big reason why, when you’re compiling (or simply downloading) software, you have to specify the operating system you want to run it on. This is true despite the fact that the underlying machine code that executes your program may be the same on all of them (e.g. <code>x86_64</code>).</p>
<p>An <strong>exceptional</strong> visual breaking down the ELF format can be found at the link to the ELF wikipedia page above, I have found myself constantly referring back to it while writing this post:</p>
<p><a title="Ange Albertini / CC BY (https://creativecommons.org/licenses/by/1.0)" href="https://oswalt.dev/assets/2020/11/elf.png"><img width="512" alt="ELF Executable and Linkable Format diagram by Ange Albertini" src="https://oswalt.dev/assets/2020/11/elf.png"></a>
</p>
<p>Commonly, executable formats like this specify a <a href="https://en.wikipedia.org/wiki/File_format#Magic_number">magic number</a> right at the beginning of the file, so that the format can be easily identified. This occupies the first four bytes in the <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#File_header">file header</a>. This is a very important field, because unless we can first identify an ELF file appropriately, we can’t reasonably expect to do anything “ELF-y” with it. We know where certain bits of information <strong>should</strong> be in an ELF file, but we first must identify using these bytes that this is what we can expect.</p>
<p>The <code>readelf</code> utility is extremely useful for printing all kinds of useful metadata and related tables of information contained within an ELF file. However, this utility expects - naturally - that the file being read is actually an ELF file, and even provides a helpful hint that the expected “magic bytes” for a non-ELF file aren’t set appropriately when used on a non-ELF file, so it doesn’t attempt to read the rest:</p>
<div><pre><code data-lang="bash">~$ readelf -l .gitignore

readelf: Error: Not an ELF file - it has the wrong magic bytes at the start
</code></pre></div><p>Once identified, the entire rest of the file can be identified using <strong>byte offsets</strong> (that is, the number of bytes from zero).</p>
<blockquote>
<p>For those that are accustomed to looking at network packet captures, this should all sound very familiar to you, as this is exactly how we know where certain fields are located in a packet header. <a href="https://en.wikipedia.org/wiki/Ethernet_frame">Ethernet frames</a> have a predictable preamble and start-of-frame delimiter. Ethernet also has a field called the “Ethertype”, which provides a clue as to what protocol is contained within the Ethernet frame (which allows computers to then parse those field as well). Just like Ethernet has a standard set of byte offsets that indicate where the various fields should be represented, the ELF format specifies its own offsets for all of the fields providing useful identifying and execution information in the <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#File_header">file header</a>, which then point to other important locations within the file.</p>
</blockquote>
<p>There’s all kinds of useful information in this header, but in particular, the <code>e_entry</code> field  in the file header points to the offset location from where the execution should start. This is the “entry point” for the program. We’ll definitely be following this down the rabbit hole in a little bit.</p>
<p>We can again use <code>readelf</code>, this time on a proper ELF file (our Rust program), and also using the <code>-h</code> flag to show the file header:</p>
<div><pre><code data-lang="bash">~$ readelf -h target/debug/rbin

ELF Header:
  Magic:   7f <span>45</span> 4c <span>46</span> <span>02</span> <span>01</span> <span>01</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> 
  Class:                             ELF64
  Data:                              2<span>'</span>s complement, little endian
  Version:                           <span>1</span> <span>(</span>current<span>)</span>
  OS/ABI:                            UNIX - System V
  ABI Version:                       <span>0</span>
  Type:                              DYN <span>(</span>Shared object file<span>)</span>
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0x5070
  Start of program headers:          <span>64</span> <span>(</span>bytes into file<span>)</span>
  Start of section headers:          <span>3195368</span> <span>(</span>bytes into file<span>)</span>
  Flags:                             0x0
  Size of this header:               <span>64</span> <span>(</span>bytes<span>)</span>
  Size of program headers:           <span>56</span> <span>(</span>bytes<span>)</span>
  Number of program headers:         <span>12</span>
  Size of section headers:           <span>64</span> <span>(</span>bytes<span>)</span>
  Number of section headers:         <span>42</span>
  Section header string table index: <span>41</span>
</code></pre></div><p>So, the “magic number” lets us parse at least the rest of the file header, which contains not only information about the file, but byte-offset locations for other important portions of the file. One of these is the “Start of program headers”, which starts after 64 bytes.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#Program_header">program header table</a> contains information that allows the operating system to allocate memory and load the program. This is also referred to as a <a href="http://www.tldp.org/LDP/LG/issue23/flower/psimage.html">process image</a>. You can think of it as a list of “instructions” that tell the system to do various things with chunks of memory in order to prepare to execute this program.</p>
<p>The <code>readelf</code> utility also allows us to read the program headers using the <code>-l</code> flag:</p>
<div><pre><code data-lang="bash">~$ readelf -l target/debug/rbin

Elf file type is DYN <span>(</span>Shared object file<span>)</span>
Entry point 0x5070
There are <span>12</span> program headers, starting at offset <span>64</span>

Program Headers:
  Type           Offset             VirtAddr           PhysAddr
                 FileSiz            MemSiz              Flags  Align
  PHDR           0x0000000000000040 0x0000000000000040 0x0000000000000040
                 0x00000000000002a0 0x00000000000002a0  R      0x8
  INTERP         0x00000000000002e0 0x00000000000002e0 0x00000000000002e0
                 0x000000000000001c 0x000000000000001c  R      0x1
      <span>[</span>Requesting program interpreter: /lib64/ld-linux-x86-64.so.2<span>]</span>
  LOAD           0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000004ed8 0x0000000000004ed8  R      0x1000
  LOAD           0x0000000000005000 0x0000000000005000 0x0000000000005000
                 0x0000000000030571 0x0000000000030571  R E    0x1000
  LOAD           0x0000000000036000 0x0000000000036000 0x0000000000036000
                 0x000000000000be44 0x000000000000be44  R      0x1000
  LOAD           0x0000000000042520 0x0000000000043520 0x0000000000043520
                 0x0000000000002b18 0x0000000000002cf8  RW     0x1000
  DYNAMIC        0x0000000000044740 0x0000000000045740 0x0000000000045740
                 0x0000000000000230 0x0000000000000230  RW     0x8
  NOTE           0x00000000000002fc 0x00000000000002fc 0x00000000000002fc
                 0x0000000000000044 0x0000000000000044  R      0x4
  TLS            0x0000000000042520 0x0000000000043520 0x0000000000043520
                 0x0000000000000000 0x00000000000000d8  R      0x20
  GNU_EH_FRAME   0x000000000003aa8c 0x000000000003aa8c 0x000000000003aa8c
                 0x0000000000000d84 0x0000000000000d84  R      0x4
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
  GNU_RELRO      0x0000000000042520 0x0000000000043520 0x0000000000043520
                 0x0000000000002ae0 0x0000000000002ae0  R      0x1

 Section to Segment mapping:
  Segment Sections...
   <span>00</span>     
   <span>01</span>     .interp 
   <span>02</span>     .interp .note.gnu.build-id .note.ABI-tag .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt 
   <span>03</span>     .init .plt .plt.got .text .fini 
   <span>04</span>     .rodata .debug_gdb_scripts .eh_frame_hdr .eh_frame .gcc_except_table 
   <span>05</span>     .init_array .fini_array .data.rel.ro .dynamic .got .data .bss 
   <span>06</span>     .dynamic 
   <span>07</span>     .note.gnu.build-id .note.ABI-tag 
   <span>08</span>     .tbss 
   <span>09</span>     .eh_frame_hdr 
   <span>10</span>     
   <span>11</span>     .init_array .fini_array .data.rel.ro .dynamic .got 
</code></pre></div><p>Each <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format#Program_header">program header type</a> does something different to a chunk of memory (segment). Next to each header can be found two 64-bit (this is a 64 bit ELF after all) hexidecimal values. As indicated at the top of the header output, the top value is the memory offset of the segment that the header refers to (where it is located). The value below that is the size of that particular segment in the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/">https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/</a></em></p>]]>
            </description>
            <link>https://oswalt.dev/2020/11/anatomy-of-a-binary-executable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24994522</guid>
            <pubDate>Thu, 05 Nov 2020 00:26:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Roam-native books: a new publishing format]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24993668">thread link</a>) | @dellannaluca
<br/>
November 4, 2020 | https://www.roambrain.com/roam-native-books/ | <a href="https://web.archive.org/web/*/https://www.roambrain.com/roam-native-books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4770">
														
							
														
							
														
							<div>
															<div>
									<p>I have just published the first Roam-native book, or “rBook” for short. Its title is <a href="https://gumroad.com/l/ergodicity"><em>Ergodicity</em></a>, and in addition to the traditional ebook formats of pdf, ePub and mobi, it is also available in Roam json format.</p>
<p>I did it because I enjoy exploring new ideas non-linearly on the internet, and I wanted to do the same with books. Readers should be able to jump between concepts, go deep on what interests them, and skim through the rest. They should be able to take notes, and their notes should become an organic part of the text.</p>
<p>I knew that books could be more. I just didn’t know how. Until recently, there wasn’t a technology that made it possible. Then came Roam Research. I remember that, within the first ten minutes of using it, I realized that it was what I’ve been looking for.</p>
<p>rBooks are very different from just copying and pasting the text of a book into Roam. They still have a table of contents with the usual structure in numbered chapters, but they can do much more.</p>
<p>First of all, most of their information is contained in pages describing concepts. The relevant blocks are then embedded in chapter pages. You still get a “linear story,” but you can break free from it at any point. You can explore the current topic deeper, and from there, jump to related topics, following your interests.</p>
<p><a href="https://www.roambrain.com/wp-content/uploads/luca_dellanna_ergodicity.png"><img loading="lazy" src="https://www.roambrain.com/wp-content/uploads/luca_dellanna_ergodicity-1013x1024.png" alt="" width="1013" height="1024" srcset="https://www.roambrain.com/wp-content/uploads/luca_dellanna_ergodicity-1013x1024.png 1013w, https://www.roambrain.com/wp-content/uploads/luca_dellanna_ergodicity-594x600.png 594w, https://www.roambrain.com/wp-content/uploads/luca_dellanna_ergodicity-1080x1092.png 1080w, https://www.roambrain.com/wp-content/uploads/luca_dellanna_ergodicity-45x45.png 45w, https://www.roambrain.com/wp-content/uploads/luca_dellanna_ergodicity.png 1500w" sizes="(max-width: 1013px) 100vw, 1013px"></a></p>
<p>As another advantage, you have the option to import the book into your own Roam graph. For decades we thought of books as “downloading information into your brain,” but never before the metaphor has been so literal. Because information in a rBook is structured into concept pages, it can neatly integrate into your pre-existing graph, keeping all the connections within the book and eventually linking to information pre-existing in your graph. Moreover, if you already have notes on the same topic, the information from the book will automatically append itself to them.</p>
<p>As a third advantage, examples and thought experiments are all tagged by topic (e.g., #example-business) so that you can quickly discover how a topic can apply to a particular field.</p>
<p><a href="https://www.roambrain.com/wp-content/uploads/luca_dellanna_examples.png"><img loading="lazy" src="https://www.roambrain.com/wp-content/uploads/luca_dellanna_examples.png" alt="" width="750" height="255" srcset="https://www.roambrain.com/wp-content/uploads/luca_dellanna_examples.png 750w, https://www.roambrain.com/wp-content/uploads/luca_dellanna_examples-700x238.png 700w" sizes="(max-width: 750px) 100vw, 750px"></a></p>
<p>These are just three of the many innovative features of rBooks. I can only wonder with amazement about the possibilities that Roam-native books offer over traditional eBooks. This is the current frontier of learning, and we are the pioneers.</p>
<p>I’ve already published 6 books, but I’ve never been this excited to release a new one. I hope you’ll all enjoy it. (<a href="https://gumroad.com/l/ergodicity">It’s here</a>.)</p>
																	</div>
														</div>
														

																				</article></div>]]>
            </description>
            <link>https://www.roambrain.com/roam-native-books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24993668</guid>
            <pubDate>Wed, 04 Nov 2020 22:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to Bayes’ theorem for intermediate developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24993637">thread link</a>) | @filiph
<br/>
November 4, 2020 | https://selfimproving.dev/bayes-theorem.html | <a href="https://web.archive.org/web/*/https://selfimproving.dev/bayes-theorem.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>

    <header>
      <div>
        <table>
          <tbody><tr>
            <th><a href="https://selfimproving.dev/">The Self-Improving Developer</a></th>
            <th>
              <a href="https://selfimproving.dev/hashing.html">&nbsp;←&nbsp;</a>
              <a href="https://selfimproving.dev/backmatter.html">&nbsp;→&nbsp;</a>

            </th>
          </tr>
          <tr>
            <td colspan="2">
              You’ve taught yourself variables, classes, functions, objects.
              What next?
            </td>
          </tr>
        </tbody></table>
      </div>

        <p>
            Chapter

          15
        </p>
        
    </header>

    <p>You have a database of notes and you want to build a system that intelligently assignes tags to the notes. For example, you write a note like this:</p>
<div><pre>I found out today that
  we're going to have a baby!
  I am really excited.
</pre></div>
<p>And the system autosuggests adding <code>#life</code> and <code>#baby</code>.</p>
<p>One easy way to do this is through the so-called Bayes’ theorem. By the end of this article, you’ll know what that is and how to use it.</p>
<p>But before we get there, let’s first make sure you’re really expecting that baby! (I promise this is going to be relevant.)</p>
<h2><a href="#probability-of-babies" name="probability-of-babies"><small>15 . 1</small> Probability of babies</a></h2>
<p>Pregnancy tests aren’t perfect. They can tell you you’re expecting when you’re not, and they can tell you you’re not expecting when you are. In other words, they can be wrong in two ways: there can be <em>false positives</em> (test says yes, but it’s incorrect) and there can be <em>false negatives</em> (test says no, but it’s incorrect).</p><table><thead><tr><th></th><th></th><th>Test says YES</th><th>Test says NO</th></tr></thead><tbody><tr><td>Actual baby</td><td>👶</td><td>True positive</td><td>False negative</td></tr><tr><td>No baby</td><td>◯</td><td>False positive</td><td>True negative</td></tr></tbody></table>
<p>Although they’re not perfect, pregancy tests still do have value, of course. They are <em>mostly</em> correct. Let’s say they correctly identify a pregnancy 93% of the time, and correctly identify non-pregnancy 95% of the time.</p><table><thead><tr><th></th><th></th><th>Test says YES</th><th>Test says NO</th></tr></thead><tbody><tr><td>Actual baby</td><td>👶</td><td>93%</td><td>7%</td></tr><tr><td>No baby</td><td>◯</td><td>5%</td><td>95%</td></tr></tbody></table>
<p>So, if you (or your partner) come out of the bathroom with a test result that says YES, what is the probability that you’re really having a baby?</p>
<p>You may be tempted to blurt out 93%. But not so fast.</p>
<h2><a href="#prevalence-of-babies" name="prevalence-of-babies"><small>15 . 2</small> Prevalence of babies</a></h2>
<p>Forget the quality of the test for a moment. What is the probability that, when you’re taking a pregnancy test, you’re actually pregnant? Note that we’re not talking about the precision of any device here. We’re talking about how likely it is you’re pregnant, in reality, as you’re entering the bathroom with the little testing device in your hand.</p>
<p>Now, look, I can’t find any good data on this, so I’ll just go ahead and estimate. My guess is that only 10% of the women who decide to take a pregnancy test are pregnant at the time.</p>

<p>To find the probabilities of the four different outcomes (true positive, true negative, false positive, false negative) among all the women who take a pregnancy test, we just need to multiply:</p><table><thead><tr><th></th><th></th><th>Test says YES</th><th>Test says NO</th></tr></thead><tbody><tr><td>Actual baby (10%)</td><td>👶</td><td>93%&nbsp;⨯&nbsp;10%&nbsp;=&nbsp;<strong>9.3%</strong></td><td>7%&nbsp;⨯&nbsp;10%&nbsp;=&nbsp;<strong>0.7%</strong></td></tr><tr><td>No baby (90%)</td><td>◯</td><td>5%&nbsp;⨯&nbsp;90%&nbsp;=&nbsp;<strong>4.5%</strong></td><td>95%&nbsp;⨯&nbsp;90%&nbsp;=&nbsp;<strong>85.5%</strong></td></tr></tbody></table>
<p>It might not be immediately obvious, but the four numbers in bold add up to 100%. That makes sense: if you’re taking a pregnancy test, you will obviously fall into one of these four categories.</p>
<p>Note the difference:</p>
<ul>
<li>There is a 93% probability that—<em>given that you are having a baby</em>—the test says YES. This is about the quality of the test.</li>
<li>There is a 9.3% probability that a random test-taking woman has a baby <em>and</em> her test says YES. This is about one of the four different outcomes of pregnancy test-taking.</li>
</ul>
<p>The first probability is higher because it talks about women who we know to be pregnant. The second probability is lower because it talks about any test-taking woman.</p>
<h2><a href="#total-probability" name="total-probability"><small>15 . 3</small> Total probability</a></h2>
<p>So, once again, if you come out of the bathroom with a test result that says YES, what is the probability that you’re really having a baby?</p>

<p>I’ll repeat the table from above here, except now it doesn’t show percentages, and instead shows whole numbers. All I did was multiply the percentages by 1000, so that instead of looking at fractions, you can imagine four groups of women. I think it makes things a bit more intuitive.</p><table><thead><tr><th></th><th></th><th>Test says YES</th><th>Test says NO</th></tr></thead><tbody><tr><td>Actual baby</td><td>👶</td><td>93</td><td>7</td></tr><tr><td>No baby</td><td>◯</td><td>45</td><td>855</td></tr></tbody></table>
<p>If you want, you can try to figure it out yourself now. The question, once again, is: “Given that your test result says YES, what is the probability that you’re really having a baby?”</p>
<p>…</p>
<p><strong>Solution:</strong> We take the group of women with a YES. That is to say, the 93 women with the true positive test, and the 45 women with the false positive test. That’s 138 women.</p>
<p>Out of these 138 women, only 93 are actually having a baby. That is to say, 93 out of 138 really are pregnant.</p>
<p>93 divided by 138 is about 67%. That is to say, holding a test result that says YES, the probability you’re really pregnant is only 67%.</p>

<h2><a href="#congrats" name="congrats"><small>15 . 4</small> Congrats!</a></h2>
<p><del>It’s a girl!</del> You just gained an intuitive understanding of Bayes’ theorem. It’s a way to convert results of a test (e.g. pregnancy strip) into the real probability of an event (e.g. pregnancy).</p>
<p>Here’s the mathematical formula:</p>
<p><img src="https://selfimproving.dev/images/bayes-pregnancy.svg" alt="{\displaystyle P(A|B)={\frac {P(B|A) \cdot P(A)}{P(B|A) \cdot P(A)+P(B|\neg A) \cdot P(\neg A)}}}"></p><!-- 
  * LaTex: {\displaystyle P(A|B)={\frac {P(B|A) \cdot P(A)}{P(B|A) \cdot P(A)+P(B|\neg A) \cdot P(\neg A)}}}
  * converted with https://viereck.ch/latex-to-svg/
  * edited in Sketch
-->
<p>You can read it like this:</p>
<ul>
<li>The probability that event A occurs given event B<br>
is equal to</li>
<li>the numerator, which is:
<ul>
<li>the probability that event B occurs given event A<br>
times</li>
<li>the probability that event A occurs  </li>
</ul>
</li>
<li>divided by the denominator, which is:
<ul>
<li>the probability that event B occurs given event A<br>
times</li>
<li>the probability that event A occurs<br>
plus</li>
<li>the probability that event B occurs given A <em>didn’t</em> occur<br>
times</li>
<li>the probability that event A <em>didn’t</em> occur.</li>
</ul>
</li>
</ul>
<p>Now replace <code>B</code> with “pregnancy test says YES” and <code>A</code> with “you’re pregnant”.</p><!-- TODO: add the formula with annotations, e.g. P(A) is "probability a test-taking woman is pregnant" -->
<h2><a href="#the-name" name="the-name"><small>15 . 5</small> The name</a></h2>
<p>The theorem is named after Reverend Thomas Bayes, an English Presbyterian minister. His work was published in 1763, so this math is well over 250 years old.</p>
<p><img src="https://selfimproving.dev/images/Thomas_Bayes.jpg" alt="Thomas Bayes"></p>

<p>When we hear “Bayes” these days, it’s either because of the theorem above, or because of a related idea of Bayesian probability. In this approach, probabilities aren’t just frequencies (e.g. “how many people are over 60 years old?”) but can also be strengths of beliefs (e.g. “how much do I believe we’ll finish the project in time?”).</p>
<h2><a href="#automatic-tagging" name="automatic-tagging"><small>15 . 6</small> Automatic tagging</a></h2>
<p>Which brings us back to our original problem. We have a note-taking app with 1000 notes that are already tagged by the user. We want a system that automatically suggests tags (like <code>#baby</code>) for new notes based on what’s written in them (like <code>"Bought a crib today!"</code>). </p>
<p>We’ll take words in the text, and we’ll use Bayes to see how probable it is that, given those words, a tag applies. For example, when there’s <code>"crib"</code> in the text, how probable is it that the tag <code>#baby</code> applies?</p><table><thead><tr><th>Test</th><th></th><th>Real event</th></tr></thead><tbody><tr><td>Pregnancy test says YES</td><td>?→</td><td>Pregnancy</td></tr><tr><td>One of the words in the text is <code>"crib"</code></td><td>?→</td><td>Tag <code>#baby</code> applies</td></tr></tbody></table><!-- TODO: rebuilt into a drawing with arrows, so that it doesn't look like a table -->
<p>It might not seem like it at first but this is essentially the same problem as above. We have a test, and we want to see how indicative it is of a real event.</p>
<p>Once again, if you’re up for it, you can try to figure it out yourself. Try to apply Bayes’ theorem to solve auto-tagging. To scope this down, don’t try to solve the whole algorithm at once. Just try to figure out a single pair of word &amp; tag. In other words, find out what’s the probability of the tag <code>#baby</code> given the word <code>"crib"</code> in the text. You might want to write things down.</p>
<p>If you’re up for it, stop reading now and go figure it out.</p>
<p>…</p>
<p><strong>Solution:</strong> We want to find the probability that a note should be tagged with <code>#baby</code> <em>given that</em> it contains the word <code>"crib"</code>. That’s our <em>P(A|B)</em>. Then, using the formula:</p>
<ul>
<li>The probability that a note is tagged with <code>#baby</code> <em>given that</em> it contains the word <code>"crib"</code><br>
is equal to</li>
<li>the numerator, which is:
<ul>
<li>the probability that a note contains the word <code>"crib"</code>  <em>given that</em> it’s tagged with <code>#baby</code><br>
times</li>
<li>the probability that a note is tagged with <code>#baby</code>  </li>
</ul>
</li>
<li>divided by the denominator, which is:
<ul>
<li>the probability that a note contains the word <code>"crib"</code> <em>given that</em> it’s tagged with <code>#baby</code><br>
times</li>
<li>the probability that a note is tagged with <code>#baby</code><br>
plus</li>
<li>the probability that a note contains the word <code>"crib"</code> given that it’s <em>not</em> tagged with <code>#baby</code><br>
times</li>
<li>the probability that a note is <em>not</em> tagged with <code>#baby</code>.</li>
</ul>
</li>
</ul><!-- TODO: replace with an annotation of the formula -->
<p>In a note-taking app, we know all those values on the right side of the equation. </p>
<p>The following code is just a transcript of the steps above into a programming language. It’s here in case you prefer reading code. No need to read through it otherwise.</p>
<div><pre><span>// All of the user's notes.</span>
<span>var</span> <span>notes</span> = <span>getAllNotes</span>();

<span>// Finding the sets we need.</span>
<span>var</span> <span>notesTaggedWithBaby</span> = <span>notes</span>
    .<span>where</span>(
        (<span>note</span>) =&gt; <span>note</span>.<span>hasTag</span>('#<span>baby</span>'))
    .<span>toSet</span>();
<span>var</span> <span>notesWithCrib</span> = <span>notes</span>
    .<span>where</span>(
        (<span>note</span>) =&gt; <span>note</span>.<span>hasWord</span>('<span>crib</span>'))
    .<span>toSet</span>();
<span>var</span> <span>notesNotTaggedWithBaby</span> =
    <span>notes</span>.<span>difference</span>(<span>notesTaggedWithBaby</span>);
<span>var</span> <span>notesWithCribTaggedWithBaby</span> =
    <span>notesTaggedWithBaby</span>
        .<span>intersection</span>(<span>notesWithCrib</span>);
<span>var</span> <span>notesWithCribNotTaggedWithBaby</span> =
    <span>notesNotTaggedWithBaby</span>
        .<span>intersection</span>(<span>notesWithCrib</span>);

<span>// Computing the numerator.</span>
<span>var</span> <span>ratioOfNotesWithCribTaggedWithBaby</span> =
    <span>notesWithCribTaggedWithBaby</span>.<span>length</span> /
        <span>notesWithCrib</span>.<span>length</span>;
<span>var</span> <span>ratioOfNotesTaggedWithBabyInGeneral</span> =
    <span>notesTaggedWithBaby</span>.<span>length</span> / <span>notes</span>.<span>length</span>;
<span>var</span> <span>numerator</span> =
    <span>ratioOfNotesWithCribTaggedWithBaby</span> *
        <span>ratioOfNotesTaggedWithBabyInGeneral</span>;

<span>// Computing the denominator.</span>
<span>var</span> <span>ratioOfNotesWithCribNotTaggedWithBaby</span> =
    <span>notesWithCribNotTaggedWithBaby</span>.<span>length</span> /
        <span>notesNotTaggedWithBaby</span>.<span>length</span>;
<span>var</span> <span>ratioOfNotesNotTaggedWithBabyInGeneral</span> =
    <span>notesNotTaggedWithBaby</span>.<span>length</span> /
        <span>notes</span>.<span>length</span>;
<span>var</span> <span>denominator</span> =
    <span>ratioOfNotesWithCribTaggedWithBaby</span> *
            <span>ratioOfNotesTaggedWithBabyInGeneral</span> +
        <span>ratioOfNotesWithCribNotTaggedWithBaby</span> *
            <span>ratioOfNotesNotTaggedWithBabyInGeneral</span>;

<span>var</span> <span>result</span> = <span>numerator</span> / <span>denominator</span>;
<span>print</span>(<span>result</span>);
</pre></div>
<p>Actually, there is one other reasons to read the code: to find the divide-by-zero bug that we’d need to deal with in a real project. I’ll leave that as an exercise to you. Where could the code break and how would you prevent that?</p>
<p>Putting aside trivialities such as division by zero, we’re done. Using this code, we can look at words in a new note and compute the probability that the note should be tagged with a particular tag.</p>
<div><pre>$ bayes "crib" "#baby"
76.92%

$ bayes "boss" "#work"
100.00%

$ bayes "today" "#work"
34.78%
</pre></div>
<p>As more notes are added and tagged, the system learns automatically. Today, there are no <code>#baby</code>-tagged notes containing the word <code>diaper</code> but trust me: there will be a lot of them in a few …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://selfimproving.dev/bayes-theorem.html">https://selfimproving.dev/bayes-theorem.html</a></em></p>]]>
            </description>
            <link>https://selfimproving.dev/bayes-theorem.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24993637</guid>
            <pubDate>Wed, 04 Nov 2020 22:20:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New study finds psilocybin greatly and quickly relieves depression]]>
            </title>
            <description>
<![CDATA[
Score 326 | Comments 171 (<a href="https://news.ycombinator.com/item?id=24993519">thread link</a>) | @neom
<br/>
November 4, 2020 | https://www.psychnewsdaily.com/new-study-psilocybin-magic-mushrooms-relieves-depression/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/new-study-psilocybin-magic-mushrooms-relieves-depression/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4933" role="main"><div><div><div><p>A <a rel="noreferrer noopener" href="https://jamanetwork.com/journals/jamapsychiatry/fullarticle/10.1001/jamapsychiatry.2020.3285?guestAccessKey=29ac3052-6203-4fb4-b1e2-d9dda5988445&amp;utm_source=For_The_Media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=110420" target="_blank">new study</a> of 24 adults with major depression finds that two doses of the psychedelic substance psilocybin, given with supportive psychotherapy, produced rapid and large reductions in depressive symptoms. Most of the participants showed improvement, and half achieved remission at the four-week follow-up.<span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Psilocybin" target="_blank">Psilocybin</a> is a compound found in so-called “magic mushrooms.” It produces visual and auditory hallucinations, and profound changes in consciousness, over a period of several hours.</p><p>The findings appeared on November 4 in&nbsp;<em><a href="https://jamanetwork.com/journals/jamapsychiatry" target="_blank" rel="noreferrer noopener">JAMA Psychiatry</a></em>.</p><h2>Effect of psilocybin 4x stronger than traditional antidepressants</h2><p>“The magnitude of the effect we saw was about four times larger than what clinical trials have shown for traditional antidepressants on the market,” said co-author <a rel="noreferrer noopener" target="_blank" href="https://hopkinspsychedelic.org/davis">Alan Davis</a> of Johns Hopkins University.</p><p>As the paper explains, “the effect sizes reported in this study were approximately 2.5 times greater than the effect sizes found in psychotherapy, and more than 4 times greater than the effect sizes found in psycho-pharmacological depression treatment studies.”<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>“Because most other depression treatments take weeks or months to work and may have undesirable effects, this could be a game changer if these findings hold up” in future clinical trials, Davis said.</p><p>And compared to traditional antidepressants, the side effects of psilocybin are more limited. These include mild-to-moderate headaches, and “challenging emotions” during the sessions. Antidepressant medications, on the other hand, have more far-reaching side effects. These include <a href="https://www.psychnewsdaily.com/new-study-finds-ethnic-variation-in-suicide-method-guns-vs-hanging/">suicidal</a> ideation, decrease in sexual drive, and weight gain.</p><p>Furthermore, the effectiveness of psilocybin <a href="https://www.psychnewsdaily.com/effects-of-therapy-for-hypochondriacs-last-10-years-or-more/">therapy</a> appears after only one or two administrations. This represents another advantage over commonly used antidepressants, which typically require daily administration.</p><h2>Two five-hour psilocybin sessions</h2><p>For the new study, the researchers recruited 24 people with a long-term history of depression. Most of the participants had experienced symptoms for about two years before enrolling in the study. <span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>The participants underwent two five-hour psilocybin sessions, under the supervision of the researchers.</p><p>The average age of participants was 39. Sixteen were women. Twenty-two identified as white, one identified as Asian, and one identified as African American.</p><p>Participants had to taper off any antidepressants prior to the study. They did so with the help of their personal physician, to ensure safe exposure to this experimental treatment.</p><p>Treatment consisted of two psilocybin doses given by two monitors who provided guidance and reassurance. The doses were given two weeks apart, between August 2017 and April 2019. Each treatment session lasted about five hours. The participants lay on a couch wearing eyeshades and headphones that played music, in the presence of the monitors.</p><h2>A very large reduction in depressive symptoms</h2><p>All participants completed the <a rel="noreferrer noopener" href="https://pubmed.ncbi.nlm.nih.gov/18408526/" target="_blank">GRID-Hamilton Depression Rating Scale</a> upon enrollment. They also did this same assessment at one and four weeks following completion of their treatment.</p><p>A score of 24 or more indicates severe depression. A score of 17-23 means moderate depression, 8-16 mild depression, and 7 or less no depression.</p><p>At enrollment, participants had an average depression scale rating of 23. But at one week and four weeks after treatment, they had an average depression scale score of 8.</p><p>After treatment, most participants showed a substantial decrease in their symptoms. Likewise, almost half were in remission from depression at the four-week follow-up.</p><p>For the entire group of 24 participants, 67% showed a more than 50% reduction in depression symptoms at the one-week follow-up, and 71% at the four-week follow-up. Overall, four weeks post-treatment, 54% of participants were considered in remission, meaning they no longer qualified as being depressed.</p><p>Compared to ketamine, another psychoactive substance that has <a href="https://pubmed.ncbi.nlm.nih.gov/25038867/" target="_blank" rel="noreferrer noopener">recently been found</a> to alleviate depression, psilocybin has several advantages. The antidepressant effects of psilocybin seem to last longer. Psilocybin also has a lower potential for addiction and adverse events than ketamine.</p><h2>More results to follow</h2><p>The researchers say they will follow the participants for a year after the study to see how long the antidepressant effects of the psilocybin treatment last. They will report these new findings in a later publication.</p><p>In 2016, Johns Hopkins Medicine researchers first reported that treatment with psilocybin under psychologically supported conditions significantly relieved existential anxiety and depression in people with a&nbsp;<a target="_blank" href="https://www.hopkinsmedicine.org/news/media/releases/hallucinogenic_drug_psilocybin_eases_existential_anxiety_in_people_with_life_threatening_cancer_" rel="noreferrer noopener">life-threatening cancer diagnosis</a>.</p><p>According to the National Institute of Mental Health, more than 17 million people in the U.S., and 300 million people worldwide, have experienced major <a rel="noreferrer noopener" href="https://www.psychnewsdaily.com/category/mental-health/depression/" target="_blank">depression</a>.</p><p>Entrepreneur and philanthropist <a href="https://tim.blog/" target="_blank" rel="noreferrer noopener">Tim Ferriss</a> supported the funding campaign for this study. “I believe this study to be a critically important proof of concept for the medical approval of psilocybin for treatment of depression, a condition I have personally struggled with for decades,” he said.</p><p>“How do we explain the incredible magnitude and durability of effects? Treatment research with moderate to high doses of psychedelics may uncover entirely new paradigms for understanding and improving mood and mind,” Ferriss said.</p><hr><p><strong>Study: </strong>“<a rel="noreferrer noopener" href="https://jamanetwork.com/journals/jamapsychiatry/fullarticle/10.1001/jamapsychiatry.2020.3285?guestAccessKey=29ac3052-6203-4fb4-b1e2-d9dda5988445&amp;utm_source=For_The_Media&amp;utm_medium=referral&amp;utm_campaign=ftm_links&amp;utm_content=tfl&amp;utm_term=110420" target="_blank">Effects of Psilocybin-Assisted Therapy on Major Depressive Disorder: A Randomized Clinical Trial</a>“<br><strong>Authors:</strong> Alan K. Davis, Frederick S. Barrett, Darrick G. May, Mary P. Cosimano, Nathan D. Sepeda, Matthew W. Johnson, Patrick H. Finan, and Roland R. Griffiths<br><strong>Published in:</strong> <a rel="noreferrer noopener" href="https://jamanetwork.com/journals/jamapsychiatry" target="_blank"><em>JAMA Psychiatry</em></a><br><strong>Publication date: </strong>November 4, 2020<br><strong>DOI: </strong>doi:10.1001/jamapsychiatry.2020.3285<br><strong>Photo: </strong>by&nbsp;<a href="https://unsplash.com/@vanillapines?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">James Bak</a>&nbsp;via <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a><br></p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/new-study-psilocybin-magic-mushrooms-relieves-depression/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24993519</guid>
            <pubDate>Wed, 04 Nov 2020 22:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter – Build a Calendly Clone Using Google OAuth]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24993284">thread link</a>) | @mmarcelline
<br/>
November 4, 2020 | https://blog.cotter.app/cotter-cloudflare-workers-google-calendar-api-build-a-serverless-calendar-booking-app/ | <a href="https://web.archive.org/web/*/https://blog.cotter.app/cotter-cloudflare-workers-google-calendar-api-build-a-serverless-calendar-booking-app/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.cotter.app/content/images/size/w300/2020/11/Cover.png 300w,
                            https://blog.cotter.app/content/images/size/w600/2020/11/Cover.png 600w,
                            https://blog.cotter.app/content/images/size/w1000/2020/11/Cover.png 1000w,
                            https://blog.cotter.app/content/images/size/w2000/2020/11/Cover.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.cotter.app/content/images/size/w2000/2020/11/Cover.png" alt="Cotter + Cloudflare Workers + Google Calendar API: Build a Calendly Clone using Google OAuth">
</figure>
<section>
<div>
 <p>During this pandemic, scheduling a meeting has become more important than ever, be it for a conference call, a consultation, or just a friendly chat.</p><p>In this guide, we'll explore how to use Google Calendar's API to make your own <strong>calendar booking app </strong>(yes, it's a platform, so other people can log in and share their own calendar link!). </p><figure><img src="https://blog.cotter.app/content/images/2020/11/calendar.gif"><figcaption>Build a Calendar Booking App with Cotter, Cloudflare Workers, and Google API</figcaption></figure><h3 id="try-out-the-live-demo-">Try out the live demo!</h3><figure><a href="https://cottercalendar.herokuapp.com/"><div><p>Calendar Booking App by Cotter</p><p>Calendar Booking App by Cotter</p><p><img src="https://cottercalendar.herokuapp.com/cottercalendar200.png"></p></div></a></figure><h3 id="we-ll-use-">We'll use:</h3><ul><li><a href="https://www.cotter.app/">Cotter</a> for logging in users and connecting to their Google Account.</li><li><a href="https://workers.cloudflare.com/">Cloudflare Workers</a> as a backend that will call Google Calendar API.</li><li><a href="https://developers.google.com/calendar/v3/reference">Google Calendar API</a> for booking time slots in your users' calendar.</li><li>We'll also use React in this tutorial.</li></ul><figure><a href="https://workers.cloudflare.com/"><div><p>Cloudflare Workers®</p><p>Build your next application with Cloudflare Workers</p><p><img src="https://workers.cloudflare.com/favicon.ico"><span>Workers logo</span></p></div><p><img src="https://repository-images.githubusercontent.com/215130914/0a128400-41f5-11ea-8dc8-b1c09a48fa06"></p></a></figure><p><a href="https://workers.cloudflare.com/">Cloudflare workers</a> allows you to deploy JavaScript code on Cloudflare's Edge network. This means you can write serverless code in Cloudflare workers and have it deployed across the globe. Your users will connect to the nearest Cloudflare network.</p><h3 id="what-about-a-database">What about a database?</h3><p>Cloudflare workers offers a <a href="https://www.cloudflare.com/products/workers-kv/">Key-Value store</a> that can keep consistent data across their locations. Note that currently, it's "eventually consistent" which means it might take some time (max 60s) for an update to be available globally.</p><h3 id="why-do-we-need-a-backend">Why do we need a backend?</h3><p>The biggest reason why we need a backend in this tutorial is that<strong><strong> we need a secure environment to store our API Secret Key</strong></strong> which is used to get Google's Access Tokens from Cotter.</p><p><strong>We don't need a database or a key-value store for our use case, </strong>so Cloudflare Workers is perfect for deploying a simple backend code that authenticates your users and calls Google's API</p><p>To try it out right now, you can use our CodeSandbox and follow the steps below to set up the Cloudflare Backend:</p><p><strong>1. Create a project at <a href="https://dev.cotter.app/">Cotter</a>, then add Sign in with Google to your Login Form</strong></p><ul><li><a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider/google-instructions">Follow these instructions to set up Google OAuth 2.0 Credentials and connect it to Cotter</a>. </li><li>Make sure you added <code>https://www.googleapis.com/auth/calendar</code> for the scope.</li><li>Enable Google for your form: Go to Branding &gt; Magic Link Form &gt; click the checkmark to enable <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider#setting-up-social-login-provider">Google Sign In</a></li><li>Add Cotter's Login Form to your website</li></ul><p><strong>2. Use this <a href="https://codesandbox.io/s/cotter-calendar-bs7qb?file=/src/constants.js">CodeSandbox</a> to get the calendar-booking React App. </strong>Update <code>src/constants.js</code> with your Cotter API KEY ID. You can also clone the project from the <a href="https://github.com/cotter-code/calendar-booker">Github Repo</a>.</p><p><strong>3. Setup Cloudflare Worker, make 3 workers with subdomains:</strong></p><ul><li><code>checkconnection.YOURSUBDOMAIN.workers.dev</code></li><li><code>createevent.YOURSUBDOMAIN.workers.dev</code></li><li><code>disconnect.YOURSUBDOMAIN.workers.dev</code></li></ul><p><a href="https://github.com/cotter-code/calendar-booker/tree/main/cloudflare">Copy the code from our Github for your Cloudflare Worker</a>.</p><p><strong>4. Enable Google Calendar API in your Google project</strong></p><p>Enable <a href="https://console.developers.google.com/apis/api/calendar-json.googleapis.com">Google Calendar API</a> to the project that you used to create Google OAuth 2.0 Credentials.</p><figure><img src="https://blog.cotter.app/content/images/2020/11/Diagram.png"></figure><p>Here's the outline of the things that we needed to do to build this platform:</p><ul><li>Users will be using "Sign in with Google" to get an access token from Google. This access token is accessible via <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider/getting-access-tokens-from-social-login-providers">Cotter's API</a>.</li><li>Make API endpoints at your Cloudflare Worker which would 1) call <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider/getting-access-tokens-from-social-login-providers">Cotter's API</a> to get the user's Google Access Token, and 2) call Google's API using that Google access token.</li></ul><hr><figure><img src="https://blog.cotter.app/content/images/2020/11/image-1.png"></figure><h2 id="getting-google-s-access-token-via-google-sign-in">Getting Google's Access Token via Google Sign In</h2><p>To access Google's Calendar API, you'll need a Google Access Token for the user to modify their calendar. This means the user needs to connect their Google Account. Using Cotter as your authentication service, this can be done in 2 ways:</p><ul><li><strong>If the user logged-in using Google Sign In</strong>, you can automatically access their Google Access Token by calling <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider/getting-access-tokens-from-social-login-providers">Cotter's API</a>.</li><li><strong>If the user logged-in with their email</strong>, you can provide a button on the dashboard and <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider#connecting-a-social-account-to-an-existing-user">ask them to connect their Google Account</a>. After that, you can access their Google Access Token by calling <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider/getting-access-tokens-from-social-login-providers">Cotter's API</a>.</li></ul><blockquote>When your user logged-in using Cotter, you'll get a <strong>Cotter Access Token</strong>. We'll use this access token to<strong> protect our API Endpoints</strong> that we're going to make in Cloudflare Workers.</blockquote><p><strong>1) Adding Sign in with Google to your Login Form</strong></p><ol><li><a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider/google-instructions">Follow these instructions to set up Google OAuth 2.0 Credentials and connect it to Cotter</a>. Make sure you added <code>https://www.googleapis.com/auth/calendar</code> for the scope.</li><li>Enable Google for your form: Go to Branding &gt; Magic Link Form &gt; click the checkmark to enable <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider#setting-up-social-login-provider">Google Sign In</a></li><li>Add Cotter's Login Form to your website</li></ol><p>Using Cotter's React SDK, you can easily use React context provider to keep track of the authentication state (i.e. is the user logged-in, etc).</p><pre><code>yarn add cotter-react</code></pre><pre><code>import React from "react";
import { Router } from "@reach/router";
import LoginPage from "../login";
import { CotterProvider, LoginForm } from "cotter-react"; // 👈  Import Cotter Provider

function App() {
  return (
    // 👇 1) Wrap CotterProvider around your ROOT COMPONENT
    // Copy paste your Cotter API Key ID below.
    &lt;CotterProvider apiKeyID="&lt;YOUR API KEY ID&gt;"&gt;
      &lt;Router&gt;
        &lt;LoginPage path="/" /&gt;
      &lt;/Router&gt;
    &lt;/CotterProvider&gt;
  );
}

function LoginPage() {
  return (
      &lt;div className="LoginPage__form-container"&gt;
      {/* 👇  2) Show the login form */}
      &lt;LoginForm
          onSuccess={(response) =&gt; console.log(response)}
          onError={(err) =&gt; console.log(err)}
      /&gt;
      &lt;/div&gt;
  );
}

export default App;</code></pre><p><strong>2) Checking if the user is logged-in in your dashboard</strong></p><p>Using <code>CotterContext</code> you can check if the user is logged-in and get their Cotter Access Token.</p><pre><code>import { CotterContext, withAuthenticationRequired } from "cotter-react"; // 👈  Import the user context
import React, { useContext, useEffect, useState } from "react";
import "./styles.css";

function DashboardPage() {
  const { user, getAccessToken, isLoggedIn } = useContext(CotterContext); // Get the logged-in user information
  const [accessToken, setaccessToken] = useState(null);

  useEffect(() =&gt; {
    if (isLoggedIn) readAccessToken();
  }, [isLoggedIn]);
    
  // Get the Cotter access token to be used for our API call
  // (for now, we'll just display it in the dashboard)
  const readAccessToken = async () =&gt; {
    const token = await getAccessToken();
    setaccessToken(token?.token);
  };
  return (
      &lt;div className="container"&gt;
      	User ID: {user?.ID} &lt;br /&gt;
      	User email: {user?.identifier} &lt;br /&gt;
        Cotter Access Token: {accessToken}
      &lt;/div&gt;
  );
}

// Protect this page using the `withAuthenticationRequired` HOC
// If user is not logged-in, they'll be redirected to the `loginPagePath`
export default withAuthenticationRequired(DashboardPage, {
  loginPagePath: "/",
});</code></pre><ul><li>Wrap your component around <code>withAuthenticationRequired</code> to automatically redirect your user to login if the user is not logged-in</li><li>Use <code>isLoggedIn</code> to check if the user is logged-in, and <code>user</code> to get the logged-in user information.</li><li>Use <code>getAccessToken</code> to get the Cotter Access Token that we'll use to call our API endpoints.</li></ul><p><strong>3) Checking if the user has connected their Google Account</strong></p><p>We'll make an endpoint for this on our Cloudflare Worker which will call <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider/getting-access-tokens-from-social-login-providers">Cotter's API</a> to see if the user has connected their Google Account.</p><p><strong>4) Show a button to connect Google Account from the Dashboard</strong></p><figure><img src="https://blog.cotter.app/content/images/2020/11/image-2.png"></figure><p>If the user has not connected their Google Account (they didn't log in using Google), show a button to <strong>connect Google Account.</strong> Call this function with your button to connect their Google Account:</p><pre><code>import { CotterContext } from "cotter-react"; // 👈  Import the user context

function DashboardPage() {
  ...
  const { getCotter } = useContext(CotterContext);

  // If the user hasn't connected their Google Account,
  // show a button to call this function to connect
  const connectToGoogle = async () =&gt; {
    var cotter = getCotter();
    cotter.connectSocialLogin("GOOGLE", accessToken);
  };
    
  return (
    &lt;div className="DashboardPage__container"&gt;
     ...
      &lt;button onClick={connectToGoogle}&gt;Connect Google Account&lt;/button&gt;
    &lt;/div&gt;
  );
}</code></pre><hr><figure><img src="https://blog.cotter.app/content/images/2020/11/image-3.png"></figure><h2 id="making-api-endpoints-at-cloudflare-workers-to-call-google-s-api">Making API endpoints at Cloudflare Workers to call Google's API</h2><p>Once you got the login flow working, you can start making the endpoints at Cloudflare Workers that would call Google's API. Specifically, you'll need these endpoints:</p><ol><li>An API to check if the user has connected their Google Account</li><li>An API to modify their Google Calendar</li></ol><h3 id="create-a-cloudflare-account-and-setup-workers">Create a Cloudflare Account and Setup Workers</h3><ol><li>Go to Cloudflare and sign up with your email and password. <strong><strong>You don't need to add a domain.</strong></strong> When asked to add a domain, <strong><strong>if you don't have a domain, you can skip this by clicking on the Cloudflare logo.</strong></strong></li><li>Click <strong><strong>Workers</strong></strong> on the right side of your dashboard, and add a subdomain that you want for your backend API endpoint. Choose the <strong><strong>Free Plan</strong></strong> and verify your email.</li></ol><h3 id="create-a-test-worker-to-see-how-this-works">Create a Test Worker to see how this works</h3><ol><li>Press <strong><strong>Create a Worker</strong>. </strong>You can see that you have a handler script on the left side, and a playground to test your API endpoint. Click <strong><strong>Send</strong></strong> and you should see <code>hello world</code> as the response.</li><li>That's it, you've just created an endpoint! To save this endpoint, press <strong><strong>Save and Deploy</strong></strong>.</li></ol><h3 id="creating-endpoints">Creating Endpoints</h3><p>Notice that you can only change the sub-subdomain, not the path.</p><figure><img src="https://blog.cotter.app/content/images/2020/10/image-15.png"></figure><p>To be able to handle different paths, you'll need to <strong><strong><a href="https://developers.cloudflare.com/workers/starters">use their CLI and use a router</a></strong></strong>. That's too advanced for this tutorial, so <strong><strong>we'll just have our endpoints on different subdomains</strong></strong>.</p><h2 id="endpoint-1-checkconnection">Endpoint #1: <code>checkconnection</code></h2><h3 id="check-if-the-user-has-google-connected-">Check if the user has Google Connected.</h3><p>Create a worker, and change the name to <code>checkconnection</code> . We'll define our endpoint as the following:</p><pre><code>$ curl --request GET \
    --header 'Authorization: Bearer &lt;COTTER_ACCESS_TOKEN&gt;' \
    --url 'https://checkconnection.YOUR_SUBDOMAIN.workers.dev?userid=&lt;COTTER_USER_ID&gt;'
</code></pre><pre><code>// If Google account is connected:
{"connected": true}

// If not:
{"connected": false}</code></pre><h3 id="here-are-the-things-that-we-ll-need-to-do-">Here are the things that we'll need to do:</h3><ul><li>Check if the Cotter access token is valid</li><li>Call <a href="https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider#connecting-a-social-account-to-an-existing-user">Cotter's API to check if this user has a Google Access Token</a></li></ul><h3 id="code-explanations">Code &amp; Explanations</h3><p>Copy the code from <a href="https://github.com/cotter-code/calendar-booker/blob/main/cloudflare/checkconnection.js">our Github repo</a>.</p><details>
<summary width="100%">Click here to see the code and explanations</summary>
<br>
<h3 id="addthecotterapikeysasanenvironmentvariables">Add the Cotter Api Keys as an environment variables</h3>
<p>Go to the Settings tab, and press Add Variable. Add both the <code>API_KEY_ID</code> and <code>API_SECRET_KEY</code> from Cotter, then press …</p></details></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cotter.app/cotter-cloudflare-workers-google-calendar-api-build-a-serverless-calendar-booking-app/">https://blog.cotter.app/cotter-cloudflare-workers-google-calendar-api-build-a-serverless-calendar-booking-app/</a></em></p>]]>
            </description>
            <link>https://blog.cotter.app/cotter-cloudflare-workers-google-calendar-api-build-a-serverless-calendar-booking-app/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24993284</guid>
            <pubDate>Wed, 04 Nov 2020 21:34:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UAV Software Prioritizes Human Safety]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24993121">thread link</a>) | @basicplus2
<br/>
November 4, 2020 | https://www.aerodefensetech.com/component/content/article/adt/stories/insider/38038 | <a href="https://web.archive.org/web/*/https://www.aerodefensetech.com/component/content/article/adt/stories/insider/38038">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="data:image/svg+xml;base64,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" data-src="https://res.cloudinary.com/tbmg/c_scale,w_auto,f_auto,q_auto/v1604422819/adt/articles/2020/insider/20201104_Aerospace_Story1.jpg" alt="Hybrid Quadrotor 90C Image"> <figcaption>NASA Armstrongâ€™s Resilient Autonomy project will use the Hybrid Quadrotor 90C vertical lift and transition remotely piloted aircraft for software testing. (Credits: NASA Photo/Ken Ulbrich)</figcaption></figure> <p>Autonomous aircraft systems have the potential to save lives, and NASA Armstrong Flight Research Centerâ€™s Resilient Autonomy project is at the forefront of development. These advanced software systems are preventing air-to-ground collisions in piloted aircraft and the project is now focusing on developments to prevent aircraft from colliding with other aircraft in the air.</p><p>The software can better manage the mission intent of the flight while always maneuvering within the acceptable performance limits of the aircraft, much like how a pilot manages a safe flight.</p> <p><a href="https://www.nasa.gov/centers/armstrong/features/resilient-autonomy-project-develops-evaa-software.html" target="_blank" rel="noopener noreferrer">Source&nbsp;<i></i></a></p>
<!-- Disqus comments block -->
  </div></div>]]>
            </description>
            <link>https://www.aerodefensetech.com/component/content/article/adt/stories/insider/38038</link>
            <guid isPermaLink="false">hacker-news-small-sites-24993121</guid>
            <pubDate>Wed, 04 Nov 2020 21:14:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create Your Own $10k/Day Outbound Sales System]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24992974">thread link</a>) | @jqvist
<br/>
November 4, 2020 | https://saleshub.ai/blog/how-to-create-your-own-10-000-20-000-day-outbound-sales-system/ | <a href="https://web.archive.org/web/*/https://saleshub.ai/blog/how-to-create-your-own-10-000-20-000-day-outbound-sales-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<div>
	<p>2 Years ago I read about how Clearbit and "G" formerly head of growth at Segment famously wrote an article how Segment build a $10,000+ pipeline daily using expensive and complex API's. At that time it was complicated, out of reach for most and yes almost impossible to deliver. Simply what they achieved is noteworthy but &nbsp;impossible for most companies. In the end it’s incredibly powerful and exciting, people struggled understanding how it works and how they could wire it together themselves.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>It’s hard. It involves connecting client-side and server-side data across five or six APIs (depending how you configure it) in a reliable way, engineers and lot of cost.</p><p>Saleshub has build it out of the box as the first company on the market, and making this strategy available to you today!</p><h3 id="backstory-what-did-they-try-to-achieve">Backstory what did they try to achieve?</h3><p>With outbound emails, sales development reps have a clear trade off between spending more time personalizing their messages vs. sending more messages. Either way, their goal is to set meetings for account executives to convert to an opportunity.</p><p>At Saleshub, we’ve experimented with timely outreach, tracking high email engagement and topical social mentions to cue in our sales team. Though it works, it’s hard to get a reliable source of data connected together, so it’s hard to scale.</p><p>But, there’s one reliable source of abundant data - website visitors. <strong><em><em>What better time to follow up after they’ve visited your website</em></em>?</strong></p><h3 id="how-do-you-follow-up-with-website-visitors">How do you follow up with website visitors?</h3><p>If we look at a traditional SaaS company, most of them have found it impossible to follow up with website visitors - even if they were really engaged - without pixels, form fills, and the constraints of ad platforms, form conversion rates, and so on.</p><p>This all pans out in, we know we have visitors but who is really visiting? We don’t know who they are from the data that we’ve got. We don’t have a key to unlocking the data.</p><p>This is where the <a href="http://whatismyipaddress.com/ip-address">IP address</a> comes in.</p><blockquote><strong><strong>IP addresses can be either static or dynamic. Static IP addresses never change</strong>, they are always the same<strong>. They serve as a permanent Internet address and provides a simple and reliable way for remote computers to contact you. Static IP addresses reveal such information as the continent, country, region, and city in which a computer is located</strong> and when using Saleshub we can identify the company behind the static IP.</strong></blockquote><p>An IP address is akin to a physical, street address for your computer.</p><p>In the B2C space, people move houses and street addresses aren’t always the most up-to-date source (we’ve all received someone else mail). IP addresses aren’t so useful for matching here either.</p><p>With businesses, there’s a much stronger “footprint” with more activity to and from that address. It’s much easier to associate an IP address with a company. This is where Saleshub and <a href="https://exactvisitor.com/">ExactVisitor.com</a> comes in.</p><figure><img src="https://saleshub.ai/blog/content/images/2020/11/Image-2020-11-04-at-15.20.04.png" alt="" srcset="https://saleshub.ai/blog/content/images/size/w600/2020/11/Image-2020-11-04-at-15.20.04.png 600w, https://saleshub.ai/blog/content/images/size/w1000/2020/11/Image-2020-11-04-at-15.20.04.png 1000w, https://saleshub.ai/blog/content/images/2020/11/Image-2020-11-04-at-15.20.04.png 1514w" sizes="(min-width: 720px) 720px"></figure><p>Saleshub have matched up IP addresses with company names. Saleshub is using ExactVisitor to make this available inside the platform. You give an IP address, and it returns a company name.</p><p><em><em>This gives us the “key” to unlock all this data</em></em>.</p><p>With a company name, we can discover all sorts of information like their industry, their employees, their revenues, and more.</p><p>And the same principle to individual contacts. If we know an employee, we can discover their email address, their job title etc.</p><p>The automations when they kick can then automatically prospect the right person on LinkedIn, automate the outreach and let you contact the right decision makers from the visiting company.</p><p>Saleshub also integrates with Techtracker.io to further provide more data to accurately target the right visitors, based on their technology usage.</p><p>Once you setup your criteria's Saleshub can live determine if this is a fit or not.</p><figure><img src="https://saleshub.ai/blog/content/images/2020/11/Image-2020-11-04-at-19.01.25.png" alt="" srcset="https://saleshub.ai/blog/content/images/size/w600/2020/11/Image-2020-11-04-at-19.01.25.png 600w, https://saleshub.ai/blog/content/images/size/w1000/2020/11/Image-2020-11-04-at-19.01.25.png 1000w, https://saleshub.ai/blog/content/images/size/w1600/2020/11/Image-2020-11-04-at-19.01.25.png 1600w, https://saleshub.ai/blog/content/images/size/w2400/2020/11/Image-2020-11-04-at-19.01.25.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Saleshub is using the data from the IP to turn it into actionable data:</p><blockquote>- Company Name<br>- Company Technology usage (matching if a fit)<br>- Company Size<br>- Company Industry<br>- Company employee range<br>- Visitor location to target the right employees</blockquote><div><p>Now it will qualify based on your criteria's if this is a fit or not. If a fit 5 min after the visit it will take your personas and prospect them on Linkedin and follow your automation.</p><p><strong>Five ways Saleshub can take this even further:</strong></p></div><p>If you’ve gone to all the effort of prospecting for anonymous visitors, and everything else there’s so many other related automations and strategies you can apply.</p><p><strong>Here’s five ideas…</strong></p><h4 id="1-write-revealed-prospects-as-leads-and-contacts-in-salesforce">1. Write “revealed” prospects as leads and contacts in Salesforce</h4><p>To keep your sales team in the loop, make sure their CRM is updated with leads who are being auto-emailed. It’s important to keep teams aligned, especially with very scalable, automated processes.</p><p>Write a Lead Source as <code>Anonymous Revealed by Saleshub</code> &nbsp;and use this to power other logic. This also clues in your sales guys with the “we noticed a lot of people from your company on the site recently…” opener.</p><h4 id="2-trigger-10x-personalized-emails-">2. Trigger 10X personalized emails.</h4><p>This outbound email recipe is entirely automated, but for certain segments (perhaps large companies, or specific titles?), you may still want to run manual outreach emails and personalize each message further.</p><p>At Saleshub, we first tested these outbound email campaigns with manual outreach. This is the example of an email that gets a meeting…</p><p><em><em><strong>can see you're interested in </strong></em><strong>Saleshub</strong><em><strong>.</strong></em><strong>ai</strong><em><strong>...</strong></em></em></p><p><em><em>Hi </em>Christina<em>,</em></em></p><p><em><em>From one data geek to another, you can understand that I track all my emails and web analytics</em></em>...</p><p><em><em>And I see several dozen folks from </em>Amazon Web Services<em> have been visiting </em>Saleshub<em>.</em>ai<em>, checking out our live customer use cases and reading about our </em>automations</em>.</p><p><em><em>If you're interested, I'd love to talk - to share what companies like </em>Speexx<em>, </em>Acronis<em>, </em>Accenture<em> and others are using </em>Saleshub<em> to do, and how we can best help you at </em>Amazon Web Services<em>. In particular, upgrading your </em>automations to save your sales team countless of hours orchestrating their outreach on Linkedin + Emails.</em></p><p><em><em>If you've got 15 minutes to talk, I'd love to schedule some time</em></em>?</p><p><em><em>Look forward to hearing from you </em>Christina</em>,</p><p><em>Jesper</em></p><p><em>Saleshub<em>.</em>ai</em></p><h4 id="3-10x-retargeting-ads">3. 10X Retargeting ads</h4><p>Traditional, pixel-based retargeting only retargets the website visitor. As well as enrolling all these anonymous revealed prospects in outbound sales campaigns, enroll them in ad audiences too so you can go multi-channel. That can be done by creating custom audiences inside Facebook.</p><p>Ad audiences can suffer delivery issues by being too small. Bulking out your audiences with prospects from the same company can help solve this too.</p><h4 id="4-create-a-personalized-website-variation">4. Create a personalized website variation</h4><p>Now you know their name, and you know things about their company, we can consider creating a variation of the website for their company we recommend using ExactVisitor's visitor.js to use with Google Optimize.</p><h4 id="5-notify-your-team-on-slack">5. Notify your team on Slack</h4><p>Slack notifications aren’t the favorite method for many sales teams we speak too (including our own!), but Slack can bring data to your whole team very quickly and easily.</p><p>For marketing teams, this can be a quick hack to excite and motivate other teams who might have missed you had Google, Uber, and Tesla all over your site this week! 😉</p><p>Use visitor Alerts and your team knows when high targeted prospects are visiting. Setting up an <strong>#interesting_web_visitors</strong> channel is one of many ideas, as well as <strong>#demo_requests</strong>, <strong>#new_stripe_subscriptions</strong>, and more.</p>
	</div>
</article></div>]]>
            </description>
            <link>https://saleshub.ai/blog/how-to-create-your-own-10-000-20-000-day-outbound-sales-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24992974</guid>
            <pubDate>Wed, 04 Nov 2020 20:56:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What We Have Left]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24992737">thread link</a>) | @mcrittenden
<br/>
November 4, 2020 | https://critter.blog/2020/11/04/what-we-have-left/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/11/04/what-we-have-left/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2951">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I read a post called <a href="https://waitbutwhy.com/2015/12/the-tail-end.html">The Tail End</a> by Tim Urban yesterday. Tim talks about how, if he lives to be 90, then he has about 56 Super Bowls left to watch, 300 books left to read, or 20 more Red Sox games to watch in person.</p>



<p>Then he gets into the scary stuff. What about the things that he did more of when he was a kid, like spending time with his parents?</p>



<blockquote><p>It turns out that when I graduated from high school, I had already used up 93% of my in-person parent time. I’m now enjoying the last 5% of that time. We’re in the tail end.</p><cite>Tim Urban</cite></blockquote>



<p>And his siblings?</p>



<blockquote><p>It’s a similar story with my two sisters. After living in a house with them for 10 and 13 years respectively, I now live across the country from both of them and spend maybe 15 days with each of them a year. Hopefully, that leaves us with about 15% of our total hangout time left.</p><cite>Tim Urban</cite></blockquote>



<p>For me, it’s a little different. My dad and my sister (and only sibling) both died years ago. I’ve used 100% of my time with them. </p>



<p>Now it’s just me and my mom, who lives right across the street. We get to see each other a lot, but she’s getting older. I hope to have 500 more days that include some time with her, but that may be optimistic.</p>



<p>Tim then talks about his old high school friends: </p>



<blockquote><p>Now, scattered around the country with totally different lives and schedules, the five of us are in the same room at the same time probably 10 days each decade. The group is in its final 7%.</p><cite>Tim Urban</cite></blockquote>



<p>I doubt I’ll ever see a single one of my high school friends again intentionally. I’ve used 100% of my time with my old friends.</p>



<p>DHH (of Basecamp and Ruby on Rails fame) wrote one of my favorite posts/rants of all time: “<a href="https://m.signalvnoise.com/growing-apart-and-losing-touch-is-human-and-healthy/">Growing apart and losing touch is human and healthy</a>“. Here’s a choice quote:</p>



<blockquote><p>I’m not the same person I was in high school. Not the same person I was at university. Not the same person I was with friends at age 15 as I was with a different group of friends at 21. I’m still not the same person with friends in programming as I am with friends in racing or with family or old mates from Denmark.</p><p>What allowed me to change and prosper was the freedom to grow apart and lose touch with people. It’s hard to change yourself if you’re stuck in the same social orbit. There’s a gravitational force that pulls you into repeating the same circular pattern over and over again. Breaking out of that takes tremendous force.</p><cite>DHH</cite></blockquote>



<p>It’s easy to read <a href="https://waitbutwhy.com/2015/12/the-tail-end.html">The Tail End</a> and end up feeling sad about the time we have left and the time we’ve used up.</p>



<p>No thanks. I will not cry about moving on from my high school friends any more than I’ll cry about moving on from roller blading or my once beloved Sega Dreamcast. </p>



<p>Tim’s post ends with this:</p>



<blockquote><p>Your remaining face time with any person depends largely on where that person falls on your list of life priorities. Make sure this list is set by you—not by unconscious inertia.</p><cite>Tim Urban</cite></blockquote>



<p>Exactly. I decide who to spend my future with. And it’s not based on who I spent my past with. </p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/11/04/what-we-have-left/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24992737</guid>
            <pubDate>Wed, 04 Nov 2020 20:27:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Features of Musl]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24992477">thread link</a>) | @jandeboevrie
<br/>
November 4, 2020 | https://dustri.org/b/security-features-of-musl.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/security-features-of-musl.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="content">
  <article>
    <header>
      
    </header>
    <div>
      <p>Now that I'm running most of my services on <a href="https://www.alpinelinux.org/">Alpine Linux</a>,
I was curious about the state security-wise of its libc, <a href="https://musl.libc.org/">musl</a>,
which used to be <em>dire</em> to say the least last time I looked at it.</p>
<h2 id="zeroing-memory"><a href="#zeroing-memory">Zeroing memory</a></h2>
<p>Albeit <code>bzero</code> is deprecated (marked as LEGACY in POSIX.1-2001, removed in POSIX.1-2008),
musl provides <a href="https://git.musl-libc.org/cgit/musl/tree/src/string/bzero.c"><code>bzero</code></a>,
as well as the nonstandard <code>explicit_bzero</code> (also known as <code>memset_explicit()</code> or <code>memset_s()</code> in other libc)
to ensure that secret don't stay laying around in memory.</p>
<h2 id="support-of-_fortify_source"><a href="#support-of-_fortify_source">Support of _FORTIFY_SOURCE</a></h2>
<p>_FORTIFY_SOURCE is supported via a <a href="https://git.2f30.org/fortify-headers/file/README.html">libc-agnostic set of headers</a>.</p>
<h2 id="invalid-state-handling"><a href="#invalid-state-handling">Invalid state handling</a></h2>
<p>musl uses <code>assert</code>, which is a wrapper around <code>__assert_fail</code> to validate
assumptions and catch invalid states/violations, resulting in an immediate halt
of the program, instead of doing some dangerous magic to parse the callstack
and the environment.</p>
<h2 id="csprng"><a href="#csprng">CSPRNG</a></h2>
<p>Currently, musl <a href="https://www.openwall.com/lists/musl/2018/07/02/5">doesn't</a>
<a href="https://www.openwall.com/lists/musl/2017/11/27/14">provide</a> a
<a href="https://en.wikipedia.org/wiki/Cryptographically_secure_pseudorandom_number_generator">CSPRNG</a>,
but it's on the todo-list.</p>
<h2 id="support-for-n"><a href="#support-for-n">Support for %n</a></h2>
<p>Nowadays, the only reasonable usage of the <code>%n</code> specifier in <code>printf</code> and its
friends is to mount <a href="https://en.wikipedia.org/wiki/Uncontrolled_format_string">format-string attacks</a>.
But since musl aims at being as compliant as possible, this specifier is unfortunately <a href="https://git.musl-libc.org/cgit/musl/tree/src/stdio/vfprintf.c">implemented and
available</a>.
It could be interesting to put it being a define, a bit like <a href="https://docs.microsoft.com/en-us/previous-versions/hf4y5e3w(v=vs.140)">Visual Studio is
doing</a>.</p>
<h2 id="relro"><a href="#relro">RELRO</a></h2>
<p><a href="https://tk-blog.blogspot.com/2009/02/relro-not-so-well-known-memory.html">RELRO</a> is supported
since <a href="https://musl.libc.org/releases.html">musl 1.1.0</a>, released in April
2014.</p>
<h2 id="atexit-hardening"><a href="#atexit-hardening">atexit hardening</a></h2>
<p>It's <a href="https://binholic.blogspot.com/2017/05/notes-on-abusing-exit-handlers.html">old</a>
<a href="https://buffer.antifork.org/security/heap_atexit.txt">news</a> that <code>atexit</code> is a
cool vector to transform and arbitrary r/w into arbitrary code exec. glibc <a href="https://github.com/bminor/glibc/blob/master/stdlib/cxa_atexit.c">is
using
mangling</a>,
like
<a href="https://moflow.org/Presentations/200703%20EuSecWest%20-%20Windows%20Vista%20Exploitation%20Countermeasures/rjohnson%20-%20Windows%20Vista%20Exploitation%20Countermeasures.pdf">microsoft</a>,
OpenBSD <a href="https://isopenbsdsecu.re/mitigations/atexit_hardening/">marks them as
RO</a>. Unfortunately,
musl <a href="https://git.musl-libc.org/cgit/musl/tree/src/exit/atexit.c">doesn't do any defensive in this area</a>.</p>
<h2 id="stack-cookies"><a href="#stack-cookies">Stack cookies</a></h2>
<p>Building musl with stack-based overflow hardening (think "cookies") is possible since <a href="https://musl.libc.org/releases.html">musl
1.1.9</a>, released in May 2015.</p>
<h2 id="setjmplongjmp-hardening"><a href="#setjmplongjmp-hardening">Setjmp/longjmp hardening</a></h2>
<p><code>setjmp</code>/<code>longjmp</code> can be used to transform a limited write + jmp into an
arbitrary write to registers and more. The glibc does some <a href="https://github.com/bminor/glibc/commit/272b289859eff42d77fac6cf3125b38b0ff01791#diff-d89bba48e8edf8d5ff67f6d548cd8306">mangling</a>, like the <a href="https://github.com/openbsd/src/commit/9d294f3012b8bf3b592930ba1f7a456527cf33e0">OpenBSD libc</a>,
while Microsoft does <a href="https://blog.trendmicro.com/trendlabs-security-intelligence/control-flow-guard-improvements-windows-10-anniversary-update/">sanity check</a> (validating that the stack pointer is pointing to the stack, that the instruction pointers points within the current module, all well as validated <code>setjmp</code> callsites, …). musl doesn't do <a href="https://github.com/ifduyue/musl/blob/master/src/setjmp/i386/longjmp.s">any hardening</a> there.</p>
<h2 id="compatibility-with-san"><a href="#compatibility-with-san">Compatibility with *SAN</a></h2>
<p>Currently, musl <a href="https://github.com/google/sanitizers/issues/1080">isn't compatible</a>
with ASAN/MSAN/TSAN/UBSAN/… which isn't really super-duper important since I'm
not fuzzing with musl anyway.</p>
<h2 id="development-practises"><a href="#development-practises">Development practises</a></h2>
<p>musl's development is pretty old school: a <a href="https://wiki.musl-libc.org/reporting-bugs.html">mailing
list</a> for bug tracker, a <a href="https://git.musl-libc.org/cgit/musl">cgit
repository</a>, no continuous builds nor
integrations with static analysers like
<a href="https://en.wikipedia.org/wiki/Coverity">coverity</a> or
<a href="https://lgtm.com/">LGTM</a>, 
no fuzzing, … meh.</p>
<h2 id="memory-allocator"><a href="#memory-allocator">Memory allocator</a></h2>
<p>This is the juicy part of the blogpost: userland heap management. musl
used to have a terrible (security-wise) allocator, replaced with <code>malloc-ng</code>
as part of <a href="https://musl.libc.org/releases.html">musl 1.2</a> released in August
2020.</p>
<ul>
<li><a href="http://jemalloc.net/">jemalloc</a>,
  <a href="https://sourceware.org/glibc/wiki/MallocInternals">ptmalloc</a>,
  <a href="https://www.nedprod.com/programs/portable/nedmalloc/">nedmalloc</a>, … are all
  using per thread memory pools, while musl uses a global lock, likely to
    guarantee global consistency and avoid race-conditions that could result in
    undetected memory corruption exploitations. On the downside, this might
    result in contention on multi-threaded programs.</li>
<li>Freed and allocated memory isn't zeroed, so data leak from previously
    allocated memory is possible. Zeroing on free and checking if the zone is
    still zeroed upon allocation would detect <code>write-after-free</code> at this time,
    but this would likely be too expensive. Zeroing the first 8-bytes would be a
    good compromise.</li>
<li>There are no guard pages everywhere à la <a href="https://elinux.org/Electric_Fence">Electric Fence</a>,
    but only a fixed-size one below the out-of-band metadata.
    But since the allocator is often returning freed memory to the system,
    this tends to leave unmmaped chunks scattered around.</li>
<li>There is a single global secret, generated once via ASLR, or using
    <a href="https://man7.org/linux/man-pages/man3/getauxval.3.html"><code>AT_RANDOM</code></a> if
    available, used to check that chunks aren't forged. Unfortunately, it's not
    recomputed for every chunk but simply stored in them, meaning that if
    leaked once, it's game over.</li>
<li>There are pointers to the OOB metadata inside of the chunk, allowing an
    attacker with limited reads to rapidly gain access to the secret.</li>
<li>It's not possible to free unaligned chunks, and if the attacker doesn't have
    read capabilities, it's also impossible to free non-allocated chunks, making
    it possible to detect double-free and invalid-free deterministically.</li>
<li>When freed, chunks are put in a FIFO, making it a bit harder to trigger an
    use-after-free, but since no randomization is applied there, it's not <em>that</em>
    hard. Also, it could be interesting to quarantine the memory by marking it as
    <code>PROT_NONE</code> to catch low-hanging stuff.</li>
<li>Zero-size allocations aren't treated as a special case. They used to be
    pretty wild due to their underspecified interaction with <code>realloc</code>,
    but are <a href="http://www.hackitoergosum.org/2010/HES2010-jvanegue-Zero-Allocations.pdf">still scary nowadays</a>.
    malloc-ng's design prevents using pointing at a non-rw area instead,
    and decision was made that the added complexity of wiring something to handle
    this special case wasn't worth it.</li>
<li>Single-byte overflows are detected via a NULL-canary at the end of the
    allocation at re-allocation/free time, to prevent string-related problems,
    but it could be interesting to make it a bit larger, and add some
    randomization to it.</li>
</ul>
<h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2>
<p>Generally better than
<a href="https://www.gnu.org/software/libc/">glibc</a>/<a href="https://uclibc.org/">µClibc</a>/<a href="https://www.fefe.de/dietlibc/">dietlibc</a>/<a href="https://uclibc-ng.org/">µClibc-ng</a>/… allocator-wise,
which is the biggest attack-surface, but worse than <a href="https://isopenbsdsecu.re/mitigations/">OpenBSD's one</a>.
More than decent in my threat model.</p>
    </div>
  </article>
</section>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/security-features-of-musl.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24992477</guid>
            <pubDate>Wed, 04 Nov 2020 19:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Find a CTO for Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24991996">thread link</a>) | @Rui_Lou
<br/>
November 4, 2020 | https://altar.io/how-to-find-a-cto-for-your-startup-the-founders-guide/ | <a href="https://web.archive.org/web/*/https://altar.io/how-to-find-a-cto-for-your-startup-the-founders-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
<p><span>When building a startup, you have many options for software development. Whether you </span><a href="https://altar.io/whats-the-best-way-to-build-your-startup-cto-freelancers-agency/" target="_blank" rel="noopener noreferrer"><span>hire a team of developers, outsource to an agency, or find a CTO</span></a><span>.&nbsp;</span></p>
<p><span>While all of these options are viable, if you find a </span><span>CTO with the right tech expertise, you’ll have gained a key player to help you succeed. </span><span>But remember, if you pick the wrong CTO you won’t survive long – you may not even make it to launch.</span></p>
<p><span>I bet you keep hearing that “Finding your dream CTO is not easy”. It’s true; it takes a lot of time and commitment. That’s why many founders spend years looking for the perfect person for the job, myself included.&nbsp;</span></p>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*pUvlHpx9e4m6OWuO" alt="Alfred: &quot;Do you need assistance to find a CTO master Wayne?&quot; " width="100%" data-image-id="0*pUvlHpx9e4m6OWuO" data-width="1440" data-height="978"></figure>
<p><span>When I first started founding startups, I experienced the hurdles of finding a CTO first-hand. Over the la</span><span>st 14 years, I have built many projects. It took me more than 30 months and more than 300 headaches before I found the right guy for the job.</span></p>
<p><span>But when I found him, he nailed it. And he kept on nailing it.&nbsp;</span></p>
<p><span>Usually, the conflict is: You want to start </span><a href="https://altar.io/service-mvp/" target="_blank" rel="noopener noreferrer"><span>building your MVP</span></a><span> as soon as possible, so you might feel tempted to commit to the first decent option you find. On the other hand, you know this is one of the most crucial decisions you will make as a </span><a href="https://altar.io/what-the-non-technical-entrepreneur-needs-to-know-about-tech/" target="_blank" rel="noopener noreferrer"><span>non-tech founder</span></a><span>.</span></p>
<p><span>There are certain traits to look out for as you try to find a CTO. Many wannabe CTOs will display the same characteristics. This includes overpromising and underdelivering on a massive scale – but more on that later.&nbsp;</span></p>
<p><span>I’ve taken my experience building six startups, advising dozens and </span><a href="https://altar.io/work/" target="_blank" rel="noopener noreferrer"><span>working with many startup founders at Altar.io</span></a><span>, and identified the vital qualities every CTO should embody.</span></p>
<p><span>Before I list said qualities, it’s important to point out that </span><b>all</b><span> of them are vital. The fact is, your Robin needs to have it all, not few or most, all.&nbsp;</span></p>
<div>
<h4>Here is the structured process that will help you find a CTO for your startup:</h4>
<ul>
<li><span><span>What to look for in a CTO</span></span>
<ul>
<li><span>Passion&nbsp;</span></li>
<li><span>Responsibility</span></li>
<li><span>Tech Expertise</span></li>
<li><span>Commitment&nbsp;</span></li>
<li><span>Founder’s Alignment</span></li>
<li><span>Leadership skills&nbsp;</span></li>
<li><span>Management Skills&nbsp;</span></li>
</ul>
</li>
<li><span>Where to find a CTO&nbsp;</span></li>
<li><span>Alternatives To Finding a CTO&nbsp;</span></li>
</ul>
</div>


<h2><span>What To Look For In A CTO</span></h2>
<h3><strong>Passion</strong></h3>
<h5><span><i><span>Your Robin should be more passionate about your idea than you are – or at least come a close second.&nbsp;</span></i></span></h5>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*Kfg9BwIQFYTC46ql" alt="Batman and Robin: Find a CTO with Passion" width="100%" data-image-id="0*Kfg9BwIQFYTC46ql" data-width="1440" data-height="978"></figure>
<p><span>To be sure you’ve found your CTO remember: Passion is an essential trait highly correlated with the tenacity needed to traverse the dark alleys of the startup journey. Every startup faces hurdles. Unless you find a CTO that has a passion for your company; during the storms, you will be navigating the challenges alone.&nbsp;</span></p>
<p><span>Before I move on, it’s essential to understand the market dynamics. We are currently in reversed HR dynamics as it pertains to finding CTOs and developers: the talent picks the company – not the other way round. This is due to more demand than supply. For example, last year for every five developer job postings, only one was filled.</span></p>
<p><span>So, if you find a CTO who’s good at what they do, chances are they’re already in a job, earning well.&nbsp;</span></p>
<p><span>For example, a typical CTO salary in the US is between </span><a href="https://www.salary.com/research/salary/benchmark/chief-technology-officer-salary" target="_blank" rel="noopener noreferrer"><span>$204,957 and $285,891</span></a><span> per annum (as of April 2020 – before bonuses &amp; benefits).&nbsp;</span></p>
<figure><img loading="lazy" src="https://cdn-images-1.medium.com/max/720/0*SOdtld9hzEfce1Li" alt="CTO Median Salary (annually) Apr 2020" width="711" height="301" data-image-id="0*SOdtld9hzEfce1Li" data-width="711" data-height="301"></figure>
<p><span>Given this, you get my perspective when I say:</span></p>
<p><span>Your CTO will most likely be taking a considerable salary; working on a project they enjoy. You will be asking them to drop all of that for your early-stage idea. It’s what you have to do. But there is no way they’re going to give up a lucrative job for your startup unless they’re genuinely passionate about your idea, I mean obsessed-passionate (otherwise they’re </span><span>just crazy or faking it).&nbsp;</span></p>
<p><span>It’s even harder to find someone at the right time who will drop their lucrative position and work just for sweat equity, no salary. As this founder experienced first-hand:&nbsp;</span></p>

<div>
<div>
<div>
<div>
<p><i>I spent six months trying to find a technical co-founder. The closest I got was Tom. He wasn’t a CTO but had the 5 years of experience I was told a co-founder needed. He was very busy, when I asked him to leave his job if I secured investment, he had second thoughts. Whilst he wasn’t a CTO on $244k, even the average developer salaries often are too good to give up!</i></p>


</div>
</div>
</div>
</div>
<p><span> If you find someone willing to jump ship, it shows how passionate they are about your vision.</span></p>

<div>
<h4>My Advice:</h4>
<div>
<p>Be sceptical about a seemingly good candidate that doesn’t put up a good struggle to leave their position and join your crew – they may be overstating their worth.</p>
</div>
<div>
<p>Be prepared that it’s going to take time to find a CTO with this level of passion; the odds are slim, but not impossible.</p>
</div>
</div>
<h3><strong>Responsibility</strong></h3>
<h5><span><i><span>Passion is great but can make people blind. Make sure Robin is still sober enough to make responsible decisions.</span></i></span></h5>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*pUzcxKef3m7uEK8q" alt="Batman &amp; Robin: Find a CTO who's Responsible" width="100%" data-image-id="0*pUzcxKef3m7uEK8q" data-width="1440" data-height="978"></figure>
<p><span>With great power comes great responsibility. It’s important to find a CTO that is a responsible professional before onboarding them as your partner in crime.&nbsp;</span></p>

<div>
<h4>My Advice:</h4>
<div>
<p>Test your potential CTO by asking for a simple deliverable. It should be something not too complicated, and you should give them a feasible time frame (again, if you are not sure on this ask an unbiased techie friend). It could be a piece of a technical challenge, but it could as well be a roadmap, budget estimate, etc.</p>
</div>
<div>
<p>If they don’t deliver, it’s a huge red flag. It brings into question the trust you can give them with your business – from both a responsibility and commitment perspective.</p>
</div>
</div>
<h3><strong>Tech Expertise</strong></h3>
<h5><span><i><span>Make sure you’re talking to a real Robin; you may find an inexperienced guy behind that mask.</span></i></span></h5>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*Qu0Yd_mD5LmqEv-x" alt="Batman &amp; Robin: Find a CTO with tech expertise " width="100%" data-image-id="0*Qu0Yd_mD5LmqEv-x" data-width="1440" data-height="978"></figure>
<p><span>You will find many wannabe CTOs. Your CTO must have the depth of knowledge to make the right technical decisions for your startup. This requires evaluation. Of course, if you don’t have a technical background, you think, “Ok, but how do I evaluate the tech expertise”, don’t worry I have a precise way to deal with that (which I will go into later).&nbsp;&nbsp;</span></p>
<p><span>Remember the importance of this point:</span><b> if your CTO lacks expertise, it can lead to bleeding ‘technical debt’ </b><span>– such as incorrect or substandard code and unwise technology choices – to name but two.</span></p>
<p><span>You should find a CTO who is, at the very least, as good at their job as you are at yours. You should be equals, working in different disciplines, towards the same goal.</span></p>

<div>
<h4>My Advice:</h4>
<div>
<p>Study your potential CTO’s portfolio and ask an unbiased expert (who is exempt from your search) to validate the quality of their previous work.</p>
</div>
<div>
<p>Benchmark: Ask your candidate to elaborate their tech rationale on technologies, architecture and infrastructure. Alongside this, ask a <a href="https://altar.io/start-a-project" target="_blank" rel="noopener noreferrer">software development agency to do the same thing.</a> Some agencies will give you their insights on which technologies, architecture and infrastructure you should follow at a lead stage – without any cost.</p>
</div>
</div>
<h3><strong>Commitment&nbsp;</strong></h3>
<h5><span><i><span>Can you imagine a part-time Robin? Me neither!</span></i></span></h5>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*OLCF6FjTLt0CqvUW" alt="Batman &amp; Robin: A CTO with Commitment " width="100%" data-image-id="0*OLCF6FjTLt0CqvUW" data-width="1440" data-height="978"></figure>
<p><span>You and your CTO will face many hurdles together on the road to success; if they don’t fully commit, your success will get further and further out of reach.</span></p>
<p><span>As I’ve talked about in a previous article, there is nothing worse than “getting married” to a CTO or technical co-founder who’s not fully committed. You will end up living in the “mistress syndrome”.&nbsp; This occurs when your CTO has another full-time job and ends up treating you and your startup as a “side-gig”. This will result in you committing to your company more than them – creating an imbalance in your relationship that is harmful.&nbsp;</span></p>

<div>
<h4>My Advice:</h4>
<div>
<p>You should find a CTO that is prepared to commit as much as you.</p>
</div>
<div>
<p>You should coordinate with your CTO and make sure you agree on the business’ milestones: The deadlines on the creation and delivery of your MVP, product iterations, etc. It’s essential to reach common ground before you plan the wedding!</p>
</div>
</div>
<h3><strong>Founders’ Alignment</strong></h3>
<h5><span><i><span>You and your Robin should agree on a plan before taking justice to the streets; you don’t want to face the Joker unprepared.</span></i></span></h5>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*0Kbl3sO33NY1kKdn" alt="Batman &amp; Robin: Founder's Alignment " width="100%" data-image-id="0*0Kbl3sO33NY1kKdn" data-width="1440" data-height="978"></figure>
<p><span>This point is highly relevant if you are bringing your CTO on board as your technical co-founder.</span></p>
<p><span>You will spend many hours working directly with your technical co-founder. So it’s crucial that you first like the person you onboard. Secondly, you should be able to trust this person with your money, ideas &amp; business. It really will become a “business marriage”.&nbsp;</span></p>
<p><strong><b>Related: </b><a href="https://altar.io/intellectual-humility-and-the-7-traits-of-great-co-founders/" target="_blank" rel="noopener noreferrer"><span>7 Traits to Consider if You Want to Find the Perfect Co-founder</span></a></strong></p>
<p><span>As I mentioned, it may take years to find a CTO for your startup. If you think you’ve found them, your expectations must be aligned. You should agree on:&nbsp;</span></p>
<ul>
<li><span>Product &amp; company roadmap</span></li>
<li><span>Co-founder equity split &amp; salaries&nbsp;</span></li>
<li><span>Work culture</span></li>
</ul>
<p><span>You will both be responsible for balancing the needs of the business, technology and even product; now and as your team grows. Therefore the overall paths you both envision for your startup have to coexist. By no means will you agree on everything 100% of the time, which is why it’s essential to have those lines of communication open.</span></p>
<p><span>Conversely, you don’t want someone who “sweats the small stuff”; when you and your CTO discuss every minute detail. I like to call this an “atomic relationship”. In my experience, it will result in using all of your energy and time discussing the wrong topics, taking attention from those that do.&nbsp;</span></p>

<div>
<h4>My Advice:</h4>
<div>
<p>Discuss all the mentioned points (Product/Company roadmap, Equity split &amp; salaries and Work culture) before you make any kind of commitment.</p>
</div>
<div>
<p>As in any relationship, be ready to discuss contentious points and, at times, prepare to compromise. Don’t waste your time with someone who gets stuck in the unnecessary details. As much as we would all like to admit, myself included, that energy is infinite, it is not.</p>
</div>
</div>
<h3><strong>Leadership Skills</strong></h3>
<h5><span><i><span>It’s important that Robin leaves the Batcave and can assemble a league of citizens to help clean up Gotham.</span></i></span></h5>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*loMbXybeWtILe5iC" alt="Batman &amp; Robin: A CTO is a Leader" width="100%" data-image-id="0*loMbXybeWtILe5iC" data-width="1440" data-height="978"></figure>
<p><span>There are many </span><a href="https://altar.io/looking-developers-10-developer-archetypes-youre-likely-encounter/" target="_blank" rel="noopener noreferrer"><span>archetypes of developers</span></a><span>, and a few stereotypes to boot. One of the most popular being that they share a disposition for sitting alone in their “cave” accompanied exclusively by seven monitors, a coffee machine, half a dozen red bull and very little light.&nbsp;</span></p>
<p><span>For developers, these archetypes are ok; your CTO, however, is a different thing entirely. You need to find a CTO that can strategically build, grow and lead the …</span></p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altar.io/how-to-find-a-cto-for-your-startup-the-founders-guide/">https://altar.io/how-to-find-a-cto-for-your-startup-the-founders-guide/</a></em></p>]]>
            </description>
            <link>https://altar.io/how-to-find-a-cto-for-your-startup-the-founders-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991996</guid>
            <pubDate>Wed, 04 Nov 2020 19:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Dark didn't choose Rust]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24991848">thread link</a>) | @pimterry
<br/>
November 4, 2020 | https://blog.darklang.com/why-dark-didnt-choose-rust/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/why-dark-didnt-choose-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/2017-11-21-18-14-57-1200x800.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/2017-11-21-18-14-57-1200x800.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/2017-11-21-18-14-57-1200x800.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/2017-11-21-18-14-57-1200x800.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/2017-11-21-18-14-57-1200x800.jpg" alt="Why Dark didn't choose Rust">
            </figure>

            <section>
                <div>
                    <p><em><em>Welcome </em>again <em>HN! <a href="https://darklang.com/">Dark</a> is a programming language, structured editor, and infrastructure—all in one—whose goal is to make it 100x easier to build backend services. Check out the <a href="https://darklang.com/">website</a>, our <a href="https://blog.darklang.com/what-is-dark/">What is Dark</a> post, and <a href="https://blog.darklang.com/how-dark-deploys-code-in-50ms/">How Dark deploys in 50ms</a></em> <em>for more. Thanks for checking us out!</em></em></p><p><em>This is the third or a 3-part series: <a href="https://blog.darklang.com/leaving-ocaml/">Leaving OCaml</a> and <a href="https://blog.darklang.com/new-backend-fsharp/">Dark's new backend will be in F#</a>. You can enjoy this without reading the previous posts.</em></p><p>With the election in the state it is, I'm going to stop pretending that I can do work right now. So instead, I'll just milk the success of my last <a href="https://blog.darklang.com/leaving-ocaml/">two</a> <a href="https://blog.darklang.com/new-backend-fsharp/">posts</a> and hope that none of you are really working right now either.</p><p>As discussed in the two <a href="https://blog.darklang.com/leaving-ocaml/">previous</a> <a href="https://blog.darklang.com/new-backend-fsharp/">posts</a>, Dark is moving to F#. This has been a bit of a surprise to people, including me. We've spoken for years about the inevitable Rust rewrite; we have a CLI written in Rust and two services, so I was pretty sure that it was going to be Rust.</p><p>People asked about a few other languages as well, so let's get them out of the way first.</p><h3 id="clojure">Clojure</h3><p>I have a lot of experience with Clojure, as CircleCI was almost all Clojure. However, we spent a whole lot of time with dealing accidental complexity, specifically "what type is this field" and nulls all over the place. So I deliberately chose not to have a dynamically typed language, even though Clojure is a lovely language. A side benefit is to escape the Cult of Rich in the Clojure community. Hearing his <a href="https://www.youtube.com/watch?v=YR5WdGrpoug">Maybe Not</a> talk really cemented for me how deep down the dynamically typed rabbit hole they are over there, and how much I disagree with that.</p><h3 id="haskell">Haskell</h3><p>I had previously tried to love Haskell, trying to <a href="https://github.com/pbiggar/rash">write an interpreter</a> in it while I was at the <a href="https://www.recurse.com/">Recurse Center</a>, and I did not like it. <a href="https://news.ycombinator.com/item?id=24978238">HN user momentumtop's explanation</a> match my feelings exactly:</p><blockquote>The Haskell community, in my experience, is far more academic. A<a href="https://mail.haskell.org/pipermail/libraries/2020-September/030789.html"> recent post to the Haskell libraries mailing list</a> began with:<p>"It was pointed out to me in a private communication that the tuple function \x-&gt;(x,x) is actually a special case of a diagonalization for biapplicative and some related structures monadicially.</p><p>It received 39 pretty enthusiast replies.</p></blockquote><h3 id="scala">Scala</h3><p>I have no experience with Scala, but my overwhelming sense of the language and the community is that the whole thing is a mess. So I didn't consider it, and still wouldn't.</p><p>I actually <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">wrote quite a bit on why I didn't like Rust</a> a few weeks ago. I think those main reasons stand, so I'll just link to them rather than repeat the <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">1800 words</a> again. As a quick summary, the good parts were:</p><ul><li>tooling is great</li><li>library ecosystem is great</li><li>community is great</li><li>macros are nice (though I feel I was overusing them to cover problems in the language)</li></ul><p>and the bad parts were</p><ul><li>having to do memory management sucks</li><li>pattern matching doesn't work all that well</li><li>too many ways to do things (Arc vs Rc, async vs sync, different stdlibs)</li><li>the language isn't immutable</li><li>having to fight the compiler</li></ul><p>Again, for more on those, have a <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">read of the previous post</a>.</p><p>Ultimately, when it came time to decide, it came down to a few major things: missing a GCP library, and the low-level nature of the language.</p><h2 id="libraries">Libraries</h2><p>Rust has a ton of libraries, and they work really well and are nicely integrated. They have 3rdparty libraries for <a href="https://www.honeycomb.io/">Honeycomb</a>, <a href="https://launchdarkly.com/">LaunchDarkly</a>, and <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/rollbar.com">Rollbar</a>, which are important services for us. However, the <a href="https://github.com/Byron/google-apis-rs">library for GCP</a> seems super sketch. It's autogenerated and the issues imply that they've gone as far as they can using this technique. So that seemed very risky to take on, given that the whole point was to have a much richer library ecosystem.</p><h2 id="async">Async</h2><p>When I wrote the <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">previous post</a>, I had just gotten the <a href="https://github.com/darklang/fizzboom/tree/main/rust-hyper">synchronous version</a> of the benchmark to work in Rust. Then I tried to <a href="https://github.com/darklang/fizzboom/tree/main/rust-hyper-async/execution-engine">make it async</a>. I really struggled with making things async. Apparently, recursion adds <a href="https://rust-lang.github.io/async-book/07_workarounds/04_recursion.html">a new level of complexity</a> to async. But the thing that killed me was <a href="https://rust-lang.github.io/async-book/04_pinning/01_chapter.html">pinning</a>.</p><p>Let's see if I can explain this. When you're writing an async, multi-threaded server in using the tokio runtime, async processes can be moved between threads. This means the memory can be copied, and so you need to ... pin things? OK, that's as much as I remember. Look in the HN comments after I publish this and I'm sure someone will explain better. The code <a href="https://github.com/darklang/fizzboom/blob/main/rust-hyper-async/execution-engine/src/eval.rs">is over here</a> if you're interested.</p><p>I tried to get my head around this for some time, before deciding that this was a waste of time. Apparently, this boxing and pinning is what you get when you don't have a GC, and that when you do have a GC, you simply don't need to deal with it. So that was the final straw for me.</p><h2 id="rust-is-a-low-level-language">Rust is a low-level language</h2><p>I'm implementing a language that's basically F#/OCaml. So it makes sense that it's easier to implement in F#/OCaml. A few people pointed out that I'm trying to write OCaml in Rust, and that's not really what it was designed for. I think that's right. Rust's semantics makes many things easy, but not what I'm trying to do.</p><p>I think most of us don't need Rust. I think Rust is a wonderful community, ecosystem, and tooling, wrapping a language that nicely solves a problem very few of us have. It's just so nice over there, until you actually write code.</p><p>It's easy to forget, given how nice everything is with the error messages and the docs, that Rust is a very low-level language. We're so attracted to the community and the tooling that we forget that low-level languages suck. Maybe Rust has a better story than most low-level languages, but remember that garbage collectors are great. By having a GC, we don't have to do any of the stuff that causes all these problems in Rust. Maybe that costs performance, but I need the ability to quickly write code a lot more than I need the extra performance.</p><p>And ultimately, that's <a href="https://blog.darklang.com/new-backend-fsharp/">why I picked F#</a>.</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p><p><em>Thanks to <a href="https://twitter.com/jf">Joël Franusic</a>, <a href="https://twitter.com/jonathansywulak">Jonny Sywulak</a> and <a href="https://twitter.com/algo_luca">Luca Palmieri</a> for feedback on drafts of this post.</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/why-dark-didnt-choose-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991848</guid>
            <pubDate>Wed, 04 Nov 2020 18:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Publicly sharing your product roadmap? Good or bad?]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24991815">thread link</a>) | @erena
<br/>
November 4, 2020 | https://www.juphy.com/advantages-of-having-a-public-product-roadmap | <a href="https://web.archive.org/web/*/https://www.juphy.com/advantages-of-having-a-public-product-roadmap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
  <section>
      <header>
        
              <img src="https://www.juphy.com/nn_themes/juphy/img/authors/alara-eren.jpg" alt="">
                <span>By Alara Eren on Mon, 19 Oct 2020</span>
      </header>
      <article>
        <p><img src="https://www.juphy.com/nn_themes/juphy/img/posts/public-product-roadmap-cover.png" alt="public-product-roadmap-cover"></p>
<p>If you are a startup founder or a product manager thinking of what to do next with your product, which features to implement first and how to better understand your target audiences needs, you are reading the correct article.</p>
<p>Today I am going to write about why we made Juphy's product roadmap public and how it helped us to better understand our customers needs in the most efficient way. </p>
<h2 id="what-s-a-public-product-roadmap-and-how-can-you-use-it-">What's a Public Product Roadmap and How Can You Use It?</h2>
<p>A public product roadmap is an easily accessible online page where your potential users, customers, team, investors and other stakeholders can view your roadmap, give feedback and decide on the future of your product. </p>
<p>Nine months ago we started using Canny for Juphy's public roadmap and we highly recommend it. Our users can request new features, upvote other feature requests, report bugs, follow Juphy's product roadmap and progress on Canny. This helps us to prioritize feature requests, track user feedback in a very organized manner, keep customers up to date on new improvements and make better product decisions by understanding the needs of our customers. Today we are very proud to publicly share our roadmap as well as why we recommend it to other startups. </p>
<h2 id="advantages-of-having-a-public-product-roadmap">Advantages of Having a Public Product Roadmap</h2>
<p><img src="https://www.juphy.com/nn_themes/juphy/img/posts/benefits-of-public-product-roadmap.png" alt="benefits-of-public-product-roadmap"></p>
<h3 id="1-better-understanding-of-customers-needs">1. Better Understanding of Customers Needs</h3>
<p>The first and the most important reason of why we have a public roadmap is to better understand our customers needs and develop a product that they can not live without. Having a public roadmap is a perfect way to get feedback from your users about what's most important to them in your product/service and it allows you to be more certain in your decision making. When your roadmap is public and open to feedback, product managers and founders have to spend less time doing market research to figure out what your potential users want. Rather, they can collect feedback through a platform like Canny and eventually have more time to focus on actually building the product. This will also help them to leave aside biases and gut feelings when making product decisions.  </p>
<h3 id="2-transparency-builds-trust">2. Transparency Builds Trust</h3>
<p>A significant reason to make your product roadmap public is to increase transparency between your company and customers. When users can contribute on your roadmap, they are showing a level of dedication to your product. It creates a community where customers are actively contributing to the future of your product by creating new feature requests and upvoting already existing requests. After all, they are able to track your teams progress and will know that their feedback is heard and respected by your organization. That alone builds trust and dedication to your company. </p>
<h3 id="3-manages-expectations">3. Manages Expectations</h3>
<p>When users can view your product roadmap, they can see what your current priorities are and get a sense of your goals. Canny's feature voting enables you to set expectations for which features are coming as much as which isn't. Your public roadmap will also manage expectations in several other ways: </p>
<ul>
<li>If a current customer sees active work on a feature they really want, it will reduce your churn rate as the customer will most probably wait for that feature to be live.</li>
<li>Similarly, a public roadmap can serve as a sales tool for potential customers as your sales team will be able to show that you are currently working on features that they need.</li>
<li>Or on the opposite side, if a feature request has a very limited number of votes, users can better understand why you haven't implemented their feedback. This prevents your users from being disappointed if their feature request is not put into action.</li>
<li>Finally, if you update your roadmap regularly, customers can easily see your progress on a certain feature and won't reach out to you to ask about progress. This will save you time and money in terms of customer support.</li>
<li>Most importantly, users will appreciate and value the fact that you’re continually working to improve based on their needs.</li>
</ul>
<p><img src="https://www.juphy.com/nn_themes/juphy/img/posts/public-roadmap-voting.png" alt="public-roadmap-voting"></p>
<h3 id="4-improves-internal-communication">4. Improves Internal Communication</h3>
<p>Lastly, having a public roadmap gives all your employees a clear direction of your product which prevents uncertainty and improves motivation. It especially allows non-customer facing employees such as engineers to build a connection and better understand customers. They are able to gain direct insight into what customers are looking for, and prioritize their work based on the upvotes on your public roadmap. </p>
<p>On the recruitment side, candidates can view the product roadmap in advance and come in with very specific knowledge about the product, the company direction and what type of capabilities are required for this job. This allows you to ask more targeted questions about their skills and gives them a real idea about what kinds of projects they will be contributing to. Overall, the hiring process will be far more efficient. </p>
<p>On the support side, your team can instantly share your roadmap with customers, prospects and other stakeholders without asking for what's happening, which features are going to be added, etc. which will enable a more informative and rapid sales process.</p>
<h3 id="competitors-can-see-your-roadmap">Competitors Can See Your Roadmap</h3>
<p>While considering to make your product roadmap public, the first disadvantage that comes to mind is the fact that competitors will get a clear idea of your products direction. However, we believe that the advantages of having a public roadmap outweigh the disadvantages, and focusing on competition is a distraction. It is always a better idea to stay focused on your customers needs and execute your roadmap to the best of your ability. In the meantime, as Bri from Canny says :</p>
<blockquote>
<p>"If competitors are looking to your roadmap for inspiration, that means they’re leaning on your customer base to tell them what to build—not their own. At the end of the day, this will hurt them, not you."</p>
</blockquote>
<p>We totally agree with her and we couldn't be more happier to use Canny.</p>
<p>Overall, we believe that having a public product roadmap is a great way to better understand our customers needs while creating a highly valuable community and making more confident product decisions for Juphy. We definitely recommend other startups to consider this option and we would like to take this opportunity to thank Canny's co-founders Sarah and Andrew for creating such a great product. </p>
<p>If you are looking forward to find out more on how to create a public roadmap, you can always check this link out: </p>
<p><a href="https://canny.io/">https://canny.io/</a></p>

         <p><b>Tags:</b> public product roadmap, feedback optimization, feature prioritization, Juphy</p> 
      </article>
              
      
    </section>

    <div>
      
        
      
      
      <div>
          <h3>Subscribe 📬 </h3>
          <p>Learning from experience are priceless! Subscribe to be informed before anyone else 🤓</p>
          <p id="subscribe_box">          
            
            <a onclick="subscribe()">Subscribe</a></p>
      </div>
<!--       <div class="side_box side_box_video_list">
          <h3>Latest News</h3>
          <ul>
              <a class="twitter-timeline" data-height="2000" data-dnt="true" href="https://twitter.com/juphy_social?ref_src=twsrc%5Etfw">Tweets by juphy</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
          </ul>
      </div> -->
    </div>              


  </div>
</div></div>]]>
            </description>
            <link>https://www.juphy.com/advantages-of-having-a-public-product-roadmap</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991815</guid>
            <pubDate>Wed, 04 Nov 2020 18:47:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is it morally wrong to write inefficient code?]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24991784">thread link</a>) | @headalgorithm
<br/>
November 4, 2020 | https://tomgamon.com/posts/is-it-morally-wrong-to-write-inefficient-code/ | <a href="https://web.archive.org/web/*/https://tomgamon.com/posts/is-it-morally-wrong-to-write-inefficient-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In this post I will explore the idea that because running code contributes to global warming, writing inefficient code is morally wrong<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. I will start by outlining the argument, before working through each of the premises in turn to see how they hold up. I will then conclude that even if we cannot concretely defend every premise in this first iteration, then it is sufficiently plausible that it should at least make us pause for thought. With that said, let’s dive in!</p><p>The argument I am considering, in summary, can be presented as:</p><ol><li>Running code produces greenhouse gasses, proportional to the computing resources it requires.</li><li>Greenhouse gasses contribute to global warming.</li><li>Global warming increases the suffering of others.</li><li>Therefore, increasing your consumption of computing resources increases your contribution to the suffering of others.</li><li>Inefficient code increases your consumption of computing resources.</li><li>Therefore, inefficient code increases your contribution to the suffering of others.</li><li>Increasing your contribution to the suffering of others is morally wrong.</li><li>Therefore, writing inefficient code is morally wrong.</li></ol><p>I believe the argument as laid out above is valid, in that the conclusions follow from the premises, so we will focus our energies on determining if it is sound, that is all the premises are true. We will now break it down and look at each premise more carefully.</p><blockquote><ol><li>Running code produces greenhouse gasses, proportional to the computing resources it requires.</li></ol></blockquote><p>The first premise is based on the fact that running code requires electricity. Electricy, in large, requires the burning of fossil fuels, which releases a number of greenhouse gasses. There are cases where this is not the case (solar energy, wind energy), and in such cases, this argument is invalid. However, if you run your code on AWS, then it is very likely that you are running on fossil fuels<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. As AWS is the largest provider of cloud computing, this is likely to be true in a good number of cases.</p><blockquote><ol start="2"><li>Greenhouse gasses contribute to global warming.</li><li>Global warming increases the suffering of others.</li></ol></blockquote><p>With regards to the second and third premises, these are statements which are consistent with the overwhelming scientific consensus, and as such are uncontroversial. For the sake of completeness, here are some supporting statements from the <a href="https://www.ipcc.ch/site/assets/uploads/2018/02/AR5_SYR_FINAL_SPM.pdf">2014 climate change report summary</a> from the Intergovernmental Panel on Climate Change, emphasis mine.</p><blockquote><p><strong>Human influence on the climate system is clear, and recent anthropogenic emissions of greenhouse gases are the highest in history</strong>. Recent climate changes have had widespread impacts on human and natural systems.</p></blockquote><blockquote><p><strong>Warming of the climate system is unequivocal, and since the 1950s, many of the observed changes are unprecedented over decades to millennia</strong>. The atmosphere and ocean have warmed, the amounts of snow and ice have diminished, and sea level has risen.</p></blockquote><blockquote><p><strong>Continued emission of greenhouse gases will cause further warming and long-lasting changes in all components of the climate system, increasing the likelihood of severe, pervasive and irreversible impacts for people and ecosystems</strong>. Limiting climate change would require substantial and sustained reductions in greenhouse gas emissions which, together with adaptation, can limit climate change risks.</p></blockquote><blockquote><p>Cumulative emissions of CO2 largely determine global mean surface warming by the late 21st century and beyond.</p></blockquote><blockquote><p><strong>Climate change will amplify existing risks and create new risks for natural and human systems.</strong> Risks are unevenly distributed and are generally greater for disadvantaged people and communities in countries at all levels of development.</p></blockquote><p>I believe these to be enough to support the argument that greenhouse gasses contribute to global warming, and that global warming will increase suffering of the human and other animal populations.</p><blockquote><ol start="4"><li>Therefore, increasing your consiumption of computing resources increases your contribution to the suffering of others.</li></ol></blockquote><p>So here we come to our first conclusion, that increasing ones consumption of computing resources increases ones contribution to the suffering of others. It is based on at least two implicit premises. The first is that if A contributes to B, and B causes C, A contributes to C. The second is that in such a transitive relationship, if you increase your contribution to A then you increase your contribution to C. To illustrate, we can imagine a much more straightforward case. Imagine that I have a dial which, when turned, increases the voltage supplied to an electric chair. There are several such dials, and their contributions are additive. It would be fair to say that if I turned up my dial, I am contributing to the suffering of whoever is in that electric chair.</p><p>Given this assertion, it would seem reasonable that if running code produces greenhouse gasses, and greenhouse gasses contribute to global warming, then running code contributes to global warming. Global warming increases the suffering of others, so it follows that running code increases ones contribution to the suffering of others.</p><blockquote><ol start="5"><li>Inefficient code increases your consumption of computing resources.</li></ol></blockquote><p>Premise five seems relatively uncontroversial, though to simplify let us just consider the length of time some piece of code takes to run (in a similar way we assess algorithmic complexity). If an efficient version runs in 1 minute, and an inefficient version runs in 1 hour, it stands to reason that the inefficient version would consume more electricity.</p><blockquote><ol start="6"><li>Therefore, inefficient code increases your contribution to the suffering of others</li></ol></blockquote><p>With point six we again come to a relatively straightforward conclusion. If you agree with the earlier conclusion at point four and the premise at point five, then this falls out as a result of the logic of the statements.</p><blockquote><ol start="7"><li>Increasing your contribution to the suffering of others is morally wrong.</li></ol></blockquote><p>Point seven is the real crux of the argument, and on the surface intuitively plausible. In the above example with the dial, it would generally be considered morally wrong for you to dial up the dial and increase the suffering of the individual in the chair. However, if we are merely counting <em>contributions</em> to suffering, this casts a wide net. Would it be morally wrong not to buy an energy efficient bulb when an energy efficient one is available at the same price? How about breathing? This expels carbon dioxide, a greenhouse gas, but would generally not be considered a morally reprehensible action.</p><p>It seems that there is some inherent provision that increasing your contribution to the suffering of others is not morally wrong if it causes equal or greater personal suffering. For example, if there was some shared well of water, it would be reasonable to claim that it is not morally wrong of you to take a sip of water in order to save yourself from dehydration, even if that means other may become more dehydrated. However, if you drained the well, and threw that water away, causing another to die to dehydration, that seems morally wrong.</p><p>I think for the purposes of this post, we can consider this sufficiently true (there is definitely some sense in which it is true), even if is vulnerable to <a href="https://en.wikipedia.org/wiki/Reductio_ad_absurdum">reductio ad absurdum</a> in it’s current form. Consider it the alpha version of the premise - solid enough to be useful, but not without it’s bugs.</p><blockquote><ol start="8"><li>Therefore, writing inefficient code is morally wrong.</li></ol></blockquote><p>Here we come to the conclusion of the argument, that writing inefficient code is morally wrong, which follows from the logic set out in the conclusion at point six and the premise at point seven. So what does this mean?</p><p>As discussed, I am aware that this argument is probably not watertight, and perhaps with some more time spent on it we could tighten it up<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. I think the premise at point seven could definitely be better defended, and there almost certainly some implicit premises and caveats that need to be put in place. However, I think it is reasonable enough that it should make us pause and reflect. Whilst a lot of code performance issues can be covered up with bigger and better hardware, these come at a greater cost than just an increased AWS bill. The decisions we make as developers have real world effects.</p><p>If there are ways that we can reduce ‘programming waste’ we should strive to do so, whether that is changing an algorithm to be <code>O(1)</code>, scaling down some cloud instances or killing of that Heroku dyno that’s not really doing anything useful<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>. Collectively we can make a real difference.</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>I have had this idea knocking around for a while, but reading <a href="https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/">this post</a> motivated me to explore it further. Definitely check out the blog if you haven’t read it. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li><li id="fn:2" role="doc-endnote"><p><a href="https://www.youtube.com/watch?v=N4hiqGwTRBU">https://www.youtube.com/watch?v=N4hiqGwTRBU</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p></li><li id="fn:3" role="doc-endnote"><p>Perfect is the enemy of good. <a href="#fnref:3" role="doc-backlink">↩︎</a></p></li><li id="fn:4" role="doc-endnote"><p>After posting this, I am going to finally kill a bot that has been producing random inspirational quotes and posting them to Twitter for the last 6 years. <a href="#fnref:4" role="doc-backlink">↩︎</a></p></li></ol></section></section></div>]]>
            </description>
            <link>https://tomgamon.com/posts/is-it-morally-wrong-to-write-inefficient-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991784</guid>
            <pubDate>Wed, 04 Nov 2020 18:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Native Runtime Performance for High-Level Dynamically Typed Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24991652">thread link</a>) | @rusini
<br/>
November 4, 2020 | https://manool.org/blog/2020-10-04/native-run-time-performance-for-a-high-level-dynamically-typed-programming-language | <a href="https://web.archive.org/web/*/https://manool.org/blog/2020-10-04/native-run-time-performance-for-a-high-level-dynamically-typed-programming-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
<!-- begin main content -->

<!-- begin post header -->



<header>
  
  <p><small>Published: <time datetime="2020-10-04">October 4, 2020</time></small></p>
  <p><small>Updated: <time datetime="2020-10-04">October 4, 2020</time></small></p>
</header>

<!-- end post header -->

<p>Since popularization of my project MANOOL has been apparently going to nowhere, I've decided to rather invest some time in my self-education, learning new
technologies and pondering about new opportunities. Surprisingly this has resulted in a concrete and viable plan for the future improvements (that is, for
MANOOL-2). If someone would like to join the project at this stage, I would be glad (any help is welcome, even with just testing the concepts).</p>

<p>For those who are not familiar with the project: MANOOL seeks to bridge the gap, in the least troublesome way, between the exploratory style of programming (for
which languages like PHP, Python, Ruby, JavaScript, or Scheme are normally used) and the more thorough style (where languages like C, C++, Java, or Rust are a
better fit), and this is something I was in fact thinking about for more than 30 years.</p>

<p>So, according to the plan, MANOOL evolves into a general-purpose language equally suitable for exploratory programming and systems programming, and even
high-performance computing (at least on traditional computer architectures, since nowadays some HPC solutions run on GPGPU and FPGA devices, and hypothetically
on emerging quantum computers, each case demanding a particular coding style usually available only in specialized, domain-specific programming languages).</p>

<p>For certain reasons (not discussed here due to lack of space) exploratory programming normally involves high-level semantics and especially the dynamic typing
discipline (when data types in programs are associated with values or objects at run time instead of variables or expressions during program compilation, as
opposed to the static typing). On the other hand, systems programming and HPC presume, well, high run-time performance. These properties conflict with each
other, since dynamic typing usually means that computers make more decisions at program run time, which slows down performance by itself and also hinders
further performance optimizations.</p>

<p>Nonetheless, real-world applications often consist of components with different flexibility and performance requirements. For instance, an application may
include inherently dynamic event-driven user interface code and much more static domain area (back-end) code where most hot (critical) instruction paths are
concentrated.</p>

<p>Sophisticated (and expensive in implementation) JIT compilation techniques (used, e.g., in V8 and Mozilla's JavaScript VMs and LuaJIT), including the so-called
tracing JIT, allow you to gain great performance for dynamic languages. Still, such techniques hardly satisfy the above goal and offer notably lower performance
than classic ahead-of-time compilation for equivalent programs written in an inherently static language (such as C, Modula-2, Ada, or Rust, to name a more
recent language); the slowdown may be somewhere between 4 and 10 times (which is still an impressive improvement compared to what more affordable
implementations offer). This happens because in practice such VMs have to anticipate the program execution profile (and hence data types) at run time (with
varying success) instead of exploiting static hints the programmer might provide about the profile, either explicitly or rather implicitly.</p>

<p>Due to the conflict described above, other languages that do achieve the above goal (e.g., Objective-C) are normally hybrid languages that solve the problem by
combining and providing both low-level but high-performance features with high-level but low-performance ones (for instance, Objective-C semantically and even
syntactically looks like a mix between C and Smalltalk).</p>

<p>The approach MANOOL-2 adopts is different: MANOOL-2 is essentially a dynamically typed language with no explicit HPC-related features (such as static types),
but its type system is specifically devised to enable significant amount of type inference during compilation (with sporadic or rather implicit help from the
programmer). In MANOOL-2 this inference is based on long-established data and control flow analysis algorithms and function inlining, and there seems to be an
intimate connection between type inference and constant/value/condition propagation (including their interprocedural variants). Note that typing discipline
(static vs dynamic) is orthogonal to this issue: there is still no such thing as “false negatives due to failed type checks” in MANOOL-2.</p>

<p>The advantage of this approach is that the programmer uses a more compact language and thus has to master fewer features and make fewer decisions as to which
features to use in each particular case and for each particular component of the program (the programmer still should be aware of how the compiler infers types
and performs other deductions and which coding techniques lead to the maximum performance boost in hot paths, but performance hints can be introduces gradually,
if needed at all).</p>

<p>Perhaps the closest such project is Julia. However, Julia is specifically oriented on the area of scientific computing, has high startup times, and still offers
suboptimal performance (albeit better than JavaScript or Lua). MANOOL-2 should overcome such issues, and it is a viable goal according to my preliminary
experiments.</p>

<p>Note that apart from higher run-time performance, statically typed languages are also traditionally associated with higher software engineering standards, as
opposed to “quick-and-dirty” exploratory style solutions. However, the position MANOOL-2 adopts is that a sophisticated static type system used for defect
preventing purposes (while being useful in practice) should belong better to external tools and not to the programming language itself (though, the type system
of MANOOL-2 makes it more suitable for programming in-the-large in comparison to an ordinary dynamically typed language).</p>

<p>All of the above is not just a business idea. I have actually performed some experiments and studied viability of the optimization algorithms and (what's most
important) what limitations of such algorithms can and should be condoned in practice. And of course, there is also the current version of MANOOL as a starting
point. In conclusion and as a matter of simple illustration, here is a piece of code in MANOOL-2 with some comments regarding its expected high-performance
hallmarks:</p>

<pre><code>{ {extern "manool.org.18/std/2.0/all"} in
: let
  Fold = -- left-fold some elements yielded by some generator G
  { proc I; Op; G as inline -- polymorphic procedure
  : do I after   -- refcounting for G on entry/exit is optimized out
  : for E = G do -- iterate over elements in RAM, no dynamic dispatch
    I = I!.Op[E] -- just "addsd" on x86, no dispatch or type checks
  }
  in
: let
  Avg = -- average elements of an array A of Binary64 floats
  { proc A as -- monomorphic procedure
    {assert Size[A.as[{array F64}]] &gt; 0} -- tiny O(1) overhead
    Fold[F64[0]$; (+); A] / F64[Size[A]] -- no dispatch or type checks
  }
  in
  -- The return type of Avg is actually known at compile-time - F64:
  Out.Write_line[Avg[{array F64}[F64[1] F64[2] F64[3] F64[4] F64[5]]$]]
  Out.Write_line[Avg[{array I64}[1 2 3 4 5]$]] -- signals Type_mismatch
}
</code></pre>

<!-- begin post footer -->

<hr>
<p><strong>The end</strong> — Questions? — Email me: <a href="mailto:info@manool.org">info@manool.org</a></p>



<!-- end post footer -->


<!-- end main content -->
    </div>
  </div></div>]]>
            </description>
            <link>https://manool.org/blog/2020-10-04/native-run-time-performance-for-a-high-level-dynamically-typed-programming-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991652</guid>
            <pubDate>Wed, 04 Nov 2020 18:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Economics of Sex Robots]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24991249">thread link</a>) | @elsewhen
<br/>
November 4, 2020 | https://dianaverse.com/2020/10/30/uncanny-vulvas/ | <a href="https://web.archive.org/web/*/https://dianaverse.com/2020/10/30/uncanny-vulvas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-441">
	<!-- .entry-header -->

	
	
	<div>
		
<p>This is a lightly edited version of an article I wrote that first appeared in <a rel="noreferrer noopener" href="https://jacobitemag.com/2018/04/24/uncanny-vulvas/" target="_blank">Jacobite</a>. I had a great conversation about this article and evolutionary psychology more generally (<a rel="noreferrer noopener" href="https://philosophicaldisquisitions.blogspot.com/2018/08/episode-44-fleischman-on-evolutionary.html" target="_blank">link here</a>) with  J<a rel="noreferrer noopener" href="https://twitter.com/JohnDanaher?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor" target="_blank">ohn Danaher</a>, who <a rel="noreferrer noopener" href="https://www.amazon.com/Robot-Sex-Social-Ethical-Implications-ebook/dp/B08BT1G87G/ref=cm_cr_arp_d_product_top?ie=UTF8" target="_blank">edited a book about sex robots</a>. Most recently, <a href="https://dianaverse.com/2020/10/30/zombiesexbots/" target="_blank" rel="noreferrer noopener">I gave a presentation as a damaged android for the Zombie Apocalypse Medicine meeting about the dangers of counterfeit fitness. </a></p>



<hr>



<p><strong>Uncanny Vulvas- Diana Fleischman</strong></p>



<p>Sex is consistently underrated as a driver of innovation. Yes, space exploration helped us develop the technology for things like cochlear implants, powdered (machine) lubricants and scratch resistant lenses. Lust has furthered the development of cash transfers, point-of-view filming and video chat. I predict that historians of the development of artificial intelligence are going to see sexual gratification as one of the phenomenon’s great motivators. Evolutionary psychology can give us insight into how sex robots are going to develop and the ramifications they’ll have on society.</p>



<p>Sexbots are usually woman-shaped&nbsp;<em>gynoid</em>&nbsp;machines. At the&nbsp;present time,&nbsp;sex robots are simple: they’re silicone sex dolls that have some capacity for movement and response. Manufacturers are rolling out new models and new promises: sex robots that respond to touch and penetration, sex robots with interchangeable faces and bodies and sex robots with&nbsp;<a rel="noreferrer noopener" href="https://www.nytimes.com/2017/07/17/opinion/sex-robots-consent.html" target="_blank">different personalities</a>. Future robots will have the allure and cues of fertility of a flesh-and-blood woman combined with the artificial intelligence that creates compulsive reward directed behavior. An intelligence, unlike the intelligence of humans, that will have the gratification of its owner as the only goal. </p>



<p>Sex robots are overwhelmingly gynoid because heterosexual men drive the market for sexual products like prostitution and pornography. Across cultures, men desire more sexual partners, need to know someone for less time before they want to have sex with them, and have lower standards for a sexual liaison than women. Looking at gay men is instructive here. Their sexual interactions are not limited by women’s sexual choosiness and they, on average, have many more sexual partners than straight men or lesbians.</p>



<figure><img data-attachment-id="448" data-permalink="https://dianaverse.com/time-partner-known-consenting-to-sex/" data-orig-file="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png" data-orig-size="568,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="time-partner-known-consenting-to-sex" data-image-description="" data-medium-file="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=300" data-large-file="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=568" src="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=568" alt="" srcset="https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png 568w, https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=150 150w, https://dianafleischman.files.wordpress.com/2020/10/time-partner-known-consenting-to-sex.png?w=300 300w" sizes="(max-width: 568px) 85vw, 568px"><figcaption>A woman would have to know someone for 3 months to be as likely to have sex with someone as a man would be after one day- via<a href="https://en.wikipedia.org/wiki/David_Buss" target="_blank" rel="noreferrer noopener"> David Buss</a></figcaption></figure>



<p>It isn’t hard to see the reason for this. Men don’t get pregnant and don’t lactate, and they have smaller, easier-to-produce sex cells than women.&nbsp;For a man, the cost of producing offspring is cheap. Getting one’s genes into the next generation is the engine of evolution. The low opportunity costs make men motivated to take every opportunity, even if it comes in the form of a robot. Ever think a dog is dumb for growling at his reflection in the mirror? Human men can become aroused looking at flat images of nude women in black and white,&nbsp;<a href="https://en.wikipedia.org/wiki/Evolutionary_mismatch" target="_blank" rel="noreferrer noopener">our evolved psychology can respond in maladaptive ways towards novel stimuli.</a></p>



<p>Courtship is expensive and complicated by design,&nbsp;and it’s the limiting factor&nbsp;of the sexual fulfillment of men.&nbsp;Women impose costs on men to gain sexual access for very good reasons: to test their genetic fitness and their long-term potential supporting a&nbsp;family. If courtship is costly and the costs are not clearly defined, this not only tests a man’s motivation toward a specific woman, it also acts to monopolize a man’s resources so he can’t afford to woo anyone else. Pornography and prostitution are popular because they arrive at sexual end goals, or a reasonable facsimile, with more clarity and lower costs than in the mating market.</p>



<p>The complications of courtship are driving improvements in sexual substitutes, like masturbation aids (e.g. fleshlight, fliphole) and 3-D&nbsp;porn. There are already thousands of <a href="https://en.wikipedia.org/wiki/RealDoll" target="_blank" rel="noreferrer noopener">RealDolls </a>in the world, silicone sex dolls that cost around $6,000 each.&nbsp;<a href="https://en.wikipedia.org/wiki/LovePlus" target="_blank" rel="noreferrer noopener"><em>LovePlus</em>&nbsp;</a>is a Japanese game in which players interact with a virtual girlfriend including kissing her by touching the screen and taking her out on dates, has&nbsp;<a href="https://www.dailydot.com/irl/video-game-girlfriend-loveplus-japan/" target="_blank" rel="noreferrer noopener">hundreds of thousands of users</a>.&nbsp;<em>LovePlus</em>&nbsp;is a great demonstration of how this market&nbsp;<a href="https://www.kotaku.com.au/2014/05/love-plus-makes-you-care-about-a-virtual-girl/" target="_blank" rel="noreferrer noopener">isn’t only about providing sex</a>, but also virtual companionship. You can’t even have virtual sex with Rinko, the ingénue of the game. These substitutes aren’t very good, and yet they are already competing with flesh-and-blood companionship.</p>



<figure><img data-attachment-id="444" data-permalink="https://dianaverse.com/sex-doll-mouth/" data-orig-file="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg" data-orig-size="621,472" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="sex-doll-mouth" data-image-description="" data-medium-file="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=300" data-large-file="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=621" src="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=621" alt="" srcset="https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg 621w, https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=150 150w, https://dianafleischman.files.wordpress.com/2020/10/sex-doll-mouth.jpg?w=300 300w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"><figcaption>A silicone facsimile of a woman’s face- <a href="https://www.shutterstock.com/image-photo/shenzhen-china-1108-female-silicone-doll-1343425748" target="_blank" rel="noreferrer noopener">via Alex Raysikh from shutterstock</a></figcaption></figure>







<p>Union&nbsp;power, increases in mandatory working standards, and minimum wage&nbsp;laws&nbsp;accelerate the push toward&nbsp;automation.&nbsp;Machines&nbsp;are already replacing cashiers&nbsp;and&nbsp;factory workers. Soon the jobs of truck drivers, clerks, and accountants&nbsp;will be automated. The current political climate around courtship and interactions between the sexes is more powerful than&nbsp;the&nbsp;market forces that are&nbsp;replacing jobs,&nbsp;because escalating costs aren’t transparent and neither is the punishment for not paying them. If a business owner wants to adhere to employment laws, he reads them. The costs of courtship are codified nowhere.</p>



<p>The average single man paying attention to&nbsp;contemporary&nbsp;social fashions&nbsp;will struggle to understand the new rules of meeting, courting, or having sex with women. Something as banal as trying to converse with a woman wearing headphones&nbsp;<a href="https://uk.askmen.com/news/dating/talking-to-women-who-are-wearing-headphones.html" target="_blank" rel="noreferrer noopener">is now often considered harassment</a>. A man’s chances of mating success increase when he approaches many women, but so too do his chances of a gaining reputation as sexist, exploitative, or immoral. To take a fraught example, how does a man know that a woman is genuinely consenting to sex?&nbsp;A lack of ability to pick up on cues can incur catastrophic costs.</p>



<p>Men high in conscientiousness, who are sensitive to social disapproval but who nonetheless have difficulty reading subtle social cues, could make good husbands for women.&nbsp;These men are unlikely to want to take the risk of approaching women. As substitutes like sex robots and virtual companions become better and cheaper,&nbsp;they will monopolize the attention of such men.</p>



<p>Think of an introverted engineer with Asperger’s syndrome who wasn’t sure how to broach a conversation with a woman back in 2015 and definitely isn’t sure how to&nbsp;do that in today’s climate. In 10 years he could have a beautiful robot companion (indeed, he could have one that could emulate the experience of having sex with dozens of&nbsp;different&nbsp;women) that has a lower barrier to entry than the mating market and that keeps him satisfied enough to&nbsp;remain a&nbsp;happy&nbsp;bachelor. Some woman misses out on a conscientious guy with a good income who might not know exactly how to respond when she says “nothing’s wrong,” but will definitely keep the cars tuned up to get the kids to their mathematics championships. The world might miss out on his sons and daughters and their analytical approaches to some of the world’s problems.</p>



<p>The kinds of men described above, who have difficulty reading social signals but who are nonetheless strongly sexually motivated, have a characteristic that means&nbsp;they’ll be less put off by sex robots than the average person: resistance to perceiving the uncanny valley. “<a href="https://en.wikipedia.org/wiki/Uncanny_valley" target="_blank" rel="noreferrer noopener">The uncanny valley</a>” is the way that representations that fall just short of looking like humans&nbsp;<a href="https://www.strangerdimensions.com/2013/11/25/10-creepy-examples-uncanny-valley/" target="_blank" rel="noreferrer noopener">often look “creepy.”</a>&nbsp;Anthropomorphized robots are more relatable and trustworthy than machine-like robots. It’s also difficult to imagine that many people would want to have sex with a conglomeration of gears and wheels.</p>



<p>My view is that&nbsp;the uncanny valley&nbsp;is something analogous to&nbsp;<a href="https://en.wikipedia.org/wiki/Capgras_delusion" target="_blank" rel="noreferrer noopener">Capgras delusion</a>,&nbsp;a psychological disorder that causes sufferers to believe that someone&nbsp;they&nbsp;know has been taken over by an imposter,&nbsp;often inhuman. According to&nbsp;<a href="https://www.ted.com/talks/vilayanur_ramachandran_on_your_mind" target="_blank" rel="noreferrer noopener">VS Ramachandran</a>, there are two aspects to recognizing faces: the identification of the external familiar representation and the “internal” validation – the warm emotion that goes along with it. In the uncanny valley, you recognize a robot as humanlike, but it’s missing the facial movement or some other characteristic that gives you a warm feeling of recognition. Many men won’t experience the uncanny valley, especially with regards to sex robots. These men are going to be the early adopters. Men are worse at identifying faces than women and are far more likely to have&nbsp;<a href="https://en.wikipedia.org/wiki/Prosopagnosia" target="_blank" rel="noreferrer noopener">prosopagnosia</a>, the inability to recognize faces.</p>



<p>Sex is weird.&nbsp;Sex is&nbsp;gross&nbsp;and awkward.&nbsp;Natural selection addressed this issue by causing arousal to attenuate the&nbsp;human&nbsp;disgust response. It’s worth noting that men have&nbsp;a&nbsp;much lower&nbsp;baseline&nbsp;sexual disgust than women,&nbsp;and that sexual excitement&nbsp;further reduces&nbsp;disgust sensitivity in men.&nbsp;In a&nbsp;<a href="http://people.duke.edu/~dandan/webfiles/PapersPI/Sexual%20Arousal%20and%20Decision%20making.pdf" target="_blank" rel="noreferrer noopener">classic paper</a>&nbsp;by Dan Ariely,&nbsp;aroused men&nbsp;had much more positive attitudes about all kinds of unusual sexual acts.&nbsp;Sexually aroused men were&nbsp;more likely to say&nbsp;that it would be fun to watch a woman urinating or that they could imagine getting sexually excited by contact with an animal). 3-D pornography of video game or cartoon characters that might be creepy in a nonsexual context are&nbsp;<a href="https://www.rollingstone.com/glixel/news/daily-glixel-people-were-thirsty-for-overwatch-zelda-porn-in-2017-w515316/the-top-video-game-porn-searches-of-2017-w515317" target="_blank" rel="noreferrer noopener">popular genres</a>. The most direct evidence that men won’t be put off by uncanny vulvas is from a&nbsp;<a href="http://faculty.utrgv.edu/zhixiang.chen/cs6174/papers/Strait_paper2.pdf" target="_blank" rel="noreferrer noopener">paper</a>&nbsp;that laments the “unabashed sexualization of female-gendered robots” in comments on YouTube&nbsp;videos of&nbsp;robots.&nbsp;Bawdy comments&nbsp;on gynoids&nbsp;– “you’ll have to replace it monthly due to semen corrosion,”&nbsp;for example&nbsp;– were more frequent than comments expressing unease.</p>



<p>Perhaps&nbsp;we should encourage&nbsp;some men&nbsp;to use sex robots. Men who get&nbsp;environmental&nbsp;cues that they’re evolutionary dead-ends disproportionately menace society. In the 1980s, evolutionary psychologist couple Wilson and Daly found that perpetrators of violence and homicide had something in common: they were young, single and didn’t have access to the kinds of resources&nbsp;<a href="https://www.economist.com/news/special-report/21688587-young-single-idle-males-are-dangerous-work-and-wedlock-can-tame-them-men-and-mayhem" target="_blank" rel="noreferrer noopener">with which to win mates</a>. Polygynous societies in which wealthier men have access to multiple women are more violent and less stable because they have a class of young men without the prospect of getting a mate. Monogamy, rather than being the state of nature, may have been an …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dianaverse.com/2020/10/30/uncanny-vulvas/">https://dianaverse.com/2020/10/30/uncanny-vulvas/</a></em></p>]]>
            </description>
            <link>https://dianaverse.com/2020/10/30/uncanny-vulvas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991249</guid>
            <pubDate>Wed, 04 Nov 2020 17:45:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Down to the Suburbs]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24991178">thread link</a>) | @eldavido
<br/>
November 4, 2020 | https://blog.shortbar.com/working-from-home-in-homewood-77368bd848ea | <a href="https://web.archive.org/web/*/https://blog.shortbar.com/working-from-home-in-homewood-77368bd848ea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@davidralbrecht?source=post_page-----77368bd848ea--------------------------------" rel="noopener"><img alt="David Albrecht" src="https://miro.medium.com/fit/c/96/96/0*sJ-ajeRfD0gwSk72." width="48" height="48"></a></p></div></div></div></div><p id="af2b">Before I got married, I ran a Chinese class. Our rotating cast of six drilled tones and measure words every Wednesday for about two years, in the 2nd Street WeWork, just south of Market Street in San Francisco.</p><p id="200a">Our teacher was a guy from Beijing named <a href="https://www.yelp.com/biz/dennis-language-services-san-francisco" rel="noopener">Dennis Zhu</a>. I got to know Dennis pretty well, and in many ways, he’s a stereotypical Boomer — mid-60s, kids in their 30s, west San Francisco house bought 20 years ago for peanuts — except he’d grown up in China. No doubt, the ’60s in the US were bad — assassinations, riots, Vietnam—but it’s a daytime sitcom compared to Dennis, who was forcibly moved to a farm, along with 10 million other “urban intellectual youth”, to play the harmonica and chop wood. They called it the <a href="https://en.wikipedia.org/wiki/Down_to_the_Countryside_Movement" rel="noopener">Down to the Countryside Movement</a>, only one part of the larger Cultural Revolution, that among other things included book burnings, mass executions, and the complete annihilation of land titles in large parts in China.</p><p id="399c">Big resettlements like this mark a generation. Fifty years on, Dennis can still tell you where he went, how he felt, and how pointless and futile the whole thing felt.</p><p id="2b6f">And here we are, somewhere in the middle (?) of the American COVID outbreak. My wife and I took a month or two off after Amelia, our first daughter, was born in early April, but the search for childcare has been difficult — reduced capacity at day cares, and a tight market for nanny share. With Caroline working remotely and me getting Dials up and running, we packed our bags and headed to my parents place in Homewood, the town of my childhood. Three generations sit down to dinner each night, and my parents couldn’t be happier.</p></div></div></section><section><div><div><p id="f055">Thus, our migration —the Down to the Suburbs Movement — or whatever we end up calling it. A forced migration, of maybe 100,000 (?) people, brought upon us not by politics, but by disease. The urban intellectual gentry, with our degrees, and money, and jobs in law / tech / finance.</p><p id="a9d9"><a href="https://www.strongtowns.org/journal/2020/10/26/developing-the-underdeveloped" rel="noopener">“Intellectual strip-mining”</a>. That’s what some call the hiring practices of the Goldman Sachs, the Googles, the DLA Pipers: showing up at the best universities across the country, grabbing the best-educated, most driven talent, and shuttling them off to well-paid jobs in glass high-rises in Denver, San Francisco, Seattle, or New York.</p><p id="48a4">And these people — I’m one of them — with my car-light lifestyle, interesting job employing novel computer vision algorithms, and successful marriage — wonder what the rest of the country “doesn’t get it”. Why someone making $12/hour at Target doesn’t want to pay yet another gas tax to get to work, living in a place without sidewalks, where the only real option is to drive.</p><p id="d2fb">The Down to the Suburbs Movement is our opportunity. A time when we can talk to our parents’ neighbors — regardless of their degrees, or what color sign they have in their yard — about how things are going.</p><p id="ede2">To many Americans, facebook is a blue square on their phone — something mystical that dropped from the sky, like calculus or the Bible — not a bunch of buildings at the end of the Dumbarton, where real people work. Ditto for Uber, Netflix, Amazon, Apple — major products, minting millionaires, profits and cashflow driving the entire S&amp;P 500. All clustered into a tiny little strip of land where shacks sell for millions and the pressure to perform is so intense, kids <a href="https://www.theatlantic.com/magazine/archive/2015/12/the-silicon-valley-suicides/413140/" rel="noopener">kill themselves</a> rather than be seen as “failures”.</p><p id="69e6">If you’re in the suburbs, here are some things you might consider.</p><p id="f0cd">Get a meeting with your city’s mayor, economic development director, or anyone else you can, in the city government. Help them understand <a href="https://twitter.com/naval/status/1002103832879419392" rel="noopener">Naval’s tweet</a>: “The Internet has massively broadened the possible space of careers. Most people haven’t figured this out yet.” Tell them about Internet marketing. Show them how code, or niche e-commerce products, or new subscription media, are enabling entirely new types of economic and creative output.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2212/1*dzc0q0xRA_mnKjXYMlRHaA.png" width="1106" height="578" srcset="https://miro.medium.com/max/552/1*dzc0q0xRA_mnKjXYMlRHaA.png 276w, https://miro.medium.com/max/1104/1*dzc0q0xRA_mnKjXYMlRHaA.png 552w, https://miro.medium.com/max/1280/1*dzc0q0xRA_mnKjXYMlRHaA.png 640w, https://miro.medium.com/max/1400/1*dzc0q0xRA_mnKjXYMlRHaA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*dzc0q0xRA_mnKjXYMlRHaA.png?q=20"></p></div></div></div><figcaption>Me talking about <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwjDqbXTuufsAhVYV80KHdHWBBMQFjAAegQIBhAC&amp;url=https%3A%2F%2Fwww.hfhighschool.org%2Ffile.aspx%3FDocumentId%3D3483&amp;usg=AOvVaw2Ng3-WPf3sh5W3pmOckN8M" rel="noopener">self-driving trucking</a> at my high school</figcaption></figure><p id="f4d9">Use your resources — know-how, connections, capital — to solve problems, get things done, and contribute. As part of our “balanced investing diet”, my wife, brother-in-law, and I started a small investment partnership last year. As I write this, I’m sitting in a building we own, next door to a pastry shop I helped get going. In the back of the building, over 100 kids show up for daycare in a 7600-square foot facility. We got tired of hearing about kids tripping on the broken asphalt, so we made drawings (my wife is an architect), borrowed money from a few friends, and managed the thing through to completion. We did it because Silicon Valley instilled in us a bias for action, and gave us the skills, and connections, to get it done.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2916/1*q6tkuFtv1KhUvpgog5MsSw.png" width="1458" height="542" srcset="https://miro.medium.com/max/552/1*q6tkuFtv1KhUvpgog5MsSw.png 276w, https://miro.medium.com/max/1104/1*q6tkuFtv1KhUvpgog5MsSw.png 552w, https://miro.medium.com/max/1280/1*q6tkuFtv1KhUvpgog5MsSw.png 640w, https://miro.medium.com/max/1400/1*q6tkuFtv1KhUvpgog5MsSw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*q6tkuFtv1KhUvpgog5MsSw.png?q=20"></p></div></div></div><figcaption>Architecture.</figcaption></figure><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/8064/1*ZV8_c7Sjn7ebrqJcfMrEdg.jpeg" width="4032" height="3024" srcset="https://miro.medium.com/max/552/1*ZV8_c7Sjn7ebrqJcfMrEdg.jpeg 276w, https://miro.medium.com/max/1104/1*ZV8_c7Sjn7ebrqJcfMrEdg.jpeg 552w, https://miro.medium.com/max/1280/1*ZV8_c7Sjn7ebrqJcfMrEdg.jpeg 640w, https://miro.medium.com/max/1400/1*ZV8_c7Sjn7ebrqJcfMrEdg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ZV8_c7Sjn7ebrqJcfMrEdg.jpeg?q=20"></p></div></div></div><figcaption>Now the kids can play outside without breaking their wrists (actually happened). Bottom-left/bottom-right shows prior condition of asphalt — the whole area used to look like that.</figcaption></figure><p id="646e">Don’t be obnoxious. Listen as much as you talk. Don’t be a blowhard. Just talk, share what you’re doing, how it’s going, and try to show people that cynicism, bickering, and bureaucracy are no match for education, well-applied effort, and progress.</p><p id="340f">From <a href="http://www.paulgraham.com/hubs.html?viewfullsite=1" rel="noopener">Paul Graham</a>:</p><blockquote><p id="8f9f">I flew into the Bay Area a few days ago. I notice this every time I fly over the Valley: somehow you can sense something is going on. Obviously you can sense prosperity in how well kept a place looks. But there are different kinds of prosperity. Silicon Valley doesn’t look like Boston, or New York, or LA, or DC. I tried asking myself what word I’d use to describe the feeling the Valley radiated, and the word that came to mind was optimism.</p></blockquote><p id="c910">Few cities anywhere have the talent or tax base of a place like San Francisco. But every city has its strengths. I still think Chicago is the ideal site for a packaged food business accelerator. The south suburbs, where I am now, delivers an incredibly good quality of life even on $20–30k/year; that’s a major achievement in its own right, something the San Francisco Board of Supervisors could never accomplish, and the recipe for a manufacturing renaissance. The solution is playing to your strengths, not trying to out-chip or out-software Silicon Valley.</p><p id="97fc">My hope — prayer, even — is that we can use this time to spread a sense of optimism, progress, and belief that things can be better. This time won’t last forever. Try to use it well.</p></div></div></section></div>]]>
            </description>
            <link>https://blog.shortbar.com/working-from-home-in-homewood-77368bd848ea</link>
            <guid isPermaLink="false">hacker-news-small-sites-24991178</guid>
            <pubDate>Wed, 04 Nov 2020 17:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building LXD Images with Packer and Ansible]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24990903">thread link</a>) | @eniac111
<br/>
November 4, 2020 | https://petrovs.info/post/2020-11-03-building-lxd-with-packer | <a href="https://web.archive.org/web/*/https://petrovs.info/post/2020-11-03-building-lxd-with-packer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">



<div>
    
    
    <p><img src="https://petrovs.info/post/img/container.gif" alt="container"> Building from scratch machines with similar configuration is not very wise. Unless it’s not often. Preparing at least LXD base images would be helpful. Small routine tasks like changing the default repositories, MOTD, adding ssh keys and base tools would take more than 5 minutes per machine. 5 new machines per week, that takes a lot. To be effective, system administrators should be lazy and rational.</p>
<p>Packer from Hashi corp is really good tool for building immutable infrastructure. It supports building of different images for the cloud, on-premise environments and desktop hypervisors simultaneously.</p>
<p>LXD is a hypervisor for Linux containers and virtual machines (since version 4.0). The containers in LXD are stateful. This means that their files are persistent compared to Docker where storage mounts are necessary. Also, the  LXD containers are most likely full system virtualization. They run a full bootstrapped operating system userspace with the init system.
The key difference between LXD and LXC is that LXD is a hypervisor for LXC containers and KVM virtual machines. LXD is based on liblxc and contains REST api.</p>
<p>I won’t cover the initial configuration of LXD in this post. Packer is written in GoLang and it’s a single binary. It could be downloaded in arhive from the <a href="https://www.packer.io/downloads">official download page</a>. Alternatively, it can also be installed with <a href="https://formulae.brew.sh/formula-linux/packer">homebrew</a>. The binary could be put in <code>/usr/local/bin</code> or in another directory of the working machine which is in the PATH.</p>
<p>The Ansible provisioner is still not compatible with the LXD builder module. There is a known bug, it hangs on “collecting artifacts” ( <a href="https://github.com/hashicorp/packer/issues/9034">#PACKER-9034</a> ). Ansible is not getting the correct IP of the container from Packer and it’s stuck on trying to connect with SSH.</p>
<p>A workaround is using the <code>ansible-local</code> provisioner. The difference is that the Ansible runs locally inside the container. It must be installed in advance with the <em>shell</em> provisioner. Now it’s not necessary to copy the playbook inside the container with <em>file</em> provisioner. <em>ansible-local</em> provisioner does it automatically and creates a temporary directory.</p>
<p>Example Packer json (<code>lxd-ansible-local.json</code>):</p>
<div><pre><code data-lang="json">{
  <span>"provisioners"</span>: [
    {
      <span>"type"</span>: <span>"shell"</span>,
      <span>"inline"</span>: <span>"[ \"$(ansible --version &gt; /dev/null &amp;&amp; echo ok)\" != 'ok' ] &amp;&amp; apt update &amp;&amp; apt -y install ansible || echo 'ansible already installed.'"</span>
    },
    {
      <span>"type"</span>: <span>"ansible-local"</span>,
      <span>"playbook_file"</span>: <span>"./playbook/example-playbook.yml"</span>,
      <span>"playbook_dir"</span> : <span>"./playbook"</span>
    }
  ],


  <span>"builders"</span>: [
    {
      <span>"type"</span>: <span>"lxd"</span>,
      <span>"name"</span>: <span>"acme-focal"</span>,
      <span>"image"</span>: <span>"ubuntu-daily:focal"</span>,
      <span>"output_image"</span>: <span>"acme_ubuntu-focal"</span>,
      <span>"init_sleep"</span>: <span>"10"</span>,
      <span>"publish_properties"</span>: {
        <span>"description"</span>: <span>"Focal image by ACME corp."</span>
      }
    }
  ]
}

</code></pre></div><p>Here we have the shell provisioner which is installing Ansible with bash one-liner.</p>
<p><code>"playbook_file": "./playbook/example-playbook.yml"</code> - The exact name of the playbook file to be executed;</p>
<p><code>"playbook_dir" : "./playbook"</code> - The playbook directory to be copied to the container. Have a look at the roles config in the playbook file below!;</p>
<p><code>"name": "acme-focal"</code> - Name of the started temporary container and name of the task for logging;</p>
<p><code>"image": "ubuntu-daily:focal"</code> - Our image is based on ubuntu-daily:focal ;</p>
<p><code>"output_image": "acme_ubuntu-focal"</code> - The name of our new image;</p>
<p><code>"init_sleep": "10"</code> - Seconds to sleep between launching the container and provisioning it. My DNS is slow. That’s why the value is high.</p>
<p>Example playbook (<code>./playbook/example-playbook.yml</code>):</p>
<div><pre><code data-lang="yaml">---

  - <span>hosts</span>: <span>127.0.0.1</span>
    <span>connection</span>: <span>local</span>
    <span>roles</span>:
      - <span>playbook/roles/acme-firstfive</span>
</code></pre></div><p>There is nothing special here. Only the roles path is important. Packer is copying this file to the root working directory. That’s why the exact path to the role must be specified, including the playbook dir.</p>
<p><code>connection: local</code> parameter is used with <code>127.0.0.1</code> for host.</p>
<h3 id="the-whole-file-tree-is-published-herehttpscodepetrovsinfoblagopacker-lxd-demo-as-example-project">The whole file tree is published <a href="https://code.petrovs.info/blago/packer-lxd-demo">here</a> as example project.</h3>
<h2 id="building">Building</h2>
<p>To build the project, simply run:</p>
<div><pre><code data-lang="bash">git clone https://code.petrovs.info/blago/packer-lxd-demo.git <span>&amp;&amp;</span> cd packer-lxd-demo

packer build lxd-ansible-local.json
</code></pre></div><p>The temporary container is deleted immediately after deployment and only the image is published. To keep the container running for debugging in case of failure, use the option <code>-on-error=abort</code>:</p>
<div><pre><code data-lang="bash">packer build -on-error<span>=</span>abort lxd-ansible-local.json
</code></pre></div>
<p>Let’s have a look at the demo:</p>
<p><a href="https://asciinema.org/a/370407"><img src="https://asciinema.org/a/370407.svg" alt="asciicast"></a></p>
<h3 id="to-be-done">To be done</h3>
<p>I didn’t try the option to build LXD VM image. It should work the same way. For virtualization, the <code>--vm</code> option is passed with <code>lxd launch</code>. Probably it must be implemented in Packer unless there is an option for command line arguments to lxc. LXD VM’s use the same format and repositories as the container images. The only difference is that they are compressed qcow’s. LXD virtualization is a topic for another post.</p>
<p>There is no option for choosing LXD profiles in Packer. It’s an important feature. For example, in my home setup, <code>lxd launch</code> must receive profiles for networking and storage. There are different networks and the default configuration won’t boot.</p>
<p>Already mentioned, the Ansible provisioner currently doesn’t work with the LXD provisioner but Ansible-local is a workaround.</p>

    <p><a onclick="openComments()">Comments</a></p>
    
    <h4><a href="https://petrovs.info/">Back to Home</a></h4>
</div>


        </div></div>]]>
            </description>
            <link>https://petrovs.info/post/2020-11-03-building-lxd-with-packer</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990903</guid>
            <pubDate>Wed, 04 Nov 2020 17:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mutated Coronavirus from Minks is a threat to Humans]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24990845">thread link</a>) | @xbmcuser
<br/>
November 4, 2020 | https://www.bt.dk/politik/alle-mink-skal-slaas-ihjel-muteret-coronavirus-fra-mink-er-en-trussel-for | <a href="https://web.archive.org/web/*/https://www.bt.dk/politik/alle-mink-skal-slaas-ihjel-muteret-coronavirus-fra-mink-er-en-trussel-for">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    

<p>Situationen omkring coronasmitte blandt mink har nu udviklet sig til et kritisk stadie i Nordjylland.</p>
<p>Helt inde i regeringskontorerne kategoriseres situationen som meget alvorlig, og der tales om en coronavirus 2.0.</p>


<p>Derfor har regeringen besluttet, at alle minkbesætninger nu skal slås ihjel, fordi coronavirus er muteret blandt mink og har spredt sig til mennesker.</p>
<p>Det fortæller statsminister Mette Frederiksen på et pressemøde onsdag.</p>
<div><p>»I mister livsværk, som i nogle tilfælde er gået i arv igennem flere generationer. Det er en sorgens dag for jer og for alle, der arbejder i mink-erhvervet. Det er regeringen bevidst om,« siger Mette Frederiksen til minkavlerne.</p><p>En muteret coronavirus er vandret fra mink til mennesker og har siden spredt sig kraftigt blandt borgerne i Nordjylland.</p></div>
<p>Tirsdag modtog regeringen et notat fra Statens Serum Institut (SSI), som har udsat den muterede coronavirus for antistoffer.</p>


<p>Resultatet var ifølge SSI dybt bekymrende, fordi den muterede coronavirus ikke reagerede godt på antistofferne.</p>
<figure itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
        <a href="https://bt.bmcdn.dk/media/cache/resolve/image_1240/image/156/1564385/23568501-mink2.jpg" title="When the Danish Veterinary and Food Administration killed mink in Brovst, they had no containers for the dead mink. Therefore, they were just thrown to the ground. Foto: Private photo">
                        <img src="https://bt.bmcdn.dk/media/cache/resolve/image_1240/image/156/1564385/23568501-mink2.jpg" width="" height="" alt="When the Danish Veterinary and Food Administration killed mink in Brovst, they had no containers for the dead mink. Therefore, they were just thrown to the ground." data-original="https://bt.bmcdn.dk/media/cache/resolve/image_1240/image/156/1564385/23568501-mink2.jpg" data-old-src="data:image/gif;base64,R0lGODlhEAAJAIAAAP///wAAACH5BAEAAAAALAAAAAAQAAkAAAIKhI+py+0Po5yUFQA7">
        
    
        </a>
                    <figcaption>
                <span>
                                            When the Danish Veterinary and Food Administration killed mink in Brovst, they had no containers for the dead mink. Therefore, they were just thrown to the ground.
                                                                <span>Foto: Private photo</span>
                                    </span>
            </figcaption>
            <a href="">Vis mere</a>
            
            </figure>

<p>Dermed er der risiko for, at en eventuel vaccine mod covid-19 ikke vil have den ønskede effekt, hvis den muterede virus fra mink spreder sig yderligere blandt mennesker.</p>
<p>Samtidig er bekymringen, at den nye coronavirus fra mink betyder, at alle mennesker, som har været smittet med corona, igen kan blive ramt af den muterede coronavirus.</p>
<p>Der er desuden nye restriktioner på vej for borgere i en række kommuner i det nordjyske for at stoppe spredningen af coronavirussen fra mink.</p>


<p>Det drejer sig indtil videre om kommunerne Hjørring, Frederikshavn, Brønderslev, Jammerbugt, Thisted og Læsø, oplyser Mette Frederiksen.</p>
<p>»Vi ved godt, at vi efterlader jer i Nordjylland i uvished til i morgen. Det beklager jeg. Men vi skal handle nu. Det drejer sig om liv og død ikke kun i Danmark, men i hele verden,« siger Mette Frederiksen.</p>
<p>De nye restriktioner bliver meldt ud torsdag.</p>
<p>Siden regeringen modtog det bekymrende notat fra SSI tirsdag, har man i regeringskontorerne arbejdet på højtryk for at finde ud af, hvilke restriktioner der skal til.</p>


<p>Coronavirussen har spredt sig voldsomt på de danske minkfarme siden sommer. I skrivende stund har mere end 207 minkbesætninger fået konstateret corona, og derfor skal alle disse mink aflives.</p>
<p>Men nu lyder befalingen fra Mette Frederiksen, at samtlige mink på de godt 1.100 minkfarme i Danmark skal aflives.</p>

</div></div>]]>
            </description>
            <link>https://www.bt.dk/politik/alle-mink-skal-slaas-ihjel-muteret-coronavirus-fra-mink-er-en-trussel-for</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990845</guid>
            <pubDate>Wed, 04 Nov 2020 17:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Denmark to cull millions of minks over mutated coronavirus]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 230 (<a href="https://news.ycombinator.com/item?id=24990724">thread link</a>) | @ndanmand
<br/>
November 4, 2020 | https://www.thelocal.dk/20201104/denmark-to-cull-millions-of-minks-over-mutated-coronavirus | <a href="https://web.archive.org/web/*/https://www.thelocal.dk/20201104/denmark-to-cull-millions-of-minks-over-mutated-coronavirus">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://storage.googleapis.com/ddos-shield.appspot.com/shield-logo-mono-darktext.svg" width="250px" height="50px" alt="Project Shield Logo"></p><p>You will be connected to <b>www.thelocal.dk</b> in just a moment...</p><p><a href="https://g.co/shield">Learn about Project Shield</a></p></div></div>]]>
            </description>
            <link>https://www.thelocal.dk/20201104/denmark-to-cull-millions-of-minks-over-mutated-coronavirus</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990724</guid>
            <pubDate>Wed, 04 Nov 2020 16:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starting a SaaS business when you’ve never met your cofounder]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24990723">thread link</a>) | @boomahora
<br/>
November 4, 2020 | https://accordably.com/blog/starting-saas-business-remote-cofounders | <a href="https://web.archive.org/web/*/https://accordably.com/blog/starting-saas-business-remote-cofounders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>The most fundamental core of any business relationship is trust. Traditionally this was built through multiple interactions, which included at least in-person meeting.</p><p>It seemed that something about meeting in person helped solidify what was discussed. Whether this is through body language or both parties being able to lower their guards and speak somewhat informally.</p><p>These in-person meetings have been a staple for long-lasting business relationships. However, the ability for these type of interactions has been put on hold thanks to the current pandemic. The startup community has had to adapt to these restrictions and in my opinion, the perfect environment for entrepreneurship was created.</p><p>People with extra time on their hands and nothing to do.</p><p>While I recognize and have experienced the downsides of this pandemic from a business perspective, I try to look at the positives. This motivation is what led to my most recent startup, <a href="https://accordably.com/" target="_blank" rel="noopener noreferrer">Accordably, which is a competitor monitoring solution</a>.</p><h2><strong>How do you find a cofounder?</strong></h2><p>Alright, great, you want to start a business, but how do you actually find a cofounder?</p><p>I wish I could tell you that this was the easy part, but it’s actually probably the hardest.</p><p>It’s going to be a lot of trial and error.</p><p>We are in more restricted social times, so it becomes even more difficult. A good place to start is with previous colleagues that you’ve worked with. You know them from a professional perspective, you’ve seen how they act with colleagues and their work ethic.</p><p>Remember, the stakes are much higher when it’s your own business, so these favourable employee working traits don’t always translate into a good cofounder.</p><p>Personally, I would recommend checking out different digital communities, you’d be surprised who you’ll meet and might find someone that has very similar goals to you.</p><p>My personal favourite community is Indie Hackers. They have a specific group called <a href="https://www.indiehackers.com/group/looking-to-partner-up" target="_blank" rel="noopener noreferrer">“Looking to partner up”</a> and you will find a wide variety of people looking to start a business.</p><p>I am biased as that’s where I met the cofounder of Accordably.</p><h2><strong><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1279,h_356/https://accordably.com/wp-content/uploads/2020/10/Version-1.png" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1279,h_356/https://accordably.com/wp-content/uploads/2020/10/Version-1.png" alt="Remote cofounders of Accordably" width="1279" height="356" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1279/https://accordably.com/wp-content/uploads/2020/10/Version-1.png 1279w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://accordably.com/wp-content/uploads/2020/10/Version-1-300x84.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://accordably.com/wp-content/uploads/2020/10/Version-1-1024x285.png 1024w" data-sizes="(max-width: 1279px) 100vw, 1279px" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1279/https://accordably.com/wp-content/uploads/2020/10/Version-1.png 1279w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_300/https://accordably.com/wp-content/uploads/2020/10/Version-1-300x84.png 300w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1024/https://accordably.com/wp-content/uploads/2020/10/Version-1-1024x285.png 1024w"></strong></h2><h2><strong>What to look for when choosing a cofounder?</strong></h2><p>The ideal match is someone who is the complete opposite of your skillset. Think of it like an ice hockey team. If your team was all goalies, you’d get nowhere. You need balance and different strengths to help push your product over the top.</p><p>Now one thing that shouldn’t be the complete opposite is your motivation. Finding someone who has the same drive is important or else there could be a growing resentment in your near future.</p><p>No two situations are the same and this is why it’s difficult to find a cofounder. There needs to be the right mix of similar professional goals and differing skillsets to build a strong tandem.</p><p>Another important attribute is whether you can see yourself getting along with this person from a social perspective. Face it, you’re going to have to spend a lot of time speaking with this person and planning out the future of your business.</p><p>There are some personality types that just don’t mix. Even if your skillsets are the perfect match, your mental health could be at risk if find yourself in a toxic work relationship.</p><p>For me, building a startup isn’t necessarily about the money (I mean it helps of course!) but it’s an outlet where my voice has a direct impact on the future of the business. I can test out crazy ideas and not worry about angry investors or upsetting management.</p><h2><strong>How to build trust when you’ve never met?</strong></h2><p>Just because you meet somebody in person doesn’t automatically create trust. Everyone has their own problems and you’ll never truly understand all the factors that go into their decisions.</p><p>So how do you build trust?</p><p>Time.</p><p>It takes time to build trust, you need to learn each others working habits, personalities and goals. After 2 weeks of working together, you should have a good understanding of the other person.</p><p>Of course, 2 weeks isn’t enough to jump into anything long term, but it will give you a good idea of direction and at that point, you can choose whether or not to continue.</p><p>While you should protect yourself, there’s no need to waste money on lawyers right at the start. Just write up a basic agreement that lays out your agreed upon terms and that you will revisit at a later stage.</p><p>Even with an agreement created by lawyers, you can get screwed over, so don’t worry about this too much at the start.</p><h2><strong>Finding the right idea</strong></h2><p>You’ve assembled a strong team, your skills match perfectly and you’re ready to go, but you’re missing one thing.</p><p>The idea!</p><p>This is difficult because whatever you choose you will be committing a large chunk of time to it, so you don’t want to make the wrong choice and get startup remorse.</p><p>Now I can’t stress this enough, no matter what you choose, make sure that it genuinely interests you. I’ve been in many situations that after the initial sparkle of an idea wears off, I’m stuck with a product that I find soul-crushingly boring.</p><p>The product may make money, but if you don’t enjoy it, it’s not worth it.</p><p>The approach that we took was rather than getting stuck in analysis paralysis, we just started with something.</p><p>We started working on a server-side web analytics solution and testing the market on this idea. We focused on building the infrastructure and easily transferable parts that we could use for other ideas.</p><p>After about a month of building, two things happened:</p><ol><li>We had enough time to see if our working styles meshed, which they did.</li><li>An idea popped up from a client request that we both believed in.</li></ol><p>Long story short, instead of beating your head against a wall trying to find the perfect idea, <strong>just start! </strong></p><p>Start with anything, inspiration will come, staying stagnant will just make you another wantrepreneur.</p><h2><strong>Maintaining communication</strong></h2><p>When it comes to remote cofounders the importance of communication is multiplied. Setting up the proper channels and maintaining a clear schedule is critical for success.</p><p>Keeping your teammate informed of your daily/weekly goals helps motivate and set accountability.</p><p>It’s very easy to procrastinate when you’re “the boss” but when you see your cofounder working their ass off and you’re doing nothing, that guilt should set in. Unless of course, you’re a prick.</p><p>Our main communication hub is Slack and we have integrated all of our tools to send notifications to this platform. This is our main dashboard and it helps keeps us on the same page for the health of the business.</p><p>Figure out what works for your duo and run with it. For us, we will have one or two calls a week and then for the smaller topics, just send each other audios clips.</p><p>This style has worked for us because when a thought is fresh, you can send a quick audio snippet and the other can listen to it when they have time.</p><p>Getting sidetracked is a big problem, so try to stay on goal and not overcommunicate with long phone calls every day.</p><p>One piece of advice that I can share when it comes to communication is that tone is not conveyed properly over text. I can’t count the number of times I’ve seen people get upset over an email or Slack message from a misunderstanding in tone.</p><p>In this digital world, don’t forget how to communicate. Jumping to conclusions or negatives will just set your team back. Clarify before making an unnecessary enemy.</p><h2><strong>Trust your gut</strong></h2><p>There is no one size fits all formula to finding a cofounder. People aren’t predictable. It takes time to find the right fit.</p><p>The one constant is your gut because no matter who you choose, you’re going to have to take a chance.</p><p>You could get burned or feel like you’re doing all the work, that’s just collateral damage in the life of an entrepreneur.</p><p>All that you can do is work with the information you’re given and decide if you believe in your cofounder. When it works, it works and you’ll eventually see success.</p><p>That’s what we’re working towards with Accordably and we’re excited to see what’s next for this project.</p></div></div></div>]]>
            </description>
            <link>https://accordably.com/blog/starting-saas-business-remote-cofounders</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990723</guid>
            <pubDate>Wed, 04 Nov 2020 16:54:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Paxos]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24990613">thread link</a>) | @matklad
<br/>
November 4, 2020 | https://matklad.github.io/2020/11/01/notes-on-paxos.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/11/01/notes-on-paxos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 1, 2020</p>
  <div id="preamble">
<div>
<p>These are my notes after learning the <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a> algorithm.
The primary goal here is to sharpen my own understanding of the algorithm, but maybe someone will find this explanation of Paxos useful!
This post assumes fluency with mathematical notation.</p>


<p>That means that I didn’t actually understand the algorithm.</p>
<p>What finally made the whole thing click are</p>

<p>I now think that the thing is actually much simpler than it is made to believe :-)</p>
<p>Buckle in, we are starting!</p>
</div>
</div>
<div>
<h2 id="what-is-paxos"><a href="#what-is-paxos"></a>What is Paxos?</h2>
<div>
<p>Paxos is an algorithm for implementing distributed consensus.
Suppose you have <code>N</code> machines which communicate over a faulty network.
The network may delay, reorder, and lose messages (it can not corrupt them though).
Some machines might die, and might return later.
Due to network delays, “machine is dead” and “machine is temporary unreachable” are indistinguishable.
What we want to do is to make machines agree on some value.
“Agree” here means that if some machine says “value is X”, and another machine says “value is Y”, then X necessary is equal to Y.
It is OK for machine to answer “I don’t know yet”.</p>
<p>The problem with this formulation is that Paxos is an elementary, but subtle algorithm.
To understand it (at least for me), a precise, mathematical formulation is needed.
So, let’s try again.</p>
<p>What is Paxos?
Paxos is a theorem about sets!
This is definitely mathematical, and is true (as long as you base math on set theory), but is not that helpful.
So, let’s try again.</p>
<p>What is Paxos?
Paxos is a theorem about nondeterministic state machines!</p>
<p>A system is characterized by a state.
The system evolves in discrete steps: each step takes system from <code>state</code> to <code>state'</code>.
Transitions are non-deterministic: from a single current <code>s1</code>, you may get to different next states <code>s2</code> and <code>s3</code>.
(non-determinism models a flaky network).
An infinite sequence of system’s states is called a behavior:</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>state_0 → state_1 → ... → state_n → ...
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Due to non-determinism, there’s a potentially infinite number of possible behaviors.
Nonetheless, depending on the transition function, we might be able to prove that some condition is true for any state in any behavior.</p>
<p>Let’s start with a simple example, and also introduce some notation.
I won’t use TLA+, as I don’t enjoy its concrete syntax.
Instead, math will be set in monospaced unicode.</p>
<p>The example models an integer counter.
Each step the counter decrements or increments (non-deterministically), but never gets too big or too small</p>
<div>
<p>Counter</p>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td><pre>Sets:
  ℕ -- Natural numbers with zero

Vars:
  counter ∈ ℕ

Init ≡
  counter = 0

Next ≡
    (counter &lt; 9 ∧ counter' = counter + 1)
  ∨ (counter &gt; 0 ∧ counter' = counter - 1)

Theorem:
  ∀ i: 0 ≤ counter_i ≤ 9

-- Notation
-- ≡: equals by definition
-- ∧: "and", conjunction
-- ∨: "or",  disjunction
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The sate of the system is a single variable — <code>counter</code>.
It holds a natural number.
In general, we will represent a state of any system by a fixed set of variables.
Even if the system logically consists of several components, we model it using a single unified state.</p>
<p>The <code>Init</code> formula specifies the initial state, the <code>counter</code> is zero.
Note that <code>=</code> is a mathematical equality, and not an assignment.
<code>Init</code> is a <em>predicate</em> on states.</p>
<p><code>Init</code> is true for <code>{counter: 0}</code>.<br>
<code>Init</code> is false for <code>{counter: 92}</code>.</p>
<p><code>Next</code> defines a non-deterministic transition function.
It is a predicate on pairs of states, <code>s1</code> and <code>s2</code>.
<code>counter</code> is a variable in the <code>s1</code> state, <code>counter'</code> is the corresponding variable in the <code>s2</code> state.
In plain English, transition from <code>s1</code> to <code>s2</code> is valid if one of these is true:</p>
<div>
<ul>
<li>
<p>Value of <code>counter</code> in <code>s1</code> is less than <code>9</code> and value of <code>counter</code> in <code>s2</code> is greater by 1.</p>
</li>
<li>
<p>Value of <code>counter</code> in <code>s1</code> is greater than <code>0</code>, and value of <code>counter</code> in <code>s2</code> is smaller by 1.</p>
</li>
</ul>
</div>
<p><code>Next</code> is true for <code>({counter: 5}, {counter: 6})</code>.<br>
<code>Next</code> is false for <code>({counter: 5}, {counter: 5})</code>.</p>
<p>Here are some behaviors of this system:</p>
<div>
<ul>
<li>
<p><code>0 → 1 → 2 → 3 → 4 → 5 → 6 → 7 → 8 → 9</code></p>
</li>
<li>
<p><code>0 → 1 → 0 → 1 → 0 → 1</code></p>
</li>
<li>
<p><code>0 → 1 → 2 → 3 → 3 → 2 → 1 → 0</code></p>
</li>
</ul>
</div>
<p>Here are some <strong>non</strong> behaviors of this system:</p>
<div>
<ul>
<li>
<p><code>1 → 2 → 3 → 4 → 5</code>: <code>Init</code> does not hold for initial state</p>
</li>
<li>
<p><code>0 → 2</code>: <code>Next</code> does not hold for <code>(0, 2)</code> pair</p>
</li>
<li>
<p><code>0 → 1 → 0 → -1</code>: <code>Next</code> does not hold for <code>(0, -1)</code> pair</p>
</li>
</ul>
</div>
<p>“behavior” means that the initial state satisfies <code>Init</code>, and each transition satisfies <code>Next</code>.</p>
<p>We can state and prove a theorem about this system: for every state in every behavior, the value of counter is between 0 and 9.
Proof is by induction:</p>
<div>
<ul>
<li>
<p>The condition is true in the initial state.</p>
</li>
<li>
<p>If the condition is true for state <code>s1</code>, and <code>Next</code> holds for <code>(s1, s2)</code>, then the condition is true for <code>s2</code>.</p>
</li>
<li>
<p>QED.</p>
</li>
</ul>
</div>
<p>As usual with induction, sometimes we would want to prove a <em>stronger</em> property, because it gives us more powerful base for an induction step.</p>
<p>To sum up, we define a non-deterministic state machine using two predicates <code>Init</code> and <code>Next</code>.
<code>Init</code> is a predicate on states which restricts possible initial states.
<code>Next</code> is a predicate on <em>pairs</em> of states, which defines a non-deterministic transition function.
<code>Vars</code> section describes the state as a fixed set of typed variables.
<code>Sets</code> defines auxiliary fixed sets, elements of which are values of variables.
<code>Theorem</code> section specifies a predicate on behaviors: <em>sequences</em> of steps evolving according to <code>Init</code> and <code>Next</code>.</p>
<p>The theorem does not automatically follow from <code>Init</code> and <code>Next</code>, it needs to be proven.
Alternatively, we can simulate a range of possible behaviors on a computer and check the theorem for the specific cases.
If the set of reachable states is small enough (finite would be a good start), we can enumerate <em>all</em> behaviors and produce a brute force proof.
If there are too many reachable states, we can’t prove the theorem this way, but we often can prove it to be wrong, by finding a counter example.
This is the idea behind model checking in general and TLA+ specifically.</p>
</div>
</div>
<div>
<h2 id="what-is-consensus"><a href="#what-is-consensus"></a>What is Consensus?</h2>
<div>
<p>Having mastered the basic vocabulary, let’s start slowly building towards Paxos.
We begin with defining what consensus is.
As this is math, we’ll do it using sets.</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
</pre></td><td><pre>Sets:
  𝕍 -- Arbitrary set of values

Vars:
  chosen ∈ 2^𝕍 -- Subset of values

Theorem:
    ∀ i: |chosen_i| ≤ 1
  ∧ ∀ i, j: i ≤ j ∧ chosen_i ≠ {} ⇒ chosen_i = chosen_j

-- Notation
-- {}:  empty set
-- 2^X: set of all subsets of X, powerset
-- |X|: cardinality (size) of the set
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The state of the system is a set of chosen values.
For this set to constitute consensus (over time) we need two conditions to hold:</p>
<div>
<ul>
<li>
<p>at most one value is chosen</p>
</li>
<li>
<p>if we choose a value at one point in time, we stick to it (math friendly: any two chosen values are equal to each other)</p>
</li>
</ul>
</div>
<p>Here’s the simplest possible implementation of consensus:</p>
<div>
<p>Consensus</p>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
</pre></td><td><pre>Sets:
  𝕍 -- Arbitrary set of values

Vars:
  chosen ∈ 2^𝕍 -- Subset of values

Init ≡
  chosen = {}

Next ≡
  chosen = {} ∧ ∃ v ∈ 𝕍: chosen' = {v}


Theorem:
    ∀ i: |chosen_i| ≤ 1
  ∧ ∀ i, j: i ≤ j ∧ (chosen_i ≠ {} ⇒ chosen_i = chosen_j)
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>In the initial state, the set of chosen values is empty.
We can make a step if the current set of chosen values is empty, in which case we select an arbitrary value.</p>
<p>This technically breaks our behavior theory: we require behaviors to be infinite, but, for this spec, we can only make a single step.
The fix is to allow empty steps: a step which does not change the state at all is always valid.
We call such steps “stuttering steps”.</p>
<p>The proof of the first condition of the consensus theorem is a trivial induction.
The proof of the second part is actually non-trivial, here’s a sketch.
Assume that <code>i</code> and <code>j</code> are indices, which violate the condition.
They might be far from each other in state-space, so we can’t immediately apply <code>Next</code>.
So let’s choose the <em>smallest</em> <code>j1 ∈ [i+1;j]</code> such that the condition is violated.
Let <code>i1 = j1 - 1</code>.
The condition is still violated for <code>(i1, j1)</code> pair, but this time they are subsequent steps, and we can show that <code>Next</code> does not hold for them, concluding the proof.</p>
<p>Yay! We have a distributed consensus algorithm which works for 1 (one) machine:</p>
<div>
<p>Distributed Consensus For One Machine</p>
<ol>
<li>
<p>Pick arbitrary value.</p>
</li>
</ol>
</div>
</div>
</div>
<div>
<h2 id="simple-voting"><a href="#simple-voting"></a>Simple Voting</h2>
<div>
<p>Let’s try to extend this to a truly distributed case, where we have <code>N</code> machine (“acceptors”).
We start with formalizing the naive consensus algorithm: let acceptors vote for values, and select the value which gets a majority of votes.</p>
<div>
<p>Majority Vote</p>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
</pre></td><td><pre>Sets:
  𝕍 -- Arbitrary set of values
  𝔸 -- Finite set of acceptors

Vars:
  votes ∈ 2^(𝔸×𝕍) -- Set of (acceptor, value) pairs

Init ≡
  votes = {}

Next ≡
  ∃ a ∈ 𝔸:
      ∃ v ∈ V: votes' = votes ∪ {(a, v)}
    ∧ ∀ v ∈ V: (a, v) ∉ votes

chosen ≡
  {v ∈ V: |{a ∈ 𝔸: (a, v) ∈ votes}| &gt; |𝔸| / 2}
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The state of the system is the set of all votes cast by all acceptors.
We represent a vote as a pair of an acceptor and the value it voted for.
Initially, the set of votes is empty.
On each step, some acceptor casts a vote for some value (adds <code>(a, v)</code> pair to the set of votes), but only if it hasn’t voted yet.
Remember that <code>Next</code> is a predicate on pairs of states, so we check <code>votes</code> for existing vote, but add a new one to <code>votes'</code>.
The value is chosen if the set of acceptors which voted for the value (<code>{a ∈ 𝔸: (a, v) ∈ votes}</code>) is at least half as large as the set of all acceptors.
In other words, if a majority of acceptors has voted for the value.</p>

<p>Let’s prove consensus theorem for Majority Vote protocol.
TYPE ERROR, DOES NOT COMPUTE.
The consensus theorem is a predicate on behaviors of states consisting of <code>chosen</code> variable.
Here, <code>chosen</code> isn’t a variable, <code>votes</code> is!
<code>chosen</code> is a function which maps current state to some boolean.</p>
<p>While it is intuitively clear what “consensus theorem” would look like for this case, let’s make this precise.
Let’s <em>map</em> states with <code>votes</code> variable to states with <code>chosen</code> variable using the majority rule, <code>f</code>.
This mapping naturally extends to a mapping between corresponding behaviors (sequences …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://matklad.github.io/2020/11/01/notes-on-paxos.html">https://matklad.github.io/2020/11/01/notes-on-paxos.html</a></em></p>]]>
            </description>
            <link>https://matklad.github.io/2020/11/01/notes-on-paxos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990613</guid>
            <pubDate>Wed, 04 Nov 2020 16:43:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sometimes two SQL queries are better than one]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24990602">thread link</a>) | @DevTalker
<br/>
November 4, 2020 | https://ddimitrov.dev/2020/10/04/optimizing-sql-queries-sometimes-two-queries-are-better-than-one/ | <a href="https://web.archive.org/web/*/https://ddimitrov.dev/2020/10/04/optimizing-sql-queries-sometimes-two-queries-are-better-than-one/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>Optimizing SQL queries can be done in many ways, but the current case that I am going to show you is a little bit different.</p>



<p>Last week my direct manager asked me to see why a list of data loads very slow. Also, if it was possible, to optimize it. &nbsp;The data set consisted of around 1000 rows. The load time for all rows was about 7 seconds. Even though each row was an elaborate business entity, that did not justify the load time. As every sane developer could see, there was something wrong.</p>



<p>We are using Entity Framework, so I started looking at the <a href="https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/linq/" target="_blank" rel="noreferrer noopener nofollow">LINQ</a> statement. It was a complex statement with a lot of joins. Also, the statement had some dynamic query building. But these things were not the problem.</p>



<p>A few lines below, I saw several fat subqueries. They also had many joins, filters end, etc. But the most “exciting” part was that they were the same. They only differed by a single where clause.</p>



<p>(simplified pseudo-code example)</p>



<pre>from organization in organisations
joinâ€¦
joinâ€¦
joinâ€¦
joinâ€¦
whereâ€¦
select
{
&nbsp;&nbsp;&nbsp;&nbsp; â€¦ other fields
&nbsp;&nbsp;&nbsp;&nbsp; PPartners = (very complex query with
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        WHERE p.Type == Type.Primary).ToList(),

&nbsp;&nbsp;&nbsp; &nbsp;SPartners = (very complex query with
&nbsp;                 WHERE p.Type == Type.Secondary).ToList(),

&nbsp;&nbsp;&nbsp; &nbsp;OPartners = (very complex query with
&nbsp;&nbsp;                WHERE p.Type == Type.Other).ToList()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
} </pre>



<p>I instantly understood that I had found the problem. I removed the subqueries to test how the load time will change. It dropped under a second.</p>



<p>Abstracting the sub queries slow execution time, you can imagine how big was the flattened dataset transferred from the SQL server.</p>



<h2><strong>Optimizing SQL queries or “Devide et impera”</strong></h2>



<p>In some cases, SQL query optimization will not help you. Yes, you can try to squeeze another 100 milliseconds using various technics, but you will hit a brick wall sooner or later.</p>



<p>Some of you will say that queries like these are avoidable with better DB design. I agree to some extent. As you know, we cannot predict everything or optimize for everything.</p>



<p>So, what was the solution that I introduced? I extracted the subqueries into a single query without any filtering (I pulled the data for all the partners). When I had both datasets loaded into the memory, I built the proper object that I needed.</p>



<p>Before doing this, I ensured that the datasets’ maximum size could not be more than a couple of thousands of rows!</p>



<p>After that <a href="https://ddimitrov.dev/2020/02/15/what-is-code-refactoring/">refactoring</a>, the load time dropped to a second and a half. Could I make it faster? Sure! <a href="https://ddimitrov.dev/2020/06/29/software-development-is-about-being-effective-and-efficient/">Is it worth it</a>? At this point, no.</p>



<p>In short â€“ sometimes it is much better to split your queries into two or even several ones.</p>



<p>When you find yourself writing a very complex query getting “everything” from the DB, think about this case.</p>
				
		</div></div>]]>
            </description>
            <link>https://ddimitrov.dev/2020/10/04/optimizing-sql-queries-sometimes-two-queries-are-better-than-one/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990602</guid>
            <pubDate>Wed, 04 Nov 2020 16:42:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Introduction to Deniability]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24990437">thread link</a>) | @some_furry
<br/>
November 4, 2020 | https://soatok.blog/2020/11/04/a-brief-introduction-to-deniability/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/11/04/a-brief-introduction-to-deniability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Earlier this week, security researcher Ryan Castellucci published a blog post with a somewhat provocative title: <em><a href="https://rya.nc/dkim-privates.html">DKIM: Show Your Privates</a></em>.</p>



<p>After reading the ensuing discussions on <a href="https://news.ycombinator.com/item?id=24972609">Hacker News</a> and <a href="https://web.archive.org/web/20201104135629/https://old.reddit.com/r/crypto/comments/jmv4qd/dkim_show_your_privates/gb0h87a/?context=9">Reddit</a> about their DKIM post, it seems clear that the importance of <strong>deniability</strong> in online communications seems to have been broadly overlooked.</p>



<h2>Security Goals, Summarized</h2>







<p>When you design or implement any communications protocol, you typically have most or all of the following security goals:</p>



<ul><li><strong>Confidentiality</strong>: Only the intended recipients can understand the contents of a message (almost always achieved through encryption).</li><li><strong>Integrity</strong>: The message will be delivered without alterations; and if it is, the recipient will know to reject it.</li><li><strong>Availability</strong>: Authorized users will have access to the resources they need (i.e. a medium they can communicate through).</li></ul>



<p>However, you may also have one or more of the following security goals:</p>



<ul><li><strong>Authenticity</strong>: In a group communication protocol, you want to ensure you can validate which participant sent each message. This is loosely related to, yet independent from, integrity.</li><li><strong>Non-Repudiation</strong>: An extension of authenticity, wherein you cannot deny that you sent a message after you sent it; it’s provable that you sent it.</li><li><strong>Deniability:</strong> The complement to non-repudiation, wherein you can prove that you sent a message to your recipient, and then at a future time make it possible for other participants to have forged the message.</li></ul>



<p>It’s tempting to think of deniability as the opposite of non-repudiation, but in practice, you want messages to have authenticity for <em>at least</em> a brief period of time for both.</p>



<p>However, you cannot simultaneously have deniability and non-repudiation in a communication. They’re mutually exclusive concepts, even if they both build off authenticity. Hence, I call it a complement.</p>



<p>Off-The-Record messaging achieved deniability through publishing the signing key of the previous message with each additional message.</p>



<h2>Security Properties of DKIM</h2>



<p><a href="https://rya.nc/dkim-privates.html">Ryan Castellucci’s blog post</a> correctly observed that the anti-spam protocol DKIM, as used by most mail providers in 2020, incidentally also offers non-repudiation…even if that’s not <em>supposed to be</em> a primary goal of DKIM.</p>



<p>Non-repudiation can be bolted onto any protocol with long-term asymmetric cryptographic keys used to generate digital signatures of messages–which is exactly what DKIM does.</p>



<h3>Real World Case Study</h3>



<p>A while ago, the New York Post published a DKIM-signed email from someone claiming to be named Vadym Pozharskyi to Hunter Biden–son of the presidential candidate and former Vice President Joe Biden. </p>



<p>Because the DKIM public keys used by Gmail during that time period are known–but <em>not</em> the private keys–it’s possible to authenticate that the emails came from Gmail and is a valid email. And someone <a href="https://github.com/robertdavidgraham/hunter-dkim">did exactly this</a>.</p>



<p>In a similar vein, if someone wanted to embarrass an executive at a large company, accessing their colleagues’ email and leaking messages would be sufficient, since DKIM could be used to verify that the emails are authentic.</p>



<h3>Deniability in DKIM</h3>



<p>Ryan’s proposal for introducing deniability in DKIM was to routinely rotate signing keys and publish fragments of their old DKIM private keys (which are RSA keys) so that anyone can reconstruct the private key after-the-fact.</p>



<p>This kind of deniability is mostly to mitigate against the harm of data leaks–such as your friend’s laptop getting stolen and someone trying to lambaste you on social media for an email you sent 10+ years ago–rather than provide a legal form of deniability. (We’re cryptography nerds, not lawyers.)</p>



<p>If the laptop theft scenario took place, with DKIM, someone can cryptographically <strong>prove</strong> you sent the email at a specific time to your friend with a specific body, because it’s signed by (presumably Gmail’s) DKIM keys.</p>



<p>Conversely, if you had used an email provider that practiced what Ryan proposed (rotating/publishing the private key at a regular interval), they couldn’t cryptographically prove anything. If the past private keys are public, anyone could have come along and forged the DKIM signature.</p>



<h2>On Post-Compromise Security</h2>



<p>The concept of <strong>Post-Compromise Security</strong> is somewhat related to deniability (but affects confidentiality rather than integrity or authenticity):</p>



<p>If someone successfully compromises one participant in a private discussion group, and their access is discovered, can the rest of the participants recover from this breach and continue to have privacy for future conversations?</p>



<p>It’s easy to see how the concepts are related.</p>



<ul><li>Deniability offers short-term authenticity followed by a long-term break in authenticity.</li><li>Post-Compromise Security offers long-term confidentiality even if there’s a short-term break in confidentiality.</li></ul>



<p>Robust private messaging protocols–such as what the IETF is trying to provide with <a href="https://datatracker.ietf.org/doc/draft-ietf-mls-protocol/">Message Layer Security</a>–would ideally offer both properties to their users.</p>



<p>Past attempts to build non-repudiation (through “message franking”) on top of cipher constructions like <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">AES-GCM</a> led to a class of attacks known affectionately as Invisible Salamanders, based on the title of the <a href="https://eprint.iacr.org/2019/016">relevant research paper</a>.</p>



<h2>In Conclusion</h2>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Apropos of nothing, I really wish Gmail would start publishing its expired DKIM secret keys.</p>— Matthew Green (@matthew_d_green) <a href="https://twitter.com/matthew_d_green/status/1323011619069321216?ref_src=twsrc%5Etfw">November 1, 2020</a></blockquote></div>
</div></figure>



<p>It might seem really weird for cryptographers to want large-scale email providers to publish their expired DKIM secret keys, but when you understand the importance of deniability in past private communications, it’s a straightforward thing to want.</p>



<p>It’s worth noting: Some security experts will push back on this, because they work in computer forensics, and making DKIM deniable would theoretically make their job slightly more difficult. </p>



<p>Keep their self-interest in mind when they’re complaining about this notion, since the proposal is <strong>not</strong> to publish non-expired DKIM secret keys, and therefore it would not make spam more challenging to combat.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/11/04/a-brief-introduction-to-deniability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990437</guid>
            <pubDate>Wed, 04 Nov 2020 16:27:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing Network Protocols with BPF]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24990261">thread link</a>) | @htroisi
<br/>
November 4, 2020 | https://blog.pixielabs.ai/ebpf-http-tracing/ | <a href="https://web.archive.org/web/*/https://blog.pixielabs.ai/ebpf-http-tracing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>This is the second in a series of posts in which we share how you can use eBPF to debug applications without recompilation / redeployment. The <a href="https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/" target="_blank" rel="noopener noreferrer">first post</a> provided a short introduction to eBPF and demonstrated how to use it to write a simple function argument tracer. In this second post, we will look at how to use eBPF to capture HTTP 1.X traffic.</p><p>Gaining visibility into HTTP traffic is valuable when working with distributed applications. This data can be used for performance, functional and security monitoring. Many applications accomplish this by utilizing middleware to add tracing or logging to HTTP requests in the application. One can also utilize popular open source frameworks like <a href="https://opentelemetry.io/" target="_blank" rel="noopener noreferrer">Open Telemetry</a> to instrument requests and related context. In this post, we will take a look at an alternative approach that utilizes eBPF to capture HTTP data without having to manually add instrumentation. One advantage of this approach is that it always works, even if applications have not been specifically instrumented.</p><p><a href="https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/" target="_blank" rel="noopener noreferrer">Part 1</a> of this series provides a more detailed overview of eBPF, which allows you to run restricted C code upon some trigger event. Kprobes provide a mechanism to trace the Kernel API or internals and uprobes provide a mechanism to intercept specific instructions in a user program. Since applications typically sit on top of the Kernel system API, if we capture the Kernel interface we should be able to capture all the ingress and egress data and reconstruct the HTTP requests.</p><p>Alternatively, we can use uprobes to carefully instrument underlying HTTP libraries (eg. net/http in Go) to capture HTTP requests directly. Since uprobes work at the application level, their implementation will be dependent on the underlying language used.</p><p>This post will explore tracing HTTP requests using both kprobes and uprobes and compare the tradeoffs for each.</p><h2>What happens during an HTTP request?</h2><p>Before we start writing any BPF code, let’s try to understand how HTTP requests are handled by the system. We will utilize the same <a href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/app/app.go" target="_blank" rel="noopener noreferrer">test application</a> we used in Part 1, a simple Golang HTTP server (simpleHTTP), however the results are generalizable to other HTTP applications.
The first step is to understand what Linux kernel APIs are used to send and receive data for a simple HTTP request.</p><p>We can use the Linux <a href="https://perf.wiki.kernel.org/index.php/Main_Page" target="_blank" rel="noopener noreferrer">perf</a> command to understand what system calls are invoked:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Using <code>curl</code>, we’ll make a simple HTTP request in another terminal window:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Back in the original terminal window, where the <code>perf</code> command is running, you should see a spew of data:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Note that we took care not to have any additional print statements in our <a href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/app/app.go" target="_blank" rel="noopener noreferrer">app.go</a> simple Golang HTTP server to avoid creating extra system calls.</p><p>Examining the output of the <code>perf</code> call shows us that there are 3 relevant system calls: <code>accept4</code>, <code>write</code>, <code>close</code>. Tracing these system calls should allow us to capture all of the data the server is sending out in response to a request.</p><p>From the server’s perspective, a typical request flow is shown below, where each box represents a system call. The Linux system call API is typically much more complex than this and there are other variants that can be used. For the purposes of this post we assume this simplified version, which works well for the application that we are tracing.</p><div><figure><img src="https://blog.pixielabs.ai/static/e9171b519eb9bd5e8cb37a3750e16f2d/http-request-flow-syscalls.png"><figcaption>System call flow for an HTTP request.</figcaption></figure></div><p>While the focus of this example is on tracing the HTTP response, it is also possible to trace the data sent in the HTTP request by adding a probe to the <code>read</code> syscall.</p><h2>Tracing with Kprobes</h2><p>Now that we know that tracing <code>accept4</code>, <code>write</code> and <code>close</code> are sufficient for this binary, we can start constructing the BPF source code. Our program will roughly look like the following:</p><div><figure><img src="https://blog.pixielabs.ai/static/351711bdbe0647329de98bc9574ed4bc/kprobe-tracing.png"><figcaption>Diagram of our eBPF HTTP tracer using kprobes.</figcaption></figure></div><p>There is some additional complexity in the implementation in order to avoid limitations in eBPF (stacksize, etc.), but at a high level, we need to capture the following using 4 separate probes:</p><ul><li><strong>Entry to <code>accept4</code></strong>: The entry contains information about the socket. We store this socket information</li><li><strong>Return from <code>accept4</code></strong>: The return value for accept4 is the file descriptor. We store this file descriptor in a BPF_MAP.</li><li><strong>Entry to <code>write</code></strong>: The write function gives us information about the file descriptor and the data written to that file descriptor. We write out this data to a perf buffer so the userspace tracing program can read it.</li><li><strong>Entry to <code>close</code></strong>: We use the file descriptor information to clear the BPF_MAP we allocated above and stop tracking this fd.</li></ul><p>Note that kprobes work across the entire system so we need to filter by PID to limit capturing the data to only the processes of interest. This is done for all the probes listed above.</p><p>Once the data is captured, we can read it to our Go userspace program and parse the HTTP response using the <a href="https://golang.org/pkg/net/http/" target="_blank" rel="noopener noreferrer"><code>net/http</code></a> library.</p><p>The kprobe approach is conceptually simple, but the implementation is fairly long. You can check out the detailed code <a href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/http_trace_kprobe/http_trace_kprobe.go" target="_blank" rel="noopener noreferrer">here</a>. For brevity, we left out a few details such as reading the return value from write to know how many bytes were actually written.</p><p>One downside to capturing data using kprobes is that we land up reparsing all responses since we intercept them after they have been converted to the write format. An alternative approach is to use uprobes to capture the data before it gets sent to the kernel where we can read the data before it has been serialized.</p><h2>Tracing with Uprobes</h2><p>Uprobes can be used to interrupt the execution of the program at a particular address and allow a BPF program to collect the underlying data. This capability can be used to capture data in a client library, but the underlying BPF code and addresses/offsets of interest will be dependent on the library's implementation . As a result, if there are changes in the client library, the uprobe will need to be updated as well. Therefore, it is best to add uprobes for client libraries that are unlikely to change significantly in order to minimize the number of updates we make to our uprobes.</p><p>For Go, we will try to find a tracepoint on the underlying <a href="https://golang.org/pkg/net/http/" target="_blank" rel="noopener noreferrer"><code>net/http</code></a> library. One approach is to directly examine the code to determine where to probe. We will show an alternate method that can be used to figure out which parts are relevant. For this, let’s run our application under <a href="https://github.com/go-delve/delve" target="_blank" rel="noopener noreferrer">delve</a>:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>As discussed earlier, the <code>write</code> syscall is utilized by the operating system in order to send a HTTP response. We therefore set a breakpoint there so that we can identify the underlying client code that triggers the syscall to 'write'. When we run the <code>curl</code> command again the program should interrupt. We get the backtrace using <code>bt</code>:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Examining the stack, we find that the <code>net/http.(*response).finishRequest</code> function on line 9 looks promising. The Go source code tells us that this function is invoked every time an HTTP request is completed. This function is a good spot to grab the data with uprobes for a particular request.</p><p>The capture of the data is a direct extension of our approach in Part 1. We employ the same strategy to read variables in the struct, except this time we need to chase a few pointers. The BPF code for this is documented and located <a href="https://github.com/pixie-labs/pixie/tree/main/demos/simple-gotracing/http_trace_uprobe" target="_blank" rel="noopener noreferrer">here</a>, along with the user space code required to read the recorded data.</p><p>In order to compare our two different approaches, we must consider</p><ol><li>Which probe is easier to design and implement?</li><li>Which probe is more performant?</li><li>Which probe is easier to maintain?</li></ol><p>To answer the first question, let’s look at the pros and cons of each approach.</p><table><thead><tr><th scope="col"></th><th scope="col">Pros</th><th scope="col">Cons</th></tr></thead><tbody><tr><td>kprobe</td><td><ul><li>Target language agnostic. </li><li>Simpler to implement and more maintainable. It does not rely on the implementation details of other libraries.</li></ul></td><td><ul><li>The user program might split a single request across multiple system calls. </li><li>There is some complexity in re-assembling these requests. </li><li>Doesn’t work with TLS.</li></ul></td></tr><tr><td>uprobe</td><td><ul><li>We can access and capture application context, such as stack trace, in addition to the request itself. </li><li>We can build the uprobes to capture the data after parsing is complete, avoiding repeated work in tracer. </li><li>Works with TLS.</li></ul></td><td><ul><li>Sensitive to the version of the underlying library being used. </li><li>Will not function with binaries that are stripped of symbols. </li><li>Need to implement a different probe for each library (and each programming language may have its own set of libraries). </li><li>Might be hard (impossible?) with dynamic languages like Python, since  it’s hard to find the right location to probe in their underlying runtime environments. </li><li>Causes an extra system call.</li></ul></td></tr></tbody></table><p>Conceptually, Kprobes are the clear winner since we can avoid any language dependence to perform HTTP capture. However, this method has the added caveat that we need to reparse every response, so we should investigate whether that introduces a significant performance overhead. It is worth calling out that kprobes do not work with TLS. However, we will share our method for tracing TLS requests using eBPF in a future blog post.</p><h2>Benchmarking performance of uprobes vs. kprobes</h2><p>Since these probes will be used to monitor applications in production, we want them to have minimal overhead. On a fully loaded system, we want to understand the impact of deploying our tracers. One metric we can use to understand the performance impact is to look at the impact on the observed latency and the ability to handle high request throughput. This is not a comprehensive test and we will utilize our simple app binary to perform it. Since the probes only add overhead when the actual HTTP request is made, rather than when the request is processed, our simple binary nearly simulates the worst-case scenario.</p><p>Our experimental setup looks like:</p><div><figure><img src="https://blog.pixielabs.ai/static/2ec33f85c5aef2844279c8a10d25b3f6/benchmark.png"><figcaption>Benchmark setup for comparing kprobes vs uprobes.</figcaption></figure></div><p>We utilize a modern Intel core-i9 machine with 14 physical cores to host both the load generator and the machine under test hosting the application and tracer. When running requests, we took care to ensure that the machine was under sufficient load to saturate the CPUs on the machine.</p><p>We captured HTTP requests of various durations by increasing the <code>iterations</code> parameter of the <code>computeE</code> function on our app.go http …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pixielabs.ai/ebpf-http-tracing/">https://blog.pixielabs.ai/ebpf-http-tracing/</a></em></p>]]>
            </description>
            <link>https://blog.pixielabs.ai/ebpf-http-tracing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990261</guid>
            <pubDate>Wed, 04 Nov 2020 16:09:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Victims of school bullying are at a higher risk of developing violent behavior]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 146 (<a href="https://news.ycombinator.com/item?id=24990064">thread link</a>) | @rustoo
<br/>
November 4, 2020 | https://www.uco.es/ucci/es/noticias-ingles/item/3138-victims-of-school-bullying-are-at-a-higher-risk-of-developing-violent-behavior-in-the-future | <a href="https://web.archive.org/web/*/https://www.uco.es/ucci/es/noticias-ingles/item/3138-victims-of-school-bullying-are-at-a-higher-risk-of-developing-violent-behavior-in-the-future">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A University of Cordoba and University of Cambridge study analyzed what factors in childhood and adolescence increase the likelihood of having violent behavior in adulthood</p><div>
			
<p>There is another pandemic that humans have been experiencing for a long time now and for which effective preventive measures have yet to be found: violence. This is shown in various ways in different aspects of life and continues to have serious consequences for society, the economy, our health and human relations. The onset of violent behavior can be observed from childhood and adolescence, so studying what aspects lead to the development of these kinds of behaviors and which curb them has become a necessary step in their prevention.</p>
<p>The University of Cordoba and the University of Cambridge have been collaborating for a long time now on research into aspects related to violence, thus helping decrease its risks and prevent it. In their latest piece of research, they studied possible risk and protection factors for violence and, in this way, they verified whether violent behavior can be predicted months or even years before it develops.</p>
<p>Specifically, the study focused on finding out if morality, victimization, empathy and social and emotional skills predict the expression of different violent behaviors in children and adolescents in different contexts, including at school and in a family setting. "These behaviors refer to, for instance, troubling behavior at home, including physical violence towards parents and siblings, at school, including physical violence towards teaching staff and schoolmates, and other settings, including bad behavior in public", explains Raquel Espejo Siles, doctoral student at the University of Cordoba who carried out this research during her stay at the Institute of Criminology at the University of Cambridge thanks to one of the ELMER grants from the Diputación de Córdoba (Cordoba's county government).</p>
<p>Raquel Espejo worked with Izabela Zych, Professor at the Psychology Department at the University of Cordoba and part of the LAECOVI (Study Laboratory on Coexistence and Violence Prevention) research group, whose line of research is this study's framework. The study also had the participation of David P. Farrington, Emeritus Professor of Criminology at the University of Cambridge, and Vicente J. Llorent, Professor at the Education Department at the University of Cordoba.</p>
<p>871 students between 10 and 17 years of age at different Andalusian educational centers took part in the research. They filled out two questionnaires, one in June 2017 and one in June 2018.</p>
<p>Interesting conclusions were drawn from the results. "We found that violence used directly towards people was related to a tendency to make impulsive decisions and to a blind motivation to accomplish one's aims, without regard for the disadvantages or negative consequences from using violence", reveals Raquel Espejo.</p>
<p>What is more, being a victim of bullying was detected as a risk factor for developing violent behavior at home against their family as well as at school. Likewise, those people who were violent in public or in class were shown to have higher scores in moral disengagement, meaning that they usually made excuses so that these acts would seem less serious than they really were.</p>
<p>At school, it was verified that higher scores for social and emotional competencies such as social awareness, self-management, motivation and decision making are protection factors against violence. Therefore, these results support prevention initiatives based on the potential of learning social and emotional skills at home as well as at school.</p>
<p>The data show that reducing victimization in a school setting could be effective in decreasing violence in different contexts in the future. "It is important to prevent violence, both victimization and bullying, since the data found in this study and others indicate that violence is a vicious cycle. Being the aggressor or the victim entails a high risk of developing the opposite role, reinforcing and increasing violence both at school and outside of school", points out Raquel Espejo.</p>
<p>According to this research study, enabling teenagers to reassess their goals and the consequences of their violent behavior could have an impact on decreasing violence further down the road. In addition, teaching different strategies to resolve issues in a different way could help them to compare and see the high individual and social price to pay for violent behavior.</p>
<p>This study is part of the "E-intelligence: risks and opportunities of emotional competencies expressed online" (PSI-2015-64114-R) project of the National Research, Development and Innovation Program, subsidized by the Ministry of Economic Affairs and Competitiveness. With the aim of having greater understanding of the reality of violence in childhood and adolescence, the team will continue to research about violent behavior in face to face and online contexts. Firstly, they have studied the factors that can curb or increase cyberhate in a study funded by the Center for Andalusian Studies. Secondly, they will continue working on the same line of research, investigating the link between bullying and drug use in a study financed by the Ministry of Health.</p>
<p>Raquel Espejo-Siles, Izabela Zych, David P. Farrington, Vicente J. Llorent. Moral disengagement, victimization, empathy, social and emotional competencies as predictors of violence in children and adolescents. Children and Youth Services Review. Doi: <a href="https://doi.org/10.1016/j.childyouth.2020.105337">https://doi.org/10.1016/j.childyouth.2020.105337</a></p>		</div></div>]]>
            </description>
            <link>https://www.uco.es/ucci/es/noticias-ingles/item/3138-victims-of-school-bullying-are-at-a-higher-risk-of-developing-violent-behavior-in-the-future</link>
            <guid isPermaLink="false">hacker-news-small-sites-24990064</guid>
            <pubDate>Wed, 04 Nov 2020 15:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bayesian’s Journey in Elections Season]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24989931">thread link</a>) | @lord_sudo
<br/>
November 4, 2020 | https://www.policypunchline.com/op-ed/2020/11/1/a-bayesians-journey-in-elections-season | <a href="https://web.archive.org/web/*/https://www.policypunchline.com/op-ed/2020/11/1/a-bayesians-journey-in-elections-season">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-layout-label="Post Body" data-type="item" data-updated-on="1604212405758" id="item-5f9e54a39e7da9554f3e11ef"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1604206981166_2407941"><div><h3>Tiger Gao, Jack Edmondson, Tom Bearpark, Michael Psenka</h3><p>This semester, Tiger, Jack, and Tom have been taking Princeton’s 1st-year PhD econometrics sequence with Prof. <a href="https://en.wikipedia.org/wiki/Christopher_A._Sims" target="_blank">Chris Sims</a>, who won the Nobel Prize in Economics in 2011 for his work in macroeconomics – more specifically, his pathbreaking application of <a href="https://en.wikipedia.org/wiki/Bayesian_inference"><strong>Bayesian</strong></a><strong> </strong>inference to evaluate economic policies. </p><p><span><strong>Nate Silver, widely considered as the preeminent pollster, uses Bayesian methods in his forecasting.</strong></span> Taking his course expanded our conception of statistics and probability theory in a way never before, and we thought it may be interesting to apply some of the influential Bayesian concepts he taught us to our political debates today. We hope this brief exploration below could be somewhat helpful in informing you of the foundational methodology that Silver uses to forecast.</p><p>The questions we seek to answer here are:&nbsp;</p><ul data-rte-list="default"><li><p>Was Nate Silver right in 2016?&nbsp;</p></li><li><p>Can we even judge whether a forecaster is right or wrong?</p></li><li><p>Are elections chaotic systems that we cannot predict or controlled systems that we can?</p></li><li><p>Should forecasters incorporate the likelihood of a coup / contested elections in their models?</p></li><li><p>Do alternative facts (or truths) exist?</p></li><li><p>Do we have enough data to make predictions for someone like Trump?</p></li><li><p>… and many more</p></li></ul><p>Our co-author Michael is a math major at Princeton, and those who have contributed to this article through comments and informal conversations include professors and graduate students in economics, mathematics, and political science. We would sincerely appreciate any feedback and hope this is only the start to many exciting conversations to come.&nbsp;</p><p>When Tiger first told his parents that he’s writing a long article on the theories and applications of elections forecasting, they said: “nobody cares about your math; just tell us who the winner will be.” This is what millions of voters truly want – clarity, simplicity, and accuracy. The fact that forecasting has become so complex that it would take us pages to explore even the most fundamental concepts only shows the progress made by political scientists, but also the unnecessary over-complication of simple ideas. The result is that the public receives much more and noisier information, while their understanding of the elections has not been improved. This is a great tragedy in our opinion, and in this article we hope to simplify and deconstruct some of those debates for you.&nbsp;</p><p><span><strong>What is Bayesian statistics?&nbsp;</strong></span><strong>(</strong>You may skip this technical segment if you just want to read why Nate Silver is worse than Crackhead Jim…)</p><p>Let us first set the scene. When we talk about statistical inference – the process that draws conclusions from sample data – two popular frameworks are the <a href="https://en.wikipedia.org/wiki/Frequentist_inference"><strong>frequentist</strong></a> and <strong>Bayesian</strong> methods.</p><p>Say you want to infer what percentage of American people want to vote for Trump. Frequentists would say: I don't know what that percentage is, but I know that value is fixed, meaning that it is a number that is not random. As long as you can ask everyone (and everyone answers truthfully), you’ll get that number. You can collect some data and make your estimation, and then only two things can happen: either your estimation is consistent with the actual “true” average, or it’s not. Well, the tricky thing is that you can never really test this hypothesis out unless you literally go out there and ask every single American.&nbsp;</p><p>Bayesians would say: sure we may never be able to ask every American’s opinion of Trump, but given our polling of people around us, we may be able to assign a probability distribution to that unknown percentage we’re interested in. For instance, I would assign almost zero probability that only less than 10% of people actually want to vote for Trump (highly improbable!); and maybe I’ll assign a 52% probability for a percentage between 25% and 35%, and such and so on…</p><p><strong>So, the Bayesian method allows you to start making predictions even with very small datasets!</strong> But the true beauty of Bayesian inference doesn’t stop here – it is that <strong>you would keep updating your beliefs as you see more data.</strong> For instance, maybe the first 50 people you talked to are all liberal college kids, so you might arrive at a belief that nobody supports Trump. But as you ask more people (hopefully now some people on the Right), you’ll realize that your “prior” belief (probability distribution) was wrong, and you can update your “posterior” belief based on the conservatives you’ve just talked to. You then go ask more people; and based on how right/wrong you are, you keep updating your belief and continue down this process…</p><p>In Bayesian statistics, you assign a probability distribution to all of your unknown parameters and predictions. The way you solve a problem using Bayesian inference is, you construct some joint probability distribution for your knowns and unknowns – and then use the laws of probability to make statements about the unknowns given the knowns.&nbsp;</p><p>It’s just three things in the equation: you have a “<strong>prior</strong>” (a belief about the true average height in your mind), and a “<strong>likelihood</strong>” (what values of that true average height is consistent with the data you have) – together, they help make up the “<strong>posterior</strong>” (the updated belief about true average height in your mind). <strong>In the later part of this article, prior simply means the belief you used to have before being exposed to any new data; posterior simply means the updated belief after seeing new facts and data.&nbsp;</strong></p><p>It sounds complicated, but in practice it’s an intuitive, iterative process: you already have some preconceived prior belief; you got some previous historical or new data; you go through them; you arrive at an updated posterior belief about the unknowns based on the data; you test this new belief against what you observe in reality; and based on how right/wrong you are, you update your belief and continue down this process…&nbsp;</p><p><strong>To get to the “truth,” you don't need to start with a lot of data; you just need to be willing to update your beliefs as you see more data, and update them especially strongly when something unexpected happens. </strong>You may wonder about all these “simulations” on 538 and why Silver’s predictions change every now and then – it’s because Silver keeps testing his beliefs against new data and updating his predictions. <span><strong>What Nate Silver does is a fundamentally beautiful statistical process.</strong></span></p><p><span><strong>Nate Silver was right – you just don’t understand statistics&nbsp;</strong></span></p><p>Nate Silver is a Bayesian, and his forecasting isn’t just popular amongst the public, but also highly regarded by many seasoned econometricians we’ve talked to. Silver’s final prediction on the 2016 election night was around 30% likelihood of Trump winning, and before then he fluctuated around 16% likelihood of Trump winning.</p><p>The side supporting Silver believes that Nate Silver wasn't wrong in 2016. We should not forget that 16% is the probability of getting a six in a die roll (or any other number), which is actually quite high.</p><p>So, the people who saw a 16% likelihood as “oh Trump is definitely going to lose" just simply didn’t understand statistics. Because of their lack of knowledge in statistics, the supporters of Silver would say, they could not grasp the true meaning of Silver’s forecast.</p><p>This is happening again in this election cycle. For the past few months, Trump has been consistently polling at below 45%, and Silver has now assigned him a <a href="https://projects.fivethirtyeight.com/2020-election-forecast/?cid=rrpromo" target="_blank">10% probability</a> of winning at the moment. This sounds absurd to most people at first sight. The difference is just 5% of the vote – how can you drastically reduce his winnings odds to 10%?!</p><p>But if you seriously reason through the probability, Silver is correct: in a two-person game where whoever gets above 50% wins, it is entirely reasonable to assign less than a 20% chance of winning to the candidate who has consistently polled at 45% or below for months. “I think you will be surprised at how far away 45% is from 50%,” an older economics graduate student extremely knowledgable in econometrics and statistics explained to us. Assuming that the remaining 55% are with Biden, then you are asking over 7.5 million Biden/undecided supporters to suddenly change their mind on elections day. 5% sounds small, but in reality it will be a dramatic shift. </p><p>So, it is entirely mathematically sound for Silver to have made his predictions back in 2016 and today. <strong>He was right then, and he is again right today saying that Trump has a 10% likelihood of winning.</strong></p><p><span><strong>Nate Silver was NOT right – because he can never be wrong!&nbsp;&nbsp;</strong></span></p><p>Those against Silver, however, would argue that Silver’s forecast was misleading, and expecting the public to understand the nuances of probability is unrealistic. <strong>You cannot expect the American public to react to a 16% likelihood as “oh Trump actually has pretty good odds!”</strong></p><p><span><strong>But we think there’s an even more <em>philosophical</em> and deeper argument to be made here, which is that Nate Silver cannot really be right or wrong when there’s no strict standard to judge him. </strong></span></p><p>Consider the example of Crackhead Jim. Every election, he just says that the Republican candidate has a 50% chance of winning, and the Democratic candidate has a 50% chance of winning.</p><p>No matter who wins, he will argue that he’s right and a genius – if Silver’s 16% were good odds, Crackhead Jim’s 50% would be <em>amazing </em>odds. So, is Jim much better than Silver? The question remains: how do you call out Crackhead Jim for the fraud he is?</p><p>The fact that we cannot make a judgement on who's right and who's wrong for a prediction of an election is in the same way that the physics community says that the famous “String Theory” cannot be right or wrong: there's no way to verify it. Sure, the math checks off in many models for String Theory, but there’s no fundamental way to say whether it’s a good theory because we still cannot run experiments on it to prove it’s in line with reality. This is why physicists refuse to definitely conclude whether String Theory is right or wrong. (This part is Michael trying to show off his physics knowledge). </p><p>Likewise, any …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.policypunchline.com/op-ed/2020/11/1/a-bayesians-journey-in-elections-season">https://www.policypunchline.com/op-ed/2020/11/1/a-bayesians-journey-in-elections-season</a></em></p>]]>
            </description>
            <link>https://www.policypunchline.com/op-ed/2020/11/1/a-bayesians-journey-in-elections-season</link>
            <guid isPermaLink="false">hacker-news-small-sites-24989931</guid>
            <pubDate>Wed, 04 Nov 2020 15:36:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The journey to a curl domain]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24989926">thread link</a>) | @headalgorithm
<br/>
November 4, 2020 | https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Good things come to those who wait?</p>



<p>When I created and started hosting the first websites for curl I didn’t care about the URL or domain names used for them, but after a few years I started to think that maybe it would be cool to register a curl domain for its home. By then it was too late to find an available name under a “sensible” top-level domain and since then I’ve been on the lookout for one.</p>



<h2>Yeah, I host it</h2>



<p>So yes, I’ve administrated every machine that has ever hosted the curl web site going all the way back to the time before we called the tool curl. I’m also doing most of the edits and polish of the web content, even though I’m crap at web stuff like CSS and design. So yeah, I consider it my job to care for the site and make sure it runs smooth and that it has a proper (domain) name.</p>



<h2>www.fts.frontec.se</h2>



<p>The first ever curl web page was hosted on “<code>www.fts.frontec.se/~dast/curl</code>” in the late 1990s (<a href="https://web.archive.org/web/19981202234521/http://www.fts.frontec.se/%7Edast/curl/">snapshot</a>). I worked for the company with that domain name at the time and ~dast was the location for my own personal web content.</p>



<h2>curl.haxx.nu</h2>



<p>The curl website moved to its first “own home”, with curl.haxx.nu in August 1999 (<a href="https://web.archive.org/web/19991013093821/http://curl.haxx.nu/">snapshot</a>) when we registered our first domain and the .nu top-level domain was available to us when .se wasn’t.</p>



<h2>curl.haxx.se</h2>



<p>We switched from curl.haxx.nu to curl.haxx.se in the summer of 2000 (when finally were allowed to register our name in the .se TLD) (<a href="https://web.archive.org/web/20001017164421/https://curl.haxx.se/">snapshot</a>).</p>



<p>The name “haxx” in the domain has been the reason for many discussions and occasional concerns from users and overzealous blocking-scripts over the years. I’ve kept the curl site on that domain since it is the name of one of the primary <a href="https://curl.haxx.se/sponsors.html">curl sponsors</a> and partly because I want to teach the world that a particular word in a domain is not a marker for badness or something like that. And of course because we have not bought or been provided a better alternative.</p>



<p><a href="https://www.haxx.se/">Haxx</a> is still the name of the company I co-founded back in 1997 so I’m also the admin of the domain.</p>



<h2>curl.se</h2>



<p>I’ve looked for and contacted owners of curl under many different TLDs over the years but most have never responded and none has been open for giving up their domains. I’ve always had an extra attention put on <code>curl.se</code> because it is in the Swedish TLD, the same one we have for Haxx and where I live.</p>



<h2>The curling background</h2>



<p>The first record on archive.org of anyone using the domain <code>curl.se</code> for web content is dated <a href="https://web.archive.org/web/20030830002347/http://www.curl.se/">August 2003</a> when the Swedish curling team “Härnösands CK” used it. They used the domain and website for a few years under this name. It can be noted that it was team <a href="https://en.wikipedia.org/wiki/Anette_Norberg">Anette Norberg</a>, which subsequently won two Olympic gold medals in the sport.</p>



<p>In September 2007 the site was renamed, still being about the sport curling but with the name “the curling girls” in Swedish (<em>curlingtjejerna</em>) which remained there for just 1.5 years until it changed again. “curling team Folksam” then populated the site with contents about the sport and that team until they let the domain expire in 2012. (Out of these three different curling oriented sites, the first one is the only one that still seems to be around but now of course on another domain.)</p>



<h2>Ads</h2>



<p>In early August 2012 the domain was registered to a new owner. I can’t remember why, but I missed the chance to get the domain then.</p>



<p>August 28 2012 marks the first date when curl.se is recorded to suddenly host a bunch of links to casino, bingo and gambling sites. It seems that whoever bought the domain wanted to surf on the good name and possible incoming links built up from the previous owners. For several years this crap was what the website showed. I doubt very many users ever were charmed by the content nor clicked on many links. It was ugly and over-packed with no real content but links and ads.</p>



<p>The last archive.org capture of the ad-filled site was done on October 2nd 2016. Since then, there’s been no web content on the domain that I’ve found. But the domain registration kept getting renewed.</p>



<h2>Failed to purchase</h2>



<p>In August 2019, I noticed that the domain was about to expire, and I figured it could be a sign that the owner was not too interested in keeping it anymore. I contacted the owner via a registrar and offered to buy it. The single only response I ever got was that my monetary offer was “too low”. I tried to up my bid, but I never got any further responses from the owner and then after a while I noticed that the domain registration was again renewed for another year. I went back to waiting.</p>



<h2>Expired again</h2>



<p>In September 2020 the domain was again up for expiration and I contacted the owner again, this time asking for a price for which they would be willing to sell the domain. Again no response, but this time the domain actually went all the way to expiry and deletion, which eventually made it available “on the market” for everyone interested to compete for the purchase.</p>



<p>I entered the race with the help of a registrar that would attempt to buy the name when it got released. When this happens, when a domain name is “released”, it becomes a race between all the potential buyers who want the domain. It is a 4-letter domain that is an English word and easy pronounceable. I knew there was a big risk others would also be trying to get it.</p>



<p>In the early morning of October 19th 2020, the curl.se domain was released and in the race of getting the purchase… I lost. Someone else got the domain before me. I was sad. For a while, until I got the good news…</p>



<h2>Donated!</h2>



<p>It turned out my friend <strong>Bartek Tatkowski</strong> had snatched the domain! After getting all the administrative things in order, Bartek graciously donated the domain to me and 15:00 on October 30 2020 I could enter my own name servers into the dedicated inputs fields for the domain, and configure it properly in our master and secondary DNS servers.</p>



<h2>curl.se is the new home</h2>



<p>Starting on November 4, 2020 <strong>curl.se is the new official home</strong> site for the curl project. The <code>curl.haxx.se</code> name will of course remain working for a long time more and I figure we can basically never shut it down as there are so many references to it spread out over the world. I intend to eventually provide redirects for most things from the old name to the new.</p>



<div><figure><a href="https://www.fastly.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-1200x630.png" alt="" width="190" height="100" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-200x105.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-450x236.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-768x403.png 768w" sizes="(max-width: 190px) 100vw, 190px"></a></figure></div>



<p>What about a www prefix? The jury is still out how or if we should use that or not. The initial update of the site (November 4) uses a www.curl.se host name in links but I’ve not done any automatic redirects to or from that. As the site is CDNed, and we can’t use CNAMEs on the apex domain (curl.se), we instead use anycast IPs for it – the net difference to users should be zero. (Fastly is a generous sponsor of the curl project.)</p>



<p>I also happen to own <code>libcurl.se</code> since a few years back and I’ll make sure using this name also takes you to the right place.</p>



<h2>Why not curl.dev?</h2>



<p>People repeatedly ask me. Names in the .dev domains are <em>expensive</em>. Registering <code>curl.dev</code> goes for 400 USD right now. <code>curl.se</code> costs 10 USD/year. I see little to no reason to participate in that business and I don’t think spending donated money on such a venture is a responsible use of our funds.</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/truthseeker08-2411480/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1923005">truthseeker08</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1923005">Pixabay</a>. Domain by Bartek Tatkowski.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24989926</guid>
            <pubDate>Wed, 04 Nov 2020 15:35:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Play the Chrome dino game on your Nintendo Switch]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24989555">thread link</a>) | @pcr910303
<br/>
November 4, 2020 | https://blog.tomayac.com/2020/11/04/play-the-chrome-dino-game-on-your-nintendo-switch/ | <a href="https://web.archive.org/web/*/https://blog.tomayac.com/2020/11/04/play-the-chrome-dino-game-on-your-nintendo-switch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article lang="en"><header><a href="https://blog.tomayac.com/2020/11/04/play-the-chrome-dino-game-on-your-nintendo-switch/"></a></header><section><p>I have landed an article over on <a href="https://web.dev/">web.dev</a> that <a href="https://web.dev/gamepad/">talks about the Gamepad API</a>. One piece of information from this article that our editorial board was not comfortable with having in there was instructions on how to play the Chrome dino game on a Nintendo Switch. So, here you go with the steps right here on my private blog instead.</p><figure><img src="https://blog.tomayac.com/images/nintendo-switch.jpg" width="800" height="240" alt="The hands of a person playing the Chrome dino game on a Nintendo Switch."><figcaption>Press any of the Nintendo Switch's buttons to play!</figcaption></figure><p>The Nintendo Switch contains a <a href="https://switchbrew.org/wiki/Internet_Browser#WifiWebAuthApplet">hidden browser</a>, which serves for logging in to Wi-Fi networks behind a captive portal. The browser is pretty barebones and does not have a URL bar, but, once you have navigated to a page, it is fully usable. When doing a connection test in system settings, the Switch will detect that the captive portal is present and display an error for it when the response for <a href="http://conntest.nintendowifi.net/">http://conntest.nintendowifi.net/</a> does not include the <code>X-Organization: Nintendo</code> HTTP header. I can make creative use of this by pointing the Switch to a DNS server that simulates a captive portal that then redirects to a search engine.</p><ol><li>Go to <strong>System Settings</strong> and then <strong>Internet Settings</strong> and find the Wi-Fi network that your Switch is connected to. Tap <strong>Change Settings</strong>.</li><li>Find the section with the <strong>DNS Settings</strong> and add <a href="http://45.55.142.122/">45.55.142.122</a> as a new <strong>Primary DNS</strong>. Note that this DNS server is <em>not operated by me</em> but a <a href="https://www.switchbru.com/dns/">third-party</a>, so proceed at your own risk.</li><li><strong>Save</strong> the settings and then tap <strong>Connect to This Network</strong>.</li><li>The Switch will tell you that <strong>Registration is required to use this network</strong>. Tap <strong>Next</strong>.</li><li>On the page that opens, make your way to <strong>Google</strong>.</li><li>Search for <strong>"chrome dino tomayac"</strong>. This should lead you to <a href="https://github.com/tomayac/chrome-dino-gamepad">https://github.com/tomayac/chrome-dino-gamepad</a>.</li><li>On the right-hand side in the <strong>About</strong> section, find the link to <a href="https://tomayac.github.io/chrome-dino-gamepad/">https://tomayac.github.io/chrome-dino-gamepad/</a>. Enjoy!</li><li>🚨 For regular Switch online services to work again, turn your DNS settings back to <strong>Automatic</strong>. Conveniently, the Switch remembers previous manual DNS settings, so you can easily toggle between <strong>Automatic</strong> and <strong>Manual</strong>.</li></ol><p>For the <a href="https://tomayac.github.io/chrome-dino-gamepad/">Chrome dino gamepad</a> demo to work, I have ripped out the Chrome dino game from the core Chromium project (updating an <a href="https://github.com/arnellebalane/trex-runner">earlier effort</a> by <a href="https://arnellebalane.com/">Arnelle Ballane</a>), placed it on a standalone site, extended the existing gamepad API implementation by adding ducking and vibration effects, created a full screen mode, and <a href="https://github.com/mehulsatardekar">Mehul Satardekar</a> contributed a dark mode implementation. Happy gaming!</p><p>You can also play <a href="https://tomayac.github.io/chrome-dino-gamepad/">Chrome dino</a> with your gamepad on this very site. The source code is available <a href="https://github.com/tomayac/chrome-dino-gamepad">on GitHub</a>. Check out the gamepad polling implementation in <a href="https://github.com/tomayac/chrome-dino-gamepad/blob/885eb6134805345bf31eeb9971830adeb84747ab/trex-runner.js#L529-L571"><code>trex-runner.js</code></a> and note how it is emulating key presses.</p></section></article></div></div>]]>
            </description>
            <link>https://blog.tomayac.com/2020/11/04/play-the-chrome-dino-game-on-your-nintendo-switch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24989555</guid>
            <pubDate>Wed, 04 Nov 2020 14:55:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toggle fullscreen mode with Fullscreen API]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24989510">thread link</a>) | @phongduong
<br/>
November 4, 2020 | https://phongduong.dev/blog/toggle-fullscreen-mode-with-fullscreen-api/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/toggle-fullscreen-mode-with-fullscreen-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Fullscreen API allows you to represent your application on the full screen. You can use it for your video player or game.</p>
<p>In this tutorial, we want to present the page in the full-screen mode by clicking turn on button</p>
<pre><code><span><span><span>&lt;</span>h1</span><span>&gt;</span></span>Fullscreen API<span><span><span>&lt;/</span>h1</span><span>&gt;</span></span>
<span><span><span>&lt;</span>button</span> <span>id</span><span><span>=</span><span>"</span>on<span>"</span></span><span>&gt;</span></span>Turn on fullscreen<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;</span>button</span> <span>id</span><span><span>=</span><span>"</span>off<span>"</span></span><span>&gt;</span></span>Turn off fullscreen<span><span><span>&lt;/</span>button</span><span>&gt;</span></span></code></pre>
<h2 id="check-the-mode-is-supported">Check the mode is supported</h2>
<p>First, you need to check whether the full-screen mode is supported first</p>
<pre><code><span>const</span> fullscreenSupported <span>=</span> <span>document</span><span>.</span><span>fullscreenEnabled</span><span>;</span></code></pre>
<p>It returns <code>false</code> if your browser doesn't support the full-screen mode or <code>fullscreen</code> feature is not allowed.</p>
<p>If the full-screen mode is not supported, you should show a notification for the user</p>
<pre><code><span>if</span> <span>(</span><span>!</span>fullscreenSupported<span>)</span> <span>{</span>
  <span>const</span> para <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>"p"</span><span>)</span><span>;</span>
  para<span>.</span><span>textContent</span> <span>=</span> <span>"Full screen mode is not supported"</span><span>;</span>
  <span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span>para<span>)</span><span>;</span>
  onButton<span>.</span><span>style</span><span>.</span><span>display</span> <span>=</span> <span>"none"</span><span>;</span>
  offButton<span>.</span><span>style</span><span>.</span><span>display</span> <span>=</span> <span>"none"</span><span>;</span>
<span>}</span></code></pre>
<h2 id="get-the-current-fullscreen-element">Get the current fullscreen element</h2>
<p>You can present any element in full-screen mode. To get the current element that is being represented in full-screen, you call <code>fullscreenElement</code>&nbsp;property of <code>document</code></p>
<pre><code><span>document</span><span>.</span><span>fullscreenElement</span><span>;</span></code></pre>
<p>It returns <code>null</code>, if the document is not in full-screen mode</p>
<h2 id="turn-on-full-screen-mode">Turn on full-screen mode</h2>
<p>You listen to the click event in the turn on button. In the event handler, you call <code>requestFullscreen()</code> of the element that you want present. It will return a <code>Promise</code> which is resolved after the full-screen mode is turned on. You need to check if the full-screen mode is supported and the mode is off.</p>
<pre><code><span>const</span> onButton <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"on"</span><span>)</span><span>;</span>

onButton<span>.</span><span>addEventListener</span><span>(</span><span>"click"</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span>fullscreenSupported <span>&amp;&amp;</span> <span>!</span><span>document</span><span>.</span><span>fullscreenElement</span><span>)</span> <span>{</span>
    <span>document</span><span>.</span><span>documentElement</span><span>.</span><span>requestFullscreen</span><span>(</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<h2 id="turn-off-full-screen-mode">Turn off full-screen mode</h2>
<p>To turn off the full-screen mode, you listen to the click event of the turn off button. In the event handler, you call the <code>exitFullscreen()</code> method of <code>document</code>. It returns a <code>Promise</code> that is resolved after the mode is off. You need to check whether the mode is supported and the mode is on.</p>
<pre><code><span>const</span> offButton <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"off"</span><span>)</span><span>;</span>

offButton<span>.</span><span>addEventListener</span><span>(</span><span>"click"</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span>fullscreenSupported <span>&amp;&amp;</span> <span>document</span><span>.</span><span>fullscreenElement</span><span>)</span> <span>{</span>
    <span>document</span><span>.</span><span>exitFullscreen</span><span>(</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<p>Full code</p>
<pre><code><span><span><span>&lt;</span>h1</span><span>&gt;</span></span>Fullscreen API<span><span><span>&lt;/</span>h1</span><span>&gt;</span></span>
<span><span><span>&lt;</span>button</span> <span>id</span><span><span>=</span><span>"</span>on<span>"</span></span><span>&gt;</span></span>Turn on fullscreen<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;</span>button</span> <span>id</span><span><span>=</span><span>"</span>off<span>"</span></span><span>&gt;</span></span>Turn off fullscreen<span><span><span>&lt;/</span>button</span><span>&gt;</span></span>

<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> onButton <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"on"</span><span>)</span><span>;</span>
  <span>const</span> offButton <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"off"</span><span>)</span><span>;</span>
  <span>const</span> fullscreenSupported <span>=</span> <span>document</span><span>.</span><span>fullscreenEnabled</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span>fullscreenSupported<span>)</span> <span>{</span>
    <span>const</span> para <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>"p"</span><span>)</span><span>;</span>
    para<span>.</span><span>textContent</span> <span>=</span> <span>"Full screen mode is not supported"</span><span>;</span>
    <span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span>para<span>)</span><span>;</span>
    onButton<span>.</span><span>style</span><span>.</span><span>display</span> <span>=</span> <span>"none"</span><span>;</span>
    offButton<span>.</span><span>style</span><span>.</span><span>display</span> <span>=</span> <span>"none"</span><span>;</span>
  <span>}</span>

  onButton<span>.</span><span>addEventListener</span><span>(</span><span>"click"</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span>fullscreenSupported <span>&amp;&amp;</span> <span>!</span><span>document</span><span>.</span><span>fullscreenElement</span><span>)</span> <span>{</span>
      <span>document</span><span>.</span><span>documentElement</span><span>.</span><span>requestFullscreen</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>
  <span>}</span><span>)</span><span>;</span>

  offButton<span>.</span><span>addEventListener</span><span>(</span><span>"click"</span><span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span>fullscreenSupported <span>&amp;&amp;</span> <span>document</span><span>.</span><span>fullscreenElement</span><span>)</span> <span>{</span>
      <span>document</span><span>.</span><span>exitFullscreen</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>
  <span>}</span><span>)</span><span>;</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/toggle-fullscreen-mode-with-fullscreen-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24989510</guid>
            <pubDate>Wed, 04 Nov 2020 14:50:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Foundation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24989505">thread link</a>) | @todsacerdoti
<br/>
November 4, 2020 | https://haskell.foundation/whitepaper/ | <a href="https://web.archive.org/web/*/https://haskell.foundation/whitepaper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><h3>Prelude</h3><p>Haskell’s slogan of “avoid success at all costs” was a clever and cheeky way of saying that
innovation and research in programming languages, especially in functional programming,
needed some insulation to succeed. Ideas that were not perfectly understood needed iteration
to fully develop in the minds of language innovators and users. By avoiding the “success at all
costs” mentality of other language communities, the Haskell community bought time and space
to try ideas that were not perfectly understood at first. Since then, the Haskell language has
sparked so many lasting innovations in language design that its impact is now beyond doubt.
What is the reason for this outsized impact? Haskell and related languages re-opened the
connection between mathematical thinking on the one hand and compilers and programming
languages on the other. It showed that these two fields should never have drifted so far apart.
By removing the ceiling on the ideas that are easier to express in Haskell, it attracted the
brightest minds and still does. It became a lingua franca for a large swath of CS research. In
education, Haskell helps CS students learn to think better. The quality of ideas represented in
the Haskell ecosystem has attracted both small and large companies. In many ways, the story
of Haskell is one of success. Perhaps it was unavoidable after all.</p><p>As good as the core concepts of Haskell are, users adopting it are often exposed to some very
rough edges. We think it is time for Haskell to have a much smoother on-ramp and more
real-world use cases where it is the clear first choice. There are now countless stories of Haskell
adoption in the industry, but not all are successful. A few companies have even switched away
from Haskell, for reasons that include difficulties with the compiler, tooling and hiring. Once
users can get past these obstacles, they can achieve amazing outcomes, but too often the path
to get there is not clear.</p><p>Haskell is an open-source community. Almost all its tooling and community is created and run
by a strong community of bright volunteers. But these contributors all have other day jobs, so
the Haskell ecosystem still lacks crucial social, technical and organizational “glue”.
We believe that every single obstacle standing in the way of Haskell adoption can be overcome.
All technical issues are tractable and require a modest investment of energy, commitment and
financial resources to fix. Likewise the social/community issues: the Haskell community is
packed with friendly, able and motivated contributors who share common values. We think that
by focusing our attention on the critical story of adoption, Haskell can
encourage yet more
innovation in the future, while bringing the benefits of its core ideas to a much larger user base.
We need to encourage adoption in new ways and renew focus on improving the Haskell
ecosystem.</p><h3>The Haskell Foundation</h3><p>That’s why we are forming a non-profit organization, provisionally called “The Haskell
Foundation” (HF), dedicated to advancing the Haskell programming language, related tools,
education and research.</p><h4>Goals</h4><p>HF has these goals:</p><ul><li>To foster a much broader understanding of the benefits of using Haskell among developers who do not currently use Haskell.</li><li>To increase adoption of Haskell substantially, by erasing barriers that inhibit adoption.</li><li>To identify and fill missing “technical gaps”: the useful stuff that makes for a smooth user experience (pain-free installers, documentation, error messages, and much more).</li><li>To help with “community glue”, by nurturing respectful, inclusive communication across the community.
Together these goals form the mission of HF.</li></ul><h4>Principles and Ethos</h4><p>How ​ we pursue the goals of HF is just as important as ​ what t ​ he goals are. HF’s actions will be guided by these core principles:</p><ul><li><strong>Open source</strong>. Haskell is an open source community and HF will embrace the open-source ethos wholeheartedly. HF may develop, or sponsor the development of tools and infrastructure, but it will all be open source.</li><li><strong>Empowering the community</strong>. A major goal of HF is to augment, celebrate, and coordinate the contributions and leadership of volunteers, not to supplant or replace them.</li><li><strong>Open, friendly, and diverse</strong>. For many of us Haskell is more a way of life than a programming language. All are welcome, all can contribute.</li><li><strong>Transparent</strong>. ​ All communication related to code and decision making will be publicly accessible, to enable asynchronous communication and collaboration. Only certain categories of sensitive information (e.g. financial, and matters concerning particular individuals) will be kept confidential.</li><li><strong>True to Haskell’s principles</strong>.​ Haskell’s design puts principle ahead of expediency, notably by cleaving closely to the principles of purely functional programming. Success, yes, but not at all costs!</li></ul><p>We have learned from other open source communities. The ​Rust community​ has a code of
conduct that has benefited the community. They do a remarkably good job of this, in large part
because the Rust community is actively led and nurtured. ​ The Apache Software Foundation​ has
developed clear standards of transparency and consistent governance across all of its 300+
projects, run by volunteers. As we set up HF we have adopted successful approaches like these
into our operating principles.</p><h4>Organization and Funding</h4><p>The organization will seek funding to ensure the longevity and continuous strengthening of the Haskell ecosystem.</p><h5>Structure</h5><p>The Haskell community comprises an amazing group of technical talent and functions today as
an almost entirely volunteer effort. Our goal is make every member of the Haskell community,
and every HF-affiliated Haskell committee feel more support and more productive. We want to
enlarge and diversify our community.</p><p>We have received and incorporated lots of feedback about the best way to
structure HF.</p><ul><li>HF will have a ​ Governing Board​ (“Board” hereafter) that reflects the Haskell community and its stakeholders, including academics, commercial users, and individuals.</li><li>HF will have a staff. The size of the staff will depend on funding, but we intend to hire an Executive​ Director​ (ED), who can organize Haskell outreach, support its funding activities and oversee the rest of the staff. The staff will mostly focus on funding, marketing, and key infrastructure.</li><li>HF will work with existing and new open source teams to channel energy into various efforts like packaging, tools, libraries, compilers, languages, documentation, user experience, and infrastructure. To reiterate, we expect that most technical contributions will be volunteer, just as it is today, but we want to position HF to fill gaps that can help adoption.</li><li>HF will establish a code of conduct and transparent decision-making that will apply to itself and any associated teams.</li><li>To the extent HF funds and pursues technical goals itself, it will pursue those goals with the same transparency as we expect from any of the teams associated with it. In this way HF will augment the community in a transparent way.</li></ul><p>We think that HF represents one of the final puzzle pieces for Haskell. A new organization will
provide a way to fund and coordinate Haskell development going forward. We hope that all key
committees that currently support Haskell will align HF’s values and mission and we are working
with those committees that wish to voluntarily affiliate with HF. Discussions with those teams are
currently underway. We don’t want to simply add another Haskell committee.</p><h5>Who are the HF organizers?</h5><p>The idea of the Haskell Foundation has been developed by an informal working group including</p><ul><li>Representatives from the haskell.org committee, the Core Library Committee (CLC), the Hackage Trustees and the GHC Devops Committee, and other Haskellers.</li><li>Haskell companies, who are generously providing financial, advisory, and in-kind support.</li><li>Numerous long-standing members of the Haskell community.</li></ul><h5>Funding</h5><p>There have been other initiatives of this kind in the past, but they have proved hard to sustain.
A big part of this has been a simple lack of bandwidth in a highly decentralised community run
entirely by volunteers.
We expect to launch with a small group of founding sponsors. The Board and staff will take over
that function after launch. Our goal is to raise around $1m/year in cash and in-kind
contributions.</p><h3>Improving the Haskell Adoption Story</h3><p>Promoting Haskell adoption has three major components:</p><ul><li>Eliminating unreasonable and perceived barriers to adoption.</li><li>Educating the tech community about the benefits of adoption, including decision makers.</li><li>Enhancing the tooling, so that the risk of adoption is dramatically reduced.</li></ul><h4>Eliminating unreasonable and perceived barriers to adoption</h4><p>We expect that with HF adding a little structure, some things can be improved immediately. For
example, we need an entry point for Haskell that speaks to the needs of a range of users: from
engineers looking for an easy on-ramp with our best advice on how to learn and use Haskell, to
team leaders who want to assess Haskell adoption as a business decision. The Haskell
community today does not cover the full range of content needed to promote adoption. This is
one example where an organization with the right focus and some resources can easily have a
positive impact.</p><h4>Educating the tech community</h4><p>Engineers are typically the ones who drive Haskell adoption. But they often need permission or
sponsorship from managers 1 or 2 levels higher. These decision makers are people who are
more concerned about speed of development, reliability, maintenance, and
people. We need to
explicitly address a broader audience and position Haskell as the best solution to many
problems, while maintaining integrity and avoiding too much “marketing speak".</p><p>Conditions for telling this story are favorable. The days of a senior sysadmin dictating which
version of Java or Python “shall be used” are dying. Containers and cloud technology have
inadvertently conspired to permit engineering teams to make these …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://haskell.foundation/whitepaper/">https://haskell.foundation/whitepaper/</a></em></p>]]>
            </description>
            <link>https://haskell.foundation/whitepaper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24989505</guid>
            <pubDate>Wed, 04 Nov 2020 14:49:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Weightlifting tracker app where you can code]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24988988">thread link</a>) | @astashov
<br/>
November 4, 2020 | https://www.liftosaur.com/about | <a href="https://web.archive.org/web/*/https://www.liftosaur.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <div>
      <nav>
        
        
      </nav>
      <section>
        <div>
          <div>
            <a href="https://www.liftosaur.com/">
              <img src="https://www.liftosaur.com/images/logo.svg" alt="Liftosaur Logo">
              
            </a>
            <p>
              The most flexible weightlifting tracker app ever. Build complex routines like
              <a href="https://stronglifts.com/5x5/" target="_blank">Stronglifts 5x5</a>,
              <a href="https://thefitness.wiki/routines/gzclp/" target="_blank">GZCLP</a>,
              <a href="https://thefitness.wiki/5-3-1-primer/" target="_blank">5/3/1</a>, etc and define the logic of
              progressions and deloads using built-in scripting language. Or choose one of the pre-created weightlifting
              routines from <a href="https://thefitness.wiki/" target="_blank">r/fitness and r/weightroom</a>.
            </p>
            <p>
              Completely free. No ads.
            </p>
            
          </div>
        </div>
        
      </section>
    </div>
    
    <section>
      <h2>Summary</h2>
      <p>
        This app allows you to get experience similar to e.g.
        <a href="https://stronglifts.com/apps/" target="_blank">Stronglifts 5x5 app</a>, but for any possible
        weightlifting routine ever. <a href="https://thefitness.wiki/routines/gzclp/" target="_blank">GZCLP</a>,
        <a href="https://thefitness.wiki/5-3-1-primer/" target="_blank">5/3/1</a>,
        <a href="https://thefitness.wiki/routines/nsuns-lp/" target="_blank">nSuns LP</a>, or any variation of those
        could be expressed via built-in scripting language <a href="https://www.liftosaur.com/docs/docs.html"><strong>Liftoscript</strong></a>. E.g. Squats progression and deload logic in Stronglifts 5x5 could be expressed in
        <strong>Liftoscript</strong> as:
      </p>

      <pre><code>
if (completedReps &gt;= reps) {
  state.weight = state.weight + 5lb
} else {
  state.failures = state.failures + 1
}
if (state.failures &gt; 2) {
  state.failures = 0
  state.weight = state.weight * 0.9
}
</code>
</pre>
      <p>
        And you can modify it in any way you want. E.g. you may change increments to 2.5lb, change max number of
        failures to 5, you may completely change the logic to anything you want. You have access to completed sets,
        reps, weights, you can create any state variables you want. There's also a bunch of example routines written in
        the same Liftoscript language from
        <a href="https://thefitness.wiki/" target="_blank">thefitness.wiki</a>.
      </p>
      <p>Read more or watch the video tutorial in <a href="https://www.liftosaur.com/docs/docs.html">Documentation</a></p>
    </section>
    <section>
      <h2>Features</h2>
      <ul>
        <li>
          <div>
            <div>
              <h4>Built-in workout routines</h4>
              <p>Choose from multiple precreated workouts, that helped thousands of Reddit lifters become stronger.</p>
            </div>
          </div>
          <div>
            <p><img src="https://www.liftosaur.com/images/choose-a-program.png" alt="Choose a program screenshot">
            </p>
          </div>
        </li>
        <li>
          <div>
            <div>
              <h4>Workout history</h4>
              <p>All your workouts will be recorded, and you'll be able to edit any recorded workout.</p>
            </div>
          </div>
          <div>
            <p><img src="https://www.liftosaur.com/images/history.png" alt="History screenshot">
            </p>
          </div>
        </li>
        <li>
          <div>
            <div>
              <h4>Tracking workout progress</h4>
              <p>
                Log all the sets you accomplished. Also, there's rest timer and plates calculator for your convenience.
              </p>
            </div>
          </div>
          <div>
            <div>
              
              
              <p>Plates Calculator</p>
              
              
              <p>Rest Timer</p>
              <p><img src="https://www.liftosaur.com/images/progress.png" alt="Progress screenshot">
            </p></div>
          </div>
        </li>
        <li>
          <div>
            <div>
              <h4>Custom workouts</h4>
              <p>You can customize any workout in any way you want, and also create yours.</p>
            </div>
          </div>
          <div>
            <p><img src="https://www.liftosaur.com/images/edit-day.png" alt="Edit Day screenshot">
            </p>
          </div>
        </li>
        <li>
          <div>
            <div>
              <h4>Add any logic to your workouts</h4>
              <p>Using built-in script language, you can customize progressions and deloads in any way you want.</p>
            </div>
          </div>
          <div>
            <p><img src="https://www.liftosaur.com/images/edit-program-script.png" alt="Edit Program Script screenshot">
            </p>
          </div>
        </li>
        <li>
          <div>
            <div>
              <h4>Cloud Storage</h4>
              <p>If you log in using your Google account, your history will be stored in the cloud.</p>
            </div>
          </div>
          <div>
            <div>
              
              
              <p>Log in here</p>
              <p><img src="https://www.liftosaur.com/images/settings.png" alt="Settings screenshot">
            </p></div>
          </div>
        </li>
        <li>
          <div>
            <div>
              <h4>Graphs</h4>
              <p>You can visually check your progress on main lifts.</p>
            </div>
          </div>
          <div>
            <p><img src="https://www.liftosaur.com/images/graphs.png" alt="Graphs screenshot">
            </p>
          </div>
        </li>
      </ul>
    </section>
    <section>
      
      <p>
        It's not a native mobile app, it's a web app. So, you visit and work with it just like with any site, open it
        e.g. in mobile Safari or Chrome, but you can add it to your phone home screen, and then it will behave like a
        regular app.
      </p>
    </section>
    
    
    
  

</div>]]>
            </description>
            <link>https://www.liftosaur.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988988</guid>
            <pubDate>Wed, 04 Nov 2020 13:48:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Role of testing in software development life cycle]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24988980">thread link</a>) | @sagevoid
<br/>
November 4, 2020 | https://abbyssoul.github.io/engineering/2020/11/02/no-time-for-testing.html | <a href="https://web.archive.org/web/*/https://abbyssoul.github.io/engineering/2020/11/02/no-time-for-testing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Recently I have joined a Sydney start-up program, <a href="https://www.antler.co/">Antler</a>, and have been hanging out with pretty unique and interesting people. As part of the program, I participated in the CTO forum, where all things tech in start-ups were discussed. One of the topics was about our approaches to testing. In any large gathering of tech-minded people, there is always a non-zero number of people who say, for whatever reason, “I don’t have time for testing…”. It always cracks me up as I find myself wanting to ask, “Have you budgeted the time for fixing issues after release then? How about the time for testing every subsequent new release manually?” I personally don’t ever want to have to come across untested software – whether on my phone, in traffic control systems, or in medical devices. Thus I feel it’s time to talk about what testing means and where it sits in the grand scheme of software engineering.</p>

<h3 id="tldr">TL;DR</h3>
<ul>
  <li>Testing is a critical part of software engineering and part of a software life-cycle (SDLC). When someone says – “no time for testing during product development” – they better budget time for fixing things in production.</li>
  <li>Testing is even more critical when new developers join your team.</li>
  <li>Testing is <strong>not</strong> about testing the <em>code</em> but making sure the <em>application is working</em> and stays that way.</li>
</ul>

<h2 id="feature-driven-development">Feature-driven development.</h2>
<p>Let us consider how a software solution develops from scratch in a start-up. The process typically starts with an idea like “I want my users to be able to do <blah> with the help of my app". In this case, <blah> is a business function we want our app to perform. This function might be a solution to a customer problem or a part of such a solution.</blah></blah></p>
<blockquote>
  <p>For example – the ToDo app allows you to create a task and then mark it as done. Some advanced versions might even feature an option to edit task descriptions and even delete them. So that’s a few functions. The functions solve a clear problem – the management of tasks.</p>

  <p>A slightly more advanced design might include scheduling tasks and notifying yourself about deadlines and nudges. This will help solve a somewhat different problem of driving tasks to completion, as opposed to just passively storing lists of things to do.</p>

  <p>Yet another tweak of design might enable you to collaborate with multiple users, assigning tasks to people etc. – all to solve a bigger problem – coordinating people and teams to work together efficiently.</p>
</blockquote>

<p>Identifying problems customers are experiencing: this is what defines a business. Implementing solutions to these problems: this is the engineering domain. Good engineering practice breaks a solution down into a set of independent components, aka features. This lowers the burden on individual engineers, as they need to keep fewer details in their active memory. A good division of labour also enables multiple people (or teams) to work in parallel, thus delivering the whole solution faster. Furthermore, it allows the solution to be delivered to customers incrementally. In some cases, it’s helpful to validate with business customers the fit and general direction of the development as well as creating an early engagement. So lots of positives! In contrast, waiting for everything to be <em>ready</em> and <em>perfect</em> before releasing the product creates certain challenges.</p>

<p>First of all, how do we know something is ready and perfect? Do you ask your customers, “Is this working for you?” What if you don’t have customers yet? What if your app is non-interactive, such as micro-controller firmware? No one to ask there. Thus we need a way to assess that solution is ready and it stays ‘<em>ready</em>’ as we update it.</p>

<blockquote>
  <p>Unit test – a piece of code specifically designed to test another piece of code. The need to create unit tests originated from the constrains of micro-controller development where the effects of bugs are not readily observable.</p>
</blockquote>

<h2 id="do-we-have-time-to-test-things">Do we have time to test things?</h2>
<p>In a good project, there is always a backlog of features we need to deliver to make an app great. This creates a dilemma; should we prioritise the development of planned features, or write tests for features already in the works, or even existing ones. In my experience, the most common response to this is – “we need to focus on getting that customer value out and we can fix things later, if ever”. Another answer is, “Or we can just write better code, right? It’s also the most incorrect answer possible.</p>

<p>To understand why this is incorrect, we need to establish the point at which a ‘feature’ is actually complete. For some projects, the answer might be simple: when the code has been written. A slightly more mature approach is to consider a feature done when a user can use it, but if it’s not ready, we don’t want to put it in front of a user. How do you assess that a user can indeed use it? Some test manually – playing the role of a user. That requires some knowledge of users’ business processes to know how they interact with the software. And how do you assess that users can use it on an ongoing basis, even after the next version has been released? Test every release, of course! Every feature in every release! For all time! That’s a lot of testing. Have you budgeted time for that?</p>

<h2 id="composition-of-features--multiplication-of-test-cases">Composition of features – multiplication of test cases.</h2>
<p>What I am talking about here is the fact that all features have a life-cycle. They are conceived, implemented and released into the wild… and occasionally – removed. What that means for the engineering team is that they need to take into account that once a code for a feature has been written, it will go on to live a separate life. It will likely stay alive through the ongoing evolution of a project as other components are added and updated.</p>

<blockquote>
  <p>Here is a personal anecdote: I had joined a team and started working on a new project that had been in production for a while. My task was to add a new feature: “No problem – it seems like an independent and well-defined piece of work”, I thought.</p>

  <p>Once the code was done and passed all the tests it got approved by other engineers. So I merged the branch and promoted my version to a staging environment for internal testing. I’d tested it as well as I could and all seemed to be in order.</p>

  <p>Sometime later an architect came looking for me asking why I had broken screen <blah>. He told me I should revert my changes! I was surprised, as I had checked the version in staging and screen "blagh" seemed in perfect order to me. I asked the architect, "Well surely you have tests for this screen functions, and they would have picked up any issues?" "We don't have 100% test coverage!" was the answer. I looked at my screen, and then at his, and they looked different. After a bit of investigation, we realised that we were using different testing accounts, and the architect's account had special features enabled, which changed the appearance on screen "blagh". These features were only available for a special type of user, and I had no idea they even existed for this app. It turned out that this architect was the only person in Engineering who knew about these features. It made me wonder what other features I didn't know about and had not tested. More importantly – what would have happened if the architect had been on holidays? Customers that actually use those special features would have had a bad day. Not a great prospect.</blah></p>
</blockquote>

<p>As engineers, we can’t reasonably expect <em>everyone</em> to know <em>everything</em>. This is especially true for new engineers joining our teams. They’re not going to know all the features of an existing product, especially if it’s not a consumer product. They can’t test features they don’t know exist. However, that’s in essence what is required of a new engineer delivering a new feature, in the absence of automated tests; they need to make sure all existing features are intact when something has been fixed, or a new feature added.</p>

<p>A natural human reaction (<em>I assume here that most developers are human, but in case our robot overlords find this blog in a distant future – this is true for all beings</em>) when approaching the unknown is to slow down and observe the environment, checking it for dangers. This ancient adaptation works well even in our modern days where our environment is not a forest, but social landscapes, product road-maps (past and present) and existing codebases. Indeed, no one wants fresh devs jumping into a codebase, changing things without considering lurking dangers. These dangers may be in the form of breaking things and processes one might be not aware of. In other words, developers naturally feel afraid to change things because they might break. This fear is paralysing. Yet this is the opposite of what developers are hired for – to make changes and thus advance products.</p>

<p>One proven way to alleviate this fear is to create a safety net of tests. For one – we can reduce the damage of a ‘failure’ by moving it from the production to the development stage. If failure is detected and remedied before it reaches customers, there will be no externally observable impact (other than disappointing your team  that things are not perfect and causing a bit of delay for fixing – which should be budgeted for anyway). With good test coverage, if something important breaks due to developer actions, a developer will see it straight away with a fresh knowledge of changes and is in control to fix it. I am sure a lot of readers would recognise this principle as “refactoring without fear”. Racing car drivers can drive at full speed because they have confidence in the safety of the track. In a similar way, when developers have an adequate support structure we shed our fear and can move fast to make changes.</p>

<h2 id="sdlc-design-and-development-deployment-and-evolution">SDLC: design and development? Deployment and Evolution!</h2>
<p>What does a proper support structure look like? We want to be able to add new features into an existing product (which may be just an app starter example – for a new project), and be sure all the current features remain working. To make sure a new code does what it is expected to do, we have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abbyssoul.github.io/engineering/2020/11/02/no-time-for-testing.html">https://abbyssoul.github.io/engineering/2020/11/02/no-time-for-testing.html</a></em></p>]]>
            </description>
            <link>https://abbyssoul.github.io/engineering/2020/11/02/no-time-for-testing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988980</guid>
            <pubDate>Wed, 04 Nov 2020 13:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The world is awash in bull]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24988875">thread link</a>) | @ultra_nick
<br/>
November 4, 2020 | https://www.callingbull.org/index.html | <a href="https://web.archive.org/web/*/https://www.callingbull.org/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
         
                
                
                <p><a href="https://www.amazon.com/Calling-Bullshit-Skepticism-Data-Driven-World/dp/0525509186"><img src="https://www.callingbull.org/img/covers.png" alt="Calling Bull: The Art of Skepticism in a Data-Driven World"></a></p>
                <p><b>Now available!</b> <i>Calling Bull: The Art of Skepticism in a Data-Driven World</i>, by  Carl Bergstrom and Jevin West. Pre-order now: <a href="https://www.amazon.com/Calling-Bullshit-Skepticism-Data-Driven-World/dp/0525509186">Available here</a></p>
                
                
                <hr>
                
                <p><b>The world is awash in bull.</b>  Politicians are unconstrained by facts. Science is conducted by press release.  Higher education rewards bull over analytic thought. Startup culture elevates bull to high art. Advertisers wink conspiratorially and invite us to join them in seeing through all the bull — and take advantage of our lowered guard to bombard us with bull of the second order. The majority of administrative activity, whether in private business or the public sphere, seems to be little more than a sophisticated exercise in the combinatorial reassembly of bull. </p>

                <p>We're sick of it. It's time to do something, and as educators, one constructive thing we know how to do is to teach people. So, the aim of this course is to help students navigate the bull-rich modern environment by identifying bull, seeing through it, and combating it with effective analysis and argument.</p>
                                              
                <p>What do we mean, exactly, by <em>bull</em> and <em>calling bull</em>? As a first approximation:</p>
                    
                <p><em>Bull</em> involves language, statistical figures, data graphics, and other forms of presentation intended to persuade by impressing and overwhelming a reader or listener, with a blatant disregard for truth and logical coherence. </p>
                
                <p><em>Calling bull</em> is a performative utterance, a speech act in which one publicly repudiates something objectionable. The scope of targets is broader than bull alone. You can call bull on bull, but you can also call bull on lies, treachery, trickery, or injustice. </p>
                
                <p>In this course we will teach you how to spot the former and effectively perform the latter.</p>
                <p>While bull may reach its apogee in the political domain, this is not a course on political bull. Instead, we will focus on bull that comes clad in the trappings of scholarly discourse. Traditionally, such highbrow nonsense has come couched in big words and fancy rhetoric, but more and more we see it presented instead in the guise of big data and fancy algorithms — and these quantitative, statistical, and computational forms of bull are those that we will be addressing in the present course.</p>
                
                <p> Of course an advertisement is trying to sell you something, but do you know whether the TED talk you watched last night is also bull — and if so, can you explain why? Can you see the problem with the latest <i>New York Times</i> or <i>Washington Post</i> article fawning over some startup's big data analytics? Can you tell when a clinical trial reported in the <i>New England Journal</i> or <i>JAMA</i> is trustworthy, and when it is just a veiled press release for some big pharma company? </p>
                    
                <p><b>Our aim in this course is to teach you how to think critically about the data and models that constitute evidence in the social and natural sciences.</b> </p>
                
                <p>Carl T. Bergstrom and Jevin West<br> Seattle, WA.
        
                </p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://www.callingbull.org/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988875</guid>
            <pubDate>Wed, 04 Nov 2020 13:37:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Referential Formula in Math (2011)]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24988704">thread link</a>) | @surround
<br/>
November 4, 2020 | https://jtra.cz/stuff/essays/math-self-reference/index.html | <a href="https://web.archive.org/web/*/https://jtra.cz/stuff/essays/math-self-reference/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <h2>Self Referential Formula in Math</h2>
      <p>Keywords: math, quine, self-reference, Tupper</p>
      <p>Published: 23 Jun 2011 - see updates at the bottom</p>
      <h3>Tupper's formula</h3>
      <p>
        <b>See newer self-referential stuff:</b>
        <a href="https://jtra.cz/stuff/essays/math-self-reference-smooth/index.html">my 2019 self-referential formula uses Bézier curves instead of bitmaps</a>.
      </p>
      <p>
        I have seen <a href="https://shreevatsa.wordpress.com/2011/04/12/how-does-tuppers-self-referential-formula-work/">
        this blog about Tupper self-referential formula</a> recently.
        This formula is interesting. Its graph contains all possible
        bitmaps that fit in region of 17 * 106 grid. So it is not much
        of wonder that one of those many bitmaps contains meaningful
        representation of the formula itself. Actually, there multiple
        ways to fit the formula in 17*106 grid, so there are multiple
        occurrences of the formula in the graph. But there are also
        all other formulas that fit. It is not truly self-referential
        since number N which you need to find right viewport is not
        included inside (see updates at the bottom, Jeff Tupper has
	produced additional formulas that are truly self-referential,
	but this famous one is not).
	You cannot fit a bitmap represented as number
        in the same bitmap as fonts you would use for base-10 number
        would take at least 4*3 "pixels" per digit while that digit
        carries only log<sub>2</sub>10 bits. Is there a better way
        than that? Some form of compression might work.
      </p>
      <h3>Trávník's formula</h3>
      <p>
        So I though how I would design a formula that would be truly
        self-referential. This design process is more like programming
        for several reasons:
      </p>
      <ul>
        <li>I expected it will take one evening (4hrs), but it took
        three evenings :-)</li>
        <li>I had to debug the formula and refine it until it started to work.</li>
        <li>Formula had to be designed incrementally, in small pieces.</li>
        <li>Getting the picture takes a lot of computational time.</li>
      </ul>
      <p>
        Here is the formula in final form (I will probably describe
        steps how I arrived to this form in some follow up article if
        there is enough interest). Originally I have used Haskell in
        design process. To verify final form, I had to create
        C program (uses GMP big number library) since Haskell was too
        slow. This allowed me to verify it again that the formula is
        matching the program. This is the formula as formated with
        LyX:
      </p>
      
      <p><img src="https://jtra.cz/stuff/essays/math-self-reference/travnik-self-referential-formula-lyx.png" alt="Travnik's self referential formula (LyX)"></p><p>
        Now this one omitted the value of N. The N is very big number,
        it contains 12876 digits. You can see the N in the graph of
        the function below. Also, you can copy and paste the N from
        C source program below. Here is the function as it graphs
        itself (inside yellow border):
      </p>
      
      <p><img src="https://jtra.cz/stuff/essays/math-self-reference/travnik-self-referential-formula-graph.png" alt="Travnik's self referential formula (graph)"></p><p>
        You can find source of the program I used to plot it <a href="https://jtra.cz/stuff/essays/math-self-reference/selfref-demo.c">here</a> (it requires <a href="http://gmplib.org/">GMP big number library</a> to
        compile and run). At the top of the program there are
        constants which allow to define viewport you want. It is set
        to some interesting region that includes part of N. But you
        can set it to whole region if you have patience. Output graph
        is printed on terminal, '#' denotes true value, ' ' denotes
        false values. If you set wider X axis than fits the terminal,
        you can redirect to file and open in non-word wrapping editor
        with monospaced font. I have transformed such file to PBM
        ASCII format and used GIMP to get the image above.
      </p>
      <p>
        Beware that the C program is very slow. On my computer it ran
        for about 30 hours. I could optimize it, but I wanted the
        functions in C to correspond closely to the functions in the
        formula. While the program uses integer values for x and
        y computation, you can graph it with real valued x and y too.
        You can make it significantly faster if you don't want
        to see all digits of the N in this way. Replace:
      </p>
      <pre>        nnnBase10Len=strlen(strnnn)-1;
      </pre>
      <p>with</p>
      <pre>        nnnBase10Len=60;
      </pre>
      <p>
        In this case, you will see only last 60 digits of the N (and
        they will be shifted to different locations).
      </p>
      <h2>Updates</h2>
      <ul>
        <li>2011-06-23 - <a href="http://www.reddit.com/r/math/comments/i75t1/tuppers_formula_popular_topic_here_few_days_ago/c21h4vn">corrected LyX version of formulas there was "x" where should be "floor(x)" in function g. It was correct in other places.</a></li>
	<li>2017-12-29 - I have noticed that Jeff Tupper has produced additional formulas that are truly self-referential, they are <a href="http://www.peda.com/selfplot/">here</a>. Files have year 2007 so they predate my formula from 2011.</li>
	<li>2019-03-30 - Added link to my <a href="https://jtra.cz/stuff/essays/math-self-reference-smooth/index.html">2019 self-referential formula that uses Bézier curves</a>.</li>
      </ul>
      <p>
        Back to index - <a href="https://jtra.cz/index.html">Jakub Trávník's
        resources</a>.
      </p>
    </div></div>]]>
            </description>
            <link>https://jtra.cz/stuff/essays/math-self-reference/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988704</guid>
            <pubDate>Wed, 04 Nov 2020 13:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLB hit podcast: mov FP, sp]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24988466">thread link</a>) | @rwmj
<br/>
November 4, 2020 | https://tlbh.it/000_mov_fp_sp.html | <a href="https://web.archive.org/web/*/https://tlbh.it/000_mov_fp_sp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<audio id="audioplayer" src="https://traffic.libsyn.com/secure/tlbhit/tlbhit0.mp3" controls="controls" preload="auto"></audio>
<h2>00:00:00 Intro</h2>
<ul>
<li>Website: <a href="https://tlbh.it/">tlbh.it</a></li>
<li>Twitter: <a href="https://twitter.com/tlbhit">@tlbhit</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/mov-fp-sp/id1538369465?i=1000496866078">This episode on Apple podcast</a></li>
<li>The stack pretty much always TLB hits!</li>
</ul>
<h2>00:00:59 Disclaimer</h2>
<ul>
<li>We're lifelong learners, only know so much!</li>
<li>Will put errata up on <a href="https://tlbh.it/">the TLB Hit website</a></li>
<li><a href="https://en.wikipedia.org/wiki/Covert_channel">"Sidechannels"</a> via Twitter</li>
</ul>
<h2>00:01:42 What's the stack?</h2>
<ul>
<li>Episode is named <code>mov fp sp</code></li>
<li><code>mov fp sp</code> in the prologue of functions</li>
<li>Epilogue has "reverse" <code>mov sp fp</code></li>
<li>Instructions that manipulate <em>the stack</em>!</li>
<li>Compiler spills values that registers can't hold onto the stack</li>
<li>Functions do it a lot -- have their own [local] state, call functions that
have their own state</li>
<li>Because subroutines can recurse without bounds would need unbounded number of
registers</li>
<li>Often different kinds of registers: arithmetic value registers, floating
point registers</li>
<li>Registers contain fairly arbitrary "stuff": pointers to data, pointers to
code, return addresses, etc.</li>
<li>Stack is <em>usually</em> contiguous and allocated on a per-thread basis</li>
<li>Idea of "GPRs": general purpose registers, though some machines have
dedicated registers for floating point values as well, or SIMD for really
wide</li>
<li>Prologue moves stack pointer to base pointer, epilogue moves base pointer
back to stack pointer, "undoing", locally manipulating the stack pointer then
rolling things back to where they previously were</li>
</ul>
<h2>00:03:50 Mechanisms in the processor</h2>
<ul>
<li>Frame pointer/base pointer (bp/fp), stack pointer (sp)</li>
<li>Usual convention is that the frame pointer doesn't change during the course
of the function's execution</li>
<li>Generated code addresses "slots" relative (at offsets from) the frame
pointer; e.g. <code>+4</code>, <code>+8</code>, etc.</li>
<li>Stack is kind of like a linked list! Pointer of the stack that says "this is
where the frame pointer <em>used to be</em> before we came into this routine".</li>
</ul>
<h2>00:05:10 Comparison to an abstract stack machine</h2>
<ul>
<li>In CS class you may learn about machines where you push two operands onto a
stack then do an add operation that consumes the top two things on the stack</li>
<li>Compare to traditional processor we use today: expanding the stack as a
single operation that makes a bunch of slots at once</li>
<li>The slots don't need to be consumed in a strictly stack-order fashion</li>
<li>Distinction of "stack machine" vs scratchpad-area style frame areas
that happen in stack-like fashion for subroutine calls</li>
</ul>
<h2>00:06:05 Some instruction set considerations</h2>
<ul>
<li>Considerations on modern machines for frequency of these operations and how
they fit in our instruction cache; e.g. on x86 <code>push</code>/<code>pop</code> are single byte
opcodes</li>
<li>On ARM we may have a "push multiple values" instruction; little CISC-y but you
do so commonly it may make some sense</li>
<li>ARMv7 had instruction allowed to push 16 registers (all GPRs) and increment
stack pointer. Yay RISC!</li>
</ul>
<h2>00:07:09 Compiler optimizations and stackiness</h2>
<ul>
<li>By moving things onto the stack -- code is constantly working with the things
in its stack frame</li>
<li>Locality, but also avoiding memory allocation subroutines (100s or 1000s of
cycle depending)</li>
<li>In scratchpad area values are tracked precisely in dataflow sort of style</li>
<li>Bring them "in" to the compiler, values becomes more trackable</li>
<li>SSA values vs arbitrary memory references</li>
<li>When structs are brought onto the stack the individual fields inside can be
broken apart and the component fields can be tracked as individual values</li>
<li>Often called "scalar replacement of aggregates" (e.g. in LLVM)</li>
<li>When we home them on the stack we can do our common optimizations, CSE, DCE;
if on the heap, may be a lot harder to to do</li>
<li>In managed languages (e.g. JavaScript, Java) would do escape analysis to show
it doesn't escape via heap to an unknown subroutine -- once placed on the
stack you can eliminate whole objects and just track sub-fields inside of it</li>
<li>Allows you to just "explode" the object itself and think about its component
fields individually and get rid of whatever doesn't matter in there</li>
</ul>
<h2>00:09:17 Eliding heap allocations in C++</h2>
<ul>
<li>Some compilers can also sometimes optimize local heap allocations, turn them
into stacky allocation</li>
<li>C++ explicitly allows you to do that as of a few years ago, Clang does that</li>
<li>If you new an object no guarantee that you're actually going to put it on the
heap / call the underlying allocator</li>
<li>Can be surprising to people -- can do SRoA, other stuff, might get rid of the
entire computation</li>
<li>Neat, unless it's not what you're trying to do</li>
<li>But seems like a key optimization to do</li>
<li>If you're thinking about things as objects instead of raw bytes having higher
level understanding you can optimize based off of is pretty key it seems?</li>
</ul>
<h2>00:10:18 Frame pointer omission</h2>
<ul>
<li>When JF started programming there was "frame pointer omission" (FPO) which
was cool because optmizers weren't as good as they are now</li>
<li>Back when you only had 8 registers for x86 the extra register could go a long
way potentially -- stack is hot in cache but doing stores and loads to memory
locations</li>
<li>Was known to some as "that flag that makes the debugger way worse" -- debug
information has to be a lot more prescriptive when you can't simply describe
where things are as an offset from a canonical (assumed unchanging) register</li>
<li>Modern CPUs doing register renaming under the hood against a much bigger
micro-architectural register set -- not as worried about saving that one
register as much of the time -- although in hot code you still might</li>
</ul>
<h2>00:11:49 "Leaf" functions</h2>
<ul>
<li>When you inline things you make bigger regions for analysis, ideally make big
fat leaf functions</li>
<li>How much of program time is generally spent in leaf functions over some set
of applications?</li>
<li>Function at the end of the call tree</li>
<li>If your subroutine doesn't call any other subroutines that's a nice property,
because now you know that everything at the end of the stack belongs to you,
you're just doing your work and popping back up to whoever called you</li>
<li>Inlining really unlocks power of leaf -- inlining into non-leaf-functions can
<em>make</em> them become the leaf</li>
<li>So long as you don't over-inline and the working set doesn't become too big
-- the compiler can know everything it does and have a good amount of work to
do</li>
<li>Small region in which you can analyze <em>everything</em>, like tiny little whole
program analysis</li>
</ul>
<h2>00:13:10 Why do we have a stack again?</h2>
<ul>
<li>Why can't we inline everything?</li>
<li>Two main issues: 1) don't necessarily know call graph for the whole program
2) recursion</li>
<li>If you knew where all the calls went (virtual/indirect/etc in your
translation unit and other ones in your program), and without recursion, you
wouldn't need a stack, you know a perfect call graph</li>
<li>For some of these you could avoid having a stack -- virtual functions but
only a few actually implementations of it, could change to test-and-branch</li>
<li>If you have a fully analyzable virtual dispatch it effectively just becomes a
switch, can potentially inline what the targets are</li>
<li>Control flow analysis takes indirect branch that can go anywhere and
enumerate the real set of possibilities (devirtualization within a
translation unit)</li>
<li>Fully analyzeable call graph is an interesting computer history topic:
FORTRAN77 classically able to do this (programs were restricted enough you
could analyze it)</li>
<li>XLA ML/array programming machine learning compiler has the same property
where the whole call graph is analyzeable so you can create a slab that's the
giant frame for the whole program you're optimizing and all allocations are
known-fixed size</li>
<li>Whole program call graph analyzeability lives on in these niche use cases!</li>
<li>In stark contrast, sometimes we need multiple different kinds of stacks at
the same time!</li>
<li>The JS engine would sometimes recur from JS calls through the VM runtime to
other JS code, and that would need to potentially create a sub-stack (!) --
multi stack problems exist beyond even just needing to analyze/manage a
single stack</li>
<li>Programming in FORTRAN is cool, for scientific code often trying to
solve a specific physics problem don't <em>usually</em> need those tools like
recursion or virtual functions</li>
<li>When everything is "monomorphized" -- you have big arrays of
fixed-value-types you can know everything about the world and really optimize
everything based off of it -- fun mode to be in for scientific computing code</li>
</ul>
<h2>00:16:34 Considerations beyond recursion and indirect calls?</h2>
<ul>
<li>Some languages use the stack for fast thread switching? Things like full
stackful coroutines?</li>
<li>Stacks in Go for example are not contiguous: more like C++ deque: linked list
of lists instead of one contiguous stack -- clever x86 code sequence that
makes it fast to find previous and next frame</li>
<li>Allows Go stacks to be distinct allocations -- each page-wise is one frame
and the next function has another frame -- can put multiple functions in one
allocation</li>
<li>Used to have really bad perf if you were in a hot loop and happened to
straddle that boundary</li>
<li>Coroutines in some languages ended up having some "stackless" stuff like
this, where the closure is heap allocated instead</li>
<li>C++ coroutines try to do away with all the heap allocations, but depends on
optimization level whether it can do that or not</li>
<li>Kind of similar for Objective-C blocks -- until recently always heap
allocated, started being stack allocated in last few years where they could</li>
<li>Language doesn't say whether stuff lives on the heap or not</li>
<li>Because stack is less constrained can live in different places, e.g. in Go</li>
<li>In some cases you remove the allocation entirely</li>
</ul>
<h2>00:18:25 Scaling to millions of threads?</h2>
<ul>
<li>If you want to be able to scale your concurrency assumptions to millions of
threads, you don't want to have huge stacks</li>
<li>Each thread has a stack, and if you have millions of threads you don't want
to be allocating too much</li>
<li>And need to be able to switch between those threads quickly</li>
<li>So raises the question: how do you usually size those stacks in the
per-thread context you have?</li>
<li>If you're doing tiny little operations; e.g. if every operation in your
program was conceptually a thread, you wouldn't want to allocate 512KiB every
time you did a tiny atomic operation</li>
</ul>
<h2>00:19:10 Managed languages putting frames on the heap</h2>
<ul>
<li>On the term "stackless": one of the <a href="https://greenlet.readthedocs.io/en/latest/">Python
"greenlet"</a> ("lightweight thread"
terminology) attempts was called <a href="https://github.com/stackless-dev/stackless/wiki">Stackless
Python</a></li>
<li>In managed languages like Python the frames can be allocated …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tlbh.it/000_mov_fp_sp.html">https://tlbh.it/000_mov_fp_sp.html</a></em></p>]]>
            </description>
            <link>https://tlbh.it/000_mov_fp_sp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988466</guid>
            <pubDate>Wed, 04 Nov 2020 12:41:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Strategist’s Dilemma: What Makes a Breakthrough Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24988437">thread link</a>) | @ShradhaSingh
<br/>
November 4, 2020 | https://www.thestrategyinstitute.org/insights/the-strategists-dilemma-what-makes-a-breakthrough-strategy | <a href="https://web.archive.org/web/*/https://www.thestrategyinstitute.org/insights/the-strategists-dilemma-what-makes-a-breakthrough-strategy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.thestrategyinstitute.org/insights/the-strategists-dilemma-what-makes-a-breakthrough-strategy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988437</guid>
            <pubDate>Wed, 04 Nov 2020 12:36:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stupid mistakes I made while building my first startup]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24988380">thread link</a>) | @soorajchandran
<br/>
November 4, 2020 | https://sooraj.io/2020/11/04/stupid-things-i-did-while-building-my-first-startup/ | <a href="https://web.archive.org/web/*/https://sooraj.io/2020/11/04/stupid-things-i-did-while-building-my-first-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-285">
	<div>
		<!-- .entry-header -->

		<div>
			
<p>Avoiding stupidity is a powerful way to reach your success goals. You don’t always need to do great things. You can go a long way if you avoid stupid mistakes.</p>



<p>In this blog post, I am talking about the stupid things I have done while building my first startup.&nbsp;</p>



<p>I joined&nbsp;<a target="_blank" href="https://blog.ycombinator.com/yc-w17-launch-lively-scaphold-marketfox-floyd-servx-fibo-and-wifi-dabba/" rel="noreferrer noopener">Marketfox</a>&nbsp;with the dream of building the next big thing.&nbsp;</p>



<p>We had the opportunity to move to the much-coveted Silicon Valley, after being funded by Ycombinator – one of the best startup accelerators in the world. It was a dream come true.&nbsp;</p>



<p>Fast forward two years, we had to shut down the company due to several reasons – one of them being the lack of revenue.&nbsp;</p>



<p>Here are a few stupid things I have done while building that startup.</p>



<h2><strong>Not taking care of ourselves</strong></h2>



<p>Rents in the Bay Area are super high.<strong>&nbsp;</strong>We didn’t have a fortune back then. We were on a budget – but I think we could have used what we had to do certain things better.</p>



<p>We slept on the carpeted floor. All we had was one table and a few chairs.&nbsp;</p>



<p>We worked mostly sitting on the floor, combating the cold mornings. It also took a toll on our productivity.&nbsp;</p>



<p>My cofounder took the picture below – I had fallen asleep writing code.</p>



<figure><img data-attachment-id="287" data-permalink="https://sooraj.io/img_20170220_135059_original/" data-orig-file="https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg" data-orig-size="2368,4208" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Mi 4i&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1487598659&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.22&quot;,&quot;iso&quot;:&quot;3047&quot;,&quot;shutter_speed&quot;:&quot;0.076923076923077&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_20170220_135059_original" data-image-description="" data-medium-file="https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg?w=169" data-large-file="https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg?w=576" src="https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg?w=576" alt="" srcset="https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg?w=576 576w, https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg?w=1152 1152w, https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg?w=84 84w, https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg?w=169 169w, https://soorajio.files.wordpress.com/2020/11/img_20170220_135059_original.jpg?w=768 768w" sizes="(max-width: 576px) 100vw, 576px"></figure>



<h2><strong>Working 15-16 hours a day</strong></h2>



<p>Hard work is romanticized by the startup world. I used to brag how many hours I worked a day as if it is an achievement.&nbsp;</p>



<p>Do not get me wrong – consistent work matters a lot if you want to be successful.</p>



<p>But the number of hours is not directly proportional to the output and is far from the outcome. Your body needs rest and good food.&nbsp;</p>



<p>After some point, we lost the notion of day and night. We slept at random times, woke up at random times, and continued working.</p>



<h2><strong>Imbalance in decision making</strong></h2>



<p>Most of the decisions were often made by a single person, without enough brainstorming. It is not the ideal way of working.&nbsp;</p>



<p>Fast decision making is crucial in a startup.&nbsp;</p>



<p>But it is also important to include the key people and letting them have their say in making that decision.</p>



<p>Talk about things you feel are wrong. If you do not value your opinions, do not expect someone else to do it.&nbsp;</p>



<p>Never let someone else control you. Never let someone else make a decision that is yours.&nbsp;</p>



<h2><strong>Not moving enough</strong></h2>



<p>It took me a while to understand the importance of a healthy lifestyle. The effects of physical exercise on mental health are still very underrated.</p>



<p>In the beginning, we worked and we slept. That was it. Over time we started going for occasional walks.&nbsp;</p>



<p>We always resort to eating junk food(which I don’t regret much, because most of them were delicious) and not exercising enough.&nbsp;</p>



<p>So far it was about personal mistakes, but we also made plenty of classic startup mistakes along the way. </p>



<h2><strong>Not talking to our customers</strong></h2>



<p>We shipped features at a tremendous pace. But we never talked to enough users to identify if it was something necessary. We assumed things and kept building – in a few months, we had a product which was an engineering marvel – but nobody cared to use.</p>



<h4><strong>Too much building and not enough selling</strong></h4>



<p>I still look back with awe at the speed with which we shipped. But it does not matter if you cannot sell the product.</p>



<p>We focused less on selling and this was a big mistake.&nbsp;</p>



<p>We were very naive to think that building software is the hardest part of building a startup.</p>



<h2><strong>Copying from competitors&nbsp;</strong></h2>



<p>All the companies do this. Look at what stories from Snapchat have done to the social apps.</p>



<p>But even when you copy features, you have to make sure your users want it. Instagram copied the stories successfully, but when Medium tried the same, it was not very successful.</p>



<p>Copying from the competition will only get you as far as them. Your goal should be to build things that are much better than them if you want to make people switch.&nbsp;</p>



<p>Unless the new product is excellent, it won’t overcome the pain of making the switch.&nbsp;</p>



<h4><strong>Lack of vision</strong></h4>



<p>It is always a good idea to have a grand vision for the company if you are raising venture capital.</p>



<p>We blindly kept building features without any vision.&nbsp;</p>



<p>A simple question we should ask ourselves is – Who is your ideal user? What do they want to achieve with your product?</p>



<p>We had a bunch of features, probably what five different products would have done. But no single user wanted.</p>



<h2><strong>Final thoughts</strong></h2>



<p>Sometimes you win, sometimes you learn. It was an experience that changed my life for the good. I’m happy that I did it – I am happy that I tried and failed.&nbsp;</p>



<p>I learned a lot. About people, trust, and startups.&nbsp;</p>



<figure><img data-attachment-id="297" data-permalink="https://sooraj.io/img_1171_original-1/" data-orig-file="https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 5s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1486136274&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.15&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_1171_original-1" data-image-description="" data-medium-file="https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg?w=300" data-large-file="https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg?w=640" src="https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg?w=1024" alt="" srcset="https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg?w=1024 1024w, https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg?w=150 150w, https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg?w=300 300w, https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg?w=768 768w, https://soorajio.files.wordpress.com/2020/11/img_1171_original-1.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I made two <strong>amazing friends</strong>…</p>



<figure><img data-attachment-id="288" data-permalink="https://sooraj.io/img_1339_original/" data-orig-file="https://soorajio.files.wordpress.com/2020/11/img_1339_original.jpg" data-orig-size="963,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 5s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1489602473&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.15&quot;,&quot;iso&quot;:&quot;50&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_1339_original" data-image-description="" data-medium-file="https://soorajio.files.wordpress.com/2020/11/img_1339_original.jpg?w=300" data-large-file="https://soorajio.files.wordpress.com/2020/11/img_1339_original.jpg?w=640" src="https://soorajio.files.wordpress.com/2020/11/img_1339_original.jpg?w=963" alt="" srcset="https://soorajio.files.wordpress.com/2020/11/img_1339_original.jpg 963w, https://soorajio.files.wordpress.com/2020/11/img_1339_original.jpg?w=150 150w, https://soorajio.files.wordpress.com/2020/11/img_1339_original.jpg?w=300 300w, https://soorajio.files.wordpress.com/2020/11/img_1339_original.jpg?w=768 768w" sizes="(max-width: 963px) 100vw, 963px"></figure>



<p>…and a lot of memories.</p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:177026833,&quot;permalink&quot;:&quot;https:\/\/sooraj.io\/2020\/11\/04\/stupid-things-i-did-while-building-my-first-startup\/&quot;}"><li><figure><img data-attachment-id="290" data-permalink="https://sooraj.io/img_1098_original/" data-orig-file="https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg" data-orig-size="2048,1536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_1098_original" data-image-description="" data-medium-file="https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg?w=300" data-large-file="https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg?w=640" src="https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg?w=1024" alt="" data-id="290" data-link="https://sooraj.io/img_1098_original/" srcset="https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg?w=1024 1024w, https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg 2048w, https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg?w=150 150w, https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg?w=300 300w, https://soorajio.files.wordpress.com/2020/11/img_1098_original.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img data-attachment-id="293" data-permalink="https://sooraj.io/img_1508_original/" data-orig-file="https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 5s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1490904563&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.15&quot;,&quot;iso&quot;:&quot;1600&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_1508_original" data-image-description="" data-medium-file="https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg?w=300" data-large-file="https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg?w=640" src="https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg?w=1024" alt="" data-id="293" data-link="https://sooraj.io/img_1508_original/" srcset="https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg?w=1024 1024w, https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg?w=150 150w, https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg?w=300 300w, https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg?w=768 768w, https://soorajio.files.wordpress.com/2020/11/img_1508_original.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img data-attachment-id="295" data-permalink="https://sooraj.io/img_1542_original/" data-orig-file="https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg" data-orig-size="3264,2448" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 5s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1490965401&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;32&quot;,&quot;shutter_speed&quot;:&quot;0.00036496350364964&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_1542_original" data-image-description="" data-medium-file="https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg?w=300" data-large-file="https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg?w=640" src="https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg?w=1024" alt="" data-id="295" data-link="https://sooraj.io/img_1542_original/" srcset="https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg?w=1024 1024w, https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg?w=2048 2048w, https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg?w=150 150w, https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg?w=300 300w, https://soorajio.files.wordpress.com/2020/11/img_1542_original.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li></ul></figure>



<hr>



<p>I was able to build my <a href="https://money.yahoo.com/oyster-acquires-carrom-accelerate-global-100000172.html">second startup</a> from all the learnings I had from this journey.</p>



<p>I’m also helping run a small community called – <a href="http://herjobs.co/">HerJobs</a> – A way for distributed teams to diversify their team by hiring female talent from around the globe.</p>
					</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</div>
</article></div>]]>
            </description>
            <link>https://sooraj.io/2020/11/04/stupid-things-i-did-while-building-my-first-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988380</guid>
            <pubDate>Wed, 04 Nov 2020 12:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disclosure: Unlimited Chase Ultimate Rewards Points]]>
            </title>
            <description>
<![CDATA[
Score 1097 | Comments 242 (<a href="https://news.ycombinator.com/item?id=24988301">thread link</a>) | @ic4l
<br/>
November 4, 2020 | https://chadscira.com/post/5fa269d46142ac544e013d6e/DISCLOSURE-Unlimited-Chase-Ultimate-Rewards-Points | <a href="https://web.archive.org/web/*/https://chadscira.com/post/5fa269d46142ac544e013d6e/DISCLOSURE-Unlimited-Chase-Ultimate-Rewards-Points">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://chadscira.com/post/5fa269d46142ac544e013d6e/DISCLOSURE-Unlimited-Chase-Ultimate-Rewards-Points</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988301</guid>
            <pubDate>Wed, 04 Nov 2020 12:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Subversive Computing]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24988273">thread link</a>) | @stargrave
<br/>
November 4, 2020 | https://datagubbe.se/subversive/ | <a href="https://web.archive.org/web/*/https://datagubbe.se/subversive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>
or <b>Better Digital Living By Making Things Harder For Yourself</b><br>
or <b>I spent a Year Without Facebook and Google - Here's What Happened Next</b><br>
</p>

<p><em>Autumn 2020</em></p>


<p>
It's easy to grow disillusioned with tech, even to the point that it 
appals you. I've been using computers since 1988 and the net since 1995
and over time, something's happened. During the last decade or so, my 
mind has increasingly been preoccupied with the following thoughts:
</p>

<ul>
<li>I'm no longer in control of my computer and my OS.</li>
<li>The modern web is a cesspool of tracking scripts, ads, 
malware and clickbait designed to suck you in and make you stupid.</li>
<li>Even the most premium commercial software and hardware more often
than not comes with contraptions to spy on you.</li>
<li>"Cloud apps" are replacing programs I'd much rather run natively.</li>
<li>Thus, we sacrifice our privacy and intellects for faux conveniences.</li>
<li>The Idealist Net we fondly remember is long dead and unlikely to come
back.</li>
<li>...but there are still pockets of sanity left.</li>
</ul>

<p>
As a child of the home computer boom, I'm used to general purpose 
machines that do my bidding without interference from neither the 
manufacturer nor some unknown other wanting to sell me Depends and 
Bitcoins. That's what I want my computing to <i>still</i> be like.
</p>

<p>
The Man wants something different, though. The Man wants you to log in, 
click accept, sell your soul and Buy More Stuff. Hence, working to avoid 
that must be some level of subversive computing: Sticking it to The Man, 
one bit at a time.
</p>

<p>
In this text, I'll try to outline how I do my best to achieve that. Fair 
warning: it doesn't come without what some would call sacrifice, because 
you can't have the cake and eat it. This "sacrifice", however, might 
ultimately turn out to be beneficial.
</p>

<h2>What I absolutely do not use</h2>

<h3>Facebook</h3>

<p>
This is a dead giveaway, of course. No facebook and no facebook services 
(E.G. instagram, whatsapp, messenger, etc).
</p>

<p>
Quitting was, considering the circumstances, very easy. I'd had a 
facebook account since 2007 and I used to live there, sometimes posting 
several times a day and checking in much more often. In the summer of 
2019, I wrote a goodbye post and the day after, I closed my account. 
This is more than a year ago now and I don't miss it.
</p>

<p>
I had an Instagram account for a while, but only used it for maybe a 
month or two. It's the second stupidest "service" available on the net 
right now, and that's saying a lot: It is, quite literally, a site 
where millions of people post daily photos of their dinners. To put it 
as nicely as I can: Instagram has absolutely zero content of any kind of 
real importance to anyone.
</p>

<p>
<b>Coping strategy:</b> None, really. It turns out that people who are 
interested in meeting with or talking to you will send an email or text 
or perhaps even call you. I'm also particularly thankful I didn't have to
witness the COVID-19 debacle unfold on social media.
</p>

<h3>Twitter</h3>

<p>
Beating Instagram, Twitter is currently the stupidest site on the net. 
Best described as a slowly decomposing swamp of infighting and political 
bickering, it's full of people who will not yield a millimeter in any 
direction and will never, ever change their opinions about anything.
</p>

<p>
<b>Coping strategy:</b> None. Ditching twitter is something I advice 
everyone to do, even those who will gladly sell their DNA for a bit of 
"free" online convenience. You'll feel much more at peace with the world 
without it.
</p>

<h3>Google</h3>

<p>
If facebook is a dead giveaway, this is the truly crucial part of the 
concept. Facebook deals with distractions - Google deals with 
infrastructure. No longer one of many actors on the net, their monopoly 
quite simply dictates what goes and what doesn't. A recent reminder was 
when their domain blacklisting suddenly identified 
pouet.net, an innocent site for discussing the demo scene, as a spreader 
of malware. Things were, as usual, only resolved because someone knew 
someone who worked at Google. To discourage their thuggish, predatory 
behavior, we should avoid them in any way possible.
</p>

<p>
I closed down my Google account together with my Facebook account. I 
haven't missed that one, either. I also switched to searching with 
DuckDuckGo. The major point here is to <i>not</i> find a "replacement 
Google", such as Office 365 and Onedrive. That's not taking back control 
over your data, that's just handing it to the next buffoon for continued 
mining.
</p>

<p>
<b>Coping strategy:</b> I now pay for my email. A mom-and-pop hosts it 
all for a very reasonable yearly fee and they throw in some pretty 
decent web hosting, too. Complete self-hosting would of course be ideal 
from a privacy standpoint, but I'm happy with this solution. I can also 
mount the home directory through sshfs, which makes it an excellent 
"cloud drive". When I've been in contact with their customer support,
they've been timely, friendly, efficient and professional.
</p>

<p>
All things considered, it's probably nowhere near as safe 
from third-party intrusion and reliable against service outage as 
the Google equivalent, but then again I didn't use Google Drive for
anything important, either. That's what my hard drives and USB sticks are for. 
Don't hand over the stuff that matters to third parties if you can avoid 
it.
</p>

<p>
<b>Caveat:</b> Some people might actually need Google Docs for work, because 
employers like to force their employees into certain ecosystems. I'm 
forced into other ecosystems by mine, see
<a href="#tacs">Tradeoffs and Concessions</a>
below. The best option in these cases is of course to use it exclusively for 
work, exclusively on your work computer and in a separate web browser if
possible.
</p>

<h3>Many more sites</h3>

<p>
There are tons of sites, services and apps I don't use, for example 
Paypal and Dropbox. In fact, I avoid most sites where I have to register 
an account.
</p>

<h3>Phone Apps</h3>

<p>
My employer supplies me with a smartphone. On it I keep only the apps I 
need for work and banking. When commuting was still a thing, I also 
listened to Spotify. Other than that, I try to use it as little as 
possible these days. I do carry it with me, though: it mostly works fine 
as a phone and mobile phones are pretty damn convenient.
</p>

<p>
<b>Coping strategy:</b> I've never been fond of having a lot of apps.
Most of them are pointless and solve completely invented problems.
</p>

<h3>My local newspaper</h3>

<p>
I used to pay for an online subscription, until I just decided to stop 
one day. Apart from the poor quality of journalism, the biased reporting and 
the insipid editorial texts, I was basically paying money to keep feeding 
the online ad machine. That's a no-go.
</p>

<p>
<b>Coping strategy:</b> It's probably a reasonable idea to keep somewhat 
informed about current events. <a href="#news">See "News" below.</a>
</p>

<h2>Things I do use</h2>

<h3>Linux</h3>

<p>
In terms of user empowerment, even Canonical's Ubuntu with its telemetry 
and mysterious snap packages is so far a much better choice than any 
proprietary home computer OS on the market. From a privacy standpoint, 
other distributions, such as Debian and Slackware, are of course even 
better.
</p>

<h3>Native software</h3>

<p>
Turns out there are plenty of good programs that can be used completely 
offline and will let you store your files locally. They're not even hard 
to find. A few tips: Abiword, GNumeric, The Gimp, WordGrinder, 
Audacious.
</p>


<h3>The Web</h3>

<h4>The web, method one: Links2</h4>

<p>
The web still has good parts and I want to get at those good parts. 
Turns out the really good parts are usually remnants of The Old Web, 
consisting of HTML and great content.
</p>

<p>
I try to do as much web browsing as possible in Links2. It's a fast, 
lean browser with zero support for JavaScript and CSS. The latter means 
some sites look a bit funky. The former means some sites won't work at 
all. My usual strategy for sites that won't render without JavaScript is 
to simply ignore them. If they can't produce something worthwhile 
without scripting, it's probably not worthwhile at all.
</p>

<p>
On the plus side, no JavaScript means that most trackers and other spy- 
and malware just won't run at all. Since Links doesn't save <i>any</i> 
cookies between sessions, other means of tracking will at least be kept 
somewhat confused. The flip side is that it's probably an extremely 
unique browser fingerprint.
</p>

<h4>The web, method two: RSS and native applications</h4>

<p>
You can subscribe to Youtube channels, subreddits and pretty much every 
blog out there using RSS. There are also plenty of specialized TUI:s and 
CLI:s for interfacing with various popular websites such as Youtube and 
Reddit.
</p>

<h4>The web, method three: Firefox with UBlock Origin</h4>

<p>
For some things, like banking and filing taxes, the Internet really has 
made things so much more convenient I don't want to live without them. 
Although my bank could easily provide the services I use completely 
without a single line of JavaScript, they have decided not to. This also 
goes for most online shopping. For these types of sites, I use Firefox.
</p>

<h3>Youtube</h3>

<p>
There's still plenty of worthwhile content published on Youtube, not 
least recordings of demo scene productions for obscure hardware.
</p>

<p>
I watch Youtube using my own <a href="https://datagubbe.se/yt">tube script</a> in 
combination with a media player. It's not ideal, since Google will be 
able to infer a bit about my habits through my IP (although that could 
of course be mitigated using a VPN) and some videos don't work due to 
various restrictions imposed by their creators (or copyright laws). 
Somewhere around 90% of them do though, especially the interesting 
ones such as Computerphile and Numberphile). The upside is freedom from 
ads and algorithmic "recommendations": I watch only the videos I really 
want to watch.
</p>

<h3>Wikipedia</h3>

<p>
Still a useful and usable site.
</p>

<h3 id="news">News</h3>

<p>
Most of the content produced by news media is either clickbait or some 
kind of "commentary" by "experts" on actual headline news, which can 
then be milked for another couple of days. More often than not, the 
reporting is either misinformed, or biased, or both. Still, keeping 
somewhat updated can be beneficial for private decision making and 
overall …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datagubbe.se/subversive/">https://datagubbe.se/subversive/</a></em></p>]]>
            </description>
            <link>https://datagubbe.se/subversive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988273</guid>
            <pubDate>Wed, 04 Nov 2020 12:03:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get Started with Infection Monkey, Open Source Security Tool]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24988227">thread link</a>) | @morchen
<br/>
November 4, 2020 | https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p><img src="https://swimm.io/media/screen-shot-2020-11-04-at-10.34.43.png" alt="Infection monkey "></p>
<p>Infection Monkey powered by Guardicore is a popular Open Source project and essentially a Breach and Attack Simulation (BAS) tool that analyzes and breaks down the robustness of cloud-based development environments, regardless of if they are of the private or public type.</p>
<p><a href="https://twitter.com/ShayNehmad">Shay Nehmad</a>, a seasoned Open Source developer, and Shreya Malviya, a contributor to Infection Monkey, spoke to the participants about how Swimm is making it easier to contribute to the project and make a difference.</p>
<p>The resiliency to post-breach attacks and lateral movement is done with the help of automatic attack simulations that inject a random machine with a proprietary Infection Monkey code, which helps gauge and discover security loopholes and vulnerabilities. Think of it as an automated Pen Testing tool.</p>
<p>The 48 hour online event devoted to encouraging contributions to open source projects hosted by Brian Douglas of Github,&nbsp; the Open Sauced community and backed by Swimm.</p>
<p>Check out the event <a href="https://www.youtube.com/playlist?list=PLHyZ0Wz_A44Ul9-YwiT-zt-JgEy3lRGns">here</a>.</p>
<h2>Getting Started with Infection Monkey using Swimm</h2>
<p><a href="https://github.com/guardicore/monkey#:~:text=The%20Infection%20Monkey%20is%20an,a%20centralized%20Monkey%20Island%20server.">Infection Monkey</a> is very straightforward and user-friendly. The Monkey, is a proprietary tool that infects random machines in the target environment and propagates to them. And there is Monkey Island, a dedicated centralized dashboard to monitor the results and findings. More about the Infection Monkey installation process <a href="https://www.guardicore.com/infectionmonkey/wt/">here</a>.</p>
<p><img src="https://swimm.io/media/screen-shot-2020-11-04-at-11.02.48.png" alt="The Map" title="github.com/guardicore/monkey"></p>
<p>Besides being a non-intrusive and plug-and-play tool, Infection Monkey requires zero maintenance and runs around the clock for comprehensive security analysis. Furthermore, users can also get actionable insights and recommendations with the ability to define alerts as per their requirements.</p>
<blockquote>
<p>Swimm makes the onboarding of contributors to open source projects easier. Since everything related to Swimm is within the Infection Monkey (henceforth: IM) repository, all that you have to do is to clone that repo, start the terminal, and run the command “swimm start” on your terminal.</p>
</blockquote>
<p>Once the server starts, it automatically opens the Swimm homepage, which already has playlists for IM. Currently, the repository includes three playlists (Post-breach action, Configuration, and System Info Collection). For this tutorial, we will use an extra-verbose playlist called “Adding a PBA in 5 Simple Steps”.</p>
<p><img src="https://lh6.googleusercontent.com/wbkmZQhpI08v8F6ivT_mEp0Dsa7mAQ-g9xS4VGAs5-GZniEwnEl_BHm4ui5BqxZRB613RULmPIk1uXOmsVQOVCR5xFmHjUevYXWcrkOk7Rs6BdYT-qQe9bZGhZL-aC1neoYxnROu" alt=""></p>
<p>In a nutshell, Infection Monkey is a penetration testing tool and it simulates a person breaking into your system. Once the person is inside your system, they can perform additional actions after conducting the breach. In IM terminology, these are referred to as the “post-breach actions” or PBAs.</p>
<h4>Define What Your New PBA Does</h4>
<p>This is the actual coding step. As the name suggests, it basically defines what your new PBA does. So, briefly, you have to define what this step will do in IM (as stated in the description). This step also gives you instructions to run the manual test after you are done. But first, let’s do the main coding part.</p>
<p>All you have to do is copy the command from the Swimm interface and run it on your terminal. This will give you some information about this particular unit.</p>
<p><img src="https://lh4.googleusercontent.com/n--uGoeV2gCm-JCZzKWr3nchhCZsHE8AkrldGNKm-L6uzNRQ4LDeB1zjwooiiENFs5_AAvdu3nSLMKeW0EUTfcewurPHMBbs_3a5RA0F_Nva7nfwAURu_3FGKjhO9QVSejoWHFL6" alt=""></p>
<p>For example, the “Definition of done” says that you need a new constant defining what the PBA does. Now, you can ask Swimm to tell you which particular files are relevant to this specific Unit by running the command “Swimm Files”. It shows you the name of one file which is relevant to this Unit.</p>
<p><img src="https://lh3.googleusercontent.com/vtfc9Vr61m_8KQr9uOBS6eK2qMRVgoeCPZRuatXYzAVR40xiq41d3jKJKNql6FRg5GIDNwo26-2X2PPhMAsXNlboVXxKwwcOXdHMrf0bun0_ZYCQtUGOGQxvxRfUSmHS-GEgg4i_" alt=""></p>
<blockquote>
<p>“This is pretty cool if you think about how you would do personal onboarding with someone. You would guide them toward the files relevant to what you are teaching.” - Shay Nehmad</p>
</blockquote>
<p>So we have to see how to define the name of the PBA which is to be done in this file. This really shows how building the Unit correctly can “emulate” or replace the personal onboarding process. Also, another thing we should notice here is that this particular file is in the module called “common”.</p>
<p>This suggests that everything we will do here is going to affect both the Monkey and the Swimm server. Open this file.</p>
<p><img src="https://lh4.googleusercontent.com/lnAb1DR5i9wnsoAZJNe76VeHqwv0wW4xyI9drUrGrH8MgXU6GK_-DRCbL8OGFHCfumQfR0KlvKALtpT-KMfox3wTMdbt0RDAyi89AZZ7CJx9ojaycexEHjTJshfvqdAXyoDGfMxd" alt=""></p>
<p>The comments generated by Swimm show you where you need to add your code. But if you are not sure about what to do next, Swimm provides hints via the command `swimm hint`.</p>
<p>If you go back to the file and look at that PBA, it basically tells you what the PBA with the name “Timestomping” does. That’s how you will also define the name of your new PBA. Add your new PBA “POST_BREACH_SCHEDULE_JOBS” and save the file. You have refined your new PBA, but how do we know this works?</p>
<p><img src="https://lh5.googleusercontent.com/ZMTPTwtUn17Qz2ABXXby8GipDAQSj9vwCgdlWgzYq85FoEBCOHHfkdijUQ5pBFPM-zXneonQNd1fuD0BFgWKtcc3tCE2CxvwD7dOelMiHXvAh9ahDusmIWZWCaEKe84Jghxvreom" alt=""></p>
<p>It's pretty easy when you are using Swimm. Let’s go back to the Swimm interface and learn about some easy and straightforward instructions to run the test.</p>
<p><img src="https://lh4.googleusercontent.com/oj-L3LjKzRhVqKbmPagGdHtkj-AoNYzEgKJ0P8tcg4es6sf1s-TnbG-Ig3BR0t4quDKl6UummO4FJXc-ifobCpWy79QOY-OfQYFexiqYVB3QnrFMxxnZ1dnFvuTuBapRClBTVMyN" alt=""></p>
<p>Let’s study the result of this test from its image.</p>
<p><img src="https://lh3.googleusercontent.com/bVQos7iG-I40XJfiDKJ7DH-SnUCed0Xtp5csLgqyLAmDTlUWkqzSRuG6H5DZB6xaLgav7qzcnEhIZrZRW1PZMemZyWYlVLp2YNNWH6Sjdfpz9jAcS4mCxMBKv_SAPd4W91wsmu7o" alt=""></p>
<p>Whatever you added to the PBA definitions file, you should be able to see in the test report. Once you are done studying it, you can mark it as done with the command `swimm done`. This will take you to a Swimm status page (see below) that also allows you to compare your solution to the original codebase.</p>
<p><img src="https://lh4.googleusercontent.com/nU2b4mGCv-mhVLPL8PotXYIeFC70Sid_prw7-oBbknXgnHJxIDSNG8DcwMZ6-19m90mJW4MPX6tEcHPLr3D6YkoO8A90Lya1T0iA9U8My7Eb3BTZntGwb20p6Tf256apGCynI5il" alt=""></p>
<h2>Implement a New PBA</h2>
<p>Now, we know that the schedule jobs PBA is pretty dangerous because if someone is able to schedule jobs on your system, they can leave open a backdoor or ensure a virus downloads itself in case it gets deleted.</p>
<p>So do you now have to schedule jobs in your operating systems? Luckily, Infection Monkey already has these commands in the codebase.</p>
<p><img src="https://lh6.googleusercontent.com/Wc1t9yejLqPPj7VTsIiOB-yIh9N-EVy27EiH9conClOaIA1HAtSpgXlqXrRK0zTqSxK2v1I7Wzw0z94HlAZy8mzfOV0D9sZ-tu5vU1MpfTJi_szhgNGrBjU2v-VRRVfiH0_tsUpI" alt=""></p>
<p>So, all you need to do is fetch commands from a function called `get_commands_to_schedule_jobs`.</p>
<p>Once again, the description of this Unit also shows a manual test to run after writing the code. Just like in the previous Unit, we can play the Unit by copying the command from the Swimm interface and running it on your terminal. You can also request Swimm to tell you the relevant files with the same command.</p>
<p><img src="https://lh3.googleusercontent.com/bMfq0Tlu_TT2BXFJ6z7Bb9SCrN158jAPBO-UKGbhAj2XLqISnxL3c6T_cKXpSGXV-FPlYcgVyQ2R7ejaeFsYM71saNVBIbiIFJ8T3irHqE75aE1TtBp7UORLrR1uAljI3NmkEBZJ" alt=""></p>
<p>This time it tells you that the relevant file is in a module called “infection_monkey” which suggests that whatever we will be doing is going to affect the Monkey (i.e. the virtual intruder simulated by Infection Monkey) itself. This makes sense because you will basically be adding new functionality.</p>
<p>So, once you open the file, you will see a comment that tells you where you need to add your new code. This is something that leaves no place for error.</p>
<p><img src="https://lh4.googleusercontent.com/wD6oSMRb2YH2qY-ZJALKj3FEs10TJO7GaZuU2CFJW2ysPjvYvyPVolFmakq549bFyec4P_hsDNr1iPqpijLwDE6uWEizlQdn9YeJMCMeiQ3BCrd5-8v-ulefx5vfCSaoyouk5EVT" alt=""></p>
<p>Let’s ask Swimm for more hints about how to proceed with coding in this Unit.</p>
<p><img src="https://lh4.googleusercontent.com/ffI32iZ3jXpwLuGRb-EGO9tQyZLRIQASQa5AUFY2tImzdEo8ZVMqoNkg0T0h6iniEx-IfowbVRxNpnUELuWi3eGjBidBtl9dP8BINBHzP5AVCkZ__u0hrW6n1EYw4t8JqaMtHTNX" alt=""></p>
<p>Swimm provides you with two hints. Let’s go ahead with the first one which suggests you check the “Time Stomping” PBA to get an idea about the implementation.</p>
<p><img src="https://lh5.googleusercontent.com/RtASkWQPjlZjjUAdFvzPXiV0Zttvuj7VxpbODATTF1aALEv4B9kKhas61sDZO7ikmID77Bs7jX2EF7n1Du-RD8djCShbTW2EpXZZy3dCyG9svG8OoXaoC_z7lgP49NHSxxgY35Vz" alt=""></p>
<p>We can see here that we are basically fetching Linux and Windows commands from a function called `get_timestomping_commands`. Then you will call the constructor for the parent class with the name of the PBA, the Linux commands, and the Windows commands as arguments.</p>
<p>So, you will do something similar to “schedule jobs” PBA.</p>
<p><img src="https://lh4.googleusercontent.com/HhKuTh0wzVAHddeJHHGY7PYUKSweb0TdHtM3hgd3WPgYVIfNL1bKzRuUsvwbH0RC1ml4wsNeivKW9AxrjUd9CvBF6wNQO0txtFfJJPFcljUrS50Gd5P3jSS8fVBygPubLS3ZMGdk" alt=""></p>
<p>Here, you can see the code fetches the commands from the function given in the description and it calls the constructor of the parent class.</p>
<p>Swimm has given you a second hint that notifies you to remove your PBA by removing the schedule jobs.</p>
<p>For that purpose, you can see a call to the function called `remove_scheduled_jobs`.</p>
<p>You can really walk through each line of the solution and see how building the Unit correctly nudged whoever’s solving it to write each line. So, from lines 13 to 18, that was the first hint telling you the general structure of how to implement post-breach actions in IM that are based on shell commands.</p>
<p>Following the hint shows you an example of how to write that code. Another cool thing pops up when we look at line 16. We can see the code is pulling the name of the PBA from the variable we defined in the previous Unit. The last line is from the second hint.</p>
<p>You may decide to not look at the hints and go blind trying to solve it. In this case, when you mark your unit done in Swimm and then compare it to the actual solution, you’ll find that discrepancy. If you forgot to remove the scheduled jobs, you will find it in the diff. It’s up to you as the Swimmer to choose if you’d rather see hints or not.</p>
<p>Now that you have added the code, let’s run the manual test by following the instructions in the Unit’s description.</p>
<p><img src="https://lh6.googleusercontent.com/h2EUcy5vZxKp9DkINaiSFjQ-5Yv7f_MtnaL5q27cucqc61GrB7xU1OlTH1w5W_1PCKJJE4Pkk1nRdAVlcsDg1EZshdSJvzHqkJS8SlV1_A5icgii59WgGcXCVtVGUX2JJPpR2gZp" alt=""></p>
<p>You can see in the attack report that it successfully scheduled a job using `crontab`. Let’s mark the Unit as done in Swimm with the command `swimm done`. Just like the last step, you will be taken to a page that gives you more information about what changes you’ve just made.</p>
<p><img src="https://lh5.googleusercontent.com/gintBnsEcmxzAzpSPUnZfi8t1657nzb4b0votoNDt9C3sVe6MkR28hl_taR46cOsVwidaJ3imRdeV439FMYmQq6VLxTEe1k6AWR7Ct7bdLSC7SKEj7YdLxL1gjyozdSNewzooDeX" alt=""></p>
<p>This summary guides the person solving the Unit to read other parts of the code. Now that you have made some contributions, you are already more familiar with the lexicon, and manually tested your changes, you now have the context to figure out the code much quicker and improve your productivity when contributing to Infection Monkey!</p>
<p><img src="https://lh5.googleusercontent.com/Ue285WOS8WBBNqmcS6QndVxB1ZHrt2U_CzeKFqxRSqP-ylm-j5nmseJ1L6l-vVNCu2ZOvh68qJGynji0p6iEyOv8Ri5eFfKKi3yV3BH2ONLZ2E7eNccTyWx6Y9rvNo8kG4Z1t9eR" alt=""></p>
<p>Once again, Swimm will let you compare your solution to the original codebase. Now that you named the PBA and implemented it, the next step is to make sure that it actually shows up in the configuration. So, let’s move on to the fourth step, where you will be adding details about your PBA.</p>
<h2>Add Details About Your New PBA</h2>
<p><img src="https://lh6.googleusercontent.com/_eTNZp-OGjYt84lmYqnQZR9_TB2QWd_I7X9T5i9cyLvDdi9vSt-2fdDdFvhdlPkG_REI1Iq9vSKoPzyACek-EqstoIe6FbZxj8wFgIhTPMf_NYUqZpyNKK0rSBiixcwsJ5mZ2bcO" alt=""></p>
<p>This is actually a pretty good example of how learning begets learning. Whenever you are trying to learn something new, you come across new terms, new terminology, and you look it up and research it. The MITRE ATT&amp;CK technique is something you will encounter a lot and you need to be ready for it.</p>
<blockquote>
<p>“The MITRE ATT&amp;CK framework is an open-source knowledge base of attack tactics and techniques which were derived from real-world scenarios. This is something professionals in the cybersecurity industry refer to a lot." - Shreya Malviya</p>
</blockquote>
<p>In this particular example, the “schedule jobs” PBA is related to two MITRE techniques that are shown in the description with their IDs. They basically do what the PBA does - scheduling jobs for Linux and Windows.</p>
<p><img src="https://lh6.googleusercontent.com/3mTHvCgEGmqJY6erSnouIhmtLugxxaCAJfOI56umZVBcgOypbl_12zUMzrtItPzrYFle2ClJwaPV74bK2k7egoJLUZTcGBTXh_QZPFNJlxGdqUBi6fnaY42VA54THouAaQtVzdka" alt=""></p>
<p>Here you can see a short recording of how the finder test should look so that it’s easier to ensure that whatever you’ve done is correct. Now, you …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/">https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/</a></em></p>]]>
            </description>
            <link>https://swimm.io/blog/infection-monkey-tutorial-start-contributing-using-swimm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988227</guid>
            <pubDate>Wed, 04 Nov 2020 11:54:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elections pages webperf on biggest news sites]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24988120">thread link</a>) | @tweereal
<br/>
November 4, 2020 | https://www.lightest.app/c/CVHdNo0ek4?view=timeline | <a href="https://web.archive.org/web/*/https://www.lightest.app/c/CVHdNo0ek4?view=timeline">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lightest.app/c/CVHdNo0ek4?view=timeline</link>
            <guid isPermaLink="false">hacker-news-small-sites-24988120</guid>
            <pubDate>Wed, 04 Nov 2020 11:29:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audible robs indie audiobook creators]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24987961">thread link</a>) | @samizdis
<br/>
November 4, 2020 | https://pluralistic.net/2020/11/03/somebody-will/#acx | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/11/03/somebody-will/#acx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1557">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
history, attack surface, hope, hopepunk, agency, elections, 2020, xkcd, webcomics, ai, machine learning, thick description, amazon, audible, exploitation, audiobooks, writing, self-publishing, monopolism, deepfakes, reckonings, mark zuckerberg, facebook, wish fulfillment, brett kavanaugh, scotus, alex jones

Summary:
Deep Reckonings; Past Performance is Not Indicative of Future Results; How Audible robs indie audiobook creators; Get an extra vote; A hopeful future

URL:
https://pluralistic.net/2020/11/03/somebody-will/

Title:
Pluralistic: 03 Nov 2020 somebody-will

Bullet:
🧂

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: 

--><br>
<a href="https://pluralistic.net/2020/11/03/somebody-will/"><img src="https://i1.wp.com/craphound.com/images/03Nov2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/03Nov2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/03/somebody-will/#contrafactuals">Deep Reckonings</a>: Using deepfakes to conjure a contrafactual reality in which monsters confront their legacies.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/03/somebody-will/#a-not-i">Past Performance is Not Indicative of Future Results</a>: The limits of theory-free statistical inference.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/03/somebody-will/#acx">How Audible robs indie audiobook creators</a>: I am altering the deal. Pray I don't alter it any further.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/03/somebody-will/#nudge-nudge">Get an extra vote</a>: Reminders from friends and family to vote have a bigger effect on turnout than anything campaigns do.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/03/somebody-will/#somebody-will">A hopeful future</a>: Optimism and pessimism are both fatalism.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/03/somebody-will/#retro">This day in history</a>: 2005, 2010, 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/03/somebody-will/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="contrafactuals"></a><br>
<img src="https://i1.wp.com/craphound.com/images/prosocial-visual-v2_orig.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/prosocial-visual-v2_orig.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>"Deep Reckonings" is Stephanie Lepp's art project: she's created three deepfake videos in which three of the current moment's most clueless powerful monsters have a moral reckoning and make a clean breast of their failings.</p>
<p><a href="https://the.ink/p/breaking-mark-zuckerberg-brett-kavanaugh">https://the.ink/p/breaking-mark-zuckerberg-brett-kavanaugh</a></p>
<p>First is Brett Kavanaugh, relating the evolution of his understanding of what sexual abuse means and his own history of sexual abuse, apologizing to the survivors of his crimes.</p>
<p><img src="https://i1.wp.com/craphound.com/images/kavanaughanimation.gif?w=840&amp;ssl=1" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p><a href="https://www.youtube.com/watch?v=nErNatAdfSw">https://www.youtube.com/watch?v=nErNatAdfSw</a></p>
<p>Next is Mark Zuckerberg, realizing that he's been kidding himself all along about the nature of Facebook, and the intrinsic harm that his business-model inflicts on the people he has imprisoned in his walled garden.</p>
<p><img src="https://i1.wp.com/craphound.com/images/zuckfakeanimation.gif?w=840&amp;ssl=1" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p><a href="https://www.youtube.com/watch?v=El7_uF-sGWE">https://www.youtube.com/watch?v=El7_uF-sGWE</a></p>
<p>Finally, there's Alex Jones, realizing that his quest to root out real conspiracies led him down a path of exploiting his audience and his victims with off-the-rails conspiracism.</p>
<p><img src="https://i1.wp.com/craphound.com/images/alexjonesanimation.gif?w=840&amp;ssl=1" data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p><a href="https://www.youtube.com/watch?v=6WNuxGXw22w">https://www.youtube.com/watch?v=6WNuxGXw22w</a></p>
<p>Here's Lepp's statement on her pieces:</p>
<p><a href="http://www.deepreckonings.com/statement.html">http://www.deepreckonings.com/statement.html</a></p>
<p>"Where I see the greatest untapped potential for prosocial synthetic media is in a capacity that emerges across all three categories: to envision and elicit the change we wish to see."</p>
<p>This really resonates with me, especially in light of my latest novel, ATTACK SURFACE, the tale of cybermercenary who confronts her lifelong legacy of complicity in human rights abuses and tries to find redemption:</p>
<p><a href="https://attacksurface.com/">https://attacksurface.com/</a></p>
<p>And in light of my next novel, THE LOST CAUSE, about truth and reconciliation with white nationalist militias after a successful GND transformation.</p>
<p><a href="https://www.patreon.com/posts/new-decameron-36398964">https://www.patreon.com/posts/new-decameron-36398964</a></p>
<p>It is such a balm, inhabiting these fictional places in which the crises that haunt me today are being addressed — painfully, imperfectly, but still: confronted rather than being left to fester.</p>
<hr>
<p><a name="a-not-i"></a><br>
<img src="https://i1.wp.com/craphound.com/images/KBLqvO.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/KBLqvO.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>My latest Locus Magazine column is "Past Performance is Not Indicative of Future Results," an essay about the limits of machine learning and the reason that statistical inference will not lead to consciousness.</p>
<p><a href="https://locusmag.com/2020/11/cory-doctorow-past-performance-is-not-indicative-of-future-results/">https://locusmag.com/2020/11/cory-doctorow-past-performance-is-not-indicative-of-future-results/</a></p>
<p>At its core, machine-learning is "theory free correlation-detection" – that is, it takes training data and finds things that appear together in it. Two things labeled an eye and one thing labeled a nose and one thing labeled a mouth all add up to a face.</p>
<p>But the classifier doesn't know what a noses, eyes, or mouths are. It doesn't know what a face is. Your doorbell camera doesn't know that the face-like thing in the melting snow on your walk <em>can't</em> be a face, so it repeatedly warns you about a stranger on your doorstep.</p>
<p>That theory-free-ness, combined with the abstruse mathematics of statistics, is what gets "AI" into so much trouble. Give machine learning classifiers of all the successful people at your company and it will tell you to hire people like them.</p>
<p>But if you've been missing great people due to bias, that is terrible advice – and it's got the veneer of empiricism. Remember when AOC got tons of shit from far-right assholes for calling an algorithm racist? How can math be racist?</p>
<p><a href="https://www.livescience.com/64621-how-algorithms-can-be-racist.html">https://www.livescience.com/64621-how-algorithms-can-be-racist.html</a></p>
<p>Theory-free isn't good enough. To understand what's happening in a complex situation, you haven't to be an anthropologist, not just a statistician. You need what Clifford Geertz called "thick description" – the qualitative accounts of the quantitative phenomenon.</p>
<p>Quantitative researchers are infamous for screwing this up. The qualitative elements are hard to do math on, so they incinerate them and leave behind a quantitative residue and do math on that, assuming it will be sufficient. It's (usually) not.</p>
<p>That's why exposure notification isn't contact tracing: knowing that two Bluetooth radios were close to each other for 15 minutes doesn't tell you if they were swapping spit or stuck in adjacent, sealed automobiles in a traffic jam.</p>
<p>Using theory-free inference to understand the world doesn't and can't lead to comprehension. "Theory-free" is the opposite of comprehension. We may not have a universal, agreed-upon definition of "artificial intelligence" but "understanding" is definitely a part of it.</p>
<p>Machine-learning classifiers have done amazing things to automate away a ton of drudgery, just as smiths did amazing things to shape metal. But smiths couldn't make reliable internal combustion engines. Incremental improvements in metal-beating don't evolve into machining.</p>
<p>Reliably turning out the precision components that produced engines needed casting and machining. Getting there required a shift in approaches, not improvement in the existing approach.</p>
<p>Theory-free statistical inference does a lot of good stuff – and produces a lot of bad outcomes – but the idea that if we do enough of it we'll get artificial intelligence is fundamentally wrong.</p>
<hr>
<p><a name="acx"></a><br>
<img src="https://i2.wp.com/craphound.com/images/audibleripoff.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/audibleripoff.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Amazon's ACX is a self-serve audiobook production platform:  writers spend thousands of dollars to produce audiobooks of their own work. Amazon strongly incentivizes ACX producers to sell exclusively through Audible (which also distributes to Itunes).</p>
<p>If you go exclusive, you get a better split of the proceeds – 40%. That's right: though you bore all production costs and Amazon has no costs associated with selling your audiobook, Amazon still keeps the majority of the revenue from it, even if you grant them exclusivity.</p>
<p>As unfair as that may sound, it gets a LOT worse. As part of its effort to lure customers to Audible, Amazon now grants no-questions-asked returns on audiobooks, and claws back the lost revenue from those returns from the audiobook creators.</p>
<p><a href="https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales">https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales</a></p>
<p>Amazon's return policy is very generous: you can return an audiobook for a full refund for a full year after you buy it. When you finish the book, the Audible app even shows you a "return book" button. Hit it and you get a refund.</p>
<p>But Amazon won't tell its authors how many returns they're getting. The only way to estimate is to sell a book for a month, take it out of circulation the next month, and see how far below zero the book's net sales are in a month when it isn't even for sale.</p>
<p>If you sold 10 copies in April, take the book off the market, and "sell" -5 copies in May, your returns are probably 50%.</p>
<p>This is the system creators have bootstrapped because Amazon, the world's most aggressive retail data-collector, somehow can't provide this number.</p>
<p>These authors spend thousands of dollars though an Amazon self-publishing platform, then the company conspires with unscrupulous readers to confiscate their payments, making the system more attractive off the backs of creators.</p>
<p>And here's the sting in the tail: if you opt for "Amazon exclusive," you are locked in for <em>seven years</em>. Amazon silently made the switch to "no hassle returns" and clawed back half its creators' money, with no chance to opt out.</p>
<p>Amazon gets to change its deal with creators when it wants to, but the creators don't get to change their deal with Amazon. For seven years after they produce their own audiobooks, they are locked to Amazon, regardless of Amazon's policy changes.</p>
<p>Seven.</p>
<p>Years.</p>
<p>Audible controls 90% of the audiobook market.</p>
<p>(<i>Image: <a href="https://commons.wikimedia.org/wiki/File:Attention_aux_pickpockets.svg">Paris 16</a>, <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA</a>, modified; <a href="https://thenounproject.com/term/ink-pen/193355/">Dmitry Baranovskiy</a>, <a href="https://creativecommons.org/licenses/by/4.0/">CC BY</a>, modified</i>)</p>
<hr>
<p><a name="nudge-nudge"></a><br>
<img src="https://i2.wp.com/craphound.com/images/election_impact_score_sheet_2x.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/election_impact_score_sheet_2x.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today on Xkcd, an "Election Impact Score Sheet" that turns on the theory that "reminders from friends and family to vote have a bigger effect on turnout than anything campaigns do."</p>
<p><a href="https://xkcd.com/2380/">https://xkcd.com/2380/</a></p>
<p>It's a call to action: if you have friends or family PA, ME, AK, MT, NM, WI, MI, IO, NC, NH, GA, NE, MI, FL, KS, MI or CO, drop them a line today – text, call, email – and remind them to vote. Prioritize these calls in roughly that order.</p>
<p>If the people you reach need help with their plan to vote, refer them to a guide like this one, and help them work through it, figuring it out together.</p>
<p><a href="https://projects.fivethirtyeight.com/how-to-vote-2020/">https://projects.fivethirtyeight.com/how-to-vote-2020/</a></p>
<p>If you remind two PA voters, the predicted impact on the election is as if you yourself had two votes.  For every 2.5 voters in AZ, ME or NE you remind, that's also predicted to shift the tally by one extra vote.</p>
<p>As the tooltip explains: "You might think most people you know are reliable voters, or that your nudge won't convince them, and you will usually be right. But some small but significant percentage of the time, you'll be wrong, and that's why this works."</p>
<hr>
<p><a name="somebody-will"></a><br>
<img src="https://i2.wp.com/craphound.com/images/AttackSurfaceCover.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/AttackSurfaceCover.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>I've been talking to Polygon's Tasha Robinson about my books for nearly two decades. She was one of the reviewers to dig into Down and Out in the Magic Kingdom, my debut novel, all the way back in 2003 when she was at The Onion's AV Club.</p>
<p><a href="https://aux.avclub.com/cory-doctorow-down-and-out-in-the-magic-kingdom-1798198255">https://aux.avclub.com/cory-doctorow-down-and-out-in-the-magic-kingdom-1798198255</a></p>
<p>She's always had smart things to say about my books (and is never shy about criticizing them) so I was delighted to talk with her about my latest, ATTACK SURFACE, for an interview: "Cory Doctorow on his drive to inspire positive futures."</p>
<p><a href="https://www.polygon.com/2020/11/2/21546161/cory-doctorow-attack-surface-utopia-interview">https://www.polygon.com/2020/11/2/21546161/cory-doctorow-attack-surface-utopia-interview</a></p>
<p>As the title suggests, the interview digs into the relationship between our narratives about the future and the future itself when …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/11/03/somebody-will/#acx">https://pluralistic.net/2020/11/03/somebody-will/#acx</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/11/03/somebody-will/#acx</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987961</guid>
            <pubDate>Wed, 04 Nov 2020 10:54:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doubleclicking on the Web (2015)]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24987829">thread link</a>) | @Mojah
<br/>
November 4, 2020 | https://ma.ttias.be/double-clicking-on-the-web/ | <a href="https://web.archive.org/web/*/https://ma.ttias.be/double-clicking-on-the-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Here’s a usability feature for the web: disable double-clicks on links and form submits.</p>
<p>Before you think I’m a complete idiot, allow me to talk some sense into the idea.</p>
<h2 id="the-double-click-outside-the-web">The Double-click Outside The Web</h2>
<p>Everywhere in the Operating System, whether it’s Windows or Mac OSX, the default behaviour to navigate between directories is by double-clicking them. We’re trained to double-click anything.</p>
<p>Want to open an application? Double-click the icon. Want to open an e-mail in your mail client? Double-click the subject. <strong>Double-clicks everywhere.</strong></p>
<p>Except on the web. The web is a single-click place.</p>
<h2 id="double-the-click-twice-the-fun">Double The Click, Twice The Fun</h2>
<p>We <em>know</em> we should only single-click a link. We <em>know</em> we should only click a form submit once. But sometimes, we double-click. Not because we do so intentionally, but because our brains are just hardwired to double-click everything.</p>
<p><strong>For techies like us, a double-click happens by accident.</strong> It’s an automated double-click, one we don’t really think about. One we didn’t mean to do.</p>
<p>For lesser-techies, also know as the <em>common man or woman</em>, double-clicks happen all the time. The user doesn’t have a technical background, so they don’t know the web works with single-clicks. Or perhaps they do, and don’t see the harm in double-clicking.</p>
<p><strong>But default browser behaviour is to accept user input. However foolish it may be.</strong></p>
<p>If you accidentally double-click a form submit, you submit it twice. It’s that simple.</p>
<pre>10.0.1.1 - - [18/Apr/2015:00:37:06 +0400] "POST /index.php HTTP/1.1" 200 0 
10.0.1.1 - - [18/Apr/2015:00:37:07 +0400] "POST /index.php HTTP/1.1" 200 0</pre>
<p>If you double-click a link, it opens twice.</p>
<pre>10.0.1.1 - - [18/Apr/2015:00:37:06 +0400] "GET /index.php HTTP/1.1" 200 9105 
10.0.1.1 - - [18/Apr/2015:00:37:07 +0400] "GET /index.php HTTP/1.1" 200 9104</pre>
<p>The problem is <em>sort of</em> solved with fast servers. If the page loads fast enough, the next page may already be downloading/rendering, so the second click of that double-click is hitting some kind of <em>void</em>, the limbo in between the current and the next page.</p>
<p>For slower servers, that just take more time to generate a response, a double-click would still happen and re-submit or re-open a link.</p>
<h2 id="workarounds">Workarounds</h2>
<p>I recently filed a feature request at <a href="https://www.nucleus.be/en">our</a> devs for a similar problem.</p>
<p>If you <em>accidentally</em> (and we’ve all done this) double-click a form submit, you submit it twice. That means whatever action was requested, is executed by the server twice.</p>
<p>The fix client-side is relatively simple, to disable the form submit button after the first submit was registered. There’s a <a href="http://stackoverflow.com/questions/2830542/prevent-double-submission-of-forms-in-jquery/2830812#2830812">simple jquery snippet</a> that can solve this for you.</p>
<pre>$(document).ready(function(){
    $("form").submit(function(){
        setTimeout(function() {
            $('input').attr('disabled', 'disabled');
            $('a').attr('disabled', 'disabled');
        }, 50);
    })
});
</pre>
<p>Server-side, a fix could be to implement some kind of rate limiting or double-submit protection within a particular timeframe. <strong>Server-side, this is a much harder problem to solve.</strong></p>
<p>It’s 2015, why is this even a thing to consider?</p>
<h2 id="proposed-solution">Proposed Solution</h2>
<p>I can not think of a single reason why something like a form submit should have to be executed twice as a result of a <em>double-click</em>.</p>
<p>For a slow responding server, it’s reasonable for a user to hit the <em>submit</em> again after more than a few seconds have passed and no feedback has been given. Because of the lack of visual feedback that the request is still being processed, the expectation has been raised that the form submit did not work.</p>
<p>So the user submits again, thinking he must have made a mistake the first attempt. If the same form submit has been registered by the browser in less than 2 seconds, surely that must have been a mistake and would count as an <em>accidental double-click</em>?</p>
<p>Why should every web service implement a <em>double-click protection</em>, either client-side or server-side, and reinvent the wheel? Wouldn’t this make for a great browser feature?</p>
<p><strong>What if a double-click is blocked by default, and can be enabled again by setting a new attribute on the form?</strong></p>
<pre>&lt;form action="/something.php" allowmultiplesubmits&gt;
...
&lt;form&gt;
</pre>
<p>Setting the <strong>allowmultiplesubmits</strong> attribute causes the browser to allow multiple submits to the same form in the same page, and by default the browser has some kind of flood/repeat/double-click protection to prevent this.</p>
<p>Maybe I’m over thinking it and this isn’t an issue. But anyone who’s active on the web has, at one point, accidentally double-clicked. And I think we’ve got all the technology available to fix that, once and for all.</p>
                </div></div>]]>
            </description>
            <link>https://ma.ttias.be/double-clicking-on-the-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987829</guid>
            <pubDate>Wed, 04 Nov 2020 10:24:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of ASync/Await in Programming]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24987797">thread link</a>) | @madeskilz
<br/>
November 4, 2020 | https://blog.doyinsoft.com/benefits-of-asyncawait-in-programming | <a href="https://web.archive.org/web/*/https://blog.doyinsoft.com/benefits-of-asyncawait-in-programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1604476219745/qjpQ1Awv1.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>In programming, the async/await pattern may be a syntactic feature of the many programming languages that permits an asynchronous, non-blocking function to be structured in a way almost like a standard synchronous function. it's semantically associated with the concept of a coroutine and is usually implemented using similar techniques, and is primarily intended to supply opportunities for the program to execute other code while expecting a long-running, asynchronous task to finish, usually represented by promises or similar data structures. The feature is found in C# 5.0, Python 3.5, Hack, Dart, Kotlin 1.1, Rust 1.39,[1] Nim 0.9.4[2], and JavaScript ES2017, with some experimental add extensions, beta versions, and particular implementations of Scala[3] and C++.</p>
<p>Asynchronous programming may be a sort of parallel programming that permits a unit of labor to run separately from the first application thread. When the work is complete, it notifies the most thread (as well as whether the work was completed or failed). There are numerous benefits to using it, like improved application performance and enhanced responsiveness.</p>
<p>The main benefits of asynchronous programming using async / await include the following:</p>
<p>Increase the performance and responsiveness of your application, particularly once you have long-running operations that don't require to dam the execution. during this case, you'll perform other work while expecting the result from the long-running task.</p>
<p>Organize your code in a neat and readable way significantly better than the boilerplate code of the traditional thread creation and handling. with async / await, you write less code and your code is going to be more maintainable than using the previous asynchronous programming methods like using plain tasks.</p>
<p>async / await is that the newer replacement to BackgroundWorker, which has been used on windows forms desktop applications.</p>
<p>You make use of the most recent upgrades of the language features, as async / await was introduced in C# 5, and there are some improvements added to the feature like for every async and generalized async type like ValueTask.</p>
<p>The non-blocking programming
when you have long-running operations that don't require to dam the execution. during this case, you'll perform other work while expecting the results of the long-running task.</p>
<p>Imagine that we've two program flow and that they can add parallel without blocking one another.</p>
<p>Example: for instance that we'd like to log every error appear but at an equivalent time this could not block the flow so therein case we will log and return a message at an equivalent time.</p>
<p>the advantage of thread management in async/await programming
we know that in normal programming (blocking), every line of code is obstructing everything after it until it finishes the method albeit we've different flows (two flows with none dependency). but in async/await programming, the appliance won't block this thread, in other words, they're going to release it to try another work and when the function finishes the work any free thread will handle the response.</p>
<p>“Basically you'll use Asynchronous programming except when the next conditions are true…”</p>
<p>You are aiming for simplicity instead of efficiency.
You are looking to run simple or short-running operations.
Asynchronous programming won't provide benefit and truly will end in additional overhead on operations that are primarily CPU operations instead of people that involve network or overhead.</p>
<p>In Conclusion
Async/await is one of the foremost revolutionary features that are added to JavaScript within the past few years. It causes you to realize what a syntactical mess promises are and provides an intuitive replacement.</p>
<p>Concerns
Some valid skepticism you would possibly have about using this feature is that it makes asynchronous code less obvious: Our eyes learned to identify asynchronous code whenever we see a callback or a .then, it'll take a couple of weeks for your eyes to regulate to the new signs, but C# had this feature for years and other people who are conversant in it know it’s worth this minor, temporary inconvenience.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.doyinsoft.com/benefits-of-asyncawait-in-programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987797</guid>
            <pubDate>Wed, 04 Nov 2020 10:15:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Protect Your Smart Home]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24987687">thread link</a>) | @SimonAC
<br/>
November 4, 2020 | https://techplanet.today/post/how-to-protect-your-smart-home | <a href="https://web.archive.org/web/*/https://techplanet.today/post/how-to-protect-your-smart-home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    <p>As technology becomes more and&nbsp; more prevalent inside our homes; everything from speakers, to TVs, to washing&nbsp; machines, fridges, light bulbs, doorbells, thermostats, and even fish tanks&nbsp; are being connected to the internet. This comes with some risk. Hackers can now break&nbsp; into your home without ever setting food in it. In this article, I'm going to give you some tips&nbsp; on how to protect yourself and your family.</p>
<blockquote>
<p>This article is&nbsp; the third in a series of how to protect yourself from hackers. The first two cover <a href="https://techplanet.today/post/how-to-protect-your-online-accounts">protecting your&nbsp; online accounts</a> and your <a href="https://techplanet.today/post/how-to-protect-your-devices-from-hackers">devices from hackers</a>, respectively; so don't forget to check those out&nbsp; as well.</p>
</blockquote>
<p>First up, let me say that I love technology and I&nbsp; have quite a few networked gadgets all around my home. The thing is... I've been working with technology&nbsp; for a long time. I'm used to evaluating products, assessing their security, and designing a safe topology within which they can be deployed. Companies... some companies take a lot of care to&nbsp; ensure they are not compromising the security of their systems when they do this; and will bring in&nbsp; outside expertise to make sure they get it right. You can't expect the same sort of rigor&nbsp; to be applied by the general public.</p>
<p>Who goes to the shop to buy a washing machine, and has a security consultant come and perform an assessment of it's networked services? This sort of&nbsp; thing catches companies out all the time. There's an American casino that got hacked because of&nbsp; an internet-connected fish tank in its lobby.</p>
<p>The buzzword for this growing collection&nbsp; of devices that hook themselves up the internet is called the "internet of things" or&nbsp; IoT for short. If it can catch a casino with a dedicated security team flat-footed, your average&nbsp; consumer at home is definitely at a disadvantage.</p>
<p>It doesn't help that a lot of the time this&nbsp; internet connectivity is included as an afterthought. Washing machines aren't getting&nbsp; designed around their network connectivity. They're designed primarily around their ability&nbsp; to wash clothes, and then other factors like energy efficiency and noise. So you've got a decent&nbsp; design for your washing machine and then you find out your competitor's has an app.</p>
<p>Marketing&nbsp; say you need an app too. Right... what's the cheapest thing we can buy to stick in there and make&nbsp; it internet-connected so we can have an app too? As you may have guessed, the cheapest&nbsp; thing is not usually the most secure thing . There are a lot of devices on the market&nbsp; with really cheap and nasty connectivity. That leaves you exposed.</p>
<p>There are some horrible&nbsp; stories floating around of people being watched in their own homes, through their own cameras, by&nbsp; strangers on the internet. Of people coming into their child's bedroom to overhear some creep&nbsp; talking to them through the baby monitor. There are stories of people having their thermostats messed&nbsp; with - cranking up or cutting off the heat in the baby's room.</p>
<p>If your internet-connected fridge is&nbsp; set to holiday mode or your thermostat is set to away mode, a burglar could know when it's safe&nbsp; to break in... if they need to break in at all. If you've got a smart lock and it gets compromised,&nbsp; they may as well have a key. If just one of these devices gets compromised, it can be used to attack&nbsp; everything else on your home network.</p>
<p>My goal here isn't to scare you. More to get you to think&nbsp; about the devices you've got on your home network, and what risk they might pose. This isn't a joke,&nbsp; and it's not the case you'll be saved by anonymity. There is literally a <a href="https://www.shodan.io/" target="_blank" rel="nofollow noopener">search engine</a> that anyone can&nbsp; use that scans the internet for insecure devices. You can use it to search for vulnerable&nbsp; devices in people's homes and it will tell you what they are, where they are, and how to&nbsp; access them. It's that easy.&nbsp;So what can we do?</p>
<h2>Reputation &amp; Account Security</h2>
<p>First of all, do a bit of research on the company&nbsp; who made the product. If you Google your internet connected products, do a whole host of horror&nbsp; stories come up? That might be a good sign not to buy it. Now I should point out that just&nbsp; because a few people got hacked doesn't mean there's something wrong with the product itself. A&nbsp; lot of the time the device is fine but the person who got hacked was using a terrible password, and it was there account that got compromised.</p>
<h2>Default Passwords</h2>
<p>It does lead me onto the topic of default passwords, though. When you get a new device;&nbsp; always, always change the default password. Some devices these days come with a random password&nbsp; instead of the same password for every customer. Change it anyway. Some of these are not as random&nbsp; as they seem. In some cases there are only a handful of different passwords, and they just cycle through&nbsp; them. In others, those random looking letters and numbers are actually the device's physical MAC address (not to be confused with an Apple Mac). The problem with using the MAC address is that's&nbsp; how other devices in the network connect to it, so it can't be a secret - it's actively advertised. In the case of a wireless router, it is blasting that MAC address across the airwaves for anyone&nbsp; to see. Change the password!</p>
<p>If you don't change the password, it's like leaving your front door&nbsp; open with a sign saying "please don't rob me". When one of those scanners find your device on the&nbsp; internet, you can guarantee the first thing they're going to do is try and log in with the default&nbsp; password. This isn't just for home users.</p>
<p>In years gone by I used to onboard a lot of new customers&nbsp; for our support team at work. There were always devices on the network that weren't documented, and more often than not I was able to get into them just by trying a few default passwords. Printers are a big culprit in the corporate world.</p>
<h2>Firmware Updates</h2>
<p>The next thing you should do with any network-connected device is check for software or firmware updates. Anything with network connectivity should&nbsp; receive updates. No software is ever perfect, and as flaws are discovered that can be exploited, the&nbsp; vendor should be providing updates to fix them. On your computer or your phone, the updates&nbsp; are probably pushed to you; so you don't have to do much other than agree to them.</p>
<p>For a&nbsp; lot of IoT devices, though, this isn't the case; so you have to remember to check yourself&nbsp; and install any updates, manually. This is a good thing to check before you buy. How does&nbsp; a device get updated? If it's automatic, great! You're good. If it's a manual process then plan&nbsp; to be in the habit of checking and applying them. If there is no way for it to receive updates, don't&nbsp; buy it! That's a sure sign they've shoehorned in the cheapest bit of connectivity they could find,&nbsp; and didn't bother to think about security at all. This is important.</p>
<p>A quick search for camera I own&nbsp; shows 35 different vulnerabilities that have been reported that affect it, specifically. Fortunately, my device has been updated to protect against them; but only because i went to the manufacturer's&nbsp; website, downloaded the new firmware, and installed it on my camera. Otherwise that would&nbsp; be 35 different ways to try and break into my home.</p>
<h2>Features you don't need</h2>
<p>Speaking of my camera, here's another tip. If you don't need internet connectivity, turn it off. The camera I'm talking&nbsp; about is used as a baby monitor. It has an internet-connected feature that lets&nbsp; me check my baby from anywhere in the world. That's... not a feature I'm ever going to use. The&nbsp; way I see it, if I'm in a position of needing to use the internet connectivity, I'm not in a&nbsp; position to be able to comfort my child anyway, so what's the point? If that's enabled,&nbsp; it's open for anyone in the world to try and abuse it. So because I don't use that&nbsp; feature, I've turned its internet connectivity off. I don't need that to use it in my own home.</p>
<p>So take&nbsp; a look at your devices, and the features they offer. Turning off every feature you don't actually&nbsp; use can dramatically reduce the attack surface of your home.&nbsp;</p>
<h2>Wireless Security</h2>
<p>The heart of most home networks is of course&nbsp; your router. Technically speaking, it's probably a combined router, switch, firewall, wireless access&nbsp; point, and modem; but we'll stick with the name "router". Hopefully you've taken my earlier&nbsp; advice, and you've already changed both its administrative password and the password for the&nbsp; wireless network. There's more to it than just the password itself, though. Most routers come with&nbsp; various levels of security that can be enabled.</p>
<p>Unfortunately for most home readers, the default&nbsp; setting is to enable all of them. This is simply because a lot of home users would get confused if&nbsp; asked to choose their own settings, so the router makers just switch everything on to make it as&nbsp; easy as possible for people to get up and running. The downside of course is that by enabling&nbsp; options with weak security, you also make it easier for hackers to get in, too.</p>
<p>The most likely&nbsp; options you'll have for wireless security are WEP, WAP, and WAP2. The latest devices may also support&nbsp; WPA3. There are variations on these including personal and enterprise versions. For most home&nbsp; users you'll be after the personal version that uses a pre-shared key. Enterprise versions are&nbsp; aimed at businesses and are more secure, but require more knowledge and infrastructure to&nbsp; set up.</p>
<p>The general rule to follow is that you want to start with the most secure, work your way&nbsp; down, and only enable the security options that are absolutely necessary to allow your devices to&nbsp; connect.<img src="https://techplanet.today/storage/posts/2020/11/5fa277d2282ac.webp" alt="How To Protect Your Smart Home" width="508" height="auto" data-src="/storage/posts/2020/11/5fa277d2282ac.webp">WAP3 is the latest and greatest so if you have that, turn it on. A lot of devices at this time&nbsp; are not going to support it, so you'll almost certainly want to enable WPA2 as well. For&nbsp; the time being at least. In most cases you won't need to enable vanilla WAP. WPA2 has been around&nbsp; for 16 years, so it's pretty well supported. If in doubt, keep WAP1 turned off and see if everything&nbsp; works. If it doesn't, try reconnecting the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techplanet.today/post/how-to-protect-your-smart-home">https://techplanet.today/post/how-to-protect-your-smart-home</a></em></p>]]>
            </description>
            <link>https://techplanet.today/post/how-to-protect-your-smart-home</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987687</guid>
            <pubDate>Wed, 04 Nov 2020 09:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Telegram via Jabber/XMPP on Symbian Phones]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24987658">thread link</a>) | @app4soft
<br/>
November 4, 2020 | http://www.symbigram.com/telegramxmpp.html | <a href="https://web.archive.org/web/*/http://www.symbigram.com/telegramxmpp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><p><span>Telegram via Jabber on
Symbian Phones<br>
</span><br>
Prerequisites:<span>&nbsp; </span>You must have registered
telegram account running on iPhone or Android. You will need to use it
every time
you add new contact because Jabber clients on Symbian are not
integrated with
Address Book.</p><p>

Please note: only individual contacts supported, groups are not
supported.</p></div>

<p><!--[if !supportLists]--><span><span>1.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>Install
Pidgin xmpp client
on Windows PC</p>
<p><!--[if !supportLists]--><span><span>2.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>Register xmpp
account on <span>jabb.im .</span> </p>
<p><!--[if !supportLists]--><span><span>3.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>In this
manual, account is
tgtest@jabb.im</p>
<div><!--[if !supportLists]--><p><span><span>4.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>Login with
this account
into Pidgin</p><p>

<span><!--[if gte vml 1]><v:shapetype id="_x0000_t75"
 coordsize="21600,21600" o:spt="75" o:preferrelative="t" path="m@4@5l@4@11@9@11@9@5xe"
 filled="f" stroked="f">
 <v:stroke joinstyle="miter"/>
 <v:formulas>
  <v:f eqn="if lineDrawn pixelLineWidth 0"/>
  <v:f eqn="sum @0 1 0"/>
  <v:f eqn="sum 0 0 @1"/>
  <v:f eqn="prod @2 1 2"/>
  <v:f eqn="prod @3 21600 pixelWidth"/>
  <v:f eqn="prod @3 21600 pixelHeight"/>
  <v:f eqn="sum @0 0 1"/>
  <v:f eqn="prod @6 1 2"/>
  <v:f eqn="prod @7 21600 pixelWidth"/>
  <v:f eqn="sum @8 21600 0"/>
  <v:f eqn="prod @7 21600 pixelHeight"/>
  <v:f eqn="sum @10 21600 0"/>
 </v:formulas>
 <v:path o:extrusionok="f" gradientshapeok="t" o:connecttype="rect"/>
 <o:lock v:ext="edit" aspectratio="t"/>
</v:shapetype><v:shape id="Picture_x0020_1" o:spid="_x0000_i1042" type="#_x0000_t75"
 style='width:355.5pt;height:248.25pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image001.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image036.jpg" v:shapes="Picture_x0020_1" height="331" width="474"><!--[endif]--></span></p></div>

<div><!--[if !supportLists]--><p><span><span>5.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>Go to Plugins
and enable
XMPP Service Discovery</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_2"
 o:spid="_x0000_i1041" type="#_x0000_t75" style='width:237pt;height:302.25pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image003.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image037.jpg" v:shapes="Picture_x0020_2" height="403" width="316"><!--[endif]--></span></p><!--[if !supportLineBreakNewLine]--><br>
<!--[endif]--></div>

<div><!--[if !supportLists]--><p><span><span>6.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>Go to
Tools-&gt;XMPP
Service Discovery-&gt;Service Discovery</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_3"
 o:spid="_x0000_i1040" type="#_x0000_t75" style='width:187.5pt;height:219pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image005.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image038.jpg" v:shapes="Picture_x0020_3" height="292" width="250"><!--[endif]--></span></p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_4"
 o:spid="_x0000_i1039" type="#_x0000_t75" style='width:261.75pt;height:225.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image007.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image039.jpg" v:shapes="Picture_x0020_4" height="301" width="349"><!--[endif]--></span></p></div>

<div><!--[if !supportLists]--><p><span><span>7.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>Enter XMPP
Server (jabb.im)</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_5"
 o:spid="_x0000_i1038" type="#_x0000_t75" style='width:277.5pt;height:243.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image009.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image040.jpg" v:shapes="Picture_x0020_5" height="325" width="370"><!--[endif]--></span></p><!--[if !supportLineBreakNewLine]--><br>
<!--[endif]--></div>
<div><!--[if !supportLists]--><p><span><span>8.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>You will get
list of
services. Select telegram.jabbim.com and click “Register”</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_6"
 o:spid="_x0000_i1037" type="#_x0000_t75" style='width:302.25pt;height:261pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image011.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image041.jpg" v:shapes="Picture_x0020_6" height="348" width="403"><!--[endif]--></span></p></div>

<p><!--[if !supportLists]--><span><span>9.<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>You get
registration screen<br>
<span><!--[if gte vml 1]><v:shape id="Picture_x0020_7"
 o:spid="_x0000_i1036" type="#_x0000_t75" style='width:368.25pt;height:153pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image013.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image042.jpg" v:shapes="Picture_x0020_7" height="204" width="491"><!--[endif]--></span></p>

<p><!--[if !supportLists]--><span><span>10.<span>&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>Enter phone
number of your
Telegram account and press OK<br>
<span><!--[if gte vml 1]><v:shape id="Picture_x0020_8"
 o:spid="_x0000_i1035" type="#_x0000_t75" style='width:410.25pt;height:195pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image015.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image043.png" v:shapes="Picture_x0020_8" height="260" width="547"><!--[endif]--></span></p>


<div><!--[if !supportLists]--><p><span><span>11.<span>&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>You get
Registration
Successful screen</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_9"
 o:spid="_x0000_i1034" type="#_x0000_t75" style='width:358.5pt;height:170.25pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image017.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image044.jpg" v:shapes="Picture_x0020_9" height="227" width="478"><!--[endif]--></span></p></div>

<p><!--[if !supportLists]--><span><span>12.<span>&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>Press
Authorize on
Authorization request from telegram.jabbim.com<br>
<span><!--[if gte vml 1]><v:shape id="Picture_x0020_10"
 o:spid="_x0000_i1033" type="#_x0000_t75" style='width:393pt;height:274.5pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image019.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image045.jpg" v:shapes="Picture_x0020_10" height="366" width="524"><!--[endif]--></span></p>

<div><!--[if !supportLists]--><p><span><span>13.<span>&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>Telegram is
going to send
authorization code to your main Android/iPhone device</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_11"
 o:spid="_x0000_i1032" type="#_x0000_t75" style='width:348.75pt;height:252.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image021.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image046.jpg" v:shapes="Picture_x0020_11" height="337" width="465"><!--[endif]--></span></p></div>

<p><!--[if !supportLists]--><span><span>14.<span>&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>Enter code <br>
<span><!--[if gte vml 1]><v:shape id="Picture_x0020_12"
 o:spid="_x0000_i1031" type="#_x0000_t75" style='width:332.25pt;height:237pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image023.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image047.jpg" v:shapes="Picture_x0020_12" height="316" width="443"><!--[endif]--></span></p>

<div><!--[if !supportLists]--><p><span><span>15.<span>&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>You are
starting to get
Authorization requests from all your Telegram contacts. Authorize all
of them.
If you do not get these requests, restart Pidgin.</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_13"
 o:spid="_x0000_i1030" type="#_x0000_t75" style='width:332.25pt;height:234pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image025.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image048.png" v:shapes="Picture_x0020_13" height="312" width="443"><!--[endif]--></span></p></div>

<div><!--[if !supportLists]--><p><span><span>16.<span>&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>Add each one
of your
Telegram contacts to contact list</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_16"
 o:spid="_x0000_i1029" type="#_x0000_t75" style='width:324pt;height:216.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image027.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image049.png" v:shapes="Picture_x0020_16" height="289" width="432"><!--[endif]--></span></p></div>


<div><!--[if !supportLists]--><p><span><span>17.<span>&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>At the end
your list will
be like this</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_17"
 o:spid="_x0000_i1028" type="#_x0000_t75" style='width:192.75pt;height:321.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image029.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image029.png" v:shapes="Picture_x0020_17" height="429" width="257"><!--[endif]--></span></p><p>

Do not remove <span>telegram.jabbim.com .</span> You
must have this
contact in contact list!</p><p>

At this point you can exit Pidgin. You will not need it anymore.</p></div>

<p><!--[if !supportLists]--><span><span>18.<span>&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>On your
Symbian phone,
install Lightbulb or Mail.Ru Agent Jabber/XMPP clients. You may use
other
clients too but some of them may not support Telegram. </p>
<p><!--[if !supportLists]--><span><span>19.<span>&nbsp;&nbsp;
</span></span></span><!--[endif]--><span dir="ltr"></span>Connect to
internet</p>
<div><!--[if !supportLists]--><p><span><span>20.<span>&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>Configure
your jabber
account (<a href="mailto:tgtest@jabb.im">tgtest@jabb.im</a> on
Lightbulb in this
example)</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_19"
 o:spid="_x0000_i1027" type="#_x0000_t75" style='width:201pt;height:415.5pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image030.jpg" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image050.jpg" v:shapes="Picture_x0020_19" height="554" width="268"><!--[endif]--></span></p></div>

<div><!--[if !supportLists]--><p><span><span>21.<span>&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>You will get
authorization
requests from all your Telegram contacts and telegram.jabbim.com<br>
If you do not get these requests, restart your Symbian Jabber/XMPP
client</p><p>

<span><!--[if gte vml 1]><v:shape id="Picture_x0020_20"
 o:spid="_x0000_i1026" type="#_x0000_t75" style='width:218.25pt;height:451.5pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image032.jpg" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image051.jpg" v:shapes="Picture_x0020_20" height="602" width="291"><!--[endif]--></span></p></div>

<div><!--[if !supportLists]--><p><span><span>22.<span>&nbsp;&nbsp;
</span></span></span></p><!--[endif]--><p><span dir="ltr"></span>At the end
your Jabber
client will get all your Telegram contacts.<br>
Do not remove <span>telegram.jabbim.com .</span> You
must have this
contact in contact list!</p><p>


<span><!--[if gte vml 1]><v:shape id="Picture_x0020_21"
 o:spid="_x0000_i1025" type="#_x0000_t75" style='width:215.25pt;height:435.75pt;
 visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image034.jpg" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img src="http://www.symbigram.com/index_files/image052.jpg" v:shapes="Picture_x0020_21" height="581" width="287"><!--[endif]--></span></p><!--[if !supportLineBreakNewLine]--><br>
<!--[endif]--></div>


</div></div>]]>
            </description>
            <link>http://www.symbigram.com/telegramxmpp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987658</guid>
            <pubDate>Wed, 04 Nov 2020 09:45:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is it morally wrong to write inefficient code?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24987629">thread link</a>) | @todsacerdoti
<br/>
November 4, 2020 | https://tomgamon.com/posts/is-it-morally-wrong-to-write-inefficient-code/ | <a href="https://web.archive.org/web/*/https://tomgamon.com/posts/is-it-morally-wrong-to-write-inefficient-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In this post I will explore the idea that because running code contributes to global warming, writing inefficient code is morally wrong<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. I will start by outlining the argument, before working through each of the premises in turn to see how they hold up. I will then conclude that even if we cannot concretely defend every premise in this first iteration, then it is sufficiently plausible that it should at least make us pause for thought. With that said, let’s dive in!</p><p>The argument I am considering, in summary, can be presented as:</p><ol><li>Running code produces greenhouse gasses, proportional to the computing resources it requires.</li><li>Greenhouse gasses contribute to global warming.</li><li>Global warming increases the suffering of others.</li><li>Therefore, increasing your consumption of computing resources increases your contribution to the suffering of others.</li><li>Inefficient code increases your consumption of computing resources.</li><li>Therefore, inefficient code increases your contribution to the suffering of others.</li><li>Increasing your contribution to the suffering of others is morally wrong.</li><li>Therefore, writing inefficient code is morally wrong.</li></ol><p>I believe the argument as laid out above is valid, in that the conclusions follow from the premises, so we will focus our energies on determining if it is sound, that is all the premises are true. We will now break it down and look at each premise more carefully.</p><blockquote><ol><li>Running code produces greenhouse gasses, proportional to the computing resources it requires.</li></ol></blockquote><p>The first premise is based on the fact that running code requires electricity. Electricy, in large, requires the burning of fossil fuels, which releases a number of greenhouse gasses. There are cases where this is not the case (solar energy, wind energy), and in such cases, this argument is invalid. However, if you run your code on AWS, then it is very likely that you are running on fossil fuels<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. As AWS is the largest provider of cloud computing, this is likely to be true in a good number of cases.</p><blockquote><ol start="2"><li>Greenhouse gasses contribute to global warming.</li><li>Global warming increases the suffering of others.</li></ol></blockquote><p>With regards to the second and third premises, these are statements which are consistent with the overwhelming scientific consensus, and as such are uncontroversial. For the sake of completeness, here are some supporting statements from the <a href="https://www.ipcc.ch/site/assets/uploads/2018/02/AR5_SYR_FINAL_SPM.pdf">2014 climate change report summary</a> from the Intergovernmental Panel on Climate Change, emphasis mine.</p><blockquote><p><strong>Human influence on the climate system is clear, and recent anthropogenic emissions of greenhouse gases are the highest in history</strong>. Recent climate changes have had widespread impacts on human and natural systems.</p></blockquote><blockquote><p><strong>Warming of the climate system is unequivocal, and since the 1950s, many of the observed changes are unprecedented over decades to millennia</strong>. The atmosphere and ocean have warmed, the amounts of snow and ice have diminished, and sea level has risen.</p></blockquote><blockquote><p><strong>Continued emission of greenhouse gases will cause further warming and long-lasting changes in all components of the climate system, increasing the likelihood of severe, pervasive and irreversible impacts for people and ecosystems</strong>. Limiting climate change would require substantial and sustained reductions in greenhouse gas emissions which, together with adaptation, can limit climate change risks.</p></blockquote><blockquote><p>Cumulative emissions of CO2 largely determine global mean surface warming by the late 21st century and beyond.</p></blockquote><blockquote><p><strong>Climate change will amplify existing risks and create new risks for natural and human systems.</strong> Risks are unevenly distributed and are generally greater for disadvantaged people and communities in countries at all levels of development.</p></blockquote><p>I believe these to be enough to support the argument that greenhouse gasses contribute to global warming, and that global warming will increase suffering of the human and other animal populations.</p><blockquote><ol start="4"><li>Therefore, increasing your consiumption of computing resources increases your contribution to the suffering of others.</li></ol></blockquote><p>So here we come to our first conclusion, that increasing ones consumption of computing resources increases ones contribution to the suffering of others. It is based on at least two implicit premises. The first is that if A contributes to B, and B causes C, A contributes to C. The second is that in such a transitive relationship, if you increase your contribution to A then you increase your contribution to C. To illustrate, we can imagine a much more straightforward case. Imagine that I have a dial which, when turned, increases the voltage supplied to an electric chair. There are several such dials, and their contributions are additive. It would be fair to say that if I turned up my dial, I am contributing to the suffering of whoever is in that electric chair.</p><p>Given this assertion, it would seem reasonable that if running code produces greenhouse gasses, and greenhouse gasses contribute to global warming, then running code contributes to global warming. Global warming increases the suffering of others, so it follows that running code increases ones contribution to the suffering of others.</p><blockquote><ol start="5"><li>Inefficient code increases your consumption of computing resources.</li></ol></blockquote><p>Premise five seems relatively uncontroversial, though to simplify let us just consider the length of time some piece of code takes to run (in a similar way we assess algorithmic complexity). If an efficient version runs in 1 minute, and an inefficient version runs in 1 hour, it stands to reason that the inefficient version would consume more electricity.</p><blockquote><ol start="6"><li>Therefore, inefficient code increases your contribution to the suffering of others</li></ol></blockquote><p>With point six we again come to a relatively straightforward conclusion. If you agree with the earlier conclusion at point four and the premise at point five, then this falls out as a result of the logic of the statements.</p><blockquote><ol start="7"><li>Increasing your contribution to the suffering of others is morally wrong.</li></ol></blockquote><p>Point seven is the real crux of the argument, and on the surface intuitively plausible. In the above example with the dial, it would generally be considered morally wrong for you to dial up the dial and increase the suffering of the individual in the chair. However, if we are merely counting <em>contributions</em> to suffering, this casts a wide net. Would it be morally wrong not to buy an energy efficient bulb when an energy efficient one is available at the same price? How about breathing? This expels carbon dioxide, a greenhouse gas, but would generally not be considered a morally reprehensible action.</p><p>It seems that there is some inherent provision that increasing your contribution to the suffering of others is not morally wrong if it causes equal or greater personal suffering. For example, if there was some shared well of water, it would be reasonable to claim that it is not morally wrong of you to take a sip of water in order to save yourself from dehydration, even if that means other may become more dehydrated. However, if you drained the well, and threw that water away, causing another to die to dehydration, that seems morally wrong.</p><p>I think for the purposes of this post, we can consider this sufficiently true (there is definitely some sense in which it is true), even if is vulnerable to <a href="https://en.wikipedia.org/wiki/Reductio_ad_absurdum">reductio ad absurdum</a> in it’s current form. Consider it the alpha version of the premise - solid enough to be useful, but not without it’s bugs.</p><blockquote><ol start="8"><li>Therefore, writing inefficient code is morally wrong.</li></ol></blockquote><p>Here we come to the conclusion of the argument, that writing inefficient code is morally wrong, which follows from the logic set out in the conclusion at point six and the premise at point seven. So what does this mean?</p><p>As discussed, I am aware that this argument is probably not watertight, and perhaps with some more time spent on it we could tighten it up<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. I think the premise at point seven could definitely be better defended, and there almost certainly some implicit premises and caveats that need to be put in place. However, I think it is reasonable enough that it should make us pause and reflect. Whilst a lot of code performance issues can be covered up with bigger and better hardware, these come at a greater cost than just an increased AWS bill. The decisions we make as developers have real world effects.</p><p>If there are ways that we can reduce ‘programming waste’ we should strive to do so, whether that is changing an algorithm to be <code>O(1)</code>, scaling down some cloud instances or killing of that Heroku dyno that’s not really doing anything useful<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>. Collectively we can make a real difference.</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>I have had this idea knocking around for a while, but reading <a href="https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/">this post</a> motivated me to explore it further. Definitely check out the blog if you haven’t read it. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li><li id="fn:2" role="doc-endnote"><p><a href="https://www.youtube.com/watch?v=N4hiqGwTRBU">https://www.youtube.com/watch?v=N4hiqGwTRBU</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p></li><li id="fn:3" role="doc-endnote"><p>Perfect is the enemy of good. <a href="#fnref:3" role="doc-backlink">↩︎</a></p></li><li id="fn:4" role="doc-endnote"><p>After posting this, I am going to finally kill a bot that has been producing random inspirational quotes and posting them to Twitter for the last 6 years. <a href="#fnref:4" role="doc-backlink">↩︎</a></p></li></ol></section></section></div>]]>
            </description>
            <link>https://tomgamon.com/posts/is-it-morally-wrong-to-write-inefficient-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987629</guid>
            <pubDate>Wed, 04 Nov 2020 09:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coleman Barks and Rumi: Are Art and Religion Related?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24987582">thread link</a>) | @thecodrr
<br/>
November 4, 2020 | https://blog.streetwriters.co/barks-rumi-art-religion/ | <a href="https://web.archive.org/web/*/https://blog.streetwriters.co/barks-rumi-art-religion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2><span data-preserver-spaces="true">Modern Art and Religion</span></h2><p><span data-preserver-spaces="true">Modern art draws a clear boundary between religion and art. Religious contemporary literature is named a pseudo art or non-art in most circles.</span></p><p><span data-preserver-spaces="true">With the emergence of the neo-classical movement in Europe, a debate began about separating art and religion. With time, this led to the complete separation of religion and arts in the Modern and Post-Modern era.&nbsp;</span></p><p><span data-preserver-spaces="true">Works of fiction moved away from all religious connotations. Modern art gradually donned a new skin - one dissociated from religion. New standards deemed it taboo to borrow metaphors, and anecdotes, from religious texts.</span></p><p><span data-preserver-spaces="true">The separation of Art and Religion in our minds is like the separation of the church and the State. Politics, however, is very different. Where art is an organic living thing, politics is a mechanistic process. Art finds worth in emotions, beliefs, ideas, and cultures - it feels, laughs, cries, and believes; whereas politics looks after power, benefit, and in rare cases, the commonwealth.</span></p><h2><span data-preserver-spaces="true">How Religion Shapes Art</span></h2><p><span data-preserver-spaces="true">Literature and art were born in religious texts. <em>Rig Vedas</em>, <em>Quran</em>, and <em>the Bible</em> inspired Milton's <em>Paradise Lost</em>, Dante's <em>Divine Comedy</em>, Rumi's <em>Mathnavi</em>, the poetry of Hafiz, and so many other poets. Shelly's poetry uses metaphors from the <em>Greek Pantheon</em> and mythology, composing devout prayers appreciating nature's beauty.</span></p><p><span data-preserver-spaces="true">Religion influenced even heretical works like Nietzsche's <em>Thus Spoke Zarathustra</em>. Zarathustra comes down from a mountain to proclaim God's death and an end to religion, but his language is archaic and Biblical. His very character is prophetic and religious - a sort of poetic contradiction.</span></p><p><span data-preserver-spaces="true">In modern classical literature like <em>the Chronicles of Narnia</em> and <em>the Lord of the Rings</em>, religious symbolism shapes many characters. Biblical Prophets like Moses have encouraged fantastical characters like the wizard.</span></p><p><span data-preserver-spaces="true">Religion affects us subconsciously, without us realizing it. It is no mere chance that religious symbols are present everywhere — in our songs, media, architecture, and even mannerisms. Our environments, cultures, and history shape our affinities, making us love Bach's <em>Art of Fugue</em>, Schubert's <em>Ave Maria</em>, and many other musical pieces, whether we are religious or not.&nbsp;</span></p><h2><span data-preserver-spaces="true">Great Art and Religion</span></h2><p><span data-preserver-spaces="true">However, religion alone cannot create great art. All great works of art, religious or irreligious, speak the true voice of the artist's heart — without propaganda. Be it atheism, religion, irreligion, or any other dogma, art should be built seamlessly like an organic thing — living and breathing a life of its own, adding beauty and a sense of completion to it.</span></p><p><span data-preserver-spaces="true">We see this profundity and beauty in Rumi's <em>Mathnavi</em>. In the beginning, he seems a madman, but the more you read, the more sense it all makes until you start seeing everything with Rumi's eyes. Great art is like that — instantaneously living, never forced, and never artificial.</span></p><h3><strong><span data-preserver-spaces="true">Rumi &amp; Coleman Barks</span></strong></h3><p><span data-preserver-spaces="true">Coleman Barks is an accurate representation of a modern artist. He takes Rumi's brilliance, forcefully tones it down to a mundane level, and presents it to us on a rusty platter. Barks blatantly molds Rumi's words into different meanings murdering their purpose. Majid Nafisi, a Persian scholar, is not wrong in saying:</span></p><blockquote><p>To remodel and fix Rumi for the American market, Barks follows the path of a New-Age Sufi. He tries to disconnect Rumi's mystical concepts from their historical and social backgrounds and modify them for our contemporary taste.</p><p>- <em>Coleman Barks and Rumi's Donkey</em>, Majid Nafisi</p></blockquote><p>The result is a completely different creation - one based on propaganda. Art does not oppose change; rather it <em>is</em> the herald of change and evolution, but when art is turned into Silver - docile, malleable, and controlled; it no longer remains art.</p><h2><span data-preserver-spaces="true">Art as an Organism</span></h2><blockquote><p><em><span data-preserver-spaces="true">A living thing never forgets its roots. You can shed its form, burn its flesh, and erase its memories, but the fundamental constituents: its mannerism, behaviors, and affinities go back to its roots, its history.</span></em></p></blockquote><p><span data-preserver-spaces="true">Art is not a machine in a factory that can be reconfigured and changed with changing trends and ideologies. It is a living, breathing, evolving organism - an unconquerable heart driven by the artist's soul. Coercion, compulsion, lies, and hypocrisy cannot create art - only propaganda.</span></p><p><span data-preserver-spaces="true">Though ideologies shape art when they influence the people, the process is gradual, evolving, and natural. Forced dogmas only kill its spirit leaving behind an empty shell.</span></p></div></div>]]>
            </description>
            <link>https://blog.streetwriters.co/barks-rumi-art-religion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987582</guid>
            <pubDate>Wed, 04 Nov 2020 09:30:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detecting Dynamic Loading in Android Applications with /Proc/Maps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24987285">thread link</a>) | @jbkkd
<br/>
November 4, 2020 | https://sayfer.io/blog/dynamic-loading-in-android-applications-with-proc-maps/ | <a href="https://web.archive.org/web/*/https://sayfer.io/blog/dynamic-loading-in-android-applications-with-proc-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><strong>TL;DR:</strong> Through dynamic loading, malware authors can covertly load malicious code into their application in order to avoid detection. We can detect such loading through the application’s /proc/[PID]/maps kernel generated file.<br>Recently, we created a simple script that allows us to detect dynamic loading in Android apps. This presented us with a good opportunity to discuss dynamic loading in general in this blog.&nbsp; <br></p>
<h2><strong>Dynamic Loading and Linking:</strong></h2>
<p>In order to understand the rest of the blog, it is important to go over the basics of linking and loading, and highlight the differences between linking vs. loading, and static vs. dynamic.<br></p>
<p><strong>What Is Linking:</strong></p>
<p>The process of compilation has multiple parts. Linking is the last step before we get a runnable <a href="https://en.wikipedia.org/wiki/Executable">executable</a>. A program is usually more than a simple self-contained file, and relies on other libraries or files to operate. As such, it’s not enough for you to compile your code into machine-code to be able to run it, but also to somehow <em>link</em> the different files into a cohesive executable.</p>
<p>How is this done in practice? After compilation and assembly, the assembler outputs object files, which usually correspond to each module in your program. Such files can be either relocatable or executable. Object files of the first variety have to undergo linking before they can be run but ones of the second type can be executed immediately. In the GNU/Linux ecosystem, the usual extension for an object file is .o. Shared object files, known as libraries, are relocatable object files that are intended to be used by many different programs, and can’t be run on their own. In GNU/Linux, they have the extension .so (Shared Object), whereas in Windows they have the .dll (Dynamic-link Library) extension.</p>
<p>The linker then takes the files, resolves the symbols (functions and variables), and points them to the correct memory addresses by writing everything down in the symbol table of the executable. For the sake of performance, it also <em>relocates</em> your code so that related pieces of code end up mapped to nearby memory addresses, regardless of how you originally organized your program, as human readability isn’t an issue anymore, and performance is the main priority.&nbsp;</p>
<figure><a href="https://lh5.googleusercontent.com/XXBewy1ae5qCqrNeXEtizLTtuiz-9wmPcWOwYn8FniarcntKqWuIwzrVE1-gpIK02fC3S_RQMadOoMg-RC2zrlT2fuduhUv_gr_UUAuTjm0dXpD-Ii2jjWYRwEM-kqDEsw6w1ukv"><img src="https://lh5.googleusercontent.com/XXBewy1ae5qCqrNeXEtizLTtuiz-9wmPcWOwYn8FniarcntKqWuIwzrVE1-gpIK02fC3S_RQMadOoMg-RC2zrlT2fuduhUv_gr_UUAuTjm0dXpD-Ii2jjWYRwEM-kqDEsw6w1ukv" alt="linking" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></a></figure>
<p><strong>The Many Different Names of the Executable:</strong></p>
<p>In both Linux and Windows those seemingly different extensions have the same underlying formats as executables. In Windows, they are PEs (Portable Executable), and usually have the extensions .exe and .dll, and in Linux, they are ELFs (Executable and Linkable File), and have the extensions .bin, .so or .o (Yes, the object files we mentioned earlier are also ELFs).</p>
<p><strong>Dynamic Linking:</strong></p>
<p>We say that something has been dynamically linked when instead of doing that process during compile-time, it is done in load-time or runtime. Which brings us to loading: a loader simply copies the contents of the linker’s output to memory, and runs the program. When dynamic linking is used, the linking process occurs just before loading, when running the program, which often leads to confusion between the two.<br> Dynamic loading, on the other hand, means that parts of the code can be loaded to memory at any point during runtime. The two processes can and frequently are done together.</p>
<p><strong>So Why Is This a Problem?</strong></p>
<div><p>Dynamic loading is certainly useful. For example, rather than loading all libraries your program will use at load-time, you could load them up only when you need to use them, thus using less memory, or only conditionally load them in certain cases.</p><p>But it also presents an easy way for malware developers to hide their malicious code. They can put all of their legitimate code in the APK, and move all of the nefarious code into a DEX (Dalvik Executable) that the application will download and then dynamically load during use and thus make their application appear innocuous upon basic static inspection of the APK.</p></div>
<p><strong>Android 10 Mitigation:</strong></p>
<p>Thankfully, our wise overlords at Google decided to prevent such abuse by <a href="https://developer.android.com/about/versions/10/behavior-changes-10">forbidding apps from loading executables</a> (ELFs like .so, .bin and so on) from their home directory – they can now (API level 29+) only load binary code that’s included in their APK.<br></p>
<p>DEX files, however, have not changed and can still be dynamically loaded, so the threat hasn’t been completely eliminated. Furthermore, apps are now forbidden from changing their binary code in-memory after it has been loaded.</p>
<p><strong>How are DEX Classes Loaded:</strong></p>
<p>Android offers an option for dynamically loading .dex files using a class called <a href="https://developer.android.com/reference/dalvik/system/DexClassLoader">DexClassLoader</a>. To load a class, we simply need to write:<br></p>
<pre><code>// Init the loader
DexClassLoader dexClassLoader = new DexClassLoader(path_to_dex, null, null, parent_class);

// Load the class:
Class dynamic_class = dexClassLoader.loadClass("DynamicClass");

// Load a method we could call it
Method method = dynamic_class.getMethod("method1");</code></pre>
<p>And then we can use the method’s invoke() to use the method.<br></p>
<p><strong>The /proc/[PID]/maps File:</strong></p>
<p>In Unix, <a href="https://en.wikipedia.org/wiki/Everything_is_a_file">everything is a file</a>, and even if it isn’t really one, it is handled and accessed like one. This includes the Kernel’s data structures, and Linux is no exception to the rule. The Linux Kernel allows us to access and read its data structures through the /proc/ <strong>pseudo-file system</strong>. Each process then has its own folder at /proc/[PID]. The files and subfolders here hold plenty of useful and important information about the process, but today we will focus on just one file: /proc/[PID]/maps.</p>
<p>/proc/[PID]/maps displays a chart of the mapped memory of a process. When we say mapped memory, we mean a virtual memory segment that has a one to one correspondence with a file. This mapping enables an application to modify and access files by reading and writing directly to memory. This means that when a program accesses a file, this will end up being recorded in its /proc/[PID]/maps file.</p>
<p>/proc/[PID]/maps also shows us what permissions the process has for each segment. This can help us determine which files the process edited and which files it has read.</p>
<p>Here is how a short segment of a normal /proc/PID/maps file looks:</p>
<pre><code>7f9cefbf7000-7f9cefbf8000 r--p 00000000 103:03 1589169            /usr/lib/libXcomposite.so.1.0.0
7f9cefbf8000-7f9cefbf9000 r-xp 00001000 103:03 1589169            /usr/lib/libXcomposite.so.1.0.0
7f9cefbf9000-7f9cefbfa000 r--p 00002000 103:03 1589169            /usr/lib/libXcomposite.so.1.0.0
7f9cefbfa000-7f9cefbfb000 r--p 00002000 103:03 1589169            /usr/lib/libXcomposite.so.1.0.0
7f9cefbfb000-7f9cefbfc000 rw-p 00003000 103:03 1589169            /usr/lib/libXcomposite.so.1.0.0
7f9cefbfc000-7f9cefc08000 r--p 00000000 103:03 1579223            /usr/lib/libxcb.so.1.1.0
7f9cefc08000-7f9cefc1b000 r-xp 0000c000 103:03 1579223            /usr/lib/libxcb.so.1.1.0
7f9cefc1b000-7f9cefc24000 r--p 0001f000 103:03 1579223            /usr/lib/libxcb.so.1.1.0
7f9cefc24000-7f9cefc25000 r--p 00027000 103:03 1579223            /usr/lib/libxcb.so.1.1.0
7f9cefc25000-7f9cefc26000 rw-p 00028000 103:03 1579223            /usr/lib/libxcb.so.1.1.0
7f9cefc26000-7f9cefc27000 r--p 00000000 103:03 1577111            /usr/lib/libX11-xcb.so.1.0.0
7f9cefc27000-7f9cefc28000 r-xp 00001000 103:03 1577111            /usr/lib/libX11-xcb.so.1.0.0
7f9cefc28000-7f9cefc29000 r--p 00002000 103:03 1577111            /usr/lib/libX11-xcb.so.1.0.0
7f9cefc29000-7f9cefc2a000 r--p 00002000 103:03 1577111            /usr/lib/libX11-xcb.so.1.0.0
7f9cefc2a000-7f9cefc2b000 rw-p 00003000 103:03 1577111            /usr/lib/libX11-xcb.so.1.0.0
7f9cefc2b000-7f9cefc47000 r--p 00000000 103:03 1584005            /usr/lib/libX11.so.6.3.0
7f9cefc47000-7f9cefcd1000 r-xp 0001c000 103:03 1584005            /usr/lib/libX11.so.6.3.0</code></pre>
<p> Each row in the file records a single memory segment in the contiguous virtual memory address space allocated to the process. </p>
<ul><li><strong>Address </strong>– The first column shows the starting and ending address of the segment.</li><li><strong>Permissions</strong> – This column shows which permissions the process has for the segment. <em><strong>r/w/x</strong></em> are the usual read/write/execute, while the last letter is <strong>s</strong> or <strong>p</strong>, meaning shared or private, respectively.</li><li><strong>Offset</strong> – This is the offset from the beginning of the file, in order to be able to calculate the starting address of the mapped data. Sometimes, a segment isn’t mapped from a file (in which case the path column will have an identifier for the nature of the segment, as explained below), in which case the offset is simply left as 0.</li><li><strong>Device</strong> – When the segment was mapped from a file, the hex number of the device where the file is stored is displayed in this column.</li><li><strong>Inode (Index Node)</strong> – If the segment came from a file, this is the <a href="https://linuxhandbook.com/inode-linux/">inode number</a> of the file.</li><li><strong>Path</strong> – This is the path for the file, if there is one. This can be [heap], [stack] or <a href="https://en.wikipedia.org/wiki/VDSO">[vsdo]</a> if the segment is the eponymous structure.</li></ul>
<p><strong>Our Humble Script:</strong></p>
<p>In offending android applications, dynamic loading of code is usually done from the home directory of the application, so files loaded to memory from that dictionary (or other common locations) ought to appear in the maps file. To automate the task of checking that file, we constructed a very simple script that uses regex to search for the string ‘/data/data’ in the maps file of a given PID in the connected device and returns the lines that match. /data/data is of course the apps home directory where files and data are stored. It is the only location from which an app can load DEX files.<br></p>
<figure><a href="https://lh4.googleusercontent.com/K7pe0inKiCFgfFFQvvBImNwu80XP9FKk8CkUvK_B0yPAWsf_Jl8bcHD-4IQsRCfnKqbwf-Fb8_9WyqUIzdsMoQw2fHc1ABI3w086islkX_XT9FY6hmGc2S6DIreydfanYgfxgcpu"><img src="https://lh4.googleusercontent.com/K7pe0inKiCFgfFFQvvBImNwu80XP9FKk8CkUvK_B0yPAWsf_Jl8bcHD-4IQsRCfnKqbwf-Fb8_9WyqUIzdsMoQw2fHc1ABI3w086islkX_XT9FY6hmGc2S6DIreydfanYgfxgcpu" alt="our dynamic loading script" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></a></figure>
<p>Interacting with ADB through Python was sometimes a challenge, as doing so using the shell can be awkward, but we found a useful set of tools called <a href="http://docs.pwntools.com/en/latest/">pwntools</a> that provide exactly that functionality. They offer a vast set of functionalities designed to help with hacking and prototyping. Definitely check it out. </p>
<p>You can see the full script we use at this <a href="https://gist.github.com/SayferIO/d697594ef542ca1172b253dd67087128">Github gist</a>.</p>
</div>
</div></div>]]>
            </description>
            <link>https://sayfer.io/blog/dynamic-loading-in-android-applications-with-proc-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987285</guid>
            <pubDate>Wed, 04 Nov 2020 08:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Google Cloud Functions]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24987197">thread link</a>) | @adrianancona
<br/>
November 4, 2020 | https://ncona.com/2020/11/introduction-to-google-cloud-functions/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/11/introduction-to-google-cloud-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Cloud Functions are Google’s offering for serverless architecture (similar to AWS lambdas).</p>

<h2 id="what-is-serverless">What is serverless?</h2>

<p>Before we look into how to use Cloud Functions, we should understand some things about it.</p>

<p>Code needs servers to run, so <code>serverless</code> doesn’t mean there are no servers, it means that we don’t need to manage those servers ourselves.</p>

<p>In a usual server based architecture, we might create a service and deploy it to a machine. This service will be running in the machine all the time waiting for requests. This has the disadvantage that even if there are no requests, the machine would need to be up, and incurring cost.</p>

<p>On the other hand, if we use Cloud Functions, we write a service and register it with Google. Google will then listen to the endpoint this service cares about and will only start it when there are requests. If it detects that there haven’t been requests for some time, it will stop the service again.</p>

<!--more-->

<p>While Google Compute Engine instances are billed by time, Cloud Functions are billed by execution time. If a Cloud Function is not being executed, then it is not being billed. This sounds very attractive, but there are draw backs, namely:</p>

<ul>
  <li>Running a Compute Engine instance for a full month is most of the time cheaper than having a Cloud Function executing for one month straight. This means that if we need a service to be always doing work, it’s better to get a whole machine for it.</li>
  <li>Cloud Functions need to warm up. If a Cloud Function hasn’t been used for a while, Google will stop the server that was running it. Next time we get a new request, a new server needs to be started, which takes some time. This will make this first request take long (This time varies a lot, but usually less than 4 seconds)</li>
</ul>

<p>For these reasons, serverless shouldn’t be used in all scenarios.</p>

<h2 id="creating-a-cloud-function">Creating a Cloud Function</h2>

<p>To make it easy to work on our Cloud Function, we need a way to run the function from our development machine.</p>

<p>Let’s start by creating a module:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>mkdir test-functions
cd test-functions
go mod init test.com/functions
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Now, we can create a file for our function:</p>



<p>With this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>package</span> <span>functions</span>

<span>import</span> <span>(</span>
	<span>"net/http"</span>
	<span>"fmt"</span>
<span>)</span>

<span>func</span> <span>DoYouLikeTacos</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Of course I like tacos!</span><span>\n</span><span>"</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To be able to test our functions from our development machine, we need to create a server. Let’s create a file for it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>mkdir cmd
touch cmd/main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And add this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
  <span>"log"</span>
  <span>"context"</span>
  <span>"github.com/GoogleCloudPlatform/functions-framework-go/funcframework"</span>
  <span>"test.com/functions"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
  <span>ctx</span> <span>:=</span> <span>context</span><span>.</span><span>Background</span><span>()</span>

  <span>// Our function will be executed when a request to /do-you-like-tacos is received</span>
  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>RegisterHTTPFunctionContext</span><span>(</span>
      <span>ctx</span><span>,</span> <span>"/do-you-like-tacos"</span><span>,</span> <span>functions</span><span>.</span><span>DoYouLikeTacos</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.RegisterHTTPFunctionContext: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>

  <span>// The server will run on port 8080</span>
  <span>port</span> <span>:=</span> <span>"8080"</span>
  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>Start</span><span>(</span><span>port</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.Start: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>To run the server:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd cmd
go run main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Once the server is running, we can use curl to test it:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl localhost:8080/do-you-like-tacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The output should be:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>Of course I like tacos!
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This example is very simple, but we can have our fucntion do whatever we want.</p>

<p>We can also add more functions by adding more files and updating our <code>main.go</code> server. Let’s create another function just to show it.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd ..
touch cerveza.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>With this content:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>package</span> <span>functions</span>

<span>import</span> <span>(</span>
	<span>"net/http"</span>
	<span>"fmt"</span>
<span>)</span>

<span>func</span> <span>Thirsty</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Cerveza, por favor</span><span>\n</span><span>"</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And add this to <code>cmd/main.go</code>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>  <span>if</span> <span>err</span> <span>:=</span> <span>funcframework</span><span>.</span><span>RegisterHTTPFunctionContext</span><span>(</span>
      <span>ctx</span><span>,</span> <span>"/thirsty"</span><span>,</span> <span>functions</span><span>.</span><span>Thirsty</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
    <span>log</span><span>.</span><span>Fatalf</span><span>(</span><span>"funcframework.RegisterHTTPFunctionContext: %v</span><span>\n</span><span>"</span><span>,</span> <span>err</span><span>)</span>
  <span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Run the server:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>cd cmd
go run main.go
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And hit the new url:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl localhost:8080/thirsty
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="deploying-to-google-cloud">Deploying to Google Cloud</h2>

<p>Once we have our functions ready, we want to make them available to the public by deploying them to Google Cloud.</p>

<p>From the root of our project we can use this command:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gcloud functions deploy DoYouLikeTacos \
    --runtime go113 --trigger-http --allow-unauthenticated
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This will spit out a bunch of information. The most important part is the URL:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>httpsTrigger:
  url: https://us-central1-proj-1234567.cloudfunctions.net/DoYouLikeTacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can curl this endpoint, the same way we did for our local endpoint:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>curl https://us-central1-proj-1234567.cloudfunctions.net/DoYouLikeTacos
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Let’s take a closer look to the command we used to deploy our function:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>gcloud functions deploy DoYouLikeTacos \
    --runtime go113 --trigger-http --allow-unauthenticated
</pre></td></tr></tbody></table></code></pre></div></div>

<ul>
  <li><code>DoYouLikeTacos</code> is the name of the function we are deploying. The tool will search the package for a function with that name.</li>
  <li><code>--runtime go113</code> tells google to use Golang 1.13. We can see the available runtimes in the help (<code>gcloud functions deploy --help</code>)</li>
  <li><code>--trigger-http</code> means that an http endpoint will be assigned to the function</li>
  <li><code>--allow-unauthenticated</code> means that the function will be available for everybody without authentication. Note that the function code itself could expect some kind of authentication independently of this flag</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>This was a quick introduction to Google Cloud Functions. We learned how to create a function, test it locally and deploy it to Google Cloud.</p>

<p>Complete applications can be built using Cloud Functions, so I’ll explore a little more in another article.</p>

  </div></div>]]>
            </description>
            <link>https://ncona.com/2020/11/introduction-to-google-cloud-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24987197</guid>
            <pubDate>Wed, 04 Nov 2020 08:04:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[School Is Broken]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24986983">thread link</a>) | @simonpurdon10
<br/>
November 3, 2020 | https://www.simonblogs.com/thoughts/school-is-broken | <a href="https://web.archive.org/web/*/https://www.simonblogs.com/thoughts/school-is-broken">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Our world is changing. Our problems are changing. It's time our education system did&nbsp;too. Here's my take on the reforms needed in education.</p><div><p>There is a storm brewing. And the rain clouds are hovering over the traditional school system. We’ve already seen the first droplets fall as a result of COVID-19, and it’s difficult to see a future where the downpour isn’t on the way.</p><p>The education system has been failing us for years. It is no secret that the outcome of the schooling process — “educated children” — is a complete mismatch with the outcome that this modern world requires. </p><p>We’re failing our children by subjecting them to this system, and we’re failing ourselves as humans by slowing down the overall development of our race, and everything we interact with. </p><h2>A Failed System</h2><p>To understand the education problem we’re now faced with, it’s important to understand the origins of education.</p><p>The formal education system (particularly in America) was born mainly from religion. Martin Luther was said to be the “godfather” of this. His justification was that in order for salvation to occur, people need to read the scriptures. He realized that in order for this to happen, people need to know how to read and write. This idea spread, and by the late 17th century, Germany was the leader in the development of formal education. However, the actual schooling was not handled by the state, but by the Lutheran Church.</p><blockquote>“In America, in the mid 17th century, Massachusetts became the first colony to mandate schooling, the clearly stated purpose of which was to turn children into good Puritans.” — Psychology Today</blockquote><p>As the idea of education spread, employer’s saw it as an opportunity to create educated workers for their companies. At the time, the ideal qualities of a worker were something along the lines of:</p><ul role="list"><li>Punctuality, </li><li>Obedience (take instructions),</li><li>Tolerance for long, tedious work hours,</li><li>Minimal ability to read and write.</li></ul><p>Aside from the last point, which has been significantly improve on, it’s hard to look at our formal education system (mostly) and see how it has adapted to the current world we live in, and our present day challenges.</p><h2>A Growing Trend</h2><p>The number of children being homeschooled in the UK has more than doubled in the last 5 years, according to <a href="https://www.forbes.com/sites/nickmorrison/2020/03/06/fears-children-going-off-grid-as-homeschooling-up-by-700/#27cafb9554b4" target="_blank">Forbes</a>. In some parts of the country, that number is as high as <a href="https://www.forbes.com/sites/nickmorrison/2020/03/06/fears-children-going-off-grid-as-homeschooling-up-by-700/#27cafb9554b4" target="_blank">700%</a>. This is only registered home-schoolers, which is not a requirement.</p><p>In the US, the current number of home-schooled students represents roughly 3.4% of the schooled population, or 2.3 million children. It’s expected that as a second generation of home-schoolers chooses the same for their kids, this number will expand to <a href="https://blog.steppingblocks.com/homeschooling-curriculum-and-programs-are-booming#:~:text=Homeschooling%20is%20catching%20on.,over%20the%20next%20few%20years." target="_blank">10 million by 2030.</a></p><p>Clearly, home schooling is finding popularity and traction outside of it’s traditional conservative and religious roots.</p><h2>A Changing World</h2><p>Bare with me for a second while I try illustrate a point with a personal anecdote. I left high-school 10 years ago. Throughout my schooling years, I found school particularly boring. In junior school, I remember faking stomach aches, headaches, putting my forehead above the toaster to mimic a temperature — every trick in the book to get out of school. I <em>hated </em>the monotony of it. Pretty soon I got shipped off to boarding school. </p><p>10 Years later, and I am staying with my parents during lockdown, and we became friends with our next-door neighbors, who had a daughter in Grade 11 (17 years old). She asked me for some help with her school work. </p><p>To my shock, the curriculum was all but identical to what I learned in high school. The only difference was that she had a laptop with her, and that’s how she got her notes from the teachers — no more note-packs. </p><h3>For perspective, 10 years ago…</h3><ul role="list"><li>There was no DoorDash (Founded 2013);</li><li>Amazon stock price was $139, it’s now $3162;</li></ul><figure><p><img src="https://uploads-ssl.webflow.com/5dc02eb64f3e3528360999cb/5fa1700d4b1252d4e2a1ffc8_1*29zfMBVl365WGrYKOF_AEg.png" alt=""></p><figcaption>Source: Google.com</figcaption></figure><ul role="list"><li>Scientists <a href="https://spaceplace.nasa.gov/gravitational-waves/en/#:~:text=In%202015%2C%20scientists%20detected%20gravitational,happened%201.3%20billion%20years%20ago." target="_blank">discovered gravitational waves exist</a> for the first time, when they observed two black holes colliding 1.5 billion years ago.</li><li>The only Tesla that was around was the original Roadster. They’ve since launched three new cars, with other big projects on the go. They’ve also got over 20 000 charging stations around the US alone. </li></ul><figure><p><img src="https://uploads-ssl.webflow.com/5dc02eb64f3e3528360999cb/5fa1700f8aa6b106087e9fa0_0*33wQbLyUAzmAzGck.jpeg" alt=""></p><figcaption>Source: <a href="https://www.roadandtrack.com/new-cars/road-tests/reviews/a3524/2010-tesla-roadster-sport/" target="_blank">Roadandtrack.com</a></figcaption></figure><ul role="list"><li>Instagram was still independently owned.</li><li>WeWork was only just being founded.</li><li>There was no such thing as Robinhood.</li><li>Over 6 million hectares of the Amazon rainforest have been lost.</li></ul><figure><p><img src="https://uploads-ssl.webflow.com/5dc02eb64f3e3528360999cb/5fa1700dba31af50c1e6c2f6_0*PolGe2XIg1oj-f7R.gif" alt=""></p><figcaption>Source: <a href="https://visibleearth.nasa.gov/images/145888/making-sense-of-amazon-deforestation-patterns/145888f" target="_blank">NASA Visible Earth</a></figcaption></figure><ul role="list"><li>Donald Trump was only <a href="https://www.theguardian.com/world/blog/2010/oct/06/donald-trump-considers-bid-president" target="_blank">considering running for president</a>.</li><li>The global mean (average) sea level has risen over <a href="https://www.wri.org/blog/2019/12/6-ways-climate-changed-over-past-decade#:~:text=Global%20mean%20sea%20level%20rise,overall%20in%20the%20past%20decade." target="_blank">50mm (between 2010 and 2018)</a>.</li></ul><figure><p><img src="https://uploads-ssl.webflow.com/5dc02eb64f3e3528360999cb/5fa1700e832c3b00f16769a6_1*G6x_mz0dNi2lzvujSX9HhQ.png" alt=""></p><figcaption>Source: NASA</figcaption></figure><ul role="list"><li>The rate of September (September is the month in which the amount of ice is at it’s lowest in the Arctic, and so the standard measuring point) sea ice decline has been <a href="https://www.wri.org/blog/2019/12/6-ways-climate-changed-over-past-decade#:~:text=Global%20mean%20sea%20level%20rise,overall%20in%20the%20past%20decade." target="_blank">13% per decade</a> compared to the 1981 to 2010 average.</li></ul><figure><p><img src="https://uploads-ssl.webflow.com/5dc02eb64f3e3528360999cb/5fa1700e168bff65713939bb_1*SZY2icDG5vXk9q9zr3pLcQ.png" alt=""></p><figcaption>Source: NASA</figcaption></figure><p>All of this has happened, but our education system has barely changed it’s curriculum.</p><p>This, despite the fact that our world is rapidly changing, and the challenges we face are vastly different from those 10, 20 and 30 years ago. </p><h2>What the Alternatives Look Like</h2><p>The traditional schooling model is one dimensional. No matter the input (type of child), you get battered with information that is mostly not relevant anymore, through outdated teaching methods, and then are expected to come out a certain way (pass exams).</p><p>We’ve now reached a point in educational research that we know that all people learn differently. </p><figure><p><img src="https://uploads-ssl.webflow.com/5dc02eb64f3e3528360999cb/5fa1700e09a79a0d525bd4fe_0*YsGK_hHeWUuWkxLs.png" alt=""></p><figcaption>Source:<a href="https://digitalhumans.com/blog/the-four-types-of-learning-how-digital-humans-cater-to-all-customers/" target="_blank"> Uneeq.com</a></figcaption></figure><p>The question then becomes: <em>So, what are the alternatives?</em></p><h3>Montessori</h3><p>Founded on the teaching principles of Dr Maria Montessori — the first female physician in Italy — the premise is that children are naturally inquisitive. They are born with “absorbent” minds, and will embark on self-directed learning if given the opportunity to do so.</p><p>Montessori’s are primarily at the pre-school and primary school level, and their ‘classrooms’ are prepared environments which allow children to seek out opportunities to learn on their own. The teachers are there as facilitators and observers. The children are allowed to concentrate for long periods of time on certain tasks, rather than being interrupted by a teacher-driven model of learning with class changes and interruptions— a foundation of the Montessori way of teaching. </p><p>The “Montessori method” is used in over 5000 schools in the US today. <a href="https://www.researchgate.net/publication/324261991_Academic_Achievement_Outcomes_A_Comparison_of_Montessori_and_Non-Montessori_Public_Elementary_School_Students" target="_blank">A 2006 study</a> where a public Montessori school was compared to traditional public schools yielded results that the Montessori students yielded better academic results overall. Google co-founders, Sergey Brin and Larry Paige are both examples of the positive results that the Montessori method can yield.</p><h3>The Steiner/Waldorf Method</h3><p>Rudolf Steiner was the mind behind the “Steiner/Waldorf” method which emphasizes the importance of the development of the “whole child”. Steiner theorized that children developed in 7 year periods, and their education should be structure as such:</p><ul role="list"><li>The first 7 years of a child’s life are based around “imitative and sensory-based” learning, and should be devoted mainly to a child’s non-cognitive abilities.</li><li>Ages 7 to 14, creativity and imagination are emphasized.</li><li>From 14 onwards, students are ready for a more structure learning environment which “stresses social responsibility”.</li></ul><p>Steiner founded his first Waldorf school in Germany in 1919. The original curriculum was for 12 years, with an emphasis on preparation for “living”. Within 10 years, Steiner’s Waldorf school was the largest private school in Germany. When World War II hit, Waldorf teachers fled to neighboring countries, and the method spread.</p><p>There are however some criticisms of the Waldorf method, which say that it borders on being too religious. </p><h3>Reggio Emilia</h3><p>Sharing a lot of the same principles as the Montessori Method, Reggio Emilia also has its roots in a post World War II world. The method is primarily aimed at children aged 3 to 6. </p><p>The first Reggio Emilia preschool opened in 1945, and became popular in the US in 1991.</p><p>The Reggio Emilia way of teaching has the following features:</p><ul role="list"><li>Parents take an active role in education;</li><li>Schools are designed to look and feel like “home”</li><li>Curriculums are flexible;</li><li>Growth on the student’s terms is paramount.</li><li>Art is a big component, with almost all RE schools having a dedicated art teacher who is their creative ‘guide’.</li></ul><blockquote>“Reggio Emilia is about full-blown human potential and how you support that in both intellectual and creative terms.”- Louis Boyd Cadwell (Teacher at RE school’s in Italy during the 90's)</blockquote><h3>Sudbury </h3><p>Sudbury schools are unique in their emphasis of individuality and democracy. They take this to the next level. Sudbury students have complete control over what they do, and what they learn at school. All students and teachers vote on almost everything relating to the schooling process:</p><ul role="list"><li>Budget,</li><li>Curriculum, </li><li>Teacher hiring/firing.</li></ul><p>The premise is that students are capable of making sound collective decisions. In the event that they don’t, they learn through the consequences of their mistakes. </p><p>Sudbury Schools rely on the premise that students are inherently motivated to learn. Their reasoning is often backed by the idea that an infant child learns to walk, rather than spending it’s whole life lying down in it’s crib — which is a viable, and easier, option.</p><h2>Predictions for the Future</h2><p>The issue with all of these alternative learning methods is that they don’t align with the way companies are viewing graduates. Traditionally, you would have to go through school in order to get a certain qualification. That qualification would give you a ‘stamp’ which a company could look at and gauge how well you may be able to do the job. </p><p>That is slowly changing. Alternative education institutions like Lambda School are changing the way companies are hiring. It’s no longer necessary for front-end developers to have a secondary education at all. If you’ve got the skills to do the job — it doesn’t matter to them how you got them. </p><p>The same applies in the marketing world. If you are a creative thinker that can create designs and think laterally where no one else can — your education doesn’t …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.simonblogs.com/thoughts/school-is-broken">https://www.simonblogs.com/thoughts/school-is-broken</a></em></p>]]>
            </description>
            <link>https://www.simonblogs.com/thoughts/school-is-broken</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986983</guid>
            <pubDate>Wed, 04 Nov 2020 07:13:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Drive Traffic to Your Website – Zero to Ranking on Google]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24986976">thread link</a>) | @moeminm
<br/>
November 3, 2020 | https://blog.moeminmamdouh.com/how-to-drive-traffic-to-your-website-side-project-edition | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/how-to-drive-traffic-to-your-website-side-project-edition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>You've been working on your side project for nearly 6 months now, launch date's today. You're super excited to show the world what you've been working on, you hit the launch button and...no traffic or users at all.</p>


<p>It's a common problem. Us IndieHackers <em>know</em> where to advertise our products, but not all of us know <em>how</em> to post our products. I've split up this blog post to two <strong>categories</strong>: </p>
<p> 👉 How to get a huge traffic boost for a short period of time with little to no work.
 👉 How to get steady traffic by using long-term strategies. </p>

<p>This is a great way to not only gain traffic, but also to validate your idea (if you haven't already). There are hundreds of directories all over the internet that you can post your side project to and in return get huge traffic boosts. Let me go over where to post your side projects, the pros and cons of posting on said websites, and <em>how</em> to post on said websites.</p>
<h3 id="where-to-post-your-side-projects">Where To Post Your Side Projects</h3>
<ul>
<li><a target="_blank" href="https://www.reddit.com/">Reddit</a></li>
<li><a target="_blank" href="https://news.ycombinator.com/">HackerNews</a></li>
<li><a target="_blank" href="https://www.producthunt.com/">ProductHunt</a></li>
<li><a target="_blank" href="https://betalist.com/">Betalist</a></li>
<li><a target="_blank" href="https://betapage.co/">Betapage</a></li>
<li><a target="_blank" href="https://www.sideprojectors.com/">Sideprojectors</a>, yes, you can showcase your projects on Sideprojectors.</li>
<li><a target="_blank" href="https://launched.io/SubmitStartup">Launched</a></li>
<li><a target="_blank" href="https://www.saashub.com/">SaaSHub</a></li>
</ul>
<p>There are hundreds more websites you can submit your side projects to, but let's keep it simple for the sake of keeping this blog post short and sweet.</p>
<h3 id="pros-and-cons-of-posting-on-directories">Pros and Cons of Posting On Directories</h3>
<p><strong>Pros:</strong></p>
<ul>
<li>Free huge traffic boost and all that comes with it. Be it sales, newsletter subscriptions, etc.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Short term traffic. You could very well succeed on Reddit, HackerNews, and ProductHunt and you'd be set for a good week or so, but it'll be drought season afterwards.</li>
<li>Wrong audience. You're not necessarily targeting the 'optimal' audience by posting your side project on all these websites. </li>
</ul>
<p>Should you do it? Short answer, yes. Long answer, yes. Despite the low quality of traffic, you'll still be seeing a good portion of your target audience on these platforms. You're not really paying to submit on these platforms, so do it, if it works, good on you. If not, you should have a backup plan (second category in this blog post). </p>
<h3 id="how-to-post-on-these-platforms">How To Post On These Platforms</h3>
<p>I've been waiting for this section. Let's assume you're releasing a website performance monitoring tool called Monitr. Things you should not do:</p>
<p>❌ Do not post your URL on all platforms meaninglessly. </p>
<p>Yup, that's it. So how do you share your product? Well, on websites such as ProductHunt, BetaPage and so on, there really isn't much you can do other than post the URL, but on community-based websites such as IndieHackers, Reddit, and HackerNews, there's so much room for creativity.</p>
<p>i.e. A post about website performance and its role in improving organic traffic with a link at the end of the article. More often than not, well thought out articles will rise to the top and your link will gain exposure. If not, you've added value to the community and you aren't really spamming your link. The mods will not be on your back.</p>
<p>Repurpose the content, you've written the blog post, will you go post that 1000+ article on Facebook/Twitter? No, try to make a simple graphic that will hook people and add your website's link within that graphic and the first comment. People on Facebook generally have low attention spans, so if you don't really grab their attention in the first few seconds they see your post, they're gone. </p>
<p>The point of this sub-section is to tell you to <em>learn</em> the platform before mindlessly spamming your links. </p>

<p>My #1 lesson learned from my side projects which you can read all about <a target="_blank" href="https://blog.moeminmamdouh.com/how-i-failed-2-side-projects-in-under-a-year-and-lessons-learned">here</a>. What do I mean by long-term strategies? SEO. </p>
<p>SEO is a waiting game. You post your content, and you wait to rank on Google, but you don't just go posting about <em>anything</em>, you need to be smart about what you're writing about.</p>
<h3 id="pick-high-volume-low-competition-keywords">Pick high volume, low competition keywords.</h3>
<p>For example, my last article <a target="_blank" href="https://blog.moeminmamdouh.com/20-free-design-resources-for-developers">20+ Free Design Resources for Developers</a> targeted the keywords 'free design resources'. According to Google Keywords, it receives 1k-10k search queries per month and has low competition, and well, it was a great pick. I'm currently the 10th result on Google for that keyword.</p>
<h3 id="write-valuable-posts">Write valuable posts</h3>
<p>If you provide value, you will get noticed. I went ahead and posted my free design resources article on IndieHackers, <a href="http://dev.to/" target="_blank">dev.to</a>, and HN just for the fun of it. I get around ~250 visitors from posting on there. Great, I head to bed, wake up and check my notifications only to find this:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604472876194/lKGEdkJFO.png?auto=format&amp;q=60" alt="Mask Group 1.png"></p>
<p>So what's so surprising? Well, the traffic sources. I only posted on 3 websites. But I open up the acquisition tab and to my surprise, my 2nd most traffic source is from a website that featured my article that I didn't even know about.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604473073706/DsH_DxO5S.png?auto=format&amp;q=60" alt="Mask Group 4.png"></p>
<p><strong>174 visitors came from traffic sources I did not submit my article to.</strong> The article was picked because it received attention on the 3 websites I posted to. Here are the stats for the article on IndieHackers and <a href="http://dev.to/" target="_blank">dev.to</a></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604473233181/1Q82l3LSp.png?auto=format&amp;q=60" alt="Mask Group 1.png"></p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1604473303797/YWjWoKvz2.png?auto=format&amp;q=60" alt="Mask Group 2.png"></p>
<p>So I post the article hoping for some short term traffic, but what I didn't know is that it brought longer short term traffic. But wait, wasn't this a short term strategy? Yes, but also no.</p>
<p>You're also building backlinks this way. When a high domain authory website such as daily.dev features your website and links back to your website, that is <strong>great</strong> news.</p>
<h3 id="setup-search-console-and-keep-track-of-your-organic-traffic">Setup Search Console and Keep Track Of Your Organic Traffic</h3>
<p>Search Console takes longer times to crawl new websites so you may find the results to be a little off at the beginning, that's fine. Set it up anyway, it's a very helpful tool. You get to see what keywords you're gaining impressions for, how many clicks you're getting, and what keywords are getting those clicks.</p>
<p>SEO is a long and tiring game, but once you start seeing results it's a great feeling. You no longer have to worry about constantly trying to find sources of traffic, they just roll in. Let me know <strong>your</strong> traffic game in the comments below and I hope you enjoyed this article!</p>
</div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/how-to-drive-traffic-to-your-website-side-project-edition</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986976</guid>
            <pubDate>Wed, 04 Nov 2020 07:12:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020 Haskell Is Ready for Prime Time]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24986803">thread link</a>) | @_query
<br/>
November 3, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986803</guid>
            <pubDate>Wed, 04 Nov 2020 06:30:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Society as a Concept Network]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24986677">thread link</a>) | @rajlego
<br/>
November 3, 2020 | https://supermemo.guru/wiki/Society_as_a_concept_network | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Society_as_a_concept_network">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This article by Dr <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> is part of <a href="https://supermemo.guru/wiki/SuperMemo_Guru" title="SuperMemo Guru">SuperMemo Guru</a> series on memory, learning, creativity, and problem solving.</small>
</p>


<h2><span id="Perfect_brain">Perfect brain</span></h2>
<p>The brain is a perfect design for an intelligent machine. That design can be extended to form a perfect society and to accelerate the progress towards super-intelligence, singularity, and perhaps even <a href="https://supermemo.guru/wiki/Intrinsically_valuable_state" title="Intrinsically valuable state">intrinsically valuable state</a>. Even though I believe that my vision of the future is optimistic and good, there is no need to bicker about its value. It seems it is just an inevitable course of things emerging as the law of intelligence. 
</p><p>My utopian words can probably be given a precise mathematical framework backed up by a proof. In the end, it might be true that the entire science of physics centers around the competitive forces of intelligence and entropy.
</p>
<h2><span id="Concept_network">Concept network</span></h2>
<p>A concept network is an improvement over the basic idea of artificial neural networks. It has the properties that are often overlooked by neural network researchers:
</p>
<ul><li> the network can grow dendrites in search of new patterns</li>
<li> the network can grow axons while seeking better dissemination of valuable information</li>
<li> the network can grow new neurons along learning demands around often used concepts</li>
<li> the network can delete neurons that are in disuse</li>
<li> network memories exhibit properties known from the <a href="https://supermemo.guru/wiki/Two_component_model_of_memory" title="Two component model of memory">two component model of memory</a></li>
<li> network memories are subject to the <a href="https://supermemo.guru/wiki/Spacing_effect" title="Spacing effect">spacing effect</a> that determines <a href="https://supermemo.guru/wiki/Stabilization" title="Stabilization">stabilization</a> (see: <a href="https://supermemo.guru/wiki/Mechanism_of_the_spacing_effect" title="Mechanism of the spacing effect">Mechanism of the spacing effect</a>)</li>
<li> network self-organizes in the process of <a href="https://supermemo.guru/wiki/Conceptualization" title="Conceptualization">conceptualization</a>, i.e. architectural changes that lead to the development of an effective network of <a href="https://supermemo.guru/wiki/Concept" title="Concept">concepts</a></li></ul>
<p>Behavior of a network of concepts cannot realistically be predicted by the behavior of individual concepts. Individual concepts usually do not have access to information about the performance of the entire network.
</p>
<h2><span id="Society">Society</span></h2>
<p>In a society structured around the idea of a <a href="https://supermemo.guru/wiki/Concept_network" title="Concept network">concept network</a>, a new layer of conceptual organization can be formed in which humans, computers, intelligent agents, databases, executive agents, organizations, corporations, etc. can form an equivalent of advanced concepts. Such a network would provide a seamless co-existence of <a href="https://supermemo.guru/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> and human <a href="https://supermemo.guru/wiki/Intelligence" title="Intelligence">intelligence</a> in a structure exhibiting super-intelligence that would quickly progress towards singularity. Mankind has already formed a de facto super-intelligent network. Its problem solving capacity will keep growing exponentially.
</p><p>Currently, societies are organized in ways that lead to a wasteful competition for resources and a conflict of interest. Instead, we could take inspiration from the brain and satisfy core ideas of main political philosophies. If we took all human resources and put them into a form of circulation system, we could drew upon those resources in proportion to the needs, and we might satisfy an old communist maxim: "to everyone according to his needs". A Nobel Prize winner could feed on the resources in proportion to inspiration generated by his brain for humanity. An anarchist or a libertarian would be happy with individual freedoms of individual neurons and concepts. Nobody tells an individual neuron what to do. Neuronal autonomy is perfect. A capitalist who loves market economy would love the efficiency of the neural market of ideas. A socialist would like the fact that even the weakest neurons could find their optimum roles and the access to the bloodstream of resources. There is even some room for religions. Super-intelligence would inevitably drive towards the concept of <a href="https://supermemo.guru/wiki/Intrinsically_valuable_state" title="Intrinsically valuable state">intrinsically valuable state</a>. Some of the religious dogma would probably need a degree of adaptation to the new reality, but I see intelligence as a source of existential answers that would fill the inevitable void.
</p>
<h2><span id="Technology">Technology</span></h2>
<p>There is no need for a revolution or a major re-design. As much as <a href="https://supermemo.guru/wiki/Tim_Berners-Lee" title="Tim Berners-Lee">Tim Berners-Lee</a> simple protocols could start the web, we might develop protocols for societal concept network. One of the first steps would be to provide protocols for redistribution of resources. Strong concepts in the network should never need to waste time on a struggle for resources. I advocate for <a href="https://supermemo.guru/wiki/Basic_income" title="Basic income">basic income</a>, which is a stopgap measure. However, blockchain micropayments are the future. An inventor cannot waste time seeking patents, angel investors, business partners, or sponsors. Too much young talent is wasted on a job search, in which a great brain lands in a secondary tier of somebody's else's sub-par effort. A good brain should be able to thrive in a concept network from the get-go without wasting a blink on existential issues.
</p>
<h2><span id="All_has_been">All has been</span></h2>
<p>The above text is just a compilation of old ideas of greater minds such as Ted Nelson, <a href="https://supermemo.guru/wiki/Tim_Berners-Lee" title="Tim Berners-Lee">Tim Berners-Lee</a>, Jeff Hawkins and many others. There are dozens of minor efforts and models that all slowly drive in that direction (did you hear of <a href="https://en.wikipedia.org/wiki/Complex_adaptive_system">CASs</a>?, or <a href="https://en.wikipedia.org/wiki/Decentralized_autonomous_organization">DAOs</a>? or <a href="https://en.wikipedia.org/wiki/Teal_organisation">Teal organizations</a>?). Most of all, a <a href="https://supermemo.guru/wiki/Concept_network" title="Concept network">concept network</a> is a self-organizing intelligent structure. So is humanity. Things are in progress already. However, it helps to see the progression using a convenient model. The brain seems like a good metaphor.
</p>
<hr>
<p><span>For more texts on memory, learning, sleep, creativity, and problem solving, see <b><a href="https://supermemo.guru/wiki/SuperMemo_Guru" title="SuperMemo Guru">Super Memory Guru</a></b></span></p>

<!-- 
NewPP limit report
Cached time: 20201105201720
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.031 seconds
Real time usage: 0.040 seconds
Preprocessor visited node count: 25/1000000
Preprocessor generated node count: 46/1000000
Post‐expand include size: 311/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   12.663      1 - -total
 49.70%    6.293      1 - ArticleGuru
 46.07%    5.834      1 - ArticleBrain
-->

<!-- Saved in parser cache with key supermem_kool_kids:pcache:idhash:1884-0!*!0!!en!*!* and timestamp 20201105201720 and revision id 23224
 -->
</div></div>]]>
            </description>
            <link>https://supermemo.guru/wiki/Society_as_a_concept_network</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986677</guid>
            <pubDate>Wed, 04 Nov 2020 05:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning my smartphone into a boring productivity tool]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24986647">thread link</a>) | @vaillancourtmax
<br/>
November 3, 2020 | https://maximevaillancourt.com/blog/turning-my-smartphone-into-a-boring-tool | <a href="https://web.archive.org/web/*/https://maximevaillancourt.com/blog/turning-my-smartphone-into-a-boring-tool">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p>👉 <em>Looking for actionables and screenshots? Scroll to the bottom of this post.</em></p>

<p>I opened my smartphone’s “screen time” app for the first time recently and was somewhat troubled to discover that on a particular day a few weeks ago:</p>
<ul>
  <li>I unlocked my phone 64 times;</li>
  <li>I used my phone for over 3 hours;</li>
  <li>I received 145 different notifications (!).</li>
</ul>

<p>My first thoughts upon seeing these numbers: how much of this time could I consider as “time well spent”? How much of it could I redirect towards healthier activities?</p>

<hr>

<p>Let’s open up an imaginary toolbox for a moment. Imagine a screwdriver.</p>

<p>A screwdriver is a tool in its purest form. It does not ask for anything, does not require maintenance, and doesn’t distract from the task at hand. It just sits there, patiently waiting to be picked up when needed.</p>

<p><strong>A tool does its job, then gets out of the way</strong>.</p>

<p>This is the kind of relationship I want with my smartphone. It should be tool, and nothing else. With that in mind, I set out to turn my smartphone into a tool again. This <a href="https://maximevaillancourt.com/blog/tech-is-not-an-end-part-1">“tool, not distraction” mentality is useful for all kinds of modern technology</a>, not just smartphones. Cal Newport’s “Digital Minimalism” covers this idea pretty well too (<a href="https://maximevaillancourt.com/bookshelf/digital-minimalism-cal-newport">view my reading notes</a>).</p>

<hr>

<p>Picking up my smartphone happens in one of two mental modes: mindfully, or mindlessly. There are no other possible modes of operation when picking up a smartphone.</p>

<p>Mindful use is the best case scenario. Ideally, every single time I’d pick up my smartphone, it would be to resolve a problem, and I’d put it down the second I’d be done. That’s entirely reasonable, though it’s not always what happens. What’s more, it’s not very realistic.</p>

<p>Let’s focus on improving the “mindless” part: I noticed that when I mindlessly pick up my phone, it’s either because a notification came in, or because I’m bored. Knowing this, I now have a few points of leverage I can use:</p>
<ul>
  <li><strong>I can reduce the number of incoming notifications</strong> (reducing the total number of potential unlocks I attempt on the device);</li>
  <li><strong>I can make it more difficult to mindlessly unlock the device</strong> (leading me to really consider if I want to use it);</li>
  <li><strong>I can make sure I spend quality time on the device</strong> once it’s unlocked (encouraging me to do something better than falling prey to distracting apps).</li>
</ul>

<p>To reduce incoming notifications:</p>

<ul>
  <li><strong>Disable notifications for most everything</strong>. I have notifications enabled for PagerDuty, phone calls, and video calls. Nothing else, not even instant messaging or email. If it’s important, I’ll go look for it myself.</li>
  <li><strong>Delete social media apps and mindfully using them on the laptop/desktop instead</strong>. I used to scroll through Twitter every day on my smartphone before. I now use it a few times a week on my laptop.</li>
</ul>

<p>To reduce the number of mindless unlocks:</p>

<ul>
  <li><strong>Hide notifications entirely from the lock screen</strong>. This is good from a privacy standpoint and a mindfulness standpoint, as it limits the information exposed to strangers while preventing your curiosity from taking over.</li>
  <li><strong>Disable biometric authentication</strong> such as face and/or fingerprint unlock and instead <strong>use a strong passphrase</strong>. It’s much less convenient, so it acts as a mindfulness check.</li>
</ul>

<p>To spend quality time on the device once it’s unlocked:</p>

<ul>
  <li><strong>Showcase useful apps on your home screen</strong>. For example, Duolingo, podcasts, Instapaper, Anki, Calendar, etc. You get the picture: not Facebook and Twitter.</li>
  <li><strong>Hide time-wasting apps</strong> from the home screen. Even better, delete them altogether! A first great step sis hiding them away in a folder of some sort.</li>
  <li><strong>Enable grayscale display mode</strong> to reduce the enticing effect of the apps icons’ bright colours.</li>
  <li><strong>Use an alternative launcher</strong> like <a href="https://jkuester.github.io/unlauncher/">Unlauncher</a>. You may even customize your launcher if you’re familiar with Java or Kotlin.</li>
</ul>

<p>All in all, the goal is to make it easier to use the device in a thoughtful, productive fashion than it is to use it for distracting purposes.</p>

<p>After these changes, screen time data for this week shows that on average I unlocked my device 11 times per day (~6x less than before), received 52 notifications per day (~3x less than before), and spent 70 minutes on the device per day (~3x less than before).  ✨</p>

<h3 id="screenshots">Screenshots</h3>

<div>
  <p><img alt="Lock screen on my Android smartphone, showing the current date and time" src="https://d33wubrfki0l68.cloudfront.net/21129c5d0da87bb1085edb1cb620c5cbd0481bc3/5e0f5/assets/lockscreen.jpg">
    Lock screen
  </p>
  <p><img alt="Home screen on my Android smartphone, showing the current time at the top as well as buttons for four apps: a podcasts app, a spaced repetition app, a language learning app, and a calendar app" src="https://d33wubrfki0l68.cloudfront.net/4c2c7916c0a7a1fbd9e4cc492f9d083ed68405ff/561ed/assets/homescreen.jpg">
    Home screen
  </p>
  <p><img alt="App draser on my Android smartphone, showing scrollable list of apps names in white text over black background" src="https://d33wubrfki0l68.cloudfront.net/2cda99cbc51945960f2b886cc6c6683af26a2499/36aa5/assets/app-drawer.jpg">
    App drawer
  </p>
</div>


  </article></div>]]>
            </description>
            <link>https://maximevaillancourt.com/blog/turning-my-smartphone-into-a-boring-tool</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986647</guid>
            <pubDate>Wed, 04 Nov 2020 05:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clean Code – Notes]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24986604">thread link</a>) | @wheresvic3
<br/>
November 3, 2020 | https://smalldata.tech/blog/2018/09/16/clean-code-notes | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2018/09/16/clean-code-notes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  The following is a list of notes taken on writing clean code, i.e. code that is maintainable and extensible.
</p>
<h5 id="names">Names</h5>
<p>
  Naming is the <i>hardest</i> and the most important part of writing clean code. Names should clearly express intent
  and the assumption here is that everyone involved in the codebase has the same cultural background which is not
  always the case in practice. Some general tips:
  </p><ul>
    <li>Classes should be Nouns, e.g. <code>User</code></li>
    <li>Methods should be verbs, e.g. <code>getById()</code>, <code>save()</code></li>
    <li>No need for prefixes such as <code>m_</code> or <code>str</code> for strongly typed languages</li>
    <li>Pick one word per concept, e.g. <code>fetch</code>, <code>retrieve</code> and <code>get</code> are
      semantically equal</li>
  </ul>

<h5 id="functions">Functions</h5>
<p>
  Functions or methods are the fundamental building blocks of programming. In fact, the internal operation of
  programs normally consists mostly of functions pushing data onto and popping data off the stack as they call each
  other. Sometimes memory needs to be allocated on the heap for data that must survive across function calls.
</p>
<p>
  When a function is called, a <strong>stack frame</strong> is created to support the function's execution. The stack
  frame contains the function's local variables and the arguments passed to the function by its caller. The frame
  also contains housekeeping information that allows the called function (the callee) to return to the caller safely.
  The exact contents and layout of the stack vary by processor architecture and function call convention.
</p>
<div>
  <p><a href="https://smalldata.tech/img/blog/call-stack-layout.svg">
      <img alt="An example of a call stack for the DrawLine function which is called by DrawSquare" src="https://smalldata.tech/img/blog/call-stack-layout.svg">
    </a>
  </p>
  
  <p>
    An example of a call stack for the <code>DrawLine</code> function which is called by <code>DrawSquare</code>.
  </p>
</div>
<p>
  Some general tips on writing functions:
  </p><ul>
    <li>Functions should be small and they should do 1 thing only:
      <ul>
        <li>Only have 1 level of indentation - highly nested functions should be refactored into sub-routines</li>
        <li>
          <strong>No side-effects!</strong>
          <pre>public int sum(int a, int b) {
    int result = a + b;
    resetGui(); // this is untestable and introduces a hidden dependency!
    return result;
}
</pre>
        </li>
      </ul>
    </li>
    <li>Do not return <code>null</code> - caller will need to always check cluttering p code, consider using <i>special
        case</i> return values</li>
    <li>Don't pass <code>null</code> as a parameter value either</li>
    <li>Prefer exceptions for error conditions except in cases were a <code>Nullable</code> or <code>Optional</code>
      type is available</li>
    <li>Should ideally return a value, especially for monadic functions as this allows function chaining</li>
    <li>Fewer arguments are better - the more the arguments, the more the complexity and test cases that need to be
      written</li>
  </ul>

<h5 id="oop">Object Oriented Programming</h5>
<p>
  An important but suble point to note in OOP is that objects hide their data behind abstractions and expose
  functions that operate on that data whereas data structures expose their data and have no meaningful functions.
  Good OOP requires knowing when to use objects and when to use data structures. Consider the following example:
  </p><pre>public class Point {
    public double x;
    public double y;
}

public interface Point {
    double getX();
    double getY();
    void setCartesian(double x, double y);
    double getR();
    double getTheta();
    void setPolar(double r, double theta);
}
</pre>
    <p>
      In the second <code>Point</code> definition the co-ordinate system being used by the implementation is not
      known and need not necessarily be cartesian nor polar!
    </p>
    <p>
      Tips on writing clean OO code:
      </p><ul>
        <li>Classes should be small and follow the Single Responsibility Principle (SRP)</li>
        <li>Classes should have high cohesion, i.e. operate on a small number of variables</li>
        <li>Avoid using boundary interfaces, e.g. instead of returning a <code>Map</code>, wrap it in a class (<code>Sensors</code>)
          to encapsulate the implementation</li>
        <li>Comments should only be used for clarification or amplification - avoid in general and let the code
          do the talking!</li>
        <li>Prefer exceptions to error codes - error codes have the habit of spilling out into the entire
          system</li>
        <li>Use unchecked exceptions to not break encapsulation</li>
      </ul>
    
    <p>
      Finally, procedural code makes it hard to add new data structures because all the functions must change. OO
      code makes it hard to add new functions because all the classes must change. Again, writing clean code
      requires insight as to when to use which style of programming.
    </p>
    <h5 id="tdd">Test Driven Development</h5>
    <p>
      Unit Tests should follow the F.I.R.S.T principle, i.e. they should be Fast, Independent of any external
      dependencies or manual setup, Repeatable, Self-validating (no manual checking verification) and Timely (run
      just before writing production code). Some general tips on writing clean tests:
      </p><ul>
        <li>Tests should be readable above all else and this might mean relaxing certain production code
          restrictions on performance</li>
        <li>Single concept per test</li>
        <li>Create helper methods to simplify complicated setups</li>
        <li>Convert multiple asserts into a single assert via a state pattern</li>
      </ul>
    

    <p>
      The three laws of TDD:
      </p><dl>
        <dt>First law</dt>
        <dd>You may not write production code until you have written a failing test.</dd><dt>Second law</dt>
        <dd>You may not write more of a test than is sufficient to fail, and not compiling is failing.</dd>
        <dt>Third law</dt>
        <dd>You may not write more production code than is sufficient to pass the currently failing test.</dd>
      </dl>
    

    <div>
      <p><a href="https://smalldata.tech/img/blog/011-clean-code.jpg">
        <img alt="" src="https://smalldata.tech/img/blog/011-clean-code.jpg">
      </a></p><p>
        Not quite TDD.
      </p>
    </div>

    <h5 id="system-design">System Design</h5>
    <ul>
        <li>Classes should follow the open-closed principle - open for extension but closed for modification.
          Consider the following example where we write an <code>AreaCalculator</code> which calculates the
          total area of a collection of rectangles.
          <pre>public class Rectangle {
    public double width;
    public double height;
}

public class AreaCalculator {

    public double calculateArea(Collection<rectangle> rectangles) {
        double result = 0;
        for (Rectangle r : rectangles) {
            result += r.width * r.height;
        }
        return result;
    }
}
</rectangle></pre> We would now like to extend this function to calculate the area of circles as well. Our new function now looks
          as follows:
          <pre>public abstract class Shape { }

public class Rectangle extends Shape {
    public double width;
    public double height;
}

public class Circle extends Shape {
    public double radius;
}

public class AreaCalculator {

    public double calculateArea(Collection<shape> shapes) {
        double result = 0;
        for (Shape s : shapes) {
            if (s instanceof Rectangle) {
                Rectangle r = (Rectangle) s;
                result += r.width * r.height;
            } else {
                Circle c = (Circle) s;
                result += c.radius * c.radius * Math.PI;
            }
        }
        return result;
    }
}
</shape></pre> Extending this further to calculate the area of triangles now requires another modification to the <code>calculateArea</code>
          method, i.e. it is not <strong>open for extension</strong>. We can change this by introducing an
          <code>area</code> method on the <code>Shape</code> data structure. Our code now looks like the
          following:
          <pre>public abstract class Shape {
    abstract double area();
}

public class Rectangle extends Shape {
    public double width;
    public double height;

    @Override
    public double area() {
        return width * height;
    }
}

public class Circle extends Shape {
    public double radius;

    @Override
    public double area() {
        return radius * radius * Math.PI;
    }
}

public class AreaCalculator {

    public double calculateArea(Collection<shape> shapes) {
        double result = 0;
        for (Shape s : shapes) {
            result += s.area(); // note the simplicity
        }
        return result;
    }
}
</shape></pre>
        </li>
        <li>Dependency Inversion Principle - depend upon abstractions and interfaces, not concrete
          implementations</li>
        <li>When building large software systems, try to avoid doing a big design up front - use a dependency
          injection container to separate cross-cutting concers like transactions, logging, etc. from
          business logic</li>
      </ul>
    
    <h5 id="references">References</h5>
    <ul>
        <li><a href="https://smalldata.tech/api/to/f838bf36866ac96dc70a088a5d559fb0">Clean Code - A handbook on agile software
            craftmanship</a></li>
        <li><a href="https://smalldata.tech/api/to/d0ed22ebb2bd98aa226ab833705aaa85">Explanation of the stack</a></li>
        <li><a href="https://smalldata.tech/api/to/779794f2469765d811744e656c1e09e2">Simple example of the Open Closed Principle</a></li>
      </ul>
    
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2018%2F09%2F16%2Fclean-code-notes&amp;t=Clean%20Code%20-%20Notes">HackerNews submission / discussion</a></p></div></div>]]>
            </description>
            <link>https://smalldata.tech/blog/2018/09/16/clean-code-notes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986604</guid>
            <pubDate>Wed, 04 Nov 2020 05:35:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All systems go for UK’s £55M fusion energy experiment]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24986528">thread link</a>) | @danboarder
<br/>
November 3, 2020 | https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/ | <a href="https://web.archive.org/web/*/https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
						
			<div>
			
			
<article id="post-14051">
  
  <div>

		<div data-hide-featured-media="0">
      
        <div><p>Clean energy from fusion is a step closer with the launch of the MAST Upgrade tokamak.</p>
<div id="attachment_14062"><p><img aria-describedby="caption-attachment-14062" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgOTYwIDY0MCIgd2lkdGg9Ijk2MCIgaGVpZ2h0PSI2NDAiIGRhdGEtdT0iaHR0cHMlM0ElMkYlMkZjY2ZlLnVrYWVhLnVrJTJGd3AtY29udGVudCUyRnVwbG9hZHMlMkYyMDIwJTJGMTAlMkZnb3YudWtfLmpwZyIgZGF0YS13PSI5NjAiIGRhdGEtaD0iNjQwIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="MAST Upgrade first plasma" width="400" height="267" sizes="(max-width: 400px) 100vw, 400px"></p><p id="caption-attachment-14062">MAST Upgrade first plasma</p></div>
<p>For the first time, after a seven-year build, UKAEA’s £55M-machine, labelled <a href="https://ccfe.ukaea.uk/research/mast-upgrade/">Mega Amp Spherical Tokamak (MAST) Upgrade</a>, has achieved “first plasma” – where all the essential components work together simultaneously.</p>
<p>The project at Culham Centre for Fusion Energy was funded by the Engineering &amp; Physical Sciences Research Council, part of UK Research &amp; Innovation and the Department for Business, Energy &amp; Industrial Strategy.</p>
<p>Fusion energy offers the potential of an abundant, inherently safe low-carbon electricity supply (the raw materials are found in seawater and the Earth’s crust). It involves fusing hydrogen particles in a hot gas known as a ‘plasma’ to unlock large amounts of energy.</p>
<p>Operating fusion technologies requires a careful balancing act of controlling extreme heat, gas and powerful magnetic fields, amongst other complex systems.</p>
<h3>Super-X factor</h3>
<p>One of the biggest challenges in fusion research has been to extract the amount of excess heat from the plasma. UKAEA’s scientists now plan to test a new exhaust system called the ‘Super-X divertor’ at MAST Upgrade.</p>
<p>This system is designed to channel plasma out of the machine at temperatures low enough for its materials to withstand – meaning that components can last much longer. The approximate tenfold reduction in heat arriving at the internal surfaces of the machine has the potential to be a game-changer for the long-term viability of future fusion power stations.</p>
<h3>A step towards fusion power</h3>
<p>MAST Upgrade will be the forerunner of the UK’s prototype fusion power plant, <a href="https://ccfe.ukaea.uk/research/step/">Spherical Tokamak for Energy Production (“STEP”)</a>, due for completion by 2040.</p>
<p>STEP – which UKAEA is designing in an initial £220 million programme funded by the UK Government – will be based on MAST Upgrade’s ‘spherical tokamak’ fusion concept. The spherical tokamak could offer a route to a compact fusion power plant. The success of MAST Upgrade is another step along the way to designing future fusion power facilities, which could have an important role as part of a future portfolio of low-carbon energy.</p>
<p>MAST Upgrade will also aid preparations for <a href="https://www.iter.org/" target="_blank" rel="noopener noreferrer">ITER</a> – the world’s largest science megaproject, now being built in the South of France, which intends to demonstrate fusion power on an industrial scale.</p>
<p><iframe title="Shaping fusion power for the future - Mega Amp Spherical Tokamak Upgrade" width="1080" height="608" src="https://www.youtube.com/embed/PVUnOZwrSx8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>UK Science Minister, Amanda Solloway, said: “We want the UK to be a world leader in fusion energy and to capitalise on its amazing potential as a clean energy source that could last for hundreds of years.</p>
<p>“Backed by £55 million of government funding, powering up the MAST Upgrade device is a landmark moment for this national fusion experiment and takes us another step closer towards our goal of building the UK’s first fusion power plant by 2040.”</p>
<p>Commenting on the achievement of first plasma, UKAEA CEO, Professor Ian Chapman, said:</p>
<p>“MAST Upgrade will take us closer to delivering sustainable, clean fusion energy. This experiment will break new ground and test technology that has never been tried before. It ensures the UK is in the premier league of countries working on fusion – and will be vital in achieving UKAEA’s goal of building the STEP fusion power plant.”</p>
<p>Video of the first plasma on MAST Upgrade:</p>

</div>        
      </div><!--/post-content-->
      
    </div><!--/inner-wrap-->
    
</article>
		</div><!--/post-area-->
			
							
		</div></div>]]>
            </description>
            <link>https://ccfe.ukaea.uk/all-systems-go-for-uks-55m-fusion-energy-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986528</guid>
            <pubDate>Wed, 04 Nov 2020 05:01:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serendipity in a Remote World]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24986523">thread link</a>) | @akhilkg
<br/>
November 3, 2020 | http://akhilkg.me/blog/serendipity | <a href="https://web.archive.org/web/*/http://akhilkg.me/blog/serendipity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p><strong>serendipity</strong></p>
<p> noun <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the occurrence and development of events by chance in a happy or beneficial way.<br>&nbsp;&nbsp;&nbsp; <em>”a fortunate stroke of serendipity"</em></p></div>
<p>I hadn't even heard of the word ‘serendipity’ before COVID and true to its nature - serendipity is events happening organically - by chance or "spontaneously".</p>
<p>In real life, we almost always fail to notice serendipity to put a word on it. I only came across the word when everything went remote and random interactions came to a full stop and now suddenly, something was missing. <br>
Obviously, it was other people.
But even with video calls, meetings, standups - it didn't feel right. </p>
<p>The truth is nothing can beat a real-life conversation with someone - not chat, audio or video. Maybe not even VR or holograms.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/97962688-b401eb00-1ddb-11eb-9903-2c485567e6e6.gif" alt="Silicon Valley GIF"></p><p><em>(Silicon Valley, S1E5)</em></p>
<hr>

<p>Random interactions in a fully remote world have to be forced. That’s just how we must play it now. But trying to duplicate in-person serendipity in a remote world - as is - might not be a great way out.</p>
<p>For instance, take the Qt World Summit this year which happened about a week ago:</p>
<p><img src="https://user-images.githubusercontent.com/32199592/97961622-ab101a00-1dd9-11eb-88b4-ab044cf9da5e.png" alt="qtws"></p><p><em>Reminds me of Club Penguin. Heh</em></p>
<p>I don’t know about you but to me, that looks extraordinarily distracting and borderline unnecessary. </p>
<p>Creating organic serendipity in a totally remote set up is a tough nut to crack - props to Qt for trying something new but to pretend that ‘online’ is the new ‘offline’ might not be the way to solve it. </p>
<p>On the same note though, multiplayer games are quite effective in the right context - simple, popular ones like <a href="http://www.innersloth.com/gameAmongUs.php">'Among Us'</a> can work both as an icebreaker and as a way to create organic interactions between a group of people and games have always been a source of a spontaneous group activity.</p>
<hr>
<br>
<h3>Embracing remote</h3>
<p><strong>The case of GitLab</strong></p>
<p><a href="https://about.gitlab.com/">GitLab</a> is an all remote company - right from the beginning as an open-source project - GitLab, in its initial days, was developed from contributors around the world. The GitLab team is now over 1,200 employees strong and Gitlab recently held its Series E round with $268M raised - and all of this without even having a physical office.</p>
<p>GitLab has an <a href="https://about.gitlab.com/company/culture/all-remote/">excellent handbook</a> on remote work, some key points - </p>
<h4>Regular engagement</h4>
<p>To simulate serendipity within a team - engage regularly on a weekly basis - in form of text or video. </p>
<p>Nothing beats seeing someone in person and the closest we can get to in-person meetings are video calls. Try to have regular video calls with your team - it might require some getting used to - to discuss something other than work but once you establish a flow, video calls are super effective.</p>
<p>Even an always-on video conferencing room or dedicated time slots for video/audio chat can also work wonders.</p>
<br>
<h4>Async</h4>
<p>Regarding work - asynchronous is preferred over synchronous communication.</p>
<p>Meetings are synchronous events - they require everyone at the same time.
Asynchronous events are things like chat/etc that do not require an immediate response.</p>
<p>An all remote culture means employees from all different timezones and so - meetings are only kept for the most important things and are also most of the times, optional. </p>
<p>Record the meetings, have an agenda, maintain the minutes, allow people to asynchronously contribute and don’t waste time.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/97961918-27a2f880-1dda-11eb-9a8d-8871b55cb778.png" alt="this meeting should have been an email"></p><h4>Role of text communication</h4>
<p>Most of remote communication happens through text and texting can get quite difficult at times - mainly because of the lack of non-verbals (like the lack of your facial expressions and tone when you are trying to tell a joke in chat but no one gets it)</p>
<p>"<em>Text communication can be easily derailed, and assumptions can lead to  good-mannered communiques being viewed as a slight.</em>"</p>
<p>Assume the best - don’t be an asshole.
From experience, when things start getting heated up on a text chat, jump immediately to a video call and straighten things up. Don’t keep it for later. </p>
<p>It’s really, really easy to get angry with someone’s stupid texts but when you see their face or hear their voice, that anger starts to dissipate ;)</p>
<br>
<hr>
<p>All in all, remote is tough and we need to intentionally create situations and design systems where we can interact organically and spontaneously.</p></div></div>]]>
            </description>
            <link>http://akhilkg.me/blog/serendipity</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986523</guid>
            <pubDate>Wed, 04 Nov 2020 04:59:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AVOD, SVOD, TVOD, PVOD Monetization Models Demystified]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24986497">thread link</a>) | @ponderingfish
<br/>
November 3, 2020 | https://ottverse.com/svod-avod-tvod-pvod-monetization-models/ | <a href="https://web.archive.org/web/*/https://ottverse.com/svod-avod-tvod-pvod-monetization-models/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/avod-tvod-svod-pvod-monetization.png?resize=678%2C381&amp;ssl=1" alt="avod-tvod-svod-pvod-monetization" title="avod-tvod-svod-pvod-monetization" data-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/avod-tvod-svod-pvod-monetization.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>Advertising VOD, Subscription VOD, Transactional VOD, Premium VOD are different monetization models in the Video On Demand (VOD) ecosystem and represent different ways of engaging and monetizing users on the platform. </strong></p>



<p>Let’s take a look at the use cases for all four in this article and help you decide the best monetization modelf for your business. </p>




<h2><span id="What_is_Video_On_Demand_(VOD)"></span>What is Video On Demand (VOD)?<span></span></h2>



<p>When I asked people in the streaming industry, what Video On Demand or VOD meant to them, this is what I got (averaging across responses). </p>



<p><em>Video On Demand is a video delivery mechanism that allows users to watch a video whenever they want to and wherever they want to.</em></p>



<p>Of course, this statement comes with caveats. VOD access can be restricted based on age, geography, monetization strategy, device, and so many other means. </p>



<p>In this article, we take a look at some of the common ways by which content providers can monetize their VOD content library. We also take a look at the advantages and pitfalls of each of these methods. </p>



<hr>



<h2><span id="AVOD_%E2%80%93_AdvertisingBased_Video_On_Demand"></span>AVOD – Advertising-Based Video On Demand?<span></span></h2>



<p>AVOD or Advertising-Based Video On Demand is a monetization strategy in which advertisements are inserted into the video to monetize it and (in almost all cases), the content can be consumed for free without paying or subscribing to the service. </p>



<h3><span id="Where_does_AVOD_Work"></span>Where does AVOD Work?<span></span></h3>



<p>AVOD is a monetization technique that is predicated on a large number of people consuming the content in order to make it financially viable. The publisher typically gets paid a couple of dollars (or more) for every 1000 ad impressions and this means, that a lot of people need to watch the video for the publisher to make a resonable amount of money. </p>



<p>AVOD is typically suited for news websites, and UGC sites such as YouTube, Hulu,  where the primary source of income is from advertising driven by large audiences. AVOD a <a href="https://www.nexttv.com/news/streamers-flock-to-avod-gold-rush" target="_blank" rel="noopener">very popular form of video monetization</a> and ad insertion is not going to go away anytime soon! </p>



<h3><span id="How_Can_AVOD_Go_Wrong"></span>How Can AVOD Go Wrong?<span></span></h3>



<p>Well, that’s not hard to answer! Have you ever watched a video on YouTube with 40 ads inserted into it? Remember the frustration you felt waiting for the “Skip Ads” button to appear?</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/memegenerator.net/img/images/12523690.jpg?resize=435%2C245&amp;is-pending-load=1#038;ssl=1" alt="Extremely Frustrated - Caption | Meme Generator" width="435" height="245" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/memegenerator.net/img/images/12523690.jpg?resize=435%2C245&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>SKIP ADS!!!</figcaption></figure></div>



<p>Well, “<strong>user frustration</strong>” is a huge problem with AVOD. </p>



<p>Too many ads can <strong>literally kill the golden goose (your audience)</strong>. But, too few ads and you won’t make any money to pay your bills at the end of the month. </p>



<p>So, it’s a balancing act between making money, not frustrating your users, and showing the correct number of relevant ads. What’s the correct number of ads? Well, you need a specialized analytics service to track and report on this. </p>



<hr>



<h2><span id="SVOD_%E2%80%93_Subscription_Video_On_Demand"></span>SVOD – Subscription Video On Demand<span></span></h2>



<p>SVOD is a type of VOD monetization where users are required to pay a certain amount of money or subscription fee upfront to get access to the content providers’ library. This is usually a recurring fee and is usually either monthly or yearly. </p>



<p>Typically, the users are not shown any ads because they have paid a certain fee already (<em>which means, the publisher has already made money off of the user</em>). </p>



<p>SVOD is a very common monetization strategy that is quite beneficial to the end-user when the plan doesn’t have any lock-in periods. People may choose to purchase a monthly plan and cancel the following month. </p>



<p>As you can see, this sort of flexibility is a double-edged sword. It </p>



<p>Netflix, Hotstar, Hulu, HBO, Amazon Prime Video are all examples of SVOD. </p>



<h3><span id="How_can_SVOD_go_Wrong"></span>How can SVOD go Wrong?<span></span></h3>



<p>SVOD can go wrong in many ways and the primary way is by setting a very high subscription fee, but, not having a large enough or relevant content library to back it up. If you charge your users $15 a month when your nearest competitor is charging $7/month, then you need to justify the $8 gap. </p>



<p>Do you have better movies? Latest releases? A bigger library? More genres? Better quality of experience? </p>



<hr>



<h2><span id="TVOD_%E2%80%93_TransactionBased_Video_On_Demand"></span>TVOD – Transaction-Based Video On Demand<span></span></h2>



<p><strong>TVOD</strong> or <strong>Transactional Video On Demand</strong> basically refers to a rental based monetization where the user rents or has access to the service for a short period of time by paying a fee. </p>



<p><strong>This is also referred to as “pay per view”. </strong></p>



<p>A simple example is that of MMA (Mixed Martial Arts) or Boxing matches. You can pay to see a fight online and then your access to the service is complete. If you want to access or use any other content, you’ll have to pay another fee. </p>



<p>Apart from one-off events, TVOD also refers to rental services offered by content providers such as YouTube and Amazon Prime Video. In either of these services, you can rent a movie for a couple of days and then your access to the content is stopped. </p>



<h3><span id="What_can_go_wrong_with_TVOD"></span>What can go wrong with TVOD?<span></span></h3>



<p>In TVOD, if one does not get the price right, then the number of live viewers will be less and people might prefer to watch it for free later on using catch-up services. The same goes for video rentals – people might choose to rent it from a different provider at a lower cost.</p>



<p>Also, since the customer is not “locked-in”, there needs to be sustained marketing and promotions to ensure that the customer makes repeat purchases. It is a tough monetization choice, but one that can provide handsome returns! </p>



<hr>



<h2><span id="PVOD_%E2%80%93_Premium_Video_On_Demand"></span>PVOD – Premium Video On Demand<span></span></h2>



<p>Premium Video on Demand is a form of TVOD or SVOD where the end-user can pay to get access to content sooner than other SVOD or TVOD customers would! Think of PVOD as a form of online-movie-theaters. You can go see the latest movie at the theaters or wait three or four months to see them on an SVOD service, right? </p>



<p>Well, that’s exactly the monetization model for PVOD. You can pay a “premium” price to watch a movie before it hits the general SVOD subscriber pool. </p>



<p>Disney’s Mulan is a good example of PVOD. You needed a subscription to Disney+ and then you had to pay an additional $25 (or so) to watch Mulan first-day-first-show! But, you retained access to the movie until it because available to the rest of the Disney+ subscribers. </p>



<p>With the COVID-19 pandemic forcing cinemas shut, I feel we are going to see more of PVOD in the coming months! </p>



<hr>



<h2><span id="Hybrid_Revenue/Monetization_Models"></span>Hybrid Revenue/Monetization Models<span></span></h2>



<p>Just to be clear, VOD monetization does not stop at AVOD, SVOD, TVOD, and PVOD. </p>



<p><strong>In fact, many popular services offer a combination of the above monetization models to appeal to different segments of users.</strong> </p>



<p>There are hybrid models such as the “<strong>Freemium Model</strong>” that merges AVOD and SVOD. In the freemium model, a user can consume content for free but will have to contend with the occasional advertisement interrupting his video session. </p>



<p>But, if that user chooses to upgrade to a paid subscription, the ads go away! </p>



<p>Another variation of the freemium model is providing a small section of your content library for free and charging a subscription fee to watch the more premium content.  </p>



<p>Freemium is a popular tactic that is used to attract users with free content, get them hooked, and hopefully convert them into paid customers. </p>



<hr>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>There you have it – different monetization models for VOD (AVOD, SVOD, TVOD, PVOD, and other Hybrid Models). All of these have their own advantages and disadvantages. The idea is to get your strategy, marketing, and focus right. And then, everything will fall into place.</p>



<p>So, what do you use to monetize your content library? </p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/svod-avod-tvod-pvod-monetization-models/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986497</guid>
            <pubDate>Wed, 04 Nov 2020 04:50:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to systems thinking – free email course]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24986454">thread link</a>) | @aelsabagh123
<br/>
November 3, 2020 | https://www.designforimpact.co/email-courses | <a href="https://web.archive.org/web/*/https://www.designforimpact.co/email-courses">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><img src="https://uploads-ssl.webflow.com/5f6f2949c7ed7c375194f663/5f6f2949db2d9e5692c5ee4e_angle.svg" alt=""><img src="https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b171440f137cda3de672b_charles-deluvio-bXqOMf5tvDk-unsplash.jpg" alt="Testimonial Image" sizes="(max-width: 767px) 100vw, 30vw" srcset="https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b171440f137cda3de672b_charles-deluvio-bXqOMf5tvDk-unsplash-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b171440f137cda3de672b_charles-deluvio-bXqOMf5tvDk-unsplash-p-1600.jpeg 1600w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b171440f137cda3de672b_charles-deluvio-bXqOMf5tvDk-unsplash-p-2000.jpeg 2000w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b171440f137cda3de672b_charles-deluvio-bXqOMf5tvDk-unsplash-p-2600.jpeg 2600w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b171440f137cda3de672b_charles-deluvio-bXqOMf5tvDk-unsplash-p-3200.jpeg 3200w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b171440f137cda3de672b_charles-deluvio-bXqOMf5tvDk-unsplash.jpg 4104w"></p><div><div><h4>I’m <strong>thankful</strong> to have been a part of Design for Impact and its Coaching Clinics. <p><strong>It has allowed me to dedicate time each week</strong> in learning Systems Thinking from the basics with the participation of <strong>an engrossed team of thinkers from around the globe</strong>. </p></h4></div></div></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5f6f2949c7ed7c375194f663/5f6f2949db2d9e5692c5ee4e_angle.svg" alt=""><img src="https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b459b337e3e555fad6_nesa-by-makers-IgUR1iX0mqM-unsplash.jpg" alt="Testimonial Image" sizes="(max-width: 767px) 100vw, 30vw" srcset="https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b459b337e3e555fad6_nesa-by-makers-IgUR1iX0mqM-unsplash-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b459b337e3e555fad6_nesa-by-makers-IgUR1iX0mqM-unsplash-p-1600.jpeg 1600w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b459b337e3e555fad6_nesa-by-makers-IgUR1iX0mqM-unsplash-p-2000.jpeg 2000w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b459b337e3e555fad6_nesa-by-makers-IgUR1iX0mqM-unsplash-p-2600.jpeg 2600w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b459b337e3e555fad6_nesa-by-makers-IgUR1iX0mqM-unsplash-p-3200.jpeg 3200w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b459b337e3e555fad6_nesa-by-makers-IgUR1iX0mqM-unsplash.jpg 6720w"></p><div><div><h4>Design for Impact has helped give me the <strong>knowledge and skills</strong> needed to enter a career in User Experience. Abram is an excellent instructor and has taught me the fundamentals of UX design and research.<p>The program attracts people from <strong>diverse cultural, educational, and employment backgrounds. </strong>I have enjoyed collaborating to <strong>work through a UX design problem from beginning to end as a team.</strong></p></h4></div></div></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5f6f2949c7ed7c375194f663/5f6f2949db2d9e5692c5ee4e_angle.svg" alt=""><img src="https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b31a52cfaf48e8b47d_priscilla-du-preez-XkKCui44iM0-unsplash.jpg" alt="Testimonial Image" sizes="(max-width: 767px) 100vw, 30vw" srcset="https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b31a52cfaf48e8b47d_priscilla-du-preez-XkKCui44iM0-unsplash-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b31a52cfaf48e8b47d_priscilla-du-preez-XkKCui44iM0-unsplash-p-1600.jpeg 1600w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b31a52cfaf48e8b47d_priscilla-du-preez-XkKCui44iM0-unsplash-p-2000.jpeg 2000w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b31a52cfaf48e8b47d_priscilla-du-preez-XkKCui44iM0-unsplash-p-2600.jpeg 2600w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b31a52cfaf48e8b47d_priscilla-du-preez-XkKCui44iM0-unsplash-p-3200.jpeg 3200w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f6b16b31a52cfaf48e8b47d_priscilla-du-preez-XkKCui44iM0-unsplash.jpg 5472w"></p><div><div><h4>I have been leveraging the Design for Impact community to continue learning experience/service design practices. Our exercises are output focused, and <strong>collaboration is productive and enjoyable. </strong><p>What I appreciate most is the <strong>various points of view</strong> I have access to from a group of designers with <strong>diverse backgrounds and expertise from around the globe.</strong></p></h4></div></div></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5f6f2949c7ed7c375194f663/5f6f2949db2d9e5692c5ee4e_angle.svg" alt=""><img src="https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f7c3cba31ccfc6dca6aef3b_kaleidico-7lryofJ0H9s-unsplash.jpg" alt="Testimonial Image" sizes="(max-width: 767px) 100vw, 30vw" srcset="https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f7c3cba31ccfc6dca6aef3b_kaleidico-7lryofJ0H9s-unsplash-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f7c3cba31ccfc6dca6aef3b_kaleidico-7lryofJ0H9s-unsplash-p-1600.jpeg 1600w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f7c3cba31ccfc6dca6aef3b_kaleidico-7lryofJ0H9s-unsplash-p-2000.jpeg 2000w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f7c3cba31ccfc6dca6aef3b_kaleidico-7lryofJ0H9s-unsplash-p-2600.jpeg 2600w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f7c3cba31ccfc6dca6aef3b_kaleidico-7lryofJ0H9s-unsplash-p-3200.jpeg 3200w, https://uploads-ssl.webflow.com/5f69c6d6c534d0f4c9292690/5f7c3cba31ccfc6dca6aef3b_kaleidico-7lryofJ0H9s-unsplash.jpg 5425w"></p><div><p><h4><strong>The variety of backgrounds of the community members </strong>is a boon for a novice like me curious to learn more about the various approaches to research, data analysis, and systems thinking as it applies to the social sector.</h4></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.designforimpact.co/email-courses</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986454</guid>
            <pubDate>Wed, 04 Nov 2020 04:29:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Tips for the Intermediate Vim User]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24986374">thread link</a>) | @quyleanh
<br/>
November 3, 2020 | https://jemma.dev/blog/intermediate-vim-tips | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/intermediate-vim-tips">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>After a decade of honing my skills as a mini-golfer, I’ve recently progressed onto playing a new version of golf: <a href="https://www.vimgolf.com/">VimGolf</a>. I’ve been using <a href="https://www.vim.org/">Vim</a> for a few years now, and noticed that my Vim skillset had plateaued. The premise of VimGolf is simple: challenges consist of a start file and an end file. The goal is to get from the start file to the end file, using Vim, in as few keystrokes as possible. I’ve been playing VimGolf as a way to acquire new skills.</p>

<p>I’ve learned all kinds of new keystrokes and Vim tips through playing. Predictably, some of them are very niche and forgettable. But, I’ve found others which I didn’t know and now incorporate daily into my Vim usage. I’d imagine reading this, some will be familiar, and some new. This is <em>not</em> meant to be an introduction to Vim. Rather if (like me) you’ve been using Vim for a little bit but haven’t recently looked up Vim commands, I’m hoping some of these will be helpful.</p>

<p>My recommendation in reading through this post is to have a file open in Vim, and try out these commands as you read them. I hope at least a few are helpful for your workflow and make their way into your regular Vim usage!</p>

<h3 id="insertion">Insertion</h3>
<ul>
  <li><code>Ctrl-n</code> in insertion mode inserts based on context. It will prompt a word based on contents of the file. Keep hitting <code>Ctrl-n</code> to get the contextually next word</li>
  <li><code>O</code> moves into insertion mode in a new line above the cursor</li>
  <li><code>ci&lt;char&gt;</code> to delete within the <code>&lt;char&gt;</code> and put you in insertion mode. For example, <code>ci(</code> deletes everything within the <code>(...)</code> and puts you in insertion mode. Also helpful, <code>ci”</code> and <code>ci{</code></li>
  <li><code>S</code> deletes the current line and puts you in insertion mode</li>
  <li><code>.</code> repeats the previous action (specifically helpful for insertion)</li>
  <li><code>Ctrl-o</code> in insertion mode escapes for one command in normal mode. This is <em>very</em> helpful for movement while inserting</li>
  <li><code>I</code> inserts at the beginning of the line</li>
</ul>

<h3 id="movement">Movement</h3>
<ul>
  <li><code>^</code> moves the cursor to the first non-whitespace character on the line</li>
  <li><code>+</code> moves to the beginning of the first word (non-whitespace character) on next line</li>
  <li><code>Ctrl-o</code> (backwards) and <code>Ctrl-i</code> (forwards) together jump the cursor around to where it was previously in any files. Keep using <code>Ctrl-o</code> to go backwards, and <code>Ctrl-i</code> to go forwards. (<code>:help jumplist</code> for more info here)</li>
  <li><code>B</code> (backwards) and <code>E</code> (forwards) move the cursor using only whitespace as delimiters</li>
  <li><code>F&lt;char&gt;</code> (backwards) and <code>f&lt;char&gt;</code> (forwards) find a character or word on the current line</li>
</ul>

<h3 id="copy-paste">Copy Paste</h3>
<ul>
  <li><code>Y</code> highlights the line and copies it (I had been using <code>Vy</code> for this)</li>
  <li><code>"+y</code> copies highlighted words to the clipboard so you can paste the value outside of Vim</li>
  <li><code>"+Y</code> copies the line the cursor is on to the clipboard so you can paste the value outside of Vim</li>
  <li><code>Ctrl-y</code> in insertion mode pastes the contents of the line directly above</li>
</ul>

<p>Tip: If you highlight a word (or lines) and then replace it, the highlighted word moves into the register, and will be the next word you paste</p>

<h3 id="indenting-text">Indenting Text</h3>
<ul>
  <li><code>&lt;&lt;</code> (left) and <code>&gt;&gt;</code> (right) shifts the current line</li>
  <li><code>&lt;iB</code> (left) and <code>&gt;iB</code> (right) shifts the code in the current block</li>
  <li><code>=i{</code> fixes indentation of block excluding the braces</li>
  <li><code>=a{</code> fixes indentation of block including the braces</li>
  <li><code>gg=G</code> to indent the full file</li>
</ul>

<p>Tip: Use <code>gg=G</code> and then <code>Ctrl-o</code> to get the cursor back to where it was</p>

<h4 id="refocusing-the-page">Refocusing the page</h4>
<ul>
  <li><code>zt</code> moves the line the cursor is on to the top of the page</li>
  <li><code>zz</code> moves the line the cursor is on to the middle of the page</li>
  <li><code>zb</code> moves the line the cursor is on to the bottom of the page</li>
</ul>

<h3 id="specific-characters">Specific Characters</h3>
<ul>
  <li><code>~</code> switches the case of a character</li>
  <li><code>Ctrl-a</code> increments numbers</li>
  <li><code>Ctrl-x</code> decrements numbers</li>
</ul>

<p>Tip: The cursor doesn’t need to be on the number itself, it’ll increment or decrement any number after the cursor on the same line</p>

<h3 id="miscellaneous">Miscellaneous</h3>
<ul>
  <li><code>ZZ</code> and <code>:x</code> both only save the file if it has been modified, and then quit</li>
  <li><code>:!&lt;command&gt;</code> to run a bash command from Vim (for example <code>:!ls</code>)</li>
  <li><code>gql</code> will split one line to the currently set width. To set the width of the split lines to be different from your current setting, you can use <code>:set textwidth=&lt;n&gt;</code>. This can be helpful for 80 character linting, for example</li>
  <li><code>dat</code> deletes everything inside an HTML tag including the tag</li>
  <li><code>dit</code> deletes everything inside an HTML tag excluding the tag</li>
</ul>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/intermediate-vim-tips</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986374</guid>
            <pubDate>Wed, 04 Nov 2020 04:01:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Audiblegate the true story of missing sales]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24986226">thread link</a>) | @abawany
<br/>
November 3, 2020 | https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales | <a href="https://web.archive.org/web/*/https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.3.0"><div dir="ltr"><div><div id="viewer-efbmm"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales" data-pin-media="https://static.wixstatic.com/media/a4d16d_a1db035a211a48f5a5bf627051a994bf~mv2.jpg/v1/fit/w_275%2Ch_183%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/a4d16d_a1db035a211a48f5a5bf627051a994bf~mv2.jpg/v1/fit/w_275,h_183,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-bv0a9"><span><span><strong>Here's an ALLEGED tale of a giant in the tech and online retail industry you'll struggle to believe.</strong> If it wasn't happening to me and many, many authors, I'd think it can't be true, that it might be an exaggeration. Grab a coffee or tea or even an alcoholic beverage and let me take you into the <em>Twilight Zone</em> of the audiobook business, where the company who now controls a majority of the publishing industry, the same company who calls themselves the most customer-centric company in the world is fleecing authors blind, emphasis on blind (since they've been hiding it very well for years.)

Your favorite authors, me included, have been used in a program by Amazon called <strong>Audible.</strong> You might have heard of them. They're just a little audiobook company that it seems  may be losing market share, or something has worried them, so they've found a way around the one thing standing between them and mega-profits: </span><strong><span>paying their content providers.</span></strong><span> You know, the little guys who spend months, years even, creating a story, then producing an audiobook to keep their readers happy and hopefully bolster their mostly meagre income in order to feed their family or pay for enough coffee to write their next book.
</span>
</span></p><p id="viewer-704bm"><span><strong><span>Returns have been actively hidden from Rights Holders and we have been robbed in broad daylight (or blank spreadsheet).<!-- --> </span></strong></span></p><p id="viewer-9ndfm"><span><span>Whether you are an author who has audiobooks currently or you are planning audiobooks, or you're a book lover or Audible customer, it's worth your while to read this saga. This is probably the single worst royalties grab by an Amazon company so far, and we need to stand together and stop this urgently. Big and small earning authors and those in-between, along with small publishers (and maybe Big Fives) are losing mega-dollars because of Audible's egregious behavior. Soon book lovers will also lose, because audiobooks will no longer be released from their beloved authors, me being one. It's just not financially worth it, plus who wants their stuff stolen when you've taken so much care to make it so nice.</span></span></p><div id="viewer-5pbpg"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales" data-pin-media="https://static.wixstatic.com/media/a4d16d_43db2e505afd472e98cb4e47cf6699f8~mv2.jpg/v1/fit/w_300%2Ch_225%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/a4d16d_43db2e505afd472e98cb4e47cf6699f8~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-ahpnm"><span><span>Audible has their own publishing/distribution company where you can produce your book and then that book is distributed to Audible, Amazon and Apple. If you choose  to <em>"go exclusive" </em>and distribute only to these three, you are granted the princely profit split of 40%. This is after spending sometimes upward of $6 to $8k on an audiobook. To give you an idea, my last audiobook </span><a href="http://readerlinks.com/l/779139/ddz" target="_blank" rel="noopener"><u><span>Destination Dark Zone</span></u></a><span> cost me $US6,200 to produce. 

If you're not exclusive to Audible and decide to distribute your book to other retail stores such as Kobo, Scrib'd and local libraries, then you only receive twenty-five percent of your sales or your share of the pot from memberships. 

Oh, that's right I didn't mention that. There's three ways an author is paid. When an Audible member uses a monthly credit that they receive as part of their membership, a rights holder receives a share of the pot created by the number of memberships paid, minus Audible's profit. This pot varies each month. So we never know how much this per download share will be until the day we are paid, but it's something close to $US5, while members pay $14.95 for a membership and one credit per month to use on a book. 

When you pay, say, $7.49 on Amazon for an add-on audiobook when you've purchased the eBook, we are paid $2.99 on the forty percent split. Should you buy an audiobook as a member from Audible and not use a credit, according to my reports, members pay $9.15 for most of my books, and I receive $3.61.  

Some rights holders don't have an exclusive deal with Audible. Many don't because they believe in not putting all their eggs in Amazon's basket. Well, they get less. So, just go right ahead and nearly halve these payments because they only receive twenty-five percent. It's not much is it compared to what readers and members pay for each book or monthly subscription fee?</span></span></p><p id="viewer-7l2n4"><span><span>Here's a crash course. You don't just record it and release like it's magic. You have to search for the perfect narrator and that sure takes some time. Then brief them, swapping emails until you're positive they're a good fit for you and your work. There's plenty of to-ing and fro-ing between you, as you nail the characters' voices and polish them to your liking before the narrator starts the narration. </span></span></p><p id="viewer-8b75k"><span><span>This involves them sending you a fifteen minute file, you listen and send them feedback until you're both happy. There's studios hired sometimes, and the narrator's fee is dependent upon their experience and quality of work. Mine have all won awards and they don't come cheap, but they're brilliant professionals so I don't begrudge their charges. After the recording, which can take a week or more, we have proofing and engineering to ensure the whole book's sound is consistent and intakes of breath and random clicks are banished.

For every hour to which you listen, it takes two to four to produce, and that's just the narrator's time. In my case, I listen through the finished audio files, and even with paying for proofing still a few mistakes slip through. So back it goes for the narrator to drop in the corrections (which takes a bit of time for the narrator, and if it's my mistake with a typo I pay extra) until it's right. You won't believe how tough it is to listen to your own book and think, G<em>ee, I could have written that sentence better, </em>or<em> hear</em> an actual typo or the same word used too many times in one paragraph.

Then, finally, yay, your audiobook is done and you pay the narrator or, in some cases, independent authors who can't afford to pay up front enter a royalty share deal and split the future income with the narrator for seven years. So, in this case, the narrator works for nothing, zip, nada, and hopes to eventually, somewhere down the track, recover their costs and actually get paid so they can buy mouth gargle and honey to keep their voices healthy and, well, eat. It's pretty tough for some if they pick the wrong book to narrate which doesn't sell and never pays out. They've worked for nothing.

The excited author then excitedly hits publish and waits for their book to go through Quality Assurance at ACX. Keep in mind, they've already paid and probably aren't rich, so they need that book out there selling to get their money back because, well, eating is kind of addictive, and life without hot water is pretty miserable. 

For the past twelve months though some authors and narrators have been waiting months to have their books approved. This is while business is booming at Audible apparently but they don't have enough staff to keep everything running smoothly. It's November 2020 now, and I've seen comments that there are some audiobooks from March, and even January, still caught up in the quality assurance system. And these kind of delays started well before COVID hit. </span></span></p><p id="viewer-29dq1"><span><span>I'd like to pause at this moment to ask where the Quality Assurance Department is for their Quality Assurance Department? <strong>"We seem to have a problem here, Captain Kirk." Where's Scotty from engineering when you need him?</strong></span></span></p><div id="viewer-22g3t"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales" data-pin-media="https://static.wixstatic.com/media/a27d24_8c5fc0fe012748d4bfca3f53157e5543~mv2.jpg/v1/fit/w_686%2Ch_427%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/a27d24_8c5fc0fe012748d4bfca3f53157e5543~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-a29fi"><span><span>So, this whole system seems a little unfair, right? Authors pay for everything, take all the risk for a smaller cut of the profits, while the richest man in the world's company keeps the lion's share and controls everything. </span></span></p><div id="viewer-d5urf"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales" data-pin-media="https://static.wixstatic.com/media/a27d24_33b6fa1acbac467f8a7dbf6d0ff786d8~mv2.jpg/v1/fit/w_736%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/a27d24_33b6fa1acbac467f8a7dbf6d0ff786d8~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-6f60j"><span><span>But, wait, this isn't the story I'm telling. This is the prologue, the background, so you're informed and will realize how dire what I'm about to share with you is for your favorite authors and why I've spent the past month not writing but trying to fight for an injustice to be rectified.

Even more insidious than the low royalty rates paid us by Audible is something I call </span><a href="https://www.susanmaywriter.net/susan-may-1/search/.hash.audiblegate" target="_self"><span>#AudibleGate</span></a><span>, of which you may not be aware. </span><strong><span>Audible is promoting returns of any audible book for "any reason, no questions asked," even if the person has listened to the whole Audible book and enjoyed it. </span></strong><span>The return is permissible up to 365 days and in some countries it's been reported that it's infinity.
<strong>
What??? </strong>

Hey now, no, Susan May, how would that work? Surely not. That would be objectively unfair to the author. Might even be illegal. </span></span></p><p id="viewer-dv8ci"><span><span>Why, yes, it is unfair and morally wrong and possibly even theft by stealth. You're so smart to realize that. Do tell Audible because they don't seem to get it.</span></span></p><p id="viewer-biqke"><span><span>Audible are actively promoting this <strong>"benefit" </strong>to their members as a way of incentivizing them to stay locked in each month because you can only return audiobooks if you're a member. Hmm, that's clever marketing. 

Audible even sends emails encouraging users to return a book, screens pop up after you finish reading suggesting a <strong><em>return</em>,</strong> and there is even </span><strong><span>an obvious "return" button on the app</span></strong><span> which changes wording depending on whether you've finished the book or are part way through. Part-finished it's <strong>"RETURN TITLE". </strong>Finish the book and it changes to <strong>"EXCHANGE."</strong></span></span></p><div id="viewer-2g9mf"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales" data-pin-media="https://static.wixstatic.com/media/a27d24_0f8ceafa1fa8416db60f7f02e1e54af1~mv2.jpg/v1/fit/w_1000%2Ch_886%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/a27d24_0f8ceafa1fa8416db60f7f02e1e54af1~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-ck9g7"><span><span><em>Who loses when I return a book? </em>readers think.</span></span></p><p id="viewer-9ukgr"><span><span>Audible! Surely, Audible? Surely not authors?  And who cares anyway, Audible's owned by the world's richest man? So, it's not big deal to return a book. It's my right. It's part of being an Audible member.</span></span></p><p id="viewer-ebd1d"><span><span>Well, you're favorite authors lose, my wonderful reader. Our accounts are debited for that returned book, sometimes a year later. </span><strong><span>We, the hard-working content creators and narrators eat this loss, not Amazon.</span></strong><span> </span><span>Let me repeat this for impact.</span><strong><span> Authors pay for this benefit and many times we are not earning any money for the sale of an audiobook </span></strong><span>even if it is thoroughly enjoyed by the reader. Audible though, they don't miss out, they still get your monthly subscription payment. Authors weren't asked if we wanted to offer this benefit or if we agreed to it or were happy to pay for it. Audible u just did it for their own commercial benefit. </span></span></p><p id="viewer-3aeba"><span><span>
<!-- -->How many readers, I hear you ask, are returning books? Surely everybody is honest and wouldn't do this unless the book is absolutely terrible and you've only listened to an hour or so?</span></span></p><div id="viewer-co8ic"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales" data-pin-media="https://static.wixstatic.com/media/a27d24_db7a91e0245a496ca4c0f841af0323ae~mv2.jpg/v1/fit/w_684%2Ch_969%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/a27d24_db7a91e0245a496ca4c0f841af0323ae~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-d8lgi"><span><span>Ah, ah, ah, nearing fifty percent returns for many authors. Some less, but not by much. <strong>My…</strong></span></span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales">https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales</a></em></p>]]>
            </description>
            <link>https://www.susanmaywriter.net/single-post/audiblegate-the-incredible-story-of-missing-sales</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986226</guid>
            <pubDate>Wed, 04 Nov 2020 03:01:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Months of Go from a Haskeller’s perspective (2016)]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24986132">thread link</a>) | @amzans
<br/>
November 3, 2020 | https://memo.barrucadu.co.uk/three-months-of-go.html | <a href="https://web.archive.org/web/*/https://memo.barrucadu.co.uk/three-months-of-go.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/BlogPosting" itemprop="mainEntity">
      

      <article>
        
<header>
  
</header>

<section itemprop="articleBody">
<p>This summer I’ve been interning at <a href="https://pusher.com/">Pusher</a>, and have been writing a lot of Go. It’s been a bit of a change coming from a Haskell background, so I decided to write up my thoughts now, at the end.</p>
<h2 id="the-good">The Good</h2>
<h3 id="incredibly-easy-to-pick-up">Incredibly easy to pick up</h3>
<p>There’s not a lot to Go, it’s quite a small language. I had never written a line of it before June, and now I’ve written about 30,000. It’s very easy to get started and become productive.</p>
<p>Haskell, on the other hand, is notorious for being hard to learn (<em>cough</em> monad tutorials <em>cough</em>). People often find it really hard to take the step from evaluating pure mathematical expressions to writing actual programs. I experienced no such disconnect in Go.</p>
<h3 id="garbage-collector-keeps-getting-better-and-better">Garbage collector keeps getting better and better</h3>
<p>Pusher previously tried to use Haskell for the project I was working on, but eventually had to give up due to unpredictable latency caused by garbage collection pauses. GHC’s garbage collector is <a href="https://blog.pusher.com/latency-working-set-ghc-gc-pick-two/">designed for throughput, not latency</a>. It is a generational copying collector, which means that pause times are proportional to the amount of live data in the heap. To make matters worse, it’s also stop-the-world.</p>
<p><a href="https://blog.golang.org/go15gc">Go’s garbage collector</a> is a concurrent mark-sweep with very short stop-the-world pauses, and it just seems to <a href="https://golang.org/doc/go1.7#performance">keep getting better</a>. This is definitely a good thing for a garbage collected language. We did have some issues with unacceptable latencies, but were able to work them all out. No such luck with the Haskell project.</p>
<h3 id="style-wars-are-a-thing-of-the-past">Style wars are a thing of the past</h3>
<p>Say what you like about <code>gofmt</code>, but it makes arguments over code style almost impossible. Just run it on save, and your code will always be consistently formatted.</p>
<p>I do find it a little strange that <code>gofmt</code> has been completely accepted, whereas Python’s significant whitespace (which is there for exactly the same reason: enforcing readable code) has been much more contentious across the programming community.</p>
<h2 id="the-neutral">The Neutral</h2>
<h3 id="code-generation-seems-to-be-the-accepted-solution-to-a-lot-of-problems">Code generation seems to be the accepted solution to a lot of problems</h3>
<p>I am not a huge fan of code generation (and I say this as <a href="https://blog.pusher.com/go-interface-fuzzer/">the author of a code generation tool</a>). I think it can do good, but it can also obscure what’s actually going on. In every discussion on Go generics, someone will come along and say you can add generics with code generation: that’s true, but at the cost of introducing additional, nonstandard, syntax.</p>
<p>I suspect the strong culture of code generation is largely because it lets you work around the flaws of the language.</p>
<h3 id="strict-not-lazy-evaluation">Strict, not lazy, evaluation</h3>
<p>Strict evaluation is typically better for performance than lazy evaluation (thunks cause allocation, so you’re gambling that <a href="https://www.barrucadu.co.uk/posts/2016-02-12-strict-vs-lazy.html">the computation saved offsets the memory cost</a>), but it does make things less composable. There have been a couple of times where I’ve gone to split up a function, only to realise that doing so would require allocating a data structure in memory which before was not needed.</p>
<p>I could trust the compiler to inline things for me, and so optimise away the additional allocations, but in a lazy language you just don’t have that issue at all.</p>
<h3 id="the-standard-library-is-not-so-great">The standard library is not so great</h3>
<p>If you know me in person, it might seem a little odd that I specifically comment on this. Normally I am all for languages having a small, really well-written, stdlib and everything else provided through libraries. I am picking on Go here a bit because the standard library seems to get a lot of praise, but I was unimpressed.</p>
<p>Parts of it are good, a lot of it is mediocre, and some of it is downright bad (like the <a href="https://golang.org/pkg/go/ast/">go/ast</a> package documentation). It seems a lot of Go’s use is in webdev, so perhaps those bits of the stdlib (which I haven’t touched at all) are consistently good.</p>
<h2 id="the-bad">The Bad</h2>
<p>I also agree with this Quora answer by Tikhon Jelvis to <a href="https://www.quora.com/Do-you-feel-that-golang-is-ugly">do you feel that golang is ugly?</a>, so have a look at that once you’ve read this section.</p>
<h3 id="a-culture-of-backwards-compatibility-at-all-costs">A culture of “backwards compatibility at all costs”</h3>
<p>In Go, you import packages by URL. If the URL points to, say, GitHub, then <code>go get</code> downloads HEAD of master and uses that. There is no way to specify a version, unless you have separate URLs for each version of your library.</p>
<p>This is just insane.</p>
<p>Go has a very strong culture of backwards compatibility, which I think is largely due to this. Even if you have a flaw in the API of your library, you can’t actually <em>fix</em> it because that would break all of your reverse-dependencies, unless they do vendoring, or pin to a specific commit.</p>
<p>Coming from the Haskell world, where the attitude is far more towards correctness than compatibility, this was probably the biggest culture shock for me. Things break backwards compatibility in Haskell, and the users just update their code because they <em>know</em> the library author did it for a reason. In Go, it just doesn’t happen <em>at all</em>.</p>
<h3 id="the-type-system-is-really-weak">The type system is really weak</h3>
<p>A common mantra in Haskell is “make illegal states unrepresentable,” which is great. If you’ve never come across it before it means to <em>choose your types such that an illegal value is a static error</em>. Want to avoid nulls? Use an option type. Want to ensure a list has at least one element? Use a nonempty list type. Use proper enums, not just ints. etc etc</p>
<p>In Go you just can’t do that, the type system isn’t strong enough. So a lot of things which are (or can be) a <em>compile-time</em> error in Haskell are a <em>runtime</em> error in Go, which is just worse.</p>
<p>Let’s pick on some specifics:</p>
<ul>
<li><p><strong>No generics</strong></p>
<p>Want to write a tree where every element is statically <em>guaranteed</em> to be the same type? Well, have fun implementing a “uinttree”, an “inttree”, a “stringtree”, and so on. You can’t just implement a generic tree.</p>
<p>But Go <em>does</em> have generics, for the built-in types. Arrays, channels, maps, and slices all have generic type parameters. So it seems that the Go developers want generics, but they don’t want to bother implementing it properly, so it remains a special case for a few things in the compiler.</p></li>
<li><p><strong>No sum types</strong></p>
<p>The way in Go to handle possibly-failing functions is to have multiple return values: an actual result, and an error. If the error is <code>nil</code>, then the actual result is sensible; otherwise the actual result is meaningless.</p>
<p>This means you can forget to check the error and use a bogus result and, because there are no compiler warnings (another wtf), you will know nothing of this until things fail at runtime.</p>
<p>With a sum type, like <code>Either error result</code>, that just can’t happen.</p></li>
<li><p><strong>No separation of pure code from effectful code</strong></p>
<p>It is very nice to know, just by looking at the type of a function, that it <em>cannot</em> perform any side-effects. Go’s type system doesn’t do that.</p></li>
</ul>
<h3 id="the-tooling-is-bad">The tooling is bad</h3>
<p>Haskell gets a lot of criticism for bad tooling, but I think it’s worlds ahead of Go in some cases.</p>
<ul>
<li><p><strong>Godoc makes it really difficult to write good documentation</strong></p>
<p>Godoc groups bindings by type, and then sorts alphabetically. Code is not written like that, code is written with related functions in proximity to each other. The source order is <em>almost always</em> better than how godoc sorts things.</p>
<p>Also, <a href="https://github.com/golang/go/issues/7873">godoc doesn’t even support lists</a>:</p>
<blockquote>
<p>Previous proposals similar to this have been rejected on grounds that it’s a slippery slope from this to Markdown or worse.</p>
</blockquote>
<p>I think that comment is particularly discouraging. Because the developers don’t like Markdown (and similar languages), they refuse to add even the most basic of formatting to godoc.</p></li>
<li><p><strong>There is nothing like GHC’s heap profiling</strong></p>
<p>Go has a snapshot-based memory profiler. You can take a snapshot at a point in time, and see which functions and types are taking up the heap space. However, there is <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/profiling.html#profiling-memory-usage">nothing like this</a>.</p>
<p>Being able to see not only a snapshot, but also how things have changed over time, is incredibly useful for spotting memory leaks. If all you have is a snapshot, all you can really say is “well, the number of allocated <code>Foo</code>s looks a bit high, is that right?” With a graph you can say “the number of allocated <code>Foo</code>s is increasing when it shouldn’t be.”</p></li>
<li><p><strong>There is (was?) nothing like ThreadScope</strong></p>
<p><a href="https://wiki.haskell.org/ThreadScope">ThreadScope</a> is a tool for profiling performance of concurrent Haskell programs. It shows which Haskell threads are running on which OS threads, when garbage collection happens, and a bunch of other information.</p>
<p>If things are slower than expected, it’s great: you can see <em>exactly</em> how things are executing. Go doesn’t <em>currently</em> have anything like it, although towards the end of Dave Cheney’s <strong>Seven ways to profile Go applications</strong> talk at <a href="http://golanguk.com/">GolangUK</a>, he did whip out something which looked rather like ThreadScope (sadly, a video isn’t up at the time of writing, that I can see).</p></li>
</ul>
<h3 id="zero-values-are-almost-never-what-you-want">Zero values are almost never what you want</h3>
<p>Go avoids the issue of uninitialised memory by having “zero values”. If you declare a variable of type <code>int</code>, but don’t give it a value, it gets the value 0. Simple.</p>
<p>Except that that’s almost never what you want.</p>
<p>What is a sensible default value for a type? Well, it depends on what you’re using it for! Sometimes there isn’t a sensible default, and not initialising a value should be an error. You can’t define a zero value for your own types, so you’re kind of stuck.</p>
<p>Zero values caused so many problems over the summer, because everything would <em>appear</em> to be fine, then it suddenly breaks because the zero value wasn’t sensible for its context of use. Perhaps it’s an unrelated change that causes things to break (like a struct getting an extra field).</p>
<p>I would much rather:</p>
<ol type="1">
<li>Drop the syntax for declaring a variable without giving it a value.</li>
<li>Make it an error to not initialise a struct field.</li>
</ol>
<h3 id="lots-of-boilerplate">Lots of boilerplate</h3>
<p>The cause of the lots of code generation, I feel.</p>
<ul>
<li><p>Because you have to check error values, if you want to perform a sequence of possibly-erroring computations, where the successful result of one feeds into the next, there is a lot of typing. In Haskell, you’d just use the <code>Either</code> monad.</p></li>
<li><p>If you want to sort a slice, because there are no generics, you need to wrap the slice in another type and implement three methods on that type. So that’s four lines of code to sort a slice of uints, four lines to sort a slice of uint8s, …</p></li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memo.barrucadu.co.uk/three-months-of-go.html">https://memo.barrucadu.co.uk/three-months-of-go.html</a></em></p>]]>
            </description>
            <link>https://memo.barrucadu.co.uk/three-months-of-go.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986132</guid>
            <pubDate>Wed, 04 Nov 2020 02:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Patching macOS Sketch.App for Unlimited Trial in Ghidra]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24986087">thread link</a>) | @delduca
<br/>
November 3, 2020 | https://duraki.github.io/posts/o/20200214-sketch.app-patch-in-ghidra.html | <a href="https://web.archive.org/web/*/https://duraki.github.io/posts/o/20200214-sketch.app-patch-in-ghidra.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
    
      <p><code>sketch.app</code><code>macos</code><code>osx</code><code>reverseengineering</code><code>ghidra</code>
        <a>night</a>
      </p>

      <hr><h2 id="intro"><a href="#intro"></a>Intro</h2>
<p>It is a wonderful day. A Valentine to precise (14/02/2020). I've spent most of the day with my waifu, enjoying little bit of snow and a cup of coffee. Exchanging each other our gifts (just like in the days we were younger). Therefore, this post is also contribution to her.</p>
<blockquote>
<p>Dedicated to my wife, Ara.</p>
</blockquote>
<p>Inhere, I will show you how easily is to bypass a SketchApp Trial, using nothing more but a Ghidra SRE [1], and a little bit of thinkering. I'm writing this for educational purpose only, but we all have to admit <strong>Sketch.app</strong> is a bit <em>too expensive</em>.  The version I'm working on is <code>Sketch v63.1</code> (latest update).</p>
<h2 id="warming-up"><a href="#warming-up"></a>Warming up</h2>
<p>I highly advice you to create a backup of your Sketch.app (later refered only as <code>Sketch</code>) executable. The usual location for this executable is in <code>/Applications/Sketch.app/Contents/MacOS</code>. The only thing you have to do is copy <code>Sketch</code> in the same directory with a different name.</p>
<p><img src="https://duraki.github.io/images/posts/sketch-how-to-copy.png" alt="Its always good to backup"></p>
<p>Open up Ghidra and create a new project importing Sketch executable from above views. To import, just drag your executable to project view in Ghidra. Refer to Ghidra docs or this [2] phenomenal video by <a href="https://twitter.com/ghidraninja">Ghidra Ninja</a> to learn more about Ghidra basics. This will ease up your reverse engineering if you need to stop and continue to work later on. Now double click on the <code>Sketch</code> from Ghidra project three and let Ghidra analyze the project in full (may take a couple of minutes).</p>
<p><img src="https://duraki.github.io/images/posts/ghidra-sketch-project.png" alt="Sketch.App in Ghidra"></p>
<h2 id="finding-the-trial-implementation"><a href="#finding-the-trial-implementation"></a>Finding the Trial implementation</h2>
<p>There are different ways to find where the trial implementation takes a place. The first and foremost is using XREF string <code>trial days remaining</code> which is shown while starting up the Sketch. The other way is searching for string <code>BCLicenseManager</code> in <code>Symbol Tree</code> window. Since the above string is directly referencing to method <code>numberOfDaysLeftInTrialMode</code>, we can also search for that string excatly in the same window. </p>
<p><img src="https://duraki.github.io/images/posts/ghidra-search-string.png" alt="Method search in Ghidra Project Tree"></p>
<p>When we point Ghidra to this function, we can see the next pseudo-code; which accepts two parameters. The interesting parameter is <code>param_1</code>. The strict business of this parameter is to refer which kind of license is in use. Two options are available in Sketch, if you follow the references: <code>BCRegularLicense</code>, and <code>BCCloudLicense</code>. One is used for offline activation, and the other is used for cloud-based activation. So this <code>BCLicenseManager</code> class has license selector, that returns some license instance.</p>
<pre><code>long_long numberOfDaysLeftInTrialMode(ID param_1,SEL param_2)
{
  ...

  puVar1 = _objc_msgSendSuper2
  uVar3 = (*(code *)_objc_msgSendSuper2)(param_1,<span>"license"</span>)
  uVar3 = _objc_retainBlock(uVar3)
  (*(code *)puVar1)(uVar3,<span>"remainingTimeInterval"</span>)
  uVar4 = (*(code *)puVar1)(&amp;_OBJC_CLASS___NSDate,<span>"dateWithTimeIntervalSinceNow:"</span>)
  uVar4 = _objc_retainBlock(uVar4)
  (*(code *)_objc_retain)(uVar3)
  uVar3 = (*(code *)puVar1)(&amp;_OBJC_CLASS___NSCalendar,<span>"currentCalendar"</span>)
  uVar3 = _objc_retainBlock(uVar3)
  uVar5 = (*(code *)puVar1)(&amp;_OBJC_CLASS___NSDate,<span>"date"</span>)
  uVar5 = _objc_retainBlock(uVar5)
  uVar6 = (*(code *)puVar1)(uVar3,<span>"components:fromDate:toDate:options:"</span>,<span>0x10</span>,uVar5,uVar4,<span>0</span>)
  uVar6 = _objc_retainBlock(uVar6)
  puVar2 = _objc_retain
  (*(code *)_objc_retain)(uVar5)
  (*(code *)puVar2)(uVar3)
  lVar7 = (*(code *)puVar1)(uVar6,<span>"day"</span>)
  (*(code *)puVar2)(uVar6)
  (*(code *)puVar2)(uVar4)
  return lVar7
}</code></pre><p>Next, we have a call to function <code>remainingTimeInterval</code>, and later on, a calculation used for using remaining time through <code>currentCalendar</code> and <code>dateWithTimeIntervalSinceNow</code>. If we search for method called first (<code>remainingTimeInterval</code>), we can see we were pretty right about two possible license classes references through <code>BCLicenseManager</code>.</p>
<p><img src="https://duraki.github.io/images/posts/ghidra-search-remainingTimeInterval.png" alt="remainingTimeInterval visible in two classes"></p>
<p>We will work with-in <code>BCRegularLicense</code> since we don't need to deal with cloud protection and adding stuff to <code>/etc/hosts</code>. Lets see what is inside. We have some interesting functions in there called through in: <code>validityInterval</code>, which basically works with <code>endTime</code> (when license should expire) and combination of <code>networkTime/currentTime</code>. We also have <code>isValid</code> method notifying impl. if license is still available for use.</p>
<pre><code>double remainingTimeInterval(ID param_1,SEL param_2)
{
  ...
  puVar2 = _objc_msgSendSuper2
  uVar1 = (*(code *)_objc_msgSendSuper2)(param_1,<span>"validityInterval"</span>)
  uVar4 = _objc_retainBlock(uVar1)
  uVar1 = (*(code *)puVar2)(uVar4,<span>"endDate"</span>)
  uVar1 = _objc_retainBlock(uVar1)
  uVar6 = (*(code *)puVar2)(param_1,<span>"networkTime"</span>)
  uVar5 = _objc_retainBlock(uVar6)
  uVar6 = (*(code *)puVar2)(uVar5,<span>"currentDate"</span>)
  uVar6 = _objc_retainBlock(uVar6)
  (*(code *)puVar2)(uVar1,<span>"timeIntervalSinceDate:"</span>,uVar6)
  puVar2 = _objc_retain
  (*(code *)_objc_retain)(uVar6)
  (*(code *)puVar2)(uVar5)
  (*(code *)puVar2)(uVar1)
  (*(code *)puVar2)(uVar4)
  cVar3 = (*(code *)_objc_msgSendSuper2)(param_1,<span>"isValid"</span>)
  auVar7 = ZEXT816(<span>0</span>)
  if (cVar3 != <span>'\0'</span>) {
    auVar7 = ZEXT816(<span>extraout_XMM0_Qa);
</span>  }
  auVar7 = maxsd(auVar7,ZEXT816(<span>0</span>))
  return <span>SUB168(auVar7,0);
</span>}</code></pre><p>Lets see what other methods are available in this class named <code>BCRegularLicense</code>. First, filter the Symbol Tree window to reflect the name and once found, scroll to <code>method_list_t</code> where you will right click on it and use Show Reference To.</p>
<p><img src="https://duraki.github.io/images/posts/ghidra-lm-methodlist.png" alt="List Method for Class"></p>
<p>If you scroll down a bit in a Assembly View window, you will find <code>isExpired</code> listed. Lets see what is inside.</p>
<p><img src="https://duraki.github.io/images/posts/isExpired-method.png" alt="isExpired Method in BCRegularLicense"></p>
<pre><code>char isExpired(ID param_1,SEL param_2)
{
  ... 

  <span>if</span> (<span>lVar4</span> == <span>0</span>) {                                            // expired
    <span>bVar6</span> = <span>true</span>;
  }
  <span>else</span> {                                                                // yet to expired
    <span>uVar3</span> = (*(code *)_objc_msgSendSuper2)(param_1,<span>"networkTime"</span>);
    <span>uVar3</span> = _objc_retainBlock(uVar3);
    <span>uVar5</span> = (*(code *)puVar1)(uVar3,<span>"currentDate"</span>);
    <span>uVar5</span> = _objc_retainBlock(uVar5);
    <span>cVar2</span> = (*(code *)puVar1)(lVar4,<span>"containsDate:"</span>,uVar5);
    <span>puVar1</span> = _objc_retain;
    <span>bVar6</span> = <span>cVar2</span> == '\<span>0</span>';
    (*(code *)_objc_retain)(uVar5);
    (*(code *)puVar1)(uVar3);
  }
  (*(code *)_objc_retain)(lVar4);
  return (char)bVar6;
}</code></pre><p>We basically have a simple method to check if the trial is expired or not. </p>
<h2 id="pathching-it-up"><a href="#pathching-it-up"></a>Pathching it up</h2>
<p>If we follow the about <code>bVar6</code>, it can be either <code>true</code> for expired license, or <code>false</code> for unexpired license. Go to this method in Ghidra Listing (Dissasemble) and find a ASM function which moves value of <code>0x1</code> (true) to R12B (<code>bVar6</code>), at address <code>0x1004a2a50</code>.</p>
<pre><code>...
1004a2a4b <span>41</span> ff d5        <span>CALL</span>       <span>R13</span>=&gt;__stubs::_objc_release                   undefined _objc_release()
1004a2a4e eb <span>03</span>           <span>JMP</span>        LAB_1004a2a53
                           LAB_1004a2a50                                   XREF[<span>1</span>]:     1004a29ec(j)  
1004a2a50 <span>41</span> b4 <span>01</span>        <span>MOV</span>        <span>R12B</span>,<span>0x1</span></code></pre><p>To patch your executable, right click on the instruction on this address and click Patch Instruction, or rather you can select the address and press keyboard shortcut <code>Shift+Command+G</code>. Patch this instruction to always return <code>0x0</code> (false), meaning the trial will never expire. See below picture for patched ASM instruction.</p>
<p><img src="https://duraki.github.io/images/posts/isExpired-patching.png" alt="isExpired Patching"></p>
<p>At address <code>0x1004a2a4e</code> we see initial JMP instruction which jumps (goto) checking procedure. We need to patch this instruction to jump to our patch at <code>0x1004a2a50</code>. The final code assembly looks like this.</p>
<pre><code><span>1004</span>a2a48 <span>4</span>c <span>89</span> ff        MOV        param_1,R15
<span>1004</span>a2a4b <span>41</span> ff d5        CALL       R13=&gt;__stubs::_objc_release                      undefined _objc_release()
<span>1004</span>a2a4e eb <span>00</span>           JMP        LAB_1004a2a50                                    Jump to return `false` instruction   -+
                     LAB_1004a2a50                                   XREF[<span>2</span>]:         .......................               |
<span>1004</span>a2a50 <span>41</span> b4 <span>00</span>        MOV        R12B,<span>0x0</span>                                         Always return `false` on isExpired  &lt;-+
<span>1004</span>a2a53 <span>4</span>c <span>89</span> f7        MOV        param_1,R14
<span>1004</span>a2a56 ff <span>15</span> ec        CALL       qword ptr [-&gt;__stubs::_objc_release]             undefined _objc_release()
         <span>68</span> <span>12</span> <span>00</span></code></pre><h2 id="bypassing-sketch-code-signature"><a href="#bypassing-sketch-code-signature"></a>Bypassing Sketch Code Signature</h2>
<p>We are not yet done. The Sketch tries to be smart on us; it checks code signature, meaning if the code signature is not valid, it will exit upon running. Since we patched the binary, the signature of the app will be invalid. But similary to other anti-crack techniques, this one is easy to tackle down. </p>
<p>While inside your Ghidra project, go to <code>0x1004a1724</code> in Dissasemble view, and you will see this code.</p>
<pre><code><span>1004</span>a1736 <span>85</span> db           TEST       EBX,EBX
<span>1004</span>a1738 <span>0</span>f <span>85</span> <span>58</span>        JNZ        LAB_1004a1896
         <span>01</span> <span>00</span> <span>00</span></code></pre><hr>

<p><strong>Update:</strong> I was asked by a fellow follower (@kiwamizamurai) on my <a href="https://twitter.com/0xduraki/status/1228682677106114561">Twitter</a> post, how I've found this address.</p>
<p><img src="https://duraki.github.io/images/posts/sketch-update-codesign.png" alt="Twitter Question"></p>
<p>I've found this address by setting up a breakpoint just before the <code>exit</code> syscall and then going step by step in dissasembler. If you try to open up Sketch.app with bad signature you'd get a system error with BAD_CODE_SIGNATURE code. Therefore, I knew the error was due to bad signature. Then I checked which instruction reference to this call. </p>
<hr>

<p>Anyway, At the address <code>0x1004a1738</code>, is instruction JNZ (Jump not equal), which calls code signature method and exit the Sketch. Just replace this jump to the next instruction at <code>0x1004a173e</code>. </p>
<p><img src="https://duraki.github.io/images/posts/sketchapp-jumpity-jump.png" alt="Sketch.App Code Signature #1"></p>
<pre><code> 1004a1736 <span>85</span> <span>db</span>           <span>TEST</span>       <span>EBX</span>,<span>EBX</span>
 1004a1738 0f <span>85</span> <span>00</span>        <span>JNZ</span>        LAB_1004a173e
           <span>00</span> <span>00</span> <span>00</span>
                       LAB_1004a173e                                   XREF[<span>1</span>]:     1004a1738(j)  
 1004a173e <span>49</span> <span>89</span> c7        <span>MOV</span>        <span>R15</span>,<span>RAX</span>                                       Jumps here
 1004a1741 <span>4d</span> <span>89</span> f4        <span>MOV</span>        <span>R12</span>,<span>R14</span></code></pre><p>Likewise, edit JZ (Jump equal) at address <code>0x1004a1879</code> to instruction JNZ. </p>
<pre><code>                     LAB_1004a186b                                   XREF[<span>1</span>]:     1004a180f(j)  
1004a186b 4c <span>89</span> ff        <span>MOV</span>        <span>RDI</span>,<span>R15</span>
1004a186e <span>41</span> ff d6        <span>CALL</span>       <span>R14</span>=&gt;__stubs::_objc_release                      undefined _objc_release()
1004a1871 4c <span>89</span> ef        <span>MOV</span>        <span>RDI</span>,<span>R13</span>
1004a1874 <span>41</span> ff d6        <span>CALL</span>       <span>R14</span>=&gt;__stubs::_objc_release                      undefined _objc_release()
1004a1877 <span>84</span> <span>db</span>           <span>TEST</span>       <span>BL</span>,<span>BL</span>
1004a1879 <span>74</span> <span>1b</span>        …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://duraki.github.io/posts/o/20200214-sketch.app-patch-in-ghidra.html">https://duraki.github.io/posts/o/20200214-sketch.app-patch-in-ghidra.html</a></em></p>]]>
            </description>
            <link>https://duraki.github.io/posts/o/20200214-sketch.app-patch-in-ghidra.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24986087</guid>
            <pubDate>Wed, 04 Nov 2020 02:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intelligence Companies Seeking to Subjugate the World with AI Singularity]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24984340">thread link</a>) | @l33tbro
<br/>
November 3, 2020 | https://unlimitedhangout.com/2020/11/reports/darktrace-and-cybereason-the-intelligence-front-companies-seeking-to-subjugate-the-world-with-the-a-i-singularity/ | <a href="https://web.archive.org/web/*/https://unlimitedhangout.com/2020/11/reports/darktrace-and-cybereason-the-intelligence-front-companies-seeking-to-subjugate-the-world-with-the-a-i-singularity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We have all been dreaming, a dream where you can float or glide across your dreamscape effortlessly. This leads to the feeling of trepidation, as though you have the ability to let go, and if you do let go, you’ll either soar or fall.&nbsp;</p><p>We’re now at a point in history where either the coming events will be studied for thousands of years, or it will be remembered as the point where we lost our humanity completely. Artificial Intelligence (A.I.) technology has entered a new phase over the past several years, where instead of the A.I. algorithms learning from humans, they are now teaching themselves, changing their own algorithms as they learn. We are on the cusp of letting go of control entirely, so early on, because of a few small companies who have quietly been given free reign under the guise of “protecting” our digital lives, all within a tech sector that is moving so fast that we can no longer see what’s just around the bend.&nbsp;</p><p>The entire free thinking population of Earth would love a little more time to discuss such epochal change. However, the technocrats and scientists, supported by venture capitalists, are already putting into action the future before the masses have a chance to even consider discussing its consequences. With very little legislation governing A.I. technologies on the books, our governments are eager to get every tech pioneer inventing whilst there is no accountability for any resulting harm. We’re not talking major societal disruption, we’re talking about a potential extinction level event of our own creation. Where we should be taking cautious baby steps, instead we’re expecting to fly just by letting go.</p><p>We are about to experience a monumental change in technology, starting with “next-generation” cybersecurity that will then move quickly into the unknown. Unsupervised A.I., now running on critical networks throughout the world as a “cybersecurity” product, is evolving its own algorithm without the need for humans to be involved. Meanwhile, the wealthy patrons funding this cutting edge future tech are out in force, working to propel our societies into this new, unexplored and dystopian technological frontier.&nbsp;</p><p>But who are the companies that these eager wealthy venture capitalists are funding to create an autonomous, A.I.-powered cyber defence system like never before? Are they even companies at all when we consider their deep and direct ties to intelligence agencies? Should these firms instead be reclassified as simply extensions of state intelligence apparatus acting without the restrictions of public accountability?&nbsp;</p><p>Each of these companies have been built by teams of former intelligence operatives, some of who have sat in the highest echelons of the intelligence apparati of their respective countries. MI5 and C.I.A. both carry considerable weight in these sinister sounding enterprises, but it is Israel’s Unit 8200 that are the main group capitalising on this advance into the world-altering realm of unsupervised Artificial Intelligence algorithms.&nbsp;</p><p>Yet, these very companies appear to be selling a defence against a potential apocalypse that they themselves may be responsible for. They have the solutions to everyone’s cyber-woes, or at least that’s the image they wish to portray. Let me introduce you to the most dangerous intelligence operations masquerading as cybersecurity companies on planet Earth. &nbsp;</p><h2 id="darktrace-the-unsupervised-machine-learning-a-i-cybersecurity-solution"><strong>Darktrace – The Unsupervised Machine Learning A.I. Cybersecurity Solution</strong></h2><p>The members of Darktrace are open about their aims. They <a href="https://youtu.be/tiJjt4YNbf4?t=82">talk about publicly held data</a> as though they already have the rights to sell it to anyone around the world. Data is the fuel of the Fourth Industrial Revolution and Darktrace has made almost $2 billion in the data business during its relatively short history, reaching <a href="https://en.wikipedia.org/wiki/Unicorn_(finance)">Unicorn status</a> with great ease. When Darktrace first launched its website in 2013, its description of the company’s vision was entitled, “The New Normal: Learn Human and Machine Behavior to Reduce Cyber Security Risks.” Back then we were less familiar with the term “the new normal,” but now it surrounds us. Darktrace is already active within the NHS, the <a href="https://edition.cnn.com/2018/02/05/tech/darktrace-cybersecurity-immune-system/index.html">U.K. power grid</a>, and many other major parts of Britain’s critical infrastructure and they are rapidly expanding around the globe.</p><p>Dave Palmer was an MI5 anti-terror agent working on the 2012 London Olympics when he and some of his colleagues first bashed out the initial idea for what would become Darktrace. They wanted to create an A.I. cybersecurity system that was based on the human immune system, a system that differed from the traditional, reactive antivirus software approach. This system would look for abnormalities in a computer network’s processes to target a wider range of more sophisticated cyber issues.&nbsp;</p><p>Palmer had spent 14 years working for MI5 and GCHQ in a role creating secure networks for British spies to communicate. He would eventually approach two mathematicians from Cambridge University to help make his dreams reality at the tail end of 2012. These mathematicians were working on projects related to using unsupervised machine learning to teach a computer to have a sense of self, a step that would bring such technology dangerously close to the so-called <a href="https://www.digitaltrends.com/cool-tech/what-is-the-singularity-ai/">singularity</a>. At that point, as critics and proponents of self-aware A.I. alike have warned, that machine intelligence will not only surpass human intelligence, but advance at an incomprehensible rate, which major and world-altering implications.</p><p>In a <a href="https://www.youtube.com/watch?v=USHgnyIGAXI&amp;t=149s"><em>TechCrunch</em> talk in 2016</a>, the freshly installed co-CEO of Darktrace, <a href="https://www.linkedin.com/in/poppy-gustafsson-41464ba0/?originalSubdomain=uk">Poppy Gustafsson</a>, is caught misleading the audience about the company’s origins. She uses the <em>TechCrunch</em> stage to claim that the “spark” for the creation of Darktrace originally came from the mathematicians at Cambridge and downplayed the involvement of intelligence agencies like MI5, GCHQ, and the C.I.A. The <em>TechCrunch</em> moderator, Natasha Lomas, displayed some fine journalistic integrity on this occasion and asked for clarification. “So did the maths research come first and then you got together with the spies. Which way round was it?” asked the intrepid Lomas. Gustafsson squirms a little before saying, “it was exactly that. First the machine learning that was talking about how to critique a computer to help it understand itself. And then it was the, um, experts from the government intelligence agencies who thought ‘ooh, this could be applied to the problem of cybersecurity.’” But that statement was an outright lie and Gustafsson isn’t the most skilled deceiver.</p><p>Gustafsson, who was initially CFO and COO for the fledgling Darktrace, runs the company alongside the other co-CEO Nicole Eagen, an alumnus of Oracle, a major tech company that also has <a href="https://paleofuture.gizmodo.com/larry-ellisons-oracle-started-as-a-cia-project-1636592238">its origins in intelligence</a>. Both parts of Darktrace’s female power duo were brought over from <a href="https://www.invokecapital.com/">Invoke Capital</a> by Darktrace’s initial angel investor and <a href="https://www.darktrace.com/en/advisory-board/">advisory board</a> member, UK billionaire <a href="http://www.drmikelynch.crazybillionaire.org/drmikelynch.php">Dr. Mike Lynch OBE</a>. Describing himself as the <a href="https://www.theguardian.com/business/2019/dec/12/autonomy-founder-mike-lynch-accused-of-lying-in-trial">“UKs answer to Bill Gates“</a>, Dr. Mike Lynch is lauded as one of the most influential investors in the tech sector. His previous successful endeavours had been with Autonomy, a tech firm that has Lynch caught up in a legal wrangle with HP over the fraudulent inflation of its valuation, and Blinkx, a video search company where Lynch was later forced to step down from the board.&nbsp;</p><p>Dr. Mike Lynch’s problems with Hewlett Packard are not to be understated as was made clear in <a href="https://www.telegraph.co.uk/technology/2019/12/09/mike-lynch-prepares-us-extradition-battle-5bn-trial-century/amp/">a Telegraph article</a> that described it as “the trial of the century.” But, before that spectacle can take place, Mike Lynch must first be extradited and his protracted court battle to resist extradition has led to some uncertainty surrounding the future of Darktrace whilst Lynch is still active within the company. It was also <a href="https://news.sky.com/story/goldman-snubs-2bn-darktrace-float-amid-lynch-extradition-battle-12075941">recently reported</a> in the mainstream media that the Wall Street bank Goldman Sachs had declined to take a role in the initial public offering (IPO) of Darktrace due to Mike Lynch’s ongoing extradition battle. &nbsp;</p><p>Yet, Darktrace is not just one man working alone. The company boasts that over 4000 organisations worldwide now rely on Darktrace’s A.I. technologies. With headquarters in San Francisco, US, and Cambridge, UK, <a href="https://www.darktrace.com/en/">Darktrace has over 1300 employees</a> spread across 44 countries and their numbers are rising. And although the connections to the state intelligence agencies are clear and obvious, Darktrace is officially a completely private enterprise with big investors including KKR, Summit Partners, Vitruvian Partners, Samsung Ventures, TenEleven Ventures, Hoxton Ventures, Talis Capital, Invoke Capital and Insight Venture Partners. Sitting alongside the controversial Dr. Mike Lynch OBE on the advisory board for Darktrace are some seriously influential people deeply connected to US and UK intelligence agencies.&nbsp;</p><p>One of the first members appointed to Darktrace’s advisory board was <a href="https://en.wikipedia.org/wiki/Jonathan_Evans,_Baron_Evans_of_Weardale">Jonathan Evans</a>, also referred to as Baron Evans of Weardale. Evans was previously the Director General of MI5, taking over from Dame Eliza Manningham-Buller in 2007 and staying in the most senior intelligence role that the UK has to offer until 2013. After his time as head of MI5, Evans initially joined HSBC Holdings as a non-executive Director, a role he also took up at Ark, a highly secure UK data centre.&nbsp;</p><p>If you were to walk into the advisory boardroom at Darktrace, you could be forgiven for thinking that you were actually attending a U.K. Home Office meeting from the past. The former Home Secretary under Prime Minister Theresa May, Amber Rudd, <a href="https://www.darktrace.com/en/press/2020/326/">became part of Darktrace</a> after her time in government ended in 2019. She is also on the advisory team of Teneo, a consulting firm co-founded and led by <a href="https://www.teneo.com/person/doug-band/">Doug Band</a>, the former advisor to Bill Clinton and close friend of the infamous Jeffrey Epstein. As always, when investigating the murky world of intelligence, many connections to Epstein and his partner Ghislaine Maxwell are revealed. &nbsp;</p><p>With that being said, yet another member of Darktrace’s advisory board also has Epstein/Maxwell links. The C.I.A. stalwart, Alan …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unlimitedhangout.com/2020/11/reports/darktrace-and-cybereason-the-intelligence-front-companies-seeking-to-subjugate-the-world-with-the-a-i-singularity/">https://unlimitedhangout.com/2020/11/reports/darktrace-and-cybereason-the-intelligence-front-companies-seeking-to-subjugate-the-world-with-the-a-i-singularity/</a></em></p>]]>
            </description>
            <link>https://unlimitedhangout.com/2020/11/reports/darktrace-and-cybereason-the-intelligence-front-companies-seeking-to-subjugate-the-world-with-the-a-i-singularity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24984340</guid>
            <pubDate>Tue, 03 Nov 2020 21:44:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Programming Glossary]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24984318">thread link</a>) | @elierotenberg
<br/>
November 3, 2020 | https://elie.rotenberg.io/b/p/modern-programming-glossary | <a href="https://web.archive.org/web/*/https://elie.rotenberg.io/b/p/modern-programming-glossary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><i>Disclaimer: I spent a LOT of time browsing Github, and read a lot of READMEs. This post is a satire, and many great repos / landing pages feature some of the following idioms. I don't mean to offend dedicated maintainers &amp; docs writers, however funny I find dev-targeted marketing tropes.</i></p><p><i><a target="_blank" rel="noopener noreferrer" href="https://github.com/elierotenberg/rotenberg.io/blob/master/posts/modern-programming-glossary.md">Suggestions welcome!</a></i></p><h2><a id="table-of-contents" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#table-of-contents">Table of contents</a></h2><ul><li><a href="#accessible">Accessible</a></li><li><a href="#battle-tested">Battle-tested</a></li><li><a href="#blazingly-fast">Blazingly fast</a></li><li><a href="#bloated">Bloated</a></li><li><a href="#bleeding-edge">Bleeding edge</a></li><li><a href="#cloud-native">Cloud-native</a></li><li><a href="#cloud-ready">Cloud-ready</a></li><li><a href="#configurable">Configurable</a></li><li><a href="#cross-plaform">Cross-plaform</a></li><li><a href="#customizable">Customizable</a></li><li><a href="#entreprise-level">Entreprise-level</a></li><li><a href="#legacy-code">Legacy code</a></li><li><a href="#lightweight">Lightweight</a></li><li><a href="#mobile-first">Mobile-first</a></li><li><a href="#modern">Modern</a></li><li><a href="#modular">Modular</a></li><li><a href="#open-standards">Open standards</a></li><li><a href="#privacy-focused">Privacy-focused</a></li><li><a href="#production-ready">Production-ready</a></li><li><a href="#progressive-web-app">Progressive web app</a></li><li><a href="#responsive">Responsive</a></li><li><a href="#robust">Robust</a></li><li><a href="#scalable">Scalable</a></li><li><a href="#secure">Secure</a></li><li><a href="#serverless">Serverless</a></li><li><a href="#tiny">Tiny</a></li><li><a href="#well-tested">Well-tested</a></li><li><a href="#unified">Unified</a></li><li><a href="#typesafe">Typesafe</a></li><li><a href="#zero-dependencies">Zero-dependencies</a></li></ul><h2><a id="accessible" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#accessible">Accessible</a></h2><p><code>alt</code> attributes on <code>img</code> are encouraged. Some of our components allow <code>aria</code> attributes.</p><p><i>See also: <a href="#responsive">responsive</a>, <a href="#mobile-first">mobile-first</a></i></p><h2><a id="battle-tested" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#battle-tested">Battle-tested</a></h2><p>We used it for the docs website of the project and we haven't received any complains except for browers other than latest Chrome.</p><p><i>See also: <a href="#production-ready">production-ready</a>, <a href="#well-tested">well-tested</a>, <a href="#modern">modern</a></i></p><h2><a id="blazingly-fast" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#blazingly-fast">Blazingly fast</a></h2><p>Fast-enough on our latest-gen Macbook Pros and on the adhoc microbenchmark we have massaged into being faster than <em>&lt;similar project&gt;</em>. We don't support edge cases though.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#lightweight">lightweight</a></i></p><h2><a id="bloated" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#bloated">Bloated</a></h2><p>Handles edge cases we don't.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#lightweight">lightweight</a>, <a href="#tiny">tiny</a></i></p><h2><a id="bleeding-edge" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#bleeding-edge">Bleeding edge</a></h2><p>Only works in latest Chrome with experimental flags enabled and a custom <code>babel</code> plugin. Expect breaking changes without notice every 1-2 months.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#legacy-code">legacy code</a></i></p><h2><a id="cloud-native" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#cloud-native">Cloud-native</a></h2><p>We have written a <code>docker-compose.yml</code> file and it works on AWS. You need to pass secrets as environment variables.</p><p><i>See also: <a href="#cloud-ready">cloud-ready</a>, <a href="#scalable">scalable</a></i></p><h2><a id="cloud-ready" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#cloud-ready">Cloud-ready</a></h2><p>We provide a <code>Dockerfile</code>.</p><p><i>See also: <a href="#cloud-native">cloud-native</a>, <a href="#scalable">scalable</a></i></p><h2><a id="configurable" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#configurable">Configurable</a></h2><p>You will need to copy/paste a subfolder from our <code>examples</code> folder to run it.</p><p><i>See also: <a href="#modular">modular</a></i></p><h2><a id="cross-plaform" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#cross-plaform">Cross-plaform</a></h2><p>Laggy on all Web, Android, iOS and Electron. All versions include 20Mb of Node API polyfills.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#progressive-web-app">progressive web app</a></i></p><h2><a id="customizable" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#customizable">Customizable</a></h2><p>Our JSON configuration interpreter is Turing-complete.</p><p><i>See also: <a href="#configurable">configurable</a>, <a href="#modular">modular</a></i></p><h2><a id="entreprise-level" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#entreprise-level">Entreprise-level</a></h2><p>We provide paid support &amp; services.</p><p><i>See also: <a href="#cloud-native">cloud-native</a></i></p><h2><a id="legacy-code" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#legacy-code">Legacy code</a></h2><p>Code not written by us less than 3 month ago.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#bleeding-edge">bleeding-edge</a></i></p><h2><a id="lightweight" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#lightweight">Lightweight</a></h2><p>With 100Gbps network speed, it takes no more than several seconds to download in NA.</p><p><i>See also: <a href="#tiny">tiny</a>, <a href="#modern">modern</a>, <a href="#blazingly-fast">blazingly-fast</a></i></p><h2><a id="mobile-first" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#mobile-first">Mobile-first</a></h2><p>We have copy-pasted <code>&lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;</code> and it works on our Macbook Pros in latest Chrome emulating iPhone X.</p><p><i>See also: <a href="#mobile-first">mobile-first</a></i></p><h2><a id="modern" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#modern">Modern</a></h2><p>Written in a language we are familiar with, using our own linting conventions. Only works on latest Chrome. Expect breaking changes every 2-3 months.</p><p><i>See also: <a href="#bleeding-edge">bleeding edge</a>, <a href="#legacy-code">legacy code</a></i></p><h2><a id="modular" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#modular">Modular</a></h2><p>Code is spread over 10 different tighly-coupled packages. We expose a <code>plugin</code> configuration option that only accepts our own plugins. Expect breaking plugin API changes every 2-3 months.</p><p><i>See also: <a href="#modern">modern</a>, <a href="#bleeding-edge">bleeding edge</a></i></p><h2><a id="open-standards" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#open-standards">Open standards</a></h2><p>We published the source code of our parser and wrote a README file that looks like an RFC.</p><p><i>See also: <a href="#modular">modular</a></i></p><h2><a id="privacy-focused" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#privacy-focused">Privacy-focused</a></h2><p>You may opt-out of automated backdoor analytics in both your config file and environment variables, and you must do so again every time you update.</p><p><i>See also: <a href="#secure">secure</a></i></p><h2><a id="production-ready" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#production-ready">Production-ready</a></h2><p>Not yet used in production.</p><p><i>See also: <a href="#enterprise-level">entreprise-level</a>, <a href="#modern">modern</a>, <a href="#well-tested">well-tested</a>, <a href="#battle-tested">battle-tested</a></i></p><h2><a id="progressive-web-app" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#progressive-web-app">Progressive web app</a></h2><p>We display a spinner while the 10Mb bundle is downloading.</p><p><i>See also: <a href="#responsive">responsive</a>, <a href="#lightweight">lightweight</a></i></p><h2><a id="responsive" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#responsive">Responsive</a></h2><p>We use <code>display: flex</code> instead of <code>display: block</code> and we have replaced <code>16px</code> with <code>1em</code>.</p><p><i>See also: <a href="#accessible">accessible</a>, <a href="#mobile-first">mobile-first</a></i></p><h2><a id="robust" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#robust">Robust</a></h2><p>It works on our machines.</p><p><i>See also: <a href="#well-tested">well-tested</a>, <a href="#battle-tested">battled-tested</a>, <a href="#production-ready">production-ready</a>, <a href="#enterprise-level">entreprise-level</a></i></p><h2><a id="scalable" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#scalable">Scalable</a></h2><p>You need a Kubernetes cluster with at least 3 nodes to serve your blog. We also provide paid hosting, by the way.</p><p><i>See also: <a href="#enterprise-level">enterprise-level</a>, <a href="#cloud-native">cloud-native</a>, <a href="#cloud-ready">cloud-ready</a></i></p><h2><a id="secure" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#secure">Secure</a></h2><p>We only use <code>eval</code> sparingly and we embed a 10Mb third party HTML sanitizer.</p><p><i>See also: <a href="#enterprise-level">entreprise-level</a>, <a href="#typesafe">typesafe</a></i></p><h2><a id="serverless" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#serverless">Serverless</a></h2><p>You need an AWS server to run it.</p><p><i>See also: <a href="#scalable">scalable</a>, <a href="#cloud-native">cloud-native</a>, <a href="#cloud-ready">cloud-ready</a></i></p><h2><a id="tiny" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#tiny">Tiny</a></h2><p>All code is inlined in a single 1k LOC file.</p><p><i>See also: <a href="#lightweight">lightweight</a>, <a href="#zero-dependencies">zero-dependencies</a></i></p><h2><a id="well-tested" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#well-tested">Well-tested</a></h2><p>We have written some tests and have more than 50% code coverage.</p><p><i>See also: <a href="#battle-tested">battle-tested</a>, <a href="#robust">robust</a>, <a href="#production-ready">production-ready</a></i></p><h2><a id="unified" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#unified">Unified</a></h2><p><a target="_blank" rel="noopener noreferrer" href="https://xkcd.com/927"><img src="https://imgs.xkcd.com/comics/standards.png" alt="Standards"></a></p><p><i>See also: <a href="#open-standards">open standards</a></i></p><h2><a id="typesafe" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#typesafe">Typesafe</a></h2><p>We have prefixed all occurences of <code>any</code> with <code>// eslint-ignore-next-line</code>.</p><p><i>See also: <a href="#secure">secure</a></i></p><h2><a id="zero-dependencies" href="https://elie.rotenberg.io/b/p/modern-programming-glossary#zero-dependencies">Zero-dependencies</a></h2><p>Our dependencies are embeded in a <code>vendor</code> folder, and/or we have custom implementations of common functions that don't support edge cases, most of which are copy/pasted from StackOverflow without attribution.</p><p><i>See also: <a href="#tiny">tiny</a>, <a href="#lightweight">lightweight</a>, <a href="#modular">modular</a>, <a href="#modern">modern</a></i></p></div></div>]]>
            </description>
            <link>https://elie.rotenberg.io/b/p/modern-programming-glossary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24984318</guid>
            <pubDate>Tue, 03 Nov 2020 21:41:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Worrying and Git YOLO]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24984273">thread link</a>) | @jamescampbell
<br/>
November 3, 2020 | https://www.jamescampbell.us/posts/yolo-git-2020/ | <a href="https://web.archive.org/web/*/https://www.jamescampbell.us/posts/yolo-git-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article">
        <p>Git yolo has changed my life for the better. It saves me tons of time. You never have to type in a commit comment again.</p>
<p>Here is how to get the yolo alias working:</p>
<p>You need to edit your gitconfig dotfile that is located at <code>~/.gitconfig</code>.</p>
<p>Mine before:</p>
<pre><code>$ cat ~/.gitconfig
# This is Git's per-user configuration file.
[user]
# Please adapt and uncomment the following lines:
	name = jamesacampbell
	email = james@jamescampbell.us
[url "git@gitlab.com:"]
		insteadOf = https://gitlab.com/
</code></pre><p>Mine after:</p>
<pre><code>$ cat ~/.gitconfig
# This is Git's per-user configuration file.
[user]
# Please adapt and uncomment the following lines:
	name = jamesacampbell
	email = james@jamescampbell.us
[url "git@gitlab.com:"]
		insteadOf = https://gitlab.com/
[alias]
yolo = !git add -A &amp;&amp; git commit -am \"`curl -s http://whatthecommit.com/index.txt `\" &amp;&amp; git push -f origin master
</code></pre><p>This has saved me <em>hours</em> over the past year. It uses random text snippets from <a href="http://whatthecommit.com/">http://whatthecommit.com</a> for your commit statements. So be prepared to have some silly commit statements.</p>
<p>Enjoy!</p>

    </article></div>]]>
            </description>
            <link>https://www.jamescampbell.us/posts/yolo-git-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24984273</guid>
            <pubDate>Tue, 03 Nov 2020 21:35:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bevy 0.3: game engine built in Rust]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24983956">thread link</a>) | @_cart
<br/>
November 3, 2020 | https://bevyengine.org/news/bevy-0-3/ | <a href="https://web.archive.org/web/*/https://bevyengine.org/news/bevy-0-3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://bevyengine.org/news/bevy-0-3/sheep_game.png"></p>
      
    
  </div><div><p>A little over a month after releasing Bevy 0.2, and thanks to <strong>59</strong> contributors, <strong>122</strong> pull requests, and our <a href="https://github.com/sponsors/cart"><strong>generous sponsors</strong></a>, I'm happy to announce the <strong>Bevy 0.3</strong> release on <a href="https://crates.io/crates/bevy">crates.io</a>!</p>
<p>For those who don't know, Bevy is a refreshingly simple data-driven game engine built in Rust. You can check out <a href="https://bevyengine.org/learn/book/getting-started/">Quick Start Guide</a> to get started. Bevy is also free and open source forever! You can grab the full <a href="https://github.com/bevyengine/bevy">source code</a> on GitHub.</p>
<p>Here are some of the highlights from this release:</p>
<h2 id="initial-android-support">Initial Android Support</h2>

<p>You can try out the <a href="https://github.com/bevyengine/bevy/tree/master/examples/android">Bevy Android example</a> by following the <a href="https://github.com/bevyengine/bevy/blob/master/examples/README.md#android">instructions here</a>. While many things work, please note that this is <em>very hot</em> off the presses. Some features will work and others probably won't. Now is a great time to dive in and help us close the gaps!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/android.png" alt="android"></p>
<p>This was a massive group effort that spanned multiple projects:</p>
<ul>
<li>Bevy: rewrote bevy-glsl-to-spirv to support android / static libraries (@PrototypeNM1, @enfipy)</li>
<li>Bevy: <code>bevy_asset</code> backend using Android Asset Manager (@enfipy)</li>
<li>Bevy: Touch support (@naithar)</li>
<li>Bevy: Texture format fix (@enfipy)</li>
<li>Bevy: UI touch fixes, touch force, and android example (@enfipy)</li>
<li>Cpal: android audio support (@endragor) </li>
<li>android-ndk-rs / cargo-apk: fix to support Bevy project structure (@PrototypeNM1)</li>
</ul>
<h2 id="initial-ios-support">Initial iOS Support</h2>
<p>authors: @simlay, @MichaelHills, @Dash-L, @naithar</p>
<p>Bevy can now run on iOS!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/ios.png"></p><p>You can try out the <a href="https://github.com/bevyengine/bevy/tree/master/examples/ios">Bevy iOS example</a> by following the <a href="https://github.com/bevyengine/bevy/tree/master/examples#ios">instructions here</a>. This one is also hot off the presses: some features will work and others probably won't.</p>
<p>This was another large group effort that spanned multiple projects:</p>
<ul>
<li>Bevy: XCode Project / Example (@simlay with help from @MichaelHills)</li>
<li>Bevy: Runtime shader compilation using shaderc (@MichaelHills)</li>
<li>Bevy: Rodio upgrade (@Dash-L)</li>
<li>Bevy: Touch support (@naithar)</li>
<li>Winit: Fix iOS portrait view (@MichaelHills) </li>
<li>RustAudio: iOS support (@simlay and @MichaelHills)</li>
</ul>
<p>Known issues:</p>
<ul>
<li><a href="https://github.com/RustAudio/cpal/pull/485">Audio doesn't quite work yet</a></li>
</ul>
<h2 id="wasm-asset-loading">WASM Asset Loading</h2>
<p>authors: @mrk-its (and ported to the new AssetIo by @cart)</p>
<p>@mrk-its has been hard at work on expanding Bevy's WASM support. In this release we landed WASM asset loading. You can now load assets when you publish to WASM just like you would on any other platform:</p>
<pre><code><span>asset_server</span><span>.</span><span>load</span><span>("</span><span>sprite.png</span><span>");
</span></code></pre>
<p>If the asset hasn't already been loaded, this will make a <code>fetch()</code> request to retrieve the asset over HTTP.</p>
<p>@mrk-its has also been building a custom WebGL2 <code>bevy_render</code> backend. It is already pretty usable, but its not <em>quite</em> ready yet. Expect more news on this soon!</p>
<h2 id="touch-input">Touch Input</h2>
<p>authors: @naithar</p>
<p>Bevy now has support for touches:</p>
<pre><code><span>fn </span><span>touch_system</span><span>(</span><span>touches</span><span>: </span><span>Res</span><span>&lt;</span><span>Touches</span><span>&gt;) {
    </span><span>// you can iterate all current touches and retrieve their state like this:
    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter</span><span>() {
        </span><span>println!</span><span>("</span><span>active touch: {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_pressed</span><span>() {
        </span><span>println!</span><span>("</span><span>just pressed {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_released</span><span>() {
        </span><span>println!</span><span>("</span><span>just released {:?}</span><span>",</span><span> touch</span><span>);
    }

    </span><span>for</span><span> touch </span><span>in</span><span> touches</span><span>.</span><span>iter_just_cancelled</span><span>() {
        </span><span>println!</span><span>("</span><span>just cancelled {:?}</span><span>",</span><span> touch</span><span>);
    }
}
</span></code></pre>
<p>You can also consume raw touch events using the <code>Events&lt;TouchInput&gt;</code> resource.</p>
<h2 id="asset-system-improvements">Asset System Improvements</h2>
<p>authors: @cart</p>
<h3 id="asset-handle-reference-counting">Asset Handle Reference Counting</h3>
<p>Assets are now automatically freed when their "handle reference count" reaches zero. This means you no longer need to think about freeing assets manually:</p>
<pre><code><span>// Calling load() now returns a strong handle:
</span><span>let</span><span> handle </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>sprite.png</span><span>");

</span><span>// Note that you no longer need to unwrap() loaded handles. Ergonomics for the win!

// Cloning a handle increases the reference count by one
</span><span>let</span><span> second_handle </span><span>=</span><span> handle</span><span>.</span><span>clone</span><span>();

</span><span>// Spawn a sprite and give it our handle
</span><span>commands</span><span>.</span><span>spawn</span><span>(</span><span>SpriteComponents </span><span>{
</span><span>    material</span><span>:</span><span> materials</span><span>.</span><span>add</span><span>(</span><span>handle</span><span>.</span><span>into</span><span>()),
    ..</span><span>Default</span><span>::</span><span>default</span><span>()
});

</span><span>// Later in some other system:
</span><span>commands</span><span>.</span><span>despawn</span><span>(</span><span>sprite_entity</span><span>);

</span><span>// There are no more active handles to "sprite.png", so it will be freed before the next update
</span></code></pre><h3 id="asset-loaders-can-now-load-multiple-assets">Asset Loaders can now load multiple assets</h3>
<p>In past releases, <code>AssetLoaders</code> could only produce a single asset of a single type. In <strong>Bevy 0.3</strong>, they can now produce any number of assets for any type. The old behavior was extremely limiting when loading assets like GLTF files, which might produce many meshes, textures, and scenes. </p>
<h3 id="sub-asset-loading">Sub-Asset Loading</h3>
<p>Sometimes you only want to load a specific asset from an asset source. You can now load sub assets like this:</p>
<pre><code><span>// Mesh0/Primitive0 references the first mesh primitive in "my_scene.gltf"
</span><span>let</span><span> mesh </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>my_scene.gltf#Mesh0/Primitive0</span><span>");
</span></code></pre><h3 id="assetio-trait">AssetIo Trait</h3>
<p>The <code>AssetServer</code> is now backed by the <code>AssetIo</code> trait. This allows us to load assets from whatever storage we want. This means on desktop we now load from the filesystem, on Android we use the Android Asset Manager, and on the web we make HTTP requests using the <code>fetch()</code> api.</p>
<h3 id="asset-dependencies">Asset Dependencies</h3>
<p>Assets can now depend on other assets, which will automatically be loaded when the original asset is loaded. This is useful when loading something like a "scene" which might reference other asset sources. We utilize this in our new GLTF loader.</p>
<h3 id="removed-assetserver-load-sync">Removed AssetServer::load_sync()</h3>
<p>This might rustle some feathers, but <code>AssetServer::load_sync()</code> had to go! This api wasn't WASM friendly, encouraged users to block game execution for the sake of convenience (which causes "hitching"), and was incompatible with the new AssetLoader api. Asset loading is now always asynchronous. Users of <code>load_sync()</code> should instead <code>load()</code> their assets, check load status in their systems, and change game state accordingly. </p>
<h2 id="gltf-scene-loader">GLTF Scene Loader</h2>
<p>authors: @cart</p>
<p>Up until this point, the GLTF loader was painfully limited. It could only load the first mesh with a single texture in a GLTF file. For <strong>Bevy 0.3</strong>, we took advantage of the asset system improvements to write a new <code>GltfLoader</code> that loads GLTF files as Bevy <code>Scenes</code>, along with all meshes and textures in the files.</p>
<p>Here's Bevy loading the Khronos Flight Helmet example, which consists of multiple meshes and textures!</p>
<p><img src="https://bevyengine.org/news/bevy-0-3/flight_helmet.png" alt="flight helmet"></p>
<p>Here is the complete code for a system that loads a GLTF file and spawns it as a scene:</p>
<pre><code><span>fn </span><span>load_gltf_system</span><span>(</span><span>mut </span><span>commands</span><span>:</span><span> Commands, </span><span>asset_server</span><span>: </span><span>Res</span><span>&lt;</span><span>AssetServer</span><span>&gt;) {
    </span><span>let</span><span> scene_handle </span><span>=</span><span> asset_server</span><span>.</span><span>load</span><span>("</span><span>models/FlightHelmet/FlightHelmet.gltf</span><span>");
</span><span>    commands</span><span>.</span><span>spawn_scene</span><span>(</span><span>scene_handle</span><span>);
}
</span></code></pre><h2 id="bevy-ecs-improvements">Bevy ECS Improvements</h2>
<p>authors: @cart</p>
<h3 id="query-ergonomics">Query Ergonomics</h3>
<p>In this release I finally was able to remove the one thing I <em>truly despised</em> in Bevy ECS. In previous versions of Bevy, iterating over the components in a <code>Query</code> looked like this:</p>
<pre><code><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in &amp;</span><span>mut</span><span> query</span><span>.</span><span>iter</span><span>() {
    </span><span>// The `&amp;mut` here just felt so unnatural
</span><span>}

</span><span>// Or if you preferred you could do this
</span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> query</span><span>.</span><span>iter</span><span>().</span><span>iter</span><span>() {
    </span><span>// query.iter().iter()? Really???
</span><span>}
</span></code></pre>
<p>Similarly, retrieving a specific entity's component's looked like this:</p>
<pre><code><span>if let </span><span>Ok</span><span>(</span><span>mut</span><span> result</span><span>) =</span><span> query</span><span>.</span><span>entity</span><span>(</span><span>entity</span><span>) {
    </span><span>if let </span><span>Some</span><span>((</span><span>a</span><span>,</span><span> b</span><span>)) =</span><span> result</span><span>.</span><span>get</span><span>() {
        </span><span>// access components here
    </span><span>}
}
</span></code></pre>
<p>In <strong>Bevy 0.3</strong> you can just do this:</p>
<pre><code><span>// iteration
</span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> query</span><span>.</span><span>iter</span><span>() {
    </span><span>// sweet ergonomic bliss
</span><span>}

</span><span>// entity lookup
</span><span>if let </span><span>Ok</span><span>((</span><span>a</span><span>,</span><span>b</span><span>)) =</span><span> query</span><span>.</span><span>get</span><span>(</span><span>entity</span><span>) {
    </span><span>// boilerplate be gone!
</span><span>}
</span></code></pre>
<p>You might naturally be thinking something like:</p>
<p><em>Why did this take so long? Why would removing a single <code>&amp;mut</code> be hard?</em></p>
<p>It's a long story! In summary:</p>
<ul>
<li>The old api looked the way it did for a reason. It was the result of good design choices that protect against unsafe memory access in a parallel environment.</li>
<li><code>query.iter()</code> didn't actually return an iterator. It returned a <em>wrapper</em> that held an atomic lock on the component storages. The same was true for the type returned by <code>query.entity()</code></li>
<li>Removing these "wrapper types" would have allowed unsafe behavior because another Query could access the same components in a way that violated Rust's mutability rules.</li>
<li>Due to the iterator implementation and quirks in the rust compiler, removing the wrapper type <em>tanked</em> iteration performance by about ~2-3x.</li>
</ul>
<p>Fortunately we finally found ways to solve all of these problems. The newly added <code>QuerySets</code> allow us to completely remove the locks (and wrapper types). And by completely rewriting <code>QueryIter</code> we were able to avoid the performance hit that removing the wrapper incurred. Read on for the details!</p>
<h3 id="100-lockless-parallel-ecs">100% Lockless Parallel ECS</h3>
<p>Bevy ECS is now completely lock free. In Bevy 0.2, we made direct <code>World</code> access and "for-each" systems lock free. This is possible because the Bevy ECS scheduler ensures that systems only run in parallel in ways that respect Rust's mutability rules. </p>
<p>We couldn't remove locks from <code>Query</code> systems because of systems like this:</p>
<pre><code><span>fn </span><span>conflicting_query_system</span><span>(</span><span>mut </span><span>q0</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> A</span><span>&gt;</span><span>, </span><span>mut </span><span>q1</span><span>: </span><span>Query</span><span>&lt;(&amp;</span><span>mut</span><span> A, </span><span>&amp;</span><span>B</span><span>)&gt;) {
    </span><span>let</span><span> a </span><span>=</span><span> q0</span><span>.</span><span>get_mut</span><span>(</span><span>some_entity</span><span>).</span><span>unwrap</span><span>();
    </span><span>let </span><span>(</span><span>another_a</span><span>,</span><span> b</span><span>) =</span><span> q1</span><span>.</span><span>get_mut</span><span>(</span><span>some_entity</span><span>).</span><span>unwrap</span><span>();
    </span><span>// Aaah!!! We have two mutable references to some_entity's A component!
    // Very unsafe!
</span><span>}
</span></code></pre>
<p>The locks ensured that the second <code>q1.get_mut(some_entity)</code> access panicked, keeping us nice and safe. In <strong>Bevy 0.3</strong>, a system like <code>conflicting_query_system</code> will fail when the schedule is constructed. By default, <em>systems cannot have conflicting queries</em>.</p>
<p>However there are some cases where a system <em>needs</em> conflicting queries to do what it needs to do. For these cases, we added <code>QuerySets</code>: </p>
<pre><code><span>fn </span><span>system</span><span>(</span><span>mut </span><span>queries</span><span>: </span><span>QuerySet</span><span>&lt;(</span><span>Query</span><span>&lt;&amp;</span><span>mut</span><span> A</span><span>&gt;</span><span>, Query</span><span>&lt;(&amp;</span><span>mut</span><span> A, </span><span>&amp;</span><span>B</span><span>)&gt;)&gt;) {
    </span><span>for</span><span> a </span><span>in</span><span> queries</span><span>.</span><span>q0_mut</span><span>().</span><span>iter_mut</span><span>() {
    }

    </span><span>for </span><span>(</span><span>a</span><span>,</span><span> b</span><span>) in</span><span> queries</span><span>.</span><span>q1_mut</span><span>().</span><span>iter_mut</span><span>() {
    }
}
</span></code></pre>
<p>By putting our conflicting <code>Queries</code> in a <code>QuerySet</code>, the Rust borrow checker protects us from unsafe query accesses.</p>
<p>Because of this, we were able to remove <em>all</em> safety checks from <code>query.iter()</code> and <code>query.get(entity)</code>, which means these methods are now <em>exactly</em> as fast as their <code>World</code> counterparts (which we made lock-free in Bevy 0.2). </p>
<h3 id="performance-improvements">Performance Improvements</h3>
<p>Bevy had a number of nice performance improvements this release:</p>
<ul>
<li>Removed atomic locks from Query access, making Bevy ECS 100% lock free</li>
<li>Removed archetype "safety checks" from Query access. At this point we have already verified …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bevyengine.org/news/bevy-0-3/">https://bevyengine.org/news/bevy-0-3/</a></em></p>]]>
            </description>
            <link>https://bevyengine.org/news/bevy-0-3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983956</guid>
            <pubDate>Tue, 03 Nov 2020 21:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It may be possible to reverse aging. Doing so risks severe overpopulation.]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24983592">thread link</a>) | @lawschool333
<br/>
November 3, 2020 | https://www.pairagraph.com/dialogue/952f0d63098645af9ed547880fca3a20?01 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/952f0d63098645af9ed547880fca3a20?01">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/952f0d63098645af9ed547880fca3a20?01</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983592</guid>
            <pubDate>Tue, 03 Nov 2020 20:25:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mind-Melting Decision Proves a Dialer Can Never Be Too Old to Be an ATDS]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24983532">thread link</a>) | @guerrilla
<br/>
November 3, 2020 | https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/ | <a href="https://web.archive.org/web/*/https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>Editor’s Note: Welcome Hackers! Not sure how Hacker News found this article but I see a ton of folks headed in from that website, which I presume is some sort of aggregator for news articles of interest to folks that like to hack stuff. Feel free to have a look around the website–<a href="https://tcpaworld.com/podcast/">check out our cool podcast</a>–and tell any friends that might like this nerdy stuff. But don’t hack anything please. Thanks.&nbsp;</em></p>
<p>Since there is absolutely nothing else going on today I figured I’d share one of the weirdest TCPA cases I’ve seen recently.</p>
<p>So apparently some guy in Nebraska named Mort who really doesn’t like a gas station called Bucky’s Gas Station. He hates it so much, in fact, that he has created a stark raving mad loony-toons (my opinion) gripes board on the internet to assail it. You can visit it, if you’d like, but be warned that your brain will melt a little: <a href="http://www.buckysgasstationsucks.com/">www.buckysgasstationsucks.com</a>.</p>
<p>I spent more time than I’d care to admit reviewing the website last night but I can’t quite figure out where the beef originated. (If you can figure it out let me know, as I am actually genuinely curious.)</p>
<p>So Bucky’s Gas Station is owned by a guy named Buchanan— who I will assume goes by Bucky whether he wants to or not—and his wife who have allegedly been subjected to years of abuse at the hands of Mort using something called a FaxTel 2000, which is something directly out of a 90s era Simpsons. Apparently Mort revs up his FaxTel 2000 and blasts Bucky and his wife with unwanted messages from time to time, just to make sure Bucky remembers how much Mort dislikes him.</p>
<p>Not stopping there, Mort also—allegedly—encourages members of the public to blast poor Bucky with calls “day and night” and to do the same with his associates and neighbors, many of whose contact information is listed on the brain-melting website. As the order tersely words it: “<em>[Mort] encourages members of the public to contact the Buchanans, their neighbors, and others they are affiliated with; and notes that the Buchanans and others will be contacted daily and nightly regarding Sullivan’s grievances</em>.”</p>
<p>Since I don’t actually know why Mort is so agitated by Bucky I can’t say that his conduct is totally inappropriate. I mean, maybe Bucky threw Mort’s puppy in a microwave or something. But either way the conduct of blasting someone’s cell phone with unwanted messages is illegal—if an ATDS is used.</p>
<p>And here’s where things finally get interesting in this yawner of a case.</p>
<p>The Plaintiff alleged that FaxTel 2000 is an autodialer because, I mean, look at the thing.</p>
<p><img data-attachment-id="9016" data-permalink="https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/faxtel-20007jpeg/" data-orig-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=350%2C267&amp;ssl=1" data-orig-size="350,267" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="FAXTEL 20007jpeg" data-image-description="" data-medium-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=300%2C229&amp;ssl=1" data-large-file="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?fit=350%2C267&amp;ssl=1" loading="lazy" src="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1" alt="" width="300" height="229" srcset="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?w=350&amp;ssl=1 350w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?w=350&amp;ssl=1 350w" data-lazy-src="https://i0.wp.com/tcpaworld.com/wp-content/uploads/2020/11/FAXTEL-20007jpeg.jpg?resize=300%2C229&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>But Mort had a clever response—this device is so old and beaten up that it can no longer dial randomly and sequentially, plus no replacement parts are available so it lacks the capacity to dial that way in the future either. So it can’t possibly meet the TCPA’s ATDS definition.</p>
<p>I mean, its kind of a brilliant argument if you think about it (and your mind has melted a little.)</p>
<p>Unfortunately for Mort, however, the case was decided at the pleadings stage and the Court simply could not accept Mort’s assertions on the FaxTel’s dialing capacity as those “facts” were outside the pleadings. Instead the Court had to accept Bucky’s claim that the dialer had all the needed functionality to behave as an ATDS.</p>
<p>Undeterred, Mort also argued that the TCPA infringed on his First Amendment rights but—as <strong><a href="https://tcpaworld.com/2020/10/29/happy-halloween-tcpaworld-heres-are-the-top-10-scariest-tcpa-stories-going-to-freak-you-out-this-halloween/">readers of my Halloween column know</a></strong>—the Constitution won’t save you in TCPAWorld.</p>
<p>*Insert left-over evil laugh from Halloween bargain bin here*</p>
<p>Mort finished his motion to dismiss with a claim that the TCPA only applies to telemarketing harassment, not good-ole-fashioned harassment harassment. No dice. The Court looks at the words of the statute and cannot find the “I just want to abuse people out of spite” TCPA exemption.</p>
<p>On the other hand, and somewhat amusingly, the Court refused to enter a preliminary injunction prohibiting Mort’s conduct finding that it wanted more information and evidence before doing so. Under the circumstances of this case one might have thought ordering one party to temporarily stop blasting the other with&nbsp; robocalls would have been pretty perfunctory. But I guess the Court also wants to know about the condition of Mort’s puppies before ordering him to stop FaxTeling Bucky.</p>
<p>The case is <em>Buchanan v. Sullivan</em>, 8:20-CV-301, 2020 U.S. Dist. LEXIS 202519 (D. Ne. October 30, 2020).</p>
<p>And now you may return to your low-anxiety and worry free Tuesday.</p>
<p>Hey, look at that bird outside.</p>
<p><strong>UPDATE: 11/3/2020 at 2:24 pm pacific</strong></p>
<p>So I apparently have a new team of hackers that work for me– Czar of TCPAWorld and Czar of the Hackers?– and they think they’ve uncovered what happened here. Below is an exchange from a hacker news message board, because that’s how I roll now:</p>

	</div></div>]]>
            </description>
            <link>https://tcpaworld.com/2020/11/03/heres-your-tcpa-distraction-for-a-normal-tuesday-with-nothing-else-going-on-mind-melting-decision-proves-a-dialer-can-never-be-too-old-to-be-an-atds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983532</guid>
            <pubDate>Tue, 03 Nov 2020 20:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decision Journal in Notion]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24983435">thread link</a>) | @saviorand
<br/>
November 3, 2020 | https://optemization.com/decision-journal-notion | <a href="https://web.archive.org/web/*/https://optemization.com/decision-journal-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://optemization.com/decision-journal-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24983435</guid>
            <pubDate>Tue, 03 Nov 2020 20:07:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Psychology of Learning to Code]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982975">thread link</a>) | @dvoloschik
<br/>
November 3, 2020 | https://vasilishynkarenka.com/the-psychology-of-learning-to-code/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/the-psychology-of-learning-to-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/10/5d62c199-2886-4143-a885-e96bb295d6ce.png" alt="The psychology of learning to code">
            </figure>

            <section>
                <div>
                    <p>Two months ago, I started learning how to code. I’ve approached coding three times in the past seven years and always quit. This time, I decided to figure out <a href="https://vasilishynkarenka.com/learning/">how to learn</a> first and gave myself a word to not stop until I can make a simple web app myself.</p><p>Last week, I finished my first <a href="https://vasilishynkarenka.com/gpt-3/">useful React app</a> and decided to reflect on what I’ve learned in the past two months. I’ve seen many articles describing tips and tricks for studying coding, but very few cover the process of learning and the psychology behind it.</p><p>In summary, you need to build a habit of learning, find what you’re obsessed with, and crawl your way through The Suck. I also explain how drawing and spatial cognition help improve understanding, how you can enhance transfer by creating more hooks for recall, and how to design an environment for concentration instead of pushing yourself to focus.</p><p><em>P.s. If you aren’t learning to code, you’ll benefit from reading the habit part as well – the principles behind it apply to any routine.</em></p><p><em>P.p.s. If you haven’t seen my work on learning, I’d recommend reading both posts so that you form a complete picture of how to learn:</em></p><figure><a href="https://vasilishynkarenka.com/learning/"><div><p>How to remember what you learn</p><p>Make it time-based, apply metacognition &amp; active recall, and learn what you’re curious about.</p><p><img src="https://vasilishynkarenka.com/favicon.png"><span>Vasili Shynkarenka</span></p></div><p><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_1517.jpg"></p></a></figure><hr><p>Most people quit learning to code because they don’t get results. But results come after months of practice – there is no way to become a senior engineer after one hour of HTML tutorials. To get there, you can’t rely on fragile motivation that fades away quickly. You must build a habit of learning.</p><p>To build a habit, you need four things:</p><ol><li>Design your intention.</li><li>Make learning time-based instead of outcome-based.</li><li>Start small.</li><li>Do not make up for missed studies.</li></ol><h2 id="design-your-intention">Design your intention</h2><p>Most people never study because they don’t specify when and where learning will happen. They just keep snoozing it because “today was really busy but let’s see if I can make it tomorrow.” And tomorrow never comes.</p><p>Intention design is a trick to help with indefinite plans. When you want to do something, write it down in the following structure:</p><blockquote><em>“I, Vasili Shynkarenka, will study React course on Scrimba from 8:00 to 8:30 am tomorrow morning in my study room, right after I brush my teeth.” (Signature)</em></blockquote><p>Here’s why it works.</p><p><strong>First, you give yourself a word.</strong> When you promise yourself in writing that you will do something, you plant a seed for consistency. And humans naturally want to be consistent in their actions to not look stupid. But consistency works only if the action is present. And when you’re merely thinking about doing something, that’s not real yet. When you write the thing down, you make it real.</p><p><strong>Second, you get clarity.</strong> Suppose you omit essential details, such as where you will be studying or which material you will use. In that case, you’re less likely to do it because you will experience increased cognitive load at the moment. Because humans don’t like thinking, you will go for the easiest option possible – to put it off.</p><p>That’s why Eisenhower famously said that while plans are useless, planning is essential. The act of planning clarifies subtleties. Your plan may change, but clarity will lower cognitive load and increase the likelihood of taking action.</p><p><strong>Third, you specify the behavior after which learning should begin.</strong> Very often, our plans go sideways because we do not clarify <em>when</em> we will do the thing. Urgent stuff keeps popping up, and we never get to do what we wanted.</p><p>The easiest solution here is to choose a trigger that you already do every day, no matter what, and schedule your learning right after that act. Brushing your teeth, having breakfast, coming back home after work – all are excellent examples. If you approach intention design that way, you have less opportunity for failure because the “must-do” thing will always be there and serve as a reminder for the action you want to take.</p><h2 id="make-learning-time-based">Make learning time-based</h2><p>If you choose to study until you finish the chapter, you incentivize yourself to optimize for speed rather than understanding. As a result, you will skim the most valuable parts to hit your goal.</p><p>The second problem with goals like “finish such and such tutorial” is that you will underestimate how much time it will take to finish the thing. And when you run out of time, you will be frustrated with yourself because you didn’t hit your goal.</p><p>Instead, set time-based goals. “Study JS course for 1h” is a good example. Or “Read new CSS tutorial for 30 min”. </p><p>When you switch to time-based learning, three things happen:</p><p><strong>First, you take control of whether you succeed or not.</strong> When you are focused on the outcome, you have to rely on an unknown variable – how much time it will take for you to understand something new. This often leads to self-hatred – you will blame yourself for being stupid because you didn’t understand the material quickly. But if you focus on time, then you always succeed if you want to. You just need to focus.</p><p><strong>Second, you can fit the learning session into your busy schedule.</strong> When you know that you’ll be learning for thirty minutes no matter what, you know where to put the thing.</p><p><strong>Third, you build self-confidence.</strong> The time you spend on learning is a continuum, but the act of showing up is binary. It doesn’t care for how long you learn to mark it as “done.” And if you keep showing up for months, you become <em>the type of person</em> who shows up. And as most people quit in the first few months, you’ll have built immunity by the moment you will face The Suck.</p><h2 id="start-small">Start small</h2><p>When you’re just getting started, lower the time of your studies to a bare minimum. Make it negligible. Even ten minutes will do, given that you’re doing it every day.</p><p>I hear you saying: “How can I possibly learn something really complex as coding by spending ten minutes a day on it?” You can’t. But you can build discipline.</p><p>Also, you’ll procrastinate less. If you only have ten minutes to learn in a day, and there’s no opportunity to make up for it, your mind will be like: “Hell, I’ve got only ten minutes today – I better focus and not scroll Instagram.”</p><h2 id="do-not-make-up">Do not make up</h2><p>You must never, ever, make up for studies that you missed. </p><p>It’s incredibly easy to sell yourself on the idea that “Oh, I don’t really want to study this morning, I’ll do it later today when I have time.” </p><p>But snoozing is dangerous for two reasons:</p><ol><li>First, you’re unlikely to do it later because you won’t have triggers to remember the thing. You screw up your intention design.</li><li>Second, you set up bad incentives for yourself in the future. There will be moments when your habit will fail you and you will skip learning. And if you’ve trained yourself to snooze things for later when any inconvenience arises, you’ll tend to do it over and over again. You’ll just keep snoozing.</li></ol><p>So what do you do if you miss a session? Nothing. You don’t reschedule. You don’t blame yourself. It’s already in the past, so there’s no reason to do any of these things. You show up again tomorrow and do the work.</p><p>When you stop rescheduling, you become less likely to skip your learning sessions because you know you can’t make up for it. Your mind will remember the contract you have agreed on and stop offering opportunities for sloth.</p><p>After you make learning a habit, the next question is how to get more of it. That’s because learning is nonlinear: if you put in two hours every day instead of one, you don’t get a 2x outcome – you get 5-10x. </p><p>The best way to allocate more time to coding is not to squeeze more hours of study but to discover your obsession. </p><p>Obsession is a multiplier for results. When you’re obsessed with something, you cannot <em>not</em> do the thing. As a result, you don’t have to decide each time whether to study or not. You just do it.</p><p>I’m obsessed with building interfaces. I don’t really care about how beautiful the app’s architecture is or what algorithm we use for compression. All I’m thinking about is how to make the user experience great.</p><p>When I realized that interfaces make me tick, I optimized my learning program to build more of them. I created all sorts of forms, confirmation alerts, and buttons. I stopped counting minutes I had yet to study and began going way <em>beyond</em> what I initially allocated for learning just because I was so curious about it. And that’s where real progress began to happen.</p><p>To find what you’re obsessed with, ask yourself two questions:</p><ol><li>Why do I want to learn how to code in the first place?</li><li>Is there anything specific about coding that drives me?</li></ol><p>If you don’t have an answer now, it’s okay. Try many things broadly to find what makes you tick about coding, and then double down in that direction. If data is your thing, go ahead and study APIs first. If you sweat when you make beautiful CSS animations, go and pick up that. Follow your own obsession.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/10/image-7.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/10/image-7.png 600w, https://vasilishynkarenka.com/content/images/2020/10/image-7.png 790w" sizes="(min-width: 720px) 720px"><figcaption>"Andy crawled to freedom through five-hundred yards of shit smelling foulness I can't even imagine, or maybe I just don't want to. Five-Hundred yards... that's the length of five football fields, just shy of half a mile."</figcaption></figure><p>Everyone who learns something complex goes through The Suck.</p><p>That’s when things get tough. When you don’t see progress for weeks. When you wake up every day and question yourself if it’s worth it. When you are ready to quit. The difference between people who end up learning how to code and those who don’t is simple – those who succeed somehow manage to crawl their way through The Suck.</p><p>Because I knew how learning works, I was aware The Suck is coming. But it hit me hard anyway. To help you get through The Suck, I’ve documented what I did to pull myself from that shithole.</p><h2 id="understand-how-learning-works">Understand how learning works</h2><p>Learning is never linear and more like a giant exponential curve. It’s a weird one, with a flat part looking like a bumpy road. One day, you get a hit and go straight up. You learn something new. Another time, you spend many hours and get nothing.</p><p>Very often, it seems that you’re not making …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/the-psychology-of-learning-to-code/">https://vasilishynkarenka.com/the-psychology-of-learning-to-code/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/the-psychology-of-learning-to-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982975</guid>
            <pubDate>Tue, 03 Nov 2020 19:22:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity Condensed – Exploring complex ideas and concepts in 500 words]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982803">thread link</a>) | @nickfrost
<br/>
November 3, 2020 | https://inboxstash.com/newsletter/complexity-condensed/ | <a href="https://web.archive.org/web/*/https://inboxstash.com/newsletter/complexity-condensed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<header data-post-id="528" itemscope="itemscope" itemtype="http://schema.org/WPHeader" data-type="header" data-sticky="0" data-sticky-breakpoint="medium" data-shrink="0" data-overlay="0" data-overlay-bg="transparent"><div data-node="5db0c75b4ac84">
	<div>
						<div>
		
<div data-node="5db0c75b4acbf">
			<div data-node="5db0c75b4acf7">
	<div>
	<div data-node="5db0c85f7d448">
	<div>
		<div itemscope="" itemtype="https://schema.org/ImageObject">
	<p><a href="https://inboxstash.com/" target="_self" itemprop="url">
				<img loading="lazy" src="https://inboxstash.com/wp-content/uploads/2019/10/inbox-stash-logo-425x80-v2.png" alt="inbox stash logo 425x80 v2" itemprop="image" height="80" width="425" title="inbox stash logo 425x80 v2" data-no-lazy="1" srcset="https://inboxstash.com/wp-content/uploads/2019/10/inbox-stash-logo-425x80-v2.png 425w, https://inboxstash.com/wp-content/uploads/2019/10/inbox-stash-logo-425x80-v2-300x56.png 300w" sizes="(max-width: 425px) 100vw, 425px">
				</a>
					</p>
	</div>
	</div>
</div>
	</div>
</div>
			
			
	</div>
		</div>
	</div>
</div>

</header>	<div id="fl-main-content" itemprop="mainContentOfPage">

		<div data-post-id="98"><div data-node="5d9f812fc9400">
	<div>
						<div>
		


<div data-node="5d9f812fccf81">
			<div data-node="5d9f812fcd0e4">
	<div>
	
<div data-node="5da22232be257">
			<div data-node="5da22232be3bb">
	<div>
	<div data-node="5d9f6ee8be505">
	<div>
		<div itemscope="" itemtype="https://schema.org/ImageObject">
	<p><img loading="lazy" src="https://inboxstash.com/wp-content/uploads/2020/11/Logo-with-blue-dot.png" alt="Logo-with-blue-dot" itemprop="image" height="817" width="817" title="Logo-with-blue-dot" srcset="https://inboxstash.com/wp-content/uploads/2020/11/Logo-with-blue-dot.png 817w, https://inboxstash.com/wp-content/uploads/2020/11/Logo-with-blue-dot-300x300.png 300w, https://inboxstash.com/wp-content/uploads/2020/11/Logo-with-blue-dot-150x150.png 150w, https://inboxstash.com/wp-content/uploads/2020/11/Logo-with-blue-dot-768x768.png 768w" sizes="(max-width: 817px) 100vw, 817px">
					</p>
	</div>
	</div>
</div>
	</div>
</div>
			<div data-node="5da22232be3f8">
	<div>
	
<div data-node="5d9f7d040845f">
	<p>
		<h5>
		<span>Complex topics explained in 500 words.</span>
	</h5>
	</p>
</div>
<div data-node="5d9f85026b514">
	<div>
		<div>
	<p><i></i> <a href="https://inboxstash.com/collection/artificial-intelligence/" rel="tag">Artificial Intelligence</a>, <a href="https://inboxstash.com/collection/blockchain-cryptocurrency/" rel="tag">Blockchain &amp; Cryptocurrency</a>, <a href="https://inboxstash.com/collection/business/" rel="tag">Business</a>, <a href="https://inboxstash.com/collection/education/" rel="tag">Education</a>, <a href="https://inboxstash.com/collection/entertainment/" rel="tag">Entertainment</a>, <a href="https://inboxstash.com/collection/entrepreneurship/" rel="tag">Entrepreneurship</a>, <a href="https://inboxstash.com/collection/general/" rel="tag">General</a>, <a href="https://inboxstash.com/collection/healthcare/" rel="tag">Healthcare</a>, <a href="https://inboxstash.com/collection/history/" rel="tag">History</a>, <a href="https://inboxstash.com/collection/personal-finance/" rel="tag">Personal Finance</a>, <a href="https://inboxstash.com/collection/philosophy/" rel="tag">Philosophy</a>, <a href="https://inboxstash.com/collection/politics/" rel="tag">Politics</a>, <a href="https://inboxstash.com/collection/psychology/" rel="tag">Psychology</a>, <a href="https://inboxstash.com/collection/science/" rel="tag">Science</a>, <a href="https://inboxstash.com/collection/technology/" rel="tag">Technology</a></p>
</div>
	</div>
</div>
	</div>
</div>
	</div>


<div data-node="5d9f8154bff5a">
	<div>
		<p>A weekly newsletter that explores complex ideas, events, and concepts and explains them in 500 words.</p>
<p>Think of it as a fast food buffet for your curious mind.</p>
	</div>
</div>

	</div>
</div>
			<div data-node="5d9f812fcd11e">
	<div>
	



<div data-node="5dc0ad94832eb">
	<div>
		
	<div data-template-id="5dc0ad9464275" data-template-node-id="5dc0ad947afe9">

		
		<div>

						<p>A weekly digest of resources for newsletter creators and our picks from InboxStash.</p>
			
			
			<div>
				<p>Please enter a valid email address.</p>
			</div>

			
			

			
			<p>Something went wrong. Please check your entries and try again.</p>
		</div>
					
			</div>

	</div>
</div>




	</div>
</div>
	</div>
		</div>
	</div>
</div>
</div>
	</div><!-- .fl-page-content -->
		</div></div>]]>
            </description>
            <link>https://inboxstash.com/newsletter/complexity-condensed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982803</guid>
            <pubDate>Tue, 03 Nov 2020 19:05:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker in 10 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24982719">thread link</a>) | @wheresvic4
<br/>
November 3, 2020 | https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  I've been exposed to docker on and off and every time I see it, I seem to need a refresher. In this article we will go
  through everything you need to know about Docker in order to either jump into an existing project or get started with
  it.
</p>

<h5>Basic concepts</h5>

<p>
  Docker is basically a system of running processes on the host machine in an isolated way, using several Linux kernel
  features. Thus, Docker is more lightweight than a full-blown virtual machine. The disadvantage of a Docker container
  vs. a virtual machine is that multiple containers share the same underlying OS kernel. While the concept of jailed
  processes is not new, Docker's popularity was essentially due to the tooling that it provided to which made it really
  straightforward to spin up and manage containers.
</p>

<p>
  Docker is made up of various components. The main component is the the docker engine, which consists of a lightweight
  runtime that manages containers, images, builds, and more. It runs natively on Linux systems and is made up of:
</p>

<ol>
  <li>Docker daemon that runs on the host machine.</li>
  <li>Docker client that communicates with the Docker daemon to execute commands.</li>
  <li>A REST API for interacting with the Docker daemon remotely.</li>
</ol>

<p>
  The Docker client is what you, as the end-user use to communicate with the Docker daemon, e.g.
  <code>docker run hello-world</code>.
</p>

<p>
  The Docker daemon is what actually executes commands like building and running containers on the host machine. The
  Docker Client can run on the same machine as well, but it does not have to. It can also communicate with the Docker
  Daemon running on a different host.
</p>

<p>We will look at other Docker components like the Docker hub, etc. later in this article.</p>

<h5>Images, containers and volumes</h5>

<p>
  A Docker image can be though of as a recipe for setting up a machine with all required software and dependencies
  installed. Apart from installing software, images can also define what processes to run when launched. Docker images
  are created via instructions written in a <code>Dockerfile</code>. Images are built on the concept of layers. There is
  always a base layer, potentially followed by additional layers that represent file changes. Each layer is stacked on
  top of the others, consisting of the differences between it and the previous layer. This is achieved via a
  <a href="https://en.wikipedia.org/wiki/UnionFS">Union file system</a>.
</p>

<!--
<p>Examples of instructions one can put into a <code>Dockerfile</code>:</p>

<ul>
  <li><code>RUN apt-get -y install some-package</code> # install a software package</li>
  <li><code>EXPOSE 8000</code> # expose a port</li>
  <li><code>ENV ANT_HOME /usr/local/apache-ant</code> # pass an environment variable</li>
</ul>
-->

<p>
  A Docker container is the running instance of an image. This includes the operating system, application code, runtime,
  system tools, system libraries, etc. A Docker image can be thought of as an executable and a container can be thought
  of as the running application. Note that in this analogy each running application is its own instance and independent
  of the others.
</p>

<p>
  The general idea is that once you have successfully created a container, you can then run it in any environment
  without having to make changes.
</p>

<p>
  A Docker volume is the "data" part of a container, initialized when a container is created. Volumes allow
  you to persist and share a container's data. Docker volumes are separate from the default Union File System and exist
  as normal directories and files on the host filesystem.
</p>

<h5>Docker comands</h5>

<p>
  As part of the docker installation process, a hello world image was downloaded and executed via:
  <code>docker run hello-world</code>
</p>

<p>List all images with <code>docker images</code>:</p>

<pre>$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
ubuntu              latest              94e814e2efa8        2 weeks ago         88.9MB
hello-world         latest              fce289e99eb9        2 months ago        1.84kB
</pre>

<p>Run a command interactively from an image in a new container: <code>docker run -it ubuntu bash</code></p>

<p>
  List all running containers: <code>docker ps</code>. To list all previously run containers use
  <code>docker ps -a</code>:
</p>

<pre>$ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                         PORTS               NAMES
d2d651741317        ubuntu              "bash"              45 minutes ago      Exited (0) 43 minutes ago                          suspicious_kalam
36813bdb6434        ubuntu              "bash"              About an hour ago   Exited (0) About an hour ago                       inspiring_banach
46f352a0cde9        hello-world         "/hello"            2 hours ago         Exited (0) 2 hours ago                             thirsty_clarke
</pre>

<p>
  Note that in the output above, for each docker <code>run</code> command, a new container was created. As mentioned
  previously, each container has it's own data volume and changes to one do not affect the others. To run an existing
  container: <code>docker run [container-name</code>. This will start the container and
  <code>docker attach [container-name]</code> will jump into it.
</p>

<p>
  At this point, you should have enough to get started with an existing docker project. Read on if you're looking to
  develop with docker.
</p>

<h5>Custom images</h5>

<p>
  As noted previously, Docker images are specified via a <code>Dockerfile</code>. Here's an extremely basic example that
  uses a ubuntu base image and copies an executable called <code>sysinfo</code> from the current directory into the
  container and executes it:
</p>

<pre>FROM ubuntu:18.04
COPY sysinfo /
CMD ["/sysinfo"]
</pre>

<p>
  Let's see how we can get this image up and running via the <code>docker build</code> command (note that gcc is
  required to compile the binary):
</p>

<pre>$ cd ~
$ mkdir -p docker/sysinfo
$ cd docker/sysinfo
$ vim sysinfo.cpp

#include &lt;iostream&gt;
#include &lt;sys/utsname.h&gt;

using namespace std;

int main() {
  struct utsname sysinfo;
  uname(&amp;sysinfo);
  
  cout &lt;&lt; "System Name: " &lt;&lt; sysinfo.sysname &lt;&lt; endl;
  cout &lt;&lt; "Host Name: " &lt;&lt; sysinfo.nodename &lt;&lt; endl;
  cout &lt;&lt; "Release(Kernel) Version: " &lt;&lt; sysinfo.release &lt;&lt; endl;
  cout &lt;&lt; "Kernel Build Timestamp: " &lt;&lt; sysinfo.version &lt;&lt; endl;
  cout &lt;&lt; "Machine Arch: " &lt;&lt; sysinfo.machine &lt;&lt; endl;
  cout &lt;&lt; "Domain Name: " &lt;&lt; sysinfo.domainname &lt;&lt; endl;
  
  return 0;
}

$ g++ sysinfo.cpp -o sysinfo
$ ./sysinfo

System Name: Linux
Host Name: coolbeans
Release(Kernel) Version: 4.18.0-16-generic
Kernel Build Timestamp: #17-Ubuntu SMP Fri Feb 8 00:06:57 UTC 2019
Machine Arch: x86_64
Domain Name: (none)


$ vim Dockerfile

FROM ubuntu:18.04
COPY sysinfo /
CMD ["/sysinfo"]

$ docker build . -t sysinfo
$ docker run sysinfo

System Name: Linux
Host Name: d8e53b009d72
Release(Kernel) Version: 4.18.0-16-generic
Kernel Build Timestamp: #17-Ubuntu SMP Fri Feb 8 00:06:57 UTC 2019
Machine Arch: x86_64
Domain Name: (none)
</pre>

<p>
  Note in the difference in hostname between local system (coolbeans) and the running container (d8e53b009d72) in the
  above output.
</p>

<p>
  If you make a mistake, you can remove an image via <code>docker rmi [image-name] --force</code>. Cleaning up unused
  containers and volumes related to the image can be accomplished via <code>docker system prune --volumes</code>.
</p>

<p>
  In the above example, we created a custom image using the standard Ubuntu image as our base image, before we go
  further with creating custom images it would be good to note that the docker
  <a href="https://hub.docker.com/search?q=&amp;type=image&amp;image_filter=official">hub</a> provides lots of free
  pre-configured images for various software. This is the second Docker component and is also sometimes called the
  Docker registry (one can also have private registries).
</p>

<h5>Networking</h5>

<p>
  In most cases, we would like to run a service via Docker. Let is look at how we can accomplish this by using a very
  simple web server as an example. Create the image as follows (note that the example below uses Go to create the
  binary):
</p>

<pre>$ cd ~
$ mkdir -p docker/webapp
$ cd docker/webapp
$ vim webapp.go

package main

import (
	"io"
	"net/http"
)

func hello(w http.ResponseWriter, r *http.Request) {
	io.WriteString(w, "Hello from webapp!")
}

func main() {
	http.HandleFunc("/", hello)
	http.ListenAndServe(":8000", nil)
}

$ go build webapp.go
$ vim Dockerfile

FROM ubuntu:18.04
COPY webapp /
CMD ["/webapp"]

$ docker build . -t webapp
$ docker run -d webapp
cfab907c828a40ce4cc53b88b26badabf8fa6672fd538d0c072fd0947f36d650
</pre>

<p>
  In the above example we built a webapp image and started the docker container with the <code>-d</code> flag. This
  started the container in detached mode and printed the container id so that we could interact with it. We can confirm
  it is running via <code>docker ps</code>:
</p>

<pre>CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
cfab907c828a        webapp              "/webapp"           4 minutes ago       Up 4 minutes                            zealous_herschel    
</pre>

<p>
  At this point we have our web application running in a docker container but we have no way to communicate with it. Run
  <code>docker inspect cfab907c828a</code> to output the container configuration in json format. We are interested in
  the <code>NetworkSettings.Networks.bridge.IPAddress</code> property. Let's try connecting to the provided ip address,
  http://172.17.0.2:8000 (in my case) and we can see our web application in action!
</p>

<p>
  It is also possible to bind ports on from the docker container to the host machine so that we can access services as
  if they were running locally, <code>docker run -d -p3000:8000 webapp</code>. Thus our web application is now available
  on http://localhost:3000!
</p>

<h5>Persistent storage</h5>

<p>
  By default Docker containers come with their own storage which lives as long as the container is running. If we would
  like to persist data across containers, we can either bind a local file/directory to our container or create and mount
  a named Docker volume. The added benefit of using a Docker volume is that it does not necessarily have to be a
  resource on the host file system, it can also be an external cloud storage service depending upon the driver.
</p>

<p>
  A very practical example of using a postgres docker image with persistent data storage can be found
  <a href="https://smalldata.tech/blog/2018/02/23/dockerized-postgresql-with-local-data-storage-on-ubuntu">here</a>.
</p>

<h5>Summary</h5>

<p>
  We looked at Docker basic concepts, created a few containers, ran some services and even persisted data across machine
  restarts! This was longer than 10 minutes but it should be enough to get going with Docker.
</p>
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2019%2F06%2F08%2Fdocker-in-10-minutes&amp;t=Docker%20in%2010%20minutes">HackerNew…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes">https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes</a></em></p>]]>
            </description>
            <link>https://smalldata.tech/blog/2019/06/08/docker-in-10-minutes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982719</guid>
            <pubDate>Tue, 03 Nov 2020 18:55:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HSTS your curl]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982517">thread link</a>) | @headalgorithm
<br/>
November 3, 2020 | https://daniel.haxx.se/blog/2020/11/03/hsts-your-curl/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/03/hsts-your-curl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/HTTP_Strict_Transport_Security" target="_blank">HTTP Strict Transport Security</a> (HSTS) is a standard HTTP response header for sites to tell the client that for a specified period of time into the future, that host is not to be accessed with plain HTTP but only using HTTPS. Documented in <a href="https://tools.ietf.org/html/rfc6797">RFC 6797</a> from 2012.</p>



<p>The idea is of course to reduce the risk for man-in-the-middle attacks when the server resources might be accessible via both HTTP and HTTPS, perhaps due to legacy or just as an upgrade path. Every access to the HTTP version is then a risk that you get back tampered content.</p>



<h2>Browsers preload</h2>



<p>These headers have been supported by the popular browsers for years already, and they also have a system setup for <em>preloading</em> a set of sites. Sites that exist in their <a href="https://hstspreload.org/">preload list</a> then never get accessed over HTTP since they know of their HSTS state already when the browser is fired up for the first time.</p>



<p>The entire <code>.dev</code> top-level domain is even in that preload list so you can in fact never access a web site on that top-level domain over HTTP with the major browsers.</p>



<h2>With the curl tool</h2>



<p>Starting in curl 7.74.0, curl has <em>experimental</em> support for HSTS. Experimental means it isn’t enabled by default and we discourage use of it in production. (Scheduled to be released in December 2020.)</p>



<p>You instruct curl to understand HSTS and to load/save a cache with HSTS information using <code>--hsts &lt;filename&gt;</code>. The HSTS cache saved into that file is then updated on exit and if you do repeated invokes with the same cache file, it will effectively avoid clear text HTTP accesses for as long as the HSTS headers tell it.</p>



<p>I envision that users will simply use a small hsts cache file for specific use cases rather than anyone ever really want to have or use a “complete” preload list of domains such as the one the browsers use, as that’s a <em>huge</em> list of sites and for most use cases just completely unnecessary to load and handle.</p>



<h2>With libcurl</h2>



<p>Possibly, this feature is more useful and appreciated by applications that use libcurl for HTTP(S) transfers. With libcurl the application can set a file name to use for loading and saving the cache but it also gets some added options for more flexibility and powers. Here’s a quick overview:</p>



<p><a href="https://curl.haxx.se/libcurl/c/CURLOPT_HSTS.html">CURLOPT_HSTS</a> – lets you set a file name to read/write the HSTS cache from/to.</p>



<p><a href="https://curl.haxx.se/libcurl/c/CURLOPT_HSTS_CTRL.html">CURLOPT_HSTS_CTRL</a> – enable HSTS functionality for this transfer</p>



<p><a href="https://curl.haxx.se/libcurl/c/CURLOPT_HSTSREADFUNCTION.html">CURLOPT_HSTSREADFUNCTION</a> – this callback gets called by libcurl when it is about  to start a transfer and lets the application preload HSTS entries – as if they had been read over the wire and been added to the cache.</p>



<p><a href="https://curl.haxx.se/libcurl/c/CURLOPT_HSTSWRITEFUNCTION.html">CURLOPT_HSTSWRITEFUNCTION</a> – this callback gets called repeatedly when libcurl flushes its in-memory cache and allows the application to save the cache somewhere and similar things.</p>



<h2>Feedback?</h2>



<p>I trust you understand that I’m very very keen on getting feedback on how this works, on the API and your use cases. Both negative and positive. Whatever your thoughts are really!</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/03/hsts-your-curl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982517</guid>
            <pubDate>Tue, 03 Nov 2020 18:34:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Object Oriented Programming in Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982505">thread link</a>) | @janprincek
<br/>
November 3, 2020 | https://www.pythonstacks.com/blog/introduction-object-oriented-programming-python/ | <a href="https://web.archive.org/web/*/https://www.pythonstacks.com/blog/introduction-object-oriented-programming-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<h3><span>Introduction</span></h3>

<p><span>Python is an Object-oriented programming language, therefore, relies heavily on objects.</span></p>

<p><span>Object-oriented programming is one of the most <span>effective</span> approaches to writing<span> software</span>. </span></p>

<p><span>In this approach of programming, you write <span>classes</span> that represent real-world things, and you create <span>objects based on these classes</span>. </span></p>

<p><span>When you write a class, you define the general behavior that a whole category of objects can have.</span></p>

<p><span>A <span>Class</span> is an object constructor for creating objects. They provide a means of bundling data and functionality together.</span></p>

<p><span><span>Creating a new class creates a new <em>type</em> of object</span>, allowing new <span>instances</span><span> </span>of that type to be made. </span></p>



<h3><span>Defining a class in python</span></h3>

<p><span>The python&nbsp;class is made up of attributes (data) and methods (functions).&nbsp;</span></p>

<p><span>Attributes and methods are simply defined as <span>normal variables</span> and <span>f</span><span>unctions.</span></span></p>

<p><span>Creating the class involves :&nbsp; </span></p>

<ul>
	<li><span>Defining the class name</span></li>
	<li><span>Defining the class attributes</span></li>
</ul>



<p><span>A Class definition introduces a little bit of new syntax. In Python, a function definition begins with the <span>def</span> keyword, but a class definition begins with a <span>class</span> keyword.</span></p>

<pre><code>class ClassName:
    # your atrributes</code></pre>



<p><span>Example of a simple class representing a Person as an Object</span></p>

<pre><code>class Person:
    name = "John"
    age = 11</code></pre>

<p><span>&nbsp;Everything defined in the class is called a <span>class attribute</span> and these class attributes can be functions (methods) or variables. </span></p>



<p><span>The making of an object from a class is called <strong>instantiation</strong>, and you work with instances of a class.</span></p>

<p><span>An example of <span>the instantiation</span> of the <code>Person</code> class is :</span></p>

<pre><code>p = Person()</code></pre>

<p><span>An instance of the <code>Person</code> class is stored in a variable p. So this creates a new object called p.</span></p>

<p><span>We can access the attributes of objects using the object name prefix.</span></p>

<pre><code>p.name        # John
p.age         # 11</code></pre>



<p><span>Note for this class, all instances you create is going to have the <span>same name and age</span>, which is not ideal. </span></p>

<p><span>We will have to improve the class so that every instance of a Person we create will have its own name and age.</span></p>



<h3><span>A little more dive into Classes</span></h3>

<p><span>Let's take a look at a more complex class representing a <span>Person</span>.</span></p>

<pre><code>class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age</code></pre>



<p><span>There's a lot to notice, but don't worry. This is the <span>basic structure of almost any class you would be writing</span>.</span></p>





<h3><span>The __init__() method</span></h3>



<div>
<p><span>Any function that’s part of a class is a<span> method</span>. Everything known about functions applies to methods as well;&nbsp;</span></p>

<p><span>Methods are a special kind of attribute defined just like a function that collectively describes the behaviors of a class (the actions it can do)</span></p>
</div>

<p><span>The <code>__init__()</code> method on line 2 is a special method that python runs whenever we create a new instance based on the <code>Person</code> class. Note it has two leading underscores and two ending underscores, it helps python to differentiate special methods from regular functions/methods.</span></p>

<p><br>
<span>We define the __init__() method to have 3 parameters: <span>self</span>, <span>name</span>, and <span>age</span>.</span></p>

<p><span>The <code>self</code> parameter is required in a method definition, and it <span>must come first</span> before the other parameters. </span></p>

<p><span>It must be included in the definition because when Python calls this <code>__init__()</code> method later, the method call will automatically pass the self argument.</span><br>
&nbsp;</p>

<p><span>Every method call associated with a class automatically passes self, which is a reference to the instance itself; it gives the individual instance access to the attributes and methods in the class. </span></p>



<p><span>The two variables defined below the method header each have the prefix <span>self</span>.</span></p>

<pre><code>self.name = name
self.age = age</code></pre>

<p><span>Any variable prefixed with self is available to every method in the class, and we’ll also be able to access these variables through any instance created from the class. </span></p>



<h4><span>Creating an instance of the <code>Person</code> class</span></h4>

<pre><code>p1 = Person("Harry", 23)            # first  instance 

p2 = Person("Potter", 32)           # second instance</code></pre>



<p><span>The Person class describes the definitive attributes of a Person; <code>p1</code> and <code>p2</code>&nbsp; are instances of the <span>Person</span> class;</span><br>
<span>Simply said, <code>p1</code> and <code>p2</code> are <span>objects of type, </span><span>Person</span>.</span></p>

<p><span>When we make an instance of <code>Person</code>, Python calls the <code>__init__()</code> method from the Person class. We also pass Person() a <code>name</code> and an <code>age</code> as arguments. <code>self</code> is passed automatically, so we don’t need to pass it.</span></p>

<p><span>Anytime we want to make an instance from the Person class, we’ll provide values for only the last two parameters, name and age.</span></p>

<h4><br>
<span>Accessing Class Attributes</span></h4>

<p><span>In the <code>Person</code> class definition, <code>self.name = name</code> takes the value stored in the parameter <code>name</code> and stores it in the variable <code>name</code>,<br>
The same process happens with <code>self.age = age</code>. </span></p>

<p><span>Variables that are defined in the <code>__init__()</code>&nbsp; are called <span><em>instance attributes. </em></span>They can be accessed by using the dot notation:</span></p>

<pre><code>p1.name         # Harry

p1.age          # 23

p2.name         # Potter

p2.age          # 32</code></pre>

<p><span>To display the output, use the <code>print()</code> function. For example: <code>print(p1.name)</code>.</span></p>





<h3><span>Writing Custom methods in a class</span></h3>

<p><span>So far, we have been introduced to only one method, the <code>__init__() </code>method which is a <span>special method</span>. </span></p>

<p><span>But we need to be able to add our own methods. Let's do that by creating a new class representing a <span>Rectangle</span>.</span></p>

<p><strong><em><span>Brainstorming:</span></em></strong></p>

<ul>
	<li><span>A rectangle object requires a <span>height</span> and a <span>width</span></span></li>
	<li><span>We should be able to perform an operation on the object to get its <span>Area</span> and <span>Perimeter</span></span></li>
	<li><span>We should be able to represent our object in a <span>string format</span>.</span></li>
</ul>

<pre><code>class Rectangle:
    def __init__(self, width, height):                  # special method
        self.width = width
        self.height = height

    def get_area(self):                                 # custom method
        area = self.width * self.height
        return area

    def get_perimeter(self):                            # custom method
        perimeter = (self.width * 2) + (self.height * 2)
        return perimeter
    
    def __str__(self):                                   # special method
        return "width = " + self.width + " &amp; height: " + self.height</code></pre>



<p><span>You should be getting the pattern here; The methods whose names<span> begin and end with double underscores</span>( __methodname__ ) are <span>special methods</span> in python.</span></p>

<p><span>In this case <code>__init__()</code> and <code>__str__()</code> are the special methods.</span></p>

<p><span>The <code>__str__()</code> method allows us to specify a string representation of our object (Rectangle). That representation is what is displayed when our object is passed as an argument to the <code>print()</code> function.</span></p>

<pre><code>r1 = Rectangle(4, 2)

r1.width                        # 4
r1.height                       # 2

# accessing methods
r1.get_area()                   # 8
r1.get_perimeter()              # 12

# calling the __str__() method
print(r1)                       # width = 4 &amp; height: 2</code></pre>



<p><span>Note that if the&nbsp;<code> __str__()</code> method&nbsp; wasn't defined in the class, <code>print(r1)</code> will give you something like this:</span></p>

<pre><code>&lt;__main__.Rectangle object at 0x000002884E517400&gt;</code></pre>

<p><span>Which isn't human-readable. So it is always a good practice to have a string representation of your class.</span></p>



<p><span>To display the output for example of <code>r1.get_area()</code>, you should write it as <code>print(r1.get_area())</code>. </span></p>



<h3><span>Examples of Class Definitions</span></h3>



<p><strong><span>A class representing a Student</span></strong></p>

<pre><code>class Student:
    def __init__(self, name, subject, score):  # __init__() method
        self.name = name
        self.score = score
        self.subject = subject

    def passed(self):  # regular method
        if self.score &gt;= 80:
            return True
        else:
            return False

    def __str__(self):
        return self.name + ": " + self.subject + " student"

# Creating an instance of the class

stud1 = Student('john', 'science', 87)          # first instance of Student
stud2 = Student("prince", 'biology', 34)        # second instance of Student

# accessing a method

print(stud1.passed())           # True

print(stud2.passed())           # False

print(stud1.subject)            # science

print(stud2.subject)            # biology

print(stud1)                    # john: science student</code></pre>





<p><strong><span>A Class representing a Programming Language</span></strong></p>

<pre><code>class Language:
    def __init__(self):
        self.data_types = []

# Using the class

java = Language()

print(java.data_types)             #  []

java.data_types.append('string')
java.data_types.append('double')

print(java.data_types)              # ['string', 'double']</code></pre>





<p><span>Note, writing of <span>efficient methods</span> in class definitions require a stable understanding of functions. Read <a href="https://www.pythonstacks.com/blog/introduction-functions/">Introduction to Functions</a> if you are not familiar with functions in python.</span></p>
        </div></div>]]>
            </description>
            <link>https://www.pythonstacks.com/blog/introduction-object-oriented-programming-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982505</guid>
            <pubDate>Tue, 03 Nov 2020 18:33:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UN actively passing names of Uighur dissidents to Chinese regime: whistleblower]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982421">thread link</a>) | @abc-xyz
<br/>
November 3, 2020 | https://www.i24news.tv/en/news/international/1604309404-un-actively-passing-names-of-uighur-dissidents-to-chinese-regime-whistleblower | <a href="https://web.archive.org/web/*/https://www.i24news.tv/en/news/international/1604309404-un-actively-passing-names-of-uighur-dissidents-to-chinese-regime-whistleblower">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.i24news.tv/en/news/international/1604309404-un-actively-passing-names-of-uighur-dissidents-to-chinese-regime-whistleblower</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982421</guid>
            <pubDate>Tue, 03 Nov 2020 18:26:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[These Are Fastest Growing SaaS Companies in 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982295">thread link</a>) | @pedro-guimaraes
<br/>
November 3, 2020 | https://lists.amplemarket.com/company_lists/dacdd0fa-8a2b-4426-93f4-295928ca4e75 | <a href="https://web.archive.org/web/*/https://lists.amplemarket.com/company_lists/dacdd0fa-8a2b-4426-93f4-295928ca4e75">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lists.amplemarket.com/company_lists/dacdd0fa-8a2b-4426-93f4-295928ca4e75</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982295</guid>
            <pubDate>Tue, 03 Nov 2020 18:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: What would be an ideal developer stack for a Machine Learning engineer?]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24982113">thread link</a>) | @krishnagade
<br/>
November 3, 2020 | https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/ | <a href="https://web.archive.org/web/*/https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
<p>In today’s world, data has played a huge role in the success of technology giants like Google, Amazon, and Facebook. All of these companies have built massively scalable infrastructure to process data and provide great product experiences for their users. In the last 5 years, we’ve seen a real emergence of AI as a new technology stack. For example, Facebook built an end-to-end platform called <a href="https://code.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/">FBLearner</a> that enables an ML Engineer or a Data Scientist build Machine Learning pipelines, run lots of experiments, share model architectures and datasets with team members, scale ML algorithms for billions of Facebook users worldwide. Since its inception, millions of models have been trained on FBLearner and every day these models answer billions of real-time queries to personalize News Feed, show relevant Ads, recommend Friend connections, etc. &nbsp;</p>



<p>However, for most other companies <strong>building AI applications remains extremely expensive</strong>. This is primarily due to<a href="https://venturebeat.com/2018/05/06/forget-agi-lets-build-really-useful-ai-tools/"> a lack of systems and tools</a><strong> </strong>for supporting end-to-end machine learning (ML) application development — from data preparation and labeling to operationalization and monitoring [1][9][10][11]<strong>.</strong></p>



<p>The goal of this post is 2-fold: </p>



<ol><li>List the challenges with adopting AI successfully: data management, model training, evaluation, deployment, and monitoring; </li><li>List the tools I think we need to create to allow developers to meet these challenges: a data-centric IDE with capabilities like explainable recommendations, robust dataset management, model-aware testing, model deployment, measurement, and monitoring capabilities.</li></ol>







<figure><img src="https://lh4.googleusercontent.com/eHHhzc1HYAh18oRETgjri9drWQpHZwF6OkyDRJ5E4r9YxSwqRViLC6LDTOt4UGLhdg0zMmTj7ScuMCOStrJk_jcmLqRrOkm5z7qIDjEIsyeIi8vpw3q8wAhltmiWA3LfUjDGcT3J" alt=""></figure>



<p>In order to build an end-to-end ML platform, a data scientist has to go through multiple hoops of the following workflow [3].</p>



<div><figure><img src="https://lh3.googleusercontent.com/O29ZMh7AatXlnuiH8_QAxbnpcxrVvl_ioNedmGNdks2QMDJbSWt-XpN757fu41qtdpoNgZ_kNYWBOV70s8LSGnMjA96sfW7A6FVX2naSq1Ukav1WlnmD3br_gw4ijLGnG8DDg1L9" alt=""></figure></div>



<p><strong>End-to-End ML Workflow</strong></p>



<p>A big challenge to building AI applications is that different stages of the workflow require new software abstractions that can accommodate complex interactions with the underlying data used in AI training or prediction. For example:</p>



<p><strong>Data Management</strong> requires a data scientist to build and operate systems like Hive, Hadoop, Airflow, Kafka, Spark etc to assemble data from different tables, clean datasets, procure labeling data, construct features and make them ready for training. In most companies, data scientists rely on their data engineering teams to maintain this infrastructure and help build ETL pipelines to get feature datasets ready. </p>



<p><strong>Training models</strong> is more of an art than science. It requires understanding which features work and what modeling algorithms are suitable to the problem at hand. Although there are libraries like PyTorch, TensorFlow, Scikit-Learn etc, there is a lot of manual work in feature selection, parameter optimization, and experimentation.</p>



<p><strong>Model evaluation</strong> is often performed as a team activity since it requires other people to review the model performance across a variety of metrics from AUC, ROC, Precision/Recall and ensure that model is calibrated well, etc. In the case of Facebook, this was built into FBLearner, where every model created on the platform would get an auto-generated dashboard showing all these statistics. &nbsp;</p>



<p><strong>Deploying models </strong>requires data scientists to first pick the optimal model and make it ready to be deployed to production. If the model is going to impact business metrics of the product and will be consumed in a realtime manner, we need to deploy it to only a small % of traffic and run an<strong> A/B test</strong> with an existing production model. Once the A/B test is positive in terms of business metrics, the model gets rolled out to 100% of production traffic.</p>



<p><strong>Inference of the models </strong>is closely tied with deployment, there can be 2 ways a model can be made available for consumption to make predictions. </p>



<ul><li><strong>batch inference</strong>, where a data pipeline is built to scan through a dataset and make predictions on each record or a batch of records.</li><li><strong>realtime inference</strong>, where a micro-service hosts the model and makes predictions in a low-latency manner.</li></ul>



<p><strong>Monitoring predictions </strong>is very important because unlike traditional applications, model performance is non-deterministic and depends on various factors such as seasonality, new user behavior trends, data pipeline unreliability leading to broken features. For example, a perfectly functioning Ads model might need to be updated when a new holiday season arrives or a model trained to show content recommendations in the US may not do very well for users signing up internationally. There is also a need for alerts and notifications to detect model degradation quickly and take action. </p>



<div><figure><img src="https://lh3.googleusercontent.com/4Km_x5ON36tuOWCwHEXI1pvbchanrGvk6ZZr0Zv789WO1g25Qo6T2_St-fnLKIwfitW_l6c304-ZVppb2iz6QRcvcq_cWoQAwrk2XWh26ZhgydZxjXKC0T140HnuJ5hyAMuY9qMt" alt=""></figure></div>



<p>As we can see, the workflow to build machine learning models is significantly different from building general software applications. If models are becoming first-class citizens in the modern enterprise stack, they need better tools. As Tesla’s Director of AI Andrej Karpathy succinctly puts it, <strong>AI is</strong><a href="https://medium.com/@karpathy/software-2-0-a64152b37c35"><strong> Software 2.0</strong></a><strong> and it needs new tools</strong> [2].<br></p>



<figure><img src="https://lh6.googleusercontent.com/ZN2xWg5G0-EYYH2iEQ7b_Vza4SO9wU8YFrKfQyl3NlWatWmz2Z2hMsKtprxOofb7PtwZAXHfeKBjvyF9tKqE4aLSLDOSS_OvaTV1PZ10CbY4N2NEdHogmhoFRVpC3rb2fot3GO9x" alt=""></figure>



<p>If we compare the stack of Software 1.0 with 2.0, I claim we require transformational thinking to build the new developer stack for AI.</p>







<p>In Software 1.0, we have seen a vast amount of tooling built in the past few decades to help developers write code, share it with other developers, get it reviewed, debug it, release it to production and monitor its performance. If we were to map these tools in the 2.0 stack, there is a big gap!<br></p>



<blockquote><p>What would an ideal Developer Toolkit look like for an AI engineer?</p></blockquote>



<p>To start with, we need to take a <strong>data-first approach</strong> as we build this toolkit because, unlike Software 1.0, the fundamental unit of input for 2.0 is data. </p>



<p><strong>Integrated Development Environment (IDE): </strong>Traditional IDEs focus on helping developers write code, focus on features like syntax highlighting, code checkpointing, unit testing, code refactoring, etc. </p>



<figure><img src="https://lh6.googleusercontent.com/ArLnwbA3Hkj2cjWIVDKgHGTjLaNidh98es1ZdDFfETtPEdQpsUiVwuay3LKdkkKVa3Q33TR5PIZPo1ggbI9H1g6ZSv4RuhX8utUkLLI_b40h509nBk7OR3a34oKZ4DZa2cFgJvXj" alt=""></figure>



<p>For machine learning, we need an IDE that allows easy import and exploration of data, cleaning and massaging of tables. Jupyter notebooks are somewhat useful, but they have their own problems, including the lack of versioning and review tools. A powerful 2.0 IDE would be more data-centric, starts with allowing the data scientist to slice and dice data, edit the model architecture either via code or UI and debug the model on egregious cases where it might be not performing well. I see traction in this space with products like StreamLit [13] reimagining IDEs for ML.  <br></p>



<p>Tools like Git, Jenkins, Puppet, Docker have been very successful in traditional software development by taking care of continuous integration and deployment of software. When it comes to machine learning, the following steps would constitute the release process. </p>



<p><strong>Model Versioning:</strong> As more models get into production, managing the various versions of them becomes important. Git can be reused for models, however, it won’t scale for large datasets. The reason to version datasets is that to be able to <strong>reproduce a model</strong>, we need the snapshot of the data the model was trained upon. Naive implementations of this could explode the amount of data we’re versioning, think 1-copy-of-dataset-per-model-version. DVC [12] which is an open-source version control system is a good start and is gaining momentum. </p>



<p><strong>Unit Testing </strong>is another important part of the build &amp; release cycle. For ML, we need unit tests that catch not only code quality bugs but also data quality bugs. </p>



<div><figure><img src="https://lh6.googleusercontent.com/I99g74dfzW1-4MoswbrjtOeSnw7aH0W8UpbwdumvSxN0FgshNyH-Jpa1WNmsJ-uoNScx6qRnw7IfnWSdcEuZekOwX-UMDliYVP69vDAyGpi4CiD0LQfE_lrfYVUWaHmYIwwBqXmS" alt=""></figure></div>



<p><strong>Canary Tests</strong> are minimal tests to quickly and automatically verify that the everything we depend on is ready. We typically run Canary tests before other time-consuming tests, and before wasting time investigating the code when the other tests are failing [8]. In Machine Learning, it means being able to <strong>replay a previous set of examples</strong> on the new Model and ensuring that it meets certain minimal set of conditions. </p>



<p><strong>A/B Testing </strong>is a method of comparing two versions of an application change to determine which one performs better [7]. For ML, AB testing is an experiment where two or more variations of the ML model are exposed to users at random, and statistical analysis is used to determine which variation performs better for a given conversion goal. For example in the dashboard below, we’re measuring click conversion on an A/B experiment dashboard that my team built at Pinterest, and it shows the performance of the ML experiments against business metrics like repins, likes, etc. CometML [14] lets data scientists keep track of ML experiments and collaborate with their team members. </p>



<figure><img loading="lazy" width="1024" height="736" src="https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-1024x736.png" alt="" srcset="https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-1024x736.png 1024w, https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-300x216.png 300w, https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-768x552.png 768w, https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2-1200x863.png 1200w, https://blog.fiddler.ai/wp-content/uploads/2019/06/image-2.png 1260w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>                                     </figcaption></figure>



<p><strong>Debugging: </strong>One of the main features of an IDE is the ability to debug the code and find exactly the line where the error occurred. For machine learning, this becomes a hard problem because models are often opaque and therefore exactly pinpointing why a particular example was misclassified is difficult. However, if we can understand the relationship between feature variables and the target variable in a consistent manner, it goes a long way in debugging models, also called<a href="https://christophm.github.io/interpretable-ml-book/"><strong> </strong>model interpretability</a>, which is an active area of research. At Fiddler, we’re working on a product offering that allows data scientists to debug any kind of models and perform root cause analysis. </p>



<p><strong>Profiling: </strong>Performance analysis is an important part of SDLC in 1.0 and profiling tools allow engineers to figure out slowness of an application and improve it. For models, it is also about improving performance metrics like AUC, log loss, etc. Often times, a given model could have a higher score on an aggregate metric but it can be performing poorly on certain instances or subsets of the dataset. This is where tools like &nbsp;Manifold [5] can enhance the capabilities of traditional performance analysis. </p>



<p><strong>Monitoring: </strong>While superficially, application monitoring might seem similar to model monitoring and could actually be a good place to start, we need to track a different class of metrics for machine learning. Monitoring is crucial for models that automatically incorporate new data in a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/">https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/</a></em></p>]]>
            </description>
            <link>https://blog.fiddler.ai/2019/06/ai-needs-a-new-developer-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24982113</guid>
            <pubDate>Tue, 03 Nov 2020 17:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plasma System Monitor Preview Release]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24981697">thread link</a>) | @ognarb
<br/>
November 3, 2020 | https://quantumproductions.info/articles/2020-2020-11/plasma-system-monitor-preview-release | <a href="https://web.archive.org/web/*/https://quantumproductions.info/articles/2020-2020-11/plasma-system-monitor-preview-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
            <div property="schema:text"><p>I would like to announce the preview release of <strong>Plasma System Monitor</strong>. It can be downloaded from <a rel="noopener noreferrer" href="https://download.kde.org/stable/plasma-systemmonitor/">here</a> <sup id="fnref-note1"><a href="#fn-note1" role="doc-noteref">1</a></sup> or you can browse the source code directly on <a rel="noopener noreferrer" href="https://invent.kde.org/plasma/plasma-systemmonitor">KDE Invent</a>. Please see the <a rel="noopener noreferrer" href="https://invent.kde.org/plasma/plasma-systemmonitor/-/blob/master/README.md">readme file</a> for what is needed to build or run it. If you run into any bugs, please report them on <a rel="noopener noreferrer" href="https://bugs.kde.org/enter_bug.cgi?product=plasma-systemmonitor">bugs.kde.org</a>.</p>
<figure role="group">
<figcaption>Plasma System Monitor's Overview Page</figcaption></figure>
<p>Plasma System Monitor is a brand new UI for monitoring system resources. It is built on top of Kirigami and a new system statistics service called "KSystemStats" that was debuted in Plasma 5.19. It shares a lot of code with the new system monitor applets that were also introduced in Plasma 5.19. It is meant to be a successor to KSysGuard.</p>
<h2>History</h2>
<figure role="group">
<figcaption>An early version of Plasma System Monitor. While the visuals have not changed much, the underlying technologies changed quite a bit.</figcaption></figure>
<p>Almost two years ago a project was started to create a new backend for monitoring system resources. This was initially intended to support a new set of system monitor widgets for Plasma. While working on this, we realised that the system monitor application could also do with a refresh, which would be a lot simpler now that we had a new system to build upon. After a little bit of iteration we had something that I was mostly happy with, with one major missing feature, there was no way of adding custom pages like KSysGuard has. To support this, we ended up unifying the display code between Plasma System Monitor and Plasma's system monitor applets, allowing one to select different display styles in the applet and also when editing pages in Plasma System Monitor.</p>
<figure role="group">
<figcaption>Unified display styles between System Monitor and Plasma: System Monitor's display configuration on the left, Plasma's applet configuration on the right.</figcaption></figure>
<h2>Features</h2>
<p>On startup, you will be greeted by the Overview page, that has been designed to give a quick overview of your entire system. It provides a view of important core resources: memory, disk space, network and CPU usage. It also provides a small version of the same table as used on the Applications page to give you a  quick view of what applications are consuming the most resources.</p>
<figure role="group">
<figcaption>Applications Page</figcaption></figure>
<p>Another new feature is the Applications page. This shows you all running applications along with detailed statistics and graphs for those applications. This makes heavy use of the grouping features that were recently introduced to Plasma. See <a rel="noopener noreferrer" href="http://blog.davidedmundson.co.uk/blog/modern-process-management-on-the-desktop/">David Edmundson's blog</a> for more details about this.</p>
<figure role="group">
<figcaption>Processes Page</figcaption></figure>
<p>The Processes page is very similar to the one in KSysGuard, but we have tried our best to streamline it and remove some of the inconsistencies in it. For example, you can now select the "Line Chart" display mode for any column that displays a numeric value. Similarly, the tree view mode no longer requires displaying all processes, but is now a simple mode toggle. (Please note: The tree view mode unfortunately requires Plasma 5.21 because some parts did not make it  for the Plasma 5.20 release.)</p>
<figure role="group">
<figcaption>History Page</figcaption></figure>
<p>The History page has undergone the least functional changes, the most prominent one is that the CPU chart will now be displayed stacked by default.</p>
<figure role="group">
<figcaption>Editing a new page</figcaption></figure>
<p>Should you find the pre-made pages lacking, there is a completely new UI to create and edit pages. The editing UI allows you to divide the page into several different rows, columns and sections. You can then select which sensors you want to display in which way.</p>
<figure role="group">
<figcaption>Display style configuration</figcaption></figure>
<h2>The Future</h2>
<p>Both the application and the underlying statistics system are still undergoing a lot of development. For example, we have been working on replacing a lot of the old statistics collection code with new code that makes use of existing libraries and systems that simply did not yet exist when the original code was written. This reduces the amount of work that needs to be done to maintain things and allows us to expose new features, like support for <a rel="noopener noreferrer" href="https://invent.kde.org/plasma/ksysguard/-/merge_requests/42">GPUs</a>. For Plasma System Monitor specifically, the plan is to include it by default with Plasma 5.21. We will probably not be replacing KSysGuard immediately, but longer term that is the goal.</p>
</div>
      



  </div><div id="comments">
      

<section id="node-article-comment" rel="schema:comment">

      
    
    
  
  
<article role="article" data-comment-user-id="0" id="comment-1" about="/comment/1" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/1#comment-1" rel="bookmark" hreflang="en">Great</a></h3>
        
            
            <p>wow this is impressive.
It looks like it gives IO/NET/GPU/CPU data per process, IO/NET/GPU/CPU charts per process, IO/NET/GPU/CPU overall charts.
Throw some sensors (temperature, fan rpm) in and you get ultimate monitor.
Do i have even more crazy ideas.. yeah, identify open files and identify window (procexp style).
Thanks!</p>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/1" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>

<article role="article" data-comment-user-id="0" id="comment-2" about="/comment/2" typeof="schema:Comment">
  
  
</article>

<article role="article" data-comment-user-id="0" id="comment-3" about="/comment/3" typeof="schema:Comment">
  
  
</article>

<div>
<article role="article" data-comment-user-id="2" id="comment-11" about="/comment/11" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/11#comment-11" rel="bookmark" hreflang="en">You see more applications…</a></h3>
        
            
            <p>You see more applications but less details - it's going to be a tradeoff either way. Vertical columns are not currently supported but are something I've considered adding  at some point, the code is flexible enough to be able to handle that. That would allow changing this for those who want it differently.</p>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/11" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>
</div>
<article role="article" data-comment-user-id="0" id="comment-4" about="/comment/4" typeof="schema:Comment">
  
  
</article>

<article role="article" data-comment-user-id="0" id="comment-5" about="/comment/5" typeof="schema:Comment">
  
  
</article>

<article role="article" data-comment-user-id="0" id="comment-6" about="/comment/6" typeof="schema:Comment">
  
  
</article>

<article role="article" data-comment-user-id="0" id="comment-7" about="/comment/7" typeof="schema:Comment">
  
  
</article>

<article role="article" data-comment-user-id="0" id="comment-8" about="/comment/8" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/8#comment-8" rel="bookmark" hreflang="en">It looks really good!</a></h3>
        
            
            <div property="schema:text"><p>Though the contrast is very low between the various CPU line stacks, and I am not even colourblind. Maybe lower the luminance a bit on the borders, a bit like the current ksysguard?</p>
<p>I also like ksysguard's "remote monitoring" capabilities. Is this going to be included somehow? One of the limitations was that it was necessary to have ksysguard on the other side, it would be nice to be able to do away with that at some point...</p></div>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/8" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>

<div>
<article role="article" data-comment-user-id="2" id="comment-10" about="/comment/10" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/10#comment-10" rel="bookmark" hreflang="en">Though the contrast is very…</a></h3>
        
            
            <div property="schema:text"><p>I assume you mean the colours for the stacked line chart on the history page. It's actually possible to change those from the editing UI, though we may be able to have a look at how the default colours are generated. Unfortunately, there's only so much we can do for autogenerated colours here.</p>
<p>With regards to remote monitoring, the new backend makes it somewhat harder to do but in theory it can still be supported. Personally though, I think remote monitoring is better left to a more dedicated system. One thing that might instead be interesting is to develop a plugin for the new backend that exposes a dedicated remote monitoring system as sensors for system monitor.</p></div>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/10" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>

<div>
<article role="article" data-comment-user-id="0" id="comment-13" about="/comment/13" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/13#comment-13" rel="bookmark" hreflang="en">With regards to remote…</a></h3>
        
            
            <div property="schema:text"><blockquote>
<p>With regards to remote monitoring, the new backend makes it somewhat harder to do but in theory it can still be supported.</p>
</blockquote>
<p>I'd be interested in that as well for monitoring remote servers.</p></div>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/13" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>
</div></div>
<article role="article" data-comment-user-id="0" id="comment-9" about="/comment/9" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/9#comment-9" rel="bookmark" hreflang="en">Thanks!</a></h3>
        
            
            <div property="schema:text"><p>I love KSysGuard and its functionality and this appears to be an excellent step forward. Thank you to all who are involved!</p>
<p>However I agree with the common sense guy that the overview panel should be changed from the default to what he mocked up.</p>
<p>I'm still going to test it out. Thanks again! :)</p></div>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/9" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>

<article role="article" data-comment-user-id="0" id="comment-12" about="/comment/12" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/12#comment-12" rel="bookmark" hreflang="en">feedback</a></h3>
        
            
            <div property="schema:text"><p>Hi, thank you for the great work. I hope you can retire the kSysguard asap as it is one of the biggest resource consumers in my system. A few points:</p>
<ul><li>I guess you know that the network monitoring doesn't work with systemd-networkd</li>
<li>it would be great if possible to choose separate colour scheme.
Thanks.</li>
</ul></div>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/12" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>

<div>
<article role="article" data-comment-user-id="0" id="comment-17" about="/comment/17" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/17#comment-17" rel="bookmark" hreflang="en">But kSysguard doesn´ t need…</a></h3>
        
            
            <div property="schema:text"><p>But kSysguard doesn´ t need any resources if you don't start it at all?
So I don´t understand why it should be retired as soon as possible.</p>
<p>I have just tested kSysguard on myself. It needs 28MB RAM and it shows 1% CPU load every now and then. It doesn´t look like very resource hungry.</p></div>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/17" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>

<article role="article" data-comment-user-id="2" id="comment-23" about="/comment/23" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/23#comment-23" rel="bookmark" hreflang="en">I guess you know that the…</a></h3>
        
            
            <div property="schema:text"><blockquote>
<p>I guess you know that the network monitoring doesn't work with systemd-networkd</p>
</blockquote>
<p>Yeah, the current network plugin in the backend only supports NetworkManager. It's been on my todo to add a backend that makes use of sysfs directly for all cases where NetworkManager is not available. I hope to have that fixed for Plasma 5.21 at least.</p>
<blockquote>
<p>it would be great if possible to choose separate colour scheme. Thanks.</p>
</blockquote>
<p>This is something that has been brought up for various other applications as well. I believe there are some plans to make this available for everything, but that may have been speculation. Could you open a feature request for it on bugs.kde.org?</p></div>
      <ul>
          <li><a href="https://quantumproductions.info/ajax_comments/reply/node/2/comment/23" data-wrapper-html-id="node-article-comment">Reply</a></li>
      </ul>
    </div>
  </div>
</article>
</div>
<article role="article" data-comment-user-id="0" id="comment-14" about="/comment/14" typeof="schema:Comment">
  
  
</article>

<div>
<article role="article" data-comment-user-id="2" id="comment-24" about="/comment/24" typeof="schema:Comment">
  
  <div>
    
    <div>
              
        <h3 property="schema:name" datatype=""><a href="https://quantumproductions.info/comment/24#comment-24" rel="bookmark" hreflang="en">In short, it's because the…</a></h3>
        
            
            <div property="schema:text"><p>In short, it's because the Intel driver does not expose that information.</p>
<p>A longer explanation: We need a non-privileged API to be able to access information from the system. Lots of things are available through either sysfs or procfs, which we expose as sensors. For GPUs, the current situation is unfortunately rather a mess:</p>
<ul><li>
<p>amdgpu exposes several files in its sysfs nodes that we can use to get global GPU usage, memory usage, speeds, etc. This is the best situation for us. Though there is a caveat: for some GPUs, the gpu_busy_percent file will not report a usage percentage and instead produce an "invalid argument" error, so even that is not perfect. I do not know the state of other kernel drivers, but if they expose the same files they should be supported.</p>
</li>
<li>
<p>nvidia GPUs do not expose anything on sysfs, but there's a tool called nvidia-smi that can be run as non-privileged user that will export a bunch of information. It even has machine parseable output. We can support this fairly easily, though it means having another binary that gets executed.</p>
</li>
<li>
<p>intel GPUs do not expose anything on sysfs. There is a tool called intel_gpu_top, but it can only …</p></li></ul></div></div></div></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quantumproductions.info/articles/2020-2020-11/plasma-system-monitor-preview-release">https://quantumproductions.info/articles/2020-2020-11/plasma-system-monitor-preview-release</a></em></p>]]>
            </description>
            <link>https://quantumproductions.info/articles/2020-2020-11/plasma-system-monitor-preview-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981697</guid>
            <pubDate>Tue, 03 Nov 2020 17:24:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix Programmer's Manual (1973) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24981678">thread link</a>) | @swatson741
<br/>
November 3, 2020 | https://dspinellis.github.io/unix-v3man/v3man.pdf | <a href="https://web.archive.org/web/*/https://dspinellis.github.io/unix-v3man/v3man.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>8'´‘dR¾ŸÃƒÒÎh¨�åä”%Æ´·j3îO(¸UZ´©¢'„$È‡§ÃT/ÎdkÍ¨¹rËËâÈÀ¨è–u†²ÅO=J½7:ÝY.ã'!}»�UÄ˜4_”)±Ý¡ö¬Ý[ÞøÉU(ùºQ2Tr*8]|è…õJÁ¾6ÃZ¤»ü4(�Ðç.\–“'£j[¶ß*ºÆÄÙôV	Ï+ŠÖoG²Ê¯ç×šBSÔþ&lt;»\,¦"
Å&gt;íº´ÌV&gt;
Œ¢KªcM*
™6“Î�ùIÜA’Q¼ÍV³(–™xÅy‹dßGa£0Ì¸LÅžýQ¾K÷�iÊÒJù´I@ÆVrà!ÓÕYä6c&nbsp;JpròŸy÷£/�®3Õ1sgsÃCÌÌ�ÌTòM¦YAŽ#wþRÊÅ‹ôØü¢eÚ/¾ý†FVYÑKàI4ãõŒkQM•øŸéÈ“l2Õ]®ú¯‘“I—æ¡Óû‰]\jÙÔp‡q€1ÓZYçÀ8‡žMKî­ú¹ûšX±[|h"ôêOÚâtª¢qúl®ýÇ0;i‰4pè¹÷
Ù0îØšNQ‘‡­ƒÚš0˜�¦LS¡DçŒ
ö~4@Ú}ÔàB÷¤ÆIª8­C“�S”M;¡´Gf ãÔ†z!ïTIUsckÙÔºã¦fÇsÔ€�ã2üº^¯¿¾âÔ'üQáÕOfdõ1Lê�ž#V¯xR÷ml¸Ü\y¬S¿ÇØç…ÝCM£ÀEãÏ˜io¥
Ttˆ¦ÕòúêÐZ¾ükf±Ý�Š�$‰Ãv¸'«rò3}&gt;Vî`endstream
endobj
14 0 obj
1065
endobj
18 0 obj
&lt;&gt;
stream
xœmVaoÛ6ý®_qË—Úƒí8mÑë§¬Û°M‚5J;`Z:Ë\%R!){ú÷{GJ–S,A#›§»{÷ÞÝ±O´^]ÑZ~‡gÑd—ŸÞRå³5UÙSv�4&lt;Š†~ÌñÂ;9ÈwYò¹¢wkz»~Cy“Íè›Ÿ›»üÓýO�ò›û;Êï)ÿõæ�n¯ï¯?Îó²W¯(ÿ˜Íò½öÔ(Ó©š*}`O%ûÂé6hk&lt;Ù…=SÛmk]Ô=©ƒÒµÚÖ&lt;‘]]Å;V¡sß}¼»ùc…Ô�Zg¡È°FGŠ*6ì�ÆØ4b¶™yfºÈ‘C|)×
/ý^9m*zè}àæ‚vÖ…
›9|,9„ä“O7mÍ
›&nbsp;õÚGwÚÌŽ{]ìÉq£´¡`iËTj¿ï¢¶žËÍ|…//_Æz¾¯¼‡Ê±"ÈwîÀ½_àpbKDoƒ"*?QRXphJ
(I˜óÔZï5¸C×T€ÞBÛN/´ÜÇcÖ¨’%h¡Y&gt;­œjÐø_U„ŒE¢fŒp†MüUˆÉÃ	¯ç"YŒ[WŠV†ð1è¢«•[ŒŒ"·vÏQxÛ°0SI)BÊÞvu‰ÒP%¤Cq×àIr&nbsp;%4H9ø&nbsp;Ú¦)d…æM]?b‹åu
°H‘ÔvAä,Q$âlfÒ(N*Æa±W¦âçj'p§
Ú…”B‰Ü�ê�¬¡Lx™®Ù¢+áÌÊÕAlˆÔö{U²6¶Ô;Í%¡‰jŽ™PèfÐ³e¡ãè4ZÁHE|�ÙÚÎ”ðáZ7Àá©›1$ôê©k—Á.Ë¨œGŸˆ3¥.pN“¶;Èœ*ð|H£3Œcê§ŒÄ	¤ù]µC¼ZÅ’Ò¥´NþlLR?ÇÒÑ$ßmæÓ œ¯|*µ´DA8ÖÕ&gt;œdûAÜeå¬dñ|°
¼Ê³yS´¥‰&amp;AåGŸhyè¶ZkÃ§óÏÑAÊ@þÈ-Ñ@¿ˆ&nbsp;·Qádˆ9=»¥Œ:¶„Þ‘¬ÓKòÖ­ö×µ2Œ	œ,0ÝŠ'e
ž¨K’�0±_,ylmö+¾•Ð:Îg’q¢¡²…¨€ÙN¡)QpJéŒ‰‚¥•…l©1žåö¦&amp;‘&nbsp;/ü	Ôjâ_®›ÿçLºˆd&amp;KA:€´®§Ëù›õzö÷6=tz˜ôÀÄÉòý_›‚ï˜”HúeþWþ[6›‚Ë,bÀŠ=«.X¨5ôä¿H`©FÝc­]Š¿ÒØ9ßE­°@ã4b¿gšˆgmÓðpíùˆ‡ß§öŽS¤E­q¼ÆíÞ"rë4ÎÄlæ³«à¼]£ô¸bœfŸf Œ—–ïZ¹Ñ¼uq×M‚.7Û¸sLÕ©ŠeýqCV=â²e§Û¶b„»À^»X`…ùÞXÓ7ÃeˆM”TpƒéÑ²iãƒëb=«(ÉPÐ5ab½“Ü˜’ô¬ó„¨Óÿþ„v*é´q„ÅñJI3,»o«�ô…Ì¥Dn¬CYãjþÊmnèZo�x]vÞ]â‹üS+%B¼~-Y…ˆoÿ{sö³ŒU/)õ§~þ­‘†Ÿóìwüþ-{<endstream endobj="" 19="" 0="" obj="" 1186="" 23="" <<="" length="" 24="" r="" filter="" flatedecode="">&gt;
stream
xœmVÛnÛF}×W,ô©�)£}JS=¨(Z´‘ÓqP¬È‘´ñrIïE
óõ=3Ë‹›‚½ÒrgæÌ™3C&gt;ªÕr­VüéÖ¢š¼þû�:†ÉJ'�“µÜTÝRTê—ÜòÆî0É6ku»RïÞÜª]5™íN¤BC…ÑVŒ¥&nbsp;ÑÔNm?©Ò„"…€ÍˆcÅI{]Dò&amp;DS„ùîëd½V»ß'³ú&nbsp;H'Ú©RSv4U—“Á,’¶¶Užäá©VÎ_ÿ95™•t6-•ºsÖ&lt;�j&lt;6ê•†A„…DvºãðÃÙ^|²K&gt;õëæƒÊ;ƒCíåp—íi¨KUØZ\“EñØ©Ù3…%Ž¿y#¹2a|›½W:Ž|�®ºH¹˜é
Ñ'äî‰�7ÚßÀGÇèKV{õ`\)±%ÞÏ˜¾éª±”ç=¶:Å&amp;EÆÝmØZ—È^»Ri©Ú[ü?Gs&amp;N7ß
›JÂ]Ÿ!6N;ûVÕÎò?”µ®*øX\GÿƒÓWÌ=êÎÌ*”FÇÎá/w*�ƒøCˆÆ×G¯«&nbsp;îgCÛû¹€quDXðS9ò–bŸîÝÛ;A-$GÞl¼q…iP!O:À%c¶Ð£@3î(5c&nbsp;	�k
†Š=Ã©á9¨ãbâ	l¢ö…&nbsp;½±-›ƒ7ö&nbsp;™pÃ’BáMÃàÁ'W^'˜z`oA#³ç$vH6"kÆc\–[=ÕM…~"kµ#ÖxOËýìÓ–™9jE‡Ô%DÁÔÁf·Û«¦ì*úNë˜åZ¹2ƒ¹EÝ¹ì¢$_§}«°ç¹)T¨+¤¢Ùéž
Ígq°åX’]akl]%ÆF9*ü�n4nH•ÞCS=ì€‘›s20¨s~O"4äEä¨ìŠ:2ìä$]Éýí[A¿‘ñÒÑ Ò	Q:G+—ª=„�ï(85œº‹à.z#�=R&nbsp;Ñ†GNùÊÀêŠÊÓ¢—Ûµœ‘LR©B¡&nbsp;öNªƒ8Íž0�ä«'7ÓR²Þ®MQóR(,-Ï¹M‹%ˆct�×OÛæ¤÷Íw*3:¶Ø9O fiˆÜ3:ª5Žß‹ÊH{kùT7bÍš<xzl°xð$Š<ârÃx‡É!alsâ…eà@&ìÝ¼pûÄ5…([eg¦×d>Ê¥&gt;&nbsp;ÍžGF­úö»‚Š1ŽÔUÜcìk—JF?�öåý|l˜÷ÖU<iø�Æ¬rÓc…¬ŽÝŸgŠ )ãüÇÕjöŸÎk•ÊË@2jeº›Ð™a©="">+”ç&amp;oþe÷[¯ñ}&amp;æm¯Â „ä4ÇØéO0…¾ÍK‡°ÎK“—îˆyòK¡›*L¦ïÝ³—û¥«T7XÑF`òØŒp/êy�â\¸\2n(‘?:ÈSh(µØs„ý\éHûi,Šê®;tTÆƒþ‚q’=�#%ÅÐ6äÑ�›cö.bÛàà× ß�‡�FÇh¿|îãcâ{¼<pägÊç ò,©»çÞ9f-õcÿ…x't‰<×†³p¿Ôr[°õÏ‰Üswa`—<ué”3åÖg·^t®ßlò«Ÿx!‹�µ¦á;].—Ó¡ly]f„ýkÐó$zp7pa¬™b4]Ë¢,lÔ}šƒ_¾ndi7*Ïœe9÷Û"¬Ínò="">ÿ­K\‡endstream
endobj
24 0 obj
1259
endobj
28 0 obj
&lt;&gt;
stream
xœ}V[oÛ6~÷¯8ÈËœÁñ’hûÚuÐ®×ÌÃ,Ã@“G2S‰TI*Ž÷ë÷R–¥&amp;››–x.ß¹}ÔWº\_Ñ¥ü
«n?\?§:..©^|]\åMÝÒ�¼�›jQt®èÅ%=ò‚6íbIÃõ’*ëTCÚ»;vÉzG6RÙÐö@iÇØi[åL”›öâ|s»¸º¢Í»“‰ÈÍÇ5l9R¡î[Ø¡-×Ö9ëjÚÛ´#E­u}¤hkGggçß�ôáÏW‰%õE¾=µ¬Eß2¾BÂ.U�ªGãSej²ÙDªëX…H0¨óÑæhö;Œ•m˜œjyª­}ß˜AlD¶ò�WbOòàö6²@Ú©;Î6âT¿ó±X�%â-\CìÉÉÓæû?‹&lt;¬“9vy¹ü›ËË¢ËÊbËÒ•%Íú²¸² ó:ÇhlÔ}Œœc7œ”mréb¿½…Èù_›·³¢©„xœùŒÕÌeóâÑsmQúì«$AJ%IBf¬FÙ?p¾ímƒä:$Uôºàë&nbsp;ÚG°¼¤8ó=,¤fÀâ,3ßë&lt;ü0zÎ7*¡­­C…[uñ˜è=
ÃÌ2¸¯g¥ð30ó¢éÇSw*š¤ÁXU;“Õr¯Ö¬U´˜¤ËôšMîVtèÑæÇä0!£ðAË�±YúàvÜÇ»`[àö³h/ÿç÷u­#¡«òà&amp;+Ý`¸²ó¬-;|„1&gt;j­"©¦9�j¢Ú¶®9J­*{�1ƒ0u°[þ¦s?¾³ìÂ¦Ì&lt;º0IrÀ[=¸m§0ãxZÀïg…ãÙì[•þ�Bß)q��	|lÁ·ÅÍÑí–µê….ÃR‚œ‹À’ß'ë2UhLUÊÄ½SÁHå:^¨"ø[DÔœuŸ|iäß&gt;¼ùcE7K¤Næˆ|0$æÂcÊi¾9‡`Í’-dRÂ�
Ôxa©2¬R¬ý@Î'µm„êOˆ&amp;®òôó,vÆõËø|ÛEïètÝ,®éñÌ¸9‡�SíMDô§5½_ÓµMzgyb`¦
÷ø4fE¯²Ñ¿­¼H¾]ÓÏkú£rNMôƒ¯ª9YFãûü‰Wý¦	þ0QIm
ÈÏFñ°keã²&gt;ÔvzÝ,�†tbC¶»
*FÕ†³ê»5½OïÕn’T'ËI¶Ñƒ,þ_¡Já0u#µ¢Š|Ähx=*ê˜3øjM¿"ƒ~Ë!Å‰bŠqe×ÉC€ù°¦OÖÍÊu³‘øh(ðË”÷tp§Èx]ÎtüVT:{Ò,xW§ûP+gÿ)ïGŽ�.SM·S[°‚Î“.ýˆ.d…Lb2ÑË|þf7B8Ä9´}álÃ÷ÿ¾'�G,Ç)8˜žß'æ‹&amp;6ÂaUtl*øåflâ¾}V9³pò£TrhHå‘þýée#†ñ'É¹(»¾E)d;�ƒdÌü–)ºR:çÎ¶ÞfT~9‰"�Ø»À-"Ì!É|’é»	+Il=*’É±xÍãi#ê$ú@JírrsvÆ—¶ß[Œ¹wØFœ|ÏAË{�Êº*&nbsp;.}£ÅXÊ°#õxúôÈ°›	›îA„]`	ÔàEÑ¸dúqìÜ§L‡&gt;ÐÀ¬æxj;3¡S1*Zù(NIŒ/f'j5[ÖÙÄ	ýÏu‘U.è.¯wÇûláõfñÿü‰[Îendstream
endobj
29 0 obj
1284
endobj
33 0 obj
&lt;&gt;
stream
xœu‹K‚@…÷÷Wœ¥Ú¤®ƒ6Q‹äî¢Å0ŽÓ”tÌèß§fËî¹ðÁy´a1i¡ªh�%0ŽµÍ!¨
;édpAßM„T Ù¤àŠ&lt;¾iHç¬ëe­4šYˆSÓuÖa|ÓÉ^Ï²|CªGÝ¼J��‡&gt;ß)[ð‘xuñðÿ?Â0Ììû³ý+hÏtõï¶4-endstream
endobj
34 0 obj
157
endobj
38 0 obj
&lt;&gt;
stream
xœ�V]oÛ6}÷¯¸ðËœÁNí$hŠæ)]³6E?°FC,CAI”ÄU"U’²ë¿ÃKY’›&lt;-z]“÷ûœÃ|§õé†Öá··Y3{öù’J7[S9û&gt;Ûð!õ&amp;kèU‚/ÂI1‹&gt;z±¦ËõsJšÙ‚žúyûé%ŸèÍMBwÉõçäæõIòïììŒ’÷³ER)GNf^M­5[•KG¾’”
§2Rº0¶|¼7i)sò†JéO~™m6Äya=¾Ç�??Þþõ’*³—jS"	�óGÓùåá(3MÓiµB�E&amp;¼DJkº²
I,yi¥E½dßÞÅvj,­hNá[H~ý{ñõäùz½x�‰¦&lt;2*ÝIÇßžü“¼›-îÑ_Ó9O™¨kâV¨°¦A$Z$n­âRûêNû;®kWã0Zc½£ë»ßno‡›˜è¾U…ÂŒÒ=O7IîéürÉŸßÜP"-�·¥§óõ:ž|��±òmÎ.Öq[a•éam¥Pè˜#øcÁÏhI®GŸÛWèìòb³BrRÓá2þ±ã&lt;‰¡ÎInmÉ;ç™Tb+1þ­¨UÛÆ%KZ4rI;”RQ#öãRN½@?¨ÂàYh§|ÅI½¬e[…:u×¤Ò.ã¤qÚp{ç%æž£Rå¼ÞX7-2?
(ÛmðØd+á®tIÂö:VÊru.lN®°6z]À�æÂ&nbsp;Tëž&nbsp;‰Äí”×T+Wq_d+¦N&amp;óÎJÊe+uÎÓÝUÈùMa¦J
þaªw;‡ÂŽ¡Ì”�°LŽÌ}ÿíy4—ý}42MóèE4u;çá=îÐÎÐAiÎý¼¤ùïÞJ×4À‹ÜçÇ`t¿÷ìÁý‹…ÞG¨…°oDM%¢ÞÌµÜ­jàeNE§ãÐÐ‰4`œ´`_)o+}g{qÁ�û{8Y’‚¦R z8âF¸ÁÐs&gt;ä¥˜÷›Ü#¥æ1}5ÑøhâÕ˜“/&gt;œœò ŸÜ\¿£õ‘YE“m£‹&amp;ÿßÛŒÆM–z×¡ï‘Jgu—Ë‰ÒLD¦1&nbsp;v®Üê§µ¶µØ�1–tóCf]P¶%%·qŸ™´�Þt­si�Ñ«a3ïDfRÔåàeÝT|J©AÌºÞ÷Ê2x3ÉaUh#BÄU¦«!�à+
§æ(~ŽU&gt;0fDÕ9^ÊJX‘!—£–5&lt;8"‘¯.ž@Ÿwm
u�¹~‚å£œÁc=ÐÎÃâ£áW'oèX~_x •�–èØÞ/„BaºÝa)P÷·«äînèï�ß¸À&gt;PFô¥’áå›ˆ³‘É;ÉÌòtP&amp;A`]
›‚3Ó�Ù	\ÈÑB¯¶ìe¬‘Îî
|±ÂÉáJ^Ëö|M­ßæCpâŠG¤RD§´�åPj�¦KÞ++çÑ‰ÉÚÖ«Ttù‘A`N	Õ Rƒ{_pf¬ÅŒbö«‘øüWÅäÁ*L]›�ÌÿþYž2ißJì	àòÕòèxÉª1Î.¨Ç’RÄ\,¹T€ü�Ô1Kxº&amp;kw]íEnÁâ7•£˜õ:S®ž9]‘6|Š¡€]xñ0ê0�N{UsâXþà�Ë˜–Dyyx„..Ž¤ìéŸUÔ2Ú²Ýª(M½9œ²Ý$³?ðû÷AIendstream
endobj
39 0 obj
1264
endobj
43 0 obj
&lt;&gt;
stream
xœ�VÛŽÛ6}÷Wµ{³»)º‹ä)¬ƒ4A»nÚ".Š15’Ø•H…¤ìøï;Cêbm7/µ([œë9sÈ/pyq—òíVUÏžýz…Ÿ]B1û2»Š/¡[T
¯·¼áVþØæ³ds·—ps}Ûzöyòù{ùÓååâ&gt;-”–jòK¥%¤Å¥Ewï`ò’&amp;{êÉV“œ„ðË¿¶ïf××°}?Kù¼u¶4°yý3\ßüxÖA(	^™Œœ·fý•ÝóÜSE*8­–ßÏ®®F�\­
V+0jò‚£®*À¦!t¯rÞÝf»e'ÉÜ°SÍîµò÷•ö%e+h»Š6sG¡uftbg¿}Øü1XûÒ¶UáÔð¾ÊÚ¼€9&nbsp;‡Œ¼rzOàÞˆí6¹x,G´) ³ä9õÐ¥“EÈéž8×Ì¯&nbsp;5•Uƒ±¤ÅÙì-ºö'ðGT)ÞäMßØŒÐdƒíÕƒ¼qTÛ@+y×åßÕ™rå¾H/Ýi%šb0o›dáN€jó¼­)Äà%^XÃíwÖlÓAý–QEF„³óc~\—Òx]7Ö4�7`€“mSFüàF´
ÖÚpIGn�Bö¤sh¬÷z_ÑKù1X¶ÜËnOE!¢ÍQ9&nbsp;&nbsp;×±Ãû–öÝØ6…Fð(È�Ã!‹1×½?q»‡ÆW¼1–èÛ½§/-q11‰{bQéK8kÒ–¡£ƒÎÈ¨1-îé�Ø©4ò¶ªNl\Ì+9÷áØ¤X_ãlá°^E6Ü—Tñp¤T¥7óïæ’»g¬w1pÜ%©êsîî‰3eòñ,ÂüŽ…7­a]ˆù#�kë£Üºe¬V2l¾­¤›!œv‹O›ÍnÉÙ”Z•�i¯ZïÉ�ùKÆqŽ uQEÈ£ÛŒê*6S»ÅæÓÄSjttë&lt;:-ƒ´yöqÌqûÃçER¢÷i±i)&amp;ËTÁ
˜lm;ŒJ&amp;­ãÌÐ	`&lt;ÐpÄSp¶
/†±ù“¡d^�g®3†2R2JRnSòÈ0wüŸN3sz¤tÁ%ƒ®l]K+*:PµJDÐ2Rù»Lä�Â?­±3Ì�àÁº	œP!œgJÈÜÇqäÉ´1&gt;û¬ûÈB;Ã�E–MaæÉª{:px†è+r•4Ñ;Êt°nˆÑš.Àà˜¾’j£""Ë¡YÇ(£NwñjsQ›§áµGs–D$ÅZs"nZG˜%¡iÂî¸L³¤ùd²1´Í×¹®¤ôL«HkßÑ.ÛÁs9ÉÊÃ‹Á\Æ‹Cz;¬Liuý@LnÆ%õ‘Sï³µ&gt;É’ÈK_aÏ¢=)lEC”Þ=‘�²5ÅºmÎôÚš³!��±c©œ ÜŠØzKÿoÅ�¨¸[¼ù¸U¢ð€\óà,ó(›ï–2/R�‰öI�ÆÊLd<bŸ8Èg*È¹ó­š"y¥0&j¦ŸîÜ(¹¶‘Ü 'ú ã±v^vÚÓÏÖn‘~³Øì–»åsbr7q‡ãô‚dar§²“‹r="3½hMnOýukê¼œÜ¾¦òÔ)YÙYœžÚãþ÷e.ißï%Óm8qòÄjž£ZäšApíT‚é_&nbsp;&nbsp;°û.¬‹<�)­Ý}¦/(w!¾&nbsp;@S¡¢Ä)vòüy�|ó³ŽI¯á×ƒN…M—~S¬ìÍvöÿ›wÓendstream" endobj="" 44="" 0="" obj="" 1277="" 48="" <<="" length="" 49="" r="" filter="" flatedecode="">&gt;
stream
xœuVïoÛ6ýî¿âà}¨3ØiÒk�}Y;lX†bE0%�%.©�Tÿ÷}w”l¹ëb$t$Þ¯wïùH7×·t#Ÿq-»Åóß_Q7T/·ú’Æ¥ìèí^Ëƒí~‘mnéõ
½zñš¶ÝbU6&amp;˜2qˆt°mKÎ'*˜jû‰%O†úàë`:\²-ý@éØ3™«í¿‹Û[Ú¾[l¿ý{8
Á­ÉDª8–Á\‘)ü'&amp;ëèãÕw77«wyñy©/›7&gt;¤¯=½¾úgûëâÅ‰¹úã·»¿4“C°HŸîž¿'i?´í¦ú–Ÿh·â§’ûD{èž[.S°åÕ³1íÌ:ëLwW×Dw‰“P`SmLƒ¿k:4¶l¨cã"¥Æ$�&gt;V¥q#‰Œ;R²¯‰7˜´&lt;ƒya§u5eók±¿§Ò!ÂÈîÏ¸VC��~Hý�ÖˆÈã÷ÜŸÆ|b±–çÖÉãY­“¥Ç/W¨è@:AJ0I¾M©k u‡VGx¬hèQD•=ôh&amp;Ëw$P£È�»’%ñÿmÃ�¥2C­íl²HR¦ó`
ùýˆÅl¯ÙmÎ-àà‡¨‘…x­}àö(ž�—ôŽ+IÍµ£:�Ç˜Xñ´N�yÑ2jý³¾bË9ê˜6O®Ö3'b“ïñ¶l¼@þ%œkÍ+&amp;ÒyÓò›%RãÎ$áÝa¤„vOP0Ôš8ó4Rè`²®”&gt;Z”;5ÿ²•^œ_GÍxâ€QWb/!Ò‚dÚdö=Å¡È}ºà„Þ�à
›9˜ã¬•ïš8¥DkgÀÎ…,XÒÒEË�3Þ�;9©H &amp;Æ‰£ŸøßYàùÀ‘dz
eràÞØ/iDìÂìHp`ù¦�þ?9&nbsp;Lä8ÍÁhO�¸ÊÄ¤4`·Pòd«8g\˜òèfžf	<z7ò¥àÚ:§c¹k^�ù bñ›+¢="" à�lÐ…~¢—¬�fæjÜÁw‡î§†–»Ýîv«{)×çõéz¹åx¼”wˆ%‚u1‰ôæþÇ»;zv¹Äk82××æš–a(="" ËÝÕ="" l„ÔØ›•‹ggè1Ý˜gÖat0iz¤”xfõ«ÒœòÂy="" Ë�—~Ü9ÚÇ7õ…7“—v”}™)uüwÑÖpì1¡#rmîiâ&¸6þ…!÷.)x£ä'Î‚?="" s©žàg[&ª="" ªæaÕcŒ�Ìt'½òîäØ¸4Ùpb@ƒ"†îrpkoh]&"¡ë0mò5Ëž5á�ÊÊ‡æØ½e25«ÁÓ÷Œh·šz2¬•m5uzŽ="" À¯äá(Æüd:œˆk¤–Ê†Çƒ"="" }Š£Æ‰ª’eÁ¬dëÖb:‹6Å‘w:Ò�ž|ggÓŒ@æ´[Ý“:Á©¬—µõqœÚË™©iÊ0ÀŸx.ì”Ê•‡¼Ø¼¤¼l æsf="" [©„fíi§9ùù~œ†�’ê|È¬�áðîÌ-s"Ñlˆo¨Ë ¨¨b«æƒ’Òñvs1ì="" h‘edÖ71‡kq+dðaÈm@l\fôòrq1Ôp¡z6öo9Úju¦o™áùxëe,.c´kÊ÷¥`a¡­‹.xû×¶¶–ƒÃÚ�f)©d×óÃœ�="" r)r|p©^âÚäÊd!á="">œÌQF7D½OFÛ
­öCìóõ)46ùæ¨&lt;W›=«zßåã¼Í§liäž„1ÍœÔƒzt@ÙAÔi—oyŠ‘ÚFüÍÎB±Ýé‰�CÈU&amp;äˆ@Wo
&nbsp;’’FáQ¢ù2€¼Ò&gt;g#ISCæ#}BÂI*È·:Œ·@ì'ÐA„¥óÕxºÆ”À4ßuz·ºCz#¸F&lt;]_¾œ¦€þÿg£s°¡&lt;öI—§é±rý§íâ&gt;ŸIèþ8endstream
endobj
49 0 obj
1439
endobj
53 0 obj
&lt;&gt;
stream
xœ}Vï�Ü4ý¾Å¨bíµ{mE+õHHB…r¡€X„¼Ž“˜&amp;vj;·—ÿž7cgÐŠž*ß93ž™7ožý‘vOoiÇ?eÕÃêÙ/¯¨�«µ«�«[ùHeÑ}[Áà5oTÍ*ûÜÒë½zþšªaµ®Ô�t§‚ÒÉ„H*š¢©©	Æô3YG¿¾½û�¢Ÿ‚64ß5Ä§DwÍ¦úgu{KÕ�«õŒÏ„ëTOµ7‘œOÔ©C©ÃDi&amp;§“õnK°&amp;­ÜæËÕZ…&nbsp;\2(MÁ!ë°G¥qZ=ëZòS§´%åjö6ºó0Tñ?fÖÁ
9Vç˜p¦Šq`‘:•8�˜£ã»IdL˜ÉØ¶K¤}?
Ž+ü¦UÙrþ1¥_†�i¿¾ÛoØýhû^ü}&nbsp;`ø—ÔÙHƒ¯
»÷Ñ‹7‚`WQc{CÇÎênËÞ¶œ¨xGUõ½xÅ'Uã[öb·;a·tŠ†#ÙŸ1�É�‰…`tB»ö¼÷ë÷wHq¿y
»çÏ¥C÷FÀ§Z#ý÷û
Õ6ê)F†dÍ1X„¢»g?!}$ÜL}?£ˆâ†sJ§?ôŸú í]ô(ï|Ö9võÕŸë¿7_ïvëïóâór¤¼¦²[þy™òâÊ®*ëxeTNj¯6U^†¼¼)ŽU^º¼˜²{½›—¾,›¿ªVëß:ã„²BÐ8i-
&gt;Ôû¶]ˆÊcb.#rFL«¾‡£tßôdè-Hé˜ªð¼žÂZ±ä.£êÜ¢úÃØ[gÀ…8ö6Å&lt;-Ó˜P'‚:5˜eDThÁ{—¢
™G£§tjšØ3WO¾H.ÚaDqy@³ƒ:ô§á¿ÌøÌ1±VH)z]bïÚ21}`fFcÈ™Ç§À¡t?!‚§Nòjíƒ‘à\HÎÃâ¼“A’‰’ÁrR-~ŠÅÌ[WËÜA‡::ŽF[ˆ“:@DŠÏ
B?ØÝ)åÇ\²6c*JÑ™YDñoI¸sMG‰qnlÑ´Æ:i÷p1~ÕîÜV„þ¨æÜ‰àÑÑå²‚I·ßœ™dSÆ"±N—¶RÖ°
žD¶ý@”âº1Ñ‡™µñ†óo/2ZŸÁ/üKÌ®sE¢9È
_‚'‚aM¼à¶w)ø^ÒbŽâÀ'_<!--�ÇR
«qjF n¦ô,@qûKž¯!ËYtx|œ©˜ªQ,Àr²"¨‚Bm¢ö`êÄ x&)Ûsë
ï(v¢àŸ¨Ï‹„¾R¤pµÉpEÊŠG�û9S}­zW&s–¹r¹êri,wX¾,ëÌÃÎš ‚î�K³�òæ\z�:Uisº¸k´êº�ý–%�[¥øÖBM¹œà€KÇ“F³˜W—´ç¶±Ï~}ÁŒexÙ92Á³Å,	§Ã{É‰O€~_±Ü[.t™ùÌæè×¦QS/ó'7ìyÔqCY§Åa¹Ð¹Xt\®Í·gg§‘I#H!ƒ¾27Á)¾Á�V�©Øò�j�ç³Œsž'±þÄ¿+€†<:‚Jfí’Ú"ãÂõÆlÅNì0ÀÓ˜ßÕY¾9äŠ`p�
¹8y 0A•�%»£\�Ð¬xÏm©1Çü|cü#ÏzBå˜œ�†(5W8•Z�W†êYF€ÐU¿åè¹9êrL=¿å
Ç—µŸ.…ÿ�%ã× °�_KMþ‚­‚¡”ydM5®öG”!øA8@Ë‚#?MðË—ËÓÿü»‘éº¡GY—¿eÚ¾«Vïðó/ÿi¡ˆendstream
endobj
54 0 obj
1334
endobj
58 0 obj
<</Length 59 0 R/Filter /FlateDecode-->&gt;
stream
xœuV]oã6|÷¯X(Î)lÇNŠ&amp;è=]‹+à¢W´=)P-Qq©#©8þ÷�]J–œ^“Ú\r?fg‡þL›õ–6üß¯Y3»ýý�Ê0ÛP9û&lt;ÛŠ‘ú%kèû=&lt;òÆ¾˜¥;[zÜÐÃÝ#í›Ù_‹n¾Ýl¿¦E¥%¦¥¢´Ú+c“�–pó÷þ§ÙÝíž-öŽ¼.´×6ÓT˜Z².’±+MYça‰”¯³èüyIg×QÓ…xóf¶ÝŠ‹.hRÔªX‘U�^ÃÒ;ÿ±«ëÑè¨K8&gt;lÌoçK	Ár…|öÎõ±V£{;8U®NiR8‡¨›5Ñ»"j/ÖP«PQæ8¾ÃÅbð®UV�UàŒ�ÊXcË”ƒ~‰ºãêr‚ï…«kwÒ9Ï¨)n¨³ÑÔHÁªº&gt;ËmIG™0IçÂâýº\‡k]ð·µnnùàË&lt;á�]º9ï·�ÌUø9®Ìß’,ìÙÄ&nbsp;ëy\%ÊÅÍ€OòÂ7CëQYèÝ!ËÂ»æÀ|wÒ©]Á�õÿm8U*pÄaÃè�ú6¶ulrIÂ¯QÐ¤á¯{=ñy¦ÃÂ:Î¼6æ€Ö“üžàÂuàeÓ:2Ô/™n£qv9%5êŒ¨Næ¤ìyÂ£ç„³¯Úõ¹CùŠK0©Q6&nbsp;�}—›"µœù˜]*V^�¡²ö°Øn–Ô&lt;÷à†|ÓIî¼-Ê7ÏºfB¶˜­Æ=k`aÖ2Dti‚sr[‹U¢�õ{f¶�3ªØ�ùðuçéªk&lt;§u�Ä#_‘op÷QºO8žÌ…óì¡QŸxD&amp;^Þ¢Šé)ÊuˆÞ�ûIj¦Ã+Ð†hN$d]h×ÐÿÉ/)è	z&gt;¬¶«íÝÃýê¤¶‹ÒTU×w&gt;yzÊZ±hÅÊ»®¬àCTcÁœ&nbsp;Ý.ÅA‹ÑÂNÕê}"èXŠMæàègmù¶‘A&nbsp;ÜÙ7¬‚èrÎ±r­ê‘ÇýU•&nbsp;Wp×káÚ9•�*�4&lt;Ö#û¯Ý~J‹O‹¹’os¥Þe/æª_Û«›®?tµ9¾H&lt;‹;XÚ«cd‘s" ˜t×zWzÕp•»ü²ûSº"LÛ¡ó�$ûJÐÖ|ÕØÌ´Àd¨7°~‰åGH®9,Ðf˜ÄÏ½²½¡È.fçi›=dƒåJí‡ô¥.V©£Ö6Õ‹ÙXÑ¿:7‘ùÇ'o"ÚJ`‰êëåŽgH¤Ä0Žä*ýmÕ"jVQ_
æø™�½büáÌ—]ƒð=PÌ¶‹2‡‰ð_¸x2x�Ì•"ŽùLßU/SAfM€@ª5"ÌìÀâ/YÕ £™q]Xòuûæ™«1‘¤Ý‰m+¥ÈapÎ®1Ö”¾{ò.J&gt;CC/U$Ð¤ÔsTl³ZË°ÔNå2‰“.ÉìÔæèJ€ö£;ÑXî}}Å1ÇÏ‡88¹/Àdf¦ˆ:¨.ºFEÃûÓWí©BŸ9ÏJ‰t¦7»tVOø¼0à"H®“‡ƒ%¦g'bˆGÍP¥uûÇZÞÕ‘ÍC½L§£�Çw–?€[lÇ+žÐNì¢�•F-@˜ŸgÃÅ0ÿjž^D×´qRÓ~ø½Ò¿Nc~T“0ß�˜�®cW–Ú/a€›ûûAŽèÿÿV¢"+z‘õÅ$q¶E\Þïg¿áÿ_íSv*endstream
endobj
59 0 obj
1260</z7ò¥àú:§c¹k^�ù></bÿ8èg*è¹ó­š"y¥0&j¦ÿîü(¹¶‘ü></pägêç></iø�æ¬róc…¬žýÿgš></xzl°xð$š<ârãx‡é!alsâ…eà@&ìý¼pûä5…([eg¦×d></endstream></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dspinellis.github.io/unix-v3man/v3man.pdf">https://dspinellis.github.io/unix-v3man/v3man.pdf</a></em></p>]]>
            </description>
            <link>https://dspinellis.github.io/unix-v3man/v3man.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981678</guid>
            <pubDate>Tue, 03 Nov 2020 17:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finland's Covid sniffer dog trial 'extremely positive': researchers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24981620">thread link</a>) | @ValentineC
<br/>
November 3, 2020 | https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nav-container="">
                                        

                
                <div>
                                <nav>
    <ol>
                    <li>                                        <a href="https://www.rfi.fr/en/" aria-label="Back to homepage"><svg xmlns="http://www.w3.org/2000/svg" viewBox="9299 -3984 9.748 12"><path fill="currentColor" d="M-1805,3480h-3v-7.125l4.875-4.875,4.874,4.875V3480H-1801v-4h-4v4Z" transform="translate(11107 -7452)"></path></svg>
</a></li>
                    <li><span>/</span>                                        <a href="https://www.rfi.fr/en/live-news/">Live news</a></li>
            </ol>
</nav>
    
                
    <article>
        

                        

            

                            <p><span>Issued on: <time datetime="2020-10-28T16:38:05+00:00" pubdate="pubdate">28/10/2020 - 17:38</time></span></p>
                    

    
                                    <div>
                                                                                                                
<figure>
    <p><img src="https://s.rfi.fr/media/display/7006f538-193c-11eb-bfd9-005056a964fe/w:310/p:16x9/61e9874f1c836ef58147abd96c3dad75be8c1d7f.jpg" alt="Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall." data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-image-dataset="{&quot;url&quot;:&quot;https:\/\/s.rfi.fr\/media\/display\/7006f538-193c-11eb-bfd9-005056a964fe\/&quot;,&quot;filename&quot;:&quot;61e9874f1c836ef58147abd96c3dad75be8c1d7f.jpg&quot;,&quot;ratio&quot;:null,&quot;displayFormat&quot;:&quot;16x9&quot;}">
    </p>
                        <figcaption>
                <span>Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall.</span>                <span>Lehtikuva/AFP</span>            </figcaption>
            </figure>
                                                            </div>
                    
                

    
            <div>
            
                            <p>Vantaa (Finland) (AFP)</p>
                        <p>A pilot project using sniffer dogs to provide instant and pain-free coronavirus testing at Helsinki airport has shown promising early results and proven popular with travellers, researchers said on Wednesday.</p><p>Three dogs, named Kossi, ET and Miina, have sniffed swabs taken from 2,200 passengers in the month since the testing booth was set up at the airport's arrivals hall, and have found the virus in 0.6 percent of travellers.</p><p>Although the research is not due for completion until December, the team say the initial findings appear broadly in line with detection rates of the nasal PCR tests also conducted on arriving travellers.</p><p>"We have done 16-17,000 PCR tests at the airport and less than one percent are positive," Timo Aronkyto, deputy mayor of Vantaa, told reporters.</p><p>Compared to the results found by the dogs, "they are about the same, I don't think there is a statistical difference," Aronkyto said.</p><p>The researchers are now analysing how closely the two sets of test results match each other -- whether the dogs found coronavirus in passengers whose infection was confirmed by a PCR test -- and hope to publicise their findings at the end of the year.</p><p>Preliminary experiments in the first major wave of infections earlier in the year suggested the dogs can detect the virus with close to 100 percent accuracy, up to five days earlier than a PCR test.</p><p>Feedback from arriving passengers, who take the free-of-charge test voluntarily, "has been exceptionally positive," project manager Soile Turunen said. </p><p>Around 100 travellers a day have been queuing up for the test, which involves wiping a swab onto the skin which is then put in front of the dog, who will quickly pass over a negative sample but will be attracted to a positive one.</p><p>"People don't complain about the queues, in fact it's the opposite," Turunen said. </p><p>"They're coming up to us to to say 'Hi' from morning until evening," she added.</p><p>A fourth dog, a German shepherd called Valo, is currently in training to begin work at the airport testing booth.</p><p>The Helsinki University researchers behind the trial, working with sniffer-dog specialists from the organisation Wise Nose, hope that their research will persuade the government to fund a rollout of the dogs for other uses, such as at tourist hotspots or large public gatherings.</p><p>Although sniffer dog trials have been undertaken elsewhere, such as in the UAE, France, Ruussia and Chile, use of canine scent-detectors to bolster coronavirus testing has not yet been widely adopted by authorities, in part because of a lack of peer-reviewed literature, some researchers believe.</p><p>Dog handling charities have previously worked with dogs to detect cancers, Parkinson's disease and bacterial infections using samples taken from humans.</p>
            <p>© 2020 AFP</p>        </div>

            
                </article>
            
        
                                            
                                    </div>
            </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/wires/20201028-finlands-covid-sniffer-dog-trial-extremely-positive-researchers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981620</guid>
            <pubDate>Tue, 03 Nov 2020 17:16:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Supermetrics Alternative on Deal (save 96%)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24981393">thread link</a>) | @pauljeba
<br/>
November 3, 2020 | https://www.dealify.com/two-minute-reports/ | <a href="https://web.archive.org/web/*/https://www.dealify.com/two-minute-reports/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div id="fws_5fa5735481263" data-column-margin="default" data-midnight="dark" data-top-percent="8%"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div id="fws_5fa5735482a2d" data-midnight="" data-column-margin="default"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p>Tired of creating the same reports again and again? Reclaim 80% of your time. Create reports once and reuse them forever. Pull dynamic data from Google Analytics, MySQL, PostgreSQL, PageSpeed, and much more.</p></div></div></div></div></div></div></div></div></div></div></div><div id="fws_5fa5735484ecf" data-column-margin="default" data-midnight="dark" data-top-percent="5%"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="left-right" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h2>Tired of creating the same reports again and again? Reclaim 80% of your time and automate reporting directly in Google Sheets with the simplest reporting automation tool available.</h2></p><div><p> <iframe width="560" height="315" src="https://www.youtube.com/embed/nIH_P4WVSyE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div><div><div><p>It’s that time of the week again! Time to send out the reporting.</p><p>You need to create the same marketing report, business report, or product reporting almost every week, or even every day.</p><p>Opening multiple platforms, downloading data, copying data one-by-one, creating charts &amp; reports to send identical emails – all taking up a lot of your time away.</p><p><strong>The same tedious task again and again.</strong></p><p>Quite tiring.</p><p>Well, think again!</p><p><strong>Meet <a href="https://www.gox.ai/two-minute-reports/" target="_blank" rel="nofollow noopener noreferrer">TwoMinuteReports</a>.</strong></p><p>The most simple reporting tool available. Monitor your product and business metrics quickly and easily, fully automated in Google Sheets.</p></div></div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h3>Automate and simplify your reporting work directly in Google Sheets</h3></p><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="15px" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="400" width="640" data-animation="none" src="https://www.dealify.com/wp-content/uploads/2020/10/welcome-popup-640x400-1.jpg" alt="" srcset="https://www.dealify.com/wp-content/uploads/2020/10/welcome-popup-640x400-1.jpg 640w, https://www.dealify.com/wp-content/uploads/2020/10/welcome-popup-640x400-1-300x188.jpg 300w, https://www.dealify.com/wp-content/uploads/2020/10/welcome-popup-640x400-1-600x375.jpg 600w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw"></p></div></div></div><div><div><p>Consolidate your Marketing/Product data from different sources into a Report or Dashboard in minutes.</p><p>The super-intuitive user interface that’s simple and easy to use so that your brain gets excited and not drained out-of-energy while creating a report.</p></div></div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h3>Simply connect all your sources in seconds and generate the reports automatically</h3></p><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="15px" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="562" width="640" data-animation="none" src="https://www.dealify.com/wp-content/uploads/2020/10/2mingif.gif" alt=""></p></div></div></div><div><div><p><strong>Pull your marketing/product performance data into Google Sheets.</strong> No restrictions, no security worries, just raw data saved to your own Google Sheets.</p><p>The tool already connects Google Sheets with many of the important data sources – <strong>MySQL, PostgreSQL, Google Analytics, Google Search Console, LinkedIn Ads, Facebook Ads, Page Speed Insights, Firebase Cloud FireStore.</strong> You get lifetime free access to new data integrations, added every week!</p></div></div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h3>Integrates with all the tools you use</h3></p><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="15px" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="479" width="1392" data-animation="none" src="https://www.dealify.com/wp-content/uploads/2020/10/tmr-integrations-v1.5.png" alt="" srcset="https://www.dealify.com/wp-content/uploads/2020/10/tmr-integrations-v1.5.png 1392w, https://www.dealify.com/wp-content/uploads/2020/10/tmr-integrations-v1.5-300x103.png 300w, https://www.dealify.com/wp-content/uploads/2020/10/tmr-integrations-v1.5-1024x352.png 1024w, https://www.dealify.com/wp-content/uploads/2020/10/tmr-integrations-v1.5-768x264.png 768w, https://www.dealify.com/wp-content/uploads/2020/10/tmr-integrations-v1.5-600x206.png 600w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw"></p></div></div></div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h3>Create beautiful reports or a dynamic dashboard on autopilot</h3></p><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="15px" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="800" width="1230" data-animation="none" src="https://www.dealify.com/wp-content/uploads/2020/10/banner-reports-2-1.jpg" alt="" srcset="https://www.dealify.com/wp-content/uploads/2020/10/banner-reports-2-1.jpg 1230w, https://www.dealify.com/wp-content/uploads/2020/10/banner-reports-2-1-300x195.jpg 300w, https://www.dealify.com/wp-content/uploads/2020/10/banner-reports-2-1-1024x666.jpg 1024w, https://www.dealify.com/wp-content/uploads/2020/10/banner-reports-2-1-768x500.jpg 768w, https://www.dealify.com/wp-content/uploads/2020/10/banner-reports-2-1-600x390.jpg 600w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw"></p></div></div></div><div><p>Create a <strong>beautiful report or a dynamic dashboard</strong> from your data. Arrange the charts and data the way you want it. Format your dashboard or report with familiar tools right within Google Sheets.</p></div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h3>Eliminate hours of manual work by scheduling automated reporting emails</h3></p><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="15px" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="800" width="1230" data-animation="none" src="https://www.dealify.com/wp-content/uploads/2020/10/banner-schedule.jpg" alt="" srcset="https://www.dealify.com/wp-content/uploads/2020/10/banner-schedule.jpg 1230w, https://www.dealify.com/wp-content/uploads/2020/10/banner-schedule-300x195.jpg 300w, https://www.dealify.com/wp-content/uploads/2020/10/banner-schedule-1024x666.jpg 1024w, https://www.dealify.com/wp-content/uploads/2020/10/banner-schedule-768x500.jpg 768w, https://www.dealify.com/wp-content/uploads/2020/10/banner-schedule-600x390.jpg 600w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw"></p></div></div></div><div><div><p>Once you’re happy with your dashboard or report, you can eliminate hours of manual work by <strong>scheduling automatic data transfers and emails</strong>.</p><p>You can <strong>automatically refresh your data</strong>, so your spreadsheet dashboard is filled with almost <strong>live data</strong>.</p><p>You can also <strong>send PDF, Excel attachments, or your entire report as an image in the email body</strong> to your recipients.</p></div></div><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="15px" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="562" width="640" data-animation="none" src="https://www.dealify.com/wp-content/uploads/2020/10/2mingif2.gif" alt=""></p></div></div></div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h3>The Best Supermetrics Alternative</h3></p><div><p>Already using Supermetrics? You’ll love Two Minute Reports even more!</p></div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h3>And there is much more to come</h3></p><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="15px" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="540" width="960" data-animation="none" src="https://www.dealify.com/wp-content/uploads/2020/11/Two-Minute-Reports-Roadmap-1.svg" alt=""></p></div></div></div><p data-direction="horizontal" data-color="extra-color-gradient-1"><h3>Trusted by hundreds of companies that save tons of time reporting</h3></p><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="15px" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="346" width="1410" data-animation="none" src="https://www.dealify.com/wp-content/uploads/2020/10/customers.png" alt="" srcset="https://www.dealify.com/wp-content/uploads/2020/10/customers.png 1410w, https://www.dealify.com/wp-content/uploads/2020/10/customers-300x74.png 300w, https://www.dealify.com/wp-content/uploads/2020/10/customers-1024x251.png 1024w, https://www.dealify.com/wp-content/uploads/2020/10/customers-768x188.png 768w, https://www.dealify.com/wp-content/uploads/2020/10/customers-600x147.png 600w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw"></p></div></div></div></div></div></div></div></div><div id="select" data-column-margin="default" data-midnight="dark"><div><div data-using-bg="true" data-t-w-inherits="default" data-border-radius="15px" data-shadow="small_depth" data-bg-cover="" data-padding-pos="all" data-has-bg-color="true" data-bg-color="#ffffff" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>Two Minute Reports Pro Plan Lifetime Subscription</h4></p></div><div data-list-icon="steadysets-icon-checkmark" data-animation="false" data-animation-delay="0" data-color="accent-color" data-spacing="default" data-alignment="left"><ul><li>Lifetime access to Two Minute Reports Pro Plan</li><li>Automate Reports in Google Sheets</li><li>Access for 1 user (stackable)</li><li>All Data Sources</li><li>Unlimited Reports</li><li>Unlimited Queries</li><li>​​Unlimited Rows per query</li><li>Send automated email reports</li><li>​​Unlimited Report Templates</li><li><strong>Unlimited Accounts per Data Source Type</strong></li><li><strong>​​Unlimited Active Schedulers</strong></li><li>Choose Google Analytics sampling method</li><li>Integrations with: MySQL, Google Analytics, PostgreSQL, PageSpeed Insights, Apple App Store, Linkedin Ads, Facebook Ads, Firebase Cloud FireStore</li><li>Slack, Trello, Stripe, Google Search Console, Play Store, Google Ads, Twitter Ads, Hubspot, Zoho (Coming soon)</li><li><strong>5 Google Data Studio Connectors (Coming soon)</strong></li><li>All future integrations included</li><li>All future updates included</li><li>30-day Money Back Guarantee</li></ul></div><p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#00d2f3" data-color-gradient=""><h3><strong><em>$129 </em></strong><span>94% off</span></h3></p><p><a href="https://www.dealify.com/checkout/?add-to-cart=62765" data-color-override="false" data-hover-color-override="false" data-hover-text-color-override="#fff"><span>Add to Cart</span><i></i></a></p></div></div></div><div data-using-bg="true" data-t-w-inherits="default" data-border-radius="15px" data-shadow="small_depth" data-bg-cover="" data-padding-pos="all" data-has-bg-color="true" data-bg-color="#ffffff" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>Two Minute Reports Startup Plan Lifetime Subscription</h4></p></div><div data-list-icon="steadysets-icon-checkmark" data-animation="false" data-animation-delay="0" data-color="accent-color" data-spacing="default" data-alignment="left"><ul><li>Lifetime access to Two Minute Reports Startup Plan</li><li>Automate Reports in Google Sheets</li><li>Access for 1 user (stackable)</li><li>All Data Sources</li><li>Unlimited Reports</li><li>Unlimited Queries</li><li>​​Unlimited Rows per query</li><li>Send automated email reports</li><li>​​Unlimited Report Templates</li><li><strong>12 Accounts per Data Source Type</strong></li><li><strong>​​30 Active Schedulers</strong></li><li>Choose Google Analytics sampling method</li><li>Integrations with: MySQL, Google Analytics, PostgreSQL, PageSpeed Insights, Apple App Store, Linkedin Ads, Facebook Ads, Firebase Cloud FireStore</li><li>Slack, Trello, Stripe, Google Search Console, Play Store, Google Ads, Twitter Ads, Hubspot, Zoho (Coming soon)</li><li>All future integrations included</li><li>All future updates included</li><li>30-day Money Back Guarantee</li></ul></div><p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#00d2f3" data-color-gradient=""><h3><strong><em>$99 </em></strong><span>94% off</span></h3></p><p><a href="https://www.dealify.com/checkout/?add-to-cart=62764" data-color-override="false" data-hover-color-override="false" data-hover-text-color-override="#fff"><span>Add to Cart</span><i></i></a></p></div></div></div><div data-using-bg="true" data-t-w-inherits="default" data-border-radius="15px" data-shadow="small_depth" data-bg-cover="" data-padding-pos="all" data-has-bg-color="true" data-bg-color="#ffffff" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>Two Minute Reports Solo Plan Lifetime Subscription</h4></p></div><div data-list-icon="steadysets-icon-checkmark" data-animation="false" data-animation-delay="0" data-color="accent-color" data-spacing="default" data-alignment="left"><ul><li>Lifetime access to Two Minute Reports Solo Plan</li><li>Automate Reports in Google Sheets</li><li>Access for 1 user (stackable)</li><li>All Data Sources</li><li>Unlimited Reports</li><li>Unlimited Queries</li><li>​​Unlimited Rows per query</li><li>Send automated email reports</li><li>​​Unlimited Report Templates</li><li><strong>4 Accounts per Data Source Type</strong></li><li><strong>​​10 Active Schedulers</strong></li><li>Choose Google Analytics sampling method</li><li>Integrations with: MySQL, Google Analytics, PostgreSQL, PageSpeed Insights, Apple App Store, Linkedin Ads, Facebook Ads, Firebase Cloud FireStore</li><li>Slack, Trello, Stripe, Google Search Console, Play Store, Google Ads, Twitter Ads, Hubspot, Zoho (Coming soon)</li><li>All future integrations included</li><li>All future updates included</li><li>30-day Money Back Guarantee</li></ul></div><p data-style="half_text" data-using-custom-color="true" data-animation-delay="false" data-color="#00d2f3" data-color-gradient=""><h3><strong><em>$39 </em></strong><span>94% off</span></h3></p><p><a href="https://www.dealify.com/checkout/?add-to-cart=62753" data-color-override="false" data-hover-color-override="false" data-hover-text-color-override="#fff"><span>Add to Cart</span><i></i></a></p></div></div></div></div></div><div id="fws_5fa5735488f69" data-column-margin="default" data-midnight="dark" data-top-percent="4%" data-bottom-percent="4%"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>How can I activate the deal?</h4></p></div><div><p>After purchasing you will get a unique activation code in your mailbox. Simply sign-up and your deal is activated!</p></div></div></div></div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>What if I’m not 100% satisfied?</h4></p></div><div><p>We offer a hassle-free 30-day money back guarantee, just drop us a message and we will make sure to process the refund as soon as possible.</p></div></div></div></div></div></div><div id="fws_5fa57354895c8" data-column-margin="default" data-midnight="dark" data-top-percent="4%" data-bottom-percent="4%"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>Will I get access to future updates?</h4></p></div><div><p>Yes, you will get access to all future updates, templates and integrations.</p></div></div></div></div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>Where can I find more information on Two Minute Reports?</h4></p></div><div><p>Feel free to check <a href="https://www.gox.ai/two-minute-reports/" rel="nofollow">their website</a> for more information on the product.</p></div></div></div></div></div></div><div id="fws_5fa5735489bc6" data-column-margin="default" data-midnight="dark" data-top-percent="4%" data-bottom-percent="4%"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>What Does “Accounts Per Data Source Type” Mean?</h4></p></div><div><p>It means the number of accounts for 1 data source that you have connected in Two Minute Reports. Eg. If you have connected 2 data sources of the type Facebook Ads in Two Minute Reports, the Accounts Per Data Source Type will be equal to 2.</p></div></div></div></div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h4>How are the limits enforced by “Accounts Per Data Source Type”?</h4></p></div><div><p>You can add as many data sources of each type depending on your plan. For example, if you have claimed the “Startup” plan, you can 12 data sources of type Facebook Ads and 12 data sources of type Google Analytics, etc.</p></div></div></div></div></div></div><div id="fws_5fa573548a13a" data-column-margin="default" data-midnight="dark" data-bottom-percent="4%"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div id="fws_5fa573548a459" data-midnight="" data-column-margin="default"><div><div data-using-bg="true" data-t-w-inherits="default" data-shadow="small_depth" data-border-radius="15px" data-bg-cover="" data-padding-pos="all" data-has-bg-color="true" data-bg-color="#ebfdff" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><blockquote data-color="default" data-style="small_modern"><div><p><span>”</span>Hi all!</p><p>Excited to be featured here on Dealify! I'm Paul, founder of Two Minute Reports.</p><p>Running repetitive reports for your business is a tedious task. It's quite a waste of time and efforts. We experienced this ourselves as well. This is the reason why we founded Two Minute Reports.</p><p>Basically we are automating all the time consuming tasks regarding reporting and data insights, directly in Google Sheets.</p><p>Looking forward to hearing your feedback!</p><p><span><span>Paul J. Emmanuel</span><span>Founder of Two Minute Reports</span></span></p></div></blockquote></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.dealify.com/two-minute-reports/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981393</guid>
            <pubDate>Tue, 03 Nov 2020 16:56:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming R at native speed using Haskell (2015)]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24981356">thread link</a>) | @behnamoh
<br/>
November 3, 2020 | https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Most good data stories start with a interesting question. If the
average request latency went down by a further 100ms, by how much
could we expect user engagement to increase? How can we detect
evidence of corruption of government officials given a list of all
bids nationwide for the building of new roads and repair of existing
ones? Can we identify a new pandemic in the making given a timeline of
common search terms? Often though, we know we have the data, but we
don’t even know what questions the data might help answer, or how the
story will unfold. From the data scientist who scratched an itch on an
idle afternoon, to a low latency, high availability, real-time
analysis deployed on hundreds of machines, the story typically
involves lots of rewrites, meanderings and building out of a lot of
code and utilities to improve the precision, speed or scale of the
analysis.</p>
<!--more-->
<p>R provides a great interactive environment for poking at the dataset
<em>du jour</em> and find what answers might be lurking in there. It provides
a wealth of readily available libraries for banging out an initial
story to tell. But R is a special purpose scripting language. Its
strength in supporting throwaway “do what I mean” programming to test
and iterate on hypotheses quickly becomes a hindrance when a model is
to be built out into an industrial scale, performant and maintainable
product or service. By then, a more general purpose language
encouraging structured, modular programming, providing strong static
guarantees of correctness and that compiles down to native code for
maximum speed becomes more appropriate. Haskell is such a language.</p>
<p>Mind you, Haskell makes for a great language to support rapid
iteration, “in the small” exploratory programming too, but it as of
yet lacks the plethora of high quality libraries from machine learning
to visualization that R provides, and perhaps also some syntactic
facilities to play it fast and loose. Today we’re proud to announce
the first public release of the
<a href="https://tweag.github.io/HaskellR/">HaskellR</a> project, which includes
a library and two interactive environments for seamlessly programming
in <em>both</em> R and Haskell in the same source file, or indeed at the same
prompt.</p>
<p>At the heart of the project lies <code>inline-r</code> (whose design later
inspired
<a href="https://www.fpcomplete.com/blog/2015/05/inline-c">inline-c</a> - they
share a coauthor), which exports a few quasiquoters for expressing
calls to R functions and indeed arbitrary R code in R’s syntax. The
principles behind the design of <code>inline-r</code> are,</p>
<ul>
<li>use R libraries the way R intends them to be used: using R’s syntax
and calling conventions;</li>
<li>keep the overhead of crossing language boundaries as low as possible
to encourage fine grained interleaving of code in both languages;</li>
<li>zero marshalling overhead in the common case;</li>
<li>optional typing of R data as executable documentation of what
functions expect and return;</li>
<li>let the user stoop as low or jump as high as (s)he likes in the
abstraction stack: everything is under the user’s control control in
case (s)he needs it.</li>
</ul>
<p>We’ll touch upon each of the above points in more detail below and in
future posts. But first, let’s get a taste of this stuff. You may want
to consider the below setup as your go-to interactive shell if you
haven’t already: it reuses existing projects and works much like GHCi,
in an isolated sandbox if you like, except that you have inline
graphics and formulas out-of-the-box, as Shae Erisson first pioneered
in the Haskell world with <a href="https://github.com/shapr/ghclive/">ghclive</a>
and Manuel Chakravarty realized more recently on OS X with
<a href="http://haskellformac.com/">Haskell for Mac</a>.</p>
<h2>Charts, code, prose and formulas in a playground</h2>
<p>HaskellR features two interactive prompts:</p>
<ul>
<li>a bare bones REPL, called H. This is a thin wrapper around GHCi
initializing it with all the right extensions and imports to hit the
road running;</li>
<li>an all singing, all dancing interactive notebook, powered by
<a href="https://jupyter.org/">Jupyter</a> (formerly IPython) and Andrew
Gibiansky’s fantastic
<a href="https://github.com/gibiansky/IHaskell">IHaskell</a> kernel.</li>
</ul>
<p>In this post, we’ll talk mostly about the latter. Thanks to
<a href="https://github.com/commercialhaskell/stack">stack</a>, getting started
with <strong>HaskellR</strong> is pretty straightforward, and more importantly,
comparatively reliable. We put together
<a href="https://hub.docker.com/r/tweag/haskellr/">a Docker container</a> to get
you started hassle-free. It includes <strong>Jupyter</strong> and <strong>IHaskell</strong>
preinstalled. To build <strong>HaskellR</strong> inside it:</p>
<div data-language="bash"><pre><code>$ <span>git</span> clone http://github.com/tweag/HaskellR
$ <span>cd</span> HaskellR
$ stack --docker build
$ stack --docker <span>exec</span> ihaskell <span>install</span></code></pre></div>
<p>And get started in your browser:</p>
<div data-language="bash"><pre><code>$ stack --docker <span>exec</span> ipython notebook</code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c1b63/haskellr-jupyter.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="HaskellR in Jupyter" title="HaskellR in Jupyter" src="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/fcda8/haskellr-jupyter.png" srcset="https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/12f09/haskellr-jupyter.png 148w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/e4a3f/haskellr-jupyter.png 295w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/fcda8/haskellr-jupyter.png 590w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/efc66/haskellr-jupyter.png 885w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c83ae/haskellr-jupyter.png 1180w,
https://www.tweag.io/static/41a8b35719ee8bafb01f70190d40a529/c1b63/haskellr-jupyter.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Or remain in your terminal:</p>
<div data-language="bash"><pre><code>$ stack --docker <span>exec</span> ipython</code></pre></div>
<p>With <strong>IHaskell</strong>, you can keep your notes and formulas together with
your code in one place, called a notebook. With <strong>HaskellR</strong>’s plugin
for <strong>IHaskell</strong>, you can use widely acclaimed and very popular
R visualization packages such as <a href="http://ggplot2.org/">ggplot2</a> for
embedding plots in your notebook. Working in notebooks (aka
<a href="http://blog.haskellformac.com/blog/from-the-read-eval-print-loop-to-playgrounds">playgrounds</a>)
is convenient: they are self contained units that is easy to share
with colleagues, via email or
<a href="https://nbviewer.jupyter.org/">on the web</a>, and you can edit earlier
definitions while keeping the later ones in sync.</p>
<p>Here’s a simple example of using R’s data analysis facilities on data
generated in Haskell. Say you have a cluster of noisy data. We’ll use
the <code>random</code> package to generate a sample set:</p>
<div data-language="haskell"><pre><code><span><span>import</span> Control.Monad</span>
<span><span>import</span> System.Random.MWC <span>as</span> MWC</span>
<span><span>import</span> System.Random.MWC.Distributions</span>

<span>main</span> <span>=</span> <span>do</span>
  <span>gen</span> <span>&lt;-</span> <span>MWC.create</span>
  <span>xs</span> <span>&lt;-</span> <span>replicateM</span> <span>500</span> <span>$</span> <span>normal</span> <span>10</span> <span>3</span> <span>gen</span>
  <span>ys</span> <span>&lt;-</span> <span>replicateM</span> <span>500</span> <span>$</span> <span>normal</span> <span>10</span> <span>3</span> <span>gen</span>
  <span>...</span></code></pre></div>
<p>We can now plot the list of x-ordinates against the list of
y-ordinates using R’s standard library <code>plot()</code> function:</p>
<div data-language="haskell"><pre><code>  <span>[</span><span>r</span><span>|</span> <span>plot</span><span>(</span><span>xs_hs</span><span>,</span> <span>ys_hs</span><span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Randomly generated points" title="Randomly generated points" src="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png" srcset="https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/12f09/haskellr-plot1.png 148w,
https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e4a3f/haskellr-plot1.png 295w,
https://www.tweag.io/static/c6d47a04f8ebdbbdef96de235500886f/e17e5/haskellr-plot1.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>Better yet: say we want some kind of visualization of the density
estimation of these points. We can use R’s 2D kernel density
estimation function, available out-of-the-box:</p>
<div data-language="haskell"><pre><code><span>[</span><span>r</span><span>|</span> <span>k</span> <span>&lt;-</span> <span>kde2d</span><span>(</span><span>Xv</span><span>,</span> <span>Yv</span><span>,</span> <span>n</span><span>=</span><span>500</span><span>)</span>
    <span>image</span><span>(</span><span>k</span><span>,</span> <span>col</span><span>=</span><span>topo</span><span>.</span><span>colors</span><span>(</span><span>8</span><span>)</span><span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><span>
      <a href="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Density estimation for our random points" title="Density estimation for our random points" src="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png" srcset="https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/12f09/haskellr-plot2.png 148w,
https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e4a3f/haskellr-plot2.png 295w,
https://www.tweag.io/static/b56b1373f1fb40b96ee512eb43296cb8/e17e5/haskellr-plot2.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>Notice how in the above, some code appears delineated in
quasiquotation blocks. This is a syntactic facility to tell the
Haskell compiler that any code inside the block should be understood
to be in R’s syntax, not Haskell’s syntax as is normally the case
outside of these blocks. We implemented a mechanism to get an embedded
instance of the R interpreter to parse that code for us, so that we
don’t have to grok R’s full surface syntax ourselves.</p>
<p>By convention, <code>_hs</code> suffixed variables don’t refer to bindings in the
R environment, but rather to bindings in the Haskell environment. In
technical terms, these variables are actually
<a href="https://downloads.haskell.org/~ghc/7.8.4/docs/html/users_guide/template-haskell.html">antiquotations</a>
(we use convention over extra syntax so that we can reuse R’s stock
parser as-is and not implement our own). Antiquotation is the
fundamental mechanism for communicating data between R and Haskell. In
common cases, we can do so with no marshalling at all, so you can
cross the language boundaries repeatedly in a tight loop with impunity
if you like.</p>
<h2>Elements of design</h2>
<p>The core idea behind <strong>HaskellR</strong> is that language interop should be
zero-cost, or close to. There should be no reason why you would
hesitate to dip into a little bit of R to get the job done, over
reimplementing the same thing in Haskell because you’re worried about
performance or the cost of sending large volumes of data to some
remote R interpreter instance. We believe that making foreign calls
practically as fast as native calls is the key to making the
experience programming with both <a href="https://cran.r-project.org/">CRAN</a>
and <a href="https://hackage.haskell.org/">Hackage</a> package functions at the
same time seamless.</p>
<p>To this end, we decided to embed the R interpreter instance, that is
to say link together in the same binary the C code of the
R interpreter with the Haskell code of Haskell programs. In this way,
we can communicate with the R interpreter in the same process address
space. Many R functions are actually written in C, for speed, and
compile down to native code. Some of these primitives can be called
from Haskell as cheaply as any other foreign function call.</p>
<p>But that’s not the end of the performance story. A typically vexing
issue in cross-language programming is that the one language insists
on one representation of the data, while the other language wants its
own representation. Therefore, data typically has to be marshalled
from one representation to another constantly. In <strong>HaskellR</strong>, we
solved that problem in the following way: just use R’s representation
throughout. It’s the form that R functions expect, so they can get
straight to computing on that data when called. The trouble is, R’s
data representation is foreign to Haskell, so you lose Haskell’s
extremely powerful language facilities that work with any native
algebraic datatype, such as pattern matching. Or do you?…</p>
<p>The trick to get the best of both worlds, zero marshalling but also
pattern matching, is to define so-called view functions that provide
you with a native view as an algebraic datatype of the foreign data.
Here’s a toy and contrived example, where we define the factorial
function in Haskell but over R integers:</p>
<div data-language="haskell"><pre><code><span>fact</span> <span>::</span> <span>SEXP</span> <span>s</span> '<span>R.Int</span> <span>-&gt;</span> <span>R</span> <span>s</span> <span>(</span><span>SEXP</span> <span>s</span> '<span>R.Int</span><span>)</span>
<span>fact</span> <span>(</span><span>hexp</span> <span>-&gt;</span> <span>Int</span> <span>[</span><span>0</span><span>]</span><span>)</span> <span>=</span> <span>R.cast</span> <span>sing</span> <span>&lt;$&gt;</span> <span>[</span><span>r</span><span>|</span> 1L <span>|</span><span>]</span>
<span>fact</span> <span>n</span><span>@</span><span>(</span><span>hexp</span> <span>-&gt;</span> <span>Int</span> <span>_</span><span>)</span> <span>=</span>
    <span>R.cast</span> <span>sing</span> <span>&lt;$&gt;</span> <span>[</span><span>r</span><span>|</span> <span>n_hs</span> <span>*</span> <span>fact_hs</span><span>(</span><span>n_hs</span> <span>-</span> 1L<span>)</span> <span>|</span><span>]</span></code></pre></div>
<p><code>hexp</code> is a view function, mapping native R data (everything is
a <code>SEXP</code> internally in R) to a Haskell-native GADT. Thanks to the type
annotations (more on that in future posts), we know statically that
the R data can only be some kind of integer vector, so we pattern
match on that, check whether it’s the singleton zero vector or not,
and recurse.</p>
<p>Aren’t we now back to marshalling? Yes and no! We carefully engineered
these view functions to be non-recursive. Non-recursive functions can
be inlined. So that when you use a view function only to pattern match
on the result immediately afterwards, as is the case above, <strong>GHC</strong> is
smart enough to recognize that the view function is constructing
a datatype value only to destructure it later, so it simplifies the
allocation away! Yes this is marshalling of sorts, but it’s
marshalling for free: there is no trace of it at runtime.</p>
<p>There’s plenty more to talk about regarding the design of
<strong>HaskellR</strong>, but this post is already …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/">https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2015-09-08-programming-r-at-native-speed-in-haskell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981356</guid>
            <pubDate>Tue, 03 Nov 2020 16:53:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I got 10k post karma on Reddit with (and without) fast.ai]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24981153">thread link</a>) | @ameerkat
<br/>
November 3, 2020 | https://www.a8b.io/posts/10k-karma-reddit-bot/ | <a href="https://web.archive.org/web/*/https://www.a8b.io/posts/10k-karma-reddit-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

    

    
      

    

    
<p><a href="https://www.a8b.io/posts/10k-karma-reddit-bot/" title="How I got 10k post karma on reddit with (and without) fast.ai">
        <img src="">
    </a>
</p>



    <figure>
    <img src="https://www.a8b.io/images/reddit/reddit_badge.png#mid" alt="My reddit profile with 10,088 post karma">
    <figcaption>Profile image made by AI Gahaku</figcaption>
  </figure>

<p>Back in 2006-2007 my friend and I put together a spreadsheet of 20 or so high-level achievements called “Everything’s a Contest”. This included goals like “Photograph a live grizzly bear in the wild”, “Have something named after you”, and <em>“Get 10,000 (post) karma on Reddit”</em>. Despite our heated discussions about what should be on this list and the criteria for success none of us ever really did anything substantial to complete any of these goals. In early 2020 I decided to tackle one of these long-standing contests. <em>But I was going to do it with AI since I wanted to see how I could apply AI to more of my problems</em>. I’m a huge fan of <a href="https://www.fast.ai/">fast.ai</a> and I appreciate its high-level abstractions and simple interfaces. For someone trying to get into deep learning, I would highly recommend it and the associated courses. This is a post about how I built a bot to gain karma on Reddit with fast.ai.</p>
<h2 id="approach">Approach</h2>
<p>Content on Reddit, in general, falls into two categories which you might call original content and found content. Trying to automate generating original content to post would be implementing something like <a href="https://imgflip.com/ai-meme">imgflip’s AI meme generator</a> and posting the resulting content to r/memes. While the memes that are generated are an amusing juxtaposition of tropes, they generally aren’t as good as memes that are generated by human users skilled in the art of observational comedy. Try the meme generator out and you’ll see what I mean. At some point, I did try posting one of those just to see how well it did.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/3migr03n6m251.jpg#mid" alt="Drake meme with text Staying in the Server / Watching Anime">
    <figcaption>I went through about 100 auto generated memes before I got this. This post got ~35 points with the title 'An AI generated this meme. Good to know it's putting its sentience to good use.'</figcaption>
  </figure>

<p>The other approach would be finding content online and posting it. I chose this route for automation because while generating high-quality content is more interesting it’s also far more challenging and involved. Rather than being disadvantaged in trying to catch up to the “human quality” of content, a computer is at the advantage since the primary differentiator between posters is the ability to search through large amounts of content and speed (who finds and posts something first). In particular, I ended up looking at news based subreddits due to a few reasons:</p>
<ul>
<li>Little chances of content being a repost</li>
<li>Lots of content being generated frequently</li>
<li>Large member bases</li>
<li>A lot of the content comes from the same set of known sites</li>
</ul>
<figure>
    <img src="https://www.a8b.io/images/reddit/business_submissions_by_domain.png" alt="">
    <figcaption>Domains for all the &gt; 1 score articles from /r/business in the last week as of October 29th 2020, showing the top few sites supply the majority of content.</figcaption>
  </figure>

<p>Why use AI at all though? If I was going to automate posting why not just create a bot that submits all links and leaves it up to the masses to sort my fate. In general, spamming on Reddit is looked down upon, though I believe banning is up to the discretion of the subreddit moderators. While in theory I might have gotten away with it or used some sort of generic rate-limiting and hope for the best, I wanted my bot to be more like a productive member of the community submitting thoughtful content, an extension of myself, rather than a spam bot that would be the bane of its existence until forcibly removed.</p>
<p>I searched for and found many good news subreddits but I targeted initially /r/business and /r/worldnews, somewhat arbitrarily and somewhat because those areas seemed interesting to me. /r/business had a sizeable community (577k members) and relatively low frequency of posts for a news subreddit so it seemed approachable as a first target. I would build a web crawler to watch popular business news sites for new articles, and then leverage an NLP-based article classifier to determine if the article had a high chance of receiving upvotes.</p>
<h2 id="implementation">Implementation</h2>
<h3 id="finding-and-loading-posts">Finding and loading posts</h3>
<p>To train the NLP model that will classify articles I need the article text and their corresponding Reddit scores. Unfortunately, the official Reddit API limits the amount of historic post data you can retrieve to 1000 items. Luckily there is an alternative, you can grab historic post data from <a href="https://pushshift.io/">pushshift.io</a> using code I shamelessly adapted from <a href="https://www.osrsbox.com/blog/2019/03/18/watercooler-scraping-an-entire-subreddit-2007scape/">WaterCooler: Scraping an Entire Subreddit (/r/2007scape)</a>. The output file of the script has individual lines like the one below, containing a JSON object of a post per line:</p>
<pre><code>{"author": "CALIPHATEMEDIA", "author_flair_css_class": null, "author_flair_text": null, "brand_safe": true, "can_mod_post": false, "contest_mode": false, "created_utc": 1514767344, "domain": "caliphatemedia.info", "full_link": "https://www.reddit.com/r/business/comments/7nc5yf/south_korea_to_regulate_bitcoin_trading_further/", "id": "7nc5yf", "is_crosspostable": false, "is_reddit_media_domain": false, "is_self": false, "is_video": false, "locked": false, "num_comments": 0, "num_crossposts": 0, "over_18": false, "parent_whitelist_status": "all_ads", "permalink": "/r/business/comments/7nc5yf/south_korea_to_regulate_bitcoin_trading_further/", "pinned": false, "retrieved_on": 1514841750, "score": 1, "selftext": "", "spoiler": false, "stickied": false, "subreddit": "business", "subreddit_id": "t5_2qgzg", "subreddit_type": "public", "thumbnail": "default", "thumbnail_height": 140, "thumbnail_width": 140, "title": "South korea to regulate bitcoin trading further with tougher measures", "url": "http://www.caliphatemedia.info/2017/12/south-korea-govt-to-introduce-tougher.html", "whitelist_status": "all_ads"}
</code></pre><p>After generating a file with all the historic posts, I loaded the contents referenced by the “url” field of each JSON line into <a href="https://github.com/slaveofcode/boilerpipe3">boilerpipe3</a> which is a python library that simplifies HTML documents into their primary content text.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/reuters_article.jpg" alt="">
    <figcaption>boilerpipe3 simplifies this (mostly) down to what we really want which is 'By Jeffrey Dastin, Akanksha Rana 4 Min Read (Reuters) - Amazon.com INC AMZN.O on Thursday...'</figcaption>
  </figure>

<p>After loading the article text I did some processing to remove pages that didn’t load properly and to truncate page text to 10k characters at most.</p>
<h3 id="training-the-model">Training the model</h3>
<p>I trained the NLP model for /r/business over a few days on approximately 271k articles from 2018-01-01 to mid-April 2020. I used an <a href="https://docs.fast.ai/text.models.awdlstm">AWD_LSTM</a> (e.g. <code>language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)</code> and <code>text_classifier_learner(data, AWD_LSTM, drop_mult=0.5)</code>) for the model with discrete labels based on the article score: neutral (0-10 points), okay (10-100), good (100-500), and great (500+). The classes are kind of arbitrary and I’ve changed them around for different iterations and subreddits. The only thing I ended up paying attention to at runtime was the non-neutral class score, so this could have been a binary classifier or even better a classifier that looks at an individual article as a candidate for multiple subreddits rather than training an individual model per subreddit. For world news I had around double the number of articles. In either case I trained in 100k article chunks due to memory limitations, reloading the existing model and tuning with the new data each time.</p>

<h3 id="building-the-bot">Building the bot</h3>
<p>I chose a few sites (Business Insider, Reuters, Bloomberg, CNN, CNBC, BBC, etc.) based on frequent sites for /r/business and put them into a script and built a crawler using requests and BeautifulSoup. Every minute or so I’d crawl the site root for new links and process the linked page with boilerpipe and pass it through the NLP model for scoring. New pages with a non-neutral score of greater than 0.25 (an arbitrary threshold I picked for this particular model) would be flagged and emailed to me using AWS SNS. Initially, I relied on filtering these incoming suggestions and submitting the articles myself using the Reddit app.</p>
<figure>
    <img src="https://www.a8b.io/images/reddit/example_email.png" alt="">
    <figcaption>An example email I received from my site poller that I called 'Reddit Postmaster'.</figcaption>
  </figure>

<h2 id="automation">Automation</h2>
<p>My site poller is acting as a personal news aggregator that I use to generate suggestions for things to post. To remove me from this loop there are a few “last mile” problems to solve. Coding up submitting via the Reddit API is easy enough, but I don’t just submit all the articles that get passed to me, I act as a quality filter choosing not to submit things which don’t seem appropriate. I also gather an appropriate title for the Reddit post. The page title is usually not good as a post title (for example containing redundancies like the site name) directly and needs to be reformatted or the title should instead be extracted from the content for example by picking the most appropriate h1 tag on the page. Rather than refining the model to be better at classifying articles and improve the accuracy of the scoring mechanism, and then coding a new component for extracting the title, I decided to try to encapsulate these tasks into a mechanical turk task and have humans as the final gate-keeper and title generator. I can take the results from these mechanical turk tasks and submit the articles to Reddit via the Reddit API utilizing those results.</p>
<h3 id="mechanical-turk">Mechanical Turk</h3>
<p>Mechanical turk is a service for leveraging humans to complete small tasks for your application. It’s great for augmenting AI applications and collecting data via labeling tasks for them. But using it effectively isn’t without difficulties. The important thing to know about mechanical turk is that many workers on the platform are (sensibly) optimizing for task completion quantity. When using a custom qualifier for tasks, ensure the qualification you’re looking for is not apparent from the question. Similarily a bad HIT (human intelligence task) would be one where you ask the user to read an article and check some box if they think it belongs in some category. For example, I did this with /r/worldnews candidates to ensure that among other things didn’t pertain to US news, however the first fully automated submission I made to /r/worldnews was “Johnson &amp; Johnson to stop selling baby powder in the United States” which was …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.a8b.io/posts/10k-karma-reddit-bot/">https://www.a8b.io/posts/10k-karma-reddit-bot/</a></em></p>]]>
            </description>
            <link>https://www.a8b.io/posts/10k-karma-reddit-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981153</guid>
            <pubDate>Tue, 03 Nov 2020 16:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WCWDIX: What can we do in 1 year, 1 month, 1 week, 1 day, 1 hour, 10 minutes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24981052">thread link</a>) | @amattn
<br/>
November 3, 2020 | https://amattn.com/p/wcwdix_what_can_we_do_in_1_year_1_month_1_week_1_day_1_hour_10_minutes.html | <a href="https://web.archive.org/web/*/https://amattn.com/p/wcwdix_what_can_we_do_in_1_year_1_month_1_week_1_day_1_hour_10_minutes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- The top of the page -->
	
	
	<table>
	<tbody><tr>
		<td>
	<h2 id="subhead">SW engineering, engineering management and the business of software</h2>
		</td>
		<td>
<!-- Begin MailChimp Signup Form -->

<!--End mc_embed_signup-->
		</td>
	</tr>
	</tbody></table>


	<br>

<!-- The middle of the page -->


	
	
	
	
	
	
	<p>One of the best tricks I’ve come across to make meaningful progress on any long term project is to start with an initial (typically long) time estimate, than play the “What Can We Do In X” game.</p>

<p>If you need a fancy mnemonic, use: WCWDIX (pronounced wick-widicks)</p>

<p>It works like this:</p>

<p>If you start with an initial, hypothetical estimate to build a product or feature of 5 months, ask yourself and your team: “What can we do in 1 month?”</p>

<h3>One Month</h3>

<p>This forces the thought process of <strong><em>Ruthless Prioritization</em></strong>.  Typically, your must have features become should-haves and your should-haves become nice-to-haves. It’s important to be ruthless here.  Strip the business down to the core, while still being usefull.  Remember that the MVP of a car is not 4 tires on the ground (useless) but a skateboard or bike.</p>

<h3>One Week</h3>

<p>Follow that up with “What can we do in 1 week?”</p>

<p>This helps with the notion of what it takes to make a <strong><em>Useful Prototype</em></strong>.  Hopefully this is mostly code/product that you can reuse over the longer journey.  Importantly, you have prioritized faster and are cutting corners to get to a product point where you can put it in front of people.  This builds technical debt, but it is almost always worth it because you are learning so much faster, earlier in the development process.</p>

<h3>One day</h3>

<p>By now, you know what comes next: “What can we do in a day?”</p>

<p>In a day, you can’t build much.  But you can <strong><em>Fake Product</em></strong>.  Sometimes this means wireframes in a mockup app.  Sometimes this means wiring together no-code SAAS apps or even a spreadsheet and tools like Zapier to simulate the guts of your business logic.  Fake Product is great for customer development or even early sales calls.</p>

<p>Another option is <strong><em>Market Discovery</em></strong>:  spend a day doing market research.  This is different from customer validation which typically happens after you have a product idea or prototype.  Market discovery is more about finding a market that has pain points and the ability to pay to address those pain points, and ideally a market you can reach via known sales/marketing strategies.  It’s important to do this process without any preconceived notions of product/solutions.  Identify the pain first!</p>

<h3>One Hour</h3>

<p>“What can we do in an hour?”</p>

<p>Not much?  Wrong!  An hour is enough for <strong><em>Short Burst of Research</em></strong>.  You can hold 2-3 customer development calls.  You can setup up a landing page and blast LinkedIn, twitter and other social media sites to see if you can get any bites.  You can do some google searches and look for evidence of your market hypothesis.  You won’t typically get enough info here to be data, more anecdotes.  But it might be enough to guide early thoughts/directions or help quickly identify a potential pivot that requires more investigation.</p>

<h3>Ten minutes</h3>

<p>Lastly “What can we do in 10 minutes?”</p>

<p>Even ten minutes is enough for <strong><em>Quick Info Wins</em></strong>.   This is kind of a mini versino of Short Burst of Research.  Send off a couple emails.  You can buy a small ad campaign and measure how many clicks it gets over time.  Counts cohorts in LinkedIn (are you marketing to poele in X profession?  go check out how many people are in that profession to get a sense of scale).  Anything you can do or setup to get Information from Outside your Team is great use of early hours on a project.</p>

<h3>Wrapping it up</h3>

<p>As you play the WCWDIX game, each step forces you to reduce “Time to Learn” by an order of magnitude. You can hopefully shine light as early as possible on the fact that you may be building the wrong product or solution.</p>

<p>The suggested activities (Fake Product, Market Discovery, etc…) are just examples.  If you have alternative ideas that roughly fit in the respective timeframes, go for it!</p>

<p>However, the output of each step must make your smarter in some way.  You could spend a few hours setting up a CI/CD system or learning about a new javascript framework. That’s work, and you have made technical progress, but you’ve <strong>learned nothing</strong> about your product, it’s viability in the market, or your ability to sell into a market.  The bulk of your technical progress should (ideally) be after you’ve proven market and channel viability.</p>

<p>Companies don’t usually fail because they can’t build a product.  They usually fail because they build the wrong product at the wrong time or they build the solution that ends up being wrong for a market that can’t or won’t bear the appropriate costs.</p>

<p>Always make sure to the best of your ability that you are building the right product!</p>



<br>


<br>


<!-- The bottom of the page -->
	<br>
	
	
	<a href="" id="backup" name="bottom">back ⬆</a>



</div>]]>
            </description>
            <link>https://amattn.com/p/wcwdix_what_can_we_do_in_1_year_1_month_1_week_1_day_1_hour_10_minutes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24981052</guid>
            <pubDate>Tue, 03 Nov 2020 16:25:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Practical Introduction to Container Security]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24980928">thread link</a>) | @gbrindisi
<br/>
November 3, 2020 | https://cloudberry.engineering/article/practical-introduction-container-security/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/practical-introduction-container-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <p>Securing containers is a complex task.  The problem space is broad, vendors are on fire, there are tons of checklists and best practices and it’s hard to prioritize solutions. So if you had to <strong>implement a container security strategy</strong> where would you start?</p>

<p>I suggest to start from the basics: understanding <strong>what container security is about</strong> and build a model to navigate risks.</p>

<h2 id="follow-the-devops-life-cycle">Follow the DevOps Life Cycle</h2>

<p>Every security initiative is eventually constrained by where security controls can be implemented, so I find practical to just follow the standard DevOps life cycle to <em>surface patterns™</em> and <em>unlock synergies™</em>.</p>

<p>The DevOps Lifecycle is an infinite iteration of:</p>

<ul>
<li>Plan</li>
<li>Code</li>
<li>Build</li>
<li>Test</li>
<li>Release</li>
<li>Deploy</li>
<li>Operate</li>
<li>Monitor</li>
</ul>

<p><img src="https://cloudberry.engineering/devops-lifecycle.jpg" alt="DevOps Lifecycle - source: ryadel.com"></p>

<p>Containers are included in the application in the form of a Dockerfiles but are not really part of it. As such they don’t interest the planning and coding phase.</p>

<p><em>(no, writing Dockerfiles is not coding.)</em></p>

<p>Every other step is in scope from a security point of view, and I would group them like this:</p>

<ul>
<li><strong>Build Time</strong>: build, test and release.</li>
<li><strong>Container Infrastructure</strong>: deploy and operate.</li>
<li><strong>Runtime</strong>: monitor.</li>
</ul>

<p>Why? Every security strategy is only effective if it can be implemented. And every step in each group share a common facility where security controls can be injected without adding much friction:</p>

<ul>
<li>Build Time: The CI/CD infrastructure, the container registry</li>
<li>Container Infrastructure: the container orchestrator</li>
<li>Runtime: the production environment</li>
</ul>

<p>Now we have three macro areas we can use as a starting point to do our risk assessments.</p>

<h2 id="security-at-build-time">Security at Build Time</h2>

<p>At build time we have in input a bunch of source files and a Dockerfile, and we get as output a Docker image.</p>

<p>This is where most vendors tend to cluster while trying to sell you the narrative of the importance of scanning container images and calling it a day.  Container security scanning is important, yes, but it’s not enough.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>minimize the risk of supply chain attacks.</li>
</ul>
</div>


<h3 id="container-images-hygiene">Container Images Hygiene</h3>

<p>First, decide how your images should look like, with a focus on how software dependencies are introduced:</p>

<ul>
<li>what base images are developers allowed to use?</li>
<li>are software dependencies pinned? From where are they pulled?</li>
<li>are there any labels that are needed to simplify governance and compliance?</li>
<li>lint the Dockerfile</li>
<li>follow <a href="https://cloudberry.engineering/article/dockerfile-security-best-practices/">Dockerfile security best practices</a></li>
</ul>

<p>All of these checks are static and can be implemented for cheap as a step in the build pipelines.</p>

<h3 id="container-images-scanning">Container Images Scanning</h3>

<p>Then we can move into scanning the container image.</p>

<p><strong>Do not scan the image as a step in the build pipeline</strong>, instead setup continuous scanning in the container registry.</p>

<p>Why? Vulnerabilities are continuously discovered while your services are not necessarily continuously built. Secondly, builds are additive: every build will generate a new image. So, assuming  your container orchestrator trust your registry, every tag you publish can always be deployed and need to be assessed.</p>

<p><em>(It’s also very slow to scan at build time)</em></p>

<p>This is where you start thinking about defining <strong>patch management</strong> and <strong>shelf life</strong> processes:</p>

<ul>
<li>patch management: results from the scanning will feed a patching process that will result in a new version of the image</li>
<li>shelf life: unpatched/old/unsafe images are deleted from the registry</li>
</ul>

<p><em>(next article will be about how to choose a container scanning solution, if you are facing the dilemma right now feel free to <a href="mailto:hello@clouberry.engineering">ping me</a>)</em></p>

<h2 id="container-infrastructure-security">Container Infrastructure Security</h2>

<p>The container infrastructure is comprised of all the moving parts that are in charge of pulling your images from the registry and run them as containers in production.</p>

<p>It’s mostly going to be the container orchestrator – <em>*cough* kubernetes *cough*</em>.</p>


<div>
<p><strong>This stage goals</strong>:</p>

<ul>
<li>Avoid platform misconfigurations with security implications</li>
<li>Minimize the <strong>breadth</strong> of an attack from a compromised container</li>
</ul>
</div>


<h3 id="security-of-the-infrastructure-misconfigurations">Security OF the Infrastructure: Misconfigurations</h3>

<p>Container orchestrators are complex, Kubernetes in particular. As of now they fail the promise of DevOps and I think we are still an abstraction layer (or two) away from being a mainstream solution without too much operational overhead.</p>

<p>Every complex platforms is prone to be misconfigured, and this is the part you want to focus on.</p>

<p>You have to threat model your infrastructure to <strong>ensure it can’t be abused</strong>.
This particular thread model should focus on every actor but a compromised container (we will cover that next).</p>

<p>I can’t go into details here, because it really depends on what you are running. For Kubernetes a good starting point for threat modelling is <a href="https://www.marcolancini.it/2020/blog-kubernetes-threat-modelling/">this</a>.</p>

<p>Additionally, if you are not doing it yet, this is also a <strong>good argument in favour of using a managed platform</strong>: the complexity is reduced if you can leverage a shared responsibility model with your (trusted) provider.</p>

<h3 id="security-in-the-infrastructure-lateral-movements">Security IN the infrastructure: Lateral Movements</h3>

<p>Next we can talk about what happens when a container is compromised.</p>

<p>You want to minimize the <a href="https://cloudberry.engineering/article/lateral-movement-cloud/">attacker’s ability to move laterally</a>, focusing on these two layers:</p>

<ul>
<li>The network layer</li>
<li>The Identity and Access management (IAM) layer</li>
</ul>

<p><strong>The network should not be flat</strong>. You can start by brutally segment everything into subnetworks and work your way up to a full fledge service meshes.</p>

<p>On the IAM layer work your way toward having a <strong>single identity for each container</strong> in order to fine tune the authorization grants. This is particularly important in multi tenant platforms: without granular identities it’s impossible to achieve least privilege.</p>

<p><em>(Google Kubernetes Engine (GKE) has a nifty feature for this called <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Workload Identity</a>)</em></p>

<p>Finally, since they are supposed to be immutable, a wonderful strategy would be to <strong>reduce the amount of time containers can run</strong>: the window of opportunity for attackers to move laterally and gain persistence is as long as the container running lifetime. Continously shut down and spin up your containers.</p>

<p>And this final consideration allow me to smoothly move into the next area.</p>

<h2 id="runtime-security">Runtime Security</h2>

<p>The last piece of the puzzle is the security of your running workloads.
At this point most of the hardening is done and here is when we move into the realm of reactive security controls, the grim land of <strong>post-fail</strong>.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>is to minimize the <strong>impact</strong> of an attack from a compromised container.</li>
</ul>
</div>


<h3 id="detection-and-incident-response">Detection and Incident Response</h3>

<p>The best way to control the impact of an attack is to minimize the time between the breach to when the security team is alerted.</p>

<p>Detecting an ongoing breach is another area where vendors are scrambling to find a silver bullet. There are many approaches, most of them will require side cars and/or daemon sets actively monitoring pod’s traffic and system calls.</p>

<p>Most solutions will provide some value but my advice is to start simple and iterate: use your existing SIEM, ingest your platform, application and audit logs.</p>

<p><strong>Incidents will happen</strong>, and it’s fine: have an incident response process.</p>

<p>The first bullet point of every post-mortem should be: <em>“how can we detect this quicker next time?”</em> answering will allow you to identify your blind spots, which you can then use to understand what signals you are missing and what makes sense to buy.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Container security is a broad problem and it is not just about scanning images.</p>

<p>This is the model I built and used to reason about container risks and solutions. It’s very high level and of course, as with every model, <strong>it’s not necessarily the right one</strong>.</p>

<p>We all know that in reality each infrastructure is a snowflake: so start with your own threat model and use this one <strong>as an inspiration</strong>.</p>
        </div>
        
    </div>
</section></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/practical-introduction-container-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980928</guid>
            <pubDate>Tue, 03 Nov 2020 16:15:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good news – The U.S. House Passes the IoT Cybersecurity bill]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24980921">thread link</a>) | @Prototype_
<br/>
November 3, 2020 | https://mender.io/blog/good-news-the-u-s-house-passes-the-iot-cybersecurity-bill | <a href="https://web.archive.org/web/*/https://mender.io/blog/good-news-the-u-s-house-passes-the-iot-cybersecurity-bill">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>

              
    <div>
      
            
      <p>Recently, the House of Representatives in the United States passed the <a href="https://www.ssa.gov/legislation/legis_bulletin_092220.html" target="_blank">IoT Cybersecurity Improvement Act of 2020</a>. This is a landmark bill whose goal is to improve the security of IoT devices. Given the bi-partisan support for the bill, it is likely to pass the Senate and soon be put into action. This represents a powerful win for everyone who truly cares about security as we enter an increasingly digital world where the virtual command controls the physical space.</p>
<p><strong>What is this regulation?</strong></p>
<p>In short, this bill will require IoT device vendors to comply with a basic minimum set of security measures. These security measurements include things like vulnerability scanning and security patching, not using hard-coded passwords, and so on. If you want all the details on this new regulation, please check out the legislation pages on Congress.gov <a href="https://www.congress.gov/bill/116th-congress/house-bill/1668?q=%7B%22search%22%3A%5B%22H.R.%2B1668%22%5D%7D&amp;s=1&amp;r=1%3Ftarget%3D_blank">here</a>.</p>
<p>Once enacted, the US Federal government will only be allowed to purchase IoT devices from vendors that comply with this regulation. This means that unless a vendor can prove that it complies with the security measures, the US Federal Government is prohibited from purchasing from them. </p>
<p>The stakes have been raised for vendors as security compliance requirements to participate in the market have just been increased dramatically.</p>
<p><strong>Why is this good news?</strong></p>
<p>There are too many IoT vendors in the market today who are not serious enough in their attitude to address security concerns. These are often vendors with shiny websites and rock-bottom pricing, but who have a complete lack of understanding the very serious security needs of the market at hand. Highly insecure and fragile internet connected devices are being pushed into the market on a massive scale. Thankfully, this new regulation will put an end to much of this, or at least so in the US public sector.</p>
<p>Fortunately, there are vendors like <a href="https://mender.io/">Mender</a>, who take security as their prime directive and put you in an enviable position of being able to win more contracts, as you will have a distinct competitive advantage over others who would have to add security measures so playing catch up to you, or else find other marketplaces. </p>
<p>Mender users care inherently about the security of their IOT devices. This valiant and noble attitude has now become a competitive advantage to win deals with the US Federal Government, which is one of the largest purchasers in the world.</p>
<p>Finally, it is the hope that the purchasing power of the US Federal Government is so strong that it will positively impact the private market and buyers as well. </p>
<p>We are moving in the right direction, and the sooner you can ensure proper security measures on connected devices you provide to the market, the better prepared you will be for the future.</p>


              
      

              

        
          </div>


    
 
    

          </div>
        </div></div>]]>
            </description>
            <link>https://mender.io/blog/good-news-the-u-s-house-passes-the-iot-cybersecurity-bill</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980921</guid>
            <pubDate>Tue, 03 Nov 2020 16:14:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DOS/65]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24980874">thread link</a>) | @elvis70
<br/>
November 3, 2020 | http://www.z80.eu/dos65.html | <a href="https://web.archive.org/web/*/http://www.z80.eu/dos65.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <td>
                            
                            <p><i>From the system description of DOS/65:</i><br>
"What I (Richard A. Leary) have done is attack the software side of the problem in order to make any 6502 system a truly workable disk based system. In addition a degree of compatibility is now possible not only between 6502 systems but with large parts of the world of CP/M systems. The result of my efforts is a system of software which I have named DOS/65."</p>
                            <p>Richard's implementation is intially made for S-100 based systems, but he began to port it to the&nbsp;C64 also (see below).</p>
                            <p>DOS/65 has a lot of CP/M&nbsp;look-alike commands for the command line and also some applications like BASIC-E included.</p>
                            <p>Of course some differences between CP/M-80 and DOS/65 exist - the lowest memory areas (e.g. the "zero page") are not usable for the TPA, so the usable system memory area starts at a higher address (e.g. $0400).</p>
                            <p>Documentation files:</p>
                            <p><a href="http://www.z80.eu/dos65/DOS-65_System_Description_A.pdf">DOS/65 System description (PDF)</a><br>
<a href="http://www.z80.eu/dos65/DOS-65_SYSGEN_Manual.pdf">DOS/65 Sysgen manual&nbsp;(PDF)<br>
</a><a href="http://www.z80.eu/dos65/DOS-65_System_Interface_Guide_A.pdf">DOS/65 System interface guide (PDF)</a><br>
<a href="http://www.z80.eu/dos65/DOS-65_Bringing_the_System_Up.pdf">DOS/65 Bringing the system up&nbsp;(PDF)</a>&nbsp;</p>
                            <p><span color="#990000"><span>* NEW ! *</span></span><span color="#FF6600"><br>
</span><a href="http://www.z80.eu/dos65/DOS-65_ASM_Manual.pdf"><span color="#CC0000"><span>DOS/65 ASM Manual.pdf</span></span></a><span color="#CC0000"><span><br>
</span></span><span><a href="http://www.z80.eu/dos65/DOS-65_BASIC-E_Manual.pdf"><span color="#CC0000">DOS/65 BASIC-E Manual.pdf</span></a><span color="#CC0000"><br>
</span><a href="http://www.z80.eu/dos65/DOS-65_EDIT_Manual.pdf"><span color="#CC0000">DOS/65 EDIT Manual.pdf</span></a><span color="#CC0000"><br>
</span><a href="http://www.z80.eu/dos65/DOS-65_DEBUG_Manual.pdf"><span color="#CC0000">DOS/65 DEBUG Manual.pdf</span></a></span><span color="#CC0000"><span><br>
</span></span><a href="http://www.z80.eu/dos65/DOS-65_IEEE_Standard_696_Guide.pdf"><span color="#CC0000"><span>DOS/65 IEEE Standard 696 Manual.pdf</span></span></a><span color="#FF6600">&nbsp;</span></p>
                            <p>Source code files (6502 Assembler):</p>
                            <p><a href="http://www.z80.eu/dos65/ASM204.zip">ASM204.zip</a> <br>
<a href="http://www.z80.eu/dos65/BOOT202.zip">BOOT202.zip</a><br>
<a href="http://www.z80.eu/dos65/EDIT202.zip">EDIT202.zip</a><br>
<a href="http://www.z80.eu/dos65/MAKECOM.zip">MAKECOM.zip</a><br>
<a href="http://www.z80.eu/dos65/MON900A.zip">MON900A.zip</a><br>
<a href="http://www.z80.eu/dos65/SIM300.zip">SIM300.zip</a><br>
<a href="http://www.z80.eu/dos65/SYSGN214.zip">SYSGN214.zip</a></p>
                            <p>BASIC-E compiler and runtime: &nbsp;<span color="#000099"><i>very useful !</i></span></p>
                            <p><a href="http://www.z80.eu/dos65/BASICE_COMP-RT.zip">BASICE_COMP-RT.zip</a></p>
                            <p>Useful info for a port to C64 &nbsp;can be found&nbsp;at the <a href="http://www.z80.eu/c64.html">C64 CP/M page</a>, Richard&nbsp;converting PDFs to readable assembler files, thank you again, Richard !</p>
                            <p><span><b><span color="red">&nbsp;</span></b></span><b><span color="yellow"><span>A working copy </span></span></b><span><span color="yellow"><b>of a C64 port of DOS/65 !!</b></span></span></p>
                            <p>Richard has prepared two&nbsp;.D64 files (now updated):<br>
<a href="http://www.z80.eu/dos65/DOS65-1C.D64">DOS65-1C.D64</a> (Bootdisk with updated SIM C64S304.ASM)<a href="http://www.z80.eu/dos65/DOS65-1A.D64"><br>
</a><a href="http://www.z80.eu/dos65/DOS65A.D64">DOS65A.D64</a> (Blank disk)</p>
                            <p>Load the bootdisk with: LOAD "DOS65",8,1:RUN</p>
                            <p>See for&nbsp;some <a href="http://www.z80.eu/dos65/ASM-DOS65.TXT">advice</a> using the assembler in the above PDF manual now.</p>
                            <p>The new source files are zipped now in one file: <a href="http://www.z80.eu/dos65/newsources.zip">newsources.zip</a></p>
                            <p>He has written a sample BASIC/E program <a href="http://www.z80.eu/dos65/FILESTAT.BAS">FILESTAT.BAS</a>&nbsp;also.<br>
&nbsp;</p>
                            <p><u>Some screenshots:</u><br>
Before boot but disk already inserted...<br>
<img src="http://www.z80.eu/screen1.jpg" width="522" height="330">&nbsp;</p>
                            <p>...after boot:<img src="http://www.z80.eu/screen2.jpg" width="522" height="337"></p>
                            <p>New ! <a href="http://www.z80.eu/equipment.html#dos65scrnshot">Screenshot</a> of running DOS/65 on a SX-64 with 1541 Ultimate.</p>
                            <p>Richard can be contacted at &nbsp;<i>richardaleary AT gmail.com</i> .</p>
                        </td>
                    </div></div>]]>
            </description>
            <link>http://www.z80.eu/dos65.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980874</guid>
            <pubDate>Tue, 03 Nov 2020 16:08:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colombia is using advertising data to track coronavirus]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24980705">thread link</a>) | @atlasunshrugged
<br/>
November 3, 2020 | https://restofworld.org/2020/tracking-in-the-name-of-corona/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/tracking-in-the-name-of-corona/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>As if being in lockdown wasn’t grim enough, Claudia Moreno saw a creepy ad while scrolling her Instagram one night last May. In red, black, and yellow, adorned with the Bogotá mayor office’s logo, the graphic warned: “Due to your location, you were likely in contact with people who have COVID.” Moreno tapped it, out of curiosity and hoping that it would stop showing up in her feed. “They were too flashy and unnerving,” she said.</p>






		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/unnamed-40x71.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/unnamed-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/unnamed-400x711.jpg 400w, https://restofworld.org/wp-content/uploads/2020/09/unnamed-600x1067.jpg 600w, " sizes="300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Thousands of <a href="https://drive.google.com/file/d/1Rx_UsYUUuvMLSZzr8bHhyFdbWLuB7TNe/view?usp=sharing%20https://drive.google.com/file/d/1Rx_UsYUUuvMLSZzr8bHhyFdbWLuB7TNe/view?usp=sharing">Colombians have seen</a> similar ads on their phones, because in the capital Bogotá and in the department of Antioquia, health officials are using mobile data in their Covid-19 contact tracing efforts. But rather than relying on dedicated apps that require active downloads, Colombian authorities are using digital advertising data present in people’s phones — without first asking their permission. While activists say this is a privacy breach, authorities claim the action is justified<strong> </strong>because it helps in contact tracing and makes sure patients are identified and get treatment.</p>



<p>Bogotá did not only run geotargeted ads on Facebook and Instagram in the neighborhoods it deemed more at risk; officials also used the data to understand how the virus was moving within city limits and how residents were socially isolating. Bogotá health authorities declined an interview request from <em>Rest of World</em> to explain their contact-tracing initiative further.</p>



<p>Antioquia also leveraged the technology behind mobile ads to locate sick individuals in the capital Medellín and the rest of the region. “We wanted to be more proactive in identifying where infected people are,” said Juan Carlos Quiceno, spokesperson for the state’s ad-tech contact tracing initiative. </p>



<p>Both governments contracted local company Servinformación, which promised contact-tracing capabilities using regular mobile ad tech to “track individuals inside an area the government would like to monitor as well as to see how the virus propagates,” says Emiliano Isaza, a data scientist for the company.</p>



<div><p>Rather than relying on a custom-made app, as many governments around the world have done, Colombia’s tracking systems use the same geolocalized data that allow marketing companies to profile users and show them personalized ads.</p><p>One of the ways that mobile apps make money is by selling information about what people do with their phones, like what websites they visit or where they are at a given moment. That information is tied to a<strong> </strong>numerical code, known as an advertising ID, embedded in Google and Apple’s operating systems.</p></div>



<p>This ID is meant to single out each individual device, creating a profile for advertisers to target ads to specific audiences. All the data obtained is supposedly <a href="https://www.iabuk.com/sites/default/files/publication-download/OnlineBehaviouralAdvertisingHandbook_5455.pdf">anonymous</a>, in the sense that it doesn’t contain any identifiable information, like names or dates of birth. But it can show locations at a given moment in time or websites visited on a smartphone. While users can opt out or reset it on their phone settings, <a href="https://www.adjust.com/glossary/idfa/">only 20% do it</a>.&nbsp;</p>



<p>According to Quiceno, every week, health officials in Antioquia send Servinformación a list of Covid-19 patients and their home addresses. The company first looks for IDs that usually spend the night at these locations. Then, the company searches for IDs found at least 10 meters from the patients’ devices for 30 minutes or more, and also for IDs that might have mingled with them and were at least 10 meters away from them for at least half an hour. Servinformación then blasts both sets of IDs with ads on social media and mobile games, asking the phones’ users to check for any Covid-19 symptoms.</p>



<figure><blockquote><p>Instead of a custom-made app, Bogotá and Antioquia are using mobile ad technology to do contact tracing and monitor how the virus is spreading.</p></blockquote></figure>



<p>There is a second part of this process. The company gathers all the spots where these IDs are spending most of their time and sends these locations to the Antioquia government.<strong> </strong>The officials then look up these properties’ owners in the state registry and send them text messages. “YOU MIGHT HAVE CORONAVIRUS,” the texts say in all caps.</p>



<p>Privacy activists worry that this system could give authorities <a href="https://www.huffingtonpost.co.uk/entry/using-just-1000-worth-of-mobile-adverts-you-can-effectively-track-anyone_uk_59e87ccbe4b0d0e4fe6d6be5?guccounter=1">too much information</a> about people’s daily lives. “It might become a surveillance system, if the government has data from every person who uses a smartphone,” said Andrés Velásquez, a researcher from the Karisma Foundation, the digital rights organization <a href="https://web.karisma.org.co/notificaciones-de-exposicion-a-traves-de-publicidad-wtf/">that first denounced</a> the use of ad tech by health authorities in Bogotá and Antioquia.</p>



<p>The question here is if the government can use these data to track and identify people against their will, particularly in a country where digital intelligence tools have been used to <a href="https://knightcenter.utexas.edu/blog/00-21801-fresh-outrage-colombia-after-semana-publishes-report-alleging-espionage-national-and-i">spy on</a> journalists, activists, and <a href="https://knightcenter.utexas.edu/blog/00-21801-fresh-outrage-colombia-after-semana-publishes-report-alleging-espionage-national-and-i">politicians</a>. “The data is not granular enough to know if two people were close enough for transmitting the virus. But it will expose where people have been and what they were doing,” said Katitza Rodríguez, international rights director of Electronic Frontier Foundation.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/IMG_9759-40x71.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/IMG_9759-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/IMG_9759-400x711.png 400w, https://restofworld.org/wp-content/uploads/2020/09/IMG_9759-600x1067.png 600w, " sizes="300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>“I just have to know where this person lives and see what IDs appear there,” Velasquez said. For example, if John Doe tests positive for Covid-19, health officials will know his address. Once Servinformación checks which IDs are spending the night in that same place, it would be easy for the government to infer which advertising ID belongs to John by seeing his location history.&nbsp;&nbsp;</p>



<p>Quiceno and Isaza say they don’t seek to identify people: The government doesn’t see the actual ID codes, and Servinformación claims it doesn’t have access to any information that could lead to people’s real identities. “The data only shows me the numerical code for the advertising ID and a time stamp,” Isaza said.&nbsp;</p>



<p>They also said that law enforcement has nothing to do with the program, and only the pandemic response team has access to the data. Servinformación is also contractually bound to erase all the information once the program is done, and neither the government nor the company can use the data for any other purpose.</p>



<p>Quiceno also defends mobile ad tracking as a way to do direct testing in high-risk areas. “We tell the cities which specific blocks they should send an epidemiological team to, as there might be a lot of positive cases there,” he told <em>Rest of World</em>. They have sent more than 411,000 ads and text messages since April, triggering more than 1,600 calls to health services — a response rate of 0.4%, below the benchmark of 0.5–0.7% for this kind of digital marketing campaign.</p>



<p>However, Quinceno said the edge Antioquia gains is worth all the hassle. Colombia had almost 600,000 Covid-19 <a href="https://ourworldindata.org/coronavirus/country/colombia?country=~COL#what-is-the-cumulative-number-of-confirmed-cases">confirmed cases</a> as of August 31, and it is <a href="https://ourworldindata.org/coronavirus-data-explorer?tab=table&amp;zoomToSelection=true&amp;country=USA~KOR~DEU~IND~BRA~ITA~IDN~ZAF~MEX~NZL~NOR~COG~COL&amp;casesMetric=true&amp;dailyFreq=true&amp;aligned=true&amp;smoothing=7&amp;pickerMetric=location&amp;pickerSort=asc">one of the countries with the highest rates of new cases</a> in the world, which puts it at a serious risk of overflowing the country’s healthcare capacity. Isaza says his company’s technology can help isolate the so-called Covid-19 “<a href="https://www.scientificamerican.com/article/how-superspreading-events-drive-most-covid-19-spread1/">superspreaders.</a>” “Just by locking down the blocks where these spreaders live,” he said, “the benefits would be huge.”</p>



<p>Colombians seem to acknowledge that. Once Moreno clicked the ad, she was redirected to a form that asked for private information, like her health antecedents&nbsp;and if she was experiencing Covid-19 symptoms. She filled it out, even though she felt like it was a bit too much. “I wanted to let them know I was here,” she said.</p>



<p>All that happened was the arrival of an SMS later that evening, at midnight: “We will call you if necessary.” No one did, but the ads kept showing up in her social feeds through the rest of the month, as a reminder that even in isolation, she was still surrounded by the virus.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/tracking-in-the-name-of-corona/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980705</guid>
            <pubDate>Tue, 03 Nov 2020 15:52:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Multicloud Gelatinous Cube]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24980702">thread link</a>) | @mooreds
<br/>
November 3, 2020 | https://cloudpundit.com/2020/09/18/the-multicloud-gelatinous-cube/ | <a href="https://web.archive.org/web/*/https://cloudpundit.com/2020/09/18/the-multicloud-gelatinous-cube/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>Pondering the care and feeding of your multicloud <a href="https://en.wikipedia.org/wiki/Gelatinous_cube">gelatinous cube</a>. (Which engulfs everything in its path, and digests everything organic.)</em></p>



<p>Most organizations&nbsp;<em>end up</em> multicloud, rather than&nbsp;<em>intending&nbsp;</em>to be multicloud in a deliberate and structured way. So typical tales go like this: The org started doing digital business-related new applications on AWS and now AWS has become the center of gravity for all new cloud-native apps and cloud-related skills. Then the org decided to migrate “boring” LOB Windows-based COTS to the cloud for cost-savings, and lifted-and-shifted them onto Azure (thereby not actually saving money, but that’s a post for another day). Now the org has a data science team that thinks that GCP is unbearably sexy. And there’s a floating island out there of Oracle business applications where OCI is being contemplated. And don’t forget about the division in China, that hosts on Alibaba Cloud…</p>



<p>Multicloud is inevitable in almost all organizations. Cloud IaaS+PaaS spans such a wide swathe of IT functions that it’s impractical and unrealistic to assume that the organization will be single-vendor over the long term. Just like the enterprise tends to have at least three of everything (if not ten of everything), the enterprise is similarly not going to resist the temptation of being multicloud, even if it’s complex and challenging to manage, and significantly increases management costs. It is a rare organization that both has diverse business needs, and can exercise the <em>discipline&nbsp;</em>to use a single provider.</p>



<p>Despite recognizing the giant ooze that we see squelching our way, along with our unavoidable doom, there are things we can do to prepare, govern, and ensure that we retain some of our sanity.</p>



<p>For starters, we can actively choose our multicloud strategy and stance. We can classify providers into tiers, decide what providers are approved for use and under what circumstances, and decide what providers are preferred and/or strategic.</p>



<p>We can then determine the level of support that the organization is going to have for each tier — decide, for instance, that we’ll provide full governance and operations for our primary strategic provider, a lighter-weight approach that leans on an MSP to support our secondary strategic provider, and less support (or no support beyond basic risk management) for other providers.</p>



<p>After that, we can build an explicit workload placement policy that has an algorithm that guides application owners/architects in deciding where particular applications live, based on integration affinities, good technical fit, etc.</p>



<p>Note that&nbsp;<strong>cost-based provider selection and cost-based long-term workload placement are both terrible ideas. </strong>This is a constant fight between cloud architects and procurement managers. It is rooted in the erroneous idea that IaaS is a commodity, and that provider pricing advantages are long-term rather than short-lived. Using cost-based placement often leads to <em>higher&nbsp;</em>long-term TCO, not to mention a grand mess with data gravity and thus data management, and fragile application integrations.</p>



<p>See my new research note, “<a href="https://www.gartner.com/document/3990249">Comparing Cloud Workload Placement Strategies</a>” (Gartner paywall) for a guide to multicloud IaaS / IaaS+PaaS strategies (including when you should pursue a single-cloud approach). In a few weeks, you’ll see the follow-up doc “Designing a Cloud Workload Placement Policy” publish, which provides a guide to writing such policies, with an analysis of different placement factors and their priorities.</p>
			
			
						</div></div>]]>
            </description>
            <link>https://cloudpundit.com/2020/09/18/the-multicloud-gelatinous-cube/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980702</guid>
            <pubDate>Tue, 03 Nov 2020 15:51:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pair Blogging: The Epoch]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24980633">thread link</a>) | @vitoc
<br/>
November 3, 2020 | https://www.vitochin.com/blog/pairblogging/ | <a href="https://web.archive.org/web/*/https://www.vitochin.com/blog/pairblogging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>AD:</strong><br>
So how do we write a blog post together Vito?</p>
<p><strong>VC:</strong> <br>
What do you want to write about?</p>
<p><strong>AD:</strong> <br>
I don’t know<br>
What should we?<br>
Tech?<br>
Culture?<br>
Life?<br>
Let’s do it bro</p>
<p><strong>VC:</strong><br>
Sure<br>
UX maybe 😊 inclusive UX?</p>
<p><strong>AD:</strong><br>
That isn’t bad<br>
Something we have strong opinions about<br>
Or maybe contrasting opinions<br>
Hah!</p>
<p><strong>VC:</strong><br>
but I tend to eventually agree with yours though 😊</p>
<p><strong>AD:</strong><br>
Other way round lol!</p>
<p><strong>VC:</strong><br>
Recently, I thought about the conversation we had at the Starbucks at the ground floor of your new office (<strong>AD:</strong>   now old office!)</p>
<p><strong>AD:</strong><br>
Remind me again</p>
<p><strong>VC:</strong><br>
You said something on how good programming practices makes the tools/language used more or less moot…</p>
<p><strong>AD:</strong><br>
Some practices transcend tools I guess</p>
<p><strong>VC:</strong><br>
Well, I had been suffering lately from maybe around 5 years of technical debt in Prudent, stemming from the lack of use of types… (Prudent is VC’s side project)</p>
<p><strong>AD:</strong><br>
That’s sort of true I think still<br>
Haha</p>
<p><strong>VC:</strong><br>
Suffering is not a good word, its an interesting relationship more like</p>
<p><strong>AD:</strong><br>
Yeah<br>
(but) you have to appreciate what was there<br>
I mean, <em>it works</em></p>
<p><strong>VC:</strong><br>
Hmm…</p>
<p><strong>AD:</strong><br>
It just can’t move<br>
Lol</p>
<p><strong>VC:</strong><br>
I am very tempted to rewrite from scratch again, time and again, and again…</p>
<p><strong>AD:</strong><br>
It’s the best feeling<br>
I kind of wish you had unlimited time<br>
Could just write non stop till it was good enough</p>
<p><strong>VC:</strong><br>
It’s like I am getting nowhere, deja vu in the quantum of years<br>
I am starting again, but this time, I will write it out with pencil first, mathematically…</p>
<p><strong>AD:</strong><br>
I think it’s just you learn to see more and more so it feels like there is more to get right<br>
The higher you are, the less the ground looks like it moves</p>
<p><strong>VC:</strong><br>
Yea, I am pretty sure I learnt, the hard way, but there’s no other way for me to learn, but this time I’d learnt, but it’s too late</p>
<p><strong>VC:</strong><br>
Programming is not something I can be satisfied with in a lifetime</p>
<p><strong>AD:</strong><br>
Yeah</p>
<p><strong>VC:</strong><br>
Need, more, time…</p>
<p><strong>AD:</strong><br>
Me too<br>
My gosh you can’t believe how little time I have now<br>
It’s crushing and depressing<br>
You know<br>
It’d be fun to do a blog series of rambling posts<br>
Sort of like today’s chat<br>
Wanna?</p>
<p><strong>VC:</strong><br>
How?</p>
<p><strong>AD:</strong><br>
Start a shared doc and start writing a lot!</p>
<p><strong>VC:</strong><br>
Okie dokie</p>
<p><strong>AD:</strong><br>
Journeys of software journeymen!<br>
The setup:<br>
Part 1) How we met, started together, and an interesting tidbit from the first months<br>
Wdyt<br>
Each post can revolve around a nugget of wisdom</p>
<p><strong>VC:</strong><br>
Hmm…<br>
let me immerse in this and try to get in this zone tonight :)</p>
<p><strong>AD:</strong><br>
😊
I was thinking it’d be cool<br>
Cause I’m going to revive my blog allending.com<br>
I was thinking MCU style<br>
Post 1 on yours<br>
Post 2 on mine<br>
etc<br>
Just seemed like something fun</p>
<p><strong>VC:</strong><br>
Yea, i had a cool idea too while going to sleep yesterday but forgot when i woke up 😅</p>
<p><strong>AD:</strong><br>
What was ittttt?<br>
😃</p>
<p><strong>VC:</strong><br>
Oh yeah<br>
Maybe something like a dialogue</p>
<p><strong>AD:</strong><br>
Oooh<br>
Vito: _____<br>
Allen: _______<br>
Chat revolving around a topic<br>
That’s not bad</p>
<p><strong>VC:</strong><br>
Yea, that is easier as it is less asynchronous</p>
<p><strong>AD:</strong><br>
Not bad<br>
We sort of chat together about something, edit it, and then post</p>
<p><strong>VC:</strong><br>
We can just start with this topic itself… let’s call it pair blogging</p>
<p><strong>AD:</strong><br>
Very meta<br>
and very smart<br>
Calendar slot will force us to do it ? 😊</p>
<p><strong>VC:</strong><br>
I can create a shared private repo on GH<br>
I think we can publish whenever ready<br>
I was thinking of publishing an edited version of this conversation as part of the first post?<br>
The title will be Pair blogging: the epoch<br>
I can send you a draft?</p>
<p><strong>AD:</strong><br>
Oooh good idea<br>
GIT<br>
Let’s</p>
<p>…</p>
<p><strong>And here we are!</strong></p>
<blockquote>
<p>Pair Blogging is a series of conversations between Vito Chin and Allen Ding about technology, culture, and life.</p>
<p><a href="https://twitter.com/vitoc">Vito</a> is a Senior CSA at Microsoft, where he helps partners <a href="https://www.vitochin.com/about/azure/">deploy apps and develop practices on Azure</a>. Vito is also the creator of <a href="https://prudent.me/">prudent.me</a>, a lifetime side project to make personal finance optimization work.</p>
<p><a href="https://twitter.com/alding">Allen</a> is a CEO at <a href="https://www.snappymob.com/">Snappymob, a web and mobile app developer</a> based in Malaysia. Allen has worked on a lot in the past, and mostly focuses on the business of software now, especially a SaaS he has in the works.</p>
</blockquote>

  </div></div>]]>
            </description>
            <link>https://www.vitochin.com/blog/pairblogging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980633</guid>
            <pubDate>Tue, 03 Nov 2020 15:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WTF Happened in 2008]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24980408">thread link</a>) | @paulpauper
<br/>
November 3, 2020 | https://greyenlightenment.com/wtf-happened-in-2008/ | <a href="https://web.archive.org/web/*/https://greyenlightenment.com/wtf-happened-in-2008/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-21619">
	
	<!-- .entry-header -->

	<div>
		<p>For the past 2 months, I have been seeing many discussions and references to the website “WTF Happened in 1971?” (wtfhappenedin1971.com), which purports to show how society underwent drastic societal and economic change around 1971. </p>
<p>If I was going to make a similar website, I would put the cut-off point as recently as 2008, as when society underwent drastic societal and economic change. I would divide it into the pre-2008 period and the post-2008 period, because that is really when the US began to pull ahead of the rest of the world economically and solidified its dominance, and the fed and other central banks began to implement 0% or lower interest rates, which in the pre-2008 era seemed inconceivable.  Also, 2008 saw the election of Obama, who I think engendered an era of increasing radicalization of the American-left (such as the rise of ‘cancel culture,’ antifa, BLM, the censorship and de-platforming of academics, and loss of creative freedom, whereas in the pre-2008 era its was conservatives who were considered repressive, and it was liberals were defenders of free speech), and the increasing polarization of US politics. </p>
<p>Although, for generations, America has always been divided into a left-right dichotomy, this division seems to have intensified under Obama, who by virtue of his skin color made race a focal issue even if unintentional (but also intentionally, such as Obama invoking the likeness of his hypothetical son to Treyvon Martin, who was killed by ‘white-Hispanic’ George Zimmerman–a case that further exacerbated such division in America, and made worse by Obama taking a side). The Obama presidency had the effect of dividing America, not just in terms of the issues, but along implicit racial lines and identity, as many whites perceived Obama as embodying or conveying anti-white sentiment, and likewise many blacks became increasingly distrustful of Whites. Groups such as the Tea Party, antifa, and BLM rose in the early 2010s, as evidence of increasing division.  Obama’s presidency seemed like a step backwards, in contrast to Clinton, who had the effect of mending race relations, especially after the 1992 Rodney King riots. Now, 18 years later, cities are burning again. Even if there is less crime than ever, as noted by Steven Pinker, it feels like America is on the precipice of blowing up, if it hasn’t already. </p>
<p>Economically, a characteristic the post-2008 era is America solidifying its dominance globally in the aftermath of the 2008 crisis; for example, the increasing strength of the US dollar relative to the Euro, Pound, and emerging market currencies, whereas pre-2008 the US dollar was not that strong or such strength was cyclical. During the crisis and its aftermath, from 2008-2010, many pundits predicted a ‘post-America era’ or that America would take a backseat to Europe or China , but the opposite has happened, with America pulling way ahead of the rest of the world (with the possible exception of China) in terms of GDP growth, stock market gains, cultural and economic influence (such as Hollywood blockbusters grossing billons of dollars overseas, and rich Chinese flocking to the safety of the US housing market, pushing up up prices in Seattle and the Bay Area, to the chagrin of the media, who for years  have been complaining about housing being unaffordable, a 180-degree change in sentient from 2008-2011 when everyone was talking about falling prices), and tech innovation. Europe initially seemed to have exited the 2008 crisis in better economic shape compared to the US, but since 2010, similar to Japan’s 3-decade-long slump, has entered a period of prolong stagnation. </p>
<p>As shown below, since 2014, the US dollar index has been very strong. Although we cannot say how long this will last, I predict the dollar will remain strong for many years, even decades, to come. The Euro/US exchange rate, now at 1.17, will likely never revisit its pre-2008 highs.</p>
<p><img src="https://fred.stlouisfed.org/graph/fredgraph.png?width=880&amp;height=440&amp;id=TWEXB"></p>
<p>Increasing global uncertainty due to Covid and other factors, but also the weakening of foreign and emerging market economies, will likely create a strong demand for the dollar and treasury bonds due to ‘flight to safety’ trade, for the foreseeable future.  As bad as the US may seem–with BLM protests, increasing Covid cases and deaths, increasing political division and uncertainty about Trump, Biden, and China–much of the rest of the world is even worse in terms of economic weakness, unrest, and uncertainty. </p>
<p>For example, in July-September during the so-called ‘second wave’ of Covid cases, Trump was criticized heavily by the media and blamed for the resurgence of cases, but now Germany, Denmark, Spain, Norway, and other European countries, which were praised earlier in the year for seemingly having the virus under control, have all experienced massive second waves. Germany is now seeing record number of new daily cases, so this shows how even countries that initially seemed to be doing better than the US, have also succumbed to second waves. Moreover, as discussed <a href="http://greyenlightenment.com/right-again-covid-deaths-had-no-effect-on-stock-market/">earlier</a>, the stock market indexes of countries with fewer per capita Covid deaths as the US, such as Germany, have not outperformed the S&amp;P 500 since the pandemic began. </p>
<p>So this counters two media narratives: that the US handled Covid exceptionally poorly compared to the rest of the world [Germany's second wave shows that either Covid is very hard to contain regardless of competence or lack thereof of leadership and that second waves are inevitable; and or, that if Trump handled it incompetently, so did other leaders, but only that such incompetence manifested itself later (in September, October) rather than sooner (June, July) due to second waves being prolonged and delayed rather than averted completely. Germany was never able to prevent a second wave, but only delayed it due to aggressive social distancing measures early on]; and the second narrative: and that the US economy is lagging or weak  due to Covid (if we use the S&amp;P 500 as a proxy for economic health). As discussed above, S&amp;P 500 performance post-Covid is equal to that of Germany, which has had 80% fewer per-capita deaths as the US. The same pattern also holds for Sweden. But also, the S&amp;P 500 made new highs in October, as further evidence of Covid’s impact on the US economy only being temporary. So even if the media is right and Trump handled Covid poorly, the US economy still came out ahead of the rest of the world as further evidence of America’s economic dominance and strength in the post-2008 era, that even Covid could not undo.</p>
<p>Low US treasury yields, even lower than in the early 40s; but more importantly, how low yields have become permanent and the ‘new normal’. This trend has also been observed globally, with Western European countries such as Germany also having permanently low interest rates, even negative rates:   </p>
<p><img src="https://image.cnbcfm.com/api/v1/image/106413802-15837750747902020030810yrfrom1900.png?v=1583775102&amp;w=678&amp;h=381"></p>
<p>Permanently low inflation, but coupled with strong real GDP growth.  Just as interest rates are permanently low in the US, so is inflation, but unlike Western European countries or Japan, there is no deflation, and real US GDP growth remains strong, at 2-3% a year [The assumption by Krugman and other Keynesians is that low inflation must come at the cost of growth. This has been the case with Japan, but not the US]. This may not seem like much, but 2% real GDP growths exceeds that of South American economies, much of Europe, Japan, Turkey, the Middle East, Russia, and much of Asia. Sure, such the economies of the of the aforementioned countries may have more nominal GDP growth, but also much more inflation and collapsing or weak currencies, so the real, US-dollar adjusted growth is either flat or negative. Moreover, since 2008, the S&amp;P 500 has also outperformed all foreign peers by a huge margin.</p>
<p>As shown below, in terms of real GDP growth, the US has outperformed all developed economies since 2008 by a considerable margin:  </p>
<p><img src="https://i.imgur.com/olCeKrN.jpg"></p>
<p><img src="https://static.seekingalpha.com/uploads/2017/6/21/saupload_GDP.png"></p>
<p>Meanwhile, in spite of trillions of dollars  of spending under Trump and Obama (and endless predictions by the likes of Peter Schiff about dollar collapse, hyperinflation, and so on)–such as the 2008 bank bailouts, The American Recovery and Reinvestment Act, Obamacare, the Covid stimulus and bailouts, defense spending, healthcare, and much more to come–inflation just refuses to budge , at around 2% year. This is partly due to insatiable demand for low-yielding US debt, as creditors (such as pensions, corporations, wealthy individuals, sovereign wealth funds, and institutions) have nowhere else to park their money, and also that such spending is not really entering the US economy in terms of activity, but rather is being parked/saved or used to pay down existing debts. For example, in regard to the CARES Act, according to the NBER, “US households report spending approximately 40 percent of their stimulus checks, on average, with about 30 percent saved and another 30 percent used to pay down debt.” When Trump in early 2018 announced tariffs against China, the economic consensus at the time was that this would hurt the US economy and or cause high inflation. The media was, yet again, wrong on all counts: inflation did not budge, there was no trade war, there was no recession, and the stock market would go on to make new highs not long after. </p>
<p>As the rest of the world stagnates, since 2008 especially, the US has also pulled way ahead in terms of innovation and tech dominance, with mega-sized tech and retail companies such as Tesla, Google, Apple, Walmart, Visa, PayPal, Nike, Amazon, Zoom, Space-X, Facebook, Microsoft, Netflix, Uber, etc., having either been founded since 2008 or have seen their dominance and and market capitalization surge since 2008, even relative to the S&amp;P 500. The Nasdaq, which is composed of such tech companies, is the best-performing index of any developed economy since 2008 by a huge margin, and even exceeding its 90s performance even after factoring in the 90s tech boom (and such performance is magnified even more so by a backdrop of …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greyenlightenment.com/wtf-happened-in-2008/">https://greyenlightenment.com/wtf-happened-in-2008/</a></em></p>]]>
            </description>
            <link>https://greyenlightenment.com/wtf-happened-in-2008/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980408</guid>
            <pubDate>Tue, 03 Nov 2020 15:21:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reddit and Lisp Psychosis (2005)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24980399">thread link</a>) | @susam
<br/>
November 3, 2020 | http://www.findinglisp.com/blog/2005/12/reddit-and-lisp-psychosis.html | <a href="https://web.archive.org/web/*/http://www.findinglisp.com/blog/2005/12/reddit-and-lisp-psychosis.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>I went away on a family vacation at the first part of this week and just got back last night. During that time, I completely missed the whole <a href="http://lemonodor.com/archives/001301.html">Reddit</a> <a href="http://pobox.com/~dnm/tdw/2005/12/contextinople.html">scandal</a>. It seems like the guys at Reddit ended up choosing to <a href="http://reddit.com/blog/2005/12/on-lisp.html">rewrite Reddit in Python</a> because Lisp just wasn't working for them. To some, this seems to be a slap in the face of Lisp. However, if you look at <a href="http://reddit.com/blog/2005/12/on-lisp.html">spez's blog entry</a>, you can see that the rationale for choosing Python was pretty sane.</p>

<p>In particular, this paragraph was interesting (also <a href="http://lemonodor.com/archives/001301.html">quoted by John at Lemonodor</a>):</p>
<blockquote>
Emacs and SLIME are a killer combination, but I develop on a Mac, and reddit.com is a FreeBSD box. On my Mac, my choices of threaded Lisp implementations was limited to OpenMCL, and in FreeBSD it's CMUCL. Because of the low-level socket and threading code we had to write, reddit would not run on my Mac, and I was always tethered to our FreeBSD development server. Not being able to program offline is a pain.
</blockquote>

<p>In a comment on <a href="http://lemonodor.com/archives/001301.html">Lemonodor</a>, Steve Huffman said:</p>
<blockquote>
The biggest trouble that plagued us was that we could never quite get Lisp reddit stable enough to sleep at night. There were weird threading issues that would bring the site to its knees a couple times a day and required constant monitoring.
</blockquote>

<p>Now, here's where the Lisp psychosis comes in. Rather than suggesting that the guys at Reddit were dopes, or that they didn't try hard enough, or that they should have done such and such a workaround, blah, blah, I wish Lispers would step up and internalize that the Reddit experience was a great case study and that the community should work to solve the issues it raised. These guys did not have a bad Lisp experience. In fact, they are quite complimentary of Lisp. For <a href="http://reddit.com/blog/2005/12/on-lisp.html">example</a>:</p>
<blockquote>
Lisp is an amazing language. After spending the entire summer working entirely in Lisp, it's nearly impossible to work in another language and not say to myself, "If only this were Lisp..." Lisp has many goodies that make programming in it a joy: the REPL, macros and the lack of syntax are some. I won't go into the details, but rest assured, it's cool. People become Lisp zealots for a reason.
</blockquote>

<p>So here's what I took away from the Reddit feedback:</p>
<ol>
<li>Lisp is a great language. Keep this point in mind. The Reddit developers gave Lisp compliments; they didn't 'diss it.</li>
<li>Lisp has a balkanized feature set. Some (necessary!) things to build modern applications are not cross-platform. When you have to work on multiple machines and environments, which is more and more the norm these days, there are no open source implementations of Lisp that run across the dominant environments without differences. (CLISP comes the closest, but you may or may not be able to tolerate its GPL license terms.) Because these features are not standardized, you're left writing compatibility layers if you want things to work across platforms.</li>
<li>In particular, networking and threading are problem areas.</li>
<li>Lisp libraries are scant. This is a well known problem in the Lisp community. The standard, basically valid, response is "Jump in and help us write some more libraries." (Kudos to Kenny Tilton for driving this line hard. He's right, but there's also a bit more to it than that.)</li>
<li>The library problems are compounded by the balkanization of feature set. In some cases you can find something that sort of works, but it may work on another implementation, not yours. If it has any dependencies on the problem areas of threads and networking, you've got a long road of tweaking ahead to get it to work. This time is better spent getting on with your real task.</li>
<li><a href="http://weitz.de/">Edi Weitz</a> (yet again) wins the Lisp Superhero award for creating the best libraries out there, bar none. Seriously, if anybody aspires to create libraries that are well-used, go take some cues from Edi. His code is always high quality, his APIs and implementations are always complete, he's absolutely responsive to problem reports, he provides great documentation, and he often tests his code across multiple implementations, trying to make them as cross-platform as possible. In short, you couldn't expect better service and support from a commercial vendor, and Edi releases his code as open source.</li>
</ol>

<p>Okay, all that said, what's the constructive response here? My suggestions are:</p>
<ol>
<li>First, stop grumbling and suggesting workarounds to the Reddit folks. They did the Lisp community a great service by documenting their experiences. Rather than harrassing them, sit down and talk with them to get more info.</li>
<li>Next, focus on the foundational balkanization problems. In my opinion, the biggest issues with Lisp are the lack of standard (defacto or otherwise) networking and threading APIs. If those were in place, it would be a lot easier to get libraries that worked all over the place. Would this solve everything? No, but it would go a long way and would enable lots of other innovation on top of that foundation instead of having everybody spending time creating compatibility libraries and generally re-inventing the wheel.</li>
<li>Work on getting a good cross-platform, open source Lisp implementation with a liberal license. Like I said previously, I really like <a href="http://clisp.cons.org/">CLISP</a>, and I use it for developing on Windows, but the license is not suitable for all code since it all-but-forces your code to be released as GPL. I'd really love to see <a href="http://www.sbcl.org/">SBCL</a> or <a href="http://www.cons.org/cmucl/">CMUCL</a> ported to Windows, with the full set of functionality. I'd also love to see SBCL's baseline functionality present on all platforms (currently threading only works on Linux, for instance, not BSD). By the way, this is no knock on any other Lisp implementation. I just happen to use SBCL on Linux and think it rocks. If <a href="http://openmcl.clozure.com/">OpenMCL</a> can make the jump off of Mac onto other platforms, that would be great. Or maybe <a href="http://www.gnu.org/software/gcl/gcl.html">GCL</a> can do the job. I don't know the exact route, but the fact is the lack of a baseline functionality across all platforms is hurting us.</li>
</ol>

<p>Can I do all the above? Nope. I've tried grokking the internals of SBCL and I'm only qualified to kibitz around the margins. I stand in awe of guys like William, Christophe, Dan, Nikodemus, Gabor, Juho, Alexey, and many others (Update: I added to this list twice already because I felt so bad for leaving out somebody's name--sorry William and Nikodemus. If you're a significant SBCL contributor--or even and insignificant one--believe me when I say I stand in awe of you too ;-). I do try to help out SBCL by reducing the friction for newbies to get started with Lisp, compiling the RPM binaries that are available on <a href="http://sourceforge.net/projects/sbcl/">SourceForge</a> and maintaining the <a href="http://www.fedoralisp.org/">FedoraLisp.org</a> Yum repository.</p>

<p>That said, I'm going to start working on the networking API issues. You'll see a document from me posted over the next couple of weeks. It's been in process for a few months, but I finally got a hankering to finish it with this Reddit bru-ha-ha. If you're interested in networking APIs and have a desire to help in such an endeavor, please drop me a line (dave at findinglisp). I'd love to spread the work around. If somebody else wants to grab the threading stuff by the throat that would be great.</p>

<p>Above all, stay productive. Use the Reddit feedback to motivate you to make Lisp better. Whatever you do, stop suggesting workarounds to the Reddit guys or making them feel bad for the choices they made. They seem like smart guys, so let's assume that they did what they did knowing all the options (they do have <a href="http://www.paulgraham.com/">Paul Graham</a> on the board, so I'm guessing that they talked about this before they did the rewrite). They have moved on and our job is to make any such workaround unnecessary for the next crew that tries to use Lisp.</p>

<p>And before anybody says it, yes I know that the commercial Lisp vendors have solved some of these problems. I have discussed before <a href="http://www.findinglisp.com/blog/2004/11/more-rad-thoughts.html">some of my thoughts about the various license terms the vendors use</a>. It isn't that those terms are bad in the abstract, they just don't allow those implementations to solve the problem I'm interested in. In short, I think it would help drive Lisp adoption if a common, cross-platform, free, open source version existed, in the same way that GCC has helped democratize programming in C. The next-best alternative would be a $99 "Turbo Lisp" environment ala Borland's language products in the 1980s/1990s. Perhaps the <a href="http://www.lispworks.com/">Lispworks</a> guys will offer such a thing (hint, hint ;-).</p><br>
          

		</div></div>]]>
            </description>
            <link>http://www.findinglisp.com/blog/2005/12/reddit-and-lisp-psychosis.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980399</guid>
            <pubDate>Tue, 03 Nov 2020 15:20:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Microsoft Z80 SoftCard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24980327">thread link</a>) | @elvis70
<br/>
November 3, 2020 | http://nicole.express/2020/nicole-gets-a-real-computer.html | <a href="https://web.archive.org/web/*/http://nicole.express/2020/nicole-gets-a-real-computer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>So there I was, very happy with my <a href="http://nicole.express/nicole-buys-stuff-apple-ii-plus.html">Apple ][<sub><i>plus</i></sub></a>. But then I saw someone on the internet post, and it seems that my Apple is an overpriced box with a toy microcontroller for a CPU, while <em>real</em> computers use an Intel 8080, 8085 or Zilog Z80 to run something called “CP/M”… but I’ve already spent so much money on the Apple, so can I turn it into a real computer?</p>

<h2 id="microcontroller-says-what">Microcontroller says what?</h2>

<p><img src="http://nicole.express/assets/img/softcard/glory6502.jpg" title="BEHOLD" alt="The Apple II plus circuitboard, with its 6502 in the center"></p>

<p>First off, is the 6502 a microcontroller? Eh, not by modern standards, with no inbuilt ROM or RAM and no IO. But at the time of its release, MOS Technology definitely saw usecases we’d call “embedded” today as part of the processor’s mission. And if you buy a <a href="https://www.westerndesigncenter.com/wdc/w65c02s-chip.php">65C02</a> today from the Western Design Center, you’re probably using it for that. Or for a hobby machine, I suppose.</p>

<p><img src="http://nicole.express/assets/img/softcard/z80time.jpg" title="I don't know who put that sticker there, but it's history now" alt="The Z80 CPU on the Apple softcard"></p>

<p>But the same is also true of the Z80. And yeah, you can get those today straight from <a href="https://www.zilog.com/index.php">Zilog</a> themselves. Good thing for TI; gotta keep that <a href="https://education.ti.com/en/products/calculators/graphing-calculators/ti-83-plus">graphing calculator</a> racket going. Insulting 8-bit processors by calling them microcontrollers, in this, the year 2020? That’s the only thing that keeps them going!</p>

<h2 id="back-to-the-1970s">Back to the 1970s</h2>

<p>But let’s take a look at the historical view to understand where my angry internet commenter friend might be coming from.</p>

<p>Today, many computer historians date the microcomputer era as starting in 1977 with the “Trinity” (a term which may not have been used at the time, but is definitely used now) of the Commodore PET, the Tandy/Radio Shack TRS-80 Model I, and the Apple ][. Two of these machines were 6502-based, and one was Z80-based. None of the three could run CP/M. (Some later TRS-80 computers could, but what Tandy did to the TRS-80 brand…)</p>

<p>But some might go back to 1974, with the Altair 8800. Nope, of course I don’t have one of those. In 1974 there were no Z80s or even 6502s; the Altair used the Intel 8080, an 8-bit design that was one of the first real heavily used microprocessors. It used a <a href="https://en.wikipedia.org/wiki/S-100_bus">100-pin bus</a> that somehow managed to get in the hands of the military, ensuring support until the 1990s.</p>

<p>The Altair 8080 spawned a whole series of clones which used the same CPU (or the later Intel 8085 and Zilog Z80, which could run the same software, but required less support circuitry and added some features), but all these clones had slight differences; some would output through a teletype or serial terminal. Maybe others had a graphics display. Disk drives were still in the throes of shifting from 8” to the 5.25” disks we now call “big”, but they called “mini”.</p>

<p>And that was what CP/M was for: a <b>C</b>ontrol <b>P</b>rogram and <b>M</b>onitor that could be ported to any of these machines, and paper over those differences for software. That’s still what operating systems do today. But the basic requirements were RAM in the right places (Tandy failed that one), and an Intel 8080-compatible CPU (Apple and Commodore whiffed that one).</p>

<p>So if you had been a microcomputer enthusiast or a business that was an early adopter in 1977, you might be a little miffed at the “Trinity”; sure, they were cheaper and more accessible than the expensive S-100 bus machines, and were a complete package, but they also ignored all the standards and were incompatible with all your software.</p>

<p><img src="http://nicole.express/assets/img/softcard/badge.jpg" title="It's just pretty" alt="The Apple II plus exterior, focusing on the logo"></p>

<p>But this is a blog post about the Apple ][. An illustrious line of computers that would outlive its competition. And it did that through its expandability. Who needs S-100 when we have A-50?</p>

<h2 id="enter-microsoft">Enter… Microsoft?</h2>

<p><img src="http://nicole.express/assets/img/softcard/notsosoft.jpg" title="Can you imagine a world where everything is done with 74xx logic" alt="The Z80 Softcard, with a rockin' Microsoft Consumer Products logo"></p>

<p>That logo on the Z80 SoftCard might surprise you. How on earth did Microsoft have such an awesome logo in the 1970s, and why would they ever give it up? Also, why are they making Apple parts?</p>

<p>Well, Microsoft was the largest vendor of BASIC, a programming language that was available all over (my Apple ][plus has Microsoft BASIC in ROM), but had made its initial start on the Intel 8080 machines. So perhaps that’s why they decided to sell a card, to allow users access to the pre-existing ecosystem they had helped build. And it’s not even the only Microsoft card in my Apple!</p>

<p>The card was, according to Wikipedia, designed by Tim Paterson, who at the time worked for Seattle Computer Products, a hardware company that Microsoft often worked with in those days. He was also clearly a CP/M fan; when the official port to Intel’s new 8086 16-bit CPU was delayed, he wrote his own clone– a clone which became MS-DOS. So this card has quite a pedigree!</p>

<h2 id="install-the-card">Install the card</h2>

<p><img src="http://nicole.express/assets/img/softcard/slots.jpg" title="I need more cards" alt="The Apple II plus circuitboard, showing its cards"></p>

<p>So now we install the card. This is a pretty typical, if bare, setup, with a Microsoft RAM card in slot 0, and a 5.25” Disk Controller in slot 6. But the interesting thing is, this isn’t what Woz expected. Apple documentation of the time suggests that cards be added from left to right to allow the DMA priority lines (more on what that means later) to be continuous. Cards were supposed to be able to inhabit any slot; writing position-independent code is a bit hard on the 6502, but it’s not impossible.</p>

<p><img src="http://nicole.express/assets/img/softcard/softcards.jpg" title="You think this is bad, look at S-100" alt="From the Microsoft SoftCard documentation, explaining the slot layout"></p>

<p>Perhaps because of that difficulty, Microsoft decided to create a standard arrangement of cards. I’m not actually sure if this originated with Microsoft, but the SoftCard documentation is the earliest I can find it.</p>

<p><img src="http://nicole.express/assets/img/softcard/iigs.jpg" title="Isn't this blog post about your II plus" alt="The Apple IIgs control panel, showing the default slot layout"></p>

<p>A memory expansion card in slot 0, a printer in slot 1, an IO device in slot 2, an 80 column card in slot 3, and disks in 5 and 6, with 7 being any type. That might seem familiar to a user of the Apple IIgs. (The Apple IIgs has a full contingent of slots, but maps its built-in hardware to the memory addresses of the original slots for backwards compatibility) Sure, they didn’t see the need for a mouse in 1980, but who did? (Xerox, yes) In any case, this card arrangement was pretty much standard among Apple users by the early-to-mid 1980s.</p>

<p>I want to run the CP/M card on my period-appropriate machine; not the IIgs, but the Apple II plus. Today, it’s hooked up to the Monitor ///; CP/M software doesn’t need color. In fact, this is a fairly period-accurate setup. While the Apple /// was not a huge success, its monitor seems to have been.</p>

<p><img src="http://nicole.express/assets/img/softcard/monitor3.jpg" title="Probably because it looks awesome" alt="The Monitor III sitting on the Apple II plus"></p>

<h2 id="turn-it-on">Turn it on!</h2>

<p><img src="http://nicole.express/assets/img/softcard/nada.jpg" title="It's still a cool boot screen" alt="The standard Apple II boot screen. Nothing's changed"></p>

<p>The Apple ][plus, with the Z80 Softcard installed, still boots to its normal Autostart ROM, waiting for you to insert a disk. It’ll boot those disks like normal, and if you press reset, you can end up in Applesoft BASIC.</p>

<p><img src="http://nicole.express/assets/img/softcard/laz80.jpg" title="Shh it can hear us, it's on the bus" alt="Applesoft BASIC, with a simple program that prints 'Wow, that lazy Z80 isn't doing anything'"></p>

<p>But of course, this is exactly how you’d want it. You wouldn’t want to suddenly lose all compatibility with 6502 software; in fact, the Z80 goes to great pains to keep compatibility, as we’ll see later. Things only change once you insert a CP/M boot disk.</p>

<p><img src="http://nicole.express/assets/img/softcard/oopsi80.jpg" title="see nicole you made it mad" alt="A boot message CANT FIND Z80 SOFTCARD"></p>

<p>Oops. Those slots are around 30 years old, some contact cleaner couldn’t hurt. And notice that it drops you in the ROM monitor (the “*” prompt) rather than BASIC. (Integer BASIC had a “&gt;” prompt, and Applesoft a “]” prompt) In this case, it probably just did a <code>BRK</code> opcode. You can get the same behavior in your own problems, which can be helpful in debugging.</p>

<p>Anyway, one deoxit later, and…</p>

<h2 id="enter-apple-cpm">Enter Apple CP/M</h2>

<p><img src="http://nicole.express/assets/img/softcard/cpmboot.jpg" title="I'm sure Microsoft will never get into a massive lawsuit with the creators of CP/M" alt="A boot message APPLE ][ CP/M"></p>

<p>And here we are! This is a “&gt;” prompt, but it’s not Integer BASIC. You’ll find none of your familiar Apple DOS or ProDOS (which didn’t even exist yet) commands like <code>CATALOG</code> will help you here.</p>

<p><img src="http://nicole.express/assets/img/softcard/catalogdir.jpg" title="this prompt will never catch on" alt="The CP/M prompt"></p>

<p>The CP/M prompt is a lot like the DOS prompt. And that shouldn’t surprise you; after all, MS-DOS started out as a clone of CP/M. Familiar commands like <code>DIR</code> to list a directory and <code>TYPE</code> to print out a file exist here too. But it’s a very early ancestor; things like directories don’t exist just yet. The COM files are executables, just like in MS-DOS; EXE files aren’t a thing.</p>

<p>And you’ll see <code>MBASIC</code>. (and <code>GBASIC</code>, a variant that supports Apple ][ high-resolution graphics) That’s right, this contains the Z80 version of Microsoft BASIC. And they even customized it for the Apple ][, which is pretty neat.</p>

<p><img src="http://nicole.express/assets/img/softcard/basic80.jpg" title="No prompt at all!" alt="Microsoft BASIC for the Z80"></p>

<p>Notice that there are only 14195 bytes free in RAM. Unlike Applesoft, which resides in ROM, CP/M <code>MBASIC</code> has to live in the free RAM, and CP/M’s OS facilities take up even more of that space. So this takes up a lot of space that could be used for your programs. But hey, the manual says it’s better.</p>

<p><img src="http://nicole.express/assets/img/softcard/mbasicman.jpg" title="Not biased" alt="MBASIC's description in the Softcard manual. It says 'This is Microsoft BASIC. This version of BASIC is disk BASIC that supports low-resolution graphics, sound, and game controls in addition to many features not found in Applesoft. This version does not support high-resolution graphics."></p>

<p>By the way, <code>GBASIC</code>, which does support high-resolution graphics, only gives you 5105 free bytes for your program. Hey, it still beats a stock VIC-20.</p>

<h2 id="lets-benchmark-this">Let’s ‘benchmark’ this!</h2>

<p>So, we have BASIC. This means that we can run our notoriously terrible benchmark, the Nicole Simulator! (For some history, this originated in my <a href="http://nicole.express/2018/replacing-the-cpu-in-a-tandy-1000-hx.html">Tandy 1000HX</a> blog post).</p>

<p>The Z80 in the Softcard is clocked at 2.041 MHz (it’s a little more complicated than that, as Apple ][ timing is a bit of a mess), which is similar to the clock speed the RAM runs at. That’s a bit slow for Z80, but remember that this test, a simple BASIC program, is primarily limited by the ability to put characters on screen. And the Apple ][ is very good at that.</p>

<p><img src="http://nicole.express/assets/img/softcard/nicode.jpg" title="Basically this is all I do" alt="A simple BASIC program which prints 'NYA' 10,000 times"></p>

<p>Fun fact: I initially wrote that first line <code>FOR I=1TO10000</code>, but something wanted the spaces. Not sure what; spaces are usually not required in BASIC, as you can see on the <code>20 PRINT"NYA"</code> line.</p>

<p>In any case, here’s the result!</p>

<table>
  <thead>
    <tr>
      <th>Computer</th>
      <th>CPU</th>
      <th>Clock speed</th>
      <th>Time to 10K nya (mm:ss)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Apple ][<em>plus</em></td>
      <td>MOS 6502</td>
      <td>1 MHz</td>
      <td>3:22</td>
    </tr>
    <tr>
      <td>Tandy 1000 HX</td>
      <td>Intel i8088</td>
      <td>7.16 MHz</td>
      <td>4:39</td>
    </tr>
    <tr>
      <td>Tandy 1000 HX</td>
      <td>NEC V20</td>
      <td>7.16MHz</td>
      <td>4:05</td>
    </tr>
    <tr>
      <td>Sega SC-3000</td>
      <td>Zilog Z80</td>
      <td>4.00MHz</td>
      <td>9:54</td>
    </tr>
    <tr>
      <td>Tandy Color Computer 2</td>
      <td>Motorola 6809A</td>
      <td>895kHz</td>
      <td>1:47</td>
    </tr>
    <tr>
      <td>Nintendo Famicom</td>
      <td>Ricoh 2A03</td>
      <td>1.79MHz</td>
      <td>8:20</td>
    </tr>
    <tr>
      <td>RetroUSB AVS</td>
      <td>Simulated 2A03</td>
      <td>1.79MHz</td>
      <td>8:30</td>
    </tr>
    <tr>
      <td>Apple ][<em>plus</em></td>
      <td>Zilog Z80</td>
      <td>2 MHz</td>
      <td>4:19</td>
    </tr>
  </tbody>
</table>

<p>Very nice! The overhead of having to go through CP/M to write on screen doesn’t help compared to the stock bare-metal Applesoft routines, but this is still a great showing.</p>

<p>You might wonder why it does so much better than the <a href="http://nicole.express/2019/8bit-battle-tandy-sega.html">Sega SC-3000</a>. And honestly, I don’t know why the SC-3000 bombed <em>that</em> badly, but the fact that both it and the NES had comparable slow speeds makes me think that it has something to do with the fact that those systems can only access Video RAM during limited intervals, and don’t have direct access to it. (This is also how CGA works, but the beefier processors help there)</p>

<p>Still, this was way faster than I expected. Good on you, Z80.</p>

<h2 id="more-technical-details">More technical details</h2>

<p>So, an interesting …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://nicole.express/2020/nicole-gets-a-real-computer.html">http://nicole.express/2020/nicole-gets-a-real-computer.html</a></em></p>]]>
            </description>
            <link>http://nicole.express/2020/nicole-gets-a-real-computer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980327</guid>
            <pubDate>Tue, 03 Nov 2020 15:13:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The tragic story of Gary Kildall (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24980239">thread link</a>) | @elvis70
<br/>
November 3, 2020 | https://bookjelly.com/the-tragic-story-of-gary-kildall/ | <a href="https://web.archive.org/web/*/https://bookjelly.com/the-tragic-story-of-gary-kildall/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

		
<article id="post-10659">
	<!-- .entry-header -->

	
	<div>
		
<p>The tech world brims with stories of triumph, showmanship, betrayal and deceit. But this is not one of those stories. This is a story of fate and confusion undoing what might have been a great testimony of <a rel="noreferrer noopener" aria-label="entrepreneurship (opens in a new tab)" href="https://bookjelly.com › category › entrepreneurship" target="_blank">entrepreneurship</a>. This is the story of Gary Kildall. </p>



<p>There was a time in the tech world when very few doubted Gary’s ascension until all of sudden things started crumbling before screeching to a heartbreaking halt. </p>



<p>What happened in between can best be described as a fateful turn of events.</p>



<p>In case you are still wondering who the heck this Kildall guy is, well, he was someone who could have been a multi-billionaire had he been in the right place at the right time. </p>



<p>He was someone who could have been as famous as Bill Gates had he played his cards right. </p>



<p>He was a tech visionary – a central figure in the development of personal computing in the ’70s and the early ’80s. </p>



<p>Gary started his career as a mathematics professor at Naval Post Graduate School in Monterey, California. With his background in mathematics, he started to lean towards programming. In 1972, he completed his Ph.D in Computer Science and started consulting for Intel. </p>



<p>It was around this time that Gary developed operating software for Intel 4004 microprocessor. He called it PL/M (<em>Programming Language for Microcomputers</em>). </p>



<p>Some time later, he came up with CP/M (<em>Control Programming for Microcomputers</em>) which could help the microprocessor control a floppy drive. </p>



<p>Apparently, CP/M failed to excite the Intel honchos and they decided to give it a pass.</p>



<p>Not happy with the cold response of Intel, Gary along with his wife Dorothy decided to go full hog with CP/M. </p>



<p>The couple started a company called Intergalactic Digital Research out of their old Victorian home in California. Later in 1977, they incorporated it as Digitial Research Inc. (DRI).</p>



<figure><img data-attachment-id="10771" data-permalink="https://bookjelly.com/the-tragic-story-of-gary-kildall/gary-kildall1/" data-orig-file="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?fit=1200%2C600&amp;ssl=1" data-orig-size="1200,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gary-Kildall1" data-image-description="" data-medium-file="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?fit=300%2C150&amp;ssl=1" data-large-file="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?fit=780%2C390&amp;ssl=1" loading="lazy" width="1200" height="600" src="https://i0.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?fit=780%2C390&amp;ssl=1" alt="" srcset="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?w=1200&amp;ssl=1 1200w, https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?resize=1024%2C512&amp;ssl=1 1024w" sizes="(max-width: 780px) 100vw, 780px" data-lazy-srcset="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?w=1200&amp;ssl=1 1200w, https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?resize=300%2C150&amp;ssl=1 300w, https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?resize=768%2C384&amp;ssl=1 768w, https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?resize=1024%2C512&amp;ssl=1 1024w" data-lazy-src="https://i0.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall1.jpg?fit=780%2C390&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Gary Kildall and his wife Dorothy (pic courtesy: <a href="http://computerhistory.org/" target="_blank" rel="noreferrer noopener" aria-label="computerhistory.org (opens in a new tab)">computerhistory.org</a>)</figcaption></figure>



<p>Before CP/M came along, every computer had to have a tailor-made software. Gary changed that. By 1979, CP/M was the most popular 8-bit operating system in the world. Microcomputer companies such as IMSAI 8080, North Star, Osborne were all running on CP/M. </p>



<p>At the same time, a little known company called <a href="https://en.wikipedia.org › wiki › Traf-O-Data" target="_blank" rel="noreferrer noopener" aria-label="Traf-O-Data (opens in a new tab)">Traf-O-Data</a> run by a certain Bill Gates and Paul Allen also used CP/M to collect data from the roadway traffic counters. </p>



<p>By the late-70s, the waves of change were sweeping away microcomputers. Gary was going to straddle the change from microcomputers to personal computers. A change even he didn’t see coming.</p>







<p><a href="https://bookjelly.com/valley-of-genius/" target="_blank" rel="noreferrer noopener">Steve Wozniak and co.</a> hit the market with first Apple personal computer in 1976 and soon others followed. </p>



<p>The PC market ballooned to $1 billion size within a matter of three years. </p>



<p>It wasn’t long before IBM – the tech giant of that era – took notice and decided to jump into the fray. </p>



<p>IBM knew it was late to the PC market and had to come out all guns blazing. </p>



<p>In 1981, the IBM crack team tasked with creating the first IBM PC decided to buy off-the-shelf components along with software in order to expedite its entry to the PC market.</p>



<p>Bill Gates and Microsoft were on the rise by the early ’80s. </p>



<p>IBM approached Gates who rightly pointed them to DRI citing that Microsoft had yet to build an operating system of its own. </p>



<p>However, before moving on, IBM legal team had Bill sign a non-disclosure agreement (NDA). </p>



<h2>What went wrong?</h2>



<p>The legend is that Bill Gates called Gary Kildall to inform him about the arrival of an important group of people. </p>



<p>His NDA with IBM forbid him to mention anything about the company and their meeting though. Sadly, Gary failed to decipher the cryptic message of Bill Gates and left for a flying trip in his private plane. </p>



<p>When IBM came knocking, Gary wasn’t home. His wife Dorothy and a team of DRI lawyers met the IBM team and apparently, failed to inspire any confidence in them.</p>



<p>IBM wanted a forever license for CP/M – something Dorothy refused flat-out. </p>



<p>Further, IBM wanted Dorothy to sign a unilateral non-disclosure agreement which she and her legal team weren’t very comfortable with.</p>



<p>By the time, Gary met the IBM team, a fair bit of damage was done. Gary wanted to sell CP/M on a royalty basis, retaining its name. IBM wanted to pay a one-time fee instead.</p>



<p>As a result, IBM team stalked out in a huff and appraoched Bill Gates again, who now sensed a clear opportunity. </p>



<p>The only issue was that Microsoft still didn’t have an operating system.</p>



<p>To solve this problem, Bill Gates scurried to <a rel="noreferrer noopener" aria-label="Seattle Computers (opens in a new tab)" href="https://en.wikipedia.org/wiki/Seattle_Computer_Products" target="_blank">Seattle Computers</a>, a me-too manufacturer of CP/M clone called Q-DOS. </p>



<p>Q-DOS was the shorthand for <em>Quick and Dirty Operating System</em>. Microsoft rechristened it as PC-DOS and presented it to IBM.</p>



<p>This upset Gary. </p>



<p>IBM sensing a legal infringement approached Gary with a solution that it would license both Microsoft’s PC-DOS and DRI’s CP/M with its line of PCs and let the market decide which one is better. </p>



<h2>Confusion reigned supreme</h2>



<p>When IBM rolled out the advertisements for both products, DRI was in for a rude shock. </p>



<p>Bill Gates had priced PC-DOS at $40 whereas Gary’s CP/M-86 sold for $240. A massive 6-to-1 chasm.</p>



<p>Some industry insiders later commented that IBM consciously priced CP/M six times higher than PC-DOS. It never had the intention to honor the agreement with DRI in spirit.</p>



<p>Microsoft now had the game rigged in its favor and it went on to conquer the world. DRI suffered a major blow and started to slip off the industry’s radar and with it did Gary Kildall.</p>



<h2>The end of the road</h2>



<p>Gary’s life wasn’t the same post-IBM-contract. </p>



<p>In 1991, he sold DRI to Novell as a last ditch effort to put up a fight against Microsoft. Sadly, that failed, too. These failures took a heavy tolly on him. </p>



<p>Everywhere he went, people would bring up IBM, Microsoft and if he was really flying out on that day. </p>



<p>As a consequence, he descended into alcholism and severed his professional connections. In 1991, he stopped appearing in ‘<a href="https://www.youtube.com/watch?v=w9EHc80HY4U" target="_blank" rel="noreferrer noopener" aria-label="The Computer Chronicles (opens in a new tab)">The Computer Chronicles</a>‘, a famous tech show on TV which he co-hosted since 1985. </p>



<p>Then came the worst. In 1994, Gary got into a brawl at a Biker’s bar and later passed away due to head injuries. It was a tragic end to a life full of passion. </p>



<p>Jacqui Morby of TA Associates – a PE firm which invested in DRI – recounts an interesting incident <a rel="noreferrer noopener" aria-label="in an interview to Stewart Cheifet (opens in a new tab)" href="https://www.youtube.com/watch?v=bLVbSjDq0DE" target="_blank">in a video interview to Stewart Cheifet</a>, Gary’s co-host at ‘The Computer Chronicles’. </p>



<p>Gary Kildall and Bill Gates were both on a panel during a tech event. Gary made a point that this (operating systems) is a very large market and there is room for lots of companies. </p>



<div><figure><img data-attachment-id="10773" data-permalink="https://bookjelly.com/the-tragic-story-of-gary-kildall/mannantech-7-2/" data-orig-file="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?fit=305%2C363&amp;ssl=1" data-orig-size="305,363" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;Jimmy&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1531306887&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mannantech-7" data-image-description="" data-medium-file="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?fit=252%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?fit=305%2C363&amp;ssl=1" loading="lazy" src="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?resize=342%2C407&amp;ssl=1" alt="Gary Kildall and Bill Gates at an event" width="342" height="407" srcset="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?w=305&amp;ssl=1 305w, https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?resize=252%2C300&amp;ssl=1 252w" sizes="(max-width: 342px) 100vw, 342px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?w=305&amp;ssl=1 305w, https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?resize=252%2C300&amp;ssl=1 252w" data-lazy-src="https://i2.wp.com/bookjelly.com/wp-content/uploads/2019/08/mannantech-7.jpg?resize=342%2C407&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>Bill Gates interjected, <strong>“<em>No! There will always be one company.</em>“</strong></p>



<h2>Lost in the footnotes of history?</h2>



<p>It’s an acknowledged fact that history remembers winners. The losers often get relegated to the footnotes of the past and sometimes, they just vanish altogether. </p>



<p>All we can do is imagine what might have been but let’s make sure that Gary Kildall’s story is not forgotten.</p>



<p>Do you think it was Gary Kildall’s operating system that underpinned Bill Gates’s empire? Was Gates right to grab the opportunity that presented itself the second time with both hands? Let me know your thoughts in the comments box below. </p>



<hr>



<div><figure><img data-attachment-id="10808" data-permalink="https://bookjelly.com/the-tragic-story-of-gary-kildall/gary-kildall-3/" data-orig-file="https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?fit=600%2C900&amp;ssl=1" data-orig-size="600,900" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Gary-Kildall-3" data-image-description="" data-medium-file="https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?fit=200%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?fit=600%2C900&amp;ssl=1" loading="lazy" width="600" height="900" src="https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?resize=600%2C900&amp;ssl=1" alt="The Tragic Story of Gary Kildall" srcset="https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?w=600&amp;ssl=1 600w, https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?resize=200%2C300&amp;ssl=1 200w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?w=600&amp;ssl=1 600w, https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?resize=200%2C300&amp;ssl=1 200w" data-lazy-src="https://i1.wp.com/bookjelly.com/wp-content/uploads/2019/08/Gary-Kildall-3.jpg?resize=600%2C900&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<hr>



<p><strong>©BookJelly. All rights reserved</strong></p>


<!-- AI CONTENT END 1 -->
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->

<!-- #comments -->

	</div></div>]]>
            </description>
            <link>https://bookjelly.com/the-tragic-story-of-gary-kildall/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24980239</guid>
            <pubDate>Tue, 03 Nov 2020 15:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supabase-JS 1.0 Launched]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24979894">thread link</a>) | @inian
<br/>
November 3, 2020 | https://supabase.io/blog/2020/10/30/improved-dx/ | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/10/30/improved-dx/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p><time datetime="2020-10-30T00:00:00.000Z">October 30, 2020  · 3 min read</time></p><div><p><a href="https://github.com/kiwicopple" target="_blank" rel="noreferrer noopener"><img src="https://avatars2.githubusercontent.com/u/10214025?s=400&amp;u=c6775be2ae667e2acae3ccd347fed62bb3f5b3e7&amp;v=4" alt="Paul Copplestone"></a></p></div></header><section><p>Today we're releasing <a href="https://github.com/supabase/supabase-js" target="_blank" rel="noopener noreferrer">supabase-js</a> version 1.0, and it comes with some major Developer Experience improvements.</p><h3>New Docs</h3><p>Before digging into the improvements, we're excited to point out our new <a href="https://supabase.io/docs/client/supabase-client">developer docs</a>. While they're still a work in progress, here are some things we think you'll like:</p><ul><li>The <a href="https://supabase.io/docs/client/supabase-client">Reference Docs</a> are auto-generated from our Typescript definitions and then enriched with examples. This forces us to document our code and makes it easier to keep everything in sync.</li><li>We added placeholders for the other languages that the community is developing. They have already started with Python, C#, Dart, Rust, and Swift. Expect to see the docs filling up soon!</li><li>We've added sections for all of the open source tools we use, including <a href="https://supabase.io/docs/postgres/server/about">Postgres</a>, <a href="https://supabase.io/docs/postgrest/server/about">PostgREST</a>, <a href="https://supabase.io/docs/gotrue/server/about">GoTrue</a>, and <a href="https://supabase.io/docs/realtime/server/about">Realtime</a>. We'll be filling these with lots of valuable information including self-hosting, benchmarks, and simple guides.</li></ul><h3>Errors are returned, not thrown</h3><p>We attribute this improvement to community feedback. This has significantly improved the developer experience. Previously we would throw errors:</p><div><div><div><div><p><span>try</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> body </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>catch</span><span> </span><span>(</span><span>error</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>error</span><span>)</span><span></span></p><p><span></span><span>}</span></p></div></div></div></div><p>And now we simply return them:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> data</span><span>,</span><span> error </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span><span></span></p><p><span></span><span>if</span><span> </span><span>(</span><span>error</span><span>)</span><span> </span><span>console</span><span>.</span><span>log</span><span>(</span><span>error</span><span>)</span><span></span></p></div></div></div></div><p>After testing this for a while we're very happy with this pattern. Errors are handled next to the offending function. Of course you can always rethrow the error if that's your preference.</p><h3>We created <code>gotrue-js</code></h3><p>Our goal for <code>supabase-js</code> is to tie together many sub-libaries. Each sub-library is a standalone implementation for a single external system. This is one of the ways we support existing open source tools.</p><p>To maintain this philosophy, we created <a href="https://github.com/supabase/gotrue-js" target="_blank" rel="noopener noreferrer"><code>gotrue-js</code></a>, a library for Netlify's GoTrue auth server. This libary includes a number of new additions, including third-party logins.</p><p>Previously:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span></span></p><p><span>  body</span><span>:</span><span> </span><span>{</span><span> user </span><span>}</span><span>,</span><span></span></p><p><span></span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> supabase</span><span>.</span><span>auth</span><span>.</span><span>signup</span><span>(</span><span></span></p><p><span>  </span><span>'someone@email.com'</span><span>,</span><span></span></p><p><span>  </span><span>'password'</span><span></span></p><p><span></span><span>)</span></p></div></div></div></div><p>Now:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> user</span><span>,</span><span> error </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> supabase</span><span>.</span><span>auth</span><span>.</span><span>signUp</span><span>(</span><span>{</span><span></span></p><p><span>  email</span><span>:</span><span> </span><span>'someone@email.com'</span><span>,</span><span></span></p><p><span>  password</span><span>:</span><span> </span><span>'password'</span><span></span></p><p><span></span><span>}</span><span>)</span></p></div></div></div></div><h3>Enhancements and fixes</h3><ul><li>Native Typescript. All of our libraries are now natively built with Typescript: <a href="https://github.com/supabase/supabase-js" target="_blank" rel="noopener noreferrer"><code>supabase-js</code></a>, <a href="https://github.com/supabase/postgrest-js" target="_blank" rel="noopener noreferrer"><code>postgrest-js</code></a>, <a href="https://github.com/supabase/gotrue-js" target="_blank" rel="noopener noreferrer"><code>gotrue-js</code></a>, and <a href="https://github.com/supabase/realtime-js" target="_blank" rel="noopener noreferrer"><code>realtime-js</code></a>.</li><li>Better realtime scalability: we only generate one socket connection per Supabase client. Previously we would create a connection for every subscription.</li><li>We've added support for OAuth providers.</li><li>60% of minor bugs outstanding for <code>supabase-js</code> have been <a href="https://github.com/supabase/supabase-js/pull/50" target="_blank" rel="noopener noreferrer">solved</a>.</li><li>You can use <code>select()</code> instead of <code>select(*)</code></li></ul><h3>Breaking changes</h3><p>We've bumped the major version because there are a number of breaking changes. We've detailed these in the <a href="https://github.com/supabase/supabase-js/releases/tag/v1.0.1" target="_blank" rel="noopener noreferrer">release notes</a>, but here are a few to be aware of:</p><ul><li><code>signup()</code> is now <code>signUp()</code> and <code>email</code> / <code>password</code> is passed as an object</li><li><code>logout()</code> is now <code>signOut()</code></li><li><code>login()</code> is now <code>signIn()</code></li><li><code>ova()</code> and <code>ovr()</code> are now just <code>ov()</code></li><li><code>body</code> is now <code>data</code></li></ul><p>Previously:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> body </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>'*'</span><span>)</span></p></div></div></div></div><p>Now:</p><div><div><div><div><p><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> supabase</span><span>.</span><span>from</span><span>(</span><span>'todos'</span><span>)</span><span>.</span><span>select</span><span>(</span><span>)</span></p></div></div></div></div><h3>Upgrading</h3><p>We have documented all of the changes in the <a href="https://github.com/supabase/supabase-js/releases/tag/v1.0.1" target="_blank" rel="noopener noreferrer">release notes</a>. </p><p>To summarise the steps:</p><ol><li>Install the new version: <code>npm install @supabase/supabase-js@latest</code></li><li>Update all your <code>body</code> constants to <code>data</code></li><li>Update all your <code>supabase.auth</code> functions with the new <a href="https://supabase.io/docs/client/auth-signup">Auth interface</a></li></ol><h3>Get started</h3><ul><li>Start using Supabase today: <a href="https://app.supabase.io/" target="_blank" rel="noopener noreferrer">app.supabase.io</a></li><li>Make sure to <a href="https://github.com/supabase/supabase" target="_blank" rel="noopener noreferrer">star us on GitHub</a></li><li>Follow us <a href="https://twitter.com/supabase_io" target="_blank" rel="noopener noreferrer">on Twitter</a></li><li>Become a <a href="https://github.com/sponsors/supabase" target="_blank" rel="noopener noreferrer">sponsor</a></li></ul></section></article></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/10/30/improved-dx/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979894</guid>
            <pubDate>Tue, 03 Nov 2020 14:26:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Color-balancing vote margins and vote totals in the US election map]]>
            </title>
            <description>
<![CDATA[
Score 201 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24979807">thread link</a>) | @mygo
<br/>
November 3, 2020 | https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/ | <a href="https://web.archive.org/web/*/https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

			<!-- start: #header -->

<!-- end: #header -->




			


<!-- start: #single -->
<main id="single" role="main">

    
    <!-- start: .center -->
    <div>


            <!-- start: .content -->
            <div>

                <article>

                        <header>
                            
                                <p><img src="https://stemlounge.com/content/images/size/w1500/2019/10/muddy_america_2016_weru_animated-1.gif">
                                    
                                </p>

                            <!-- start: .meta -->
                            
                            <!-- end: .meta -->

                            

                        </header>

                    <section>


                        <div><p>Graphs can inform, and informed discussions can be more civil than uninformed ones. But graphs can also mislead, so we need to understand what a graph is saying when we're using it. In 2015 I gave gave a TEDx talk on making clearer election maps. The original recording was lost, then recovered and <a href="https://www.youtube.com/watch?v=U5qn33KR7us">uploaded to Youtube</a> this summer. As election season ramps up, I'd like to continue the discussion by talking about this often-misleading map.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/countywinner_2016.png"><figcaption>2016 County-Level Winner-Takes-All map</figcaption></figure><!--kg-card-end: image--><p>Different graphs are designed for different purposes. The graph above is a county-level winner-takes-all map. I'll call it a County Winner map for short. Scientists use it to quickly see which way the counties went in an election. While there is arguably no better map for seeing who won in which county, this map can be misleading when used for other purposes. We need to be aware of two of its characteristics:</p><ol><li>It doesn’t express the <strong>relative voting populations</strong> between each county. Instead, it can make people feel like each county has the same population.</li><li>It’s not designed to express the <strong>margin of victory</strong> within each county. It shows who won in a county, even if they won by just one vote. It’s a winner-takes-all graph, after all.</li></ol><h3 id="relative-voting-population">Relative Voting Population</h3><p>Half of the US population lives in these counties:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/image-1.jpg"><figcaption>Half lives in blue. Half lives in gray. Census/Business Insider</figcaption></figure><!--kg-card-end: image--><p>America can be described as a collection of densely populated metros buffered by less densely populated communities. Here’s what the “population mountains” look like:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/where_we_live_pop_lg.jpg"><figcaption>This map of U.S. population density appeared in Time magazine Oct. 30, 2006 issue.</figcaption></figure><!--kg-card-end: image--><p>When we take the County Winner map and resize each county’s land-area to be proportionate to its population, here’s how the US looks.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/image-4.jpg"><figcaption>Mark Newman, University of Michigan</figcaption></figure><!--kg-card-end: image--><p>One downside to the cartogram, however, is that the shape and location of many territories are distorted beyond recognition. This is maybe one reason why the cartogram isn't very mainstream.</p><p>The County Winner map, however, doesn’t convey this relative population information. It's not designed to. But one might think it does. </p><h3 id="margin-of-victory">Margin of Victory</h3><p>In the general election, there are 50 concurrent presidential races, one for each state. In some of these states, the margin of victory turns out to be very small. In New Hampshire, <code>743,117 votes</code> were cast for the president in the 2016 general election. Hillary Clinton won New Hampshire by <code>2,701 votes</code>. We can seat as many people in a set of high school football bleachers.<br></p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/IMG_2944.jpeg"><figcaption>How New Hampshire was won.</figcaption></figure><!--kg-card-end: image--><p>There was a <code>75.03% turnout</code> in New Hampshire, so more people could have voted that didn’t. If just 2,702 more eligible voters in New Hampshire exercised their right to vote and voted for Trump, then New Hampshire would have gone to Trump instead. With such hair thin margins, New Hampshire is neither Blue nor Red in 2016. It’s <code>50:50</code> and leaning red or blue depending on traffic and dinner plans. It would be misleading to have all of New Hampshire colored as either blue or red to represent the statewide popularity of a presidential candidate. </p><p>This characteristic also holds true at the county level. The losing candidate in a county can receive a significant number of votes. In many counties the winner won by less than a 25% margin.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/2016_margin_histogram_rb.jpg"><figcaption>Kenneth Tay, Stanford University. Modified to add color to the scale and to highlight 25% range.</figcaption></figure><!--kg-card-end: image--><h6 id="a-margin-of-0-is-50-50-clinton-s-county-level-percent-win-margins-are-on-the-left-trump-s-county-level-percent-win-margins-are-on-the-right-the-yellow-area-highlights-counties-won-with-vote-margins-within-25-note-that-these-are-percent-vote-margins-not-absolute-vote-margins">A margin of 0 is 50:50. Clinton's county-level percent-win margins are on the left. Trump's county-level percent-win margins are on the right. The yellow area highlights counties won with vote margins within 25%. Note that these are percent vote margins, not absolute vote margins</h6><p>In general, smaller counties were won by larger percent margins. Larger counties were won by smaller percent margins. So in the counties with the most votes cast, the runner up got a lot of votes, too. </p><p>Here’s what the County Winner map looks like when we account for vote margins by blending each red and blue vote together within each county. Purple represents 50:50:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/purple-map-2016.png"><figcaption>2016 Purple Map</figcaption></figure><!--kg-card-end: image--><p>The neutralizing map is designed to express vote margins more clearly. It uses a grey intermediary, adjusting for <a href="https://www.fastcompany.com/3035951/the-glaring-design-flaw-in-us-election-maps">the way humans perceive purple</a>. Here’s the 2016 neutralizing map:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/2016_neutralizing_map.png"><figcaption>2016 Neutralizing Map</figcaption></figure><!--kg-card-end: image--><p>Rarely are all of the votes in a county cast for one candidate. The County Winner map, however, doesn’t convey this win margin information.</p><p>The contiguous United States aren't very contiguous. The County Winner map's inability to express vote population and margin of victory can be misleading. Cartograms account for population, but they distort the shape of the US, which can add confusion. The neutralizing map accounts for vote margin, but it doesn't account for population.</p><p><strong>Can we construct a single map that shows both vote margin and vote population without distorting the shape of the US?</strong></p><p>Here's one way:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_america_2016_weru_animated.gif"><figcaption>Animated GIF that goes from the County Winner map to old muddy.</figcaption></figure><!--kg-card-end: image--><p>Here's a less-distracting, static version of the graph:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_america_2016_static-1.png"></figure><!--kg-card-end: image--><p>The map leverages Color Theory to express <code>vote margins</code> and <code>vote populations</code> in a 2-dimensional scale. </p><p>Here's the key blown up:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_key_labeled_compressed.png"></figure><!--kg-card-end: image--><p>Horizontal scale represents vote margins. Vertical scale represents vote totals.</p><h4 id="lightness-vertical-scale-">Lightness (Vertical Scale)</h4><p>The lighter counties had fewer votes. The darker counties had more votes. </p><h4 id="hue-saturation-horizontal-scale-">Hue + Saturation (Horizontal Scale)</h4><p>The closer a county gets to gray, the closer the votes were 50:50. </p><p>A highly saturated red county was won by Trump with high percent vote margins. A highly saturated blue county was won by Hillary with high percent vote margins.</p><h2 id="the-mathematics-of-the-muddy-map">The mathematics of the muddy map</h2><h4 id="hsl">HSL</h4><p>All colors can be described as a combination of <code><u>H</u>ue(°)</code>, <code><u>S</u>aturation(%)</code>, and <code><u>L</u>ightness(%)</code>. </p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/640px-HSL_color_solid_cylinder_saturation_gray.png"><figcaption>The HSL color model.</figcaption></figure><!--kg-card-end: image--><p>We can leverage these individual components of the <code>HSL color model</code> to faithfully express 2-dimensional data such as vote totals vs margin on a 2d color scale.</p><h4 id="county-fill-colors">County Fill Colors</h4><p>The fill-color of each county is constructed using the MuddyColor algorithm, which is expressed as the following mathematical formula:</p><!--kg-card-begin: html--><!--
MuddyColor =

HSL \left (  

Hue \left (winner(D,R ) \right ), 

\frac{ \left |D-R \right | }{totalVote}, 

 \frac{ \left (1-\frac{totalVote}{upperFence}   \right )*100}{2} + 50

\right )
--><!--kg-card-end: html--><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddyColor_Formula-1.gif"><figcaption>Formula for county fill color</figcaption></figure><!--kg-card-end: image--><p>This produces the following two dimensional scale, which also doubles as a map key, with the upper fence labeled for the 2016 data set:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_key_labeled_compressed.png"><figcaption>Color scale produced by MuddyColor, used for county fill colors.</figcaption></figure><!--kg-card-end: image--><h4 id="county-border-colors">County Border Colors</h4><p>For the borders of each county, I use the same formula, but just give them a constant lightness (L) of 50%. </p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddyBorderColor_Formula.gif"><figcaption>Formula for county border color</figcaption></figure><!--kg-card-end: image--><p>This results in a 1-dimensional scale which we use for the county borders. It's the same color-scale scale used in the Neutralizing Map, which is designed to more-accurately express vote margins. &nbsp;<code>Left = higher DEM %margin</code>. <code>Right = higher GOP %margin</code>.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/neutralized_scale.png"><figcaption>Color scale produced by MuddyBorderColor, used for county border colors.</figcaption></figure><!--kg-card-end: image--><p>Giving each county an opaque border color allows even the lightest-filled counties to be recognized, including their vote margins.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_zoom.png"><figcaption>With opaque county borders, you can see the counties with even the lowest vote totals.</figcaption></figure><!--kg-card-end: image--><p>You don't need to look at the whole nation to see where one county's vote total lies on the overall lightness scale. The &nbsp;<code>county border color</code> and the &nbsp;<code>county fill color</code> differ only by lightness, so the greater the <code>contrast</code> between a county's border color and its fill color, the lower its vote total.</p><h4 id="upper-fence">Upper Fence</h4><p>A few counties have enough votes to skew the vote totals scale. Here's how the graph looks when the <code>vote totals</code> scale maxes out at <code>2,514,055</code>, the maximum number of votes in a county:</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/muddy_no_upper_limit-1.jpg"><figcaption>A few counties have enough votes to skew the whole vote scale.</figcaption></figure><!--kg-card-end: image--><p>One may suggest using a logarithmic scale to bring the sky-high outliers down to Earth. However, this would be visually misleading. A logarithmic scale flattens the min:max vote totals proportion from <code>1:39,282</code> closer to<code>1:3.5</code>, visually equating population mountains with population plains.</p><!--kg-card-begin: image--><figure><img src="https://stemlounge.com/content/images/2019/10/logarithmic_scale-16.png"><figcaption>In this log-scale graph of northwest Texas, can you distinguish a county with 1,000 votes from one with 50,000 votes?</figcaption></figure><!--kg-card-end: image--><p>We maintain a linear vote totals scale and use the statistical <code>upper fence</code> to account for outliers. The statistical upper fence can be calculated using the formula <code>Q3 + 1.5 * IQR</code>. Since the county vote margins are only concerned with %DEM|%GOP, county vote totals are DEM+GOP. For vote totals, we calculate the statistical upper fence to be <code>59,828 DEM+GOP votes</code>. We need to keep in mind that <code>432 counties</code> have vote totals ≥ <code>59,828 DEM+GOP</code> and are fully opaque in the Muddy Map. </p><h2 id="practical-uses-of-the-muddy-map">Practical uses of the Muddy Map</h2><p>The formulas give the Muddy Map graph some interesting characteristics. For each county, both the percent vote margin, as well as the vote totals (≤ the statistical upper fence), are embedded in the colors of the graph.</p><p>The Practical Characteristics of the Muddy Map Algorithm:</p><ul><li>There are only two hues, <code>red (hue#0 aka hue#360)</code> and <code>blue (hue#240)</code>. Red indicates GOP win, blue indicates DEM win.</li><li>A county with a <code><em>vote margin</em> of 100%</code> will have <code>100% saturation</code>. </li><li>A county with a <code><em>vote margin</em> of 0%</code> will have <code>0% saturation</code>. Such a county will be a pure gray, since gray appears at 0% saturation. So the closer a county gets to 50:50, the more gray it appears. No county in the 2016 election had a vote margin of 0%.</li><li>A county with <code>0 <em>total votes</em></code> will have <code>100% lightness</code>. Pure white appears at 100% lightness, so the closer the vote totals get to 0, the more white the counties appear. &nbsp;No county in the 2016 election had 0 votes. </li><li>A county with <code>≥ 59,828 <em>total votes</em></code> (the statistical upper fence) has <code>50% lightness</code>. &nbsp;432 counties in the 2016 election have this property.</li></ul><p>If a computer can faithfully render all of the colors described by the formula, then you can use a color picker to get …</p></div></section></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/">https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/</a></em></p>]]>
            </description>
            <link>https://stemlounge.com/muddy-america-color-balancing-trumps-election-map-infographic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979807</guid>
            <pubDate>Tue, 03 Nov 2020 14:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark’s new backend will be in F#]]>
            </title>
            <description>
<![CDATA[
Score 343 | Comments 256 (<a href="https://news.ycombinator.com/item?id=24979578">thread link</a>) | @nikivi
<br/>
November 3, 2020 | https://blog.darklang.com/new-backend-fsharp/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/new-backend-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/El5FcMQWkAAnkTX.jpeg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/El5FcMQWkAAnkTX.jpeg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/El5FcMQWkAAnkTX.jpeg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/El5FcMQWkAAnkTX.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/El5FcMQWkAAnkTX.jpeg" alt="Dark's new backend will be in F#">
            </figure>

            <section>
                <div>
                    <p><em>Welcome HN! Dark is a programming language, structured editor, and infrastructure—all in one—whose goal is to make it 100x easier to build backend services. Check out the <a href="https://darklang.com/">website</a>, our <a href="https://blog.darklang.com/what-is-dark/">What is Dark</a> post, and <a href="https://blog.darklang.com/how-dark-deploys-code-in-50ms/">How Dark deploys in 50ms</a> for more. Thanks for checking us out!</em></p><hr><p><em>Part of a set with <a href="https://blog.darklang.com/leaving-ocaml/">Leaving OCaml</a> and <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Why Dark didn't choose Rust</a>.</em></p><p>Nothing in my life so far would have prepared me for the fact that I would be willfully choosing to move to .NET, but it's 2020, and nothing matters anymore.</p><p>I've been evaluating new languages for the Dark backend over the last 2 months or so. For a <a href="https://blog.darklang.com/leaving-ocaml/">bunch of reasons</a>, OCaml has been a little unsatisfactory.</p><p>Over the last few years we've always said "when we rewrite the backend", "at some point we'll rewrite and this will go away", etc. There's a lot of new code to be written on the backend, to meet our roadmap. Are we really going to write it once, and then rewrite it later? Or would it be faster to just port it now, and write the new code in the new stack?</p><p>Ultimately, I decided that if there was going to be a change, now was the time. And more importantly, if there wasn't going to be a change, now was an excellent time to fully commit to OCaml, and not be second guessing the choice.</p><p>Initially, I expected to go to Rust. <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">Rust has excellent tooling, great libraries, a delightful community, etc</a>. But after spending about a month on it, I can't say I like writing Rust. Especially, I don't like writing async code in Rust. I like a nice high level language, and that's kinda what you need when you have a project as big as Dark to build. And Rust is not that. I'll publish "Why Dark didn't choose Rust" next. Or I might call it "you'll never believe just how much a Garbage Collector does for you!", because that's the summary.</p><p>When I was working on <a href="https://github.com/darklang/fizzboom/">Async benchmarks</a> before, what I was really doing was evaluating "are any of these OCaml alternatives better? And if so are they also faster?". I evaluated and expected not to like F#. I actually quite like it. It's close enough to OCaml, has great library support, and tooling which so far has been a mix of great and terrible. The 90's Microsoft tooling is still there, and that bit isn't all that great, but overall it's a much better situation than OCaml or Rust.</p><h2 id="why-did-i-chose-f-">Why did I chose F#?</h2><p>Let's start with the obvious, F# is OCaml. It's OCaml backed by the world's largest and most experienced creators of programming languages. And in the areas that OCaml is great, F# is also great! Sum types, static typing, eager execution, pipelines, immutable values, all of this is really great.</p><p>It actually has a much better type system, in my opinion. One thing that sticks out is that OCaml made it really cumbersome to use maps. Like, hashtables, associative arrays, whatever you call them. It seems the old version of Real World OCaml has been taken down, so I can't show you how unpleasant they were at the start. Now, in the latest version, they are <a href="https://dev.realworldocaml.org/maps-and-hashtables.html">more moderately unpleasant</a> to use. Whereas in F#, you have a <code>Map&lt;OneType,AnotherType&gt;</code> and that's really it. Magic!</p><p>Of course, the main reason I chose .NET was the libraries. It has libraries for everything, what a surprise. While there aren't all that many F# first-party libraries, every vendor out there has a .NET SDK that you can use directly from F#. I look forward to finally having first-party support for <a href="https://honeycomb.io/">Honeycomb</a>, <a href="https://rollbar.io/">Rollbar</a>, and Google Cloud. I'm even finally going to get to use <a href="https://launchdarkly.com/">LaunchDarkly</a>, after <a href="https://www.heavybit.com/library/podcasts/to-be-continuous/">years of telling Edith</a> I would.</p><p>The other thing I've really enjoyed is how good the docs and community content are. A lot of OCaml community content is on the language and what you can do with it. F# developers seem to just want to get shit done. There's a million blog posts, youtube videos, etc, from enterprise software developers talking about the best way to build web software. And then of course the massively detailed and useful <a href="https://fsharpforfunandprofit.com/">FSharpForFunAndProfit</a>, as well as <a href="http://tomasp.net/">Tomas Petricek</a>'s work - it's really great.</p><p>I think most of this is due to the size of the community. I've heard people say that there are very few F# developers; something like there's 1M C# users, 100k VB users, and 10K F# users, or something like that. I'm not sure exactly what counts as user, but I would imagine that OCaml has fewer than 100 "users" in this metric, so it feels like I'm moving to a massive community.</p><p>Not everything is amazing though. The build system is attrocious. While <code>paket</code> is roughly on par with <code>esy</code>, msbuild is 1000 times worse than <code>dune</code>. An incremental build in dune is like 1s for me, and 6s in .NET, even if nothing is happening. I know they have fancy incremental compilers for .NET so this puzzles me; if anyone has tips on getting really fast compilation in F#, <a href="mailto:paul@darklang.com">I would appreciate them</a>.</p><p>An important thing to check was whether I could compile my code to JS. Dark's execution engine runs it the editor as well, and that's one of the core things that makes Dark special. Because of this, I want to take unaltered backend code and compile it directly to JS. This isn't like <a href="https://rescript-lang.org/">Rescript</a> (which is OCaml compiled to JS with slightly different semantics and ecosystem, or it's equivalent in F#, <a href="https://fable.io/">Fable</a>). Fortunately, F# code can be compiled to Wasm using <a href="https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor">Blazor</a>. Blazor compiles the .NET runtime to WASM and runs your code in that. It <a href="https://github.com/darklang/dark/tree/main/fsharp-backend/src/Wasm">barely took any code</a> to get working either (though figuring out the right incantation was not trivial).</p><h2 id="feedback-from-leaving-ocaml-blog-post">Feedback from "Leaving OCaml" blog post</h2><p><a href="https://blog.darklang.com/leaving-ocaml/">Yesterday's post</a> got a lot of people to add their opinions. In addition to some <a href="https://news.ycombinator.com/item?id=24976630">Scala</a> and <a href="https://twitter.com/fakenickels/status/1323304778089304070">Erlang</a> love, a lot of people pointed to F#:</p><blockquote>So...I think a decent choice to make here is to switch from OCaml to F#. You'll get almost all of the benefits and most of the drawbacks go away. And for the most part, you can directly translate the code from OCaml to F#. - <a href="https://news.ycombinator.com/item?id=24978526">darksaints</a></blockquote><blockquote>I've been using F# on GCP in production for 3 years now and it's fantastic and only getting better. You can leverage existing .NET libraries (for example, you get official GCP libraries from google) and if you use them enough it's easy enough to write a functional wrapper around them. - <a href="https://news.ycombinator.com/item?id=24978526">angio</a></blockquote><blockquote>We have considered OCaml but went for F# instead. I could not be happier. Great libraries, good tooling, in 2020 F# is a first class citizen in the cloud thanks to C# and .NET Core. You can develop on Linux, Windows, MacOS and without modification it works. Compilation times are great. Unless you want to deal with the low level nature and the C++ influence in Rust F# is a much more logical step to move from OCaml. There is dotnet fsi for REPL too. F# has access to C# libraries and it is relatively easy to write a thin wrapper that convert nulls to Nones, so you are null safe or C# style functions to ML style functions so you can use |&gt; or &lt;| etc. - <a href="https://lobste.rs/s/bcwbuw/leaving_ocaml#c_uoy61u">l1x</a></blockquote><h2 id="next-steps">Next steps</h2><p>I recently merged the <a href="https://github.com/darklang/dark/tree/main/fsharp-backend">first F# code into the codebase</a>. It's an async version of the core of the Dark interpreter, connected to Giraffe (F#'s low-level interface to .NET's Kestrel web server).</p><p>My plan is to reimplement the same language, but with some of the learnings that are in the <a href="https://roadmap.darklang.com/">roadmap</a>. For example:</p><ul><li><code>Result</code> and <code>Options</code> will be types, not special cased into the language</li><li><code>Int</code> will be infinite precision (this is technically a breaking change, but not a significant one AFAICT)</li><li>breaking out the API server, using F# builtin middleware libraries</li><li>refactoring the Dark public HTTP server into composable middleware, available from within Dark</li></ul><p>I'll be working on making the equivalent to the existing Dark interpreter, keeping the semantics the same. After that, I'll be making new features from the <a href="https://roadmap.darklang.com/">Dark Roadmap</a>.</p><h2 id="implementation-plan">Implementation plan</h2><p>Dark's backend is 37K lines of OCaml, of which 8K lines are tests, and 10K lines are the Dark standard library. So there's about 20K lines to port. Should be fun. My implementation plan is to get to parity - there's plenty of time after that to take advantage of the ecosytem:</p><ul><li>finish the interpreter</li><li>connect Dark's F# backend to Dark's DB, so it can read the same data</li><li><s>compile Dark's F# interpreter to JS</s> (done, see above)</li><li>make an OCaml library to deserialize the binary opcodes in the DB and covert them into F# (via, I presume, a JSON intermediary). This will allow incoming requests to (optionally) be routed to the F# service.</li><li>add a fuzzer to ensure the semantics of the OCaml and F# versions of Dark are the same (especially the library functions)</li><li>do all the devops (getting it into k8s, etc)</li><li>add the APIs we have available in OCaml</li><li>add a way for users to safely try their code in the new version</li><li>port over 170 or so functions we have in the standard library</li><li>start recording traces using <a href="https://blog.darklang.com/evolving-darks-tracing-system/">the new design</a> (this is actually the main thing driving the whole change, believe it or not!)</li><li>use <a href="https://www.honeycomb.io/">Honeycomb</a>, R<a href="http://rollbar.com/">ollbar</a>, and Google Cloud using their .NET native interfaces</li><li>port our <a href="https://github.com/darklang/dark/tree/main/services">various services</a> to F# (lower priority)</li><li>port our accounts to self-managed from Auth0</li><li>translate the <a href="https://docs.darklang.com/contributing/ocaml-for-dark-developers">contributor docs</a> to F#</li></ul><p>There's lots to do, and <a href="https://docs.darklang.com/contributing/getting-started">Dark contributors</a> are welcome to take part. Porting standard library functions might be an easy place to get started, as is adding language features. Most things are a straight port from OCaml, except as mentioned above. As always, feel free to ask in <a href="https://darklang.com/slack-invite">the Slack</a> or <a href="https://github.com/darklang/dark/issues">issues</a> if you've any questions.</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p><p><em>Thank you<a href="https://twitter.com/JaggerJo1/status/1323571699330260993"> JaggerJo</a> for the header image!</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/new-backend-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979578</guid>
            <pubDate>Tue, 03 Nov 2020 13:45:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Suzieq: Network Observability]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24979461">thread link</a>) | @gjvc
<br/>
November 3, 2020 | https://suzieq.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://suzieq.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
          <div role="main">
            <div>
              
                
<p><strong>Suzieq</strong> is both a framework and an application using that framework, that is focused on 
<strong>improving the observability of your network</strong>.  We define observaility as the ability of a system to 
answer either trivial or complex questions that you pose as you go about operating your network. How easily 
you can answer your questions is a measure of how good the system's observability is. A good observable 
system goes well beyond monitoring and alerting. Suzieq is primarily meant for use by network engineers and designers.</p>
<p>Suzieq does multiple things. It collects data from different devices and systems. It normalizes the data and 
then stores it in a vendor independent way. Then it allows analysis of that data. </p>
<p>We believe Suzieq is novel because it is a disaggregated framework that allows you to independently pick:</p>
<ul>
<li>how you gather your data (agentless or agent-based)</li>
<li>how you store your data</li>
<li>how you interact with the data i.e. how you ask the questions and how you see the answers.</li>
</ul>
<p>With the applications that we build on top of the framework we want to demonstrate a different and more 
systematic approach to thinking about networks. We want to show how useful it is to think of your network holistically.</p>
<p>In this very early release of Suzieq, we've chosen some answers for the framework to get the ball rolling. </p>
<ul>
<li>We gather data using an agentless model using either SSH or REST API as the transport. </li>
<li>We normalize the data into a vendor-agnostic format.</li>
<li>We store all data in files using the popular big data format, Parquet. </li>
<li>All the analysis are exposed either via a CLI or via Python objects. The output can be rendered in various formats from plain text to JSON and CSV.</li>
<li>The analysis engine used in this release is pandas.</li>
</ul>
<p><strong>We support gathering data from Cumulus, Arista, JunOS and NXOS routers, and Linux servers.</strong> We gather:</p>
<ul>
<li>Basic device info</li>
<li>Interfaces</li>
<li>LLDP</li>
<li>MAC address table</li>
<li>MLAG (only for Cumulus and EOS at this time)</li>
<li>Routing table</li>
<li>ARP/ND table</li>
<li>OSPFv2</li>
<li>BGP (v4 unicast, v6 unicast and evpn AFI/SAFI)</li>
<li>EVPN VNI info (not for EOS at this time)</li>
</ul>
<p>We are just getting started with Suzieq. As befitting an early release, what you see is only a brief 
demonstration of what this approach can bring about. We've many, many ideas to implement in our upcoming 
releases, but we wanted to get this out so that people can start using it. And start understanding their 
networks to solve problems, validate or to make changes.</p>
<p>You can join the conversation via <a href="https://netenglabs.slack.com/">slack</a>. Send email to Dinesh or Justin with the email address to send the Slack invitation to. </p>
<p>We're also looking for collaborators to help us make Suzieq a truly useful multi-vendor, open source platform 
for observing all aspects of networking. Please read the <a href="https://suzieq.readthedocs.io/en/latest/CONTRIBUTING.md">collaboration document</a> for 
ideas on how you can help. </p>
              
            </div>
          </div>
          
      
        </div>
      </div></div>]]>
            </description>
            <link>https://suzieq.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979461</guid>
            <pubDate>Tue, 03 Nov 2020 13:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Months of NixOS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24979460">thread link</a>) | @figomore
<br/>
November 3, 2020 | https://catgirl.ai/log/nixos-experience/ | <a href="https://web.archive.org/web/*/https://catgirl.ai/log/nixos-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articlebody">
    <p>About 8 months ago, I decided that I'd gotten tired of macOS. It's a
Unix, which is nice, and I like that I can set up things with
relatively minimal effort through Homebrew, but I wanted something
that actually gave me more control over my system. So I decided that
2020 was going to be the Year Of Linux On Ash's Laptop.</p>
<p>In addition, I decided to try out <a href="https://nixos.org/">NixOS</a>, which
is an operating system oriented around the Nix package manager. The
big thing that distinguishes Nix from other operating systems is that
it lets you manage your packages <em>declaratively</em>: you specify what
you want the state of your system to be, then run <code>sudo nixos-rebuild switch</code>, and it reconfigures your system to be in that state. I also
decided I would use
<a href="https://github.com/nix-community/home-manager">home-manager</a>, which
lets you do the same thing for your dotfiles. As is tradition, I also
decided to <a href="https://git.catgirl.ai/ext0l/nixos-config">version my
dotfiles</a>, though they're
still kind of a mess.</p>
<h2 id="the-good">the good</h2>
<h3 id="hardware-support">hardware support</h3>
<p>I bought a used Thinkpad T450s off of eBay, because I wanted to make
sure I had good hardware support, and the Thinkpad line has
historically had a reputation for things working out of the box. And
everything has worked fine: Bluetooth, wireless, even the touch screen
(not that I use it). I didn't have to hunt down any weird driver
repositories or modprobe anything into my kernel.</p>
<p>The one thing I haven't tested is the fingerprint reader, because I
don't trust it to be secure, so I never set it up in the first place.</p>
<p>I did run into one issue: when I bought a replacement battery off
eBay, Linux was having trouble recognizing it and reading its
status. I had to do some kind of magic dance to reset something or
another: I think it was 'pull the battery and AC adapter, hold the
power button for 5 seconds, then plug it back in'. But once I did
that, everything was fine.</p>
<h3 id="declarative-package-management">declarative package management</h3>
<p>This was the reason I specifically wanted to use NixOS in the first
place. I liked the idea of having my system's configuration explicitly
written out, and not just determined by whatever series of packages I
happen to have apt-get installed. And NixOS delivers; my <a href="https://git.catgirl.ai/ext0l/nixos-config">nixos-config
repo</a> contains not only my
dotfiles, but a list of all the programs I have installed, my fonts,
and so on. I also don't have to worry about having accidentally
installed something weird and then forgotten about it; whatever's not
in my /etc/nixos might as well not exist (though it can still leave
stuff in ~/.config and similar places).</p>
<p>I intend to eventually switch the server this blog is hosted on over
to NixOS for similar reasons, and I'm <em>definitely</em> looking forward to
being able to declaratively manage things like nginx configuration and
systemd scripts as opposed to scattering them all over my filesystem.</p>
<h3 id="customizability">customizability</h3>
<p>I've got everything set up the way I like it. I decided to finally
give tiling window managers a shot, and after using
<a href="https://awesomewm.org/">awesomewm</a>, I don't think I could go back to
having to arrange all of my windows by hand. Even on a laptop screen,
I like putting my messaging applications (Discord, Telegram, IRC)
side-by-side. And of course, having purpose-driven workspaces is
nice. Instead of hunting down my music player in a window switcher, I
just hit <code>Win-6</code>, since I always keep <code>cmus</code> on the 6th workspace.</p>
<p>I've also got bars set up to display things like my upcoming todo
count, my CPU usage, battery life, currently-playing music, and so
on. I could certainly have done this on MacOS using
<a href="https://tracesof.net/uebersicht/">Übersicht</a> or something similar,
but it feels intuitively 'cleaner' in some way to be doing this in an
operating system set up to have this kind of flexibility in the first
place.</p>
<h2 id="the-not-so-good">the not-so-good</h2>
<h3 id="the-nix-language">the nix language</h3>
<p>The Nix package manager uses its own language, which is also called
Nix, to define how packages work. The language is functional in the
style of something like Haskell or the ML family, but lacks a lot of
the niceties those languages have like a strong static type system or
a means for doing imperative stateful programming. I ran into this
when I was trying to generate a configuration file by iterating
through a list and having the callback update some amount of state;
Haskell has the state monad, but Nix has no such thing.</p>
<p>This is especially salient because Nix does <em>not</em> follow the standard
Linux filesystem hierarchy; it stores almost all of its libraries and
binaries under <code>/nix/store</code>. This means that you can have multiple
copies of something installed without them interfering with each
other, but it also means that you <em>need</em> to know how Nix packaging
works to compile anything. Even libc isn't in its usual place, so
downloading prebuilt binaries usually won't work.</p>
<p>Fortunately, packaging simple software generally just involves telling
it how to fetch it and what its build dependencies are, but figuring
out how exactly to do that and how to integrate it into the rest of
your configuration requires reading documentation. Which brings me to
the next point:</p>
<h3 id="extremely-sparse-documentation">extremely sparse documentation</h3>
<p>Even though the Nix language itself is fairly simple to understand,
the way in which Nix puts everything together can be... obtuse. For
example, each package in the nixpkgs monorepo is implemented as <a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/applications/misc/hello/default.nix">a
function</a>
(here, the <code>{stdenv, fetchurl}:</code> syntax at the top means that the file
declares a function that takes a record with two fields named <code>stdenv</code>
and <code>fetchurl</code>. However, when defining my own derivations to include
in my personal configuration for programs not packaged by Nix, instead
of defining a function, I just wrote out the derivation by hand. The
difference to me wasn't obvious, until I did some deep digging and
learned that behind the scenes, the nixpkgs repo invokes
<a href="https://nixos.org/guides/nix-pills/callpackage-design-pattern.html"><code>callPackage</code></a>,
which invokes the function with the relevant arguments.</p>
<p>Even just writing those packages involved searching the nixpkgs repo
for similar programs and then copy-pasting what they did. The
<a href="https://nixos.wiki/wiki/Packaging/Tutorial">official NixOS wiki</a> has
basically similar recommendations, and I found the NixOS manual to not
be super helpful here. I wound up making heavy use of the <a href="https://nixos.org/guides/nix-pills/">Nix
Pills</a>, which are a series of
posts that show you not only how Nix package management is
implemented, but <em>why</em> it works the way it does.</p>
<p>Similarly: some commands are invoked like <code>nix run</code>, some are
<code>nix-shell</code>. I don't know why. </p>
<h2 id="would-i-recommend-nix">would i recommend nix?</h2>
<p>Only to power users. If you're going to use it, you're going to have
to deal with the packaging stuff at some point, either to debug a
package or to use software that doesn't have one. And this means
you'll need to learn the Nix language, and wade through the nixpkgs
monorepo and some fairly iffy documentation. But if you can put up
with that, the 'everything is declarative' setup is <em>exactly</em> as nice
as I hoped it'd be, and I've had multiple instances where an update
broke something so I was able to just boot to an older
generation. Similarly, when the BleedingTooth vulnerability came out,
I was able to disable my Bluetooth stack with a one-liner in
<code>/etc/nixos/configuration.nix</code> to just blacklist the entire hardware
support and then when the kernel updates came out I was able to just
remove that single line as opposed to trying to remember where the
fuck I'd stored that definition.</p>

<ul>
<li><strong>Better documentation.</strong> Stuff that covers "I have a piece of
software that's not packaged, how do I package it locally". Or "the
software in nixpkgs is broken in some way, I'd like to test out some
changes to the package definition, how do I set up the overrides for
that". That sort of thing. A lot of this is covered on the wiki, so
the usual
<a href="https://en.wikipedia.org/wiki/Wikipedia:Be_bold">WP:SOFIXIT</a>
applies, but this is the sort of thing that I think should have
already been written.</li>
<li><strong>Faster switches for trivial changes.</strong> The big reason I don't
manage my .emacs.d via nix is that it means that even a trivial
change requires me to do the whole <code>sudo nixos-rebuild switch</code>
dance, which can take 20-30 seconds just to make a one-line
change. This kills my iteration velocity. There are workarounds like
having a 'staging' file that gets sourced and then every so often
moving code from the staging file into the main file, but that seems
like a workaround for a problem that shouldn't exist.</li>
<li><strong>Some kind of lockfile to store package versions.</strong> One of the bits
of state that <em>isn't</em> stored in <code>/etc/nixos</code> is what version of the
nixpkgs and home-manager repos I'm currently on. This means that if
I run a <code>switch --upgrade</code>, there's no way to go back without
rolling back those channels via <code>nix-env</code>. On the other hand, if
those versions were stored alongside my nix files, then I could just
revert them in case of a bad upgrade. My understanding is that
<a href="https://nixos.wiki/wiki/Flakes">flakes</a> are an upcoming feature
that solves this problem, among others.</li>
</ul>
<h2 id="final-thoughts">final thoughts</h2>
<p>Overall, I've definitely enjoyed the switch to Linux, and I can't see
myself going back to macOS any time soon. I may wind up buying a more
powerful laptop at some point, since this one is having problems with
driving a 2560x1440 monitor due to a low fill rate on the graphics
card, but I want to reduce my electronics waste footprint (hence why I
bought this one used), so I'm going to stick with it for at least a
few more years.</p>
<p>I'm also <em>probably</em> going to stick with NixOS, but I hope it becomes
better documented and more newbie-friendly. Right now, I'd hesitate to
recommend it to anyone who wants something that just works and isn't
interested in diving into the guts of their system or learning a new
language just to install software.</p>

  </div></div>]]>
            </description>
            <link>https://catgirl.ai/log/nixos-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979460</guid>
            <pubDate>Tue, 03 Nov 2020 13:32:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[URLs in C (2011)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24979396">thread link</a>) | @susam
<br/>
November 3, 2020 | https://susam.in/blog/urls-in-c/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/urls-in-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 03 Jun 2011</p>
<p>
Here is an interesting C puzzle I created recently. It is a silly one
but you might find it amusing.
</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    https://susam.in/
    printf("hello, world\n");
    return 0;
}</code>
</pre>

<p>
This code compiles and runs successfully.
</p>

<pre><samp>$ <kbd>c99 hello.c &amp;&amp; ./a.out</kbd>
hello, world</samp>
</pre>

<p>
However, the <a href="http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1256.pdf">C99
standard</a> does not mention anywhere that a URL is a valid syntactic
element in C. How does this code work then?
</p>

<p>
<em><strong>Update on 04 Jun 2011:</strong> The puzzle has been solved
in the <a href="https://susam.in/blog/urls-in-c/comments/">comments</a> section. If you want to think
about the problem before you see the solutions, this is a good time to
pause and think about it. There are spoilers ahead.</em>
</p>

<p>
The code works fine because <code>https:</code> is a label and
<code>//</code> following it begins a comment. In case, you are
wondering if <code>//</code> is indeed a valid comment in C, yes, it is,
since C99. Download the <a href="http://www.open-std.org/JTC1/SC22/WG14/www/docs/n1256.pdf">C99
standard</a>, go to section 6.4.9 (Comments) and read the second
point which mentions this:
</p>

<blockquote>
Except within a character constant, a string literal, or a comment, the
characters <code>//</code> introduce a comment that includes all
multibyte characters up to, but not including, the next new-line
character. The contents of such a comment are examined only to identify
multibyte characters and to find the terminating new-line character.
</blockquote>

<div>
  <h2>More ...</h2>
  <p>
    If you liked this post, you might also like these:
  </p>
  <ul>
     <li><a href="https://susam.in/blog/sequence-points/">Sequence Points in C</a></li>
     <li><a href="https://susam.in/blog/stack-overwriting-function/">Stack Overwriting Function in C</a></li>
     <li><a href="https://susam.in/blog/writing-boot-sector-code/">Writing Boot Sector Code in ASM</a></li>
     <li><a href="https://github.com/susam/uncap">Map Caps Lock to Escape</a></li>
  </ul>
  <p>
    Also,
    <a href="https://twitter.com/intent/follow?screen_name=susam">follow me on Twitter</a>
    where I often post about Python, Lisp, Linux, Unix Shell, TeX, Vim,
    InfoSec, mathematics, etc.
  </p>
</div>


</div></div>]]>
            </description>
            <link>https://susam.in/blog/urls-in-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979396</guid>
            <pubDate>Tue, 03 Nov 2020 13:25:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Design Resources for Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24979222">thread link</a>) | @moeminm
<br/>
November 3, 2020 | https://blog.moeminmamdouh.com/20-free-design-resources-for-developers | <a href="https://web.archive.org/web/*/https://blog.moeminmamdouh.com/20-free-design-resources-for-developers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1604407002218/KHUKkE-Sx.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Design resources are all over the internet, this list intends to curate some of the best out there for you to find easily. I plan on releasing a monthly version of this blog article with 20+ resources in every issue.</p>

<ul>
<li><a target="_blank" href="https://colorhunt.co/?ref=blog.moeminmamdouh.com">Color Hunt</a>:  Free and open platform for color inspiration with thousands of trendy hand-picked color palettes</li>
</ul>
<ul>
<li><a target="_blank" href="https://coolors.co/?ref=blog.moeminmamdouh.com">Coolors</a>: Create the perfect palette or get inspired by thousands of beautiful color schemes.</li>
</ul>
<ul>
<li><a target="_blank" href="https://colorsinspo.com/?ref=blog.moeminmamdouh.com">Colorinspo</a>: Thousands of beautiful color palettes you can use it directly by one click.</li>
</ul>
<ul>
<li><a target="_blank" href="https://www.grabient.com/?ref=blog.moeminmamdouh.com">Grabient</a>: Beautiful and simple UI for generating web gradients.</li>
</ul>
<ul>
<li><p><a target="_blank" href="http://khroma.co/?ref=blog.moeminmamdouh.com">Khroma</a>: Khroma uses AI to learn which colors you like and creates limitless palettes for you to discover, search, and save.</p>
</li>
<li><p><a target="_blank" href="https://pigment.shapefactory.co/?ref=blog.moeminmamdouh.com">Pigment by ShapeFactory</a>: A unique way to generate fresh and vibrant colors based on lighting and pigment, instead of math. Find a beautiful, free color palette in seconds to kick off your next project.</p>
</li>
</ul>

<ul>
<li><p><a target="_blank" href="https://blush.design/?ref=blog.moeminmamdouh.com">Blush</a>: Easily create and customize stunning illustrations with collections made by artists across the globe.</p>
</li>
<li><p><a target="_blank" href="https://www.openpeeps.com/?ref=blog.moeminmamdouh.com">Open Peeps</a> : A hand-drawn illustration library.</p>
</li>
<li><p><a target="_blank" href="https://avataaars.com/?ref=blog.moeminmamdouh.com">Avataaars</a>: Create avatar illustrations in Sketch App with this free library. Combine clothes, hair, emotions, accesories, and colors. Video 📺</p>
</li>
<li><p><a target="_blank" href="https://www.opendoodles.com/?ref=blog.moeminmamdouh.com">Open Doodles</a>: A Free Set of Sketchy Illustrations.</p>
</li>
<li><p><a target="_blank" href="https://lukaszadam.com/illustrations/?ref=blog.moeminmamdouh.com">Lukaszadam</a>: MIT licensed SVG illustration images in different shapes &amp; styles. Completely free for commercial projects - no attribution required. Open Source Illustrations. </p>
</li>
<li><p><a target="_blank" href="https://www.pixeltrue.com/free-illustrations/?ref=blog.moeminmamdouh.com">Pixeltrue</a>: Free SVG Illustrations AND Lottie Animations are available for free for personal and commercial use (MIT License).</p>
</li>
<li><p><a target="_blank" href="https://www.uplabs.com/?ref=blog.moeminmamdouh.com">Uplabs</a>: UpLabs is the place to find high-quality design resources for designers, creative agencies and developers. </p>
</li>
</ul>

<ul>
<li><p><a target="_blank" href="https://growth.design/case-studies/?ref=blog.moeminmamdouh.com">Growth Design</a>: Growth &amp; UX case studies in a comic book format. Improve your product skills with real-world examples.</p>
</li>
<li><p><a target="_blank" href="https://www.designbetter.co/?ref=blog.moeminmamdouh.com">Design Better</a>: <a href="http://designbetter.co/" target="_blank">DesignBetter.Co</a> is the essential guide to the best design practices from top design experts. Learn how to build a world-class design organization and more.</p>
</li>
<li><p><a target="_blank" href="https://www.reallygoodux.io/?ref=blog.moeminmamdouh.com">ReallyGoodUX</a>: Screenshots and examples of great UX from real mobile and web products. Discover the best UX examples—including onboarding tours and walkthroughs, new feature and rebrand announcements, UX copywriting, signup flows and more. </p>
</li>
<li><p><a target="_blank" href="https://lawsofux.com/?ref=blog.moeminmamdouh.com">Laws of UX</a>: A collection of the maxims and principles that designers can consider when building user interfaces. </p>
</li>
</ul>

<ul>
<li><p><a target="_blank" href="https://mobbin.design/?ref=blog.moeminmamdouh.com">Mobbin</a>: A hand-picked collection of the latest mobile design patterns from apps that reflect the best in design. Get inspiration from over 250 iOS apps and 25,000 patterns (screenshots from iPhone 12) available on the platform. Sign up to save your favorite patterns.</p>
</li>
<li><p><a target="_blank" href="https://onepagelove.com/?ref=blog.moeminmamdouh.com">Onepagelove</a>: One Page website design gallery showcasing the best Single Page websites, templates and resources.</p>
</li>
<li><p><a target="_blank" href="https://www.landingfolio.com/?ref=blog.moeminmamdouh.com">Landingfolio</a> </p>
</li>
<li><p><a target="_blank" href="https://land-book.com/?ref=blog.moeminmamdouh.com">Landbook</a>: Design gallery with the best and most carefully collected websites. We help creatives find inspiration &amp; motivation to do rad stuff.</p>
</li>
</ul>
<p>That's it for this issue! Be sure to leave a comment if you feel like there's a resource that should be in any upcoming issue.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.moeminmamdouh.com/20-free-design-resources-for-developers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979222</guid>
            <pubDate>Tue, 03 Nov 2020 13:01:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Computer Unit” – A PDP-11/34 at my school (1979)]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24979179">thread link</a>) | @qmacro
<br/>
November 3, 2020 | https://qmacro.org/2020/11/03/computer-unit-1979/ | <a href="https://web.archive.org/web/*/https://qmacro.org/2020/11/03/computer-unit-1979/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>I’ve transcribed an article about the arrival of the “Computer Unit” - a PDP-11/34 - at my school in 1979. The unit became the early focus of a fascination with computing that’s never left me.</em></p>

<p>I went to school in the late 1970s and early 1980s - the dawn of computing for everyone. My very first experience of computing was at a terminal connected to a timesharing minicomputer, rather than at the keyboard of one of the personal computers of the day.</p>

<p>There was an article in the 1979 edition of my school’s magazine “The Hulmeian”, written by our head of Mathematics Morris Loveland. It brings back many happy memories, and provides some insight into computing in the early days.</p>

<p>Below the article, I’ve included some pictures accompanied by brief descriptions.</p>

<p><em>COMPUTER UNIT</em></p>

<p><em>In 1974 the School purchased a single computer terminal, a TEXAS 733, and established the G.P.O. dial-up link to Salford University. This project, initially between School and the University, made available on-line computer time to us and later to other educational establishments. It proved to be a most useful and successful facility and reports have been given in this magazine of some of the work undertaken in the five years in which the link was used. The School had between ten and fifteen hours of on-line time each week, mainly during lunch hours and after school. Some time was available during teaching time and a large number of boys had experience of using the BASIC language to a large remote processor.</em></p>

<p><em>Computing was mainly organised for small groups or for individual users, although a certain amount of class teaching was undertaken. The limitations of a single terminal caused delays and frustration. Boys were foreced to wait to use the system and it was found to be extremely difficult to teach a class of thirty boys where the visual display was a single sheet of typed material. Salford University extended the computer facility to several other schools resulting in a considerable reduction in the on-line time available to us.</em></p>

<p><em>Early in 1978 it was decided to investigate the possibility of installing a complete on-site computer system at School. The searches took nearly a year and in that time a system which would satisfy the requirements of the School was determined. The financial aspects were agreed in November 1978 and the system was delivered in January 1979.</em></p>

<p><em>The computer which has been installed is a SYSTIME 3000 comprising a PDP11/34 processor with 196Kb of working memory, two 4.8Mb disc drives for data storage, three visual display terminals (one of which is used for system control), a Superterm paper printer and the necessary hardware to include the original Texas terminal into the system. Thus four terminals instead of one are available for use with no restriction on the time when a boy may use the computer.</em></p>

<p><em>The language used is BASIC PLUS which is a variant of the BASIC language used during the past five years. Very few problems have been experienced with this minor change of language and it is a most suitable language for teaching purposes. BASIC PLUS is interactive, that is, one which enables a two way ‘conversation’ between user and machine. If an error is made by the user, either in typing or in the logic of what is communicated to the machine, he is informed of that error immediately and can make the required corrections.</em></p>

<p><em>The processor and system control is housed in the careers room and is linked by cables running across the quadrangle and over the roof of the Science block to room 34. This room has been redesigned and redecorated to be a terminal room, housing at present the four computer terminals.</em></p>

<p><em>The system is a fairly standard computer package apart from one important modification. The signal from one visual display unit is taken and fed to a television monitor. Normally a single terminal is used by an individual or at most by a small group working on a particular project. The intention of having the signal from one terminal displayed on a large television monitor was to enable full classes of thirty boys to see a particular piece of computing. However, one monitor proved insufficient and by including a signal converter and amplifier the signal from one terminal can now be displayed on three domestic television sets. When a full class is taken into the terminal room teaching can be given to all by linking all four terminals together and displaying the data on them and on the three television sets. As far as is known this particular part of the system is an innovation as regards the teaching of computing in schools, particularly as part of the electronics required to convert the signals to be compatible with domestic television sets was designed and built in School.</em></p>

<p><em>The system is thus being used in two different ways: for individual and small group activity or with the system linked together for class teaching. So far no examination teaching has been undertaken and at present none is envisaged. The intention is to use the computer in the classroom as a tool to teach a computer language, which will enable boys to undertake projects on their own, and as an aid to enrich and extend the normal teaching of Mathematics. Boys will find that they are taken to the terminal room perhaps for a complete period or for only ten minotes of a Mathematics period during which some particular part of the subject matter being developed will be illustrated using the computer.</em></p>

<p><em>The system has been planned with future expansion in mind. When the wiring was installed two extra cables were taken into room 34; and therefore two more terminals can be added to the system fairly easily as and when they are required. Further expansion is possible; up to twenty-four terminals can be serviced by the processor! To achieve this additional memory will have to be added to the processor.</em></p>

<p><em>Following the delivery of the system in January 1979 and after all testing had been carried out by the suppliers the computer was in limited use in early March. Since then the number of users has increased considerably. The computer is available for general use from 8.00 am to 5.00 pm and is heavily used by boys from the first to the sixth form before morning school, during the lunch hour and after school. Considerable use has been made during teaching time for class sessions, and sixth formers are able to use the computer in their private study time. During the final three weeks of the summer term about nine hundred log-ins were recorded! As this period included the preparation for the Open Days when the system was out of general use, there appears to be a growing for the facility the computer now provides.</em></p>

<p><em>During the summer term three after-school courses were provided to each the BASIC language, two for juniors new to the system and one for those with considerable experience in computing. It is hoped that more of these courses will be provided for boys at all levels in the School in the coming years.</em></p>

<p><em>Looking back over the period of the installation of the computer and the enthusiasm it has generated with boys of all ages, I anticipate a growing demand for computer time and an enhancement of the teaching of Mathematics in the School.</em></p>

<p><em>M.L.</em></p>

<p><img src="https://qmacro.org/content/images/2020/11/computerunit.jpg" alt="A picture of schoolboys using the terminals of the computer unit">
<em>A photo that accompanied the article in the school magazine</em></p>

<p>Here’s a grainy photo that accompanied the article in the school magazine. You can see one of the “VDU” (Visual Display Unit) terminals, and you can see a better picture of one of these in the photo of the Systime unit at the end of this post, but can you also spot the <a href="http://vtda.org/docs/computing/IntertecDataSystems/1100500-00_SuperTermMaintenance_1978.pdf">Superterm</a> paper-based terminal (back right)?</p>

<p><img src="https://qmacro.org/content/images/2020/11/superterm.png" alt="A grainy photo of the &quot;Superterm Data Communications Terminal&quot;">
<em>A Superterm Data Communications Terminal</em></p>

<p>Moreover, furthest away from the camera, there’s the original Texas 733 terminal, also paper-based. Here’s a better picture of one, from the <a href="http://www.bitsavers.org/pdf/ti/terminal/brochures/TI-327-A-10M_Silent_700_Model_732_733_Brochure_Sep_1973.pdf">original brochure</a>.</p>

<p><img src="https://qmacro.org/content/images/2020/11/texas.png" alt="A Texas 733 terminal&quot;">
<em>A Texas 733 terminal</em></p>

<p>Here’s a picture of what the computer unit looked like - it’s a photo (courtesy of <a href="http://www.chilton-computing.org.uk/">Computing at Chilton</a>, thank you) of a Systime unit, and the terminal on the desk is the same as those that we had in the computer room.</p>

<p><img src="https://qmacro.org/content/images/2020/11/systime.png" alt="A picture of a very similar Systime unit">
<em>A Systime unit</em></p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://qmacro.org/2020/11/03/computer-unit-1979/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979179</guid>
            <pubDate>Tue, 03 Nov 2020 12:55:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We made our SaaS home page cookie-free]]>
            </title>
            <description>
<![CDATA[
Score 374 | Comments 181 (<a href="https://news.ycombinator.com/item?id=24979167">thread link</a>) | @jivings
<br/>
November 3, 2020 | https://blog.leavemealone.app/no-more-cookies/ | <a href="https://web.archive.org/web/*/https://blog.leavemealone.app/no-more-cookies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.leavemealone.app/content/images/size/w300/2020/11/cookies.jpg 300w,
                            https://blog.leavemealone.app/content/images/size/w600/2020/11/cookies.jpg 600w,
                            https://blog.leavemealone.app/content/images/size/w1000/2020/11/cookies.jpg 1000w,
                            https://blog.leavemealone.app/content/images/size/w2000/2020/11/cookies.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.leavemealone.app/content/images/size/w2000/2020/11/cookies.jpg" alt="How we made our SaaS homepage cookie-free 🍪">
            </figure>

            <section>
                <div>
                    <p>If you've browsed the web in the last 10 years then you'll have seen more than your fair share of cookie banners!</p><p>Intended as a workaround to the <a href="https://www.cookielaw.org/the-cookie-law/">2011 EU Cookie Law</a>, cookie consent banners have become so commonplace that most people <a href="https://www.amazeemetrics.com/en/blog/76-ignore-cookie-banners-the-user-behavior-after-30-days-of-gdpr/">don't even bother to look at them</a>, or just click accept on everything. </p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-10.png"></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-9.png"></figure><!--kg-card-end: image--><p>As I see it, the purpose of the Cookie Law was to <strong>stop websites from storing data in your browser unless they absolutely needed to</strong>, by requiring them to prompt their visitors for consent. The end goal being to give you more control over your online privacy, stop needless tracking, and make website owners think twice about what they were doing. In short - a good intentioned idea.</p><p>However, basically every website in the world took the easier, less introspective approach - prompting for consent - creating an objectively worse web experience for everyone.</p><p>Since at <a href="https://leavemealone.app/">Leave Me Alone</a> we're trying to set an example of how to run a privacy friendly company, we decided to figure out how we could remove all the cookies from our landing page without sacrificing anything important. This means no more cookie banner, no more tracking! 🍪</p><p>We had three main cookie monsters that will be well known to SaaS companies;</p><ol><li>Web analytics</li><li>Live Chat</li><li>Security (DDOS protection etc)</li></ol><p>Before we start, I'm not neccessarily saying I distrust any of these companies and how they use cookies...so make your own judgement about them. We're just in this to get cookie free! </p><h2 id="web-analytics">Web Analytics</h2><p>To track our page views and general visitor behaviour, like <a href="https://trends.builtwith.com/analytics/Google-Analytics">most sites</a>, we were using Google Analytics. </p><p>Google Analytics sets a little cookie on page load to "remember" what a visitor has done on each page as they navigate around a site. This allows it to create a profile of the visitor so you can figure out exactly what it takes to get a visitor to sign up or convert, or whatever it is that you're trying to measure.</p><p>Realistically we never really use this information, so it's an easy one to get rid of. There are actually a handful of simpler web analytics platforms that don't use cookies, and we opted to try <a href="https://simpleanalytics.com/">Simple Analytics</a>. With this we get basically all the info we ever got out of Google Analytics (page views), so it seems like a great compromise.</p><p>You can even make your analytics pages public, which fits nicely with our "<a href="https://blog.leavemealone.app/how-we-share-company-stats-and-metrics-publicly/">open startup</a>" work ethic. For example you can view the stats for this <a href="https://simpleanalytics.com/blog.leavemealone.app">blog post here</a>!</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-1.png"><figcaption>The page view anaylitcs for Simple Analyics - meta!</figcaption></figure><!--kg-card-end: image--><p>🍪 Cookie Verdict = 5/5, no cookies, no problem.</p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="live-chat">Live Chat</h2><p>Having an annoying chat widget is another common thing for a SaaS homepage. We used to use Crisp for this, which uses a cookie to match a browser session to messages in their system. Their <a href="https://help.crisp.chat/en/article/crisp-chatbox-cookie-and-ip-policy-1147xor/">privacy policy</a> says this is "not used for tracking purposes", but given all the data they show in their UI about visitors that's not exactly much comfort. </p><p>(It even guesses a load of personal info from the visitors' email address like what company they work for and their job title using something called <a href="https://go.crisp.chat/notice/domain-enrich/">Crisp Enrich</a> which is apparently impossible to find any info about but sounds shady as hell).</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-6.png"><figcaption>I don't know why I would care about half of the stuff Crisp automatically collect on people who are just asking for help on my website 🤷‍♂️</figcaption></figure><!--kg-card-end: image--><p>So, this is a top priority since it looks like an absolute privacy and tracking nightmare.</p><p>I get that this is a difficult one, but there's literally no service we could find to do this cookieless (or even mildly privacy focused) so we ended up heavily modifying an open-source project called <a href="https://github.com/idoco/intergram">Intergram</a> to do what we wanted. Intergram works like a regular chat widget, but it communicates with the chat app Telegram via a self-hosted server - meaning at least we're in control of the code. Our modified chat widget now looks like this (and the code is <a href="https://github.com/squarecat/squarechat">open-source</a>);</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Group-54.png"></figure><!--kg-card-end: image--><p>Unfortunately it still requires some place to store the messages locally so that the visitor has a copy of them, but we still made this work by only storing anything <em>after</em> the chat has been opened. Unlike Crisp that injected it's cookies when it felt like it. We also don't collect any tracking crap like Crisp does, only chat messages!</p><p>We sweetened the deal by adding a consent prompt to the chat widget itself like this;</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Group-53.png"></figure><!--kg-card-end: image--><p>🍪 Cookie Verdict = 3/5 - fewer cookies, more privacy.</p><h2 id="security">Security</h2><p>This was a tricky one. We use Cloudflare as a security layer to protect the website from denial-of-service attacks. We also use their CDN to cache our assets so that the site loads extra fast, and use their DNS because it's hella convenient.</p><p>To perform their protection Cloudflare stores a cookie called <em><code>_cfduid</code></em>,<em> </em>which is used to track each client and somehow figure out if they're a malicious actor or something. I don't really know and <a href="https://support.cloudflare.com/hc/en-us/articles/200170156-Understanding-the-Cloudflare-Cookies">their description is clear as mud</a>. Whatever it does, it's got to go.</p><p>I didn't really know where to start with this one, so <a href="https://twitter.com/JamesIvings/status/1315945593471205376">I tweeted about it</a> and got a reply from a systems engineer that works there:</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/Slice-1-1.png"></figure><!--kg-card-end: image--><p>Which is a bit of a non-answer, since the Enterprise plan costs $200/month and I'd end up with fewer features for my trouble.</p><p>Since we've never actually had to use Cloudflare protection, my solution was to disable Cloudflare forwarding completely and switch to a proper CDN provider. You can do this by clicking the cloud icon on the DNS settings switching to "DNS only":</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-11.png"></figure><!--kg-card-end: image--><p>This means we are now just using Cloudflare for DNS. But it's possible to hit this button again and <strong>re-enable</strong> Cloudflare forwarding temporarily if we find ourselves under attack, so I figure this is a good option.</p><p>For a CDN provider we decided on recommendation to check out <a href="https://bunnycdn.com/">BunnyCDN</a>. I'm actually really impressed by this service, compared to Cloudflare everything feels a bit faster and it's easier to know what's going on, which I like. Also since it's just a file CDN there are zero cookies of course!</p><p>🍪 Cookie Verdict = 6/5 - No cookies AND a faster website!</p><p>The website now has no cookies on load, with some storage being used if a visitor opens the chat widget, which I think is a pretty successful outcome! </p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/11/image-8.png"></figure><!--kg-card-end: image--><p>You can check it out <a href="https://leavemealone.app/">here</a>, you'll notice there's no cookie banner to annoy you, it's almost like stepping back in time ;)</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>PS.</p><p>If you enjoyed this post then check out <a href="https://twitter.com/JamesIvings">my Twitter</a>. I spend my free time tweeting about how much I hate anti-privacy web practices and crappy mailing list emails. See you there!</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Cover photo by <a href="https://unsplash.com/@clemono?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Clem Onojeghuo</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>

            <section>
                <h3>Subscribe to Leave Me Alone Blog</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.leavemealone.app/no-more-cookies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979167</guid>
            <pubDate>Tue, 03 Nov 2020 12:53:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fatal Flaw of Ownership Semantics]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24979129">thread link</a>) | @komuW
<br/>
November 3, 2020 | http://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/ | <a href="https://web.archive.org/web/*/http://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
<header>
	
	
	<p>
		<span>2020-06-21</span>
		</p>
</header>
<p>I have been toying with a theoretical idea for the past 18 months off-and-on in my head and I have not fully articulated it aloud yet. It is regarding the concept of <em>Ownership Semantics</em> (OS) or <em>Move Semantics</em> in programming languages. Fundamentally this article is a criticism of the concept and states that the concept is a duality of traditional OOP but applied to a different area.</p>
<h2 id="general-definitions-of-terminology">General Definitions of Terminology</h2>
<p>A general list of definitions of terminology used within this article in order to minimize confusion.</p>
<ul>
<li>
<p>A <em>Value</em> is a datum with an associated type</p>
</li>
<li>
<p>A <em>(Data) Type</em> is an attribute of a value which encodes information about how the data value can be operated upon</p>
</li>
<li>
<p>An <em>Object</em> is a value with associated behaviour, and thus implies it has <em>agency</em></p>
</li>
<li>
<p>A <em>Class</em> is the data type of an <em>Object</em></p>
</li>
<li>
<p>A hierarchy of value ownership is a hierarchy of responsibility of values</p>
</li>
<li>
<p>An <em>Owned-Value</em> is a value which belongs to a hierarchy of value ownership, which implies it is governed by an <em>agent</em></p>
</li>
<li>
<p>An <em>Agent</em> is an actor with the capacity to act within a given environment</p>
</li>
<li>
<p>A <em>Model of Interpretation</em> is a way to view and analyse a subject</p>
</li>
<li>
<p>A <em>Paradigm</em> is a way of classifying models of structure of programming languages; a <em>Paradigm</em> is a <em>model of interpretation</em></p>
</li>
<li>
<p><em>Object Orient(at)ed Programming (OOP)</em> - A paradigm of structuring a program around the sole concept of <em>Objects</em>, commonly through coupling data and code into a single unit.</p>
</li>
<li>
<p><em>Ownership/Move Semantics (OS)</em> - Orientation around responsibility of values in a hierarchical fashion</p>
</li>
</ul>
<h2 id="foundations-of-the-object-orientation-paradigm">Foundations of the Object Orientation Paradigm</h2>
<p>Though the original conception of the term coined by Alan Kay<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> was never used as he intended it to be, the term <em>Object Orient(at)ed Programming (OOP)</em> has been commonly understood to be a paradigm of structuring a program around the concept of <em>Objects</em>, commonly through coupling data and code into a single unit. Many languages support multiple paradigms, including aspects for the OOP paradigm, but I would class those as multiparadigm rather than being <em>solely</em> an OOP language.</p>
<p>Most languages implement <em>Objects</em> and <em>Classes</em> in the Simula tradition; most of the notable OOP languages have a similar form by defining methods (member functions) within the class definition. Traditionally languages such as Java can be classed as <em>solely</em> an OOP language.</p>
<p>Most traditional OOP languages are based around the concept of <em>inheritance</em>, a mechanism of deriving a class data type from another class data type and retaining similar information. Most people generally view inheritance as a combination of <a href="https://en.wikipedia.org/wiki/Subtyping">subtyping</a> and <a href="https://en.wikipedia.org/wiki/Dynamic_dispatch">dynamic dispatch</a> through <a href="https://en.wikipedia.org/wiki/Virtual_method_table">virtual method tables (vtables)</a>. This has lead to many discussions asking whether a language can be called as OOP if it does not support inheritance<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p>In recent times, <em>inheritance</em> has been falling out of fashion in favour of <em>composition</em><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. This is mostly due to the issue of conforming a <em>class</em> to a strict (singular) hierarchy of agency when in reality, things can belong to many (if not infinite) categories and hierarchies, as well as another aspect which I will be discussing throughout this article.</p>
<p>There are many criticisms of OOP<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup><sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup><sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup><sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup> but my general criticism is that by placing emphasis on trying to solve problem in the type system, it shifts focus from the data structures and algorithms, <a href="http://www.gingerbill.org/article/2020/05/31/progamming-pragmatist-proverbs/#the-concept-of-programming">the core of what a program fundamentally is</a>.</p>
<p>Since objects themselves are being treated <em>as if</em> they have behaviour (not just type properties), they are effectively being treated as if they were <em>agents</em> in the program. This mental model has many conclusions, many of which cause issues.</p>
<p>In my article <a href="https://www.gingerbill.org/article/2020/05/31/progamming-pragmatist-proverbs/"><em>Pragmatism in Programming Proverbs</em></a>, I state:</p>
<blockquote>
<p>Object orientated programming is a form of misinterpreted and misapplied Aristotelian Metaphysics applied to a domain it was never meant to model</p>
</blockquote>
<p>What I mean by this statement is that <em>artificially</em> conforming any/all relationships between data and types to an artificial hierarchy of <em>agency</em> is a form of naïve-Aristotelian metaphysics. Since there is no actual <em>agency</em> in the programming objects, it is a partial fallacy. When trying to conform a program to have a particular structure when it does not naturally, the absence of a structure in a program is more useful than a bad structure.</p>
<h3 id="methods">Methods</h3>
<p>The concept of adding methods to classes/objects has proven useful to many. The real questions are:</p>
<ul>
<li>Why?</li>
<li>And how do people actually conceptualize methods on a day-to-day basis?</li>
</ul>
<p>For most people, I am going to bet that methods, in languages with an emphasis on inheritance rather than composition (such as C++ or Java), are treated as a way of categorizing and associating functions/procedures with a data record. There are a few reasons for this approach:</p>
<ul>
<li>Easy to organize and search for procedures by a data type</li>
<li>Allowing methods as a form of syntactic sugar for writing calls in a <em>subject verb object</em> manner e.g. <code>foo_do_thing(x, y)</code> vs <code>x.do_thing(y)</code></li>
<li>Mental model of behaviour for objects</li>
</ul>
<p>From experience, I have found that long time users of “OOP” languages eventually start treating methods primarily in the first two approaches.</p>
<p>I will not go into depth about the other main aspects of OOP such as encapsulation, local retention, forms of polymorphism, etc, as the hierarchical nature is the fundamental aspect of focus for this article. The (linear) hierarchy of agency is the main problem. The reason why people argue for <em>composition over inheritance</em> is that it flattens this linear hierarchy, reducing its effect. It is the transition from <a href="https://en.wikipedia.org/wiki/Nominal_type_system">nominal typing</a> to <a href="https://en.wikipedia.org/wiki/Structural_type_system">structural typing</a>, which is more flexible because many data structures and problems have a <em>non-linear</em> nature to them, which <em>linear</em> approaches <strong>cannot</strong> handle. When trying to adhere to the the strict hierarchical type system approaches, it leads to numerous issues because data is more commonly graph-like (non-linear) than tree-like (linear) for most problems. This strict hierarchy does occur with encapsulation at the object level too, a strict hierarchy of messages/references; this hierarchical nature arises from the concept agency itself, inheritance is not the root cause.</p>
<p><strong>n.b.</strong> Inheritance is not all bad and does have many real life practical uses, but these costs must be known before using them, like with any tool.</p>
<p><strong>n.b.</strong> The linearity is with regards to the data structures themselves and not the algorithms.</p>
<h2 id="foundations-of-the-ownership-semantics-paradigm">Foundations of the Ownership Semantics Paradigm</h2>
<p><a href="https://en.wikipedia.org/wiki/C%2B%2B">C++11</a> introduced the concept of <em>move semantics</em> or <em>ownership semantics</em> (OS), a way to minimize the copying of data through copy constructors. It utilizes the added concept of r-value references (<code>T &amp;&amp;</code>) as a means to do this. However, the concept began to be used for a lot more than its basic purpose. The concept adds the high level abstraction of “moving” objects rather than “copying” objects. Physically, a computer only ever copies and this high level abstraction, to treat objects <em>as if</em> they were “real objects”, is not what actually happens. It is also a <a href="https://en.wikipedia.org/wiki/Category_mistake">category error</a> to treat them as “real objects” since “real objects” and “programming objects” have little connection with each other ontologically. When a value or object is “moved”, this means is that the <em>responsibilities</em> of the resources of that object have been transferred to another object or environment—<em>agents</em>. In this case, ownership/move semantics is fundamentally based around the <em>responsibilities of values</em> by tracking value usage.</p>
<p>In this model of agency, the arena of agency can take on many forms, such as blocks, procedure bodies, or aggregate values. Therefore some <em>owned-values</em> also <em>own</em> other values, and thus a value could have agency.</p>
<p>If we were to call Ownership Semantics a paradigm, it would be the orientation around the <em>responsibility of values</em> in a hierarchical fashion, placing emphasis on this system of responsibility, shifting focus from data structures and algorithms.</p>
<p>The concept of <em>responsibility</em> and <em>ownership</em> is similar to the real world counter parts in that to own something means to have exclusive use and full responsibility over it.</p>
<p><a href="https://www.rust-lang.org/">Rust</a> is a multi-paradigm programming language but at its core is an Ownership-Orientated language. Everything in Rust has a concept of <em>“ownership”</em> and <em>lifetime</em> associated with it. Rust is designed around trying to be first and foremost “safe”, especially with regards to concurrency. Rust derives from the C++ family in terms of philosophy and style, but uses a more <a href="https://www.gingerbill.org/article/2018/03/12/on-the-aesthetics-of-the-syntax-of-declarations/">qualifier-focused</a> declaration syntax and many concepts from functional languages from the <a href="https://en.wikipedia.org/wiki/ML_%28programming_language%29">ML family</a>.</p>
<p><em>Lifetimes</em> are theoretically orthogonal to <em>ownership</em> but in practical, they usually are intrinsically coupled. I will not discuss the problems with object-based lifetimes in this article.</p>
<p>The following Rust code can be used to demonstrate this responsibility transfer between different capturing things such as <code>let</code> statements:</p>
<pre><code>pub struct Foo {
	value: i32,
}

fn main() {
	let foo = Foo{value: 123};
	let bar = foo; // the responsibility of `foo` is transferred to `bar`

	println!("{}", foo.value); // error: use of moved value: `foo.value`
	println!("{}", bar.value);
}

</code></pre>
<p>Rust is an immutable-by-default language, with the option to opt into mutability with <code>mut</code>. Immutability helps a lot with mathematical proofs for logic since things things can be “flattened” quite easily, however virtually all computers are fundamentally mutable things, even if the abstraction of immutability is a useful tool. As a result, the ownership semantics system requires a few more rules to take into account mutability, by adding the concept of “borrowing” through references. The general rules for the borrow checker are:</p>
<ul>
<li>Each value may have as many immutable borrows as you want</li>
<li>Each value may only have one mutable borrow at a time</li>
<li>Each value may not borrow immutably and mutably at the same time</li>
<li>Values will be “dropped” when the owning connecting goes out of scope</li>
<li>Taking a value by <code>self</code> <code>Drop</code>s the original value</li>
</ul>
<p>When using Rust (or move semantics to their full extent in C++11), most people will fight the borrow …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/">http://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/</a></em></p>]]>
            </description>
            <link>http://www.gingerbill.org/article/2020/06/21/the-ownership-semantics-flaw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979129</guid>
            <pubDate>Tue, 03 Nov 2020 12:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Fundamentals: What I’m Learning]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24979103">thread link</a>) | @buaiscia
<br/>
November 3, 2020 | https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals | <a href="https://web.archive.org/web/*/https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="intro"><a href="#intro" aria-label="intro permalink"></a>Intro</h2>
<p>At this moment in my career, I’m a Javascript fullstack developer in the early stages. I’ve a good knowledge of Javascript, however React gives me sometimes a little more than a headache to understand deeply. I grew up in my learning with class based components, so later, when hooks were introduced, I found a little difficult to transition to this new way of writing React. That’s why I wanted this course. </p>
<p>As part of my learning process, I’m going to note down not everything, but what I learnt, for each section. Often my solution was, although working, more complicated and less elegant than Kent’s one. That’s another aspect I wish to improve in my coding. </p>
<p>Of course you will find many more details and, well, the workshop itself directly in <a href="https://epicreact.dev/">epicreact.dev</a>
I hope this will be useful to somebody else apart from me, and forgive my mistakes in English (not a native speaker).
<br></p>
<h2 id="01-basic-javascript-rendered"><a href="#01-basic-javascript-rendered" aria-label="01 basic javascript rendered permalink"></a>01: Basic JavaScript-rendered</h2>
<p>In the first exercise, it’s necessary to make some DOM manipulation with plain Javascript. As I’m using this method in my daily work, I had no difficulties in the first part. As a matter of fact, I’m learning a lot into transforming a codebase that is heavily relying on jQuery into plain Javascript.</p>
<p>However, I did have to do some thinking on the additional exercise, as I’m not used to work with the root element of the body. So I personally didn’t know -but now that I know, it makes sense - that there’s a body object inside the document object. I won’t give here the solution, but it’s an important reminder to always check the parent elements… what are they hiding inside :)
<br></p>
<h2 id="02-intro-to-raw-react-apis"><a href="#02-intro-to-raw-react-apis" aria-label="02 intro to raw react apis permalink"></a>02: Intro to raw React APIs</h2>
<p>The second exercise of the workshop was already trickier - which I was happy about because definitely I didn’t want to learn again the same stuff.
It’s not often, if ever, that we are using the React.createElement. Using JSX we just skip this part, but that’s how it works under the hood.
So after learning what jQuery is doing in Javascript, now it’s React in Javascript. </p>
<p>First thing I learnt here is that the famous property ‘children’, in React, corresponds to textContent in plain JS. It makes sense, of course, as a matter of fact we are rendering some text made visually in HTML.</p>
<p>The second thing is that createElement has three - or more - arguments that can be passed. </p>
<ol>
  <li>The type of element (span, div, etc)</li>
  <li>The object passed inside the element (class, children, etc)</li>
  <li>A n number of other objects, that will be rendered as additional children.</li>
</ol>
<p>As a matter of fact, the children property doesn’t even have to be defined inside the second argument of createElement, but can be listed at the end of the method.
<br></p>
<h2 id="03-using-jsx"><a href="#03-using-jsx" aria-label="03 using jsx permalink"></a>03: Using JSX</h2>
<p>The third exercise was about creating simple JSX elements that Babel will transform in normal JS with React.createElement. As it’s basically almost a reverse engineering of the previous exercises, it was not difficult. However, it was interesting the use of the spread operator inside a div element, which createElement puts in the correct position:</p>
<div data-language="text"><pre><code>const className = 'myClass';
const children = 'this is my text';
const props = { children, className }
element = &lt;div {...props}/&gt;</code></pre></div>
<p>It will create a div with its own class and the innertext as children.</p>
<p>Another interesting point in the video is about prioritazion of position using the spread operator. Supposing that we have the above props, but then we want to override the className with another name, we have to place the spread props before. In synthesis, the right argument will always override the left ones.</p>
<div data-language="text"><pre><code>&lt;div {...props, className='secondClass'} /&gt; // &lt;div className="secondClass"&gt;
&lt;div {className='secondClass', ...props} /&gt; // &lt;div className="myClass"&gt;</code></pre></div>
<h2 id="04-creating-custom-components"><a href="#04-creating-custom-components" aria-label="04 creating custom components permalink"></a>04: Creating custom components</h2>
<p>So here we go finally to start creating components. The first part consists in creating a function that basically returns a div, so instead of repeating div div in the rendered element, we just pass the function with the string as “children”. One thing that I knew but forgot explicitly is that if I pass a parameter to the function as an object, the argument must be an object as well. So:</p>
<div data-language="text"><pre><code>helloFunction = ({children}) =&gt; {
  return &lt;div&gt;{children}&lt;/div&gt;
}

helloFunction({ children: 'Hello' });</code></pre></div>
<p>The next point was to implement this function as an element:</p>
<p><code>const myElement = React.createElement(message, { children: 'Hello!' })</code></p>
<p>and finally incorporate it in the element itself, which will be taken into ReactDom.render:</p>
<div data-language="text"><pre><code>const element = (
  ...
  {myElement}
)</code></pre></div>
<p>Following that, it’s about referring the same helloFunction but make it directly compiled through Babel as an element, without needing to pass through createElement. This is possible thanks to JSX, and it’s enough to make the function name with first letter as capital, and reference it inside the element object as that.
<code>HelloFunction = () = {}</code></p>
<p><code>&lt;HelloFunction&gt;Hello!&lt;/HelloFunction&gt;</code></p>
<p>This is the equivalent of <code>React.createElement(HelloFunction, null, 'Hello!')</code></p>
<p>Next, it was the time of implementing propTypes for typechecking, giving the same above function to have two parameters, both strings. In the workshop, it’s explained how to make a propTypes function for checking manually the type. But it’s interesting that it’s not taking advantage of the prop-types library. It is true that for a simple check of two props, importing a whole library is excessive; but I don’t think I’ll ever just use two checks. </p>
<p><code>&lt;script src="https://unpkg.com/prop-types@15.6/prop-types.js"&gt;&lt;/script&gt;</code></p>
<div data-language="text"><pre><code>HelloFunction.propTypes = {
      greeting: PropTypes.string,
      subject: PropTypes.string,
    }</code></pre></div>
<p>I’m not getting either a personalized message, but the standard warning is understandable enough</p>
<div data-language="text"><pre><code>Invalid prop `subject` of type `number` supplied to `Message`, expected `string`. in HelloFunction</code></pre></div>
<p>Ah, here we go, in the next exercise there’s the implementation of the library… ooooops, I went a little over head. But good point, to implement also ‘isRequired’</p>
<div data-language="text"><pre><code>HelloFunction.propTypes = {
      greeting: PropTypes.string.isRequired,
      subject: PropTypes.string.isRequired,
    }</code></pre></div>
<p>Anyway, Typescript rules!
<br></p>
<h2 id="05-styling"><a href="#05-styling" aria-label="05 styling permalink"></a>05: Styling</h2>
<p>In this  exercise it was needed to apply style to a custom component in various ways. On a first part, just adding inline styling to a small div; then to a custom component passing its className prop; finally, passing only a string as a size prop and selecting dynamically the style inside the custom component.</p>
<p>First note: when making a reusable component, normally it’s good to place all defaults on the left and what the user is providing (spread operator) after, because we don’t want to enforce something.</p>
<p>Second note: as usual I overcomplicated things. As the size property passed would be only small, medium and large, and the classes are called box—small, box—medium, box—large, it’s enough to substitute the size with the size prop passed into the component.</p>
<p><code>box--${size}</code></p>
<p>adding that to a ternary operator in case it’s the prop is not present.
What I did instead was a nested ternary operator with an object created with the classes names inside. Much more complicated, although it was working 😁</p>
<div data-language="text"><pre><code>const sizes = {
  small: 'box--small',
  medium: 'box--medium',
  large: 'box--large'
}

className={`box ${size === 'small' ? sizes.small : size === 'medium' ? sizes.medium : sizes.large}`}</code></pre></div>
<h2 id="06-forms"><a href="#06-forms" aria-label="06 forms permalink"></a>06: Forms</h2>
<p>In the first exercise, the object is creating a submit listener/handler that will call the function in the main component, which is passed through as a prop.</p>
<p>We can put events (will be React synthetic events) on each element; however, the onSubmit goes inside the form to catch every field that is contained.
Synthetic events are objects that React creates that look and behave like regular DOM events.
It’s still possible to access the DOM event with <code>event.nativeEvent</code>, however, the synthetic one is optimized to work with React code, and the virtual DOM.</p>
<p>I created then a function inside the function (a callback), called once the submit button is clicked. And I’ve added the preventDefault() to that event to prevent the page to refresh (as default event for a form).</p>
<p>Another interesting thing is about accessibility. Screen readers need to associate the input with its label. So it’s needed to give the input an id and the label a htmlFor (the same for= parameter in normal HTML). Moreover, this gives the property of focusing on the input when clicking on it.</p>
<p>The second part of the exercise was about doing the same as above but using the useRef hook. UseRef are simply reference pointers to an element.
First, it’s needed to be imported from ‘react’ and not ‘react-dom’.</p>
<p>Then, adding the reference to our input
<code>&lt;input ref={usernameInput}&gt;</code>
In the main function (or custom component), we can call the hook: <code>const usernameInput = useRef(null);</code>
Why null? The argument of useRef is the initial value. But in this case we don’t need that, just what will be in usernameInput.</p>
<p>Finally, we can access all our referenced properties, like the input value, this way: <code>usernameInput.current.value</code></p>
<p>In the next credit, it was needed to create a controlled input. A controlled input is an input field that is controlled by the component state. That means setting the value of the input by the state: <code>&lt;input ref={usernameInput}  value={username} onChange={handleChange} /&gt;</code></p>
<p>Then, we can set the state at the top of the component: <code>const [username, setUsername] = useState('');</code>
And finally, use that state to change the value of the input in the handleChange function. In this case, transforming every key to lowercase:</p>
<div data-language="text"><pre><code>const { value } = event.target;
setUsername(value.toLowerCase());</code></pre></div>
<p>So the flow is the following:
input from user —&gt; update input state —&gt; transforming input state -&gt; sending the state as value of the input —&gt; input appears on screens.
<br></p>
<h2 id="07-rendering-arrays"><a href="#07-rendering-arrays" aria-label="07 rendering arrays permalink"></a>07: Rendering Arrays</h2>
<p>The exercises were just little demonstrations in this case, to show the importance of using a unique index key when showing elements in the DOM through a mapping. Not without, not with the pre-built index of the map function, but with a preset set of keys to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals">https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals</a></em></p>]]>
            </description>
            <link>https://buaiscia.github.io/posts/learning-on-epic-react-fundamentals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24979103</guid>
            <pubDate>Tue, 03 Nov 2020 12:44:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Duterte’s vicious war against telecom operators]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24978868">thread link</a>) | @donohoe
<br/>
November 3, 2020 | https://restofworld.org/2020/duterte-dito-and-the-duopoly/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/duterte-dito-and-the-duopoly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>In late July, during a meeting with his cabinet, Phillipine President Rodrigo Duterte sat at the head of a large table, the country’s official seal hanging behind him. “That’s Ernest Cu,” he said with a slight smile, gesturing to one of the men seated nearby. “I told him, if you don’t improve the service, I will hang you on one of your towers.”</p>



<p>Cu is the president and CEO of Globe Telecom, one of only two mobile network companies operating in the Philippines. Just days before, during his annual state of the nation address, Duterte warned that he was prepared to shut down Globe and its competitor, Philippine Long Distance Telephone (PLDT), and seize their assets, if the companies failed to improve service by the end of the year.</p>



<p>A strongman populist who came to power in 2016, Duterte has singled out the telecom industry as part of a broader war against powerful oligarchs who dominate the country’s economy. During his election campaign, he pointed to painfully slow internet speeds — at the time, the second-slowest in Asia — and warned that, if they didn’t improve, he would bring in a third operator to boost competition. Speeds in the Philippines have since increased dramatically, <a href="https://technology.inquirer.net/87428/internet-speed-in-ph-doubles-from-q3-2016-to-q1-2019-report">more than doubling</a> between 2016 and 2019. But Duterte handed out a third license anyway, to Dito, a Chinese-backed company expected to launch in the coming months.&nbsp;</p>



<p>Duterte is a divisive figure who often lobs outrageous threats at his opponents. He recently <a href="https://www.nytimes.com/2020/09/29/business/rodrigo-duterte-facebook-philippines.html">lashed out</a> at Facebook, for example, after the social network took down an army of fake accounts that spread support for his policies. But broadband speeds are a popular issue with voters: In 2018, <a href="https://edition.cnn.com/2019/02/01/health/philippines-highest-internet-use-scli-intl/index.html">Filipinos were the heaviest users of the internet anywhere in the world</a>, spending on average more than 10 hours a day online, according to one report by the marketing agency We Are Social.&nbsp;</p>



<p>“Part of the genius of the president is that his team is able to pick out issues that are really close to the gut of Filipinos,” says Michael Henry Yusingco, a senior research fellow at the Ateneo School of Government. He says that, if the president can use his tough policies to drastically improve internet service, “it’s a big plus for his dynasty and also for the allies of his dynasty.”</p>



<h3><strong>How did cell towers get so political?</strong></h3>



<p>A small group of elite families has long controlled the Philippines, overseeing everything from mining to real estate and infrastructure. The internet is no different, partly because barriers to entry in the sector are so high. A 1995 law regulating telecom companies still requires new entrants to invest in expensive and often unprofitable landlines. “It actually forces industry players to invest in technology or offer a service that is becoming obsolete,” says Mary Grace Mirandilla-Santos, an independent telecommunications researcher in the country.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/GettyImages-1075210436-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/GettyImages-1075210436-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/GettyImages-1075210436-400x600.jpg 400w, https://restofworld.org/wp-content/uploads/2020/11/GettyImages-1075210436-600x900.jpg 600w, https://restofworld.org/wp-content/uploads/2020/11/GettyImages-1075210436-1000x1500.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/11/GettyImages-1075210436-1600x2400.jpg 1600w, " sizes="(max-width: 640px) 100vw, 300px" alt="The headquarters of telecommunications company PLDT Inc. in Manila.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Kyodo News Stills via Getty Images</span>
			</figcaption>
		</figure>






<p>The only companies that could afford to invest in landlines were cash-rich conglomerates and those run by “old-money” families, like the Ayalas, who are major stakeholders in Globe, or the real-estate-to-airlines conglomerate JG Summit, which is a major shareholder in PLDT. “Our current investment structure in the Philippines is very limited. There are only a few families or groups that can raise the amount of money to put forward a third telco business,” says Yusingco.</p>



<p>Larger companies have also swallowed new upstarts in the space. In 2016, <a href="https://www.reuters.com/article/us-pldt-san-miguel-m-a-approval-idUSKCN0YL07K">PLDT and Globe together bought out their only rival, Vega Telecom</a>, which was started by San Miguel Corporation, another giant conglomerate. Mirandilla-Santos says that, during its short stint, Vega did have a positive impact on the market: In 2015, <a href="http://www.investphilippines.info/arangkada/wp-content/uploads/2016/02/BROADBAND-POLICY-BRIEF-as-printed.pdf">1GB of data cost approximately $7.10</a>, according to her research. By the end of 2018, that number fell to just <a href="https://mgmresearch.com/worldwide-mobile-data-pricing-rankings-2019/">$3.16</a>. Dito’s entry could similarly drive down prices.</p>



<p>Without competition, there was little incentive for Globe or PLDT to invest in upgrading their network infrastructure or lowering data rates costs. A <a href="https://lirneasia.net/2014/03/broadband-quality-of-service-experience-qose-indicators/">2014 study by the think tank LIRNEasia</a> found that internet users in the Philippines paid more for worse connectivity than in almost anywhere else in Asia, holding back development of the country’s technology sector.</p>



<p>“The issue has historically been that data is just too expensive,” says Henry Motte-Muñoz, the founder and CEO of Edukasyon, the country’s leading digital education platform. “So you have a lot of users who, if they could, would spend more time on your site, but they don’t.”</p>



<h3><strong>Will a third mobile operator really help?</strong></h3>



<p>Duterte’s war against Globe and PLDT appears to be working. When the new president came into office, 25% of Edukasyon’s internet traffic came from Free Basics, a Facebook program that gives Fillipinos free access to some websites, including Motte-Muñoz’s. Today, it’s closer to 10%. “[The price cut] was massive for us because, for lower-income students, Free Basics was the only way to use the internet,” Motte-Muñoz says.&nbsp;</p>


<div>

<div>

<div>
<table>
<tbody>
<tr><td>Licensed telecoms companies:</td><td>Globe Telecom, PLDT, Dito Telecommunity</td></tr>
<tr><td>Internet penetration (2020):</td><td>67%</td></tr>
<tr><td>Population:</td><td>106.7 million</td></tr>
<tr><td>Number of cell towers:</td><td>18,000</td></tr>
<tr><td>Mobile phone connections:</td><td>173.2 million</td></tr>
<tr><td>Data cost (2015):</td><td>$7.10/1GB</td></tr>
<tr><td>Data cost (2020):</td><td>$1.42/1GB</td></tr>
<tr><td>Average download speed:</td><td>8.5/Mbps</td></tr>
</tbody></table>
</div>
</div>
</div>






<p>More affordable data has also spurred entrepreneurship. In 2018, after prices came down, Rexy Josh Dorado founded <a href="https://restofworld.org/2020/the-disneyland-of-social-media/">Kumu, a livestreaming app that now has more than 1 million monthly active users</a>. Price, though, is only one part of the problem: The quality of internet connections remains patchy at best, particularly outside of major urban areas. In the rural city of Dumaguete, where Dorado is from, the internet works just on the main street of his hometown. “If you drive five minutes out, it’s basically dead,” he says.</p>



<p>Together, Globe and PLDT have constructed around 18,000 cell towers, half of what the Philippines’ Department of Information and Communications Technology says is needed for optimal coverage. To build more, Globe told <a href="https://business.inquirer.net/303993/dutertes-telco-takeover-threat-compounds-red-tape-woes-200-days-to-get-permits"><em>The Philippine Daily Inquirer</em></a>, it has to comply with burdensome state requirements, including getting 28 to 30 licenses that can take upward of eight months to secure. But over the last three years, Globe and PLDT, up against the same regulations, have poured 30% more money into infrastructure investments, according to data from the credit agency Fitch Ratings.</p>



<p>So why, after all that progress, did the president decide to bring in a third competitor?</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/GettyImages-812534470-40x28.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/GettyImages-812534470-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/11/GettyImages-812534470-400x277.jpg 400w, https://restofworld.org/wp-content/uploads/2020/11/GettyImages-812534470-600x415.jpg 600w, https://restofworld.org/wp-content/uploads/2020/11/GettyImages-812534470-1000x692.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/11/GettyImages-812534470-1600x1107.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/11/GettyImages-812534470-2800x1938.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Philippine President Rodrigo Duterte rings the bell at the Philippine Stock Exchange alongside political ally Dennis Uy.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Ted Aljibe/AFP via Getty Images</span>
			</figcaption>
		</figure>


<h3><strong>What is Dito, and will it succeed?</strong></h3>



<p>Dito, Duterte’s new competitor for Globe and PLDT, is run in part by the Udenna Group, a shipping and oil giant owned by Dennis Uy, an old political ally of the president and one of the <a href="https://news.abs-cbn.com/focus/12/05/16/p334m-from-only-13-donors-funded-dutertes-presidency">largest contributors</a> to his campaign in 2016.</p>



<p>The company fits neatly into two patterns typical of Duterte’s time in office. Giving Dito access to the Philippines internet market enriches a figure who is outside of the traditional oligarchy but is also aligned with the president. And Dito relies heavily on Chinese investment: The company is a partnership with the state-owned China Telecommunications Corporation. Duterte has <a href="https://www.scmp.com/week-asia/politics/article/3034666/china-promised-duterte-us9-billion-infrastructure-hes-had-only">previously courted</a> Beijing for investment in a number of other infrastructure projects.&nbsp;</p>



<p>That money and political support could give Dito a leg up as it tries to contend with two enormous companies with decades of experience and infrastructure. But it will still need to overcome the same challenges that killed off previous competitors that tried challenging the existing duopoly. Even if it fails, however, it may have already served its political purpose. “For the Duterte government, the entry of Dito is really about the <em>perception</em> that they’ve tried to do something about the really bad internet,” says Yusingco.</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/duterte-dito-and-the-duopoly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978868</guid>
            <pubDate>Tue, 03 Nov 2020 12:06:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Products should be “slick”, not just viable]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24978808">thread link</a>) | @HermanMartinus
<br/>
November 3, 2020 | https://herman.bearblog.dev/mvp-vs-slc/ | <a href="https://web.archive.org/web/*/https://herman.bearblog.dev/mvp-vs-slc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><h3 id="i-hate-the-term-mvp">I hate the term MVP.</h3>
<p>Over the past decade, it’s been overused and misunderstood to the point where something labeled as an MVP is automatically assumed to be pretty shit. Most MVPs are unfortunately too M to be V, and the culture of “ship it while you’re embarrassed by it” tends to lead to products providing users with an embarrassingly bad experience.</p>
<h3 id="the-problem-is-that-your-users-hate-mvps">The problem is that your users hate MVPs.</h3>
<p>Building products is a difficult and time-consuming effort. Figuring out what the problems, finding a potential solution to that problem, and then building that solution all take a decent chunk of time and effort. It’s due to this process that the minimum viable product was born. The motivation for building an MVP is still valid. Build something small and easy to test, launch quickly, and pivot or trash it if it doesn’t perform as desired.</p>
<p>There is another, less selfish way.</p>
<p>I read an <a href="https://blog.asmartbear.com/slc.html">article</a> by Jason Cohen a few years ago which changed the way I think about product development. Instead of building MVPs, we should be building SLCs. Something Simple, Loveable, and Complete.</p>
<h3 id="simple">Simple</h3>
<p>When something is simple, it is easier to modify, build on, and maintain (all of which are very important in the early stages of product development). This is different from something being minimal as something can be minimal but not simple. Conversely, few things are simple without being minimal. One of the pieces of feedback I get regularly for <a href="https://justsketch.me/">JustSketchMe</a> is how simple the interface is, and how easy it is to use. By having a small set of powerful tools we keep the simplicity of interaction while providing the ability to create complex scenes.</p>
<h3 id="loveable">Loveable</h3>
<p>Coming from game development, it has always been a priority of mine to ensure my creations elicit joy. It needs to be loveable. If people aren’t getting that “ooh, this is nice” feeling from your early-stage project, they’re unlikely to stick around. Both <a href="https://bearblog.dev/">Bear Blog</a> and <a href="https://somewordsfor.me/">Some words for me</a> were explicitly built to be loveable. From the copy to the way that the user interacts with them, everything is built with <a href="https://en.wikipedia.org/wiki/Marie_Kondo">Marie Kondo</a> in mind. (There’s even an Easter egg on the Bear Blog home page. Happy hunting!)</p>
<h3 id="complete">Complete</h3>
<p>This is the most important of the three traits. The product needs to be complete.</p>
<p>I don’t mean that your product cannot be worked on and expanded anymore. It means that the product is not reliant on additional features for it to be useful to your users. A good way to test this is to think: “If I don’t expand and improve this product anymore, will people still use it?”.
If we take a look at tech products that are doing fairly well, you’ll notice that most (if not all) of them were built as complete products initially. Twitter is so similar to the initial concept, while Facebook has morphed into something else entirely; but both products were completely useable in their inception.</p>
<p>To use one of my projects as an example again, <a href="https://justsketch.me/">JustSketchMe</a> started out with just 2 characters (male and female) and only one in the scene at a time. This was very useful and had I walked away from the project at that point, it would have still been complete. I have since built out the functionality to add many characters to the scene, along with props and saving to the cloud.</p>
<h3 id="design-by-subtraction">Design by subtraction</h3>
<p>With SLCs (as opposed to MVPs) the trick is to design by subtraction. My favourite example of this is the game <a href="https://en.wikipedia.org/wiki/Ico">Ico</a>. It’s a fetch quest game where you need to escort another character and prevent her from being dragged to the underworld by little beasties. The developers started out by designing combat, weapons, and upgrade systems. Loot systems. Health and damage counters. They then sat down to examine which features actually emphasise the core mechanic, and which ones do not. Long story short, they ended up removing almost all the systems we would traditionally see in a game like this. The character now has a stick that is used to fight off beasties (instead of a complex weapon/upgrade system). The character can’t even take damage. The lose state is if the character you’re escorting is dragged to the underworld.</p>
<p>This culminated in one of the best games of the generation. The developers went on to build the iconic Shadow of the Colossus using the same techniques.</p>
<h3 id="conclusion">Conclusion</h3>
<p>Here are some steps to think about when building your next project:</p>
<ol>
<li>Keep the feature-set small and manageable (as opposed to large and hastily built).</li>
<li>Make the product delightful to interact with.</li>
<li>Stay focused on the core idea of the project.</li>
<li>Have fun with it!</li>
</ol>
</div>
</div></div>]]>
            </description>
            <link>https://herman.bearblog.dev/mvp-vs-slc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978808</guid>
            <pubDate>Tue, 03 Nov 2020 11:57:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kingdom – The little known story of how Sikkim was annexed]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24978744">thread link</a>) | @yukiari
<br/>
November 3, 2020 | https://fiftytwo.in/story/kingdom/ | <a href="https://web.archive.org/web/*/https://fiftytwo.in/story/kingdom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-09b8f8d3="" data-v-20489b7b=""><div data-v-09b8f8d3=""><div data-v-df82986e=""><div data-v-df82986e=""><div data-v-df82986e=""><div data-v-df82986e=""><div data-v-df82986e=""><!----> <p>In the days leading up to 9 April 1975, the sedate capital of an autonomous Himalayan kingdom became a fortress. In and around Gangtok, troops belonging to neighbouring India were mobilised on a large scale. In the market squares, people gathered over chhang and chhurpi<a href="" onclick="return!1"><sup id="wr6ardmgiobm">[1]</sup></a> and wondered if there was going to be another clash with China. </p></div></div></div></div>  <!----></div><section data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><!----> <div data-v-58180b62=""><p>In his hilltop palace, Palden Thondup Namgyal, the Chogyal of Sikkim,<a href="" onclick="return!1"><sup id="xjtge4t3hylq">[2]</sup></a> sensed a trap. The Indian Army claimed to be carrying out a routine exercise, but his guards were not convinced. They pleaded with him to escape to Nepal disguised as a monk. They were thinking, perhaps, of a day in 1959 when a 24-year-old from Tibet, anointed the Dalai Lama of his people, had made the opposite journey, fleeing the Chinese regime in soldier’s disguise. </p><p>The Chogyal rejected the plan, but his worst fears were confirmed. At 12.45pm on 9 April, a platoon of jeeps full of soldiers armed for battle surrounded the palace. A guard in the sentry box was shot dead after he raised his rifle. Inside the palace, the Chogyal called up Gurbachan Singh, the political officer who represented the Indian administration. </p><p>“What the hell are you doing?” he exploded. The line went dead. Indian soldiers had jammed the radio communication, and the palace had been cut off from the outside world.<a href="" onclick="return!1"><sup id="qtrmq27pswjw">[3]</sup></a></p><p>The coup was over in twenty minutes. At the end of it, the Chogyal was placed under house arrest, bringing about the end of a regime that had ruled Sikkim for 333 years. Just over a month later, on 16 May 1975, Sikkim joined the union of India as its twenty-second state.</p></div></div></div></div></section><blockquote data-v-6f86352e=""><div data-v-6f86352e=""> <p data-v-6f86352e="">“What is the Indian obsession with annexing Sikkim?”</p>  </div></blockquote><section data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><!----> <div data-v-58180b62=""><div data-v-58180b62=""><p>
              T
            </p> <div data-v-58180b62=""><p>his year, the forty-fifth anniversary of Sikkim’s statehood passed unremarked. For a generation of young Sikkimese, 16 May is just another public holiday. But recent border clashes between India and China have re-established India’s eastern boundary as one of the world’s great fault lines, and also highlighted Sikkim’s historical role as a centrepiece of the dispute. </p><p>The last time lives were lost in the conflict between India and China was in 1967, the second and “forgotten” war<a href="" onclick="return!1"><sup id="9fjkcvx2znxq">[4]</sup></a> along the border between Sikkim and Tibet.</p></div></div><p>Depending on which side is telling the story, the “Sikkim affair” is variously referred to as an ‘integration’, an ‘annexation’ or a ‘merger’. What we know about it is largely down to three books that differ in the detail about what transpired and why. </p><p>The first was actively suppressed by the Indian state for nearly three decades. Journalist Sunanda Datta-Ray’s book<em> Smash and Grab: The Annexation of Sikkim</em> was published in 1984, but was kept out of circulation with the aid of a defamation suit filed by the government. It was republished in 2014. The book, engrossing in its detail, paints a picture of the Chogyal—a close friend of Dutta-Ray’s—as a lonely bastion, valiantly resisting an expansionist India. </p><p>The Scottish journalist Andrew Duff was initially drawn to Sikkim by reading his grandfather’s account of a trek from Darjeeling to Pemayangtse Monastery in 1922. Duff’s book, S<em>ikkim: Requiem for a Himalayan Kingdom</em>, is largely based on the letters written home by two Scottish principals of a girls’ school in Gangtok.</p><p>In 2018, GBS Sidhu, a retired officer from India’s intelligence agency, the Research and Analysis Wing (R&amp;AW), published <em>Sikkim: Dawn of Democracy </em>(sub-titled “The Truth Behind The Merger With India”). Finally, it publicly owned up to the role played by the agency in Sikkim’s accession to India.</p><p>“What is the Indian obsession with annexing Sikkim?” asked US Secretary of State Henry Kissinger in bewilderment in a staff meeting in Washington when news of the coup reached the world.<a href="" onclick="return!1"><sup id="dgjjygozta6j">[5]</sup></a> It was a naïve question. The answer is inextricably tied to the tumultuous decade of the 1970s when Indira’s India (or India’s Indira) was consolidating its power within and around its borders in the near neighbourhood. It is also tied to the events of the 1960s, particularly the lingering effects of the 1962 war, which in turn was partly triggered by the Dalai Lama’s escape to India. It stretches further back in history to a century of colonial expansionism under British rule that had left Sikkim vulnerable in the first place.</p><p>Sikkim is a tiny, thumb-shaped state wedged between Nepal, Bhutan and Tibet.&nbsp;For centuries, it was the primary route into the two Buddhist kingdoms. When Tibet was occupied in 1950, the expansion of China was brought “almost up to our gates”, as a deeply-worried Sardar Patel wrote to India’s first prime minister, Jawaharlal Nehru.<a href="" onclick="return!1"><sup id="urero0rsaa1s">[6]</sup></a></p><p>The British had made Sikkim a protectorate in 1861, according it the same status as other princely states on the subcontinent. In 1950, three years after independence, Sikkim became a protectorate of the new republic. The kingdom had autonomy in domestic matters but India was responsible for defence, external affairs and communications. For Nehru, Sikkim’s autonomy was nearly sacred. “If we bring a small country like Sikkim within our fold by using force,” he said, “it would be like killing a fly with a bullet.” </p><p>Twenty-five years later, that was no longer the republic’s position. How the change came about is a story with multiple plots involving India’s greatest spymaster, a defiant king, his ambitious political rival, and two enigmatic foreign women. </p></div></div></div></div></section><section data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><div data-v-58180b62=""><p data-v-58180b62=""><header>On Her Majesty’s Secret Service</header></p> <div data-v-58180b62=""><div data-v-58180b62=""><p>
              I
            </p> <div data-v-58180b62=""><p>n December 1972, Indira Gandhi, fresh from victory in the 1971 war for Bangladesh’s liberation, summoned Rameshwar Nath Kao to her office. In 1968, she had handpicked this tall Kashmiri with a formidable intellect to set up the R&amp;AW. In three years’ time, Kao had delivered the agency’s first significant success, providing critical support for the covert training of the guerrilla army Mukti Bahini in what was then East Pakistan. </p><p>“Can you do something about Sikkim?” she asked him. </p></div></div><p>Relations between the Indian state and the kingdom had reached a stalemate. India wanted to create a treaty of Permanent Association, even dangling the carrot of sponsoring Sikkim’s membership to UN organisations in return. But over the 1960s, the Chogyal had been demanding full independence with increasing vigour.&nbsp; </p><p>In the Chogyal’s backyard, the demand for merger with India had originated from the first leader of the Sikkim State Congress,<a href="" onclick="return!1"><sup id="9fqfsawkh439">[7]</sup></a> Tashi Tshering, who had even gone to Delhi in 1948 to negotiate it. Patel, the man in charge of India’s integration, was keen on bringing Sikkim into the fold. Nehru chose to overrule him and sent Tshering back.<a href="" onclick="return!1"><sup id="hop5ace01e8g">[8]</sup></a></p><p>But Nehru’s India kept more than a watchful eye over Sikkim, much like the British had. “The Sikkimese kingdom became highly dependent on the political officers from the time that the British established direct control of Sikkim,” Saul Mullard, a researcher at  Oxford University and author of a book of Sikkimese history, explained. “Indians took over the role of political officers in Sikkim. They inherited the authority of the British and it weakened the ability of the king to set his own agenda.”</p><p>After Indira Gandhi asked him to “do something” about Sikkim, Kao concocted a plan with PN Banerjee, the joint secretary of the R&amp;AW’s eastern division and a fellow mastermind of the Bangladesh operation. He assured the prime minister that the R&amp;AW could handle Sikkim’s merger.<a href="" onclick="return!1"><sup id="fwxp7sqb0kgy">[9]</sup></a> A three-member special ops team was dispatched to Gangtok.</p><p>One of these men was GBS Sidhu, who maintained a meticulous diary of his time in Gangtok. He wrote his book at the prodding of his former boss, who had always been keen for the story of the R&amp;AW’s role in Sikkim to be made public someday. On his passing in 2002, Kao’s own notes on the operations in Sikkim and Bangladesh were handed over to the Nehru Memorial Museum and Library. These will be made public in 2027, according to his will.</p><p>To preserve its reputation as a country that respected the sovereignty of its smaller neighbours, India was keen to legitimize its takeover of Sikkim. It made common cause with the political movement started by Tashi Tshering. India would maintain that the merger was a natural consequence of the peoples’ desire for a democratic form of government. The denouement that came with the coup took more than two years of meticulous planning on the part of the Indian state. </p><p>Like its neighbours Tibet and Bhutan, Sikkim was a conservative Buddhist theocracy. The ruling elite came from two communities: the Bhutia, who migrated from Tibet in the thirteenth century, and the Lepcha, indigenous to Sikkim. The royal family of Namgyals were Bhutia who’d come from Tibet in the sixteenth century. The demographic dynamic of Sikkim started shifting in the late nineteenth century, when Jean Claude White, the first British political officer of Sikkim, began to bring in labour from Nepal to build roads and cultivate land.</p><p>There was another reason why the British encouraged Nepali immigration—to counteract Tibetan influence in Sikkim. There were close religious, cultural and political ties between the two kingdoms. White’s successors tried to undo the policy, but by the early twentieth century, the native population of Bhutia and Lepcha people was already a minority.</p><p>From the 1940s onwards, this, then, was the defining divide in Sikkim’s politics: the tension between its powerful minority and the landless and disenfranchised Nepalis, who had grown to 75 percent of the population by the 1970s. The Chogyal’s inability to provide political representation for the majority of his subjects became his Achilles heel. The R&amp;AW recognized this and surreptitiously worked to exploit it. </p><p>The Sikkim operation helped Kao cement his legacy and strengthen India’s position in relation to China. “It is a fantastic piece of work, handled in a way that it took place under the cover of democracy in process,” the former R&amp;AW officer Rana Banerji, who’s studied the Sikkim papers in the archives of the R&amp;AW’s Kolkata office, told me in a phone interview. “It showed a lot …</p></div></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fiftytwo.in/story/kingdom/">https://fiftytwo.in/story/kingdom/</a></em></p>]]>
            </description>
            <link>https://fiftytwo.in/story/kingdom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978744</guid>
            <pubDate>Tue, 03 Nov 2020 11:47:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing for the Internet Across a Human Lifetime]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24978738">thread link</a>) | @mooreds
<br/>
November 3, 2020 | http://len.falken.ink/misc/writing-for-the-internet-across-a-human-lifetime.txt | <a href="https://web.archive.org/web/*/http://len.falken.ink/misc/writing-for-the-internet-across-a-human-lifetime.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://len.falken.ink/misc/writing-for-the-internet-across-a-human-lifetime.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978738</guid>
            <pubDate>Tue, 03 Nov 2020 11:47:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Computers Were Cool]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24978637">thread link</a>) | @aphrax
<br/>
November 3, 2020 | https://datagubbe.se/coolcomp.html | <a href="https://web.archive.org/web/*/https://datagubbe.se/coolcomp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>
When I was a kid, computers were cool.</p><p>

Nowadays? Not so much.</p><p>

I know, I know. Grumpy old gits are a dime a dozen, and their views about the past are often filtered through a golden haze of blissful forgetfulness and nostalgia. This is of course the case for me, too, but I still think the point is valid: computers used to be much cooler - by orders of magnitude - than they are now.</p><p>

The situation can perhaps be explained by an analogy: You've got a rusty old 1994 FIAT Punto and there is a rather pressing need for you to invest in a new vehicle. Of course, you can dream big - maybe you'd like some kind of armoured personnel carrier, perhaps a souped-up, pimped-out Tesla with all the bells and whistles or why not a Ferrari? Realistically, though, you're probably considering something along the lines of a brand new Ford: the kind of sensible family car that would still be an upgrade to the withering piece of junk you're currently driving. And, as soon as you've amassed enough funds, that's probably what you're going to buy. That APC, though... Man, how sweet would it be to drive one of those? Just thundering through morning traffic, fist pumping in the air, shouting crude insults at that guy with the SUV who always cuts in front of you at the intersection down by the grocery store. Not so smug now, eh, Mr. Sports Utility?</p><p>

That's what it used to be like with computers.</p><p>

Don't get me wrong. You can spend nearly infinite amounts of money on a computer if you'd like to - it's always been like that and probably will be for the foreseeable future. This is especially true for supercomputer clusters used in science and the mainframes keeping the banks and stock markets ticking. But when dreaming about computer power, few of us imagine having access to a behemoth like that. The things we do with our machines can only go faster up to a certain point, unless we dabble in computational biology in our spare time. It would be like replacing our feeble FIAT with an aircraft carrier: sure, it's powerful, but it's not very practical for getting to and from work.</p><p>

No, the computer we dream about having on our desk is usually something a little bit faster, a little bit sleeker and just a little bit more expensive than what we can actually afford. If you're a dedicated games player, there's always the next graphics card, that extra gig of RAM, those extra few frames per second you can chase - but that's still the realistic dreaming, it's something within reach; perhaps not quite in line with a sensible Ford, but not as far out there as an APC.</p><p>

And, even if you are currently dreaming of the home computer equivalent of an APC (let's pretend that's a top of the line Mac Pro, just for the sake of argument), getting one won't make much of a difference in day to day use. Sure, the machine might be faster than your current one, but except for the rare few cases when you actually utilize all that power, it won't provide a profoundly different user experience compared to what an iMac will deliver at a fraction of the cost. It's the same OS, the same applications and the same basic architecture. This is true for Windows and Linux machines as well: you can add more RAM and disk and CPU cores, but the machine won't behave in a significantly different way from what you're used to.</p><p>

Now, when I was a kid... computers were cool.</p><p>

In 1994, I bought a second hand Amiga 1200 with a 120 megabyte hard drive. It was a low cost, capable home computer with good sound and graphics. It was more than enough for the kind of gaming and school work a kid my age wanted to do, but the 14 MHz processor was a tad slow when it came to heavy lifting. Applying just a hint of Gaussian blur to a very low resolution JPEG file took ages. Dabbling in animation, I frequently hit the barrier of the 2 megs of RAM it came with. However, it also had a motherboard connector for adding more memory and a faster CPU. This was the reasonable dream: it was within my reach, it was the sensible family Ford.</p><p>

Thus, in 1995, I got a CPU and RAM upgrade for it, making it roughly four times faster. In those days, that was a pretty hefty upgrade: speeding up from 10 to 40 MPH is more noticeable to a human compared to the difference between the 10000 and 40000 MPH speeds of today's machines. But the speed-up didn't profoundly change my user experience. I was still shuffling about with the same old software and I was still waiting around for that Gaussian blur calculation to finish - although not quite as many minutes as before.</p><p>

As I sat there, watching the Gaussian blur progress bar, I of course dreamt of the computing equivalent of an Armoured Personnel Carrier. It wasn't an Amiga 4000 or a Pentium PC or one of those new-fangled PowerMacs. It was something completely different, something that would have utterly changed my all-round user experience, from boot-up to shutdown. I wanted something the likes of which actually no longer exists: I dreamt of a Unix Workstation.</p><p>

Not just any old Unix box mind you, but a rather specific one: a Silicon Graphics Indy with a 24-bit frame buffer, 128 megabytes of memory and a 175 MHz MIPS R4400 CPU.</p><p>

It was, hands down, just about the most maxed-out piece of hardware that could grace the top of a desk. Design-wise, computers have always been kind of beige - literally and figuratively. Black computers became commonplace some time around, say, 2000, but that was hardly a giant leap in design. Depending on your tastes, you might think companies like Apple or Alienware produce attractive machines - but then again, perhaps you've never seen an SGI Indy.</p><p>

The teal blue pizza box case sports a horizontal, slightly diagonally skewed cut along the middle, shifting the top and bottom parts in a slight offset. The monitor was huge for its time: a 17" CRT cased in grey granite plastic, matching the mouse and keyboard. Both the computer and the screen were adorned with embossed SGI cube logos in a gleaming silver finish. It was over the top, maximalist 1990s more-is-more design in a strangely tasteful package and a far cry from the sleek, subdued designer machines of today. Yet, it wasn't an overstatement - it might've talked the talk, but it sure as hell could walk the walk.</p><p>

For example, it didn't even have a regular floppy drive - it had a bizarre floptical unit capable of storing 20 megabytes on a single, magneto-optical disk. On top of the giant screen a webcam was poised, surely one of the absolutely first computers to come with such a device as standard. In fact, it was called an IndyCam - the term webcam hadn't really caught on yet and was more commonly used to describe just about any camera that regularly uploaded a still image to a public web server.</p><p>

And that, of course, are all trivial oddities compared to the guts of the machine. Even though it was an entry-level workstation, SGI's custom hardware was capable of churning out both 2D and 3D graphics unmatched by any contemporaneous gaming PC, however expensive, and the CPU could run in circles around even the most outrageously-priced Pentium home computer available at the time.</p><p>

And then there was the operating system. And the software.</p><p>

IRIX, SGI's in-house Unix flavour, came with their own proprietary GUI and desktop. It was called Indigo Magic and, featuring things like scalable vector icons, animated desktop backgrounds and visual feedback cues, it was just about as outlandish as the name suggests. It should be noted that this was ten years before any PC owner had gotten the chance to grow tired of such pointless flash and that for the serious hacker, there was always a terminal emulator with a capable shell on hand.</p><p>

Apart from all the usual Unix-related niceties such as stability, pre-emptive multitasking, multi-user support, excellent command line utilities and a bunch of readily available programming languages, it had an impressive array of professional productivity software. Most of it was not available on my home computer, and even if it was, the Indy could run it both faster and in higher resolution. Apart from industry standards such as Photoshop and Netscape, there was a world of curious and wonderful applications written with nothing but SGI hardware in mind: web authoring, video editing, image manipulation and graphics creation unavailable on any other platform. It was a true digital media production workhorse, an overgrown distant cousin to the machines available on the then budding multimedia PC market.</p><p>

In short, it was a cool computer. Far too expensive for any home user, of course. But so. Damn. Cool.</p><p>

There are computers aimed at this kind of work today as well. One of the high-end Macs mentioned before, for example, or perhaps a suitably high-powered Windows machine. In fact, pretty much any dirt cheap home computer will, pixel for pixel, do what the Indy did - except faster, cheaper and in many cases better.</p><p>

Yet there isn't, today, an equivalent of the SGI Indy, or the Sun SPARCstation, or the DEC Alpha, or any of the other professional workstations. The only thing that's on offer is more of the same user experience, only slightly faster.</p><p>

That's why computers are so boring these days. Because even though IRIX, Indigo Magic and the Indy by no means was a perfect solution to all of my computational desires back then, it had the lure of the unknown and unattainable: it was a goal to strive for, a source of inspiration and aspiration and a promise that better things were possible.</p><p>

Today, we all know about the different quirks, mannerisms, privacy issues, drawbacks and occasional benefits of Windows update loops, overpriced Mac hardware and the tiresome fiddliness of Linux. Those are the choices we have and they're not going to change any time soon.</p><p>

I'd somehow be more okay with all of this if it wasn't for the fact that, to top it all off, we have no other platform left to dream of.</p><p>

That's just not cool.
</p></div></div>]]>
            </description>
            <link>https://datagubbe.se/coolcomp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978637</guid>
            <pubDate>Tue, 03 Nov 2020 11:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java Concurrency – Understanding the Executor Framework & Thread Pool Management]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24978557">thread link</a>) | @turkogluc
<br/>
November 3, 2020 | https://turkogluc.com/java-concurrency-executor-services/ | <a href="https://web.archive.org/web/*/https://turkogluc.com/java-concurrency-executor-services/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p>In the previous post, I was writing about the <a href="https://turkogluc.com/java-concurrency-basics-of-threads/">Basics of Threads</a>. This post is going to focus on a higher-level abstraction of thread creation and management.</p><p>Concurrent programs generally run a large number of tasks. Creating thread on demand for each task is not a good approach in terms of performance and usage of the resource as the thread creation and threads itself is very expensive. There is also a limitation for the maximum number of threads a program can create, couple of thousands depending on your machine (this is going to be changed with Project Loom).</p><p>A call center is one of the good example given to illustrate parallelisation; you can have bounded number of customer representatives in the call center and if there will be more customer calling than your employees, customers wait in the queue until one representative will be available to take the next call. So, hiring a new representative on each call would not make sense.</p><p>Therefore it is a better idea to have a thread pool containing a number of threads that would execute the tasks we are sending. Thread pool may create the threads statically (at the time of the creation of the pool), or dynamically (on demand), but it should have a reasonable upper bound. If you like to see a simple thread pool implementation that is queuing the submitted tasks and using the threads from the pool to execute them please check the example in the <a href="https://turkogluc.com/java-concurrency-basics-of-threads/">previous post</a>. </p><p>Using the low-level Thread API is also hard and it requires very much attention each time we need to use it. Java Executor framework helps us in this manner by decoupling the creation and management of the Threads from the rest of the application.</p><p>In the following sections, I will try to explain consecutively, the <code>ExecutorService</code> interface and its methods, implementations of the <code>ExecutorService</code>, and using the factory methods of <code>Executors</code> to simplify creation of <code>ExecutorService</code>.</p><h2 id="the-executor-service">The Executor Service</h2><p>At the heart of the executor framework, there is the <code>Executor</code> interface which has the single <code>execute</code> method:</p><figure><img src="https://turkogluc.com/content/images/2020/11/Screenshot-2020-11-01-at-22.10.39.png"></figure><p><code>ExecutorService</code> is the main interface extending the <code>Executor</code> and we are going to mostly interact with. It is an abstraction around a Thread Pool, and exposes the <code>submit</code> method that we use to send the tasks. It contains a number of threads in its pool depending its implementations which we will see in the following sections.</p><p>When we send the <code>Runnable</code> or <code>Callable</code> tasks by <code>submit</code> method, the threads from the pool are going to run them.</p><ul><li><strong>Runnable</strong>: So far we have mentioned only about runnable, which does not return anything or is not able to throw any exception.</li><li><strong>Callable</strong>: As similar to the Runnable, designed for classes whose<br>instances are potentially executed by another thread<em>,</em> &nbsp;but <em>returns a result</em> and <em>may throw exception</em>.</li></ul><figure><img src="https://turkogluc.com/content/images/2020/11/Screenshot-2020-11-01-at-23.28.44.png"><figcaption>Runnable vs Callable</figcaption></figure><p>Submit method returns a <code>Future</code> object that represents the result of an asynchronous computation. &nbsp;Future has methods to check if the task is complete, to wait for its completion, and to retrieve the result. Its <code>get</code> method returns the result but it is a <strong>blocking method</strong>, so we can postpone calling the get method as long as possible and do other operations. Once we need the result of the task, we call the get method and if the result is not ready the calling thread will be blocked and we need to wait the result. If we can not afford waiting for long time, we can call the method with a <strong>timeout</strong>.</p><figure><img src="https://turkogluc.com/content/images/2020/11/Screenshot-2020-11-01-at-22.55.06.png"><figcaption>Future interface</figcaption></figure><p>The <code>ExecutorService</code> also provides methods for sending collection of tasks all together. We can use <code>invokeAll</code> method to send multiple tasks, and it returns List of Futures. <code>InvokeAny</code> method can be used to run similar tasks, and it returns the fastest answer</p><p>Another important advantage executor service provides is that it has shutdown functionality to stop the pool and the threads. There is an important difference between <code>shutdown</code> and <code>shutdownNow</code> methods:</p><ul><li><strong>shutdown</strong>: Calling this method indicates that no new tasks will be accepted to the queue, and previously sent tasks are going to be waited to complete. Note that if the tasks are long running tasks (infinite loop) they will never complete.</li><li><strong>shutdownNow</strong>: This method interrupts all the active threads, stops the processing of new tasks from the queue and returns the list of those tasks that were waiting in the queue. </li></ul><p>Note that in order to stop the processing, we need to <em>handle the interruption</em> in our <code>Runnable/Callable</code> tasks. Otherwise <code>shutdownNow</code> will trigger interruption but no thread will show reaction to it, and it behaves same as <code>shutdown</code>.</p><p>We can also see the <code>ScheduledExecutorService</code> in the first diagram, as it extends the <code>ExecutorService</code> and provides methods to run scheduled tasks. It is an high-level abstraction for the <code>Timer</code>, and it is easier and better way to run periodic tasks.</p><h2 id="implementations-of-the-executorservice">Implementations of the ExecutorService</h2><p><code>ExecutorService</code> instances are mostly created by using <code>Executors</code> factory methods, and I will show it in the next section. <code>Executors</code> factory methods are easy way to generate Thread Pools, however before using that, I would like to show the important concrete classes that implements the <code>ExecutorService</code>, because the factory method internally retrieves one of these implementations, and I believe it is important to understand the internals. Knowing some of the concrete <code>ExecutorServices</code>, we can create custom pools in case we have specific needs.</p><p>If we look at the following diagram, we have <code>AbstractExecutorService</code> which provides default implementations of <code>submit</code>, <code>invokeAny</code> and <code>InvokeAll</code> methods of the <code>ExecutorService</code>. Concrete implementations overrides some of the implementation details.</p><figure><img src="https://turkogluc.com/content/images/2020/11/Screenshot-2020-11-02-at-17.22.20.png"><figcaption>Implementations of Executor interface</figcaption></figure><h3 id="1-threadpoolexecutor">1- ThreadPoolExecutor</h3><p>The <code>ThreadPoolExecutor</code> is a one of the core implementation of the <code>ExecutorService</code> and it executes each submitted task using one of possibly several pooled threads. This class provides many adjustable parameters and extensibility for configuring and managing the pool. We can configure the following parameters in this class:</p><ul><li><strong>corePoolSize</strong>: minimum number of Threads in the pool.</li><li><strong>maximumPoolSize</strong>: it is self explanatory, the upper bound of pool size. By setting the <code>corePoolSize</code> and <code>maximumPoolSize</code> the same number, we simple create a fixed size pool.</li><li><strong>ThreadFactory</strong>: New threads are created by using a <code>ThreadFactory</code> which is by default <code>Executors#defaultThreadFactory</code> that creates threads to all be in the same <code>ThreadGroup</code>, with the same <code>priority</code> and <code>non-daemon</code> status. If you like to customise it, you can set a different <code>ThreadFactory</code>.</li><li><strong>keepAliveTime</strong>: When the pool has more than minumum number and the threads are idle, exceeding ones are terminated after the <code>keepAliveTime</code>.</li><li><strong>Queue</strong>: A <code>BlockingQueue</code> can be configured to keep the submitted tasks. Example queues and the queueing strategies are as follows:</li></ul><ol><li><code>SynchronousQueue</code>: It is provides a <strong>direct handoff strategy</strong>, which means that tasks are delivered directly to the workers without storing them in a queue. If no threads are available to take the received task, then a new thread will be constructed. If a maximumPoolSize is set and that limit is reached, task will be rejected.</li><li><code>LinkedBlockingQueue</code>: It provides <strong>unbounded queue strategy</strong> which means, using a queue without a predefined capacity. This will cause new tasks to wait in the queue when all corePoolSize threads are busy. So no more than corePoolSize threads will be created and the value of maximumPoolSize does not have any effect.</li><li><code>ArrayBlockingQueue</code>: It provides <strong>bounded queue strategy </strong>which means, using a queue with a predefined capacity. It has a limited space in its queue therefore there should be enough number of threads to consume the tasks rapidly. When the queue is not full tasks are added to the queue. When queue becomes full, and the number of threads are less than maximumPoolSize a new thread is created. Finally when number of threads reaches the limit, the task is rejected.</li></ol><p>We can configure parameters mentioned above at the construction time or later with the setter methods.</p><pre><code>public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue&lt;Runnable&gt; workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
</code></pre><p>Example of running multiple tasks by <code>ThreadPoolExecutor</code>:</p><pre><code>public class Main {

    private static final int CORE_POOL_SIZE = 4;
    private static final int MAX_POOL_SIZE = 4;

    private static final AtomicInteger taskCounter = new AtomicInteger(0);
    private static final ThreadFactory threadFactory = (runnable) -&gt; new Thread(runnable,
        "thread " + taskCounter.incrementAndGet()); // name each thread

    public static void main(String[] args) throws InterruptedException {
        
        ThreadPoolExecutor pool = new ThreadPoolExecutor(CORE_POOL_SIZE,
            MAX_POOL_SIZE,
            0L, // No timeout.
            TimeUnit.MILLISECONDS,
            new LinkedBlockingQueue&lt;&gt;(),
            threadFactory);

        Collection&lt;Callable&lt;Long&gt;&gt; tasks = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; 10; i++) {
            int var = i;
            tasks.add(() -&gt; {
                System.out.println("[" + Thread.currentThread().getName() + "]"
                    + " running the task: " + var);
                return Long.valueOf(var * var);
            });
        }

        List&lt;Future&lt;Long&gt;&gt; futures = pool.invokeAll(tasks);
        futures.forEach(longFuture -&gt; {
            try {
                Long result = longFuture.get();
                System.out.println("Result: " + result);
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (ExecutionException e) {
                e.printStackTrace();
            }
        });

        pool.shutdown();
        pool.awaitTermination(1, TimeUnit.SECONDS);
    }
}</code></pre><p>It would give the following result:</p><pre><code>[thread 4] running the task: 3
[thread 2] running …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turkogluc.com/java-concurrency-executor-services/">https://turkogluc.com/java-concurrency-executor-services/</a></em></p>]]>
            </description>
            <link>https://turkogluc.com/java-concurrency-executor-services/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978557</guid>
            <pubDate>Tue, 03 Nov 2020 11:17:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to test HTTP requests in Elixir with ExVCR]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24978507">thread link</a>) | @szsoppa
<br/>
November 3, 2020 | https://curiosum.dev/blog/test-http-requests-in-elixir-with-exvcr | <a href="https://web.archive.org/web/*/https://curiosum.dev/blog/test-http-requests-in-elixir-with-exvcr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>As your app grows so does its integrations base. At some point, you may need to consume API from third-party services. Today you'll learn how to test them properly with the exvcr library.</p><div>
<h2>Demo app</h2>
<p>To illustrate why testing 3-rd party services is a problem, let's create a simple wrapper within the sample <code>Address Converter</code> app that will return the latitude and longitude of a geographical object. We're going to consume <a href="https://nominatim.openstreetmap.org/" target="_blank">https://nominatim.openstreetmap.org</a> free API for this purpose.</p>
<p>For simplicity, let's assume that the <code>Address Converter</code> app is already created. To interact easily with external API let's use the <code>HTTPoison</code> and <code>Jason</code> libraries.</p>
<p>In mix.exs:</p>
<pre><code><span><span>defp</span> <span>deps</span></span> <span>do</span>
  ...
  {<span>:jason</span>, <span>"~&gt; 1.0"</span>},
  {<span>:httpoison</span>, <span>"~&gt; 1.6"</span>}
  ...
<span>end</span></code></pre>
<p>and after that:</p>
<pre><code>mix deps.<span>get</span></code></pre>
<p>The next step is to implement Nominatim API wrapper. In <code>lib/address_converter/nominatim.ex</code> file, let's add few lines of code:</p>
<pre><code><span><span>defmodule</span> <span>AddressConverter.Nominatim</span></span> <span>do</span>
  <span>@base_url</span> <span>"https://nominatim.openstreetmap.org/search?format=json&amp;q="</span>
  <span>@headers</span> [{<span>"Content-Type"</span>, <span>"application/json"</span>}]

  <span><span>def</span> <span>fetch_coordinates</span></span>(query) <span>do</span>
    <span>with</span> %{ <span>body:</span> body } &lt;- HTTPoison.get!(<span>@base_url</span> &lt;&gt; query, <span>@headers</span>),
         response &lt;- Jason.decode!(body) <span>do</span>
      response
      |&gt; Enum.map(&amp;%{ <span>lat:</span> &amp;<span>1</span>[<span>"lat"</span>], <span>lon:</span> &amp;<span>1</span>[<span>"lon"</span>] })
      |&gt; Enum.at(<span>0</span>)
    else
      <span>_</span> -&gt; %{}
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre>
<p>As you can see we are fetching data from <code>https://nominatim.openstreetmap.org</code> with proper query and JSON Content-Type header to easily interact with a response later on.</p>
<p>Thanks to the <code>Jason</code> library we can decode the returned body and use <code>Enum.map</code> to map each result's latitude and longitude. As <code>nominatim.openstreetmap.org</code> lists all possible geographical places that match the given query, there might a lot of mapped coordinates. For simplicity, let's assume that we only need the first one, and that's exactly why we use <code>Enum.at(0)</code>.</p>
<p>Quick demo of how it works:</p>
<pre><code>iex&gt; AddressConverter.Nominatim.fetch_coordinates(<span>"Poznan, Poland"</span>)
%{<span>lat:</span> <span>"52.4082663"</span>, <span>lon:</span> <span>"16.9335199"</span>}</code></pre>
<h2>Testing external API problem</h2>
<p>As our wrapper is ready to rock the world, we can proceed to the test phase.</p>
<p>In <code>test/address_converter/nominatim_test.exs</code> let's create the following test case scenario:</p>
<pre><code><span><span>defmodule</span> <span>AddressConverter.NominatimTest</span></span> <span>do</span>
  <span>use</span> ExUnit.Case, <span>async:</span> <span>true</span>

  <span>alias</span> AddressConverter.Nominatim

  describe <span>"fetch_coordinates/1"</span> <span>do</span>
    test <span>"for given query it should return proper coordinates"</span> <span>do</span>
      cords = %{<span>lat:</span> <span>"52.4082663"</span>, <span>lon:</span> <span>"16.9335199"</span>}

      assert Nominatim.fetch_coordinates(<span>"Poznan, Poland"</span>) == cords
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre>
<p>It's as easy as checking whether the coordinates match proper values. Let's check it out in action:</p>
<pre><code>$ mix <span>test</span>

.

Finished <span>in</span> 0.4 seconds
1 <span>test</span>, 0 failures</code></pre>
<p><em>Side note: If you want to make sure that our code is making a real HTTP request, turn off the internet connection and run this test once again.</em></p>
<p>Ok, our test works as intended. So what's the problem?</p>
<p>Well, with this solution, <strong>each time we run this test</strong> it's executing a real HTTP request to fetch the data. It's not a good idea, and there are at least five reasons why:</p>
<ul>
<li>request/response cycle might take some time, you don't want to slow down your tests,
</li>
<li>it might not be a free API, you may pay for requests that are being executed during tests,
</li>
<li>some APIs have rate limits,
</li>
<li>you need an internet connection all the time even if you didn't change test and code,
</li>
<li>response for a given request <strong>in most cases</strong> should always be the same (we can mock it).
</li>
</ul>
<h2>Meet exvcr library</h2>
<p>In this case, the solution to our problem is to record the response in a file. We don't have to do it manually, there is a lib for that, and it's called <a href="https://github.com/parroty/exvcr" target="_blank">exvcr</a>.</p>
<p>Let's add this lib to deps:</p>
<pre><code><span><span>defp</span> <span>deps</span></span> <span>do</span>
  ...
  {<span>:exvcr</span>, <span>"~&gt; 0.11"</span>, <span>only:</span> <span>:test</span>}
  ...
<span>end</span></code></pre>
<p>As you can see we're only adding it to test dependencies, as most likely you'll not gonna use it in the dev/prod environment.</p>
<p>Let's fetch our new dependency:</p>
<pre><code>mix deps.get</code></pre>
<p>If you take a look at the documentation, you'll notice that currently <code>exvcr</code> works well with three HTTP clients:</p>
<ul>
<li>hackney,
</li>
<li>httpc,
</li>
<li>ibrowse.
</li>
</ul>
<p>It means that if you're trying to test a code that makes an HTTP request using one of these clients under the hood then you're good to go. In our case, we're using <code>HTTPoison</code> which is built on top of <code>Hackney</code>.</p>
<p>Here is an updated test code that takes leverage of <code>exvcr</code>:</p>
<pre><code><span><span>defmodule</span> <span>AddressConverter.NominatimTest</span></span> <span>do</span>
  <span>use</span> ExUnit.Case, <span>async:</span> <span>true</span>
  <span>use</span> ExVCR.Mock, <span>adapter:</span> ExVCR.Adapter.Hackney

  <span>alias</span> AddressConverter.Nominatim

  setup <span>do</span>
    ExVCR.Config.cassette_library_dir(<span>"fixture/vcr_cassettes"</span>)
    <span>:ok</span>
  <span>end</span>

  describe <span>"fetch_coordinates/1"</span> <span>do</span>
    test <span>"for given query it should return proper coordinates"</span> <span>do</span>
      use_cassette <span>"nominatim"</span> <span>do</span>
        response = %{<span>lat:</span> <span>"52.4082663"</span>, <span>lon:</span> <span>"16.9335199"</span>}

        assert Nominatim.fetch_coordinates(<span>"Poznan, Poland"</span>) == response
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre>
<p>Let's break it down.</p>
<p>First, we use the <code>ExVCR.Mock</code> module with a proper adapter. As already mentioned, <code>HTTPoison</code> uses <code>Hackney</code> under the hood:</p>
<pre><code><span>use</span> ExVCR.Mock, <span>adapter:</span> ExVCR.Adapter.Hackney</code></pre>
<p>Next, we need to configure <code>ExVCR</code> cassettes path:</p>
<pre><code>setup <span>do</span>
  ExVCR.Config.cassette_library_dir(<span>"fixture/vcr_cassettes"</span>)
  <span>:ok</span>
<span>end</span></code></pre>
<p>Once we run the test, it'll create a file with recorded HTTP request/response data and save it in the <code>fixture/vcr_cassettes</code> folder. Can we choose the name for this file? We can, and that's exactly what happens here:</p>
<pre><code>use_cassette <span>"nominatim"</span> <span>do</span>
  ...
<span>end</span></code></pre>
<p><code>use_cassette</code> wraps the block of code to ensure that all HTTP requests and responses will be saved into the <code>nominatim</code> file cassette.</p>
<p>Ok, since we're now familiar with <code>ExVCR</code> and how it can be used within a test case scenario let's run our test:</p>
<pre><code>$ mix <span>test</span>

.

Finished <span>in</span> 0.7 seconds
1 <span>test</span>, 0 failures</code></pre>
<p>It works! As you should notice, there is a new file in your repo - <code>fixture/vcr_cassettes/nominatim.json</code>:</p>
<pre><code>[
  {
    <span>"request"</span>: {
      <span>"body"</span>: <span>""</span>,
      <span>"headers"</span>: {
        <span>"Content-Type"</span>: <span>"application/json"</span>
      },
      <span>"method"</span>: <span>"get"</span>,
      <span>"options"</span>: [],
      <span>"request_body"</span>: <span>""</span>,
      <span>"url"</span>: <span>"https://nominatim.openstreetmap.org/search?format=json&amp;q=Poznan, Poland"</span>
    },
    <span>"response"</span>: {
      <span>"binary"</span>: <span>false</span>,
      <span>"body"</span>: ..., // The body is a bit long to paste it here
      <span>"headers"</span>: {
        <span>"Server"</span>: <span>"nginx"</span>,
        <span>"Date"</span>: <span>"Thu, 29 Oct 2020 17:51:44 GMT"</span>,
        <span>"Content-Type"</span>: <span>"application/json; charset=UTF-8"</span>,
        <span>"Transfer-Encoding"</span>: <span>"chunked"</span>,
        <span>"Connection"</span>: <span>"keep-alive"</span>,
        <span>"Keep-Alive"</span>: <span>"timeout=20"</span>,
        <span>"Access-Control-Allow-Origin"</span>: <span>"*"</span>,
        <span>"Access-Control-Allow-Methods"</span>: <span>"OPTIONS,GET"</span>
      },
      <span>"status_code"</span>: <span>200</span>,
      <span>"type"</span>: <span>"ok"</span>
    }
  }
]</code></pre>
<p>In the end, <code>ExVCR</code> runs a real HTTP request to save request and response data, and then when you run the test again, it's trying to match the pattern of request to deliver response without performing HTTP request again. If it finds a match, it returns a saved response. If there is no match, again, a real HTTP request will be performed to save data into a cassette file.</p>
<p>To make sure that our test doesn't depend on internet connection anymore (so there is no real HTTP request), let's turn it off and run our test once again:</p>
<pre><code>$ mix <span>test</span>

.

Finished <span>in</span> 0.7 seconds
1 <span>test</span>, 0 failures</code></pre>
<p>Great! This is how you can improve tests that depend on external services with the <code>ExVCR</code> cassette mechanism. There is more configuration stuff in this library, as well as little details that you may want to use. Makes sure to check the <a href="https://github.com/parroty/exvcr" target="_blank">documentation</a>.</p>
      </div></div>]]>
            </description>
            <link>https://curiosum.dev/blog/test-http-requests-in-elixir-with-exvcr</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978507</guid>
            <pubDate>Tue, 03 Nov 2020 11:09:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Model of Small Decisions]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24978356">thread link</a>) | @SerCe
<br/>
November 3, 2020 | https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/ | <a href="https://web.archive.org/web/*/https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p><img src="https://ahitrin.github.io/images/a-model-of-small-decisions/forest.jpg" alt="a dence forest">
<small>Would you like to walk here at night? Photo: Andrey Hitrin</small></p>

<p>Sometimes thoughts of our human nature makes me sad.
Our attempts to share own thoughts to others can be compared with attempts to find a way out from the dense forest during a moonless night aimed only with a laser pointer.
The only thing you could show to others is a little spot of light randomly jumping back and forth, appearing and disappearing spontaneously.
How could you find a trail with such a weak tool?
How could you convince your party to follow it?
How could you understand if this trail should take you out of the forest?</p>

<p>That’s why people try to invent new and new words to explain same conceptions.
Everyone hopes that his/her explanations will be good enough to make other understand “the inner nature of things”.
Most of the time it’s worthless: others don’t see more than chaotically jumping light spot.</p>

<p>Nevertheless, here is my own attempt.
Words written here are not the truth, they are nothing more than my biased reflection of it, based on my limited experience.
I don’t know if they are contains some wisdom, or just a bunch of useless commonplace.
That’s you who will judge.</p>

<h2 id="the-quest-for-mastery">The quest for mastery</h2>

<p>As usual, I want to speak about programming.</p>

<p>There is an idea that programming has many similarities with martial arts or musical performing.
In all of these areas you could show some results after relatively little amount of practice, but it requires years of studying and training if you want to achieve truly significant level.
Often you even have to perform at the edge of your own abilities.</p>

<p>And when you want to perform at such level, you must be aware of all aspects of your profession.
Today I want to speak about small and often invisible decisions that guide you through your everyday work.</p>

<h2 id="small-decisions">Small decisions</h2>

<p>In our job, you need to do a lot of small decisions every day.
Just watch after yourself during work process, and soon you will be able to notice them.</p>

<p>Imagine you’ve just started to work on some feature.
Small decisions appear instantly.
How will you start you work?
By reading documentation, or by checking code out, or by asking your colleagues?
Change some code first, or think about test cases?
Implement straightforward change, or roll out few refactorings beforehand?</p>

<p>How will you deal with “bad code” challenging your way: ignore it, or try to fix right now, or defer a fix for a “better time”?
How will you act when feeling struck: ask your teammate (and which one, when you have several of them), google your problem, stackoverflow it?
Or maybe simply wait until an answer forms inside your head (also known as ‘procrastinating’)?
Or maybe wait until someone asks you about the progress?</p>

<p>That’s what I mean by the “small decisions” term.
A lot (tens, or even hundreds per day) micro-choices you make in your work.
Sometimes you make this choice consciously, but often not!
You choose your path without even thinking about it, without even noticing the fact of choosing.</p>

<p>Does this matter?
I think it does.</p>

<h2 id="choosemove-dichotomy">Choose/move dichotomy</h2>

<p>Let’s draw your way through the imaginary “work task”.
I like to draw graphs, so it’s depicted as a graph.</p>

<p><img src="https://ahitrin.github.io/images/a-model-of-small-decisions/01_a_to_b.jpg" alt="one way from Start to Goal"></p>

<p>Every node here is a small choice you’ve made.
Arrows represent the “movement” between them.
A number of intermediate steps is arbitrary and depends on your own definition of “small decision”.
When you zoom out, they almost disappear.
When you zoom in, a single decision could be even as small as “<em>which finger should hit the given keyboard button?</em>”.
Here I choose something intermediate.</p>

<p>And now let’s imagine more possible moves that also could solve your task.</p>

<p><img src="https://ahitrin.github.io/images/a-model-of-small-decisions/02_a_to_b.jpg" alt="many ways from Start to Goal"></p>

<p>Here we see a whole net of possible decisions.
What would happen if you choose another step at the start?
Some of alternative ways could be shorter (containing less hops), some of them could be much, much longer!
Of course, here I simplify the problem <strong>a lot</strong>.
But I need this simplification to show you few important things.
Here are following key points:</p>

<ol>
  <li>
    <p><strong>You have to make a lot of decisions</strong>.
There are points in almost every task that requires your decision.
For example, you need to ask yourself at least once: “<em>have I reached my goal?</em>”.
And then either get done with it or continue to work.</p>
  </li>
  <li>
    <p><strong>Even small decisions may have big impact</strong>.
When you choose the wrong path at start, it may lead you far away from the goal.
You have to move along the non-optimal path or return back to the start.</p>
  </li>
  <li>
    <p><strong>Every decision takes your time and energy</strong>.
Usually delay on decision come from one of two or three sources.
The first source is <strong>delay between a question and an answer</strong>.
Say you’re struck and don’t know where to move next.
You try to ask your colleague via IM for help.
But currently he/she is busy, and only can answer you in 20 minutes.
This delay is the cost of your decision.
The second source is <strong>delay on choosing</strong> by itself.
It may happen when you see two or more alternative paths and hesitate which one should be followed on (maybe a “frustration” word is suitable here).
The third one is <strong>a need to remember</strong> a known, but currently forgotten solution (more on this in the next chapter).</p>
  </li>
</ol>

<p>All of these make me conclude that it’s important to consider the impact of decision making to our work.
Low-quality decisions reduce your productivity <em>every day</em>.
They make you stray in the dark without help.</p>

<p>Surprisingly, even after reading a lot of books and articles on programmer’s productivity, I haven’t found enough much attention to this theme (please correct me if I’m wrong!).
That’s the main reason why I’ve started to write this article.</p>

<h2 id="a-table-of-decision-rules">A table of decision rules</h2>

<p>OK, maybe quality of decisions is important.
But how could we ever manage them?
Here I suggest a simple <em>model</em>.
As any other model, it doesn’t describe things as they are, but uses simpler (and more manageable) view on it instead.
The main power of modeling is its ability to predict effects of our actions, but we should never forget about its boundaries.
Outside boundaries, our model will be wrong - and I don’t know where they are.
I sincerely hope that your feedback could help determine them.</p>

<p>The model is heavily inspired by the work [1].
Think for a minute: this paper is already 40 years old!
Why no one still haven’t developed it into the similar direction as I did?
I don’t know (or maybe I’m just wrong - please let me know in that case).</p>

<p>This prelude was necessary - but now let’s proceed to the model.
So, suppose each of us have some kind of <em>table</em> in the head (I warned you, it’s a simplified view).
It contains two columns:</p>

<ol>
  <li>
    <p><strong>Trigger</strong>.
An external stimulus that could activate current “table row” or <em>rule</em>.
For example: a piece of code you’re looking at; a letter from CI server; a message from your colleague; your current thoughts about your task; and so on.</p>
  </li>
  <li>
    <p><strong>Acton</strong>.
A thing you do when the <em>rule</em> is being activated.</p>
  </li>
</ol>

<p>It may look like this:</p>

<table>
<colgroup>
<col width="35%">
<col width="5%">
<col width="60%">
</colgroup>
<thead>
<tr>
<th>Trigger</th>
<th></th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td>You need to find the source of a bug</td>
<td>→</td>
<td>Run <code>git bisect</code> to find a commit where it was introduced. Then analyse the code</td>
</tr>
<tr>
<td>You want to check if your code is ready to deploy</td>
<td>→</td>
<td>Push changes to remote repository and run CI service</td>
</tr>
<tr>
<td>You want to check if your code is ready to deploy</td>
<td>→</td>
<td>Push changes to remote repository and ask someone to review it</td>
</tr>
<tr>
<td>You have detected the "smell of ugly code"</td>
<td>→</td>
<td>Try to refactor it out immediately</td>
</tr>
<tr>
<td>You have detected the "smell of ugly code"</td>
<td>→</td>
<td>Ignore it: we don't have time to refactor</td>
</tr>
<tr>
<td>Selenium test on CI server has failed</td>
<td>→</td>
<td>Look at screenshot to check where is the problem</td>
</tr>
<tr>
<td>Selenium test on CI server has failed</td>
<td>→</td>
<td>Look at job logs</td>
</tr>
<tr>
<td>Selenium test on Ci server has failed</td>
<td>→</td>
<td>Launch that job again: maybe it's just flaky test?</td>
</tr>
<tr>
<td>You're struck and don't know what to do next</td>
<td>→</td>
<td>Ask your teammates for help</td>
</tr>
<tr>
<td>You're struck and don't know what to do next</td>
<td>→</td>
<td>Wait until someone asks you what's going on</td>
</tr>
<tr>
<td>...</td>
<td>→</td>
<td>...</td>
</tr>
</tbody>
</table>

<p>This table has important properties:</p>

<ol>
  <li>
    <p>It <strong>changes over time</strong>, depending on your own experience and knowledge.
When you discover new tricks, they have a chance to hold in the table.
In other hand, even the best practices without repetition pass away from your memory.
Of course, they do not always being erased completely.
Rather, they are removed from “the cache”, the fastest part of your memory.
And you’ll have to make an effort of remembering to bring it back.</p>
  </li>
  <li>
    <p>It has <strong>limited size</strong>.
You cannot know literally everything.
You cannot have the best solution for every possible situation you may face.</p>
  </li>
  <li>
    <p>It may have <strong>several rules for one situation</strong>.
In that case your final choice may depend on current context.
Sometimes you may even need to spend additional time and effort to make a choice between alternative actions (“resolve a conflict”).</p>
  </li>
  <li>
    <p>It models <strong>only small decisions</strong>.
Only little choices that often even pass your spotlight and perform automatically could be modelled that way.
In terms of “Thinking, Fast and Slow” [2], it relies to the “System 1” only.</p>
  </li>
</ol>

<p>There could be different sources where these rules come from:</p>

<ul>
  <li>Your previous successful and unsuccessful experience.</li>
  <li>Observations of your teammates: how do they behave in different situations.</li>
  <li>Direct rules of the project you’re working on (like “use <code>./gradlew check</code> to verify correctness of your code”).</li>
</ul>

<p>I hope to write more on it in following articles, but the current one has grown big enough.
Seems like I have to go to conclusions.</p>

<h2 id="any-benefits">Any benefits?</h2>

<p>What benefits could the awareness about these rules bring to you?</p>

<p>First of all, you should take into consideration the limited size of your memory.
In order to make better decisions, you need to consciously “tune” your rule table.
How could it be done?</p>

<ul>
  <li>
    <p><strong>Remember your good (effective) decision rules</strong>.
Practice them from time to time so they don’t leave your working memory.
Write them down in known place so they could be remembered effectively when needed.</p>
  </li>
  <li>
    <p>Try to <strong>free your memory from unneeded decision rules</strong>.
If they aren’t needed, forget them.
If they still may be useful, keep them in an external place.
For example, imagine you have a complex …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/">https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/</a></em></p>]]>
            </description>
            <link>https://ahitrin.github.io/work/2020/11/03/a-model-of-small-decisions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978356</guid>
            <pubDate>Tue, 03 Nov 2020 10:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Track only when it makes sense – how I conditionally include Adwords tracking]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24978242">thread link</a>) | @ValCanBuild
<br/>
November 3, 2020 | https://www.valcanbuild.tech/conditional-adwords-tracking/ | <a href="https://web.archive.org/web/*/https://www.valcanbuild.tech/conditional-adwords-tracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I believe in people's right to privacy. I believe we shouldn't be needlessly tracked all over the web by big tech companies. At the same time, I am trying to run an online business. This means that if I want to be successful, I would have to at least partially play ball with the tech giants.</p><h2 id="the-challenge">The challenge </h2><p>My latest challenge on this front was search ad conversion tracking. After trying out a few different acquisition channels for my product, <a href="https://thankbox.co/">Thankbox</a>, I noticed that search ads work really well. I set up both Microsoft Bing and Google Adwords and started seeing a steady stream of new users. For this article, I'll focus on Adwords.</p><p>Adwords has a conversion tracking feature which lets you track which keywords "convert" best. In my case, I wanted to track which keywords resulted in a user actually signing up and creating a Thankbox. </p><p>In order to do that, I'd have to add Google's trackers to my website. This is some JS code that they encourage you to add to the <code>&lt;head&gt;</code> tag of <strong>every page in your website.</strong> Here is an extract from Google's instructions, which uses their Google Tag Manager for this.</p><figure><img src="https://www.valcanbuild.tech/content/images/2020/11/CleanShot-2020-11-02-at-15.53.42@2x.png" alt="" srcset="https://www.valcanbuild.tech/content/images/size/w600/2020/11/CleanShot-2020-11-02-at-15.53.42@2x.png 600w, https://www.valcanbuild.tech/content/images/size/w1000/2020/11/CleanShot-2020-11-02-at-15.53.42@2x.png 1000w, https://www.valcanbuild.tech/content/images/2020/11/CleanShot-2020-11-02-at-15.53.42@2x.png 1492w" sizes="(min-width: 720px) 720px"></figure><p>I cringed when I read that. I take pride in not having polluted my website with trackers but now I was fighting with what seems to be good business sense - knowing where your customers come from.</p><h2 id="do-they-really-need-to-track-every-page">Do they really need to track every page?</h2><p>After a bit of thought I realised that there's no way, from a functional standpoint, for Google to need this script installed on every page. Surely for tracking a conversion you just need it on the pages involved in the steps. For me, that was actually just two pages for the four step process.</p><p><strong>Adwords click -&gt; Landing page -&gt; Create Thankbox page -&gt; Create a Thankbox finished (conversion)</strong></p><p>It seemed to me that I only needed to install this on my Landing page and the "Create Thankbox" page. </p><p>That's already a win but not a big one - my landing page is (naturally) my most visited page so <strong>I'd still be exposing all visitors to a script</strong> <strong>intended to be used only for people coming off search ads</strong>.</p><p>💡 That's when a lightbulb turned on.</p><h2 id="do-they-really-need-to-track-every-user">Do they really need to track every user?</h2><p>No - they don't! I certainly didn't want to. </p><p>I realized that the most responsible thing to do in this case would be to <strong>only track users who arrive from Adwords</strong>. Only those people would get the script included. </p><h2 id="knowing-who-to-track-using-refs">Knowing who to track - using refs</h2><p>In order to only load the script conditionally I had to be able to discern the users that came from Adwords from everyone else. The easiest way to do that was to just add a <code>?ref</code> parameter to the ad, since Google are totally OK with you doing that. <code>utm_source</code> would have also worked here. </p><figure><img src="https://www.valcanbuild.tech/content/images/2020/11/image-1.png" alt="" srcset="https://www.valcanbuild.tech/content/images/size/w600/2020/11/image-1.png 600w, https://www.valcanbuild.tech/content/images/2020/11/image-1.png 912w" sizes="(min-width: 720px) 720px"></figure><p>Thankbox runs on Laravel and using the Laravel blade components (server side rendering) it was really easy for me to conditonally add the tracker only if the ref contained the word "Google". I include this in both my landing and Create Thankbox pages. </p><pre><code>&lt;head&gt;
    @if(str_contains(request()-&gt;query('ref'), 'Google'))
        @include('partials.scripts.adwords-tracker')
		@include('partials.scripts.cookie-consent')
    @endif
&lt;/head&gt;</code></pre><p>Then I had to make sure to pass this ref to my Create Thankbox page. I do that by modifying the <code>href</code> link of the Create <code>&lt;a&gt;</code> tag &nbsp;if there is a ref in the request.</p><pre><code>@php
$create_link = '/app/thankbox/create';
$ref = request()-&gt;query('ref');
if ($ref) {
    $create_link .= '?ref=' . $ref;
}
@endphp

&lt;a href="{{ $create_link }}"&gt;Create a Thankbox&lt;/a&gt;</code></pre><p>Here is an image that shows what happens:</p><figure><img src="https://www.valcanbuild.tech/content/images/2020/11/TrackMeSteps-2.png" alt="" srcset="https://www.valcanbuild.tech/content/images/size/w600/2020/11/TrackMeSteps-2.png 600w, https://www.valcanbuild.tech/content/images/size/w1000/2020/11/TrackMeSteps-2.png 1000w, https://www.valcanbuild.tech/content/images/size/w1600/2020/11/TrackMeSteps-2.png 1600w, https://www.valcanbuild.tech/content/images/size/w2400/2020/11/TrackMeSteps-2.png 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>The final step was to actually attribute the Thankbox creation. That was as simple as just checking if <code>gtag</code> (Google Tag Manager) exists and calling it once the form is submitted.</p><pre><code>if (typeof gtag === 'function') {
    gtag('event', 'conversion', {})
}</code></pre><h2 id="privacy-minded">Privacy minded</h2><p>That's it! With some extra thought and a little bit of extra effort I was able to keep tracker scripts from taking over my whole website. I've contained them just to the places I need them.</p><p>As an added bonus to this work it means that I only have to show a cookie notice to those tracked users, not everyone. This is because my normal landing page has no trackers that require one to be shown. When it comes to website analytics I didn't go with the web standard Google Analytics. Instead, I went with <a href="https://usefathom.com/ref/WRPOFE">Fathom Analytics</a> - a privacy focused alternative. It is GDPR-friendly and doesn't require a cookie prompt.</p><p>For easy cookie &amp; privacy notice management I ended up using <a href="http://iubenda.refr.cc/N3BCKCN">Iubenda</a>, which was recommended by a fellow founder.</p>
		</div></div>]]>
            </description>
            <link>https://www.valcanbuild.tech/conditional-adwords-tracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978242</guid>
            <pubDate>Tue, 03 Nov 2020 10:26:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[[Deleted]]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24978225">thread link</a>) | @midef
<br/>
November 3, 2020 | https://www.superhighway98.com/nvidia | <a href="https://web.archive.org/web/*/https://www.superhighway98.com/nvidia">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-310d23d06aadf10082e8"><div><p>If you work in technology, you've probably seen "<a href="https://thispersondoesnotexist.com/">This Person Does Not Exist</a>.” It's a simple web interface that uses AI to generate human faces. It's also the tool that is used routinely to fool journalists into quoting sources who don't exist.</p><h2><strong>Meet the team</strong></h2></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604325790588_13792"><div><p>The screenshot above is taken from the masthead of a fast-growing affiliate website (i.e. a website that earns money by referring customers to make purchases on another website).</p><p>These seem like real people at first glance, but they aren't. Someone who is familiar with generative adversarial networks can spot the “tells” that give the technology away. For example, look at the distorted backgrounds and mismatched earrings. </p><p>These so-called "experts" might not exist, but the spammers behind them were able to fool reporters at legitimate publications like New York Magazine, Woman's Day, Business.com, Inverse, Reader's Digest, Lifehacker, The Simple Dollar, Score, Fatherly, Legal Zoom, Business News Daily and Cheapism.</p><p>On top of that, the stories that quoted these non-existent people were about topics like parenting, mental health and COVID-19.</p><h2><strong>Help a reporter out</strong></h2><p>When a reporter is writing a story that requires a source that he or she does not have, that reporter will likely turn to <a href="https://www.helpareporter.com/">HARO</a>, a service that "connects journalists seeking expertise to include in their content with sources who have that expertise." </p><p>It's no secret that <a href="https://www.superhighway98.com/seo">search engine optimization specialists</a> use the service to build links to content that profits them, but the rise of "deepfake" technology has made it easier than ever to exploit overworked and undertrained reporters who are <a href="https://www.superhighway98.com/google">hungry for clicks</a>.</p><p>Now, shady “SEOs” hide behind fake photos and personalities.</p><h2><strong>The “woman behind Superhighway 98”</strong></h2></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604325790588_27439"><div><p>I'm a caucasian male, but there is nothing (<a href="https://www.superhighway98.com/politics">other than my own morals</a>) to stop me from pretending that this website is published by a woman of color. The photo above isn’t real, but it’s real enough to fool a journalist on a deadline. To combat this fraud, newsrooms must quickly adopt new methods for verifying sources.</p><h2><strong>Trust, but verify</strong></h2><p>GAN renderings are realistic and those that are retouched in Photoshop are nearly perfect, but they are not readily extensible (yet). The upshot: Always ask for two photographs of your source.</p><p>Take those photographs and plug them into a reverse image lookup service like <a href="https://tineye.com/">Tineye</a> (or even Google Images). Have they appeared on the web before? Does the context make sense?</p><p>Ask for links to social media profiles. How long have the accounts been active? Do they tell a consistent story?</p><p>Deepfake technology will only get more advanced and prevalent. To rely on Big Tech to solve this problem is like relying on Big Tobacco to cure cancer. It’s up to each of us to fight for the truth.</p><p>###</p><p><a href="https://www.superhighway98.com/">&lt;- RETURN TO SUPERHIGHWAY 98</a></p></div></div></div>]]>
            </description>
            <link>https://www.superhighway98.com/nvidia</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978225</guid>
            <pubDate>Tue, 03 Nov 2020 10:21:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My game won't sell and that's ok]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24978084">thread link</a>) | @chr15m
<br/>
November 3, 2020 | https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok | <a href="https://web.archive.org/web/*/https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="game_devlog_post_page_93823"><div><div><section id="video_embed_widget_44081"><iframe frameborder="0" allowfullscreen="" src="//www.youtube.com/embed/7efdmAJAUVY"></iframe></section><section><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzYuZ2lm/original/HaqSXO.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzYuZ2lm/x200/lnOYDd.gif" data-image_id="4488836" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0OTMzNDguZ2lm/original/0NaSBi.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0OTMzNDguZ2lm/x200/ZLnRgb.gif" data-image_id="4493348" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0NDAxMDAuZ2lm/original/kTd%2Bi3.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0NDAxMDAuZ2lm/x200/kCBUJY.gif" data-image_id="4440100" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzUuZ2lm/original/tRRdDT.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzUuZ2lm/x200/bwgJDH.gif" data-image_id="4488835" height="200"></a></section><section><p>I discovered Nethack and Rogue some 25 years ago and ever since then I have wanted to make my own roguelike game. On Friday I followed through on that youthful dream and shipped Asterogue, yay!</p>
<p>This game won’t sell. I have been around the indie games scene long enough to know its a crap-shoot. To make a successful indie game you have to execute at peak performance, do everything right, and then you still roll the dice on success. I’ve seen stone cold geniuses build glorious works of art and watch them get zero downloads. A single tear rolls down their cheek one week after launch and tiny pixellated violins play a chiptune version of Mozart’s Requiem.</p>
<p>My game won’t sell and that’s ok. I am at peace with it after all of these years of game jams and side projects. It is the way of things. I’m just happy to have had the chance to fulfill this dream.</p>
<p>I had so much fun making Asterogue. I’ve never worked harder on a side project. I publically committed to an October 30th release, and I’ve done it. I built the thing I dreamed of making since I was a kid, and I am simply grateful to the universe that this opportunity was within my reach.</p>
<p>I want to thank the people who took a chance and bought the game. It’s amazing to me that our tiny club of people who like this kind of game has more than one member. You guys rock!</p>
<p>I also want to thank from the bottom of my heart the people who tested the game and gave me feedback. It’s an honor when somebody is willing to sacrifice their time to try out something you built, and I really appreciate it. It’s your feedback that made this the best possible game I could make in the time allocated. Thank you.</p>
</section><section><h2>Get Asterogue</h2></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978084</guid>
            <pubDate>Tue, 03 Nov 2020 09:50:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Math Keeps Changing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24978027">thread link</a>) | @vonadz
<br/>
November 3, 2020 | https://macwright.com/2020/02/14/math-keeps-changing.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/02/14/math-keeps-changing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This is a written version of a talk that I gave at <a href="https://wafflejs.com/">WaffleJS</a> in February, which itself was an expansion of a <a href="https://twitter.com/tmcw/status/1187782634623000576">Twitter conversation</a> from October.</em></p><p><picture><source srcset="https://macwright.com/images/2020-02-14-math-keeps-changing-math-education.webp" type="image/webp"><img alt="Math education" src="https://macwright.com/images/2020-02-14-math-keeps-changing-math-education.jpg"></picture></p><p>Okay, so it starts with my delayed math education. As part of my Computer Science program, I had access to world-class math professors, access that I mostly wasted. I didn’t like math: the topics were so removed from practice, and I was already frustrated by the highly theoretical, and – I thought at the time and mostly still do – out-of-touch CS program.</p><p>Unfortunately, a few years after graduating, I got the hunger for math. Seeing how I could apply just a little bit of math knowledge to great effect in my work &amp; hobbies had me inspired. But I had no clear way of learning it.</p><p>So I <a href="https://macwright.com/2012/06/26/simple-statistics.html">started Simple Statistics in 2012</a> as a way to learn math, and ever since then, I’ve expanded and maintained the project. It now includes a lot of different algorithms, is one of the most ‘starred’ JavaScript math projects, and presumably is used by people.</p><p>But I started it in 2012. In tech years that’s a really long time ago. Between then and now, there have been 8 LTS releases of <a href="https://nodejs.org/en/">Node</a>. JavaScript and its environments have radically changed. 2012 was before the introduction of React or the first commit to Babel.</p><p><picture><source srcset="https://macwright.com/images/2020-02-14-math-keeps-changing-time-passing.webp" type="image/webp"><img alt="Time passing" src="https://macwright.com/images/2020-02-14-math-keeps-changing-time-passing.jpg"></picture></p><p>So what I noticed over the years was that tests kept breaking when I updated Node. I’d have a test like:</p><div><div><pre><code><span>t</span><span>.</span><span>equal</span><span>(</span><span>ss</span><span>.</span><span>gamma</span><span>(</span><span>11.54</span><span>),</span> <span>13098426.039156161</span><span>);</span>
</code></pre></div></div><p>That would work in Node v10 and break in Node v12. And this is not some complex method: gamma is implemented with arithmetic, Math.pow, Math.sqrt, and Math.sin.</p><h3 id="arithmetic">Arithmetic</h3><p>So I know what you might be thinking: arithmetic. JavaScript, on Twitter, gets a lot of heat for this behavior:</p><div><div><pre><code>0.1 + 0.2 = 0.30000000000000004
</code></pre></div></div><p>As I wrote in <a href="https://macwright.com/2017/07/29/javascript-wats-dissected.html#numbers-are-weird">JavaScript wats, dissected</a>, this is the behavior of every popular programming language, even stodgy pedantic ones like Haskell. Floating point arithmetic might be weird, but it’s very consistent and well-specified: the <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> specification is rigorously implemented. So it’s not arithmetic: addition, subtraction, division, and multiplication are pretty set in stone.</p><h3 id="math">Math</h3><p>What it was, was Math. In particular, all of <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math">the methods that come after <code>Math.</code></a></p><p>Methods like Math.sin, Math.cos, Math.exp, Math.pow, Math.tan: <a href="https://macwright.com/2013/03/05/math-for-pictures.html">essential ingredients for geometry</a> and basic computation. I started isolating changes in basic function behavior between versions. For example:</p><p>Calculating Math.tanh(0.1)</p><div><div><pre><code>// Node 4
0.09966799462495590234
// Node 6
0.09966799462495581907
</code></pre></div></div><p>Calculating Math.pow(1/3, 3)</p><div><div><pre><code>// Node 10
0.03703703703703703498
// Node 12
0.03703703703703702804
</code></pre></div></div><p>To make matters worse, it’s not just Node’s behavior that’s changing: so are browsers and other places you use JavaScript.</p><p>So this led to the question: <strong>what is math?</strong></p><svg fill="none" viewBox="0 0 1105 572" width="100%" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h1105v572H0z" fill="#fff"></path><path d="M551.933 460.719c92.311 0 167.143-74.833 167.143-167.143 0-92.311-74.832-167.143-167.143-167.143-92.31 0-167.143 74.832-167.143 167.143 0 92.31 74.833 167.143 167.143 167.143z" stroke="#000" stroke-width="3" stroke-linecap="round"></path><path d="M573.104 247.619a50.608 50.608 0 0129.506 45.71l-50.607.288 21.101-45.998z" fill="#fff"></path><path d="M551.933 478.638V93" stroke="#000" stroke-width="3"></path><path d="M573.104 247.619a50.608 50.608 0 0129.506 45.71" stroke="#000" stroke-width="3.58" stroke-linecap="round"></path><path d="M356 294.18h393.984m-197.951-1.075l69.694-151.216" stroke="#000" stroke-width="3"></path><path d="M621.601 142.175V293.47" stroke="#000" stroke-width="5" stroke-linecap="round" stroke-opacity=".941"></path><path d="M552.842 293.576h68.763" stroke="#000" stroke-width="5" stroke-linecap="round"></path><path d="M621.768 145.349a3 3 0 100-6 3 3 0 000 6zm-31.76 38.227h-2.498V167.02l-5.008 1.839v-2.256l7.116-2.672h.39v19.645zm-6.801 91.04c0 2.873-.528 5.071-1.584 6.593-1.057 1.513-2.583 2.269-4.579 2.269-1.961 0-3.474-.743-4.539-2.229-1.065-1.486-1.616-3.607-1.651-6.365v-2.752c0-2.838.528-5.004 1.584-6.499s2.583-2.243 4.579-2.243c1.987 0 3.504.725 4.552 2.176 1.056 1.45 1.602 3.549 1.638 6.297v2.753zm-9.869-2.162h7.371v-.739c0-2.032-.313-3.585-.939-4.659-.618-1.083-1.536-1.625-2.753-1.625-1.2 0-2.113.542-2.739 1.625-.627 1.074-.94 2.627-.94 4.659v.739zm7.371 2.041h-7.371v.524c0 2.05.326 3.634.98 4.753.653 1.119 1.562 1.679 2.726 1.679 1.163 0 2.059-.538 2.685-1.612.636-1.074.963-2.627.98-4.659v-.685zm54.214-5.38c0-.672-.256-1.191-.766-1.558-.501-.376-1.383-.698-2.645-.967-1.253-.268-2.251-.591-2.994-.967-.735-.376-1.281-.823-1.639-1.342-.349-.52-.523-1.137-.523-1.853 0-1.191.501-2.198 1.504-3.022 1.011-.823 2.3-1.235 3.867-1.235 1.647 0 2.981.425 4.001 1.276 1.03.85 1.544 1.938 1.544 3.263h-2.497c0-.681-.291-1.267-.873-1.759-.573-.493-1.298-.739-2.175-.739-.904 0-1.612.197-2.122.591-.51.394-.765.908-.765 1.544 0 .6.237 1.052.711 1.356.475.305 1.33.595 2.565.873 1.244.277 2.252.609 3.021.994.77.385 1.339.85 1.706 1.396.376.537.564 1.195.564 1.974 0 1.298-.519 2.341-1.558 3.129-1.038.778-2.386 1.168-4.042 1.168-1.163 0-2.193-.206-3.088-.618-.895-.412-1.598-.984-2.108-1.719-.501-.743-.752-1.544-.752-2.403h2.484c.045.832.376 1.495.994 1.987.626.484 1.45.725 2.47.725.94 0 1.692-.188 2.256-.564.573-.385.86-.895.86-1.53zm8.419 3.853h-2.484V258.44h2.484v14.528zm-2.686-18.382c0-.403.121-.743.363-1.021.25-.277.617-.416 1.101-.416.483 0 .85.139 1.101.416.251.278.376.618.376 1.021 0 .403-.125.738-.376 1.007-.251.268-.618.403-1.101.403-.484 0-.851-.135-1.101-.403-.242-.269-.363-.604-.363-1.007zm9.024 3.854l.08 1.826c1.11-1.397 2.56-2.095 4.351-2.095 3.07 0 4.619 1.732 4.646 5.196v9.601h-2.484v-9.614c-.009-1.047-.251-1.822-.725-2.323-.466-.501-1.195-.752-2.189-.752-.806 0-1.513.215-2.122.645a4.37 4.37 0 00-1.423 1.692v10.352h-2.484V258.44h2.35zm12.729 6.593c0-2.024.269-3.966.806-5.828a17.059 17.059 0 012.43-5.076c1.074-1.522 2.189-2.596 3.344-3.222l.51 1.638c-1.307 1.002-2.381 2.533-3.223 4.592-.832 2.059-1.289 4.364-1.369 6.915l-.014 1.142c0 3.455.631 6.454 1.894 8.996.76 1.522 1.665 2.713 2.712 3.572l-.51 1.517c-1.191-.662-2.328-1.772-3.411-3.33-2.113-3.043-3.169-6.682-3.169-10.916zm21.605-.658c0 2.873-.528 5.071-1.584 6.593-1.056 1.512-2.583 2.269-4.579 2.269-1.96 0-3.473-.743-4.539-2.229-1.065-1.486-1.615-3.608-1.651-6.365v-2.753c0-2.837.528-5.004 1.584-6.499 1.057-1.495 2.583-2.242 4.579-2.242 1.987 0 3.505.725 4.552 2.175 1.057 1.45 1.603 3.55 1.638 6.298v2.753zm-9.869-2.162h7.372v-.739c0-2.032-.313-3.585-.94-4.659-.618-1.083-1.535-1.625-2.753-1.625-1.199 0-2.112.542-2.739 1.625-.627 1.074-.94 2.627-.94 4.659v.739zm7.372 2.041h-7.372v.523c0 2.05.327 3.635.98 4.754.654 1.119 1.562 1.678 2.726 1.678s2.059-.537 2.686-1.611c.635-1.074.962-2.627.98-4.659v-.685zm11.776.913c0 1.996-.264 3.912-.792 5.747a16.802 16.802 0 01-2.404 5.062c-1.074 1.549-2.202 2.65-3.384 3.303l-.523-1.517c1.378-1.056 2.484-2.694 3.316-4.915.842-2.229 1.271-4.699 1.289-7.412v-.429c0-1.88-.197-3.626-.59-5.237-.394-1.62-.945-3.071-1.652-4.351-.698-1.28-1.486-2.278-2.363-2.994l.523-1.517c1.182.653 2.305 1.745 3.371 3.276a16.797 16.797 0 012.403 5.062c.537 1.844.806 3.818.806 5.922zm-128.345 52.119c.887 0 1.661-.269 2.323-.806.663-.537 1.03-1.208 1.101-2.014h2.35c-.044.832-.331 1.625-.859 2.377-.528.752-1.235 1.351-2.122 1.799a6.067 6.067 0 01-2.793.671c-1.978 0-3.554-.658-4.726-1.974-1.164-1.324-1.746-3.133-1.746-5.424v-.417c0-1.414.26-2.672.779-3.773s1.262-1.956 2.229-2.565c.976-.608 2.126-.913 3.451-.913 1.629 0 2.981.488 4.055 1.464 1.083.976 1.661 2.242 1.732 3.8h-2.35c-.071-.94-.429-1.71-1.074-2.31-.635-.608-1.423-.913-2.363-.913-1.262 0-2.242.457-2.941 1.37-.689.904-1.034 2.216-1.034 3.934v.47c0 1.674.345 2.963 1.034 3.868.69.904 1.674 1.356 2.954 1.356zm7.909-5.64c0-1.423.278-2.703.833-3.84.564-1.137 1.343-2.014 2.336-2.632 1.003-.618 2.144-.927 3.424-.927 1.979 0 3.577.685 4.794 2.055 1.226 1.369 1.84 3.191 1.84 5.465v.174c0 1.415-.273 2.686-.819 3.814-.538 1.119-1.312 1.992-2.323 2.618-1.003.627-2.158.94-3.465.94-1.969 0-3.567-.685-4.794-2.054-1.217-1.37-1.826-3.183-1.826-5.438v-.175zm2.498.295c0 1.612.371 2.905 1.114 3.881.752.976 1.755 1.464 3.008 1.464 1.262 0 2.265-.493 3.008-1.477.743-.994 1.114-2.382 1.114-4.163 0-1.593-.38-2.882-1.141-3.867-.752-.994-1.754-1.491-3.008-1.491-1.226 0-2.215.488-2.967 1.464-.752.976-1.128 2.372-1.128 4.189zm22.303 3.25c0-.671-.255-1.191-.765-1.558-.501-.376-1.383-.698-2.645-.966-1.254-.269-2.252-.591-2.995-.967-.734-.376-1.28-.824-1.638-1.343-.349-.519-.524-1.137-.524-1.853 0-1.191.502-2.198 1.504-3.021 1.012-.824 2.301-1.236 3.868-1.236 1.647 0 2.98.426 4.001 1.276 1.029.85 1.544 1.938 1.544 3.263h-2.497c0-.68-.291-1.267-.873-1.759-.573-.492-1.298-.739-2.175-.739-.905 0-1.612.197-2.122.591-.51.394-.765.909-.765 1.544 0 .6.237 1.052.711 1.357.475.304 1.33.595 2.565.872 1.244.278 2.251.609 3.021.994s1.338.85 1.705 1.397c.376.537.564 1.195.564 1.973 0 1.298-.519 2.341-1.557 3.129-1.039.779-2.386 1.168-4.042 1.168-1.164 0-2.193-.206-3.088-.617-.895-.412-1.598-.985-2.108-1.719a4.21 4.21 0 01-.752-2.404h2.484c.044.833.376 1.495.993 1.988.627.483 1.451.725 2.471.725.94 0 1.692-.188 2.256-.564.573-.385.859-.895.859-1.531zm5.627-4.082c0-2.023.268-3.966.805-5.828a17.02 17.02 0 012.431-5.075c1.074-1.522 2.188-2.596 3.343-3.223l.51 1.638c-1.307 1.003-2.381 2.534-3.222 4.592-.833 2.059-1.289 4.364-1.37 6.916l-.013 1.141c0 3.455.631 6.454 1.893 8.997.761 1.521 1.665 2.712 2.712 3.571l-.51 1.518c-1.19-.663-2.327-1.773-3.411-3.33-2.112-3.044-3.168-6.683-3.168-10.917zm21.605-.658c0 2.874-.528 5.071-1.585 6.593-1.056 1.513-2.582 2.269-4.579 2.269-1.96 0-3.473-.743-4.538-2.229-1.065-1.486-1.616-3.607-1.652-6.364v-2.753c0-2.838.528-5.004 1.585-6.499 1.056-1.495 2.582-2.243 4.579-2.243 1.987 0 3.504.726 4.552 2.176 1.056 1.45 1.602 3.549 1.638 6.297v2.753zm-9.87-2.162h7.372v-.738c0-2.032-.313-3.586-.94-4.66-.617-1.083-1.535-1.625-2.752-1.625-1.2 0-2.113.542-2.74 1.625-.626 1.074-.94 2.628-.94 4.66v.738zm7.372 2.041h-7.372v.524c0 2.05.327 3.634.981 4.753.653 1.119 1.562 1.679 2.725 1.679 1.164 0 2.059-.537 2.686-1.612.636-1.074.962-2.627.98-4.659v-.685zm11.776.913c0 1.996-.264 3.912-.792 5.747a16.781 16.781 0 01-2.403 5.063c-1.075 1.548-2.203 2.649-3.384 3.303l-.524-1.518c1.379-1.056 2.484-2.694 3.317-4.914.841-2.229 1.271-4.7 1.289-7.412v-.43c0-1.88-.197-3.625-.591-5.237-.394-1.62-.944-3.07-1.652-4.35-.698-1.28-1.486-2.279-2.363-2.995l.524-1.517c1.181.653 2.305 1.746 3.37 3.276a16.805 16.805 0 012.404 5.063c.537 1.844.805 3.818.805 5.921z" fill="#000"></path></svg><p>Trigonometry methods are easy to <em>show</em>: given a unit circle and a few months of high school, you know that cosine and sine will get you coordinates on the rim, and that they’ll draw little squigglies if plotted on X &amp; Y. Actually <em>deriving</em> those methods is what you’ll learn in advanced classes, but the method that you use - the <a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor series</a> - relies on an <em>infinite</em> series, which would be rather laborious for a computer to solve.</p><blockquote><p>“There is no standard algorithm for calculating sine. IEEE 754-2008, the most widely used standard for floating-point computation, does not address calculating trigonometric functions such as sine.”</p></blockquote><p>-<a href="https://en.wikipedia.org/w/index.php?title=Sine&amp;oldid=939445047#Software_implementations">Wikipedia</a></p><p>Computers use a variety of different estimations and algorithms to do math, things like <a href="https://en.wikipedia.org/wiki/CORDIC">CORDIC</a> and various cheating algorithms and lookup tables. This heterogeny explains all of the <a href="https://github.com/search?q=fastmath">‘fastmath’</a> libraries you can find on GitHub: there’s more than one way to implement Math.sin. Famously, Quake III Arena used a <a href="https://en.wikipedia.org/w/index.php?title=Fast_inverse_square_root&amp;oldid=940101226">faster replacement for the inverse square root method</a> in order to speed up rendering.</p><p>So math is implemented as algorithms, and there are multiple common algorithms –&nbsp;and variations of those algorithms –&nbsp;used in practice.</p><p>Instead of telling implementations to pick an algorithm, the JavaScript specification grants them a <em>lot</em> of wiggle room in terms of how they implement these basic functions.</p><blockquote><p>The behaviour of the functions acos, acosh, asin, asinh, atan, atanh, atan2, cbrt, cos, cosh, exp, expm1, hypot, log,log1p, log2, log10, pow, random, sin, sinh, sqrt, tan, and tanh is not precisely specified here except to require specific results for certain argument values that represent boundary cases of interest.</p></blockquote><p>-<a href="https://www.ecma-international.org/ecma-262/10.0/index.html#sec-function-properties-of-the-math-object">ECMA-262, 10th edition, section 20.2.2 aka “JavaScript”</a></p><p>I don’t know the inner workings of the standards committees, but I imagine they wanted to make sure that just in case Intel or AMD introduce super-fast new math instructions in a new processor, JavaScript wouldn’t have a compatibility crisis.</p><p>Because there are a lot of JavaScript interpreters that are commonly used, because JavaScript is often used via web browsers and there still is some competition between web browsers, and because even popular JavaScript implementations are under pressure to evolve quickly to be the most performant…&nbsp;because of all that, this matters. You actually will encounter, on a regular basis, differences in math.</p><p>This doesn’t matter as much in other interpreted languages, because they tend to have ‘canonical’ interpreters: most of the time you use the Python interpreter of the Python language.</p><h3 id="where-math-happens">Where math happens</h3><p>Next let’s zoom into <em>where</em> these math implementations live. See, in JavaScript, there are three places where basic math can happen:</p><ol><li>The CPU</li><li>The language interpreter (the C++ and C code that underlies JavaScript implementations)</li><li>In software itself, as a library</li></ol><p><strong>1: The CPU</strong></p><p>This was my first guess: I assumed that since CPUs implement arithmetic, they might implement some higher-level math. It turns out that CPUs do have instructions to do trigonometry and other operations, but they’re rarely invoked. The CPU (x86) implementation of sine doesn’t get much love because it’s not reliably faster than an implementation in software (using arithmetic operations on the CPU), nor as accurate.</p><p>Intel also bears some blame for <a href="https://randomascii.wordpress.com/2014/10/09/intel-underestimates-error-bounds-by-1-3-quintillion/">overstating the accuracy of their trigonometric operations</a> by many magnitudes. That kind of mistake is especially tragic because, unlike software, you can’t patch chips.</p><p><strong>2: The language interpreter</strong></p><p>This is how most of the implementations do it, and they implement math in a variety of ways.</p><ul><li>V8 &amp; SpiderMonkey use (slightly different) ports of the <a href="http://www.netlib.org/fdlibm/">fdlibm</a> library for most operations. It has been passed down through the generations, originally written at Sun Microsystems.</li><li>JavaScriptCore (Safari) uses cmath for most operations.</li><li>Internet Explorer used some cmath, but <a href="https://github.com/microsoft/ChakraCore/blob/d86452259dd534718b7eb9ce024ed35aefd33036/lib/Runtime/Library/MathLibrary.cpp#L1028-L1047">also used some assembly instructions and actually <em>did</em> use CPU-provided trig methods</a> when it was compiled for CPUs that had them.</li></ul><p>Historically, all of these implementations have shifted: V8 used to use a homegrown solution for math, and then used <a href="https://github.com/v8/v8/blob/ff7975aa8d1ff6f0904f0f5112d17ea819466983/src/math.js">a port of fdlibm to JavaScript</a>, before finally settling on fdlibm in C.</p><h3 id="why-this-is-an-issue">Why this is an issue</h3><p>Here’s why this is a problem: it chips away at JavaScript’s ability to give consistent results to any problem including mathematics. And that especially hits <em>data science</em>. I want JavaScript to be a contender for data science in the browser, and – amongst some other issues, like number types and a confounding lack of a commonly-used data-frames library –&nbsp;an inability to produce replicable results means adding more crisis to the <a href="https://en.wikipedia.org/wiki/Replication_crisis">replication crisis</a> in the sciences.</p><h3 id="the-third-way">The third way</h3><p>There is a way out that we can use today. <a href="https://github.com/stdlib-js/stdlib">stdlib</a> is a JavaScript library that reimplements higher-level math using arithmetic alone. Arithmetic is fully-specified and standard, so the results that stdlib gives you are also fully consistent, across all the platforms.</p><p>This comes at the cost of complexity and speed: stdlib isn’t consistently as fast as built-in methods, and you’ll need to require a library ‘just’ to compute sine.</p><p>But in the wider view, this is pretty normal! WebAssembly, for example, doesn’t give you higher-level math methods at all and recommends you include a math implementation in your modules themselves:</p><blockquote><p>“WebAssembly doesn’t include its own math functions like sin, cos, exp, pow, and so on. WebAssembly’s strategy for such functions is to allow them to be implemented as library routines in WebAssembly itself (note that x86’s sin and cos instructions are slow and imprecise and are generally avoided these days anyway).”</p></blockquote><p>And this is the way that compiled languages have always worked: when you compile a C program, the methods you import from <code>math.h</code> are included in the compiled binary.</p><h3 id="using-an-epsilon">Using an epsilon</h3><p>If you don’t want to include stdlib to do math but you do want to test math-heavy code, you’ll probably have to do what simple-statistics does right now: use an epsilon. Of the <a href="https://en.wikipedia.org/w/index.php?title=Epsilon&amp;oldid=938802001#Symbol">5+ uses of epsilon in math</a>, the one I’m referring to is “an arbitrarily small positive quantity”. It’s a tiny number. Here’s <a href="https://github.com/simple-statistics/simple-statistics/blob/727eaed049af4f788fb2299e5c8263573618e78c/src/epsilon.js#L35">simple-statistics’s implementation</a>: the number 0.0001.</p><p>You then compare <code>Math.abs(result - expected) &lt; epsilon</code> to make sure you got within range of the desired value, with a little bit of wiggle room.</p><h3 id="the-moral-of-the-story">The moral of the story</h3><p>Here’s where I was a little short on time in person and have some room to expand.</p><p><em>First, what’s under the hood is rarely what you expect.</em> Our current tech stack is heavily optimized and a lot of optimizations are really just dirty tricks. For example, the number of hardware instructions it takes to solve <code>Math.sin</code> varies based on the input, because there are lots of special cases. When you get to more complex cases, like ‘sorting an array’, there are often multiple algorithms that the interpreter chooses between in order to give you your final result. Basically, the cost of anything you do in an interpreted language is variable.</p><p><em>Second, don’t trust the system too much.</em> What I was seeing between Node versions really <em>should</em> have been a bug in the testing library, or something in my code, or maybe in simple-statistics itself. But in this case, digging deeper revealed that what I was seeing was exactly what you don’t expect: a glitch in the language itself.</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2020/02/14/math-keeps-changing.html">https://macwright.com/2020/02/14/math-keeps-changing.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2020/02/14/math-keeps-changing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24978027</guid>
            <pubDate>Tue, 03 Nov 2020 09:42:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browser extension Honey also collects their user’s history data]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24977935">thread link</a>) | @n3wham
<br/>
November 3, 2020 | https://www.datarequests.org/blog/honey-data-collection/ | <a href="https://web.archive.org/web/*/https://www.datarequests.org/blog/honey-data-collection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>The free browser extension “Honey” wants to save their users money by automatically finding and applying coupon codes. They describe themselves as advocates for data protection and allegedly only collect history data on online shopping websites. Two of our members who have used Honey in the past, have asked for access to the data saved on them using the GDPR. Our analysis of the responses shows that Honey collects history data on a large scale, contrary to what their own privacy policy says. Thus, we have submitted complaints with the data protection authorities.</strong></p><p>“Stop wasting money – Honey helps you find some of the best coupon codes on 30,000+ sites.” That’s how Honey describe themselves on their homepage. The free browser extension is heavily advertised on YouTube and other websites. The idea behind it is nothing new. There have been websites that collect coupon codes for various online shops for a long time.</p><p>But Honey goes one step further and wants to make this process easier for their users. Sometimes, the coupon codes found on such websites are expired or only work for certain items. Trying the different coupons codes, that are often spread across many websites, can genuinely be quite frustrating. Honey promises to do that work for their users. Once installed in the browser, the addon automatically enters all coupons it knows on the shopping cart pages of supported websites. Afterwards, it applies the one that yields the biggest savings.</p><p>Honey then earn money through so-called “affiliate marketing”. The participating shops pay a commission to Honey for the coupons used.</p><p>So far, so good. But as a non-profit promoting data protection, we are mostly interested in one thing: How does Honey process their users’ data? As a browser extension, Honey could in theory record all internet traffic and thus log the entire browser history. This is especially problematic as Honey is run by a US company, <a href="https://www.datarequests.org/company/joinhoney/">Honey Science LLC</a>, that was recently <a href="https://help.joinhoney.com/article/302-what-does-honey-joining-paypal-mean-for-members">bought by PayPal</a>.</p><p>To find out what data Honey collects, we could first take a look at their privacy policy (and, of course, <a href="#honey-privacy-policy">we did</a>). But these unfortunately tend to be pretty general. They don’t really give users an idea on what data is actually collected on them. Luckily, the GDPR can help here. It grants users <a href="https://www.datarequests.org/blog/your-gdpr-rights/">extensive rights with regards to their data</a>. One of those is the so-called <em>right to data access</em>, which is defined in Art. 15 GDPR, and allows all consumers to demand a copy of the data companies have saved on them. This makes it possible to verify a company’s statements.</p><p>Two of our members, Benni and Malte, have made use of this right. They had both used the Honey extension in the past for a while. Benni had created an account and used that to log into the extension, while Malte has used the extension without an account. Both used our <a href="https://www.datarequests.org/generator/">generator</a> to send an access request to Honey.</p><p>We have then analysed the responses they received.</p><p>When logged into the extension with an account, accessing the data was very easy. The response containing the data arrived within a little more than two weeks. It contained various CSV files on different topics. The first couple contained details that one would expect: the data from the user profile, country and language, the <em>Honey Gold</em> balance, a list of transactions qualifying for Honey Gold, the IP addresses and browsers used at the time of registering for an account and installing the extension.</p><p>However, it also contained a file called <code>PageViews.csv</code> that was a lot more surprising. As the name implies, this file contains a list of page views. For Benni, who used the extension from mid February 2020 to mid May 2020, it contained a staggering 2591 entries.</p><p>To give an example, one of the lines in the file looks like this (displayed as a column here for better readability):</p><p>We can see: <strong>For every visit of a page in an online shop, Honey logs at least the following information</strong>: a timestamp, multiple <strong>unique IDs</strong> for user, session and device, the operation system, the browser and browser version, geolocation details, and the <strong>full URL of the visited page</strong>.<br>From that, the company gains an incredibly detailed insight into the shopping behaviour of its users. It knows not only the products that users buy but also all the products that they looked at but ultimately didn’t end up buying, as well as how long they looked at the product page.</p><p>We consider even this processing to be excessive. But it may be possible to barely justify it given that Honey’s purpose is to find coupon codes for the products that users look at. But Honey collects <em>a lot</em> more data.</p><p>Indeed, not only product pages from online shops are logged. Instead, Honey saves any visit to a page whose domain the company has classified as an “online shopping website”. But many shopping websites don’t just include the actual product pages. They often have a multitude of other content, like blog posts or login pages.<br>And Honey goes even further yet: They log page views even for subsites that are on different subdomains. Thus, the user’s browsing habits on countless forums, support pages and other sites are also documented. And for all of these pages, the full URL is saved, even including the document fragment that may allow reconstructing the precise position of the page the user looked at. The logged URLs and included parameters can also contain sensitive data but in any case they allow Honey to get a detailed view into the users’ browsing habits.</p><p>To demonstrate the scope of the profiles that Honey could create from this data, we have selected a few rows from Benni’s data export and will now describe what information could be inferred from this. The exact raw data of the corresponding rows is published below.</p><p>Honey knows, that on February 13, 2020 at 2:57 PM, Benni looked at an <a href="https://www.ifixit.com/Guide/Nintendo+Wii+DVD+Drive+Lens+Replacement/4491">iFixit guide</a> on how to swap the DVD lens on a Wii. He viewed the details for his AliExpress order <code>3002876007952992</code> a total of 13 times, starting on February 17 at 7:43 PM. He started a dispute for this order on February 25 at 10:01 AM. But before that, he went looking for an Airbnb in Berlin-Mitte on February 24 at 8:02 PM. He was looking for an entire accommodation or a hotel room for two adults for the period from March 04 to March 05. On March 01 at 6:46 PM, he looked at an <a href="https://support.apple.com/en-us/HT204306">Apple support page</a> describing how to reset an iPhone if you forgot the unlock code. The next day at 2:25 PM, he was interested in the <a href="https://creativecommons.org/licenses/by/4.0/">CC-by license</a> by Creative Commons and on March 10 at 9:04 PM, he looked at the <a href="https://developer.microsoft.com/en-us/fabric">Fabric UI Framework</a> by Microsoft. He is apparently also a member of a Microsoft family, as he added another member to his family the next day at 7:45 PM to share the benefits of his Office 365 subscription with them. On March 14 at 11:49 AM, he read an <a href="https://www.trustwave.com/en-us/resources/blogs/spiderlabs-blog/cve-2018-1000136-electron-nodeintegration-bypass/">article</a> on a security vulnerability in the Electron framework. On March 23 at 5 PM, he watched the documentary <a href="https://curiositystream.com/video/1984/scanning-the-pyramids">“Scanning The Pyramids”</a> via the streaming provider CuriosityStream. He signed up for the service only half an hour earlier, at 4:29 PM, having been recruited by YouTuber Tom Scott and registering via his affiliate link. On March 25 at 6:51 PM, he was again interested in a trip, this time via FlixBus. He planned the trip as a one-way trip between Berlin and Leipzig for an adult on May 01. But this trip never took place, as there are no further entries for FlixBus. On April 22 at 8:33 AM, Benni redeemed a game on Steam with the code <code>5HGP6-JVK5C-I92YW</code>. On May 11 at 9:04 PM, he then informed himself about the lack of support for exporting in the MKV format in Adobe Premiere on the <a href="https://community.adobe.com/t5/premiere-pro/premiere-pro-cc-doesn-t-support-mkv-anymore/td-p/10586989?page=1">Adobe support forum</a>. He has an AWS account and access to the S3 bucket named <code>dacdn-static</code>. This contains a file with the path <code>talks/subtitles/20200511-okl-berlin-en.vtt</code>, which he looked at on May 13 at 3:09 PM.</p><p><strong>Honey can infer all this information directly from the data they collected.</strong> And the examples we gave only represent a tiny fraction of the information that Honey has. The 27 lines that the examples are based on, only make up just over 1&nbsp;% of the entries Honey has collected on Benni. We have focussed on non-product related page views. But in addition, Honey also knows every product that Benni looked at while he had installed the extension. Further, they could use the data they have for even more conclusions and profiles. For example, they could infer sleep cycles from the timestamps or build interest profiles based on the sites that were visited.</p><div><summary>Raw data as saved by Honey for the events described above</summary><pre>ts,timestamp,store,extension,product,src,sub_src,user_id,device_id,visitor_id,session_id,platform,version,referrer_url,first_referrer_url,language,campaign,location,os,browser,group,is_logged_in,client_ts
2020-02-13T14:57:51.523Z,,"{country=US, id=7583916003951006414, label=i-fix-it, name=iFixit, session_id=1581602269900}","","",extension,,8291877052743772122,8291877052743758554,8291895932342390791,1581595975000,ff,11.11.4,https://www.ifixit.com/Guide/Nintendo+Wii+DVD+Drive+Lens+Replacement/4491,,en-US,"","{city=Bad Oldesloe, country=DE, region=SH}","{name=Windows, version=10}","{major=68, name=Firefox, version=68.0}",,,2020-02-13T13:57:51.4Z
2020-02-17T19:43:17.236Z,,"{country=US, id=7370049848889092396, label=aliexpress, name=AliExpress, session_id=1581968534100}","","",extension,,8291877052743772122,8281837226426454371,8281837231485163268,1581936825700,ff,11.11.4,https://trade.aliexpress.com/order_detail.htm?orderId=3002876007952992,,en-US,"","{city=Bad Oldesloe, country=DE, region=SH}","{name=Windows, version=10}","{major=68, name=Firefox, version=68.0}",,,2020-02-17T19:43:16.3Z
2020-02-24T20:02:12.145Z,,"{country=US, id=7587516493463718696, label=airbnb, name=Airbnb, session_id=1582574363800}","","",extension,,8291877052743772122,8281837226426454371,8281837231485163268,1582534687100,ff,11.11.4,https://www.airbnb.com/s/Berlin~Mitte--Berlin--Germany/homes?refinement_paths%5B%5D=%2Fhomes¤t_tab_id=home_tab&amp;selected_tab_id=home_tab&amp;place_id=ChIJjw3Y6t9RqEcR8jUVWEcgISY&amp;source=mc_search_bar&amp;search_type=filter_change&amp;screen_size=large&amp;hid…</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datarequests.org/blog/honey-data-collection/">https://www.datarequests.org/blog/honey-data-collection/</a></em></p>]]>
            </description>
            <link>https://www.datarequests.org/blog/honey-data-collection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977935</guid>
            <pubDate>Tue, 03 Nov 2020 09:24:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Add a cookie consent to your Laravel application in just 5 minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24977888">thread link</a>) | @max_hutsch
<br/>
November 3, 2020 | https://42coders.com/add-a-cookie-consent-to-your-laravel-application-in-just-5-minutes | <a href="https://web.archive.org/web/*/https://42coders.com/add-a-cookie-consent-to-your-laravel-application-in-just-5-minutes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>
                    Laravel Package
                </p>
                

                <p>
                    Max Hutschenreiter - <time datetime="10-29-2020">
                        29 Oct 2020
                    </time>
                </p>
                <figure>
                    <img src="https://42coders.com/storage/82/cookie_gdpr_header.jpg" alt="" width="1310" height="873">
                </figure>
            </div><div>
                <div><p>In this short tutorial, we will show you how you can add a GDPR compliant cookie popup to your Laravel site.</p><figure data-trix-attachment="{&quot;contentType&quot;:&quot;image/png&quot;,&quot;filename&quot;:&quot;cookie_gdpr.png&quot;,&quot;filesize&quot;:66934,&quot;height&quot;:321,&quot;href&quot;:&quot;https://42coders.com/storage/CsHO87rUraZedIbt0HDofjzF9CEww8Y401AfgMuj.png&quot;,&quot;url&quot;:&quot;https://42coders.com/storage/CsHO87rUraZedIbt0HDofjzF9CEww8Y401AfgMuj.png&quot;,&quot;width&quot;:1182}" data-trix-content-type="image/png" data-trix-attributes="{&quot;caption&quot;:&quot;cookie popup&quot;,&quot;presentation&quot;:&quot;gallery&quot;}"><a href="https://42coders.com/storage/CsHO87rUraZedIbt0HDofjzF9CEww8Y401AfgMuj.png"><img src="https://42coders.com/storage/CsHO87rUraZedIbt0HDofjzF9CEww8Y401AfgMuj.png" width="1182" height="321"><figcaption>cookie popup</figcaption></a></figure><p>Find the Package on the <a href="https://github.com/42coders/eu-cookie-consent">Github</a>!</p><p> Lately, the Courts decided that you need to give your users the option to opt-in for every third-party service you are using. A lot of our clients were asking about a popup like this. Unfortunately, the famous <a href="https://github.com/spatie/laravel-cookie-consent">Spatie package</a> we used on most of our Sites is not addressing this. That was the point where we decided to write our own EU Cookie Consent package.&nbsp;</p><p>&nbsp;Our Goals have been to give users the option to opt-in per service and the developers to check if the user gave permission. As a small goodie, we implemented also an easy way to play out the allowed scripts to your page.</p></div><p><strong>Installation:</strong></p><p>You can install the package via composer:</p><pre><code>composer require the42coders/eu-cookie-consent</code></pre><p><strong>Customize the popup:</strong></p><p>Most of the customization can be done through the config file. First, you need to publish it.</p><pre><code>php artisan vendor:publish --provider="the42Coders\eu-cookie-consent\EuCookieConsentServiceProvider" --tag="config" </code></pre><div><p>The config file has a lot of comments to help you get started.&nbsp;</p><p>The core of the popup is defined in the cookies array. Here you can define the categories and inside of the categories the cookies. Categories are meant to organize the cookie permissions to topics. But feel free to just use one if it fits you.<br>Every parameter in the array which is marked with Optional: in the comment above is optional :). Let's assume you want to add a Facebook cookie permission to the popup.</p><p>This is how the cookies part is looking at the moment.</p></div><pre><code>cookies' =&gt; [
    //The key defines the key in the translations and is used to access the Cookie specific information
    'session' =&gt; [
        //Optional: you can set forced to make it impossible for the user to not accept this cookie.
        'forced' =&gt; 'true',
        //Optional: The description defines the key in the translations
        //'description' =&gt; 'key in translation File'
    ],
    'xsrf-token' =&gt; [
        'forced' =&gt; 'true',
    ],
],</code></pre><p>Now we add facebook permission to it.</p><pre><code>cookies' =&gt; [
    //The key defines the key in the translations and is used to access the Cookie specific information
    'session' =&gt; [
        //Optional: you can set forced to make it impossible for the user to not accept this cookie.
        'forced' =&gt; 'true',
        //Optional: The description defines the key in the translations
        //'description' =&gt; 'key in translation File'
    ],
    'xsrf-token' =&gt; [
        'forced' =&gt; 'true',
    ],
    'facebook' =&gt; [],
],</code></pre><p>Since this Package has multi-language support all the texts are set in the language files. To make changes we need to publish them first.</p><pre><code>php artisan vendor:publish --provider="the42Coders\eu-cookie-consent\EuCookieConsentServiceProvider" --tag="lang" </code></pre><p>In the language file, you just need to add a new key and the content.</p><pre><code>'facebook' =&gt; 'We want facebook to know everything about you. Please let us :).',</code></pre><div><p>That's it! You added new cookie permission to the popup. You can also delete the already existing ones if you don't need them.</p></div><p><strong>Use the Popup:</strong></p><p>Now you want to show the popup on your Laravel site. We recommend to integrate it into your base blade file like the app.blade.php.&nbsp;<br>This will render the Popup HTML and that is all you need.</p><pre><code>{!! EuCookieConsent::getPopup() !!}</code></pre><p><strong>Check for Permissions:</strong></p><p>But now you want to integrate the Facebook connection based on the permission of the user. The package gives you two ways to do so.<br><strong>1. Check for permission in your blade file.</strong></p><pre><code>&lt;head&gt;
    @if(EuCookieConsent::canIUse('facebook'))
        &lt;script&gt;
            alert('all the crazy facebook script stuff');
        &lt;/script&gt;
    @endif
&lt;/head&gt;</code></pre><div><p>This will insert the Script tag only if the User agreed to it in the popup.</p><p><strong>2. Mass render them in your blade file.</strong><br>To do this we need to make a small adjustment to the config file.</p></div><pre><code>'facebook' =&gt; [
    'header' =&gt; '&lt;script&gt;alert(\'all the crazy facebook script stuff\');&lt;/script&gt;',
],</code></pre><p>You can define any non taken key here as you will see later. You just need to use the same on all the cookie permissions you want to render at the same place.<br>In your blade File, you can do this.</p><pre><code>&lt;head&gt;
    {!! EuCookieConsent::getHtml('header') !!}
&lt;/head&gt;</code></pre><div><p>This will collect the header tag from all the cookie permissions the user allowed you to use and just output them here. If you want to have one part in the header and one in the footer you can just define both in the config array.</p></div><p><strong>You made it!</strong></p><p>Your page is now cookie GDPR compliant.&nbsp;<br>If you have any ideas for improvements to this package feel free to contact us.</p>
            </div></div>]]>
            </description>
            <link>https://42coders.com/add-a-cookie-consent-to-your-laravel-application-in-just-5-minutes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977888</guid>
            <pubDate>Tue, 03 Nov 2020 09:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The free-range future of work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24977860">thread link</a>) | @brokebroadbeat
<br/>
November 3, 2020 | https://visitmy.website/2020/11/02/free-range-future-of-work/ | <a href="https://web.archive.org/web/*/https://visitmy.website/2020/11/02/free-range-future-of-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For organisations that use computers to get stuff done, the Internet means you can spread bits of your organisation out geographically and temporally.</p>

<p>Spreading a workforce geographically is usually called remote working or distributed working. That’s when workers aren’t necessarily close to the location of the main office, they live and work elsewhere. There’s also hybrid working, which is when people are expected to come into an office some times but can work from wherever they like the rest of the time.</p>

<p>Spreading a workforce temporally is usually called flexible working or asynchronous working. That’s when workers aren’t always required to be working at the same time as each other. Although more often than not, there’s usually some ‘core hours’ workers have to be present and available.</p>

<p>For various reasons, some groups of people have experimented with the opportunity the Internet has provided. It has allowed them to find new ways of doing things or new ways of living. And, for another variety of reasons, some people haven’t bothered.</p>

<p>Then, in March, that all changed. Anyone who could work online, usually from a computer, was forced to try this stuff out. If their company hadn’t tried out these new ways of working, they became a guinea pig overnight. A <a href="https://www.cliffsnotes.com/literature/f/flowers-for-algernon/character-analysis/algernon">mouse in a maze</a>, without a scientist overseeing the experiment.</p>

<p>That sucks because, as an organisation, you don’t know what works and what doesn’t. Your workers have been forced to try new things and will have reached their own conclusions. Some might like it, others might not be so keen. There will likely be some people for whom the experience has been traumatic, and those people are going to need our help.</p>

<p>So, ignoring whoever’s job it is to do this stuff, I think it’s time for people working on computers to look sideways (metaphorically) and help each other out. If you manage a team or you’re part of a team, it’s time to build your own New Normal.</p>

<p>Here’s some notes I’ve been making on free-range working<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. And you might like to read about <a href="https://gds.blog.gov.uk/2020/10/07/what-happened-when-we-stopped-having-meetings-and-sending-emails/">this experiment we tried with meetings and emails</a>.</p>

<h2 id="notes-on-free-range-working">Notes on free-range working</h2>

<ol>
  <li>
    <p>We’re trying to create more serendipity for innovation, and make collaboration easier when we’re not in the same place. Show &amp; Tells don’t have to be polished. Share progress, ideas and half-finished thoughts; invite people to comment on your work before it’s completed. This helps replicate putting work up on the wall and giving people a chance to comment on things, especially if they’re not on your team.</p>
  </li>
  <li>
    <p>Check in on your colleagues’ home-working setup. Do they have space? Do they have a desk? Is it well-lit and comfortable? People with better working environments have a new kind of privilege, and so we should be equitable in our approach to free-range working.</p>
  </li>
  <li>
    <p>When everyone you work with is on a screen, everyone is more equal – it’s harder for people to dominate the room. Also, we tend to stop talking over each other and let people finish what they were saying. Cultivate that atmosphere, creating the space for diverse or unheard voices to come to the fore.</p>
  </li>
  <li>
    <p>Spontaneous socialising is a joy. Create a tea break channel and head in there when you’re going to make a cup of tea or coffee. Start a voice chat, either using your work laptop or some headphones connected to a phone.</p>
  </li>
</ol>

<hr>



  </div>
</article><div>
  
    <li>
      <span> 7 July 2019</span>

<h3>
  <a href="https://visitmy.website/2019/07/07/kicking-off-new-quarter-with-your-product-team/" onclick="window.fathom.trackGoal('3T2PDDS0', 0);">Kicking off a new quarter with your product team</a>
</h3>
<p>Here's how I frame what we've achieved so far, what's left to do and what's next with product teams at GOV.UK.</p>

    </li>
  
    <li>
      <span>27 April 2019</span>

<h3>
  <a href="https://visitmy.website/2019/04/27/product-teams-deliver-outcomes-not-outputs/" onclick="window.fathom.trackGoal('3T2PDDS0', 0);">Product teams deliver outcomes, not outputs</a>
</h3>
<p>It's a change in mindset for leadership to manage outcomes or results, instead of the traditional way of managing effort and output. Here's how I turn 'Build this' into 'Realise that' on GOV.UK at the UK's Government Digital Service.</p>

    </li>
  
    <li>
      <span> 1 November 2020</span>

<h3>
  <a href="https://visitmy.website/2020/11/01/why-i-write-weeknotes/" onclick="window.fathom.trackGoal('3T2PDDS0', 0);">Why I write weeknotes</a>
</h3>
<p>Each weekend I spend around 2 hours writing about what I did in the ~38 hours I spent at work that week. Why? Good question.</p>

    </li>
  
</div></div>]]>
            </description>
            <link>https://visitmy.website/2020/11/02/free-range-future-of-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977860</guid>
            <pubDate>Tue, 03 Nov 2020 09:10:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Untimely Demise of Workstations]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 192 (<a href="https://news.ycombinator.com/item?id=24977652">thread link</a>) | @ingve
<br/>
November 3, 2020 | https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Last month’s news that <a href="https://arstechnica.com/information-technology/2020/10/ibm-to-split-into-two-companies-by-the-end-of-2021/">IBM would do a Hewlett-Packard</a> and divide into two—an IT consultancy and a buzzword compliance unit—marks the end of “business as usual” for yet another of the great workstation companies.</p>
<p>A quick aside on computing history. You can imagine personal computing being driven by two distinct schools of thought. The “top down” school, represented by research-led organisations including Xerox PARC, Bell Labs,academia and the military, asked “what would the world be like if everyone had their own minicomputer”? They took large, time-sharing systems like UNIX and installed them first under, then on, employees’ desks for their own personal use.</p>
<p>The “bottom up” school was made up of hobbyists who asked “can we make an interesting computer out of inexpensive components”? Thus companies like Apple and MITS in the US, Acorn and Sinclair Radionics in the UK, and others took chips that were usually used as peripherals controllers in “real” computers and built interactive programming systems around them. The microcomputer revolution came from the bottom-up school, as they made home computing affordable. The workstation revolution came from the top-down school, as they made powerful on-demand computing feasible.</p>
<p>The two schools came into very close proximity in the 1980s, when the Motorola 68000 family of CPUs (along with the 68881/68882 FPU and 68851 MMU) were the processors of choice in everything from entry-level PCs like the Atari 520ST, through games consoles like the Sega Mega Drive (Genesis in the US), to the most expensive UNIX workstations from NeXT Computer, Sun Microsystems, and Apollo Computer.</p>
<p>But then the workstation makers invested heavily in their own CPU architectures based on RISC design principles and again the two diverged. The workstation market became highly differentiated: RS/6000 from IBM (later PowerPC), Alpha from Digital Equipment Corp, MIPS from, well, MIPS, SPARC from Sun, PA-RISC from HP. The software on these workstations, while superficially very similar, was also differentiated and surprisingly incompatible. Take a program from HP-UX and you’ll have difficulty running it on NeXTSTEP, unless the authors shared the source code and used the nascent GNU autotools to support portable building. As Yoda said: begun, the <a href="https://www.livinginternet.com/i/iw_unix_war.htm">UNIX wars</a> have.</p>
<p>Of course we know that the (desktop) computing world today is mostly Intel and that workstations are mostly fancy PCs, rather than bespoke designs by vertically-integrated companies, Apple being the two trillion dollar outlier. How we got here was that the commodity parts got good enough that there was no evident advantage to workstation-grade hardware. A high-end PC could easily run a workstation OS like System V UNIX (Solaris was an early example), BSD (386BSD which later became FreeBSD, or NeXTSTEP) or Windows NT.</p>
<p>Along the way, the workstation companies consolidated (Apollo and eventually DEC got absorbed into HP; MIPS into SGI) or disappeared altogether (Sun became Oracle Hardware; SGI went bankrupt and sold its assets to sgi; Symbolics did similar—incidentally Symbolics was the first company with a .com domain). IBM long ago stopped even making its own brand PCs, and the news of its split means that there are now very few workstation companies trading in the same form they had “back in the day”. The only ones I can think of that have not had major changes to their corporate structures are Xerox and Sony, whose management may not even have known that they sold workstations.</p>
<p>What’s got lost alongside the death of the workstation is the business model where you sell expensive computers as part of an integrated solution into a particular vertical market, where that expensive solution will cost a lot less than cobbling something together out of cheap PCs. Why? I think people have a lower expectation and higher pain threshold when using computers now; they expect an amount of friction based on their own experience and translate that expectation into realms where it doesn’t belong. As I described way back in issue 2, <a href="https://deprogrammaticaipsum.com/the-various-meanings-of-quality/" target="_blank" rel="noopener noreferrer">computing is a lemon market</a>.</p>
<p>Organisations would go to the workstation vendors because they solved particular problems very well. If you’re in AI, you need Symbolics. Computer graphics, SGI. Telecoms, that’d be Sun. If you want to write software in Ada for the military-industrial complex, you’ll be buying a Rational workstation. Yes, the first IDE was a completely integrated package of hardware and software. And, of course, Apple for Desktop Publishing, the Mac being a workstation of sorts itself. People would buy computers <em>because</em> applications like AutoCAD, Quark or Mathematica ran well on them. They wouldn’t buy the computer then browse the App Store to see whether it could do anything useful.</p>
<p>And the strange thing is that catering to those vertical markets with integrated solutions is easier than ever now. The wide availability of free software means that the basic job of “being a desktop computer” is taken care of at zero cost, so business can focus on contributing valuable bespoke behaviour. And hardware costs are lower than ever: the availability of high-capability SoCs and single-board computers like the Raspberry Pi and Rock64 should make it a no-brainer to sell the computers as accessories for the applications, not the other way around.</p>
<p>In high-tech domains, an engineer could readily have a toolchest of suitable computers in the same way that a mechanic has different tools for their tasks. This one has an FPGA connected by both PCI-E and JTAG to allow for quick hardware prototyping. This one is connected to a high-throughput GPU for visualisations; that one to a high-capacity GPU for scientific simulations.</p>
<p>The general purpose hardware vendors want us to believe that an okay-at-anything computer is the best for everything: you don’t need a truck, so here’s a car. But when you’re hauling a ton of goods, you’ll find it cheaper and more satisfying to shell out more for a truck. Okay-at-anything is good for nothing.</p>
<p>Cover photo by <a href="https://unsplash.com/@serejahh">Serhii Butenko</a> on <a href="https://unsplash.com/photos/zx2Vc1zPDIs">Unsplash</a>.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/the-untimely-demise-of-workstations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977652</guid>
            <pubDate>Tue, 03 Nov 2020 08:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Hardening Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24977488">thread link</a>) | @robertwinter
<br/>
November 3, 2020 | https://elastisys.com/security-hardening-kubernetes/ | <a href="https://web.archive.org/web/*/https://elastisys.com/security-hardening-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="7a49ff87" data-element_type="column"><div><div><div data-id="1b308d22" data-element_type="widget" data-widget_type="text-editor.default"><div><div><h2><span>Description</span></h2><p>Developers and operators in today’s digital world are facing an ever-increasing set of regulatory requirements, security challenges and privacy concerns. In addition to constant attacks on IT assets there is growing legal pressure to deliver and maintain regulatory guidelines in our networked world. Requirements such as PCI-DSS, HIPAA, GDPR or SOC2 are becoming the pre-requisite of any operation in various industries.</p><p>Modern cloud native architectures and Kubernetes provide tools to address these demands, but the knowledge of these tools and methods are not widely understood. Today what is needed most is guidance on what exists and how best to use the right resources to meet the security and compliance requirements while still benefiting from the speed and agility Cloud Native environments offer.</p><p>In this video Johan Tordsson, CTO of Elastisys, provides provide a deep dive on security development tools and open source Kubernetes services available to meet these growing needs.</p><h2>Follow us</h2><p>Elastisys is an active member of the cloud-native community and participates in public webinars and meetups. Keep up to date by <a href="https://www.linkedin.com/company/elastisys" target="_blank" rel="noopener">following Elastisys on LinkedIn</a>&nbsp;to never miss a public event. If you would like us to speak at your event, or conduct training in Kubernetes or related cloud-native technologies, don’t hesitate to&nbsp;<a href="https://elastisys.com/contact-us-contact-information-email-visit-us-social-media/">contact us</a>!</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://elastisys.com/security-hardening-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977488</guid>
            <pubDate>Tue, 03 Nov 2020 08:07:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Two Scales of DevOps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24977441">thread link</a>) | @rastko
<br/>
November 2, 2020 | https://rastko.tech/blueprints/cloud/cloud-native/devops/sre/kubernetes/infrastructure/architecture/solutions/2020/11/02/two-scales-of-devops.html | <a href="https://web.archive.org/web/*/https://rastko.tech/blueprints/cloud/cloud-native/devops/sre/kubernetes/infrastructure/architecture/solutions/2020/11/02/two-scales-of-devops.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>02 Nov 2020</span>
  <span>
    
      •

      
      
      

      
        blueprints
      
    
      •

      
      
      

      
        cloud
      
    
      •

      
      
      

      
        cloud-native
      
    
      •

      
      
      

      
        devops
      
    
      •

      
      
      

      
        sre
      
    
      •

      
      
      

      
        kubernetes
      
    
      •

      
      
      

      
        infrastructure
      
    
      •

      
      
      

      
        architecture
      
    
      •

      
      
      

      
        solutions
      
    
  </span>
</p><div>
    <blockquote>
  <p><strong>Whatever happens always happens on time.</strong> <br> <em>Zen quote about software delivery</em>
<img src="https://rastko.tech/images/two-scales-00.jpg"></p>
</blockquote>

<p><br>
This article is a continuation of the discussion about NFRs of being <a href="https://rastko.tech/blueprints/cloud/cloud-native/kubernetes/infrastructure/architecture/solutions/2020/10/22/native-to-cloud.html">Native to the Cloud</a></p>

<h2 id="the-scale-of-things-to-come">The scale of things to come</h2>

<p>The set of complexities that you have to manage in your system, from its inception to the end of days, is immense. It represents a summary of its architecture, the way it is built, a structure that creates and delivers it, and the structure that is being serviced by it.</p>

<blockquote>
  <p><strong>I want to be fully focused on non-functional requirements in this article, so the “the way it is built” part will be avoided, we are currently not interested in software itself, just surrounding stuff - the footprint of its life.</strong></p>
</blockquote>

<p><strong>The architecture</strong> of the system defines the end-to-end structure of the system, the layout of components, and their correlation. It defines events and data flows and makes the footprint in the infrastructure. This is the part that gets deployed to Kubernetes and other connected systems.</p>

<p><img alt="microservice architecture deployed to kubernetes and coud with cdn elements databases etc" src="https://rastko.tech/images/two-scales-0.jpg"></p>

<p><strong>In the picture -</strong> Microservice architecture with event-driven components and two UIs, which would be considered medium complexity projects at the start. The central piece is handled by Kubernetes while there are few mounted components from cloud solutions and CDN to handle static content (UI) and caching.</p>

<blockquote>
  <p>I intend to analyze most of the complexities of setting up and running the above and similar systems through a series of articles I am writing on the topic of non-functional requirements (NFR). I want to give more concrete approaches and more clarity on the implications of every approach and decision in this space. To make things easier, I will probably make some choices, like <strong>the choice to do everything in the Kubernetes space</strong>.</p>
</blockquote>

<h3 id="fluidity">Fluidity</h3>

<p>Further on, I would like you to understand that your system will, in most cases, have to handle the fluid nature of software architecture: you have to be ready for ever-changing software design (emergent design). And there we get to the actual problem space.</p>

<blockquote>
  <p><strong>Emergent design-</strong> The idea is that the design of the system emerges (and changes) little by little, in small increments - in the same way, I hope your development process is organized.</p>
</blockquote>

<p>Effects of emergent design manifest on all aspects of your software’s development, delivery, and lifecycle. This is continuously changing NFR problem space, which consequentially requires you to continuously adapt your solution. The actual problem we are solving is represented by twofold complexity you are bound to manage till the end of the day. These two parts of the problem are best analyzed and tackled together, through one thought process.</p>

<p>Over a period of many years I have spent working on all the aspects of software, I ended up calling this <strong>“the two scales of devops”.</strong> Of course, scales are complexity and volume measurements of particular software aspects:</p>

<ul>
  <li><strong>The development and delivery</strong> - the scale of development.</li>
  <li><strong>The production part</strong> - the scale of life.</li>
</ul>

<p>This <strong>problem of two scales</strong>, as I would usually call it, has to be solved day in and day out, which means that, in our case, it becomes a <strong>paradigm - we want to discuss and collect some established patterns for solving its usual components</strong>.</p>

<h3 id="the-first-scale">The first scale</h3>

<p>The scale of development is about providing a good development experience at any pace, about development tooling, about flow efficiency, security, and ease of onboarding. You measure the quality of the solution in this area through build times, lead times to production, testing capabilities, release confidence, employee satisfaction (eNPS?), security, and process transparency metrics.</p>

<blockquote>
  <p><strong>Flow efficiency -</strong> every workflow is composed of periods of problem-solving focused work and everything else (less important work and wait periods), the efficiency of the flow is the coefficient that shows what percentage of all the time you spend in the flow is actual problem-solving work.</p>
</blockquote>

<p>At this side of the equation, structure and method of delivery is the central point of the solution, the focus is mostly not on tools (apart from Kubernetes and few chosen specifics just for this analysis to even be possible), but on a way to utilize set of tools you chose to best manage any development process.</p>

<blockquote>
  <p>One of the key points of any analysis like this is actually leaving the solution open-ended to enable the development team to accommodate for new use cases.</p>
</blockquote>

<p><img alt="system for delivering microservice architecture to production" src="https://rastko.tech/images/two-scales-1.jpg">
<strong>In the picture -</strong> Developing and delivering a system with certainty and high quality is quite a complex set of tasks and problems on its own.</p>

<p>Creating fast and resilient tooling to deliver your application smoothly, and allow flexibility to set up a good process around it is the key. It is about technically enabling your engineering team and setting the whole team up for success.</p>

<blockquote>
  <p><strong>KPIs</strong> - ultimately, our solutions on this side would be measured by three main metrics:</p>
  <ul>
    <li>Lead Time for a change - mostly relaying on flow efficiency (less approvals needed, less process bottlenecks of other kinds) and technical characteristics of a build process (faster builds, faster quality checks…)</li>
    <li>Change failure rate - relying on QA and SRE, mostly backed by Defect Detection Percentage (DDP) that makes sure to detect as many as possible quality issues before code hits production, and MttR (Minimum time to Resolve) that makes sure that we can notice problems in prod earlier and solve them using various automatic or one-touch recovery tools.</li>
    <li>Deployment frequency - relying on quality and flexibility of the process and technical solutions with focus to make changes smaller and more frequent.</li>
  </ul>
</blockquote>

<blockquote>
  <p>Good further read on this topic is <a href="https://itrevolution.com/book/accelerate/">Accelerate</a>, the book which explains the approaches around building annual State of DevOps report.</p>
</blockquote>

<h3 id="the-second-scale">The second scale</h3>

<p>This side of your system takes the software over after it is delivered to production, it is the area where the long term stability of the app is defined. It is about a long term perspective of running it in production.</p>

<p>The scale of life is focused on operation, stability (resilience), security, and capacity planning. You measure the quality in this area through SLOs, API contract tests, quality of service, and incident response metrix (MttX).</p>

<blockquote>
  <p>This scale is about serving the end-user with a high-quality product, it is about the business value we are delivering and how to serve it in the best way.</p>
</blockquote>

<p>Deeper down it is all about operational tooling, telemetry, good capacity planning, and other more specific SRE approaches.</p>

<h2 id="the-devops-and-sre">The DevOps and SRE</h2>

<blockquote>
  <p><strong>KPIs and signals</strong> - KPIs (key performance indicators) of your service can be observed through two lenses:</p>
  <ul>
    <li>Operational - how good capabilities and people are working together, which is measured through Minimum time to Detect, Diagnose and Resolve a problem (MttX where X can be D for detect, R for resolve and many more based on what you want to measure). Signals to measure here are partly communicational - how automated the system is and how close are the teams involved, and partly in following category.</li>
    <li>Application - Quality on Service level, which is measured through service level objectives (how we want it to perform), indicators (what system metrics we use to determine this performance) and agreements /contract that we make with our clients in regards to how our app should perform (SLX). Signals we observe and combine in these case are also known as <strong>four golden signals - error rate, latency, traffic and saturation.</strong></li>
  </ul>
</blockquote>

<p>In order to efficiently handle the problem space we just defined, the team has to be able and empowered to fully own everything they are building. The team should also own the process, and sometimes the team itself. Depending on the size of the scope, the team, and the company, it might not be the same team owning the whole thing end to end, it might be a couple of teams working together in certain, hopefully, efficient collaboration.</p>

<p>This approach of high ownership is better known as DevOps, the concept aiming to blur the boundaries between software development, delivery, and operation, bringing it closer together, with the goal to make software development and delivery a lot more efficient and high quality.</p>

<blockquote>
  <p><strong>SRE -</strong> site reliability engineering is a set of software engineering practices focused on infrastructure reliability and operations. It is born from the direct application of DevOps methodologies on live systems with a heavy focus on automation and observability. SRE focused teams usually split their focus roughly 50-50 between software engineering (building tools, features, or automation), and operations/support tasks (like incident handling, on-call, and so on).</p>
</blockquote>

<blockquote>
  <p>Good further read on this topic and many other topics that I write about can be found in the <a href="https://landing.google.com/sre/sre-book/toc/">SRE book</a></p>
</blockquote>

<h3 id="to-tame-the-scales">To tame the scales</h3>

<p>Goal of delivering high-quality software as soon as possible represents both scales. It puts focus on smooth delivery of your software and making sure it is reliable (high quality). <strong>Taking DevOps concepts and more closely applying them to live systems belongs to the site reliability engineering (the SRE)</strong>.</p>

<p>Systems that are native to the cloud are able to adopt DevOps approaches faster than others through building tools and capabilities (like on-demand infrastructure for engineers, fast and safe releases, security-first design…).</p>

<p>If built correctly, these systems often have the right tool for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rastko.tech/blueprints/cloud/cloud-native/devops/sre/kubernetes/infrastructure/architecture/solutions/2020/11/02/two-scales-of-devops.html">https://rastko.tech/blueprints/cloud/cloud-native/devops/sre/kubernetes/infrastructure/architecture/solutions/2020/11/02/two-scales-of-devops.html</a></em></p>]]>
            </description>
            <link>https://rastko.tech/blueprints/cloud/cloud-native/devops/sre/kubernetes/infrastructure/architecture/solutions/2020/11/02/two-scales-of-devops.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977441</guid>
            <pubDate>Tue, 03 Nov 2020 07:58:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust from a Gopher – Lessons 3 and 4]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24977373">thread link</a>) | @BookPage
<br/>
November 2, 2020 | https://levpaul.com/posts/rust-lesson-3-and-4/ | <a href="https://web.archive.org/web/*/https://levpaul.com/posts/rust-lesson-3-and-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><em>Update: There has been discussion on this post on <a href="https://news.ycombinator.com/item?id=24977373">Hacker News</a> - feel free to see the comments there</em></p><p><em>Warning: Incoming opinion monologue; feel free to skip to <a href="#give-me-the-lessons">The Lesson Review</a> review if that’s what you’re after</em></p><p>Hello and welcome to the third post in my series about learning Rust. In case you want to hit it from the start, <a href="https://levpaul.com/posts/rust-lesson-1/">here’s</a> a link to the first one! This entire series covers my journey from being a completely land-locked Gopher to becoming (hopefully) a hardened Rustacean, able to skitter the hazardous seabed of any application safely.</p><h4 id="how-rust-is-makin-me-feel">How Rust is Makin' Me Feel</h4><p>Let me begin not by thwacking loosely about in concepts I know little yet of, as there’s plenty of time for that, but instead allow me to paint the landscapes I see for both Rust and Go. At quite the visceral it occurred to me that these modern languages are built not just to make our coding lives more delightful - but instead to shepherd us into particular engineering and organizational goals.</p><p>The needs for new general purpose languages no longer stem from the “simple” software problems. Take the problems of using variables (Assembly), using custom data types (C), cross-platform, cross-architecture compatibility (JVM languages) or even being dead simple (Python). Today’s languages can instead choose features from all the preceding and <em>then</em> apply engineering and organizational direction.</p><h4 id="the-coercion-of-go">The Coercion of Go</h4><p>I’ve been writing in Go as a hobby since 2014 but professionally only since 2018. As a hobbyist I’ll admit I used to think “Go is <em>opinionated</em>”. That seemed cool, because opinions mean something! Right? But <em>why</em> was it opinionated Levi, WHY? WAKE UP MAN!</p><p>Well today I have a completely different look on it. Go is simply a language that is very <em>safe</em> to share across engineers. This is because engineers don’t need to make a lot of decisions when they use Go. If an application has had its design completed in theory then in Go it often really is just a matter of whacking out the code to make it a reality.</p><p>Just look at how much of Go’s development tooling Google owns. With Java, I remember choosing between Ant or Maven for your build tooling. Go doesn’t let you chose. The closest we got to having a choice was with <code>dep</code> for dependency management. But finally Google caved and <code>gomod</code> was brought about as the standard. Go does its best to take choices away from you. You don’t need to chose between Tomcat or Jetty - the Go <code>net/http</code> package will handle 10kRPS for you no problem. Hell I’ve looked at apps serving 50kRPS, whilst <em>logging</em> a third of said requests simply using <code>fmt.Println</code>. You just don’t need to stray far from the standard library to scale and that is a huge plus of the language. (A large part of this is also comes from the fact that webservers haven’t changed a heck of a lot in the past 10 years so Go didn’t have to “keep up” - on the other hand my experience with http2 in Go has been far from ideal).</p><h5 id="_anyone_-can-pick-up-your-code-and-fix-it"><em>Anyone</em> can pick up your code and fix it</h5><p>This is by far the biggest selling point of using Go <em>in a company</em>. If you need to hire help you can find basically <em>anyone</em> with backend experience, and they will pick up 90% of Go in a week or two. You don’t need to worry at all if they have experience with Struts, JUnit or Spring - what’s in the standard library is plenty. I mean it. Do they need to know about passing pointers or values? Not really - general software engineering practices like peer review and simple unit testing will uncover those types of issues with ease.</p><p>Now on the other hand - who in their right mind would hire <em>me</em> to join their Rust team right now? Nobody - because I would be a gigantic liability to that team.</p><h5 id="gos-purpose-is-for-dev-shops-to-crank-out-web-services-that-are-scalable-easy-to-develop-and-do-not-require-mission-critical-performance">Go’s purpose is for dev shops to crank out web services that are scalable, easy to develop and do not require mission critical performance.</h5><h4 id="rust-no-rust">Rust no Rust</h4><p>I’m a noob. 100%. But even so, in my feeble mind I can already see what Rust is. I see a very sharp knife; but this knife is completely and utterly shrouded and encased in tamper-proof, child-proof, thief-proof hardened and sealed plastic shells. Yes shells as in the plural of shell. These shells are even adult-proof too, where the adult is a generic engineer trained generally in other languages only. The compiler is the packaging, and it will let you wield the knife when it knows exactly what your action plan is. -But oh no, not just any plan will do, your plan <em>must</em> adhere to each and every rule and regulation from the Knife Safety Measurement Act of 1938 and its associated amendments!! (This may not be strictly true as I’ve heard about an <code>unsafe</code> keyword).</p><p><em>But why so much plastic broseidon?</em> You know, and I know that it’s to keep mild-minded people like myself exactly, from nicking fingers with that very sharp knife. Warping back to a meta-level, those fingers don’t even necessarily belong to me the coder, but to the end users of the code. It is no secret to anybody even slightly interested in Rust that a major driving factor for the language was to be able to replace C++ code with something <em>as</em> efficient but much less susceptible to security exploits. Thus, the safety plastic aims not to protect individual coders, but the <em>coding organization</em>.</p><p>Okay, you’ve probably heard enough of my opinion, let’s move on before this analogy implodes and actually hurts someone.</p><hr><h2 id="give-me-the-lessons">Give Me The Lessons!</h2><h4 id="3-common-programming-conceptshttpsdocrust-langorgbookch03-00-common-programming-conceptshtml">3. <a href="https://doc.rust-lang.org/book/ch03-00-common-programming-concepts.html">Common Programming Concepts</a></h4><p>One of the first ‘huh’ moments in this lesson was this compiler message:</p><div><pre><code data-lang="rust"><span>compiler</span><span> </span><span>error</span>:
<span>For</span><span> </span><span>more</span><span> </span><span>information</span><span> </span><span>about</span><span> </span><span>this</span><span> </span><span>error</span><span>,</span><span> </span><span>try</span><span> </span><span>`</span><span>rustc</span><span> </span><span>--</span><span>explain</span><span> </span><span>E0384</span><span>`</span><span>.</span><span>
</span></code></pre></div><p>Naturally I ran the command listed, which took me to a <code>less</code> window (buffer?) containing the following:</p><div><pre><code data-lang="fallback">An immutable variable was reassigned.
Erroneous code example:
'''
fn main() {
    let x = 3;
    x = 5; // error, reassignment of immutable variable
}
'''
By default, variables in Rust are immutable. To fix this error, add the keyword
`mut` after the keyword `let` when declaring the variable. For example:
'''
fn main() {
    let mut x = 3;
    x = 5;
}
'''
</code></pre></div><p>…and this slightly let me down. There isn’t a whole lot of information in this “explanation”. I proceeded to allow <code>rustc</code> to “explain” some more random error codes to me, most of them seemed also to be quite small or to have been deprecated. I am hoping either A) I don’t have to use this feature much or B) I can make rustc/cargo/intellij just tell me the detailed stuff by default.</p><hr><div><pre><code data-lang="rust"><span>const</span><span> </span><span>MAX_POINTS</span>: <span>u32</span> <span>=</span><span> </span><span>100_000</span><span>;</span><span> </span><span>// wtf is this ugly numeric shit
</span></code></pre></div><p>For some reason this irked me when I first saw it (the comment taken verbatim from my lesson notes). On second look it actually seems really, really helpful for readability.</p><hr><h4 id="shadowinghttpsdocrust-langorgbookch03-01-variables-and-mutabilityhtmlshadowing"><a href="https://doc.rust-lang.org/book/ch03-01-variables-and-mutability.html#shadowing">Shadowing</a></h4><p>This seems like a really handy trick. You get to write code as if your variable was immutable, but the compiler does the switching for you. What is really messing my head up though is that you learn about Shadowing before you learn about Ownership. So does my naive understanding of shadowing change after this? I don’t think so … at least. Here’s something I wrote to verify my learnings:</p><div><pre><code data-lang="rust"><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>s</span><span> </span><span>=</span><span> </span><span>String</span>::<span>from</span><span>(</span><span>"hello"</span><span>);</span><span>
</span><span>    </span><span>let</span><span> </span><span>r1</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>s</span><span>;</span><span>
</span><span>    </span><span>let</span><span> </span><span>r1</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>s</span><span>;</span><span>
</span><span>    </span><span>println</span><span>!</span><span>(</span><span>"{}"</span><span>,</span><span> </span><span>r1</span><span>);</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>…and it works. It also answers a question I had when originally learning ownership. For some reason when reading the examples in the book I came away thinking Rust could infer when immutable references' scopes end, but not mutable ones. I was puzzled by this and had a follow-up item but this little example proves I was wrong. Happy days!</p><hr><h5 id="small-nit">Small Nit?</h5><p>The <a href="https://doc.rust-lang.org/book/ch03-02-data-types.html#invalid-array-element-access">Invalid array element access example</a> didn’t work - it was supposed to produce a runtime error but instead it failed to compile:</p><div><pre><code data-lang="rust"><span>   </span><span>Compiling</span><span> </span><span>variables</span><span> </span><span>v0</span><span>.</span><span>1.0</span><span> </span><span>(</span><span>/</span><span>home</span><span>/</span><span>levi</span><span>/</span><span>rustprojs</span><span>/</span><span>variables</span><span>)</span><span>
</span><span></span><span>error</span>: <span>this</span><span> </span><span>operation</span><span> </span><span>will</span><span> </span><span>panic</span><span> </span><span>at</span><span> </span><span>runtime</span><span>
</span><span> </span><span>-</span>-&gt; <span>src</span><span>/</span><span>main</span><span>.</span><span>rs</span>:<span>5</span>:<span>19</span><span>
</span><span>  </span><span>|</span><span>
</span><span></span><span>5</span><span> </span><span>|</span><span>     </span><span>let</span><span> </span><span>element</span><span> </span><span>=</span><span> </span><span>a</span><span>[</span><span>index</span><span>];</span><span>
</span><span>  </span><span>|</span><span>                   </span><span>^^^^^^^^</span><span> </span><span>index</span><span> </span><span>out</span><span> </span><span>of</span><span> </span><span>bounds</span>: <span>the</span><span> </span><span>len</span><span> </span><span>is</span><span> </span><span>5</span><span> </span><span>but</span><span> </span><span>the</span><span> </span><span>index</span><span> </span><span>is</span><span> </span><span>10</span><span>
</span><span>  </span><span>|</span><span>
</span><span>  </span><span>=</span><span> </span><span>note</span>: <span>`</span><span>#[deny(unconditional_panic)]</span><span>`</span><span> </span><span>on</span><span> </span><span>by</span><span> </span><span>default</span><span>
</span></code></pre></div><p>I don’t even know if I should call this a nit or just straight up be impressed. Did Rust <em>evolve</em> to the point the <em>book</em> can no longer trick me into making a runtime panic?! This is some straight-jacket level packaging I swear to god. Much applause.</p><hr><h4 id="_a-smol-walk-in-the-woods_"><em>A smol walk in the woods</em></h4><p>Having picked up many a good pointer during this lesson I figured I had bumped myself up a couple of notches. Maybe white-belt, double-yellow-tip or something along those lines… “<em>Let’s go for a wander</em>” I thought to myself with quiet confidence. Looking left, and then looking right, under the shelter of a single raised eye-brow I chose to descend toward the belly of Rust.</p><p><em><strong><code>Ctrl + *click*</code></strong></em></p><p>I chose a simple avenue. I chose something concrete to all beginners. I chose the pinnacle of <code>Hello_World</code>…</p><p>I chose to dive into <code>println!</code></p><p>… and dive I did. Straight into the ground after clanking my head into a hard iron post of this macro. My eyes but glimpsed Sauron directly and from then on and always, I am blind:</p><div><pre><code data-lang="rust"><span>#[macro_export]</span><span>
</span><span></span><span>#[stable(feature = </span><span>"rust1"</span><span>, since = </span><span>"1.0.0"</span><span>)]</span><span>
</span><span></span><span>#[allow_internal_unstable(print_internals, format_args_nl)]</span><span>
</span><span></span><span>macro_rules</span><span>!</span><span> </span><span>println</span><span> </span><span>{</span><span>
</span><span>    </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>$crate</span>::<span>print</span><span>!</span><span>(</span><span>"\n"</span><span>));</span><span>
</span><span>    </span><span>(</span><span>$($arg</span>:<span>tt</span><span>)</span><span>*</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>({</span><span>
</span><span>        </span><span>$crate</span>::<span>io</span>::<span>_print</span><span>(</span><span>$crate</span>::<span>format_args_nl</span><span>!</span><span>(</span><span>$($arg</span><span>)</span><span>*</span><span>));</span><span>
</span><span>    </span><span>})</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>What in God’s sweet name is this acrid assault on all of my senses?</p><p>I am going to be honest here. There is no way in hell I will understand this macro by the end of my twentieth lesson. Will I?
I’m not sure actually. I guess there’s hope? Chapters <a href="https://doc.rust-lang.org/book/ch10-00-generics.html">10</a>, <a href="https://doc.rust-lang.org/book/ch14-00-more-about-cargo.html">14</a> and <a href="https://doc.rust-lang.org/book/ch19-00-advanced-features.html">19</a> all look they will be mandatory. <em>Hoping Intensifies … ?</em></p><hr><h4 id="expressions-versus-statements">Expressions versus Statements</h4><blockquote><p>If you add a semicolon to the end of an expression, you turn it into a statement, which will then not return a value. Keep this in mind as you explore function return values and expressions next.</p></blockquote><p>This was a mind fuck - about 10 minutes before reading this I thought to myself that semi-colons seemed optional and kind of pointless in rust. Boy was I well outside the woods.</p><p>A later thought did have me wondering though; do Rustaceans really just write expressions at the end of their getter functions or is it more common to explicitly <code>return</code>?</p><hr><blockquote><p>In …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://levpaul.com/posts/rust-lesson-3-and-4/">https://levpaul.com/posts/rust-lesson-3-and-4/</a></em></p>]]>
            </description>
            <link>https://levpaul.com/posts/rust-lesson-3-and-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977373</guid>
            <pubDate>Tue, 03 Nov 2020 07:46:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeBSD Wall Display Computer – TykBlog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24977319">thread link</a>) | @rodrigo975
<br/>
November 2, 2020 | https://blog.tyk.nu/blog/freebsd-wall-display-computer/ | <a href="https://web.archive.org/web/*/https://blog.tyk.nu/blog/freebsd-wall-display-computer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    

                    <!-- Author -->
                    <p>
                        by <a href="https://blog.tyk.nu/about/">Tykling</a>
                    </p>
                    <hr>
                    
                    <!-- Date/Time -->
                    <p><span></span> 10. oct 2020 16:22 UTC</p>

                    <hr>

                    <!-- Post Content -->
                    <p>I've recently added a wall mounted 30" monitor for Grafana in my home. I can highly recommend doing the same, especially in a world where more work from home is becoming the norm.</p>

<p>Having metrics visible at all times can be incredibly helpful in spotting trends and issues. This is the reason we all have wall mounted Grafanas in our workplaces! Since we are all going to be working from home for the foreseeable future it makes sense to have visible metrics at home as well. Also, much of the stuff I need metrics for is not work related at all - <a href="https://blog.uncensoreddns.org/">UncensoredDNS</a> for example, the <a href="https://bornhack.dk/bornhack-2020/">BornHack</a> infrastructure, and so on. I see no reason why projects run outside of $dayjob should receive any less attention, such as visualisation of metrics.</p>

<p>Sometime before summer I physically mounted the screen using <a href="https://vivo-us.com/collections/monitor-mounts/products/stand-v002l">this very nice</a> over/under 2 monitor stand, and then started considering which computer to use for it. Ideally something I already had lying around, and of course something with enough power to run some Grafana dashboards without choking.</p>

<p>Not for a moment had I anticipated that actually displaying the graphs in a browser that doesn't crash constantly would be the most time-consuming part of getting this up and running. I mean, I've spent hours playing with various Prometheus exporters for all the different servers I run (and Ansible roles for them). I've also spent hours fiddling with Grafana dashboards until they show the level of information I like. Both of these are complex jobs and and I am absolutely fine with spending time on them. But when I finally had nice working dashboards in my Firefox browser on my laptop I fully expected it to be trivial to put those on a monitor on the wall. It was not. This tale is left here for future metrics aficionados in the hopes that you will spend less time on this dreary task than I did.</p>

<p>I've documented the failed attempts as well as the final well-working solution. Feel free to skip over the first two sections if you are just here to learn what works :)</p>

<h3>First Attempt: ODROID-C2 with Ubuntu</h3>
<p>Originally I wanted to use an <a href="https://wiki.odroid.com/odroid-c2/odroid-c2">ODROID C2</a> which I had lying around because I used it as a mediacenter with <code>Kodi</code> provided by <code>Liberelec</code> previously. This seemed like a good choice, I mean if it can show a 1080p video without choking it should be able to render a few <code>Grafana</code> dashboards, right?</p>

<p>The <code>ODROID-C2</code> is an <code>Amlogic S905</code> SOC with a <code>Cortex A53</code> ARMv8 64bit CPU. It has 4 cores and 2GB RAM. It supports <code>eMMC</code> storage which is a nice and faster alternative to the SD cards used by many of the "Raspberry PI-sized" computers that exists today.</p>

<p>I tried to figure out wether it was possible to run <code>FreeBSD</code> on it, but the <a href="https://www.freebsd.org/platforms/arm.html">ARM Wiki page</a> seems to say that 64bit ARM support is still being worked on. I thought it was too much to hope for anyway.</p>

<p>Then I tried to go for a stock Debian, but that didn't boot at all. Turns out I need to use either the <a href="https://wiki.odroid.com/odroid-c2/os_images/ubuntu/ubuntu">Ubuntu</a> image provided by the ODROID people, or a <a href="https://wiki.odroid.com/odroid-c2/os_images/third_party">third party</a> OS image.</p>

<p>Once I got Ubuntu up and running and found a Firefox browser it quickly became apparent that it would not work. The browser kept freezing up, or crashing, or both. I tried using Chromium which annoyingly worked a bit better. It was not stable, but it would run for half a day or maybe a day and then stop working somehow. And this was with just one dashboard, If I opened another tab with another Grafana dashboard it made matters worse.</p>

<p>It wasn't immediately clear what the problem was, in hindsight it was probably RAM, but either way I decided to try something else.</p>

<h3>Second Attempt: Raspberry PI 3b+ with Raspbian</h3>
<p>I had an RPI3b lying around and decided to try that instead. I am not a big fan of the RPI platform in general, I've had way too many weird issues over the years, I guess I just prefer a more normal computer. But I needed something to show my graphs, so I launched <a href="https://www.raspberrypi.org/downloads/noobs/">NOOBS</a> and asked it to install <code>Rasbbian</code> and I was pretty soon up and running with graphs on my wall again.</p>

<p>The Raspberry PI 3b+ has a full 1GB of RAM, much more than previous PIs, but only half of what the <code>ODROID-C2</code> has. It still performed about the same as the <code>ODROID-C2</code>. It didn't work at all with Firefox, with Chromium it was okay with a single tab or two, but after 12-24 hours it would stop working. Sometimes it would be an "unresponsive tab" error from the browser, and sometimes the whole OS would freeze up completely.</p>

<p>Around this time the annual <a href="https://bornhack.dk/bornhack-2020/">BornHack</a> was approaching, so my attention was needed elsewhere. I made due with the unstable PI for a couple of months - daily reboot helped a little, but it isn't exactly a nice solution.</p>

<h3>Third Time is the Charm: A NUC with FreeBSD</h3>
<p>So last week I finally got around to taking another whack it. No more beating around the bush, I was going to buy something with enough power, and then some. I started looking around and soon found that a Danish shop with pickup service had an Intel <code>NUC8I7BEH</code> in stock. While physically larger than the Raspberry PI and ODROID-C2 (it is just under 12x12cm long and wide, and just under 6cm tall, including the VESA mount), it is still a pretty small computer.</p>

<p>I picked it up around along with 2 sticks of <code>Kingston 16GB DDR4 2400MHz SODIMM</code> non-ECC RAM, (the NUCs are delivered as a "kit" without RAM and storage) and a <code>Samsung 870 QVO MZ-77Q1T0BW</code> 1TB SATA SSD. Assembling it was really easy, four screws and and a couple of minutes later the RAM and SSD were in, and the NUC POST revealed it found all 32GB RAM and also the SSD. It refused to boot from the FreeBSD installer USB stick though. This was because secure boot was enabled in the BIOS. After disabling it the FreeBSD install was absolutely standard, no issues at all.</p>

<p>This was in the beginning of October 2020 so the latest <code>12-STABLE</code> was something like <code>12.2-BETA3</code> or so, it doesn't really matter since I upgrade to latest <code>12-STABLE</code> after installing anyway. As always I used the auto-ZFS option in the installer so I can use <code>bectl</code> to make nice boot environments for easy rollbacks in case of problems when upgrading.</p>

<p>A quick <code>pkg install xorg slim fluxbox firefox</code> and a bit of fiddling later I was looking at a very smoothly running Grafana dashboard in X. The rest of this blogpost is about the configuration of FreeBSD, X, Slim, Fluxbox and Firefox for an ideal wall-mounted Grafana screen. Much of this is done in Ansible, but not all of it. I've documented everything here for the sake of completeness, but a lot of basic configuration is done by my Ansible roles, and is not that relevant for this blogpost. Stuff like configuring syslog, monitoring, SSH keys and all the other sysadminy stuff that all machines need. This blogpost just focuses on what to do to go from a fresh FreeBSD machine to a well oiled Grafana wall display.</p>

<p>Finally: I realize that comparing a NUC to a Raspberry PI is not even close to a fair comparison, for starters the NUC is ten times more expensive. It has a powerful <code>CPU: Intel(R) Core(TM) i7-8559U CPU @ 2.70GHz (2712.12-MHz K8-class CPU)</code> and 32GB memory, so obviously it is going to perform a lot better. But overkill was the whole point of this exercise! I  had spent <i>far</i> too much time faffing about with insufficient hardware and at this point I was perfectly happy to throw money at the problem until it went away. YMMV.</p>

<h3>Dedicated User</h3>
<p>First off I added a dedicated user to show the graphs, since I intend to enable autologin for this setup. This user is not going to have <code>wheel</code> or <code>sudo</code> access, it really only has to be able to start X and Firefox. I also have another user with my regular SSH key which I used for debugging and whatever else is needed (rarely sysadm stuff though, since that is handled by Ansible).</p>


<h3>X Configuration</h3>
<p>On modern FreeBSD X mostly configures itself, but the <code>i7-8559U</code> inside the <code>NUC8i7BEH</code> is a Gen9 Intel Coffee Lake CPU, the integrated <code>Iris Plus Graphics 655</code> GPU inside it is too new to be supported by the <code>i915kms</code> module in FreeBSD base. This is the output from <code>pciconf -lv</code> concerning the GPU:</p>

<pre>vgapci0@pci0:0:2:0:     class=0x030000 card=0x20748086 chip=0x3ea58086 rev=0x01 hdr=0x00
    vendor     = 'Intel Corporation'
    device     = 'Iris Plus Graphics 655'
    class      = display
    subclass   = VGA
</pre>

<p>Fortunately there is a meta-port called <code>drm-fbsd12.0-kmod</code> (which also works on 12.2 it seems) which installs a newer <code>i915kms.ko</code> which supports the GPU. Since building the driver requires kernel sources it is not available from the official FreeBSD package builders, and since I needed to upgrade anyway I started a <code>buildworld</code> with the following beauty of a oneliner (run as root, not with sudo): <code>time (make -j$(sysctl -n hw.ncpu) buildworld &amp;&amp; make -j$(sysctl -n hw.ncpu) kernel &amp;&amp; mergemaster -pFUi &amp;&amp; make installworld &amp;&amp; mergemaster -FUi &amp;&amp; make BATCH_DELETE_OLD_FILES=yes delete-old &amp;&amp; make BATCH_DELETE_OLD_FILES=yes delete-old-libs) &amp;&amp; date</code>. Note that a reboot before the first <code>mergemaster</code> is recommended, but for small upgrades I usually don't bother. If <code>installworld</code> fails with weird errors try again after a reboot :)</p>

<p>Including a few minutes for some <code>mergemaster</code> fun near the end it took just 59 minutes before I had a newly built world and kernel. Then I could build the driver from ports, and add the line <code>kld_list="boot/modules/i915kms.ko"</code> to <code>/etc/rc.conf</code> and reboot. After the reboot X started with no issues at all. For reference this is a <code>dmesg(8)</code> from the NUC after the new driver was enabled (I've highlighed the GPU related stuff):</p>

<pre>[tykling@nuc1 ~]$ sudo cat /var/run/dmesg.boot 
---&lt;<boot>&gt;---
Copyright (c) 1992-2020 The FreeBSD Project.
Copyright (c) 1979, 1980, 1983, 1986, 1988, 1989, 1991, 1992, 1993, 1994
        The Regents of the University of California. All rights reserved.
FreeBSD is a …</boot></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tyk.nu/blog/freebsd-wall-display-computer/">https://blog.tyk.nu/blog/freebsd-wall-display-computer/</a></em></p>]]>
            </description>
            <link>https://blog.tyk.nu/blog/freebsd-wall-display-computer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977319</guid>
            <pubDate>Tue, 03 Nov 2020 07:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimization: what I did to make the game 300 times faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24977108">thread link</a>) | @Woseseltops
<br/>
November 2, 2020 | https://thesaplinggame.com/devlogs/optimization.html | <a href="https://web.archive.org/web/*/https://thesaplinggame.com/devlogs/optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_column">
		<div id="main_area">
			
<div id="label_bar"><p>Announcement</p><p>Technical</p><p>Graphics</p><p>Music</p></div>
<p id="first_p">A major point of feedback for evolution simulator The Sapling is that the players wanted larger levels. To make this possible, I spent three months optimizing the underlying game engine. This article is an in-depth explanation of one of the main insights I had. There are several interactive simulations you can play with in your browser to get a deeper understanding of how everything works.</p>
<p><span id="first_character">T</span>he first major update for The Sapling, the flower update, was released in September. It adds pollination, flowers (obviously), a new scenario, a complete overhaul of the sandbox level, bioluminescence and much more. A number of scenes from the trailer:</p>
<video width="320" loop="" autoplay="" muted="">
  <source src="https://thesaplinggame.com/devlogs/optimization/flower_highlights.mp4" type="video/mp4">
</video>

<p>Importantly, it addresses a major point of feedback that kept coming back: players wanted more space for their creations to grow and evolve. I couldn't easily make the levels larger, however, because the game already had performance problems in the smaller levels and with each new spot where organisms could live this would get worse exponentially. The hard part is that there are not one, but two computationally heavy things going on at the same time: simulating an ecosystem where hundreds of organisms are all doing their own things (moving, eating, reproducing, mutating) AND visualizing these hundreds of objects. With larger levels, this would be thousands, essentially bringing the game to a halt with 1 frame per 5 seconds (FPS) instead of the regular 60 per 1 second. </p>
<p>Besides my obvious desire to please the players, having larger levels was also crucial for my own ambitions with the game, because a number of the simulation mechanics didn't really work with the smaller maps; for example, why evolve an instinct to run away from a predator if you have nowhere to go? Or for plants, why evolve things like bark or high leaves if the biggest reason that your offspring is dying is because all seeds are landing on spots that are already taken? In nearly 100% of the cases, all plants evolved to do was getting as much offspring as possible, in the hopes that at least one of them by accident landed in a spot that was free.</p>
<p>In other words, if there was going to be one major feature in the first big update, it should be larger maps. To make this possible, I spent 3 months in the beginning of 2020 with that one focus: optimize, optimize, optimize the game's code, so I could get that FPS up and shave off more of the milliseconds it takes to render a scene. It was frustrating at times, but the main feeling I remember was actually excitement, as this really forced me to investigate the major bottlenecks (when I close my eyes, I can still see the Unity profiler), and come up with several new creative solutions for them. During this period I was reading a book about how John Carmack, the brilliant programmer behind the first Doom engine, was doing endless optimizations to make first person shooters a reality in the 90s, which was a great help in keeping me motivated.</p>
<p>While I implemented all kinds of larger and smaller ideas that made significant positive contributions to the performance of the game, there is one insight that had the biggest impact for the visualization part of the problem (how do you show thousands of unique organisms on screen?), which is to <strong>fake it before you make it</strong>. Let's go through my thought process step by step to see what I mean by that in this context. For every step, there is an interactive simulation you can run in your browser, so you can play with the idea yourself.</p>
<h2>Step 1: the raw, unoptimized goal</h2>
<p>This is the basic idea, without any optimization: players can add their self created species somewhere in the world, and see whether it is strong enough to survive. In the interactive example below, you can add two species, 1 and 2, and then run the simulation. </p>








<p>The simulation and subsequent visualization should be instant in your browser, but this is of course a 2D table with precreated images. When we have to create fully animated 3D models in a 3D world instead, it quickly becomes too much. </p>
<hr>
<p>The main problem is that building an organism in 3D is expensive.</p>
<hr>
<p>The main problem is that <strong>building/visualizing an organism in 3D is expensive</strong>. While I have done major rewrites of the code that builds plants and animals, mostly focusing on not doing things twice and skipping parts of the procedure that are not 100% necessary (like building the roots of plants that are underground anyway), creating new organisms from scratch remained, and still is, expensive.</p>
<h2>Step 2: object pooling</h2>
<p>The textbook solution when a lot of objects need to be created and removed in a game is to use object pooling. The idea is that when an object dies (in The Sapling, quite literally), the game object is not destroyed but reincarnates as the next object that is created, instantly moving to the position of the newborn organism and resetting any animations it was showing. That is, you think you are looking at a large amount of objects being created and destroyed again, but in reality you are looking at a smaller amount of objects that are just changing locations quickly.</p>
<p>In the interactive example below, I have added a pool to the right. When plants die, their models are either immediately reused or are stored in the pool until they are needed again, so a lot less 3D models need to be created. Comparing this simulation to the one above, the difference becomes clear when you skip 10 days a few times; in the first simulation, the model identifier (the part below each plant were it says 'model 10', for example) gets higher and higher, while here it stays low, reflecting the small number of 3D models that needed to be created.</p>




<p>Object pooling greatly improves the FPS in a stable ecosystem, as you can simply reuse what you already have and there is no need to create new objects on the fly. Unfortunately, in practice ecosystems in the game are very frequently unstable, most notably in the beginning of every new scenario when there is empty land to colonize. In other words, an object pool is not going to help if that pool is empty... so we'll also need a faster way to fill it.</p>
<h2>Step 3: prebuilt organism library</h2>
<p>So far, when a plant was not available in the pool, we built it from scratch. If we are building a 3D model that we have built before, however, this is not necessary: why not store an example somewhere and just copy it? This is more expensive than taking an object from the pool, but way cheaper than building it from scratch. In the current example, there is a limited number of species (species 1 and species 2), so that would mean we only have to build a 3D model two times, and then be done with it.</p>




<p>At this point, we will get an acceptable FPS in an ecosystem with a small number of species, and no variation within a species... which is actually the case during the scenarios! In the sandbox mode, however, there is a <em>random mutations mode</em> that has a 30% chance of introducing a random change to a newborn plant or animal; that is, for 1 out of 3 newborn plants we won't have anything in the object pool AND the prebuilt organism library, so we're back to building from scratch.</p>
<h2>Step 4: faking it and showing ancestors instead</h2>
<p>I came up with this final step when actually playing around with the (then still sluggish) random mutations mode in larger levels. The main insight is that in random mutations mode the player has no idea of what something is supposed to look like. For example, if a new plant is a little taller than its ancestors, but this is not shown to the player, will the player ever know? Almost certainly not, in particular if you take into account that the player is often looking at hundreds of plants and animals simultaneously. On the other hand, will the player notice performance problems? Yes, for sure... so a 100% smooth experience should get a higher priority than a 100% accurate visualization.</p>
<hr>
<p>The player has no idea of what something is supposed to look like</p>
<hr>
<p>In practice, this means that if random mutation leads to a completely new organism, the game will not automatically build it from scratch, even though it is not in the pool or the library. Instead, it will look at what was shown for the parent and show this as a substitute. Later, when the game has time to breathe, the missing model might be added to the library. The game keeps track which organisms have a 'fake' appearance, and I can vary in how fast gaps in the library should be closed. Right now, I have settled on building a maximum of 1 organism per second. </p>
<p>In the simulation below, random mutations are turned on for the first time. This means that after some time you will not only see plants like the ones you added yourself (species 1 and species 2); instead, the number will go up each time a newborn plants changes a little bit from its parent, so after some time you will see species 3, species 4, species 5, etc. The accompanying model, however, will NOT change, meaning that the real plant and its 3D model go out of sync; the name will turn orange if this is the case. So you might see the model of a plant 1, while the text in orange tells you it is actually a plant 3. To catch up, you have to click the 'Add 1 model to library' button.</p>




<p>And this way, we have scaled back from building hundreds of 3D models per second to just one! Of course, there are a number of details, quirks and edge cases that I have left out of the explanation above to keep things simple. Two of them I want to mention to give you a more complete idea of the problem:</p>
<ul>
<li>In the simulation above, whenever you create a new 3D model, it's just the next one in line. In the real game, I'm trying to do this smarter by looking at which organisms are visually the most different from the 3D model they are using. That is, an animal that evolved an extra pair of feet is way more likely to get its model updated than a plant that evolved deeper underground roots.</li>
<li>When you leave the simulation running for a longer …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesaplinggame.com/devlogs/optimization.html">https://thesaplinggame.com/devlogs/optimization.html</a></em></p>]]>
            </description>
            <link>https://thesaplinggame.com/devlogs/optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24977108</guid>
            <pubDate>Tue, 03 Nov 2020 06:55:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Host Your Own Private Git Repos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24976912">thread link</a>) | @deafcalculus
<br/>
November 2, 2020 | http://www.sagargv.com/blog/host-your-own-private-git-repos/ | <a href="https://web.archive.org/web/*/http://www.sagargv.com/blog/host-your-own-private-git-repos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><em>Mar 31, 2018</em></p>
<p>Hosting git repos on your own server is actually quite easy.
Login to the server, create a new directory, and initialize a bare repo:</p>
<pre><code>mkdir foo.git
cd foo.git
git init --bare
</code></pre>

<p>That's it! Now, from the client, clone this repo with:</p>
<pre><code>git clone username@example.com:path/to/foo.git
</code></pre>

<p>Having a dedicated user for git repos on the server makes it easier share access to the repo.
Create a new user <code>git</code> with a login shell restricted to git commands:</p>
<pre><code>sudo adduser --shell $(which git-shell) git
</code></pre>

<p>Now create a repo in the home directory of the <code>git</code> user:</p>
<pre><code>cd /home/git
sudo -u git mkdir bar.git
cd bar.git
sudo -u git git init --bare
</code></pre>

<p>As before, clone the new repo from the client using:</p>
<pre><code>git clone git@example.com:bar
</code></pre>

<h2>Backup the repos</h2>
<p>This is my script to take daily backups of all the git repos on the server to Amazon S3.</p>
<pre><code>#!/bin/bash

set -e

GITDIR=/home/git
TMPDIR=/tmp/gitbackup

renice -n 15 $$

trap "rm -f /tmp/gitbackup/*.git.tar.gz" EXIT

mkdir -p ${TMPDIR}
cd ${TMPDIR}

for proj in ${GITDIR}/*.git; do
    base=$(basename $proj)
    tar -C $GITDIR -zcf ${base}.tar.gz $base
done

export AWS_ACCESS_KEY_ID=xxxxx
export AWS_SECRET_ACCESS_KEY=yyyyy
export AWS_DEFAULT_REGION=us-west-2

aws s3 cp ${TMPDIR}/*.git.tar.gz s3://mygitbucket/
</code></pre>

<p>If the repos are large, it might be worthwhile checking whether
the hash of the gzipped repo has changed before uploading.
It's also good idea to use <code>envdir</code> to manage the access keys rather
than putting them in the backup script.</p>
<h2>Web front-end using cgit and nginx</h2>
<p>Sometimes it's useful to view source code and commits on a
web browser. <code>cgit</code> is an awesome light-weight webapp for this.
Unlike heavy apps like GitLab, <code>cgit</code> needs no database, which
reduces the administrative burden.</p>
<p>Install cgit, nginx, fcgiwrap, and apache-tools (to create a <code>.htpasswd</code> file).</p>
<pre><code>sudo apt install cgit nginx fcgiwrap apache2-utils
</code></pre>

<p>Specify the location of the git repos and static assets in the 
<code>cgit</code> config at <code>/etc/cgitrc</code>.</p>
<pre><code>css=/cgit-static/cgit.css
logo=/cgit-static/cgit.png
favicon=/cgit-static/favicon.ico

#source-filter=/usr/lib/cgit/filters/syntax-highlighting.py

scan-path=/home/git/
</code></pre>

<p>To get syntax highlighting, install <code>python-pygments</code> and uncomment the source-filter option.</p>
<p>If you'd like to password protect access to <code>www.example.com/git/</code>, create a <code>.htpasswd</code> file:</p>
<pre><code>sudo htpasswd /etc/nginx/.htpasswd &lt;username&gt;
</code></pre>

<p>This is my <code>nginx</code> conf file to serve <code>cgit</code> from <code>www.example.com/git/</code>.</p>
<pre><code>server {
    listen 80;
    listen [::]:80;

    server_name www.example.com;

    location /.well-known/acme-challenge/ {
        root /var/www/www.example.com;
    }
    location / {
        return 301 https://www.example.com$request_uri;
    }
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;

    server_name www.example.com;

    ssl_certificate /etc/letsencrypt/live/www.example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/www.example.com/privkey.pem;

    location /cgit-static/ {
        alias /usr/share/cgit/;
    }

    location /cgit/ {
        auth_basic "Restricted";
        auth_basic_user_file /etc/nginx/.htpasswd;

        include fastcgi_params;
        fastcgi_split_path_info ^(/cgit)(.*)$;
        fastcgi_param   PATH_INFO        $fastcgi_path_info;
        fastcgi_param   SCRIPT_FILENAME  /usr/lib/cgit/cgit.cgi;
        fastcgi_param   QUERY_STRING     $args;
        fastcgi_param   HTTP_HOST        $server_name;
        fastcgi_pass    unix:/var/run/fcgiwrap.socket;
    }

    location / {
        root /var/www/www.example.com;
    }
}
</code></pre>

<p>You might also want to restrict repo access to only whitelisted IPs.</p>
<hr>
<p>
    <a href="http://www.sagargv.com/blog/">Archive</a> ·
    <a href="http://www.sagargv.com/blog/atom.xml">RSS</a> ·
    <a href="http://eepurl.com/doq18z" rel="nofollow" target="_blank">Mailing list</a>
</p>

        </div></div>]]>
            </description>
            <link>http://www.sagargv.com/blog/host-your-own-private-git-repos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24976912</guid>
            <pubDate>Tue, 03 Nov 2020 06:22:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nassim Taleb vs. Nate Silver: who is right about election forecasting?]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 154 (<a href="https://news.ycombinator.com/item?id=24976175">thread link</a>) | @probe
<br/>
November 2, 2020 | http://quant.am/statistics/2020/10/11/taleb-silver-feud/ | <a href="https://web.archive.org/web/*/http://quant.am/statistics/2020/10/11/taleb-silver-feud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Perhaps lost in the whirlwind of presidential name-calling, a lesser-known multi-year old feud has resurfaced on Twitter this election season. Nate Silver is the founder of <a href="https://fivethirtyeight.com/">FiveThirtyEight</a> and is a popular statistician frequently called upon by media members to give commentary and expertise on election forecasting. Nassim Taleb is a statistician/quant turned philosopher, perhaps most well known for authoring the book “The Black Swan”. He is second most well known for calling people names on Twitter. In this 2018 instance he seemed to take issue with FiveThirtyEight’s election forecasts, saying that <a href="https://twitter.com/nntaleb/status/1059202026184282113">“klueless Nate Silver” “doesn’t know how math works”</a>, among a host of other insults. Silver responded that Taleb was an <a href="https://twitter.com/NateSilver538/status/1062782704159256576">“intellectual-yet-idiot”</a>, an phrase coined by Taleb himself. Ouch. A litany of statisticans, mathematicians, and data scientists came out of the woodwork to take sides. Taleb himself <a href="https://twitter.com/nntaleb/status/1314902682570764288">doubled down</a> on Oct. 10, 2020, again calling Silver “totally clueless”.</p>

<p>In this article I take a look behind the mathematical premises of Taleb’s arguments, and give intuitive explanations of why or why not they hold up. In short, while Taleb’s math is sound, he still manages to miss the mark by ignoring the nuance of Silver’s forecasts.</p>

<p>Taleb’s main gripe is that forecasters change their opinion too much over time. Take a look at FiveThirtyEight’s forecast from the 2016 presidential election, where the probability of Clinton winning peaked at 90%, and hit a low of 50%. 
<img src="http://quant.am/assets/2016election.png" alt="2016 election"></p>

<p>Taleb insists that Clinton never should’ve received a probability of winning of 90%. Even if polls were heavily in favor of Clinton at the time, he says Silver should’ve taken into account the uncertainty that polls would change over the next few months leading up to the election, or the possibility of major news breaking. If Silver had factored in the “unknown unknowns” his forecast should’ve been closer to 50%. In essence, this single number should reflect all <em>current and future uncertainty</em>. Taleb constructs this argument by way of quantitative finance, which perhaps led to him and traditional statisticians talking past each other. In the following sections I step through his argument in intuitive terms.</p>


<p>A well known truth to economists, quants, and traders: if I tell you a number, I must be willing to transact at that number. If I tell you the fair value of this house is $500,000, I must be willing to buy AND sell at that price. Otherwise, the number I gave you is meaningless. Likewise, if I tell you the probability of Biden winning this election is 73%, I must be willing to pay $0.73 to make the following wager: if Biden wins I receive $1, if he loses I receive $0.</p>

<p>This is important because it turns the predicted probabilities into a tradeable financial instrument known as a binary option. If the prediction is 50%, I can buy the option at $0.50. If the prediction moves to 65%, I can now sell the option at $0.65, turning a $0.15 profit.</p>

<p>This brings us to another important principle known as the <em>no-arbitrage condition</em>. If the election predictions are accurate, there should be no way for a trader to make guaranteed money by trading this option. To give an illustrative example, let’s say that we live in an unchanging world where the probability of Candidate A winning is static at 50%. If a pollster does not report a static forecast day after day, he will create an arbitrage opportunity. We will sell when the prediction is above 50%, and buy below. 
<img src="http://quant.am/assets/arbitrage-pollster.jpeg" alt="Arbitrage condition"></p>

<p>OK, so now we’ve established that if an arbitrage condition exists, then the pollster is wrong and should not have made that prediction in the first place. Still, it’s not obvious that there’s an arbitrage condition within Silver’s predictions yet (remember, the trader doesn’t have access to an oracle, and only has the same information available to him as the pollster). There’s two more building blocks that we need in order to establish an arbitrage condition.</p>


<p>To paraphrase Taleb, if I tell you an event has a 0% chance of occurring, I cannot change my mind and tell you tomorrow it now has a 50% chance of occurring. Otherwise I shouldn’t have told you it has a 0% chance in the first place. Probability and confidence are inextricably linked, and the number a pollster predicts should encapsulate both. To go to the other extreme, if the uncertainty is extremely high (and therefore confidence low), <em>it does not matter what the polls today are saying</em>. I should give both candidates a 50% chance of winning, because I am admitting the extremely likely possibility that an external event will happen that will invalidate today’s polls. To put it in technical terms, maximum uncertainty implies maximum entropy, and the maximum entropy distribution on the [0, 1] interval is the uniform distribution, which has a mean at .5. The following figure (from <a href="https://arxiv.org/pdf/1703.06351.pdf">this paper</a>) shows the relationship between probability (x-axis) and volatility (y-axis) under a specific option pricing formulation.
<img src="http://quant.am/assets/confidence-probability.png" alt="Confidence vs volatility"></p>

<p>At this point we are suspecting something doesn’t look right with FiveThirtyEight’s predictions, as they seem to have both high volatility and high probability, which contradict each other. Where is the threshold though? How can we prove that the volatility is too high?</p>


<p>Now we’re going to go a little bit technical and show that a no-arbitrage condition was likely violated. The basic construction is as follows:</p>

<ol>
  <li>In order to satisfy the no-arbitrage condition, all information must be “priced in” into the pollster’s current prediction.</li>
  <li>Therefore, the time series of predictions must be a martingale.</li>
  <li>Martingales cannot show trending or mean-reverting behavior, therefore Silver’s predictions violated the martingale property, and therefore the no-arbitrage condition.</li>
</ol>

<p>The definition of a martingale is a stochastic process \(X_1, X_2, ... X_t\) that satisfies</p><p>

\[E[X_{t+1} | X_1, ... ,X_t] = X_t\]

</p><p>To quote <a href="https://www.researchgate.net/profile/Christopher_Wlezien/publication/344419648_Information_incentives_and_goals_in_election_forecasts/links/5f73c994a6fdcc0086484861/Information-incentives-and-goals-in-election-forecasts.pdf">Andrew Gelman</a>,</p>

<blockquote>
  <p>In non-technical terms, the martingale property says that knowledge of the past will be of no use in predicting the future…One implication of this is
that it should be unlikely for forecast probabilities to change too much during the campaign (Taleb, 2017). Big events can still lead to big changes in the forecast: for example, a series of polls with Biden or Trump doing much better than before will translate into an inference that public opinion has shifted in that candidate’s favor. The point of the martingale property is not that this cannot happen, but that the possibility of such shifts should be anticipated in the model, to an amount corresponding to their prior probability. If large opinion shifts are allowed with high probability, then there should be a correspondingly wide uncertainty in the vote share forecast a few months before the election, which in turn will lead to win probabilities closer to 50%.</p>
</blockquote>

<p>In other words, all information is already priced into the current market. If it were not so, a trader could make money by taking advantage of the information that is not priced in already. So last thing we need to check: is it likely that Silver’s predictions have the martingale property? It is not in dispute that the answer is no…it shows clear mean-reversion behavior and can be validated by a statistical test of the martingale hypothesis (for example, a <a href="http://www.planchet.net/EXT/ISFA/1226.nsf/9c8e3fd4d8874d60c1257052003eced6/35822efeb009804cc1257afe006b0063/$FILE/11park.pdf">Kolmogorov-Smirnov test</a>). It seems that Taleb’s math is sound here. So where did he go wrong?</p>


<p>I believe Nate Silver is answering a subtly different question with his election forecasts. Each data point that Silver produces is answering the question: <em>if the election were to happen today</em>, what is the probability of each candidate winning? I argue that this is a valid and useful formulation. To put it slightly differently: if the question is “Who will win the election on Nov. 3?”, which of the following answers is more satisfying?</p>

<ul>
  <li>“If nothing else changes between now and the election, Joe Biden has a 85% chance of winning.” (Silver’s argument)</li>
  <li>“I dunno, anything could happen between now and the election, I give neither candidate chances much more than 50%.” (Taleb’s argument)</li>
</ul>

<p>It is a valid criticism that perhaps Silver is not very clear on explaining what his numbers represent, and therefore the media misreports his predictions. Still, I wager that most people would find the first answer more useful. In this interpretation, the “financial instrument” is a binary option that expires every day. Thefore the time series of Silver’s predictions is not interpretable as a martingale, as it strings together the price of a completely different instrument every day.</p>

<p>It is also a valid criticism that Silver’s predictions prior to Nov. 3 mean absolutely nothing, whereas in the Taleb formulation it has a natural interpretation as the betting odds for each candidate. Silver has explicitly stated that he only judges his models based on his finalized prediction. To that end, his models are extremely well calibrated, i.e., when he says something has a 50% chance of happening it actually does happen 50% of the time.
<img src="http://quant.am/assets/538-calibration.png" alt="538 calibration"></p>

<p>In conclusion, Taleb and Silver should be having a philosophical debate on what pollsters’ numbers actually mean, and stay away from the useless distraction of calling each other names on Twitter.</p>

<h3 id="update-10122020">Update (10/12/2020)</h3>
<p>Andrew Gelman, Aubrey Clayton, Dhruv Madeka and many other statisticians respond and give their thoughts: <a href="https://statmodeling.stat.columbia.edu/2020/10/12/more-on-martingale-property-of-probabilistic-forecasts-and-some-other-issues-with-our-election-model/">https://statmodeling.stat.columbia.edu/2020/10/12/more-on-martingale-property-of-probabilistic-forecasts-and-some-other-issues-with-our-election-model/</a></p>

<h3 id="update-2-1132020">Update 2 (11/3/2020)</h3>
<ul>
  <li>Nassim Taleb responds to this post on <a href="https://twitter.com/nntaleb/status/1323594733797679104">Twitter</a></li>
  <li><a href="https://news.ycombinator.com/item?id=24976175">Hacker News discussion</a></li>
</ul>

		</div></div>]]>
            </description>
            <link>http://quant.am/statistics/2020/10/11/taleb-silver-feud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24976175</guid>
            <pubDate>Tue, 03 Nov 2020 04:04:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of ABAC on AWS]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975952">thread link</a>) | @arkadiyt
<br/>
November 2, 2020 | https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/ | <a href="https://web.archive.org/web/*/https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Two years ago, in November 2018, AWS <a href="https://aws.amazon.com/blogs/security/add-tags-to-manage-your-aws-iam-users-and-roles/">announced</a> new conditions keys <code>aws:PrincipalTag</code> and <code>aws:RequestTag</code>, and <a href="https://aws.amazon.com/blogs/security/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles/">started to push</a> the concept of Attribute Based Access Control (ABAC).  This post will describe what this is, the difficulties with implementing this strategy, and what AWS needs to do for customers to be successful with this concept.</p>


<p>A long standing problem with AWS security has been that if you had two projects in a single AWS account, it was often impossible to ensure that some principals (meaning the users and roles there) could only interact with the resources of one project and not the other.  In order to implement a least privilege strategy, you want to isolate the actions each principal can take to only certain resources to ensure they cannot impact or exfil data from the other project.</p>

<p>The solution many customers have been forced to adopt is to isolate their projects into separate AWS accounts, but that’s not always ideal. For example, it can be difficult to take an existing account and move resources into another account as an account grows.  So AWS started focusing on tagging resources and restricting access via tags.  Over time, many privileges started to be able to work with the condition key <code>aws:ResourceTag</code> so that you could restrict who could interact with an existing resource. But what if you wanted the principal to create new resources, but restrict what tags they could use, so they couldn’t create a resource with the tag of another project?  For this AWS <a href="https://aws.amazon.com/blogs/security/add-tags-to-manage-your-aws-iam-users-and-roles/">released</a> <code>aws:RequestTag</code>.</p>

<p>What if you had many principals and projects and you didn’t want to create separate IAM policies for each one? You want a single policy that you can apply to all principals that says “Only interact with resources that match the same tag as you have” or the common request of “You can only interact with resources you created.”  To implement this concept, AWS released <code>aws:PrincipalTag</code>, so you could now use a conditions such as:</p>

<pre><code>StringEquals: { "aws:RequestTag/project": "${aws:PrincipalTag/project}" }
</code></pre>

<p>Attribute-based access control (ABAC) is an authorization strategy that defines permissions based on attributes, which on AWS means tags.  Two of the best resources on this concept are <a href="https://twitter.com/bjohnso5y">Brigid Johnson’s</a> re:Inforce talk <a href="https://www.youtube.com/watch?v=Iq_hDc385t4">Scale Permissions Management in AWS w/ Attribute-Based Access Control</a> and <a href="https://twitter.com/mchancloud">Michael Chan</a>’s blog post <a href="https://aws.amazon.com/blogs/security/working-backward-from-iam-policies-and-principal-tags-to-standardized-names-and-tags-for-your-aws-resources/">Working backward: From IAM policies and principal tags to standardized names and tags for your AWS resources</a>.</p>



<h2 id="lack-of-privilege-support">Lack of privilege support</h2>
<p>The first issue people ran into with ABAC was that not all resources supported tags. Of those resources that did, not all supported IAM conditions to restrict these tags. Of those that did, not all supported tag on create, so you could only restrict access to tag existing resources, leaving resources untagged.  Let’s get some stats on how much coverage AWS has today.  Using the IAM data from <a href="https://github.com/duo-labs/parliament/blob/main/parliament/iam_definition.json">Parliament</a> (which is just the AWS <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_actions-resources-contextkeys.html">docs</a> scraped into a json file), we find there are 869 privileges that contain the word <code>create</code>, which we can assume to be the privileges that grant permission to create a resource.</p>

<pre><code>$ cat parliament/iam_definition.json | jq '.[]|.prefix as $prefix|.privileges[]|.privilege as $privilege|select($privilege|ascii_downcase|contains("create"))|$prefix+":"+$privilege'  | sort | uniq | wc -l
     869
</code></pre>

<p>Next, we’ll find all the privileges of these that allow the <code>RequestTag</code> condition key:</p>

<pre><code>$ cat parliament/iam_definition.json | jq '.[]|.prefix as $prefix|.privileges[]|.privilege as $privilege|select($privilege|ascii_downcase|contains("create")).resource_types[].condition_keys[]|select(.|ascii_downcase |contains("requesttag"))|$prefix+":"+$privilege' | sort | uniq | wc -l
     381
</code></pre>

<p>We find that 381 of 869 (43%) privileges for creating resources on AWS allows you to both tag the new resources and to restrict what tags are used for that.  This search does miss some privileges that are used to create resources but do not include the word <code>create</code>, such as <code>ec2:RunInstances</code> that lets you create an EC2 and <code>route53:ChangeResourceRecordSets</code> that lets you create a subdomain.  It also misses situations where AWS has two privileges for creating a resource, where one privilege is used for creating the resource with tags and one without, such as <code>cloudfront:CreateDistribution</code> and <code>cloudfront:CreateDistributionWithTags</code>.  However, 43% seems roughly correct.</p>

<p>One might try to argue that the more widely used resources do support tag on create and restricting those tags, but there are some popular resources that do not.  For example, the following privileges are all unable to restrict tag on create: <code>lambda:CreateFunction</code>, <code>dynamodb:CreateTable</code>, <code>kms:CreateKey</code>, <code>logs:CreateLogGroup</code>, <code>s3:CreateBucket</code>, <code>sqs:CreateQueue"</code>, and <code>iam:CreateRole</code>.</p>

<p>As a hack, for resources that don’t support tag on create, you can use the names of the resources in a similar way as a tag, but this is awkward.</p>


<p>Given a resource in an AWS account, there is not much tooling available that can tell you who all has access to it.  Some tools (ex. <a href="https://github.com/FSecureLABS/awspx">awspx</a>) will tell you who has certain privileges, but they don’t understand conditions, among other details.  So for example, they can tell you who has <code>secretsmanager:CreateSecret</code>, but they won’t tell you who can create a secret with the tag <code>foo</code>.</p>

<p>I built some functionality into <a href="https://github.com/duo-labs/cloudmapper">CloudMapper</a> through it’s <code>access_check</code> command that tries to understand more IAM logic. It has some understanding of conditions and will also take IAM Boundaries into consideration, but it does not understand the existing tags on a resource, and lacks a lot of other functionality.  Its answers will be more correct than other tools for some questions, but will still be incorrect for a lot of cases.  The project <a href="https://github.com/nccgroup/PMapper">PMapper</a> also has some additional logic in it.</p>

<h3 id="simulateprincipalpolicy">SimulatePrincipalPolicy</h3>
<p>There is an API called <a href="https://docs.aws.amazon.com/IAM/latest/APIReference/API_SimulatePrincipalPolicy.html">SimulatePrincipalPolicy</a> that can be used to understand who has access to resources, but it is missing a lot of functionality you would expect.  For example, you can pass it the ARN of a principal, the ARN of a resource, and associated privilege to check for, but if there are any conditions, you then have to also include the condition values that should be used when checking this.  This means you have to figure out the tags of the resource and the resource policy to then pass to this call.</p>

<p>So for example, assume we have a principal that can call <code>secretsmanager:GetSecretValue</code> only on secrets that have been tagged with a <code>project</code> key that has a value <code>foo</code>, and we have a secret with that tag.  In order to check if our principal can access this secret, we can run:</p>

<pre><code>aws iam simulate-principal-policy \
  --policy-source-arn arn:aws:iam::123456789012:user/testuser \
  --action-names secretsmanager:getsecretvalue \
  --resource-arns arn:aws:secretsmanager:us-east-1:123456789012:secret:test-abcdef \
  --context-entries ContextKeyName=secretsmanager:ResourceTag/project,ContextKeyValues=foo,ContextKeyType=string
</code></pre>

<p>Notice in the last line, I have to tell it the value of the tag for the resource that I want it to check. The policy simulator does not figure that out for you.  So if you were to try to automate this, you would have to make a describe call, knowing where in the response to find the tag value, and how to format the call to <code>SimulatePrincipalPolicy</code> with this value.  Also, if the IAM policy has unrelated condition keys for other privileges, you have to provide context keys for those too. Next, you have to provide the resource policy if one exists, the IAM boundary if one exists, and potentially other data.</p>

<p>Because of these limitations, this API is not as useful as you might hope.</p>

<h3 id="zelkova">Zelkova</h3>
<p>Zelkova is an automated reasoning solution for IAM policies that was announced by AWS in 2017 and available for private beta.  When I talk to people about the problem of understanding who has access what, this project often comes up as a possible option by those who aren’t familiar with what exactly it does. Unfortunately, Zelkova is an engine that you still have to figure out the inputs to.  It can answer some IAM related questions, but for our goals of understanding who has access to what, it has all the same limitations as iam:SimulatePrincipalPolicy.</p>

<h2 id="limited-capabilities-of-tag-policies">Limited capabilities of Tag Policies</h2>
<p>An AWS Organization feature called <a href="https://aws.amazon.com/blogs/aws/new-use-tag-policies-to-manage-tags-across-multiple-aws-accounts/">Tag Policies</a> was supposed to help enforce tagging, but it is critically limited by only being able to enforce what tag values may be used when defined tag keys are used.  This means you cannot enforce that a resource is tagged. You can only enforce that when someone attempts to tag a resource with a certain key, that the value is one of a defined set.  In order to enforce tagging actually be used in an organization, you have to use SCPs as described <a href="https://aws.amazon.com/blogs/security/securing-resource-tags-used-for-authorization-using-service-control-policy-in-aws-organizations/">here</a>.</p>

<p><a href="https://summitroute.com/img/tag_policies_limitation.png">
<img src="https://summitroute.com/img/tag_policies_limitation.png" alt="Enforcement has no effect on resources that are created without tags." title="Enforcement has no effect on resources that are created without tags."></a></p>
<p>This warning is from the docs <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_tag-policies-enforcement.html">here</a>.</p>

<p>Further, Tag Policies do not have coverage across all resources that support tags.  The list of supported resources is <a href="https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_supported-resources-enforcement.html">here</a>.  An example of a resource that supports tags, but is not supported by Tag Policies, is S3 objects.</p>

<p>AWS needs to extend the functionality of this feature to support enforcement of using tag keys, as there is little value in it in its current form.</p>

<h2 id="lack-of-support-for-working-with-multiple-tag-values">Lack of support for working with multiple tag values</h2>
<p>People often work on multiple projects, but there is no way to tag a principal with a key that has multiple tag values.  As an example, imagine you have two projects, <code>foo</code> and <code>bar</code>, and you want to allow a person to work on just <code>foo</code> and all the resources they create should have a <code>Project</code> tag with value <code>foo</code>, and likewise you have another person who should only work on the <code>bar</code> projects.  AWS <a href="https://aws.amazon.com/blogs/security/simplify-granting-access-to-your-aws-resources-by-using-tags-on-aws-iam-users-and-roles/">has shown</a> how to create a single IAM policy that can be applied to both people, and you’d just need to make sure to apply a <code>Project</code> tag to the principals to define which project they can work on.</p>

<p>Now imagine that one of these employees needs to work on both projects. You cannot tag a principal with both <code>foo</code> and <code>bar</code>.  One solution is to have the person assume different IAM roles depending on …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/">https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/</a></em></p>]]>
            </description>
            <link>https://summitroute.com/blog/2020/11/02/state_of_abac_on_aws/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975952</guid>
            <pubDate>Tue, 03 Nov 2020 03:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a Git Diff in Markdown]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975629">thread link</a>) | @nilsandrey
<br/>
November 2, 2020 | https://blog.alispit.tel/create-a-git-diff-in-markdown/ | <a href="https://web.archive.org/web/*/https://blog.alispit.tel/create-a-git-diff-in-markdown/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of my favorite blogging tips is using diff formatting in GitHub flavored markdown. I use this to show what has changed in code snippets. This works for code snippets in most markdown packages and on Dev.to.</p>
<p>If I wanted to show that I was changing a function from one thing to another, I could add a snippet that looks like this!</p>
<div data-language="diff"><pre><code>function addTwoNumbers (num1, num2) {
<span><span>-</span><span>  return 1 + 2
</span></span><span><span>+</span><span>  return num1 + num2
</span></span>}</code></pre></div>
<p>First, instead of specifying the programming language, use <code>diff</code> after the backticks. Then at the beginning of any lines of code you want to show as removed, add a <code>-</code>. At the beginning of any lines of code you want to show as added, add a <code>+</code>.</p>
<p>The code would look like this:</p>
<div data-language="text"><pre><code>```diff
function addTwoNumbers (num1, num2) {
-  return 1 + 2
+  return num1 + num2
}
```</code></pre></div>
<p>I have used this in tons of my coding tutorials, such as <a href="https://welearncode.com/beginners-guide-react/" target="_blank" rel="nofollow noopener noreferrer">this</a> one. It makes it a lot easier for readers to see what is changing from snippet to snippet.</p>
</div></div>]]>
            </description>
            <link>https://blog.alispit.tel/create-a-git-diff-in-markdown/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975629</guid>
            <pubDate>Tue, 03 Nov 2020 02:01:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Seems a cool idea – to send friends a personalized game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24975546">thread link</a>) | @codeguppy
<br/>
November 2, 2020 | https://codeguppy.com/run.html?ad/snk_adrian | <a href="https://web.archive.org/web/*/https://codeguppy.com/run.html?ad/snk_adrian">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://codeguppy.com/run.html?ad/snk_adrian</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975546</guid>
            <pubDate>Tue, 03 Nov 2020 01:48:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Mill Burgers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24975510">thread link</a>) | @koch
<br/>
November 2, 2020 | https://robko.ch/2020/10/31/red-mill-burgers.html | <a href="https://web.archive.org/web/*/https://robko.ch/2020/10/31/red-mill-burgers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>  <blockquote> <p>Red Mill Burgers in Seattle has some great burgers. They make them quickly and they’re a good size. But I swear to God, Google doesn’t give me the correct damn search results when I go to Google them. I mean Jesus FUcking christ i just want to order their delicious burgers online.</p> </blockquote> <p><small><em>What I initially wrote when I started this blog post. Note the aggitated tone the author takes.</em></small></p> <h4 id="scenario-i-want-red-mill">Scenario: I want Red Mill</h4> <p>I google <code>red mill burgers</code> so that I can order online. What do I get? Behold:</p> <div> <p><img loading="lazy" src="https://lh3.googleusercontent.com/5svMZOQr5G8a9_87aJQyekUteEGRXChN-x-JUgtcenCoS6TRZ-0OOx0T9BQtnwWs13-xObl95lzqskyiHpb81oeL4KaMsCnaz3H0fyg2Lji9ELqP75TWCm0OIHyq7RkTM0ubFyC4izA=w2000"> </p> </div> <p>Ok, not bad. I have a few things to say about the results. But before we go any further, a disclaimer: I work at Google, though not on <a href="https://www.google.com/">Search</a>.</p> <p>Most of my issue with the results can be summed up by the first suggested search at the bottom:</p> <div> <p><img loading="lazy" src="https://lh3.googleusercontent.com/hCwfXBcsJIRdknNJfZHuDu7KF4yz_QTefaOJEWZXo8gsh0QdsO7AIl35cYF8LgqCKpjMvm3Ptc4KZ72mmwA9Ot7QIK8Gy7OWb43Jb2ozwyP5dccByA2f4VGiyKcP6psPM7J_LOWvz60=w2000"> </p> </div> <p><a href="https://www.redmillburgers.com/">Their website</a> is not a result of the query <code>red mill burgers</code>! You shouldn’t have to put “website” in your google query, we’re on the internet here folks. There’s yelp, facebook, toasttab, a wikipedia article ffs, but not their website.</p> <p>Now, the observant among you will notice that their website actually is here: where the map results are.</p> <div> <p><img loading="lazy" src="https://lh3.googleusercontent.com/tFdZw7QON4YpG2fD4p3WkfyR4MUrkwZ4JAk6iLFy1ANbEfk4iarT-Bm-tO9qRcbq3_2m35qW1WsQF3E-n8NjNLtohLhgSGlMiN7JsO7l3ohKJIpza6XOEwNl9fEtiKUf52GWlER64Yk=w2000"> </p> </div> <p>But I don’t trust these. Why? There’s a difference between a link that says “Red Mill Burgers” versus a button that says “Website.” And there’s no visible URL unlike the other results. It’s like I have no idea where it will take me; for all I know it will direct me to one of the top links above, of which, again, none are the restaurant’s site. This is more pronounced on mobile where you can’t hover above a link to see where it will take you.</p> <h4 id="other-search-engines">Other search engines</h4> <p>Bing and DuckDuckGo have the same problem, though Bing has more “Website” buttons, so that’s nice, I guess?</p> <div> <div> <p><img loading="lazy" src="https://lh3.googleusercontent.com/Gyn0irJSkaKY4g-2AnijIVnShO9b1xiRWjYn3DtBOG2wVQqft_yKdeM-QwNTe2bnpZMC1jd5_0vomt8wJTybX6dvZ2ONn-A9LsJxtlfc-a-kyexMqv5xW4Nl_GeSnRs99vDduEGGcjI=w2000"></p><p><em>This is what Bing results look like</em></p> </div> </div> <h4 id="question-whose-fault-is-this">Question: Whose fault is this?</h4> <p>Actually we have to answer another question first.</p> <h4 id="question-is-what-im-describing-even-an-issue">Question: Is what I’m describing even an issue?</h4> <p>Is what Google returned actually the information people are looking for? Am I the odd one out? Should I want to go to yelp or facebook or <code>places.singleplatform.com</code>, whatever that is? No. This is an issue to me. So back to the other question.</p> <h4 id="question-whose-fault-is-this-1">Question: Whose fault is this?</h4> <p>Couple possibilities:</p> <ul> <li> <h5 id="red-mill">Red Mill</h5> </li> </ul> <p><a href="https://www.redmillburgers.com/">Red Mill</a> could be doing more <a href="https://en.wikipedia.org/wiki/Search_engine_optimization">SEO</a>. I think this is stupid, most businesses shouldn’t have to cater to search engines or indexers, <em>unless</em> the query was <code>burgers</code> or <code>restaurants</code>. I searched for <code>red mill burgers</code> though.</p> <p>I understand that this is a naïve position. But it leads to our current problem, because obviously the other results on this page are doing <a href="https://en.wikipedia.org/wiki/Search_engine_optimization">SEO</a> to the detriment of the actual business in question and to those looking for it.</p>  <ul> <li> <h5 id="google">Google</h5> </li> </ul> <p>Google should know what the website is and return it.</p>  <ul> <li> <h5 id="the-other-results-on-the-page">The other results on the page</h5> </li> </ul> <p>These would be the Yelps and Facebooks and TripAdvisors of the world. They become less and less interesting to me over time, because they’re all the same - some questionable reviews, some pictures, contact information, all of which are at varying degrees of outdated-ness. And what do I end up looking for on these pages anyway? <strong>Their website.</strong></p> <h4 id="isnt-toast-what-they-use-for-online-ordering-isnt-that-the-first-result">Isn’t Toast what they use for online ordering? Isn’t that the first result?</h4> <p>Yeah that first result is for Phinney Ridge. I go to Interbay.</p> <h4 id="conclusion">Conclusion</h4> <p>In true software engineering fashion, writing this post has taken more time than I will ever spend trying to get to red mill’s website, and way more time than it would take to bookmark it.</p> <br> <hr> </div> </div></div>]]>
            </description>
            <link>https://robko.ch/2020/10/31/red-mill-burgers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975510</guid>
            <pubDate>Tue, 03 Nov 2020 01:42:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: White Labeled Resume Builder]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24975508">thread link</a>) | @jacob_rezi
<br/>
November 2, 2020 | https://www.rezi.io/white-label-resume-builder | <a href="https://web.archive.org/web/*/https://www.rezi.io/white-label-resume-builder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.rezi.io/white-label-resume-builder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975508</guid>
            <pubDate>Tue, 03 Nov 2020 01:41:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EME, CDM, AES, CENC, and Keys – Building Blocks of DRM]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24975487">thread link</a>) | @jayjohn436
<br/>
November 2, 2020 | https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/ | <a href="https://web.archive.org/web/*/https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/08/eme-cdm-cenc-featured-image.png?resize=678%2C381&amp;ssl=1" alt="eme cdm cenc keys" title="eme-cdm-cenc-featured-image" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/08/eme-cdm-cenc-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>Anyone trying to understand DRM (Digital Rights Management) will be confronted with acronyms such as AES, CDM, CENC, EME, etc. This can get very confusing for a newcomer, but understanding them is important to get a good understanding of DRM. In this article, let’s take a gentle tour of the building blocks of DRM:- EME, CDM, AES, CENC, and the use of Keys &amp; Key Servers.</strong></p>








<h2 id="simplified-architecture-of-a-drm-system"><span id="Simplified_Architecture_of_a_DRM_System"></span>Simplified Architecture of a DRM System<span></span></h2>



<p>As we saw&nbsp;<a href="https://ottverse.com/what-is-drm-digital-rights-management/">in the previous article</a>,&nbsp;<strong>DRM is a combination of encryption and business rules to control access and consumption of digital content.</strong></p>



<p>Simply put, DRM is a system that,</p>



<ul><li>provides the tools and infrastructure to enable a content provider to encrypt their content, and</li><li>build an ecosystem around the encrypted content so that the content provider can control who/what can decrypt and consume their content.</li></ul>



<p><a href="https://ottverse.com/what-is-drm-digital-rights-management/">In the previous article of the series</a>, we saw Ram and Shyam sending coded messages to each other. At the same time, Hari maintained the codebooks and decided who got to read/write the notes – remember?</p>



<figure><img data-attachment-id="156" data-permalink="https://ottverse.com/with-drm/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=1316%2C878&amp;ssl=1" data-orig-size="1316,878" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="with-drm" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?fit=1024%2C683&amp;ssl=1" loading="lazy" width="1024" height="683" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1200%2C801&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?w=1316&amp;ssl=1 1316w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/with-drm.png?resize=1024%2C683&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Now, let’s take this simple system and replace it with the technology needed to secure and distribute video. What do we get?</p>



<figure><img data-attachment-id="138" data-permalink="https://ottverse.com/step-0/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=1396%2C818&amp;ssl=1" data-orig-size="1396,818" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="step-0" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?fit=1024%2C600&amp;ssl=1" loading="lazy" width="1024" height="600" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;ssl=1 1024w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=300%2C176&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=768%2C450&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1200%2C703&amp;ssl=1 1200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?w=1396&amp;ssl=1 1396w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0.png?resize=1024%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Let’s describe what we have here. There is a movie that we want to send to an authenticated user securely.</p>



<p>So,</p>



<ol><li>we ask a DRM company’s server for a codebook to encrypt our video,</li><li>then, we encrypt the video using that codebook</li><li>we send the movie to the user.</li><li>the user then asks the DRM company’s server for the codebook to unlock the video (decrypt it)</li><li>and then he watches the movie!</li></ol>



<p>Fantastic!</p>



<p>Is this all there is to know about DRM for video?</p>



<p>Nope! What we have here is a simple, toy-example of how to transfer movies securely using DRM. It captures the essence of DRM perfectly but wouldn’t work well in the real world.</p>



<p>In the rest of this article, let’s take each piece of this simple system, re-think it, re-design it, and see how it fits within the world of video delivery and DRM, shall we?</p>



<h2 id="step-0-lets-move-to-adaptive-bitrate-streaming"><span id="Step_0_Let%E2%80%99s_Move_to_Adaptive_Bitrate_Streaming"></span>Step 0: Let’s Move to Adaptive Bitrate Streaming<span></span></h2>



<p>Before we talk about the order, let’s modify our example to suit the ABR (<strong>A</strong>daptive&nbsp;<strong>B</strong>it<strong>R</strong>ate) model of video delivery.</p>



<p><strong>ABR Refresher:</strong>&nbsp;in ABR, a movie is encoded into different bitrate-resolution combinations&nbsp;<em>(a.k.a ladder)</em>&nbsp;and then split into&nbsp;<strong>chunks or segments</strong>. Each chunk represents a few seconds of video and it is independently decodable.</p>



<p><strong>“Packaging”</strong>&nbsp;refers to chunking or breaking up a movie into small pieces and describing it in a manifest or playlist document. When the user wants to play the movie, he needs to refer to this manifest.</p>



<p>Depending on the available bandwidth, the player requests a chunk/segment of a particular bitrate&nbsp;<em>(rendition, or rung of the ladder)</em>&nbsp;and a CDN (Content Delivery Network) responds with the requested chunk.</p>



<p>Popular methods of video delivery using ABR are MPEG DASH and HLS. For a deeper understanding, please refer to our articles on&nbsp;<a href="https://ottverse.com/what-is-ott-video-streaming/">OTT</a>&nbsp;and&nbsp;<a href="https://ottverse.com/what-is-abr-video-streaming/">ABR</a>&nbsp;video streaming.</p>



<p>Let’s change our block digram to reflect ABR video delivery.</p>



<figure><img data-attachment-id="139" data-permalink="https://ottverse.com/step-0-with-abr/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=1476%2C868&amp;ssl=1" data-orig-size="1476,868" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="step-0-with-abr" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?fit=1024%2C602&amp;ssl=1" loading="lazy" width="1024" height="602" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;is-pending-load=1#038;ssl=1" alt="aes-cenc-cdm-eme-keys" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=300%2C176&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=768%2C452&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1200%2C706&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?w=1476&amp;ssl=1 1476w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/step-0-with-abr.png?resize=1024%2C602&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The only changes here are the packaging and CDN-based delivery steps. That’s all.</p>



<p>Okay, let’s move on and start with the encryption process.</p>



<h2 id="step-1-video-encryption"><span id="Step_1_Video_Encryption"></span>Step 1: Video Encryption<span></span></h2>



<p>The whole idea of encryption is to ensure that when someone intercepts our data, they should not read it or watch it in the case of video.</p>



<p><strong>Encryption refresher:</strong>&nbsp;–&nbsp;<em>encryption is a technique used to keep data confidential and prevent unauthorized people from reading it. Encryption uses a “key” to convert input data (plaintext) into an alternate form called ciphertext. It is almost impossible to convert the ciphertext back to plaintext without the key.</em></p>



<p><em>However, practically speaking, decryption without the key is possible, and encryption algorithms are designed make reverse-engineering extremely expensive – in terms of time, money, and computing resources needed.</em></p>



<p>One of the most popular encryption techniques is the “Advanced Encryption Standard” or “AES” for short. It is also called Rijndael (after its inventor) and was established by the U.S. National Institute of Standards and Technology (NIST) in 2001 to encrypt electronic data.</p>



<p>Some important points to remember about AES:-</p>



<ul><li>It’s a&nbsp;<strong>symmetric-key algorithm</strong>: encryption and decryption are performed using the same key.</li><li>It has three variants based on the key-length: 128, 192, and 256 bits. The longer the key, the harder it is to crack.</li><li>Cracking the AES-128 without the key would require a “billion times a billion years” and a super-computer (<a href="https://www.eetimes.com/how-secure-is-aes-against-brute-force-attacks/" target="_blank" rel="noopener">source</a>).</li></ul>



<p>If you are interested in going deep into the AES standard, look at the&nbsp;<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" target="_blank" rel="noopener">AES’s Wikipedia page</a>.&nbsp;<em>I am not an expert in cryptography and won’t be able to do justice to the AES.</em></p>



<p><strong>Note:</strong>&nbsp;Please remember that&nbsp;<strong>encryption is not encoding, and decryption is not decoding in the video space</strong>. For videos, encoding and decoding are words used to refer to compression and decompression, respectively. To learn more about encoding, decoding, and video codecs, please read our articles on&nbsp;<a href="https://ottverse.com/need-for-video-compression/">the need for compression</a>&nbsp;and a&nbsp;<a href="https://ottverse.com/what-is-a-video-codec/">simple introduction to video codecs</a>.</p>



<h3 id="is-aes-128-the-only-encryption-technique"><span id="Is_AES128_The_Only_Encryption_Technique"></span>Is AES-128 The Only Encryption Technique?<span></span></h3>



<p>No, it isn’t, and let’s think about the implication of this for a minute.</p>



<p>If a content provider decides to engage with three different DRM companies, and all three use different encryption techniques, then it means that the content provider needs to encrypt their videos three times, resulting in a waste of storage space and other resources.</p>



<p>That is why the CENC specification came into being – to reduce this encryption-driven fragmentation of the market and to reduce storage requirements.</p>



<p>Let’s learn about this next.</p>



<h3 id="cenc-or-common-encryption"><span id="CENC_or_Common_Encryption"></span>CENC or Common Encryption<span></span></h3>



<p><strong>Actually, before we dive into CENC, let’s step back and take a look at the state of OTT streaming protocols and CMAF in particular.</strong></p>



<p>There are primarily two protocols in use today – MPEG-DASH and HLS.&nbsp;<em>There are others such as MSS (Microsoft Smooth Streaming) and HDS, but, we’ll leave them aside for this discussion.</em></p>



<p>MPEG-DASH uses the&nbsp;<code>mp4</code>&nbsp;container format for its videos and HLS uses the MPEG-TS (<code>ts</code>) container for its files. If a content provider uses both MPEG-DASH and HLS, then they need to store a copy of their videos in both&nbsp;<code>mp4</code>&nbsp;and&nbsp;<code>ts</code>&nbsp;file formats.</p>



<p>Now, let’s add the DRM encryption problem to it. If our three hypothetical DRM providers use three different encryption standards, then a content providers needs to store&nbsp;<code>2 * 3</code>&nbsp;… six copies of each video! What a waste of storage space!!</p>



<p><strong>To combat the first problem posed by video streaming protocols, the&nbsp;<a href="https://mpeg.chiariglione.org/standards/mpeg-a/common-media-application-format" target="_blank" rel="noopener">CMAF</a>&nbsp;specification was created</strong> which said that videos can be stored in the&nbsp;<strong>fragmented mp4</strong>&nbsp;container format (<code>fmp4</code>). With support from both MPEG-DASH and HLS, you can now create only one set of videos, store it in&nbsp;<code>fmp4</code>&nbsp;format, and use a common set of files for both protocols. </p>



<p><strong>Just make sure you create two manifests (sigh!).</strong></p>



<h3><span id="How_About_Unifying_the_Encryption"></span><strong>How About Unifying the Encryption?</strong><span></span></h3>



<p>We still need to store multiple copies of each file if different DRM technologies use different encryption standards, right?</p>



<p>For this purpose, the MPEG developed the&nbsp;<a href="https://www.iso.org/standard/68042.html" target="_blank" rel="noopener">CENC or Common Encryption specification</a>, specifying that videos can be encrypted using either&nbsp;<code>cenc</code>&nbsp;(AES-128 CTR) or&nbsp;<code>cbcs</code>&nbsp;(AES-128 CBC).&nbsp;<em>CTR stands for Counter; and CBC stands for Cipher Block Chaining.</em></p>



<p>The implication of CENC is that a content provider needs to encrypt his videos only once and any decryption module can decrypt it.&nbsp;<em>Note: Exposing the encryption algorithm is not a problem as long as the keys are strongly protected.</em></p>



<p><strong>Well, CENC might sound like a magic wand for DRM-unification, but it is not.</strong></p>



<p>There are three primary DRM technologies in the market – Apple FairPlay, Google Widevine, and Microsoft PlayReady.</p>



<ul><li>Apple FairPlay supports only AES-CBC&nbsp;<code>cbcs</code>&nbsp;mode.</li><li>HLS supports only AES-CBC&nbsp;<code>cbcs</code>&nbsp;mode (irrespective of CMAF)</li><li>Widevine and PlayReady support both AES-128 CTR&nbsp;<code>cenc</code>&nbsp;or AES-128 CBC&nbsp;<code>cbcs</code>&nbsp;modes.</li><li>MPEG-DASH with CMAF supports both AES-128 CTR&nbsp;<code>cenc</code>&nbsp;or AES-128 CBC&nbsp;<code>cbcs</code>&nbsp;modes.</li><li>MPEG-DASH without CMAF supports only AES-128 CTR&nbsp;<code>cenc</code>&nbsp;mode.</li></ul>



<p>As you can see, the CMAF and CENC specs have lead to confusion and fragmentation in the streaming space. </p>



<p><strong>A possible convergence point is the universal use of CMAF and AES-CBC&nbsp;cbcs&nbsp;mode, but, how will these impact legacy devices that support only CTR or only MPEG-TS?</strong></p>



<p>That’s a discussion for another time.</p>



<h2 id="step-2-key-keyid-and-the-license-server"><span id="Step_2_Key,_KeyID,_and_the_License_Server"></span>Step 2: Key, KeyID, and the License Server<span></span></h2>



<p>By now, we have established that we will be encrypting or videos using AES-128 bit encryption. At this stage, a few questions that come up are –</p>



<ol><li>Where do we get the AES-128 Encryption Keys?</li><li>How do we associate an Encryption Key with a movie?</li><li>Where do we store the Encryption Keys?</li></ol>



<p>Let’s answer them one at a time.</p>



<h3 id="where-do-we-get-the-aes-128-bit-encryption-keys"><span id="Where_do_we_get_the_AES128_bit_encryption_keys"></span>Where do we get the AES-128 bit encryption keys?<span></span></h3>



<p>Any content provider can generate the encryption keys manually using specialized software. Alternatively, several DRM vendors provide the necessary tools and software to generate these keys.</p>



<h3 id="how-do-we-associate-an-encryption-key-with-a-movie"><span id="How_do_we_associate_an_encryption_key_with_a_movie"></span>How do we associate an encryption key with a movie?<span></span></h3>



<p>Let’s understand the “why” first. When you go to a hotel, you ask the receptionist for the keys to a particular room by mentioning the room number – right? You’re providing the association here between a key and a room by telling her the room number.</p>



<p>Similarly, when we encrypt a movie with a particular key, we need to create that association and provide that to the DRM license server&nbsp;<em>(our receptionist, if you will)</em>.</p>



<p>In DRM, a “<strong>KeyID</strong>” provides the association between an encryption key and a movie. It is a&nbsp;<strong>unique</strong>&nbsp;string of characters generated at the time of creating an encryption key for a particular movie.</p>



<p><em>And finally,</em></p>



<h3 id="where-do-we-store-the-encryption-key--its-keyid"><span id="Where_do_we_store_the_Encryption_Key_its_KeyID"></span>Where do we store the Encryption Key &amp; its KeyID?<span></span></h3>



<p><strong>The Encryption Key and the KeyID are stored in a secure server (Key Store) that works alongside a DRM license server</strong>.</p>



<p>When a client needs to play an encrypted movie, it requests the DRM license server for the decryption key by providing that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/">https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/eme-cenc-cdm-aes-keys-drm-digital-rights-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975487</guid>
            <pubDate>Tue, 03 Nov 2020 01:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales as a Core Competency in Your Company]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24975300">thread link</a>) | @neinasaservice
<br/>
November 2, 2020 | https://21-lessons.com/sales-as-a-core-competency-in-your-company/ | <a href="https://web.archive.org/web/*/https://21-lessons.com/sales-as-a-core-competency-in-your-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1361">
			
		<!-- .entry-media -->
	

	<div>

		<!-- .entry-header -->

		<div>
			
<p>Currently, you might not be actively selling (as in approaching leads). Or the product sells itself right now (people get in touch with you and buy).&nbsp;</p>



<p>You feel weird about cold-calling, approaching strangers about your offerings. It’s a valid concern.&nbsp;</p>



<p>When you look at your current customer base and revenues: Can you predict when you make a sale? Can you be confident if somebody will follow through with the purchase?&nbsp;</p>



<p>If you don’t have Sales People on staff, this is a challenge. Why should you care, though?</p>



<p>For starters, you might need to plan revenue for the next few months, to hire a new employee, or invest in that new project you’ve been anxious to kick off.</p>



<p>Whatever the motivation is in the end, you need to predict incoming revenue. And for that, you need to sell. As always, there are multiple approaches to this.</p>



<p>As a starting point, you can start to work off all inbound sales inquiries. Your Advantage: No cold outreach to anyone. You focus solely on incoming requests and work them off.&nbsp;</p>



<p>You increase your odds of closing deals with a well-defined sales process. A sales process helps you confidently walk a prospect through each step and increase the chance to become a paying customer.</p>



<p>It still might not allow you to increase revenue as you need it, but you can more effectively predict incoming revenue. This circumstance is already worth a lot because it provides you with a lot more financial stability.&nbsp;</p>



<p>Another circumstance should also make this process more comfortable for you: You are already selling to those who gave you permission. You are allowed to sell. These prospects got in touch with you because they need something from you. Now it’s on you to professionally handle the request and walk them through the process.</p>



<p>With this approach, you’re slowly building Sales Competency in your organization for a more stable revenue foundation.</p>

					</div><!-- .entry-content -->

		
			</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://21-lessons.com/sales-as-a-core-competency-in-your-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975300</guid>
            <pubDate>Tue, 03 Nov 2020 01:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLB hit: a podcast about systems and compilers – Episode 0: mov fp, sp]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975206">thread link</a>) | @matt_d
<br/>
November 2, 2020 | https://tlbh.it/000_mov_fp_sp.html | <a href="https://web.archive.org/web/*/https://tlbh.it/000_mov_fp_sp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<audio id="audioplayer" src="https://traffic.libsyn.com/secure/tlbhit/tlbhit0.mp3" controls="controls" preload="auto"></audio>
<h2>00:00:00 Intro</h2>
<ul>
<li>Website: <a href="https://tlbh.it/">tlbh.it</a></li>
<li>Twitter: <a href="https://twitter.com/tlbhit">@tlbhit</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/mov-fp-sp/id1538369465?i=1000496866078">This episode on Apple podcast</a></li>
<li>The stack pretty much always TLB hits!</li>
</ul>
<h2>00:00:59 Disclaimer</h2>
<ul>
<li>We're lifelong learners, only know so much!</li>
<li>Will put errata up on <a href="https://tlbh.it/">the TLB Hit website</a></li>
<li><a href="https://en.wikipedia.org/wiki/Covert_channel">"Sidechannels"</a> via Twitter</li>
</ul>
<h2>00:01:42 What's the stack?</h2>
<ul>
<li>Episode is named <code>mov fp sp</code></li>
<li><code>mov fp sp</code> in the prologue of functions</li>
<li>Epilogue has "reverse" <code>mov sp fp</code></li>
<li>Instructions that manipulate <em>the stack</em>!</li>
<li>Compiler spills values that registers can't hold onto the stack</li>
<li>Functions do it a lot -- have their own [local] state, call functions that
have their own state</li>
<li>Because subroutines can recurse without bounds would need unbounded number of
registers</li>
<li>Often different kinds of registers: arithmetic value registers, floating
point registers</li>
<li>Registers contain fairly arbitrary "stuff": pointers to data, pointers to
code, return addresses, etc.</li>
<li>Stack is <em>usually</em> contiguous and allocated on a per-thread basis</li>
<li>Idea of "GPRs": general purpose registers, though some machines have
dedicated registers for floating point values as well, or SIMD for really
wide</li>
<li>Prologue moves stack pointer to base pointer, epilogue moves base pointer
back to stack pointer, "undoing", locally manipulating the stack pointer then
rolling things back to where they previously were</li>
</ul>
<h2>00:03:50 Mechanisms in the processor</h2>
<ul>
<li>Frame pointer/base pointer (bp/fp), stack pointer (sp)</li>
<li>Usual convention is that the frame pointer doesn't change during the course
of the function's execution</li>
<li>Generated code addresses "slots" relative (at offsets from) the frame
pointer; e.g. <code>+4</code>, <code>+8</code>, etc.</li>
<li>Stack is kind of like a linked list! Pointer of the stack that says "this is
where the frame pointer <em>used to be</em> before we came into this routine".</li>
</ul>
<h2>00:05:10 Comparison to an abstract stack machine</h2>
<ul>
<li>In CS class you may learn about machines where you push two operands onto a
stack then do an add operation that consumes the top two things on the stack</li>
<li>Compare to traditional processor we use today: expanding the stack as a
single operation that makes a bunch of slots at once</li>
<li>The slots don't need to be consumed in a strictly stack-order fashion</li>
<li>Distinction of "stack machine" vs scratchpad-area style frame areas
that happen in stack-like fashion for subroutine calls</li>
</ul>
<h2>00:06:05 Some instruction set considerations</h2>
<ul>
<li>Considerations on modern machines for frequency of these operations and how
they fit in our instruction cache; e.g. on x86 <code>push</code>/<code>pop</code> are single byte
opcodes</li>
<li>On ARM we may have a "push multiple values" instruction; little CISC-y but you
do so commonly it may make some sense</li>
<li>ARMv7 had instruction allowed to push 16 registers (all GPRs) and increment
stack pointer. Yay RISC!</li>
</ul>
<h2>00:07:09 Compiler optimizations and stackiness</h2>
<ul>
<li>By moving things onto the stack -- code is constantly working with the things
in its stack frame</li>
<li>Locality, but also avoiding memory allocation subroutines (100s or 1000s of
cycle depending)</li>
<li>In scratchpad area values are tracked precisely in dataflow sort of style</li>
<li>Bring them "in" to the compiler, values becomes more trackable</li>
<li>SSA values vs arbitrary memory references</li>
<li>When structs are brought onto the stack the individual fields inside can be
broken apart and the component fields can be tracked as individual values</li>
<li>Often called "scalar replacement of aggregates" (e.g. in LLVM)</li>
<li>When we home them on the stack we can do our common optimizations, CSE, DCE;
if on the heap, may be a lot harder to to do</li>
<li>In managed languages (e.g. JavaScript, Java) would do escape analysis to show
it doesn't escape via heap to an unknown subroutine -- once placed on the
stack you can eliminate whole objects and just track sub-fields inside of it</li>
<li>Allows you to just "explode" the object itself and think about its component
fields individually and get rid of whatever doesn't matter in there</li>
</ul>
<h2>00:09:17 Eliding heap allocations in C++</h2>
<ul>
<li>Some compilers can also sometimes optimize local heap allocations, turn them
into stacky allocation</li>
<li>C++ explicitly allows you to do that as of a few years ago, Clang does that</li>
<li>If you new an object no guarantee that you're actually going to put it on the
heap / call the underlying allocator</li>
<li>Can be surprising to people -- can do SRoA, other stuff, might get rid of the
entire computation</li>
<li>Neat, unless it's not what you're trying to do</li>
<li>But seems like a key optimization to do</li>
<li>If you're thinking about things as objects instead of raw bytes having higher
level understanding you can optimize based off of is pretty key it seems?</li>
</ul>
<h2>00:10:18 Frame pointer omission</h2>
<ul>
<li>When JF started programming there was "frame pointer omission" (FPO) which
was cool because optmizers weren't as good as they are now</li>
<li>Back when you only had 8 registers for x86 the extra register could go a long
way potentially -- stack is hot in cache but doing stores and loads to memory
locations</li>
<li>Was known to some as "that flag that makes the debugger way worse" -- debug
information has to be a lot more prescriptive when you can't simply describe
where things are as an offset from a canonical (assumed unchanging) register</li>
<li>Modern CPUs doing register renaming under the hood against a much bigger
micro-architectural register set -- not as worried about saving that one
register as much of the time -- although in hot code you still might</li>
</ul>
<h2>00:11:49 "Leaf" functions</h2>
<ul>
<li>When you inline things you make bigger regions for analysis, ideally make big
fat leaf functions</li>
<li>How much of program time is generally spent in leaf functions over some set
of applications?</li>
<li>Function at the end of the call tree</li>
<li>If your subroutine doesn't call any other subroutines that's a nice property,
because now you know that everything at the end of the stack belongs to you,
you're just doing your work and popping back up to whoever called you</li>
<li>Inlining really unlocks power of leaf -- inlining into non-leaf-functions can
<em>make</em> them become the leaf</li>
<li>So long as you don't over-inline and the working set doesn't become too big
-- the compiler can know everything it does and have a good amount of work to
do</li>
<li>Small region in which you can analyze <em>everything</em>, like tiny little whole
program analysis</li>
</ul>
<h2>00:13:10 Why do we have a stack again?</h2>
<ul>
<li>Why can't we inline everything?</li>
<li>Two main issues: 1) don't necessarily know call graph for the whole program
2) recursion</li>
<li>If you knew where all the calls went (virtual/indirect/etc in your
translation unit and other ones in your program), and without recursion, you
wouldn't need a stack, you know a perfect call graph</li>
<li>For some of these you could avoid having a stack -- virtual functions but
only a few actually implementations of it, could change to test-and-branch</li>
<li>If you have a fully analyzable virtual dispatch it effectively just becomes a
switch, can potentially inline what the targets are</li>
<li>Control flow analysis takes indirect branch that can go anywhere and
enumerate the real set of possibilities (devirtualization within a
translation unit)</li>
<li>Fully analyzeable call graph is an interesting computer history topic:
FORTRAN77 classically able to do this (programs were restricted enough you
could analyze it)</li>
<li>XLA ML/array programming machine learning compiler has the same property
where the whole call graph is analyzeable so you can create a slab that's the
giant frame for the whole program you're optimizing and all allocations are
known-fixed size</li>
<li>Whole program call graph analyzeability lives on in these niche use cases!</li>
<li>In stark contrast, sometimes we need multiple different kinds of stacks at
the same time!</li>
<li>The JS engine would sometimes recur from JS calls through the VM runtime to
other JS code, and that would need to potentially create a sub-stack (!) --
multi stack problems exist beyond even just needing to analyze/manage a
single stack</li>
<li>Programming in FORTRAN is cool, for scientific code often trying to
solve a specific physics problem don't <em>usually</em> need those tools like
recursion or virtual functions</li>
<li>When everything is "monomorphized" -- you have big arrays of
fixed-value-types you can know everything about the world and really optimize
everything based off of it -- fun mode to be in for scientific computing code</li>
</ul>
<h2>00:16:34 Considerations beyond recursion and indirect calls?</h2>
<ul>
<li>Some languages use the stack for fast thread switching? Things like full
stackful coroutines?</li>
<li>Stacks in Go for example are not contiguous: more like C++ deque: linked list
of lists instead of one contiguous stack -- clever x86 code sequence that
makes it fast to find previous and next frame</li>
<li>Allows Go stacks to be distinct allocations -- each page-wise is one frame
and the next function has another frame -- can put multiple functions in one
allocation</li>
<li>Used to have really bad perf if you were in a hot loop and happened to
straddle that boundary</li>
<li>Coroutines in some languages ended up having some "stackless" stuff like
this, where the closure is heap allocated instead</li>
<li>C++ coroutines try to do away with all the heap allocations, but depends on
optimization level whether it can do that or not</li>
<li>Kind of similar for Objective-C blocks -- until recently always heap
allocated, started being stack allocated in last few years where they could</li>
<li>Language doesn't say whether stuff lives on the heap or not</li>
<li>Because stack is less constrained can live in different places, e.g. in Go</li>
<li>In some cases you remove the allocation entirely</li>
</ul>
<h2>00:18:25 Scaling to millions of threads?</h2>
<ul>
<li>If you want to be able to scale your concurrency assumptions to millions of
threads, you don't want to have huge stacks</li>
<li>Each thread has a stack, and if you have millions of threads you don't want
to be allocating too much</li>
<li>And need to be able to switch between those threads quickly</li>
<li>So raises the question: how do you usually size those stacks in the
per-thread context you have?</li>
<li>If you're doing tiny little operations; e.g. if every operation in your
program was conceptually a thread, you wouldn't want to allocate 512KiB every
time you did a tiny atomic operation</li>
</ul>
<h2>00:19:10 Managed languages putting frames on the heap</h2>
<ul>
<li>On the term "stackless": one of the <a href="https://greenlet.readthedocs.io/en/latest/">Python
"greenlet"</a> ("lightweight thread"
terminology) attempts was called <a href="https://github.com/stackless-dev/stackless/wiki">Stackless
Python</a></li>
<li>In managed languages like Python the frames can be allocated …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tlbh.it/000_mov_fp_sp.html">https://tlbh.it/000_mov_fp_sp.html</a></em></p>]]>
            </description>
            <link>https://tlbh.it/000_mov_fp_sp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975206</guid>
            <pubDate>Tue, 03 Nov 2020 00:52:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New study finds deaths in Game of Thrones follow predictable rules]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24975083">thread link</a>) | @Bologo
<br/>
November 2, 2020 | https://www.psychnewsdaily.com/data-science-study-finds-that-deaths-in-game-of-thrones-are-not-random/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/data-science-study-finds-that-deaths-in-game-of-thrones-are-not-random/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4885" role="main"><div><div><div><p>A <a rel="noreferrer noopener" href="https://www.pnas.org/cgi/doi/10.1073/pnas.2006465117" target="_blank">new study by researchers from five universities</a> across the UK and Ireland has found that the overarching social structure and the distribution of deaths in <em>Game of Thrones </em>reflect the typical numbers found in real human societies. As such, the study “provides quantitative support, for example, for the widespread view that deaths appear to be randomly distributed throughout the narrative even though, in fact, they are not,” the authors write.<span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The new paper appeared on November 2 in the journal <a rel="noreferrer noopener" href="https://www.pnas.org/" target="_blank"><em>Proceedings of the National Academy of Sciences</em></a>.</p><h2><strong>Deaths in <em>Game of Thrones</em> are anything but random</strong></h2><p>The research team consisted of physicists, mathematicians, and psychologists. They used data science and network theory to analyze <em>A Song of Ice and Fire</em>, the acclaimed book series. These books, by George R.R. Martin, formed the basis for the mega-successful HBO television series <em>Game of Thrones</em>.</p><p>“A distinguishing feature of&nbsp;<em>Ice and Fire</em>&nbsp;,” the paper writes, “is that character deaths are perceived by many readers as random and unpredictable.” Indeed, it continues, “the storyteller has manipulated the timeline of the story in such a way as to make it continuously more appealing by making significant events seem random so as to heighten the reader’s engagement.”</p><p>Likewise, the study writes,<em> “A Song of Ice and Fire</em>&nbsp;is a prodigious modern epic of considerable complexity that remains accessible to a vast congregation of devotees. Among its appeals are the uncertainty and unpredictability of its storyline as characters, including important ones, can be killed off seemingly at random.” And not even the main characters “are guaranteed safe passage from one book to the next.”<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>But as the study points out, when the chronological sequence is reconstructed, the deaths are not random at all. Instead, they resemble how a wide range of common human activities are distributed for in the real world. &nbsp;&nbsp;&nbsp;</p><h2>Unravelling the sequence of deaths in Game of Thrones</h2><p>To analyze the evolution of the narrative, the authors use an approximate timeline of the events depicted in <em>Ice and Fire</em>&nbsp;based on the Westerosi calendar date. It has been compiled by fans, <a href="https://www.reddit.com/r/asoiaf/comments/1c07jw/spoilers_all_most_precise_asoiaf_timeline_in/" target="_blank" rel="noreferrer noopener">and is maintained</a> by the Reddit user identified as <a href="https://www.reddit.com/user/PrivateMajor/" target="_blank" rel="noreferrer noopener">PrivateMajor</a>. They use this timeline to assign an approximate date to each chapter of each book, which allows them to study events as they occur within the in-story timeline.</p><p>Their analysis considers only the deaths of significant characters, deemed to because they appeared in more than one chapter. They made this distinction to avoid including the deaths of “cannon-fodder” characters, “whose main purpose in the story is to die immediately after they are introduced.”</p><p>Past research has shown that inter-event time distributions for “many (nonviolent) human activities in the real world, including communication, entertainment, trading, and work, have power-law tails.” <span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>The distribution of deaths in <em>Game of Thrones </em>and <em>A Song of</em>&nbsp;<em>Ice and Fire</em>&nbsp;are close to what we expect in real social networks, the study finds.</p><h2>“Almost” random intervals</h2><p>As the authors summarize, the way the deaths are distributed in the narrative makes the reader think that these deaths “occur almost at random intervals.” But then “analyzing deaths in terms of story time, this is not the case, with significant events occurring in a more natural way. Portraying significant events by discourse time instead of as they happen appears to maintain the reader’s suspense,” they write.</p><p>“These books are known for unexpected twists, often in terms of the death of a major character,” said <a rel="noreferrer noopener" href="https://www.ul.ie/dafinet/p%C3%A1draig-mac-carron" target="_blank">Pádraig MacCarron</a> of the University of Limerick. “It is interesting to see how the author arranges the chapters in an order that makes this appear even more random than it would be if told chronologically,” he said.</p><h2><strong>Thousands of characters, but Dunbar’s Number still applies</strong></h2><p>The more than 2,000 characters in <em>A Song of Ice and Fire</em> have about 41,000 interactions between them. That’s indeed a lot. But at the chapter-by-chapter level, these numbers average out to match what most people experience in real life.</p><p>Even the most predominant characters, the ones who narrate the story, have only about 150 other people to keep track of, on average. This is the same number that the average human brain has evolved to deal with. It is known as <a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">Dunbar’s number</a>, named after the renowned British anthropologist <a href="https://en.wikipedia.org/wiki/Robin_Dunbar">Robin Dunbar</a>. Dunbar was also a co-author of this new study.</p><p>Despite the huge number of (new) characters and interactions, Martin manages to maintain a consistent social network structure. The number of these interactions is at the upper end of the <a href="https://www.psychnewsdaily.com/new-study-shows-that-bed-sharing-couples-sleep-better/">cognitive</a> capacity of an average reader. As the study’s authors write, “the social network a reader has to consider in order to follow the story is similar in scale to natural cognitive capacity.”</p><p>So, despite there being more than 2,000 characters, none has a social network of more than about 150 people, on average. Plus, there are only 14 major “point of view” characters narrating the story. “These are frequent numbers in the structure of real social networks,” the study writes, “and they allow the reader to work within natural templates.”</p><h2>Keeping cognitive load within realistic limits</h2><p>In other words, “the story reflects experiences in the everyday social world and therefore does not overtax cognitive abilities that are evolved to match these scales.”</p><p>Similar limits have been reported for <a href="https://link.springer.com/article/10.1007%2Fs12110-003-1013-1" target="_blank" rel="noreferrer noopener">Shakespeare’s plays</a>, and seem to “reflect natural limits on mentalizing competences — the cognitive skills that underpin our <a href="https://www.psychnewsdaily.com/why-are-americans-vocabulary-skills-stagnating/">ability</a> to handle social relationships in the virtual mental sphere of the everyday social world.”</p><p>The paper also finds that <em>A Song of Ice and Fire</em> is more similar to the Icelandic sagas than to mythological stories such as England’s Beowulf or Ireland’s Táin Bó Cúailnge.</p><h2><strong>Predicting tomorrow’s complex narratives</strong></h2><p>“People largely make sense of the world through narratives,” said co-author <a href="http://www.colmconnaughton.net/" target="_blank" rel="noreferrer noopener">Colm Connaughton</a> of the University of Warwick, “but we have no scientific understanding of what makes complex narratives relatable and comprehensible. The ideas underpinning this paper are steps towards answering this question.”&nbsp;&nbsp;&nbsp;&nbsp;</p><p>Studies like this one might even be used to map out book and film series that have yet to be created. “I am excited to see the use of network analysis grow in the future,” said <a href="http://www.complexity-coventry.org/people/single-view/detail/Yoseph_Jose/" target="_blank" rel="noreferrer noopener">Joseph Yose</a> of Coventry University. “Hopefully, combined with machine learning, we will be able to predict what an upcoming series may look like,” he said.</p><figure><img loading="lazy" width="1024" height="553" src="https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-1024x553.jpg" alt="" srcset="https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-1024x553.jpg 1024w, https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-300x162.jpg 300w, https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-768x414.jpg 768w, https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1-360x194.jpg 360w, https://www.psychnewsdaily.com/wp-content/uploads/2020/11/game-of-thrones-social-1.jpg 1160w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The social network at the end of the first book <em>A Game of Thrones</em>. Blue nodes represent male characters, red are female characters. Transparent grey are characters who are killed by the end of the first book.</figcaption></figure><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/data-science-study-finds-that-deaths-in-game-of-thrones-are-not-random/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24975083</guid>
            <pubDate>Tue, 03 Nov 2020 00:32:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The perfect file server setup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24974971">thread link</a>) | @geek_at
<br/>
November 2, 2020 | https://blog.haschek.at/2020/the-perfect-file-server.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2020/the-perfect-file-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>If you've ever thought of building a file server, you probably had one or more of these thoughts</p>
<ul>
<li>Do I really need to <strong>waste one disk</strong> for the operating system?</li>
<li>I only have <strong>old hardware</strong> with limited RAM, can I still use it as a file server?</li>
<li>If someone <strong>steals my equipment</strong>, how can I make sure they won't have access to my data?</li>
<li>How can I set up a <strong>samba share</strong> that will allow my windows computers to access the data?</li>
<li>I don't have a display to connect to my file server. How can I do it all <strong>headless</strong>?</li>
<li>Is <strong>software raid</strong> any good? What about ZFS?</li>
</ul>
<p><strong>Well, wonder no more!</strong></p>
<p>We're going to build a system that will handle all those things!</p>

<ol>
<li><a href="#usbboot">Preparing the USB to boot</a></li>
<li><a href="#diskman">Managing the disks</a></li>
<li><a href="#fileshares">Creating file shares</a></li>
<li><a href="#docker">Docker and more</a></li>
<li><a href="#faq">FAQ</a></li>
</ol>
<p>My motivation for this was, that I inherited an HP Data Vault x312 <a href="https://www.reddit.com/r/DataHoarder/comments/jkb35f/neighbor_died_of_cancer_and_his_wife_told_me_shes/">from my neighbor who died</a> recently and this device is pretty old, has an Intel Atom d510 with only 2 GB of RAM and no display. It was meant to be used with Windows Home Server. My goal is to use it as an encrypted storage pool for backups running headless Alpine Linux.</p>
<figure><img loading="lazy" src="https://pictshare.net/6c1h06.png"><figcaption>HP Data Vault x312</figcaption></figure>
<hr>


<p>As in my <a href="https://blog.haschek.at/2019/build-your-own-datacenter-with-pxe-and-alpine.html">previous</a> server related <a href="https://blog.haschek.at/2020/the-encrypted-homelab.html">posts</a>, my choice of operating system for file servers is <a href="https://alpinelinux.org/about/">Alpine Linux</a> because it's so damn small (ram usage after boot will be ~100mb), fast and has a ton of up to date packages we're going to be using.</p>
<p>Also it can be configured to run from a RAM disk with configuration stored on a USB drive. Which is exactly what we're going to do.</p>
<h2>You're going to need 2 USB drives</h2>
<p>The size doesn't really matter, I'm using two 16G drives. They don't even have to be USB3, it won't make a difference.</p>
<figure><img loading="lazy" src="https://pictshare.net/800/3xiz7b.png"><figcaption>2 USB drives we'll be using</figcaption></figure>
<p>Why two?</p>
<p>We're going to put the ISO of Alpine Linux on one of them and boot it. Then we're using it to create the second one (which will be the one we're actually putting in our server).</p>
<h3>Flashing the USB</h3>
<p>Go to <a href="https://alpinelinux.org/downloads/">https://alpinelinux.org/downloads/</a> and download the latest x68_64 <strong>EXTENDED</strong> ISO and flash it <strong>to one of the USB drives</strong> using dd or some other etcher program.</p>
<p>Command if you're using dd like a pro: <code>dd if=/path/to/your/alpine-extended.iso of=/dev/sdx</code> where sdx is the device name of your USB drive. If unsure run <code>lsblk | grep disk</code> it will show you the device names and sizes for all connecte drives.</p>
<h2>Booting the install USB drive</h2>
<p>This can still be done on one of your devices and not on the file server. We're just preparing the USB installer here.</p>
<p>Plug your freshly flashed USB in a computer or laptop and boot it. You should see this screen</p>
<p>![Freshly booted Alpine Linux]()</p>
<p>Enter <code>root</code> and press enter, you're now logged in.</p>
<h2>Preparing the USB drive for the file server</h2>
<p>Now is a good time to look at the out put of <code>fdisk -l | grep Disk</code> to see which disks are found.</p>
<figure><img loading="lazy" src="https://pictshare.net/vf0ews.png"><figcaption>It should look something like this</figcaption></figure>
<p>Now plug in the second USB drive and run <code>fdisk -l | grep Disk</code> again to see which device name it has.</p>
<figure><img loading="lazy" src="https://pictshare.net/7ylr9z.png"><figcaption>USB drive is known as /dev/sdc</figcaption></figure>
<p>Great now we have to set up the new USB correctly: <code>fdisk /dev/sdc</code> (use the device name of your USB drive)</p>
<p>Now we're in fdisk. We'll empty the USB drive and create a partition that will host the image and configuration.</p>
<p>Press the following keys in fdisk:</p>
<pre><code>o -&gt; enter
n -&gt; enter
p -&gt; enter
1 -&gt; enter
enter (when asking for first sector)
enter (when asking for last sector)
a -&gt; enter
1 -&gt; enter
w -&gt; enter</code></pre>
<p>now if you run <code>fdisk -l /dev/sdc</code> you should see the new layout like this</p>
<figure><img loading="lazy" src="https://pictshare.net/gr1s3i.png"><figcaption>New USB layout</figcaption></figure>
<p>Now we format the new partition FAT32 and install the system from our booted USB drive</p>
<pre><code>mkdosfs -F32 /dev/sdc1
setup-bootable /media/sdb /dev/sdc1</code></pre>
<p>Note: <code>/media/sdb</code> should already be mounted, it's the file system of the live USB you're using. It might have a different name, check <code>df -h</code> to see what device is mounted to <code>/media/</code></p>
<figure><img loading="lazy" src="https://pictshare.net/0grvrm.png"><figcaption>Successful installation</figcaption></figure>
<h2>Let's prepare it for the fileserver</h2>
<p>If you want to install multiple servers, just plug in more USB drives, <code>fdisk</code> and <code>setup-bootable</code> them.</p>
<p>But now we want to set up the USB drive for our file server. Shut down the PC/Laptop/Server you were using, plug in only the second USB drive (the one you just installed Alpine to) and boot it.</p>
<p>It should look exactly like the first USB drive we were using but now we can save changes we make to the system.</p>
<p>The first thing we're going to run is <code>setup-alpine</code>. Here's a small guide what to enter/choose</p>
<pre><code>[your language code] us -&gt; enter
[probably the same code again] us -&gt; enter
[the hostname you want your machine to have] fileserver -&gt; enter
[eth0] -&gt; enter
[dhcp] -&gt; enter (or you can configure static IP here)
done -&gt; enter
[no] -&gt; enter
[your password] -&gt; enter
[password again] -&gt; enter
[your timezone] Europe/Vienna -&gt; enter
[none] -&gt; enter
[chrony] -&gt; enter
[1] -&gt; enter
[openssh] -&gt; enter
Which disks would you like to use: none -&gt; enter
Enter where to store configs: usb -&gt; enter
[/media/usb/cache] -&gt; enter
(ignore the last warning)</code></pre>
<p>Now you have successfully configured your image! To save changes you made to the system write .</p>
<p><code>lbu commit -d</code></p>
<p>To be able to connect to alpine from the network we need to either set up SSH to allow root logins (by editing <code>/etc/ssh/sshd_config</code> and setting <code>PermitRootLogin</code> to <code>yes</code>) or by adding your ssh keys to the authorized_keys file.</p>
<pre><code>ssh-keygen # press enter until it's done
nano .ssh/authorized_keys # and add your SSH public keys in here
lbu include /root/.ssh # we need to tell alpine that we want to include the .ssh folder to the saved config on the USB
lbu commit -d # and saving to USB</code></pre>
<p>You always need to run <code>lbu commit -d</code> after you changed any config file or installed a program otherwise it will be lost on reboot. To see which files are included run <code>lbu ls</code></p>
<p>The idea for this is that the USB has all the programs and config but all data is stored on the mounted drives.</p>
<p>To confirm it really works, reboot the system and boot from the same USB again. If it needs your new password at login everything worked.</p>
<p>Now it can be plugged into the file server and booted. If you already have other disks in your server, make sure it's set to boot from USB. For my Data Vault I didn't have to (or would have been able to) change anything in the BIOS because if it can't find a boot partition on any disk, it will go straight to USB boot. Neat!</p>
<p>If you didn't set a fixed IP address then you'll have to do a lan scan</p>
<hr>


<p>I did all the dirty benchmarking for you already. Here it is</p>
<figure><a href="https://pictshare.net/8l2o1b.png"><img loading="lazy" src="https://pictshare.net/8l2o1b.png"><figcaption>Graph that shows how slow/fast different disk configurations are. I have no idea what happend to the RAID 5 read speeds, they don't even match RAID0</figcaption></a></figure>
<p>Now that we have our system up and running it's time to add the drives and use them. But first let's install a few things that will make our lives easier.</p>
<p><code>apk add nano htop lsblk e2fsprogs</code></p>
<p>Let's look at the disk configuration we have: <code>lsblk | grep disk</code></p>
<figure><img loading="lazy" src="https://pictshare.net/x7l1qa.png"><figcaption>All disks that have been found. Data disks from sda to sdd</figcaption></figure>
<p>Awesome so we have 3x3TB and 1x 2.5TB disks (I'll change the smaller one when my new 3TB gets here)</p>
<p>From here it's basically a "choose your own adventure" thing. We have 4 drives so we can set them up in different ways.</p>
<p>My choice is: RAID 5 using <code>mdadm</code> and over the combined storage LUKS encryption. If you feel you won't need encryption you can just skip it. If your CPU is as old as mine and doesn't have the aes-ni extension, encryption will probably be bottlenecking file transfers but personally I just can't say no to an encrypted homelab.</p>
<h2>Side note: ZFS</h2>
<p>Alpine Linux fully supports ZFS. You can read <a href="https://wiki.alpinelinux.org/wiki/Setting_up_ZFS_on_LUKS">this guide</a> how to use it even with encryption on Alpine. Since ZFS requires a bit more CPU than mdadm I'll be using the latter but on my main file server at home I'm using ZFS as well.</p>
<h2>Settung up RAID 5</h2>
<p>First we'll going to need <code>mdadm</code>,  we can install it using <code>apk add mdadm</code></p>
<p>Then we`ll have to make sure it runs on boot using</p>
<pre><code>rc-update add mdadm boot
rc-update add mdadm-raid boot</code></pre>
<p>Let's create or RAID!</p>
<pre><code>mdadm --create /dev/md0 --level=5 --raid-devices=4 /dev/sda /dev/sdb /dev/sdc /dev/sdd</code></pre>
<p>Depending on your hardware and disk size it might take pretty long for the RAID to sync so you can watch it using <code>watch cat /proc/mdstat</code></p>
<figure><img loading="lazy" src="https://pictshare.net/va1pwf.png"><figcaption>Watching the raid getting made</figcaption></figure>
<p>After it's finished, we can save the raid configuration info using <code>mdadm --examine --scan &gt; /etc/mdadm.conf</code> and don't forget to <code>lbu commit -d</code> after doing so.</p>
<p>Ok so now you have to choose</p>
<h3>a) No encryption</h3>
<p>If you don't need encryption then you're almost done.</p>
<p>First we need to give the RAID device (<code>/dev/md0</code>) a file system and then mount it.</p>
<pre><code>mkfs.ext4 /dev/md0
mount -t ext4 /dev/md0 /mnt</code></pre>
<p>At this stage you should see the disk array when running <code>df -h</code>. Congratulations if you made it this far!</p>
<p>To automate mount on boot add the following to your <code>/etc/fstab</code></p>
<pre><code>/dev/md0    /mnt    ext4    rw  0   0</code></pre>
<h3>b) Using LUKS disk encryption</h3>
<p>For testing purposes I'll be using a password for encryption but if you want your server to automatically unlock after boot, see this post I wrote about the subject: <a href="https://blog.haschek.at/2020/the-encrypted-homelab.html">The encrypted homelab</a></p>
<p><code>openssl rand 512 | base64 -w 0 | tr -cd '[:alnum:]._-' | head -c 64</code></p>
<figure><img loading="lazy" src="https://pictshare.net/11ukk1.png"><figcaption>This should spit out a good password for us to use but you can use your own if you like</figcaption></figure>
<p>Now that we have our password, we encrypt the raid device</p>
<pre><code>cryptsetup -v -c serpent-xts-plain64 -s 512 --hash sha256 luksFormat /dev/md0</code></pre>
<p>Then we'll have to unlock it (after every boot too, see <a href="https://blog.haschek.at/2020/the-encrypted-homelab.html">my other post</a> on how to automate it)</p>
<pre><code>cryptsetup open /dev/md0 data</code></pre>
<p>The second parameter is now used as our new block device we can use. It creates <code>/dev/mapper/data</code> and we can now use it as if it were a normal hard disk.</p>
<p>So let's first give it a file system and then mount it</p>
<pre><code>mkfs.ext4 /dev/mapper/data
mount -t ext4 /dev/mapper/data /mnt</code></pre>
<p>Now you should see your fully encrypted data drive on <code>/mnt</code> (use <code>df -h</code> to check if it's mounted). Since you have to encrypt it before you can mount it, we can't add it to <code>/etc/fstab</code> but in <a href="https://blog.haschek.at/2020/the-encrypted-homelab.html">my other post</a> I explain how it can still be automated on boot.</p>
<hr>


<p>We're going with the obvious solution here: Samba. That's linux powered windows shares which can be accessed by basically all operating systems.</p>
<p>Fi…</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.haschek.at/2020/the-perfect-file-server.html">https://blog.haschek.at/2020/the-perfect-file-server.html</a></em></p>]]>
            </description>
            <link>https://blog.haschek.at/2020/the-perfect-file-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974971</guid>
            <pubDate>Tue, 03 Nov 2020 00:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leaving OCaml]]>
            </title>
            <description>
<![CDATA[
Score 236 | Comments 180 (<a href="https://news.ycombinator.com/item?id=24974907">thread link</a>) | @rbanffy
<br/>
November 2, 2020 | https://blog.darklang.com/leaving-ocaml/ | <a href="https://web.archive.org/web/*/https://blog.darklang.com/leaving-ocaml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.darklang.com/content/images/size/w300/2020/11/skeleton-camel.jpg 300w,
                            https://blog.darklang.com/content/images/size/w600/2020/11/skeleton-camel.jpg 600w,
                            https://blog.darklang.com/content/images/size/w1000/2020/11/skeleton-camel.jpg 1000w,
                            https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.darklang.com/content/images/size/w2000/2020/11/skeleton-camel.jpg" alt="Leaving OCaml">
            </figure>

            <section>
                <div>
                    <p><em>Part of a 3 part series. Followups on <a href="https://blog.darklang.com/new-backend-fsharp/">F#</a>, <a href="https://blog.darklang.com/why-dark-didnt-choose-rust/">Rust</a></em></p><p>I built the first demo of Dark in Python, in about two weeks. A few months later when I started productizing it, I rebuilt it in OCaml. Back in 2017, when I was considering the language and platform to use for Dark, OCaml was extremely compelling:</p><ul><li>it's a high-level language with static types, so easy to make large scale changes as we figure out what the language/product was</li><li>you mostly model data with sum types, which in my mind are the best way to model data</li><li>it's very similar to the language I wanted to build (in particular, we could reuse built-in immutable data structures for Dark's values)</li><li>it had a reputation for being high-performance, which meant that we could write an interpreter for Dark and not have it be terribly slow (vs writing an interpreter in python, which might be too slow)</li></ul><p>Unfortunately, as we've built Dark we've run into significant problems that have made it challenging to build in OCaml.</p><h2 id="lack-of-libraries">Lack of libraries</h2><p>When you bet on an off-mainstream language, one of the things you accept is that many libraries are not going to be available. When there is a small community, often there aren't enough people working in the language to make important libraries. This is especially true if few people are building business applications.</p><p>In OCaml there are many high quality libraries, especially for data structures and data manipulation. The annual<a href="https://opensource.janestreet.com/core/"> Jane Street code dump</a> has been quite useful and very high quality. However, we really felt the lack of several libraries. The most obvious of these is that we had to build a <a href="https://github.com/darklang/dark/blob/main/backend/libexecution/unicode_string.mli">Unicode string library</a> ourselves (built on top of the <a href="https://erratique.ch/software/uuseg">very impressive OCaml Unicode libraries</a> built by <a href="https://erratique.ch/contact.en">Daniel Bünzli</a>), but we needed many more libraries than that.</p><p>The lack of an SDK for Google Cloud has affected us greatly. When you're searching for product-market fit, you do the simplest, easiest thing. If you lack a good SDK for your cloud provider, the simplest, easiest thing is often a terrible architectural choice. We've built our own queue on top of our database rather than using the production-quality cloud queues available on GCP. Similarly, we barely use the Cloud Storage (GCP's version of S3), because we initially put things in the database <a href="https://blog.darklang.com/evolving-darks-tracing-system/">because it was easier</a>. We've built 3 services, 2 <a href="https://github.com/darklang/dark/tree/main/containers/stroller">in</a> <a href="https://github.com/darklang/dark/tree/main/containers/queue-scheduler">Rust</a>, and 1 in <a href="https://github.com/darklang/dark/tree/main/containers/postgres-honeytail">Go</a>, to workaround the challenges we've faced.</p><p>The biggest challenge here is our use of Postgres. Postgres is a great database and we're big fans, but Cloud SQL is not a great hosted database. GCP's position is that Cloud SQL is there to tick a box and we should be using Cloud Spanner. I would love to switch to Cloud Spanner, but we have no driver for it in OCaml. Given the Postgres driver in OCaml is not particularly mature, it's hard to expect that a Cloud Spanner driver would exist, and indeed it doesn't. We've had to contribute to the <a href="https://github.com/mmottl/postgresql-ocaml/commit/81a4ae5240decd8f483a90568257cfbc1558c7ed">OCaml Postgres driver</a>, and some parts of our codebase have been <a href="https://github.com/darklang/dark/blob/main/backend/libbackend/serialize.ml#L226">well and truly mangled</a> when working around features not supported in that driver.</p><p>We've also suffered from a lack of a high-level, production web stack (there are <a href="https://github.com/anmonteiro/ocaml-h2">low-level stacks with good reputations</a> that I've struggled to use, and a <a href="https://github.com/oxidizing/sihl">few</a> <a href="https://github.com/reason-native-web/morph">new</a> ones out there that look good), in particular lacking a user authentication module. We've been using <a href="https://auth0.com/">Auth0</a> to work around this for now, which has more moving pieces than I'd like, and a shockingly high cost (our 7000 users, most of whom never log in, costs us over $500/mo).</p><p>We've worked around other missing vendor SDKs by calling their HTTP endpoints directly and that's been mostly fine. However, for libraries like encryption we don't have that option - we <a href="https://github.com/darklang/dark/pull/1455/files">hacked around a missing encryption library</a>, but decided not to ship it to production until we audited it for security (which was never actually worth the cost).</p><p>At CircleCI, we bet on Clojure. That was also a non-mainstream language, but its ability to call Java SDKs meant we had a mature cloud library, which was essential for building CircleCI. Of course, in OCaml we could call C libraries (and <a href="https://github.com/darklang/dark/pull/1841">even Rust libraries</a>, perhaps), but it doesn't match having native libraries we can call directly.</p><h2 id="learnability">Learnability</h2><p>I'm mostly in the camp that anyone can learn any language, but I saw a team struggle with OCaml, and for good reason. Language tutorials are extremely poor in OCaml compared to other languages; they're mostly lecture notes from academic courses.</p><p>The compiler isn't particularly helpful, certainly compared to Rust or Elm (both of which have been in our stack at one point). Often it gives no information about an error. Syntax errors typically say "Syntax error"; though it will try to give a good error for a mismatched brace, often incorrectly. Type errors can be a real burden to read, even after 3 years of experience with it.</p><p>The docs in OCaml are often challenging to find. The <a href="https://ocaml.janestreet.com/ocaml-core/latest/doc/base/index.html">Jane Street docs</a> have improved significantly in the last few years, but it can be a challenge to even figure out what functions are available in a particular module for most libraries. Compare to the excellent <a href="https://docs.rs/">docs.rs</a> in Rust, which has comprehensive API docs for every package in Rust.</p><p>One of the ways I personally struggled in OCaml is around <code>Lwt</code>. Lwt is (one of!) OCaml's async implementations. I couldn't figure it out several years ago and so just built a single-threaded server. The amount of workarounds and downtime we've suffered from that single decision is immense. A tutorial around building high-performance (or even medium performance!) web servers would be very valuable. </p><p>Tooling is something I read would be good in OCaml. I remember reading there was a debugger that could go back in time! I don't know where that's gone but I've never heard of anyone using it.</p><p>We have struggled to make editor tooling work for us. This is partially because we also use ReasonML and this seems to break things. Unfortunately, this is common in programming, but even more so in small communities: you might be the first person to ever try to use a particular configuration.</p><p>Finally, the disconnect between the various tools is immense. You need to understand Opam, Dune, and Esy, to be able to get something working (you could also do it without Esy and just rely on Opam, but that's much worse). I talked about a bunch of these challenges <a href="https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/">here</a>.</p><h2 id="language-problems">Language problems</h2><p>Multicore is coming Any Day Now™️, and while this wasn't a huge deal for us, it was annoying. </p><h2 id="minor-annoyances">Minor annoyances</h2><p>One of my biggest annoyances was how often OCaml folks talk about Fancy Type System problems, instead of how to actually build products and applications. In other communities for similar languages (ReasonML, Elm, F#), people talk about building apps and solving their problems. In OCaml, it feels like people spend an awful lot of time discussing Functors. It's not quite at the level that I perceived in the Haskell world, but it pointed out that the people building the core of the ecosystem do not have the same problems that I do (which is building web-y stuff).</p><p>I honestly think OCaml was a great choice at the start. Being able to quickly and safely make large-scale changes to your app is something that staticly-typed functional languages excel at. I'm happy that we made the choice, and in retrospect, it still seems like the best choice of those we had at the time.</p><p>I'm working on building the next version of the backend. We have about 20k lines to be replaced, and they'll be rewritten in a new language while keeping the semantics the same. I plan to leave keep the frontend in ReasonML: it doesn't suffer from the same library problems as it can interface nicely to JS, and it's nearly 50k lines of code so it would be a much bigger undertaking.</p><p>Read <a href="https://blog.darklang.com/new-backend-fsharp/">the followup</a> to see what we picked!</p><hr><p><em><em><em><em><em><em><em><em>You can sign up for Dark </em></em></em></em></em></em></em></em><a href="https://darklang.com/signup" rel="noopener nofollow"><em><em><em><em><em><em><em><em>here</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>. For more info on Dark, follow our </em></em></em></em></em></em></em></em><a href="https://blog.darklang.com/rss" rel="noopener nofollow"><em><em><em><em><em><em><em><em>RSS</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, follow </em></em></em></em></em></em></em></em><a href="https://twitter.com/darklang" rel="noopener nofollow"><em><em><em><em><em><em><em><em>us</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em> (or </em></em></em></em></em></em></em></em><a href="https://twitter.com/paulbiggar" rel="noopener nofollow"><em><em><em><em><em><em><em><em>me</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>) on Twitter, join our </em></em></em></em></em></em></em></em><a href="https://darklang.com/slack-invite" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Slack Community</em></em></em></em></em></em></em></em></a><em><em><em><em><em><em><em><em>, watch our </em></em></em></em></em></em></em></em><a href="https://github.com/darklang/dark" rel="noopener nofollow"><em><em><em><em><em><em><em><em>GitHub repo</em></em></em></em></em></em></em></em></a><em>, or join our <a href="http://darklang.com/mailing-list">mailing list</a><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.darklang.com/leaving-ocaml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24974907</guid>
            <pubDate>Tue, 03 Nov 2020 00:03:20 GMT</pubDate>
        </item>
    </channel>
</rss>
