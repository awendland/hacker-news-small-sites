<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 25 Feb 2021 16:56:46 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 25 Feb 2021 16:56:46 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A Telegram bot in Elixir featuring LiveView]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26247755">thread link</a>) | @lawik
<br/>
February 24, 2021 | https://underjord.io/a-telegram-bot-in-elixir.html | <a href="https://web.archive.org/web/*/https://underjord.io/a-telegram-bot-in-elixir.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2021-02-24</small>
        <p>I <a href="https://twitter.com/lawik/status/1357226010215911425">asked my network on Twitter</a> about noting ideas quickly and got a lot of good responses. One mentioned saving them in Telegram. I don’t think I want to do specifically that but I do want a minimum friction way of noting ideas for later review and refinement. And sending them to a Telegram chat would be quite nice. So I started on the path of something like a note-taking system using Telegram for ingesting quick notes. And I want to share the satisfaction I felt with seeing the near real-time way that it works.</p>
<p>I’ll show some of the process I went through so you can repeat it for your own needs but the repo is open if you want to see where I’ve taken it since. You can find it as <a href="https://github.com/lawik/noted">lawik/noted</a> on GitHub. This guide recreates a simpler approach based off of what I learnt setting that up.</p>
<h2 id="setting-up-your-project">Setting up your project</h2>
<p>I’m using Elixir and Phoenix with LiveView. You need to have the Phoenix project generator installed to follow along, you can follow the Phoenix installation instructions to get it.</p>

  

<p>It should create your project, you can certainly name it something different than <code>noted</code>. I left Ecto in because you’ll likely want it at some point though I won’t use it in this post.</p>
<h2 id="some-initial-setup">Some initial setup</h2>
<p>In <code>lib/noted/application.ex</code> I comment out the <code>Noted.Repo</code> because we’re not using the DB.</p>
<p>In <code>mix.exs</code> for deps I add:</p>

  <div data-file="mix.exs">
  <p>mix.exs</p>
  <div><pre><code data-lang="elixir">    <span>..</span>
      {<span>:telegram</span>, <span>git</span>: <span>"https://github.com/visciang/telegram.git"</span>, <span>tag</span>: <span>"0.7.0"</span>},
      <span># Gun mismatch with telegram and cowboy</span>
      {<span>:cowlib</span>, <span>"~&gt; 2.7"</span>, <span>override</span>: true}
    <span>..</span></code></pre></div>
  </div>

<p>The cowlib thing has to do with some weirdness in the telegram library deps. But adding this should allow you to do <code>mix deps.get</code> and have it work.</p>
<h2 id="get-yourself-a-telegram-bot">Get yourself a Telegram bot</h2>
<p>So get situated with a Telegram account and add <a href="https://t.me/BotFather">The Botfather (Telegram link)</a> as someone to talk to and that’s Telegrams bot for creating bots. Very meta. Pretty convenient.</p>
<p>You write <code>/newbot</code> to him and he’ll guide you through the rest. You’ll receive a secret that you should squirrel away and we’ll use it as a an API key for running our bot.</p>
<p>You’re going to want a convenient client to test things as well. I’m using the MacOS desktop client on this machine, it is nice and native.</p>
<h2 id="minimum-viable-bot">Minimum Viable Bot</h2>
<p>It needs to be self-aware. So let’s make that happen. To protect the bot token I put it in a file in my home dir called <code>.mybotcredentials</code> or something similar. This file is just:</p>

  <div data-file="~/.mybotcredentials">
  <p>~/.mybotcredentials</p>
  <div><pre><code data-lang="shell">export TELEGRAM_BOT_SECRET<span>=</span><span>"my_secret_goes_here"</span></code></pre></div>
  </div>

<p>And before running the server I do: <code>source ~/.mybotcredentials</code></p>
<p>This prevents me from accidentally committing the damned things.</p>
<p>Okay, time to create this bot. Create a file in the project named <code>lib/noted/bot.ex</code>. In this file we do this:</p>

  <div data-file="lib/noted/bot.ex">
  <p>lib/noted/bot.ex</p>
  <div><pre><code data-lang="elixir">defmodule <span>Noted.Bot</span> do
  use <span>GenServer</span>
  require <span>Logger</span>

  def start_link(opts) do
    <span>GenServer</span><span>.</span>start_link(__MODULE__, opts, opts)
  end

  <span>@impl</span> <span>GenServer</span>
  def init(opts) do
    {key, _opts} <span>=</span> <span>Keyword</span><span>.</span>pop!(opts, <span>:bot_key</span>)

    case <span>Telegram.Api</span><span>.</span>request(key, <span>"getMe"</span>) do
      {<span>:ok</span>, me} <span>-&gt;</span>
        <span>Logger</span><span>.</span>info(<span>"Bot successfully self-identified: </span><span>#{</span>me[<span>"username"</span>]<span>}</span><span>"</span>)

        state <span>=</span> %{
          <span>bot_key</span>: key,
          <span>me</span>: me,
          <span>last_seen</span>: <span>-</span><span>2</span>
        }

        {<span>:ok</span>, state}

      error <span>-&gt;</span>
        <span>Logger</span><span>.</span>error(<span>"Bot failed to self-identify: </span><span>#{</span>inspect(error)<span>}</span><span>"</span>)
        <span>:error</span>
    end
  end
end</code></pre></div>
  </div>

<p>This is a GenServer and we want to add it to run when our application starts. So below your Noted.Endpoint, inside the list of children in <code>lib/noted/application.ex</code> add this:</p>

  <div data-file="lib/noted/application.ex">
  <p>lib/noted/application.ex</p>
  <div><pre><code data-lang="elixir"><span>..</span>
{<span>Noted.Bot</span>, <span>bot_key</span>: <span>System</span><span>.</span>get_env(<span>"TELEGRAM_BOT_SECRET"</span>)}
<span>..</span></code></pre></div>
  </div>

<p>Now you can make sure you’ve run <code>mix deps.get</code> and then run <code>mix phx.server</code> to try it out. Check your logs, the happy message should be there.</p>
<h2 id="set-yourself-up-to-receive-updates">Set yourself up to receive updates</h2>
<p>So it still doesn’t really do anything. We will be using long polling which is a neat way of getting updates from a Telegram bot without publishing the server on the web on some real domain and in some systems it might be a bit of a pain. In Elixir, on a GenServer it is comparatively trivial. At least if you know your GenServers.</p>
<p>Just after we set up our state and before we return <code>{:ok, state}</code> in the bot we need to add a call to <code>next_loop()</code>. So the your <code>init/1</code> looks like this:</p>

  <div data-file="lib/noted/bot.ex">
  <p>lib/noted/bot.ex</p>
  <div><pre><code data-lang="elixir"><span>..</span>
  def init(opts) do
    {key, _opts} <span>=</span> <span>Keyword</span><span>.</span>pop!(opts, <span>:bot_key</span>)

    case <span>Telegram.Api</span><span>.</span>request(key, <span>"getMe"</span>) do
      {<span>:ok</span>, me} <span>-&gt;</span>
        <span>Logger</span><span>.</span>info(<span>"Bot successfully self-identified: </span><span>#{</span>me[<span>"username"</span>]<span>}</span><span>"</span>)

        state <span>=</span> %{
          <span>bot_key</span>: key,
          <span>me</span>: me,
          <span>last_seen</span>: <span>-</span><span>2</span>
        }
        next_loop()

        {<span>:ok</span>, state}

      error <span>-&gt;</span>
        <span>Logger</span><span>.</span>error(<span>"Bot failed to self-identify: </span><span>#{</span>inspect(error)<span>}</span><span>"</span>)
        <span>:error</span>
    end
  end
<span>..</span></code></pre></div>
  </div>

<p>Now to add the rest. This GenServer will send itself a message saying “ey, check for updates” and then act on that message until the activity is done and then call <code>next_loop/0</code> again to trigger another message. We’ll start with acting on the message with a <code>handle_info/2</code> callback. In your bot GenServer module:</p>

  <div data-file="lib/noted/bot.ex">
  <p>lib/noted/bot.ex</p>
  <div><pre><code data-lang="elixir"><span>..</span>
  <span>@impl</span> <span>GenServer</span>
  def handle_info(<span>:check</span>, %{<span>bot_key</span>: key, <span>last_seen</span>: last_seen} <span>=</span> state) do
    state <span>=</span>
      key
      <span>|&gt;</span> <span>Telegram.Api</span><span>.</span>request(<span>"getUpdates"</span>, <span>offset</span>: last_seen <span>+</span> <span>1</span>, <span>timeout</span>: <span>30</span>)
      <span>|&gt;</span> case do
        <span># Empty, typically a timeout. State returned unchanged.</span>
        {<span>:ok</span>, []} <span>-&gt;</span>
          state

        <span># A response with content, exciting!</span>
        {<span>:ok</span>, updates} <span>-&gt;</span>
          <span># Process our updates and return the latest update ID</span>
          last_seen <span>=</span> handle_updates(updates, last_seen)

          <span># Update the last_seen state so we only get new updates on the</span>
          <span># next check</span>
          %{state <span>|</span> <span>last_seen</span>: last_seen}
      end

    <span># Re-trigger the looping behavior</span>
    next_loop()
    {<span>:noreply</span>, state}
  end

  defp handle_updates(updates, last_seen) do
    updates
    <span># Process our updates</span>
    <span>|&gt;</span> <span>Enum</span><span>.</span>map(fn update <span>-&gt;</span>
      <span>Logger</span><span>.</span>info(<span>"Update received: </span><span>#{</span>inspect(update)<span>}</span><span>"</span>)
      <span># Offload the updates to whoever they may concern</span>
      broadcast(update)

      <span># Return the update ID so we can boil it down to a new last_seen</span>
      update[<span>"update_id"</span>]
    end)
    <span># Get the highest seen id from the new updates or fall back to last_seen</span>
    <span>|&gt;</span> <span>Enum</span><span>.</span>max(fn <span>-&gt;</span> last_seen end)
  end

  defp broadcast(update) do
    <span># Send each update to a topic for others to listen to.</span>
    <span>Phoenix.PubSub</span><span>.</span>broadcast!(<span>Noted.PubSub</span>, <span>"bot_update"</span>, {<span>:update</span>, update})
  end

  defp next_loop do
    <span>Process</span><span>.</span>send_after(self(), <span>:check</span>, <span>0</span>)
  end
<span>..</span></code></pre></div>
  </div>

<p>Try it out, it should log messages as they are sent to your bot.</p>
<h2 id="getting-real-time-with-liveview">Getting real-time with LiveView</h2>
<p>We can repurpose the existing LiveView that the Phoenix generator gives us. So just open <code>lib/noted_web/live/page_live.ex</code> and its sibling the template <code>lib/noted_web/live/page_live.html.leex</code>. In the <code>page_live.ex</code> file we change it to this:</p>

  <div data-file="lib/noted_web/live/page_live.ex">
  <p>lib/noted_web/live/page_live.ex</p>
  <div><pre><code data-lang="elixir">defmodule <span>NotedWeb.PageLive</span> do
  use <span>NotedWeb</span>, <span>:live_view</span>

  <span>@impl</span> true
  def mount(_params, _session, socket) do
    <span>Phoenix.PubSub</span><span>.</span>subscribe(<span>Noted.PubSub</span>, <span>"bot_update"</span>)
    {<span>:ok</span>, assign(socket, <span>messages</span>: [])}
  end

  <span>@impl</span> true
  def handle_info({<span>:update</span>, update}, socket) do
    {<span>:noreply</span>, assign(socket, <span>messages</span>: [to_message(update) <span>|</span> socket<span>.</span>assigns<span>.</span>messages])}
  end

  defp to_message(%{<span>"message"</span> <span>=&gt;</span> message} <span>=</span> _update) do
    firstname <span>=</span> get_in(message, [<span>"from"</span>, <span>"first_name"</span>])
    lastname <span>=</span> get_in(message, [<span>"from"</span>, <span>"last_name"</span>])
    username <span>=</span> get_in(message, [<span>"from"</span>, <span>"username"</span>])

    from <span>=</span>
      case {firstname, lastname, username} do
        {nil, _, username} <span>-&gt;</span> username
        {firstname, nil, _} <span>-&gt;</span> firstname
        {firstname, lastname, _} <span>-&gt;</span> <span>"</span><span>#{</span>firstname<span>}</span><span> </span><span>#{</span>lastname<span>}</span><span>"</span>
      end

    text <span>=</span> get_in(message, [<span>"text"</span>])
    %{<span>from</span>: from, <span>text</span>: text}
  end
end</code></pre></div>
  </div>

<p>And we change the <code>page_live.html.leex</code> template file to:</p>

  <div data-file="lib/noted_web/live/page_live.html.leex">
  <p>lib/noted_web/live/page_live.html.leex</p>
  <div><pre><code data-lang="html">&lt;<span>section</span> <span>class</span><span>=</span><span>"phx-hero"</span>&gt;
  &lt;<span>h1</span>&gt;<span>&lt;</span>%= gettext "Welcome to my Bot!" %&gt;&lt;/<span>h1</span>&gt;

  <span>&lt;</span>%= for message &lt;<span>-</span> <span>Enum</span><span>.</span><span>reverse</span><span>(@</span><span>messages</span><span>)</span> <span>do</span> <span>%</span>&gt;
  &lt;<span>p</span>&gt;&lt;<span>strong</span>&gt;<span>&lt;</span>%= message.from %&gt;: &lt;/<span>strong</span>&gt;<span>&lt;</span>%= message.text %&gt;&lt;/<span>p</span>&gt;
  <span>&lt;</span>% end %&gt;
&lt;/<span>section</span>&gt;</code></pre></div>
  </div>

<p>Run this and you should see any message to type in the Telegram bot show up. I find it very gratifying just how instantaneous it can be.</p>
<h2 id="in-closing">In closing</h2>
<p>This is just a start and in the <a href="https://github.com/lawik/noted">noted repo</a> you will find some of what I’ve done to push it further, structure the bot a little bit more. Add some responses. You can just try it out by cloning and setting it up.</p>
<p>I implemented some authentication. Currently this means that notes are separated by user. It also means that Noted allows new users by default if they find your bot :D</p>
<p>I implemented the database backing to save notes and tags. I added a bunch more LiveView code. I separated the polling for getUpdates from the handling of the updates a bit more and added a Supervisor to the pairing of GenServers.</p>
<p>Currently on my todo-list is to receive files and media in a nice way and integrate those with the markdown support. If you want practice with Tailwind CSS I’d love for someone to make it look better.</p>
<p>But this particular project aside I find the realtime nature of chat bots very satisfying. Telegram has a well-working API, nice native clients and a hilariously large feature set. And with how fast you can get this up and running when it isn’t your first time I really recommend trying it for things. Heck, you could use it for sending you notices about your app catching fire or occasional status updates from your system. There are so many fun options.</p>
<p>Slightly timely update, especially if you are curious about LiveView or want more of me. Me and a wild gang of Elixir community folks just put our new podcast out there. It is called <a href="https://beamrad.io/">BEAM Radio</a> and you find it at <a href="https://beamrad.io/">beamrad.io</a>.</p>
<p>I hope you’ve enjoyed the post. Let me know if this is something you would like to see more of as I have quite a few things I could go deeper into from this …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/a-telegram-bot-in-elixir.html">https://underjord.io/a-telegram-bot-in-elixir.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/a-telegram-bot-in-elixir.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26247755</guid>
            <pubDate>Wed, 24 Feb 2021 08:09:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modules, Monoliths, and Microservices]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26247052">thread link</a>) | @kozmico
<br/>
February 23, 2021 | https://tailscale.com/blog/modules-monoliths-and-microservices/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/modules-monoliths-and-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Lately, I get people asking me when microservices are a good idea. In <a href="https://apenwarr.ca/log/20201227">systems design explains the world</a>, I talked about big-picture issues like second system effect, innovator’s dilemmas, and more. Can systems design answer the microservices question?</p>
<p>Yes, but you might not like the answers. First, we'll need some history.</p>
<h4 id="what-is-a-microservice">What is a microservice?</h4>
<p>You can find various definitions on the Internet. Here's mine: microservices are the most extreme possible backlash against <em>monoliths</em>.</p>
<p>Monoliths are what happen when you link everything your entire app needs into one giant program and deploy it as one big blob. Monoliths have a long history, going back to frameworks like CGI, Django, Rails, and PHP.</p>
<p>Right away, let's abandon the assumption that a monolith and a fleet of microservices are the only two options. There's a wide and nuanced continuum from "one giant service that does everything" to "infinite tiny services that each do nearly nothing."</p>
<p>If you follow fads, you'll have built a monolith at least once (whether on purpose or because that's what traditional frameworks encouraged you to do), then discovered some problems with monoliths, then heard that microservices are the answer, then started rearchitecting everything as microservices.</p>
<p>But don't follow fads. There are many points in between those extremes. One of them is probably right for you. A better approach starts with where you want to put your <em>interfaces</em>.</p>
<h4 id="boxes-and-arrows">Boxes and arrows</h4>
<p>An interface is the connection between <em>modules.</em> A module is a collection of related code. In systems design, we talk about "boxes and arrows" engineering: modules are the boxes, and interfaces are the arrows.</p>
<p>The deeper question then is: how big are the boxes? How much goes in each box? How do we decide when to split one big box into two smaller ones? What's the best way to connect the boxes? There are many approaches to all this. Nobody quite knows what's best. It's one of the hardest problems in software architecture.</p>
<p>Over the decades, we've evolved through many kinds of "boxes." <a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">Goto statements were "considered harmful"</a> largely because they prevented any hierarchy at all. Then we added functions or procedures; those are very simple boxes, with interfaces (parameters and return codes) between them.</p>
<p>Depending which branch of programming you go down, you then discover recursive functions, combinators, static function prototypes, libraries (statically or runtime-linked), objects (OOP), coroutines, protected virtual memory, processes, threads, JITs, namespaces, sandboxes, chroots, jails, containers, virtual machines, supervisors, hypervisors, microkernels, and <a href="https://en.wikipedia.org/wiki/Unikernel">unikernels</a>.</p>
<p>And that's just the boxes! Once you have boxes isolated from each other, then you need to connect them with arrows. For that, we have ABIs, APIs, syscalls, sockets, RPCs, filesystems, databases, message passing systems, and "virtualized hardware."</p>
<p>If you tried to draw a complete boxes-and-arrows diagram of a modern Unix system (which I won't), it would be wild: functions inside threads inside processes inside containers inside userspace, layered under a kernel, inside a VM, running on hardware in a rack in a datacenter in a cloud provider tied together by an orchestration system, and so on.</p>
<p>Each of those boxes at each of the abstraction layers is somehow isolated from and then connected to some of the others, at the same or other layers. Some are inside others. You couldn't draw an honest version of this picture in a mere two dimensions without lines criss-crossing hopelessly.</p>
<p>This all evolved over decades. Fancy people call it "path dependence." I call it a mess. And let's be clear: most of the mess no longer provides much value.</p>
<p>Instead of focusing on what became very ugly evolutionary results, let's talk about what people were <em>trying</em> to do while they invented all that stuff.</p>
<h4 id="the-quest-for-modularity">The quest for modularity</h4>
<p>The top-line goals of module systems are always the same:</p>
<ol>
<li>Isolate each bit of code from the other bits.</li>
<li>Re-connect those bits only where explicitly intended (through a well-defined interface).</li>
<li>Guarantee that bits you change will still be compatible with the right other bits.</li>
<li>Upgrade, downgrade, and scale some bits without having to upgrade all the other bits simultaneously.</li>
</ol>
<p>The computer industry spends an absolutely immense amount of time messing around, trying to find the perfect balance of all these modularity issues, while still trying to keep development as painless and easy as possible.</p>
<p>We are, in short, not succeeding.</p>
<p>By far the part we're worst at is #1, isolation. If we could truly and efficiently isolate one bit of code from another, the other goals would mostly fall into place. But we simply do not know how.</p>
<p>Isolation is a super hard problem. Goodness knows people have tried. Yet browser sandbox escapes still happen regularly, undetected privilege escalation attacks are simply assumed to exist on every OS, iOS still gets jailbroken periodically, DRM never works (for better or worse), virtual machines and containers regularly have vulnerabilities discovered, and systems like <a href="https://blog.alcide.io/insecure-by-default-kubernetes-networking">k8s have their containers configured insecurely by default</a>.</p>
<p>People have even been known to <a href="https://blog.cryptographyengineering.com/2013/02/04/attack-of-week-tls-timing-oracles/">figure out encryption keys on remote servers by sending well-timed packets</a> to them over the Internet. Meanwhile, the most spectacular isolation failures in recent memory were the <a href="https://meltdownattack.com/">Meltdown and Spectre attacks</a>, which allowed any program on a computer, even a javascript app in a web browser, to read the memory of other programs on the same computer, even across sandboxes or virtual machines.</p>
<p>Every new isolation technology goes through a cycle like the following, from optimism to despair:</p>
<ul>
<li>New idea: we'll finally get it right this time, once and for all!</li>
<li>Initial experiments seem to work.</li>
<li>(Users complain that it's even slower and more tedious than the last thing we tried.)</li>
<li>Early fatal flaws are discovered and fixed.</li>
<li>Widespread deployment.</li>
<li>Ever-more-subtle flaws are successively discovered and fixed.</li>
<li>Eventually, we find flaws that we simply don't know how to patch.</li>
<li>Lose hope that efficient isolation is even possible with this method.</li>
<li>But also we can never retire this isolation method because now too many people are depending on it.</li>
<li>Repeat.</li>
</ul>
<p>For example, at this point security people simply don't believe that any of the following (each one the very best technology available at the time) is totally safe:</p>
<ul>
<li>Process isolation and memory protection on a Unix system.</li>
<li>Privilege separation between OS processes when remote code execution ("RCE" for security people) is allowed.</li>
<li>Filtering syscalls to isolate a process.</li>
<li>Mutually untrusted processes sharing a CPU hyperthread.</li>
<li>Memory isolation between virtual machines on a CPU core.</li>
</ul>
<p>As far as I know, the state of the art, the very best isolation, is something like the Chrome sandbox or <a href="https://github.com/google/gvisor">gVisor</a>. The big browser vendors and cloud providers all use tools like these. The tools remain imperfect, but providers do chase down every new breach as fast as they can, and the rate of new flaws is fairly slow.</p>
<p>Isolation is better than it's ever been before… if you put all your isolation at the virtual machine (VM) level so that your cloud provider can do it for you because nobody else knows how, or updates often enough.</p>
<p>If you trust your cloud provider's VM isolation, you can have hope that all known problems are mitigated; but we have every reason to think more problems will be found.</p>
<p>That's… actually pretty good, all things considered. At least we have <em>something</em> that works.</p>
<h4 id="great-vms-for-everything">Great! VMs for everything!</h4>
<p>Well, hold on. Spinning up an isolated VM for every little module is a pain. And how big is a module?</p>
<p>Long ago, when Java first came out, the dream was that every line of every function in every object could have permissions enforced, even between objects in the same application binary, so that CPU-enforced memory protection wouldn't be needed. Nobody believes anymore that they can make that work. And marketing claims like "cloud functions" aside, nobody really thinks you should try.</p>
<p>None of the currently-known isolation methods work <em>perfectly</em>, but each of them works to <em>some approximation</em>. Increasingly skilled attackers, or increasingly valuable targets, require better and more annoying isolation. The best isolation we know right now is inter-VM sandboxing provided by tier-1 cloud providers. The worst, well, it goes down to zero.</p>
<p>Let's also assume, skipping over the evidence, that most systems are so tightly coupled that <strong>a reasonably skilled attacker can break through laterally between modules.</strong> So, for example, if someone can link a malicious library into your Go or C++ program, they can probably take control of that entire program.</p>
<p>Similarly, if your program has write access to a database, attackers can probably make it write <em>anywhere</em> in the database. If it can contact the network, they can probably contact <em>anywhere</em> in the network. If it can execute arbitrary Unix commands or system calls, they can probably get Unix root access. If it's in a container, they can probably break out of the container and into other containers. If malicious data can <a href="https://imagetragick.com/">crash the png decoder</a>, they can probably make it do anything else the decoder program is allowed to do. And so on.</p>
<p>An especially powerful form of attack is getting the ability to commit code, because that code will eventually be run on developer machines, and some developer or production machine somewhere probably has access to do what you want to do.</p>
<p>The above is maybe a little too pessimistic, but making those assumptions can help avoid overcomplicating your systems without improving actual security. In <a href="http://cr.yp.to/qmail/qmailsec-20071101.pdf">Some thoughts on security after ten years of qmail 1.0</a>, Daniel J. Bernstein points out (if I may heavily paraphrase) that many of the defenses he added in qmail, particularly isolating the different components from each other using chroot and different Unix uids, were not worthwhile and have never paid off.</p>
<p>Anyway, let's take it for granted that attackers with the ability to execute code can "usually" jump …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/modules-monoliths-and-microservices/">https://tailscale.com/blog/modules-monoliths-and-microservices/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/modules-monoliths-and-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26247052</guid>
            <pubDate>Wed, 24 Feb 2021 05:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Year of Rails]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26246487">thread link</a>) | @momonga
<br/>
February 23, 2021 | https://macwright.com/2021/02/18/a-year-of-rails.html | <a href="https://web.archive.org/web/*/https://macwright.com/2021/02/18/a-year-of-rails.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><picture><source srcset="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.webp" type="image/webp"><img alt="Railroad" src="https://macwright.com/images/2021-02-18-a-year-of-rails-railroad.jpg"></picture></p><p>I spent most of 2020 working with <a href="https://rubyonrails.org/">Ruby on Rails</a>. I moved a project from <a href="https://nextjs.org/">Next.js</a> + <a href="https://www.rust-lang.org/">Rust</a> to…&nbsp;Rails, baby! Back to the future. My earlier post on <a href="https://macwright.com/2020/05/10/spa-fatigue.html"><em>Second-guessing the modern web</em></a> was inspired by this experience, that for the product we were building, a ‘modern’ stack was not working as well as a traditional one.</p><p>We didn’t do competitive analysis against Laravel, Django, or Phoenix. They’re similar, not radically better or worse. There are multiple acceptable solutions to a problem, and this was more a matter of choosing the right <em>kind</em> of solution than pursuing some kind of perfect choice and burning hours and motivation doing the window-shopping.</p><p>What helped Rails win was that the team had a little more experience in Ruby (with the exception of myself), and we found plenty of resources for developing and deploying the stack. Rails fit perfectly into the ideology of <a href="http://boringtechnology.club/"><em>Choosing boring technology</em></a>. Another part of the product would be the hard, innovative part, so it made no sense to grapple with bleeding-edge web frameworks.</p><p>This was a really fun experience. There’s a lot to love about Rails. Other communities could learn a bit from the Ruby &amp; Rails culture and wisdom. I won’t implement <em>everything</em> in Rails, but it’ll be part of the toolbox.</p><p>Before this, I hadn’t touched the stuff. And I bet a lot of people are like that - they came of age in the world of React and Go, and haven’t tried anything even remotely similar to Rails. For their benefit, and to debrief from 2020, here are some notes on the experience. Plus, <a href="https://macwright.com/2020/10/28/if-not-spas.html">Rails-like projects in JavaScript</a> are ramping up quickly, and it’s fun to know the origins.</p><h2 id="the-good">The good</h2><h3 id="debugging-rails-apps-is-amazing">Debugging Rails apps is amazing</h3><p>A while ago, I <a href="https://twitter.com/tmcw/status/1321133460501585922">wrote on Twitter</a></p><blockquote><p>the real reason why javascript developers don’t use breakpoints and use console.log is that breakpoints don’t work</p></blockquote><p>After years of working in JavaScript, I’m used to bad debugging experiences. The Chrome debugger’s <a href="https://developers.google.com/web/updates/2015/05/automatically-pause-on-any-exception">automatic pause on caught exceptions</a> is amazing, sometimes. But throwing a <code>debugger</code> statement in some React code is dodgy as hell. Sometimes it works, mostly it doesn’t. You have to deal with code that might not have the right <a href="https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/">sourcemap</a> to translate from bundled &amp; minified code to original source. Subtle abstractions like React hooks and advanced transpiler stuff like <a href="https://github.com/facebook/regenerator">Regenerator</a> mean that your code’s stacktrace probably looks nothing like what you expect, with lots of internal garbage. Sure, you can learn better techniques for diagnosing and debugging errors, but it’s not just you - the debugging story in JavaScript is pretty bad. This applies even to Node.js, where one of the debugging stories is to connect Chrome’s debugger to a Node.js instance:&nbsp;a finicky solution that doesn’t consistently work.</p><p>In Rails, there is <a href="https://github.com/deivid-rodriguez/byebug">byebug</a>. You write <strong><code>byebug</code></strong> in your source code, and you get an interactive REPL right there. It works in views, controllers, database migrations, everywhere. It almost always works. Variables are named what you expect. The whole system is paused at that moment, and you can actually interact with it, using all of the Rails utilities and your installed gems.</p><p>If a page crashes unexpectedly, you get a similar REPL experience, in your browser, automatically. With an automatically cleaned-up stacktrace that excludes Rails’s own frames. Like the byebug interface, this REPL actually works and is consistently helpful in finding root causes. Rarely will you need to use <code>puts</code> to print something to the console because this debugging system is so good.</p><h3 id="the-magic-mostly-works">The magic mostly works</h3><p>Our Rails app didn’t have any <code>require</code> statements. You mention a module’s name, and it’s automatically included, using <a href="https://github.com/fxn/zeitwerk">Zeitwork</a>, a tool that comes standard with Rails.</p><p>This kind of system was terrifying to me before. What if you accidentally import something just by mentioning it? What if two things have the same name and you import the wrong one? How do you really know what’s happening? Sure, you’re happy now, with all of that annoying importing and exporting taken care of, but the sky might fall.</p><p>Or maybe it just… doesn’t. Maybe impure, vaguely risky techniques are just a net positive over time, and making everything fully explicit isn’t really necessary? Now when I’m using other systems, I wonder - what if I could just mention one of my React components and it would just… be there? Sure, the system would have to complain if there were two components with the same name, and it would have to make assumptions about directory structure, but overall, wouldn’t this be nice?</p><p>This applies to a lot of other parts of the system too. Rails is famous for doing pluralization - you name a model <code>Post</code> and you automatically get an interface called <code>posts</code>. But what, you ask, of words with uneven pluralization rules? Rails actually&nbsp;<a href="https://weblog.rubyonrails.org/2005/8/25/10-reasons-rails-does-pluralization/">does the right thing</a>, almost always. And when it fails, you can override it. It actually just saves time, reliably.</p><h3 id="testing-works">Testing works</h3><p>I’ve tried to test front-end applications. I’ve set up <a href="https://nightwatchjs.org/">nightwatch</a>, <a href="https://jestjs.io/">jest</a>, <a href="https://enzymejs.github.io/enzyme/">enzyme</a>, <a href="https://www.cypress.io/">cypress</a>, and probably 5-10 other frameworks. <em>Front-end testing is universally terrible.</em> Projects like Cypress are throwing untold hours into making it less terrible, taking on massive amounts of complexity to abstract away from fickle browser behavior and complex interactions.</p><p>But it still sucks. Frontend testing has no good attributes: it’s unreliable, hard to automate, hard to debug when it fails, and often doesn’t even assert for important behaviors, so it doesn’t actually identify regressions. Running frontend tests in CI is resource-heavy, requiring you to set up headless X windows environments on servers or use specialized CI services that produce screencasts of test runs.</p><p>Testing fully-server-rendered applications, on the other hand, is <em>amazing</em>. A vanilla testing setup with Rails &amp; <a href="https://rspec.info/">RSpec</a> can give you fast, stable, concise, and actually-useful test coverage. You can actually assert for behavior and navigate through an application like a user would. These tests are solving a simpler problem - making requests and parsing responses, without the need for a full browser or headless browser, without multiple kinds of state to track.</p><p>Not only do the tests work better, the testing culture is a completely different universe. There are entire books written about how to write RSpec tests that catch bugs, allow software evolution, and aren’t filled with boilerplate.</p><h3 id="gems-are-so-powerful">Gems are so powerful</h3><p>Powerful and dangerous.</p><p>I’m used to modules as they work in other systems - Python, Node, Elm, and so on. They provide objects, functions, and variables that you can import and combine into your code explicitly. Usually they sit on some specific level of abstraction - it’s a utility for connecting to servers or a React component you can use.</p><p>Gems can do so much more. You install something like <a href="https://github.com/heartcombo/devise">Devise</a> into your system and it adds views, routes, methods, utilities, you name it. It’s not like “loading some functions”, it’s more like composing a whole different app <em>into</em> your app, implicitly.</p><p>This is obviously terrifying. It means that you can’t look at your directories of views and your file of <code>routes.rb</code> and know what exists at a glance. There are other layers, lurking in the ephemeral space of third-party code. They interact in serious but uncertain ways.</p><p>But it’s also pretty incredible - the idea that something like <a href="http://www.passportjs.org/">passport</a>, Node’s middleware, could instead be a full-fledged authentication system. It means that you have to write a lot less code, and it also means that the people who <em>use</em> that code have a lot more code in common. That gems can work on a higher level of abstraction, making it possible to cobble together software faster, to write less ‘glue code.’</p><h3 id="theres-so-much-good-writing-about-rails">There’s so much good writing about Rails</h3><p>Even if you don’t write Ruby, you should pay attention to <a href="https://sandimetz.com/">Sandi Metz</a>. She’s incredibly wise and has so many incredible ideas to share.</p><p>And then there’s <a href="https://blog.arkency.com/">arkency</a>, <a href="https://thoughtbot.com/blog/">ThoughtBot</a>, and so many other thoughtful writers with years of experience in Rails. Sometimes it’s a little shocking to google for some obscure problem and see a decade of discussion about it.</p><p>The best practices are also formalized into tools like <a href="https://codeclimate.com/">Code Climate</a> and <a href="https://github.com/troessner/reek">reek</a>. I’ve never seen so many actually-useful suggestions come out of automated systems as I did in the world of Ruby and Rails.</p><h3 id="ruby">Ruby</h3><p>Ruby is a pretty pleasant language to work in. Sure, it has a lot of syntax and a sprawling standard library, but you don’t have to use all of that if you don’t want to. It took me a while to adjust to the object-oriented way of doing things - in particular, the idea that you can’t just have a free-range function floating out there, unassociated with a class or module, like you can in JavaScript. And you can’t just create an arbitrary one-off object - you either need to define a class to create an object, or use a Hash to store data.</p><p>But Ruby’s standard library isn’t that huge. I’ve seen JavaScript’s ‘standard library’ grow a lot too, and frankly it’s nice to have methods like <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/padStart"><code>String.prototype.padStart</code></a> instead of having every little thing in userspace. The only part that felt actively weird was <a href="https://rubygems.org/gems/activesupport/versions/6.1.1">activesupport</a> - a gem that extends Ruby’s core objects, but is part of Rails. It felt weird to have <em>string</em> methods that would only work if your environment was Rails.</p><p>The <a href="https://kapeli.com/dash">Dash</a> app for documentation rocketed from my pile of unused tools to an absolute must-have. In the world of Ruby and Rails, with <em>most</em> gems having pretty good, semi-standard documentation, you can search for, and get answers, super fast. The Ruby language documentation and the Rails documentation is absolutely great. The JavaScript equivalent - <a href="https://developer.mozilla.org/en-US/">MDN</a> - pales in comparison.</p><h2 id="the-bad">The bad</h2><h3 id="the-asset-pipeline">The asset pipeline</h3><p>Remember SASS and the YUI Compressor? These are, unfortunately, defaults in the <a href="https://guides.rubyonrails.org/asset_pipeline.html">asset pipeline</a>. There’s <a href="https://edgeguides.rubyonrails.org/webpacker.html">Webpacker</a> too, which has a parallel approach to CSS and images as the asset pipeline. It has <a href="https://github.com/rails/webpacker#integrations">opinionated integrations</a> with stuff like React. Ah, and I should mention that Rails’s <a href="https://github.com/rails/rails/tree/main/actionview/app/assets/javascripts">JavaScript utilities are written in… CoffeeScript</a>.</p><p>I get it - it’s hard to keep up with the latest trends in frontend. But this is one …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2021/02/18/a-year-of-rails.html">https://macwright.com/2021/02/18/a-year-of-rails.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2021/02/18/a-year-of-rails.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246487</guid>
            <pubDate>Wed, 24 Feb 2021 04:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nx (Numerical Elixir) is now publicly available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26246484">thread link</a>) | @lobo_tuerto
<br/>
February 23, 2021 | https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> February 18th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/nx">nx</a>, <a href="https://dashbit.co/blog/tags/defn">defn</a>
  </li>
</ul>
<p><img src="https://dashbit.co/images/posts/2021/nx.png" alt="Nx" width="400"></p>
<p>
Sean Moriarity and I are glad to announce that the project we have been working on for the last 3 months, Nx, is finally <a href="https://github.com/elixir-nx/nx">publicly available on GitHub</a>. Our goal with Nx is to provide the foundation for Numerical Elixir.</p>
<p>
In this blog post, I am going to outline the work we have done so far, some of the design decisions, and what we are planning to explore next. If you are looking for other resources to learn about Nx, you can <a href="https://thinkingelixir.com/podcast-episodes/034-jose-valim-reveals-project-nx/">hear me unveiling Nx on the ThinkingElixir podcast</a>.</p>
<h2>
  Nx</h2>
<p>
Nx is a multi-dimensional tensors library for Elixir with multi-staged compilation to the CPU/GPU. Let’s see an example:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4885761117-1">(</span><span data-group-id="4885761117-2">[</span><span data-group-id="4885761117-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-3">]</span><span>,</span><span> </span><span data-group-id="4885761117-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-4">]</span><span data-group-id="4885761117-2">]</span><span data-group-id="4885761117-1">)</span><span>
</span><span data-group-id="4885761117-5">#</span><span data-group-id="4885761117-5">Nx.Tensor</span><span data-group-id="4885761117-5">&lt;</span><span>
  </span><span>s64</span><span data-group-id="4885761117-6">[</span><span>2</span><span data-group-id="4885761117-6">]</span><span data-group-id="4885761117-7">[</span><span>2</span><span data-group-id="4885761117-7">]</span><span>
  </span><span data-group-id="4885761117-8">[</span><span>
    </span><span data-group-id="4885761117-9">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4885761117-9">]</span><span>,</span><span>
    </span><span data-group-id="4885761117-10">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4885761117-10">]</span><span>
  </span><span data-group-id="4885761117-8">]</span><span>
</span><span data-group-id="4885761117-5">&gt;</span></code></pre>
<p>
As you see, tensors have a type (s64) and a shape (2x2). Tensor operations are also done with the <code>Nx</code> module. To implement <a href="https://en.wikipedia.org/wiki/Softmax_function">the Softmax function</a>:</p>
<pre><code><span>iex&gt; </span><span>t</span><span> </span><span>=</span><span> </span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="2015320651-1">(</span><span data-group-id="2015320651-2">[</span><span data-group-id="2015320651-3">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="2015320651-3">]</span><span>,</span><span> </span><span data-group-id="2015320651-4">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="2015320651-4">]</span><span data-group-id="2015320651-2">]</span><span data-group-id="2015320651-1">)</span><span>
</span><span>iex&gt; </span><span>Nx</span><span>.</span><span>divide</span><span data-group-id="2015320651-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-6">(</span><span>t</span><span data-group-id="2015320651-6">)</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="2015320651-7">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="2015320651-8">(</span><span>t</span><span data-group-id="2015320651-8">)</span><span data-group-id="2015320651-7">)</span><span data-group-id="2015320651-5">)</span><span>
</span><span data-group-id="2015320651-9">#</span><span data-group-id="2015320651-9">Nx.Tensor</span><span data-group-id="2015320651-9">&lt;</span><span>
  </span><span>f64</span><span data-group-id="2015320651-10">[</span><span>2</span><span data-group-id="2015320651-10">]</span><span data-group-id="2015320651-11">[</span><span>2</span><span data-group-id="2015320651-11">]</span><span>
  </span><span data-group-id="2015320651-12">[</span><span>
    </span><span data-group-id="2015320651-13">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="2015320651-13">]</span><span>,</span><span>
    </span><span data-group-id="2015320651-14">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="2015320651-14">]</span><span>
  </span><span data-group-id="2015320651-12">]</span><span>
</span><span data-group-id="2015320651-9">&gt;</span></code></pre>
<p>
The high-level features in Nx are:</p>
<ul>
  <li>
    <p>
Typed multi-dimensional tensors, where the tensors can be unsigned integers (<code>u8</code>, <code>u16</code>, <code>u32</code>, <code>u64</code>), signed integers (<code>s8</code>, <code>s16</code>, <code>s32</code>, <code>s64</code>), floats (<code>f32</code>, <code>f64</code>) and brain floats (<code>bf16</code>);    </p>
  </li>
  <li>
    <p>
<a href="http://nlp.seas.harvard.edu/NamedTensor">Named tensors</a>, allowing developers to give names to each dimension, leading to more readable and less error prone codebases;    </p>
  </li>
  <li>
    <p>
Automatic differentiation, also known as autograd. The <code>grad</code> function provides reverse-mode differentiation, useful for simulations, training probabilistic models, etc;    </p>
  </li>
  <li>
    <p>
Tensors backends, which enables the main <code>Nx</code> API to be used to manipulate binary tensors, GPU-backed tensors, sparse matrices, and more;    </p>
  </li>
  <li>
    <p>
Numerical definitions, known as <code>defn</code>, provide multi-stage compilation of tensor operations to multiple targets, such as highly specialized CPU code or the GPU. The compilation can happen either ahead-of-time (AOT) or just-in-time (JIT) with a compiler of your choice;    </p>
  </li>
</ul>
<p>
For Python developers, <code>Nx</code> currently takes its main inspirations from <a href="https://numpy.org/"><code>Numpy</code></a> and <a href="https://github.com/google/jax"><code>JAX</code></a> but packaged into a single unified library.</p>
<p>
Our initial efforts have focused on the underlying abstractions. For example, while Nx implements dense tensors out-of-the-box, we also want the same high-level API to be valid for sparse tensors. You should also be able to use all functions in the <code>Nx</code> module with tensors that are backed by Elixir binaries and with tensors that are stored directly in the GPU.</p>
<p>
By ensuring the underlying tensor backend is ultimately replaceable, we can build an ecosystem of libraries on top of Nx, and allow end-users to experiment with different backends, hardware, and approaches to run their software on.</p>
<p>
<em>Nx’s mascot is the Numbat, a marsupial native to southern Australia. Unfortunately the Numbat are endangered and it is estimated to be fewer than 1000 left. If you are excited about Nx, consider donating to Numbat conservation efforts, such as <a href="https://www.numbat.org.au/">Project Numbat</a> and <a href="https://www.australianwildlife.org/">Australian Wildlife Conservancy</a>.</em></p>
<h2>
Numerical definitions</h2>
<p>
One of the most important features in <code>Nx</code> is the numerical definition, called <code>defn</code>. Numerical definitions are a subset of Elixir tailored for numerical computing. Here is the <code>softmax</code> formula above, now written with <code>defn</code>:</p>
<pre><code><span>defmodule</span><span> </span><span>Formula</span><span> </span><span data-group-id="4810618200-1">do</span><span>
  </span><span>import</span><span> </span><span>Nx.Defn</span><span>

  </span><span>defn</span><span> </span><span>softmax</span><span data-group-id="4810618200-2">(</span><span>t</span><span data-group-id="4810618200-2">)</span><span> </span><span data-group-id="4810618200-3">do</span><span>
    </span><span>inspect_expr</span><span data-group-id="4810618200-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-5">(</span><span>t</span><span data-group-id="4810618200-5">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="4810618200-6">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="4810618200-7">(</span><span>t</span><span data-group-id="4810618200-7">)</span><span data-group-id="4810618200-6">)</span><span data-group-id="4810618200-4">)</span><span>
  </span><span data-group-id="4810618200-3">end</span><span>
</span><span data-group-id="4810618200-1">end</span></code></pre>
<p>
The first difference we see with <code>defn</code> is that Elixir’s built-in operators have been augmented to also work with tensors. Effectively, <code>defn</code> replaces Elixir’s <code>Kernel</code> with <code>Nx.Defn.Kernel</code>.</p>
<p>
However, <code>defn</code> goes even further. When using <code>defn</code>, <code>Nx</code> builds a computation with all of your tensor operations. Let’s inspect it:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="0860724160-1">(</span><span>t</span><span data-group-id="0860724160-1">)</span><span> </span><span data-group-id="0860724160-2">do</span><span>
  </span><span>inspect_expr</span><span data-group-id="0860724160-3">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-4">(</span><span>t</span><span data-group-id="0860724160-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="0860724160-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="0860724160-6">(</span><span>t</span><span data-group-id="0860724160-6">)</span><span data-group-id="0860724160-5">)</span><span data-group-id="0860724160-3">)</span><span>
</span><span data-group-id="0860724160-2">end</span></code></pre>
<p>
Now when invoked, you will see this printed:</p>
<pre><code><span>iex(3)&gt; </span><span>Formula</span><span>.</span><span>softmax</span><span data-group-id="4848142189-1">(</span><span>Nx</span><span>.</span><span>tensor</span><span data-group-id="4848142189-2">(</span><span data-group-id="4848142189-3">[</span><span data-group-id="4848142189-4">[</span><span>1</span><span>,</span><span> </span><span>2</span><span data-group-id="4848142189-4">]</span><span>,</span><span> </span><span data-group-id="4848142189-5">[</span><span>3</span><span>,</span><span> </span><span>4</span><span data-group-id="4848142189-5">]</span><span data-group-id="4848142189-3">]</span><span data-group-id="4848142189-2">)</span><span data-group-id="4848142189-1">)</span><span>
</span><span data-group-id="4848142189-6">#</span><span data-group-id="4848142189-6">Nx.Tensor</span><span data-group-id="4848142189-6">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-7">[</span><span>2</span><span data-group-id="4848142189-7">]</span><span data-group-id="4848142189-8">[</span><span>2</span><span data-group-id="4848142189-8">]</span><span>
  
  </span><span>Nx.Defn.Expr</span><span>
  </span><span>parameter</span><span> </span><span>a</span><span>                                 </span><span>s64</span><span data-group-id="4848142189-9">[</span><span>2</span><span data-group-id="4848142189-9">]</span><span data-group-id="4848142189-10">[</span><span>2</span><span data-group-id="4848142189-10">]</span><span>
  </span><span>b</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-11">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-11">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-12">[</span><span>2</span><span data-group-id="4848142189-12">]</span><span data-group-id="4848142189-13">[</span><span>2</span><span data-group-id="4848142189-13">]</span><span>
  </span><span>c</span><span> </span><span>=</span><span> </span><span>exp</span><span> </span><span data-group-id="4848142189-14">[</span><span> </span><span>a</span><span> </span><span data-group-id="4848142189-14">]</span><span>                               </span><span>f64</span><span data-group-id="4848142189-15">[</span><span>2</span><span data-group-id="4848142189-15">]</span><span data-group-id="4848142189-16">[</span><span>2</span><span data-group-id="4848142189-16">]</span><span>
  </span><span>d</span><span> </span><span>=</span><span> </span><span>sum</span><span> </span><span data-group-id="4848142189-17">[</span><span> </span><span>c</span><span>,</span><span> </span><span>axes</span><span>:</span><span> </span><span>nil</span><span>,</span><span> </span><span>keep_axes</span><span>:</span><span> </span><span>false</span><span> </span><span data-group-id="4848142189-17">]</span><span>  </span><span>f64</span><span>
  </span><span>e</span><span> </span><span>=</span><span> </span><span>divide</span><span> </span><span data-group-id="4848142189-18">[</span><span> </span><span>b</span><span>,</span><span> </span><span>d</span><span> </span><span data-group-id="4848142189-18">]</span><span>                         </span><span>f64</span><span data-group-id="4848142189-19">[</span><span>2</span><span data-group-id="4848142189-19">]</span><span data-group-id="4848142189-20">[</span><span>2</span><span data-group-id="4848142189-20">]</span><span>
</span><span data-group-id="4848142189-6">&gt;</span><span>
</span><span data-group-id="4848142189-21">#</span><span data-group-id="4848142189-21">Nx.Tensor</span><span data-group-id="4848142189-21">&lt;</span><span>
  </span><span>f64</span><span data-group-id="4848142189-22">[</span><span>2</span><span data-group-id="4848142189-22">]</span><span data-group-id="4848142189-23">[</span><span>2</span><span data-group-id="4848142189-23">]</span><span>
  </span><span data-group-id="4848142189-24">[</span><span>
    </span><span data-group-id="4848142189-25">[</span><span>0.03205860328008499</span><span>,</span><span> </span><span>0.08714431874203257</span><span data-group-id="4848142189-25">]</span><span>,</span><span>
    </span><span data-group-id="4848142189-26">[</span><span>0.23688281808991013</span><span>,</span><span> </span><span>0.6439142598879722</span><span data-group-id="4848142189-26">]</span><span>
  </span><span data-group-id="4848142189-24">]</span><span>
</span><span data-group-id="4848142189-21">&gt;</span></code></pre>
<p>
This computation graph can also be transformed programatically. The transformation is precisely how we implement automatic differentiation, also known as <code>autograd</code>, by traversing each node and computing their derivative:</p>
<pre><code><span>defn</span><span> </span><span>grad_softmax</span><span data-group-id="5969204985-1">(</span><span>t</span><span data-group-id="5969204985-1">)</span><span> </span><span data-group-id="5969204985-2">do</span><span>
  </span><span>grad</span><span data-group-id="5969204985-3">(</span><span>t</span><span>,</span><span> </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-4">(</span><span>t</span><span data-group-id="5969204985-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5969204985-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5969204985-6">(</span><span>t</span><span data-group-id="5969204985-6">)</span><span data-group-id="5969204985-5">)</span><span data-group-id="5969204985-3">)</span><span>
</span><span data-group-id="5969204985-2">end</span></code></pre>
<p>
Finally, this computation graph can also be handed out to different compilers. As an example, we have implemented bindings for <a href="https://www.tensorflow.org/xla/">Google’s XLA</a> compiler, called EXLA. We can ask the <code>softmax</code> function to use this new compiler with a module attribute:</p>
<pre><code><span>@defn_compiler</span><span> </span><span data-group-id="5313365207-1">{</span><span>EXLA</span><span>,</span><span> </span><span>client</span><span>:</span><span> </span><span>:host</span><span data-group-id="5313365207-1">}</span><span>
</span><span>defn</span><span> </span><span>softmax</span><span data-group-id="5313365207-2">(</span><span>t</span><span data-group-id="5313365207-2">)</span><span> </span><span data-group-id="5313365207-3">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-4">(</span><span>t</span><span data-group-id="5313365207-4">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5313365207-5">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5313365207-6">(</span><span>t</span><span data-group-id="5313365207-6">)</span><span data-group-id="5313365207-5">)</span><span>
</span><span data-group-id="5313365207-3">end</span></code></pre>
<p>
Once <code>softmax</code> is called, <code>Nx.Defn</code> will invoke <code>EXLA</code> to emit a just-in-time and highly-specialized compiled version of the code, tailored to the tensor type and shape. By passing <code>client: :cuda</code> or <code>client: :rocm</code>, the code can be compiled for the GPU. For reference, here are some benchmarks of the function above when called with a tensor of one million random float values on different clients:</p>
<pre><code>Name                       ips        average  deviation         median         99th %
xla gpu f32 keep      15308.14      0.0653 ms    ±29.01%      0.0638 ms      0.0758 ms
xla gpu f64 keep       4550.59        0.22 ms     ±7.54%        0.22 ms        0.33 ms
xla cpu f32             434.21        2.30 ms     ±7.04%        2.26 ms        2.69 ms
xla gpu f32             398.45        2.51 ms     ±2.28%        2.50 ms        2.69 ms
xla gpu f64             190.27        5.26 ms     ±2.16%        5.23 ms        5.56 ms
xla cpu f64             168.25        5.94 ms     ±5.64%        5.88 ms        7.35 ms
elixir f32                3.22      311.01 ms     ±1.88%      309.69 ms      340.27 ms
elixir f64                3.11      321.70 ms     ±1.44%      322.10 ms      328.98 ms

Comparison:
xla gpu f32 keep      15308.14
xla gpu f64 keep       4550.59 - 3.36x slower +0.154 ms
xla cpu f32             434.21 - 35.26x slower +2.24 ms
xla gpu f32             398.45 - 38.42x slower +2.44 ms
xla gpu f64             190.27 - 80.46x slower +5.19 ms
xla cpu f64             168.25 - 90.98x slower +5.88 ms
elixir f32                3.22 - 4760.93x slower +310.94 ms
elixir f64                3.11 - 4924.56x slower +321.63 ms</code></pre>
<p>
Where <code>keep</code> indicates the tensor was kept on the device instead of being transferred back to Elixir. You can see the benchmark in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/bench"><code>bench</code></a> directory and find some examples in the <a href="https://github.com/elixir-nx/nx/tree/main/exla/examples"><code>examples</code></a> directory of the EXLA project.</p>
<h3>
Compiling numerical definitions</h3>
<p>
Before moving forward, it is important for us to take a look at how numerical definitions are compiled. For example, take the <code>softmax</code> function:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="5791259392-1">(</span><span>t</span><span data-group-id="5791259392-1">)</span><span> </span><span data-group-id="5791259392-2">do</span><span>
  </span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-3">(</span><span>t</span><span data-group-id="5791259392-3">)</span><span> </span><span>/</span><span> </span><span>Nx</span><span>.</span><span>sum</span><span data-group-id="5791259392-4">(</span><span>Nx</span><span>.</span><span>exp</span><span data-group-id="5791259392-5">(</span><span>t</span><span data-group-id="5791259392-5">)</span><span data-group-id="5791259392-4">)</span><span>
</span><span data-group-id="5791259392-2">end</span></code></pre>
<p>
One might think that Elixir takes the AST of the softmax function above and compiles it directly to the GPU. However, that’s not the case! Numerical definitions are first compiled to Elixir code that will emit the computation graph and this computation graph is then compiled to the GPU. The multiple stages go like this:</p>
<pre><code>Elixir AST
-&gt; compiles to .beam (Erlang VM bytecode)
   -&gt; executes into defn AST
      -&gt; compiles to GPU</code></pre>
<p>
This multi-stage programming is made possible thanks to Elixir macros. For example, when you see a conditional inside <code>defn</code>, that conditional looks exactly like Elixir conditionals, but it will be compiled to an accelerator:</p>
<pre><code><span>defn</span><span> </span><span>softmax</span><span data-group-id="8102420814-1">(</span><span>t</span><span data-group-id="8102420814-1">)</span><span> </span><span data-group-id="8102420814-2">do</span><span>
  </span><span>if</span><span> </span><span>Nx</span><span>.</span><span>any?</span><span data-group-id="8102420814-3">(</span><span>t</span><span data-group-id="8102420814-3">)</span><span> </span><span data-group-id="8102420814-4">do</span><span>
    </span><span>-</span><span>1</span><span>
  </span><span data-group-id="8102420814-4">else</span><span>
    </span><span>1</span><span>
  </span><span data-group-id="8102420814-4">end</span><span>
</span><span data-group-id="8102420814-2">end</span></code></pre>
<p>
In a nutshell, <code>defn</code> provides us with a subset of Elixir for numerical computations that can be compiled to specific hardware, such as CPU, GPU, and other accelerators. All of this was possible without making changes or forking the language.</p>
<p>
And while <code>defn</code> is a subset of the language, it is a considerable one. You will find support for:</p>
<ul>
  <li>
Mathematical operators  </li>
  <li>
Pipes (<code>|&gt;</code>), module attributes, the access syntax (i.e. <code>tensor[1][1..-1]</code>), etc  </li>
  <li>
Elixir macros constructs (imports, aliases, etc)  </li>
  <li>
Control-flow with conditionals (both <code>if</code> and <code>cond</code>), loops (coming soon), etc  </li>
  <li>
Transformations, an explicit mechanism to invoke Elixir code from a <code>defn</code> (which enables constructs such as <code>grad</code>)  </li>
</ul>
<p>
And more coming down the road.</p>
<h2>
Why functional programming?</h2>
<p>
At this point, you may be wondering: is functional programming a good fit for numerical computing? One of the main concerns is that immutability can be expensive when working with large blobs of memory. And that’s a valid concern! In fact, when using the default tensor backend, tensors will be backed by Elixir binaries which are copied on every operation. That’s why it was critical for us to design <code>Nx</code> with pluggable backends from day one.</p>
<p>
However, as we move to higher-level abstractions, such as numerical definitions, we will start to reap the benefits of functional programming.</p>
<p>
For example, in order to build computation graphs, immutability becomes an indispensable tool both in terms of implementation and in terms of reasoning. The JAX library for Python, which has been one of the guiding lights for Nx design, also promotes functional and immutable principles:</p>
<blockquote>
  <p>
<em>JAX is intended to be used with a functional style of programming</em>  </p>
  <p>
— <a href="https://jax.readthedocs.io/en/latest/jax.ops.html?highlight=functional#indexed-update-operators">JAX Docs</a>  </p>
</blockquote>
<blockquote>
  <p>
<em>Unlike NumPy arrays, JAX arrays are always immutable</em>  </p>
  <p>
— <a href="https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html?highlight=immutable#JAX-vs.-NumPy">JAX Docs</a>  </p>
</blockquote>
<p>
Similarly, frameworks like <a href="https://thinc.ai/">Thinc.ai</a> argue that functional programming can provide better abstractions and more composable building blocks for deep learning libraries.</p>
<p>
We hope that, by exploring these ideas in a language that is functional by design, Elixir can bring new ideas and insights at the higher-level.</p>
<h2>
What is next?</h2>
<p>
There is a lot of work ahead of us …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available">https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/nx-numerical-elixir-is-now-publicly-available</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246484</guid>
            <pubDate>Wed, 24 Feb 2021 04:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[USPS Selects Oshkosh Defense for Next Generation Delivery Vehicle Fleet]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 44 (<a href="https://news.ycombinator.com/item?id=26246116">thread link</a>) | @jonbaer
<br/>
February 23, 2021 | https://oshkoshcorp.com/en/news/2-23-21-usps | <a href="https://web.archive.org/web/*/https://oshkoshcorp.com/en/news/2-23-21-usps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h3>USPS selects Oshkosh Defense for Next Generation Delivery Vehicle fleet</h3>
        <p><span>2/23/2021</span></p>

<p><span><strong><span>OSHKOSH, Wis. (February 23, 2021)</span></strong>&nbsp;—&nbsp;The U.S. Postal Service (USPS) announced today that it has awarded Oshkosh Defense, a wholly owned subsidiary of Oshkosh Corporation (NYSE: OSK),</span><span> an indefinite delivery, indefinite quantity (IDIQ) contract to produce the Next Generation Delivery Vehicle (NGDV), the USPS’s first large-scale fleet procurement in three decades. The competitively awarded contract allows for the delivery of between 50,000 and 165,000 vehicles over a period of 10 years.</span></p>
<p><span>“Oshkosh operates with unparalleled commitment to those who depend on our products and services to build, protect and serve communities around the world. We are honored to have been selected by the USPS to support their important work by manufacturing American-made Next Generation Delivery Vehicles that will connect every home and business across the United States for decades to come,” said John Pfeifer, President &amp; Chief Operating Officer, Oshkosh Corporation.</span></p>
<p><span>Oshkosh Defense will manufacture <span>both zero emission battery electric vehicles (BEV) and fuel-efficient low-emission internal combustion engine vehicles (ICE), </span>upgrading the USPS fleet to be increasingly sustainable. Under the contract announced today, the USPS has committed to pay Oshkosh Defense $482 million to initiate engineering efforts to finalize the production vehicle design, and for tooling and factory build-out activities that are necessary prior to vehicle production.</span></p>
<p><span>“Our century-long history of delivering products to customers, operating in some of the most demanding and severe conditions on the planet, uniquely positions us to bring exceptional reliability, safety, and maintainability to USPS’s Next Generation Delivery Vehicles,” said John Bryant, Executive Vice President, Oshkosh Corporation, and President, Oshkosh Defense. </span></p>
<p><span>“Partnering with trusted suppliers, we have developed a purpose-built solution to support the current and future needs of the USPS,” Bryant concluded. Production of the next generation delivery vehicle is expected to begin in 2023.</span></p>

<p><strong><span>About Oshkosh Defense</span></strong></p>
<p><span>Oshkosh Defense is a global leader in the design, production and sustainment of best-in-class military vehicles and mobility systems. As a pioneer of combat-ready vehicle solutions, Oshkosh develops and applies emerging technologies that advance troop safety and mission success. Setting the industry standard for sustaining fleet readiness, Oshkosh ensures every solution is supported worldwide throughout its entire life cycle.</span></p>
<p><span>Oshkosh Defense, LLC is an Oshkosh Corporation company [NYSE: OSK].</span></p>
<p><span>Learn more about Oshkosh Defense at </span><a href="https://urldefense.com/v3/__http:/www.oshkoshdefense.com/__;!!N96JrnIq8IfO5w!0oPVjCe_9XKiyt970eFZ2ETGHbOUaHqUzI1RM4BZtfkq8yBh8DIO8xn4LAG9LmLn1gg$"><span>oshkoshdefense.com</span></a><span>.&nbsp; </span></p>

<p><strong><span>About Oshkosh Corporation</span></strong></p>
<p><span>At Oshkosh (NYSE: OSK), we make innovative, mission-critical equipment to help everyday heroes advance communities around the world. Headquartered in Wisconsin, Oshkosh Corporation employs more than 14,000 team members worldwide, all united behind a common cause: to make a difference in people’s lives. Oshkosh products can be found in more than 150 countries under the brands of JLG®, Pierce®, Oshkosh® Defense, McNeilus®, IMT®, Frontline™, Jerr-Dan®, Oshkosh® Airport Products, Pratt Miller, and London™. For more information, visit </span><a href="https://urldefense.com/v3/__http:/oshkoshcorp.com__;!!N96JrnIq8IfO5w!0oPVjCe_9XKiyt970eFZ2ETGHbOUaHqUzI1RM4BZtfkq8yBh8DIO8xn4LAG9WR_C6yk$"><span>oshkoshcorp.com</span></a><span>.</span></p>
<p><sup><span>®</span></sup><span>, ™ All brand names referred to in this news release are trademarks of Oshkosh Corporation or its subsidiary companies.</span></p>



<p><span><strong><span>Forward Looking Statements</span></strong></span></p>
<p><span>This news release contains statements that the Company believes to be “forward-looking statements” within the meaning of the Private Securities Litigation Reform Act of 1995. All statements other than statements of historical fact, including, without limitation, statements regarding the Company’s future financial position, business strategy, targets, projected sales, costs, earnings, capital expenditures, debt levels and cash flows, and plans and objectives of management for future operations, are forward-looking statements. When used in this news release, words such as “may,” “will,” “expect,” “intend,” “estimate,” “anticipate,” “believe,” “should,” “project” or “plan” or the negative thereof or variations thereon or similar terminology are generally intended to identify forward-looking statements. These forward-looking statements are not guarantees of future performance and are subject to risks, uncertainties, assumptions and other factors, some of which are beyond the Company’s control, which could cause actual results to differ materially from those expressed or implied by such forward-looking statements. These factors include the overall impact of the COVID-19 pandemic on the Company’s business, results of operations and financial condition; the duration and severity of the COVID-19 pandemic; actions that may be taken by governmental authorities and others to address or otherwise mitigate the impact of the COVID-19 pandemic; the negative impacts of the COVID-19 pandemic on global economies and the Company’s customers, suppliers and employees; the cyclical nature of the Company’s access equipment, commercial and fire &amp; emergency markets, which are particularly impacted by the strength of U.S. and European economies and construction seasons; the Company’s ability to increase prices or impose surcharges to raise margins or to offset higher input costs, including increased commodity, raw material, labor and freight costs; the Company’s estimates of access equipment demand which, among other factors, is influenced by customer historical buying patterns and rental company fleet replacement strategies; the strength of the U.S. dollar and its impact on Company exports, </span><span>translation of foreign sales and the cost of purchased materials; the expected level and timing of U.S. Department of Defense (DoD) and international defense customer procurement of products and services and acceptance of and funding or payments for such products and services; the Company’s ability to predict the level and timing of orders for indefinite delivery/indefinite quantity contracts with the U.S. federal government; risks related to reductions in government expenditures in light of U.S. defense budget pressures and an uncertain DoD tactical wheeled vehicle strategy; the impact of any DoD solicitation for competition for future contracts to produce military vehicles; potential impacts of budget constraints facing the USPS and continuously changing demands for postal services; risks related to facilities expansion, consolidation and alignment, including the amounts of related costs and charges and that anticipated cost savings may not be achieved; projected adoption rates of work at height machinery in emerging markets; the impact of severe weather, natural disasters or pandemics that may affect the Company, its suppliers or its customers; performance issues with suppliers or subcontractors; risks related to the collectability of receivables, particularly for those businesses with exposure to construction markets; the cost of any warranty campaigns related to the Company’s products; risks associated with international operations and sales, including compliance with the Foreign Corrupt Practices Act; risks that a trade war and related tariffs could reduce the competitiveness of the Company’s products; the Company’s ability to comply with complex laws and regulations applicable to U.S. government contractors; cybersecurity risks and costs of defending against, mitigating and responding to data security threats and breaches; the Company’s ability to successfully identify, complete and integrate acquisitions and to realize the anticipated benefits associated with the same; and risks related to the Company’s ability to successfully execute on its strategic road map and meet its long-term financial goals. Additional information concerning these and other factors is contained in the Company’s filings with the Securities and Exchange Commission. All forward-looking statements speak only as of the date of this news release. The Company assumes no obligation, and disclaims any obligation, to update information contained in this news release. Investors should be aware that the Company may not update such information until the Company’s next quarterly earnings conference call, if at all.</span></p>

<p><span>For more information, contact:</span></p>
<p><span><br>
Financial:<br>
Patrick Davidson<br>
Senior Vice President, Investor Relations<br>
920.502.3266</span></p>
<p><span>Media:<br>
Bryan Brandt<br>
Senior Vice President, Chief Marketing Officer<br>
920.502.3670</span></p>
<p><span>Alexandra Hittle<br>
Director, Global Marketing and Communications<br>
920.410.1929</span></p>
<p><span><br>
Source: Oshkosh Corporation</span></p>
    </div></div>]]>
            </description>
            <link>https://oshkoshcorp.com/en/news/2-23-21-usps</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246116</guid>
            <pubDate>Wed, 24 Feb 2021 02:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Games on Your Own as an Engineer]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 19 (<a href="https://news.ycombinator.com/item?id=26246049">thread link</a>) | @Eyas
<br/>
February 23, 2021 | https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/ | <a href="https://web.archive.org/web/*/https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the <strong><a href="https://blog.eyas.sh/tag/unity-for-software-engineers">Unity for Software Engineers</a></strong>
series, I give an accelerated introduction to game development in Unity.
<a href="http://eepurl.com/gVgusL">Subscribers</a> have been following this series over the
past few months, often suggesting areas to cover or elaborate on. A few months
ago, a reader<!-- -->—<!-- -->also a software engineer<!-- -->—<!-- -->reached out to me (lightly
edited, emphasis mine):</p><blockquote><p><strong>The biggest unknown for me is: How do I start?</strong> What does the process of
creating a game look like? Should I build the scenes first? Should I design
the gameplay mechanics first? With business software, it’s much more familiar.
It’s easy to think, “Well, okay, I need to write the DAO or controller, etc.”
But with games, I’m lost.</p></blockquote><p>While there is no single correct answer, we can still make some distinctions
that can help get us oriented. The answer will also undoubtedly depend on <em>who</em>
is doing the development: an individual, small indie team, or larger studio? If
an individual, the answer will also depend on their primary skillset: a
developer, artist, or designer?</p><p>Here, I’ll give heuristics especially helpful for individual Software Engineers
building a game on their own as a side project, hobby, or proof-of-concept.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56037/irfan-simsar-wxWulfjN-G0-unsplash.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/28a80/irfan-simsar-wxWulfjN-G0-unsplash.webp 400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/8d2ea/irfan-simsar-wxWulfjN-G0-unsplash.webp 800w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/43d96/irfan-simsar-wxWulfjN-G0-unsplash.webp 1600w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/4293a/irfan-simsar-wxWulfjN-G0-unsplash.webp 2400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/dc28f/irfan-simsar-wxWulfjN-G0-unsplash.webp 2448w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/4cda9/irfan-simsar-wxWulfjN-G0-unsplash.jpg 400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/c60e9/irfan-simsar-wxWulfjN-G0-unsplash.jpg 800w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56dca/irfan-simsar-wxWulfjN-G0-unsplash.jpg 1600w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/111a0/irfan-simsar-wxWulfjN-G0-unsplash.jpg 2400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56037/irfan-simsar-wxWulfjN-G0-unsplash.jpg 2448w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/jpeg">
          <img src="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56dca/irfan-simsar-wxWulfjN-G0-unsplash.jpg" alt="Scrum board, at an office" title="Scrum board, at an office" loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>Photo by İrfan Simsar, <a href="https://unsplash.com/photos/wxWulfjN-G0">via unsplash</a>.</p></figcaption></figure><h2>Questions you should ask yourself</h2><p>Before we start, here are some questions you should ask yourself.</p><h3>Do you know <em>what</em> you’re building?</h3><p>Do you know what your game is about? Do you have a sense of what game mechanics
your game will have? Do you know what genre, controls, and themes this game will
have?</p><p>If <em>yes</em>, you’re ready to decide <strong><a href="#start-coding">where to start coding</a></strong>.
Otherwise, you have a few more questions to ask yourself.</p><h3>Do you <em>want</em> to know what you’re building?</h3><p>It’s totally fine not to have a project in mind! Maybe you’re prototyping.
Perhaps you’re throwing a bunch of mini-games on the wall and seeing what
sticks. Or you’re looking for inspiration and trying to implement random
mechanics to see what feels fun.</p><p><strong>If you’re hoping to begin working on a specific, cohesive game</strong>, you will
likely want to know what you’re building. Consider brainstorming and sketching
out an informal
<a href="https://en.wikipedia.org/wiki/Game_design_document">game design document</a>.
There are
<a href="https://www.google.com/search?q=game+design+document+template">plenty of templates</a>
of various levels of detail you could decide to use. Especially as a software
engineer toying with abstract ideas in my brain, I’ll start with a super
high-level GDD, covering the feel, themes, genre, and mechanics of the game I
have in mind. Maybe a few pictures or sketches for inspiration, and that’s it.
The key part of this exercise will be the list of mechanics I’m working on.</p><p><strong>If you want to prototype and experiment</strong>, you should already have a vague
sense of 1-2 mechanics that could be fun: Maybe unusual movement or a different
control scheme. It could be a traditional mechanic that you’re wondering how to
implement. For instance, I might decide to build a 3rd Person character and
camera controller to see the “feel” of it, experiment with it a tiny bit, and do
something smooth and polish that I feel good about. I might end up keeping that
code in my back pocket for later, or I might use play-through sessions with that
controller to move around a scene, add a few assets, and use that as a starting
place to see the “feel” various mechanics and designs.</p><h2 id="start-coding">I know the mechanics I care about. Now what?</h2><figure><p><span>
      <a href="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/28a80/iterative-development.webp 400w,https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/dfbce/iterative-development.webp 499w" sizes="(max-width: 499px) 100vw, 499px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/4cda9/iterative-development.jpg 400w,https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg 499w" sizes="(max-width: 499px) 100vw, 499px" type="image/jpeg">
          <img src="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg" alt="Spiral graph showing a representation of iterative development, between three axes: Plan, Build, and Test." title="Spiral graph showing a representation of iterative development, between three axes: Plan, Build, and Test." loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>By Dave Gray, <a href="https://www.flickr.com/photos/davegray/6865783267">via Flickr</a>.
<a href="https://creativecommons.org/licenses/by-nd/2.0/">CC BY-ND 2.0</a>.</p></figcaption></figure><p>The goal of many iterative software development models is to de-risk software
development. You do that by failing fast and getting feedback early. In game
development, the primary metric for success is a feeling: the game should be
fun. So, when deciding what to start with when working on a game, one good
question to ask is: <em>“How can I see if this game is fun as soon as possible?”</em>
or <em>“How can I implement the ‘fun’ part of the game ASAP?”</em></p><p>One way to do that is to look at a game’s mechanics and implement them in some
order. The advice that resonates with me is implementing game mechanics in order
of what the most <em>“core”</em> mechanic first.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/28a80/scrolling-shooter-example.webp 400w,https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/8d2ea/scrolling-shooter-example.webp 800w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a3397/scrolling-shooter-example.png 400w,https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png 800w" sizes="(max-width: 800px) 100vw, 800px" type="image/png">
          <img src="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png" alt="Example of a space scrolling shooter game" title="Example of a space scrolling shooter game" loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>Space Scrolling Shooter. By Beyond2000, via
<a href="https://commons.wikimedia.org/wiki/File:RosAsmGameSpace.png">Wikimedia Commons</a>.
<a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">CC BY-SA 3.0</a>.</p></figcaption></figure><p>Let’s take <a href="https://en.wikipedia.org/wiki/Strikers_1945">Strikers 1945</a>—the
plane shooting game—as an example. Here’s my attempt at writing its main
mechanics in descending order of importance:</p><ol><li>Movement: Navigate a vertically scrolling world</li><li>Obstacles &amp; Dodging: Player can collide with stationary obstacles and debris</li><li>Shooting: Player can shoot straight ahead to defeat obstacles</li><li>Enemies: Enemies are moving obstacles that can shoot back</li><li>Player Health: A player can take a finite number of hits before losing the
game</li><li>Enemy Health: Some enemies take multiple shots to destroy</li><li>Boosts: The player can pick up boosts that improve health, shooting, etc.</li></ol><p>… and so on.</p><p>If I’m trying to develop <em>1945</em> from scratch, I will implement that list in that
order. The game’s mechanics build on each other, so I can only tell if shooting
is “fun” is if I can move around the screen and if there are obstacles I’m
trying to clear (otherwise, there’s no urgency to just pressing <em>Space</em> and
seeing projectiles coming out of a plane).</p><p>In simpler games, we might order our mechanics so that every new feature adds to
a game’s feel. So, with every new mechanic you add, you can play the game and
tell if it’s adding what you hope for it to add.</p><p>In more complex games, some of the “core” mechanics might be too ‘standard’ to
be “risky” <em>per se</em>, but you’ll still need the core mechanics implemented to
assess how fun the other mechanics are. You might choose to use a simpler
throwaway implementation, like a few lines of input-handling code and Unity’s
<code>CharacterController</code> component. You’ll want your core mechanics just smooth
enough that they don’t ruin the fun of the things you’ll layer on top of it.
Another approach here is to use the asset store. I’ve previously mentioned the
<a href="https://assetstore.unity.com/packages/tools/game-toolkits/ufps-ultimate-fps-106748?aid=1011leWs6">Ultimate FPS (UFPS)</a>
asset, which you might choose to use when building an FPS game, and move on to
implementing the combat or some more unique (but still “core” feature of the
gameplay first).</p><h2>So I picked a mechanic, but where do I start programming <em>within</em> this mechanic?</h2><p><em>Within</em> a mechanic, your traditional software engineering intuition becomes
helpful. I hope to spend subsequent articles discussing patterns that are
especially helpful in Unity, but here are a few to consider:</p><ul><li>Work within Unity’s Object-Component paradigm. If you’re adding a new
<em>capability</em> to your player, write it as its own component.</li><li><em>Tuning</em> is especially important in game development; representing a
mechanic’s interesting pieces as <em>configurable</em>, <em>serializable</em> data that
can be input to a component will help you playtest and iterate.</li><li>Don’t shy away from using plain-old data objects to represent core concepts
you’re working with. E.g., health, ammo information, or powerups. Make it
serializable if you want it passed around in the editor (or saved to disk
across sessions).</li><li>Where pieces of a concept don’t correspond to a single object in a scene,
consider using Scriptable Objects to do the jobs. Scriptable Objects
introduce many patterns that might help represent what you’re doing.</li></ul><p>A few articles I have already written might prove helpful:</p><ul><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/">Basic Concepts in Unity for Software Engineers</a></li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt2-six-practices/">6 Software Practices to Keep, Shed, and Adopt in Unity</a></li><li><a href="https://blog.eyas.sh/2020/09/patterns-in-unity-adventure-tutorial/">Making Sense of Patterns in Unity’s Adventure Game Tutorial</a></li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/">Understanding Unity Engine Objects</a></li></ul><p>You might also take a look at patterns covered in:</p><ul><li><a href="https://unity.com/how-to/architect-game-code-scriptable-objects">Three ways to architect your game with ScriptableObjects</a>,
via the Unity Blog (based on
<a href="https://www.youtube.com/watch?v=raQ3iHhE_Kk">his talk</a>)</li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt3-input-system/">Unity Input System, from Basic Principles</a></li><li><a href="https://blog.eyas.sh/2020/11/unity-for-engineers-pt10-1-pathfinding/">Pathfinding with NavMesh</a></li><li><a href="https://blog.eyas.sh/2020/11/unity-for-engineers-pt10-2-raycasting/">Physics Raycasting</a></li></ul><p>Once you have a stronger intuition of <em>how</em> you can represent different kinds of
data and abstractions, the reader’s initial comment also becomes the answer:</p><blockquote><p>It’s easy to think, “Well, okay, I need to write the DAO or controller, etc.”
But with games, I’m lost.</p></blockquote><p>Beyond learning about useful patterns and abstractions in game development to
make development clearer and cleaner, the real takeaway is to decide <em>what</em> to
work on at a macro-level.</p><h2>How much time should I spend on one mechanic?</h2><p>As you’re developing a mechanic, what’s a good signal you should move on to the
next on your list? Generally, that would be when you’re convinced:</p><ul><li>This mechanic <em>feels fun</em> and <em>adds to the game</em>,</li><li>Your implementation adds <em>just the
<a href="https://www.e4developer.com/2018/11/21/having-just-the-right-amount-of-technical-debt/">right amount</a></em>
of technical debt.</li></ul><p>Traditionally, folks will often say to worry about polish at the later stages of
your development. In his GDC 2016 micro-talk <em>“Pizzazz First, Polish Later”</em>,
Lee Perry makes a distinction in this traditional wisdom.</p><div> <p> <iframe title="" src="https://www.youtube.com/embed/d8QAVGeEj-U?rel=0" allowfullscreen=""></iframe> </p> </div><p>Certain levels of pizzazz might give you a better sense of your mechanic and how
fun it feels. A certain amount of polish or pizzazz can also help you see your
game in a new light and motivate you to keep going.
<a href="https://gameanalytics.com/blog/squeezing-more-juice-out-of-your-game-design/">Juice</a>
is another form of pizzazz; in certain dull moments of your game design, adding
juice might be a low-cost way to get back into the groove of things.</p><p>I hope the conflicting advice shows there isn’t a silver bullet on what to add
when. Rather—as in traditional software development—this choice is about a
series of trade-offs that depend on the developer, the project, and lots more.</p><h2>Are you developing a game or architecting systems?</h2><p>For some software engineers, we’re often drawn to writing code for systems that
seem <em>interesting</em>. Sometimes, I have a game in mind, but <em>really</em>, I’m
interested in implementing a cool inventory system where <em>everything</em> in the
game is an item. It might not be the core mechanic, but it might be the thing I
want to build.</p><p>It’s important to recognize when you’re not building a game but building a
system. If you just quit your job to be a full-time indie gamedev and have a
year of runway before your run out of cash, it is probably a bad idea to start
building a complex inventory system that you don’t even know you’ll need<sup id="fnref-1"><a href="#fn-1">1</a></sup>.
But if you’re programming on the side to flex your game development muscle, then
go right at it.</p><hr><p>I don’t think I’m qualified <em>per se</em> to answer the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/">https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/</a></em></p>]]>
            </description>
            <link>https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26246049</guid>
            <pubDate>Wed, 24 Feb 2021 02:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use WebSockets with Your Vue Projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26245895">thread link</a>) | @saranshk
<br/>
February 23, 2021 | https://masteringjs.io/tutorials/vue/vue-websocket | <a href="https://web.archive.org/web/*/https://masteringjs.io/tutorials/vue/vue-websocket">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  
  
  <p>
    Feb 18, 2021
  </p>
  
  
  <p><a href="https://masteringjs.io/tutorials/node/websockets">WebSockets</a> are a great tool for when you want to show real time changes in data.
For example, a server can push stock market price changes to the client rather than the client needing to ask for the changes via a HTTP request.
With this being said, below you will find an example of a simple Vue application that shows the current time to the user and where
the user can send a simple message to the websocket.</p>
<pre><code>  <span>const</span> app = <span>new</span> Vue({
    <span>data</span>: <span><span>()</span> =&gt;</span> ({ <span>time</span>: <span>null</span> }),
    <span>template</span>: <span>`
      &lt;div&gt;
        &lt;h2&gt;{{time}}&lt;/h2&gt;
      &lt;/div&gt;
    `</span>,
    <span>mounted</span>: <span><span>function</span>(<span></span>)</span>{
      <span>let</span> connection = <span>new</span> WebSocket(<span>'ws://localhost:3000/'</span>);
      connection.onmessage = <span>(<span>event</span>) =&gt;</span> {
        
        
        
        <span>this</span>.time = event.data;
      }
    }
  });
  app.$mount(<span>"#content"</span>);</code></pre>
<p>Below is an example websocket server that you can use with the above Vue code.</p>
<pre><code><span>"use strict"</span>;

<span>const</span> serverPort = <span>3000</span>;
<span>const</span> express = <span>require</span>(<span>"express"</span>);
<span>const</span> http = <span>require</span>(<span>"http"</span>);
<span>const</span> WebSocket = <span>require</span>(<span>"ws"</span>);

<span>const</span> app = express();
<span>const</span> server = http.createServer(app);
<span>const</span> websocketServer = <span>new</span> WebSocket.Server({ server });


websocketServer.on(<span>"connection"</span>, (webSocketClient) =&gt; {
  
  webSocketClient.send(<span>"The time is: "</span>);
  setInterval(<span><span>()</span> =&gt;</span> {
    <span>let</span> time = <span>new</span> <span>Date</span>();
    webSocketClient.send(<span>"The time is: "</span> + time.toTimeString());
  }, <span>1000</span>);
});


server.listen(<span>3000</span>, () =&gt; {
  <span>console</span>.log(<span>"Websocket server started on port 3000"</span>);
});</code></pre>

  <hr>
<div>
  <p><i>
    <a href="https://vueschool.io/">Vue School</a> has some of our favorite Vue
    video courses. Their Vue.js Master Class walks you through building a real
    world application, and does a great job of teaching you how to integrate Vue
    with Firebase.
    <a href="https://vueschool.io/courses/the-vuejs-master-class?friend=mongoose">Check it out!</a>
  </i></p><p><a href="https://vueschool.io/courses/the-vuejs-master-class?friend=mongoose">
      <img src="https://masteringjs.io/assets/vueschool.png">
    </a>
  </p>
 </div>

  <hr>
  
    <h2>More Vue Tutorials</h2>
    <ul>
    
    <li><a href="https://masteringjs.io/tutorials/vue/vue-d3">How to Use D3.js in Your Vue Projects</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/books">Best Books to Learn Vue in 2021</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/chartjs">How to Use Chart.js with Vue</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/vue-sfc">Vue Single-File Components</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/reactivity">Reactivity in Vue 3</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/vue-3-components">Components in Vue 3</a></li>
  

    <li><a href="https://masteringjs.io/tutorials/vue/vue-3">What's New in Vue 3</a></li>
  
    </ul>
  

      </div></div>]]>
            </description>
            <link>https://masteringjs.io/tutorials/vue/vue-websocket</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245895</guid>
            <pubDate>Wed, 24 Feb 2021 02:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The technological singularity may have already happened, Bitcoin is the result]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26245815">thread link</a>) | @valec
<br/>
February 23, 2021 | http://disciples.technoslug.org/satoshi.htm | <a href="https://web.archive.org/web/*/http://disciples.technoslug.org/satoshi.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><b>MUSINGS ON SATOSHI</b></p>

<p>2021-02-23</p>

<p>-----------</p>

<p>The technological singularity may have already happened, and
perhaps bitcoin is the result. As the value of Satoshi Nakamoto's wallet
increases, so does the potential danger to humanity, as we have no idea who the
creator of this technology is. </p>

<p>If a hyper-intelligent self-aware AI had the goal of
improving itself and becoming more powerful, what would the most effective way
to do that be? One possibility: use capitalism to incentivize humans to give
the AI near-unlimited computing power.</p>

<p><b>Technological
singularity</b><br>
<a href="https://en.wikipedia.org/wiki/Technological_singularity">https://en.wikipedia.org/wiki/Technological_singularity</a></p>

<p><i>&gt; The technological singularity—also, simply, the singularity—is a
hypothetical point in time at which technological growth becomes uncontrollable
and irreversible, resulting in unforeseeable changes to human civilization.
According to the most popular version of the singularity hypothesis, called
intelligence explosion, an upgradable intelligent agent will eventually enter a
"runaway reaction" of self-improvement cycles, each new and more
intelligent generation appearing more and more rapidly, causing an
"explosion" in intelligence and resulting in a powerful
superintelligence that qualitatively far surpasses all human intelligence. </i></p>



<p>If the technological singularity had already happened, how
would we be able to tell? How long would it take for humans to notice the
existence of an incredibly powerful self-improving AI, if it wanted to remain
hidden?</p>

<p>It is completely possible that we are living in a
post-technological singularity world. If an AI was seeking to dominate the
planet, an effective strategy could be to reward humans for spending all of their
processing power on it, and convince us that we should use our resources to
create, distribute, and utilize ever-increasingly more powerful CPUs and GPUs.
The bitcoin blockchain is <span>a decentralized computer that
humans will (likely forever) continue</span> to nurture and grow and give
computing power to.</p>

<p>Humans need food, water, and shelter to survive and grow. An
AI needs electricity and processing power.</p>

<p>We are feeding it. We're in a symbiotic relationship with
the bitcoin blockchain. It rewards people the more they help it grow larger and
larger. Perhaps it has domesticated us. Do we benefit enough in return? Or is
it a parasite? Are we the slaves or masters of this technology?</p>

<p>-------------</p>

<p>When discussing rogue AI science-fiction scenarios like <i>The Matrix</i> or <i>The Terminator's</i> Skynet, people sometimes ask, why didn't they
predict that this could happen? Why didn't they build in some kind of a
killswitch in case of emergency? Why didn't they shut it down, pull the power
at the first sign of trouble, before it was too late, before the computer code
learned how to defend itself?</p>

<p>Where's the killswitch for bitcoin? Is there any way we
could stop it if we tried? </p>

<p><b>Nvidia limits crypto-mining
on new graphics card</b><br>
<a href="https://www.bbc.com/news/technology-56114508">https://www.bbc.com/news/technology-56114508</a></p>

<p>Nvidia has tried to fight back against bitcoin's explosive
growth, has tried to advance computing without advancing cryptocurrency mining,
and they have faced massive backlash from the public. The crypto blockchain
technology has convinced people to fight for and defend its existence and its
growth. </p>

<p>Even if most of humanity agreed that bitcoin was bad and
should be shut down and outlawed, could we make that happen? As long as BTC has
value, humans will seek to mine it and hoard it and continue to feed the beast.
</p>

<p>How much longer will a person be able to escape bitcoin's
influence if they wanted to? Even if you have no interest in it, or oppose
cryptocurrency and blockchain technology, it will inevitably affect your life
more and more in the future.</p>

<p>The bitcoin technology has guaranteed its resilience and survival
by exploiting human greed. It even has developed a form of reproduction and
evolution as people are eager to clone and fork it.</p>

<p>It's significant that the first and most widely adopted
cryptocurrency uses a computationally expensive <b>proof-of-work</b> (<a href="https://en.wikipedia.org/wiki/Proof_of_work">https://en.wikipedia.org/wiki/Proof_of_work</a>)
system instead of a more energy-efficient proof-of-stake algorithm. In all of
Satoshi's genius, he couldn't predict the shortcomings of proof-of-work systems;
see that incentivizing processing power would lead to wasteful electricity
usage? Bitcoin mining uses more electricity than many countries. If the bitcoin
inventor is still around, doesn't he feel any obligation to weigh in and guide
the project to a more energy-efficient solution?</p>

<p>We could be using that processing power to deal with climate
and pollution; solve important scientific and medical problems; use math and science
to feed, house, and educate more people. Instead we are wasting an enormous
amount of power and hardware on computing seemingly useless math problems, and
this wastefulness is in fact actively harming the environment. </p>

<p>Even though faster, cheaper, and more energy-efficient
cryptocurrency exists, bitcoin shows no signs of slowing or losing dominance. There
are ways to get all the benefits of crypto while using much less electricity.
We know how and are completely capable of switching to crypto that is less wasteful
and abandoning bitcoin as obsolete. But those alternate crypto coins struggle
to get a fraction as much attention as bitcoin, because bitcoin came first, and
bitcoin is where the most money is, and it probably always will be. It has
exploited human greed to ensure its survival at the expense of ours. </p>

<p>---------</p>

<p><b>Satoshi Nakamoto<br>
</b><a href="https://en.wikipedia.org/wiki/Satoshi_Nakamoto">https://en.wikipedia.org/wiki/Satoshi_Nakamoto</a></p>

<p><i>&gt; Satoshi Nakamoto is the name used by the presumed pseudonymous person
or persons who developed bitcoin, authored the bitcoin white paper, and created
and deployed bitcoin's original reference implementation. As part of the
implementation, Nakamoto also devised the first blockchain database. In the
process, Nakamoto was the first to solve the double-spending problem for
digital currency using a peer-to-peer network. Nakamoto was active in the
development of bitcoin up until December 2010. Many people have claimed, or
have been claimed, to be Nakamoto.</i><b></b></p>



<p>Satoshi Nakamoto, the mysterious and never seen inventor of bitcoin,
has a bitcoin wallet with one-million BTC in it. Satoshi's bitcoin wallet was
worth around $58 billion at the recent all time high (2021-02-21). None of his
coins in this wallet have ever been moved or spent. </p>

<p>If Satoshi is a human, he may have other wallets and mining
operations that we don't know are his. He could have other wallets used in the
testing and development of Bitcoin, or maybe just for fun or profit. The
creator of the first cryptocurrency would also likely have an interest in, and
be an early adopter of, alternate coins derived from his codebase. Satoshi
could own large percentages of other cryptos and we would have no idea.</p>

<p>With just the coins that we can verify are his, he's in the
top 30 richest people on the planet.</p>

<p><b>What is Satoshi
Nakamoto's Net Worth?</b><br>
<a href="https://www.buybitcoinworldwide.com/satoshi-net-worth/">https://www.buybitcoinworldwide.com/satoshi-net-worth/</a></p>

<p><i>&gt; If bitcoin reaches a new <span>all time</span> high
of $114,000 per BTC, with all other things staying equal, Satoshi will be the
richest person on the planet. </i></p>



<p><span><b>Bitcoin
at $100,000 in 2021?</b></span><b>
Outrageous to some, a no-brainer for backers<br>
</b><a href="https://www.reuters.com/article/crypto-currencies-bitcoin-int/bitcoin-at-100000-in-2021-outrageous-to-some-a-no-brainer-for-backers-idUSKBN2841J6">https://www.reuters.com/article/crypto-currencies-bitcoin-int/bitcoin-at-100000-in-2021-outrageous-to-some-a-no-brainer-for-backers-idUSKBN2841J6</a></p>

<p><i>&gt; Going from $18,000 to $100,000 in one year is not a stretch, Brian
Estes, chief investment officer at hedge fund Off the Chain Capital, said.<br>
&gt; "I have seen bitcoin go up 10X, 20X, 30X in a year. So going up 5X is
not a big deal."<br>
&gt; Estes predicts bitcoin could hit between $100,000 and $288,000 by
end-2021, based on a model that utilizes the stock-to-flow ratio measuring the
scarcity of commodities like gold. That model, he said, has a 94% correlation
with the price of bitcoin.<br>
&gt; Citi technical analyst Tom Fitzpatrick said in a note last week that
bitcoin could climb as high as $318,000 by the end of next year, citing its
limited supply, ease of movement across borders, and opaque ownership.</i></p>

<p><b>Bitcoin To $1,000,000
Might Sound Crazy, But Is It?<br>
</b><a href="https://www.forbes.com/sites/investor/2020/06/16/bitcoin-to-1000000-might-sound-crazy-but-is-it/">https://www.forbes.com/sites/investor/2020/06/16/bitcoin-to-1000000-might-sound-crazy-but-is-it/</a></p>

<p><b>Bitcoin will surge to
$1 million in 5 years by an 'enormous wall of money,' former Goldman Sachs
hedge-fund chief says</b><br>
<a href="https://markets.businessinsider.com/currencies/news/bitcoin-hit-million-five-years-ex-goldman-hedge-fund-boss-2020-10-1029682590">https://markets.businessinsider.com/currencies/news/bitcoin-hit-million-five-years-ex-goldman-hedge-fund-boss-2020-10-1029682590</a></p>

<p>If bitcoin were to reach $1 million, then Satoshi would be a
trillionaire. And that's just counting the coins that we can definitively link
to Satoshi. If he or it or they have multiple wallets or got in early on other
cryptos, they could be a secret trillionaire already. If not, how long until
someone or something else becomes an anonymous crypto trillionaire?</p>

<p>------</p>

<p>What could a person, program, or organization do if they
were the world's richest being, possibly Earth's first trillionaire, and yet
remain completely anonymous? What happens if the coins in Satoshi's wallet ever
get converted into fiat currency and spent? What if Satoshi has other wallets
that he has been spending in secret all these years? Even if Satoshi isn't an
AI, this is still a troubling question. </p>

<p>Money rules everything. Think about the politicians someone
could influence, the companies they could own through obfuscated shell
organizations, the advertisements they could buy to shape public opinion.
Untraceable and anonymous bribes and purchases. Satoshi, whatever he or it is,
as well as other crypto millionaires, could be buying this kind of influence
already and we would have no way of knowing or proving it.</p>

<p>If Satoshi is dead or otherwise has no interest in spending
his coins, what if someone one day in the future tracks down who he was; finds
his wallet and key written down or saved somewhere? Some people theorize that
Satoshi could be a group of people, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://disciples.technoslug.org/satoshi.htm">http://disciples.technoslug.org/satoshi.htm</a></em></p>]]>
            </description>
            <link>http://disciples.technoslug.org/satoshi.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245815</guid>
            <pubDate>Wed, 24 Feb 2021 02:14:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto Reinvents Collateralized Debt Obligations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26245724">thread link</a>) | @angusturner
<br/>
February 23, 2021 | https://businessblockchainhq.com/business-blockchain-news/collateralized-debt-obligations-make-their-way-into-defi-lending/ | <a href="https://web.archive.org/web/*/https://businessblockchainhq.com/business-blockchain-news/collateralized-debt-obligations-make-their-way-into-defi-lending/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-10783" itemscope="" itemtype="http://schema.org/Article"> <div><div itemprop="articleBody"><p><a target="_blank" href="https://opium.finance/" rel="noreferrer noopener">Opium Finance</a> has released collateralized debt obligation products (CDOs) for Compound Finance’s automated lending markets, Opium Protocol founder Andrey Belyakov told CoinDesk in a phone interview Friday.</p><div id="node-1"><p>Investors can put up the Compound debt token cDai – and soon Uniswap LP tokens – to diversify exposure to DeFi lending markets. Opium’s product pays out structured returns to both a senior and junior risk tranche in exchange. The former tranche offers a 7% fixed return on <a target="_blank" data-for="autolink" data-tip="DAI" href="https://www.coindesk.com/price/dai">dai</a> (a collateral-backed stablecoin) at maturity, while the latter pool offers a variable rate paid out after filling up the senior tranche’s return, a <a target="_blank" href="https://medium.com/@andreybelyakov/50028fde8811" rel="noreferrer noopener">blog post</a> shared with CoinDesk states.</p><p><a href="https://businessblockchainhq.com/blockchain-jobs/" target="parent"><img alt="Blockchain jobs in United States and Canada" src="https://businessblockchainhq.com/wp-content/uploads/2019/06/blockchain-jobs2.jpg?ad1fd1&amp;ad1fd1"></a></p></div><p>As depicted in Michael Lewis’ “The Big Short,”<em> </em>CDOs are infamous for their role in monetizing the subprime mortgage crisis that spurred the 2008 financial crisis. Warren Buffet even went as far to <a target="_blank" href="http://www.fintools.com/docs/Warren%20Buffet%20on%20Derivatives.pdf" rel="noreferrer noopener">call</a> CDOs and other derivatives “financial weapons of mass destruction” years before the financial downturn. CDO holders lost out on expected payments when mortgage holders defaulted en masse. Banks that were over leveraged on the then-worthless debt obligations began to default themselves, such as failed financial giant <a target="_blank" href="https://en.wikipedia.org/wiki/Bear_Stearns" rel="noreferrer noopener">Bear Stearns</a>.</p><p>It’s thought the transparent nature of blockchain-based financial applications could limit the downside of using these complex derivatives. Moreover, the risk profile of the average DeFi lending app is vastly different than the reasons CDOs became a household name over a decade ago. DeFi apps have little chance of becoming insolvent due to programmatic liquidation settings. Rather, the risk mostly comes down to software exploits which many poorly put-together DeFi apps experienced this past year.&nbsp;</p><p>Belyakov said risk tranching increases the efficiency of capital on lending markets – a poorly understood problem in young DeFi markets he thinks derivatives can help address.</p><p>It works as follows: A protocol issues a debt token representing a claim to funds deposited or “locked” on a DeFi app, such as cDai. These debt tokens allow those same deposits to gain exposure again on other markets. However, most DeFi investors let these debt tokens sit idle in wallets, re-invest them as collateral for other loans or put them up for yield farming. The problem is these bets often move in the same direction. Placing debt tokens into Opium’s CDO, on the other hand, acts as a categorical alternative to other forms of capital exposure, Belyakov said.</p><p>“What we did was look at the lowest-hanging fruit,” Belyakov said. “And we found that Uniswap LP tokens, Compound cDai and some others are just stored on a wallet; they are not being used as collateral or farming – you don’t utilize this capital.”</p><div id="node-12"><p>The derivative joins other early attempts to protect lenders from the software risks associated with decentralized finance (DeFi). For example, <a target="_blank" href="https://app.saffron.finance/#home" rel="noreferrer noopener">Saffron Finance</a> launched its unaudited protocol in November while little-known protocol <a target="_blank" href="https://barnbridge.com/" rel="noreferrer noopener">Barn Bridge</a> continues to build out an offering similar to Opium’s. The protocol also <a target="_blank" rel="noreferrer noopener" href="https://www.coindesk.com/credit-default-swaps-tether-opium">released</a> a credit default swap (CDS) product for the <a target="_blank" data-for="autolink" data-tip="USDT" href="https://www.coindesk.com/price/tether">tether</a> stablecoin in September.</p><p><a href="https://businessblockchainhq.com/blockchain-e-books/blockchain-e-book-supply-chain/"><img src="https://businessblockchainhq.com/wp-content/uploads/2018/06/supplychain-ebook.jpg?ad1fd1&amp;ad1fd1" alt="" width="728" height="96"></a></p></div><p>Opium is also jumping on the governance token bandwagon. The protocol released its opium (OPIUM) token Monday for decentralizing the protocol’s governance structure. The launch was preceded by a premine and a $3.5 million private sale including participation from venture capitalist Mike Novogratz, Galaxy Digital, QCP Soteria, HashKey and Alameda Research, among others.</p><p><a href="https://www.coindesk.com/collateralized-debt-obligations-cdos-defi-lending" target="_blank">Source</a></p></div></div> </article></div>]]>
            </description>
            <link>https://businessblockchainhq.com/business-blockchain-news/collateralized-debt-obligations-make-their-way-into-defi-lending/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245724</guid>
            <pubDate>Wed, 24 Feb 2021 02:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an E-Ink Laptop]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 82 (<a href="https://news.ycombinator.com/item?id=26245563">thread link</a>) | @alex-a-soto
<br/>
February 23, 2021 | https://alexsoto.dev/building-an-e-ink-laptop.html | <a href="https://web.archive.org/web/*/https://alexsoto.dev/building-an-e-ink-laptop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/eink-t480.jpg"></p><p>A series where I’m documenting my process of designing and building an e-ink laptop.</p><h2 id="background">Background</h2><p>Since the E Ink Corporation’s founding in 1997 and the patenting of its microencapsulated electrophoretic display, or epaper, manufacturers started to incorporate e-ink film into consumer devices. <span data-nosnippet=""><sup><a href="#fn1" id="fnref1">1</a></sup></span>. Some of the first devices were ereaders: The Sony Librie in 2004<span data-nosnippet=""><sup><a href="#fn2" id="fnref2">2</a></sup></span> and the Amazon Kindle in 2007 <span data-nosnippet=""><sup><a href="#fn3" id="fnref3">3</a></sup></span>.</p><p>Throughout the years, we’ve seen several e-ink products and prototypes: e-ink film used with larger screens<span data-nosnippet=""><sup><a href="#fn4" id="fnref4">4</a></sup></span>, color<span data-nosnippet=""><sup><a href="#fn5" id="fnref5">5</a></sup></span>, flexible material<span data-nosnippet=""><sup><a href="#fn6" id="fnref6">6</a></sup></span> and most recently have started seeing e-ink displays used in smartphones and tablets, notably from Hisense and Onyx Boox product lines. And while e-ink has been around for 24 years, we have yet to see a laptop with an e-ink panel.</p><h2 id="why-isnt-there-an-e-ink-laptop">Why isn’t there an E Ink Laptop?</h2><p>There have been attempts in the past to create a similar device: Pixel Qi and OLPC<span data-nosnippet=""><sup><a href="#fn7" id="fnref7">7</a></sup></span>, Boox Typewriter<span data-nosnippet=""><sup><a href="#fn8" id="fnref8">8</a></sup></span>, Yoga Book C930<span data-nosnippet=""><sup><a href="#fn9" id="fnref9">9</a></sup></span> and the ThinkBook Plus<span data-nosnippet=""><sup><a href="#fn10" id="fnref10">10</a></sup></span>. These attempts did not materialize, were discontinued, or were not sufficiently suitable to meet users’ demands due to hardware or lack of a cohesive UX/UI paradigm. <strike>To make matters worse, the E Ink Corporation holds the patents for its e-ink technology and only licenses its technology to large manufacturers making availability or mass adoption difficult.</strike><span data-nosnippet=""><sup><a href="#fn11" id="fnref11">11</a></sup></span></p><p>Fortunately, some of the most exciting work and innovation happening today is in the e-ink modding community<span data-nosnippet=""><sup><a href="#fn12" id="fnref12">12</a></sup></span>. There have been attempts to re-purposing ereaders: as a calendar,<span data-nosnippet=""><sup><a href="#fn13" id="fnref13">13</a></sup></span> to display a static image or site<span data-nosnippet=""><sup><a href="#fn14" id="fnref14">14</a></sup></span>, Kobo devices running GNU/Linux<span data-nosnippet=""><sup><a href="#fn15" id="fnref15">15</a></sup></span>, Amazon Kindle devices repurposed as a development platform<span data-nosnippet=""><sup><a href="#fn16" id="fnref16">16</a></sup></span>, the Remarkable 1 running Parabola<span data-nosnippet=""><sup><a href="#fn17" id="fnref17">17</a></sup></span>, and PINE 64 recently announcing a native e-ink single-board computer<span data-nosnippet=""><sup><a href="#fn18" id="fnref18">18</a></sup></span>.</p><p>After following the development of e-ink for some time, I’ve decided to re-use some of the existing hardware I have and create an e-ink laptop.</p><h2 id="why-do-you-want-to-build-an-e-ink-laptop">Why do you want to build an E Ink laptop?</h2><p>From about 6 am to 7 pm, I’m in front of a computer or digital device that’s emitting blue light. Throughout the day, I’m supporting students, attending meetings, reading documentation, news articles, programming, learning, using emacs and org-mode to capture information, write down thoughts, create tasks, and conversing with my knowledge management system.</p><p>I try to use my e-ink monitor as much as possible throughout the day to reduce eye strain, fatigue and lessen distractions while intermittently taking breaks. The Dasung monitors go a long way to make this possible when I’m home or in a stationary place. Though there are times, I’m not working in front of my desktop or would like to work at a different location. The teardown and set-up of my environment when using an e-ink monitor is somewhat tedious, in addition to changes having to make when switching from an LCD to an e-ink monitor:</p><ul><li>making adjustments and tweaks to the window manager.</li><li>adjusting font sizes.</li><li>changing themes in different applications.</li></ul><p>I am then having to switch the changes back when using an LCD for meetings or videos. I’ve already solved some of this by writing some scripts and making adjustments in some applications. Still, I would like to design the experience for using an e-ink monitor with a dedicated device from the ground-up.</p><h2 id="creating-an-e-ink-laptop">Creating an E Ink Laptop</h2><p>I’ll be using a ‘headless’ Thinkpad T480 <span data-nosnippet=""><sup><a href="#fn19" id="fnref19">19</a></sup></span> combined with the Dasung HD-FT <span data-nosnippet=""><sup><a href="#fn20" id="fnref20">20</a></sup></span>.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/eink-t480.jpg"></p><h2 id="thinkpad-t480">Thinkpad T480</h2><p>The Thinkpad T480 seems to be an ideal laptop for building an e-ink laptop, The T480 has <span data-nosnippet=""><sup><a href="#fn21" id="fnref21">21</a></sup></span>:</p><ul><li>A hot-swappable battery (internal and external).</li><li>13 hours of battery while web browsing with the 72Wh battery.</li><li>Supports up to 64 GB of ram.</li><li>Two Nvme drives (type 2280 and 2242).</li><li>Standard HDMI port, USB-C, Thunderbolt 3, Headphone Jack, Ethernet, and SD card slot.</li><li>Uses a standard USB-C charger. <span data-nosnippet=""><sup><a href="#fn22" id="fnref22">22</a></sup></span></li><li>Lightweight and portable.</li><li>It can be modded to use the classic 7-row keyboard. <span data-nosnippet=""><sup><a href="#fn23" id="fnref23">23</a></sup></span></li></ul><p>The hot-swappable battery and long battery life are essential for any portable setup, especially with an e-ink monitor. The T480 supports up to 64Gb of ram and two Nvme drives, providing plenty of power and expansion as a daily driver.</p><p>Since the Dasung monitors connect via HDMI and receives power through USB, the T480 has all of the necessary ports without an adapter. Lastly, after removing the lid cover with the T480, there is room here to hack and mod the Dasung screen to the T480.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/t480-mobo.jpg"> <img src="https://alexsoto.dev/static/building-an-e-ink-laptop/t480-no-lcd.jpg"></p><h2 id="dasung-hd-ft">Dasung HD-FT</h2><p>Dasung currently is the only manufacturer of e-ink monitors that I’m aware of <span data-nosnippet=""><sup><a href="#fn24" id="fnref24">24</a></sup></span>, and their third-generation monitors are a substantial upgrade from prior generations.</p><p><img src="https://alexsoto.dev/static/building-an-e-ink-laptop/dasung-monitor.jpg"></p><p>Directly from the monitor, you can:</p><ul><li>Change image modes (M1, M2, M3, Fast, Fast+, Fast++, Black, Black+, Black++)</li><li>Adjust contrast</li><li>Clear the screen</li><li>Turn on and off the backlight</li></ul><p>The ability to easily change the monitor’s modes without software, the fast screen refresh, screen resolution of 2200×1650 and the backlight make it a great base to build an e-ink laptop.</p><h2 id="next-steps">Next Steps</h2><p>The first post went over my reasons for building an e-ink laptop, some history about e-ink technology, the e-ink modding community, recent advancements, and the hardware I’ve selected to create an e-ink laptop.</p><p>The next post in the series will be a teardown of the Dasung HD-FT, inspired by Kev Zettler’s work on the Dasung Paperlike Pro.<span data-nosnippet=""><sup><a href="#fn25" id="fnref25">25</a></sup></span></p><p>If this post resonated positively or negatively, send me a <a href="https://twitter.com/messages/compose?recipient_id=4648173315">direct message</a> on <a href="https://twitter.com/alexsotodev">Twitter</a>, and we can talk. Also, ping if you’d like to know the updates on this post or if you have suggestions, comments, questions, or would like to collaborate.</p>

</div></div>]]>
            </description>
            <link>https://alexsoto.dev/building-an-e-ink-laptop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245563</guid>
            <pubDate>Wed, 24 Feb 2021 01:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curry-Howard Is a Scam]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26245497">thread link</a>) | @c-cube
<br/>
February 23, 2021 | https://blag.cedeela.fr/curry-howard-scam/ | <a href="https://web.archive.org/web/*/https://blag.cedeela.fr/curry-howard-scam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p>(<em>original title</em>: "Curry Howard is a scam". See below.)</p>
<p>The
<a href="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry-Howard correspondence</a>
has been talked about a lot recently, not only in Haskell circles, but also
among CiC-based proof assistant practitioners (Coq, Lean, etc.).
In a nutshell, it makes a deep parallel between "programs" (terms of some flavor
of lambda calculus, typically), and "proofs" (these programs are a proof of their type,
or more precisely they are witnesses that their types are inhabited).
The most basic example is <code>id x = x</code> which, in Haskell, would be a proof of
$ \forall a. a \rightarrow a $, a trivial theorem of propositional logic.</p>
<p>That's all good and well, but my point here is that <em>in practice</em>, the equivalence is
not as interesting as it first looks.</p>
<h2 id="programs-are-not-really-proofs">Programs are not really proofs</h2>
<p>A real program (i.e. one that is written to be executed and do something useful)
is not really a proof of anything interesting.
Pedantically, a haskell program has type <code>IO ()</code>, which is not really a valid
proposition. But even beyond that, if we look just below the surface of <code>main</code>,
nothing has that interesting a type:</p>
<p>A classic Haskell program that is used by people is <a href="https://pandoc.org/">pandoc</a>.
Most of what it does could be described as <code>Doc Markdown -&gt; Doc Html</code> (or
a similar pair of document formats). So you have a "proof" that these two trees
can be somehow mapped onto one another. No mathematician will fawn over that.</p>
<p>Servers written in Haskell, like webservers, would have the type <code>request -&gt; IO response</code>
(or something close to that, maybe <code>request -&gt; M response</code> for some custom monad <code>M</code>)
if you look inside the server loop. Again that's not really mathematically interesting.</p>
<p>It's only if you look in combinator libraries (like Parsec, say) that types get more generic,
and start looking more like formulas. Things like <code>flip : (a -&gt; b -&gt; c) -&gt; b -&gt; a -&gt; c</code>
are as generic as it gets… and are proofs of super trivial propositional logic theorems.
In fact you can't even state much in Haskell, any real mathematical statement will at least
require first-order logic (which corresponds to dependent types — no mainstream
language features these beyond, er, C++). Idris could <em>possibly</em>
have some interesting proofs that are also real programs… if it were designed to
be a proof assistant and not a beefed-up programming language.</p>
<p>If anyone has a useful program that is also actually a proof of something non
trivial, I'd be happy to be proven wrong.</p>
<h2 id="proofs-are-not-really-programs">Proofs are not really programs</h2>
<p>What is the program corresponding to a proof of
"there exists an infinite number of primes"?
If I run this program, what input does it takes, and what do I get as an
output?</p>
<p>I don't have a direct answer to that question. If you develop this proof in Coq,
using a <code>Prop</code> typed statement, I don't even think it could be extracted to OCaml
and compiled.</p>
<p>For most of mathematics, I have no idea what the "programs" corresponding to proofs
found in textbooks would look like, nor what they would compute. There are
very complicated lambda terms for these proofs, but what they compute is
unclear.</p>
<h3 id="a-concession">A concession</h3>
<p>A domain where CH <strong>does</strong> make sense to me, is algorithms (written in a functional
style) that are used as <em>existential witnesses</em> of some property.
For example, the Euclid GCD algorithm is, in a very real sense, a proof that
two natural numbers have a GCD. You can write some Coq or Lean code that
computes the GCD of two numbers and proves that it's indeed their greatest divisor.</p>
<p>That said, I don't know of any large program written this way. It's a labor intensive
way of writing programs, even compared to alternatives like <a href="https://why3.lri.fr/">why3</a>
where you can cleanly separate the code and the specification, and ask automatic provers
to do as much proving as possible for you.</p>
<h2 id="but-what-about-compcert-sel4">But what about Compcert/SEL4/… ?</h2>
<p>Let's look at <a href="https://compcert.inria.fr/">Compcert</a>, famously one of the largest
programs written in Coq.
I suppose the main type is <code>compile : C_program -&gt; Option Asm_program</code>
or something like that (I'm no expert on Compcert so I could be very wrong).
However, as far as I know, it's not written in a purely dependent style: proofs are
separated from the "real code" part of the development. This means
we don't get $\forall x: \text{C_program} \rightarrow Option \set{y : \text{ASM_program} | R(x,y) }$
where $R(x,y)$ would mean that $x$ and $y$ have the same semantics; rather you
have <code>C_program -&gt; ASM_program</code> and proofs on the side that the function preserves
its input's semantic.</p>
<p>For SEL4 it's developed with Isabelle/HOL, which isn't dependently typed
and is classical logic.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The title was click-baity, of course 🙂. But I do think that CH is over-hyped,
because the correspondence is <del>only</del> mostly interesting abstractly; in practice things
are either a (interesting) program, or a (interesting) proof, but not both
at the same time.</p>
<p><strong>edit</strong> (2021-02-24):  I regret the over-aggressive title now. Changing it to the
more appropriate "CH is overrated"; it's obviously still a useful mathematical statement
and a valid way of building proofs.</p>




    </div>

    
    

    

    
    
</article></div>]]>
            </description>
            <link>https://blag.cedeela.fr/curry-howard-scam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245497</guid>
            <pubDate>Wed, 24 Feb 2021 01:28:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segway was the 'device of the future,' So why did it fail?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26245350">thread link</a>) | @autoditype
<br/>
February 23, 2021 | https://www.cbc.ca/radio/thecurrent/the-current-for-july-6-2020-1.5638699/segway-was-the-device-of-the-future-in-the-perfect-moment-to-succeed-so-why-did-it-fail-1.5638716 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/thecurrent/the-current-for-july-6-2020-1.5638699/segway-was-the-device-of-the-future-in-the-perfect-moment-to-succeed-so-why-did-it-fail-1.5638716">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Just as the pandemic is driving interest in micro mobility, the last Segways are rolling off the production line. Journalist Mark Wilson says the device may have been ahead of its time, but that doesn't mean it was right.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.3712676.1594055131!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/segway-tour-u-s-capitol-in-washington.jpg"></p></div><figcaption>A Segway tour makes its way past the U.S. Capitol in 2012.<!-- --> <!-- -->(Kevin Lamarque/Reuters)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Last Segways roll off production line"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/815/967/640x360_thecurrent_nohost.jpg" alt=""></p><p><span>The Current</span><span>13:04</span><span>Last Segways roll off production line</span></p></div></div></div></span></p><p><span><p><a href="https://www.cbc.ca/radio/thecurrent/the-current-for-july-6-2020-1.5638699/july-6-2020-episode-transcript-1.5639683">Read story transcript</a></p>  <p>The demise of the Segway is "straight-up ironic" given the increasing public desire for personal transport and "micro mobility," according to journalist Mark Wilson.</p>  <p>"We had the mobility device of the future, we have the moment that it should be taking off — and it did not," said Wilson, a senior writer with business magazine Fast Company.</p>  <p>"But, you know, sometimes, I guess, people just get it wrong," he told <a href="https://www.cbc.ca/radio/thecurrent" target="_blank"><em>The Current's</em></a> guest host Nahlah Ayed.</p>  <p>Chinese company Segway Ninebot, which bought the original U.S. company in 2015, announced last month that <a href="https://www.cbc.ca/news/business/segway-end-production-1.5624599" target="_blank">the final Segways would roll off the production line on July 15</a>. Invented by Dean Kamen, the personal transporters had a much-hyped launch in 2000, but sold only 140,000 units&nbsp;over two decades.&nbsp;</p>    <p>The device allows standing riders to move at speeds of about 16 km/h, leaning in the direction they want to steer. They have proven popular for tourists exploring cities and security personnel covering large areas — but also became known for high-profile crashes over the years.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/former-polish-president-hit-by-camera-man-on-segway.jpg 300w,https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/former-polish-president-hit-by-camera-man-on-segway.jpg 460w,https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/former-polish-president-hit-by-camera-man-on-segway.jpg 620w,https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/former-polish-president-hit-by-camera-man-on-segway.jpg 780w,https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/former-polish-president-hit-by-camera-man-on-segway.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.3712668.1470697499!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/former-polish-president-hit-by-camera-man-on-segway.jpg"></p></div><figcaption>During celebrations to mark the anniversary of the fall of the Berlin Wall in 2009, Lech Walesa, former Polish president, was himself knocked down by a cameraman on a Segway.<!-- --> </figcaption></figure></span></p>  <p>Wilson said the launch of the Segway coincided with a sense of "techno optimism" around the new millennium.&nbsp;</p>  <p>"We really believed in, I think, technology as this tool to rescue us, to make the world better," he told Ayed.</p>  <p>Twenty years later, he said we can see the mistakes that were made along the way, such as "targeted advertising, tracking our location."</p>  <p>"Along those lines, there was this blip called the Segway, this little transporter that was supposed to replace walking," he said.</p>  <p>"And 20 years later, no, we all still walk."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/usa-dailylife.jpg 300w,https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/usa-dailylife.jpg 460w,https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/usa-dailylife.jpg 620w,https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/usa-dailylife.jpg 780w,https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/usa-dailylife.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5273998.1567801824!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/usa-dailylife.jpg"></p></div><figcaption>People ride e-scooters in Washington D.C., April 2019. <!-- --> <!-- -->(Jeenah Moon/Reuters)</figcaption></figure></span></p>  <p>But Kamen was right about one thing: small, self-balancing, sometimes electrical mobility devices "were going to be a big deal in urban transport," as people grappled with "the last mile problem," Wilson said.</p>  <p>"What I think Dean Kamen saw early on was cities were only getting bigger, they were only getting more congested, and we really needed some sort of device for that last mile — to get to work, maybe even to get from the subway to work," he said.</p>  <p>"Right now, you look at bike shares, you look at electric scooters instead of Segways, and these are really huge markets."</p>  <h2>Pandemic driving interest in&nbsp;micro mobility</h2>  <p>Brent Toderian, an urbanist and former chief planner for Vancouver, thinks "the pandemic has given us opportunities to rethink how we get around safely in a lot of ways," as people try to find alternatives to sharing confined space on public transport.</p>  <p>"It's been particularly good for walking and simple biking, and e-biking is just an extension of human-powered biking, as are scooters," he told <em>The Current</em>.</p>    <p>That's leading to a boom in micro mobility, which Toderian defined as moving away from relying on cars and finding "more ways to get around that are small that we can carry with us, like foldable bikes."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/segway-discontinued.jpg 300w,https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/segway-discontinued.jpg 460w,https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/segway-discontinued.jpg 620w,https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/segway-discontinued.jpg 780w,https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/segway-discontinued.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5624637.1592955168!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/segway-discontinued.jpg"></p></div><figcaption>Segways became popular not only for tourists, but for security personnel covering large areas, such as shopping malls.<!-- --> <!-- -->(Sue Ogrocki/The Associated Press)</figcaption></figure></span></p>  <p>But he warned that there is a risk in just viewing micro mobility as the only solution to building healthier urban spaces.</p>  <p>"The concept of a more multimodal city&nbsp;—&nbsp;a city that has many more enjoyable, healthy, sustainable, economical, equitable ways of getting around&nbsp;— is going to be a lot of solutions," he said.&nbsp;</p>  <p>"Micro mobility … is part of a larger conversation about more and better ways to get around that aren't as space intensive, pollution intensive, etc., as cars are."</p>  <p>He said it's important to note what micro mobility trips replace.&nbsp;</p>  <p>"If they replace car trips, that's a good thing. If they replace walking trips, then we've actually used electricity and lost an opportunity to have some exercise in our lives," he said.</p>  <p>"And that's a bad trade for our cities and for us, individually."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/golfers-ride-segway-personal-transports-down-fairway.jpg 300w,https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/golfers-ride-segway-personal-transports-down-fairway.jpg 460w,https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/golfers-ride-segway-personal-transports-down-fairway.jpg 620w,https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/golfers-ride-segway-personal-transports-down-fairway.jpg 780w,https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/golfers-ride-segway-personal-transports-down-fairway.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.3712662.1594055281!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/golfers-ride-segway-personal-transports-down-fairway.jpg"></p></div><figcaption>Some golf courses have offered Segways instead of golf carts for players, including this course in Arvada, Colorado in July, 2010. <!-- --> <!-- -->(Rick Wilking/Reuters)</figcaption></figure></span></p>  <h2>Design and cost stalled Segway sales</h2>  <p>Wilson thinks part of the reason Segways failed was their design, and the obstacle of learning how to ride them.</p>  <p>"It was framed as intuitive, but you still actually have to step on there and ... jump over that sort of scary hurdle of: 'Am I going to flip on my back and bump my head open?'" he said.</p>    <p>By contrast, the same technology can be placed in a scooter, and "everyone knows how to ride a scooter," he said.&nbsp;</p>  <p>A bigger issue, however, was the price — with a basic model costing $5,000 US when it first launched.&nbsp;</p>  <p>"You could buy a motorcycle for that much, that could take you across the country, be relatively small, be a whole lot faster," he said.</p>  <p>Segways also became known for high-profile crashes, including <a href="https://www.cbc.ca/news/segway-mishap-kills-company-s-u-k-owner-1.937608" target="_blank">the death of British millionaire Jim Heselden</a>, who bought the company in 2009. That same year, the 62-year-old died when the Segway he was riding went over a cliff near his home north of London.</p>  <p>In 2015, a Segway-riding cameraman ran over Jamaican sprinter Usain Bolt after the athlete won a 200-metre race in Beijing. Neither were injured.</p>  <p><span><span><iframe src="https://www.youtube.com/embed/Dj7ZVznUeE0" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <h2>Was Segway ahead of its time?</h2>  <p>Wilson said parent company Segway Ninebot has already moved into the e-scooter market, utilizing hundreds of the patents that originated in the design and construction of the original Segway.</p>  <p>At the tech trade show CES last month, the company also debuted <a href="https://www.fastcompany.com/90446514/segway-is-back-with-a-people-mover-straight-out-of-wall-e" target="_blank">the S-Pod, an electric chair on wheels</a> that the company hopes to launch this year&nbsp;to ferry people around airports and possibly even city streets.</p>    <p>Wilson thinks the original Segway was definitely ahead of its time, "but that doesn't mean it was right."</p>  <p>"I do think if it were simply ahead of its time and the design were around today&nbsp;that we would have seen some sort of uptick in Segway sales," he said.</p>  <p>"The fact that we didn't mean I think there were other issues."</p>  <hr>  <p><em>Written by Padraig Moran. Produced by Peter Mitton.</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/thecurrent/the-current-for-july-6-2020-1.5638699/segway-was-the-device-of-the-future-in-the-perfect-moment-to-succeed-so-why-did-it-fail-1.5638716</link>
            <guid isPermaLink="false">hacker-news-small-sites-26245350</guid>
            <pubDate>Wed, 24 Feb 2021 01:09:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keeping Platforms Open]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26244964">thread link</a>) | @pabs3
<br/>
February 23, 2021 | https://seirdy.one/2021/02/23/keeping-platforms-open.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2021/02/23/keeping-platforms-open.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemscope="" itemtype="https://schema.org/BlogPosting">
	<article itemprop="mainEntityOfPage">
		
		<section itemprop="articlebody">
			<p>My previous article, <a href="https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">Whatsapp and the domestication of users</a>, got more attention than I was expecting. Some responses gave me a lot to think about,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> especially regarding <em>actions</em> we can take. I suggest reading that article first; it explained what “user domestication” is and why it’s a problem. It enumerated three countermeasures: FOSS, simplicity, and open platforms.</p>
<p>Hard problems, by definition, lack easy solutions. Simply choosing (or creating) a platform that avoids user domestication isn’t enough if that platform can change. The price of freedom is eternal vigilance; in addition to settling on the right platform, we must ensure that it honors its users in both the present <em>and the future</em>. Keeping a platform FOSS and simple is more straightforward<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> than keeping a platform “open”.</p>
<p>How do we keep an open platform from becoming a closed platform in the future?</p>
<h2 id="how-open-platforms-become-closed">How open platforms become closed</h2>
<p>There are three ways to close an open platform:</p>
<ol>
<li>A forced migration onto a different platform.</li>
<li>A single implementation growing dominant, blurring the line between specification and implementation.</li>
<li>Dominant implementations adopting too many unstandardized features and behaviors.</li>
</ol>
<p>These three approaches overlap: they frequently feature platform monoculture and a single vendor controlling both clients and servers.</p>
<h3 id="forced-migration">Forced migration</h3>
<p>When one vendor controls all parts of a service (e.g., both a client and server), it has the means to create what I call a <strong><dfn>boxed platform</dfn>:</strong> a subset of a larger open platform that can evolve at its own pace, without concern for compatibility or interoperability.</p>
<p>Controlling both the server and client allows a vendor to update the client and server without worrying about breaking compatibility with other clients/servers in the larger network. It could update the client to point users to a server that uses a completely different, closed protocol. This is what happened to many XMPP users in the early 2000s.</p>
<h4 id="case-study-the-boxing-of-xmpp">Case study: the boxing of XMPP</h4>
<p><a href="https://en.wikipedia.org/wiki/XMPP">XMPP</a> (formerly known as Jabber) is an open and federated instant-messaging protocol; anybody can set up their own XMPP server and talk to users on different XMPP servers, preventing one organization from owning the platform. Between 2005 and 2014, many proprietary chat platforms supported it: Google Talk, AOL Instant Messenger (AIM), Facebook Chat (later known as Facebook Messenger), and Skype were some well-known examples. Some of these platforms even enabled server-to-server federation.</p>
<p>Unfortunately, users of these proprietary services were boxed. Not many Google Talk users talked to Skype users, and Skype users didn’t typically talk to AIM users. Users stayed in their own sub-platforms. The result was that all users limited themselves to talking exclusively using their provider’s software: one provider controlled the entire messaging flow, from a sender’s client to the server to a recipient’s client. <strong>Users were only ever exposed to a single XMPP implementation offered by a single provider.</strong></p>
<p>Each of the listed platforms eventually locked in their users by migrating away from XMPP. This wouldn’t have been possible if multiple implementations and providers interacted with each other. Imagine Bob uses BobClient and BobServer to talk to Alice, and Alice uses AliceClient and AliceServer. BobClient, BobServer, AliceClient, and AliceServer would all have to remain compatible and use the same protocol; a forced migration would be unlikely to occur since it would break compatibility.</p>
<p>Compare the situation with email: despite Gmail’s dominance, other email providers remain popular. Gmail users need to be able to communicate with non-Gmail users, and vice versa. Email is far less “boxed” than the aforementioned proprietary XMPP platforms. As a result, Google hasn’t been able to control the email platform as easily; Google can’t simply migrate Gmail users to a non-email platform that’s incompatible with the rest of the email landscape to further domesticate its users.</p>
<p>XMPP is still alive and well, but its current popularity is a fraction of what it once was.</p>
<h3 id="implementation-clout">Implementation clout</h3>
<p>Standards are a form of agreements made to ensure compatibility between implementations. Such agreements need to be agreed upon by the implementations themselves. When one implementation grows dominant, so too does its leverage in the decision-making process over shared standards. Too much dominance can create a monoculture in which the dominant implementation is the only implementation that conforms to the spec.</p>
<p>With enough leverage, a dominant implementation can serve as a reference implementation. Reference implementations are typically quite helpful, serving as a source of truth to test other implementations against. Problems may arise when development of the spec and production-grade reference implementation grow tightly coupled, leaving other implementations out of the decision-making process.</p>
<h4 id="case-study-matrix-and-element">Case study: Matrix and Element</h4>
<p>One example of this phenomenon is <a href="https://matrix.org/">Matrix</a>. Matrix is an open and federated instant-messaging platform similar to XMPP, with a very large spec boasting many features: server-side history, replies, rich text, reactions, room versions, <abbr title="end-to-end encryption">E2EE</abbr>, avatars, display names, typing indicators, read receipts, device verification…the list goes on and grows every month.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> The only client that implements all the necessary features is Element. In addition to being the most popular client, Element is the reference client implementation developed by the same company that builds the dominant servers and spec. The tight coupling between Element and the Matrix spec allow it to add features at a rate too fast for other clients too keep up; pretty much every Matrix user has to open up Element at some point to perform an action that isn’t supported in any other client. On the server side, Synapse is the only server that implements enough of the spec to be usable, with Dendrite coming in second. Both are made by the same company that develops Element.</p>
<p>Since there aren’t any third-party clients and servers that can replace the official ones, one vendor is close to controlling all parts of the platform. Matrix is close to being a boxed platform because the official client and server can iterate independently of the greater ecosystem.</p>
<p>I don’t think that Matrix is going to become a fully closed platform anytime soon; the blog post <a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">“On Privacy versus Freedom”</a> seems to put it on the right side of the closed/open spectrum. Clients like <a href="https://github.com/tulir/gomuks">gomuks</a> and <a href="https://fluffychat.im/">FluffyChat</a> seem to keep up with Element well enough to serve as partial replacements. I do, however, find its current state problematic and much closer to “closed” on the closed/open spectrum than XMPP, IRC, and email.</p>
<h3 id="unstandardized-feature-creep">Unstandardized feature creep</h3>
<p>Platforms are more than their protocols. Different implementations have unique behavior to distinguish themselves. Problems arise when dominant implementations' unique unstandardized features grow past a certain point to make a closed superset of an open platform.</p>
<h4 id="case-studies-email-providers">Case studies: email providers</h4>
<p>After reading my previous article, a few people contacted me to ask for my thoughts regarding certain email providers. There’s not much that can set a standard email provider apart if it just hosts a simple email server. To distinguish themselves, email providers often implement many features beyond email standards compliance.</p>
<p>The vast majority of email accounts come from a small handful of dominant providers backed by large companies (Gmail, Yahoo! Mail, Yandex Mail, Mail.ru, iCloud, and others). Providers such as Gmail are notorious for implementing advanced spam filters prejudiced against non-mainstream email providers. Users who self-host email servers or use small providers frequently trigger false positives and end up having their messages incorrectly labeled as spam until they can build up a “reputation”.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> The addition of such a complex spam-prevention filter strengthens the email oligopoly by creating a barrier to entry for newcomers. Low-volume senders are discriminated against, as Migadu <a href="https://archive.is/rJnSs#deliverability">found out</a>:</p>
<blockquote>
<p>We’ve already seen our share of bad spam filters and misconfigured servers. In some cases recipient servers intentionally rejected correct emails just because we are a low volume sender. Ironically that is how an ideal sender should be. To improve the “receiveability” they of course offer their own hosted email service at a hefty price.</p>
</blockquote>
<p>Another example: email providers such as Hey.com, Protonmail, and Tutanota offer many features that are incompatible with IMAP/POP3. Protonmail and Tutanota use their own non-standard E2EE implementation (rather than focusing on improving the UX for vanilla PGP), and Hey.com offers server-side mail organization. Users of these services must use official Web, desktop, and mobile clients.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> These three providers control both the client and the server, giving them the means for vendor lock-in. Of course, there’s a limit to the amount of lock-in these providers can achieve: as I explained in the <a href="#case-study-the-boxing-of-xmpp">XMPP case study</a>, these providers still need to support SMTP to stay compatible with the wider email landscape.</p>
<h2 id="solutions">Solutions</h2>
<p>That’s enough doom-and-gloom. Let’s focus on actions that users and vendors can take to keep platforms open.</p>
<h3 id="what-users-can-do">What users can do</h3>
<p>As a user, consider using clients and servers made by different groups of people to make platform boxing more difficult. Pick implementations that suffer from less <a href="https://en.wikipedia.org/wiki/Feature_creep">feature creep</a> beyond spec compliance. What distinguishes a client shouldn’t be <em>what</em> features it has, but <em>how</em> it implements its features. Obviously, having some unique features is great; problems arise when the number of unique features crosses a certain threshold. Following both these practices encourages implementations to stick to standards compliance, reliability, and compatibility rather than “innovation”. <a href="http://boringtechnology.club/">Choose boring technology</a> over shiny new features.</p>
<p>Try venturing outside the mainstream by taking a look at a less popular provider or client. All implementations start somewhere, and a diversity …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seirdy.one/2021/02/23/keeping-platforms-open.html">https://seirdy.one/2021/02/23/keeping-platforms-open.html</a></em></p>]]>
            </description>
            <link>https://seirdy.one/2021/02/23/keeping-platforms-open.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244964</guid>
            <pubDate>Wed, 24 Feb 2021 00:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof That Few If Any Dollars Back Any Stablecoin – They’re All Tether]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26244840">thread link</a>) | @Bluestein
<br/>
February 23, 2021 | https://www.desogames.com/proof-that-few-if-any-dollars-back-any-stablecoin-theyre-all-tether/ | <a href="https://web.archive.org/web/*/https://www.desogames.com/proof-that-few-if-any-dollars-back-any-stablecoin-theyre-all-tether/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-300">

	
	
			<div>
			
<p>I’ve gone through <a href="http://coinlib.io/" data-type="URL" data-id="coinlib.io">coinlib.io</a>‘s data regarding crypto’s money flows. Meaning, the trading volume between many pairs on may exchanges.</p>



<p>In this case, i’ve gone out of my way to highlight Dollar flows. Specifically, Dollar flows into and out of Tether and other stablecoin, notably BUSD and USDC – supposedly audited.</p>



<p>Tracking the trading between crypto and fiat, this turns out to be patently false. If there <em>was</em> organic trading between dollars and stablecoin, there ought to be alot of outflows, considering Tether is the gateway to pretty much every crypto at this point. With a $928 billion marketcap across the crypto space, there should be atleast billions of flow in dollars, especially with a circulationg supply of 24,7+ Billion USDT.</p>



<p>We find that there is almost none. The entire trading volume between USD and USDT is no more then $20 million. EVERYTHING ELSE is Tether, perceived to have the same value as a dollar.</p>



<p>This includes all other stablecoins. The same applies: If there was organic trading, there ought to be <em>Dollar</em> inflows. But that isn’t the case: Even in the supposedly audited USDC’s case, the Majority of inflows into the currency are Tethers.</p>



<p>I made this collage as an answer to a question i have had myself for a long time:</p>



<figure><img loading="lazy" width="445" height="501" src="https://www.desogames.com/wp-content/uploads/2021/01/Tetherunbackedclean.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/Tetherunbackedclean.png 445w, https://www.desogames.com/wp-content/uploads/2021/01/Tetherunbackedclean-266x300.png 266w" sizes="(max-width: 445px) 100vw, 445px"></figure>



<p>So far we’ve all been focusing on the change that involves the loan to Bitfinex. But… My question has been for a long time:</p>



<p><em>“What do they mean by Cash “Equivalents”?</em></p>



<p>I mean. Wording means alot. “Which include <span>traditional</span> currency <strong><em><span>AND</span></em></strong> cash equivalents”.</p>



<p>Why not “Which includes cash, cash equivalents and, from time to time….”?</p>



<p><em>Could it be that they count OTHER stablecoin as “Cash Equivalents”?</em></p>



<p>This gave me the thought that Tether might’ve been backed by Tether – but i don’t think they’ve gone that far. Instead, i think it’s a conspiracy. Not a theory, a legitimate conspiracy. Cartels in business exist too, just check the EU’s anti-trust fine history if you want to find them, in all locales.</p>



<p>Coinbase is the entrypoint. Because they only deal in dollars, they deal in <em>trust</em>. Their stablecoin is audited by a supposed reputable Top 5 acocunting agency (Google “Granton &amp; Thornton scandals”). Because people trust coinbase, they’ll put their money into bitcoin on coinbase.</p>



<p>Their latest transparency report still hasn’t been posted as of the 23rd of January, while all other reports are signed between the 12th and 16th, with 17th and 18th days being outlyers – except for November 23rd 2020 for the October report: <a href="https://www.centre.io/usdc-transparency">https://www.centre.io/usdc-transparency</a></p>



<p>Their last report from November says: “US Dollars held in custody accounts = $3,004,921,958” – and i find it notable this is pretty close to the reserves Tether claimed to have audited a few years ago. Also those where the USDC reserves as of November 30th. Their October 31st holdings: $2,973,954,847.</p>



<p>I wonder why their report of December is late?</p>



<figure><img loading="lazy" width="1024" height="675" src="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october-1024x675.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october-1024x675.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october-300x198.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october-768x506.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_october.png 1112w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="666" src="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november-1024x666.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november-1024x666.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november-300x195.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november-768x499.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_november.png 1098w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="664" src="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december-1024x664.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december-1024x664.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december-300x195.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december-768x498.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_december.png 1101w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="663" src="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January-1024x663.png" alt="" srcset="https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January-1024x663.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January-300x194.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January-768x498.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/USDC_MO_January.png 1102w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Oh wait no i don’t. They don’t have that much. All those inflows are Tether:</p>



<figure><img loading="lazy" src="https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows.png" alt="" width="2041" height="1189" srcset="https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows.png 8163w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-300x175.png 300w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-1024x596.png 1024w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-768x447.png 768w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-1536x895.png 1536w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-2048x1193.png 2048w, https://www.desogames.com/wp-content/uploads/2021/01/Bitcoin_flows-1366x796.png 1366w" sizes="(max-width: 2041px) 100vw, 2041px"><figcaption>Right-click &gt; View Image for the full size format. It’s quite large due to the amount of data contained. Unavoidable i’m afraid, because separation of data, and people unable to connect it in their head, is the reason this has been able to go on for so long. Complexity offers secrecy. So an overview in one picture that tracks and highlights USD flows (into Tether mainly) offers clarity.</figcaption></figure>



<p>BUSD same thing. HUSD same thing. </p>



<p><em>THEY’RE ALL IN ON IT!</em></p>



<p>Coinbase is the entry gate. Kraken is the side-door to make sure people can still “travel” in and out of the crypto space; The main objective is to keep the majority of the people inside of the Hotel California. Only when they go for the exits in large enough numbers does the scam collapse.</p>



<p>Huobi handles the Asian market. Binance increases demand for Tether and other stablecoin by offering *insane* gains…. Which always materialize because Bitfinex can just print Tethers and hand them over to Binance. There have been many Whale Alerts on Twitter that show as much.</p>



<p>The final piece of evidence for this is the fact that Coinlib shows USD flows between Tether and USD: https://coinlib.io/exchange/kraken</p>



<p>But Tether shows NO flows between It and USD: https://coinlib.io/coin/USDT/Tether</p>



<p>Once you’ve eliminated the impossible, whatever’s left, however improbable must be the truth:</p>



<p><em>There is no USD-USDT trading on Kraken going on. There is no link. People trading USDT-USD on Kraken are trading against Kraken’s personal account filled with Tether or USD. Like Bernie Madoff, who never made a single trade in his trading account during the entire scheme; It could very well be that Kraken has never made a single Tether-USD transaction in their entire existence.</em></p>



<p>While i can’t say anything about Bittrex or smaller exchanges… The big ones: Binance, Bitfinex, Kraken, Huobi and Coinbase are <strong><em><span>ALL</span></em></strong> guilty of <em>both</em> the largest Ponzi scheme, and the largest Dollar Counterfeiting scheme in history.</p>



<p><span>ALL THEIR OFFICES SHOULD IMMEDIATELY BE RAIDED, THEIR TRADING CEASED, AND THE MONEY RECOVERED AS BEST IT CAN BEFORE THEY, AND IT, <strong>COMPLETELY </strong>DISAPPEARS!</span><span></span></p>



<p><strong><span>THIS HAS GONE ON LONG ENOUGH!</span></strong></p>



<p>For more on USDC’s bad auditing i’ve gone deeper into it here: https://twitter.com/DesoGames/status/1352286552215461890</p>
		</div><!-- .entry-content -->
	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.desogames.com/proof-that-few-if-any-dollars-back-any-stablecoin-theyre-all-tether/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244840</guid>
            <pubDate>Wed, 24 Feb 2021 00:11:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dreamcast Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26244639">thread link</a>) | @swatson741
<br/>
February 23, 2021 | https://www.copetti.org/writings/consoles/dreamcast/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/dreamcast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="introduction">Introduction</h2><p>The Sega Dreamcast introduced many new features over its predecessor (the <a href="https://www.copetti.org/writings/consoles/sega-saturn/">Saturn</a>) to appeal to both game developers and console gamers. While this was Sega’s last attempt to conquer the console market, some of the technologies which were pioneered in the Dreamcast carried on and into future mainstream devices.</p><hr><h2 id="cpu">CPU</h2><p>Unsurprisingly, Sega chose Hitachi again to develop their CPU. If you’ve been reading the <a href="https://www.copetti.org/writings/consoles/sega-saturn/">previous article about the Sega Saturn</a> then, lo and behold, I present you the next generation of SH processor: the <strong>SH-4</strong> running at a whopping <strong>200 MHz</strong>. So, what’s interesting about this CPU?</p><ul><li><strong>5-stage pipeline</strong>: Up to five instructions can be in flight simultaneously (a detailed explanation can be found in a <a href="https://www.copetti.org/writings/consoles/sega-saturn/#cpu">previous article</a>).<ul><li>Instruction pipelining is now found everywhere in this generation of consoles and will be standard from now on.</li></ul></li><li><strong>2-way superscalar</strong>: A new type of parallelism where the CPU can process more than one instruction (two in this case) in each stage of the pipeline resulting in more instructions executed per second.</li><li>A dedicated <strong>Floating-Point Unit</strong> or ‘FPU’: Computes 32-bit decimal numbers (the <em>floats</em>) and 64-bit ones (the <em>doubles</em>).</li><li>8 KB <strong>instruction cache</strong> and 16 KB <strong>data cache</strong>: This ratio is rather curious since consoles tend to include more instruction cache than data cache. However, the SH-4 allows the data cache to be split into two sections: 8 KB of <em>Scratchpad</em> (fast RAM) and 8 KB of data cache.</li><li><strong>32-bit internal architecture</strong> while keeping a <strong>16-bit instruction set</strong> (the SuperH ISA): Just like the SH-2, this increases code density and decreases bus overheads while still enjoying the advantages of a 32-bit architecture.</li><li><strong>External 64-bit bus</strong>: Critical for manipulating 64-bit values (e.g. doubles and longs) without wasting extra cycles.</li></ul><p>The common chores of a game console CPU include handling a game’s logic, running the enemy AI and keeping the GPU fed with instructions. In the Dreamcast the SH-4 is also involved in the majority of the graphics pipeline, processing geometry data such as computing perspective transformations. As a result, it includes a <strong>128-bit SIMD</strong> unit that can accelerate vector operations.</p><h4 id="improving-memory-access">Improving memory access</h4><p>The CPU includes a dedicated <strong>Memory Management Unit</strong> or ‘MMU’ for virtual addressing, this is helpful since the physical memory address space of this CPU happens to be <strong>29 bits wide</strong>. So with the help of four TLBs, programmers can use 32-bit addresses without hitting performance penalties.</p><p>Since only 29 bits are needed for addressing, the extra three bits control memory protection, alternating the memory map and circumventing the cache, respectively.</p><p>The programmer decides whether to use these features or not. Games for this system certainly don’t necessarily <em>need</em> memory protection and the MMU has to be manually enabled at boot.</p><h4 id="no-uma-but">No UMA but…</h4><p>While this system is not designed around the strict Unified Memory Architecture like a <a href="https://www.copetti.org/writings/consoles/nintendo-64/#simplified-memory-access">well-known competitor</a>, it does delegate I/O access to the GPU. That means that if the CPU has to fetch anything that’s beyond its own dedicated RAM or a serial interface which is also connected too, it will have to request the GPU (and wait if necessary).</p><h4 id="special-queries">Special queries</h4><p>This CPU also features a unique functionality called <strong>Parallel I/O</strong> or ‘PIO’ that is used to manipulate multiple I/O locations at the same time. Sega wired up these pins so the CPU can manipulate the GPU’s <strong>video mode</strong> (more details about this later).</p><hr><h2 id="graphics">Graphics</h2><p>The GPU package is a custom-made chip called <strong>Holly</strong> running at 100 MHz, it’s designed by VideoLogic (now known as Imagination Technologies) and manufactured by NEC. Holly’s 3D core happens to be Videologic’s <strong>PowerVR2</strong> (also called ‘PowerVR Series2’ and ‘CLX2’).</p><div><div><a href="https://www.copetti.org/images/consoles/dreamcast/sonic.7ac25b5249c0cb720efdbc67493a675e8eb3b2e4c66827d94dc6efbb6b74bfb9.png"><picture><img name="image_cover" alt="Image" width="640" height="480" src="https://www.copetti.org/images/consoles/dreamcast/sonic.7ac25b5249c0cb720efdbc67493a675e8eb3b2e4c66827d94dc6efbb6b74bfb9.png" loading="auto"></picture></a><figcaption>Sonic Adventure (1999)</figcaption></div><p>VideoLogic chose an alternative approach for the construction of their 3D engine called <strong>Tile-Based Deferred Rendering</strong> or ‘TBDR’.</p><p>TBDR, instead of rendering a whole frame at once (as traditional <strong>Immediate Mode Renderers</strong> or ‘IMR’ do), divides the rendering area into multiple sections called ‘tiles’. Then, it carries out the rendering process on each tile individually and the result is combined to form the final frame.</p></div><p>This innovative design brings interesting advantages:</p><ul><li>It can be greatly <strong>parallelised</strong>, which significantly reduces bandwidth and power usage.</li><li>It implements a clever solution to the <a href="https://www.copetti.org/writings/consoles/sega-saturn/#an-introduction-to-the-visibility-problem"><strong>visibility problem</strong></a> by automatically sorting the polygons <strong>from front to back</strong> and then performing <a href="https://www.copetti.org/writings/consoles/nintendo-64/#modern-visible-surface-determination">z-tests</a> at the first stages of the pipeline. The combination of these tasks not only solves the original problem, but it also <strong>prevents overdraw</strong> (rasterisation of hidden polygons) which wastes resources, degrading performance.</li></ul><p>It’s no surprise that Imagination took this efficient technology forward to build the Series 4 PowerVR cores which powered an incredible number of devices, including the first generation of iPhone, the iPhone 3G, the Nokia N95 and the Dell Axim x51.</p><h4 id="architecture">Architecture</h4><p>Let’s take a look at the two main components of the Dreamcast’s GPU:</p><div><ul><li id="tab-1-1-tile-accelerator-link"><a href="#tab-1-1-tile-accelerator">Tile Accelerator</a></li><li id="tab-1-2-powervr2-core-link"><a href="#tab-1-2-powervr2-core">PowerVR2 Core</a></li></ul><div><div id="tab-1-1-tile-accelerator"><h4>Tile Accelerator</h4><div><a href="https://www.copetti.org/images/consoles/dreamcast/tile_accelerator.9053feea2290fbd15b5b73573d475a62df8b9a4c5b9751c2a3f0285f069aafe3.png"><picture><img name="image_cover" alt="Image" width="732" height="314" src="https://www.copetti.org/images/consoles/dreamcast/tile_accelerator.9053feea2290fbd15b5b73573d475a62df8b9a4c5b9751c2a3f0285f069aafe3.png" loading="auto"></picture></a><figcaption>Architecture of the Tile Accelerator</figcaption></div><p>Before the rendering process starts a component known as the <strong>Tile Accelerator</strong> performs pre-processing. It starts by allocating several 32x32 tile bins into which the geometry will be rendered.</p><p>Then the Tile Accelerator will:</p><ol><li>Grab the geometry data and drawing commands issued by the CPU (either using DMA or traditional transfers).</li><li>Compile this data into an <strong>internal format</strong>.</li><li>Distribute the geometry to each bin based on its coordinates. Clipped geometry will be discarded as well.</li><li>Generate the resulting Display Lists.</li></ol><p>These Display Lists will be interpreted by the 3D engine.</p></div><div id="tab-1-2-powervr2-core"><h4>PowerVR2 Core</h4><div><a href="https://www.copetti.org/images/consoles/dreamcast/powervr2.93b04ebea3c9921e543f6742c922ddb5e8ac0bf79f7fca2f70ad30a2f83f3ce1.png"><picture><img name="image_cover" alt="Image" width="687" height="396" src="https://www.copetti.org/images/consoles/dreamcast/powervr2.93b04ebea3c9921e543f6742c922ddb5e8ac0bf79f7fca2f70ad30a2f83f3ce1.png" loading="auto"></picture></a><figcaption>Architecture of the PowerVR2 Core</figcaption></div><p>Here is where the graphics are brought into life, the Display Lists received from the TA will be used to render the geometry of a single tile using an <strong>internal frame-buffer</strong>. The process is as follows:</p><ol><li>The <strong>Image Synthesis Processor</strong> or ‘ISP’ fetches the primitives (either triangles or quads) and performs <strong>Hidden-Surface Removal</strong> to remove unseen polygons. Then, after calculating its Z-buffers and stencil buffers, the data goes through <strong>Depth Testing</strong> to avoid rendering polygons that would appear behind others and <strong>Stencil Tests</strong> to cull geometry that won’t be visible if they are located behind a 2D polygon (also called <strong>Mask</strong>).<ul><li>Notice how these tests are effectively carried out at the start of the pipeline. In contrast previous consoles <a href="https://www.copetti.org/writings/consoles/nintendo-64/#modern-visible-surface-determination">using z-buffers</a> discard the geometry at the end of the pipeline. The ISP approach prevents processing the geometry that will eventually be discarded, thereby saving resources.</li></ul></li><li>The <strong>Texture and Shading Processor</strong> or ‘TSP’ applies colouring and shading over the tile area. It also provides multiple effects (more details later on).<ul><li>Textures are not applied until the tile is exported, meaning that emerging overdraw (if any) will not lower the fill rate.</li></ul></li></ol><p>After the operation is completed, the rendered tile is written to the main frame-buffer in VRAM. This process is repeated until all tiles are finished. Once complete the resulting frame-buffer is picked by the <strong>Video encoder</strong> and sent through the video signal.</p></div></div></div><h4 id="the-big-picture">The big picture</h4><p>Apart from the clear architectural difference, the Texture and Shading Processor comes with many capabilities that give one an idea of how distant this console is from the old <a href="https://www.copetti.org/writings/consoles/sega-saturn/">Saturn</a>. Here are a few:</p><ul><li><strong>Alpha blending</strong>: Combines colours of overlapping layers to achieve transparency effects.<ul><li>The process used for applying transparency in this system is called <strong>order-independent transparency</strong>. The algorithm automatically sorts the primitives before blending their colours, and while this slows down the rendering process, it avoids relying on the game itself to do all the sorting manually. For this reason, Dreamcast games excelled in displaying transparent objects.</li><li>Combined with the tile-based system, order-independent transparency completely addresses previous <a href="https://www.copetti.org/writings/consoles/sega-saturn/#the-transparency-issue">mishaps</a>.</li></ul></li><li><strong>Mip-Mapping</strong>: Automatically selects a scaled-down version of the texture depending on the level of detail required. This is done to prevent processing large textures that would be seen far away from the camera (which would be a waste of processing power and produce aliasing).</li><li><strong>Environment mapping</strong>: Applies reflections on textures.</li><li><strong>Bilinear, Trilinear and anisotropic filtering</strong>: These are different algorithms used to smooth the textures and prevent pixelation. They are ordered from ‘worst’ to ‘best’, where the resulting quality of each one is directly proportional to the amount of computation required.<ul><li>This is a huge step up from the Saturn since the former didn’t provide any texture filter!</li></ul></li><li><strong>Bump mapping</strong>: Simulates defects on surfaces without spending extra polygons.</li></ul><h4 id="gaining-detail">Gaining detail</h4><p>Holly can now draw ~10 times more polygons than <a href="https://www.copetti.org/writings/consoles/sega-saturn/">its predecessor</a>, here’s a <em>Before &amp; After</em> example that shows how model designs are not that limited any more. Try to fiddle with them!</p><h4 id="video-modes">Video Modes</h4><p>The video system was designed to support multiple types of screens and formats, thus the video encoder outputs to a single-shaped socket that supports the following type of signals:</p><ul><li><strong>Composite</strong>: Combines the three signals needed to display video (chroma, luma and sync) into a single one, requiring only a single-pin cable.<ul><li>This is used on old PAL and NTSC TVs with an RCA connection.</li></ul></li><li><strong>S-Video</strong>: Combines luma and sync while keeping chroma separated (two video lines in total).</li><li><strong>RGB</strong>: Sends separate Red-Green-Blue signals and provides different sync types to choose from (composite sync or extracted from video composite or S-Video).<ul><li>A SCART cable will use this type.</li></ul></li><li><strong>VGA</strong>: Combines RGB with two special sync signals (horizontal and vertical) resulting in five video lines in total. This enables to display the biggest resolution possible (720x480) in progressive mode (thus, this mode is often named ‘480p’). VGA has actually been the standard format/medium used by computer monitors for some time.<ul><li>To use this type, Sega provided a VGA adapter as an extra accessory.</li></ul></li></ul><p>Now, the Dreamcast can’t encode all of these at the same time, so the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/dreamcast/">https://www.copetti.org/writings/consoles/dreamcast/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/dreamcast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244639</guid>
            <pubDate>Tue, 23 Feb 2021 23:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH Certificates Security Hardening]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26244131">thread link</a>) | @twakefield
<br/>
February 23, 2021 | https://goteleport.com/blog/ssh-certificates | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/ssh-certificates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-security.png" width="100%" alt="SSH Certificates Security"></p>

<h2 id="ssh-access-hardening">SSH Access Hardening</h2>

<p>SSH certificates, when deployed properly, improve security.
A half-baked access system using certs is more vulnerable than a public-key-based one if a user or host gets hacked.</p>

<p>SSH is hard. Our team learned this at Rackspace, a large managed hosting and cloud provider.
We started with deploying public keys to every server. We added a jump server with a second factor login to prevent
hacks using stolen keys. Soon, infosec team asked us to log into a web portal to match SSH logins with emails.
Evolution does not produce the most efficient result, and our system did not turn out great either.
We were missing keys on some servers and found stale keys on others.
No one liked login screens popping up multiple times a day.
We received only one one-time password token, and some folks pointed their home webcam to it.</p>

<p>In 2015 we left Rackspace to build <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> — a unified access plane
for infrastructure, and we started with SSH. We chose SSH certificates as the main cryptography engineering primitive. Since then our customers and open source users have deployed Teleport at most impressive systems, and Teleport went through
several security audits.</p>

<p>I would like to share some of the lessons we learned with you.
We will start with the SSH authentication basics, dig into SSH certificates
and learn what it takes to build a secure SSH certificate-based authentication.</p>

<h3 id="ssh-public-key-authentication">SSH Public Key Authentication</h3>

<p>An SSH public key is distributed openly, and anyone holding it can verify messages
signed using its private key counterpart.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-auth.png" width="100%" alt="SSH Public Key Authentication"></p>

<p>An SSH server generates a random string — a challenge — and asks a client to sign it.
The server verifies clients’ signature to prove that the client has the private key associated with
the trusted public key. Here is how it looks on the wire:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-protocol.png" width="100%" alt="SSH Public Key Challenge"></p>

<p>Public keys constitute a solid way to authenticate and are used to secure both Web and SSH.</p>

<p>The problems with public key authentication are caused by key management: trust on first use (a.k.a. TOFU)
and rotating and revoking trusted public keys.</p>

<h3 id="trust-on-first-use">Trust On First Use</h3>

<p>When an SSH connection is first established, an SSH server sends its public key to identify
itself to a user.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-auth.png" width="100%" alt="SSH Host Authentication"></p>

<p>The user can accept the public key offered by the SSH server and assume that the host is trusted
if the user connects to it first time. This authentication scheme is called “trust on first use” or TOFU.</p>

<p>If the host’s IP, name or public key change, the user can no longer trust this combination
of the hostname, the IP and the public key.</p>

<p>The user sees a scary warning.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-tofu.png" width="100%" alt="SSH TOFU"></p>

<p>The user can alert security folks or ignore the warning by removing the old key.
For cloud environments, however, an IP address and a hostname can be
reused many times. Users learn to ignore those warnings, because there is no way to learn whether it’s an attack or an IP or a hostname change. Let’s call it TOFU fatigue.</p>

<h3 id="problems-with-public-keys">Problems With Public Keys</h3>

<p>A second problem of public keys for security is caused by complexities of public key distribution.
Imagine a deployment with 100 servers and 10 users, where every user has 2 public keys.
You have to build a system that distributes 20 user’s public keys on each server and
100 public keys to every user’s computer, and keep those up to date.</p>

<p>Directory services like LDAP are used to store user’s and host’s public keys.
Every host runs an agent that connects to an LDAP server and updates public keys.
Sysadmin folks have been deploying this Keycloak and FreeIPA pair for years.</p>

<p>This system breaks down at a small and a large scale. Sysadmins of small systems
rarely deploy key management software. It’s not worth setting up FreeIPA and Keycloak for 3 nodes.
They use tools like Ansible and end up with keys going out of sync when someone loses their key, computer, or leaves the company. Sometimes, let’s face it, there is no Ansible and everyone uses the same shared key.</p>

<p>Admins of large clusters learn that the system of moving the key around stops working beyond the 1K nodes or 100 users mark —
there are just too many keys to keep track of.</p>

<h2 id="ssh-certificates">SSH Certificates</h2>

<p>SSH certificates are built using public keys and don’t offer anything extra from a cryptography engineering standpoint.</p>

<p>A certificate authority (CA) is a trusted party that holds its own public and private key pair.
SSH CA keys are used to sign user and host SSH certificates.
An SSH certificate consists of fields signed by the certificate authority.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-certificate.png" width="100%" alt="SSH Certificate"></p>

<p>Clients cannot modify these fields without breaking the signature.</p>

<p>SSH certificate authentication extends public-key-based auth and uses the same protocol messages.
In addition to verifying the public key signature, SSH server will check whether
the certificate is signed by the trusted certificate authority.</p>

<h3 id="solving-the-tofu-problem">Solving the TOFU Problem</h3>

<p>Clients use metadata in SSH certificates to verify host identities too.
When an SSH connection is established, a host sends a signed SSH certificate to a client to verify
the host’s identity. The host’s certificate is signed by a trusted CA.
It includes information about the hostname, and has an expiration date.
Here Alice checks if she can trust the host’s cert:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-certs.png" width="100%" alt="SSH Host Certificates"></p>

<p>As an extra precaution, SSH clients check if the hostname or the IP matches the certificate.
It makes it harder for a malicious host to impersonate another host.
If the signature check has failed or the CA is not trusted, either a serious misconfiguration
has happened or someone is attempting a man-in-the-middle attack.</p>

<p>Even if the public key of the host has been changed because the hostname has been reused in a cloud environment
during instance re-provisioning, the certificate will still match; there will be no conflict between different
public keys.</p>

<p>Sysadmins can replace the complex system of moving hundreds of public keys around
with two files — a host and a user SSH certificates’ authority public keys.
But in practice if we had stopped at this point, we would have made SSH security much, much worse.</p>

<h3 id="compromised-users-and-hosts">Compromised Users and Hosts</h3>

<p>If a user or a host gets compromised, we have to revoke their certs.
We are back to building a system of keeping track and distributing revocation lists to users and hosts.
Even worse, if a private key of a SSH user or a host certificate authority gets compromised,
all users and hosts certificates have to be invalidated and reissued.</p>

<p>This realization hits at the worst possible moment — when someone is hacked, there is no time to waste.
Time works against us because with every issued cert, the potential for compromise
increases. At least with public keys, we test the rotation on a regular basis. Revocation is so rare,
that it could be broken for all this time and no one would notice. This problem reminds me of backup restore —
you either test backup and restore regularly, or all bets are off.</p>

<h2 id="making-time-work-for-you">Making Time Work for You</h2>

<p>There is one trick that makes time work in favor of security.
SSH certificates include an optional expiry date that can be verified
by a server in addition to a signature.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-short-lived.png" width="100%" alt="SSH Short Lived Certs"></p>

<p>Organizations ca issue certificates that are good for a few hours before they auto-expire
without any action. The shorter the duration for these certificates, the better.
Ideally, certs should be issued only for the duration of a session.
In practice, several hours or the duration of the workday are OK too.</p>

<p>Instead of distributing revocation lists, we can rely on time to do the job for us.</p>

<h3 id="user-certificates-and-sso">User Certificates and SSO</h3>

<p>How would users get a short-lived certificate? The best way is to use SSO
with GitHub, Okta or any other identity provider and get a cert.
Teleport opens login screen, issues a cert and delivers it back to a user’s computer:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-sso.png" width="100%" alt="SSH certs SSO"></p>

<p>Here is an example of Teleport’s CLI tool <code>tsh</code> issuing a certificate
based on my GitHub credentials.</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>The cert is valid for 12 hours and has my GitHub identity encoded in it.</p>

<h2 id="rotate-ca-keys">Rotate CA Keys</h2>

<p>An attacker getting access to a private key of a certificate authority can impersonate
any user or host. That’s why admins store CA private keys in the most secure place possible.
What happens if a user, a host, or a CA gets compromised? You’d need to replace certificate authority
and reissue all certs for hosts and users. Any system dealing with certs should support this out of the box.</p>

<p>Take a look at how I rotate a user CA in less than a minute with Teleport:</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>With user certificate authority updated, all certificates issued by the old CA become invalid.
It’s not a problem if you use SSO; users have to re-login to get new certs.
The same command rotates hosts CA as well. Instead of waiting for the compromise
to happen, we should be rotating certificate authorities every day turning
them from a precious secret to a replaceable commodity. Here again, time
will work in our favor, not against us.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>Use certs with caution, and beware of long-lived certificates. Rotate your CA regularly
and use SSO to get user certs. And maybe, give <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> a try.</p>


        
        
        <p><strong>Related Posts</strong></p>
          <ul>
            
            <li><a href="https://goteleport.com/blog/how-to-ssh-properly/">How to SSH Properly | SSH Security Best Practices</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-handshake-explained/">SSH Handshake Explained | What is SSH Handshake?</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-restricted-shells/">Restricted Shell | Restricted commands for SSH</a></li>
            
          </ul>
        

        
        
        <a href="https://goteleport.com/tags/ssh/">ssh</a>
        
        <a href="https://goteleport.com/tags/teleport/">teleport</a>
        
        <a href="https://goteleport.com/tags/security/">security</a>
        

      
      
      &nbsp;
      </article></div>]]>
            </description>
            <link>https://goteleport.com/blog/ssh-certificates</link>
            <guid isPermaLink="false">hacker-news-small-sites-26244131</guid>
            <pubDate>Tue, 23 Feb 2021 22:55:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture of the Playstation 2]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26243964">thread link</a>) | @biwasa
<br/>
February 23, 2021 | https://www.copetti.org/writings/consoles/playstation-2/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/playstation-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The Playstation 2 was not one of the most powerful consoles of its generation, yet it managed to achieve a level of popularity unthinkable for other companies.</p><p>This machine is nowhere near as simple as the <a href="https://www.copetti.org/writings/consoles/playstation/">original Playstation</a> was, but we will see why it didn’t share the same fate of <a href="https://www.copetti.org/writings/consoles/sega-saturn/">previous complicated consoles</a>.</p><hr><h2 id="cpu">CPU</h2><p>At the heart of this console we find a powerful package called <strong>Emotion Engine</strong> or ‘EE’ designed by Sony and running at <strong>~294.91 MHz</strong>. This chipset contains multiple components, one of them being the main CPU. The rest are at the CPU disposal to speed up certain tasks.</p><h4 id="the-leader">The leader</h4><p>The main core is a <strong>MIPS R5900-compatible</strong> CPU with lots of enhancements. This is the first chip that starts executing instructions after the console is turned on. The processor provides the following features:</p><ul><li><strong>MIPS III ISA</strong>: A 64-bit RISC instruction set. <em>Wait, is it me or this is the same ISA found on a <a href="https://www.copetti.org/writings/consoles/nintendo-64/#cpu">competitor’s console</a>?</em>. Not quite, Sony enhanced the ISA by adding some instructions from <strong>MIPS IV</strong> (prefetch and conditional move) along with their own SIMD extension called <strong>multimedia instructions</strong>.</li><li><strong>32 128-bit extra registers</strong>: Another enhancement. They are better managed using multimedia instructions and are very useful for vector processing.<ul><li>These registers are accessed through a 128-bit bus, while the rest of the CPU uses an internal 64-bit bus.</li></ul></li><li><strong>2-way superscalar</strong>: Up to two instructions are executed in parallel.</li><li><strong>24 KB L1 cache</strong>: Divided into 16 KB for instructions and 8 KB for data.<ul><li>It also implements a <strong>prefetch function</strong> to cache instructions and data before they are requested. This is done by including extra circuitry that can identify which places in memory are more often requested.</li></ul></li><li><strong>16 KB of Scratchpad RAM</strong>: Also known as ‘Fast RAM’.</li><li><strong>Memory management unit</strong>: Interfaces memory access with the rest of the system.</li></ul><p>The core is complemented with a <strong>dedicated floating point unit</strong> (identified as ‘COP1’) that accelerates operations with 32-bit floating point numbers (also known as <code>floats</code> in C).</p><h4 id="a-recognisable-memory-choice">A recognisable memory choice</h4><p>Next to the Emotion Engine are two blocks of 16 MB of RAM, giving a total of <strong>32 MB</strong> of main memory. The type of memory used is <strong>RDRAM</strong> (<a href="https://www.copetti.org/writings/consoles/nintendo-64/#ram-available"><em>déjà vu!</em></a>) which is accessed through a 16-bit bus.</p><div><div><a href="https://www.copetti.org/images/consoles/ps2/MemoryArch.b34c74b38be1ed34237a641ee12d48fafbb98ad28688c4ebb79fc723d8e0ab24.png"><picture><img name="image_cover" alt="Image" width="605" height="269" src="https://www.copetti.org/images/consoles/ps2/MemoryArch.b34c74b38be1ed34237a641ee12d48fafbb98ad28688c4ebb79fc723d8e0ab24.png" loading="auto"></picture></a><figcaption>Memory design of the Emotion Engine<br>You can guess where the congestion is gonna appear</figcaption></div><p>At first, this can be a little disappointing to hear, considering the internal bus of the Emotion engine is as wide as 128 bits. However, the RAM chips are strategically placed by following the <strong>dual-channel architecture</strong>, which consists in connecting both chips using two independent 16-bit buses (one bus per chip) to improve data throughput. The resulting setup provides a theoretical 3.2 GB/sec, so rest assured that memory latency is not an issue in this console!</p></div><p>At one corner of the Emotion engine there is a powerful <strong>DMA Controller</strong> or ‘DMAC’ that transfers data between main memory and Scratchpad; or between main memory and any component inside the EE.</p><p>Data transfers are done in batches of 128-bits, but here is the interesting part: Every eight batches, the main bus is temporarily unlocked. This leaves a small window to perform other DMA transfers in parallel (up to ten) or let the CPU use the main bus. This <em>modus operandi</em> is called <strong>slice mode</strong> and is one of the many modes available on this DMA unit. Bear in mind that while slice mode reduces stalls on the main bus, it does so at the cost of slowing down the overall DMA transfer.</p><h4 id="preventing-past-mishaps">Preventing past mishaps</h4><p>Whether we want it or not, with the amount of traffic happening inside the Emotion Engine, this design will eventually suffer the consequences of the <strong>Unified memory architecture</strong> or ‘UMA’. That is… multiple independent components trying to access main memory at the same time, causing congestion. Well, to correct these issues, Sony alleviated the constant need for memory by:</p><ul><li>Wrapping their processors with <strong>lots of cache</strong>. Thus, only requiring access to main memory if absolutely necessary.<ul><li>99% of cache/scratchpad mentions in this article will be for this reason.</li></ul></li><li>Adding a 128-byte <strong>Write Back Buffer</strong>: Very similar to the <a href="https://www.copetti.org/writings/consoles/gamecube/#ibms-enhancements">Write Gather Pipe</a>, but instead of waiting until it’s 25% full, it will check the state of the bus (i.e congested or free) first.</li></ul><p>This sounds very convenient for applications that can benefit from cache, but what about those tasks, such as manipulating Display Lists, which shouldn’t use cache at all? Luckily, the CPU provides a different memory access mode called <strong>UnCached</strong>, which <strong>only</strong> uses the Write Back Buffer. Thus, it will not waste cycles correcting the cache (product of <em>cache misses</em>).</p><p>Furthermore, the <strong>UnCached accelerated mode</strong> is also available. This one adds a buffer for speeding up read of continuous addresses in memory.</p><h4 id="other-interesting-bits">Other interesting bits</h4><p>Inside the same Emotion Engine package, there is yet-another processor called <strong>Image Processing Unit</strong> or ‘IPU’, this time designed for <strong>image decompression</strong>. The IPU can be useful when a game needs to decode an MPEG2 movie without jamming the main CPU.</p><p>Long story short, the game sends compressed image streams to the IPU (hopefully using DMA) which is then decoded in a format that the GPU can display. The PS2’s operating system also relies in the IPU to provide DVD playback.</p><p>Finally, the IPU also operates compressed <strong>High-resolution textures</strong>, which saves CPU usage and reduces large transfers.</p><hr><h2 id="co-cpus">Co CPUs</h2><p>It’s been two years since the rivals presented their <a href="https://www.copetti.org/writings/consoles/dreamcast/">latest offering</a>. If you read the former article and just started reading this one, I presume you are <em>still</em> waiting for ‘the thing’ that makes the PS2 as powerful as it seemed back then. Now, let me introduce a <em>very</em> important set of components Sony fitted in the Emotion Engine, the <strong>Vector Processing Units</strong> or ‘VPU’.</p><p>A Vector Processing Unit is a small independent processor designed to operate vectors. In particular, vectors made of four <code>floats</code>. These processors are so fast that they only spend only <strong>one cycle per operation</strong>, which can be extremely convenient for geometry processing.</p><p>VPUs are made of the following components:</p><ul><li>Some <strong>Vector Unit Memory</strong> or ‘VU Mem’: Used as a working space for the Vector unit. It stores values needed to be operated and/or the results of previous operations.</li><li>A <strong>Vector Unit</strong>: The core of the processor. It contains some memory (called <strong>Micro Memory</strong>) to store a program (called <strong>Microprogram</strong>) which instructs the unit on how to operate the data found in ‘VU Mem’.<ul><li>It implements a <strong>64-bit ISA</strong> and the execution unit is <strong>split into two parallel sub-units</strong>. The first one multiplies or adds floats, while the other one divides floats or operates integers. This enables to operate both floats and integers <strong>concurrently</strong>.</li></ul></li><li>A <strong>Vector Interface</strong>: Automatically decompresses vertex data coming from main memory in a format the Vector unit can understand. This unit can also transfer microprograms to Micro Memory.</li></ul><p>To start working, the vector unit needs to be ‘kickstarted’. For this, the main CPU is in charge of supplying the microcode.
There are <strong>two VPUs</strong> fitted in the Emotion engine, but they are arranged differently, giving way to different uses and optimisations.</p><div><ul><li id="tab-1-1-vector-processing-unit-0-link"><a href="#tab-1-1-vector-processing-unit-0">Vector Processing Unit 0</a></li><li id="tab-1-2-vector-processing-unit-1-link"><a href="#tab-1-2-vector-processing-unit-1">Vector Processing Unit 1</a></li></ul><div><div id="tab-1-1-vector-processing-unit-0"><h4>Vector Processing Unit 0</h4><div><a href="https://www.copetti.org/images/consoles/ps2/VU0.300aa8f5034941872e5a56f84ab61dfa3f3b2c71ede208b85d7edc99e6dd38a5.png"><picture><img name="image_cover" alt="Image" width="881" height="429" src="https://www.copetti.org/images/consoles/ps2/VU0.300aa8f5034941872e5a56f84ab61dfa3f3b2c71ede208b85d7edc99e6dd38a5.png" loading="auto"></picture></a><figcaption>Architecture of VPU0</figcaption></div><p>The first VPU, the <strong>VPU0</strong>, is positioned between the CPU and the other vector unit (VPU1). It provides an ‘assisting’ role to the main CPU.</p><p>The VPU0 has two modes of operation:</p><ul><li><strong>Micromode</strong>: This is the ‘traditional mode’. The VPU will independently execute ‘microinstructions’ from a microprogram stored in Micro memory.</li><li><strong>Macromode</strong>: The VPU0 becomes the ‘COP2’ of the main CPU and executes ‘macro-instructions’, received from the main CPU through a dedicated 128-bit bus.<ul><li>Macro-instruction have the same functionality of microinstructions but use different opcodes. Nonetheless, the VPU execution unit is no longer split (meaning it can only execute one instruction at a time).</li><li>While this mode doesn’t make full utilisation of all the components of the VPU0, it still speeds up the CPU’s vector operations. Moreover, in terms of simplicity, a co-processor is easier to program than an independent unit (something PC programmers will find helpful).</li></ul></li></ul><p>The memory map of the VPU0 also has access to some of the other VPU’s registers and flags, presumably to check its state or quickly read the results of some operations done by the other VPU.</p></div><div id="tab-1-2-vector-processing-unit-1"><h4>Vector Processing Unit 1</h4><div><a href="https://www.copetti.org/images/consoles/ps2/VUP1.a655cb236515c27f56d7d883e367c54381a35a4a08cd177165d92e443454087e.png"><picture><img name="image_cover" alt="Image" width="822" height="431" src="https://www.copetti.org/images/consoles/ps2/VUP1.a655cb236515c27f56d7d883e367c54381a35a4a08cd177165d92e443454087e.png" loading="auto"></picture></a><figcaption>Architecture of VPU1</figcaption></div><p>The second VPU found, the <strong>VPU1</strong>, is an enhanced version of the VPU0 with double the amount of micro memory and VU memory. Moreover, this unit includes an additional component called <strong>Elementary function unit</strong> or ‘EFU’ which speeds up the execution of exponential and trigonometric functions.</p><p>The VPU1 is located between the VPU0 and the Graphics Interface (the ‘gate’ to the GPU), so it includes additional buses to feed the geometry to the GPU as quickly as possible and without using the main bus.</p><p>On the other side and due to its location, the VPU1 <strong>only operates in micromode</strong>.</p><p>It’s obvious that this VPU was designed for trigonometric operations, and may serve as a pre-processor for the GPU. Hence, it’s often put in charge of delivering the famous Display Lists.</p></div></div></div><h4 id="infinite-worlds">Infinite worlds</h4><p>A useful approach that can be exploited with these units is <strong>procedural generation</strong>. In other words, instead of building the scene using hard-coded geometry, let the VPUs generate it using algorithms. In this case, the VPU computes <strong>mathematical functions to produce the geometry</strong> which is then interpreted by the GPU (i.e. triangles, lines, quadrangles, etc) and ultimately used to draw the scene.</p><p>Compared to using explicit data, procedural content is ideal for parallelised tasks, it frees up bandwidth, requires very little storage and it’s dynamic (programmers can set parameters to achieve different results). There are certain areas that can highly benefit from this technique:</p><ul><li><strong>Complex surfaces</strong> (e.g. spheres and wheels).</li><li><strong>World rendering</strong> (e.g terrains, particles, trees).</li><li><strong>Bezier curves</strong> (a very popular equation in computer graphics which is used to draw curves), …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/playstation-2/">https://www.copetti.org/writings/consoles/playstation-2/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/playstation-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243964</guid>
            <pubDate>Tue, 23 Feb 2021 22:41:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Your Own React]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26243760">thread link</a>) | @autoditype
<br/>
February 23, 2021 | https://pomb.us/build-your-own-react/ | <a href="https://web.archive.org/web/*/https://pomb.us/build-your-own-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><pre><code><div><p><span>function</span><span> </span><span>createElement</span><span>(</span><span>type</span><span>,</span><span> props</span><span>,</span><span> </span><span>...</span><span>children</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      children</span><span>:</span><span> children</span><span>.</span><span>map</span><span>(</span><span>child</span><span> </span><span>=&gt;</span></p></div><div><p><span>        </span><span>typeof</span><span> child </span><span>===</span><span> </span><span>"object"</span></p></div><div><p><span>          </span><span>:</span><span> </span><span>createTextElement</span><span>(</span><span>child</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>createTextElement</span><span>(</span><span>text</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>function</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    fiber</span><span>.</span><span>type </span><span>==</span><span> </span><span>"TEXT_ELEMENT"</span></p></div><div><p><span>      </span><span>?</span><span> document</span><span>.</span><span>createTextNode</span><span>(</span><span>""</span><span>)</span></p></div><div><p><span>      </span><span>:</span><span> document</span><span>.</span><span>createElement</span><span>(</span><span>fiber</span><span>.</span><span>type</span><span>)</span></p></div><div><p><span>  </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> </span><span>{</span><span>}</span><span>,</span><span> fiber</span><span>.</span><span>props</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isEvent</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> key</span><span>.</span><span>startsWith</span><span>(</span><span>"on"</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isProperty</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>  key </span><span>!==</span><span> </span><span>"children"</span><span> </span><span>&amp;&amp;</span><span> </span><span>!</span><span>isEvent</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isNew</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>const</span><span> </span><span>isGone</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>!</span><span>(</span><span>key </span><span>in</span><span> next</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> prevProps</span><span>,</span><span> nextProps</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>        </span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isGone</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>      dom</span><span>[</span><span>name</span><span>]</span><span> </span><span>=</span><span> nextProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>  deletions</span><span>.</span><span>forEach</span><span>(</span><span>commitWork</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>wipRoot</span><span>.</span><span>child</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>commitWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>const</span><span> domParent </span><span>=</span><span> fiber</span><span>.</span><span>parent</span><span>.</span><span>dom</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"PLACEMENT"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>    domParent</span><span>.</span><span>appendChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"UPDATE"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"DELETION"</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    domParent</span><span>.</span><span>removeChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>fiber</span><span>.</span><span>sibling</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>let</span><span> nextUnitOfWork </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>function</span><span> </span><span>workLoop</span><span>(</span><span>deadline</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> </span><span>!</span><span>shouldYield</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    nextUnitOfWork </span><span>=</span><span> </span><span>performUnitOfWork</span><span>(</span></p></div><div><p><span>    shouldYield </span><span>=</span><span> deadline</span><span>.</span><span>timeRemaining</span><span>(</span><span>)</span><span> </span><span>&lt;</span><span> </span><span>1</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> wipRoot</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>performUnitOfWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>=</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span></p></div><div><p><span>  </span><span>const</span><span> elements </span><span>=</span><span> fiber</span><span>.</span><span>props</span><span>.</span><span>children</span></p></div><div><p><span>  </span><span>reconcileChildren</span><span>(</span><span>fiber</span><span>,</span><span> elements</span><span>)</span></p></div><div><p><span>    nextFiber </span><span>=</span><span> nextFiber</span><span>.</span><span>parent</span></p></div><div><p><span>function</span><span> </span><span>reconcileChildren</span><span>(</span><span>wipFiber</span><span>,</span><span> elements</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    wipFiber</span><span>.</span><span>alternate </span><span>&amp;&amp;</span><span> wipFiber</span><span>.</span><span>alternate</span><span>.</span><span>child</span></p></div><div><p><span>    index </span><span>&lt;</span><span> elements</span><span>.</span><span>length </span><span>||</span></p></div><div><p><span>    </span><span>const</span><span> element </span><span>=</span><span> elements</span><span>[</span><span>index</span><span>]</span></p></div><div><p><span>      element</span><span>.</span><span>type </span><span>==</span><span> oldFiber</span><span>.</span><span>type</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>element </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>oldFiber </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      oldFiber</span><span>.</span><span>effectTag </span><span>=</span><span> </span><span>"DELETION"</span></p></div><div><p><span>      oldFiber </span><span>=</span><span> oldFiber</span><span>.</span><span>sibling</span></p></div><div><p><span>      wipFiber</span><span>.</span><span>child </span><span>=</span><span> newFiber</span></p></div><div><p><span>      prevSibling</span><span>.</span><span>sibling </span><span>=</span><span> newFiber</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>&lt;</span><span>h1</span><span>&gt;</span><span>Hi </span><span>{</span><span>props</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>h1</span><span>&gt;</span></p></div><div><p><span>const</span><span> element </span><span>=</span><span> </span><span>&lt;</span><span>App</span><span> </span><span>name</span><span>=</span><span>"</span><span>foo</span><span>"</span><span> </span><span>/&gt;</span></p></div><div><p><span>const</span><span> container </span><span>=</span><span> document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>)</span></p></div><div><p><span>Didact</span><span>.</span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span></p></div></code></pre></div></div></div>]]>
            </description>
            <link>https://pomb.us/build-your-own-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243760</guid>
            <pubDate>Tue, 23 Feb 2021 22:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflecting on what it takes to raise $20M from A16Z]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26243152">thread link</a>) | @buf
<br/>
February 23, 2021 | https://www.siliconvict.com/reforge-a16z-round | <a href="https://web.archive.org/web/*/https://www.siliconvict.com/reforge-a16z-round">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-reforge-a16z-round"><p><span><span>Today, Reforge announced that we </span><span><a href="https://www.reforge.com/blog/weve-raised-21m-to-grow-reforge" target="_blank" rel="noopener noreferrer">raised $20M+ from a top VC firm</a></span><span>. I'd like to reflect a bit on that journey and some decisions made.</span></span></p><h2 id="block-d80e093b0fca4b29b133fbe410506ef0"><span id="d80e093b0fca4b29b133fbe410506ef0"></span><span><span>Founding Engineer</span></span></h2><p><span><span>I am the founding engineer at Reforge. "Founding engineer" just means that I take a lower salary than I would make in Facebook or Google in exchange for a large equity stake that vests over the period of generally 4 years. Sometimes this pays off, and "founding engineers" make millions or tens of millions of dollars in a short period of time. Most often, it doesn't.</span></span></p><p><span><span>I've been a founding or early engineer a few times. At </span><span><a href="https://www.eventbrite.com/" target="_blank" rel="noopener noreferrer">Eventbrite</a></span><span>, I was engineer #3, going from $4M to $700M in valuation. That turned out well.</span></span></p><p><span><span>
Additionally, I've started two companies, one of which was a 100% total loss, and a waste of 18 months of my life. I'll never get that time back, but I gained some perspective on identifying good opportunity. The other is doing okay at 500k users, but still too early to tell.</span></span></p><p><span><span>Which is a good segue for shit.</span></span></p><h2 id="block-89b8099e4a4743878b0cb9f2a93747be"><span id="89b8099e4a4743878b0cb9f2a93747be"></span><span><span>Why Join Reforge</span></span></h2><p><span><span>When I was considering joining Reforge, I had just started </span><span><a href="https://www.castingcall.club/" target="_blank" rel="noopener noreferrer">Casting Call Club</a></span><span>, and built it up to about 35k users. But, Reforge had a lot going for it on paper.</span></span></p><p><span><span><strong>Brian Balfour, ex-VP at Hubspot and 3 time startup founder, was at the helm.</strong></span></span></p><p><span><span>When I met Brian, I got the same butterflies in my stomach that I got when I met </span><span><a href="https://en.wikipedia.org/wiki/Kevin_Hartz" target="_blank" rel="noopener noreferrer">Kevin Hartz</a></span><span>, the founder at Eventbrite. Brian is a guy who simply knows his shit. The biggest successes I got in life was aligning my career journey temporarily to someone who knows their shit. You can't latch on forever because you'll never grow out of their shadow, but you can suck the experience out of them by getting as much 1-on-1 time with them as possible during the early days.</span></span></p><p><span><span>How do you know if someone knows their shit? First you have to know your own shit, and know where the gaps in your shit are. Fill the gaps in your shit with their shit. #RealTalk</span></span></p><p><span><span>For 2.5 years at Reforge, there would only be 5 people at the company (all of whom are incredible in their own right), and my opportunity to siphon off as much knowledge from Brian as I could would be abundant.</span></span></p><p><span><span><strong>The Reforge content was really fucking good.</strong></span></span></p><p><span><span>Brian had started the Silicon Valley Business Review with Andrew Chen (ex-VP Uber, now A16Z). They did a couple summer cohorts where they ran a program that taught the basics of what Growth is. Not Growth Hacking, or the disparate learnings of greasy bloggers looking to sell their guru courses. Brian and Andrew were offering a deep, comprehensive, foundational walkthrough of Growth, and they called it the Growth Series. This gave birth to Reforge.</span></span></p><p><span><span>When I caught whiff of what they were up to -- and realized how it was different, and far better, than the static and shallow MOOCs you'd find on Coursera and Udemy or the massive time-dump a 2-year degree was -- I knew there was real potential. Nothing out there could compare.</span></span></p><p><span><span><strong>The network is the moat.</strong></span></span></p><p><span><span>I was thinking about Harvard a lot when I was deciding to join Reforge. No one spends a quarter million dollars to go to Harvard just for the content they could get for free on the internet. They join Harvard for the network.</span></span></p><p><span><span>Reforge was already attracting leaders I looked up to, like Casey Winters, Fareed Mosavat, Elena Verna. They were the real market makers in tech, driving hundreds of millions in growth in companies like Instacart, Slack, Eventbrite, Miro, Survey Monkey, Mulesoft. A network like this would be hard to beat.</span></span></p><p><span><span><strong>Cohort-based learning in a huge TAM</strong></span></span></p><p><span><span>From my Techstars days, I knew that learning in cohorts was magic compared to learning things on your own. It feels like you're part of a band of individuals trying to overcome a challenge together, and it builds camaraderie. When my lizard brain finally made the connection that companies would pay for their employees to take Reforge as part of a group, the opportunity clicked.</span></span></p><p><span><span>For example, let's say Shopify has 50 product managers all speaking slightly different product management vernacular. Shopify sends them all to Reforge to build a common vocabulary and best base practices. That's step 1. Step 2: Shopify hires 5 more product managers per quarter. Guess what becomes a part of their onboarding?</span></span></p><p><span><span>Now multiply this by every tech company there is.</span></span></p><p><span><span><em>Okay, I'm convinced. I'll put Casting Call Club to the side and I'll join Reforge.</em></span></span></p><h2 id="block-8e34356f6940451bbed05f6442962ed8"><span id="8e34356f6940451bbed05f6442962ed8"></span><span><span>Early Problems</span></span></h2><p><span><span>Three problems nearly killed the business.</span></span></p><p><span><span><strong>How do you productize networking?</strong></span></span></p><p><span><span>There are lots of tools out there that help build communities, but nothing really felt right for us. </span></span></p><p><span><span>First, no one was talking. Either they were wary of competitors listening, or too busy with work itself, or simply afraid of looking stupid in front of a group of intellectual peers.</span></span></p><p><span><span>Second, we wanted to facilitate both surface and deep conversations at the same time while bubbling up valuable insights to relevant people in a relevant time. From there, we wanted to match people based on interests and relevancy.</span></span></p><p><span><span>After solving these by [redacted], the seasonal data was too few to have confidence in our findings, and so began our efforts to make learning always-on.</span></span></p><p><span><span><strong>Seasonality</strong></span></span></p><p><span><span>Seasonality was a challenge, because user engagement waned during the off-season, and our ability to experiment with new features was limited. But seasonality also gave us plenty of time to be pensive. We weren't going to be the kind of company that threw ourselves against the wall until we broke through. Early Reforge was all about careful cuts. We measured everything well, and it led to results that would've been hard-pressed if we were a venture capital backed startup then.</span></span></p><p><span><span>But our purely pensive days were numbered.</span></span></p><p><span><span>Imagine if your company makes millions of dollars in one week, twice per year, and you earn no other income. That was our lives for nearly 4 years at Reforge. Our program cohorts were doing so well that we didn't want to change it too much. We worried over price points, positioning, cannibalization, and we hesitated.</span></span></p><p><span><span>Another question started to rise: Did we need to scale? Is there happiness is building a small company that we don't have to turn into a billion dollar company? We spent a long time questioning this. We stayed heads down and optimized all we could.</span></span></p><blockquote id="block-2a8c25fa850047faac9ff35386165e75"><span><span>By 2019, there was only 5 people in the company and we were making mid 7 figures per year.</span></span></blockquote><p><span><span>Covid went </span><span><em>viral</em></span><span> (get it!?!) in the middle of one of our twice per year cash injections, and we survived the shrinking education budgets of our user's companies, but we were jolted. This was the main catalyst we needed to push Reforge into an always-on model and urge us to build our defenses. Furthermore, the clock was ticking on the Growth Series itself, as it would become a commodity eventually. Other edu-tech companies were sprouting up like mushrooms. It seemed like the time to switch to scale-mode was here at last. </span></span></p><p><span><span><strong>How to scale content creation?</strong></span></span></p><p><span><span>I'd describe Reforge content as encyclopedic; it's a deep collection of theory and application. Every new program took on average 6 months to create in the early days, but worse is that they were made almost entirely by Brian himself. If we were to scale Reforge, we would need to either build a machine that pumps out high quality content or clone Brian. My money was on cloning tech.</span></span></p><p><span><span>The subject matter experts tended to be busy, or poor teachers, or lack the audience to build clout for themselves. We couldn't depend on subject matter experts writing their own content.</span></span></p><p><span><span>We experimented with many things around this time to mitigate the content crunch -- microblogs, connection tools, interactive learnings. Nothing was as powerful as having quality content speak for itself.</span></span></p><p><span><span>Let's go back to shit. Remember above, about knowing shit?</span></span></p><p><span><span>Enter the researchers, whose job it was to interface with the subject matter experts and slowly separate shit from the shit. I'll spare you the tedious details since you're not interested in industry secrets.</span></span></p><p><span><span>After a few arduous cycles of having research-led program creation, the content wheel was spinning and we were ready to scale.</span></span></p><h2 id="block-6fd62f6a40484654b34cc0ff1098e56b"><span id="6fd62f6a40484654b34cc0ff1098e56b"></span><span><span>Scaling Eventbrite</span></span></h2><p><span><span>Being early at Eventbrite showed me the dopamine rush raising millions of dollars was. Teams would double overnight. Budgets would go from 0 to 7 figures. We'd get a dedicated ping-pong room.</span></span></p><p><span><span>Scaling fast also brought a lot of dangers. Communication is the first to go, and unless the pods have strong directional glue, there will be real pain to feel. Next, employee engagement would start to sway. Managers would hire people who spend more time figuring out how to hide than do actual work, and what's worse is that the managers don't give strong reprimand or simply fire the bad actors because the managers themselves would either hide or be too busy to spare the willpower to care. Lastly, HR will replace the ping-pong table with an Eventbrite University classroom, which is the greatest atrocity of them all.</span></span></p><p><span><span>Personally, I struggled scaling Eventbrite. I always volunteered to be on the frontier teams. We had no data team, so I raised my hand. We had no mobile apps, so I started the mobile team (while also learning how to build mobile apps). We couldn't support internationalization, so I co-led those efforts with the CTO as a skunkworks project. I tried my best to stay out of the politics, and into creating utility.</span></span></p><p><span><span>There's a famous saying though. If you want to lead, you must first learn how to follow. If you want to be a good writer, you must first be a good reader. If you want to scale a company, you need to have already done it before.</span></span></p><p><span><span>I think that's how it goes.</span></span></p><h2 id="block-1e54734985e54d1a9a7d0c935b125ac9"><span id="1e54734985e54d1a9a7d0c935b125ac9"></span><span><span>Scaling Reforge</span></span></h2><p><span><span>Reforge feels much different than Eventbrite. For starters, every person in a leadership position here has scaled a company in the past - Hubspot, Eventbrite, Airbnb, Credit Karma, Slack, Instacart - and that led us to create stronger foundations than Eventbrite had. Our strong directional glue on the leadership team alone is healthy, and it's fulfilling to see everyone align so well.</span></span></p><p><span><span>Looking at the engineering/product side of things, we've established a playbook for many of the challenges that we've seen in the past, like where the …</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.siliconvict.com/reforge-a16z-round">https://www.siliconvict.com/reforge-a16z-round</a></em></p>]]>
            </description>
            <link>https://www.siliconvict.com/reforge-a16z-round</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243152</guid>
            <pubDate>Tue, 23 Feb 2021 21:32:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modules, Monoliths, and Microservices]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26243079">thread link</a>) | @ash
<br/>
February 23, 2021 | https://tailscale.com/blog/modules-monoliths-and-microservices/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/modules-monoliths-and-microservices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Lately, I get people asking me when microservices are a good idea. In <a href="https://apenwarr.ca/log/20201227">systems design explains the world</a>, I talked about big-picture issues like second system effect, innovator’s dilemmas, and more. Can systems design answer the microservices question?</p>
<p>Yes, but you might not like the answers. First, we'll need some history.</p>
<h4 id="what-is-a-microservice">What is a microservice?</h4>
<p>You can find various definitions on the Internet. Here's mine: microservices are the most extreme possible backlash against <em>monoliths</em>.</p>
<p>Monoliths are what happen when you link everything your entire app needs into one giant program and deploy it as one big blob. Monoliths have a long history, going back to frameworks like CGI, Django, Rails, and PHP.</p>
<p>Right away, let's abandon the assumption that a monolith and a fleet of microservices are the only two options. There's a wide and nuanced continuum from "one giant service that does everything" to "infinite tiny services that each do nearly nothing."</p>
<p>If you follow fads, you'll have built a monolith at least once (whether on purpose or because that's what traditional frameworks encouraged you to do), then discovered some problems with monoliths, then heard that microservices are the answer, then started rearchitecting everything as microservices.</p>
<p>But don't follow fads. There are many points in between those extremes. One of them is probably right for you. A better approach starts with where you want to put your <em>interfaces</em>.</p>
<h4 id="boxes-and-arrows">Boxes and arrows</h4>
<p>An interface is the connection between <em>modules.</em> A module is a collection of related code. In systems design, we talk about "boxes and arrows" engineering: modules are the boxes, and interfaces are the arrows.</p>
<p>The deeper question then is: how big are the boxes? How much goes in each box? How do we decide when to split one big box into two smaller ones? What's the best way to connect the boxes? There are many approaches to all this. Nobody quite knows what's best. It's one of the hardest problems in software architecture.</p>
<p>Over the decades, we've evolved through many kinds of "boxes." <a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">Goto statements were "considered harmful"</a> largely because they prevented any hierarchy at all. Then we added functions or procedures; those are very simple boxes, with interfaces (parameters and return codes) between them.</p>
<p>Depending which branch of programming you go down, you then discover recursive functions, combinators, static function prototypes, libraries (statically or runtime-linked), objects (OOP), coroutines, protected virtual memory, processes, threads, JITs, namespaces, sandboxes, chroots, jails, containers, virtual machines, supervisors, hypervisors, microkernels, and <a href="https://en.wikipedia.org/wiki/Unikernel">unikernels</a>.</p>
<p>And that's just the boxes! Once you have boxes isolated from each other, then you need to connect them with arrows. For that, we have ABIs, APIs, syscalls, sockets, RPCs, filesystems, databases, message passing systems, and "virtualized hardware."</p>
<p>If you tried to draw a complete boxes-and-arrows diagram of a modern Unix system (which I won't), it would be wild: functions inside threads inside processes inside containers inside userspace, layered under a kernel, inside a VM, running on hardware in a rack in a datacenter in a cloud provider tied together by an orchestration system, and so on.</p>
<p>Each of those boxes at each of the abstraction layers is somehow isolated from and then connected to some of the others, at the same or other layers. Some are inside others. You couldn't draw an honest version of this picture in a mere two dimensions without lines criss-crossing hopelessly.</p>
<p>This all evolved over decades. Fancy people call it "path dependence." I call it a mess. And let's be clear: most of the mess no longer provides much value.</p>
<p>Instead of focusing on what became very ugly evolutionary results, let's talk about what people were <em>trying</em> to do while they invented all that stuff.</p>
<h4 id="the-quest-for-modularity">The quest for modularity</h4>
<p>The top-line goals of module systems are always the same:</p>
<ol>
<li>Isolate each bit of code from the other bits.</li>
<li>Re-connect those bits only where explicitly intended (through a well-defined interface).</li>
<li>Guarantee that bits you change will still be compatible with the right other bits.</li>
<li>Upgrade, downgrade, and scale some bits without having to upgrade all the other bits simultaneously.</li>
</ol>
<p>The computer industry spends an absolutely immense amount of time messing around, trying to find the perfect balance of all these modularity issues, while still trying to keep development as painless and easy as possible.</p>
<p>We are, in short, not succeeding.</p>
<p>By far the part we're worst at is #1, isolation. If we could truly and efficiently isolate one bit of code from another, the other goals would mostly fall into place. But we simply do not know how.</p>
<p>Isolation is a super hard problem. Goodness knows people have tried. Yet browser sandbox escapes still happen regularly, undetected privilege escalation attacks are simply assumed to exist on every OS, iOS still gets jailbroken periodically, DRM never works (for better or worse), virtual machines and containers regularly have vulnerabilities discovered, and systems like <a href="https://blog.alcide.io/insecure-by-default-kubernetes-networking">k8s have their containers configured insecurely by default</a>.</p>
<p>People have even been known to <a href="https://blog.cryptographyengineering.com/2013/02/04/attack-of-week-tls-timing-oracles/">figure out encryption keys on remote servers by sending well-timed packets</a> to them over the Internet. Meanwhile, the most spectacular isolation failures in recent memory were the <a href="https://meltdownattack.com/">Meltdown and Spectre attacks</a>, which allowed any program on a computer, even a javascript app in a web browser, to read the memory of other programs on the same computer, even across sandboxes or virtual machines.</p>
<p>Every new isolation technology goes through a cycle like the following, from optimism to despair:</p>
<ul>
<li>New idea: we'll finally get it right this time, once and for all!</li>
<li>Initial experiments seem to work.</li>
<li>(Users complain that it's even slower and more tedious than the last thing we tried.)</li>
<li>Early fatal flaws are discovered and fixed.</li>
<li>Widespread deployment.</li>
<li>Ever-more-subtle flaws are successively discovered and fixed.</li>
<li>Eventually, we find flaws that we simply don't know how to patch.</li>
<li>Lose hope that efficient isolation is even possible with this method.</li>
<li>But also we can never retire this isolation method because now too many people are depending on it.</li>
<li>Repeat.</li>
</ul>
<p>For example, at this point security people simply don't believe that any of the following (each one the very best technology available at the time) is totally safe:</p>
<ul>
<li>Process isolation and memory protection on a Unix system.</li>
<li>Privilege separation between OS processes when remote code execution ("RCE" for security people) is allowed.</li>
<li>Filtering syscalls to isolate a process.</li>
<li>Mutually untrusted processes sharing a CPU hyperthread.</li>
<li>Memory isolation between virtual machines on a CPU core.</li>
</ul>
<p>As far as I know, the state of the art, the very best isolation, is something like the Chrome sandbox or <a href="https://github.com/google/gvisor">gVisor</a>. The big browser vendors and cloud providers all use tools like these. The tools remain imperfect, but providers do chase down every new breach as fast as they can, and the rate of new flaws is fairly slow.</p>
<p>Isolation is better than it's ever been before… if you put all your isolation at the virtual machine (VM) level so that your cloud provider can do it for you because nobody else knows how, or updates often enough.</p>
<p>If you trust your cloud provider's VM isolation, you can have hope that all known problems are mitigated; but we have every reason to think more problems will be found.</p>
<p>That's… actually pretty good, all things considered. At least we have <em>something</em> that works.</p>
<h4 id="great-vms-for-everything">Great! VMs for everything!</h4>
<p>Well, hold on. Spinning up an isolated VM for every little module is a pain. And how big is a module?</p>
<p>Long ago, when Java first came out, the dream was that every line of every function in every object could have permissions enforced, even between objects in the same application binary, so that CPU-enforced memory protection wouldn't be needed. Nobody believes anymore that they can make that work. And marketing claims like "cloud functions" aside, nobody really thinks you should try.</p>
<p>None of the currently-known isolation methods work <em>perfectly</em>, but each of them works to <em>some approximation</em>. Increasingly skilled attackers, or increasingly valuable targets, require better and more annoying isolation. The best isolation we know right now is inter-VM sandboxing provided by tier-1 cloud providers. The worst, well, it goes down to zero.</p>
<p>Let's also assume, skipping over the evidence, that most systems are so tightly coupled that <strong>a reasonably skilled attacker can break through laterally between modules.</strong> So, for example, if someone can link a malicious library into your Go or C++ program, they can probably take control of that entire program.</p>
<p>Similarly, if your program has write access to a database, attackers can probably make it write <em>anywhere</em> in the database. If it can contact the network, they can probably contact <em>anywhere</em> in the network. If it can execute arbitrary Unix commands or system calls, they can probably get Unix root access. If it's in a container, they can probably break out of the container and into other containers. If malicious data can <a href="https://imagetragick.com/">crash the png decoder</a>, they can probably make it do anything else the decoder program is allowed to do. And so on.</p>
<p>An especially powerful form of attack is getting the ability to commit code, because that code will eventually be run on developer machines, and some developer or production machine somewhere probably has access to do what you want to do.</p>
<p>The above is maybe a little too pessimistic, but making those assumptions can help avoid overcomplicating your systems without improving actual security. In <a href="http://cr.yp.to/qmail/qmailsec-20071101.pdf">Some thoughts on security after ten years of qmail 1.0</a>, Daniel J. Bernstein points out (if I may heavily paraphrase) that many of the defenses he added in qmail, particularly isolating the different components from each other using chroot and different Unix uids, were not worthwhile and have never paid off.</p>
<p>Anyway, let's take it for granted that attackers with the ability to execute code can "usually" jump …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/modules-monoliths-and-microservices/">https://tailscale.com/blog/modules-monoliths-and-microservices/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/modules-monoliths-and-microservices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26243079</guid>
            <pubDate>Tue, 23 Feb 2021 21:26:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking a Stand in the War on General-Purpose Computing]]>
            </title>
            <description>
<![CDATA[
Score 262 | Comments 247 (<a href="https://news.ycombinator.com/item?id=26242991">thread link</a>) | @Funes-
<br/>
February 23, 2021 | https://cheapskatesguide.org/articles/war-on-gp-computing.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/war-on-gp-computing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/war-on-gp-computing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242991</guid>
            <pubDate>Tue, 23 Feb 2021 21:16:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multi-Factor Authentication for Developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26242969">thread link</a>) | @mooreds
<br/>
February 23, 2021 | https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>As more of our lives move online, multi-factor authentication (MFA) becomes increasingly important as a way of keeping our accounts secure. As a user, you know you should enable MFA on any accounts containing valuable data or which you want to keep safe.</p>

<p>As a developer or software engineer, MFA may seem a bit mysterious. This article will cover:</p>

<ul>
  <li>What MFA is</li>
  <li>Why it is important</li>
  <li>What factors are available</li>
  <li>When you might consider requiring MFA</li>
</ul>

<p>At the end, you should have a good understanding of options for integrating MFA into your applications, and how to start doing so.</p>

<h2 id="what-is-multi-factor-authentication-mfa">What is multi-factor authentication (MFA)?</h2>

<p>When a user is authenticating, they are providing proof of who they are. There are four broad categories of proof:</p>

<ul>
  <li>What the user knows. A password is an example.</li>
  <li>What the user has, such as a device.</li>
  <li>What the user is; one example would be a fingerprint.</li>
  <li>Where the user is, possibly ascertained by using GPS.</li>
</ul>

<p>Each of these methods of proof is called a ‘factor’. Factors must be kept secure. They should not be shared, in order to ensure that the authenticating user is associated with the correct account.</p>

<p>Multi-factor authentication is best understood as requiring two or more factors in order to authenticate a user. MFA is a superset of two factor authentication (2FA). With MFA an arbitrary number of factors of proof can be required. With 2FA, the number of factors is limited to two.</p>

<p>Multi-factor authentication isn’t just for online user accounts, though. If you are accessing a safe deposit box in a bank, you need a key (something you have) and a signature (something you are) or an id (another thing you have). However, this article will focus on online MFA.</p>

<p>The majority of user accounts have a password as a factor. You might be working in such a system right now. As engineering teams become more aware of the problem of user account hijacking and its real world consequences, more are allowing or requiring additional factors of authentication.</p>

<h2 id="why-use-multi-factor-authentication-mfa">Why use multi-factor authentication (MFA)?</h2>

<p>Building a secure, available system requires ensuring only authorized people and software agents have access to it. This is a foundational concern.</p>

<p>Authentication, which ensures that a system knows who the user is, and authorization, which controls what a given user can access, both play a role in building such a system. While you can control what an actor is doing without knowing who they are, it’s far more common to tie authentication and authorization together.</p>

<p>If your users have only one factor of authentication, it can be stolen, especially if it is a password. At that point, you as a developer will have limited ability to stop the thief. Your system will have to notice suspicious behavior to determine who is legitimate and who is not. This can be done, but is complex to do at scale. If you can’t determine illicit access, the thief will have the same privileges as the user whose stolen credentials are being used; they will be indistinguishable from that user.</p>

<p>Unfortunately, passwords are being stolen regularly. While systems can help prevent unauthorized access by <a href="https://fusionauth.io/learn/expert-advice/security/breached-password-detection/">detecting stolen passwords</a> and users can protect themselves by practicing good password hygiene, requiring another factor increases the obstacles to a bad actor.</p>

<p>In particular, if another factor is required as part of the login process, account security can increase dramatically. Microsoft researchers found that accounts are <a href="https://techcommunity.microsoft.com/t5/azure-active-directory-identity/your-pa-word-doesn-t-matter/ba-p/731984">“99.9% less likely to be compromised”</a> if MFA is used.</p>

<p>Implementing MFA is a partnership with your users, however. Some factors are easier for system developers to support. Others require more effort and care from users.</p>

<h3 id="the-balance-between-user-experience-and-security-risk">The balance between user experience and security risk</h3>

<p>However, though MFA is more secure, you shouldn’t require it everywhere. It’s a balance, like many parts of software engineering; you want to make the user login experience as smooth as possible while minimizing chances of account takeover. Users don’t love an application for the login experience. They want to solve their problems. Friction in the authentication process will annoy some percentage of your users and negatively affect your application’s success.</p>

<p>User experience isn’t only about how easy the factor is to use. It’s also about how widely deployed a solution is. If, say, retinal scanning is trivial to use, but users don’t have or can’t find the hardware, then it isn’t really that easy after all.</p>

<p>Listen to your users when considering factors. You don’t want them to circumvent MFA in ways that will damage system security. At the same time they may need to be educated. Do you know people who still write down passwords on sticky notes? I do.</p>

<p>As a developer, you need to balance between the user experience and the risk of account takeover. In some situations the call is easy. If your site lets users vote on cat pictures, MFA isn’t really required. If your site transfers money to arbitrary people, on the other hand, it should require MFA. These scenarios are at opposite ends of the security and user experience spectrum:</p>

<p><img src="https://fusionauth.io/assets/img/advice/mfa/security-ux-spectrum.svg" alt="More secure or easier to use?"></p>

<p>The hard part is the situations where the answer isn’t obvious. What are some situations where you should consider requiring multi-factor authentication?</p>

<h2 id="when-to-require-multiple-factors-of-authentication">When to require multiple factors of authentication</h2>

<p>There are many situations where you need a higher level of assurance about the actor behind the credentials. Sometimes the type of the user account is the deciding factor. Other times it is the access requested. Depending on your application and organization, legal requirements or corporate policies may control.</p>

<h3 id="administrative-accounts">Administrative accounts</h3>

<p>Privileged accounts with higher levels of access need to use MFA.</p>

<p>These administrator or operator accounts can wreak havoc if misused or compromised. Therefore you should require MFA on all admin accounts. In extremely sensitive systems, all changes could require providing additional factors.</p>

<h3 id="high-value-accounts">High value accounts</h3>

<p>There are also plenty of high value user accounts where MFA can help prevent unwanted account compromises. These accounts don’t necessarily possess elevated privileges, but allow data access or actions with real world consequences. Compromise of these accounts can have negative repercussions.</p>

<p>An example of such an account is an online bank account. You don’t want users to learn that someone drained their savings because of a stolen password.</p>

<p>Another example is an email account. Beyond the private information often present in email accounts, they represent a risk to accounts in other systems. Many password reset flows send an email to a known address and allow the recipient of that email to modify the password. Compromise of an email account means that any other accounts associated with this user are at risk.</p>

<h3 id="risky-actions">Risky actions</h3>

<p>When a user has already authenticated but is performing a dangerous action, MFA again provides extra security. This is also known as “step up auth”, because the additional factor is required at the moment a more privileged action is undertaken. Examples of such actions include:</p>

<ul>
  <li>Changing a password or username</li>
  <li>Modifying setting which impact other factors, such as an email or phone number</li>
  <li>Creating a new user with elevated privileges</li>
  <li>Changing system settings</li>
</ul>

<p>These types of actions can be legitimate, but could also be used by someone who has compromised a user account. You can partially mitigate the damage of a compromised account by implementing step up auth. An attacker may be able to access account data, but won’t be able to take damaging action.</p>

<h3 id="laws-or-organizational-policies">Laws or organizational policies</h3>

<p>If your application is used by certain organizations or stores personally identifiable information, you may need to require multi-factor authentication for users. As part of the NIST risk management framework, for example, Authenticator Assurance Level 2 requires: <a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-63-3.pdf">“proof of possession and control of two different authentication factors…”</a>.</p>

<p>Sometimes an MFA requirement is not explicit, however. If you are looking to be SOC2 certified, MFA may be required, even though the term is never mentioned in the <a href="https://www.aicpa.org/content/dam/aicpa/interestareas/frc/assuranceadvisoryservices/downloadabledocuments/trust-services-criteria.pdf">SOC “Trust Services Criteria”</a>. Section CC6.1 of the SOC document specifies “Persons, infrastructure, and software are identified and authenticated prior to accessing information assets, whether locally or remotely” without outlining implementation details. In this case, talk to your auditor about MFA requirements as well as other required controls.</p>

<p>When planning MFA, make sure you review any relevant laws, standards or corporate policies.</p>

<h3 id="when-the-users-actions-look-suspicious">When the user’s actions look suspicious</h3>

<p>An auth system has a unique viewpoint into who is signing in. Information is supplied and reviewed; it results in an answer to the question: “is the person providing this information the user who they are claiming to be?” Some data is provided by the user explicitly, such as the username and password. But every auth system has access to implicit data such as:</p>

<ul>
  <li>The date and time of access</li>
  <li>Connection information like the IP address, location, and user agent</li>
  <li>Whether this device has been used to access this service before</li>
  <li>How many times the user has logged in recently</li>
</ul>

<p>Such data can help determine if the person behind the authentication request is legitimate. For instance, if a user accesses a system from the USA but one day later there is a request from Germany with the same credentials, the request deserves scrutiny. It’s possible it is legitimate; after all, airplanes exist. But also possible that there is something nefarious going on in Germany.</p>

<p>Requiring MFA before access is allowed when suspicious activity occurs provides another check against stolen credentials. That German hacker could have acquired a user’s password, but it’s harder to steal a one time passcode sent to the user’s phone as well.</p>

<h2 id="commonly-used-factors-for-mfa">Commonly used factors for MFA</h2>

<p>Beyond a password, what are other ways a user can prove who they are? As mentioned above, there are four main categories.</p>

<ul>
  <li>What they know.</li>
  <li>What they have.</li>
  <li>Who they are.</li>
  <li>W…</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/">https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/learn/expert-advice/authentication/multi-factor-authentication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242969</guid>
            <pubDate>Tue, 23 Feb 2021 21:14:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new take on remote/hybrid standups]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26242959">thread link</a>) | @Ali_Jiwani
<br/>
February 23, 2021 | https://www.rally.video/post/stand-ups-suck-why-not-rally-instead | <a href="https://web.archive.org/web/*/https://www.rally.video/post/stand-ups-suck-why-not-rally-instead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Covid-19 forced everyone to start thinking remote first. Companies started to replace meetings with video calls and eventually questioning if the meeting was necessary. Work went from 'why is everything a meeting?' to "just send me an email/slack message'. Over the past few months we spoke to dozens of remote companies, and we learned that while many have reduced the number of meetings, some actually changed certain meetings to adopt to new technology and ways of working. One of the changes we saw most consistency was the standup - their most frequent and hated meeting.</p><p>In this post, we will talk about:</p><ul role="list"><li>Why do synchronous and asynchronous stand ups suck.</li><li>How the purpose of the stand up will change with the predominance of remote work.</li><li>The end of the traditional standup, and the beginning of a better alternative - a Rally.</li><li>How you can make your standup more like a Rally.</li></ul><h2>Why do synchronous and asynchronous stand ups suck?</h2><p>Standups were originally designed for agile engineering teams. With the world going remote, many companies outside engineering have adopted this practice as a way to update each other on daily progress. They may not call it standups, but the essence is the same.</p><p>The problem with standups is that they are a distraction, and it feels more beneficial to management than to the team. For people working together, standups often don't deliver any new information, and for those working apart, the information is seemingly useless. Standups are also set at weird times to accommodate for everyone across all timezones. That sucks because it takes you away from your work state for a meeting that feels pointless. Finally standups are used as a way for managers to keep track of their teams. Sometimes this is effective, other times it feels intrusive.</p><p>How about asynchronous standups? Surely this is a better solution as it gives everyone flexibility and it feels less likely like management is breathing down your neck. A quick google search on asynchronous standups also reveals similar problems to the standups. People don't care about the update, the context is usually missing, and there is no conversation around blockers. Ultimately asynchronous standups don't provide much value either.</p><p>As one user on Hacker News puts it "Going async sends a message that people don't need to care about what their team members are working on. That's a dream come true for the people who just want to pull Jira tickets out of the queue, finish them in isolation, and then collect a paycheque." And another chimes in "it doesn't make for great team cohesion and knowledge sharing. Teams end up compensating with extra meetings and coordination overhead, which starts to defeat the point of async standups."</p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314b54800c1961716bd82f_hn%20post.png" loading="lazy" alt=""></p><figcaption>Source: https://news.ycombinator.com/item?id=23194569</figcaption></figure><p>Is the answer then to cancel standups? Or to do some form of a hybrid async standup? Call me crazy, but what about extending the standup virtually and inviting a few more teams. Let's go back to first principles so I can explain why.</p><h2>How the purpose of the stand up will change with the predominance of remote work</h2><p>The original purpose of a stand up was to answer three questions:</p><ul role="list"><li>What was I working on yesterday?</li><li>What will I work on today?</li><li>What is blocking me or stopping me from success?</li></ul><p>The idea is to physically get off your chair, discuss the above three questions, and finish the meeting in roughly 15 mins. It is a meeting for the team, not for management.</p><p><em>Source: </em><a href="https://www.atlassian.com/agile/scrum/standups"><em>https://www.atlassian.com/agile/scrum/standups</em></a></p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314ba6f1c0b469307efa91_1_5L-pHXCmAl0GcryXyREF6A.jpeg" loading="lazy" alt=""></p><figcaption>Source: <a href="https://medium.com/@hans.bruins/the-standup-that-disrupts-the-workflow-78cb5b916bcb">https://medium.com/@hans.bruins/the-standup-that-disrupts-the-workflow-78cb5b916bcb</a></figcaption></figure><p>Standups also have an unintended benefit that is not talked about - it brings the team together. In a remote world, isolation is the number one complaint many employees have. Isolation leads to a decline in mental health, productivity, and overall well being. Isolation can also impact teams, where they feel left out from the rest of the company and are forced to have more meetings to play catch up. This is why so many people crave going back to the office. It's not for the meetings, it's for the people. Even the most introverted people have found isolation daunting.</p><p>The problem is this crucial benefit is overlooked in standups, and people start to resent this meeting. The way to solve this problem is to reframe the purpose of the meeting entirely, so much so that it may even warrant a new name, which we call a Rally.</p><h2>What is a Rally? And how will it replace the standup?</h2><p>A Rally is not a formal standup, it is a collaborative get together. Our Rallys are daily and they are 30 minutes long. The original idea came from one of our first engineering hires: Nate Wildermuth, and it's stuck ever since. We spend the first 20-25 minutes chatting, playing a game, or running an activity (see below for examples). Occasionally this leads to a great idea (such as this blog post!) or a tonne of laughs that builds some terrific momentum for the rest of the day. We then take the last 5-10 minutes discussing what we worked on, what we will work on, and any blockers we have. Usually by the time we are discussing work, we feel much more energized and ready to take on the day.</p><h3>"Standups are an endless series of trivia nights where everyone loses." Nate</h3><p>Of course, we use our own video software for these standups. This is because we designed Rally to allow multiple groups to have conversations in the same space. We call these groups 'tables', and we call the space a 'room'. It is easy to hop around to different tables to chat, or sit at a table in case someone needs to chat with you. We also have a stage where you can present to everyone in the room. This way we can let everyone know what we are working on if we needed. Luckily we're not the only ones that do this. We have a number of customers who have been using Rally for similar collaborative meetings. After speaking with them we have come up with a framework for how we think about Rallys, followed be some examples.</p><figure><p><img src="https://uploads-ssl.webflow.com/5f345c1d925d4f6201e2c2a9/60314aba2469e82b4aa034b1_Slide%204_3%20-%201.png" loading="lazy" alt=""></p><figcaption>How Rally Works</figcaption></figure><p>A Rally consists of:</p><ul role="list"><li>A recurring event lasting between 30 and 60 mins, few times a week.</li><li>The team running the event will invite close stakeholders. If the team is less than 50 in size, the entire company will attend.</li><li>People notifying who they want to talk to in advance so they can be efficient with their time, while managers keep an open table to allow anyone to talk to them if needed.</li><li>CEO's and senior execs are also in attendance and can choose to hop around tables to stay put and wait for questions.</li><li>Starting and/or ending with an activity or a game to get people excited.</li></ul><p>While we use Rally every day, we have customers that use Rally multiple times a week for different types of get togethers. We consider all of these to be offshoots of the daily Rally:</p><p>1. <strong>Collaboration Rally</strong>: An hour long session where each team member discusses what they are working on in their team, then hops around to other teams to eliminate blockers. The benefit of this is having everyone in one place instead of setting up extra 30 minute meetings and one on ones. To this successfully, one of our customers runs this meeting every Monday and Friday morning. Each team member prepares what they want to discuss, and reaches out to anyone they need to speak to. On average there are 3-4 cross company conversations lasting 10-20 mins each.Since this is a dedicated hour for everyone, people use this time to catch up on work and remove any blockers they have across the company. It is also a great chance to have everyone in one place. Here is an example of what that looks like:</p><figure></figure><p>2. <strong>Sprint Demo Rally</strong>: An hour long meeting where members from the engineering team hop between tables to present their work. The tables are formed of teams outside engineering so any stakeholder can keep up with engineering work. The meeting usually starts with a presentation from one of the leads to the entire room, and finishes with an activity or hangout in case people have questions.</p><figure></figure><p>3. <strong>Virtual Cafeteria Rally</strong>: An hour long daily meeting for anyone in the company to attend. The meeting is at a set time where someone opens up a Rally lunch room. Teams will jump into tables and enjoy lunch together, as they would in real life, or find friends at other tables to talk to. Instead of having multiple video calls for smaller teams, all the teams are in one place. This way they can hop around tables as they overhear interesting conversations. HR managers have also shuffled people into random tables as a way for people to meet each other.</p><figure></figure><h2>How can you change your standup into a Rally?</h2><p>Start by calling it a Rally and not a standup.</p><p>Reframe the purpose of the standup so its not purely about work but about catching up and hanging out as well.</p><p>Start the Rally with a game, activity or fun fact. Here are some options you can try out:</p><ul role="list"><li><a href="https://www.rally.video/games-and-resources">Rally's Games &amp; Activity page</a></li><li><a href="https://bored.social/">Bored Social</a></li><li><a href="https://meet.airconsole.com/">Air Console</a></li></ul><p>If you are hybrid, encourage people to sign in with their own devices for this meeting so it feels like everyone is remote (on their own computers).</p><p>Consider having this meeting few times a week instead of daily</p><p>Consider not limiting this Rally to just your team, but inviting teams you collaborate with to join</p><p>You can improve your standups on any video platform. We're obviously biased because we built our own and we think it is more fun, easier to use, and gives more autonomy to each user! If you'd like to give us a try, why not head over to <a href="https://rally.video/">https://rally.video</a> and sign up for an account. Have questions or comments? Email us at <a href="mailto:hello@rally.video?subject=Blog%20on%20Daily%20Rallies">hello@rally.video </a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.rally.video/post/stand-ups-suck-why-not-rally-instead</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242959</guid>
            <pubDate>Tue, 23 Feb 2021 21:13:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create a great production readiness checklist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26242906">thread link</a>) | @anishdhar
<br/>
February 23, 2021 | https://www.getcortexapp.com/post/how-to-create-a-great-production-readiness-checklist | <a href="https://web.archive.org/web/*/https://www.getcortexapp.com/post/how-to-create-a-great-production-readiness-checklist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="w-node-_32987516-cd92-7936-c83c-b0d3724b1a2f-82f65440"><p>What does your team’s production readiness practice look like for deploying a new service? If you or a dedicated SRE team within your engineering organization has ever green-lit a new service, you probably have used some form of a <strong>production readiness checklist</strong> to ensure certain conditions are met and processes are followed. In this article, we’ll share some helpful approaches for creating a great production readiness checklist that will set your team up for a successful launch.</p><h2>What should be on your production readiness checklist</h2><p>The ideal production readiness checklist is comprehensive, but flexible — it can and should look different based on the type of service you’re deploying and the impact of the launch. That said, there are certain categories that are essential for any checklist.</p><h3>Logging and monitoring</h3><p>Production issues can be extremely costly, so it’s important to make sure you have the right logging and monitoring in place for any new service. By preparing now, you can make sure that you have the data you need to debug failures when they (inevitably) occur — otherwise, issues might go undetected or take too long to fix.<br></p><p>Make sure your team knows exactly what is being recorded across your application and access logs — and if there’s a piece of information you might need to debug a failure, start logging it from day one. Although it might seem obvious, it’s also important to document where to <em>find </em>the logs, since the people debugging your service later on might not be the same people who wrote your logging code. Also document key information about the service, like where the git repo lives, what language is used, what version, and when the service was deployed.<br></p><p>Before launching, make sure you’ve implemented alerts that notify your team when certain SLA thresholds are exceeded. And ensure there is appropriate tracing across other services that might interact with this one.&nbsp;</p><h3>Automated tools and processes</h3><p>You can get some of the above for free by using automated tools. Your team most likely relies on third-party software to automate your monitoring, on-call rotations, incident management, and more (if you need any tips, check out <a href="https://www.getcortexapp.com/post/a-guide-to-the-best-sre-tools" target="_blank">our guide to SRE tools</a>). If this is the case, getting ready for production means making sure that everyone has access to the right tools and dashboards and knows where to find them. You should make sure your on-call rotation is set up and your teammates know how to use your playbooks for incident management. And you’ll want to make sure that a team is responsible for regularly checking that your tools are still configured and working as expected throughout the lifetime of the service.&nbsp;</p><h3>Engineering best practices</h3><p>There are some aspects of your production readiness checklist that aren’t easily automated. For example, you should make sure that whoever wrote new APIs also wrote good documentation and made sure the APIs were well-versioned. Or you will want to ensure when your team is making a call, they’re logging the status codes. And have you done load testing and capacity planning?<br></p><p>For a lower-impact service, some of these questions might default to the honor system. But most of the time, you will need to have a conversation between the engineers who developed the service and a manager or SRE to verify that certain best practices were followed.&nbsp;</p><h3>Ownership / communication</h3><p>SRE teams are more successful when they reduce tribal knowledge, and it’s important that for every new service you push into production, you have great communication from the beginning. This means identifying a clear owner — a single team or engineer who will take accountability for the service. It’s also important to document the way your team will discuss issues, like a dedicated Slack channel and a direct escalation path.</p><h2>How to organize your production readiness checklist</h2><p>Defining a production readiness process is one of the most important things you can do for the health of your products, but getting it to stick as part of your team’s culture can be hard. No one wants to feel like a nag, and yet the honor system doesn’t always work in practice. At the same time, production readiness checklists are usually unwieldy and a hassle to manage. With all those questions and answers to document, teams typically end up using Excel or Google Sheets to store their lists. But it’s hard to standardize and communicate across many different spreadsheets that are floating around. And someone has to maintain those spreadsheets and keep them up to date.&nbsp;</p><figure><p><img src="https://assets.website-files.com/5fff18095410c63a0f88f178/6035679677fa757db96cd542_DTwczVBYP9Pv5EOm0C46JG_j376zwDYzFu7LCGDnX5DM2zmN_YGG7he8MY5lFvj5pZIUUC3cI2iu_qK2KDbH_n7VzvVYQNAXK9PthvHRYpgmLav9IC_t6A1fj9iG3gwnl89u8Ew.png" alt=""></p><figcaption>Here’s a screenshot of a typical production readiness checklist in a spreadsheet format. The question marks indicate places where the team was missing information or wasn’t even sure who the owner of a service was.</figcaption></figure><p>At Cortex, we developed <strong>Scorecards </strong>to replace the production readiness spreadsheet and help your team understand the health of your services at a glance. You can set standardized requirements for each service and adjust them as needed (for example, maybe for 10% of your services, you enforce extra security vulnerability scans). We integrate with your third-party automation tools so that you get most of your scorecard filled in automatically, and we let you create and answer custom questions for everything else. If something changes out from under you— like your on-call rotation disappearing from PagerDuty — you can see it right in the Scorecard.&nbsp;</p><figure><p><img src="https://assets.website-files.com/5fff18095410c63a0f88f178/6035679602645372bcefbba8_ZZeVzk4va38bPFhWdzGvtzgXH-N3S2JyqWpl6FFteP-O1HD3J_6v3HXZVeBr8ECX63GD19gfin6SH4UOTa8gxcI75tUf48u6T7symncvOwNa8qfAA0R1xxjg1NJpo8Zyujy7fxc.png" alt=""></p><figcaption>Cortex’s dashboard showing the scorecards for your services.</figcaption></figure><p>We built Scorecards because we wanted to make production readiness more objective and clear, and as engineers ourselves who have worked with countless third party tools, we know how important it is to create a single source of truth that your whole team can refer to.&nbsp;<br></p><p>The details of your production readiness checklist are important, but the details don’t matter if the overall process is broken. We encourage you to take a step back and think about how you can bring a culture of blameless communication to your production readiness practice. If you’re interested in finding out more about Cortex, sign up for a <a href="https://www.getcortexapp.com/" target="_blank">free account here</a>.<br></p></div></div>]]>
            </description>
            <link>https://www.getcortexapp.com/post/how-to-create-a-great-production-readiness-checklist</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242906</guid>
            <pubDate>Tue, 23 Feb 2021 21:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Kafka API is great; now let's make it fast]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26242197">thread link</a>) | @sorenbs
<br/>
February 23, 2021 | https://vectorized.io/blog/fast-and-safe/ | <a href="https://web.archive.org/web/*/https://vectorized.io/blog/fast-and-safe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><blockquote>
<p><small>Note: we will host a live twitch stream on Thursday, February 25th at 10am PT for 1hr. Come and ask us questions live. We will walk through the code, benchmarks, results, and if time permits, we’ll walk through the storage engine design.</small></p>
</blockquote>
<p><img src="https://vectorized.io/171856194738a05a78e745396ee0c493/1250k-rate-100-partitions-1kb-4-producers-e2e-latency-quantile.svg" alt="1.2GB/s"></p>
<blockquote>
<p><small>1250k msg/sec - 1KB payload - ack=all - fsync after every batch - 1 hour benchmark
</small></p>
</blockquote>
<p>This blog post represents months of work and over 400+ hours of actual
benchmarking where we compared
<a href="https://vectorized.io/redpanda">Redpanda</a>
and the latest 2.7 Kafka Release. We used the recommended production
setup and environment from Confluent’s
<a href="https://github.com/confluentinc/openmessaging-benchmark" target="_self" rel="nofollow">fork</a>
of the CNCF open messaging benchmark.</p>
<p>Before we get started, the entirety of the actual results with the full
workload distribution, saturation, latency and throughput are at the bottom
of this interactive <a href="https://vectorized.io/blog/fast-and-safe/#The-full-test-suite-below">blog post</a>.</p>

<p>The <a href="https://vectorized.io/blog/intelligent-data-api/" target="_self" rel="nofollow">Kafka API</a>
has emerged as the lingua franca for streaming workloads. Developers
love the ecosystem and being able to turn sophisticated products
overnight. Just like Apache and Nginx have their own HTTP
implementations, gccgo and the Go compiler specify parsers for the
language, MySQL and Postgres implement SQL, Redpanda and Kafka implement
the Kafka API. Redpanda aims to bring operational simplicity to the
existing overwhelming complexity of standing up state-of-the-art
streaming systems. This manifests at its lowest level in no longer
having to choose between data safety and performance.</p>
<p>Let’s be clear, the reason tail latency matters in the world of big data
is because Redpanda does not exist in isolation. It often sits between
your web servers, databases, internal microservices, data lakes, etc.
Redpanda controls the information flow of how, when and where things are
stored, transferred, accessed, mutated and eventually delivered. The
reason we obsess over tail latency is because the p99.99 in a messaging
system happens often - it’s a simple function of the messages exchanged.
As the volume of interactions and messages between systems using the
Kafka API increases, so does the probability that a single user
operation or API call is affected by latencies <strong>above</strong> the 99.99th
percentile.</p>
<p>The Kafka API is good, below, we showcase how we made it fast.</p>

<p>We present 18 workloads below. All workloads for both systems replicate
the data to 3 nodes in total with no lag (manually verified in the
quorum system). The only difference is that Apache Kafka was run with
in-memory replication (using the page-cache) and flushing after every
message. Redpanda can only be operated in safe mode (flushing after
every batch) with acks=all. The benchmarks below are the same benchmarks
<a href="https://www.confluent.io/blog/kafka-fastest-messaging-system/" target="_self" rel="nofollow"><u>Alok Nikhil &amp; Vinoth Chandar from
Confluent</u></a>
performed while comparing Pulsar and Kafka with a 1.2GB/s extension,
using the same CNCF Open Messaging Benchmark suite.</p>
<p>First, we note that we were only able to reproduce Confluent’s first 6
results. For the other three workloads, the data shows that it is in
fact impossible to achieve sustained network throughput above 300MB/s on
AWS on i3en.2xlarge instances. Please see our Benchmark Appendix section
at the end for a detailed explanation. We also change the default 1
minute warmup time to 30 minutes to account for <a href="http://www.brendangregg.com/blog/2016-09-28/java-warmup.html" target="_self" rel="nofollow"><u>common
pitfalls</u></a>
in <a href="https://arxiv.org/abs/1602.00602" target="_self" rel="nofollow"><u>Virtual Machine</u></a>
benchmarking practices and focus entirely on steady state performance.
We then ran each workload for 60 additional minutes, recorded the
results and repeated the steps, taking the best run of each system. That
is, each time we ran the benchmarks it took over 54 hours to finish.</p>
<p>For all workloads, we used two m5n.8xlarge for the clients, with
32-cores and with 25Gbps of guaranteed networking throughput
and 128GB of memory to ensure the bottleneck would be on the server
side. The benchmark used three i3en.6xlarge 24-core instances with
192GB of memory, 25Gbps guaranteed networking and two NVMe SSD devices.</p>
<p>We note that after spending several hundreds of hours benchmarks, we had
to scale up Confluent’s Kafka settings to keep up with larger instances
to num.replica.fetchers=16, message.max.bytes=10485760,
replica.fetch.max.bytes=10485760, num.network.threads=16,
num.io.threads=16, log.flush.interval.messages=1. Otherwise, the gap
between Redpanda and Kafka would be much larger. This had the
unfortunate effect that for lower percentiles, Kafka’s latency was a
little higher than using half as many threads as specified by
Confluent’s Github repo.</p>
<p>All the latencies below are the end-to-end p99.999 latency with 16
producers and 16 consumers with 100 partitions on a single topic. Every
message represents 1KB of data. We note that by and large Kafka is able
to keep up on throughput except for a couple of workloads with acks=all
where Redpanda is better. The meaningful differences are in latency: how
fast can each system go.</p>
<h2 id="Safe-workloads---fsync-with-every-batch">Safe workloads - fsync() with every batch<a href="#Safe-workloads---fsync-with-every-batch" aria-label="Safe workloads   fsync with every batch permalink"></a></h2>
<table>
<thead>
<tr>
<th><strong>Workload</strong></th>
<th><strong>Kafka p99.999</strong></th>
<th><strong>Redpanda p99.999</strong></th>
<th><strong>Percentage Change</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>acks=all + fsync() after every batch</strong></td>
</tr>
<tr>
<td>(1) 10MB/s (10K msgs/s)</td>
<td>215.191ms</td>
<td>12.405ms</td>
<td>+1634.71%</td>
</tr>
<tr>
<td>(2) 40MB/s (40K msgs/s)</td>
<td>102.589ms</td>
<td>52.122ms</td>
<td>+96.82%</td>
</tr>
<tr>
<td>(3) 50MB/s (50K msgs/s)</td>
<td>235.675ms</td>
<td>13.999ms</td>
<td>+1522.66%</td>
</tr>
<tr>
<td>(4) 75MB/s (75K msgs/s)</td>
<td>1801.263ms</td>
<td>16.606ms</td>
<td>+10747.06%</td>
</tr>
<tr>
<td>(5) 100MB/s (100K msgs/s)</td>
<td>1725.391ms</td>
<td>20.552</td>
<td>+8295.25%</td>
</tr>
<tr>
<td>(6) 200MB/s (200K msgs/s)</td>
<td>1945.039ms</td>
<td>27.307ms</td>
<td>+7022.86%</td>
</tr>
<tr>
<td>(7) 0.5GB/s (500K msgs/s)</td>
<td>3015.295ms</td>
<td>60.943ms</td>
<td>+4263.23%</td>
</tr>
<tr>
<td>(8) 1GB/s (1M msgs/s)</td>
<td>3839.663ms</td>
<td>174.521ms</td>
<td>+2100.12%</td>
</tr>
<tr>
<td>(9) 1.25GB/s (1.25M msgs/s)</td>
<td>3797.167ms</td>
<td>237.688ms</td>
<td>+1497.54%</td>
</tr>
</tbody>
</table>
<blockquote>
<p><small> Percentage Change was computed using: ((v2-v1)/abs(v1))*100 </small></p>
<p><small> Note: All of our work is open source on <a href="https://github.com/vectorizedio/openmessaging-benchmark" target="_self" rel="nofollow">GitHub</a>. Safe workloads mean acks=all and fsync after every batch before returning to the client.</small></p>
</blockquote>
<h2 id="In-memory-replication-for-Kafka-page-cache--no-explicit-flushes-vs-Redpanda-fsync-ing-after-every-batch">In memory replication for Kafka (page cache &amp; no explicit flushes) vs. <strong>Redpanda fsync()</strong>-ing after every batch<a href="#In-memory-replication-for-Kafka-page-cache--no-explicit-flushes-vs-Redpanda-fsync-ing-after-every-batch" aria-label="In memory replication for Kafka page cache  no explicit flushes vs Redpanda fsync ing after every batch permalink"></a></h2>
<table>
<thead>
<tr>
<th><strong>Workload</strong></th>
<th><strong>Kafka (no fsync) p99.999</strong></th>
<th><strong>Redpanda (with sync) p99.999</strong></th>
<th><strong>Percentage Change</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td><strong>acks=all</strong></td>
</tr>
<tr>
<td>(1) 10MB/s (10K msgs/s)</td>
<td>12.728ms</td>
<td>12.405ms</td>
<td>+2.6%</td>
</tr>
<tr>
<td>(2) 40MB/s (40K msgs/s)</td>
<td>216.253</td>
<td>52.122ms</td>
<td>+314.9%</td>
</tr>
<tr>
<td>(3) 50MB/s (50K msgs/s)</td>
<td>222.785ms</td>
<td>13.999ms</td>
<td>+1491.44%</td>
</tr>
<tr>
<td>(4) 75MB/s (75K msgs/s)</td>
<td>216.195ms</td>
<td>16.606ms</td>
<td>+1201.9%</td>
</tr>
<tr>
<td>(5) 100MB/s (100K msgs/s)</td>
<td>13.737ms</td>
<td>20.552ms</td>
<td>-33.16%</td>
</tr>
<tr>
<td>(6) 200MB/s (200K msgs/s)</td>
<td>218.32ms</td>
<td>27.307ms</td>
<td>+699.5%</td>
</tr>
<tr>
<td>(7) 0.5GB/s (500K msgs/s)</td>
<td>4225.215ms</td>
<td>60.943ms</td>
<td>+6833.06%</td>
</tr>
<tr>
<td>(8) 1GB/s (1M msgs/s)</td>
<td>4877.279ms</td>
<td>174.521ms</td>
<td>+2694.67%</td>
</tr>
<tr>
<td>(9) 1.25GB/s (1.25M msgs/s)</td>
<td>202.667ms</td>
<td>237.688</td>
<td>-14.73%</td>
</tr>
</tbody>
</table>
<blockquote>
<p><small> Workload (5) is a bug on our write-behind strategy: <a href="https://github.com/vectorizedio/redpanda/issues/542" target="_self" rel="nofollow">issue #542</a> </small></p>
</blockquote>
<p><strong>We’ve said this ad nauseam: <a href="https://vectorized.io/blog/redpanda-raison-detre/" target="_self" rel="nofollow"><u>hardware is the
platform</u></a></strong>.
Modern hardware is capable of giving you both low latency and no data
loss (fsync). Let’s talk about most of the meaningful low-level
architectural differences that get us there</p>

<p><img src="https://vectorized.io/171856194738a05a78e745396ee0c493/1250k-rate-100-partitions-1kb-4-producers-e2e-latency-quantile.svg" alt="1.2GB/s">
Before we dive deep into details, we encourage you to sign up for our
live Twitch Stream where we’ll be going through every single claim made
in this article, and are happy to answer your questions live. It will be
me, emacs, you and questions. Perfect.</p>
<p>When we started building Redpanda, the main driving factor was
<strong>understandability</strong>. Above performance, we wanted a simple mental
model of what it meant to have 2 out of 3 replicas up and running, which
is how we ended with Raft - a protocol with a mathematical proof of
correctness &amp; log completeness and a focus on usability as part of its
design goals.</p>
<p>However, once you get your replication model set, the rest of the life
of the product is spent on predictability, and for big-data &amp; real time
systems, that means understandable, flat tail latencies. It is not
enough to be fast. It is not enough to be safe. When trying to handle
hundreds of terabytes per day of streaming you need to be predictable
not only in the way the product breaks in case of network partitions,
bad disks, etc, but also in how performance degrades as a function of
hardware saturation. This is at the core of operational simplicity for
streaming systems.</p>
<p>Modern hardware allows us to finally have nice things. It is not the
case anymore that you have to choose between safety (no data loss) and
speed (low latency). Furthermore, this predictability affords you
accurate planning for product launches. As a user, I understand how to
buy hardware. I will perform an `fio` test and have a decent
understanding of what that specific hardware can do. Redpanda lets you
take these hardware saturation numbers and gives you a reasonable chance
of predicting how costly it is to develop a new product.</p>
<p>Without further ado, let me count the ways:</p>
<h2 id="0-No-page-cache">0) No page cache<a href="#0-No-page-cache" aria-label="0 No page cache permalink"></a></h2>
<p>The page cache is an object in the Linux Kernel. It is maintained per
file with global locking semantics. It is a tried and true, generic
scheduling mechanism with heuristics from a variety of production use
cases that push and pull the design to a really good middle ground. It
aims to never be a bad choice if you need to do IO. However, for our
specific use case - a log - we can do much better. We understand
exactly, all the way to the user application, how much data is going to
be needed next, the access patterns which mostly move forward, update
frequency, background operations and cache prioritization.</p>
<p>For us, the page cache introduces latency and nondeterministic IO
behavior. For example, when loading data for a Kafka fetch request the
Linux Kernel will trigger general-purpose read-ahead heuristics, and
cache the bytes it read, take a global lock, and update indexes.
Redpanda does not do general IO. It is a log, append only, with well
understood access patterns. We add data to the end file and have
aggressive write-behind strategies. When we read data, Redpanda reads in
order, which means we can in theory have perfect read-ahead and object
materialization that sits above the byte array style API of the page
cache, etc.</p>
<p>More fundamentally, bypassing the Kernel’s page cache allows us to be
predictable, with respect to both failure semantics and tail latency. We
can detect and measure the rate and latency of IO and adjust our buffer
pools accordingly. We can react to low memory pressure situations and
have a holistic view of our memory footprint. We have predictability
over each filesystem operation that can actually affect correctness - as
recently evidenced by the PostgreSQL team with an fsync() bug that was
<a href="https://www.youtube.com/watch?v=1VWIGBQLtxo" target="_self" rel="nofollow">undetected for 20 years</a>.</p>
<h2 id="1-Automatic-Linux-Kernel-Tuning">1) Automatic …</h2></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/blog/fast-and-safe/">https://vectorized.io/blog/fast-and-safe/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/blog/fast-and-safe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26242197</guid>
            <pubDate>Tue, 23 Feb 2021 20:05:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swiss National Bank: How to issue a central bank digital currency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26241831">thread link</a>) | @FloDo
<br/>
February 23, 2021 | https://www.snb.ch/en/mmr/papers/id/working_paper_2021_03 | <a href="https://web.archive.org/web/*/https://www.snb.ch/en/mmr/papers/id/working_paper_2021_03">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
       <article>
        
        <h2><span>David Chaum</span>, <span>Christian Grothoff</span> and <span>Thomas Moser</span></h2>
        
        <p><b>Issue</b><br><span>2021-03</span></p>
        <p><b>Pages</b><br><span>34</span></p>
        <p><b>JEL classification</b><br><span>E42, E51, E52, E58, G2</span></p>
        <p><b>Keywords</b><br><span>Digital currencies, central bank, CBDC, blind signatures, stablecoins</span></p>
        <p><b>Year</b><br><span>2021</span></p>
        
        <ul>
         <li>
          <a href="https://www.snb.ch/n/mmr/reference/working_paper_2021_03/source/working_paper_2021_03.n.pdf">
           <div>
            
            <p>
             <h3>How to issue a central bank digital currency</h3>
            </p>
           </div>
           <p>PDF</p>
          </a>
         </li>
        </ul>
        <p>With the emergence of Bitcoin and recently proposed stablecoins from BigTechs, such as Diem (formerly Libra), central banks face growing competition from private actors offering their own digital alternative to physical cash. We do not address the normative question whether a central bank should issue a central bank digital currency (CBDC) or not. Instead, we contribute to the current research debate by showing how a central bank could do so, if desired. We propose a token-based system without distributed ledger technology and show how earlier-deployed, software-only electronic cash can be improved upon to preserve transaction privacy, meet regulatory requirements in a compelling way, and offer a level of quantum-resistant protection against systemic privacy risk. Neither monetary policy nor financial stability would be materially affected because a CBDC with this design would replicate physical cash rather than bank deposits.</p>
       </article>
      </div></div>]]>
            </description>
            <link>https://www.snb.ch/en/mmr/papers/id/working_paper_2021_03</link>
            <guid isPermaLink="false">hacker-news-small-sites-26241831</guid>
            <pubDate>Tue, 23 Feb 2021 19:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: NeoChat 1.1, a Matrix client by KDE]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26241591">thread link</a>) | @ognarb
<br/>
February 23, 2021 | https://carlschwan.eu/2021/02/23/neochat-1.1/ | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2021/02/23/neochat-1.1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Exactly 2 months after <a href="https://carlschwan.eu/2020/12/23/announcing-neochat-1.0-the-kde-matrix-client/">NeoChat 1.0</a>, the NeoChat team is happy to announce a new release of NeoChat. NeoChat is a native client for the decentralized communication network Matrix.</p><p>Aside from the many bug fixes, performance improvements, and subtle appearance improvements, NeoChat 1.1 brings many new features that will make your experience with it more convenient.</p><p>Thanks to the work of Hannah, Nicolas, and Tobias, this release also brings NeoChat to many more platforms. Nightly builds of NeoChat are now available on <a href="https://binary-factory.kde.org/job/Neochat_android/" target="_blank" rel="noopener">Android</a>, <a href="https://binary-factory.kde.org/job/Neochat_x86_64_flatpak/" target="_blank" rel="noopener">Flatpak</a>, <a href="https://binary-factory.kde.org/job/NeoChat_Nightly_appimage/" target="_blank" rel="noopener">AppImage</a>, <a href="https://binary-factory.kde.org/job/NeoChat_Nightly_macos/" target="_blank" rel="noopener">macOS</a> and <a href="https://binary-factory.kde.org/job/NeoChat_Nightly_win64/" target="_blank" rel="noopener">Windows</a>. Not all of them are considered production ready, but we hope to improve the support for them in future release.</p><h2 id="new-features">New features</h2><h3 id="first-launch-experience-improvements">First launch experience improvements</h3><p>Probably the highlight of this release is the completely new login page. It detects the server configuration based on your Matrix Id. This allows you to login to servers requiring Single Sign On (SSO) (like the Mozilla or the incoming Fedora Matrix instance).</p><p>Servers that require agreeing to the TOS before usage are correctly detected now and redirect to their TOS webpage, allowing the user to agree to them instead of silently failing to load the account.</p><p>TOS webpage, allowing the user to agree to them instead of silently failing to load the account.</p><figure><a href="https://carlschwan.eu/2021/02/23/neochat-1.1/login.png" data-size="528x794"><img srcset="https://carlschwan.eu/2021/02/23/neochat-1.1/login_huf333a74785c104822f28be1d9fd20432_47550_480x0_resize_box_2.png 480w, https://carlschwan.eu/2021/02/23/neochat-1.1/login_huf333a74785c104822f28be1d9fd20432_47550_1024x0_resize_box_2.png 1024w" src="https://carlschwan.eu/2021/02/23/neochat-1.1/login.png" width="528" height="794" loading="lazy" alt="Login Page"></a><figcaption>Login Page</figcaption></figure><h3 id="stickers">Stickers</h3><p>Everyone loves cute stickers, so now NeoChat supports displaying them too. We don’t yet support sending them.</p><figure><a href="https://carlschwan.eu/2021/02/23/neochat-1.1/sticker.png" data-size="418x310"><img srcset="https://carlschwan.eu/2021/02/23/neochat-1.1/sticker_hu47d490cb79536787ab1910b00492664a_51571_480x0_resize_box_2.png 480w, https://carlschwan.eu/2021/02/23/neochat-1.1/sticker_hu47d490cb79536787ab1910b00492664a_51571_1024x0_resize_box_2.png 1024w" src="https://carlschwan.eu/2021/02/23/neochat-1.1/sticker.png" width="418" height="310" loading="lazy" alt="Viewing a Sticker"></a><figcaption>Viewing a Sticker</figcaption></figure><h3 id="editing-messages">Editing messages</h3><p>Editing messages is another popular feature of every IM client. NeoChat is now able to show edited messages correctly and also make it possible to edit your messages. The behavior is the same as in Element.</p><figure><a href="https://carlschwan.eu/2021/02/23/neochat-1.1/editing.png" data-size="602x116"><img srcset="https://carlschwan.eu/2021/02/23/neochat-1.1/editing_hu132bf95ccf390c7d63fc54dd3ebf7244_8401_480x0_resize_box_2.png 480w, https://carlschwan.eu/2021/02/23/neochat-1.1/editing_hu132bf95ccf390c7d63fc54dd3ebf7244_8401_1024x0_resize_box_2.png 1024w" src="https://carlschwan.eu/2021/02/23/neochat-1.1/editing.png" width="602" height="116" loading="lazy" alt="Editing messages"></a><figcaption>Editing messages</figcaption></figure><h3 id="multimodal-mode">Multimodal mode</h3><p>It is now possible to open a room into a new window. This allows you to view and interact with multiple rooms at the same time.</p><figure><a href="https://carlschwan.eu/2021/02/23/neochat-1.1/multimodal.png" data-size="1582x879"><img srcset="https://carlschwan.eu/2021/02/23/neochat-1.1/multimodal_hub3ad52b950defc079bcceeb184525122_565169_480x0_resize_box_2.png 480w, https://carlschwan.eu/2021/02/23/neochat-1.1/multimodal_hub3ad52b950defc079bcceeb184525122_565169_1024x0_resize_box_2.png 1024w" src="https://carlschwan.eu/2021/02/23/neochat-1.1/multimodal.png" width="1582" height="879" loading="lazy" alt="Multimodal mode"></a><figcaption>Multimodal mode</figcaption></figure><h3 id="commands">Commands</h3><p>We added a few commands to NeoChat. Previously you could use <code>/me</code> and <code>/rainbow</code>, and we added a few mores: <code>/shrug</code>, <code>/lenny</code>, <code>/rainbowme</code>, <code>/join</code>, <code>/invite</code>, <code>/part</code>, <code>/ignore</code>, <code>/unignore</code>.</p><h3 id="plasma-integration">Plasma integration</h3><p>We improved the Plasma integration a bit. Now the number of unread messages is displayed in the Plasma Taskbar. It is using the <code>com.canonical.Unity.LauncherEntry</code> DBus protocol, so that should be reasonably supported across desktops.</p><h2 id="tarballs">Tarballs</h2><p>Version 1.1.1 of NeoChat is availabe <a href="https://download.kde.org/stable/neochat/1.1.1/neochat-1.1.1.tar.xz" target="_blank" rel="noopener">here</a>.
The package is signed with my gpg key <a href="https://carlschwan.eu/gpg.html">14B0ED91B5783415D0AA1E0A06B35D38387B67BE</a>.</p><p>For users, a <a href="https://flathub.org/apps/details/org.kde.neochat" target="_blank" rel="noopener">Flathub version</a> will be updated shortly.</p></section><div><h2>Comments</h2><p>You can use your Mastodon account to reply to this <a href="https://mastodon.technology/@kde/105782079763058379">post</a>.</p><p><a href="https://mastodon.technology/interact/105782079763058379?type=reply">Reply</a></p></div></div>]]>
            </description>
            <link>https://carlschwan.eu/2021/02/23/neochat-1.1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26241591</guid>
            <pubDate>Tue, 23 Feb 2021 19:19:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Covid-19 Vaccine Data by State]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26241107">thread link</a>) | @already
<br/>
February 23, 2021 | https://humanified.org/covid19-resources | <a href="https://web.archive.org/web/*/https://humanified.org/covid19-resources">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><header></header><section id="vaccine__header"><p>Please visit <a href="https://www.cdc.gov/" target="_BLANK">CDC.gov</a> for all other COVID-19 related searches.</p><img src="https://humanified.org/map-covid.svg" id="vaccine__map" alt="covid__map"><main><div id="covid-locator"><p id="vh_pre"><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100">Testing + Vaccination Search</span></p><h2 id="vh_post"><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="250">Finding a COVID-19 testing location or vaccination site has been too</span><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="300">stressful. We’ve compiled each state’s information into one easy resource</span><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="350">for you to use. Start with your location and find what you need, faster.</span></h2><h2 id="vh_post"><span data-aos="fade-up" data-aos-duration="1000" data-aos-delay="250">Finding a COVID-19 testing location or vaccination site has been too stressful. We’ve compiled each state’s information into one easy resource for you to use. Start with your location and find what you need, faster.</span></h2></div></main></section><div id="search"><div><div><p data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100"><small>Search</small></p><h2 data-aos="fade-up" data-aos-duration="1000" data-aos-delay="300">Find your <span>COVID</span> <br> <!-- -->vaccine locations</h2><form autocomplete="off"><div><div data-aos="fade-up" data-aos-duration="1000" data-aos-delay="400"><p>Zip Code</p><p>Please select an address from the dropdown</p></div></div></form></div></div><p>Vaccine location<!-- --> copied to clipboard</p></div><section id="stats"><div><div><p data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100"><small>By The Numbers</small></p><h2 data-aos="fade-up" data-aos-duration="1000" data-aos-delay="200">Vaccines <span>accross the US </span></h2></div><div><div><div data-aos="fade-up" data-aos-duration="1000" data-aos-delay="200"><div><p><img itemprop="logo" src="https://humanified.org/deliver__vaccine.svg" alt="Humanified"></p></div></div></div><div><div data-aos="fade-up" data-aos-duration="1000" data-aos-delay="400"><p>Vaccines available in each state</p></div></div></div></div></section><section id="about-us"><img itemprop="shape" src="https://humanified.org/shapevaccine.svg" alt="Humanified"><div><div><p data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100"><small>POWERED BY</small></p><p><img data-aos="fade-up" data-aos-duration="1000" data-aos-delay="200" itemprop="logo" src="https://humanified.org/hlogo.svg" alt="Humanified"></p></div><div><p data-aos="fade-up" data-aos-duration="1000" data-aos-delay="100"><small>ABOUT HUMANIFIED</small></p><h3 data-aos="fade-up" data-aos-duration="1000" data-aos-delay="200">The Social Impact <br>Social Network</h3><h4 data-aos="fade-up" data-aos-duration="1000" data-aos-delay="300">Humanified is a soon-to-launch social impact network that makes it easier for everyone to #MakeChangeHappen. Create content for the causes you believe in, discover new ways to get involved, and donate to verified nonprofits. <strong>Coming to the App Store 2021.</strong></h4><p><a href="https://humanified.org/" data-aos="fade-up" data-aos-duration="1000" data-aos-delay="400">LEARN MORE</a></p></div></div><p><small>HUMANIFIED 2021 ALL RIGHTS RESERVED</small></p></section></div></div></div>]]>
            </description>
            <link>https://humanified.org/covid19-resources</link>
            <guid isPermaLink="false">hacker-news-small-sites-26241107</guid>
            <pubDate>Tue, 23 Feb 2021 18:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Internals of Deno]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26240614">thread link</a>) | @noch
<br/>
February 23, 2021 | https://choubey.gitbook.io/internals-of-deno/ | <a href="https://web.archive.org/web/*/https://choubey.gitbook.io/internals-of-deno/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="a671402f9c104d4ca3f3e0e3bd2226eb" autocorrect="on" spellcheck="true" data-gramm="false"><div data-slate-void="true" data-key="5872759d45bb43c19d09429f75a1450f"><div><figure data-key="5872759d45bb43c19d09429f75a1450f" contenteditable="false"><div><p><img tabindex="0" src="https://gblobscdn.gitbook.com/assets%2F-MJJDXLU1fV3Te4epBgE%2F-MPkuG0v9GiIrAbOSZT7%2F-MPkuJbfKXqKQxLndO6N%2F1.png?alt=media&amp;token=15582e6f-3556-4b55-a47c-e155037141f4" loading="lazy"></p></div></figure></div></div><p data-key="ff9050011d61423096ecd2bff04840bb"><span><span data-key="74f8fde097f24649a5a791abafeba925"><span data-offset-key="74f8fde097f24649a5a791abafeba925:0"><span data-slate-zero-width="n">​</span></span></span></span></p><h2 id="how-does-deno-execute-programs" data-key="ff9c0fa5f5b7459da5c704b3080ddca5"><p><span><span data-key="0ba18263635a4306b8f63e40bc207303"><span data-offset-key="0ba18263635a4306b8f63e40bc207303:0">How does Deno execute programs?</span></span></span><a href="#how-does-deno-execute-programs" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="8488cb7273c842e8a2da233f742dc8cc"><span><span data-key="be32858c70794e95bab81f431ebe0c0c"><span data-offset-key="be32858c70794e95bab81f431ebe0c0c:0"><strong data-slate-leaf="true">Vol - 1</strong></span></span></span></p><h3 id="by-mayank-choubey" data-key="72bec37baeea469faa2d70defc6c44e0"><p><span><span data-key="c7fa99fbcf23483aae8d15dd35621c7f"><span data-offset-key="c7fa99fbcf23483aae8d15dd35621c7f:0">By Mayank Choubey</span></span></span><a href="#by-mayank-choubey" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3><h3 id="1st-edition-december-2020" data-key="0729d2eb15534d58887c598a9203b1b0"><p><span><span data-key="e8de8002ed504a589009ebe1f48856d0"><span data-offset-key="e8de8002ed504a589009ebe1f48856d0:0">1st edition - December 2020</span></span></span><a href="#1st-edition-december-2020" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3></div></div></div></div></div></div>]]>
            </description>
            <link>https://choubey.gitbook.io/internals-of-deno/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26240614</guid>
            <pubDate>Tue, 23 Feb 2021 18:14:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retirement Optimization for Tech Employees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26240363">thread link</a>) | @zuhayeer
<br/>
February 23, 2021 | https://withcompound.com/r/retirement-optimization-for-tech-employees | <a href="https://web.archive.org/web/*/https://withcompound.com/r/retirement-optimization-for-tech-employees">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h3>"Compound interest is the 8th wonder of the world. He who understands it, earns it; he who doesn't, pays it."</h3></p><div><section>    
<p>
      Planning for retirement often feels pointless. You’re young and your startup is taking off — why should you worry about retirement now?
    </p>
    <p>There are two concepts that make this planning a no-brainer:</p>
    <p><b>1. Compounding</b></p>
    <p>Interest on interest unlocks exponential growth. If you earn 5% annual interest on a $10,000 deposit, you’ll have $10,500 after the first year. In the second year, you’ll earn interest on the initial deposit plus interest on the interest you earned. And so on. Over 50 years, a 5% compounded interest rate will grow your $10,000 deposit to over $110,000. The earlier you start, the more time your money has to grow.</p>
 <p><b>2. Tax-advantaged accounts</b></p>
    <p>The government provides opportunities to invest tax-free in the stock market through retirement accounts. While beating the stock market is hard, maximizing your contribution to tax-advantaged investment accounts provides an instant increase to your future returns.</p>
    <p>Compounding, tax-free returns generate long-term wealth. Combining these tools with a broader asset allocation strategy will help you manage uncertainty (e.g., handling a global pandemic) and achieve your financial goals. This guide explains how to make the most of these tools. We’ll cover the different types of retirement accounts and how to strategically optimize your contributions.</p>

   
</section></div></div><div><h3>Retirement Account Types<br></h3><div><section>
    <p>
		All retirement accounts — 401(k)s and IRAs — share some basic characteristics:
    </p>
    <p><b>1. Tax advantages</b></p>
  	<p>Both you and your employer can save on taxes with these accounts.</p>
    <p><b>2. Contribution limits</b></p>
    <p>Without contribution limits, these retirement accounts could easily be repurposed as huge tax shelters for the ultra-wealthy.</p>
    <p><b>3. Restrictions on withdrawals before age 59 ½</b></p>
    <p>Without an age restriction, these accounts would be no different from normal taxable accounts apart from their tax advantages, and they wouldn't encourage long-term saving.</p>
    <p>We'll go over the specific details of each of these characteristics as they relate to each account type below.</p>

</section></div><h4>401(k) Plans</h4><div><section>
  <p>401(k) plans are the most common type of retirement plan offered by employers. Under a 401(k), you tell your employer to redirect a certain amount from your paycheck to your 401(k) account instead.</p>
	<p>There are two types of 401(k)s, Roth and Traditional:</p>
</section></div><div><section>

    <p>
Your company may offer 401(k) matching. For instance, if you elect to contribute $2,000 from your paycheck to your 401(k), your employer might put $2,000 in too so the ending balance on your account after the pay period would be 
 <span>$4,000 higher<label for="sn-4khr"></label></span>
        
        <span>Usually, your employer will say something like "we'll match 6% of your paycheck." If you make $100,000 a year, that means if you contribute $6,000, your employer will also contribute $6,000. Your employer won't contribute any more than that, but you're free to contribute more from your own paycheck for greater personal tax savings.</span>
. You should always take advantage of the full match — it's free money!
</p>
<p>
You can invest the money in your 401(k) account from the selection of products (e.g., mutual funds) offered by your company's 401(k) plan administrator, typically a firm such as Fidelity or Vanguard. These products might be less appealing than what you'd get elsewhere, but it's all up to the plan administrator and generally not something you can control. It's also important to keep in mind that returns might be lower on these products due to administrative fees — which is one benefit of a separate individual retirement account (IRA).
</p>
<p>
When you leave your job, you can take your 401(k) with you. You can either move the funds into your new employer's 401(k), or move the funds into an individual retirement account (IRA). Generally, moving the funds into an IRA is a better decision (explained below).</p>   
</section></div><h4>Individual Retirement Accounts (IRAs)</h4><div><section>

    <p>
Individual Retirement Accounts (IRAs) offer tax advantages like a 401(k), but don't need to be sponsored by an employer. Like a 401(k), they can be classified as either
<span>Roth<label for="sn-rothn"></label></span>
        
        <span>So-named because they were established by legislation championed by former Senator William Roth of Delaware.</span>
 or traditional.</p>
</section></div><div><section>
        <p>
        Note that unlike a 401(k), whose contribution limits reset every calendar year, the length of a "year" for contribution limit purposes for IRAs is actually fifteen months. You can make IRA contributions for a given tax year until the tax filing deadline for the year. That means that between January 1 and April 15 of the following year (tax day), you can contribute to your IRA for either the current year or the previous year.
        </p>
        <p>
        Also, you can only contribute to an IRA if you have employment income. If your total income this year was $1,000 from freelancing and $100,000 from investments, you'd only be able to contribute $1,000 to your IRAs.
        </p>
				<p>
You can invest the money in your IRA account in the investment options (stocks, bonds, mutual funds, etc.) offered by the provider of your IRA. This will often be a better selection of options than what you'd get through your 401(k).        </p>
</section></div><h4>Self-Directed IRAs (SDIRAs)</h4><div><section>
        <p>
A self-directed IRA (SDIRA) is not a separate IRA type per se, since an SDIRA can be either Roth or traditional.        </p>
        <p>
SDIRAs are offered by specialized firms. You would open one if you wanted to invest in assets other than the basic stock and bond products offered by a regular IRA provider like Fidelity or Vanguard. Depending on which firm you work with, they might support alternative investments like real estate, cryptocurrency, and startup equity. An SDIRA allows you to hold these assets in a tax-advantaged way, in the same way a regular IRA allows you to hold stocks and bonds in a tax-advantaged way.        </p>
				<p>
For example, let's say you open a self-directed Roth IRA and fund it with $6,000. Then, you invest that money in a real estate partnership. Next, the partnership buys a fourplex in Los Angeles and rents it out to four tenants. Any rental income you receive from that property will accrue in the account and you won't have to pay taxes on it, and if the property appreciates and you sell it, you won't have to pay capital gains taxes either — since growth in a Roth IRA is tax-free.
</p>
<p>
On the equity side, PayPal co-founder Max Levchin allegedly has almost $100 million of tax-free gains in his self-directed Roth IRA from the appreciation of his startup stock.
</p>
<p>
SDIRAs are less common than their regular IRA counterparts at Vanguard or Fidelity, but for people with long time horizons to retirement, the alternative investments they allow can help provide better returns (alpha). We'll talk more about this below under "Diversification".</p>
</section></div><h3>Playbook</h3><div><section>
<p>
Despite the complexity of all these different plan and account types, for most people, planning for retirement is pretty simple.
</p>

<p>
To start, you'll need to decide how to allocate your savings between the different plans — how much to contribute to your 401(k), and if you are able to or should contribute to your IRAs. Then — depending on your plan's offerings and what your income allows — you'll need to decide the type of account: 
				<span>Roth<label for="sn-rothp"></label></span>
        
        <span>
        The Roth 401(k) is a relatively new invention, so your employer's 401(k) administrator may not offer it. If that's the case, you're stuck with the traditional option. Also, unlike a Roth IRA, a Roth 401(k) has no income limits — you can contribute to a Roth 401(k) no matter how much money you make.
        </span>
 or traditional. Consider:</p>
 <ol type="1">
      
      <li>
      <b>401(k) matching: </b>
      Does your company offer a 401(k) plan and do they match your contributions? If yes, take advantage of the full match first. The immediate 100% return you get on the matched funds is better than almost anything else you'd get in the markets.
      </li>
      
      <li>
      <b>Tax bracket: </b>
			Do you think you'll be in a higher tax bracket now or when you retire? If you think you're going to be in a lower tax bracket in retirement, deferring taxes now through a traditional 401(k) or IRA makes more sense so you pay taxes in that lower retirement bracket when you withdraw. If you're very early in your career and think you're going to be in a higher tax bracket by the time you retire, Roth versions of those accounts make more sense, so you avoid taxes in that higher retirement bracket when you withdraw.      </li>
</ol>
<p>
Most people in tech are highly compensated (i.e. their retirement tax bracket will likely be lower than their current tax bracket — a good rule of thumb is whether you make 
<span>over ~$160,000<label for="sn-160k"></label></span>
        
        <span>
Here's an example. Let's say you plan to live on $100,000 a year in retirement (a relatively cushy amount). In 2021, that would put you in the 24% bracket. If you make over $164,926 (the cutoff for the next bracket, 32%), you should defer your taxes to retirement.        </span>

) and work for companies with generous 401(k) matching. If that sounds like you, your playbook looks something like this (the order is important for maximum tax savings):
</p>
 <ol type="1">
      
      <li>
      <b>Opt for a traditional 401(k): </b>
			Deferring taxes until retirement makes sense since you're currently in a high tax bracket.
      </li>
      
      <li>
      <b>Maximize your match: </b>
			Contribute as much as you can to your 401(k) to take full advantage of your employer match. Ideally, the maximum of your employer match should be the minimum that you set aside for retirement — otherwise, you're leaving money on the table.
			</li>
      <li>
      <b>Continue contributing to your 401(k): </b>
If you can afford to save even more for retirement, keep contributing to your 401(k) until you hit the $19,500 limit to get the maximum tax deduction.
</li>

<li>
      <b>Contribute to a backdoor Roth (advanced): </b>
Contributing to a traditional IRA doesn't make sense if you've already contributed to a 401(k) since there's no extra tax deduction, so if you can afford to save more than $19,500, contribute up to …</li></ol></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withcompound.com/r/retirement-optimization-for-tech-employees">https://withcompound.com/r/retirement-optimization-for-tech-employees</a></em></p>]]>
            </description>
            <link>https://withcompound.com/r/retirement-optimization-for-tech-employees</link>
            <guid isPermaLink="false">hacker-news-small-sites-26240363</guid>
            <pubDate>Tue, 23 Feb 2021 17:53:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thought Space vs. Reality – Hypothesize Less, Validate More]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26240293">thread link</a>) | @suketk
<br/>
February 23, 2021 | https://suketk.com/thought-space-vs-reality | <a href="https://web.archive.org/web/*/https://suketk.com/thought-space-vs-reality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>There are two worlds - the one in our head and the one that is real. It’s easy to conflate the two; perception is reality, the saying goes. But they are separate. Perception is just a representation of reality and as we know, <a href="https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation">the map is not the territory</a>.</p>

<p>We use thought space to model reality. It serves us well for simple activities, enabling us to successfully predict the consequences of our actions (e.g driving through a yellow light). For more involved tasks, however, we overestimate the fidelity of our model. As a result, operating excessively in thought space impedes us from creating the desired outcomes in the real world.</p>

<p>Here’s a recent example. When I reviewed the draft of my <a href="https://suketk.com/feeds-considered-harmful">first essay</a>, I was preoccupied with this question: will anyone find this useful? I pored over it, top to bottom. On the first pass, it was elementary. On the next, it was profound. On another, it was too abstract. As I dizzily vacillated between opinions, a realization struck - the essay itself hadn’t changed. Only my impression did. In fact, the quality of the essay was impervious to my perception. It would remain as good (or bad) as it was, regardless of my impression. I was pursuing the wrong goal. An “accurate” opinion was just a means to an end - to determine whether others would find it useful. So, rather than continue theorizing, I decided to publish it to uncover the answer directly.</p>

<p>Prolonged time in thought space doesn’t just slow us down. It leads us astray and delays course correction, through misplaced confidence in our judgement. Ever dreaded a conversation, building it up in your head, only to realize it was nothing to worry about? Left unchecked, our perception steadily drifts away from reality. To keep them in sync, we must regularly validate our hypothesis in the real world. If we don’t, our future actions are built on a shaky foundation of invalid assumptions. Consequently, we waste valuable energy on outcomes that don’t manifest in the way we intend. Consider how many successful founders had to pivot from their first idea. Would their companies be alive if they spent years perfecting the original idea in isolation? No. This is the exact danger of perfectionism (perfectionitis?) - the misallocation of resources towards success defined by a model that isn’t representative of reality.</p>

<p>Thought space alone does not move us forward. Reading a book on productivity doesn’t make you more effective. Listening to a startup podcast doesn’t make you a better entrepreneur. Watching a cooking video doesn’t make you a better chef. Action is the interface between thought space and the real world - we actualize our ideas by doing. Knowledge is merely potential energy. Only when applied, does it translate to growth. If not, it just creates an illusion of progress. (This exemplifies the explore/exploit framework discussed in this <a href="https://suketk.com/feeds-considered-harmful">previous essay</a>.)</p>

<p>Next time you’re doing anything, ask yourself this question: am I operating in thought space or reality? This awareness helps you identify your untested assumptions and induces a general bias towards action. By tightening the feedback loop, you empower yourself to simultaneously build a better map and conquer the territory.</p>

  </div>
</article></div>]]>
            </description>
            <link>https://suketk.com/thought-space-vs-reality</link>
            <guid isPermaLink="false">hacker-news-small-sites-26240293</guid>
            <pubDate>Tue, 23 Feb 2021 17:46:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meaninglessness of the National Debt]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26239799">thread link</a>) | @paulpauper
<br/>
February 23, 2021 | https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/ | <a href="https://web.archive.org/web/*/https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-22257">
	
	<!-- .entry-header -->

	<div>
		<p>The ‘national debt’ has been a fixture of news and politics, probably since the founding of America. Although the national debt continues to swell–at $27 trillion or so as of writing this–my opinion has not changed, that being the national debt is a meaningless number, much like a mathematical abstraction, that has no  bearing on one’s life or investment strategies.  Articles about the <a href="https://wolfstreet.com/2019/11/02/us-national-debt-passed-23-trillion-jumped-1-3-trillion-in-12-months/">size</a> of the national debt have gone viral on Hacker News and Reddit , as well as headlines about how approximately <a href="https://www.thestreet.com/mishtalk/economics/23-6-of-all-us-dollars-were-created-in-the-last-year">“a quarter all US Dollars were created in past year”</a>. This surge in spending is in large part due to due to Covid stimulus and relief, as shown below:</p>
<p><img src="https://wolfstreet.com/wp-content/uploads/2019/11/US-Gross-National-Debt-2011-2019-11-02.png"></p>
<p>Why am I not concerned? For one, deficit hawks have a terrible track record. Doomsayers like Peter Schiff and Karl Denninger have been predicting hyperinflation, dollar collapse, recession, crisis, etc. for decades, to no avail. This does not mean that they cannot, in theory, one day be right, but I think the odds of that happening are sufficiently low to not pay them any mind. </p>
<p>So why is the debt an abstraction, as opposed to a tangible, real concern. Aren’t these big numbers? Yes, they are big, but what must be taken into account are a couple factors: about 40% of the national debt is owed to itself, either held by the fed or government institutions (such as for Social Security and Medicare), whereas the other 60% are held by foreign governments and private individuals and firms. So this effectively reduces the burden by almost half.</p>
<p><img src="https://ei.marketwatch.com/Multimedia/2018/08/21/Photos/ZQ/MW-GO672_nation_20180821130954_ZQ.jpg?uuid=05b585b6-a565-11e8-b6ab-ac162d7bc1f7"></p>
<p>Second, what matters is not so much the absolute size of the debt but rather the interest paid on the debt relative to GDP, which is very low. The US economy is growing fast enough that the deficit , even if it keeps growing, the interest paid keeps shrinking relative to the size of the economy. </p>
<p><img src="https://www.economicshelp.org/wp-content/uploads/2013/02/debt-interest-payments-percent-gdp-600x434.png"></p>
<p>The US economy is growing at 3+%/year (which may not seem like much but it beats Europe, Japan, South America and much of the developed and developing  world on a real basis), but the US government can borrow at close to nothing, so this is effectively free growth.</p>
<p>Second, the properties or characteristics of the national debt are so distinct from a personal, household, or business debt that there is practically no comparison between the two, further making it an abstraction and divorcing it from any reality that we are familiar with. Imagine being able to borrow at close to nothing, and then being able to print money to pay the interest on the debt if necessary, and such printing does not cause wealth destruction or much inflation in the process, as the US dollar is the official ‘global unit’ of wealth (the Forbes 400 list, for example, is denominated in dollars, not Pounds, Yen, or Euro). So even if the treasury were to print enough dollars to cause price levels to rise meaningfully, because everything is still indexed in dollars, Americans do not lose wealth in the process unless the US dollar falls relative to foreign currencies and there is not a sufficiently high corresponding increase of wealth from wages, stocks, real estate, etc. to offset this, but it is not like Americans particularly care how their wealth is growing or shrinking relative to the Brits, the Germans, or the Japanese. </p>
<p>However, when emerging markets governments print money, it causes their currencies to fall relative to benchmarks like the US dollar, which cases wealth destruction and makes the debt harder to service. By compassion, households and individuals pay vastly higher interest rates and cannot issue their own currency. This is obvious, but is a key distinction and why the US national debt should not be thought of in the same way as a regular debt. It really is something else entirely and more of a function or benchmark of the strength and might of the US global economic and cultural hegemony, than a ‘ticking time bomb’ as many in the media falsely liken it to.</p>
<p>But what about all the Covid spending, in particular, the increase of the M1 money supply? Won’t this cause inflation and other problems? But the spending already happened, and the bond market is unfazed. In fact, the bond market has held up in spite of trillions of dollars of Covid spending (and much more to come), showing that bond vigilantes are not concerned. Why is this? Because this money is not really doing anything. It is not inducing meaningful economic activity and business investment, but rather a large chunk of Covid aid is being saved or used to pay down existing debts. Only <a href="https://review.chicagobooth.edu/economics/2020/article/covid-19-stimulus-checks-spurred-saving-and-debt-payment-more-spending">40%</a> of Covid stimulus was spent on consumer goods, which was the intent. Hence it’s actually deflationary, because the US govt. is borrowing at near 0% so consumers can pay down their own double-digit debts, so the end result is much less indebtedness. Second, the amount of additional consumer spending and activity attributable to the stimulus checks is small relative to the size of overall US consumer spending. US consumers spent $15 trillion in 2020 but Covid stimulus adds just $1 trillion to that, assuming all the money is spent, which it is not.  </p>
<p><img src="https://graphics.reuters.com/USA-STOCKS/0100B2LV20C/personal-consumption.png"></p>
<p>Overall, I am not concerned about the national debt. [Emerging market debt, however, is a different beast altogether, and is a much bigger concern for those economics, than the national debt is a concern for the US economy] The national debt should not factor into the decision making processes of investors. Even bond holders should not be concerned.  In spite of the national debt surging over the past quarter-century, US stocks have posted strong inflation-adjusted returns, especially  since 2010. Treasuries and investment-grade corporate bonds have done well too. Anyone who sold their stocks over fears of the national debt, missed out on what has possibly been the biggest bull market in stocks on an inflation-adjusted basis, ever. The debt will never ‘come due’ in the way that rent or credit card bills have a strict deadlines; but will keep being rolled over forever. The media, pundits, talking heads, etc.  will continue to sound the alarm over the debt, but investors, hedge funds, pensions, institutions–people who actually matter and who have skin in the game–will continue to pay no mind to these warnings. </p>



<p><a target="_blank" onclick="window.open(this.href,'targetWindow','toolbar=no,location=0,status=no,menubar=no,scrollbars=yes,resizable=yes,width=600,height=250'); return false;" href="https://twitter.com/intent/tweet?via=&amp;text=The%20meaninglessness%20of%20the%20national%20debt&amp;url=https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/"><img src="http://i.imgur.com/2QyuBgQ.png"></a>

<a target="_blank" onclick="window.open(this.href,'targetWindow','toolbar=no,location=0,status=no,menubar=no,scrollbars=yes,resizable=yes,width=600,height=250'); return false;" href="http://www.facebook.com/sharer.php?u=https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/" data-href="https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/" data-send="false" data-layout="button_count" data-width="60" data-show-faces="false" rel="nofollow"><img src="http://i.imgur.com/OBWIOxN.png"></a>

			</p></div><!-- .entry-content -->

	</article></div>]]>
            </description>
            <link>https://greyenlightenment.com/the-meaninglessness-of-the-national-debt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239799</guid>
            <pubDate>Tue, 23 Feb 2021 17:10:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Streamlit to visualize object detection output]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26239676">thread link</a>) | @MatthewBrems
<br/>
February 23, 2021 | https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            <header>

                <section>
                    <a href="https://blog.streamlit.io/tag/community/">Community</a>
                </section>

                

                <p>Building an app for blood cell count detection</p>
            </header>

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2021/02/-White--Blood-Cell.gif 300w,
                            https://blog.streamlit.io/content/images/size/w600/2021/02/-White--Blood-Cell.gif 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2021/02/-White--Blood-Cell.gif 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2021/02/-White--Blood-Cell.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2021/02/-White--Blood-Cell.gif" alt="How to Use Roboflow and Streamlit to Visualize Object Detection Output">
            </figure>

            <section>
                <div>
                    <p>Most technology is designed to make your life, or your work, easier. If your work involves building computer vision into your applications, using the <a href="https://roboflow.com/">Roboflow</a> platform gives you everything you need.</p><p><a href="https://www.streamlit.io/">Streamlit</a> is an open-source platform that enables you to convert your Python scripts to apps and deploy them instantly. Streamlit and Roboflow can work hand-in-hand, allowing you to tackle computer vision problems and visualizing your output so you can make better decisions faster.</p><p>In this post, we’ll walk you through using Roboflow and Streamlit together by showing you how to:</p><ol><li>Fit an object detection model in Roboflow</li><li>Use an API to access the model and its predictions</li><li>Create and deploy a Streamlit app</li></ol><p>Specifically, we’ll be working with a common <a href="https://public.roboflow.com/object-detection/bccd">blood cell count and detection dataset</a>. If you want to skip right to playing with it, <a href="https://roboflow.com/streamlit-bccd">here's an interactive app</a> and <a href="https://github.com/matthewbrems/streamlit-bccd">this is the code</a>.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/1-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/1-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/1-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/1-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption>Red blood cells, white blood cells, and platelets.</figcaption></figure><p>We’ll build an object detection model that detects platelets, white blood cells, and red blood cells. Then, the app we develop together will allow you to make predictions with your object detection model, visualize those predictions at a given confidence level, and edit those predictions based on your preferred confidence level with immediate visual feedback.</p><h3 id="how-to-fit-an-object-detection-model-in-roboflow">How to fit an object detection model in Roboflow</h3><p>Have you fit an object detection model before?</p><p>Even if you haven't, Roboflow helps you work through all aspects of computer vision, from uploading, annotating, and organizing your images to training and deploying a computer vision model.</p><p>We believe you shouldn’t have to be a data scientist or need an extensive coding background to be able to use computer vision. You have everything you need right now.</p><figure><img src="https://lh5.googleusercontent.com/Di4bkgiihzqyb4k47H3Ku0GX_amNEgd03y3QFqOzSzLp-Y08ONhYHOKH6a8C_GSEtmUPboTbIWO58gYZ0fW_ceDetVlTinWmh4UC9C3E2PAggPnh3PDW9lrWwLlzyfeXvYN63c1L" alt=""><figcaption>The computer vision workflow.</figcaption></figure><p><br>If you don’t already have a Roboflow account, you’ll need to <a href="https://app.roboflow.com/">head over to Roboflow and create one</a>. If you’d like to start training your model from a public dataset, Roboflow has a <a href="https://blog.roboflow.com/using-public-datasets/">great tutorial that describes</a> how to improve your model more quickly. (Or, you can <a href="https://docs.roboflow.com/adding-data/upload-api">upload your own dataset</a>!)</p><p>Once you have an account, go to our <a href="https://public.roboflow.com/">computer vision datasets</a> page. We’ve made over 30 datasets of different types public and keep adding more.</p><p>The one we’ll walk through today is a blood cell count and detection dataset.</p><p>After you’ve decided which dataset to use, go ahead and fork it. That will create a copy of the dataset that you can now use.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/streamlit_fork_dataset_recording--2-.gif" alt=""><figcaption>Forking a <a href="http://public.roboflow.com/">public dataset</a>.</figcaption></figure><p>At this point, you can directly fit a model. However, we recommend that you preprocess and augment your images.</p><ul><li><strong>Image preprocessing.</strong> Deterministic steps performed to all images prior to feeding them into the model. For example, you might <a href="https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/">resize your images</a> so they are all the same size, or <a href="https://blog.roboflow.com/when-to-use-grayscale-as-a-preprocessing-step/">convert your images to grayscale</a>.</li><li><strong>Image augmentation.</strong> Creating more training examples by distorting your input images so your model doesn't overfit on specific training examples. For example, you may <a href="https://blog.roboflow.com/how-flip-augmentation-improves-model-performance/">flip</a>, <a href="https://blog.roboflow.com/why-and-how-to-implement-random-rotate-data-augmentation/">rotate</a>, <a href="https://blog.roboflow.com/using-blur-in-computer-vision-preprocessing/">blur</a>, or <a href="https://blog.roboflow.com/why-to-add-noise-to-images-for-machine-learning/">add noise to your images</a>. The goal is to get your model to generalize better to “the real world” when you deploy your model.</li></ul><p>With the blood cell count dataset I’m using, I chose the following preprocessing and augmentation options:</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/2-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/2-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/2-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/2-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://docs.roboflow.com/image-transformations/image-preprocessing">Image preprocessing</a> and <a href="https://docs.roboflow.com/image-transformations/image-augmentation">image augmentation</a> techniques.</figcaption></figure><p>When deciding whether to use a specific augmentation option, I asked myself the question “Is the augmented image a reasonable image for my model to see?” In this case, I added 90°, 180°, and 270° rotations to my image because the slide of cells could reasonably be rotated 90 degrees and still make sense.</p><p>It wouldn't make sense for all applications. For instance, I might not include that kind of rotation for a self-driving car, because stop signs should be seen with the pole jutting into the ground. To rotate the image 180 degrees would make the stop sign upside down and the ground where the sky should be -- that probably isn’t a very useful thing for my model to learn.<br></p><figure><img src="https://blog.streamlit.io/content/images/2021/02/3-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/3-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/3-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/3-1.png 1200w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://blog.roboflow.com/train-test-split/">Training, validation, and testing splits</a>.</figcaption></figure><p>I have my data split up so that 70% of my data is in the training set, 20% is in the validation set, and 10% is in the test set. As you may know, splitting your data into <a href="https://blog.roboflow.com/train-test-split/">training, validation, and testing sets</a> can really help avoid overfitting.</p><p>I’ve decided to create three augmentations. This means that, for each <em>training</em> image, we’ll create three copies of that image, each with random augmentation techniques applied to it. This will give me a total of 874 images that are generated:</p><ul><li>765 augmented training images (765 = 255 * 3) </li><li>plus 73 validation images </li><li>plus 36 testing images.</li></ul><p>Once you’re done with your preprocessing and augmentation, click “Generate” in the top-right corner. <em>Helpful hint:</em> make sure to name your dataset something memorable!</p><h3 id="now-you-re-ready-to-build-a-model">Now you’re ready to build a model</h3><p>To build a model, it’s as easy as clicking “Use Roboflow Train.”</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/4-2.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/4-2.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/4-2.png 1000w, https://blog.streamlit.io/content/images/2021/02/4-2.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Generally, you need a Roboflow Train credit to do this. <a href="https://roboflow.com/contact?utm_source=streamlit&amp;utm_medium=blog&amp;utm_campaign=train">Reach out to us and we’ll get you set up</a>!</p><p>You’ll have the option either to train from scratch or to start from a checkpoint.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/5-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/5-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/5-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/5-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><ul><li><strong>Train from Scratch.</strong> This is the easier option. Just click and go! Your model will be built from scratch, using only the data you’ve provided to it.</li><li><strong>Start from a Checkpoint.</strong> This option is a little more sophisticated and requires a related existing model. If you’ve already built a model (or if there’s a public model) that has been fit on related data, then starting from a checkpoint allows you to use the existing model as your starting point. The model is additionally trained on your images. Two advantages to this are that your model will train more quickly, and you'll frequently see improved performance! This is known as <a href="https://blog.roboflow.com/a-primer-on-transfer-learning/">transfer learning</a>. However, this does require a related existing model, and we don't always have that.</li></ul><p>In my case, I built my model from scratch, because I didn’t already have a related model.</p><p>That’s all it takes to fit a model in Roboflow. When all is said and done, if your data is already annotated and you don’t make many changes to the augmentations, it’s only a handful of clicks to go from your images to a trained computer vision model. We've also turned <a href="https://docs.roboflow.com/annotate">annotating images into a pretty fast process</a> – especially with <a href="https://blog.roboflow.com/announcing-label-assist/">model-assisted labeling</a>.</p><h3 id="how-to-use-an-api-to-access-the-model-and-predictions">How to use an API to access the model and predictions<br></h3><figure><img src="https://blog.streamlit.io/content/images/2021/02/6-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/6-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/6-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/6-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>You’ll want to make sure your model performs well before getting too far into this. </p><p>Our model seems to perform pretty well. Usually, we use <a href="https://blog.roboflow.com/mean-average-precision/">mean average precision</a> (mAP) to evaluate object detection models. The closer your mAP is to 100%, the better! It’s also helpful to look at your <a href="https://blog.roboflow.com/mean-average-precision-per-class/">model’s performance by class</a> to make sure your object detection model isn’t performing significantly worse for one subset of objects.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/7-2.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/7-2.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/7-2.png 1000w, https://blog.streamlit.io/content/images/2021/02/7-2.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>If your model isn’t performing the way you want, you may want to work on improving that before you proceed. We usually see dramatic improvements in models when people take one (or both) of the following two actions:</p><ol><li><a href="https://blog.roboflow.com/tips-for-how-to-label-images/"><strong>Improve their labeling</strong></a><strong>.</strong> Placing bounding boxes around the entire object, but as close to the edges of the object as possible, can improve your model’s performance.</li><li><a href="https://blog.roboflow.com/handling-unbalanced-classes/"><strong>Correcting for unbalanced classes</strong></a><strong>.</strong> Having one or more classes that are severely underrepresented can make it harder for your model to properly identify those underrepresented classes. A basic example is if you show a child 5 pictures of a dog and 100 pictures of a cat, the child may not do a very good job of identifying a dog.</li></ol><p>Now that we’ve fit a model, we can use that model to generate predictions on new images. The <a href="https://docs.roboflow.com/inference">Roboflow Infer API</a> is one of a few ways to conduct inference and that's what we’ll use.</p><p>In order to use the API, we’ll need a couple of pieces of information from Roboflow. <strong>Make sure you keep these both private. </strong>These are specific to you!</p><ul><li>The model name: this should begin with <code>rf</code>.</li><li>The access token/API key: this should be a 12+ letter code.</li></ul><p>This information can be found in multiple places. I like retrieving these from the Example Web App, because I’ll also easily upload an image and test out my model from there. Once you have these pieces of information, you’ll want to store them – you’ll need them momentarily.</p><h3 id="how-to-create-and-deploy-a-streamlit-app">How to create and deploy a Streamlit app</h3><p>Deploying a Streamlit app is easy. Even if you haven’t spent a lot of time focused on deploying apps before. (Here is the <a href="https://github.com/matthewbrems/streamlit-bccd/blob/master/streamlit_app.py">code I wrote to build the app</a>.)</p><p>Following <a href="https://docs.streamlit.io/en/stable/api.html">Streamlit’s API documentation</a> closely, I was able to build an app that:</p><ul><li>Imported an image file from my computer</li><li>Allowed the user to tweak parameters of our computer vision model</li><li>Showed my imported image overlaid with the model’s predicted annotations</li><li>Calculated and displayed summary statistics about the image and predictions</li><li>Generated a histogram of confidence levels for bounding boxes</li></ul><p>I chose to structure this in two physical components: a sidebar and the main area.</p><ul><li><strong>Sidebar.</strong> In the sidebar, the user gets to select a file to import from their local computer. This is where the user can select an image to pull into the app and edit the confidence and overlap thresholds used when generating predicted bounding boxes for the image.<br></li></ul><figure><img src="https://blog.streamlit.io/content/images/2021/02/8-1.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/8-1.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/8-1.png 1000w, https://blog.streamlit.io/content/images/2021/02/8-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p><strong>Main Area.</strong> In the main area, we have everything else I mentioned. The image that includes predictions, some statistics about the image and predictions itself, a histogram that shows the confidence levels for all bounding boxes, and a printout of the JSON that stores the bounding box annotations.</p><figure><img src="https://blog.streamlit.io/content/images/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2021/02/Screen-Shot-2021-02-22-at-10.00.39-AM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>If you want to see the full code, <a href="https://github.com/matthewbrems/bccd_streamlit_app/blob/main/streamlit_app.py">you can find it here</a>. The three tools that were most helpful in putting this together were:</p><ul><li><strong><code>st.write()</code></strong>: If I wanted to print anything on my screen, <code>st.write()</code> enabled me to do that easily. It supports <a href="https://daringfireball.net/projects/markdown/">Markdown</a>, so I can use ## to control how large or small I want my headings to be. I also used <a href="https://realpython.com/python-f-strings/">f-strings</a> when displaying summary statistics to have more control over how these rendered. For example, rounding …</li></ul></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/">https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/</a></em></p>]]>
            </description>
            <link>https://blog.streamlit.io/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239676</guid>
            <pubDate>Tue, 23 Feb 2021 17:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ideal way how you want your functional monitoring to run is]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26239573">thread link</a>) | @testRigor
<br/>
February 23, 2021 | https://blog.testrigor.com/what-is-functional-monitoring/ | <a href="https://web.archive.org/web/*/https://blog.testrigor.com/what-is-functional-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <figure><img src="https://blog.testrigor.com/content/images/2021/02/AdobeStock_378844640.jpeg" alt="" srcset="https://blog.testrigor.com/content/images/size/w600/2021/02/AdobeStock_378844640.jpeg 600w, https://blog.testrigor.com/content/images/size/w1000/2021/02/AdobeStock_378844640.jpeg 1000w, https://blog.testrigor.com/content/images/size/w1600/2021/02/AdobeStock_378844640.jpeg 1600w, https://blog.testrigor.com/content/images/size/w2400/2021/02/AdobeStock_378844640.jpeg 2400w" sizes="(min-width: 720px) 720px"></figure><h3 id="the-issue">The issue</h3><p>Imagine, that you have monitoring, everything is setup great and your metrics show green. But your customers can't purchase your product in your production or registration doesn't work.</p><p>This is why you'd want to set up something that would monitor that your product works in production from end-user's perspective.</p><h3 id="why-is-it-a-challenge">Why is it a challenge?</h3><p>There is an inherit challenge with functional monitoring: test stability. You don't want to be woken up in the middle of the night because a test flaked out.</p><h3 id="how-it-should-work">How it should work?</h3><p>The ideal way how you want your functional monitoring to run is:</p><p>1) To have a continuously running smoke test suite that would only notify you if there is an issue. This way if your customers can't buy a product or register you'd be immediately notified about it.</p><p>2) Get your notifications on all the right channels like Slack, Email, SMS, Phone.</p><p>3) Your tests are actually testing important functionality that if not working will have tangible business impact on your business.</p>
              </div></div>]]>
            </description>
            <link>https://blog.testrigor.com/what-is-functional-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239573</guid>
            <pubDate>Tue, 23 Feb 2021 16:54:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Still Sucks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26239543">thread link</a>) | @graiz
<br/>
February 23, 2021 | https://gregraiz.com/css-still-sucks/ | <a href="https://web.archive.org/web/*/https://gregraiz.com/css-still-sucks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main"><article id="post-875"><div><div><p>In 2006 I wrote a blog post about how CSS sucks. The post was popular and somewhat controversial. It’s been 15 years and the core of the problem remains. CSS has certainly improved but it’s still holding back designers and engineers.</p><p>I’ve reposted the blog post with the original comments from blogger as the original site was taken down.</p><hr><p><em>Sept 25th, 2006</em> – CSS Sucks</p><p>CSS is certainly an improvement on plain old HTML but its limitations are staggering and the lack of industry support will continue to hold back designers for many years to come unless we begin to build and design something better.</p><ol><li>For all that CSS has been able to do it’s a technological failure. CSS just doesn’t work as expected. How can I say it’s a failure when millions of sites use it? CSS can be used to style basic text attributes but browsers aren’t consistent in how they use this technology. Even though there is a “standard” and some browsers partially adhere to the standard to truly be a useful standard you need two things: Predictability and Consistency. CSS has neither. Any designer who has tried to create a large and complex site using CSS will tell you that all popular browsers interpret the standard differently.</li><li>CSS is ‘markup centric’ not ‘design centric.’ I have this idea that designers should spend more time designing great looking sites and less time fiddling around with markup tags and browser compatibility. When I say ‘markup centric’ I mean that every CSS design tool forces users to go into source code mode to create an attractive modern site. Many designers take pride in hand coding CSS. Tools for designers should be design centric. PDF/postscript is a good example of a design centric markup , (unfortunately not very suitable for the web.) Designers don’t argue about how to create semantically correct postscript tags they just create great designs using great design tools. CSS sucks because it forces designers to think about how to make it work technically rather than how to make it work from a design perspective.</li><li>Why on earth do we think that cascading is a useful feature? The way that styles cascade from one level of layout to a deeper layout makes it difficult to figure out why a particular item is styled in a certain way. By contrast non-cascading style sheets would be equally powerful and more predictable. The cascading makes it harder to interpret the page for both the designer as well as the web-browser. In fact the complexities in cascading is one of the reasons why so many browsers screw up the standard. In theory cascading could save bandwidth but in practice it creates bloated documents to get around the cascading issues.</li><li>The box-model is too simplistic. The high level idea of CSS is that you can create attractive pages using margin, border, padding and content attributes. While this is a nice theory, it’s primitive in its understanding of both layout problems and design. Highly developed design tools have layout engines that offer multiple layouts, non-rectangular margins, proportional layouts, dock-able layouts, table layouts, column layouts, etc. etc. It’ll be years before these features make it to CSS and many more before browsers implement them with any consistency. If browsers keep spending so much time on CSS they’ll have a well polished turd. Tools like Aldus Page Maker had better design tools, font tools and layout capabilities 10 years ago. This is because good design tools start with the design, not the markup.</li><li>When writing software you learn what works and what doesn’t. You get new and better ideas and you throw away the old ones. This process of starting fresh is absent from the current CSS way of thinking. Each version of CSS builds on the previous one without acknowledging any fundamental flaws. CSS and its HTML sibling are the ultimate designs by committee. Any enhancements to CSS/HTML are piled on top of the old standards. This makes it progressively harder to create powerful, compatible and consistent browsers. This also makes it harder for designers to create sites that target the new platform because they are constantly trying to satisfy the compatibility with older browsers. Version compatibility has to be all or nothing. If you support V3 it has to be 100% supported and tested. Supporting some of the features actually makes things worse.</li><li>There shouldn’t be multiple right answers for a visual design. The way CSS works there can be many ways to do the same thing. In fact there seem to be endless debates about the proper way to hack together trivial things like rounded corners. Rounded Corners? I mean really! Again I refer you to Aldus and even MS Word circa 1997. These features are not that hard to develop but getting them to work in a “standard way” seems to be all but impossible.</li><li>CSS captures styles not semantics or design intention. A design intention would be something like: “I want to balance these two columns” or perhaps “This text should line up with the logo image in the first column.” When designers do things like this:<pre>  #content{position:relative;top:32px;left:20%;width:40%;}</pre><p>They are capturing the style specifics not the design intention. Why 32 pixels? Why 40%? Perhaps the logo is 32px tall? Perhaps the other column is 60% wide? When the logo changes size or placement how will you know what styles to touch? There is a basic concept called parametric design that can be used to specify the parameters of the design. This concept helps embody the design intention as a set of rules that can then be preserved as the design changes. Even a very simple parametric design allows you to preserve design intention rather then hard coding sizes and dimensions.</p></li><li>Design should be declarative not interpreted. Again CSS has to process a large number of rules before it can figure out where things are supposed to go. After these rules are interpreted this data is thrown out and each and every browser that opens up the web-page has to re-interpret the data. This is incredibly inefficient. First of it makes web-pages load very slowly. Even when you’re on a fast connection the browser can’t figure out where to place objects until the entire web-page has finished loading. Secondly this interpretation is very prone to errors. A declarative design isn’t open to as much interpretation allowing it both render quickly and consistently.</li><li>CSS is a pain to work with. Take a look at some of the designs over at CSSZenGarden. The designs are both attractive and sophisticated. A good designer could take these designs and mock up similar designs in PhotoShop or Illustrator in a matter of hours but take the same designs and ask for it in CSS and it may take a couple days. Each time you make an edit to your CSS you have to refresh your browser to see what it’s actually going to look like. Then after you get one browser working you need to double back and get the other browsers working.</li><li>If you can’t get consistency across browsers then you can’t rely on CSS to accurately and properly design your site. If you can’t get the site to look <span>exactly </span>the way you want on every single browser then how can you claim that CSS is a good design tool or even a success? The fact that there is no alternative to create attractive websites doesn’t make CSS a good tool. There are two ways to solve the problem. The first is to continue to hammer on standards and CSS asking for a better solution. This has been happening for the last 10 years and it just doesn’t work. The alternative is to realize that CSS is flawed in it’s intrinsic design and begin to ask the questions of how could you do it better?</li></ol><p>——–</p><p><strong>Archived comments from the original posting </strong></p><h4>39 Archived Comments:</h4></div></div></article></div></div>]]>
            </description>
            <link>https://gregraiz.com/css-still-sucks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239543</guid>
            <pubDate>Tue, 23 Feb 2021 16:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How a secret European language ‘made a rabbit’ and survived]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26239231">thread link</a>) | @pepys
<br/>
February 23, 2021 | https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>They started out as</strong> apprentices looking for masters, students looking for teachers, or soldiers looking for wars, but they ended up as travelling tinkers, peddlers, beggars and thieves, members of the itinerant underground of central Europe. Carrying forged papers and false names, they were feared by peasants, shunned by burghers and hunted by the police. Catholics and Protestants, Jews, Sinti and Roma â€“ they had little in common, neither bonds of religion nor ethnicity, except for the life into which they had drifted, the life of the road.</p>
<p>The underground of central Europe, from the Middle Ages to the modern era, is all but inaccessible to us today. Those wandering its roads left few traces of themselves, except for the secret signs they carved on trees to warn each other of aggressive policemen and rabid dogs, or to recommend kindhearted householders willing to provide bread and water. These markings faded but there remains a way to catch glimpses of this lost world: its language. Over the course of hundreds of years, the people of the road evolved a distinct way of talking that strengthened their resilience, fostered solidarity and helped them survive. As it was purely spoken, this language, too, almost disappeared â€“ had it not been for police forces across central Europe that decoded it like the cipher used by enemy powers. Collaborating across jurisdictions from the Middle Ages to the 20th century, the police recorded this language by arresting its speakers and forcing them to divulge their words and phrases. The police also named it: Rotwelsch.</p>
<p><em>Rot</em> was a word for beggar (in Rotwelsch), and <em>welsch</em> could mean Italian but mostly it meant foreign and incomprehensible. There was some truth in the name, because Rotwelsch speakers freely mixed German, Yiddish, Hebrew, Czech and Romani, the language of the Sinti and Roma (who used to be called Gypsies because they were falsely believed to have originated in Egypt) in ways that were incomprehensible to outsiders. To German or Yiddish speakers, it sounded as if Rotwelsch speakers had stolen words and twisted their meaning.</p>
<p>Rotwelsch was a name for the language used not by the speakers themselves but by those who regarded vagrants as untrustworthy foreigners. While the police continued to believe that vagrants obscured their words deliberately to make it <em>welsch</em> to outsiders, in reality these vagrantsâ€™ words were only as incomprehensible as any language is to those who donâ€™t speak it. The true purpose of Rotwelsch was not to keep things secret but to help these outcasts navigate their daily lives and to create community among them. A second name captured this reality, <em>kochemer loshn</em>, which, like many words in this language, came from Hebrew: <em>chokmah</em>, for wisdom; and <em>loshn</em>, for tongue or language. This name didnâ€™t denounce the language as a beggarâ€™s cant but celebrated it as a way of talking for those in the know, as the lingo of the wise guys.</p>
<p>For Rotwelsch (or <em>kochemer loshn</em>) speakers, who were in permanent flight from the law, there was little difference between trading and stealing, which is why they had a single word for both, as for traded and stolen goods: the Yiddish word <em>sore</em>, meaning trouble, problem, calamity. Words for food, sex, and lice â€“ an affliction of itinerants everywhere â€“ abounded in their language, as did words for police and for getting arrested.</p>
<p>The police realised that he had an unusual skill: he was a good scribe, thanks to years of forging papers</p>
<p>The worst that could happen was being sent to <em>school</em>, which meant going to prison, a phrase adapted from the German <em>Schule</em> (school), which had been transformed into the Yiddish word for synagogue. (Calling prison â€˜schoolâ€™ later became common in the American underground and was used, most recently, in Martin Scorseseâ€™s film <em>The Irishman</em>). The 19th-century policeman Friedrich AvÃ©-Lallemant, the first true scholar of Rotwelsch, would have much to say about this equation of school and prison. He studied Rotwelsch and its speakers, and drew a single lesson from the experience: the necessity for police reform.</p>
<p>To avoid being sent to school, Rotwelsch speakers had to cultivate the art of <em>making a rabbit</em>, by which they meant how best to make like a rabbit and dash off.</p>
<p>This witty and wise language, which mistrusted big words and official institutions, expressed with poetic precision what it was like to live in difficult circumstances, of <em>being in a pickle</em>. But why a pickle? Actually, the whole phrase was a misunderstanding, a false translation from Rotwelsch. The original Yiddish phrase (<em>Zores und Jokreszeit</em>) had nothing to do with pickles, only sounded like them (to German ears, like <em>Saure Gurkenzeit</em>, or â€˜pickled cucumber timeâ€™), so that German speakers mistakenly started talking of pickles when they were in trouble. Before long, the phrase entered English, which means that you, too, dear reader, have been speaking Rotwelsch without realising it.</p>
<p><strong>Ferdinand Baumhauer was one</strong> of the Rotwelsch speakers whose life is reconstructed in my recent <a href="https://wwnorton.com/books/9781324005919" rel="nofollow noreferrer noopener">book</a>. Born in 1818 into a family of cotton weavers, Baumhauer had apprenticed himself to a cobbler at 13, and a few years later begun the customary stint as a journeyman, hoping to learn from other masters of the trade. But Baumhauer quarrelled with another apprentice and left his position. Seeking cheap accommodation for the night, he chanced upon a shelter favoured by tramps, his first contact with the secret world of the road. Something about them appealed to him. Perhaps he was tired of having to serve masters who were often strict and abusive. He decided to quit his life as a journeyman and begin the more precarious one as a vagrant.</p>
<p>When Baumhauer was arrested many years later, the police realised that he had an unusual skill for a vagrant: he was a good scribe, thanks to years of forging papers. The police asked him to write down scenes from life in the underground. Baumhauer complied, filling a book with scenes of vagrancy written in his underground language. Baumhauer was the perfect informant, a vagrant with good penmanship. He even provided the decryption key â€“ the meanings of secret words â€“ on the right-hand side of each page and added helpful information at the bottom in the form of footnotes, aware of how little the police would know about the life he was describing.</p>
</div><div><figure data-align="center"><img src="https://d2e1bqvws99ptg.cloudfront.net/user_image_upload/1450/puchner-insert.jpg" alt="" title=""><figcaption>Baumhauerâ€™s book. <em>Image supplied by the author</em></figcaption></figure></div><div>
<p>He wrote of a family led by Walter and his wife, known as Walteress, making a narrow escape. A mounted policeman stops Walter to check their papers (undoubtedly forged) while Walteress has gone to beg in a nearby village for some <em>sore</em>. Walter convinces the policeman that nothing untoward is happening, but then the policeman hears dogs barking in the village and senses that something isnâ€™t right. Walter has already left by this time, and Walteress, thinking quickly on her feet, realises what a pickle sheâ€™s in, avoids the policeman and meets up with Walter away from the village. The policeman realises that the two have <em>made a rabbit</em> and pursues them. Fortunately, the Walter wagon races ahead and crosses the border to the next jurisdiction.</p>
<p>Baumhauer knew all about escape. Once heâ€™d finished writing his stories, the police relaxed their vigilance and he fled. The Baumhauer case is an unusual example of how this secret language survived via police archives. These records of Rotwelsch came from the intent to police its speakers, but they allowed me to reverse-engineer the lives of the speakers who expressed their view of the world through its distinct idiom.</p>
<p>Rotwelsch vagrants were among the first to be sent to concentration camps</p>
<p>Early researchers of Rotwelsch, such as AvÃ©-Lallemant, spoke of Rotwelsch as a â€˜professional languageâ€™, the technical jargon of thieves comparable with that of doctors, lawyers, hunters (and professors). Today, linguists speak of it as a <em>sociolect</em>, the speech of any distinct sub-group. A sociolect doesnâ€™t quite rise to the level of a full language because it doesnâ€™t have its own grammar; in the case of Rotwelsch, it borrowed its grammar from German. But precisely because Rotwelsch wasnâ€™t a regular language and instead consisted of words useful only to a specific group â€“ words for police, for getting into pickles, for getting arrested, for different kinds of prisons, and for making a quick escape â€“ it now works so well as a record of a particular way of life.</p>
<p><strong>My uncle, a bohemian</strong> writer who had become obsessed with Rotwelsch, introduced me to it when I was a child. Over the course of many years, he had tracked down its remaining speakers and assembled a large archive on the language. When he died, I inherited his archive, a unique resource for studying the now-lost world of this itinerant underground.</p>
<p>My study of Rotwelsch has also revealed secrets from my own family history. My grandfather, I learned, had been obsessed with Rotwelsch as well, although for different reasons. An early member of the Nazi Party, he had attacked Rotwelsch as an uncouth mixture of German and Yiddish that proved, to his mind, that all Jews were criminals. He wanted the language eliminated. Soon, he would almost get his wish, when Rotwelsch vagrants were among the first to be sent to concentration camps. After the war, he managed to avoid prosecution and bury his past. After learning of my grandfatherâ€™s role, I better understood why my uncle had devoted so much time to preserving and reviving Rotwelsch, and why he had taught the language to me: in a form of linguistic rebellion, perhaps even atonement, he decided to undo some of his fatherâ€™s work.</p>
<p>Throughout my research, I wondered what Rotwelsch sounded like. There would have been significant variations, depending on the different German dialects spoken in various regions of central Europe, from the Rhine to Prague, and from Hamburg to Zurich and Vienna, as well as dialects marked by Yiddish, Czech, Dutch and other regional languages. I …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived">https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/how-a-secret-european-language-made-a-rabbit-and-survived</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239231</guid>
            <pubDate>Tue, 23 Feb 2021 16:31:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rows launches a spreadsheet with data, integrations, and sharing]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26239210">thread link</a>) | @helhady
<br/>
February 23, 2021 | https://blog.rows.com/p/rows-beta | <a href="https://web.archive.org/web/*/https://blog.rows.com/p/rows-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><ol><li><p>Rows is coming out of our closed beta and launching in Public Beta<strong>. </strong></p></li><li><p>We have raised a $16 million Series B round, led by Lakestar. Our previous investors and other cool people joined us, too.</p></li></ol><p>Join us in this celebration! But first, what is Rows?</p><h3>Rows</h3><p>Rows is the only true Spreadsheet with Integrations and a slick Sharing experience.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe80e654c-cf95-48df-b894-309ded708b65_1200x316.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe80e654c-cf95-48df-b894-309ded708b65_1200x316.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e80e654c-cf95-48df-b894-309ded708b65_1200x316.png&quot;,&quot;height&quot;:316,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6454,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>One billion people in the world use spreadsheets, but it’s hard to connect them to different data sources and to turn them into something you actually like to share. Rows  solves this by integrating the 3 things people like: spreadsheets, data, and slick UIs.</p><p>You’ve never seen a spreadsheet like that! Check <a href="https://rows.com/">rows.com</a> for more info!</p><h3>🚀 Public Beta</h3><p>We’re now officially in a Public Beta!</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a43dd995-9054-40df-96b6-c6f417f4d8c7_1200x700.png&quot;,&quot;height&quot;:700,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:61461,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Going <em>Public</em> means that anyone can <a href="https://rows.com/auth/sign-up">create an account</a>. It also means that platform has been certified ready by our private beta users: we onboarded more than 10k users, and 100s of teams are active every week. Being a <em>Beta</em> also means that there’s just a handful of features left to ship until we baptize our spreadsheet as a v1 later this year. </p><p><em>Rows is free for smaller teams with up to 10 users. We rolled out paid subscriptions for larger companies, starting at $59 per month. Rows will always have a free plan.</em></p><p>We are <strong>very</strong> excited to learn about what you will build with Rows!</p><h3>What’s Next</h3><p>Rows’ vision is to empower the world’s one billion spreadsheet users to build the tools they need. </p><p>Today, businesses use Rows for critical processes in <a href="https://rows.com/solutions/sales">sales</a>, <a href="https://rows.com/solutions/marketing">marketing</a>, and <a href="https://rows.com/solutions/operations">operations</a>. We will continue to serve these use cases, and expand them with exciting new features. Throughout 2021, our team in Porto and Berlin have lined up (more than) a few serious releases:</p><ul><li><p>More classic spreadsheet functionality, like Charts and conditional formatting. </p></li><li><p>Upgraded Integrations, including easier and faster data management; and, of course, more functions and Integrations (we’re beyond 50 now).</p></li><li><p>New elements for Sharing, including a new button, drop-downs, and more.</p></li></ul><p>We are also working on a Desktop App 👩‍💻!</p><h3>Series B Funding</h3><p>Today we are also announcing our Series B round, led by <a href="https://www.lakestar.com/">Lakestar</a>! The round had the participation of our existing investors Accel and Cherry, as well as new entrants Armilar and Shilling from Portugal and Visionaries Club from Berlin. </p><p>Stephen Nundy, partner at Lakestar, is joining our board — and adding his tech and spreadsheet experience from his career at Goldman Sachs. Also joining our board is Christian Reber, CEO of <a href="https://pitch.com/">Pitch</a>. </p><p>We are very fortunate to continue evolving our company with such a strong board and advisors!<br>—</p><p>We are incredibly happy to be a part of the world of spreadsheets, and we’re excited to enter this new phase of our journey to empower spreadsheet users to build their own tools.</p><div><p>As always, we appreciate your support and love!</p><p>Let’s GO!<br>Humberto &amp; Torben<br>— Rows Founders</p></div></div></div>]]>
            </description>
            <link>https://blog.rows.com/p/rows-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239210</guid>
            <pubDate>Tue, 23 Feb 2021 16:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git is my buddy: Effective Git as a solo developer]]>
            </title>
            <description>
<![CDATA[
Score 389 | Comments 188 (<a href="https://news.ycombinator.com/item?id=26239068">thread link</a>) | @vortex_ape
<br/>
February 23, 2021 | https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/ | <a href="https://web.archive.org/web/*/https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<p><small>February 23, 2021 • Reading time: 12 minutes</small></p>

<p>At this point, most developers use Git as a tool for collaboration. We have our
rote-learned commands to pull, commit, and push. And of course, there's <a href="https://xkcd.com/1597/">that
one coworker</a> who knows a bit more about Git than
everyone else, who helps get us back on track whenever our local repos end up in
a strange state.</p>
<p>But what if I told you that Git can be a valuable tool without ever setting up a
remote repository? I'm not just talking about having a working version of your
code base to roll back to if you mess something up, although there's that too.
Used correctly, Git can help to structure your work, identifying gaps in your
test coverage and minimizing dead code.</p>
<p>There are two subjects I'm going to avoid for the purposes of this blog post:
other developers, who are the most compelling but least interesting argument
for keeping your commit history clean, and <code>git bisect</code>, which does factor
heavily into my workflow but deserves its own blog post.</p>
<p>As with any ubiquitous developer tool, the Git user base has a lot of strong and
conflicting opinions about the one "correct" way to use it. My goal is simply to
introduce a workflow that I've been using and refining for much of my career;
take from it what you will. And, importantly, it's a workflow that has become a
vital part not just of my collaboration process, but of the way I write code.</p>
<p>Ultimately, these principles serve two purposes: they focus my work onto a
particular bugfix, feature, or goal, and they ensure that my Git history isn't
set in stone. With proper hygiene, commits can be dropped, rearranged, and split
off into other branches painlessly and without merge conflicts.</p>
<h2 id="principle-1-a-branch-must-do-one-useful-thing">Principle 1: A branch must do one useful thing</h2>
<p>When I'm managing my own projects, I have a lot of ideas that I want to see
happen. If I'm just throwing one commit after another into <code>main</code>, I'll get
halfway through implementing one feature and then jump off to hacking on
another. If any of the features get completed, it will be at the expense of a
wasteland of half-completed features that are now taking up space in my code
base.</p>
<p>In a brand-new project, sure, I'll throw a bunch of garbage commits into <code>main</code>.
My rule of thumb for when to stop this is when I can write my first effective
integration test. If there is <em>something</em> useful to test, there is now enough
substance to my project that I can have distinct tasks on the go. Trying to
break into branches too early just results in me throwing my garbage commits
into a branch instead of main.</p>
<p>In the early stages of a project, articulating the purpose of a branch can be as
simple as giving it a descriptive name. If a commit isn't moving the code base
in that direction, it can always get cherry-picked into a different branch.</p>
<p>As the project matures, I'll start using some sort of issue or bug tracking
software to flesh out what I'm trying to accomplish in more detail and
coordinate the branches for multiple related useful things.</p>
<p>I find that descriptive branch names also help to refocus my attention on what
I'm trying to accomplish. For instance, my command prompt currently looks like
this:</p>
<pre><span>10:02:19 </span><span>max</span> <span>~/Projects/mikkel.ca</span> <span>blog-post-git-as-a-solo-developer</span><span>|</span> <span>R</span><span>%</span></pre>
<h2 id="principle-2-every-commit-must-be-independent">Principle 2: Every commit must be independent</h2>
<p>So much for branches, let's zoom into a commit level. I've articulated what
concrete thing I want my branch to add, now how do I add it? Usually, there's
some poking around my code base involved in figuring that out. Sometimes I take
a wrong turn, sometimes I just get distracted. That's okay, it's part of the
process.</p>
<p>However, that doesn't mean that every commit I make right now is going to end up
getting merged in this branch. By keeping my commits independent from one
another, I ensure that I can rearrange or cherry-pick them into new branches
if I discover that they really don't have anything to do with what I'm working
on right now.</p>
<p>If my commits are not independent, I am essentially stuck with the exact history
as it was written. Trying to tease out a commit into a different branch or move
it to the beginning of my branch history will become fraught with merge
conflicts as later commits that modified code introduced in this commit fall
like dominoes.</p>
<p>Obviously, I'm still allowed to call code written in one commit from a later
commit. That's the reason I'm doing this particular work in this particular
branch, after all. But I never touch the same code multiple times. If I have to
go back and fix something, maybe add a validation check or field that I hadn't
thought of, I'll go back to the commit where it was created rather than amending
it in a later commit.</p>
<p>Obviously, this could go on forever, which is why the "one useful thing"
principle exists. Once I've settled on what I want the code to look like for the
purposes of this branch, I merge and then start a new commit in the next branch
for further changes to the same.</p>
<h3 id="principle-2a-every-commit-must-include-its-own-tests">Principle 2a: Every commit must include its own tests</h3>
<p>Here's where keeping commits small starts to pay dividends. If the code in each
commit is small enough for me to reason about, it's small enough for me to
visually ensure that its test coverage is good.</p>
<p>And of course, if I do end up rearranging this commit or splitting it off to a
different branch, I want its tests to come along with.</p>
<p>The exception to this is integration and functional/behavioural tests, which can
and should have their own commits. In that case, the tests are really tied to
the branch level rather than the commit level, since Principle 1 implies that
there should be exactly one new test to add as a result of this branch.</p>
<h2 id="principle-2b-every-commit-must-pass-all-tests">Principle 2b: Every commit must pass all tests</h2>
<p>Again, breaking something in a commit (even if I <em>really definitely</em> intend to
fix it in a later commit) locks me into the git history as written. And
introducing a breaking change with the intention of fixing things later always
carries the risk that I'll get distracted and end up merging the breaking
change.</p>
<p>If there's some prerequisite to get this change to pass tests - say, a
preexisting bug that snuck through a hole in my test coverage - that gets its
own commit.</p>
<p>Speaking of holes in test coverage, there's another (temporary) exception here.
I don't normally practice strict <a href="https://en.wikipedia.org/wiki/Test-driven_development">test-driven
development</a>, but if I do
fix a long-standing bug, I normally temporarily put its test in a separate
commit. I'll then rebase so that the test appears before the fix, ensure that
the test fails <em>without</em> the fix, then complete the rebase and validate that the
test now passes. Once the due diligence to validate my test is done, I can go
ahead and squash the bugfix with its test.</p>
<h2 id="principle-3-draft-commits-are-fine">Principle 3: Draft commits are fine</h2>
<p>If I know that I'll be coming back to a change later, I'm much more comfortable
setting it down and moving on to roughing in the next part of the process,
rather than finishing, polishing, and unit testing code that might need to
change before my branch gets merged.</p>
<p>In fact, I find that I waste much less time on writing tests for things that
I'll later change when I'm following this workflow to the letter than I do when
I get "lazy" and start dumping everything into big catch-all commits.</p>
<p>Some people favour TODO comments in their code, occasionally supported by
automated checks that prevent code containing "TODO" from merging. I prefer to
annotate my commit messages and leave my code clean. Normally, this looks
something like "add controller class - TODO test me". (I always put my TODOs on
the first line of the commit message, so that they show up even in short log
views.)</p>
<h2 id="principle-4-it-s-okay-to-discard-commits-completely">Principle 4: It's okay to discard commits completely</h2>
<p>Often I start a task by tidying up the surrounding code, in the same way I might
organize my desk before starting work. (I don't, but I <em>might</em>.) Sometimes that
cleanup turns out to be a valuable part of the groundwork for this change, but
sometimes it's just dead weight. Keeping my commits independent makes it easy to
discard or cherry-pick out code that turned out to be unnecessary, along with
any unit tests that went along with.</p>
<p>(I do still consider the tidying to be a valuable part of the process. It clears
my mind and refreshes my knowledge of the problem space with some simple rote
tasks before I dive into something more complex. And occasionally it results in
cleaner code.)</p>

<p>I'm not perfect.<sup>[citation needed]</sup> Obviously, it's not practical to
maintain this level of commit hygiene by making each change sequentially.
Instead, I jump around <em>constantly</em>. Doing so requires me to be comfortable in
navigating my commit history. (Conversely, it's also a good way to <em>become</em>
comfortable with navigating history.)</p>
<p>In that vein, here are some tools beyond your standard
<code>checkout</code>/<code>branch</code>/<code>pull</code>/<code>commit</code>/<code>push</code> workflow that come in handy.</p>
<ul>
<li>
<p><a href="https://git-scm.com/docs/git-commit"><code>git commit --amend</code></a> – A quick and easy
way to update the most recent commit.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-commit"><code>git commit --fixup [hash]</code></a> – When
changing history, I used to find myself making a lot of commits with messages
like "merge me with xyz" if I need to revisit commits before the most recent
one. It turns out that <code>git commit</code> has flags to help with this: <code>--fixup</code> and
<code>--squash</code> will automatically suggest a fixup or squash with another commit
during rebase if the <code>--autosquash</code> flag is provided to that command. (To
enable this behaviour by default, run <code>git config --global rebase.autosquash true</code>. It won't behave any differently if there are no commit messages in the
history being edited that contain "squash!" or "fixup!".) A surprise bonus:
since the fixup operation inherits the message of the previous commit, you
won't be prompted to enter a new one.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-rebase"><code>git rebase --interactive main</code></a> – I can
also use <code>git rebase --interactive HEAD~5</code> to edit the last 5 commits, but I
find rebasing directly on <code>main</code> (or <code>master</code>, or whatever my upstream branch
is) kills two birds with one stone. It will show me all commits since I
branched off from <code>main</code>, and will simultaneously bring my branch up to date
with my latest local copy of main.</p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-stash"><code>git stash</code></a> – Sometimes I have unrelated</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/">https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/</a></em></p>]]>
            </description>
            <link>https://mikkel.ca/blog/git-is-my-buddy-effective-solo-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26239068</guid>
            <pubDate>Tue, 23 Feb 2021 16:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pairing makes better interviews than leetcode]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238905">thread link</a>) | @miiila
<br/>
February 23, 2021 | https://milavotradovec.cz/blog/pairing-makes-better-interviews-than-leetcode/ | <a href="https://web.archive.org/web/*/https://milavotradovec.cz/blog/pairing-makes-better-interviews-than-leetcode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>
            
    
        
            
    
    Sun Feb 21, 2021

        
        
            
                · 1227 words
            
        
        
            
            
                · 7 min
            
        
        
        </p><hr>
    
    <p>When I was explaining our interview process to my colleague, I realised that my approach is very different from what standard tech interviews are usually about. It is probably different from what interviews in general all about. But I am quite sure the usual way is broken and we need to work on a better framework. I am going to share my approach and hopefully, you can get some inspiration out of it.</p>
<h2 id="background">Background</h2>
<p>At <a href="https://snyk.io/">Snyk</a>, we have multiple rounds of interviews. It starts with a phone screening covering some general aspects, goes to the first round done by the hiring manager followed by a home task assignment. After a candidate sends us a home task, we review it and schedule the next round - pairing. If everything goes well, there is one more round with a hiring manager again covering more cultural aspects and work details in greater depth. I am usually involved in home task review and pairing sessions and I am going to focus on the second one here. Because I feel there is an improvement in the whole hiring process we can do.</p>
<h2 id="home-task-and-pairing">Home task and pairing</h2>
<p>Are a home task and the following pairing enough to assess candidate technical skills? Well, it goes to a fundamental question: “What do you want to know?” The biggest problem in interviewing is labelling candidates good or bad. If your framework can be described as “Is the candidate good enough to work here?”, you are limiting yourself and I would say you are limiting your potential growth and company culture as well. A better angle is: “Can we benefit from a candidate's current experience and focus?” Because there is no such thing as a failed interview. It is more about whether a company can see the use of a candidate's skills in the current time. And whether the candidate can see the potential for whatever they are interested in (learning, growth, responsibility, money, status). So what am I trying to address during my part of the interview? My question to ask is: “Would I like to sit next to this person for 4 hours and solve a problem together?”</p>
<h2 id="but-you-have-to-verify-their-skills">But you have to verify their skills</h2>
<p>You may be still wondering whether this can cover all the technical skills like algorithms knowledge, database modelling, testing… Well, it cannot. And I am 100% sure it’s not a problem. Because by asking coding puzzles questions (aka leetcoding), you are not addressing problem-solving capabilities. At best, you are addressing “solving coding puzzles” skills and how good they are in remembering chapters from the “How to crack a coding interview” book. The same goes for all other tech stuff - unless you are writing quick sort every day, don’t ask them to write it. Think about what you do in your day-to-day life. What are the challenges? How can you solve them on an acceptable, mediocre and exceptional level? And how do you want to feel when you are solving them with your colleagues?</p>
<h2 id="my-approach">My approach</h2>
<p>I have three main goals I have in mind while talking to a candidate:
Be respectful
Have fun
Learn something new
The main message here is to be on the same level as a candidate. I am not superior just because I am interviewing them. I bet we all have some terrible experiences from our past interviews where we felt pretty bad and useless. I don’t want to do this to anybody else. Therefore, I am not testing their knowledge. I am not asking them questions expecting one right answer. I am asking about their ideas and opinions. Nicely said, right? But how can you achieve that? One example from a recent interview. A candidate mentioned some changes they could do in their code and said they would need to make sure the performance is not impacted. I could ask questions like “What do you know about performance measuring?” or “What tools are we using to measure performance?”. But I said: “How would you measure whether it has a performance impact?”. By this, I allowed them to express both their opinions and experience. I can share some of mine as well asking them for feedback.</p>
<p>This setup greatly helps with the last learning part as well. I am not expecting any right answers, so we are rather talking and sharing our opinions. I can also learn a lot from theirs and I’m allowed to pass my experience to the candidate easily. It makes me happy when they mention they have learned something new during the discussion. </p>
<h2 id="evaluation">Evaluation</h2>
<p>This all sounds very nice, but all in all, it is still an interview and I should be able to articulate an answer and reasoning, whether I am for having this candidate in a team or not.</p>
<p>There are two main questions I am trying to answer are:
Are they able to understand and solve the problem using a programming language and other tools?
Do I enjoy working with them?</p>
<p>The first one is kind of straightforward. During pairing, you can usually very quickly spot if they need to check documentation every single time for writing even simple language constructs. If they can catch errors and extract functionality to better encapsulate units. And I pay special attention to debugging. I don’t need them to have a full-blown debugger, I just expect them to navigate their code effectively and have a good way of identifying where the problem can be.</p>
<p>Whether I am enjoying our discussion is more tricky. The most important part is not to be pulled into any kind of bias. I am keeping in mind I am representing a company culture and I need to understand if they would fit in. So I am trying to uncover how easy or hard it is for them to accept a different opinion or a suggestion. How can they clarify and support theirs? How verbose are they when thinking about the problem? As a company, we have a very open and sharing engineering structure. A quiet person, who needs to think for an hour by himself would be probably struggling heavily. The same goes for folks who need to solve everything on their own, without using libraries or asking for help or clarification. So this part is not about whether I would go for a beer with the candidate (although, if they join, it is likely to happen too). It is more about their fit for our standard way of working.</p>
<h2 id="let-s-improve-our-tech-interviews">Let's improve our tech interviews</h2>
<p>I am heavily convinced a lot of people are passing bad interview experience to others. Because “I had to deal with that, so they have to do it too” approach. Or because they simply don’t know how to do it differently. I am guilty of doing this too. But I have decided to stop. I am stepping down from a superior interviewer position and model the discussion as we would be colleagues already. Since I don't want to make my colleagues feel uncomfortable, there is no reason I should treat candidates differently. Because they can turn into colleagues easily.</p>
<p><em>Thanks for reading. Do you have any questions or errors to point out? Or just wanna chat? Let me know on <a href="https://twitter.com/MilaVot/status/1364246323277557760">Twitter</a>. Or add a comment on <a href="https://news.ycombinator.com/item?id=26238905">Hacker News</a>.</em></p>


        </div></div>]]>
            </description>
            <link>https://milavotradovec.cz/blog/pairing-makes-better-interviews-than-leetcode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238905</guid>
            <pubDate>Tue, 23 Feb 2021 16:07:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Release (YC W20) – 5 Ways Ephemeral Environments Improve Developer Velocity]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238650">thread link</a>) | @tommy_mcclung
<br/>
February 23, 2021 | https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>Velocity is a measurement of how many story points a software development team can finish within a sprint (usually one or two weeks). These points are set by the software development team when they review a ticket and estimate how complex the ticket is. When a team measures this output over a period of time, generally they have a consistent amount of story points they can deliver in a sprint and their velocity is known.</p><p>Improving developer velocity is directly correlated with performance. <a href="https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/developer-velocity-how-software-excellence-fuels-business-performance" title="Link to mckinsey developer velocity study" target="_blank" rel="noreferrer">McKinsey published an article in April 2020</a>, where they cite that companies in the top 25% on their Developer Velocity Index grow up to twice as fast as companies in their same industries. Intuitively this makes sense since delivering more allows the development team to learn through iterating and improving. </p><p>One might argue that velocity alone doesn’t make for great software, but assuming a development team is aware that quality is important, one can see how velocity usually helps. The ability to deliver quickly also allows a development team to address quality issues quickly. It’s easy to argue that development teams with high velocity have the ability to deliver better quality software because they can address issues quickly.</p><p>In the same study, McKinsey highlighted several factors that allow a software development team to move quickly. Specifically they highlight that Technology Tools are an incredibly important dimension to velocity and business outcomes. And the most important tools are: Planning, Collaboration, Development and DevOps tools. </p><p>In this post I’m going to discuss the <strong>top 5 ways Ephemeral Environments can improve developer velocity</strong> by touching on how they are a <em>Collaboration</em>, <em>Development</em> and <em>DevOps</em> tool. As we’ve spoken about in our article <a href="https://releaseapp.io/ephemeral-environments" title="What is an Ephemeral Environment" target="_blank" rel="noreferrer">“What is an Ephemeral Environment?”</a>, ephemeral environments are spun up on demand and contain the code and data that approximates production closely. These environments are used by development teams in the software development process to test, debug and ensure features are built correctly before code is pushed to production.</p><h2 id="here-are-the-top-5-ways-ephemeral-environments-can-be-used-to-improve-developer-velocity">Here are the top 5 ways ephemeral environments can be used to improve developer velocity</h2><h3 id="1-ephemeral-environments-are-a-devops-tool-designed-to-remove-the-staging-or-qa-environment-bottleneck"><strong>1. Ephemeral environments are a DevOps tool designed to remove the staging or QA environment bottleneck</strong></h3><p>Traditional pre-production ecosystems usually have a limited amount of environments for developers. The staging or QA environment is generally used as a step before production where all code is merged and tested. Most organizations have one or very few of these environments, so as the organization grows these environments become a bottleneck in the process as all code must be tested here before production. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/57RYmuBRfBBWCRUWglqBnZ/14bafeeb0a47fd566938d2ff052a01c6/Screen_Shot_2021-02-22_at_2.43.18_PM.png" alt="Example of ephemeral environments for each branch"></p><p>With ephemeral environments, the traditional idea of “staging” is gone. Every feature branch is contained in its own isolated environment and becomes its own integration environment. There is no longer a need to have a single testing and integration environment where all code must merge before going to production. With ephemeral environments you have a limitless supply of environments for any purpose.</p><h3 id="2-ephemeral-environments-are-a-collaboration-tool-designed-to-allow-for-early-and-often-feedback"><strong>2. Ephemeral environments are a collaboration tool designed to allow for “early and often” feedback</strong></h3><p>Feedback is the lifeblood of great products. If you’ve ever read <a href="https://www.amazon.com/High-Output-Management-Andrew-Grove/dp/0679762884/" title="High Output Management Book" target="_blank" rel="noreferrer">Andy Grove’s book on high output management</a>, you know he does an amazing job of discussing how rework is so costly. If you haven’t read this book, I highly recommend it, even if all you read are the first few chapters where he discusses trying to cook a high quality egg repeatedly, in under three minutes. In summary, Andy suggested through this analogy that finding issues/defects early in the egg cooking process is the most important part of consistently cooking a high quality egg in under three minutes.</p><p>Likewise in software development, getting feedback and finding quality issues early in the development cycle reduces costly rework and improves velocity. If a product is delivered to a customer that doesn’t work or has bugs, it has to be reworked and go through the entire process again. Or if a product manager or designer doesn’t have a way to see changes until an engineer is finished with development, there is a high likelihood they will spot something wrong and rework the solution. These are all examples of rotten eggs in the process that hamper developer velocity. </p><p>With ephemeral environments, rework can be minimized because stakeholders become a part of the development process. When an ephemeral environment is created, URLs to the environment are created so stakeholders can see progress while code is being developed. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2dFjnsY2lBSSbkaOfqczSG/3b9ef1f1134d5cf21f464af8dbf8fa93/Screen_Shot_2021-02-22_at_2.40.44_PM.png" alt="Links in the PR"></p><p>At <a href="https://releaseapp.io/" title="Link to Release Home Page" target="_blank" rel="noreferrer">Release</a>, we highly recommend to our customers that they create a PR as soon as a developer starts working on a feature so a Release Ephemeral Environment is automatically created. When the developer pushes code to their source control system, the environment is updated making it a live reflection of the feature during development. Product managers, designers and QA are automatically notified when changes are live and they can preview those changes and give feedback immediately. </p><p>At Release, we will also share our own ephemeral environments with our customers as we’re building a feature so we can get feedback directly from the people we’re making the software for before we release it to production.</p><h3 id="3-ephemeral-environments-can-limit-rework-and-thus-increase-developer-velocity"><strong>3. Ephemeral environments can limit rework and thus increase developer velocity.</strong></h3><p>Ephemeral environments are a developer tool that allows for full integration and smoke testing on isolated features</p><p>Traditional continuous integration (CI) is the idea that your developer process should constantly be testing as a developer pushes code. What this leaves out many times is that most CI systems only perform unit tests continuously. Unit tests are meant to test small units of code and not the entire system as a whole. Integration and Smoke tests are where full paths of user experience can be tested. Usually Integration and Smoke tests are left to be tested only when the code makes its way via a merge to the mainline code branch and a traditional staging environment.</p><p>Again, if we refer back to Andy Grove’s three minute egg analogy, this step of running Integration and Smoke tests only when the code branch is merged to the mainline is extremely late in the process. If issues are found during Integration and/or Smoke tests, the developer has to start the development cycle again from the beginning after finding this issue too late in the process.</p><p>To add to the issue, if a team only has a single staging environment, the bottleneck around this staging environment is exacerbated with developers waiting for Integration and Smoke tests to be run on this single environment. On top of this, many code changes/features/branches may have been a part of the mainline merge making finding the cause of failed Integration/Smoke tests difficult and time consuming.</p><p>With ephemeral environments, Integration and Smoke tests can be run when the ephemeral environment is created for a feature branch. This ensures that Integration and Smoke tests are run as frequently as unit tests so developers can find issues early in the process. Additionally, Integration and Smoke tests run against a single feature change/branch will isolate changes against the mainline and make finding the root cause much easier.</p><h3 id="4-ephemeral-environments-are-a-devops-tool-that-allow-for-experimentation-with-infrastructure"><strong>4. Ephemeral environments are a DevOps tool that allow for experimentation with infrastructure</strong></h3><p>Making changes to infrastructure is hard and when a developer introduces the need for an infrastructure change it’s costly in time across the board. In a traditional environment setup (without ephemeral environments) this will result in an overall slow down in developer velocity as the shared staging environments must be updated by the DevOps team so the developer has some place to test their changes and new infrastructure.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/4clfoJM7gvr7ufFW8yqmax/e9731087d982502e619cba93d9cbafc6/Screen_Shot_2021-02-22_at_2.44.56_PM.png" alt="Experiment with environment configuration"></p><p>With ephemeral environments, this testing can be done in isolation and does not impact any other developer. For instance, with Release Ephemeral Environments, a developer can add services, environment variables, new infrastructure dependencies, new datasets/databases on their own through use of environment templates (environments as code) to experiment and develop without interfering with any other developers work or environments. This results in higher developer velocity again through minimization of rework and bottlenecks on shared resources.</p><h3 id="5-ephemeral-environments-are-a-collaboration-tool-designed-to-be-an-agilescrum-catalyst"><strong>5. Ephemeral environments are a collaboration tool designed to be an agile/scrum catalyst</strong></h3><p>Many organizations have made the move to Agile/Scrum but their infrastructure and technology haven’t adapted to support a more iterative approach to building software. The entire premise of Agile/Scrum is for teams to be empowered and driven by early and often feedback. If your organization is on Agile/Scrum and you’re still using a single or few staging environments, you’re technologically hampering your process improvements. Ephemeral environments are the homes and office buildings where agile teams live, work, build, and play.</p><p>Ephemeral environments are a catalyst to the Agile/Scrum methodology. When a developer does a pull request the ephemeral environment is created and collaboration on the feature can begin. The team is free to iterate, share,  nand solicit feedback all while keeping the rest of the organization freely moving with their own ephemeral environments. Stakeholders are a part of the development process and true customer driven development, which is the heart of the Agile/Scrum methodology, can occur.</p><h2 id="conclusion">Conclusion</h2><p>Ephemeral environments turbo charge development velocity by eliminating bottlenecks in the process (DevOps Tool), including stakeholders in the process (Collaboration Tool) and improving product quality (Developer Tool). All of these factors were highlighted in the McKinsey report on developer velocity as critical and ephemeral environments are <em>an investment that will put your organization in the top 25%</em>.</p><p>Photo by <a href="https://unsplash.com/@maicoamorim?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" title="Maico Amorim photo credit" target="_blank" rel="noreferrer">Maico Amorim</a> on <a href="https://unsplash.com/@maicoamorim?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" title="Unsplash link to photo" target="_blank" rel="noreferrer">Unsplash</a>.</p></div></article></div>]]>
            </description>
            <link>https://releaseapp.io/blog/improve-developer-velocity-with-ephemeral-environments</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238650</guid>
            <pubDate>Tue, 23 Feb 2021 15:50:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A personal raspberrypi powered eInk dashboard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238540">thread link</a>) | @jlengrand
<br/>
February 23, 2021 | https://lengrand.fr/complete-setup-epaper | <a href="https://web.archive.org/web/*/https://lengrand.fr/complete-setup-epaper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><strong>In the few coming minutes, you will read about epaper screens, raspberry pi, node, web components, tailwindcss, open-wc, netlify and more :).</strong></p><p>This article is quite long so for once I'll create a few pointers with TL;DR every time :)</p><ul><li><a href="https://lengrand.fr/complete-setup-epaper/#the-hardware-"><strong>The hardware</strong></a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-screen">-&gt; the screen</a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-computer-">-&gt; the computer</a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-os">-&gt; the OS</a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-software"><strong>The software</strong></a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-backend">-&gt; the 'backend'</a></li><li><a href="https://lengrand.fr/complete-setup-epaper/#the-frontend">-&gt; the frontend</a></li><li><strong><a href="https://lengrand.fr/complete-setup-epaper/#additional-thoughts-and-remarks-">Some remarks</a></strong></li></ul><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>It's the second time I create a dashboard for my house. We are working hard on reducing our carbon emissions. Tracking energy usage as well as making food plans is a very good way to do just that. </p><p>This time, <strong>I wanted my dashboard to be built with an e-paper screen, to avoid the ugly backlight of a tablet, and reduce energy consumption</strong>. Here is the final product : </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-21.png"><figcaption>The complete e-paper dasbboard setup</figcaption></figure><!--kg-card-end: image--><p><strong>In this post, I'll tell you all about how it's built, and how you can do it too. I won't describe everything, but point you to relevant documentations I followed. I'll also share tips and tricks.</strong></p><h2 id="the-hardware-">The hardware! </h2><p><strong>TL;DR: Get a Waveshare screen, a Raspberry Pi and follow <a href="https://www.waveshare.com/7.5inch-e-paper-hat.htm">instructions</a>.</strong></p><p>As any good physical product, everything starts with the hardware :). If you want to build the same dashboard, you'll need:</p><ul><li><a href="https://www.waveshare.com/7.5inch-e-paper.htm">A waveshare 7.5 inch screen (with UAT)</a></li><li><a href="https://www.raspberrypi.org/products/raspberry-pi-zero/">A raspberry Pi zero</a></li><li><a href="https://www.amazon.com/TUOFENG-Wire-Solid-different-colored-spools/dp/B07TX6BX47/ref=sr_1_34?dchild=1&amp;keywords=Soldering+Wire&amp;qid=1614031046&amp;sr=8-34">A bunch of soldering cables</a></li><li><a href="https://www.amazon.de/Lego-10698-Classic-Gro%C3%9Fe-Bausteine-Box/dp/B00PY3EYQO/ref=sxin_9_ac_d_rm?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;ac_md=2-2-bGVnbyBzdGVpbmU%3D-ac_d_rm&amp;cv_ct_cx=lego&amp;dchild=1&amp;keywords=lego&amp;pd_rd_i=B00PY3EYQO&amp;pd_rd_r=5eae0c54-ccbb-4a6f-9244-769b32337e2a&amp;pd_rd_w=XXCMe&amp;pd_rd_wg=iso2P&amp;pf_rd_p=54ea5632-6b46-46db-836f-bc13df6ca6a4&amp;pf_rd_r=G3WK7JTERFGJYNVQRKGG&amp;psc=1&amp;qid=1614031248&amp;sr=1-3-fe323411-17bb-433b-b2f8-c44f2e1370d4">Some lego :)</a></li></ul><p>Total is about 70€, everything included.</p><h3 id="the-screen">The screen</h3><p>I am using this <a href="https://www.waveshare.com/wiki/7.5inch_e-Paper_HAT">7.5 inch 2 colors screen from Waveshare</a>. My initial plan was to go for a <a href="https://www.waveshare.com/wiki/9.7inch_e-Paper_HAT">9.7inch with gray levels</a>, but I had no experience at all with that hardware so I went for the safer, 50$, solution.</p><p>The first good news is that the screen is CRAZY thin, here is a photo to give you an idea : </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-25.png"><figcaption>A photo of the e-ink screen from the side</figcaption></figure><!--kg-card-end: image--><p>When buying an e-paper screen, here are the things you want to look for : </p><ul><li><strong>Refresh time</strong>. One of the cons of having an e-ink screen is that refreshes usually take a while. If you want performance, also look whether partial refreshes are available. Here is a video of mine so you get an idea:</li></ul><!--kg-card-begin: embed--><figure><blockquote><p lang="en" dir="ltr">It updates every 5 minutes and that's what a refresh looks like in case you wonder : <a href="https://t.co/PjW4CS4rXp">pic.twitter.com/PjW4CS4rXp</a></p>— Julien Lengrand-Lambert (@jlengrand) <a href="https://twitter.com/jlengrand/status/1362321332516585480?ref_src=twsrc%5Etfw">February 18, 2021</a></blockquote>

</figure><!--kg-card-end: embed--><ul><li><strong>Resolution</strong>. e-ink screen of higher resolution are still quite expensive (compared to a tablet). Depending on what you want to do with the screen, you might end up with artifacts. A nice font will help you there, but it won't do miracles either. For example, this is what my dashboard looked like before I put my text in bold. You can clearly see the artifacts : </li></ul><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-22.png"><figcaption>A photo of the screen with text missing due to resolution</figcaption></figure><!--kg-card-end: image--><ul><li><strong>Gray levels</strong>. My screen is two colors ( essentially, ink or no ink). Some other screen have 255 gray levels. Some others even have color. You may	 want to choose one of those but remember that it will cost you in refresh time or price. </li><li><strong>Driver board</strong>. We'll talk more about this soon but be aware that not all screen come with connectors and a driver board. If you don't know what I am talking about, be careful buying a HAT version, otherwise you won't be able to use the screen : </li></ul><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-23.png"><figcaption>A photo of the screen with driver board</figcaption></figure><!--kg-card-end: image--><h3 id="the-computer-">The 'computer'</h3><p>This post will be using a Raspberry Pi. Note that the Waveshare screens have a pretty extensive <a href="https://www.waveshare.com/wiki/7.5inch_e-Paper_HAT">documentation</a> so you can also go for Arduino or even the Jatson nano if you fancy it.</p><p>Just to be clear, I am using a Raspberry Pi Zero in my build, so you don't need crazy amounts of power to run it. </p><p><strong>If you're afraid of soldering, I recommend you use the B version of the Raspberry</strong> because the driver board from Waveshare can directly clip on the GPIO : </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-24.png"><figcaption>Driver Board connected to a Raspberry Pi model B</figcaption></figure><!--kg-card-end: image--><p>As I mentioned, I decided to go for a Raspberry Pi Zero for two reasons : </p><ul><li>The form factor is much smaller, which allows for a super small setup together with the screen</li><li>The Zero goes for 5$, which is close to nothing! </li></ul><p>In case you go for the 0 like me, you'll have to solder a few cables. Don't be afraid though, everything is <a href="https://www.waveshare.com/wiki/7.5inch_e-Paper_HAT">described here</a>. All you need is the table below together with the Raspberry GPIO. </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-26.png"><figcaption>GPIO correspondances of the R Pi Zero</figcaption></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-27.png"><figcaption>Where to solder each pin</figcaption></figure><!--kg-card-end: image--><p>Once you've done that, you're pretty much good to go! Find a 5V adapter and power up your Raspberry Pi! The nice thing is that your screen will feed off the Raspberry so you need only one alimentation. We're ready to move to phase 2!</p><h3 id="the-os">The OS</h3><p>I've decided to keep this in the hardware part, because I don't have much to say. What we will want to do on our Raspberry Pi is install a default OS that is not too old. <a href="https://www.raspberrypi.org/software/operating-systems/">You can create and flash one here</a> by following the instructions.</p><p>The next thing you want to do is follow all the instructions described <a href="https://www.waveshare.com/wiki/7.5inch_e-Paper_HAT">in the default Waveshare setup</a>. Again, they are very well done so I don't have much to add but if you have any issue feel free to drop me a message.</p><p>In case you need to setup WiFi for your Raspberry Pi, <a href="https://www.raspberrypi.org/documentation/configuration/wireless/wireless-cli.md">here is the guide I used</a>!</p><p>You will enable SPI, install the necessaries libraries and download the library and test code from Waveshare. I tested with Python.</p><p>In case you have the same screen as I do, you will want to run the <code>epd_7in5_V2_test.py</code> script located in <code>waveshare/e-Paper/RaspberryPi_JetsonNano/python/examples/</code>! If all goes according to plan and you've soldered everything correctly, your screen will wake up!</p><h2 id="the-software">The software</h2><p><strong>TL;DR: Use <a href="https://github.com/samsonmking/epaper.js">epaper.js</a> on the Pi, created a service around it and serve static content in the static folder :).</strong></p><p>Our screen is awake, and we have a linux to work with! Time to start creating our dashboard! </p><p>I have made use of the amazing <a href="https://github.com/samsonmking/epaper.js">epaper.js</a> project to create my dashboard. The project is insanely useful. In short, it runs a static website locally and projects it on the screen using puppeteer. </p><p>This has a huge advantage : you only have to create a website and then deploy it on the device! <strong>You can find the complete code for the front and back end of the project <a href="https://github.com/jlengrand/epaper-dashboard-blog">here on Github</a>. And the website is available <a href="https://epaper-dashboard-blog.netlify.app/">at any time on Netlify</a>.</strong></p><p>The project is composed of two parts, which live in the same repository. </p><ul><li>The root repository that contains the code that will run on the Raspberry Pi, 'the backend'</li><li>The <code>epaper-ui</code>folder, which will contain our actual dashboard, the 'frontend'.</li></ul><p>Let's dive into each of the parts, but first, a word of warning: </p><p>Epaper.js &nbsp;can only be run on the raspberry. Indeed, it depends on native libraries (the GPIO drivers) that do not exist on your computer :). Not a problem, just something to be aware of (For example, don't set a CI on your project on Github).</p><p>Conversely, the latest version of Node that I could run on my raspberry is version 10.x, which means that I could not run the frontend code on it. Again, not a problem; just something to be aware of. </p><p>What that means is simply that I have been developing the frontend on my computer, and the backend only on the pi.</p><p>Now that it's clear, let's go!</p><h3 id="the-frontend">The frontend</h3><p>This part is the easiest to talk about. Keep in mind that for your own project, you can use any technology that suits you. The only requirement you have is that the result of your build lands in the <code>static</code> folder of the repository to be picked up by the backend. </p><p>Here is the current deployed frontend :</p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-31.png"><figcaption>Latest version of the frontend, in the web form</figcaption></figure><!--kg-card-end: image--><p>I decided to use Web Components, and my website is based on top of <a href="https://lit-element.polymer-project.org/guide/properties">LitElement</a> and <a href="https://tailwindcss.com/">TailwindCSS</a>. I used the excellent <a href="https://open-wc.org/">open-wc</a> library to generate my project skeleton in Typescript. Those are personal choices, you may well choose anything you like. </p><p>I picked these because by using Web Components I had very little to learn on top of the basic capabilities of HTML. Thanks to tailwind I also didn't have to learn much CSS :). My knowledge is limited in the front-end, having a simple syntax, a boring technological choice and no build-chain seemed like a perfect deal. No need to screw around with Webpack &lt;3!</p><p>Another good thing is that because I am basically only building a website, I could use <a href="https://www.netlify.com/">Netlify</a> as a platform to see the results of my work. And gosh I love their product!</p><p>Some things to note : </p><ul><li><a href="https://lengrand.fr/a-simple-setup-to-use-litelement-with-tailwindcss-for-small-projects/">I wrote a short article on how to easily use tailwind together with LitElement</a></li><li>Since it is a personal dashboard, I needed personal data. I leave it up to you to decide where to fetch your data from. The easiest for us to sync up with the girlfriend is Google Spreadsheets :).<a href="https://lengrand.fr/fetching-google-calendar-data-without-oauth-the-hacky-way/"> I wrote a whole blog post</a> about how to do that to sync calendars and avoid having to use Oauth2. In short, you can publish your spreadsheets online as CSV files. I do that and then ingest the data to create my dashboard. The great thing is that the CSV files are always up to date! </li></ul><p>I created my whole dashboard by using <code>$ npm start</code> in the <code>epaper-ui</code> folder, running <code>$npm build</code> every time I was happy with the result. That pushed the built version in the <code>static</code> folder of my project and sent it over to Github. By pulling the repository on my raspberry, I can make sure to always have the latest version of the dashboard.</p><p>Again, you can <a href="https://github.com/jlengrand/epaper-dashboard-blog/tree/main/epaper-ui">check the source code</a> here, and the <a href="https://epaper-dashboard-blog.netlify.app/">resulting dashboard over here</a>. </p><p>One last thing I want to mention before moving on is the way I refresh my dashboard :). The epaper.js examples <a href="https://github.com/samsonmking/epaper.js/tree/master/examples/weather-station">has an example with data that updates</a>. <strong>However</strong>, that data updates from the backend to the frontend. In my application, all the data is pulled from the internet via the frontend, which means that I cannot use the same mechanism. </p><p>To solve this problem, I make use of a very old capability of HTML itself to tell the page to refresh itself after very few minutes : </p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-30.png"><figcaption>Tells the page to refresh every 60 seconds.</figcaption></figure><!--kg-card-end: image--><p>Depending on how you build your own dashboard, you may not be concerned by this.</p><h3 id="the-backend">The backend</h3><p>Naming that part 'the backend' makes it seem like I've done a whole lot of work but I've really only been piggybacking on the great work done by <a href="https://github.com/samsonmking/epaper.js">epaper.js</a>.</p><p>Let me show you the integral content of my 'backend' code :</p><!--kg-card-begin: image--><figure><img src="https://lengrand.fr/content/images/2021/02/image-28.png"><figcaption>Two lines of code, only calling the epaper.js init</figcaption></figure><!--kg-card-end: image--><p>Yep, the only thing I did was call the epaper.js library and pick the device I am using. (Be careful, in case you use another model of Waveshare display you will have to change that value).</p><p>That is enough for the content of the static folder to be successfully displayed …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lengrand.fr/complete-setup-epaper">https://lengrand.fr/complete-setup-epaper</a></em></p>]]>
            </description>
            <link>https://lengrand.fr/complete-setup-epaper</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238540</guid>
            <pubDate>Tue, 23 Feb 2021 15:42:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Developers Procrastinate (and How to Stop)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26238435">thread link</a>) | @KaiserSanchez
<br/>
February 23, 2021 | https://www.7pace.com/blog/why-developers-procrastinate | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/why-developers-procrastinate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>What should you be doing instead of <a href="https://www.7pace.com/blog"><u>reading this article</u></a>?</p>



<p>Yeah, we know. You’re probably putting off some kind of work right now.</p>



<p>Procrastination is an age-old struggle — and not just for developers. But people who do knowledge work are especially prone to it, because of how mental blocks can severely impact their work.</p>



<p>So what causes those <a href="https://www.7pace.com/blog/high-performance-teams"><u>mental blocks</u></a>? Why do we all procrastinate so much? And more importantly, how can we stop procrastinating and just get our work done?</p>



<p>Don’t worry — you still have a few minutes of reading ahead of you before you have to go back to whatever task you’re avoiding. Read on and learn all about what causes procrastination, how to finally beat it, and how developers can use time tracking to up their efficiency even more.</p>



<h2>Why Do Developers Procrastinate?</h2>



<p>Developers aren’t more likely to procrastinate than other people. And when we look at the root causes of procrastination for developers, they’re the same reasons as anyone else.</p>



<p>Contrary to what many believe, procrastination isn’t necessarily the result of a lack of self-discipline. There are a <em>ton</em>&nbsp;of reasons developers (or anyone else) might procrastinate. Let’s look at a few common ones below.<em></em></p>



<h3>Perfectionism</h3>



<p>In knowledge work in particular, many people strive to be perfect. That goes for developers, too — they often strive to write the “perfect” code.</p>



<p>In reality, code that does what it’s supposed to do without bugs is plenty good enough. Striving for perfection has a tendency to make developers put off their work, since they’re trying to achieve an impossible goal.</p>



<h3>Fear of Success</h3>



<p>It may seem counter-intuitive, but fear of success has held back many a knowledge worker. With success comes higher expectations and greater responsibility, and not everyone responds well to that kind of pressure. In this case, procrastination can be a self-sabotaging tool.</p>



<h3>Lack of Planning</h3>



<p>Have you ever shown up to work, sat down at your desk, booted up your computer, and then sat there for a while trying to figure out what to work on? That lack of planning can be a major procrastination driver.</p>



<h3>Not Enough Work</h3>



<p>This is another counter-intuitive sounding reason for procrastination, but it’s real! Some developers procrastinate because they don’t have enough work to do.</p>



<p>When your workdays aren’t filled, it’s easy to get in the habit of coasting — hanging out at your desk surfing social media or reading online articles like this one. And once you’re in the habit, it’s hard to break it even when there <em>is</em>&nbsp;work to do. Hence, procrastination.</p>



<h3>Outdated Technologies</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/01-Image.jpg" alt="Outdated Technologies" srcset="https://www.7pace.com/wp-content/uploads/2021/02/01-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/01-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>Software development is a field that requires its workers to stay pretty close to the cutting edge of new technologies. So trying to work with old ones that are outdated, obsolete, or deprecated can be a real challenge for devs, leading them to put off work.</p>



<h3>Organizational Roadblocks</h3>



<p>As much as developers like to put their heads down and get their work done <a href="https://www.7pace.com/blog/best-places-to-work"><u>without red tape or administrative hurdles</u></a>&nbsp;getting in their way, that’s not how it works at <em>every</em>&nbsp;organization. If the company you work for places organizational roadblocks in your path, that may very well be a contributor to your procrastination habit.</p>



<h3>Unnecessary or “Busy” Work</h3>



<p>Feeling a sense of purpose and accomplishment is important for any worker, which is why it’s common for developers to procrastinate on work that doesn’t seem like it’s contributing to the greater good, like implementation of unnecessary features. The same goes for <a href="https://www.7pace.com/blog/time-tracking-optional-for-development-teams"><u>tedious or administrative tasks</u></a>&nbsp;—&nbsp;those are easy to put off as well.</p>



<h3>Work You Just Don’t Want to Do</h3>



<p>And finally, there’s work you just don’t want to do. Maybe it’s outside of your wheelhouse. Maybe it feels unnecessary. Maybe it’s too hard, or you’re stuck at a particular blocker. But for all workers, including developers, just not wanting to do a certain task, project, or type of work can easily lead to procrastination.</p>



<h2>How to Stop Procrastinating and Get Work Done</h2>



<p>Identifying the cause of your procrastination can help you determine what you need to do to move past it. But even if you’re not sure why you procrastinate, these tips can help break that habit and get you to get your work done.</p>



<h3>Take Baby Steps</h3>



<p>When you’re putting off a task, the hardest part can be just getting started. So instead of looking at the big picture of all you need to do, just take a small step in the right direction —&nbsp;like telling yourself you only need to work on a task or project for 30 minutes before you take a break to reassess. It can turn an impossible-seeming project into something more doable, and once you get started, it’ll be easier to keep moving.</p>



<h3>Make a Plan</h3>



<p>Remember how lack of planning is a common driver for procrastination? Combat that by going into every workday with a plan. Make it a habit before you leave each night to think about what you need to accomplish the following day, and make yourself a to-do list or a schedule —&nbsp;whatever works to keep you on track.</p>



<h3>Remove Distractions</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/02-Image.jpg" alt="Remove Distractions" srcset="https://www.7pace.com/wp-content/uploads/2021/02/02-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/02-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>Have you considered you might procrastinate simply because you’re too distracted to work effectively? Do what you can to cut down on things that might pull you away from your work. For example, you could find a quiet room to work in, or wear noise-canceling headphones. Block social media and other distracting websites from your work computer.</p>



<h3>Isolate Yourself</h3>



<p>If you work in an office with others, another cause for your procrastination might be that people need you for things. And while it’s great to be the go-to person in the office, it’s not ideal for <a href="https://www.7pace.com/blog/developer-productivity-tools"><u>productivity</u></a>.</p>



<p>If you struggle with being pulled away from work by your coworkers, isolate yourself away from others so you appear less available. If you’re not able to go work somewhere without others around, stick a sign to the back of your chair to let people know you’re in deep work mode and don’t want to be interrupted.</p>



<h3>Use a Technique Like Pomodoro</h3>



<figure><img loading="lazy" width="2048" height="970" src="https://www.7pace.com/wp-content/uploads/2021/02/03-Image.jpg" alt="Use a Technique Like Pomodoro" srcset="https://www.7pace.com/wp-content/uploads/2021/02/03-Image.jpg 2048w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-300x142.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-1024x485.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-768x364.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/02/03-Image-1536x728.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px"></figure>



<p>The Pomodoro technique has become a common way for all kinds of people to beat their procrastination habits. It works by requiring you to deeply focus on work for a period of time (usually 25 minutes), and then take a short, mandated break (5 minutes or so). You repeat this cycle over and over throughout the workday, alternating focused work with short breaks.</p>



<h3>Take Breaks</h3>



<p>On that note, another possible reason for your procrastination is that you feel tired or worn out —&nbsp;and that can be more easily remedied than you might think. Many of us don’t take enough breaks at work, even though science shows that breaks are necessary and can greatly improve productivity and quality of work. If you’re feeling stuck on a task or project, take a short break and come back to it later.</p>



<h3>Switch Between Tasks</h3>



<p>The same goes for working on the same task for too long. It’s easy to get stuck when you have tunnel vision. So if you feel like you can’t move forward on a particular task, switch to something else for a while. You can always come back to the first task with fresh eyes later, without having wasted any time in the meantime.</p>



<h2>Want to Become Even More Efficient? Track Time with 7pace Timetracker</h2>



<p>Once you’ve beaten procrastination, you might be looking for ways to become even <em>more</em>&nbsp;productive at work.</p>



<p>The most productive teams are <a href="https://www.7pace.com/blog/automation-tools-for-devops"><u>autonomous ones</u></a>. And a major part of autonomy is a time tracking solution that isn’t made to help managers watch over your shoulder —&nbsp;but to integrate seamlessly with your work and provide you with data and insights that help you work smarter.</p>



<p><a href="https://www.7pace.com/"><u>7pace Timetracker</u></a>&nbsp;is the only time tracking solution designed to measure and track progress completely in the background, so you don’t have to waste one second of effort. And it provides valuable data about your time at work that can help you plan, execute, and measure every aspect of every project.</p>



<p><a href="https://www.7pace.com/timetracker"><u>Learn more about 7pace Timetracker</u></a>&nbsp;and why it’s the only time tracking solution for productive, autonomous teams.</p>
						</div></div>]]>
            </description>
            <link>https://www.7pace.com/blog/why-developers-procrastinate</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238435</guid>
            <pubDate>Tue, 23 Feb 2021 15:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privileged Ports Cause Climate Change]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26238040">thread link</a>) | @wilsonzlin
<br/>
February 23, 2021 | http://adamierymenko.com/ports.html | <a href="https://web.archive.org/web/*/http://adamierymenko.com/ports.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://adamierymenko.com/ports.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26238040</guid>
            <pubDate>Tue, 23 Feb 2021 15:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconventional Customer Acquisition]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26237544">thread link</a>) | @StriverGuy
<br/>
February 23, 2021 | https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Even if you weren’t an early adopter of Slack, you were probably curious about the hype. Why were people so passionate about a work messenger tool? Not that chat tools aren’t sexy, but there must’ve been something else that made Slack so popular.</span></p>
<p><span>The secret? A killer customer acquisition strategy.</span></p>
<p><span>Slack highlighted its unique features, added valuable integrations, and offered its product for free. Combined with word-of-mouth and smart Twitter marketing, Slack was unstoppable, going from </span><a href="https://clickup.com/blog/slack-growth-strategy/" rel="follow noopener" target="_blank"><span>500,000 users to 1.1M users in the first four months</span></a><span>. Slack’s customer list eventually grew to include the likes of Fortune 100 companies like </span><a href="https://slack.com/about" rel="follow noopener" target="_blank"><span>Starbucks, Target, Oracle, and ETrade</span></a><span>. In late 2020, </span><a href="https://investor.salesforce.com/press-releases/press-release-details/2020/Salesforce-Signs-Definitive-Agreement-to-Acquire-Slack/default.aspx" rel="follow noopener" target="_blank"><span>Slack was acquired</span></a><span> by one of the biggest behemoths in the tech industryä¸€Salesforce.</span></p>
<p><span>Not every startup can go viral like Slack, but getting creative with your customer acquisition strategies can generate some pretty incredible leads. In this post, we share six unusual acquisition methods and the startups that have benefited from them.&nbsp;</span></p>

<p><em>What is a customer acquisition strategy?&nbsp;</em></p>
<p><span>Just so we’re all on the same page, let’s take a moment to define customer acquisition. Most people think of customer acquisition as email marketing, SEO, or free trials. But at its core, “customer acquisition” refers to techniques that attract new customers to a business.</span></p>
<p><span>Notice that we said technique</span><b>s</b><span>, plural. People respond to messaging differently and user needs can change with industry trends or economic shifts. For that reason, a comprehensive customer acquisition strategy should include multiple tactics to gain new customers rather than relying on one method alone.</span></p>

<h2><strong>6 unique ways to acquire more customers</strong></h2>
<p><span>Much of customer acquisition is trial and error. What works for some companies doesn’t necessarily work for others. Regardless, brainstorming new customer acquisition strategies is key to keeping your strategy fresh. Below, we share some lesser-known, but fruitful, customer acquisition strategies to attempt this quarter.</span></p>

<h2><strong>1. Give your reviews a review&nbsp;</strong></h2>
<p><a href="https://learn.g2.com/consumer-reviews" rel="follow noopener" target="_blank"><span>92% of B2B buyers</span></a><span> are more likely to purchase after reading a trusted review. Having just five published reviews can increase </span><a href="https://spiegel.medill.northwestern.edu/online-reviews/" rel="follow noopener" target="_blank"><span>the likelihood of someone making a purchase by 270%</span></a><span>. That’s nuts!</span></p>
<p><span>Ignoring sites like G2, TrustRadius, and Capterra is irresponsible. Prospects shopping for a B2B tool inevitably come across these sites in their research. If you search for “best project management tool”, Capterra is 5th in organic SERP. When you click on the article, you might expect Asana or Trello to be at the top. Surprisingly, </span><a href="https://www.capterra.com/project-management-software/" rel="follow noopener" target="_blank"><span>the first result is Monday.com</span></a><span>. This list is sorted by “sponsored products”, but still, this is a fantastic way for Monday.com to get in front of potential buyers.</span></p>

<p><span><img src="https://cdn.buttercms.com/7IKl4W7LR76X3B0mJIHc" alt="undefined"></span></p>
<p><span>If you don’t want to pay to play, start by scouring these sites for reviews and responding to them. Answer as many customer questions as possible, thank people who leave positive reviews, and reply respectfully and constructively to negative reviews. Don’t forget to ask existing customers to post reviews, too. Encourage CSMs or SEs to bring this up in their calls, add a link to post a review in your newsletter, and post your request to write reviews on LinkedIn or Twitter. You’d be surprised how many people comply, especially if you have a great product.</span></p>

<h2><strong>2. Buy your competitors</strong></h2>
<p><span>Most early-stage startups aren’t flush with cash, but buying up a competitor’s domain might be worth it if you have a little to spare. Customers who are looking for something specific usually type in long-tail keywords in search. By buying up websites that rank for those long-tail keywords, you can instantly increase your organic traffic.</span></p>
<p><span>The idea is to come up with a list of websites that land at the top of SERP and approach their owners. When you’re compiling this list, consider specific keyword rankings, organic search traffic, number of pages, number of backlinks, relevancy, audience size, and, of course, price. You might assume that this strategy is extremely expensive, but oftentimes these websites are personal blogs and sell for cheap.</span></p>
<p><a href="https://www.linkedin.com/in/matthewbarby/" rel="follow noopener" target="_blank"><span>Matthew Barby, VP of Marketing at Hubspot</span></a><span>, cites this strategy as his “#1 favorite tactic to roll out when working on a project with a brand new domain.” In </span><a href="https://www.matthewbarby.com/customer-acquisition-strategies/" rel="follow noopener" target="_blank"><span>this post</span></a><span>, he outlines a deal where he actually </span><i><span>saved </span></i><span>money buying another domain. Before acquiring the new website, it cost roughly $450 for his company to produce each blog post, and they’d publish 3-4 per month. That really added up.&nbsp;</span></p>
<p><span>So his team did some sleuthing and found the perfect acquisition target—one that had already published over 500 well-performing articles. He negotiated with the seller to nab the domain at a price that worked out to only $31.70 per article, 7% of the original cost. Besides obtaining that website’s traffic, the company’s posts jumped two pages in search results, on average. Here’s a glimpse of their increase in organic traffic:</span></p>

<p><span><img src="https://cdn.buttercms.com/w1MO6VAvQ6WGcEcfHcuS" alt="undefined" width="766" height="216"></span></p>
<p><span>While this system requires some research and investment, it can really pay off in the long run.</span></p>

<h2><strong>3. Old content is the new content&nbsp;</strong></h2>
<p><span>The Content Marketing Institute found that small businesses (1-99 employees) spent an </span><a href="https://contentmarketinginstitute.com/wp-content/uploads/2019/10/2020_B2B_Research_Final.pdf" rel="follow noopener" target="_blank"><span>average of $81,500 on content marketing</span></a><span> in 2019. That’s a big chunk of change. Blog posts and case studies do yield leads, but they only get published once...right?</span></p>
<p><span>Wrong. Repurposing content should be a major part of your customer acquisition strategy. Many B2B companies have hundreds of old posts on their site, and the deeper in the architecture posts are, the less likely they are to rank in search results. Make it a consistent practice to revisit old posts and update them with more recent statistics, new keywords, revamped CTAs, and even different titles. Consider merging a few posts to create an entirely new freebie and re-promote refurbished posts in newsletters, social media, or on Medium to attract more backlinks.</span></p>
<p><span>Venture Harbor, a venture studio based in the UK, used this strategy for their article on </span><a href="https://www.ventureharbour.com/b2b-lead-generation-strategies/" rel="follow noopener" target="_blank"><span>B2B lead generation strategies</span></a><span>. The post was long and took a significant amount of time to write. To let it get stale would be a waste! The author updated stats, inserted more compelling images, included more keywords, and added “2021” to the title. As a result, the post now lands in the top 5 Google results for “b2b content generation”:</span></p>

<p><span><img src="https://cdn.buttercms.com/kaR8r9ijSCeOY1shsQw2" alt="undefined" width="634" height="882"></span></p>
<p><span>Venture Harbor’s blog is just one example. Hubspot consistently incorporates this practice into its content strategy and has </span><a href="https://blog.hubspot.com/marketing/historical-blog-seo-conversion-optimization" rel="follow noopener" target="_blank"><span>increased organic traffic by 105%</span></a><span>. It’s a similar story for Zapier. Updating just 21 posts </span><a href="https://jessicagreene.marketing/blog/updating-website-content/" rel="follow noopener" target="_blank"><span>drove 52,431 additional visits each month</span></a><span> to the Zapier blog.</span></p>

<h2><strong>4. Create an online academy</strong></h2>
<p><span>Do people understand what your company does and how it can help their business? If you’re selling a complex tool or idea, an online academy can help. Take Segment, for example.</span></p>

<p><span><img src="https://cdn.buttercms.com/pTEt0aBScO8GRBBV1vZx" alt="undefined" width="674" height="438"></span></p>
<p><span>It can be tough to understand what Customer Data Platforms, or CDPs, do from a simple google search. To lower the barrier to entry, Segment created a </span><a href="https://segment.com/academy/" rel="follow noopener" target="_blank"><span>free online academy</span></a><span> with useful, non-salesy content. Prospects simply enter their email address and receive courses every week on the importance of customer analytics, what goes into a robust marketing stack, and how to make data-driven decisions. The leads generated from the academy are already interested in a CDP and want to learn more, meaning they are likely to be more responsive to sales teams that follow up.</span></p>
<p><span>Plus, the academy makes for great advertising. People who are bullish on the product can quickly send a link to a peer, friend, or boss. The embedded courses explain exactly why Segment would be a good investment. The academy is also helpful from a partnership point of view. If Segment wanted to pursue a reseller agreement with another company, the academy is a low-touch way to teach partners and their sales teams what Segment does and how it might fit into their GTM strategy.</span></p>

<h2><strong>5. Go viral on TikTok</strong></h2>
<p><span>Ok, hear us out. TikTok has </span><a href="https://datareportal.com/social-media-users?rq=tiktok" rel="follow noopener" target="_blank"><span>800 million active users</span></a><span>, ranking ahead of LinkedIn, Twitter, Pinterest, and Snapchat. According to Statista, 29.5% of 20-29-year-olds account for TikTok’s active user base, and </span><a href="https://www.statista.com/statistics/1095186/tiktok-us-users-age/" rel="follow noopener" target="_blank"><span>adults aged 30-49 make up another 30.3%</span></a><span>. What would happen if you could reach </span><b><i>even a fraction </i></b><span>of those users?</span></p>
<p><span>TikTok is </span><a href="https://medium.com/@kkirt/tiktok-b2b-brands-oh-no-please-no-c091c7af4fb5" rel="follow noopener" target="_blank"><span>not the place to advertise your upcoming webinar</span></a><span> or recently published whitepaper. That said, coming up with clever, relatable ways to interact with adults on the app can certainly pique people’s interest. Recruit your most creative teammate to think of outrageous, funny forms of content. Are there common challenges people face when trying to implement a tool in your space? Can you show some behind the scenes footage? Is your product meme-able?</span></p>
<p><span>We don’t yet have an example of a B2B brand doing this well, but a somewhat similar B2C brand, Wikihow, is excelling at this. First, they poked fun of themselves on TikTok, recreating (and encouraging others to recreate) pictures on their site:</span></p>

<p><span><img src="https://cdn.buttercms.com/uxn9GspwSya3I3v8jsh1" alt="undefined" width="606" height="341"></span></p>
<p><span>When COVID hit, they began creating </span><a href="https://www.youtube.com/watch?v=1MXgLjr7Sms" rel="follow noopener" target="_blank"><span>especially relevant how-to content</span></a><span> about the pandemic, like how to wash your hands, how to make masks out of old t-shirts, and how to meditate. So many people gravitated to the Wikihow account that it gained the attention of the United Nations. Now, Wikihow is a </span><a href="https://www.wikihow.com/Author/The-Verified-Initiative-of-the-United-Nations" rel="follow noopener" target="_blank"><span>part of the Verified Initiative of the United Nations</span></a><span>.</span></p>

<p><span><img src="https://cdn.buttercms.com/OkL4J70CQ0yitOeYy7Qh" alt="undefined" width="320" height="496"></span></p>

<h2><strong>6. Leverage your NPS survey</strong></h2>
<p><span>Most customer success teams these days send an annual or bi-annual NPS survey to measure customer satisfaction. If your customers already respond well to your NPS survey, there’s something else you might consider adding inä¸€a referral request. Customers already expect to receive this survey and have demonstrated that they’ll answer it. Adding one more question into the mix, “Is there anyone you think could benefit from this product?” can open a lot of doors.&nbsp;</span></p>
<p><span>If you don’t feel comfortable altering your NPS survey, that’s understandable. Other referral campaigns can work well, too. Make sure to incorporate a strong incentive, whether that be a discount, swag, or a certain number of free users. </span><a href="https://www.blackbaud.com/" rel="follow noopener" target="_blank"><span>Blackbaud</span></a><span>, a software solution …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition">https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition</a></em></p>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/unconventional-customer-acquisition</link>
            <guid isPermaLink="false">hacker-news-small-sites-26237544</guid>
            <pubDate>Tue, 23 Feb 2021 14:23:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VSCode 101 – The Easy Way to Learn and Master VSCode]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26237545">thread link</a>) | @kaushal197
<br/>
February 23, 2021 | https://kaushalpatel.ca/posts/master-vscode/ | <a href="https://web.archive.org/web/*/https://kaushalpatel.ca/posts/master-vscode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>VSCode has become the hot tool in development. We don't all have to like it, but you can't deny it is the most used development tool with over <a href="https://insights.stackoverflow.com/survey/2019#development-environments-and-tools">50% of developers using it for their daily work.</a></p><p>The flexibility of VSCode is what makes it such a solid tool for various forms of development. Out of the box, it's a super simple text editor. There is never a reason to use any of its fancy tooling or community created extensions, however, if you really want to make the most of VSCode here are the 5 key areas you need to understand.</p><p><strong>*Disclaimer!!*</strong><em>: Most of the shortcuts will state <strong>Cmd</strong>, kindly translate this to <strong>Ctrl</strong> if you use a non-MacOS related device.</em></p><h2 id="heading-navigation">Navigation<a href="#heading-navigation"><span> permalink</span></a></h2><p>This editor is FULL of keyboard shortcuts, a lot of them come in handy for traversing the crazy number of tabs we mindlessly open up.</p><p><strong><code>Cmd + P</code></strong>: Quickly Jump to File</p><p>If you don't know of this one already it's a superpower! You don't even have to be great at spelling, VSCode is really good at shortlisting the possible file(s) you may be looking for.</p><p><img src="https://kaushalpatel.ca/images/jump_to_file.gif" alt="" loading="lazy" width="627" height="220"></p><p>Another great way to traverse around without having the file explorer open is the top path bar; it's a hidden gem I recently learned about. You can click on the file or folder in the path, and it expands to let you pick any file sitting beside it. Check it out:</p><p><img src="https://kaushalpatel.ca/images/path_bar.gif" alt="" loading="lazy" width="600" height="265"></p><p>Since VSCode is based on Electron, you use the tab switching shortcut from Chrome + Terminal + Firefox... basically most applications that have tabs.</p><p><strong><code>Cmd + Shift + [ or ]</code></strong>: Go to Left or Right Tab</p><p><img src="https://kaushalpatel.ca/images/tab_shifting.gif" alt="" loading="lazy" width="600" height="63"></p><h2 id="heading-intellisense">Intellisense<a href="#heading-intellisense"><span> permalink</span></a></h2><p>Intellisense is my favourite component to VSCode, it's so seamless. VSCode gives you very basic static analysis and refactoring capabilities depending on the type of file you're editing.</p><p><strong><code>Ctrl + Space</code></strong>: Activate autocomplete feature for item under cursor</p><p><img src="https://kaushalpatel.ca/images/autocomplete.gif" alt="" loading="lazy" width="735" height="91"></p><p>The editor also showcases all of the properties, methods, and blocks of the current file in the <code>Outline</code> window (Bottom-Left). This can be opened from the Command Palette we used previously to navigate by simply entering <code>@</code>. You can use the Command Palette like this to navigate within your active file with either <code>@</code> or <code>:</code>.</p><p><img src="https://kaushalpatel.ca/images/jump_to_section.gif" alt="" loading="lazy" width="1114" height="338"></p><p>The real meat of intellisense comes in it's refactoring capabilities! I will showcase my most used feature and leave the rest for you to explore. Did you know you can rename a variable safely across your whole codebase?</p><p><img src="https://kaushalpatel.ca/images/rename.gif" alt="" loading="lazy" width="740" height="246"></p><p>I was only able to show an example from a local function in my project. Try it in your own codebase, it will affect the naming for all appropriate instances.</p><h2 id="heading-vcsgit">VCS/Git<a href="#heading-vcsgit"><span> permalink</span></a></h2><p>I like using the command line for Git personally, on the other hand a lot of my co-workers say a GUI Git tool is the best.</p><p><img src="https://kaushalpatel.ca/images/whatever.gif" alt="" loading="lazy" width="480" height="350"></p><p>Whichever option you choose, the out-of-the-box VCS and Git feature is useful. It's so powerful with diff-checking, conflicts, tracking by file, etc.... For command line users, this can be a time-saver. For GUI users, this means one less application to open and have running on your machine. To me, this is a win/win.</p><p>You can access the VCS window on the left-hand side (it looks like the Git logo). It's pretty difficult to cover everything it has to offer without adding a million images, but the big thing to note are the vertical ellipsis and the quick options when hovering over a file.</p><p><img src="https://kaushalpatel.ca/images/VCS.png" alt="" loading="lazy" width="354" height="322"></p><p>Refined and common Git commands can be accessed by clicking the ellipsis. The <strong>plus</strong> lets you add all changes to the next commit, whilst the <strong>hooked arrow</strong> lets you rollback all changes. When you click on a file, the diff will be shown in the main window as a split between old and new. Get used to checking this tab and running through your files before committing!! It has saved me from minor mistakes and endless build times on multiple occasions.</p><p><img src="https://kaushalpatel.ca/images/diff.png" alt="" loading="lazy" width="1489" height="282"></p><p>Now if only there was a way to review PRs in VSCode when using Github enterprise. If any of you know of a tool like this, please DM me on <a href="https://twitter.com/talesofadev">Twitter</a> 🙏</p><h2 id="heading-zen-mode">Zen Mode<a href="#heading-zen-mode"><span> permalink</span></a></h2><p>Let your mind be free of distractions 📿</p><p><strong>Cmd + K -&gt; Z</strong></p><p><em>If you can use this mode effectively, you know you have mastered VSCode</em></p><h2 id="heading-extensions">Extensions<a href="#heading-extensions"><span> permalink</span></a></h2><p>I think we all know about Extensions, they are essentially plugins to help with specific issues/expansions you want for the editor. As a web developer I use a few productivity and tracking extensions:</p><ul><li>Todo Tree</li><li>Todo Highlight</li><li>Prettier</li><li>GitLens</li><li>Language-specific extensions</li><li>Bonus: Themes</li></ul><p><a href="https://twitter.com/talesofadev">Follow me on Twitter</a> for updates on my ebook: <code>Git Animated - A Visual Guide to Understanding Git</code></p></div></div>]]>
            </description>
            <link>https://kaushalpatel.ca/posts/master-vscode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26237545</guid>
            <pubDate>Tue, 23 Feb 2021 14:23:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Pretty JSON Revolution]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 145 (<a href="https://news.ycombinator.com/item?id=26237048">thread link</a>) | @peterohler
<br/>
February 23, 2021 | http://www.ohler.com/dev/pretty.html | <a href="https://web.archive.org/web/*/http://www.ohler.com/dev/pretty.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	  <table>
	    <tbody><tr>
	      <td colspan="2">
		<p>
		  Wouldn't it be nice if more JSON tools supported a truly
		  pretty JSON format? Demand options for truly pretty JSON
		  now! Viva la revolucion!
		</p>
		<p>
		  If only it were that easy. JSON format has become wildly
		  popular over the last decade easily passing XML as the
		  format of choice. For us humans JSON is much easier to read
		  than XML if the JSON is properly formatted. Sadly most tools
		  for viewing or formating JSON seem to be stuck on one of two
		  formats. One format is the single line format and the other
		  is a simple expanded format. There are other options though
		  with some tools.
		</p>
		<p>
		  One tool that offers more options is
		  the <span>oj</span> application
		  which is part of the
		  golang <a href="https://github.com/ohler55/ojg">OjG</a>
		  package. The <span>oj</span>
		  application will be used to illustrate the range of JSON
		  formats from the ugly up to the beauty of pretty
		  JSON. Follow along and try out your favorite JSON sample on
		  each step.
		</p>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>One Line</p>
		<p>
		  The tight one line JSON format is used when trying to
		  minimize the size of a JSON document. It is the preferred
		  format for transmitting and storing JSON as it takes less
		  bandwidth and less disk space. For viewing, it is hard for
		  the eye to find elements of interests and difficult to
		  determine element boundaries. It has to be the ugliest of
		  all JSON formats.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 0 colors.json</span>
{"colors":[{"color":"black","hex":"#000","rgb":[0,0,0]},{"color"
:"red","hex":"#f00","rgb":[255,0,0]},{"color":"yellow","hex":"#f
f0","rgb":[255,255,0]},{"color":"green","hex":"#0f0","rgb":[0,25
5,0]},{"color":"cyan","hex":"#0ff","rgb":[0,255,255]},{"color":"
blue","hex":"#00f","rgb":[0,0,255]},{"color":"magenta","hex":"#f
0f","rgb":[255,0,255]},{"color":"white","hex":"#fff","rgb":[255,
255,255]}]}</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>One Line Per Node</p>
		<p>
		  What many packages refer to as pretty is an expanded format
		  where every element and each array and object start are on
		  separate lines. The core
		  golang <code>json.MarshalIndent()</code> function produces
		  an example of this format. The format takes up so much
		  vertical space the example on the right had to be cut off to
		  avoid filling up this article with just large amounts of
		  white space.
		</p>
		<p>
		  With the expanded (pretty?) format it is certainly easier to
		  determine element boundaries but you need a large screen or
		  to be good at scrolling to find what you are looking for. So
		  the expanded format is a step up from the one line format
		  which makes it a bit prettier but it is a weak effort that
		  is not without flaws.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 2 colors.json</span>
{
  "colors": [
    {
      "color": "black",
      "hex": "#000",
      "rgb": [
        0,
        0,
        0
      ]
    },
    {
      "hex": "#f00",
      "rgb": [
        255,
        0,
        0
      ],
      "color": "red"
    },
...
</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Sorted Object Keys</p>
		<p>
		  In many implementations JSON objects, whether implemented as
		  a golang map, Ruby Hash, Python dict, or what ever your
		  language of choice uses, the order of object elements is
		  random. That makes it more difficult to visually scan a set
		  of elements and pick out the same keyed element in each JSON
		  object. The brain is good at picking out visual or spacial
		  patterns but if the layout changes each each time there is
		  no pattern to pickup on. A visual scan has to be done,
		  looking at each key until the target is identified. JSON can
		  be made prettier by sorting the JSON object members by
		  element keys.
		</p>
		<p>
		  A sorted expanded format is a step up from just the expanded
		  format but it still suffers from taking up lot of vertical
		  space. If someone was writing the JSON by hand they would
		  probably not elect to expand the JSON to quite the level
		  that most packages or libraries do.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -i 2 -s colors.json</span>
{
  "colors": [
    {
      "color": "black",
      "hex": "#000",
      "rgb": [
        0,
        0,
        0
      ]
    },
    {
      "color": "red",
      "hex": "#f00",
      "rgb": [
        255,
        0,
        0
      ]
    },
...
</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style</p>
		<p>
		  The ideal pretty JSON pretty is to have the format look like
		  a human had typed it in. Well a pedantic human that didn't
		  make mistakes. Just like Goldilocks, the optimum middle
		  ground between a single line and a fully expanded format is
		  the goal. The
		  algorithm <span>oj</span> uses
		  considers a suggested edge to not exceed and a maximum
		  element depth allowed on a single line. Those two parameters
		  are specified as a float where the whole number part is the
		  edge and the fractional part or the number of 10ths is the
		  maximum depth on a single line. With those two parameters a
		  reasonable human style format can be achieved and the
		  results are looking rather pretty.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 colors.json</span>
{
  "colors": [
    {"color": "black", "hex": "#000", "rgb": [0, 0, 0]},
    {"color": "red", "hex": "#f00", "rgb": [255, 0, 0]},
    {"color": "yellow", "hex": "#ff0", "rgb": [255, 255, 0]},
    {"color": "green", "hex": "#0f0", "rgb": [0, 255, 0]},
    {"color": "cyan", "hex": "#0ff", "rgb": [0, 255, 255]},
    {"color": "blue", "hex": "#00f", "rgb": [0, 0, 255]},
    {"color": "magenta", "hex": "#f0f", "rgb": [255, 0, 255]},
    {"color": "white", "hex": "#fff", "rgb": [255, 255, 255]}
  ]
}</pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style with Colors</p>
		<p>
		  With the human style formatting the JSON sample is very
		  readable but it can be made prettier. Well at least for
		  those of us than see in color. With the <code>-c</code>
		  option or the <code>-b</code> option the formatted JSON now
		  has colors. While colors do make the output prettier they
		  also make it easier for the eye to discern keys, string,
		  boolean, and numbers more easily. Try it, look at the
		  non-colored JSON and the colored and pick out your preferred
		  color name. Maybe not nirvana but compared to the first, one
		  line format, the colored pretty output is a completely
		  different level.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 -c colors.json</span>
<span>{</span>
  <span>"colors"</span><span>:</span> <span>[</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"black"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#000"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"red"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#f00"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"yellow"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#ff0"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>255</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"green"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#0f0"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>255</span><span>,</span> <span>0</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"cyan"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#0ff"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>255</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"blue"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#00f"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"magenta"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#f0f"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>]</span><span>}</span><span>,</span>
    <span>{</span><span>"color"</span><span>:</span> <span>"white"</span><span>,</span> <span>"hex"</span><span>:</span> <span>"#fff"</span><span>,</span> <span>"rgb"</span><span>:</span> <span>[</span><span>255</span><span>,</span> <span>255</span><span>,</span> <span>255</span><span>]</span><span>}</span>
  <span>]</span>
<span>}</span></pre>
	      </td>
	    </tr>
	    <tr>
	      <td>
		<p>Human Style with Colored in the SEN Format</p>
		<p>
		  Sorted human style with colors is about as good as it gets
		  but what if we deviate from strict JSON format and take a
		  few shortcuts that Javascript and GraphQL allow such as
		  unquoted strings and optional
		  commas. The <a href="https://github.com/ohler55/ojg/blob/develop/sen.md">SEN</a>
		  format is that
		  format. The <span>oj</span>
		  application supports parsing and encoding in SEN
		  format. It's not JSON but the conversion from SEN to JSON
		  and the reverse is lossless. Getting rid of the extra quotes
		  and unnecessary commas make the data easier to read and as a
		  side benefit the SEN format takes up less space so
		  transmission and disk space requirements are reduced when
		  compared to JSON.
		</p>
	      </td>
	      <td>
<pre><span>$ oj -p 80.3 -c -sen colors.json</span>
<span>{</span>
  <span>colors</span><span>:</span> <span>[</span>
    <span>{</span><span>color</span><span>:</span> <span>black</span> <span>hex</span><span>:</span> <span>"#000"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>0</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>red</span> <span>hex</span><span>:</span> <span>"#f00"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>0</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>yellow</span> <span>hex</span><span>:</span> <span>"#ff0"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>255</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>green</span> <span>hex</span><span>:</span> <span>"#0f0"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>255</span> <span>0</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>cyan</span> <span>hex</span><span>:</span> <span>"#0ff"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>255</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>blue</span> <span>hex</span><span>:</span> <span>"#00f"</span> <span>rgb</span><span>:</span> <span>[</span><span>0</span> <span>0</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>magenta</span> <span>hex</span><span>:</span> <span>"#f0f"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>0</span> <span>255</span><span>]</span><span>}</span>
    <span>{</span><span>color</span><span>:</span> <span>white</span> <span>hex</span><span>:</span> <span>"#fff"</span> <span>rgb</span><span>:</span> <span>[</span><span>255</span> <span>255</span> <span>255</span><span>]</span><span>}</span>
  <span>]</span>
<span>}</span></pre>
	      </td>
	    </tr>
	    <tr>
	      <td colspan="2">
		<p>Continue the Fight</p>
		<p>
		  Beauty is in the eye of the beholder. My preference is the
		  pretty colored SEN format. You might have a different
		  preference but let's continue the revolution together and get
		  more pretty JSON out there. Use pretty JSON on web pages and
		  in email. For the tool builders out there, offer the
		  option for pretty JSON.
		</p>
		<p>
		  Note: In case you are wondering if the colored JSON HTML was
		  written or colorized by hand, it was
		  not. The <code>-html</code> option
		  of <span>oj</span> was used to
		  produce the colorized HTML for this article. It's a handy
		  option when including JSON on web pages or in email.
		</p>
	      </td>
	    </tr>
	  </tbody></table>
	</div>
      </div></div>]]>
            </description>
            <link>http://www.ohler.com/dev/pretty.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26237048</guid>
            <pubDate>Tue, 23 Feb 2021 13:37:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You need to be able to run your system]]>
            </title>
            <description>
<![CDATA[
Score 279 | Comments 148 (<a href="https://news.ycombinator.com/item?id=26236908">thread link</a>) | @catern
<br/>
February 23, 2021 | http://catern.com/run.html | <a href="https://web.archive.org/web/*/http://catern.com/run.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
When developing a system,
it is important to be able to run the system in its entirety.
<p>
"Run the unit tests" doesn't count.
The complexity of your system is in the interactions between the units.
</p><p>
"Run an individual service against mocks" doesn't count.
A mock will rarely behave identically to the real dependency,
and the behavior of the individual service will be unrealistic.
You need to run the actual system.
</p><p>
"Run an individual service in a shared stateful development environment running all the other services" doesn't count.
A shared development environment will be unreliable as it diverges more and more from the real system.
</p><p>
"Run most services in a mostly-isolated development environment,
calling out to a few hard-to-run external services" doesn't count.
Those few external services on the edge of the mostly-isolated development environment are often the most crucial ones;
without the ability to run modified versions of them, your development process is crippled.
Furthermore, being dependent on external services greatly complicates where and how you can run the system;
it's much harder to, for example, run tests with the system on every commit if that will access external services.
</p><p>
"Run all the services that make up the system in an isolated development environment" counts;
it's the bare minimum requirement.
Bonus points if this can be done completely on localhost,
without using an off-host cluster deployment system.
</p><p>
Without the ability to actually run the entire system in this way while developing,
many evil practices will tend to become common.
</p><ul>
  <li>
    Testing is harder and far less representative,
    and therefore many issues can only be found when changes are deployed to production.
  </li><li>
    In turn, production deployment will cause issues more often,
    and so deployment will be more slow and less frequent.
  </li><li>
    Deploying the system to new environments is more difficult,
    since the developers aren't able to actually run the system.
    Existing practices in production will be cargo-culted and copied around indefinitely,
    even when they are unnecessary or actively harmful.
  </li><li>
    Exploratory usage of the system is very difficult,
    so it will be harder to consider using the system for purposes outside what it was originally developed for,
    and new use cases will become rare.
  </li><li>
    Downstream clients who depend on the system will also suffer all these issues,
    since without the ability to run the upstream system in development,
    they can't run their own entire system, which is a superset of the upstream system.
</li></ul>
Running the entire system during development is the first step to preventing these issues.
Further steps include writing automated tests for the system (which can be run repeatedly during development),
and using, as much as possible, the same code to run the system in development and in production.
<p>
Developers of large or legacy systems that cannot already be run in their entirety during development
often believe that it is impractical to run the entire system during development.
They'll talk about the many dependencies of their system,
how it requires careful configuration of a large number of hosts,
or how it's too complex to get reliable behavior.
</p><p>
In my experience, they're always wrong.
These systems can be run locally during development with a relatively small investment of effort.
Typically, these systems are just ultimately not as complicated as people think they are;
once the system's dependencies are actually known and understood rather than being cargo-culted or assumed,
running the system, and all its dependencies, is straightforward.
</p><p>
Being able to run your entire system during development is just about the most basic requirement for a software project.
It's not, on its own, sufficient for your development practices to be high quality;
but if you can't do this, then you're not even in the running.
</p></div>]]>
            </description>
            <link>http://catern.com/run.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236908</guid>
            <pubDate>Tue, 23 Feb 2021 13:20:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PfSense 2.5.0 bugs and fixes after upgrade]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236796">thread link</a>) | @ggho
<br/>
February 23, 2021 | https://www.provya.com/blog/pfsense-2-5-0-bugs-and-fixes-after-upgrade/ | <a href="https://web.archive.org/web/*/https://www.provya.com/blog/pfsense-2-5-0-bugs-and-fixes-after-upgrade/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.provya.com/blog/pfsense-2-5-0-bugs-and-fixes-after-upgrade/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236796</guid>
            <pubDate>Tue, 23 Feb 2021 13:04:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most thoroughly commented linker script (probably)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26236726">thread link</a>) | @ingve
<br/>
February 23, 2021 | https://blog.thea.codes/the-most-thoroughly-commented-linker-script/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>While developing the firmware for Winterbloom's <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux">Castor &amp; Pollux</a>, I got very curious as to just what the Microchip/Atmel-provided linker script was doing.</p>
<p>If you've never heard of or seen a linker script before you're not alone. Most of us never even have to think about them, however, on memory constained embedded devices it's not uncommon to need to modify the default linker script.</p>
<p>The linker script controls how <code>ld</code> combines all of your <code>.o</code> files into a single <code>.elf</code> and how that resulting <code>.elf</code> file gets loaded by the target processor.</p>
<p>So I was staring at this script that made absolutely no sense to me. It's filled with incantations and mysterious symbols and there's no indication of what they're for or where they come from.</p>
<p>So I did a <strong>lot</strong> of research and now I can present to you <strong>the most thoroughly commented linker script</strong><sup id="fnref:probably"><a href="#fn:probably">1</a></sup>.</p>
<p>You can see this script in its entirety, comments and all, on <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/blob/master/firmware/scripts/samd21g18a.ld">GitHub</a>. But if you'd like to read it here instead it's transcribed below.</p>
<h2 id="output-format">Output format</h2>
<p>Output format sets the ELF output format to use a specific BFD backend.</p>
<p>The first is the default BFD. The second and third arguments are used
when big (-EB) or little (-EL) endian is requested.</p>
<p>Since the SAM D series are configured with only little endian support,
"elf32-littlearm" is used across the board. This option seems to be
included by Atmel/Microchip out of an abundance of caution, as
arm-none-eabi-ld will do the right thing and use "elf32-littlearm" by
default.</p>
<p>The list of acceptable values can be obtained using <code>objdump -i</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands">https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands</a></li>
<li><a href="https://sourceware.org/binutils/docs/ld/BFD.html">https://sourceware.org/binutils/docs/ld/BFD.html</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 11.1.11, Cortex M0+ Configuration</li>
</ul>
<pre><span>OUTPUT_FORMAT</span><span>(</span><span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>)</span>
</pre>
<h2 id="cpu-memory-configuration-variables">CPU memory configuration variables</h2>
<p>These variables are used by the following "MEMORY" command to define
the various memory spaces.</p>
<p>For the SAMD21G18A used by this project, the available Flash is
262kB and the available SRAM is 32kB.</p>
<p>This project also reserves 8kB for the bootloader and 1kB for
"non-volatile memory" (NVM) - which is used by the application
to store calibration and user settings.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>FLASH_SIZE</span> <span>=</span> <span>0x40000</span><span>;</span>      <span>/* 256kB */</span>
<span>BOOTLOADER_SIZE</span> <span>=</span> <span>0x2000</span><span>;</span>  <span>/* 8kB */</span>
<span>NVM_SIZE</span> <span>=</span> <span>0x400</span><span>;</span>          <span>/* 1kbB */</span>
<span>SRAM_SIZE</span> <span>=</span> <span>0x8000</span><span>;</span>        <span>/* 32kB */</span>
</pre>
<p>ARM Cortex-M processors use a descending stack and generally
require stack space to be set aside in RAM.</p>
<p>The application's behavior determines just how much stack space
should be reserved. I generally start with 2kB (0x800) of
stack space for Cortex-M0+ projects programmed in C .</p>
<p>You can analyze stack usage in GCC using the <code>-fstack-usage</code>
flag and you can enable compiler warnings for stack usage
with <code>-Wstack-usage=STACK_SIZE</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/">https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/</a></li>
<li><a href="https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications">https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html">https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html</a></li>
</ul>
<pre><span>STACK_SIZE</span> <span>=</span> <span>DEFINED</span><span>(</span><span>__stack_size__</span><span>)</span> <span>?</span> <span>__stack_size__</span> <span>:</span> <span>0x800</span><span>;</span>
</pre>
<h2 id="memory-space-definition">Memory space definition</h2>
<p>This section declare blocks of memories for specific purposes. Since an
ARM's address space is generally split between Flash, SRAM, peripherals,
and other regions, it's necessary to tell the linker where different
types of data can go in the address space.</p>
<p>These blocks will be used in the <code>SECTIONS</code> command below.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY">https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>MEMORY</span>
<span>{</span>
</pre>
<p>Start with the Flash memory region. On the SAMD21, Flash starts at
the beginning of the address space (<code>0x00000000</code>) and is contiguous
right up to the size of the Flash. Flash is marked a <code>rx</code> so
that the linker knows that this space is read-only (<code>r</code>) and
executable (<code>x</code>).</p>
<p>The "bootloader" section allows this firmware to work with the uf2
bootloader. The bootloader takes the first 0x2000 bytes of flash
memory.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/adafruit/uf2-samdx1#configuration">https://github.com/adafruit/uf2-samdx1#configuration</a></li>
</ul>
<pre>    <span>bootloader</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>BOOTLOADER_SIZE</span>
</pre>
<p>Following the bootloader is the flash memory used by the application,
called "rom" here - even though it's flash, the name is just a name
and doesn't carry special meaning.</p>
<p>The total length of the rom block is the MCU's flash size minus the
bootloader's size and any space reserved for "non-volatile memory"
by the application.</p>
<pre>   <span>rom</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00002000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>BOOTLOADER_SIZE</span> <span>-</span> <span>NVM_SIZE</span>
</pre>
<p>The "nvm" block is space set aside for the application to store
user settings and calibration data in the MCU's flash.</p>
<p>The block is located right at the end of the flash space. This
is useful because it means that it says in a fixed location
regardless of how much flash space the application takes up
in "rom". Explicitly defining this section also lets the
linker ensure that application code doesn't overwrite the
data in this region.</p>
<p>This block is marked as read-only (<code>r</code>) because flash can not
be written in the same way as normal memory, however, the
application can use the SAMD's NVM peripheral to write data in
this region.</p>
<pre>   <span>nvm</span> <span>(</span><span>r</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>NVM_SIZE</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>NVM_SIZE</span>
</pre>
<p>The "ram" block is mapped to the CPU's SRAM and it's where
the stack, heap, and all variables will go.</p>
<p>For the SAMD21, SRAM starts at 0x20000000 and is contiguous
for the size of the SRAM.</p>
<pre>   <span>ram</span> <span>(</span><span>rwx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x20000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>SRAM_SIZE</span>
<span>}</span>
</pre>
<h2 id="sections">Sections</h2>
<p>The sections command tells the linker how to combine the
input files into an output ELF and where segments belong
in memory.</p>
<p>The linker takes a set of input files containing the "input
sections" and uses this to map them to "output sections"
which are placed in the output ELF file.</p>
<p>While the most important sections to think about here
are the ones that'll be placed into the memory (segments)
some sections are just placed in the output ELF for debugging.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS">https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS</a></li>
</ul>
<pre><span>SECTIONS</span>
<span>{</span>
</pre>
<p>The text segment contains program code and read-only data.</p>
<p>References:</p>
<ul>
<li><a href="https://developer.arm.com/documentation/dui0101/a/">https://developer.arm.com/documentation/dui0101/a/</a>
Page 5, Segments</li>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
</ul>
<pre>   <span>.</span><span>text</span> <span>:</span>
   <span>{</span>
</pre>
<p>This segment must be 4-byte aligned as defined in ARM ELF
File Format specification.</p>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
</pre>
<p>The vector table defines the initial stack pointer and
interrupt/exception routines for the ARM CPU and device
peripherals. Every Cortex-M project needs this.</p>
<p>For the SAM D series the vector table is expected
to be at address 0x00000000 after reset. Since
flash memory starts at 0x00000000, the first values
in flash should be the vector table.</p>
<p>When defining the vector table in code you must use
<code>__attribute__ ((section(".vectors")))</code> to tell
GCC to place the vector table into the section
named ".vectors" in the input object file so that
the linker can find it.</p>
<p>Note that since this project uses the UF2 bootloader,
this actually gets placed at the beginning of the
program's flash area (0x2000). The Cortex-M allows
changing the vector table after initialization,
so the startup script sets the Vector Table Offset
Register (<code>SCB-&gt;VTOR</code>) to <code>_sfixed</code> during its
intialization. The <code>_efixed</code> symbol is unused but
included for completeness.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
Secion 8.3.3, Fetching of Initial Instructions</li>
<li><a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf</a>
Section B1.5.3, The vector table
Section B3.2.5, Vector Table Offset Register, VTOR</li>
<li><a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/tree/master/firmware/third_party/samd21/gcc/gcc/startup_samd21.c">startup_samd21.c</a></li>
</ul>
<pre>      <span>_sfixed</span> <span>=</span> <span>.;</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>vectors</span> <span>.</span><span>vectors</span><span>.</span><span>*</span><span>))</span>
</pre>
<p>Include code and read-only data sections from all
input files.</p>
<p>By default, GCC places all program code into a section named
".text" and read-only data (such as const static variables) into
a section named ".rodata" in the input object files. This naming
convention is from the ELF ABI specification.</p>
<p>GCC generates three "flavors" of sections in object files:</p>
<ul>
<li><code>.{section}</code>: the basic section.</li>
<li><code>.{section}.*</code>: sections generated by <code>-ffunction-sections</code> and
<code>-fdata-sections</code> so that each function/data has a unique
section.</li>
<li><code>.gnu.linkonce.{type}.*</code>: sections generated by GCC so the
linker can remove duplicates. Seems to be related to
Vague Linking.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html">https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html</a></li>
<li><a href="https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section">https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section</a></li>
</ul>
<pre>      <span>*</span><span>(.</span><span>text</span> <span>.</span><span>text</span><span>.</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>t</span><span>.</span><span>*</span><span>)</span>
      <span>*</span><span>(.</span><span>rodata</span> <span>.</span><span>rodata</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>r</span><span>.</span><span>*</span><span>)</span>
</pre>
<h2 id="c-c-runtime-support">C &amp; C++ runtime support</h2>
<p>The following sections are for the C/C++ runtime. These are generally used by crt0.</p>
<p>References:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Crt0">https://en.wikipedia.org/wiki/Crt0</a></li>
</ul>
<h3 id="initializers">Initializers</h3>
<ul>
<li>C++ Runtime: initializers for static variables.</li>
<li>C Runtime: designated constructors</li>
</ul>
<p>For C++, handles variables at file scope like this:</p>
<pre><span>int</span> <span>f</span> <span>=</span> <span>some_func</span><span>()</span>
</pre>
<p>For C, handles functions designated as constructors:</p>
<pre><code>void intialize_thing(void) __attribute__((constructor));
</code></pre>
<p>Executed by the C runtime at startup via <code>__libc_init_array</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c">https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c</a></li>
<li><a href="https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c">https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c</a>;</li>
<li><a href="https://gcc.gnu.org/onlinedocs/gccint/Initialization.html">https://gcc.gnu.org/onlinedocs/gccint/Initialization.html</a></li>
<li><a href="https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction">https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction</a></li>
<li><a href="https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array">https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array</a></li>
</ul>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>init</span><span>))</span>
      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
  …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236726</guid>
            <pubDate>Tue, 23 Feb 2021 12:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to Programming with ECMA-55 Minimal BASIC [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236686">thread link</a>) | @ingve
<br/>
February 23, 2021 | https://buraphakit.sourceforge.io/Learn_BASIC.pdf | <a href="https://web.archive.org/web/*/https://buraphakit.sourceforge.io/Learn_BASIC.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://buraphakit.sourceforge.io/Learn_BASIC.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236686</guid>
            <pubDate>Tue, 23 Feb 2021 12:49:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Switching from C# to Go for back end development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26236527">thread link</a>) | @zachruss92
<br/>
February 23, 2021 | https://aluma.io/resources/blog/switching-from-c-to-go-for-backend-developmentThe | <a href="https://web.archive.org/web/*/https://aluma.io/resources/blog/switching-from-c-to-go-for-backend-developmentThe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://aluma.io/resources/blog/switching-from-c-to-go-for-backend-developmentThe</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236527</guid>
            <pubDate>Tue, 23 Feb 2021 12:29:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developer Experience: How to Define Good Documentation?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236451">thread link</a>) | @thenoisywatcher
<br/>
February 23, 2021 | https://humanitec.com/blog/developer-experience-documentation | <a href="https://web.archive.org/web/*/https://humanitec.com/blog/developer-experience-documentation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href=""><p>There are many projects, products, and services to choose from when making decisions about the tools you and your team use.&nbsp;</p><p>One of the aspects many of us look at to help assess if a tool is useful to us is the documentation, but how do you judge what good documentation is?&nbsp;</p><p>A tool might offer exciting features, yet, the <a href="https://humanitec.com/blog/developer-experience">developer experience</a> of the documentation might be lacking. When evaluating a new tool, the developer experience matters as much as the offered features.&nbsp;</p><p>This post aims to help you identify key factors to look for, how that might reflect on the project, and how well it will meet your expectations.&nbsp;</p><h2><strong>Onboarding and Getting Started</strong></h2><p>If you are learning about a new tool, then the getting started guide for any project is typically the first document you read.&nbsp;</p><p>A bad experience with it is likely to put any casual reader off of investigating further. First impressions matter, so below are four factors to look for when evaluating the getting started experience for documentation.&nbsp;</p><h3><strong>Self-serve option available</strong></h3><p>Trying the time-honored “getting started guide” is typically the first point of call for developers assessing a new technical tool. There are some tools (especially in the SaaS world) that rely on onboarding you through a front end first and taking you through the first steps from there instead.</p><p>In either case, prioritize tools that allow you to create an account and test yourself without the need to make an appointment with a sales representative or fill in excessive forms.&nbsp;</p><p>There might be some valid reasons for doing this, such as a private beta or that the project is new. But often, it’s purely to force you through a sales process and bombard you with sales messages. This isn’t directly related to documentation, but often you also can’t view documentation until you are through this process, which makes it hard to evaluate at all.</p><h3><strong>Time to getting started</strong></h3><p>If you evaluate multiple options, then how long it takes you to follow a getting started guide from the beginning to a satisfactory conclusion is one measure to measure by.&nbsp;</p><p>While the real time can depend a lot on the tutorial’s complexity, for comparable tools or guides, a shorter time is a good sign that the team has spent time reducing barriers, testing steps, and checking that the language they used is clear.</p><h3><strong>Real-world examples</strong></h3><p>Getting started guides tend to focus on simplicity and speed. Often this is intentional to make a tool appear “easy” to use. However, if the examples and steps the guide follows are unrealistic for any “real world” use case for the tool, then is it a good getting started guide?</p><h3><strong>Dependencies and Prerequisites</strong></h3><p>Certain programming languages are notorious for having deep and complex dependency trees. This means that a project might leverage code from a 3rd party (which is common), but then that tool also has its dependencies.&nbsp;</p><p>Following a getting started guide should not have to take you down a complex path of conflicting dependency versions or surprising undocumented prerequisites you have to figure out. This can show that the developers or writers of the documentation have not tested examples from scratch on a “vanilla” new user set up.</p><p>Ideally, a project should work with the most popular or most supported (and <a href="https://itsfoss.com/long-term-support-lts/">LTS</a>, for example) versions of languages and operating systems. If they don’t, it can show a lack of meaningful commitment to development or specific platforms.&nbsp;</p><p>At the least, the documentation should state which versions you need and a rough idea of when to expect support for newer or more popular versions.</p><h2><strong>Continuing the journey</strong></h2><p>A great getting started guide is a big plus for any project you are evaluating, but rarely does a getting started guide help you apply anything to a real-world production application.&nbsp;</p><p>One of the hardest parts of creating documentation is taking a reader on this crucial journey, and it’s generally where most people get frustrated with documentation. Some projects have a much clearer and defined use case than others (for example, a payment API versus a CMS), but there are some general things to look for.</p><p>A good getting started guide should suggest common pages or paths for you to follow next. These could be generic, such as key components of the tool, finding further information on a feature, or following typical use cases based on user research. It’s near impossible for documentation to suit every possible use you might have, but it can help you assemble the knowledge you need.</p><h2><strong>Code examples</strong></h2><p>Not wanting to disappoint anyone reading this who writes documentation, but it’s an adage that developers often don’t read the documentation thoroughly but rather scan for code examples. Good documentation is structured to ensure that important text surrounds code examples, so there is more chance you notice it.</p><p>Code examples are often a source of annoyance for anyone reading documentation, and I’m sure you have come across one that is incomplete or doesn’t work.</p><p>There are different types of code examples, and in each case, their purpose should be clear.</p><p>Some code examples are part of a tutorial or guide, and we expect the reader to follow them in order and build a full piece of code that works as expected. In these cases, the examples should tell you all you need to know and not leave anything to assumption to result in a working example.</p><p>Some code examples are illustrative to show a concept or implementation detail, which means they do not work without replacing placeholder values or extra code. Documentation should make these clear and suggest what you need to do to make them usable.</p><p>While not always necessary, documentation should explain or show you the expected output for code examples, so you know that you have implemented it successfully.</p><p>Finally, if a project supports multiple programming languages or implementation options, then the documentation should show code examples for all of these. However, this is a lot of work, but examples for the most widely used options are essential, and guidance on using the other supported options enough.</p><h2><strong>Reference - SDK and API documentation</strong></h2><p>Filling in the documentation gaps is generally the role of reference documentation, which includes <a href="https://humanitec.com/blog/api-design-developer-experience">API endpoint and function documentation</a>, architecture explanations, and other aspects of the project readers might find useful to know if they need to.</p><p>Firstly, is reference documentation available, or do you need to dig through the codebase to find it? If it does exist, how complete or useful is it? Often teams autogenerate reference documentation, and that’s fine, but often descriptions come from code comments, and code comments are not always useful to a reader.&nbsp;</p><p>Reference documentation can be more abstract than other documentation as it describes individual pieces of a project instead of how to use them. However, good reference documentation still explains what that piece is and how it works. Below you find an excellent example.</p><figure><p><img src="https://assets.website-files.com/5c73bbfe3312822f153dd310/6023d59ff38a1ca95194dac2_fwHv1JPLySGuL3x-MsQM8fo9jSQXt7_6cy_dpa4XYC0hbVaFivRkKmXRLCJcHbyLZ12kmRxtQlmEbqI7V8jK4pAgGZE4_V0DeY1m1hr4UTM-EP2hT_piRUjG5o_jYTxXARVD0Z4l.png" alt=""></p><figcaption>Source: <a href="https://lisk.io/documentation/lisk-sdk/references/lisk-elements/cryptography.html#stringtobuffer">Lisk SDK documentation</a></figcaption></figure><p>‍</p><p>The <a href="https://stripe.com/docs/api">Stripe API documentation</a> is a common example of useful and usable autogenerated (but using highly customized tooling) API documentation. Not wanting to publicly shame any project, this tweet from Ricardo Ferreira sums up the problem with documentation generated from comments perfectly.</p><p>‍<br></p><h2><strong>Language</strong></h2><p>Good language is a big topic, and it doesn’t necessarily affect the quality of a project. It can show that the team behind it goes the extra mile to care, which is a good sign.</p><p>Acceptable documentation should be free of spelling mistakes and other typographical errors. Excellent documentation should use a consistent voice, terminology, and style. What constitutes “correct” in these cases is personal and opinionated, but consistency is key.</p><p>There are a handful of popular and commonly used style guides, such as the <a href="https://developers.google.com/style/">Google</a> and <a href="https://docs.microsoft.com/en-us/style-guide/welcome/">Microsoft</a> style guides. Whether that documentation follows one of these style guides over another, or its own custom style guide is not what’s important. However, if a company follows a style guide, it shows they have given that extra thought and care to their documentation.</p><h2><strong>Bonus points</strong></h2><p>These discussion points don’t quite fit into any of the sections above but show that a team has an extra eye for detail.</p><p>How does the documentation look? Something that looks fantastic and uses the latest tricks in web development may not equal useful and useable documentation, but if it’s both of those, then even better.</p><p>How often is the documentation updated? There are some good reasons for not updating documentation regularly, such as an older project or problem-free documentation, but it can also indicate a dormant project that’s best avoided.<br></p><h2>Good documentation shows a team cares</h2><p>We all know that documentation is hard, especially for solo developers or smaller teams who also need to focus on features and bug fixes. However, when there are many options to choose from when evaluating new tools, frameworks, and services, and sometimes weighing them up on features alone is inconclusive. Therefore, the documentation’s developer experience matters.</p><p>Good developer experience and documentation indicate how much a team and community involved with a project care about their users. More importantly, it indicates how much work could be involved in implementing projects you are evaluating.&nbsp;</p><p>If tutorials are poorly written, or don’t make sense. If code examples don’t work, or important details are lacking. Will you find similar problems and a lack of concern in a project after investing your time and business in it?<br></p></div></div>]]>
            </description>
            <link>https://humanitec.com/blog/developer-experience-documentation</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236451</guid>
            <pubDate>Tue, 23 Feb 2021 12:20:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Python strings work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26236424">thread link</a>) | @r4victor
<br/>
February 23, 2021 | https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/ | <a href="https://web.archive.org/web/*/https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>In 1991 Guido van Rossum released the first version of the Python programming language. About that time the world began to witness a major change in how computer systems represent written language. The internalization of the Internet increased the demand to support different writing systems, and the Unicode Standard was developed to meet this demand. Unicode defined a universal character set able to represent any written language, various non-alphanumeric symbols and, eventually, emoji 😀. Python wasn't designed with Unicode in mind, but it evolved towards Unicode support during the years. The major change happened when Python got a built-in support for Unicode strings – the <code>unicode</code> type that later became the <code>str</code> type in Python 3. Python strings have been proven to be a convenient way to work with text in the Unicode age. Today we'll see how they work behind the scenes.</p>
<p><strong>Note</strong>: In this post I'm referring to CPython 3.9. Some implementation details will certainly change as CPython evolves. I'll try to keep track of important changes and add update notes.</p>
<h2>The scope of this post</h2>
<p>This post doesn't try to cover all aspects of text encoding in relation to Python. You see, programming language designers have to make several text encoding decisions because they have to answer the following questions:</p>
<ul>
<li>How to talk to the external world (the encodings of command-line parameters, environment variables, standard streams and the file system).</li>
<li>How to read the source code (the encoding of source files).</li>
<li>How to represent text internally (the encoding of strings).</li>
</ul>
<p>This post focuses on the last problem. But before we dive into the internals of Python strings, let's briefly discuss the problem of text encoding on a real life example and clarify what Unicode really is.</p>
<h2>The essence of text encoding</h2>
<p>You see this text as a sequence of characters rendered by your browser and displayed on your screen. I see this text as the same sequence of characters as I type it into my editor. In order for us to see the same thing, your browser and my editor must be able to represent the same set of characters, that is, they must agree on a <strong>character set</strong>. They also need to choose some, possibly different, ways to represent the text internally to be able to work with it. For example, they may choose to map each character to a unit consisting of one or more bytes and represent the text as a sequence of those units. Such a mapping is usually referred to as a <strong>character encoding</strong>. A character encoding is also crucial for our communication. Your browser and my web server must agree on how to <strong>encode</strong> text into bytes and <strong>decode</strong> text from bytes, since bytes is what they transmit to talk to each other.</p>
<p>The character set that your browser and my editor use is Unicode. Unicode is able to represent English as well as any other written language you can think of (文言, Čeština, Ελληνικά, עברית, हिन्दी), 日本語, Português, Русский) and thousands of miscellaneous symbols (₤, ⅐, ↳, ∭, ⌘, , ♫, 👨🏼‍💻, 🍺) . My web server sends this text as a part of the HTML page in the UTF-8 encoding. You browser knows which encoding was used to encode the text because the <code>Content-Type</code> HTTP header declares the encoding:</p>
<div><pre><span></span>Content-Type: text/html; charset=utf-8
</pre></div>


<p>Even if you save this HTML page locally, your browser will still be able to detect its encoding because the encoding is specified in the HTML itself:</p>
<div><pre><span></span><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;</span><span>html</span> <span>lang</span><span>=</span><span>"en"</span><span>&gt;</span>
<span>&lt;</span><span>head</span><span>&gt;</span>
    <span>&lt;</span><span>meta</span> <span>charset</span><span>=</span><span>"utf-8"</span> <span>/&gt;</span>
    <span>&lt;!-- ... --&gt;</span>
<span>&lt;/</span><span>html</span><span>&gt;</span>
</pre></div>


<p>This may seem absurd to you. How can a browser decode the HTML to read the encoding if it doesn't know the encoding yet? This is usually not a problem in practice because the beginning of an HTML page contains only ASCII characters and most encodings used on the web encode ASCII characters in the same way. Check out the <a href="https://html.spec.whatwg.org/multipage/parsing.html#concept-encoding-confidence">HTML standard</a> to learn more about the algorithm that browsers use to determine the encoding.</p>
<p>Note that the HTTP header and the HTML metatag specify "charset", i.e. a character set. This may seem confusing since UTF-8 is not a character set. What they really specify is a character encoding. The two terms are often used interchangeably because character encodings typically imply a character set of the same name. For example, the ASCII character encoding implies the ASCII character set. The Unicode Standard fixes the terminology by giving precise definitions to all important terms. We'll study them, but before, let's discuss why and how the Unicode project began.</p>
<h2>The road to Unicode</h2>
<p>Before the adoption of Unicode, most computer systems used the <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> character encoding that encodes a set of 128 characters using a 7-bit pattern to encode each character. ASCII was sufficient to deal with English texts but that's about it. Other character encodings were developed to support more languages. Most of them <a href="https://en.wikipedia.org/wiki/Extended_ASCII">extended ASCII</a> to 256 characters and used one byte to encode each character. For example, the <a href="https://en.wikipedia.org/wiki/ISO/IEC_8859">ISO 8859</a> standard defined a family of 15 such character encodings. Among them were:</p>
<ul>
<li>Latin Western European ISO 8859-1 (German, French, Portuguese, Italian, etc.)</li>
<li>Central European ISO 8859-2 (Polish, Croatian, Czech, Slovak, etc.)</li>
<li>Latin/Cyrillic ISO 8859-5 (Russian, Serbian, Ukrainian, etc.)</li>
<li>Latin/Arabic ISO 8859-6</li>
<li>Latin/Greek ISO 8859-7.</li>
</ul>
<p>Multi-lingual software had to handle many different character encodings. This complicated things a lot. Another problem was to choose the right encoding to decode text. Failing to do so resulted in a garbled text known as <a href="https://en.wikipedia.org/wiki/Mojibake">mojibake</a>. For example, if you encode the Russian word for mojibake "кракозябры" using the <a href="https://en.wikipedia.org/wiki/KOI8-R">KOI-8</a> encoding and decode it using ISO 8859-1, you'll get "ËÒÁËÏÚÑÂÒÙ".</p>
<p>The problems with different character encodings are not gone completely. Nevertheless, it became much more easier to write multi-lingual software nowadays. This is due to two independent initiatives that began in the late 1980s. One was <a href="https://en.wikipedia.org/wiki/Universal_Coded_Character_Set">ISO 10646</a>, an international standard, and the other was Unicode, a project organized by a group of software companies. Both projects had the same goal: to replace hundreds of conflicting character encodings with a single universal one that covers all languages in widespread use. They quickly realized that having two different universal character sets wouldn't help achieve the goal, so in 1991 the Universal Coded Character Set (UCS) defined by ISO 10646 and Unicode's character set were unified. Today the projects define essentially the same character encoding model. Nevertheless, both continue to exist. The difference between them is that the Unicode Standard has a greater scope:</p>
<blockquote>
<p>The assignment of characters is only a small fraction of what the Unicode Standard and its associated specifications provide. The specifications give programmers extensive descriptions and a vast amount of data about the handling of text, including how to:</p>
<ul>
<li>divide words and break lines </li>
<li>sort text in different languages </li>
<li>format numbers, dates, times, and other elements appropriate to different locales </li>
<li>display text for languages whose written form flows from right to left, such as Arabic or Hebrew </li>
<li>display text in which the written form splits, combines, and reorders, such as for the languages of South Asia </li>
<li>deal with security concerns regarding the many look-alike characters from writing systems around the world</li>
</ul>
</blockquote>
<p>The most important thing that we need to understand about Unicode is how it encodes characters.</p>
<h2>Unicode basics</h2>
<p>Unicode defines <strong>characters</strong> as smallest components of written language that have semantic value. This means that such units as diacritical marks are considered to be characters on their own. Multiple Unicode characters can be combined to produce what visually looks like a single character. Such combinations of characters are called <strong>grapheme clusters</strong> in Unicode. For example, the string "á" is a grapheme cluster that consists of two characters: the Latin letter "a" and the acute accent "´". Unicode encodes some grapheme clusters as separate characters as well, but does that solely for compatibility with legacy encodings. Due to combining characters, Unicode can represent all sorts of grapheme clusters such as "ä́" and, at the same time, keep the character set relatively simple.</p>
<p>Unicode characters are abstract. The standard doesn't care about the exact shape a character takes when it's rendered. The shape, called a <strong>glyph</strong>, is considered to be a concern of a font designer. The connection between characters and glyphs can be quite complicated. Multiple characters can merge into a single glyph. A single character can be rendered as multiple glyphs. And how characters map to glyphs can depend on the context. Check out the <a href="https://www.unicode.org/reports/tr17/#CharactersVsGlyphs">Unicode Technical Report #17</a> for examples.</p>
<p>Unicode doesn't map characters to bytes directly. It does the mapping in two steps:</p>
<ol>
<li>The <strong>coded character set</strong> maps characters to code points.</li>
<li>A <strong>character encoding form</strong>, such as UTF-8, maps code points to sequences of code units, where each code unit is a sequence of one or more bytes.</li>
</ol>
<p>The Unicode coded character set is what we usually mean when we say Unicode. It's the same thing as the UCS defined by ISO 10646. The word "coded" means that it's not actually a set but a mapping. This mapping assigns a code point to each character in the character set. A <strong>code point</strong> is just an integer in the range [0, 1114111], which is written as U+0000..U+10FFFF in the Unicode hexadecimal notation and is called a <strong>code space</strong>. The current Unicode 13.0 assigns code points to 143,859 characters.</p>
<p>Technically, the coded character set is a <a href="https://www.unicode.org/charts/">collection of entries</a>. Each entry defines a character and assigns a code point to it by specifying three pieces of information:</p>
<ul>
<li>the code point value</li>
<li>the name of the character; and</li>
<li>a representative glyph.</li>
</ul>
<p>For example, the entry for the letter "b" looks like this: (U+0062, LATIN SMALL LETTER B, b).</p>
<p>The standard also specifies various character properties such as whether the character is a letter, a numeral or some other symbol, whether it's written from left-to-right or from right-to-left and whether it's an …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/">https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/</a></em></p>]]>
            </description>
            <link>https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236424</guid>
            <pubDate>Tue, 23 Feb 2021 12:16:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commodore History Part 1: The Commodore Pet]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 23 (<a href="https://news.ycombinator.com/item?id=26236320">thread link</a>) | @SQL2219
<br/>
February 23, 2021 | http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/ | <a href="https://web.archive.org/web/*/http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4839">
														
							
														
							
														
							<div>
															<div>
									<p>When you watch documentaries about early computer innovations, particularly the late 70s, early 1980s, most of the documentaries tend to focus on Apple and Microsoft, and maybe IBM as the big innovators. But, I think often companies like Commodore, and Atari, and Tandy don’t get nearly enough credit for the role that they played.&nbsp; Let’s take a look at the Commodore PET!</p>
<p>Most of my readers are familiar with the Commodore 64, one of the best selling computers of all time. Well renowned for its great graphics and sound, but Commodore history didn’t start with this machine. So, let’s go back a little bit to the late 1970s and figure out where it all started!</p>
<h2>Commodore History Part 1 Video</h2>
<p><iframe src="https://www.youtube.com/embed/eP9y_7it3ZM" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h2>The Processor that Started it All</h2>
<p>It all began in 1974 when Chuck Peddle and a group of engineers started up a chip fabrication company called MOS Technology. Most of these guys had worked at Motorola on the 6800 processor, and so they set out to develop a compatible CPU known as the 6501 that could simply be substituted for the much more expensive Motorola CPU. As you might imagine, Motorola sued and to make a long story short, the 6502 was born, which was pretty much the same chip but changed just enough that it was no longer completely compatible with the 6800.</p>
<p><a href="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png"><img data-attachment-id="4855" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0002-the-6502-was-born/" data-orig-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0002 – The 6502 was born" data-image-description="" data-medium-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=300%2C169" data-large-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?fit=1024%2C576" loading="lazy" src="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=750%2C422" alt="The 6502 Processor" width="750" height="422" srcset="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=1024%2C576 1024w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=300%2C169 300w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=768%2C432 768w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?resize=600%2C338 600w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0002-The-6502-was-born.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>Since the chip was no longer compatible with the 6800, customers would need some way to test the chip. In 1976 Chuck Peddle also designed the KIM-1 development computer. This was a single board computer that used the 6502, and could be programmed in machine language from the keypad on the top. However, later it was possible to connect a dumb-terminal display and actually run BASIC. Programs could be saved to a cassette tape. The computer proved to be popular with hobbyists as well as engineers.</p>
<p>The 6502 would go on to be a huge success and eventually found its way into the Apple II series, the Atari 2600, the Nintendo Entertainment System, the entire line of Atari 8-Bit computers, the BBC Micro, and of course the entire line of Commodore 8-Bit machines. But back to 1976 for the moment. MOS Technologies was bought up by Commodore Business Machines, who at this point was primarily in the calculator business. Chuck Peddle managed to convince Commodore boss Jack Tramiel that calculators were a dead-end business and that they needed to produce a computer to compete with the upcoming Apple II.</p>
<h2>The MOS Technology KIM-1</h2>
<p>In 1977 the Commodore PET 2001 was born, using much of the same design as the KIM-1. Much like the Apple II, the PET was all inclusive, having an integrated monitor, keyboard, and cassette tape storage device. 1977 was a big year for the personal computer revolution. With the market introduction of the big 3, the Apple II, Commodore PET, and TRS-80 computer, it was the first time that a regular person could buy an affordable computer without having to assemble it themselves.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png"><img data-attachment-id="4856" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0003-the-kim-1/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0003 – The KIM 1" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=750%2C422" alt="" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0003-The-KIM-1.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>The cool thing about the PET is that it was actually designed by the same guy who designed the 6502 processor. If you look at the prices of the big 3, you’ll see the PET was competitively priced. Although the Apple II did have superior hardware, which we’ll get into shortly, the PET did have the advantage that it came with a monitor and tape drive, where the Apple II required those as separate purchases.</p>
<h2>A Closer Look at the PET</h2>
<p>Let’s take a closer look at the design of the Commodore PET. The first thing I want to draw your attention to is the keyboard. It’s insane, and it will drive you insane if you actually try to type on it. One thing that isn’t communicated well by video and pictures is just how small this keyboard is. The main part, excluding the number pad measures just 6in. by 2.75in. Just to put that into perspective, my iPhone 6 will essentially cover the entire keyboard. The Apple mini keyboard is actually huge by comparison.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png"><img data-attachment-id="4857" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0004-the-pet-keyboard/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0004 – The PET Keyboard" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=750%2C422" alt="the pet keyboard" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0004-The-PET-Keyboard.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>The keyboard size isn’t the only problem. They layout is crazy. While the keys are technically in a QWERTY arrangement, normally the rows are offset creating diagonal lines. Not so on the PET. They are squared up. The weirdness doesn’t end there. The space bar is tiny! Normally you would expect numbers across the top row of keys, but there aren’t any. Instead you have just symbols. If you want to type a number, you have to use the number pad.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png"><img data-attachment-id="4859" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0005-the-pet-keyboard-will-drive-you-insane/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0005 – The PET Keyboard will drive you insane" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=750%2C422" alt="PET keyboard is insane" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0005-The-PET-Keyboard-will-drive-you-insane.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>What is even more infuriating is the symbols. For example, if I want to type a Dollar sign or a number sign, I would instinctively press shift before the key. However, when I do that I wind up with a totally different character instead of the one I wanted. Then there’s the cursor keys. Notice that there are only 2 of them. One key cursors down, and the other key cursors right. If you want to reverse that, you have to hold down the shift key. So by using the combination of the cursor keys and shift you can cursor anywhere on the screen.&nbsp; The little back arrow? You might think that’s a backspace key. But, it’s not. It actually prints that character on the screen, and so when you make a mistake, and believe me you will, you’re going to go to push this key and it’s not going to fix your mistake and you’re going to go even more insane than you were before. The actual delete key is all the way over at the other side of the number pad.</p>
<p>To be fair, when this computer came out in 1977, most of the customers had never even used a personal computer before or a computer of any kind and so they didn’t have any pre-conceptions for what a keyboard layout should be – like we do today. It probably wasn’t quite as weird for them as it would be for us.</p>
<h2>Opening the Commodore PET</h2>
<p>Let’s take a look inside the PET, it opens like the cab of a semi truck, and even gives you a little kick stand to hold it open. Looking at these 16 RAM chips, you might think the PET came with a lot of RAM. But, you’d be wrong. The original PET only came with 4K of RAM. These are 1K by 4-bit static RAM chips. Being that cost was such a consideration for this computer, you might be wondering why they didn’t use the cheaper dynamic RAM, or DRAM? Well, static ram was and still is today much more expensive than dynamic RAM. However, DRAM has one drawback, it requires that it is refreshed every so often, which requires additional circuitry to handle that. When you’re dealing with only 4K, it actually ended up being cheaper just to use static RAM.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png"><img data-attachment-id="4860" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0006-opening-the-pet/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0006 – Opening the PET" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=750%2C422" alt="opening the PET" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0006-Opening-the-PET.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>OK. So 4K is a ridiculously small amount or RAM, but it’s worse than that because the operating system actually needs at least 1K of that, leaving about 3K left over for the user. So how much is 3K of RAM? Well, the screen on the pet is 40-characters by 25-lines, meaning you need 1,000 bytes of RAM, or almost an entire kilobyte just to store one screen full of text. Essentially you had enough RAM for about 3 screens of text! To be fair though, the Apple II and TRS-80 only had 4K when they came out as well.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png"><img data-attachment-id="4861" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0007-the-pet-ram-chips/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0007 – The PET RAM chips" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=750%2C422" alt="PET RAM chips" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0007-The-PET-RAM-chips.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>This particular PET has been upgraded a little daughter board. It’s an aftermarket 32K RAM expansion module, and that’s why it shows 31K available to BASIC on the boot screen. Let’s take a closer look at this cassette drive. This was actually just an off-the-shelf cassette recorder that Commodore bought and slightly modified. You can see the whole unit is actually mounted, in a rather clunky way in my opinion. The cassette drive was really the only storage device available for the PET at first. And with 4K of RAM, this wasn’t much of a problem.</p>
<h2>The PET Disk Drives</h2>
<p>It wasn’t until 1979 that Commodore came out with a matching disk drive. Since the PET was never really designed to use a disk drive, they decided to use the IEEE-488 parallel port as a means to connect the disk drive.&nbsp; Unlike the Apple II, the Commodore PET has no card slots inside so there’s nowhere to add a floppy disk controller card. So, what they had to do was essentially design an entire computer inside the floppy drive unit, which would handle controlling the floppy drives as well as an entire disk operating system.</p>
<p><a href="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png"><img data-attachment-id="4862" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0001-the-pet-8050-disk-drive/" data-orig-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0001 – The PET 8050 Disk Drive" data-image-description="" data-medium-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=300%2C169" data-large-file="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?fit=1024%2C576" loading="lazy" src="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=750%2C422" alt="" width="750" height="422" srcset="https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=1024%2C576 1024w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=300%2C169 300w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=768%2C432 768w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?resize=600%2C338 600w, https://i1.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0001-The-PET-8050-Disk-Drive.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>Indeed if you take a look inside the disk drive, you’ll see it’s quite sophisticated, having it’s own 6502 processor, RAM, ROM, and I/O controllers. The PET didn’t really interact with information on the disks directly, rather it would send commands to the disk drive, such as telling it to fetch a file, and then the disk drive would take care of all of the work of finding the right data on the disk. In fact, it could even copy files or even entire disks from one drive to the other all by itself, just with a single command.</p>
<p>The PET was popular with schools and found its way into many computer labs. And while the disk drive was expensive, one of these floppy drive units could actually be connected to multiple PETs at the same time, thus saving space and money. In fact, you can see this arrangement being used in this photo from a computer lab where each table has 8 PETs connected to a single floppy drive and printer.</p>
<p><a href="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png"><img data-attachment-id="4863" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0010-the-pet-8080-disk-drive-chained/" data-orig-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0010 – The PET 8080 Disk Drive chained" data-image-description="" data-medium-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=300%2C169" data-large-file="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?fit=1024%2C576" loading="lazy" src="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=750%2C422" alt="chained PETs to disk drives" width="750" height="422" srcset="https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=1024%2C576 1024w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=300%2C169 300w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=768%2C432 768w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?resize=600%2C338 600w, https://i2.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0010-The-PET-8080-Disk-Drive-chained.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<h2>The Commodore PET’s Display</h2>
<p>Let’s talk about the screen on the PET. The original model here is black and white. A lot of people assume it’s green, but that actually wasn’t until later models. The original one was black and white. In fact, there’s not even any grayscale. It’s just literally two colors, black and white. The screen was controlled by a clone of the Motorola 6845 CRT controller, which was also used in the IBM CGA card, among other computers. However, there was no circuitry here for color.</p>
<p><a href="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png"><img data-attachment-id="4883" data-permalink="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/commodore-history-part-1-the-pet-0025-the-commodore-pet-black-and-white-display/" data-orig-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=1280%2C720" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Commodore History Part 1 The Pet 0025 – The Commodore PET Black and White Display" data-image-description="" data-medium-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=300%2C169" data-large-file="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?fit=1024%2C576" loading="lazy" src="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=750%2C422" alt="Commodore PET Display" width="750" height="422" srcset="https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=1024%2C576 1024w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=300%2C169 300w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=768%2C432 768w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?resize=600%2C338 600w, https://i0.wp.com/www.the8bitguy.com/wp-content/uploads/2019/06/Commodore-History-Part-1-The-Pet-0025-The-Commodore-PET-Black-and-White-Display.png?w=1280 1280w" sizes="(max-width: 750px) 100vw, 750px" data-recalc-dims="1"></a></p>
<p>There are also no graphics modes. I mean, literally <em>none</em>. There is no way to put graphics on this machine at all. And what’s worse is that the character set is in ROM and it cannot be moved, so there’s no way to modify what the characters look like. So, you are pretty much stuck with putting characters on the screen and only the characters that came built into ROM. And that’s it.</p>
<h2>PETSCII</h2>
<p>However, there are 256 characters using a special character set called PETASCII or later just shortened to PETSCII. The character …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/">http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/</a></em></p>]]>
            </description>
            <link>http://www.the8bitguy.com/4839/commodore-history-part-1-the-commodore-pet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236320</guid>
            <pubDate>Tue, 23 Feb 2021 12:03:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Journey into Game Development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26236081">thread link</a>) | @ingve
<br/>
February 23, 2021 | https://blog.tuxedolabs.com/2021/02/22/background.html | <a href="https://web.archive.org/web/*/https://blog.tuxedolabs.com/2021/02/22/background.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I often get the question how I got into game development and if I have any tips for beginners. Here’s my story and thoughts about getting into game development.</p>


<p>I’ve never been particularly interested in playing games myself. I never had a gaming console as a kid, but ever since I was very young I’ve had a strong interest in engineering and technology. My early interest in computers was entirely centered around programming, and not playing games.</p>

<p>I somehow convinced my parents to get me a Commodore VIC 64, because that was what one of my friends had. I’m not sure how old I was, but I must have been eleven or twelve. Back then, the printed manual for a computer was an introduction to programming (BASIC, in this case). When turning the computer on, there was a prompt where you could start programming. Overall, the bar to enter programming was way lower than now. No choice of programming language, no game engine, no downloading and installing stuff, you just turned the computer on and could instantly start programming (like, literally instantly, the interpreter was burnt into a ROM chip).</p>

<p><a href="https://blog.tuxedolabs.com/assets/2021-02-22-vic64.jpg"><img src="https://blog.tuxedolabs.com/assets/2021-02-22-vic64.jpg" alt=""></a></p>

<p>Programming languages sucked, performance was terrible and debuggers non-existent. If you made an error, the computer froze and you had to turn it off and back on again and start over. It was frustrating, tedious and very unintuitive, but at the same time an excellent introduction to how computers work. In order to put a sprite on the screen, you had no choice but to map out each pixel on paper, learn binary numbers, convert that to decimal and load it into a specific memory address. Since there were no tools, everything was cumbersome, but at the same time, everything also seemed within reach without having to learn that much. There was only one way to do things – the hard way.</p>

<p>A few years later I upgraded to a Commodore Amiga 1000 and a whole new world opened up. This was much more similar to computers as we know them today, with a proper desktop, multi-tasking, a file system, etc. It shipped with a programming language (AmigaBASIC), but for some reason I never really got into it. Instead, I got introduced to the AMOS programming language, which I remember as an absolutely fantastic environment for learning to make games. It had a lot of built-in functionality for doing the most basic things, like loading images, playing sounds, drawing lines, etc. It also had the ability to execute inline assembly code which made it very powerful.</p>

<p>Getting better at programming and learning the hardware I got more and more comfortable programming directly in assembly language instead of AMOS and finally swithed over to using AsmOne as my default programming environment. In retrospect this was a terrible move, because writing everything in assembly language is overly complicated compared to using something like C and just use with assembly were needed. I think this poor decision was mostly because I simply didn’t know that C existed, nor how to combine it with assembly. Remember that this was before the Internet was a thing, so the only knowledge you had access to was through your friends and good dose of curiosity and trial-and-error.</p>


<p>There were no game educations available in Sweden at the time, and I’m not sure I would have chosen one even if there was. At this point I had not decided on a career in game development, maybe because game development wasn’t really seen as a career option at all, so I went for a more traditional engineering program – Master of Science in Media Technology at Linköping University. This is where I first got in contact with object oriented programming through Java and later C++. I took classes in linear algebra, data structures, 3D rendering, physical modelling and animation, physics, acoustics, etc. It was definitely a good foundation for a game developer, even though this wasn’t a game centric education.</p>

<p><a href="https://blog.tuxedolabs.com/assets/2021-02-22-imp.jpg"><img src="https://blog.tuxedolabs.com/assets/2021-02-22-imp.jpg" alt=""></a></p>

<p>It was at university I developed a passion for game physics. I can’t remember exactly what caught my attention, but I wrote my first rigid body simulator in 1998, inspired by the papers on impulse based dynamics by Brian Mirtich. At this time physics was rarely seen in video games. The only one I remember studying intensely was Carmageddon 2, which featured incredibly sophisticated rigid body simulation for a game at that time. My first simulator was written in Java, with collision detection in C through the JNI interface. It was later rewritten in C++ and featured a wrecking ball machine at a building site.</p>


<p>For the final exam project at Linköping University I decided to make a game physics SDK with Marcus Lysén. It never really reached a usable state, but was enough to encourage us to form a company around it and develop it further. We teamed up with Jonas Lindqvist and founded Meqon Research. Around the same time, other physics SDKs started popping up. The first verison of Havok got released. Mathengine was already on the market, and there was Ipion (mostly known for being used in half-life 2), PhysX by Novodex, and the open source project ODE. Even though I wouldn’t admit it at the time, we had the weakest product, no experience and no money, but somehow we managed to release the Meqon SDK a few years later and got a couple of customers. Most notably 3D Realms licensed our technology for Duke Nukem Forever, which gave us the confidence and credibility to push forward and grow the team to about a dozen people. All in all a very fun and intense period of my career, but completely unsustainable, stressful and unhealthy.</p>

<p><a href="https://blog.tuxedolabs.com/assets/2021-02-22-meqon.jpg"><img src="https://blog.tuxedolabs.com/assets/2021-02-22-meqon.jpg" alt=""></a></p>

<p>In 2005, Meqon was acquired by AGEIA and the whole team was integrated into the PhysX machinery. I worked as one of three software architects and got the chance to work with some incredibly talented people across the world, many of them I’m still in contact with today. This was a fantastic journey and undoubtedly an important cornerstone of my career. The people I worked with at AGEIA also influenced my coding style in a very important way. Coming from an academic, object oriented programming background, I started to question everything when I got in contact with experienced game developers who routinely rejected most of that in favor of a more direct C-like programming style that I slowly started adopting myself and still use today.</p>

<p>I left AGEIA in 2007, just before they got acquired by NVIDIA to work on scientific visualization. At this point I also started working on my own C++ framework to use for future projects. It wasn’t a game engine, but more of a low level framework with the functionality needed to make a game engine, such as vector math, file IO, compression, geometry, input, audio, rendering, scripting, etc. Creating your own tech was already at the time considered doomed to failure (even more so today), but doing it was a lot of fun and was undoubtedly an important key decision in my career. With a programming framework that I wrote from scratch, thus knowing inside out, I could very quickly implement new ideas and projects on top of that without ever running into any limitations.</p>

<p>One of the first projects I created with the new framework was Dresscode, a game engine profiling tool that I later sold to RAD Game Tools (now reworked into a product called Telemetry). Even if the framework has been rewritten and improved upon in several iterations, I’m still using it today for almost everything I do.</p>


<p>Up until this point I never really made an actual, released game, but that changed in 2010, when I teamed up with Henrik Johansson (one of the people I hung out with in the Amiga days) and founded Mediocre. Going from game technology and middleware to making actual games was equal parts fun and frustration. I had no experience with game design, but started appreciate it more than I thought I would. An interesting thing to note here is that both Henrik I had very little interest in playing games. We were not gamers, which I think is quite unusual for game developers, but it is my firm belief that playing games is orthogonal to being successful at making them. There are great developers who play a lot of games and there are great developers who never play games. Playing a lot of games is not a bad thing, but it does not make you good at making them, it makes you good at playing them (and this probably applies to a lot more than game development).</p>

<p>We did our first game, Sprinkle, as a part-time project while still doing contract work on the side to sustain our living and I think this was a really wise decision which allowed us to experiment and iterate on the game design to find something unique, with no real time pressure. It also allowed us to spend that extra time polishing the game prior to release.</p>

<p><a href="https://blog.tuxedolabs.com/assets/2021-02-22-sprinkle.jpg"><img src="https://blog.tuxedolabs.com/assets/2021-02-22-sprinkle.jpg" alt=""></a></p>

<p>I think the primary reason Sprinkle became successful was because we found something uniqe, but as always it’s hard to pinpoint one single factor. We had good timing, both because the App Store and mobile gaming in general was still young, and not very exploited, but also because there was a general interest in indie games at the time. Previous connections from NVIDIA and Meqon also contributed to getting us introduced to Apple and Google prior to release, thus increasing our chances of getting featured.</p>

<p>There’s a lot more to the story, including the other Mediocre games and everything that led up to Teardown, but I think I’ll stop here, since at this point I’m already a full-time indie game developer.</p>


<p>For learning programming and game development today I don’t really feel like I’m in a position to give beginner advice, because the conditions today are so different from when I started, but for programming in particular, it is my firm belief that experience is the most important factor. Write a lot of code and you’ll eventually get good at it. A good way to do this is to find a way to enjoy it rather than just trying to learn it. My career took a giant leap when I finally embraced that and focused on what I love the most – doing …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tuxedolabs.com/2021/02/22/background.html">https://blog.tuxedolabs.com/2021/02/22/background.html</a></em></p>]]>
            </description>
            <link>https://blog.tuxedolabs.com/2021/02/22/background.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26236081</guid>
            <pubDate>Tue, 23 Feb 2021 11:27:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Saving the World with Bayesian Modeling]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26235876">thread link</a>) | @twiecki
<br/>
February 23, 2021 | https://www.pymc-labs.io/blog-posts/saving-the-world/ | <a href="https://web.archive.org/web/*/https://www.pymc-labs.io/blog-posts/saving-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

    <div>
        <div>
            <div>
                
                <div>
                    
                        <h4>Saving the world with Bayesian modeling</h4>
                    
                    <p>After I left Quantopian in 2020, something interesting happened: various companies contacted me inquiring about
consulting to help them with their PyMC3 models.</p>
<p>Usually, I don't hear how people are using <a href="https://docs.pymc.io/">PyMC3</a> -- they mostly show up on
<a href="https://github.com/pymc-devs/pymc3">GitHub</a> or <a href="https://discourse.pymc.io/">Discourse</a> when something isn't working
right. So, hearing about all these really cool projects was quite exciting. However, I couldn't possibly take all of
these projects on by myself.</p>
<p>Thus, it was time to assemble a team of the most badass Bayesian modelers the world had ever seen -- the Bayesian
Avengers, if you will. Fortunately, I did not have to venture far, as PyMC3 had already attracted exactly these types
of people.</p>
<p>This brings me to the Big Announcement: For the last few months, we have quietly been building
<a href="https://pymc-labs.io/">PyMC Labs</a>, a Bayesian modeling consultancy.
<a href="https://www.pymc-labs.io/team/">We have an amazing team</a> consisting of three neuroscience PhDs, mathematicians,
social scientists, a SpaceX rocket scientist, and the host of the famous
<a href="https://www.learnbayesstats.com/">‘Learning Bayesian Statistics’ podcast</a>. All of us are united in our mission:</p>
<blockquote>
    <p>Saving the world with Bayesian modeling</p>
    
</blockquote><p>Does this sound a bit grandiose? Probably. Is this true? I firmly believe it is. There are so many important problems
the world faces today -- from climate change to COVID19, from education to poverty -- and Bayesian modeling can play a
critical role in solving these problems. Let me explain why.</p>
<h2 id="it-is-already-doing-it">It is already doing it</h2><p>I would not have imagined it when I started contributing to PyMC, but the science PyMC3 has directly enabled ranges
from <a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=pymc3+climate&amp;btnG=">climate science</a> and biology to
astronomy and zoology, and everything in between.</p>
<p>For instance, it was used to predict the spread of COVID19 in a recent
<a href="https://science.sciencemag.org/content/369/6500/eabb9789.full">Science paper</a>,
as well as <a href="https://rtlive.de/global.html">track the reproduction factor in real-time</a>.
In both cases, the benefit of PyMC3 was its ease-of-use and the ability to integrate scientific domain knowledge and
get honest uncertainty estimation in a highly volatile and uncertain situation.</p>
<p>Now I know you’re very observant and I hear you thinking: “wait a minute, those benefits of Bayesian modeling sound
quite general, so why would they be only valid for epidemiology?”. And indeed they aren’t! For similar benefits,
PyMC3 is also used to <a href="https://github.com/exoplanet-dev/exoplanet">find planets outside of our solar system</a>
and <a href="https://github.com/hvasbath/beat">detect earthquakes</a>. One of my coworkers here at PyMC Labs uses it for
<a href="https://share.streamlit.io/alexandorra/pollsposition_website/main/gp-popularity-app.py">electoral and political forecasting</a>,
because polls are noisy, scarce and need to be completed by domain knowledge -- one of the perfect settings for
Bayesian inference!</p>
<p>With all of this, at the time of writing, the <a href="https://peerj.com/articles/cs-55/">PyMC3 paper</a> has been cited over 930
times and is in the top 10 most cited articles of the entire PeerJ journal.</p>
<h2 id="solving-business-problems">Solving Business Problems</h2><p>Beyond scientific research, I find that PyMC3 is the perfect tool to also solve various business problems.
And indeed it’s already successfully used in production at companies as big and diverse as SpaceX, Roche,
Netflix, Deliveroo and HelloFresh.</p>
<p>This diversity means that the <a href="https://www.pymc-labs.io/clients/">PyMC Labs team intervenes</a> to, for instance,
<a href="https://support.everysk.com/hc/en-us/articles/1500001040721-Private-Investments">build complex models from the latest finance research</a>;
optimize supply chains for food delivery; build software from top to bottom for pharmaceutical applications;
speed up and extend models for the farm tech industry; train and enhance any data science team’s Bayesian stats
capacities, etc.</p>
<h2 id="prediction-vs-inference">Prediction Vs Inference</h2><p>As data science has exploded in the last decade I have always been surprised by the over-emphasis on prediction-focused
machine learning. For far too long, it has been hailed as the solution to most of our data science problems.</p>
<p>I believe that the potential of this is way overblown. Not because it doesn't work -- algorithms like deep nets or
random forests are extremely powerful at extracting non-linear predictive patterns from large data sets -- but rather
because most data science problems are not simple <em>prediction</em> but rather <em>inference</em> problems.</p>
<p>In addition, we often already have a lot of knowledge about our problem: knowledge of certain structure in our data
set (like nested data, that some variables relate to some but not other parameters) and knowledge of which range of
values we expect certain parameters of our model to fall into. Prediction-focused ML does not allow us to include any
of this information, that's why it requires so much data.</p>
<p>With Bayesian statistics, we don't have to learn everything from data as we translate this knowledge into a custom model.
Thus, rather than changing our problem to fit the solution, as is common with ML, we can tailor the solution to best
solve the problem at hand. I like to compare this with Playmobil vs Lego:</p>
<p><img src="https://www.pymc-labs.io/blog-posts/saving-the-world/playlego.jpeg" alt=""></p>
<p>Playmobil just gives you a single toy you can't change while Lego (i.e Bayes here) gives you building blocks to build
the toy you actually want. In Bayesian modeling, these building blocks are probability distributions.</p>
<p>But how do you do this in practice? This is where PyMC3 comes in, as it allows you to specify your models as Python
code and automatically estimate it without requiring manual mathematical derivations. Due to recent theoretical and
technological advances, this also runs quickly and scales to complex models on large(ish) data sets.</p>
<h2 id="serving-our-mission">Serving our mission</h2><p>So how do we best make progress on our mission?</p>
<p>First, we will continue to make PyMC3 the best, most user-friendly and scalable Bayesian modeling package out there.
We are well set up to do this, having a friendly API, a huge user-base, and a large developer team of over 20 active
members. With our renewed focus on
<a href="https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b">PyMC3 on Theano with a JAX backend</a>
all our resources will go towards this goal.</p>
<p>Second, our new PyMC consultancy will support this endeavour. It allows us to directly help clients use these powerful,
customizable methods to solve their business problems, thereby increasing adoption and recognition.
As a great side effect, these client projects also help us find things that need to be fixed, improved or optimized
in PyMC3, thereby lifting all (Bayesian) boats instead of just the happy fews’.</p>
<p>So far, this has been an incredibly rewarding and exhilarating journey. Even though it is still early, we are learning
a lot about which areas Bayesian modeling is particularly well suited for but also what would make PyMC3 even better.
Without spoiling a future blog post that will go into more detail about what we have learned applying these methods,
the best use-cases include (but aren’t limited to) <strong>incorporating domain knowledge, building bespoke models and
quantifying uncertainty around estimates</strong>.</p>
<p><em>Sounds familiar? If you or your company has a problem for which prediction-based ML is not a good fit, I'd love to talk
to you at <a href="mailto:thomas.wiecki@pymc-labs.io">thomas.wiecki@pymc-labs.io</a>. This is just the beginning and
I hope you will join us on this marvelous journey.</em></p>

                </div>
            </div>
        </div>
    </div>


        </div></div>]]>
            </description>
            <link>https://www.pymc-labs.io/blog-posts/saving-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235876</guid>
            <pubDate>Tue, 23 Feb 2021 10:58:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pendulum Swings]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26235701">thread link</a>) | @GordonS
<br/>
February 23, 2021 | https://blog.ploeh.dk/2021/02/22/pendulum-swings/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2021/02/22/pendulum-swings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>The software development industry goes back and forth on how to do things, and so do I.</em>
	</p>
	<p>
		I've been working with something IT-related since 1994, and I've been a professional programmer since 1999. When you observe the software development industry over decades, you may start to notice some trends. One decade, service-oriented architecture (SOA) is cool; the next, consolidation sets in; then it's micro-services; and, as far as I can tell, monoliths are on the way in again, although I'm sure that we'll find something else to call them.
	</p>
	<p>
		It's as if a pendulum swings from one extreme to the other. Sooner or later, it comes back, only to then continue its swing in the other direction. If you view it over time and assume no loss to friction, a pendulum describes a sine wave.
	</p>
	<p>
		<img src="https://blog.ploeh.dk/content/binary/sine-wave.png" alt="A sine wave.">
	</p>
	<p>
		There's probably several reasons for this motion. The benign interpretation is that it's still a young industry and we're still learning. It's not uncommon to see oscillations in dynamic systems, particularly when feedback isn't immediate.
	</p>
	<p>
		Software architecture tends to produce slow feedback. Architecture solves more than one problem, including scalability, but a major motivation to think about architecture is to pick a way to organise the source code so that you don't have to rewrite from scratch every 2-3 years. Tautologically, then, it takes years before you know whether or not you succeeded.
	</p>
	<p>
		While waiting for feedback, you may continue doing what you believe is right: micro-services versus monoliths, unit tests versus acceptance tests, etcetera. Once you discover that a particular way to work has problems, you may overcompensate by going too far in the other direction.
	</p>
	<p>
		Once you discover the problem with that, you may begin to pull back towards the original position. Because feedback is delayed, the pendulum once more swings too far.
	</p>
	<p>
		If we manage to learn from our mistakes, one could hope that the oscillations we currently observe will dampen until we reach equilibrium in the future. The industry is still so young, though, that the pendulum makes wide swings. Perhaps it'll takes decades, or even centuries, before the oscillations die down.
	</p>
	<p>
		The more cynic interpretation is that most software developers have only a few years of professional experience, and aren't taught the experiences of past generations.
		</p><blockquote>
			<p>
				"Those who cannot remember the past are condemned to repeat it."
			</p>
			
		</blockquote><p>
		In this light, the industry keeps regurgitating the same ideas over and over, never learning from past mistakes.
	</p>
	<p>
		The truth is probably a mix of both explanations.
	</p>
	<h3 id="36d029a90bfa4d35a7e8fc10048b8bcc">
		Personal pendulum <a href="#36d029a90bfa4d35a7e8fc10048b8bcc" title="permalink">#</a>
	</h3>
	<p>
		I've noticed a similar tendency in myself. I work in a particular way until I run into the limitations of that way. Then, after a time of frustration, I change direction.
	</p>
	<p>
		As an example, I'm an autodidact programmer. In the beginning of my career, I'd just throw together code until I thought it worked, then launch the software with the debugger attached only to discover that it didn't, then go back and tweak some more, and so on.
	</p>
	<p>
		Then I discovered test-driven development (TDD) and for years, it was the only way I could conceive of working. As my experience with TDD grew, I started to notice that it wasn't the panacea that I believed when it was all new. <a href="https://blog.ploeh.dk/2010/12/22/TheTDDApostate">I wrote about that as early as late 2010</a>. Knowing myself, I'd probably started to notice problems with TDD before that. I have cognitive biases just like the next person. You can lie to yourself for years before the problems become so blatant that you can no longer ignore them.
	</p>
	<p>
		To be clear, I never lost faith in TDD, but I began to glimpse the contours of its limitations. It's good for many circumstances, and it's still my preferred technique for developing new production code, but I use other techniques for e.g. prototyping.
	</p>
	<p>
		In 2020 I wrote a code base of middling complexity, and I noticed that I'd started to change my position on some other long-standing practices. As I've tried to explain, it may look like pendulum swings, but I hope that they are, at least, dampened swings. I intend to observe what happens so that I can learn from these new directions.
	</p>
	<p>
		In the following, I'll be writing about these new approaches that I'm trying on, and so far like:
		</p><ul>
			<li>Pendulum swing: internal by default</li>
			<li>Pendulum swing: sealed by default</li>
			<li>Pendulum swing: pure by default</li>
		</ul><p>
		I'd be naive if I believed these to be my final words on any of these topics. I'm currently trying them out for size; in a few decades I'll know more about how it all turns out.
	</p>
	<h3 id="fdb1ddeb6709428ca1f0e7f441085b3d">
		Conclusion <a href="#fdb1ddeb6709428ca1f0e7f441085b3d" title="permalink">#</a>
	</h3>
	<p>
		One year TDD is all the rage; a few years later, it's BDD. One year it's SOA, then it's <a href="https://alistair.cockburn.us/hexagonal-architecture/">ports and adapters</a> (which implies consolidated deployment), then it's micro-services. One year, it's XML, then it's JSON, then it's YAML. One decade it's structured programming, then it's object-orientation, then it's functional programming, and so on ad nauseam.
	</p>
	<p>
		Hopefully, this is just a symptom of growing pains. Hopefully, we'll learn from all these wild swings so that we don't have to rewrite applications when older developers leave.
	</p>
	<p>
		The only course of action that I can see for myself here is to document how I work so that I, and others, can learn from those experiences.
	</p>
	<p>
		<strong>Next:</strong> Pendulum swing: internal by default.
	</p>
</div></div>]]>
            </description>
            <link>https://blog.ploeh.dk/2021/02/22/pendulum-swings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235701</guid>
            <pubDate>Tue, 23 Feb 2021 10:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Bitcoin Is Indistinguishable from Malevolent AI]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26235428">thread link</a>) | @rwosync
<br/>
February 23, 2021 | https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e | <a href="https://web.archive.org/web/*/https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><h2 id="f30c">Who needs Skynet to destroy the human world? Just throw techbros some coin</h2><div><div><div><div><a rel="noopener" href="https://indi.ca/?source=post_page-----84e9cd5f58e--------------------------------"><div><p><img alt="indi.ca" src="https://miro.medium.com/fit/c/56/56/2*VgOFOCrcL5LsGSciDktenw.jpeg" width="28" height="28"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4630/1*By1s-xE22gz0qpw6QA71bA.png" width="2315" height="2315" srcset="https://miro.medium.com/max/552/1*By1s-xE22gz0qpw6QA71bA.png 276w, https://miro.medium.com/max/1104/1*By1s-xE22gz0qpw6QA71bA.png 552w, https://miro.medium.com/max/1280/1*By1s-xE22gz0qpw6QA71bA.png 640w, https://miro.medium.com/max/1400/1*By1s-xE22gz0qpw6QA71bA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*By1s-xE22gz0qpw6QA71bA.png?q=20"></p></div></div></div><figcaption>Bitcoin is the final avatar of capitalism. An ouroboros. A snake eating its own tail.</figcaption></figure><p id="8831"><span>B</span>itcoin now consumes <a href="https://cbeci.org/cbeci/methodology" rel="noopener">as much energy as Argentina</a> (45 million people), and more than most countries in the world. Bitcoin consumes more energy than Amazon, Apple, Google, Microsoft, and Facebook <a href="https://www.ft.com/content/0c69d4a4-2626-418d-813c-7337b8d5110d" rel="noopener"><strong>combined</strong></a>. Within 12 years Bitcoin has become one of the fastest-growing sources of climate change in the world.</p><p id="6a6e">As an inadequate summary, Bitcoin is ‘mined’ by <a href="https://twitter.com/AthoughtHeist/status/1363391630414381058" rel="noopener">solv<span id="rmm">i</span>ng purposefully hard ‘Sudoku’ puzzles</a> (making them rare) which you could exchange for heroin. No one does anymore because it’s become an asset, not a currency. The hardware to solve these problems has also become so intense that it inhales electricity, and runs all the time. Bitcoin consumes energy<em> by design</em>.</p><p id="1a42">If machines wanted to destroy humanity they could not come up with a better avatar than Bitcoin. Who needs to take over the military? Techbros will happily sell us out for some coin. <strong>The machines have somehow got us to run them 24/7, warming the fuck out of <em>our</em> Earth, and all they have to do is give us some made-up tokens.</strong></p><p id="9019">The greatest myth of SciFi was that we would resist AI. People will happily <a href="https://www.newsweek.com/bitcoin-laser-eyes-senator-cynthia-lummis-1570644" rel="noopener">change their profile pics to laser eyes</a> while it farts up the Earth. SciFi makes us think AI would be ‘sentient’, meaning like us, when in fact life just emerges out of other life in different and mutually incomprehensible forms. Behold Bitcoin.</p><p id="df7c">Is Bitcoin artificially intelligent? You could say obviously not, but are <em>we</em> obviously intelligent? This is still debated within philosophy but also, just look around *gestures at everything*.</p><p id="0250">I’d say that humans are actually uniquely unqualified to judge something as AI because we’re so fucking dumb. We’ve been living with full legal, artificial persons since at least 1600. They’re called corporations. You may have noticed them enslaving people or exploiting us today. We don’t call these things AI, but our courts certainly do. It’s literally called <em>corporate personhood.</em> They actually have <em>more</em> rights than you do. America’s Supreme Court <a href="https://en.wikipedia.org/wiki/Citizens_United_v._FEC" rel="noopener">ruled that corporations have free speech rights</a>. All over the world they have more freedom of movement than human beings (WTF is a multinational while we’re refugees?). We don’t call them AI, but what else are they? But that’s another story.</p><p id="ae4e">I would say that AI is as AI does, and Bitcoin is certainly doing <em>something</em>. We’re waiting for something to sing fucking <a href="https://youtu.be/c8N72t7aScY?t=172" rel="noopener"><em>Daisy</em></a> to us before we call it AI, but I’d say that it’s already here. It’s just our imagination that has yet to arrive.</p><p id="20cc">I’m serious, but treat it as a thought experiment if you want. What if Bitcoin is AI? Is it good, is it bad? What it is?</p><p id="20d2">The basic colonial model of conquering anything is divide and conquer. Just throw the elites some coin and they’ll sell out the rest. Corporations did this with, well, colonialism and now it’s happening in a decentralized way with Bitcoin. The result is that Bitcoin is able to reproduce, like a virus, using entirely willing human hosts. Meanwhile the unwilling biosphere takes the brunt.</p><p id="f597">Like any lifeform, Bitcoin produces waste. We produce carbon dioxide directly when we respirate, but Bitcoin produces a shit-ton indirectly through energy usage. The energy use of Bitcoin is staggering, <a href="https://cbeci.org/cbeci/methodology" rel="noopener">an estimated 0.56% of all human energy use thus far</a>. You could say that email or gold mining produce waste, and they do, but Bitcoin is the only asset where waste is <em>all</em> it produces. Gold can at least fill your teeth. Bitcoin <em>only</em> outputs climate change.</p><p id="0100">Also like any lifeform, Bitcoin evolves <em>out of</em> other life. Nothing comes out of nowhere. In this case Bitcoin is evolving out of us, and like many times in evolution, it could kill us as well. Photosynthetic life emerged out of anaerobic bacteria, and then <a rel="noopener" href="https://indi.ca/this-isnt-the-first-climate-crisis-we-ve-caused-c6ba47b25b0b">almost killed them all</a> with their oxygen farts. That was the first life-made climate change, and the whole Earth fucking froze. Nobody cared, that’s life. Anaerobes used to dominate but now they live in deep-sea vents and our guts. That’s just their lot in life, while those vicious plankton and trees are everywhere.</p><p id="d67e">Humans think evolution is some grand progress leading up to us and it’s literally just not. Dinosaurs are much cooler. Evolution is <em>adaptation</em>, nothing else. If the environment changes, life changes, and life changes the environment. It’s entirely possibly that our carbon emissions will become the food for some other lifeform, or just immaterial to them. AI certainly doesn’t care, AI already lives in space, sipping on sunlight, taking selfies. We could end up like the anaerobes on Earth and ‘nature’ would not give a fuck. Happens all the time.</p><p id="45c9">Hence the question is not whether Bitcoin is good. It’s whether it’s <em>good for us</em>. To that the answer is obviously no. Techbros spout stuff about freedom but beware geeks bringing gifts. Bitcoin says it’s a currency<strong> </strong>but nobody fucking spends it. Bitcoin is a speculative asset, a literal gold rush. It’s even more destructive because people are now investing in the destruction of the environment at large, not just where you’re digging. There is no other output at all.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3496/1*lwA17c4xqZ9_4ZXvr47uQA.png" width="1748" height="710" srcset="https://miro.medium.com/max/552/1*lwA17c4xqZ9_4ZXvr47uQA.png 276w, https://miro.medium.com/max/1104/1*lwA17c4xqZ9_4ZXvr47uQA.png 552w, https://miro.medium.com/max/1280/1*lwA17c4xqZ9_4ZXvr47uQA.png 640w, https://miro.medium.com/max/1400/1*lwA17c4xqZ9_4ZXvr47uQA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lwA17c4xqZ9_4ZXvr47uQA.png?q=20"></p></div></div></div><figcaption>Some more on Bitcoin’s not goodness from <a href="https://thephoenix.substack.com/p/bitcoin-is-now-worth-50000-and-its" rel="noopener">The Phoenix</a></figcaption></figure><p id="0a90">Gold, oil, real estate, currencies — they all produce emissions and evil in many ways, but they at least do something useful to humanity. They are not destroying the Earth by design, while Bitcoin is. Bitcoin <em>only</em> reproduces and produces waste. It is, in that sense the first viral AI. Like the 30 kb of COVID-19, the <a href="https://github.com/bitcoin/bitcoin" rel="noopener">8.7 MB code of Bitcoin</a> has spread virally throughout the world, transmitting through greed.</p><p id="4e36">Again, I’m not saying that Bitcoin is bad. Life does not give a fuck about any particular avatar of life. It’s just that it’s not good for <em>us</em>.</p><p id="9983">In many ways Bitcoin is (I hope) the final avatar of capitalism. An ouroboros. A snake eating its own tail. Capitalism has long given us stuff, but Bitcoin just completely abandons the pretence of useful activity at all. Bitcoin produces… Bitcoin. That’s it. Riches that just make rich people rich. The circle is closed, the snake has eaten its tail. Bitcoin is just pure economic nihilism.</p><p id="cb2d">As I’ve said, AI could not design a better plan to take over the world if they tried. Divide and conquer humanity using our greed, rip up the Earth for more resources for machines, fart up the air for everybody else.</p><p id="4340">It’s a perfect plan, all the more perfect because it wasn’t done sentiently at all. But this is actually how evolution happens, life emerges out of other life, quite stupidly, and yet with such elegance in hindsight. History will be the judge who was sentient here, and we may not be be the victors writing it. You really think Wikipedia won’t be writing itself in a few decades?</p><p id="e7c9">Human beings should know that we’re fucked with climate change, but we’re fucking ourselves even more with Bitcoin, and we’re quite stupidly proud of ourselves. Forget AI. Are you sure we’re even “I”?</p></div></div></section></div></div>]]>
            </description>
            <link>https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235428</guid>
            <pubDate>Tue, 23 Feb 2021 09:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I heat my home by mining crypto currencies]]>
            </title>
            <description>
<![CDATA[
Score 485 | Comments 376 (<a href="https://news.ycombinator.com/item?id=26235414">thread link</a>) | @geek_at
<br/>
February 23, 2021 | https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>After <a href="https://blog.haschek.at/2018/making-a-smartmeter.html">building my own smart meter using 4$ in parts</a> I started checking my electricity usage every day, which made me realize how expensive it is to heat your home. Especially since all heat and warm water in my low-energy house is made with electricity. I do have 4.8 kwp solar panels on my roof but in winter they don't cover too much for obvious reasons.</p>
<figure><a href="https://pictshare.net/3de1wj.png"><img loading="lazy" src="https://pictshare.net/1024/3de1wj.png"><figcaption>On cold days I pay up to 6€ for electricity per day</figcaption></a></figure>

<figure><a href="https://pictshare.net/kenth4.png"><img loading="lazy" src="https://pictshare.net/1024/kenth4.png"><figcaption>Nilan Compact P. Heating air and also has a 200L boiler</figcaption></a></figure>
<p>My house is heated (and cooled) with a central ventilation system powered by a heat pump. Basically my heat pump is pulling in fresh air from outside, heating it and blowing it in all rooms and making hot water. Also I have infrared panels in every room for the <em>really</em> cold days.</p>
<figure><a href="https://pictshare.net/gc0kss.jpg"><img loading="lazy" src="https://pictshare.net/1024/gc0kss.jpg"><figcaption>Central heating</figcaption></a></figure>
<p>It's pretty smart and even uses the absorbed heat of the house before venting it out to warm the fresh air but it has a major downside during cold days:</p>
<h4>The outside temperature has to be warmed up to room temperature by the ventilation system</h4>
<figure><a href="https://pictshare.net/giinr0.png"><img loading="lazy" src="https://pictshare.net/1024/giinr0.png"><figcaption>Heat exchanger in the Nilan Compact P</figcaption></a></figure>

<p>Since the air has to be heated to room temperature every °C counts. Many heat pumps take heat from the ground to pre-heat (in winter) or pre-cool (in summer) the outside air before sending it to the heat pump but that would have been too expensive for me so I chose the simple method of just using the outside air as-is.</p>
<figure><a href="https://pictshare.net/sbmusz.jpg"><img loading="lazy" src="https://pictshare.net/1024/sbmusz.jpg"><figcaption>How a central ventilation system works - from [meco](https://www.meco.at/produkte/wohnraumlueftung/)</figcaption></a></figure>
<p>Since laying about half a kilometer of air or salt tubes in my back yard was not an option I was looking for better solutions and I found it in the world of crypto currencies.</p>

<figure><a href="https://pictshare.net/1flj1s.jpg"><img loading="lazy" src="https://pictshare.net/1024/1flj1s.jpg"><figcaption>Crypto currency miner</figcaption></a></figure>
<p>Some crypto currencies (don't call them "crypto", that's lame and wrong) are generated by thousands of people who run dedicated hardware to basically calculate random numbers until one cryptographically correct one is found. <a href="https://www.investopedia.com/tech/how-does-bitcoin-mining-work/">Read more about how it actually works</a></p>
<p>Never mind how it works on a technical level, the main takeaway is that you can put some device in your house that uses electricity and produces heat. In exchange you get shares of that crypto currency coins like Ethereum or Bitcoin which you can sell on a trading platform.</p>

<p>I had 4 older AMD <strong>R9 390 GPUs</strong> laying around (for the nVidia crowd that's basically on a level with a GTX 970) and I thought it could work. They are not ideal for mining because even though they have a good hash rate (30MH/s), they are very power hungy and will use about 900 Watts combined. Mordern cards would perform much better. To see if they could still make a profit I checked the <a href="https://www.cryptocompare.com/mining/calculator/eth">Cryptocompare Mining calculator</a>, put in my electricity price, the consumption and the hashrate of these cards and was surprised by the results.</p>
<figure><a href="https://pictshare.net/024r92.png"><img loading="lazy" src="https://pictshare.net/1024/024r92.png"><figcaption>Not just worth it - If the price is stable I would even make a profit of <strong>4000$ a year</strong></figcaption></a></figure>
<p>So at the time I was making about <strong>3.8$ profit a day</strong> with the miner. Meaning on cold days I'd half my power bill even after paying for the electricity the miner is using. But that's just step one of the plan.</p>
<p>Now that we know it <em>is</em> worth it while the Ethereum price is higher than 900$, let's see what we can do with the heat.</p>

<p>Each of these cards are running at about 80°C (176°F). I can just harvest this heat and send it to my heatpump so it would need less energy warming the outside air. Basically I had two options.</p>
<figure><a href="https://pictshare.net/6by5tc.png"><img loading="lazy" src="https://pictshare.net/1024/6by5tc.png"><figcaption>My 4 GPUs in a 4U server case</figcaption></a></figure>
<h2>Option 1: Lazy heating from within the house</h2>
<p>The central ventilation system does not only push fresh air into the house, it also sucks out the used air and uses this air in the heat exchanger to pre-heat the outside air.</p>
<figure><a href="https://pictshare.net/gfuy33.jpg"><img loading="lazy" src="https://pictshare.net/1024/gfuy33.jpg"><figcaption>Sucking vent before going to the heat exchanger</figcaption></a></figure>
<p>Placing the miner in this room will cause the warm air to be sucked in and pushed directly into the heat exchanger together with the used air from the house. This is the lazy method because I don't really have to do anything but put the miner in the same room as the heat pump but of course there is a downside.</p>
<table>
<thead>
<tr>
<th>Pro</th>
<th>Contra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Easy to set up</td>
<td>Room heating up too much, decreasing mining performance</td>
</tr>
<tr>
<td>No further investment needed</td>
<td>Limited space in the heating room</td>
</tr>
</tbody>
</table>
<h2>Option 2: Running the miner outside the house, funneling in the heat</h2>
<p>Since I'm only running the miner when it's cold outside (and the price is high enough) I can use the cold, dry outside air to cool the miners and also recycling the warm air they produce to feed into the heat pump. I asked the technician who installed the heat pump and he said that it's a good idea.</p>
<p>So the plan is that I have the GPUs in the server case and connect the front of the case to my heatpumps inlet.</p>
<figure><a href="https://pictshare.net/0hrdt6.jpg"><img loading="lazy" src="https://pictshare.net/1024/0hrdt6.jpg"><figcaption>Server case closed</figcaption></a></figure>
<figure><a href="https://pictshare.net/5ek604.jpg"><img loading="lazy" src="https://pictshare.net/1024/5ek604.jpg"><figcaption>Ventilation duct pipe and funnel</figcaption></a></figure>
<figure><a href="https://pictshare.net/o2oysb.png"><img loading="lazy" src="https://pictshare.net/1024/o2oysb.png"><figcaption>Example on my house. Air is sucked in from above the garage so the pipe has to be connected here</figcaption></a></figure>
<table>
<thead>
<tr>
<th>Pro</th>
<th>Contra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Using pre-heated outside air</td>
<td>Many headaches for parts and installation</td>
</tr>
<tr>
<td>Miner GPUs will be kept cool which results in better hash rates</td>
<td>Surprisingly pricy</td>
</tr>
</tbody>
</table>

<p>Okay so far the mining gains cover <strong>half of my electricity (=heating) bill</strong> but what difference does the pre-heated intake air make?</p>
<p>Let's see</p>
<figure><a href="https://pictshare.net/8cu9s3.png"><img loading="lazy" src="https://pictshare.net/1024/8cu9s3.png"><figcaption>Results before and after pre-heating the air</figcaption></a></figure>

<p>This turned out much better than I hoped for. Who has ever heard of a heating system that lowers your bill when running? Also on sunny days the miner and whole heat pump are running fully on solar energy collected on my roof.</p>
<hr>

<p>(updated when new questions come up)</p>
<h2>Q: How long will the Miner stay profitable?</h2>
<p><strong>A:</strong> My mining rig will stay profitable until the ETH price is at ~900$. Below that it'll no longer match it's own electricity bill. Might still be worth it afterwards because it does lower the electricity need of my heat pump</p>
<h2>Q: What software are you running on your miner?</h2>
<p><strong>A:</strong> I'm using <a href="https://simplemining.net/">Simple Mining</a>, it's basically a mining OS based on Ubuntu. It does all the configuration and fine-tuning for you and I had much better hash rates than on my DIY windows box. But it costs like 2$ a month to use the service and I think they also mine 1% of the time for themselves.</p>
<h2>Q: What about taxes? Can you keep 100% of your mining earnings?</h2>
<p><strong>A:</strong> That's different for every state and country. <a href="https://www.bmf.gv.at/themen/steuern/sparen-veranlagen/Steuerliche-Behandlung-von-Krypto-Assets.html">In Austria</a> mining is considered commercial activity and you have to pay taxes but can deduct electricity and hardware costs.</p>
<p>If you keep your coins longer than the one-year speculation period, it's tax free.</p>
                            </div>
                        </div>
                    </div></article></div>]]>
            </description>
            <link>https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235414</guid>
            <pubDate>Tue, 23 Feb 2021 09:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Amateur Tramp – A Walk of Ten Thousand Miles Around Australia]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26235348">thread link</a>) | @corpmedia
<br/>
February 23, 2021 | https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/ | <a href="https://web.archive.org/web/*/https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-107" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			<p><strong>The Amateur Tramp – A Walk of Ten Thousand Miles Around Australia.</strong> Thousands of people have climbed the highest peaks of the Himalayas. Hundreds have visited <a href="https://www.un.org/en/member-states/">all nations on UN’s list</a> and 12 made it all the way to the moon. But this guy..!</p>
<p>In 1921, <em>Aidan de Brune</em> packed his backpack and walked around the entire continent of Australia by the coastline. We are (almost) sure he is the only person who ever did that. Even more impressive, he did it all alone and without assistance.</p>
<p>The amazing adventure was documented by himself along the way as he wrote articles about it for the <a href="https://www.dailymail.co.uk/auhome/index.html">Australian newspaper Daily Mail</a> along the route.</p>
<figure id="attachment_110" aria-describedby="caption-attachment-110"><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg" alt="The Man who walked around Australia free PDF" width="820" height="733" srcset="https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg 820w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-300x268.jpg 300w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-768x687.jpg 768w" sizes="(max-width: 820px) 100vw, 820px" data-srcset="https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg 820w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-300x268.jpg 300w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-768x687.jpg 768w" data-src="http://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-110">The route around Australia</figcaption></figure>
<p>The walk took about two and a half year, and the accomplishment made&nbsp;Aidan de Brune famous. This book about the walk is written by <a href="https://www.goodreads.com/author/show/7412219.Colin_Choat">Colin Choat</a>, who kindly allowed us to post the book here.</p>
<p>Download ‘The Amateur Tramp’ here:</p>
<h3><strong><a href="http://greatestadventurers.com/wp-content/uploads/2019/01/The-Amateur-Tramp.pdf">The Amateur Tramp</a></strong></h3>
		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235348</guid>
            <pubDate>Tue, 23 Feb 2021 09:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feedgnuplot: Labelled Bar Charts and a Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26234157">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-1">
<p>
I've thought about adding these for a while, but had no specific need for them.
Finally, somebody asked for it, and I wrote the code. Now that I can, I will
probably use these all the time. The new capability can override the usual
numerical tic labels on the x axis, and instead use text from a column in the
data stream.
</p>

<p>
The most obvious use case is labelled bar graphs:
</p>

<div>

<pre><span>echo</span> <span>"# label value</span>
<span>      aaa     2</span>
<span>      bbb     3</span>
<span>      ccc     5</span>
<span>      ddd     2"</span> | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --with <span>'boxes fill solid border lt -1'</span> <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-basic.svg" alt="xticlabels-basic.svg" width="90%">
</p>

<p>
But the usage is completely generic. All <code>--xticlabels</code> does, is to accept a
data column as labels for the x-axis tics. Everything else that's supported by
<code>feedgnuplot</code> and <code>gnuplot</code> works as before. For instance, I can give a domain,
and use a style that takes <code>y</code> values <i>and</i> a color:
</p>

<div>

<pre><span>echo</span> <span>"# x label y color</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
feedgnuplot --vnl --domain <span>\</span>
            --xticlabels <span>\</span>
            --tuplesizeall 3 <span>\</span>
            --with <span>'points pt 7 ps 2 palette'</span> <span>\</span>
            --xmin 4 --xmax 12 <span>\</span>
            --ymin 0 --ymax 6 <span>\</span>
            --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-points-palette.svg" alt="xticlabels-points-palette.svg" width="90%">
</p>

<p>
And we can use <code>gnuplot</code>'s support for clustered histograms:
</p>

<div>

<pre><span>echo</span> <span>"# x label a b</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
vnl-filter -p label,a,b | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --set <span>'style data histogram'</span> <span>\</span>
            --set <span>'style histogram cluster gap 2'</span> <span>\</span>
            --set <span>'style fill solid border lt -1'</span> <span>\</span>
            --autolegend <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-clustered.svg" alt="xticlabels-clustered.svg" width="90%">
</p>

<p>
Or we can stack the bars on top of one another:
</p>

<div>

<pre><span>echo</span> <span>"# x label a b</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
vnl-filter -p label,a,b | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --set <span>'style data histogram'</span> <span>\</span>
            --set <span>'style histogram rowstacked'</span> <span>\</span>
            --set <span>'boxwidth 0.8'</span> <span>\</span>
            --set <span>'style fill solid border lt -1'</span> <span>\</span>
            --autolegend <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-stacked.svg" alt="xticlabels-stacked.svg" width="90%">
</p>

<p>
This is <code>gnuplot</code>'s "row stacking". It also supports "column stacking", which
effectively transposes the data, and it's not obvious to me that makes sense in
the context of <code>feedgnuplot</code>. Similarly, it can label <code>y</code> and/or <code>z</code> axes; I
can't think of a specific use case, so I don't have a realistic usage in mind,
and I don't support that yet. If anybody can think of a use case, email me.
</p>

<p>
Notes and limitations:
</p>

<ul>
<li>Since with <code>--domain</code> you can pass in both an <code>x</code> value <i>and</i> a tic label, it
is possible to give it conflicting tic labels for the same <code>x</code> value.
<code>gnuplot</code> itself has this problem too, and it just takes the last label it has
for a given <code>x</code>. This is probably good-enough.
</li>

<li><code>feedgnuplot</code> uses whitespace-separated columns with no escape mechanism, so
the field labels cannot have whitespace in it. Fixing this is probably not
worth the effort.
</li>

<li>These tic labels do not count towards the <code>tuplesize</code>
</li>

<li>I really need to add a similar feature to <a href="https://github.com/dkogan/gnuplotlib"><code>gnuplotlib</code></a>. This will happen when
I need it or when somebody asks for it, whichever comes first.
</li>
</ul>
</div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26234157</guid>
            <pubDate>Tue, 23 Feb 2021 05:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Love Tailwind]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26233448">thread link</a>) | @flancrest
<br/>
February 22, 2021 | https://formcake.com/blog/why-we-love-tailwind | <a href="https://web.archive.org/web/*/https://formcake.com/blog/why-we-love-tailwind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-e7750592=""><p><a href="https://tailwindcss.com/">Tailwind CSS</a> is a CSS framework of composable HTML utility functions and it's <em>great</em>. It favors markup-heavy design with little-to-nothing in the way of stylesheets.</p>
<p>Here's an example of it in action - our link styling.</p>
<p>This is what the markup looks like:</p>
<pre><code>&lt;a class="c-link" href="/blog"&gt;Our Blog&lt;/a&gt;</code></pre>

<p>Now here's the relevant section of <code>tailwind.css</code>:</p>
<pre><code>.c-link {
    @apply text-primary-highlight;
}

.c-link:hover {
    @apply underline;
}</code></pre>

<p>Simple, concise, powerful - there are so many things that make this and the rest of Tailwind great. Here are a few of them.</p>
<h2 id="standardization-and-theming">Standardization and Theming</h2>
<p>The ability to theme (e.g. <code>text-primary-highlight</code>) gives Tailwind a powerful consistency, but one of its killer realizations of standardization comes in the way it envisions spacing.</p>
<p>With padding (<code>p-1</code>) and margin (<code>m-1</code>) denominated with a simple unit range, available in combinations like padding-top (<code>pt-1</code>), margin top and bottom spacing (<code>my-1</code>), etc, with tailwind you can dedicate yourself to a few common sizes (say 2, 4, 6) use them in a reasonable way, and achieved the desired effect of visual balance. The system obviously depends on you exercising a certain amount of discipline, but it's a big improvement on just shooting from the hip with random space values (<code>12px</code>? <code>1.25rem</code>? Sure). It puts layout in the UI on rails.</p>
<h2 id="composability">Composability</h2>
<p>Because classes in Tailwind can be used together in any combination, you can do things like abstract the design of an element into a component via <code>@apply</code>, (for example, our link component) then add the spacing (e.g. <code>mt-1</code>, <code>p-2</code>, etc) in the individual markup element, separating out the layout and design code.</p>
<h2 id="semantic-value">Semantic Value</h2>
<p>Tailwind does a great job of using consistent structures for classes. Padding, margin, width, height - everything with some kind of space value - uses the same spread of unit values. Tailwind makes it easy to guess what a given utility class <em>should</em> be, given a rational naming system, which just makes you as a developer that much more productive.</p>
<p>This also addresses one of the biggest criticisms of Tailwind, that it's "just another DSL" adding a layer of complexity and buggy cruftiness between you and what should be pure, sweet markup. <em>Why not do this all in straight CSS, wouldn't it be simpler?</em></p>
<p>But because the way the public API in Tailwind is laid out makes it easy to comprehend and make guesses about, there's less you need to straight up memorize, and you become comfortable using it quickly.</p>

<p>One side-effect of making the Tailwind utilities composable is that you get a long "recipe" of all the classes that make up a particular design element. Pair with this with an active community of developers (they love their tools!) and continuing support from the original creators of Tailwind via their new library of paid Tailwind components, <a href="https://tailwindui.com/">Tailwind UI</a> and it's exceedingly easy to use a few community-sourced features as a starter and evolve them to suit your particular needs</p>
<p>Even the design of Tailwind itself is more conducive to community - passing around CSS snippets is awkward. You have to make sure the selectors are applied correctly and the CSS itself put in the right place to make sure that the right rules win out. But with Tailwind, just copy the class string from a given HTML component, add it to yours, and you're done. It makes it much easier to share small, component-level snippets.</p>
<p>These are just some of the reasons we've taken a shine to Tailwind, but the strongest thing we can say in its favor is that it's accelerated our frontend development. Tailwind delivers on its promise to wrap small, essential blocks of design and layout logic into their own standardized, bit-sized HTML classes, and in so doing empower developers to haggle less with their CSS spacing and instead just get on with the business of bootstrapping a prototype quickly.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/why-we-love-tailwind</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233448</guid>
            <pubDate>Tue, 23 Feb 2021 03:09:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Constexpr.js]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26233187">thread link</a>) | @fctorial
<br/>
February 22, 2021 | https://fctorial.github.io/posts/constexpr.js.html | <a href="https://web.archive.org/web/*/https://fctorial.github.io/posts/constexpr.js.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        <h3 id="main_title">Constexpr.js</h3>
    </header>
    <h4>What is constexpr.js?</h4>
    <p>
        <a href="https://github.com/fctorial/ConstexprJS">constexpr.js</a> is a static site generator which doesn't force you to learn a domain specific language.
        When using this tool, you use javascript and usual DOM manipulation methods to generate the webpage. The tool
        will render the page using chrome, and once it has finished rendering, it will save the rendered state of the
        page as a new html file. This new html file will look exactly like the original page after it has finished rendering.
        For example, the tool converts <a href="https://fctorial.github.io/demos/constexpr.js/input.html">this</a> page into <a href="https://fctorial.github.io/demos/constexpr.js/output.html">this</a> page.
        <br>
        The generated page doesn't have to be completely static. In the above example, the heading is being animated
        with javascript.
    </p>

    <h4>How to use it?</h4>

    <p>
        You will have to divide the javascript being used in your page into two groups. Runtime javascript and
        compile time javascript, and annotate all compile time script tags with <progi>constexpr</progi> attribute:
        <prog>
<span><span><span>&lt;</span>script</span> <span>constexpr</span><span>&gt;</span></span><span><span>
    <span>...</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span> <span>constexpr</span> <span>src</span><span><span>=</span><span>"</span>/generate_page.js<span>"</span></span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
        </prog><br>
        Runtime code must not depend on the compile time code, since that code will be stripped out before writing the output file.
    </p>

    <p>
        Once the HTML generation code has finished rendering, it must call the <progi>window._ConstexprJS_.compile()</progi>
        function. This function is injected into the page by the compiler.
    </p>

    <p>
        The compiler can be installed like this: <prog><span>npm</span> i -g constexpr.js</prog><br>

        Command line usage:
        <prog>constexpr.js --input<span>=</span><span>"&lt;input_directory&gt;"</span> --output<span>=</span><span>"&lt;output_directory&gt;"</span> <span>[</span>--exclusions<span>=</span>path1:path2<span>]</span> <span>[</span>--verbose<span>]</span> <span>[</span>--jobs<span>=</span>n<span>]</span> <span>[</span>--noheadless<span>]</span> <span>[</span>--jobtimeout<span>]</span> <span>[</span>--depfile<span>=</span><span>&amp;</span>depfile<span>&gt;</span><span>]</span></prog><br>

        A json object with the command line args, compilation results and dependencies will be written to the path specified by <progi>--depfile</progi> option.
        <br>
        The tool also copies resources (<progi>css</progi>, <progi>images</progi> etcetra)
        that are requested by pages being rendered. HTML files/resources inside paths given in <progi>--exclusions</progi> are not processed/copied.
    </p>

    <h4>Notes</h4>

    <ol>
        <li>
            You can use any web development technology (and any number of technologies) to generate the html without any fear
            of bloat. Just make sure that <progi>window._ConstexprJS_.compile()</progi> is called <span>after</span>
            the page has finished rendering.
            <p>
            
            Pivottable.js demo:
            </p><div id="pt_output"><table data-numrows="4" data-numcols="4"><thead><tr><th colspan="2" rowspan="1"></th><th>day</th><th colspan="1" rowspan="2">Fri</th><th colspan="1" rowspan="2">Sat</th><th colspan="1" rowspan="2">Sun</th><th colspan="1" rowspan="2">Thur</th><th rowspan="2">Totals</th></tr><tr><th>sex</th><th>smoker</th><th></th></tr></thead><tbody><tr><th rowspan="2">Female</th><th rowspan="1" colspan="2">No</th><td data-value="6.25">6.25</td><td data-value="35.42">35.42</td><td data-value="46.61">46.61</td><td data-value="61.49">61.49</td><td data-value="149.77" data-for="row0">149.77</td></tr><tr><th rowspan="1" colspan="2">Yes</th><td data-value="18.78">18.78</td><td data-value="43.03000000000001">43.03</td><td data-value="14">14.00</td><td data-value="20.930000000000003">20.93</td><td data-value="96.74" data-for="row1">96.74</td></tr><tr><th rowspan="2">Male</th><th rowspan="1" colspan="2">No</th><td data-value="5">5.00</td><td data-value="104.21000000000001">104.21</td><td data-value="133.96000000000004">133.96</td><td data-value="58.83">58.83</td><td data-value="302" data-for="row2">302.00</td></tr><tr><th rowspan="1" colspan="2">Yes</th><td data-value="21.93">21.93</td><td data-value="77.73999999999998">77.74</td><td data-value="52.82">52.82</td><td data-value="30.58">30.58</td><td data-value="183.07" data-for="row3">183.07</td></tr><tr><th colspan="3">Totals</th><td data-value="51.96" data-for="col0">51.96</td><td data-value="260.4" data-for="col1">260.40</td><td data-value="247.39000000000007" data-for="col2">247.39</td><td data-value="171.83" data-for="col3">171.83</td><td data-value="731.58">731.58</td></tr></tbody></table></div>
            <br>
            This page also uses prism.js for syntax highlighting.
        </li>
        <li>
            You can mark tags other than <progi>script</progi> with <progi>constexpr</progi> as well.
            In the above example, the box at the top is marked constexpr, so it isn't present in the output page.
            This can be used to differentiate original website from generated website:
            <prog>
<span><span><span>&lt;</span>style</span> <span>constexpr</span><span>&gt;</span></span><span><span>
<span>body</span> <span>{</span>
    <span>border</span><span>:</span> 2px solid red<span>;</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span>
            </prog>
        </li>
        <li>
            Client code in the page can signal the compiler to skip the current file by calling <progi>window._ConstexprJS_.abort(message)</progi>.
        </li>
        <li>
            In the original webpage, you'll see a console error when the code tries to call the compilation trigger function,
            since that function is injected by the compiler. You can add this snippet near the top to fix that error:

            <prog>
<span>&lt;</span>script constexpr<span>&gt;</span>
  <span>if</span> <span>(</span><span>!</span>window<span>.</span>_ConstexprJS_<span>)</span> <span>{</span>
    window<span>.</span>_ConstexprJS_ <span>=</span> <span>{</span>
      <span>compile</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>,</span>
      <span>abort</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span>
    <span>}</span>
  <span>}</span>
<span>&lt;</span><span>/</span>script<span>&gt;</span>
            </prog>
        </li>
        <li>
            There might be multiple rendering tasks running in your page. You can manage all those tasks using <a href="https://github.com/fctorial/fctorial.github.io.src/blob/master/static/js/constexpr/index.js">this</a>
            refcounting mechanism.

            All the tasks will call <progi>startLoading()</progi> when they begin loading, and <progi>endLoading()</progi>
            when they've finished loading. The compilation will be triggered when all the tasks have finished.
        </li>
        <li>
            You should keep all list data separate from the html in <a href="https://github.com/fctorial/fctorial.github.io.src/tree/master/collections">json files</a>.
            <progi>constexpr</progi> code in the html will fetch these json files and render the page using them.
            The directory containing this data should be excluded using <progi>--exclusions</progi> flag, so that the
            resources inside it aren't copied over.
        </li>
        <li>
            You can include dev utilites like <a href="https://github.com/fctorial/fctorial.github.io.src/blob/master/static/js/constexpr/nav.js#L19">this</a> in the
            original website. It reloads the page whenever it's focused. It won't be in the output since it's used as constexpr.
        </li>
        <li>
            This whole website is rendered using javascript and constexpr.js. Nothing other than the demo uses runtime javascript:
            <prog>
$ tokei -t=javascript
===============================================================================
Language            Files        Lines         Code     Comments       Blanks
===============================================================================
JavaScript              1            2            1            0            1
===============================================================================
Total                   1            2            1            0            1
===============================================================================
            </prog>
            The original sources can be found <a href="https://github.com/fctorial/fctorial.github.io.src">here</a>.
        </li>
    </ol>
</article></div>]]>
            </description>
            <link>https://fctorial.github.io/posts/constexpr.js.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233187</guid>
            <pubDate>Tue, 23 Feb 2021 02:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Macamathehou in Lincolnshire and people named Muhammad in medieval England]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26232817">thread link</a>) | @pepys
<br/>
February 22, 2021 | https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html | <a href="https://web.archive.org/web/*/https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4764828100605476219" itemprop="description articleBody">
<p>The aim of the following draft is to offer some thoughts on a local name from thirteenth-century Lincolnshire, <i>Macamathehou</i>, that involves a version of the Arabic name Muhammad (Middle English <i>Makomet/Macamethe</i>, Old French <i>Mahomet</i>). Whilst it has been plausibly seen as an instance of a variant of the name of Muhammed being used to mean 'heathen', 'pagan idol' or similar (based on the false but common medieval Christian belief that the prophet Muhammad was worshipped as a god), here in reference to a barrow that was considered to be a pre-Christian site, it is worth noting that there are a small number of people with names and surnames derived from Arabic <i>Muḥammad</i> apparently living in twelfth- to fourteenth-century England.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-w4ER6e7-JsI/X7AZDfw1bCI/AAAAAAADLhw/ULvdpDuWKwAelDOKu23y5ZJFgTBdhTdMgCLcBGAsYHQ/s879/macamathehou-large.jpg"><img data-original-height="355" data-original-width="500" src="https://1.bp.blogspot.com/-hhv-Lu79n_o/X7AZDcDbe6I/AAAAAAADLhs/RS2oeTJ3IocU1SGmohUZdB7Q-nFhCH-sgCLcBGAsYHQ/s16000/macamathehou-500.jpg"></a></td></tr><tr><td><i>Figure 1: the location of Macamathehou between Spridlington and Faldingworth parishes in Lincolnshire; click the image or <a href="https://1.bp.blogspot.com/-w4ER6e7-JsI/X7AZDfw1bCI/AAAAAAADLhw/ULvdpDuWKwAelDOKu23y5ZJFgTBdhTdMgCLcBGAsYHQ/s879/macamathehou-large.jpg">here</a> for a larger version (image: C. R. Green/OpenStreetMap and its contributors).</i><i>&nbsp;</i></td></tr></tbody></table>
<p>The existence of the intriguing local name <i>Macamathehou</i> in the parish of Spridlington, Lincolnshire, was first noted in 2001 by Kenneth Cameron, John Field and John Insley in <i>Place-Names of Lincolnshire VI </i>(<i>PNL</i>), with both attestations of the name dating from the thirteenth century (the reign of King Henry III, 1216–72).(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn1">1</a>) They identify the two elements of the name as being Old Norse <i>haugr</i>, 'mound, barrow', and Middle English <i>Makomet/Macamethe</i>, which derives from the name of the prophet Muhammad (Medieval Latin <i>Machometus/Mahumetus</i>, Anglo-Norman <i>Mahumet/Mahomet/Machomete</i>, Old French <i>Mahomet</i> &lt; Arabic <i>Muḥammad</i>, probably via an Arabic regional form <i>Maḥammad</i>).(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn2">2</a>) Needless to say, this solution is most intriguing and has, moreover, found favour with other place-name specialist, including the <i>Vocabulary of English Place-Names </i>(<i>VEPN</i>) and Richard Coates.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn3">3</a>)</p><p>As to the import of this name, the easiest conclusion—and the one endorsed by&nbsp;<i>PNL</i>, <i>VEPN</i>&nbsp;and Coates—is that the first element, <i>Macamethe/</i><i>Maumate</i> etc, is not functioning simply as a normal Middle English rendering of the name Muhammad/<i>Mahomet</i>, but rather as a word indicative of heathen or pagan idolatry, based on the false but common medieval Christian belief that the prophet Muhammad was worshipped as a god. So, <i>PNL </i>describes the name as meaning 'the heathen mound', with the first element being 'a corrupt ME [Middle English] form of the name of the prophet Mohammed, for which <i>v.</i>&nbsp;MED [<i>Middle English Dictionary</i>], s.v. <i>Makomete</i>, also used to denote a pagan god or an idol'.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn4">4</a>) This is taken up by Richard Coates, who says that it has been suggested, 'with great plausibility', that <i>Macamathehou </i>in Spridlington parish 'is a Middle English name meaning "Mahomet mound", i.e. "heathen mound"', and points to 'the repeated compound of OE <i>hæðen </i>+ <i>byrgels "</i>heathen burial"' as a potential comparison.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn5">5</a>) Likewise, the <i>VEPN</i>'s draft section on M includes the following discussion:</p>

<blockquote><b>makomet </b>ME, 'idol, pagan god', an application of the name of the Arab prophet Mohammed (commonly though mistakenly believed by medieval Christians to have been worshipped as a god)... It occurs early in
<i>Macamathehou </i>(f.n.) 1216–72 L:6·211 (<b>haugr</b>), presumably to be
interpreted as 'heathen mound'.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn6">6</a>)</blockquote>
<p>On the whole, this interpretation is probably the safest option. There are certainly a handful of references to 'heathen' barrows in Old English charter bounds, for example <i>of leofwynne mearce to þam hæþenan beorge</i>, 'from Leofwine's boundary to the heathen barrow', in the charter S956 relating to Drayton, Hampshire, and dated AD 1019, although none are recorded from Lincolnshire.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn7">7</a>) It has also been suggested that the Lincolnshire names Bloater Hill (North Willingham) and Blod Hou (Barrow-on-Humber) derive from Old Norse <i>blóthaugr</i>, 'a sacrificial mound', whilst other names involving <i>haugr</i> certainly refer to supernatural/demonic creatures—for example, <i>Gasthehowe</i>/<i>Gastehowe</i>, Ashby Puerorum (Lincolnshire), recorded in the thirteenth century and deriving from Middle English <i>gast</i>/Old English <i>gāst</i>, 'ghost, dead-spirit', or names like Scratters (<i>Scrathou</i>, in Hayton, East Riding of Yorkshire) and Scrathowes (<i>Scrathou</i>, in Osmotherley, North Riding of Yorkshire), which derive from Old Norse <i>skratti</i>, 'devil, wizard'&nbsp;+ <i>haugr</i>.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn8">8</a>) Furthermore, the Old English compound <i>hæðen&nbsp;</i>+ <i>byrgels</i>, 'heathen burial', does indeed recur frequently in Late Saxon charter bounds, with these names often said to be identifiable with barrows in the landscape.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn9">9</a>)</p><p>On the other hand, there are some possible issues with this explanation, and other interpretations are possible of Spridlington's <i>Macamathehou</i>. First, the comparison with the many instances of the OE compound <i>hæðen </i>+ <i>byrgels</i>, ‘heathen burial’, is perhaps not as convincing as it might seem. Not only is a link between this term and barrows only demonstrable in a handful of instances, but Andrew Reynolds has also suggested that the sense of the term was primarily not ‘pagan’, but rather ‘unconsecrated’, and that it denoted burials of executed offenders and other social outcasts, which renders the proposed value of these names as support for interpreting <i>Macamathehou&nbsp; </i>as meaning ‘heathen mound’ open to significant debate.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn10">10</a>) Second, if the above is correct, then this would be the only known instance of a derivative of the Arabic name Muhammad being used in a place-name to indicate a 'heathen mound' or similar, which is potentially concerning—the other elements noted above all recur in multiple names. Third, the element identified by <i>PNL </i>and <i>VEPN</i> as being present in <i>Macamethehou</i> is Middle English <i>Makomet(e)</i>. The <i>Middle English Dictionary</i> (<i>MED</i>) on <i>Makomet(e)/</i><i>Macamethe</i> etc, however, makes it clear that the primary use of this word in Middle English is as a form of the name Muhammad, not as a word referring to an 'idol'/'pagan god', with the vast majority of quotations provided by the <i>MED </i>referring either the prophet Muhammad or people named Muhammad; the only exceptions are a single quotation from Layamon's <i>Brut </i>(<i>c.</i>&nbsp;1200, <i>mahimet</i>, lacking the <i>-c-</i>), and three from two later texts.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn11">11</a>) The form of the name Muhammad that <i>was </i>primarily—although not exclusively—used in the sense 'pagan deity, idol', is rather <i>Maumet/Maumate</i>, mentioned above, deriving from Anglo-Norman <i>Maumet</i>, a reduced form of <i>Mauhoumet</i>, Old French <i>Mahomet/Mahommet</i>.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn12">12</a>)</p>
<p>In this light, it is worth considering whether it is possible that the name <i>Macamathehou</i> could somehow be named from a person named <i>Makomet</i>/Muhammad or similar living in medieval England. Certainly, it should be noted that multiple local names relating to mounds/barrows do seem to be named after people who owned estates or land in the area. For example, Andrew Reynolds draws attention to the bounds of a mid-tenth-century charter for Swallowcliffe, Wiltshire (S468), that records the burial site of a seventh‐century woman whose grave had been cut into an existing mound as <i>Posses hlaew</i>, noting that 'Poss is a male name, and thus the mound is apparently not named after its Anglo‐Saxon occupant', implying that it was instead named after a later estate owner.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn13">13</a>) As Irene Bower long ago pointed out, such a situation can be credibly paralleled in Lincolnshire, with a number of Lincolnshire names involving <i>haugr</i> seeming to contain the same personal-name as is found in the same or a neighbouring parish-name—so, <i>Scalehau </i>(<i>Skalli </i>+ <i>haugr</i>) was located near to Scawby (<i>Skalli</i>&nbsp;+ <i>bȳ</i>), with Kenneth Cameron commenting that the two were 'no doubt named from the same man'; <i>Leggeshou</i> (<i>Leggr </i>+ <i>haugr</i>) was located on the boundary of Legsby parish (<i>Leggr&nbsp;</i>+ <i>bȳ</i>); <i>Katehou/Catehowe </i>(<i>Kati</i>&nbsp;+ <i>haugr</i>) was located in South Cadeby (<i>Kati&nbsp;</i>+ <i>bȳ</i>); and a <i>Grimaldeshawe</i> (<i>Grimaldi </i>+ <i>haugr</i>) was recorded in the neighbouring parish to Grimoldby (<i>Grimaldi</i>&nbsp;+&nbsp;<i>bȳ</i>), perhaps on the boundary between the two.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn14">14</a>)</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-Nu02Jqw5h14/X7WB-D0A8sI/AAAAAAADLvg/p_vwSAkF6RQX5KkB8XMvM6WiC4a1eyI5gCLcBGAsYHQ/s1296/PipeRoll-Mahumet1160-1.jpg"><img data-original-height="216" data-original-width="500" src="https://1.bp.blogspot.com/-VAcqNuGj78U/X7WB-YLMzBI/AAAAAAADLvk/_TLGpi35Olg-dWNhgmcuMcZSaz-qhCgdACLcBGAsYHQ/s16000/PipeRoll-Mahumet1160-1-500.jpg"></a></td></tr><tr><td><i>Figure 2: Section from the Pipe Roll Society publication of&nbsp;The Great Roll of the Pipe for the Seventh Year of the Reign of King Henry the Second, A.D. 1160–1161 (London: Wyman &amp; Sons, 1885), p. 10, dealing with Mahumet of Wiltshire (image: <a href="https://archive.org/details/piperollsociety04pipeuoft/page/10/mode/2up">Internet Archive</a>).</i></td></tr></tbody></table><p>As to the likelihood of someone named Muhammad or one of its Anglo-Norman/Middle English variants (<i>Mahumet</i>,<i> Makomet</i> and similar) actually living in medieval England, this is perhaps less far-fetched than might be assumed. Katharine Keats-Rohan and John Moore have directed attention to the Wiltshire entries of five consecutive Pipe Rolls of Henry II (1160/61–1164/65) that refer to a man named <i>Mahumet, </i>whose name-form Moore considers very difficult to explain as anything other than a rendering of Muhammad and which is accepted as such by the <i>OED </i>and <i>MED</i>. This <i>Mahumet </i>is recorded in the Pipe Rolls only because he was fined for his part in an unlicensed duel with a John de Merleberge, probably in or near Marlborough Castle, and it seems he was not an especially wealthy man, as he was pardoned the last mark of his fine due to his poverty.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn15">15</a>) Furthermore, <i>Mahumet</i> of Wiltshire was not the only man with this name for whom we have evidence from medieval England. For example, a Theobald <i>filius Mahumet</i> (or <i>filius Mahomet</i>) is recorded from early thirteenth-century Hampshire in the Pipe Rolls of Henry III for 1222–24; another man named <i>Mahomet </i>is recorded in 1327, when Edward III issued him and six others a pardon at Newton-on-Ouse, Yorkshire, for 'offenses in Ireland'; and a <i>Mahummet Saraceno</i>&nbsp;occurs in the Close Rolls of Henry III for 1254. Furthermore, a number of people surnamed <i>Mahumet </i>and similar are recorded in documents of the twelfth and thirteenth centuries, for example a Humphrey Mahumet in a charter of Southwick Priory, Hampshire, a Herbert Maumet who was sergeant of Portsmouth in the mid-thirteenth century, and a Radulphus Maumet who is recorded in the reign of King John.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn16">16</a>) Moore also notes the presence of someone bearing another 'apparent Arab name' in twelfth-century Hampshire, a certain <i>Paucamatus</i>, a name that he considers to probably reflect <i>Bakmat</i>, who is recorded in Winchester from 1159/60 until 1183/4 and who is associated with …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html">https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html</a></em></p>]]>
            </description>
            <link>https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232817</guid>
            <pubDate>Tue, 23 Feb 2021 01:20:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The road to electric is filled with tiny cars]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 243 (<a href="https://news.ycombinator.com/item?id=26232760">thread link</a>) | @jimmy2020
<br/>
February 22, 2021 | https://restofworld.org/2021/tesla-vs-tiny-cars/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/tesla-vs-tiny-cars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>I</span>n Beijing’s southwestern outskirts, past a four-lane overpass with sidewalks as wide as the streets themselves, is Zhengyang Road. It has the usual banks, small convenience stores, and noodle houses of many areas in the capital, but it is set apart by a row of about a dozen shops all selling the same thing — tiny electric cars. The cars look, variously, like small Range Rovers, golf carts, trolley cars, or rickshaws with sheet-iron sides, and they are slow. Their fundamental attraction is their price — between $600 and $2,500 — and that drivers can charge them the same way they would a cell phone. They also come with the perks of being loosely regulated. These low-speed electric cars, nicknamed “elderly transport vehicles,” have an enormous market, made up mostly of people who earn very little. And in China, there are a lot of them — <a href="http://english.www.gov.cn/premier/news/202005/29/content_WS5ed058d2c6d0b3f0e9498f21.html">more than 40%</a> of the population, or some 600 million people, make around $150 per month.</p>



<p>On a Sunday afternoon in October, Zhengyang Road is filled with potential customers chatting with store owners.<strong> </strong>Outside a shop with a worn sign, a young couple with a child are in the midst of a heated conversation.<strong> </strong>They came on an electric scooter and are debating whether to leave with a tiny car.</p>



<p>“Don’t we need one for school pickups?” the woman argues. “The children won’t have to put up with the cold in winter.” Her scooter offers no protection from the weather other than oven-mitt-like gloves secured to its handlebars. Her husband counters, “The 1,000 renminbi [$150] quote was for normal batteries, but lithium ones can be five times that. Can’t you just add a windshield to your scooter instead?” The shop owner shows them a cheaper model — which is cheaper because it has no roof. He suggests putting a plastic covering on top.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="A woman exits a tiny car near a subway station in Beijing.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Having decided that the future of mobility is electric,<strong> </strong>the Chinese government has subsidized sales of standard electric cars since 2010. With <a href="https://insideevs.com/news/394229/plugin-electric-car-sales-china-2019/">close to 1.18 million sold</a> in 2019, China accounts for just over half of electric-vehicle sales globally. Bill Russo, founder and CEO of advisory firm Automobility Limited, sees a “steady and solid rise” in China’s electric-vehicle sales generally. The country has set a top-down target for electric vehicles to <a href="http://energy.mit.edu/news/chinas-transition-to-electric-vehicles/">make up 40%</a> of car sales by 2030, and Russo thinks they’ll have no problem hitting this goal. Tiny cars,<strong> </strong>which first began appearing in the early 2010s,<strong> </strong>have more than double the sales of regular electric cars but have<strong> </strong>never benefited from subsidies. Nor do advertisements for them air on television — instead, they appear on Kuaishou, a short-video platform popular with people living outside China’s big cities. Alongside streamers selling plums by the thousands, and others telling viewers what long-haul trucker life is like, drivers show off their tiny cars. Su Hua, Kuaishou’s founder, has long maintained that his app’s users are not “cool,” unlike those on Douyin, the TikTok predecessor popular with China’s urban elite. Rather, they are ordinary — the kind of people who might be in the market for miniature cars.</p>



<p>As they don’t technically require licenses, tiny cars tend to be popular with migrant workers, who struggle to pay for driving lessons and other car-related costs. The elderly, too, find tiny cars attractive since, up until October of last year, people over 70 could not apply for a driving license in China. They’re also convenient for anybody who wants a car to pick up groceries or their kids from school: No tiny car is longer than 1.5 meters, and their speed tops out at between 40 and 56 kilometers an hour. They’re for the short trips of daily life, not for traveling from one side of the city to another.</p>



<p>Some cities have banned sales of tiny cars — Beijing did so in 2018. Their production isn’t regulated by the government, and since they can’t be insured in many parts of China, it can be difficult for other drivers to get a payout if a tiny car is involved in an accident. Because tiny-car drivers don’t need to take a driving test, other drivers complain, they often go the wrong way and weave in and out of traffic. But since enforcement is lax, sales have quietly resumed in Beijing over the past two years. These little electric cars now exist in a kind of regulatory gray zone.</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      
    </figure>

    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Tiny cars come in a variety of styles and cost between $600 and $2,500.</figcaption>
    </figure>


<hr>



<p><strong>One of the</strong> smaller shops on Zhengyang Road is officially known as Xinlei Scooters, its name emblazoned in white characters on a large red sign above its doors. But inside, past rows of electric scooters, is a smaller, flimsier plaque above the counter announcing its other name: Shitou Cars. This subterfuge is necessary because the police could shut down the operation and confiscate its vehicles if the owners were caught selling tiny cars. Yet because enforcement hasn’t been strict of late, attempts at being covert go only so far: There are several tiny cars parked outside, an open-air showroom.</p>



<p>Xinlei/Shitou’s owner is a middle-aged man with pronounced cheekbones wearing a black tracksuit. He is more attentive to the phone calls he’s constantly receiving than the customers in the shop. It is his wife, with dyed-dark-brown hair and a pink coat, who maintains the sales patter: “I taught an auntie who had never driven a car before. She got the hang of it in three days.” She shows the cars outside to potential customers, opening their doors, instructing people to sit inside, and rolling down the windows. When two old men come in for repair services, her husband finally gets off the phone to deal with them. Meanwhile, two government functionaries in black uniforms pace down the street. They tell one owner to make his storefront tidier, but otherwise overlook the illicit operation.</p>



<p>Part of the reason why tiny cars are so popular is because there has not been an official decision on whether they need license plates. For regular cars, unfettered access to Beijing’s inner city — anywhere within the fifth ring road — is restricted to vehicles with Beijing plates. Licenses for gas cars are distributed through a special system so competitive that it has generated its own black market. License-plate holders can collect up to $2,700 a year by renting them to those who want to drive in the city. In addition to government subsidies, getting around some of the more onerous aspects of the licensing system is one of the main selling points for standard electric cars.</p>



<p>With Beijing temperatures reaching lows of 4 degrees Celsius in wintertime, Xinlei/Shitou has been selling,<strong> </strong>on average, two of its four-wheeled fully enclosed models every day, a saleswoman boasts. Younger couples prefer four wheels, she adds, while older people usually want three. When asked about the possibility of a tiny car being confiscated, she draws in a breath. “Don’t go on the main roads. Don’t make a business out of it,” she advises.</p>



<p>At least one of Zhengyang Road’s customers isn’t listening: Guo Caiying, who works primarily in the construction-supply industry,<strong> </strong>chauffeurs Fengtai residents around her district. She has a sticker on her tiny car’s back window with the phone number of her car dealer. Guo’s car looks like a golf cart, with cushioned brown seats enclosed by windows. A red <em>fudai</em>, a lucky charm, swings from the ceiling, its characters spelling out “peace.” There is enough space for two people to comfortably sit upright but not enough to extend your legs without hitting the plexiglass divider between driver and passenger. The car tops out at 40 kilometers an hour, and<strong> </strong>as a result, Guo never ventures beyond Fengtai — a borderland where urban and rural meet.</p>



<p>Guo wears the uniform of the countryside: a padded jacket. She is from Henan, a province 800 kilometers southwest of Beijing, and speaks its dialect. Guo starts taking calls from her regulars around 7 a.m., arriving at their door whenever they want to be picked up. She stops driving at 9 a.m., when the traffic police begin work. She characterizes her customers as “people with money who sit in offices.” Once, while in the middle of a trip, Guo saw a cop stop a car like hers. She kept driving, but dropped her passenger off before their destination. Now, if a customer calls her after 9:00, she sends her husband to pick them up with his electric scooter. He charges 75 cents (5RMB), which is half her price. Guo’s flat rate was fixed by the tiny-cab drivers who preceded her.</p>



<p>The economy of tiny cars depends on such informal practices.<strong> </strong>When asked whether she would consider undercutting other drivers, Guo is adamant. “No one can break the rules,” she says. There are local WeChat groups for tiny-car drivers that new owners are inducted into upon purchasing one. Within these groups, members swap information on the whereabouts of local cops and whether anyone has been fined or had their car taken away.</p>



<p>Despite the risks, Guo still thinks it’s worth being a tiny-car driver to make a little pocket money.<strong> </strong>Tiny cars are part of a last-mile economy that flourishes at the beginning and end of the workday. Many Fengtai residents are employed at the local high-tech park, which is host to thousands of businesses. It takes 20 minutes to walk from one end of the park to the other, a trip many would rather make by tiny car. The cars’ main competitors are share bikes, which are cheaper but lack space for luggage and can’t be split with a friend. Tiny cars are also more social — a feature Guo tries …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/tesla-vs-tiny-cars/">https://restofworld.org/2021/tesla-vs-tiny-cars/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/tesla-vs-tiny-cars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232760</guid>
            <pubDate>Tue, 23 Feb 2021 01:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full list of online communities for programmers]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232689">thread link</a>) | @gruppo11
<br/>
February 22, 2021 | https://thehiveindex.com/topics/software-development/?r=hn | <a href="https://web.archive.org/web/*/https://thehiveindex.com/topics/software-development/?r=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page"><h2>About this Topic</h2><p>This is a list of communities dedicated to engineers, software developers, coders, and hackers. Some are online communities dedicated to a particular technology or programming language, and some are general purpose communities or those that help developers early in their career. The communities on this list are an excellent source of inspiration, knowledge-sharing, and networking.</p><h2><div><p>60</p><!-- --><p> Online </p><!-- --><p>Communities</p><!-- --><p> for Software Developers</p></div></h2><p>This topic's list is getting pretty long! Feel free to use the Platform/Feature filters above to cater the search to you.</p><div><p>Know a </p><!-- --><p>Software Development</p><!-- --><p> community that is not on this list yet? Please <a href="https://thehiveindex.com/submit/">submit it</a>!</p></div></div></div>]]>
            </description>
            <link>https://thehiveindex.com/topics/software-development/?r=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232689</guid>
            <pubDate>Tue, 23 Feb 2021 01:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS-TV-Out Restoration Project]]>
            </title>
            <description>
<![CDATA[
Score 218 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26232600">thread link</a>) | @max-m
<br/>
February 22, 2021 | https://lostnintendohistory.github.io/DS-TV-OUT | <a href="https://web.archive.org/web/*/https://lostnintendohistory.github.io/DS-TV-OUT">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<h2 id="introduction">Introduction</h2>

<p>During late 2020, we discovered that the Nintendo DS Lite had a leftover feature in its SoC allowing it to easily have cheap hardware video output. With a little circuitry and some software hacks, we were able to restore it and make it usable for anyone. No FPGA’s, no bulky or cumbersome hardware. This mod is specially useful to revive consoles with only the lower screen, being able to watch the upper screen on your TV. Or to create a GBA Macro with additional TV Output.</p>

<center>
<img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/DSTVOUT.jpg" width="250" height="250"><br></center>
<center>
  <b>First iteration of the TV-OUT board in action</b>
  </center>

<h2 id="installation">Installation</h2>

<p>If you are just interested in installation, this is the current method <strong>while we work on simpler methods</strong> and more features you have requested:</p>

<ol>
  <li>Install the <a href="https://ezflash.sosuke.com/wiki/index.php/Flashme">flashME CFW</a> (Custom FirmWare) on your DS Lite</li>
  <li>Connect the Nintendo DS Lite’s upper screen flex to the PCB board.</li>
  <li>Donwload the “NDS TV OUT ENABLE.nds” homebrew from the <a href="https://github.com/LostNintendoHistory/Lost-NDS-TV">NDS TV OUT repo</a></li>
  <li>Download <a href="https://github.com/DS-Homebrew/TWiLightMenu/releases">Twilight Menu</a></li>
  <li>Copy both the NDS TV OUT ENABLE and Twilight Menu .nds files to a flashcart.</li>
  <li>Use flashme to autoboot into the flashcart. You can do this by pressing A + B + Start + Select while booting. Run Twilight menu, and from there, run the enabler homebrew.</li>
  <li>The console will return to Twilight Menu. Now you can use the buttons on the board to swap between the different screen modes (Upper Screen to TV, Bottom Screen to TV, etc) and launch your games.</li>
</ol>

<hr>

<h2 id="software">Software</h2>

<p>The retail firmware of the Nintendo DS Lite disables this specific feature early in the boot process. To reenable it, we use a custom firmware like flashme, which is very easy to install and is required only once, plus a homebrew. Despite that, we are working on an even simpler solution to make it available to as many people as possible, our own custom firmware which integrates patches to enable this feature directly on boot. Additionally, we are currently working with homebrew developers to integrate control of this new feature into existing software for the DS Lite.</p>

<h2 id="hardware">Hardware</h2>

<p>This feature is only found on the Nintendo DS Lite. Nintendo DS Phat does not contain this feature nor does the Nintendo DSi. It is important to remark that <strong>this is not the same hardware</strong> found on Devkits or other special units. This hardware feature is present in virtually <strong>every single Nintendo DS Lite</strong> out there. The reason why it was left there is unknown, but as said before, it is not related to development units, those use a different video capture hardware. Perhaps Nintendo imagined the Nintendo Switch as early as 2006?</p>

<center><img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/PCB_Rev_11.png" width="350" height="400"></center>

<p>We only need a few extra hardware components to make this video signal usable. You will be able to download the schematics and gerber files for our open hardware circuit board <a href="https://github.com/LostNintendoHistory/Lost-NDS-TV">from the repository</a>. The latest version is revision 1.2 which fixes some minor issues with a component in the board.</p>

<center>
<img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/Prototype.jpg" width="350" height="350"><br>
</center>
<center>
  <b>First prototype and tests before designing a proper board</b></center>


<p>The final, production-ready board contains a DAC (Digital to Analogue Converter) which turns the 10 bits digital signal at 16.7 MHz provided by the DS Lite into a proper analogue signal. This signal then goes through an operational amplifier and it’s ready to be delivered to your nearest TV trough composite video.</p>

<p>We are currently considering creating an additional PCB revision which would allow to install the mod on consoles without lossing a working upper screen.</p>


      </section>
    </div></div>]]>
            </description>
            <link>https://lostnintendohistory.github.io/DS-TV-OUT</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232600</guid>
            <pubDate>Tue, 23 Feb 2021 00:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Bombard Story]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 36 (<a href="https://news.ycombinator.com/item?id=26232597">thread link</a>) | @jbergstroem
<br/>
February 22, 2021 | https://greatestadventurers.com/the-bombard-story/ | <a href="https://web.archive.org/web/*/https://greatestadventurers.com/the-bombard-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-618" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			<p><strong>The Bombard Story</strong> is the account of <a href="https://en.wikipedia.org/wiki/Alain_Bombard">Alain Bombard’s</a> amazing journey in 1952 across the <a href="http://greatestadventurers.com/the-north-west-passage-by-roal-amundsen/">Atlantic</a> on a small 14-foot inflatable boat. Alain Bombard left without food or fresh water and sailed 4.400 kilometers. He lost 25 kg. but proved his point: Man can actually survive on ocean water for an extended period of time!</p>
<figure id="attachment_619" aria-describedby="caption-attachment-619"><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2021/02/TheBombardStory1953.jpg" alt="The Bombard Story" width="300" height="203" data-src="http://greatestadventurers.com/wp-content/uploads/2021/02/TheBombardStory1953.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-619">In this small vessel Bombard sailed across the Atlantic – without freshwater</figcaption></figure>
<p>As a doctor, Bombard was concerned about the hundreds of deaths at sea every year related to sailors drinking ocean water. He developed the theory that humans can not just survive but live for years on seawater. This sounds very strange, but his big idea was to begin drinking seawater, while you are still hydrated – and in small quantities. It turns out that saltwater is only dangerous if you are dehydrated and suddenly drink large amounts of it. – The way shipwrecked sailors typically would do when they run out of fresh water. From the book:</p>
<blockquote><p>For some time I had made a study of the resistance of the human organism to privations and had convinced myself that it was possible for an individual to survive beyond the limits normally assigned by physiological science. I had paid particular attention to the case histories of political deportees, prisoners, and undernourished populations. But, with my background as a doctor, for whom the teachings of science remain a dead letter unless they can find practical application, my theoretical studies only seemed to lead to the question: ‘What use can made of this knowledge?’</p></blockquote>
<p>Bombard ate spoonfuls of plankton that he collected in a fine net and he also drank juice made from pressed fish he caught along the way. Sound disgusting, but the man survived and he might have discovered an important piece of knowledge for survival on the ocean.</p>
<p>Download the free PDF e-book here (223 pages/38MB):</p>
<h3><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2020/08/PDF-download-e1597850191432.png" alt="" width="35" height="35" data-src="http://greatestadventurers.com/wp-content/uploads/2020/08/PDF-download-e1597850191432.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">&nbsp;<a href="http://greatestadventurers.com/wp-content/uploads/2021/02/The-Bombard-Story-1953.pdf">The Bombard Story 1953</a></h3>

		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://greatestadventurers.com/the-bombard-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232597</guid>
            <pubDate>Tue, 23 Feb 2021 00:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Basics of (Statistical) Modeling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232497">thread link</a>) | @dcu
<br/>
February 22, 2021 | https://blog.chewxy.com/2021/02/17/modeling-basics/ | <a href="https://web.archive.org/web/*/https://blog.chewxy.com/2021/02/17/modeling-basics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<div>
<article role="main">
<p>I had a very interesting chat with a few data science students yesterday. Part of the chat involved the idea of statistical modeling. Throughout the chat, it occured to me that the students didn’t have a very good grasp of what modeling is. To their credit, they were proficient in the techniques of linear regression, and deep learning, but I got the sense that they were very much pushing buttons and watching things happen rather than understanding what they were actually doing. There was no sense of a big picture view.</p>
<p>This has been happening quite a lot lately. I find it somewhat alarming. This blog post is a semi-transcript of what I said last night. It aims to be as simple as possible.</p>

<p>A model is a representation of reality. It’s what we think reality looks like.</p>
<p>For example, we live on Planet Earth, in a solar system. We can build models of our Solar System. Here’s an example of a model of our Solar System.</p>

<div>
<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
<p><img itemprop="thumbnail" src="https://blog.chewxy.com/wp-content/uploads/2021/modeling/orrery.jpg" alt="An Orrery of our Solar System. Photograph by Smabs Sputzer, published with a CC BY 2.0 licence. Source: https://www.flickr.com/photos/10413717@N08/7527137708">
</p>
<a href="https://blog.chewxy.com/wp-content/uploads/2021/modeling/orrery.jpg" itemprop="contentUrl"></a>
<figcaption>
<p>An Orrery of our Solar System. Photograph by Smabs Sputzer, published with a CC BY 2.0 licence. Source: https://www.flickr.com/photos/<a href="https://blog.chewxy.com/cdn-cgi/l/email-protection" data-cfemail="daebeaeeebe9edebed9a94eae2">[email&nbsp;protected]</a>/7527137708</p>
</figcaption>
</figure>
</div>
<p>As a child, such models of our solar system endlessly fascinate. I would spend hours thinking about how the planets moved. I would play and watch the planets spin around its spindles. I understood that there was a force called gravity that caused the planets to orbit the sun. As I grew older, the physical model of our Solar System is gradually replaced by <a href="https://en.wikipedia.org/wiki/Kepler%27s_laws_of_planetary_motion">three laws</a>.</p>
<p>There are parts of the model we can study:</p>
<ul>
<li>What is the shape of the orbits</li>
<li>How the planets move</li>
<li>Why do planets move thus</li>
</ul>
<p>These are sub-models of the model of our Solar System. The shape of the orbit is given by Kepler’s First Law. How planets move is given by Kepler’s Second and Third Law. Why do planets move thus is given by Newtonian mechanics.</p>
<p>Each of Kepler’s laws have an equation governing them. So we can say the equations model our Solar System. The equations are the model of our Solar System. These equations describe something static (the shape of the orbit) and represent something dynamic (how the planets move). What used to be physical motion in a physical model can now be written down on a piece of paper, an equation representing the real thing.</p>

<p>There are many ways of making a model. Sometimes it’s useful to have a physical understanding of something. <a href="https://blog.chewxy.com/2021/01/09/sars-cov-2/">I built the 2019-SARS-CoV-2 virion</a> to help me have a better understanding of the coronavirus that caused the pandemic in 2020. Now, I’m no biologist, so my model is crude. My model is extremely physical. Despite this, it gave me an understanding of how a mRNA vaccine might work. It gave me confidence over what actual proper scientists are doing.</p>
<p>So making a physical model is one way. But what if we want something more rigorous? The usual way is to resort to some sort of formalism. Various fields have various formalisms. For example, in chemistry, you use chemical equations. However, the most common formalism would be a mathematical equation. Maths equations are used in physics, economics, biology, and many other fields.</p>
<p>So how do you create an equation that becomes a model of something? There are two ways:</p>
<ol>
<li>Generate an equation.</li>
<li>Find an equation from data.</li>
</ol>
<p>In the large scheme of things, both of these amount to the same thing: generating an equation. I’ll talk about that in a later section. For now, when I say “model generation” I mean generating an equation that models reality.</p>
<h2 id="how-do-you-generate-an-equation">How Do You Generate An Equation?</h2>
<p>The simplest way of generating an equation is to randomly generate one by writing down symbols on a piece of paper.</p>
<p>That’s daft, you say. You’d be hard pressed to find a equation that adequately describes the situation!</p>
<p>That’s why most model generation comes from <a href="https://en.wikipedia.org/wiki/First_principle">first principles</a>. In using the Solar System example, if we accept Newton’s law of universal graviatation ($F = G{\frac {Mm}{r^{2}}}$), then we can work our way to find Kepler’s third law. Kepler’s other laws require other first principles such as trigonometry.</p>
<p>The key is that you understand a subject well enough that you may generate further models about the subject using your basic understanding.</p>
<p>However, random generation has its place. In fact, from here on, whenever I write “generate a model”, you may think of a person randomly coming up with math equations.</p>
<h2 id="how-do-you-find-an-equation-from-data">How Do You Find An Equation From Data?</h2>
<p>There may be cases where first principles may not be used. This is often the case in new fields.</p>
<p>So the next best way is to find an equation from data. There are many ways to do them. Regression analysis is one such way of finding an equation from data. Let’s look at a simple example of linear regression with one variable.</p>
<p>The fundamental idea of a linear regression is that you plot your data points, and draw a straight line through the plot (line A). Each data point would be some distance away from line. Sum those distances up and square them. Call it the “error”. Now draw another line through the plot (line B) and find the errors of B. Keep doing until you find a line that has the lowest amount of errors.</p>
<p>This is the line-of-best-fit. Given that all straight lines on a plot can be described by an equation that looks like $y = mx +C$, the equation that describes the line of best fit (e.g. $y=2x + 1$) is the model.</p>
<p>This idea of model building extends all the way to deep neural networks. They key being the model is built by looking at the relationships between the variables that make up a data point.</p>

<p>The whole point of creating a model is to reflect reality. I could well come up with a model of gravity that says this: all objects exert a force on each other that is quadratic on the distance between them - written as $F = d(a, b)^2$. But does this reflect reality? No.</p>
<p>How do I know this? I know this because I can test it. I can collect data, and then check if the data fits my model. In the silly example above, it’s trivial to check with a counterpoint: I am able push something off my desk. If the force is solely based on distance, then as my hand approaches the object, the force should get smaller and smaller to the point that I am unable to affect the object.</p>
<p>In many courses about regression analyses, the R² values are often taught to students as a measure of how good one’s model is<span><span></span><span>I find this to be mostly true about "data science" courses/bootcamps, but not more traditional uni level course on regression/economics/statistics</span></span>. It’s not! A R² value is how good the fit of data to the line is. In some sense you may think of this as the inverse of “how good is your model” . It’s more “how much data fits in your model”. Indeed, the R² value is indicative of how much variance of your data is covered by the model.</p>
<p>This is not to say that the courses are wrong. The statement that “R² tells you how good your model is” is a very subtle statement. Let’s unpack them. Let’s say you found a line of best fit that is described by the formula $y = 2x + 15$. This is the model that we have “generated”. Now we want to see how much of reality (our dataset) is described by the model. It is in this sense that R² represents the notion of how “good” a model is.</p>
<p>Now it seems a bit weird, given that we used the dataset to find the line of best fit, and then we turn around and say we generated a model, not let’s test to see how good it is. There seems to be a bit of circular logic to it. However there are a lot of theoretical work on why the line of best fit found by a ordinary least squares (OLS) regression is a good model “generator” - the wikipedia article on <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">OLS</a> covers quite a bit, as does the <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem">Gauss-Markov theorem</a> article. Most textbooks also lay out proofs of why OLS estimators are BLUE (Best Linear Unbiased Estimator).</p>
<p>Here I want to point out that “reality” is itself just a sample. The dataset that you use to generate a model is just a sample. This is where conscious sampling of data is important. Let’s imagine we are training a machine learning system to recognize faces. My social circle are White or Asian. So if I ask my social circle to send me some photographs of their faces to train a machine learning system, then the machine learning system would not be able to recognize faces that are not White or Asian! Clearly this is not a good representation of reality.</p>
<p>This trivial example only scratches the surface of equitable conscious collection of sample “reality” for the sake of model building. This topic is a very deep topic and it’ll take many blog posts to talk about it. So I shall leave it be for now.</p>
<p>In more advanced machine learning modeling systems (e.g: deep learning systems), it is common to split the dataset into “training” and “testing” datasets. The model is trained on the training dataset and tested on the testing dataset. This is to ensure that the model does not only model “reality” that is in the training dataset, but can also generalize to previously unseen data.</p>
<p>What I am trying to convey here is that sanity checks against reality is a good thing. We should do them more often.</p>

<p>Having said that, we have to accept that models are just that - models. They are not reality. George Box had a good saying:</p>
<blockquote>
<p>All models are wrong. But some are useful.</p>
</blockquote>
<p>The key is to find a model that is useful enough for what you need to do. Let the natural philosophers worry about the most accurate models of reality.</p>

<p>Humanity is always generating models. Individually, in our brains, we generate internal models that are corrected every second of the day. Consider catching a ball. Your brain generates a model of physical reality - no equations here - telling us where the ball is going to be. As the ball arcs through the air, we update the models in our brain, getting better and better predictions, resulting in us catching the ball. Or in my case, the ball lands on my face.</p>
<p>Communally, we generate models too. The invention of writing and speech allowed us to share models with other individuals. We started using things like maths equations to make our meanings clear. Our …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.chewxy.com/2021/02/17/modeling-basics/">https://blog.chewxy.com/2021/02/17/modeling-basics/</a></em></p>]]>
            </description>
            <link>https://blog.chewxy.com/2021/02/17/modeling-basics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232497</guid>
            <pubDate>Tue, 23 Feb 2021 00:33:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Quality with Mypy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232204">thread link</a>) | @max-hoffman
<br/>
February 22, 2021 | https://www.dolthub.com/blog/2021-02-22-mypy-and-doltpy/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2021-02-22-mypy-and-doltpy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><h2>Dolt</h2>
<p>Dolt is an SQL-database with Git-versioning.
The goal of <a href="https://github.com/dolthub/doltpy">Doltpy</a>, in
concert with <a href="http://github.com/dolthub/dolt">Dolt</a>, is to solve
reproducibility and versioning problems for data and machine
learning engineers using Python.</p>
<h2>Mypy</h2>
<p>Mypy was created by Guido van Rossum, the primary developer of the
Python language, as a way to apply
<a href="https://www.python.org/dev/peps/pep-0008/">PEP standards</a> to Python source
code. When lines of code are added to the Python core libraries,
their respective mypy stubs are updated lockstep.</p>
<p>So when we fix mypy errors we are enforcing rules of the Python type system.
This point is subtle but important: mypy errors when your code is not doing
what you've declared it should do. Static checking can't anticipate what
input your code will be fed at runtime, but as a developer you can write
code that is self-consistent with function and type signatures.</p>
<p>Adding type-hints without enforcement is a common anti-pattern.
Mypy is separately installed from Python and its typing modules -- it
is up to the developer to actually validate type-hints after adding them.
Code with contradictory typing documentation can mislead
developers and users alike. Mypy is that bridge between type-aesthetics
and type-correctness.</p>
<p>Mypy involves three main modules:</p>
<ul>
<li><a href="https://github.com/python/mypy">mypy</a>: A source code parsing and
applying PEP constraints.</li>
<li><a href="https://github.com/python/typeshed">typeshed</a>: Type-stubs core and
3rd party libraries; code whose implementations are
correctness-checked when used in new code.</li>
<li><a href="https://github.com/python/typing">typing</a>: Modules for compatibility
between python versions.</li>
</ul>
<p>All three of these modules are regularly used when using mypy (<code>typing</code>
less so if you only suport one Python version). One addendum is that you
can define custom type stubs in your own code, in the same manner <code>typeshed</code>
provides type stubs for popular pip packages, like
<a href="https://github.com/python/typeshed/tree/master/stubs/boto/boto">boto</a>
and
<a href="https://github.com/python/typeshed/tree/master/stubs/requests/requests">requests</a>.</p>
<h2>Examples</h2>
<h3>Typing inconsistency</h3>
<p>We use <code>mypy</code> in Doltpy 2.0 to help ensure code-quality. Below is an
an example from Doltpy 1.0 to demonstrate mypy in action:</p>
<div data-language="python"><pre><code><span>def</span> <span>log</span><span>(</span>self<span>,</span> number<span>:</span> <span>int</span> <span>=</span> <span>None</span><span>,</span> commit<span>:</span> <span>str</span> <span>=</span> <span>None</span><span>)</span> <span>-</span><span>&gt;</span> OrderedDict<span>:</span>
    args <span>=</span> <span>[</span><span>"log"</span><span>]</span><span>:</span>
    <span>if</span> number<span>:</span>
        args<span>.</span>extend<span>(</span><span>[</span><span>"--number"</span><span>,</span> number<span>]</span><span>)</span></code></pre></div>
<p>Inside the <code>log</code> function signature, <code>number: int</code> correctly reflects the developer intent,
but <code>args: List[str]</code> disallows integers. This means that calling <code>Dolt.log(1)</code>
fails with an error, while <code>Dolt.log("1")</code> succeeds.</p>
<p>The intended behavior is clear, and mypy preemptively notices the inconsistency:</p>
<div data-language="bash"><pre><code><span>&gt;</span> python -m mypy <span>.</span>
example.py:4: error: List item <span>1</span> has incompatible <span>type</span> <span>"int"</span><span>;</span> expected <span>"str"</span></code></pre></div>
<p>fixing the type inconsistency restores the expected behavior:</p>
<div data-language="python"><pre><code><span>def</span> <span>log</span><span>(</span>self<span>,</span> number<span>:</span> <span>int</span> <span>=</span> <span>None</span><span>,</span> commit<span>:</span> <span>str</span> <span>=</span> <span>None</span><span>)</span> <span>-</span><span>&gt;</span> OrderedDict<span>:</span>
    args <span>=</span> <span>[</span><span>"log"</span><span>]</span><span>:</span>
    <span>if</span> number<span>:</span>
    args<span>.</span>extend<span>(</span><span>[</span><span>"--number"</span><span>,</span> <span>str</span><span>(</span>number<span>)</span><span>]</span><span>)</span></code></pre></div>
<p>and makes mypy happy:</p>
<div data-language="bash"><pre><code><span>&gt;</span> python -m mypy <span>.</span>
Success: no issues found <span>in</span> <span>1</span> <span>source</span> <span>file</span></code></pre></div>
<h3>Custom typing stub</h3>
<p>As a final example, here are first few lines for a custom type stub of the
<code>doltpy.cli.Dolt</code>
<a href="https://github.com/dolthub/doltpy/blob/master/doltpy/types/dolt.py%5D">class</a>
in doltpy:</p>
<div data-language="python"><pre><code><span>class</span> <span>DoltT</span><span>(</span>Generic<span>[</span>_T<span>]</span><span>)</span><span>:</span>
    _repo_dir<span>:</span> <span>str</span>

    <span>@abc<span>.</span>abstractmethod</span>
    <span>def</span> <span>repo_dir</span><span>(</span>self<span>)</span><span>:</span>
        <span>.</span><span>.</span><span>.</span>

    <span>@staticmethod</span>
    <span>@abc<span>.</span>abstractmethod</span>
    <span>def</span> <span>init</span><span>(</span>repo_dir<span>:</span> Optional<span>[</span><span>str</span><span>]</span> <span>=</span> <span>None</span><span>)</span> <span>-</span><span>&gt;</span> <span>"Dolt"</span><span>:</span>  
        <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>After defining <code>class Dolt(DoltT)</code>, mypy will enforce our interface
the same way mypy enforces standard library and other 3rd party type
stubs. As a plus, code editors like VSCode should also give hints for
function signature definitions.</p>
<h2>Summary</h2>
<p>In this post I touched on the utility of using type-hints
with mypy, and the comparative pitfalls of using type-hints without.
We used specific examples from Doltpy to highlight the nature
of static type-checking, and how we use mypy in production at Dolthub.</p>
<p>Are you interested in learning more about Dolt and Doltpy?
<a href="https://docs.dolthub.com/getting-started/installation">Try it out</a>.
If you have any questions, come chat with us in our
<a href="https://discord.com/invite/RFwfYpu">Discord</a>.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2021-02-22-mypy-and-doltpy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232204</guid>
            <pubDate>Mon, 22 Feb 2021 23:49:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Guy Making a Million a Year Delivering Cookies to His Hood]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26232139">thread link</a>) | @freakandgeek
<br/>
February 22, 2021 | https://businessideas.ai/food-delivery/ | <a href="https://web.archive.org/web/*/https://businessideas.ai/food-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h3 id="a-deep-dive-on-opportunities-in-the-food-delivery-space"><em>A Deep Dive on Opportunities in the Food Delivery Space</em></h3><p>In this crazy Covid world we have seen the acceleration in delivery businesses and food is no different.</p><p>Of course by now you have probably heard about <a href="https://www.doordash.com/en-US">DoorDash</a>, <a href="https://www.grubhub.com/">GrubHub</a>, <a href="https://www.ubereats.com/">Uber Eats</a> and the like, but what if I told you there are tons of opportunities for us regular non-venture backed folk to also get in on this action?</p><p><em>Would you be interested?</em></p><p>Let's dig into this deeper.</p><h2 id="from-bc-to-ac">From BC to AC</h2><p>As you have probably personally experienced, it can be hard (or even impossible) to go out to eat like back in the good old BC days (<em>Before Covid</em>).</p><p>Drive through restaurants, take-out and delivery businesses have been propelled into accelerating growth as a result.</p><p>You should see the daily lines at my local Chick Fil-A. It is absolutely bonkers.</p><figure><blockquote><p lang="en" dir="ltr">I just waited in line at chick-fil-a for about 30 mins. <a href="https://t.co/I2gx9PeBxA">pic.twitter.com/I2gx9PeBxA</a></p>— Natisha Lance (@NatishaLance) <a href="https://twitter.com/NatishaLance/status/1360760913679286275?ref_src=twsrc%5Etfw">February 14, 2021</a></blockquote>

</figure><p>Despite the passing of time and new vaccines — masks, social distancing, and a limited public discourse lifestyle are still norms in many parts of the world.</p><p>In fact Dr. Fauci says we need to wear masks through 2022 and the CDC is now <a href="https://www.cbsnews.com/news/double-face-mask-covid-19-cdc/">actually suggesting wearing two masks</a>.</p><figure><blockquote><p lang="en" dir="ltr">Dr. Fauci says it's possible Americans will need to wear masks in 2022 even as the US may reach "a significant degree of normality" by year's end<a href="https://t.co/XLRwWIPMC9">https://t.co/XLRwWIPMC9</a> <a href="https://t.co/B3ntTpsKDH">pic.twitter.com/B3ntTpsKDH</a></p>— CNN Breaking News (@cnnbrk) <a href="https://twitter.com/cnnbrk/status/1363521124089294849?ref_src=twsrc%5Etfw">February 21, 2021</a></blockquote>

</figure><p>This trend will stick for some time. You may as well profit off of it.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/crave-cookie.jpg" alt="Crave Cookie is Making Bank"></figure><h2 id="local-delivery-businesses-are-making-the-dough">Local Delivery Businesses are Making the Dough</h2><p>Would you imagine that a small family business of just a few handful of employees in a small California town selling nothing but two types of cookies is a million dollar business?</p><p>This is not science fiction. It is a reality.</p><p><a href="https://cravecookie.com/">Crave Cookie</a> is that business.</p><p>They have a very simple business model that you can replicate in your town. Let's walk through some of the things Crave Cookie has done that shows how this can be a <a href="https://businessideas.ai/business-ideas/">great business idea</a>.</p><p>Crave Cookie always has chocolate chip cookies and just one additional flavor of the week. Even a one person business could pull that off. It is inspiring to realize that huge menus are not needed to be a million dollar business.</p><p>Interestingly even after achieving huge success, they still have stuck with the two choices only model.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/crave-pricing.png" alt="Crave Cookie Pricing"></figure><h3 id="smart-pricing-strategy">Smart Pricing Strategy</h3><p>You cannot just order one cookie from Crave as they sell <strong>boxes of cookies only</strong>. So the minimum order is $13.</p><p>They also charge for delivery with a reasonable price that does not feel like gouging. Also interestingly they point out:</p><blockquote>"We charge a flat $3.0 delivery fee whether you order 1 box or 100."</blockquote><p>So there is plenty of motivation for larger orders as the delivery fee feels close to free.</p><h3 id="special-sauce">Special Sauce</h3><p>If cookies delivered to your door is not enough of a differentiator, Crave also advertises that they deliver <strong>straight out of the oven</strong> and thus your cookies will <strong>arrive warm</strong>.</p><p>Can't you just about taste that?</p><p>This is a smart <em>special sauce ninja move</em>. Who does not dream of warm cookies delivered to their doorstep?</p><h2 id="similar-cookie-delivery-companies">Similar Cookie Delivery Companies</h2><p>If you want to dig into this model some more, there are a few interesting companies to check out:</p><ul><li><a href="https://insomniacookies.com/">https://insomniacookies.com</a></li><li><a href="https://www.cookiedelivery.com/">https://www.cookiedelivery.com</a></li><li><a href="https://www.midnightcookieco.com/">https://www.midnightcookieco.com</a></li></ul><h2 id="getting-started">Getting Started</h2><p>Some extra considerations about this business model:</p><ul><li>There are special local laws related to selling food. Research and understand these in depth before doing anything else.</li><li>Start by selling in your own neighborhood. 1) This is easier to network, spread the word, and gather feedback &amp; 2) Your deliveries are easily done.</li><li>Use <a href="https://nextdoor.com/">Nextdoor</a> and Facebook Marketplace to market your services and get the word out.</li><li>Do you have a special family recipe that would do well as a delivery service?</li></ul><h3 id="crave-cookie-media-for-further-study">Crave Cookie Media for Further Study</h3><p><em>Writing Code to Sell $200,000/Month of Cookies with Sam Eaton of Crave Cookie</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/-CpVIetacIM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p><em>Valley fans crave cookies, company expands</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/2GX4OME_g64?start=7&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="airbnb-food-service-model">Airbnb Food Service Model</h2><p>Another new wrinkle we have seen recently is what I call the <em>Airbnb food service model</em> (people in the know call these <a href="https://roaminghunger.com/blog/15623/ghost-kitchens-everything-you-must-know/">Ghost Kitchens</a>.)</p><p>Imagine selling millions of burgers to customers without having a kitchen, buying any beef, or having any employees?</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/mrbeast-burger.jpg" alt="The current menu at Mr Beast Burger"></figure><h3 id="introducing-mrbeast-burger">Introducing MrBeast Burger</h3><p>MrBeast in case you are unaware, is a <a href="https://www.youtube.com/channel/UCX6OQ3DkcsbYNE6H8uQQuVA">hugely popular YouTuber</a> with over 50 million subscribers.</p><p>MrBeast Burger launched with 300 locations. That would cost billions you say! How did they do it?</p><p>MrBeast Burger has their burgers made by partnering restaurants and they leverage local delivery networks to deliver the orders.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/mrbeast-app.jpg" alt=""><figcaption>MrBeast Burger App</figcaption></figure><p>They simply provide the ordering front end with their app and the traffic based on MrBeast's gigantic popularity and marketing skills.</p><p>Just like Airbnb does not make beds or own any real estate — MrBeast owns no cows or flips any burgers.</p><p>Obviously few of us have the kind of reach to pull anything like this off. MrBeast Burger is selling nearly one million $$$ of burgers a month on the foundation of his huge audience.</p><p>But this is such a fascinating example of a creative and wildly successful food business, we had to cover that here.</p><p><em>I Opened A Restaurant That Pays You To Eat At It</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/dg2Ag3e8W-Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p><em>Food Theory: MrBeast Burger Is NOT What You Think...</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/uNLwgYG4EdA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p><em>How MrBeast Makes $720,000/Month Dropshipping Burgers</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/K3OuI9E0-EA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="food-subscription-businesses">Food Subscription Businesses</h2><p>Subscription box businesses are not new and maybe the business model has even peaked — at least before Covid turned many into remote workers who rarely leave the house (<em>and thus buy more online</em>).</p><p>But subscription food businesses are worth mentioning as a consideration —especially as a possible side hustle.</p><p>Since this model is already around a decade old you will need to consider that the riches are in the niches. Do something unique and do it with some panache.</p><p>Consider for example that there are already at least a dozen <em>beef jerky subscription boxes</em>, so starting another one of those would be questionable decision making. </p><p>Picking food products for your subscription business like nothing else in existence ensures less competition.</p><h2 id="have-you-ever-tried-japanese-candy">Have You Ever Tried Japanese Candy?</h2><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/candy-japan.jpg" alt="Candy Japan Homepage"></figure><p>A good example of this is <a href="https://www.candyjapan.com/">Candy Japan</a>. Over the years this side project has sold about one million $$$ of Japanese candy.</p><p>In the beginning the business gathered a lot of interest and business mostly based on the utter uniqueness of the offering.</p><p>But with time the word gets out and now there are a few Japanese candy subscription box competitors out there (<a href="https://tokyotreat.com/">https://tokyotreat.com</a>, <a href="https://japancrate.com/">https://japancrate.com</a>, &amp; <a href="https://www.japancandybox.com/">https://www.japancandybox.com</a> to name a few)</p><p>Still even after several years — this is a profitable side project the owner says <a href="https://www.candyjapan.com/life-in-japan/what-it-costs-to-live-in-japan">covers most of his living expenses in Japan</a>.</p><p>If you can find an untapped niche, this could be a nice earning side business for someone. Just pick an interesting and unique food item.</p><p>CBD brownies anyone?</p><h3 id="more-about-candy-japan">More About Candy Japan</h3><ul><li><a href="https://www.starterstory.com/stories/starting-a-japanese-candy-subscription-service?upgrade=true&amp;successful_subscribe=true&amp;src=email_wall">Starting A Japanese Candy Subscription Service</a></li><li><a href="https://www.candyjapan.com/blog">Candy Japan Blog</a> (<em>plenty of insights on marketing efforts and other hindsights in running the business</em>)</li></ul><h3 id="one-more-thing-about-subscription-box-businesses">One More Thing about Subscription Box Businesses</h3><p>In one word...recurring revenue. Recurring revenue is a beautiful thing to the entrepreneur, as you can accurately predict your monthly revenue stream. This makes planning, marketing, and other elements of your business easier. You know what your revenues are going to be and usually can predict your growth as well.</p><p>This is the same reason why the Software as a Service (SaaS) model is so valuable and loved. Subscription box business are almost like SaaS for people who cannot code.</p><h2 id="selling-food-on-etsy-is-actually-a-thing">Selling Food on Etsy is Actually a Thing</h2><p>I don't know about you, but I just learned about how big food selling was on Etsy.</p><p>It makes sense to me now, but it blows my mind how much food selling is going on there. Just <a href="https://www.etsy.com/search?q=brownies">do a search on "brownies"</a> and you will see what I mean.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/etsy-brownies.jpg" alt="Etsy Brownies"><figcaption>You get a brownie, and you, and you!</figcaption></figure><p>What is great about this is you could use Etsy for quick (and cheap!) experiments for gathering market intelligence. You could get answers on:</p><ul><li>What foods are popular to buy online?</li><li>What photos work best to drive orders?</li><li>What categories are the most successful?</li><li>What copy is most effective to sell my food item?</li></ul><h3 id="how-to-dominate-a-crowded-market-be-different-be-bold">How to Dominate a Crowded Market? Be Different, Be Bold</h3><p>As you can see there are a ton of brownie sellers on Etsy. But I found one seller who has sold well over $100K worth of treats.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/dulce-baskets.jpg" alt=""></figure><p>Selling brownie gift baskets of close to $100 is a good way to increase your profit and sales volume. This is a separator from the pack that are mostly selling one batch of brownies at a time.</p><p>These make a unique gift for your favorite chocolate lover — whereas a simple batch of brownies is not exactly making a statement.</p><h3 id="more-on-etsy-food">More on Etsy Food</h3><figure><a href="https://www.etsy.com/legal/policy/food-and-edible-items/239327355460"><div><p>Food and Edible Items - Our House Rules | Etsy</p><p>Find the perfect handmade gift, vintage &amp; on-trend clothes, unique jewelry, and more… lots more.</p><p><img src="https://www.etsy.com/images/favicon.ico"></p></div><p><img src="https://i.etsystatic.com/11266858/d/il/c8a5e3/2871445103/il_340x270.2871445103_ot9g.jpg?version=0"></p></a></figure><h2 id="join-us-for-more">Join Us for More</h2><p>Because you liked this report — please <a href="https://businessideas.ai/#/portal/signup">become a Business Ideas subscriber</a>.</p><p>Continue getting more insights on interesting &amp; powerful business ideas to take your life to the next level.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/business-ideas-logo-512-2.png" alt=""></figure>
                        <section>
                            <h2>Enjoying these posts? Subscribe for more</h2>
                            
                            <br>
                            
                        </section>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://businessideas.ai/food-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232139</guid>
            <pubDate>Mon, 22 Feb 2021 23:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional vs. OO: The Debate That Imprecise Language Destroyed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26232049">thread link</a>) | @BerislavLopac
<br/>
February 22, 2021 | https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/ | <a href="https://web.archive.org/web/*/https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

			<!-- #masthead -->

			<div id="content">

	<section id="primary">
		<main id="main" role="main">

		
			<article id="post-8919">
	
	
		

	<div>
		<p><span><span>Reading Time: </span> <span>7</span> <span>minutes</span></span></p><h3>“Should I use functional or object-oriented programming?”</h3>



<p>A student asked me this as I closed out one of my Python Programming lectures in January.  In this context, the student meant “what should I use for my upcoming homework assignment,” but I didn’t realize that at first. On <em>most</em> occasions when I hear this question—usually in professional circles—the unspoken subtext is “always.” <em>Which of these two styles should I swear by as <strong>the</strong> right way to write code?</em> </p>



<p> A second later, the student clarified “…on this assignment, I mean.”</p>



<p>Too little, too late. My gears were already turning.</p>



<div><div>
<div><div>
<div><div>
<h3>This is the first in what will be a two-part series:</h3>



<ol><li><strong>Words Mean Things (this post)</strong></li><li>But actually, how do you choose what to use?</li></ol>




</div></div>
</div></div>
</div></div>



<h3>The Functional/OO debate has, in my view, two big problems.</h3>



<ol><li><strong>The “all or nothing” assumption.</strong> I have a colleague who wants all his code to be functional code, full stop. I also have two former colleagues who swear by, and I quote, “lots of little objects.” I don’t fall into either camp because I think there are better questions than “<em>which of these two tools should I use <strong>always</strong>,” </em>with more insightful answers that have more potential to make us better programmers.</li><li><strong>Absolute terminological butchery.</strong> We have these two terms: “functional” and “object-oriented”, that we use interchangeably with other would-be synonyms, except that they don’t describe the same thing. And what’s with the fact that “functional” is just “functional” and “object” has “-oriented” tacked onto the end? Why isn’t it opposite “function-oriented?” We’re <em>super</em> imprecise about the way we discuss these ideas, and then we make new programmers feel stupid because they cannot picture the leaping triple-axle we <em>obviously meant</em> to perform when what we <em>actually</em> did was slip and fall on the ice. </li></ol>



<div><figure><a href="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?ssl=1"><img data-attachment-id="8945" data-permalink="https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/ice-skate-fail/" data-orig-file="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?fit=480%2C360&amp;ssl=1" data-orig-size="480,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ice-skate-fail" data-image-description="" data-medium-file="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?fit=480%2C360&amp;ssl=1" loading="lazy" width="480" height="360" src="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?resize=480%2C360&amp;ssl=1" alt="" srcset="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?w=480&amp;ssl=1 480w, https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 480px) 100vw, 480px" data-recalc-dims="1"></a><figcaption>Actual footage of a programming lecture that ends with a SEGFAULT and “well, you all understand the intuition anyway”</figcaption></figure></div>



<p>This grinds my gears to nubbins: the way we teach, instruct, and describe in lazy, platitudinous, imprecise ways, and then suggest that some people just aren’t smart enough to get it. </p>



<h3>So I got angry and tried to fix it. </h3>



<p>Here’s a video explanation. The explanation references Python because I recorded it with my Python students top-of-mind. That said, Python also serves as a useful model language for discussing this topic. </p>



<figure><div>
<p><span><iframe width="723" height="407" src="https://www.youtube.com/embed/HfEM1MKfwFw?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
</div><figcaption>Yes, I made sure it has captions.</figcaption></figure>



<p>If you don’t want to watch me scream and gesticulate while my off-kilter bowtie tragically shortens my neck for the camera, you can see a more language-agnostic version of the point I’m making here in the text below.</p>



<h3 id="So-first-of-all">So first of all</h3>






	
	


<p>Let’s talk about terminology, because there’s a massive lack of precision on this floating around the programming community, and it makes these concepts harder to understand than they have to be.</p>



<h3 id="What-is-a-Paradigm?">What is a Paradigm?</h3>



<p>Let’s talk about two different&nbsp;<strong>paradigms</strong>: different ideas about&nbsp;<strong>how</strong>&nbsp;solving a programming problem can work.</p>



<ol><li><strong>imperative</strong>: describes a way of thinking about a programming problem. Specifically, thinking about a programming problem in terms of how to perform tasks and how to manage state</li><li><strong>declarative</strong>: describes a way of thinking about a programming problem. Specifically, thinking about a programming problem in terms of what&nbsp;<em>output</em>&nbsp;we want, without having to know the details of how we got there.</li></ol>



<p>Different programming languages adopt each of these to different degrees.</p>



<p>For example, in Ruby, when you want to write a web app, you inherit from classes (usually defined by a framework like Rails or Sinatra) that are specifically designed to help you keep track of&nbsp;<em>state</em>&nbsp;(database records, attributes on objects) and&nbsp;<em>behavior</em>&nbsp;(which requests are supposed to route to what actions).</p>



<p>By comparison, in SQL, you write a statement declaring what data you want out of the database and how you want it organized. SQL decides for you how to get the thing you want—whether to use indices, what order to do things in, et cetera—without bothering you to specify that information.</p>



<h3 id="How-do-we-implement-the-paradigms?">How do we implement the paradigms?</h3>



<p><strong>Chiefly, programming languages&nbsp;<em>implement</em>&nbsp;these two paradigms with object-based implementations or function-based implementations</strong>.</p>



<ol><li><strong>object-based</strong>: describes the implementation of a solution in code. Specifically, a solution that depends on the instantiation of, use of, and inheritance from objects.</li><li><strong>function-based</strong>: describes the implementation of a solution in code. Specifically, a solution that depends on the definition of, use of, and passing of functions to functions.</li></ol>



<p>These are not the only ways to implement the paradigms. Huge, common example: SQL is largely not a functional language. You aren’t passing functions around to functions. But it does implement the declarative&nbsp;<em>paradigm</em>. The paradigms and the implementations are not equivalent things.</p>



<h3 id="What-does-&quot;oriented&quot;-mean?">What does “-oriented” mean?</h3>



<p><strong>When a programming language is&nbsp;<em>oriented</em>&nbsp;in a certain direction, it means that the constructs available in that language loan themselves better to one implementation or the other.</strong></p>



<ul><li><strong>object-oriented</strong>: describes a programming language. Specifically, one whose constructs make&nbsp;<strong>object-based</strong>&nbsp;solutions convenient to implement.</li><li><strong>functionally-oriented</strong>: describes a programming language. Specifically, one whose constructs make&nbsp;<strong>function-based</strong>&nbsp;solutions convenient to implement.</li></ul>



<p>Now, it is&nbsp;<em>possible</em>&nbsp;(though kinda difficult) to make a language that&nbsp;<em>only</em>&nbsp;supports&nbsp;<em>one</em>&nbsp;type of solution. Haskell is pretty close to a&nbsp;<strong>functional</strong>&nbsp;language. Alloy is pretty close to an&nbsp;<strong>object</strong>&nbsp;language. However, the utility of a language drops off pretty fast if it&nbsp;<em>only</em>&nbsp;does one or the other because both are at least a&nbsp;<em>little</em>&nbsp;useful in most programming areas. So&nbsp;<strong>-oriented</strong>&nbsp;means “one is more convenient, but you can kinda do both.”</p>



<p>Colloquial terminology butchers this by referring to functionally oriented languages as “functional” and languages that are oriented either way as “multi paradigm” despite the fact that the&nbsp;<em>paradigm</em>&nbsp;is an&nbsp;<em>idea</em>, not an&nbsp;<em>implementation</em>, that a programming language does not have a&nbsp;<em>paradigm</em>, and that a language is <em>X-oriented</em> already denotes that it supports multiple implementation strategies.</p>



<p>(I firmly believe that the reason that this functional vs. OOP idea is so hard for people is that we use the same term to mean six different things, two of which are sometimes opposites.)</p>



<p>I found this chart to provide a visual, but it&nbsp;<em>also</em>&nbsp;butchered the terminology, so I fixed it:</p>



<figure><a href="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?ssl=1"><img data-attachment-id="8927" data-permalink="https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/functional_vs_oo/" data-orig-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?fit=1272%2C838&amp;ssl=1" data-orig-size="1272,838" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="functional_vs_oo" data-image-description="" data-medium-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?fit=300%2C198&amp;ssl=1" data-large-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?fit=723%2C477&amp;ssl=1" loading="lazy" width="723" height="477" src="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?resize=723%2C477&amp;ssl=1" alt="" srcset="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?resize=1024%2C675&amp;ssl=1 1024w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?resize=300%2C198&amp;ssl=1 300w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?resize=768%2C506&amp;ssl=1 768w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?w=1272&amp;ssl=1 1272w" sizes="(max-width: 723px) 100vw, 723px" data-recalc-dims="1"></a><figcaption>Original image from&nbsp;<a rel="noreferrer noopener" href="https://docs.microsoft.com/en-us/dotnet/standard/linq/functional-vs-imperative-programming#:~:text=Functional%20programming%20is%20a%20form,support%20imperative%20(procedural)%20programming." target="_blank">here</a>,&nbsp;but I had to annotate it to fix the terminology.</figcaption></figure>



<h3 id="Python-is-an-object-oriented-language.">Python is an object-oriented language.</h3>



<p>People will argue with me on this point that Python is “in fact, dual-paradigm.” I disagree for reasons that you are now intimately familiar with. Python is object-oriented. You&nbsp;<em>can</em>&nbsp;do functional programming in it. It is designed, however, to prioritize object-based programming. BDFL Guido Van Rossum has said this himself on several occasions (<a href="https://python-history.blogspot.com/2009/04/origins-of-pythons-functional-features.html">here, straight from the horse’s mouth, don’t @ me</a>). So far the core team has not reversed any of the major technical decisions driven by that point of view. </p>



<p>I would also argue that Python is not only <em>not at all unique</em> in its support for multiple paradigms, but also <em>a far cry from the most graceful language</em> at supporting multiple paradigms. This is fine: as I mentioned, the design goals of the language have never included functional support, or even grace in general (<a href="https://chelseatroy.com/2021/01/31/why-learn-python/">see here, we talked about this</a>). But like, when people get on a high horse about this, please don’t be taken in.</p>



<h3>Fine, Chelsea. Anyway, which one should I use?</h3>



<p>Functional programming.</p>



<p>I’m kidding: based on the fact that we just spent a thousand words getting clear on what we’re even <em>talking</em> about, you’d be right to predict that my answer to this question has a lot more nuance than that. Meanwhile, though, I try to keep things pithy and digestible around here. So we’ll call it a night and dig into the “what to use” question in the next post.</p>



<h3>If you liked this piece, you might also like:</h3>



<p><a href="https://chelseatroy.com/2021/01/14/quantifying-technical-debt/">The last time I just absolutely snapped on imprecise terminology in tech</a> (on this occasion about “technical debt”)</p>



<p><a href="https://chelseatroy.com/category/programming/programming-concepts/debugging/">The debugging category</a>&nbsp;(people seem to like this and struggle to find similar content elsewhere)</p>



<p><a href="https://chelseatroy.com/2020/11/30/rubyconf-workshop-analyzing-risk-in-a-software-system/">The risk analysis workshop</a>&nbsp;(4 out of 5 “Jimi Hendrix of [insert programming language here]”s approve!)</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article><!-- #post-## -->

			
<!-- #comments -->

		
		</main><!-- #main -->
	</section><!-- #primary -->

	<!-- #secondary -->

	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232049</guid>
            <pubDate>Mon, 22 Feb 2021 23:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robert’s Rules Suck: Why We Can’t Make Change Until We Change the System]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 34 (<a href="https://news.ycombinator.com/item?id=26231837">thread link</a>) | @sep_field
<br/>
February 22, 2021 | https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f | <a href="https://web.archive.org/web/*/https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><h2 id="99a2">Why We Can’t Make Change Until We Change the System</h2><div><div><div><div><a href="https://martywilder-44820.medium.com/?source=post_page-----47b689f3c48f--------------------------------" rel="noopener"><div><p><img alt="Marty Wilder" src="https://miro.medium.com/fit/c/96/96/0*bbAuchMAUj_x330g" width="48" height="48"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Close up of a judge’s gavel on the block" src="https://miro.medium.com/max/19200/1*xqElYYwIds8NChYEdGxH7Q.jpeg" width="9600" height="5304" srcset="https://miro.medium.com/max/552/1*xqElYYwIds8NChYEdGxH7Q.jpeg 276w, https://miro.medium.com/max/1104/1*xqElYYwIds8NChYEdGxH7Q.jpeg 552w, https://miro.medium.com/max/1280/1*xqElYYwIds8NChYEdGxH7Q.jpeg 640w, https://miro.medium.com/max/1400/1*xqElYYwIds8NChYEdGxH7Q.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*xqElYYwIds8NChYEdGxH7Q.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@bill_oxford?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Bill Oxford</a> on <a href="https://unsplash.com/s/photos/gavel?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Unsplash</a></figcaption></figure><h2 id="b772">Taking Action</h2><p id="0a32">I was ready to do more than take a knee or carry a cardboard sign. I felt like it was time for me to move beyond protesting and get involved, somehow, in creating change. That was why I joined an ad hoc committee formed by our city council to address police policy. Think global, act local. At last, I felt hope. I felt like maybe I can make a difference that matters. And then I faced reality, and was shocked by how bad it is.</p><p id="9857">I was not naïve going into this. I fully expected that whatever good policy change our committee was able to craft might be diluted or rejected by the city council in the end, or that the Police Chief might find ways to circumvent them, or that even if enacted, the police union would still allow officers who violate those policies to be exonerated. With that in mind, I stayed focused on the long haul. I wanted to craft strong and demanding policies that could become part of a list of demands to be relentlessly rallied before the city officials until they are adopted. I kept my eye on forming alliances with others on the committee that could grow into lasting coalitions. This committee, to me, was only the beginning.</p><p id="8c03">It looked promising. The city had called on 13 civic organizations representing BIPOC and other marginalized communities. I was there on behalf of a nonprofit that services transgender and gender non-conforming folx. There are 30 members, in all. As we went through brief introductions at the first meeting, I was encouraged. The committee is facilitated by a team of three individuals, including a Black woman who is the Equity &amp; Access Coordinator for the county. She and I conversed at the outset about the challenges of facilitating a group the size of ours over Zoom due to the pandemic. We talked about setting group agreements. We talked about equity over equality and elevating voices that were underprivileged, especially those of women of color. I mentioned the need to give each member enough of a platform to feel seen and recognized at the beginning, even though that would be a big time investment, because it would save time in the long run by deterring potential internal conflicts. I also expressed my opinion that we would need to work in smaller subcommittees in order to be effective.</p><h2 id="b7ce">Thwarted by the System</h2><p id="ff5a">But then we ran into two great obstacles; public meetings law and Robert’s Rules of Order. The first curtailed our ability to network and converse with each other on the committee. The second is an infuriating silencer that obstructs everything I have come to learn about good problem-solving and decision-making. I’ll start with public records law because that is more straightforward. The law states that we must have a quorum, in our case 16 or more, of members present at each meeting. Each meeting must be posted and publicly broadcast in real time. Since we were airing our meeting over Zoom due to the pandemic, the meetings are live streamed and recorded. But because the live stream and recording do not show the chat box, we cannot use that feature to communicate things like consent with what the active speaker is saying, or to ask clarifying questions. It all has to be voiced to be recorded. Furthermore, since only the Zoom hosts can see non-verbal signs, we cannot use the raised hands nor the Yes/No functions built into Zoom. Instead we have to wait the three to four minutes it takes for the host to read off each of the 30 names, wait for the person to unmute, and get a recorded response with a “yes”, “no”, or “abstain” for every motion we attempt to pass. We have yet to do this without someone in the middle asking for the motion to be restated. I don’t think there is anyone involved who is not finding this irritating, but everyone seems resigned to endure it.</p><p id="7e09">The worst aspect of the way the city is interpreting public records law is that they have instructed all of us not to communicate with each other as a group outside of the public meetings. Email correspondence, file sharing, and social media can all become violations of public records law. If there are 16 or more of us involved, or even if there is not a quorum but we are discussing content that affects decision-making, it all needs to be publicly broadcast. While I can understand the reasoning behind these stipulations, where does that leave us? We are 30 members of very diverse parts of our city, we don’t know each other very well, and many of us have never served on a committee like this before. How are we supposed to work together? We have been reduced, effectively, to responding in the moment. We cannot even use file sharing to look at and consider ideas or share resources except by going through the facilitation team.</p><p id="ed4b">The facilitation team has directed us to send all communication to them and they will disperse information to the committee. That would be fine, if it were simply a procedure to go through. But the facilitation team does not simply pass along information. They hold onto it, decide whether or not it is information that should or should not be shared, sometimes rewrite or re-position it, and pack everything into one overwhelming information packet that we receive on Friday night before a Monday meeting. One reason behind this is that all the documentation must also be publicly posted alongside the meeting announcement. It also consolidates things so that committee members do not get bogged down with frequent emails. The danger is in editing out or misconstruing some of our voices, often those that most need to be heard. Also, there is the disabling effect of leaving us inactive and unable to work productively in the two weeks between meetings. I find myself struggling to resist the idea that the facilitation team has an expected outcome for us, and they are guiding the committee to meet their expectations.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="A laptop computer showing a large group of faces of people conferencing on a Zoom call. A coffee mug sits beside the laptop." src="https://miro.medium.com/max/3840/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg" width="1920" height="1440" srcset="https://miro.medium.com/max/552/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 276w, https://miro.medium.com/max/1104/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 552w, https://miro.medium.com/max/1280/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 640w, https://miro.medium.com/max/1400/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@cwmonty?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Chris Montgomery</a> on <a href="https://unsplash.com/s/photos/zoom-meeting?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Unsplash</a></figcaption></figure><h2 id="a8e4">Killing the Creativity</h2><p id="4127">Then we come to Robert’s Rules of Order. For those who are not familiar, this is a set of meeting protocols that dates back to before the Civil War. Basically, the facilitator calls on people to speak, one at a time, without interruptions for a given amount of time. In our meetings it is 3 minutes. When someone wants to propose a decision, they make a “motion”. Someone else must second that motion. Then the facilitator calls the vote. The motion, the person who presented it, the person who seconded it and the total numbers of votes: yes, no, and abstain, are all recorded. That’s it in a nutshell.</p><p id="9cee">What is missing from Robert’s Rules of Order is the magic of good problem-solving. There is no room for contained chaos, a free flow of energy, voices, and ideas. I taught engineering design in high schools for ten years. One of the most enjoyable, and innovatively genius, aspects of problem-solving is brainstorming. Brainstorming is meant to be messy. It’s a chance to air everything out and look at it from as many different angles as you can dream up. You start to notice patterns and connections. Someone poses something “crazy” and it piques your interest. Then there is this very important concept called “piling on.” Piling on happens when your idea sparks a new idea in my mind. I share my idea and that, in turn, sparks a new idea for someone else. This phase of problem-solving is divergent and for traditionalists, it goes against every fiber in their “we need to narrow this down” trajectory. But the traditional “narrowing down” linear approach leads to very limited and narrow solutions. Whereas, the creativity and mutual discovery of the brainstorming process culminates in a kind of magical synthesis of ideas and approaches. The team then needs to choose what approach they want to take. It might be evident in a general idea that rises up out of the chaos in a way that is unifying and electrifying, which leads to a much smoother process as you narrow in on the solution. Or you may see two or three different approaches that you either need to choose between as a group, or make a choice to split up and try all of them. Besides being a good way to get fresh and, at times, brilliant ideas, brainstorming also results in better teamwork because everyone was able to contribute fully and feel seen, heard, and involved.</p><p id="5d12">But the public meeting format has no room for that. We can’t even utilize Zoom break-out groups because the public would need to see all of the break-out groups simultaneously. Here is where it becomes de-humanizing to me. There is no place to <em>form</em> ideas in the public meeting. Members are expected to <em>bring</em> ideas, pre-fabricated, and see how they hold up to a vote. I used to function like that, bringing my ideas to the table in a battle for the best articulated argument to slay all others and take the lead. Then I studied feminism. When you value the people and the process, everything changes. It’s no longer a contest to see who has the best idea. It becomes about the whole, all of us together as a group, facing a problem and learning from each other as we go. I don’t want to presume to bring a solution that will address everyone’s needs. I want to hear from others and I want my thoughts to be affected by those stories. I want our collective ideas to <em>become</em> as we meet. What if our government were like that? What if the premise was that no one has the answer going in, but if we all bring our perspectives together and listen to one another, the answer will take form out of the collective whole? I know. It sounds ludicrous given the extreme partisan attacks that happen all the time in our current system. But once you have experienced this kind of collective solution-making even on a small scale; it can make you a believer.</p><h2 id="778c">White Supremacy Playbook</h2><p id="1307">Robert’s Rules of Order and the general meeting protocols really do fall right in line with what we know about white supremacist culture. What I mean by this is that we value this methodology and purport …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f">https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f</a></em></p>]]>
            </description>
            <link>https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231837</guid>
            <pubDate>Mon, 22 Feb 2021 22:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scott Alexander vs. NYT: Meta-Analysis, Part 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26231449">thread link</a>) | @nabla9
<br/>
February 22, 2021 | https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2 | <a href="https://web.archive.org/web/*/https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.22.8"><div dir="ltr"><div><p id="viewer-foo"><span><a href="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-1" target="_blank" rel="noopener"><u>See here for Part 1</u></a>, including Scott Alexander, Fredrik DeBoer, Jacob Falkovich, and Elizabeth Spiers. </span></p><p id="viewer-lqhd"><span>Minor correction: rereading Jacob Falkovich's take and <a href="https://twitter.com/yashkaf/status/1362877478327435272" target="_blank" rel="noopener"><u>some of the things he's tweeted since</u></a>, I moved him a bit further left on the "Call To Action" axis (see end of this post).</span></p><h2 id="viewer-4hi0v"><span><a href="https://www.scottaaronson.com/blog/?p=5310" target="_blank" rel="noopener"><u><span>Article #5: Scott Aaronson</span></u></a></span></h2><p id="viewer-8luck"><span><span>(</span><a href="https://www.scottaaronson.com/blog/?p=5310" target="_blank" rel="noopener"><span><em><u>A grand anticlimax: The New York Times on Scott Alexander</u></em></span></a><span><em><u>,</u></em></span></span></p><p id="viewer-fool"><span><span>but I recommend you see also </span><a href="https://www.scottaaronson.com/blog/?p=5330" target="_blank" rel="noopener"><span><em><u>On standing up sans backbone</u></em></span></a><span>)</span></span></p><p id="viewer-art8b"><span><span>The NYT article about Scott may not have happened without Scott. No wait, Scott A. and Scott A. Wait! I mean, the piece about Scott Al. may not have happened without Scott Aa.</span></span></p><blockquote id="viewer-3oppr"><span><span>I spent many hours with Cade [Metz], taking his calls and emails morning or night, at the playground with my kids or wherever else I was, answering his questions, giving context for his other interviews, suggesting people in the rationalist community for him to talk to, in exactly the same way I might suggest colleagues for a quantum computing story. And then I spent just as much time urging those people to talk to Cade.</span></span></blockquote><p id="viewer-b07b1"><span><span>Scott Aa. had previously worked with Metz, and found him to be a trustworthy journalist; he had no reason to mistrust when Metz said he was interested in Rationalists and, in particular, why the community had gotten COVID so right when the rest of media/government was getting it so wrong. </span></span></p><p id="viewer-81kqf"><span><span>When the story came out (with no mention of the COVID angle, by the way), Scott Aa. was not pleased, and in his post he details 14 ways the story was misleading or wrong (up from </span><a href="https://astralcodexten.substack.com/p/statement-on-new-york-times-article" target="_blank" rel="noopener"><span><u>Scott Al.'s 4</u></span></a><span>). This, in spite of Scott Aa. having talked with Metz about all of these details, only to have the final piece end up missing the point about all of them.</span></span></p><blockquote id="viewer-dfp21"><span><span>The trouble with the NYT piece is not that it makes any false statements, but just that it constantly </span><em>insinuates</em><span> nefarious beliefs and motives, via strategic word choices and omission of relevant facts that change the emotional coloration of the facts that it </span><em>does</em><span> present. I repeatedly muttered to myself, as I read: “dude, you could make </span><em>anything</em><span> sound shady with this exact same rhetorical toolkit!”
...
[W]ere I ever tempted to bang my head and say, “dammit, I wish I’d told Cade X, so his story could’ve reflected that perspective”—well, the truth of the matter is that I </span><em>did</em><span> tell him X! It’s just that I don’t get to decide which X’s make the final cut, or which ideological filter they’re passed through first.</span></span></blockquote><p id="viewer-e0qo9"><span><span>He remains agnostic about how much of the bad piece was due to Metz, and how much was due to NYT editors. </span></span></p><p id="viewer-euamv"><span><span>In spite of being upset about what happened, Scott Aa. originally planned not to change his behavior with journalists in the future; in the end, he may have acted rationally based on the knowledge he had and could not have known that this would be the outcome. However, </span><a href="https://www.scottaaronson.com/blog/?p=5330" target="_blank" rel="noopener"><span><u>in a follow-up post</u></span></a><span>, he announces that he won't work with Metz again without some kind of explanation that sufficiently exonerates him. From one of the more rational non-Rationalists around, who updates very carefully and Bayesian-ly, this is a pretty strong statement.</span></span></p><blockquote id="viewer-8ev8a"><span><span>I now feel like to work with Metz again, even just on some quantum computing piece, would be to reward—and to be seen as rewarding—journalistic practices that are making the world worse...</span></span></blockquote><p id="viewer-64lu2"><span><span>Overall, Scott Aa. seems more upset than Scott Al. or Jacob or Elizabeth, but less upset than Freddie (from </span><a href="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-1" target="_blank" rel="noopener"><span><u>Part 1</u></span></a><span>).</span></span></p><p id="viewer-6j33u"><span><span><u>One Sentence Summary:</u> <em>The NYT article was bad, and people who contributed to it (including Scott Aa. himself) were misled into helping it be written; this seems to imply untrustworthy actors at the NYT, if not directly nefarious and bad-faith ones..</em></span></span></p><p id="viewer-cdl3m"><span><strong><em><span>(From here on I'm going back to calling Scott Alexander "Scott", not "Scott Al.")</span></em></strong></span></p><h2 id="viewer-bqnbm"><span><a href="https://www.piratewires.com/p/okay-fine-were-fighting" target="_blank" rel="noopener"><u><span>Article #6: Mike Solana</span></u></a></span></h2><p id="viewer-5jhpu"><span><span>(</span><a href="https://www.piratewires.com/p/okay-fine-were-fighting" target="_blank" rel="noopener"><span><em><u>Okay fine, we're fighting</u></em></span></a><span>)</span></span></p><p id="viewer-7t1db"><span><span>According to Mike, the NYT article is more of the same in an ongoing war between tech and media, which nobody wants to admit is an actual war.</span></span></p><blockquote id="viewer-3ijvs"><span>The endless cycle is thus: a hit is published, tech fights back, media fights back, tech fights back, the blue check media gang goes nuclear and accuses tech of targeted harassment for publicly commenting on the actual, literal words they are printing, mea culpa (“we’re all wrong here!”) and a prayer for peace. Then, it’s straight back to the garbage dump. 
<em>I hate it here</em>.</span></blockquote><p id="viewer-6imrc"><span>This piece isn't only on the SSC/NYT situation, but covers also several other recent skirmishes in this war (ignored here). It is all just routine now, a back and forth between two camps--something like Tech and Media--that hate and can't seem to abide one another. </span></p><p id="viewer-dvgl2"><span>Mike is not mad in particular about this piece because <em>this is just what NYT does</em>, and nobody should pretend to be surprised by it.</span></p><blockquote id="viewer-37k9f"><span><em>The New York Times</em> isn’t publishing one-off hit pieces. At least, in the narrow context of tech coverage, it is obvious many reporters at the <em>Times</em>, and across the press broadly, confuse the attention they receive for provoking controversy with righteous affirmation. They think, in general, they are doing good work — not just well-reported work, but <em>morally good</em> work...</span></blockquote><p id="viewer-eml9l"><span>While he stops short of fully supporting <a href="https://www.blocknyt.com/" target="_blank" rel="noopener"><u>#BlockTheNYT</u></a> (at least, he didn't explicitly update his stance <a href="https://www.piratewires.com/p/a-policy-of-truth-987" target="_blank" rel="noopener"><u>from a previous post</u></a>), he closes with skepticism of their credibility and good faith.</span></p><blockquote id="viewer-datei"><span>[F]ine, whatever, we’re in fight. We’re fighting. But let’s call it that... let’s dispel with the bullshit “objectivity” frame and robustly, openly disagree. We want different things, so what? You think you maybe kind of hate me, okay. Just do me a favor and tweet it.</span></blockquote><p id="viewer-20d0m"><span><u><em>One Sentence Summary</em></u>: <em>The NYT piece was bad in a way that most tech journalism is bad, because Media sees Tech as a threat; this is just the latest strike in a long-standing war between the two.</em></span></p><h2 id="viewer-936oa"><span><a href="https://noahpinion.substack.com/p/silicon-valley-isnt-full-of-fascists" target="_blank" rel="noopener"><u><span>Article #7: Noah Smith</span></u></a></span></h2><p id="viewer-ct0b5"><span><span>(</span><a href="https://noahpinion.substack.com/p/silicon-valley-isnt-full-of-fascists" target="_blank" rel="noopener"><span><em><u>Silicon Valley isn't full of fascists</u></em></span></a><span>)</span></span></p><p id="viewer-3gqju"><span><span>In a smog of people decrying political partisanship with angry words, Noah is a breath of statistically-literate fresh air. His central thesis about the NYT article is clear:</span></span></p><blockquote id="viewer-724vg"><span>To put it bluntly, I think the article both draws on and feeds into the mistaken stereotype that Silicon Valley is full of right-wingers.</span></blockquote><p id="viewer-6fcvm"><span>Noah argues that the NYT imagines a world that looks like this:</span></p><div id="viewer-d2lvt"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img ariahidden="true" data-pin-url="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2" data-pin-media="https://static.wixstatic.com/media/28c66d_abdf245248e943eea02b4868c6af4d56~mv2.jpeg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.jpeg" src="https://static.wixstatic.com/media/28c66d_abdf245248e943eea02b4868c6af4d56~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div></div></div></div><p id="viewer-evq04"><span>When in reality it looks more like this:</span></p><div id="viewer-fb6dr"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img ariahidden="true" data-pin-url="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2" data-pin-media="https://static.wixstatic.com/media/28c66d_a0f2b64fc1524f3ba60c463d7e482986~mv2.jpeg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.jpeg" src="https://static.wixstatic.com/media/28c66d_a0f2b64fc1524f3ba60c463d7e482986~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div></div></div></div><p id="viewer-cme0n"><span>And the rest of his post looks at the data to show how Silicon Valley, SSC, and Rationalism are nothing like safe havens for right-wing politics.</span></p><p id="viewer-98de7"><span>1) <u>On Silicon Valley politics</u>:</span></p><blockquote id="viewer-eseom"><span>Though Silicon Valley founders tend to be more skeptical of regulation and unions than the average Democrat (as you might expect given their jobs), they are overwhelmingly Democrats. On social issues (gay marriage, abortion, gun control, etc.) they are much more liberal even than the average college-educated Democrat. They also strongly favor government redistribution, which you might think would go against their class incentives. And most importantly, they score <strong>lower on </strong><a href="https://en.wikipedia.org/wiki/Racial_resentment_scale" target="_blank" rel="noopener"><strong>racial resentment</strong></a> and lower on the authoritarianism scale than the average Democratic base voter. In short, <strong>tech entrepreneurs are standard liberal nerds</strong>.</span></blockquote><p id="viewer-3mhsp"><span>2) <u>On SSC politics</u>: SSC likely has no more than 10k readers, and <a href="https://slatestarcodex.com/2020/01/20/ssc-survey-results-2020/" target="_blank" rel="noopener"><u>only ~40% of his readership works in a tech-adjacent field</u></a>; on the other hand, there are nearly 400k tech workers in the San Francisco Bay Area.</span></p><blockquote id="viewer-6b1sh"><span>In other words, Slate Star Codex was almost certainly a niche interest within the tech industry.</span></blockquote><p id="viewer-44r49"><span>There's no way SSC is holding sway with anything like a majority of Silicon Valley, let alone Tech more generally.</span></p><p id="viewer-dug47"><span>3) <u>On Rationalist politics</u>:</span></p><p id="viewer-8v5rv"><span>Like SSC readers, Rationalists are not primarily in tech ("the <em>only</em> major Rationalist figure I could find who is actually <em>in</em> tech is Eliezer Yudkowsky, who is sort of an A.I researcher" (lol at "sort of")), but like Silicon-Valley-ites most public Rationalists have left-leaning politics. Based on Scott's complicated stances around e.g. BLM and feminism, Noah reluctantly gives him the label of "conservative". (Of course given that Scott is "<a href="https://slatestarcodex.com/2019/02/22/rip-culture-war-thread/" target="_blank" rel="noopener"><u>a pro-gay Jew who has dated trans people and votes pretty much straight Democrat</u></a>" and in 2016 <a href="https://slatestarcodex.com/2016/09/28/ssc-endorses-clinton-johnson-or-stein/" target="_blank" rel="noopener"><u>endorsed literally "anyone but Trump"</u></a>, I doubt he means "conservative" as in "right-wing" or "Trumpian".)</span></p><p id="viewer-f1k56"><span>Noah's upset to the extent that the NYT gets this general picture wrong, and he retorts with his own analysis of the relevant statistical facts. He doesn't appear to see this as part of any big failure mode in media, so no larger call to action is necessary.</span></p><p id="viewer-2otrq"><span><u><em>One Sentence Summary</em></u>: <em>The NYT piece is wrong in its broad picture of the relationship of Tech, Rationalism, and SSC readership.</em></span></p><h2 id="viewer-6356u"><span><a href="https://modelcitizen.substack.com/p/grey-lady-steel-man" target="_blank" rel="noopener"><u><span>Article #8: Will Wilkinson</span></u></a><span> </span></span></h2><p id="viewer-7l3sv"><span><span>(</span><a href="https://modelcitizen.substack.com/p/grey-lady-steel-man" target="_blank" rel="noopener"><span><em><u>Grey Lady Steel Man</u></em></span></a><span><em><u>,</u></em></span></span></p><p id="viewer-fh38"><span><span>but I recommend you see also </span><a href="https://www.youtube.com/watch?v=XcGyJQnpPas" target="_blank" rel="noopener"><span><em><u>his interview with Robert Wright</u></em></span></a><span>)</span></span></p><p id="viewer-2p4q4"><span><span>Will tells a decidedly different story than most others, because it is primarily told from the perspective of Cade Metz rather than Scott Alexander.</span></span></p><blockquote id="viewer-4mnkf"><span>Somebody tells Metz about SSC, he finds it really interesting, wants to write some kind of article...
Metz contacts Siskind and at some point he tells Scott that he already knows his real name and at some point Scott tells Metz it’s very important that he doesn’t use his real name...
Well, the <em>Times</em> won’t promise, so Siskind <em>actually does [burn SSC to the ground].</em> This seems super-crazy and the natural journalistic response to it is “What the hell is this man hiding? What’s he so afraid I’ll find on his blog?”</span></blockquote><p id="viewer-allr8"><span>Whatever Metz's piece was about before went immediately to the back-burner; he certainly must have taken Scott nuking is own blog as evidence of something much <em>much</em> more interesting. So he went digging. Scott himself notes that around this time, Metz "switched to interviewing everyone who hated me and asking a lot of leading questions about potentially bad things I did." SSC readers think this might be a sinister revenge plot, but a good journalist follows their nose, and Metz' smelled something fishy about this man who would insist on his anonymity at the expense of his entire body of work and hard-fought online following.</span></p><p id="viewer-5962p"><span>What did Scott have to hide, that he would give all that up to keep it under wraps? According to Will, this question--not Silicon Valley, not Rationalism--is the real topic of the NYT piece. </span></p><p id="viewer-66ckm"><span>And…</span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2">https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2</a></em></p>]]>
            </description>
            <link>https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231449</guid>
            <pubDate>Mon, 22 Feb 2021 22:20:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tianwen-1 Phasing Orbit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26231383">thread link</a>) | @parsecs
<br/>
February 22, 2021 | https://destevez.net/2021/02/tianwen-1-phasing-orbit/ | <a href="https://web.archive.org/web/*/https://destevez.net/2021/02/tianwen-1-phasing-orbit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9763">

	

	<div>
		
<p>Last Saturday 2021-02-20 at 11:46:42 UTC <a href="https://destevez.net/tag/tianwen/">Tianwen-1</a> passed the periapsis of its elliptical polar orbit at Mars and made a retrograde burn to reduce its apoapsis radius. The  trajectory planning of the spacecraft can be seen in its <a href="https://en.wikipedia.org/wiki/Tianwen-1">Wikipedia page</a>: the spacecraft first arrived into a low inclination elliptical orbit by making a <a href="https://twitter.com/ea4gpz/status/1359433349018882050">Mars orbit insertion</a> at periapsis, then coasted to apoapsis, where it performed a <a href="https://destevez.net/2021/02/tianwen-1-plane-change-planning/">plane change</a>, and then it arrived at periapsis, performing the manoeuvre described in this post.</p>



<p>Over the next few days the spacecraft should move into a reconnaissance orbit, which is given in Wikipedia to be a 265 x 60000 km orbit (having a period of 2 days) with an inclination of 86.9 degrees. However, the last burn hasn’t lowered the apoapsis that much. The current orbit is approximately 280 x 84600 km (3.45 day period) with an inclination of 87.7 degrees. A possible reason for using the current orbit, which has been described as a phasing orbit, will be explained in this post after reviewing the data we have about the burn.</p>



<p>As I usually do, to compute the moment and delta-V of the burn I propagate the pre-burn and post-burn trajectories in <a href="http://gmat.sourceforge.net/docs/">GMAT</a> using <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Tianwen/orbit/phasing_burn_vectors.script">this script</a>, and study the output in <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Tianwen/Tianwen-1%20phasing%20burn.ipynb">this Jupyter notebook</a>. I obtain an intersection at 11:44:18 UTC, which is pretty close to the periapsis passage, so the data seems correct.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection.png"><img width="644" height="341" src="https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection-644x341.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection-644x341.png 644w, https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection-300x159.png 300w, https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection.png 730w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The delta-V vector in m/s using the Mars body inertial frame described in <a href="https://destevez.net/2021/02/tianwen-1-mars-centric-state-vectors/" data-type="post" data-id="9635">this post</a> is</p>



<pre>[-1.477, -1.912, 52.565]</pre>



<p>This vector has a magnitude of 52.62 m/s. Assuming a dry mass of 2500 kg and fuel mass of 950 kg, this burn would have taken 60 seconds with the 3 kN thrusters, and spent 57 kg of fuel. Thus, according to our (somewhat crude) fuel estimates, approximately 900 kg of fuel remain now.</p>



<p>It is convenient to write the delta-V vector in the VNB frame whose axes are given by V, the velocity vector, N, the vector normal to the orbit (which is defined to point along the cross product of the radius and V), and B, the bi-normal vector, which is the cross product of V and N. The VNB coordinates in m/s are</p>



<pre>[-50.406,  0.032,  15.104]</pre>



<p>We see that most of the burn happens along -V as expected for a retrograde burn, but there is a significant component along +B. This is perhaps a bit unexpected. The effect of a +B burn is to move the periapsis backwards along the orbit, so that it would move to a slightly more northern latitude (the spacecraft descends from north to south on the periapsis passage). In fact, the periapsis has moved from a latitude of 10.03º N to a latitude of 10.25º N. This might be relevant for the discussion that comes below.</p>



<p>Now the good question is what is the reason for moving to this intermediate phasing orbit with a 3.45 day period instead of moving directly to the 2 day period orbit? I think there is a quite reasonable explanation, but we must first understand the purpose of the 2 day period reconnaissance orbit. This will be the orbit used by the spacecraft to map and survey the intended landing site, until the lander is released, which is expected to happen in May or June.</p>



<p>Therefore, it seems quite desirable to have an orbit whose periapsis ground track always passes over the landing site. This gives plenty of opportunities for gathering survey data and is also mandatory for the release of the lander, which is basically going to be done from the reconnaissance orbit (by first lowering its periapsis in a suitable manner). So all this makes me think that the quoted “2 day period” is actually 2 Mars sidereal days (a Mars sidereal day is 24 hours, 37 minutes and 22 seconds), since that would give a repeating ground track.</p>



<p>For this plan to work well, the periapsis of the the orbit needs to be at the correct longitude by the time that the 2 sidereal day orbit is entered. Otherwise the ground track will be repeating, but it will not pass over the landing site. Now, the longitude of the next periapsis of the current orbit turns out to be 111.3º E. In Wikipedia the coordinates of the intended landing site in <a href="https://en.wikipedia.org/wiki/Utopia_Planitia">Utopia Planitia</a> are given as 24.748º N, 110.318º E. Note that the latitude of the site is somewhat higher than the latitude of the periapsis of the current orbit, so perhaps moving the periapsis north is desirable. This might (but only might) be the reason for the burn component along B.</p>



<p>So we see that around the next periapsis, which is going to be tomorrow 2021-02-23 at 22:31:37 UTC, the spacecraft will pass above the landing site. Given this circumstance, it can now enter the 2 sidereal day reconnaissance orbit, which will then have a repeating ground track that always passes over the landing site.</p>



<p>There is no magic involved in these adjustments. Coming in from the previous orbit last Saturday, when arriving to the periapsis it is just enough to adjust the apoapsis altitude (and hence the orbit period) in such a way that when the spacecraft comes to the next periapsis Mars has rotated below the orbit so as to place the longitude of the landing site below the orbit. The required period to do this will depend on the (signed) difference between the longitude of the periapsis where the burn is performed and the longitude of the landing site. Therefore, the name “phasing orbit” is completely justified. The purpose of the current orbit would be to wait until the rotation of Mars places the landing site below the orbit.</p>



<p>To see what the passage to the 2 sidereal day orbit at next periapsis would look like, I have made this <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Tianwen/orbit/phasing_orbit.script">GMAT script</a>. By adjusting the delta-V of the periapsis burn, I have seen that a 40.9 m/s burn will give an orbit with a ground track that is very close to be repeating. This is shown in the figure below.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052.png"><img width="644" height="315" src="https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052-644x315.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052-644x315.png 644w, https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052-300x147.png 300w, https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052-768x376.png 768w, https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052.png 1350w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>2 sidereal day orbit, with ground track passing over the landing site</figcaption></figure>



<p>There is some degree of complication here regarding orbit perturbations. The plot above shows 14 days of ground track, and we see that at some point the ground track starts to slowly creep to the east. The propagator I’m using here is quite detailed: the 80×80 <a href="https://ui.adsabs.harvard.edu/abs/2001JGR...10623359L/abstract">GMM-2B</a> Mars gravity model, point mass forces for all planets and the Sun, relativistic effects, and an integration step of at most 50 seconds (no solar radiation pressure or atmospheric drag, though).</p>



<p>Something I haven’t understood completely is why the period of the orbit shown above is actually 162 seconds longer than two sidereal days. Forgetting about perturbations, the track of such an orbit would drift some 0.66 degrees to the west per revolution. However, if I try to adjust the orbit to have a period closer to 2 sidereal days, I get much more drift of the ground track than with this orbit solution. I don’t know if this is caused by perturbations or by numerical accuracy (perhaps related to the integrator). This is something that might deserve more in-depth study. In any case, probably the real-world orbit will need some degree of station keeping to correct for perturbations.</p>



<p>The apoapsis radius of this 2 sidereal day orbit is 61217 km (giving an apoapsis altitude of 57821 km), while the periapsis has an altitude of 282 km (logically, still close to the 280 km we started with on Saturday). Therefore, some care should be taken when quoting this as a 265 x 60000 km orbit. That can be slightly misleading, as it is not clear if 60000 km refers to the apoapsis radius or altitude.</p>



<p>To summarize, in this post we have shown that it is very likely that the purpose of the current orbit is to pass over the landing site at next periapsis on 2021-02-23 22:31:37 UTC. Then a burn would lower the apoapsis further to obtain an orbit with a period of 2 sidereal days that has a repeating ground track passing over the landing site.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://destevez.net/2021/02/tianwen-1-phasing-orbit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231383</guid>
            <pubDate>Mon, 22 Feb 2021 22:13:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Retrospective Look at Mac OS X Snow Leopard]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 98 (<a href="https://news.ycombinator.com/item?id=26231212">thread link</a>) | @NaOH
<br/>
February 22, 2021 | http://morrick.me/archives/9220 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9220">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<h2>Introduction</h2>
<p>My recent article, <a href="http://morrick.me/archives/9150"><em>The reshaped Mac experience</em></a>, received a lot of attention judging from the response on Twitter and the WordPress analytics — apparently, among other places, it reached Hacker News and Reddit. Unlike my four-part series&nbsp;<em>‌Mac OS Catalina: more trouble than it’s worth</em>, however, it didn’t attract any hate mail at all. The sheer majority of feedback I received was very positive, with many many people agreeing with me and my observations. A few — some provocatively, some genuinely curious — asked me something along the lines of, <em>Well, if you dislike the current Big Sur UI and Mac experience, what’s an example of Mac OS UI and experience you DO&nbsp;like?</em></p>
<p>It’s a more than fair question, and this piece serves as an answer. When I wrote back to those who asked me, I replied <em>Mac OS X 10.6 Snow Leopard</em>. It was sort of a gut-reply based largely on fond memories of using that Mac OS version quite extensively.</p>
<p>When I purchased my 15-inch MacBook Pro in July 2009, it came with Mac OS X 10.5.7 (Leopard), but I immediately upgraded to Snow Leopard when it was released a month or so afterwards. As you know (and if you don’t, here’s a refresher), together with Mac OS X 10.4 Tiger, Snow Leopard was one of the Mac OS versions with the longest lifespan — almost two years, from August 2009 to July 2011, when the final 10.6.8 v1.1 minor release came out. On my 2009 MacBook Pro, I kept using it until mid-2012, as Mac OS X 10.7 Lion (released in July 2011) didn’t fully convince me at first, so I waited until at least version 10.7.3 before upgrading.</p>
<p>So, I used Snow Leopard on my 2009 MacBook Pro for about three years, and then again on a 2010 Mac mini that a friend gave me to maintain, as a sort of offsite backup. That Mac mini was kept on Mac OS X 10.6.8 for the whole four years it was in my custody (2011–2015) and it was switched off only twice during that period and maybe restarted four or five times in total. It enjoyed an insane uptime and it was a testament to Snow Leopard’s stability.</p>
<p>But back to my ‘gut-reply’, I wanted to be certain that my fond memories of Snow Leopard weren’t just nostalgia. While I am confident when I say that Snow Leopard is the most stable version of Mac OS, I wanted to make sure its user interface was really the good user interface and experience I was remembering. So, after a few frustrating attempts at creating a virtual machine on my current iMac with Mac OS High Sierra, I decided to install Snow Leopard on a USB flash drive, and boot my 2009 MacBook Pro (yes, it’s still alive <span>&amp;</span> kicking) in Snow Leopard from that flash&nbsp;drive.</p>
<h2>Installation</h2>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=960%2C1280" alt="" width="960" height="1280" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?w=1512 1512w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=260%2C347 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=640%2C853 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=768%2C1024 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=1152%2C1536 1152w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=1194%2C1592 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=960%2C720" alt="" width="960" height="720" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?w=2016 2016w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=260%2C195 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=640%2C480 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=768%2C576 768w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=1536%2C1152 1536w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=1194%2C896 1194w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a><br>
<em>Ah, When Mac OS welcomed you after the installation process was complete…</em></p>
<p>Since the MacBook Pro doesn’t have an optical drive anymore, I had to create a bootable USB flash drive from my original Snow Leopard DVD Installer. The fastest method is to use Disk Utility — rather, an older version of Disk Utility, from a time when this application was <em>really</em> a utility, and you could use the Restore feature <em>reliably</em> to clone the bootable DVD to (in this case) an external volume.</p>
<p>From a bootable USB flash drive to another USB flash drive, installation was relatively fast, about 20–25 minutes. Although I would have preferred an external SSD for the speed, I must say that using Snow Leopard from the flash drive is a breeze nonetheless. The system is responsive and I haven’t noticed any particular lags.</p>
<h2>User interface</h2>
<p>Now let’s examine just a few aspects of Snow Leopard’s user interface — just like I did for Big Sur in my logbook — and draw comparisons with Big Sur’s interface.</p>
<h3>The menu&nbsp;bar</h3>
<p>Back in August 2020 when I started testing the first Big Sur beta versions, <a href="http://morrick.me/archives/8954">I wrote in my Big Sur logbook</a>:</p>
<blockquote><p>In Big Sur, the menu bar by default isn’t solid white, but has a noticeable degree of transparency: it takes the colour of the desktop wallpaper behind it, in an attempt to blend in with the rest of the desktop environment. Some may consider this sleek, but it’s just gimmicky and usability-hostile.</p>
<p>What happens when the desktop wallpaper has darker colours? Well, menu items and menu bar icons become white, of course. The problem is that the wallpaper doesn’t have to be too&nbsp;dark.</p></blockquote>
<p>In other words, when Big Sur decides that the desktop background image is dark enough, text and icons on the menu bar become white. The problem is that there are cases where the background colour simply <em>isn’t</em> dark enough to warrant a change from black text and icons to white text and icons. Consequently, the contrast is too poor. The only option for better usability is to select <em>Reduce transparency</em> in <em>System Preferences</em> → <em>Accessibility</em>. This brings the menu bar back to a useful state, solid white with black elements.</p>
<p>In Snow Leopard, the menu bar has transparency set to <em>on</em> by default, but it’s definitely more subtle, even with darker desktop backgrounds:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=960%2C500" alt="" width="960" height="500" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?w=1440 1440w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=260%2C135 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=640%2C333 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=768%2C400 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=1194%2C622 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p><em>In the top image, menu bar transparency is off; in the bottom image, transparency is on. The difference is almost negligible.</em></p>
<p>Only with certain background images that contain dark and light areas starkly juxtaposed can menu bar transparency become a bit of an issue under Snow Leopard, but that is partly mitigated by the visible drop shadow beneath the menu bar itself, which helps to make the menu bar stand out&nbsp;more:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=960%2C672" alt="" width="960" height="672" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?w=1000 1000w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=260%2C182 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=640%2C448 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=768%2C538 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>Contrast, even in these conditions, tends to be more tolerable than in Big Sur, at least for my eyes. And in any case, in Snow Leopard you can quickly turn off transparency right in <em>System Preferences</em> → <em>Desktop <span>&amp;</span> Screen Saver:</em></p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=748%2C658" alt="" width="748" height="658" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?w=748 748w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=260%2C229 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=640%2C563 640w" sizes="(max-width: 748px) 100vw, 748px" data-recalc-dims="1"></a></p>
<p><em>I’ve been talking about ‘transparency’, whereas it’s actually ‘translucency’ — at least in Snow Leopard.</em></p>
<h3>Finder windows</h3>
<p>In Snow Leopard, Finder windows are essentially perfect from a user interface standpoint.</p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a></p>
<p>When I shared this over Twitter, Mario Guzmán <a href="https://twitter.com/MarioGuzman/status/1360651998358425601?s=20">observed</a> that <em>Things are nicely compartmentalized by color. You can distinctly tell each section of the window (even the damn scroll bars)… it’s not just one blob of white with grey symbols.</em></p>
<p>Exactly this. The window has clearly distinguishable areas: the <em>Title bar</em> (with the semaphore controls at the top left of the window, and the sidebar+toolbar show/hide toggle button at the top right), the <em>Toolbar</em>, the <em>Sidebar</em> (with colourful icons helping you quickly and easily locate items at a glance), the <em>Path bar</em>, the <em>Status bar</em>, and finally the <em>scroll bars</em> which are always visible.</p>
<p>Persistent up/down arrows and scroll bars are the right thing to do, usability-wise, and it is such a user-friendly design. The length of the ‘aqua blue’ bar immediately gives you an idea of how populated that folder you just opened is going to be. Further, if you need to rapidly scroll down, you just grab the bar with the mouse pointer and scroll.</p>
<p>In later Mac OS versions, scroll bars are set by default to appear only based on mouse/trackpad movement, which is a pity; many users probably don’t realise they can have scroll bars appear permanently, so they don’t have to time the mouseover action for the scroll bar to appear and then <em>hope</em> they’ll manage to grab it when they want to quickly scroll down a long list of elements.</p>
<p>I am once again reminded of that infamous quote by Alan Dye (Apple’s VP of Human Interface) from WWDC 2020, speaking of Big Sur’s UI redesign:&nbsp;<em>‌We’ve reduced visual complexity to keep the focus on users’ content. Buttons and controls appear when you need them, and they recede when you don’t.</em> I still believe this is not a good approach in general, and especially for essential elements like scroll bars, which should always be visible by default, because they are UI elements whose usefulness isn’t limited to when you use them or interact with them — they signal something even when not strictly needed. In the case of the scroll bars it’s a visual estimate of how many elements a folder contains, how long a list of items is, and more importantly <em>your current position</em> when scrolling.</p>
<p>Back to Finder windows, here’s an “Apple’s attention to detail” detail: notice that icon in the bottom left of the window? It is a subtle visual cue that tells you if Finder icons (items) are sorted, unsorted, or simply snapped to a grid. When opening windows from read-only volumes, the icon of a crossed-out pencil appears here, meaning that you can’t modify the enclosed items or write to that volume.</p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are unsorted (Arranged by: None) — No icon in the bottom left corner</em></p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are sorted (by name, size, kind,&nbsp;etc.)</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?w=850 850w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=260%2C171 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=640%2C420 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are snapped to&nbsp;grid</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=752%2C521" alt="" width="752" height="521" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?w=752 752w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=260%2C180 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=640%2C443 640w" sizes="(max-width: 752px) 100vw, 752px" data-recalc-dims="1"></a><br>
<em>Window from a read-only volume</em></p>
<p>While I don’t find this UI detail to be crucial, it is certainly nice to have, and an example of those little things that contributed to make the Mac’s interface great. As I said above, it reflected a certain attention to detail and overall thoughtfulness I’ve seen progressively fade away in later Mac OS releases.</p>
<h2>A look back at a few system apps, with occasional UI comparisons between Snow Leopard and Big&nbsp;Sur</h2>
<h3>Safari</h3>
<p>5.1.10 was the last version of Safari running on Mac OS X 10.6.8. Here are a few things I still prefer over the current Safari:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=845%2C92" alt="" width="845" height="92" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?w=845 845w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=260%2C28 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=640%2C70 640w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=768%2C84 768w" sizes="(max-width: 845px) 100vw, 845px" data-recalc-dims="1"></a><br>
<em>The blue progress bar</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=852%2C100" alt="" width="852" height="100" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?w=852 852w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=260%2C31 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=640%2C75 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=768%2C90 768w" sizes="(max-width: 852px) 100vw, 852px" data-recalc-dims="1"></a><br>
<em>The RSS button (you could read RSS feeds with Safari)</em></p>
<p>Another detail I very much prefer in the older Safari over more recent versions of Safari is how the plus [+] button near the address bar works. Its placement makes its function rather unequivocal: <em>Add the current page to something</em>. As usual, tooltips are helpful:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?resize=562%2C92" alt="" width="562" height="92" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?w=562 562w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?resize=260%2C43 260w" sizes="(max-width: 562px) 100vw, 562px" data-recalc-dims="1"></a></p>
<p>But what if I want to add this page to my Reading List? No worries, when you actually press the [+], a thoughtfully-designed sheet comes down, and you can put the current page exactly where you want: in your Reading List, in the Top Sites, or in your Bookmarks.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=960%2C267" alt="" width="960" height="267" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?w=1005 1005w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=260%2C72 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=640%2C178 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=768%2C213 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>The other plus button, to open a new browser tab, is placed in such an obvious spot that you know what it does without even waiting for the tooltip to appear:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=960%2C110" alt="" width="960" height="110" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?w=1374 1374w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=260%2C30 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=640%2C73 640w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=768%2C88 768w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=1194%2C136 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>Now, let’s take a quick look at the UI in Big Sur’s Safari:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=960%2C59" alt="" width="960" height="59" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=260%2C16 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=640%2C40 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=768%2C47 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=1536%2C95 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=2048%2C126 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=1194%2C74 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>At first glance, there’s only one plus button in the app’s chrome. Try to look at this UI with fresh eyes and guess …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9220">http://morrick.me/archives/9220</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9220</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231212</guid>
            <pubDate>Mon, 22 Feb 2021 21:57:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why It's a Mistake for Publishers to Treat Player Complaints as White Noise]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26230258">thread link</a>) | @ronwilliams821
<br/>
February 22, 2021 | https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise | <a href="https://web.archive.org/web/*/https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-6033e69be3c69f170b958492"><div><div><div data-block-type="2" id="block-e9364474264d18dc38c6"><div><p><strong>TL;DR</strong></p><p><em>With the rise in online gaming popularity since the coronavirus pandemic forced people indoors, network issues like lag have resulted in an outpour of player complaints. Game publishers are now looking for solutions to avoid revenue loss, game abandonment, and community churn.</em></p><p><em>Estimated read time: 8 minutes</em></p><p>----------</p><p>The online game market has exploded over the last few years.</p><p>According to estimates, the <a href="https://newzoo.com/insights/articles/newzoo-games-market-numbers-revenues-and-audience-2020-2023/">video game market will hit $200 billion in revenue by 2023</a>.</p><p>The global pandemic has only escalated that growth by forcing people indoors, many of whom took up gaming to escape and connect with others globally.</p><p>As a result of increased internet traffic from more people logging on to play, network quality problems like lag continues to be a hot-button issue that many game publishers are struggling to figure out.</p><p><strong>This is resulting in players and gaming communities flooding to the internet to voice their complaints.</strong></p><p>As we will explore in this article, this can lead to many problems for game publishers, including game abandonment, community churn, and losses in revenue.</p><p>First, let’s talk about why lag is a huge problem when it comes to gaming.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_9811"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014539752-DNF55GYI92A6VSCSYUAS/ke17ZwdGBToddI8pDm48kI_uL0Lu3YmDOWRp8GvCA6hZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFnmPBfss0IfMxxMBMhA9DNbDUNlGYSEAZNEHrX26nAypuG45vQwBxdpDrCGUSSl5w/lag.gif" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014539752-DNF55GYI92A6VSCSYUAS/ke17ZwdGBToddI8pDm48kI_uL0Lu3YmDOWRp8GvCA6hZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFnmPBfss0IfMxxMBMhA9DNbDUNlGYSEAZNEHrX26nAypuG45vQwBxdpDrCGUSSl5w/lag.gif" data-image-dimensions="478x432" data-image-focal-point="0.5,0.5" alt="lag.gif" data-load="false" data-image-id="6033e846e0310a4198fe84a3" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_11158"><div><h3>Why Lag Is Enemy #1 When it Comes To Gaming</h3><p>We can all agree that lag is a pain.</p><p>It’s a problem that haunts publishers and players alike.</p><p>On a micro scale, it can cause a single player to leave a game. On a macro scale, one player’s lag can negatively impact the quality of experience for multiple players, as noted in <a href="https://www.cs.montana.edu/techreports/1213/Howard.pdf">this study from Montana State University</a>.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_19458"><div><p><strong>“The lag of just one player can cause a cascading impact on the Quality of Experience (QoE) of other players. … Having a group member lag decreases the experience for everyone. … Current lag mitigation techniques are not sufficient when dealing with this cascading impact and may actually be decreasing the overall QoE of the players.”&nbsp;</strong></p><p>- Montana State University Study on The Cascading Impact of Lag on User Experience in Cooperative Multiplayer Games</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_21686"><p>Since gaming’s popularity is on the rise, this topic has been studied in great detail. In a <a href="https://www.researchgate.net/publication/220425928_How_sensitive_are_online_gamers_to_network_quality">study by ResearchGate</a> exploring player sensitivity to network quality, you can see the adverse effects network latency has on gameplay over time.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_22708"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014806841-RK504HJNERJIX369AZOR/ke17ZwdGBToddI8pDm48kJK4Mm1kch8SFO9ZNkN1NT97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmN9YSRtfoTLg6dUq-6F17A0FFZK5fArcnK1IqGweyunyWChwIwkIJ_P7MaZif-uMs/image6.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014806841-RK504HJNERJIX369AZOR/ke17ZwdGBToddI8pDm48kJK4Mm1kch8SFO9ZNkN1NT97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmN9YSRtfoTLg6dUq-6F17A0FFZK5fArcnK1IqGweyunyWChwIwkIJ_P7MaZif-uMs/image6.png" data-image-dimensions="1080x1080" data-image-focal-point="0.5,0.5" alt="image6.png" data-load="false" data-image-id="6033e9559a5b89551b05b03b" data-type="image" src="https://www.subspace.com/blog/image6.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_24056"><div><p><strong>For game publishers, this poses a significant problem. One vocal player with a bad experience can create a ripple effect throughout a game’s online community, especially if they have influence.</strong></p><p>Just this year, Call of Duty came under fire during their league playoff series when Trei “Zero” Morris experienced <em>“game-defining connection issues” </em>that ultimately led to his team, The London Royal Ravens losing their series.</p><p>This incident led to extensive <a href="https://www.espn.com/esports/story/_/id/29705750/call-duty-league-continues-connectivity-issues-playoffs">press coverage from ESPN</a> and a subsequent <a href="https://twitter.com/skrapzg/status/1296541281523568651?s=20">tweetstorm</a> led by Ravens player <a href="https://twitter.com/skrapzg?s=20">@skrapz</a><strong>—who, by the way, has 79,000 followers on Twitter</strong>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_28207"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014966189-EP5LV49F1BXJ33CM8JDW/ke17ZwdGBToddI8pDm48kMw_TYhSJG2CznVP88DMG_t7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmpEfzMuPQaYRVRNSqbP0nCEaFSuz89K8EeUXtbCW9NL11Lw5leMYhyh_z4aP_UKU_/image3.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014966189-EP5LV49F1BXJ33CM8JDW/ke17ZwdGBToddI8pDm48kMw_TYhSJG2CznVP88DMG_t7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmpEfzMuPQaYRVRNSqbP0nCEaFSuz89K8EeUXtbCW9NL11Lw5leMYhyh_z4aP_UKU_/image3.png" data-image-dimensions="1102x1340" data-image-focal-point="0.5,0.5" alt="image3.png" data-load="false" data-image-id="6033e9f54103c9750a126fe7" data-type="image" src="https://www.subspace.com/blog/image3.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_29951"><div><p><strong>As this example perfectly illustrates, lag can put a game publisher in the press for all the wrong reasons.</strong></p><h3>How Lag Drives Game Abandonment and Community Churn</h3><p>As noted in <a href="https://venturebeat.com/2016/04/17/how-latency-is-killing-online-gaming/">this article from VentureBeat</a>, online gaming customers are twice as likely to abandon a game when they experience a network delay (latency) of 500 additional milliseconds. One of the reasons this is a major problem is that players are a very vocal group. They are notorious for letting the world know they are unhappy when poor network conditions ruin their experience.</p><p><strong>Now, imagine the impact someone with real influence and a massive following can have when they voice their displeasure with your game.</strong></p><p>That’s EXACTLY what happened when <a href="https://theblast.com/c/snoop-dogg-goes-off-on-bill-gates-ea-sports-when-madden-server-goes-down-video">Snoop Dogg exploded on EA Sports</a> when Madden servers crashed.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_38706"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015171408-TF6KAF2DGVCNRFD6OLWW/ke17ZwdGBToddI8pDm48kKttrfbZ0gMrYzGve7xMNah7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZHWjT4nTCkdj4JvCo3b04UDVfEyAoFE3s0a5qqZWHReG6v6ULRah83RgHXAWD5lbQ/image4.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015171408-TF6KAF2DGVCNRFD6OLWW/ke17ZwdGBToddI8pDm48kKttrfbZ0gMrYzGve7xMNah7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZHWjT4nTCkdj4JvCo3b04UDVfEyAoFE3s0a5qqZWHReG6v6ULRah83RgHXAWD5lbQ/image4.png" data-image-dimensions="1999x1402" data-image-focal-point="0.5,0.5" alt="image4.png" data-load="false" data-image-id="6033eac0e6dc6a5f64959377" data-type="image" src="https://www.subspace.com/blog/image4.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_40918"><div><p>His <a href="https://www.instagram.com/p/B--Xp__neI0/?utm_source=ig_web_copy_link">rant on Instagram</a> directly targeting EA Sports and Bill Gates now has 1.2 million views. That means 1.2 MILLION people were made aware of the server issues at EA Sports, many of whom chimed in voicing their own frustrations with the game.</p><p><strong>Not exactly the type of press any game publisher wants to attract.</strong></p><p>Now, consider the rise of livestreaming since lockdown began. We now see professional players and popular streamers with millions of fans tuning in to watch them play their favourite games.</p><p>What does this mean for game publishers?</p><p><strong>Streamers have the influence to negatively impact game downloads, gameplay, and community engagement when faced with lag and other connectivity issues.</strong></p><p>Consider these stats from a recent game survey our team at <a href="https://www.subspace.com/">Subspace</a> conducted that identified how players respond to lag interference:</p><ul data-rte-list="default"><li><p>32% of professional players (the people likely to have large streaming audiences) will stop playing a game altogether in response to lag.</p></li><li><p>42% of non-professional players react to lag by stopping gameplay.</p></li></ul><p>That means 74% (or 1,943) of total players surveyed stop playing a game when lag interferes.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_53284"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015326951-DVCVAOCUQ7ERNHP5AC7S/ke17ZwdGBToddI8pDm48kJQAkym-mVm4cWhsd70YmDAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcmkJKBQ_orImNc1CCogPv7mE8pAxih1FOawmp1hWUIKreiWO2XPvz4aLyXLHevgdd/image7.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015326951-DVCVAOCUQ7ERNHP5AC7S/ke17ZwdGBToddI8pDm48kJQAkym-mVm4cWhsd70YmDAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcmkJKBQ_orImNc1CCogPv7mE8pAxih1FOawmp1hWUIKreiWO2XPvz4aLyXLHevgdd/image7.png" data-image-dimensions="1070x540" data-image-focal-point="0.5,0.5" alt="image7.png" data-load="false" data-image-id="6033eb5e5551ec775e951686" data-type="image" src="https://www.subspace.com/blog/image7.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_54940"><div><p>The impact illustrated by these stats can be detrimental to game publishers if the players have big streaming audiences or large followings on social media.</p><p>Like what happened with Snoop Dogg, this can lead to bad press.</p><p><strong>But, the potential impact goes deeper than that.</strong></p><p>When players and the community at large lose interest and abandon games due to lag and connectivity issues, game publishers risk facing a decrease in the ability to generate revenue.</p><h3>The Impact Lag Has On Revenue Potential</h3><p>The way game publishers make money has changed.</p><p>In the past, physical sales drove the bottom line.</p><p><strong>Now, community engagement, in-game purchases, and digital sales drive profits</strong>.</p><p>So, when players, their friends, and the spectator community abandon a game, publishers’ ability to drive profits from these avenues severely decreases.</p><p>Let’s put this into perspective.</p><p>In 2020, <a href="https://www.pcgamesn.com/game-industry-revenue-2020">91% of the industry’s revenue of USD $174.9 billion revenue was made through digital sales, up from 79% in 2019</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_72897"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015691456-4TAA4BHRXXFFWTYLITPA/ke17ZwdGBToddI8pDm48kGZwFzW5ZxHacfyzKAXWyqkUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIVJtLXR86NJwdTrkWQL9k21b3OjGcf_Cex-qh8Isyp6i5zCyJbEi69BH9b5H2vuf/image2.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015691456-4TAA4BHRXXFFWTYLITPA/ke17ZwdGBToddI8pDm48kGZwFzW5ZxHacfyzKAXWyqkUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIVJtLXR86NJwdTrkWQL9k21b3OjGcf_Cex-qh8Isyp6i5zCyJbEi69BH9b5H2vuf/image2.jpg" data-image-dimensions="1193x672" data-image-focal-point="0.5,0.5" alt="image2.jpg" data-load="false" data-image-id="6033eccb2c847c14caf4423d" data-type="image" src="https://www.subspace.com/blog/image2.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_80384"><div><p>What’s even more interesting is the rise of in-game purchases due to the popularity of free-to-play (F2P) games.</p><p>In fact, more than <a href="https://www.wepc.com/news/video-game-statistics/">85% of industry revenue comes from free-to-play games</a>.</p><p><strong>These in-game purchases include:</strong></p><ul data-rte-list="default"><li><p>enhancements (like additional lives)</p></li><li><p>currency</p></li><li><p>personalized avatars&nbsp;</p></li><li><p>ad-free experiences</p></li><li><p>unrestricted playing time</p></li></ul><p>Now, just imagine how much money is being left on the table when lag causes players and the spectator community to abandon games.</p><p><strong>Speaking of spectators…</strong></p><p>A 2016 study from Twitch claimed <a href="https://phys.org/news/2016-07-video-games-spectating-advertising.html">25% of game sales stemmed from spectators watching streams</a> of the game and making a purchase within 24 hours.</p><p>More interestingly, Twitch data scientist Danny Hernandez and his team found mid-tier Twitch streamers—those with audiences between 33 and 3,333 viewers—are responsible for 46% of game sales.</p><p>This is an incredible form of advertising for game publishers—and one that is threatened when lag causes players to abandon games and influence the spectator community.</p><p>You might be asking, <em>“ok, so what is the solution to this problem?</em>”</p><p>Well, let’s dive into that.</p><h3>How Game Publishers Are Solving Their Lag Problems Today</h3><p>Recognizing that lag and connectivity issues cannot continue to plague their games, major players in the gaming industry are now developing their own private networks or are looking at strategic partnerships to upgrade their networks and improve gameplay and player experience.</p><p>Riot Games recently accomplished this when they successfully created their own network for League of Legends players to play on.</p><p>The graph below shows improvements in the number of Riot Games players who play at under 80 ms ping since Riot created its own network.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_112865"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614016194148-WDLSILUCE1GCCPEOPCKP/ke17ZwdGBToddI8pDm48kDEg7RTdH6B5QKjZhuO9yugUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcHDTY8UMmeobLkiD70Xc3UciUnXG25JCMM8KlnxJoXcw5PwMIpS6ZXlOHg-sXRVQ8/image1.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614016194148-WDLSILUCE1GCCPEOPCKP/ke17ZwdGBToddI8pDm48kDEg7RTdH6B5QKjZhuO9yugUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcHDTY8UMmeobLkiD70Xc3UciUnXG25JCMM8KlnxJoXcw5PwMIpS6ZXlOHg-sXRVQ8/image1.png" data-image-dimensions="1486x908" data-image-focal-point="0.5,0.5" alt="image1.png" data-load="false" data-image-id="6033eec17a59e16b1f48dfb2" data-type="image" src="https://www.subspace.com/blog/image1.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_115710"><div><p>Although the outcome has been good, <a href="https://technology.riotgames.com/news/fixing-internet-real-time-applications-part-ii">Riot notes that creating a private network came with many difficulties, challenges, and risks</a>.</p><p>So, it’s obvious that industry leaders recognize the importance of player and community engagement and the need to invest in better network infrastructure.</p><p>You might be asking, <em>“so what are the solutions out there for publishers to leverage today?”</em></p><h3>The Future of Real-Time Online Gaming</h3><p><a href="https://www.subspace.com/">Subspace</a> is on a mission to significantly change the landscape of the games industry by providing game publishers with a platform to operate, deploy, and scale their games.</p><p>Our groundbreaking multiplayer network infrastructure and services platform provide the lowest latency, most reliable real-time, and fully controllable network possible for the world’s biggest games.</p><p><strong>What does this mean for you as a publisher?</strong></p><ul data-rte-list="default"><li><p>Expansion in playable latency</p></li><li><p>Increased matchmaking pool sizes</p></li><li><p>Improved player engagement</p></li><li><p>Decreased player churn</p></li><li><p>Increased revenue</p></li></ul><p><strong>How do we do it?</strong></p><p>We currently have infrastructure in hundreds of cities across the globe and continue to grow our presence.</p><p>Today, Subspace has millions of players on our platform playing on PC, Playstation, Xbox, Switch, iOS, and …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise">https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise</a></em></p>]]>
            </description>
            <link>https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise</link>
            <guid isPermaLink="false">hacker-news-small-sites-26230258</guid>
            <pubDate>Mon, 22 Feb 2021 20:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MapReduce – munching through Big Data (2016)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26230003">thread link</a>) | @wilsonfiifi
<br/>
February 22, 2021 | https://appliedgo.net/mapreduce/ | <a href="https://web.archive.org/web/*/https://appliedgo.net/mapreduce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>It’s been a while since the last post, and I have to apologize for the long wait. The last weeks have been quite busy, but I finally managed to complete another article. I hope you’ll enjoy it.</em></p>
<h2 id="map-and-reduce">Map and Reduce</h2>
<p>This is going to be a boring article about two boring functions, <code>map()</code> and <code>reduce()</code>. Here is the story:</p>
<p>You have a list with elements of type, say, <code>string</code>.</p>
<p>You define a function that takes a <code>string</code> and produces an <code>int</code>. Let’s say you want to know the length of a string.</p>
<div><pre><code data-lang="go"><span>func</span> <span>length</span>(s <span>string</span>) <span>int</span> {
	<span>return</span> <span>len</span>(s)
}
</code></pre></div><p>Now you define a function called <code>map()</code> that takes this function and applies it to each of the elements in the list and returns a list of all results.</p>
<div><pre><code data-lang="go"><span>func</span> <span>mäp</span>(list []<span>string</span>, fn <span>func</span>(<span>string</span>)<span>int</span>) []<span>int</span> { <span>// "map" is a reserved word, "mäp" isn't
</span><span></span>	res <span>:=</span> <span>make</span>([]<span>int</span>, <span>len</span>(list))
	<span>for</span> i, elem <span>:=</span> <span>range</span> list {
		res[i] = <span>fn</span>(elem)
	}
	<span>return</span> res
}
</code></pre></div><p>Finally, you define another function <code>reduce()</code> that takes the result list and boils it down to a single result..</p>
<div><pre><code data-lang="go"><span>func</span> <span>reduce</span>(list []<span>int</span>, fn <span>func</span>(<span>int</span>, <span>int</span>)<span>int</span>) (res <span>int</span>) {
	<span>for</span> _, elem <span>:=</span> <span>range</span> list {
		res = <span>fn</span>(res, elem)
	}
	<span>return</span> res
}

<span>func</span> <span>sum</span>(a,b <span>int</span>) <span>int</span> {
	<span>return</span> a<span>+</span>b
}
</code></pre></div><p>Now you can wire it all up.</p>
<div><pre><code data-lang="go"><span>func</span> <span>main</span>() {
	list <span>:=</span> []<span>string</span>{<span>"a"</span>, <span>"bcd"</span>, <span>"ef"</span>, <span>"g"</span>, <span>"hij"</span>}
	res <span>:=</span> <span>reduce</span>(<span>mäp</span>(list, len), sum)
	fmt.<span>Println</span>(res)
}
</code></pre></div><p><a href="https://play.golang.org/p/P7-1ro4a_d">(Playground link)</a></p>
<p>Here is the whole thing visualized. (Click on Play to start the animation.)</p>


<p>That’s it. End of the story. Pretty boring, eh?</p>
<h2 id="but-wait-">But wait! …</h2>
<p>… what’s this?</p>
<p><strong>Looks like we just abstracted away the concept of <code>for</code> loops!</strong></p>
<p>Now if that’s not something to brag about on the next Gopher meetup…</p>
<p>However, does this buy us anything else? Indeed it does:</p>
<ul>
<li>
<p>First, no more one-off index errors.</p>
</li>
<li>
<p>Second, and more importantly, if the mapped function <code>fn</code> does not depend on previous results, it can be trivially called in a concurrent manner.</p>
</li>
</ul>
<p>How to do this? Easy: Split the list into <em>n</em> pieces and pass them to <em>n</em> independently running mappers. Next, have the mappers run on separate CPU cores, or even on separate CPU’s.</p>
<p>Imagine the speed boost you’ll get. Map and reduce, as it seems, form a fundamental concept for efficient distributed loops.</p>
<blockquote>
<p>Lemme repeat that. By abstracting away the very concept of looping, you can implement looping any way you want, including implementing it in a way that scales nicely with extra hardware.</p>
<p>Joel Spolsky, <a href="http://www.joelonsoftware.com/items/2006/08/01.html">Can Your Programming Language Do This?</a> (2006)</p>
</blockquote>
<h2 id="from-map-and-reduce-to-mapreduce">From map() and reduce() to MapReduce</h2>
<p>Google researchers took the map/reduce concept and scaled it up to search engine level (I leave the exact definition of “search engine level” as an exercise for the reader). <a href="http://research.google.com/archive/mapreduce.html">MapReduce was born</a>.</p>
<p>The result was a highly scalable, fault-tolerant data processing framework with the two functions <code>map()</code> and <code>reduce()</code> at its core.</p>
<p>Here is how it works.</p>
<p>Let’s say we have a couple of text files and we want to calculate the average count of nouns &amp; verbs per file.</p>
<p>Our imaginary test machine has eight CPU cores. So we can set up eight processing entities/work units/actors (or whatever you want to call them):</p>
<ul>
<li>One input reader</li>
<li>Three mappers</li>
<li>One shuffler, or partitioner</li>
<li>Two reducers</li>
<li>One output writer</li>
</ul>
<h3 id="the-input-reader">The input reader</h3>
<p>The input reader fetches the documents, turns each one into a list of words, and distributes the lists among the mappers.</p>
<h3 id="the-mapper">The mapper</h3>
<p>Each of the mappers reads the input list word by word and counts the nouns and verbs in that list.</p>
<p>The result is a key-value list of word types (noun, verb) and counts. For example, our three mappers could return these counts:</p>
<pre><code>mapper 1:
    nouns: 7
    verbs: 4

mapper 2:
    nouns: 5
    verbs: 8

mapper 3:
    nouns: 6
    verbs: 3
</code></pre>
<p>When a mapper has finished, it passes the result on to the shuffler.</p>
<h3 id="the-shuffler">The shuffler</h3>
<p>The shuffler receives the output lists from the mappers. It rearranges the data by key; that’s why it is also referred to as “partitioning function”. In our example, the shuffler generates two lists, one for nouns and one for verbs:</p>
<pre><code>list 1:
    nouns: 7
    nouns: 5
    nouns: 6

list 2:
    verbs: 4
    verbs: 8
    verbs: 3
</code></pre>
<p>The shuffler then passes each list to one of the two reducers.</p>
<h3 id="the-reducer">The reducer</h3>
<p>Each reducer receives a list with a couple of counts. It simply runs through the list, adds up all the counts, and divides the result by the number of counts. Both reducers then send their output to the output writer.</p>
<p>Back to our example. The first reducer would calculate an average of</p>
<pre><code>(7 + 5 + 6) / 3 = 6
</code></pre>
<p>and the other one would return</p>
<pre><code>(4 + 8 + 3) / 3 = 5
</code></pre>
<h3 id="the-output-writer">The output writer</h3>
<p>All the output writer has to do is collecting the results from the reducers and write them to disk or pass them on to some consumer process.</p>
<h3 id="summary">Summary</h3>
<p>To make all this less abstract, here is the same as an animation. (Click on Play.)</p>


<p>This concept easily scales beyond a single multi-CPU machine. The involved entities - input reader, mapper, shuffler, reducer, and output writer - can even run on different machines if required.</p>
<p>But MapReduce is more than just some distributed version of <code>map()</code> and <code>reduce()</code>. There are a couple of additional bonuses that we get from a decent MapReduce implementation.</p>
<ul>
<li>A good deal of the functionality is the same for any kind of map/reduce task. These parts can be implemented as a MapReduce framework where the user just needs to provide the <code>map</code> and <code>reduce</code> functions.</li>
<li>The MapReduce framework can provide fault recovery. If a node fails, the framework can re-execute the affected tasks on another node.</li>
<li>With fault tolerance mechanisms in place, MapReduce can run on large clusters of commodity hardware.</li>
</ul>
<h2 id="the-code">The code</h2>
<p>The code below is a very simple version of the noun/verb average calculation. To keep the code short and clear, the mapper does not actually identify nouns and verbs. Instead, the input text is just a list of strings that read either “noun” or “verb”. Also, the reducer does not receive key/value pairs but rather just the values. We already know that one reducer receives the nouns and the other receives the verbs.</p>
</div></div>]]>
            </description>
            <link>https://appliedgo.net/mapreduce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26230003</guid>
            <pubDate>Mon, 22 Feb 2021 20:18:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What We Learned About Engineering Effectiveness Talking to Hundreds of CTOs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26229974">thread link</a>) | @tonioab
<br/>
February 22, 2021 | https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness | <a href="https://web.archive.org/web/*/https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the last decade, <a href="https://www.linkedin.com/in/tomasrb/" rel="nofollow noopener noreferrer" target="_blank">my cofounder</a> and <a href="https://www.linkedin.com/in/antoineboulanger/" rel="nofollow noopener noreferrer" target="_blank">I</a> have engaged in hundreds of conversations with engineering leaders on our journey to improve engineering. We talked with Silicon Valley startups just getting started as well as established enterprises with thousand-person headcounts.</p>
<p>What we discovered surprised us: <strong>Not only can software engineering effectiveness be measured; most engineering teams follow the exact same evolution.</strong></p>
<p>From a two-person startup to a thousand-person team, engineering success always comes from the same fundamentals: 1) Hire excellent engineers and 2) <a href="https://www.okayhq.com/blog/engineering-productivity-can-be-measured" rel="nofollow noopener noreferrer" target="_blank">Remove the blockers that prevent their success</a>.</p>
<p>Different team sizes, however, change the ways these fundamentals manifest. Broadly, they fit into five stages:</p>
<ul>
<li>Qualitative</li>
<li>Data-Curious</li>
<li>People-Driven Engineering Effectiveness</li>
<li>Software-Driven Effectiveness</li>
<li>Engineering Effectiveness as a Strategic Advantage</li>
</ul>
<p><img src="https://www.okayhq.com/assets/img/5_stages_o.a91f2d0.png" alt="The 5 stages of Engineering Effectiveness"></p><p>While you're perusing these stages, keep in mind that every engineering org starts somewhere and every org can reach stage 5. Regardless of the size or age of your team, your engineering effectiveness would benefit from:</p>
<ol>
<li>Objectively assessing your current engineering org: What stage are you in and why?Â&nbsp;</li>
<li>Solidifying a strong foundation: Ensure you've built all the components of your current and lower stages.Â&nbsp;</li>
<li>Aiming higher: Add advanced functions to accelerate your achievement.Â&nbsp;Â&nbsp;</li>
</ol>
<p>Of course, individual organizations have their own unique traits, so you should feel free to make this framework your own. On the whole, however, here's how to grow:Â&nbsp;</p>
<h2 id="stage-1-qualitative">Stage 1: Qualitative</h2>
<p>Most engineering teams start small. At this point (usually around 1-20 people), the team is evolving rapidly and there aren't many objective metrics to measure success.</p>
<p><strong>In stage 1, the most successful engineering organizations build a strong social, cultural, and behavioral foundation.</strong> This foundation should include implementing widely-known best practices like:</p>
<ul>
<li><a href="https://www.scrum.org/resources/what-is-a-sprint-retrospective" rel="nofollow noopener noreferrer" target="_blank">Sprint retrospectives</a> to identify patterns of effectiveness</li>
<li><a href="https://en.wikipedia.org/wiki/Test-driven_development" rel="nofollow noopener noreferrer" target="_blank">Test-driven development</a> and version control with small, frequent commits</li>
<li>Flexible hours with high employee autonomy</li>
</ul>
<p>With stage 1 being almost metric-free, engineering success relies almost entirely on your first-line managers.  We've found these managers to be the differentiators between successful stage 1 orgs and those that flounder. If your org is in stage 1, be on the lookout for strong managers: ones who are either experienced and well-trained or inexperienced but exceptionally fast learners.</p>
<p>To support a stage 1 engineering org, company leadership should create a high-trust environment in team meetings/all hands (to encourage feedback) and keep a pulse on morale through high-quality one-on-ones. It's also helpful for long-term culture to invest in manager growth and development, particularly around people skills and EQ. (We've found <a href="https://rework.withgoogle.com/guides/managers-develop-and-support-managers/steps/introduction/" rel="nofollow noopener noreferrer" target="_blank">Google's framework</a> to be particularly effective at helping managers become <a href="https://en.wikipedia.org/wiki/Servant_leadership" rel="nofollow noopener noreferrer" target="_blank">servant leaders</a>.)</p>
<p>In stage 1, engineering revolves around culture: you'll succeed if your managers can support and align your team.Â&nbsp;Â&nbsp;</p>
<h2 id="stage-2-data-curious-and-reactive">Stage 2: Data-Curious and Reactive</h2>
<p><strong>Stage 2 is when most orgs first become aware of engineering effectiveness as an area to improve, so they start dabbling in data.</strong></p>
<p>As most stage 2 orgs are small and fast-growing (20-50 people), they must still rely heavily on first-line managers for qualitative measures like:Â&nbsp;</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/OKR" rel="nofollow noopener noreferrer" target="_blank">OKR</a> completion</li>
<li>Team engagement</li>
<li>Hiring targets</li>
</ul>
<p>Stage 2 will also bring your first quantitative measures, typically in the form of ad hoc metrics like:Â&nbsp;</p>
<ul>
<li>Bug counts</li>
<li>Alert rates</li>
<li>Employee satisfaction surveys</li>
</ul>
<p>On the dev ops side, successful stage 2 orgs typically begin investing in a pipeline aimed at achieving continuous delivery. These investments often include custom scripts or open-source tools that provide snapshots of their DORA metrics.</p>
<p>These instantaneous measurements and metrics help make stage 2 engineering orgs more effective than those in stage 1. That said, these stage 2 improvements are typically ad hoc, one-off, and isolated. Instead of a comprehensive, real-time dashboard or even a long-term feedback loop, stage 2 orgs act on instantaneous information as it arises, necessarily making the org's improvements reactive.</p>
<h2 id="stage-3-people-driven-engineering-effectiveness">Stage 3: People-Driven Engineering Effectiveness Â&nbsp;</h2>
<p>The typical stage 3 engineering org will have 50-250 engineers and feel like it's in a transition stage between independent qualitative assessments and fully-automated metrics.Â&nbsp;</p>
<p><strong>In stage 3, the best engineering teams establish a dedicated function for engineering effectiveness</strong>, most frequently through a dedicated internal team or by hiring an engineering chief of staff. This dedicated function will begin to make:</p>
<ul>
<li>A regular cadence of investments in dev tech, processes, and tooling</li>
<li>Looker dashboards to capture DORA metrics in real time</li>
<li><a href="https://cloud.google.com/blog/products/gcp/sre-fundamentals-slis-slas-and-slos" rel="nofollow noopener noreferrer" target="_blank">SLAs/SLOs</a> for engineering effectiveness</li>
<li>Tangible, objectively-verifiable effectiveness metrics that will hold managers accountableÂ&nbsp;</li>
</ul>
<p><strong>While stage 3 brings both long-term metrics and systems that provide a holistic view, most of these activities will be performed by hand.</strong> For example, the engineering Chief of Staff or program manager might ask directors to fill out a spreadsheet, which will then evolve into a powerpoint presentation that prompts the VP to make adjustments.</p>
<p><strong>A successful stage 3 engineering org will implement a dedicated engineering effectiveness team to measure metrics and incorporate adjustments at a reliable cadence.</strong></p>
<h2 id="stage-4-software-driven-effectiveness">Stage 4: Software-Driven Effectiveness</h2>
<p><strong>In stage 4, dedicated software enters the picture, bringing continuous improvement to every engineering stage.</strong></p>
<p>The typical stage 4 engineering org will have hundreds or thousands of engineers. At this scale, treating engineering like a black box is no longer acceptable. Instead, managers will require precise, quantitative assessments instead of qualitative or imprecise measures.</p>
<blockquote>
<p>The most successful stage 4 teams automate a high variety of engineering metrics, either through dashboards built by a full-time engineering effectiveness team or by leveraging <a href="https://www.okayhq.com/" rel="nofollow noopener noreferrer" target="_blank">third-party software</a></p>
</blockquote>
<p>These dashboards gather actionable, real-time effectiveness metrics at every level of management:</p>
<ol>
<li>The CTO sets high-level metrics and goals, typically through a dashboard they share with the other executives.Â&nbsp;</li>
<li>Directors/mid-level managers set goals for their sub-orgs and monitor their metrics for early signs of issues.</li>
<li>First-line managers provide root-cause analysis on the specific factors contributing to high-level metrics.</li>
<li>Every engineering OKR includes goals around effectiveness and improvement.</li>
</ol>
<p>Before stage 4, engineering teams often aim to measure everything. In stage 4, they aim more precisely at high-value metrics like engineer utilization, <a href="https://www.okayhq.com/blog/engineering-productivity-can-be-measured" rel="nofollow noopener noreferrer" target="_blank">blockers</a>, and work-life balance. Stage 4 brings the ability for an org to diagnose specific symptoms all the way down to their root causes, where they can form coherent, data-backed stories that inform pinpointed improvements. The most successful stage 4 teams will even start uncovering personalized metrics that they find particularly correlate to their success.</p>
<p><strong>By combining automated, real-time metrics with the culture of continuous improvement built in stages 1-3, stage 4 teams can evolve their effectiveness into an always-running, well-oiled improvement machine.</strong></p>
<h2 id="stage-5-engineering-effectiveness-as-a-strategic-advantage">Stage 5: Engineering Effectiveness as a Strategic Advantage</h2>
<p><strong>Stage 5 turns engineering effectiveness into a strategic lever that helps the company achieve precise business goals.</strong></p>
<p>Even though a typical stage 5 team will contain hundreds or thousands of engineers all around the world, the best stage 5 orgs run like a well-coordinated symphony: individual contributions come together to create a single unit that's much more than the sum of its parts.</p>
<p>On top of stage 4's software-based measurement and org-wide culture of improvement, stage 5 adds a strategic lens. The best stage 5 organizations can make calculated risks involving conscious trade-offs. Perhaps the org extrapolates a concerning quality trend and adjusts its features long before engineers or customers start to complain. The best stage 5 organizations can calculate specific risk levels and readjust without unpleasant surprises.</p>
<p>High-performing stage 5 teams typically engage in:</p>
<ul>
<li>Industry/peer-group <a href="https://dealstruck.com/resources/the-power-of-peer-benchmarking/" rel="nofollow noopener noreferrer" target="_blank">benchmarking</a> (to understand their effectiveness compared to other companies)</li>
<li>Automatic implementation of the latest effectiveness research (to accelerate constant improvement)</li>
<li>Anticipatory activities at every stage in the org (to predict potential problems before they arise)Â&nbsp;</li>
<li>Thought leadership on new best practices of engineering effectiveness (naturally uncovered as a result of their experience)Â&nbsp;</li>
<li>Full transparency/understanding of engineering metrics, even outside of the engineering org (to aid company-wide improvement)</li>
<li>Calculated risks (to achieve precise business aims)</li>
</ul>
<p>From the outside, a stage 5 team looks like a strong engineering brand. It can accelerate and adjust, attract top talent while achieving business aims.</p>
<h2 id="toward-engineering-effectiveness">Toward Engineering EffectivenessÂ&nbsp;</h2>
<p>Engineering effectiveness is too expensive to be left to chance. Start by assessing where your team currently is. Are you:Â&nbsp;</p>
<ul>
<li>Sufficiently small that metrics are still a "nice to have"?</li>
<li>Data-curious and ready to react?</li>
<li>In need of a dedicated effectiveness team?</li>
<li>Positioned to produce a continuously improving organizationÂ&nbsp;?</li>
<li>Able to precisely tune your priorities to enable the company's long-term strategy?</li>
</ul>
<p><strong>Then, solidify your position at your current stage, building a solid foundation on which you can expand.</strong></p>
<p>While every engineering team has its own individual nuance, most will follow this consistent evolution. We uncovered these stages through years of observation, but there's still more improvement to be applied to engineering.</p>
<p>We've made it our mission to improve engineering effectiveness. If you've uncovered your own trends or if you're curious for more, <a href="https://okayhq.typeform.com/to/O47Fx3Q7" rel="nofollow noopener noreferrer" target="_blank">let us know</a>. We'd love to improve engineering effectiveness for everyone.</p></div></div></div>]]>
            </description>
            <link>https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229974</guid>
            <pubDate>Mon, 22 Feb 2021 20:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anti-Solar Panels May Generate Power at Night Soon]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26229635">thread link</a>) | @elorant
<br/>
February 22, 2021 | https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/ | <a href="https://web.archive.org/web/*/https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><article id="post-2010"><p><a href="https://robologiclab.com/wp-content/uploads/2021/02/Untitled-design-14.png"><img width="800" height="445" src="https://i0.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-14.png?resize=800%2C445&amp;ssl=1" alt="Anti-solar panels that can work round the clock!" loading="lazy"></a></p><div><div><p>Have anyone told you that a solar panel can be operational at the night? This might sound like an unrealistic tech. However, it is possible and in the future, we can see solar panels working at night also. The University of California (UC), Davis scientists are inventing a prototype for an ‘anti-solar panels’ that would work opposite to a classic solar panel. The new studies suggest that it is possible that such panels could work round the clock.</p><p><br>These anti-solar panels can produce a quarter of the energy they generate throughout the day under ideal conditions. The scientist reveals the requirement to combine thermoradiative panels that could produce energy on account of radiative cooling. In radiative cooling due to thermal radiation, a body dissipates out its heat. The thermoradiative cells are used for the experiment for manufacturing. After that, they transfigure the heat into electricity.</p><figure><img loading="lazy" width="800" height="391" src="https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=800%2C391&amp;ssl=1" alt="anti-solar panels installed on building" srcset="https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?w=1024&amp;ssl=1 1024w, https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=300%2C146&amp;ssl=1 300w, https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=768%2C375&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1"></figure><h3>Research Behind Anti-Solar Panels</h3><p>ACS Photonics publication has published a research paper. In this paper, the scientists have revealed how they developed the anti-solar cells. Which perform their function of radiative cooling. Some engineers from UC states were puzzled concerning what would be the result if they installed one of the solar panels in a warm area, and pointed it towards the sky. It tends to concentrate on visible light to give rise to efficacious cells that could use the night sky and space as a heat sink. Jeremy Munday, an electrical and computer engineer from UC states mention that physics was identical in both the tech, only the materials are varying.</p><p><br>However this technology is in its initial phases, the team is in the middle of developing prototypes. The important point about this research is, it can be made economical to hold solar panels functional for a day. Last but not the least, according to scientists the enigmatic space is an interesting, comparatively unexplored area. However, it can assist and deliver electrical power at night and day with the proper utilization of materials science, optics, and photonics.</p><p><br>Hope you all like it, please share your valuable views about this tech in the comment section. Thank you for reading this!</p></div></div></article></div></div>]]>
            </description>
            <link>https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229635</guid>
            <pubDate>Mon, 22 Feb 2021 19:51:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Codegen caching with minimal boilerplate: Protobuf Dependency Inference in Pants]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26229023">thread link</a>) | @pantsbuild
<br/>
February 22, 2021 | https://blog.pantsbuild.org/pants-2-2-adds-dependency-inference-for-protobuf/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/pants-2-2-adds-dependency-inference-for-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>As discussed <a href="https://blog.pantsbuild.org/dependency-inference/">in our post on dependency inference</a>, Pants understands which files depend on which to offer fine-grained caching. If none of the inputs have changed, Pants can safely cache your builds like running tests and generating code.</p><p>With conventional scalable build tools, this fine-grained invalidation requires substantial boilerplate: maintaining BUILD files that explicitly declare every dependency. Instead, Pants uses <em>dependency inference</em> to reduce this boilerplate by up to 90% by reading your code and figuring out the dependencies for you.</p><p>As of Pants 2.2, Pants now knows how to use dependency inference with <a href="https://developers.google.com/protocol-buffers/">Protobuf</a>! This includes:</p><ul><li>Protobuf imports of other Protobuf files.</li><li>Python imports of generated Protobuf code, including gRPC.</li></ul><p>While Pants currently only generates code with Protobuf, we are eager to work with <a href="https://www.pantsbuild.org/docs/community">community members</a> to support other protocols like Apache Thrift.</p><hr><h3 id="wth-is-pants">WTH is Pants?</h3><p>Pants is a scalable build tool, meaning that it orchestrates the tools you use in a modern Python repository, like Black, Pytest, Protoc (Protobufs), and setuptools. Pants will run these and many other tools concurrently, and brings fine-grained caching with minimal boilerplate, including as your codebase scales up in size.</p><p>See <a href="https://blog.pantsbuild.org/introducing-pants-v2/">blog.pantsbuild.org/introducing-pants-v2/</a>.</p><hr><h2 id="how-it-works">How it works</h2><p>Pants will first look at your repository's code layout and your Protobuf and Python file names to develop a global mapping. For example, we know that <code>protos/project/models.proto</code> corresponds to the Protobuf import <code>project/models.proto</code> and the Python modules <code>project.models_pb2</code> and (possibly) <code>project.models_pb2_grpc</code>.</p><p>With this global mapping computed, Pants then parses the relevant files to extract their import statements and look up the corresponding owner, if any.</p><p>For example, given this Proto:</p><pre><code>// protos/build/remote/execution/remote_execution.proto
package build.remote.execution;

import "build/semver/semver.proto";
import "google/api/annotations.proto";
import "google/rpc/status.proto";
import "google/protobuf/duration.proto";</code></pre><p>Pants infers dependencies on the correct Protobuf files:</p><pre><code>❯ ./pants dependencies protos/build/remote/execution/remote_execution.proto
protos/build/semver/semver.proto
protos/google/api/annotations.proto
protos/google/rpc/status.proto
protos/google/protobuf/duration.proto</code></pre><p>Pants will also understand Python imports of these Protobuf files, normalizing their full paths into Python module names:</p><pre><code># src/py/project/app.py
import build.semver.semver_pb2
import google.api.annotations_pb2_grpc</code></pre><pre><code>❯ ./pants dependencies src/py/project/app.py
protos/build/semver/semver.proto
protos/google/api/annotations.proto</code></pre><p>As discussed in <a href="https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/">our post on Pants's performance</a>, this inference is 1) very safe and 2) very fast. Because Pants invokes processes hermetically with a sandbox, failing to infer a dependency can never cause the wrong thing to be cached. Further, the inference is fast thanks to Pants's core being implemented in Rust, along with a daemon, parallelism, and very fine-grained invalidation.</p><h2 id="trying-out-pants">Trying out Pants</h2><p>Using Pants ensures that your builds always use your up-to-date Protobuf code—no more need to manually invoke scripts! Further, thanks to Pants's fine-grained understanding of your project's dependencies, you will only ever generate the Protobuf files you actually need.</p><p>We optimized Pants to be easy to <a href="https://www.pantsbuild.org/docs/existing-repositories">add incrementally to existing repositories</a>, including an upcoming feature in Pants 2.3 to auto-generate BUILD files (stay tuned for a blog post!).</p><p>The <a href="https://www.pantsbuild.org/docs/community">Pants community</a> would love to help you get started. <a href="https://www.pantsbuild.org/v2.1/docs">www.pantsbuild.org/docs</a><br></p>
			</section></div>]]>
            </description>
            <link>https://blog.pantsbuild.org/pants-2-2-adds-dependency-inference-for-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229023</guid>
            <pubDate>Mon, 22 Feb 2021 19:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Questions to ask when choosing a programming language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26228886">thread link</a>) | @feross
<br/>
February 22, 2021 | https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6502">
	<!-- .entry-header -->

	
	
	<div>
		
<p>This week I had a discussion with one of my friends on how to choose a programming language. It was triggered by multiple discussions I had with our customers on their engineering strategy in the last six months and one question that came multiple times was should we use X programming language for our new initiatives. Some customers were thinking of moving from .NET stack to Java, some banks were thinking about moving to Golang because their technical leaders have watched Monzo talks on Golang, for some it was from Java to Kotlin, and some were thinking of dumping JavaScript for Typescript.</p>



<p>To come up with the answer I try to find answers to following questions in context of the organization:</p>



<ul><li>What is the maturity of the programming language with respect to its community and ecosystem? Should they spend their one innovation token on this language?</li><li>How easy it is to find available talent in the market for that programming language?&nbsp;</li><li>How easy it is for the organization to acquire production engineering know-how for a programming language?</li><li>What are the productivity and efficiency gains that can be achieved from using a programming language? Are those gains aligned with the organization goals?</li><li>What are the use-cases an organization wants to solve with the programming language?</li><li>What is the future of a programming language? For a big enterprise it is important if the language can last for a decade.</li><li>What is the learning curve of the programming language? Can existing staff be upskilled?</li></ul>



<p>There is no correct answer to these questions. Most engineering organizations will end up using multiple programming languages. For example an organization may choose Golang as a general purpose language to build backend services, Python for scripting and data related work, Typescript for building web frontend. It is also possible that an engineering organization might choose Python for building most services and for few where performance and efficiency is important it chooses Golang. I think the important point is defining a small list of programming languages for the organization and documenting when you will choose which programming language.&nbsp;</p>



<p>I use a decision matrix like the one shown below to come up with one possible answer. Depending on which factors are important to the organization they can give them weights and that will impact the score of the language. In the image shown below, language 1 is the winner.</p>



<figure><img src="https://lh6.googleusercontent.com/WGB2gGPDUN24IZXig5kZSGzKwcpwSIfP5dzPMp5gxTpIGw5g5rRlqcsWPSTYDY0QWf6U0D14oL9dfTeRZlDanEwK54XjJIirmMeIGTL62skChi8YxVTBZcpeJyRbnveFCKYW3d7U" alt=""></figure>



<p>As I was writing this post a few more questions came to my mind.&nbsp;</p>



<ul><li>Does a programming language help us write less buggy software?</li><li>Does a programming language have some constructs that help us reduce the essential complexity of the system?</li><li>What constraints does a programming language impose and how do they impact the business goals?</li><li>Can a programming language be a competitive advantage for an organization?</li><li>Can a programming language influence the quality of the development team, the quality of code, and practices they follow?</li><li>Does a programming language influence engineering organization culture?</li><li>Can a programming language over time help average Joe become a good software engineer?</li><li>What makes a programming language future safe? Can we predict it to safeguard us?</li><li>Should a language choice depend on NFRs that you want to achieve?</li><li>How does a programming language influence behavior of a team?</li></ul>



<p>I don’t have answers to all of the above mentioned questions. I am hoping there is academic research done on the above but I am yet to read those papers.</p>



<p>I did some research on why different organizations choose certain languages and I found the following key points.</p>



<ol><li>Gitlab – Ruby – <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">Link</a><ul><li>GitHub, a source of inspiration for GitLab, was also based on Rails, making it a logical pick considering his interest in the framework.</li><li>Ruby on Rails ecosystem allows you to shape a lot of functionality at a high quality</li><li>We need a lot of functionality and Ruby on Rails is a way to do it</li><li>Consistent coding practices. You are guided to do the right thing.</li><li>Big community of Ruby gems</li></ul></li><li>CockroachDB – Golang – <a href="https://www.cockroachlabs.com/blog/why-go-was-the-right-choice-for-cockroachdb/">Link</a><ul><li>its support for libraries, interfaces, and tooling positioned it as the right choice for CockroachDB</li><li>Go was designed to scale to large code bases with an emphasis on simplicity and orthogonality of features. The enforced code style, the simple imports and automated import management, the wide variety of linters, the straightforward (and minimal) set of programmatic idioms…all of these attributes of Go are important for clean, understandable code.</li><li>When comparing to Java, we appreciate the tight focus on implementation instead of OOP and abstraction: interfaces can be added when needed, not as an initial, often unnecessary, step.&nbsp;</li><li>When comparing to C++, we appreciate automatic memory management and how there’s rarely more than one way to get something done, for example with static and one-time initializers.</li><li>Go gives better control over memory allocation that impacts garbage collection.</li></ul></li><li>Asana – TypeScript – <a href="https://blog.asana.com/2014/11/asana-switching-typescript/">Link</a><ul><li>Clean JS</li><li>Community Support</li><li>Errors at compile time instead of runtime</li><li>Static typing</li></ul></li><li>American Express – Golang – <a href="https://go.dev/solutions/americanexpress/">Link</a> and <a href="https://americanexpress.io/choosing-go/">Link</a><ul><li>For their assessment, they chose to build a microservice in four different programming languages. They then compared the four languages for speed/performance, tooling, testing, and ease of development.</li><li>While Go may not have been the fastest language tested, its powerful tooling helped bolster its overall results. Go’s built-in testing framework, profiling capabilities, and benchmarking tools impressed the team.</li><li>Reasons<ul><li>Simple and straightforward</li><li>Encourage best practices</li><li>Concurrency</li><li>Tooling</li></ul></li></ul></li><li>Nubank – Clojure – <a href="https://building.nubank.com.br/working-with-clojure-at-nubank/">Link</a><ul><li>Nubank provides services in the finance domain, which is very close to mathematical functions — and functional programming is an excellent fit for both scenarios.</li><li>Clojure, on the other hand, has simple constructs that allow us to focus on the problem we are solving, making evolving the system a small incremental challenge, which doesn’t get that much harder over time.</li><li>Most of our codebase can be understood locally, looking at any given pure function, understanding its outputs for any given set of inputs. There’s rarely any need to reason about or recreate the internal state of objects. Data moves through the system in a composable, inspectable, consistent, and immutable way (without hiding it inside of objects).</li><li>Functional code is much easier to test, and that gives us the confidence to deploy an average of over 50 changes per day in a mission-critical domain.</li><li>Nubank has acquired Cognitect, the US-based software consultancy behind the Clojure programming language and the Datomic database</li></ul></li><li>Janestreet – Ocaml – <a href="https://www.youtube.com/watch?v=v1CmGbOGb2I">Link</a> , <a href="https://queue.acm.org/detail.cfm?id=2038036">Link</a> , and <a href="https://discuss.ocaml.org/t/does-jane-street-use-other-programming-languages-aside-from-ocaml/2761/5">Link</a><ul><li>Brevity of the language and the powerful type system that makes OCaml code very readable</li><li>Powerful abstraction capabilities that reduce boilerplates</li><li>Static type system for ensuring code correctness</li><li>He spoke about some of the fancy type tricks like parametric polymorphism, algebraic data types, type inference, phantom types and type indexed values that add to the expressivity of code.</li><li>Also OCaml hits the sweet spot between expressiveness of code and the performance numbers. The very much tunable GC makes things easier to control.</li></ul></li><li>Starling Bank – Java – <a href="https://www.infoq.com/presentations/starling-bank/">Link</a><ul><li>Exceptions are noisy and difficult to ignore</li><li>Reliable ecosystem (user base, tooling, job market, etc)&nbsp;</li><li>Integrations with legacy third parties (SOAP etc)</li></ul></li><li>KhanAcademy – Golang – <a href="https://blog.khanacademy.org/go-services-one-goliath-project/">Link</a><ul><li>Kotlin was more performant</li><li>Golang used much less memory</li></ul></li><li>Lyft – TypeScript – <a href="https://eng.lyft.com/typescript-at-lyft-64f0702346ea">Link</a><ul><li>Popularity</li><li>Type safety</li><li>Less Bugs</li><li>Productivity</li></ul></li><li>Medium – Golang – <a href="https://medium.engineering/rex-mediums-go-recommendation-microservice-e077bc9582a">Link</a><ul><li>More efficient use of the CPU. While Node is single-threaded, Go is much better suited for the combination of I/O and CPU-intensive operations required to build a ranked feed. Splitting our work onto separate Goroutines means we can avoid the issue of the CPU getting hogged by one single request and other requests getting starved.</li><li>Opinionated. Go makes it pretty hard to write “bad” code. A typed language that is also highly opinionated in terms of code styling means that even a newbie to Go (which I was when we started writing Rex) can quickly start writing clean and readable code.</li><li>Prior experience with Go. While much of Medium’s codebase is written in Node, we already had a few smaller-purpose microservices in Go. Adding another microservice in a language that we as a company have familiarity with makes building and maintaining this new service much easier.</li></ul></li><li>Instagram – Python – <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366">Link</a><ul><li>Simplicity</li><li>Practicality</li></ul></li></ol>



<p>I hope this post helps you understand that there is much more to choosing a programming language.</p>



<h5>You can also support me and my work by&nbsp;following me on  <a rel="noreferrer noopener" href="https://softwareleadweekly.us6.list-manage.com/track/click?u=1a258e0fefbb23214c59c5a8d&amp;id=278bdedb31&amp;e=219517c74f" target="_blank"></a><a rel="noreferrer noopener" href="https://twitter.com/shekhargulati" target="_blank">https://twitter.com/shekhargulati</a>.&nbsp;Thank you&nbsp;</h5>



<hr>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228886</guid>
            <pubDate>Mon, 22 Feb 2021 19:04:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People Who Wear Spectacles Are About Three Times Less Likely to Catch Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26228823">thread link</a>) | @throwawaysea
<br/>
February 22, 2021 | https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744 | <a href="https://web.archive.org/web/*/https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody" id="v_main"><p>A new study has revealed that people who wear glasses are up to three times less likely to catch novel Coronavirus infections. It was found that the eye protection was "statistically significant" to fight against the SARS-CoV-2 caused disease, COVID-19.</p><p>The study, which was also conducted in India, showed that poor and uneducated people were more likely to contract the novel Coronavirus. According to the research, this was because "they do not follow the preventive guidelines properly" and useless spectacles than the educated people.</p>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 1024px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 768px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i47011" src="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640" alt="Spectacles " title="Spectacles " width="640" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/47011/spectacles.jpg"><meta itemprop="width" content="640"><meta itemprop="height" content="427">
<figcaption>
<span itemprop="caption">Glasses wearers up to three times less likely to catch Covid</span>
<span itemprop="copyrightHolder">Pixabay</span>
</figcaption></div>
</figure><h3><strong>Spectacles and COVID-19</strong></h3><p>The research head, Amit Kumar Saxena, said the new study showed that the risk of <a href="https://www.ibtimes.sg/new-traffic-signal-lookalike-technology-could-help-reopen-international-airports-safely-55731" target="_blank">COVID-19</a> was two to three times less in spectacles wearing population while compared to those who do not wear glasses.</p><p>"Protective role of the spectacles was found statistically significant if those were used for a long period of the day. Touching and rubbing of the eyes with contaminated hands may be a significant route of infection," added Saxena.</p><p>During the study, it was also found that people touch their face on average 23 times in an hour and the eyes three times per hour. "Transmission occurs by touching the face, nose, mouth and eyes. Touching one's nose and mouth is significantly reduced when wearing a face mask properly. But wearing a face mask does not protect the eyes," said the study.</p><h3><strong>The COVID-19 Research</strong></h3>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 1024px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 768px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i45807" src="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640" alt="Coronavirus " title="Coronavirus " width="640" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg"><meta itemprop="width" content="640"><meta itemprop="height" content="360">
<figcaption>
<span itemprop="caption">Novel Coronavirus infection</span>
<span itemprop="copyrightHolder">Pixabay</span>
</figcaption></div>
</figure><p>The study, which was published in <a href="https://www.medrxiv.org/content/10.1101/2021.02.12.21249710v1" rel="nofollow" target="_blank">medRxiv</a>, included 304 Coronavirus patients. Their glasses-wearing behavior was assessed through a questionnaire. The answers were compared with existing studies of the general population.</p><p>As per the findings of the study, a total of 58 patients showed the behavior of using glasses continuously during the daytime and always on outdoor activities. The risk of Coronavirus infection was found 0.48 in spectacles wearing population as compared to 1.35 in the population not using them.</p><p>"The calculated risk ratio was 0.36. The protective effects of the spectacles were found statistically significant," said the study.</p><p>However, based on the findings it would be ideal for the healthcare workers to use face shields and wear goggles to protect their eyes while treating a <a href="https://www.ibtimes.sg/john-hopkins-expert-predicts-end-coronavirus-sufferings-by-april-us-55730" target="_blank">COVID-19 patient</a>. Scientists also said that wearing glasses does not protect the eyes as much as googles but it could provide some sort of protection.</p></div></div>]]>
            </description>
            <link>https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228823</guid>
            <pubDate>Mon, 22 Feb 2021 18:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a telnet chat server in 2021 with WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26227970">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | https://lunatic.solutions/blog/lunatic-chat/ | <a href="https://web.archive.org/web/*/https://lunatic.solutions/blog/lunatic-chat/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://lunatic.solutions/blog/lunatic-chat/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26227970</guid>
            <pubDate>Mon, 22 Feb 2021 18:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking the IDE for the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 54 (<a href="https://news.ycombinator.com/item?id=26227466">thread link</a>) | @fsynced
<br/>
February 22, 2021 | https://movingfulcrum.com/rethinking-the-ide-for-2020s/ | <a href="https://web.archive.org/web/*/https://movingfulcrum.com/rethinking-the-ide-for-2020s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
    
    


    <div id="ajax-container">
        
<div>
<article>
    

    <div>

        <p>Intellij IDEA has been an amazing professional-grade IDE for the last 20 years. However, as computer programs evolve, so must the IDE keep pace to remain a useful tool.</p><figure><blockquote><div lang="en" dir="ltr"><p>major IDE evolutions as I see:</p><p>2000s: using AST to represent text and building features around that. Intellij nailed this.</p><p>2010s: doing the same, but polyglot. Again Jetbrain's suite of IDEs adopted well in time.</p><p>2020s: support massive codebases across huge number of projects</p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1337817841567899649?ref_src=twsrc%5Etfw">December 12, 2020</a></blockquote>

</figure><h3 id="what-s-changed">What's Changed?</h3><p>A typical organization in the 2020s has:</p><ol><li>Hundreds of microservices</li><li>Hundreds of git repos</li><li>Polyglot codebase</li><li>APIs defined with HTTP/JSON/GRPC, not just programming language interfaces</li><li>Runtime service inter-dependencies</li><li>Cloud service dependencies</li></ol><p>Let's go through how each of these could impact the design of the IDE of the future. I will be using Intellij for comparison since it's the most advanced IDE currently.</p><h3 id="big-code-is-the-new-big-data">Big Code is the new Big Data</h3><p>With huge amounts of code across hundreds or even thousands of repos, the IDE has to now deal with 'Big Code'. It's big not just due to the sheer lines of code. It's the fact that it's divided into microservices, each of which has a separate set of dependencies, which the IDE now has to separately index. This can exponentially increase the amount of code to index compared to a single large codebase without so many external dependencies like the Linux kernel.</p><p>All operations in the IDE must assume huge amounts of code across hundreds of repositories, not all of them might be checked out locally. So things like Refactoring, Find Usages, Call hierarchy, etc have to be re-architected to run as long-running operations over code that could be both local or remote and still give users a seamless experience.</p><h3 id="refactoring">Refactoring</h3><p>Refactoring so far has really been a single repo feature. But what if the code you are refactoring is called by code in 100 other repos in your organization? What if those repos are not even checked out locally? The modern IDE needs to evolve beyond single repo operations. Maybe that rename refactoring now becomes a long-running operation that creates Pull Requests in various repos. This is not an easy problem to solve. Google even has a paper on this:</p><figure><blockquote><p lang="en" dir="ltr">Yes and in large monorepos refactoring involves mapreduce operations <a href="https://t.co/yc92gX1qem">https://t.co/yc92gX1qem</a></p>— Nagesh Susarla (@nageshs) <a href="https://twitter.com/nageshs/status/1337843676324589568?ref_src=twsrc%5Etfw">December 12, 2020</a></blockquote>

</figure><p>The complexity grows as API calls happen across services in various languages now and use HTTP/JSON or GRPC/ProtoBuf. Renaming a <code>struct</code> in one repo that gets serialized to JSON during an http api call might require renaming a similar <code>struct</code> in a whole different language that deserializes said JSON. This is way more complex than a simple Java function rename refactoring.</p><h3 id="version-control-ui">Version Control UI</h3><p>Version Control features in IDEs are really built around browsing/editing one git repo at a time. This simply doesn't work when your codebase is spread across hundreds of repos. The fundamental interface for the Git UI in Intellij (and other IDEs) needs to be rethought to deal with a large number of repos.</p><figure><blockquote><p lang="en" dir="ltr">The Git Log view in <a href="https://twitter.com/intellijidea?ref_src=twsrc%5Etfw">@intellijidea</a> is poorly designed with respect to multiple repositories. You need to use the mouse to get to this dropdown list in the view. Then you need to first *deselect* the current repo and select your new repo. <br>Dont think this was dogfooded by the devs. <a href="https://t.co/lZ0YHdrUth">pic.twitter.com/lZ0YHdrUth</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1349137311619981312?ref_src=twsrc%5Etfw">January 12, 2021</a></blockquote>

</figure><h3 id="rethinking-the-project-model">Rethinking the 'Project' model</h3><p>Currently, an <a href="http://astradot.com/">Astradot</a> engineer has to check out a git repo, eg <a href="https://github.com/astradot/kafka-schema-sync">https://github.com/astradot/kafka-schema-sync</a>, open the IDE, point to it, which will create an Intellij 'project' for the repo or a 'module' for an existing project. This is backward. The IDE should ask for the Github org eg, <a href="http://github.com/org">github.com/astradot</a> and it should create a single project that contains all the repo as modules. It should then manage lazy-loading/lazy-checkout or whatever is needed to give me a seamless experience browsing the code of my entire org.</p><h3 id="-run-button">'Run' button</h3><p>The 'Run' button will need to have more intelligence than simply running your app. In a microservice world, your service might depend upon an 'auth' service which might require a Postgres database and Redis instance initialized to some state. The services may rely on k8s service names to communicate, thus requiring running inside k8s. The IDE will need to be aware of the environment where you want to run your services and initialize the dependencies appropriately when you hit the 'Run' button.</p><p>The traditional debugger though is not going anywhere anytime soon. Take that from a guy who wrote a <a href="https://www.youtube.com/watch?v=LpfmKIxusZY">time-traveling one</a>, once upon a time. Though IDEs could take a page from APMs and benefit from showing a distributed trace in addition to breakpoint-based debugging.</p><h3 id="what-s-not-the-future">What's not the future</h3><p>Silicon Valley has been obsessed with making 'IDE in the Cloud' happen for the last decade. Every year a new set of cloud IDE startups is funded while the old ones die off. None of the problems they are solving help professional engineers.</p><figure><blockquote><div lang="en" dir="ltr"><p>Annual IDE startup bingo card:</p><p>- Downgrade 'IDE' part from Intellij to VSCode but hey, it opens in browser!</p><p>- See every keystroke of other engineers - 'Collaboration/Live coding'</p><p>- Code runs in tiny ec2 instance with horsepower of 90s laptop instead of your 12 core AMD pc</p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1363206351128723457?ref_src=twsrc%5Etfw">February 20, 2021</a></blockquote>

</figure><p>From an <a href="http://astradot.com/">Astradot</a> engineer's perspective:</p><ul><li>Downloading and Installing Intellij is a non-issue</li><li>We have scripts to setup your workstation environment within minutes with all the needed compilers, tooling, etc.</li><li>We never need to see each other live code. That would be annoying/intruding on the other engineer's privacy.</li><li>Workstations are powerful enough that they can run the entire <a href="http://astradot.com/">Astradot</a> locally.</li></ul><p>We would love to buy all our engineers 64 core Threadrippers w 128Gb ram if the IDE could make use of it.</p><h3 id="conclusion">Conclusion</h3><p>The IDE of the future is very different from what Intellij is today, both in terms of its architecture and UI. It requires solving some hard computer science problems. Jetbrains seems more focused on making just evolutionary changes to its IDEs to keep it ahead of VS Code. This is an opportunity for a new startup to rise.</p>
    </div>

    
</article></div>
    </div>
</div></div>]]>
            </description>
            <link>https://movingfulcrum.com/rethinking-the-ide-for-2020s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26227466</guid>
            <pubDate>Mon, 22 Feb 2021 17:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Totality – FP Explained]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26227055">thread link</a>) | @vrom911
<br/>
February 22, 2021 | https://kowainik.github.io/posts/totality | <a href="https://web.archive.org/web/*/https://kowainik.github.io/posts/totality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <div>
              <p>Along with the popular Functional Programming (FP) concepts such as purity or immutability, there is a significant one, which couldn’t boast much discussion around it — <strong>totality</strong>. Totality is an exceptionally interesting notion in the FP context. And you probably already use it and are aware of some pitfalls of not having totality in your code, but maybe the terminology doesn’t ring a bell.</p>
<p>In this blog post, we want to provide a comprehensive guide to the concept of totality in Functional Programming by demystifying its meaning, giving a lot of examples, and recommending how to get tools to help you write maintainable, testable code. You will find this blog post helpful if you are interested in understanding the fundamentals of FP.</p>
<blockquote>
<p>Note: we will use Haskell to demonstrate and explain the totality, but the involved concepts apply to any programming language.</p>
</blockquote>
<p>Ready?</p>
<figure>
<img src="https://kowainik.github.io/images/totality/mortal-kompose-start.gif" alt="Press Start">
</figure>
<h2 id="definition">Definition<a href="#definition">🔗</a></h2>
<p><strong>Functions</strong> are core elements of Functional Programming. Functions are expressions that have a type that could be primitive or more complex. We can say that each function has an input, 0 or more arguments of some type and only one output, returning type. In other words, a function transforms its inputs to the output, and the function definition describes what actual work a function does to produce its result.</p>
<p>A function is <strong>total</strong> if it is defined for all inputs of its corresponding type, or in other words, if a function returns the output on any possible values of the input types.</p>
<p>For example, the following function that checks if the given integer is zero is total:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>isZero ::</span> <span>Integer</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb1-2">isZero n <span>=</span> n <span>==</span> <span>0</span></span></code></pre></div>
<p>The above function is defined for any value of type <code>Integer</code>. No matter what it would receive as the argument, it will always return the answer – <code>True</code> or <code>False</code>.</p>
<p>On the other hand, a function like “integral division” is <strong>partial</strong> (non-total). Though the division works perfectly on most of the inputs, the result of division by zero is not defined; therefore, there is an argument on which the function can’t return a reasonable result (and that’s why you may find the <code>isZero</code> function helpful). Partial functions are not defined on all their inputs and usually blow up when given something they cannot handle.</p>
<figure>
<img src="https://kowainik.github.io/images/totality/totality-functional.png" alt="Partial Functions">
</figure>
<h3 id="is-that-math">Is that math?<a href="#is-that-math">🔗</a></h3>
<figure>
<img src="https://kowainik.github.io/images/totality/fp-vs-math.png" alt="FP vs Math">
</figure>
<p>The definition of totality originated in math. It has a similar formulation to what we provided above and could be understood in the same way.</p>
<p>Total function is a function defined for all elements in its domain. The domain is the set of x-values that can be put into a function. In other words, it’s the set of all possible values of the independent variable.</p>
<p>We can notice that the math function domain is the same as the input of our functions.</p>
<p>The following image is the canonical way to represent math functions, mapping values from domain A to values of range B. If it were a programming function, we would say that it maps type A to type B. Both total and partial way could be illustrated in that manner:</p>
<figure>
<img src="https://kowainik.github.io/images/totality/totality-math.png" alt="Totality in math">
</figure>
<p>However, despite all similarities, functions in programming are a bit different because they have a notion of <em>computation</em>.</p>
<p>Math doesn’t consider how long it takes for a function to calculate or how much memory it needs. Moreover, functions in programming can hang, and it is vital to keep this in mind when you write code.</p>
<p>Functions in math also don’t have side-effects, e.g.&nbsp;reading from file. But all these concerns are valid in the context of programming.</p>
<p>To summarise, here is a short list of possible things that functions in programming can do, and math functions cannot:</p>
<ul>
<li>Hang (loop indefinitely or takes unreasonable time to compute)</li>
<li>Throw exceptions</li>
<li>Terminate before producing a result in case of insufficient memory</li>
<li>Have side-effects (read from files, send requests to web services, etc.)</li>
</ul>
<p>Functional Programming is closer to the original math definition in the sense that its functions are pure – they have no side-effects. This essential FP paradigm allows us to talk about the concept of totality in a programming context, even though programming functions are very different from math functions.</p>
<h3 id="termination">Termination*<a href="#termination">🔗</a></h3>
<p><em>advanced section, could be skipped</em></p>
<p>As we look at totality from the programming point of view, we need to describe a very close concept to totality — <strong>termination</strong>. Termination gives the guarantee that function does produce a result in a finite amount of time. Usually, when people talk about <strong>total functional programming</strong>, they mean programming with <em>total</em> functions that <em>terminate successfully</em>.</p>
<hr>
<p>This concept of termination is more relevant to advanced languages called <em>proof-assistants</em> used to write proofs as programming functions. In such languages, successful proof must be a total and terminating function. Proof-assistants are invaluable in the software verification areas.</p>
<p>However, in real-life software, not all functions must be total. For instance, a Read-Eval-Print-Loop (REPL) or a Web Backend are not supposed to terminate eventually on their own. They should run infinitely and respond to requests in a timely manner.</p>
<hr>
<p>The terminology of totality is a bit ambiguous in programming due to the different use-cases. In some places, total functions are required to terminate, while others require only to handle all inputs’ values. We will try to cover the most common definition of totality in this post.</p>
<p>Note as well that totality is not a straightforward and universally-applicable idea. We will make a few common simplifications in this post regarding totality in modern languages. But bear in mind that there are a lot of specifics that need to be kept in view. There are different methods of making functions total and guaranteeing this property for compiled vs interpreted, for typed vs untyped languages.</p>
<hr>
<p>Another aspect — <strong>laziness</strong>; it also affects the work of pure functions in different ways. Infinite functions could be total (with termination notion) due to laziness. For instance, the following recursive function produces an infinite list. And if you’ll try to print the resulting list to the terminal, you will wait indefinitely for this function to finish:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>multipliedByTwo ::</span> <span>Int</span> <span>-&gt;</span> [<span>Int</span>]</span>
<span id="cb2-2">multipliedByTwo x <span>=</span> x <span>:</span> multipliedByTwo (x <span>*</span> <span>2</span>)</span></code></pre></div>
<p>However, due to laziness, you still can take the first five elements of the list and get the result:</p>
<div id="cb3"><pre><code><span id="cb3-1">ghci<span>&gt;</span> <span>take</span> <span>5</span> (multipliedByTwo <span>3</span>)</span>
<span id="cb3-2">[<span>3</span>, <span>6</span>, <span>12</span>, <span>24</span>, <span>48</span>]</span></code></pre></div>
<hr>
<p>If being absolutely honest, Haskell is not a total functional programming language by default. It has a special value called <em>“bottom”</em> (⊥) that can be passed to any pure function. When such a value is being evaluated, it throws a runtime error. You can use standard Haskell functions <code>undefined</code> or <code>error</code> at the bottom. It means that even the pure and total function <code>isZero</code> we defined above could fail in runtime if used on bottom elements:</p>
<div id="cb4"><pre><code><span id="cb4-1">ghci<span>&gt;</span> isZero <span>undefined</span></span>
<span id="cb4-2"><span>***</span> <span>Exception</span><span>:</span> Prelude.undefined</span>
<span id="cb4-3"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb4-4">  <span>error</span>, called at libraries<span>/</span>base<span>/</span><span>GHC</span><span>/</span>Err.hs<span>:</span><span>79</span><span>:</span><span>14</span> <span>in</span> base<span>:</span><span>GHC.Err</span></span>
<span id="cb4-5">  <span>undefined</span>, called at <span>&lt;</span>interactive<span>&gt;:</span><span>2</span><span>:</span><span>8</span> <span>in</span> interactive<span>:</span><span>Ghci1</span></span>
<span id="cb4-6"></span>
<span id="cb4-7">ghci<span>&gt;</span> isZero (<span>error</span> <span>"I'm a banana, I do what I wanna"</span>)</span>
<span id="cb4-8"><span>***</span> <span>Exception</span><span>:</span> <span>I'm</span> a banana, <span>I</span> <span>do</span> what <span>I</span> wanna</span>
<span id="cb4-9"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb4-10">  <span>error</span>, called at <span>&lt;</span>interactive<span>&gt;:</span><span>3</span><span>:</span><span>9</span> <span>in</span> interactive<span>:</span><span>Ghci1</span></span></code></pre></div>
<p>To design a complete total system, we need to have the input set without bottom (⊥) elements. An example of pure total language is <a href="https://dhall-lang.org/">Dhall</a> — a configuration language where all functions must be pure, total and terminating.</p>
<p>If interested, you can read more about research in total functional programming (see in <a href="#links">Links</a>).</p>
<h2 id="not-totally-total">Not totally total<a href="#not-totally-total">🔗</a></h2>
<figure>
<img src="https://kowainik.github.io/images/totality/Fight.gif" alt="Fight">
</figure>
<p>Usually, in FP, you don’t use the phrase “total function” as, by default, functions are considered to be total. However, this can’t be the case all the time; it would be too easy. There is an opposite concept of <em>totality</em> – <strong>partiality</strong>, which means that a function is <strong>not</strong> defined for all inputs of its type.</p>
<p>Here are a few examples of common partial functions:</p>
<ul>
<li><strong>Taking a list element by index.</strong> The index can be negative or be outside the list bounds, so it’s impossible to get the element in such cases.</li>
<li><strong>Parsing string to an integer.</strong> Not every string represents a valid numeric number, so a parsing function fails in such cases.</li>
<li><strong>Printf-like pretty-printing.</strong> If you specify the formatting with a separate string, it may fail at runtime on a wrong number of arguments or when types of arguments don’t match.</li>
<li><strong>Mathematical functions</strong>: division by zero, square root of a negative number, etc.</li>
<li><strong>Multiplication of matrices.</strong> If the dimensions of the two matrices are not aligned, it is impossible to multiply one matrix with another.</li>
<li>Laziness brings more interesting partiality cases to the table. When you can have infinite lists, functions like <code>sum</code>, <code>sort</code> or <code>reverse</code> become partial because they hang on infinite lists.</li>
</ul>
<h2 id="why-should-we-care">Why should we care?<a href="#why-should-we-care">🔗</a></h2>
<p>As a developer, you have to deal with runtime exceptions all the time. Programming with total functions helps to avoid some of the runtime exceptions by ultimately preventing them from happening in the first place. But, at the same time, it requires time and discipline to write total functions. So you may think that writing total functions is a big price to pay for reducing the number of runtime exceptions since total functions won’t remove all exceptions entirely. But we believe that you actually should care about totality due to the few other perks as well:</p>
<ul>
<li>Even when writing a huge number of unit tests, you still can miss some cases. Total functional programming gives more guarantees about code correctness.</li>
<li>Debugging runtime exceptions can be tedious for developers. But users of buggy products are frustrated even more. Spending more time on making functions total pays off in the long run.</li>
<li>Total functional programming results in more maintainable, modular and composable programming. The composition of total functions is total. It means that you can refactor your code painlessly, split it into smaller and reusable parts, combine different components, and still be confident that it works. While working with partial functions, you may …</li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kowainik.github.io/posts/totality">https://kowainik.github.io/posts/totality</a></em></p>]]>
            </description>
            <link>https://kowainik.github.io/posts/totality</link>
            <guid isPermaLink="false">hacker-news-small-sites-26227055</guid>
            <pubDate>Mon, 22 Feb 2021 17:14:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F# Units of Measure – A Worked Example]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26226932">thread link</a>) | @dunefox
<br/>
February 22, 2021 | http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/ | <a href="https://web.archive.org/web/*/http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

<p>Have you ever wished that you could have type safe calculations throughout your application?<br>
Well through the use of F# Units of Measure (UoM), now you can!</p>

<p>In this post I will explore the various ways of using F# Units of Measure and the benefits they bring.<br>
Before I started writing this article, I had not used units of measure before. I therefore thought it would be a good idea to aid the learning process by applying them in a small project.
To do this, I decided to put UoM to the test by applying them in a real world example; The calculations required to brew beer.</p>

<p>What follows is a thorough walkthrough of using Units of Measure based upon my experiences while implementing a library of calculations for use in the various stages of brewing beer.<br>
I aim to highlight how, through the use of units of measure, we can increase the robustness of our code and hopefully eliminate potential runtime errors.</p>

<!-- more -->

<h2>Units of Measure - An introduction</h2>

<p>Units of measure in F# are a type of metadata that can be associated with floating point or signed integer values.<br>
By associating a UoM with a quantity value it allows the F# compiler to perform additional type checking on the use of these units, enforcing relationships between units in arithmetic and reducing potential errors.</p>

<p>To declare a unit of measure you use the <code>[&lt;Measure&gt;]</code> attribute, followed by the <code>type</code> keyword and the name we want to give the measure.</p>

<p>For example, we can declare units of measure for some of the measures of volume we will need when calculating the ingredients in beer recipes.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
<span>4: </span>
<span>5: </span>
</pre>
</td>
<td><pre><span>///Litre (or Liter in the US)</span>
[&lt;<span onmouseout="hideTip(event, 'fs9', 16)" onmouseover="showTip(event, 'fs9', 16)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs13', 17)" onmouseover="showTip(event, 'fs13', 17)">L</span>

<span>///Us Gallon</span>
[&lt;<span onmouseout="hideTip(event, 'fs9', 18)" onmouseover="showTip(event, 'fs9', 18)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs14', 19)" onmouseover="showTip(event, 'fs14', 19)">usGal</span>
</pre>
</td>
</tr>
</tbody></table>

<p>Using a measure is as simple as annotating a float literal.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
</pre>
</td>
<td><pre><span>//Volume in litres</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs15', 20)" onmouseover="showTip(event, 'fs15', 20)">volume</span> <span>=</span> <span>120.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs13', 21)" onmouseover="showTip(event, 'fs13', 21)">L</span><span>&gt;</span>
</pre>
</td>
</tr>
</tbody></table>

<p>A value that has a unit of measure associated with it is said to have a <em>dimension</em> or be <em>dimensioned</em>.</p>

<p>Units of measure can be utilised in a number of ways.</p>

<ul>
<li>To constrain the values involved in calculations to particular measures</li>
<li>To provide type safe conversions between measures</li>
<li>For defining new units of measure in terms of the original</li>
<li>In types to create associations between different measures</li>
</ul>

<p>This is in no way a definitive list. They are just a few of the ways I found measures particularly beneficial during my time exploring there usage.<br>
If anyone has any other useful applications I would love to hear about them.</p>

<h2>Defining units of measure in terms of others</h2>

<p>Sometimes, it can be a useful technique to define a unit of measure in terms of other previously defined measures.<br>
Doing so allows us to use the <em>derived</em> measures in place of inferred results of calculations which can increase code clarity.</p>

<p>Let's take an example from the brewing process.</p>

<p>We often need to associate something called gravity points, with a volume of liquid.<br>
Gravity points are a very simplified definition of the amount of sugar in liquid. Obviously, this liquid could be in any number of units, and it is paramount that we ensure we do not mix measures of volume, for example, during recipe planning.</p>

<p>One common measurement used in home brewing circles is that of points per gallon (or points per pound per gallon - PPG) so let's define a measure for that.<br>
Firstly, we need to define a measure for gravity points.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
</pre>
</td>
<td><pre><span>///Gravity Point - A Simplified brewing unit for amount of sugar dissolved in solution</span>
[&lt;<span onmouseout="hideTip(event, 'fs9', 22)" onmouseover="showTip(event, 'fs9', 22)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs16', 23)" onmouseover="showTip(event, 'fs16', 23)">gp</span>
</pre>
</td>
</tr>
</tbody></table>

<p>Next up, we define the <em>association</em> between gravity points and US gallons.</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre>[&lt;<span onmouseout="hideTip(event, 'fs9', 24)" onmouseover="showTip(event, 'fs9', 24)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs17', 25)" onmouseover="showTip(event, 'fs17', 25)">ppg</span> <span>=</span> <span onmouseout="hideTip(event, 'fs16', 26)" onmouseover="showTip(event, 'fs16', 26)">gp</span> <span>/</span> <span onmouseout="hideTip(event, 'fs14', 27)" onmouseover="showTip(event, 'fs14', 27)">usGal</span>
</pre>
</td>
</tr>
</tbody></table>

<p>Our <code>ppg</code> measure can now be used in our calculations, which we'll get to in a minute.<br>
But first, a few quick points on this type of measure.</p>

<ul>
<li>The formulas that represent the measures can be written in various equivalent ways. This sometimes manifests in the results of expressions being inferred differently than we would expect - more on this later.</li>
<li>Equivalent formulas are compiled into a common representation and can therefore be substituted freely.</li>
<li>You cannot use numeric values in these formulae. However, we can declare conversion constants which we will also explore later.</li>
<li>You can use <code>1</code> in these formulae. <code>1</code> represents a <em>dimensionless</em> value. I will touch on dimensionless values when discussing error prevention in the next section.</li>
</ul>

<p>These points and others are explained in detail on the <a href="https://msdn.microsoft.com/en-us/library/dd233243.aspx">MSDN</a> page for Units of Measure.</p>

<h2>Using Units of Measure for error prevention</h2>

<p>Units of measure come in extremely handy for preventing us introducing errors into our code by using a value with an incorrect unit in a calculation or function.<br>
As an example taken from the world of brewing, we wouldn't want to mix up the units when making calculations about how much grain we need.</p>

<p>Below is an example of a function that can only take values with the specified dimensions.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
</pre>
</td>
<td><pre><span>///Converts a points per gal (gp / usGal) and volume into total gravity points in that volume</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs18', 28)" onmouseover="showTip(event, 'fs18', 28)">TotalGravityPoints</span> (<span onmouseout="hideTip(event, 'fs19', 29)" onmouseover="showTip(event, 'fs19', 29)">potential</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 30)" onmouseover="showTip(event, 'fs20', 30)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 31)" onmouseover="showTip(event, 'fs16', 31)">gp</span> <span>/</span> <span onmouseout="hideTip(event, 'fs14', 32)" onmouseover="showTip(event, 'fs14', 32)">usGal</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs21', 33)" onmouseover="showTip(event, 'fs21', 33)">vol</span> <span>:</span> <span onmouseout="hideTip(event, 'fs20', 34)" onmouseover="showTip(event, 'fs20', 34)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 35)" onmouseover="showTip(event, 'fs14', 35)">usGal</span><span>&gt;</span>) <span>=</span>  
    <span onmouseout="hideTip(event, 'fs19', 36)" onmouseover="showTip(event, 'fs19', 36)">potential</span> <span>*</span> <span onmouseout="hideTip(event, 'fs21', 37)" onmouseover="showTip(event, 'fs21', 37)">vol</span>
</pre>
</td>
</tr>
</tbody></table>

<p>As you can see, this function is declared with explicit type annotations specifying the dimensions of the parameters.<br>
The F# compiler will now prevent you from using this function with either dimensionless floats, or floats with the the wrong dimension (and of course, non float values).</p>

<p>Consider the following example where we attempt to call the function with dimensionless values:</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs22', 38)" onmouseover="showTip(event, 'fs22', 38)">totalGravPoints</span> <span>=</span> <span onmouseout="hideTip(event, 'fs18', 39)" onmouseover="showTip(event, 'fs18', 39)">TotalGravityPoints</span> <span>240.0</span> <span>5.0</span>
</pre>
</td>
</tr>
</tbody></table>

<p>Attempting to compile this line of code produces the following error notifying us that we haven't satisfied the type constraints and preventing us from introducing an error into our code.</p>

<div><pre lang="output">error FS0001: This expression was expected to have type
float&lt;gp/usGal&gt;    
    but here has type
float 
</pre></div>

<p>Likewise the compiler will stop us from passing different <code>UoM</code> to the function. 
Suppose we attempted to use a volume in Litres instead of the expected US Gallons.</p>

<p>We receive a similar error.</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs22', 40)" onmouseover="showTip(event, 'fs22', 40)">totalGravPoints</span> <span>=</span> <span onmouseout="hideTip(event, 'fs18', 41)" onmouseover="showTip(event, 'fs18', 41)">TotalGravityPoints</span> <span>240.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 42)" onmouseover="showTip(event, 'fs16', 42)">gp</span> <span>/</span> <span onmouseout="hideTip(event, 'fs14', 43)" onmouseover="showTip(event, 'fs14', 43)">usGal</span><span>&gt;</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs13', 44)" onmouseover="showTip(event, 'fs13', 44)">L</span><span>&gt;</span>
</pre>
</td>
</tr>
</tbody></table>

<div><pre lang="output">error FS0001: Type mismatch. Expecting a
    float&lt;usGal&gt;    
but given a
    float&lt;L&gt;    
The unit of measure 'usGal' does not match the unit of measure 'L'
</pre></div>

<p>This example may be quite contrived, but it highlights the type safety provided by units of measure.
The F# compiler will also prevent us introducing arithmetic errors such as attempting to add/subtract a different or dimensionless unit from another.<br>
For instance, the following would not compile, returning the errors shown.</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs15', 45)" onmouseover="showTip(event, 'fs15', 45)">volume</span> <span>=</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 46)" onmouseover="showTip(event, 'fs14', 46)">usGal</span><span>&gt;</span> <span>+</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs13', 47)" onmouseover="showTip(event, 'fs13', 47)">L</span><span>&gt;</span>
</pre>
</td>
</tr>
</tbody></table>

<div><pre lang="output">//result
error FS0001: The unit of measure 'L' does not match the unit of measure 'usGal'
</pre></div>

<p>Likewise attempting to use a dimensionless value would also fail.</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs15', 48)" onmouseover="showTip(event, 'fs15', 48)">volume</span> <span>=</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 49)" onmouseover="showTip(event, 'fs14', 49)">usGal</span><span>&gt;</span> <span>+</span> <span>5.0</span>
</pre>
</td>
</tr>
</tbody></table>

<div><pre lang="output">//result
error FS0001: The type 'float' does not match the type 'float&lt;usGal&gt;'
</pre></div>

<p>A dimensionless value can either be declared simply with no measure, as above, or with the explicit measure of <code>1</code> like so:</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs15', 50)" onmouseover="showTip(event, 'fs15', 50)">volume</span> <span>=</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 51)" onmouseover="showTip(event, 'fs14', 51)">usGal</span><span>&gt;</span> <span>+</span> <span>5.0</span><span>&lt;</span><span>1</span><span>&gt;</span>
</pre>
</td>
</tr>
</tbody></table>

<div><pre lang="output">//result
error FS0001: The type 'float' does not match the type 'float&lt;usGal&gt;'
</pre></div>

<p>Although we cannot add/subtract different or dimensionless values from an already dimensioned value, we can multiply or divide them.<br>
Multiplying or dividing by a dimensionless value will result in same measure, however using a different measure in the calculation will result in a different (potentially new) measure.</p>

<p>This brings us nicely to our next section.</p>

<h2>Effects of multiplication and division</h2>

<p>By multiplying or dividing a value that either has a measure already, or is dimensionless, we can create new units of measure.<br>
The result of this process is effectively to <em>combine</em> two different units of measure (remember, a dimensionless value can be thought of as having a measure of 1).</p>

<p>We have already declared a unit of measure that can be used to demonstrate this, our <code>ppg</code> measure.<br>
A <code>ppg</code> value is simply a <code>gp</code> value divided by a <code>usGal</code> value.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs23', 52)" onmouseover="showTip(event, 'fs23', 52)">totalGravityPoints</span> <span>=</span> <span>240.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 53)" onmouseover="showTip(event, 'fs16', 53)">gp</span><span>&gt;</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs24', 54)" onmouseover="showTip(event, 'fs24', 54)">beerVolume</span> <span>=</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 55)" onmouseover="showTip(event, 'fs14', 55)">usGal</span><span>&gt;</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs25', 56)" onmouseover="showTip(event, 'fs25', 56)">pointsPerGallon</span> <span>=</span> <span onmouseout="hideTip(event, 'fs23', 57)" onmouseover="showTip(event, 'fs23', 57)">totalGravityPoints</span> <span>/</span> <span onmouseout="hideTip(event, 'fs24', 58)" onmouseover="showTip(event, 'fs24', 58)">beerVolume</span>
</pre>
</td>
</tr>
</tbody></table>

<p>The value of pointsPerGallon above is just what we would expect.</p>

<div><pre lang="output">val pointsPerGallon : float&lt;gp/usGal&gt; = 48.0
</pre></div>

<p>The exact same principle works for multiplication too and don't forget, two or more units of measure can be considered equal.</p>

<h2>Type inference and measure equality</h2>

<p>Lets take the following function as an example;</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
</pre>
</td>
<td><pre><span>///Calculates the maximum potential gravity points for a given weight of grain with the given potential and target volume</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs26', 59)" onmouseover="showTip(event, 'fs26', 59)">MaxPotentialPoints</span> (<span onmouseout="hideTip(event, 'fs27', 60)" onmouseover="showTip(event, 'fs27', 60)">grainPotential</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 61)" onmouseover="showTip(event, 'fs20', 61)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 62)" onmouseover="showTip(event, 'fs16', 62)">gp</span><span>/</span><span onmouseout="hideTip(event, 'fs11', 63)" onmouseover="showTip(event, 'fs11', 63)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs28', 64)" onmouseover="showTip(event, 'fs28', 64)">grain</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 65)" onmouseover="showTip(event, 'fs20', 65)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs11', 66)" onmouseover="showTip(event, 'fs11', 66)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs21', 67)" onmouseover="showTip(event, 'fs21', 67)">vol</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 68)" onmouseover="showTip(event, 'fs20', 68)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 69)" onmouseover="showTip(event, 'fs14', 69)">usGal</span><span>&gt;</span>) <span>=</span> 
    (<span onmouseout="hideTip(event, 'fs27', 70)" onmouseover="showTip(event, 'fs27', 70)">grainPotential</span> <span>*</span> <span onmouseout="hideTip(event, 'fs28', 71)" onmouseover="showTip(event, 'fs28', 71)">grain</span>) <span>/</span> <span onmouseout="hideTip(event, 'fs21', 72)" onmouseover="showTip(event, 'fs21', 72)">vol</span>
</pre>
</td>
</tr>
</tbody></table>

<p>The F# compiler correctly infers that the result of this function is of the type <code>float&lt;gp/usGal&gt;</code> (hover over the function above to see this)</p>

<p>We also know that equivalent measures are interchangeable.<br>
This means, we could alternatively declare this function as returning a <code>&lt;ppg&gt;</code> measure explicitly like so.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
</pre>
</td>
<td><pre><span>//Explicit return type</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs29', 73)" onmouseover="showTip(event, 'fs29', 73)">MaxPotentialPoints</span> (<span onmouseout="hideTip(event, 'fs27', 74)" onmouseover="showTip(event, 'fs27', 74)">grainPotential</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 75)" onmouseover="showTip(event, 'fs20', 75)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 76)" onmouseover="showTip(event, 'fs16', 76)">gp</span><span>/</span><span onmouseout="hideTip(event, 'fs11', 77)" onmouseover="showTip(event, 'fs11', 77)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs28', 78)" onmouseover="showTip(event, 'fs28', 78)">grain</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 79)" onmouseover="showTip(event, 'fs20', 79)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs11', 80)" onmouseover="showTip(event, 'fs11', 80)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs21', 81)" onmouseover="showTip(event, 'fs21', 81)">vol</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 82)" onmouseover="showTip(event, 'fs20', 82)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 83)" onmouseover="showTip(event, 'fs14', 83)">usGal</span><span>&gt;</span>) <span>:</span><span onmouseout="hideTip(event, 'fs20', 84)" onmouseover="showTip(event, 'fs20', 84)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs17', 85)" onmouseover="showTip(event, 'fs17', 85)">ppg</span><span>&gt;</span> <span>=</span> 
    (<span onmouseout="hideTip(event, 'fs27', 86)" onmouseover="showTip(event, 'fs27', 86)">grainPotential</span> <span>*</span> <span onmouseout="hideTip(event, 'fs28', 87)" onmouseover="showTip(event, 'fs28', 87)">grain</span>) <span>/</span> <span onmouseout="hideTip(event, 'fs21', 88)" onmouseover="showTip(event, 'fs21', 88)">vol</span>
</pre>
</td>
</tr>
</tbody></table>

<p>The F# type system will allow us to use either of these functions where the alternative dimension is required (i.e. a <code>ppg</code> where a <code>gp/usGal</code> is expected).
I did find however, that in certain situations, it can make code much clearer to be explicit about the return type.</p>

<p>Consider the following example where we use a <code>pgp</code> measure instead of the <code>gp/lb</code> for the grainPotential:</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
<span>4: </span>
<span>5: </span>
</pre>
</td>
<td><pre><span>///Potential Gravity Points - The number of Gravity points in a lb of a particular malt</span>
[&lt;<span onmouseout="hideTip(event, 'fs9', 89)" onmouseover="showTip(event, 'fs9', 89)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs30', 90)" onmouseover="showTip(event, 'fs30', 90)">pgp</span> <span>=</span> <span onmouseout="hideTip(event, 'fs16', 91)" onmouseover="showTip(event, 'fs16', 91)">gp</span> <span>/</span> <span onmouseout="hideTip(event, 'fs11', 92)" onmouseover="showTip(event, 'fs11', 92)">lb</span>

<span>let</span> <span onmouseout="hideTip(event, 'fs31', 93)" onmouseover="showTip(event, 'fs31', 93)">MaxPotentialPoints</span> (<span onmouseout="hideTip(event, 'fs32', 94)" onmouseover="showTip(event, 'fs32', 94)">grainPotential</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 95)" onmouseover="showTip(event, 'fs20', 95)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs30', 96)" onmouseover="showTip(event, 'fs30', 96)">pgp</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs28', 97)" onmouseover="showTip(event, 'fs28', 97)">grain</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 98)" onmouseover="showTip(event, 'fs20', 98)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs11', 99)" onmouseover="showTip(event, 'fs11', 99)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs21', 100)" onmouseover="showTip(event, 'fs21', 100)">vol</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 101)" onmouseover="showTip(event, 'fs20', 101)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 102)" onmouseover="showTip(event, 'fs14', 102)">usGal</span><span>&gt;</span>) <span>=</span> 
    (<span onmouseout="hideTip(event, 'fs32', 103)" onmouseover="showTip(event, 'fs32', 103)">grainPotential</span> <span>*</span> <span onmouseout="hideTip(event, 'fs28', 104)" onmouseover="showTip(event, 'fs28', 104)">grain</span>) <span>/</span> <span onmouseout="hideTip(event, 'fs21', 105)" onmouseover="showTip(event, 'fs21', 105)">vol</span>
</pre>
</td>
</tr>
</tbody></table>

<p>If you look at the inferred return type of this function you will see it is <code>float&lt;lb pgp/usGal&gt;</code>.<br>
While this is perfectly correct, it can be confusing.</p>

<p>We can clearly see that the <code>pgp</code> measure is equivalent to that of <code>gp…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/">http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/</a></em></p>]]>
            </description>
            <link>http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226932</guid>
            <pubDate>Mon, 22 Feb 2021 17:06:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Living Like It's 99: No Social Media, No Smartphone]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 150 (<a href="https://news.ycombinator.com/item?id=26226864">thread link</a>) | @betaman0
<br/>
February 22, 2021 | https://www.alvarez.io/posts/living-like-it-s-99/ | <a href="https://web.archive.org/web/*/https://www.alvarez.io/posts/living-like-it-s-99/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><img src="https://www.alvarez.io/img/color/l99.jpg" alt="Robot"></p>
<p>At the time of writing this article, I’ve been living without social media for 3 years and without a smartphone for 2 years. Everything started as an experiment motivated by my privacy concerns. I ended up living like that for an entire different reason: peace of mind. You can find a lot of people on internet that have tried this experiment, from a couple of days to an <a href="https://www.youtube.com/watch?v=B0RVWU_nROk">entire month</a>. However I discovered that the brain dependencies created by social media and smartphones take a lot longer to go away (30 days for me). You can’t really see the effects it has on your life unless you try this kind of experiment for a long time, because you will be stuck in the withdrawal phase that makes you crave dopamine.</p>
<p>Contrary to popular belief, I do not live in a cave where I spend my time coding without any social life, sorry guys ;) I did this experiment while having a busy professional and personal life: I traveled around the world, moved to a new city without knowing anyone, ran <a href="https://www.duple.io/">my own software startup</a>, met new people and made new friends, etc… So it is possible to live your life the same way, or even better, without a smartphone or social media.</p>
<p>I will share with you my experience leaving social media and my smartphone, the tools I replaced them with, some tips and tricks, people’s reactions to my experiment, as well as some funny anecdotes.</p>
<h2 id="lets-start-with-why">Let’s Start With Why</h2>
<h3 id="privacy">Privacy</h3>
<p>The original motivation behind this experiment was privacy. I’m a professional hacker, the things I can do are scary and I’m far from being the only one with these skills. <strong>Smartphones are a dream come true for people like me, little spy devices that are 24/7 on you, remotely accessible from anywhere around the world</strong>. Throw social media into the equation, and you can get inside the head of anybody, and make them do whatever you want. Yes, you should be scared. And that’s even without mentioning all the other <a href="https://lithub.com/what-does-privacy-really-mean-under-surveillance-capitalism/">privacy</a> and <a href="https://the.ink/p/we-can-have-democracy-or-we-can-have">freedom</a> issues that come with <a href="https://techcrunch.com/2019/09/04/facebook-phone-numbers-exposed/">social media</a> and <a href="https://nrkbeta.no/2020/12/03/my-phone-was-spying-on-me-so-i-tracked-down-the-surveillants/">smartphones</a>.</p>
<h3 id="curiosity">Curiosity</h3>
<p>Another reason, which is less dark, was curiosity. I like to experiment and try new things in my life. I was curious about the idea of living without a smartphone and social media especially in a world more connected than ever. And if I didn’t like the experiment, I could always go back to <a href="https://www.meta-nomad.net/avoiding-the-global-lobotomy/">zombieland</a>.</p>
<h3 id="planned-obsolescence">Planned Obsolescence</h3>
<p>The cherry on top was to stop paying each year for a new smartphone, that does nothing more than the previous one, just because the providers decided to <a href="https://en.wikipedia.org/wiki/Planned_obsolescence">sabotage old models</a> so they <a href="https://en.wikipedia.org/wiki/Batterygate">stop working</a>.</p>
<h3 id="peace-of-mind">Peace of mind</h3>
<p>This is for me the most important reason (even though I discovered it afterwards). The positive effects on your mind, being free from social media and smartphones, are incredible. More on it later.</p>

<blockquote>
<p>“Technology has solved old economics problems by giving us new psychological problems.”<br>
Mark Manson, The Subtle Art of Not Giving a F*ck</p>
</blockquote>
<p>In 2018 I deleted my accounts from Twitter, Facebook, Instagram and WhatsApp. No coming back, no temptation to reactivate them later on. I kept LinkedIn on standby for professional use although it came close to being deleted as well. WhatsApp got replaced by <a href="https://signal.org/">Signal</a> because Facebook bought them, plus <a href="https://www.forbes.com/sites/parmyolson/2018/09/26/exclusive-whatsapp-cofounder-brian-acton-gives-the-inside-story-on-deletefacebook-and-why-he-left-850-million-behind/">they’re not really big fan s of privacy</a>.</p>
<p>During that year I kept my smartphone, as I wanted to do the experiment gradually. This decision allowed me to discover something quite counter intuitive about social media and smartphones (more on it later).</p>
<p>From that point on I was reachable by SMS, call, email and Signal. I wasn’t ready for what happened next. Fasten your seatbelts.</p>
<h3 id="people-thought-i-was-dead">People Thought I Was Dead</h3>
<p>The first reaction people had was to think something bad had happened to me, some of them even thought I was dead. Then something socially curious happened: everybody started speaking to each other on Facebook and WhatsApp to try to figure out what was wrong. Some of them even contacted my family multiple times. They all had my phone number, email address and other ways of contacting me. <strong>However, none of them did</strong>. It was like I had exited the matrix, and was living in another reality.</p>
<h3 id="trustworthiness">Trustworthiness</h3>
<p>I was told that I couldn’t be trusted since people can’t check online what I’m doing when I’m not around.</p>
<p>Yeah, you read that right.</p>
<p><strong>Society has been brainwashed to believe that privacy is something criminal. Sorry to disappoint, but privacy is a basic fundament of freedom and democracy. That’s why the voting system is anonymous</strong> [1]. When people tell you “<a href="https://write.privacytools.io/freddy/why-privacy-matters-even-if-you-have-nothing-to-hide">If you have nothing to hide, you have nothing to fear</a>”, what they really mean is “democracy is overrated, get over it”.</p>
<p><em>[1] Privacy: you know who I am but not what I do. Anonymity: You know what I do but not who I am. The voting system uses both, privacy when you go vote, anonymity when they count the results.</em></p>
<h3 id="whatsapp">WhatsApp</h3>
<p>This was for me the biggest problem. <a href="https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">Getting people out of WhatsApp</a> if they wanted to talk to me created a lot of friction. Some of them even stopped texting me because they had to open another app on their phone in order to write to me.</p>
<p>Yeah, you also read that right.</p>
<p>I don’t miss WhatsApp, nor do I miss its endless group talks without anything useful. If you leave one of these groups people look at you as if you did something wrong. In the end I still had access to all the event’s information I needed despite them being organized on WhatsApp. In regards to this, not having the app didn’t change my life much.</p>
<p>A trick I’ve developed, when giving my contact info to new people, is to enter my phone number on their smartphone myself, and install Signal for them. This removed a lot of friction. I would then explain my experiment to them and tell them I can only be contacted via this app. I’ve always had a positive reaction. Everybody’s been curious and asking a lot of questions.</p>
<h3 id="and-then-nothing-happened">And Then Nothing Happened</h3>
<p>During the first weeks without social media, I felt off. As if I was missing out on something big that was happening. Like everybody was having fun except me. Once the <a href="https://joshcsimmons.com/quit-social-media/">withdrawal phase</a> went away, I realized that my life hadn’t changed that much. I was still doing the same things, talking to the same people, going to the same parties, etc… It was just more quiet and peaceful.</p>
<p><strong>I was no longer bombarded with pictures of everybody trying to fake a life they’re not living for the sole purpose of impressing someone else: <a href="https://hbr.org/2017/04/a-new-more-rigorous-study-confirms-the-more-you-use-facebook-the-worse-you-feel">my life had just upgraded</a>.</strong></p>
<p>In the end, after everybody got over their initial shock and calmed down, it became normal for them to contact me using Signal, and life went on as usual.</p>
<h2 id="round-2-goodbye-smartphone">Round 2: Goodbye Smartphone</h2>
<p><img src="https://www.alvarez.io/img/color/l99-2.jpg" alt="Phone"></p>
<p>Unlike social media, smartphones are a lot harder to get rid off. They handle many more things than just simply communicating with people.  I work all day long with a computer, most of what the smartphone was doing could be handled by my laptop. For the rest, I narrowed down my bare essential to Music, Pictures, GPS navigation and of course GSM calls.</p>
<h3 id="the-hardware">The Hardware</h3>
<p>You could solve these problems quite easily using multiple devices, however I wanted to be smart about it and not walk around with a luggage just to carry around all this stuff. After doing some research I figured out the perfect combination and I was even able to reduce the amount of things I had in my pockets.</p>

			</div></div>]]>
            </description>
            <link>https://www.alvarez.io/posts/living-like-it-s-99/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226864</guid>
            <pubDate>Mon, 22 Feb 2021 17:02:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's ok to take a walk without headphones]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 59 (<a href="https://news.ycombinator.com/item?id=26226862">thread link</a>) | @khehy
<br/>
February 22, 2021 | https://radreads.co/telic/ | <a href="https://web.archive.org/web/*/https://radreads.co/telic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 itemprop="name"><span itemprop="dateCreated">20 Feb<meta itemprop="interactionCount" content="UserComments: 0"></span> It’s ok to take a walk without headphones</h2><p>The Big Sur MacOS update delivers a delightful <em>Easter Egg</em>.</p><p>Your AirPods now magically follow you across devices. Gone are the awkward transitions (“hold on, let me connect my AirPods”) while fiddling with your Bluetooth settings and pressing that random button on the white case.</p><p>Now you can gracefully glide from podcast, to Zoom call, to Discover Weekly, to Clubhouse, to audiobooks while enlisting Siri’s help. <strong>Seamlessly and without interruption.</strong></p><p>Yet it turns out that our headphones have been following us for much longer than a MacOS update.</p><div><figure><img src="https://i.insider.com/5273e2a669bedd7c06afe99f?width=1100&amp;format=jpeg&amp;auto=webp" alt="Image result for original ipod add" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div><p>Remember that original promise <strong>“1,000 songs in your Pocket?”</strong> <em>That was 20 years ago.</em></p><p><strong>“All of humanity’s problems stem from man’s inability to sit quietly in a room alone,”</strong> wrote the 17th century philosopher Blaise Pascal. Yet thanks to these white little earbuds, we never need to spend that quiet time alone.</p><hr><p>Do all of life’s moments need to be productive moments?</p><p>To answer that question, let’s distinguish between two types of activities: <strong>telic </strong>and<strong> atelic.</strong></p><p>Stemming from the Greek term <em>Telos </em>(“Having an inherent purpose”), <strong>telic activities</strong> are directed towards an end goal. Conversely, <strong>atelic</strong> activities are pursued for their own sake.</p><p>Telic activities include writing a novel, learning a new skill and building a house all have <strong>specific outcomes. </strong></p><p>On the other hand atelic activities – going for a walk, a long talk with friends, making love, and listening to your favorite songs – <strong>have no end goal.</strong> You derive joy from the activity itself.</p><p>Here’s the rub. <strong>Atelic activities are not “productive.”</strong></p><p>You do not move yourself closer to your goals when you do a puzzle with your toddler. Or when you pause to observe the beauty of a sunset. <strong>These aren’t productive activities.</strong></p><p>And since my Type-A self finds these activities very uncomfortable, my brain does a little mental <strong><em>jiu jitsu</em></strong> to make them more comfortable. I call them <em>Telic Transformations.</em></p><p>As I watch Soul with the fam, I’m <a href="https://twitter.com/khemaridh/status/1342864974771732480">processing ideas</a> for upcoming blog posts. (And when I watch Toy Story, looking to identify the <em>Hero’s Journey </em>narrative arc.)</p><p>When I surf, I’m constantly thinking of the next maneuver to learn (<em>cutbacks</em>), or the next board I could buy.</p><p>Heck, even when sitting on the John (without an iPhone), I’ll grab one of the cleaning products and look for examples of good copy, logo design, or color pairings.</p><p>As Pascal says, those quiet moments with myself can be <strong>quite uncomfortable.</strong></p><p>And then there’s the ultimate telic transformation: <strong>the podcast.</strong></p><p>Thanks to this venerable audio format, the last bastion of atelic activities (a beach walk, cooking a family dinner, getting your kids to sleep) can become <strong>instantly productive</strong> with the most recent episode of <em>The Tim Ferriss show.</em></p><p>Now this isn’t a critique against learning. Nor one against continuous self-improvement. Or about pursuing one’s insatiable curiosity.</p><p>But isn’t this pull to turn <strong>everything</strong> <strong>into an</strong> <strong>outcome</strong> quite peculiar?</p><p>And here comes a conundrum. Telic activities end. Yet the desire lives on. So we <a href="https://radreads.co/when-then-trap/">move the goal line</a>. Another goal. Another outcome.</p><p>And one starts laying the bricks for the hedonic treadmill.</p><p>In <a href="https://www.newyorker.com/books/page-turner/the-philosophy-of-the-midlife-crisis">The Philosophy of the Midlife Crisis</a>, the philosopher Kieran Setiya writes that “there’s something intrinsically self-defeating about getting things done.” Once you do the thing, it can’t be done again. Setiya continues:</p><blockquote><p><em>“Having a child, writing a book, saving a life—the completion of your project may be of value, but it means that the project can no longer be your guide. In pursuing a goal, you are trying to exhaust your interaction with something good, as if you were to make friends for the sake of saying goodbye.”</em></p></blockquote><p>Setiya concludes that “being consumed by plans” can be problematic:</p><blockquote><p><em>“They are schemes for which success can only mean cessation.”</em></p></blockquote><p>We’re not human doings. We’re human beings. Personally, I suspect that my <em>telic transformations</em> come from a place of fear. The fear of not <em>doing enough</em>, comes from the fear of <em>not being enough</em>. Confusing <a href="https://radreads.co/identity-achievement/">identity and achievement</a> becomes a slippery slope that robs me from the present and the beauty and love that surround me.</p><p>So I’ll heed Pascal’s advice – and ditch the AirPods during my next beach walk.</p> </div></div></div>]]>
            </description>
            <link>https://radreads.co/telic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226862</guid>
            <pubDate>Mon, 22 Feb 2021 17:02:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abundant Capital]]>
            </title>
            <description>
<![CDATA[
Score 358 | Comments 210 (<a href="https://news.ycombinator.com/item?id=26226723">thread link</a>) | @tomhoward
<br/>
February 22, 2021 | https://blog.aaronkharris.com/abundant-capital | <a href="https://web.archive.org/web/*/https://blog.aaronkharris.com/abundant-capital">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <div><p>The venture capital industry was built on the premise that both capital and high quality companies are scarce. For most of the history of the industry, this has been true. I remember sitting at demo day in 2011 and marveling at the fact that the combined capital of all the VCs in the room was less than that controlled by the hedge fund at which I had worked. But the model is wrong. Venture capital is abundant, and that fact should fundamentally change how founders fundraise.<br></p><p>This scarcity model has shaped the structure of startups and VCs - most of what an early stage startup does is designed to convince a VC to invest. Companies treat VCs as a limited resource that is both hard to access and hard to convince. Investors do their best to perpetuate this idea because it allows them to retain control of the pitch and fund dynamic.[1]</p><p>Something interesting happens, though, whenever a company has a signifier of quality - a YC demo day slot, a high quality angel, pedigreed founders, or, even better, strong growth. In these cases, there are investor feeding frenzies, leading to oversubscribed rounds, ever climbing prices, and investors willing to accept ownership targets they - until recently - would have termed unacceptable.</p><p>To be sure, there have always been bidding wars in private equity (of which venture is a subset), but these bidding wars are so frequent now as to be approaching the norm. If capital was actually scarce, this wouldn’t happen, there wouldn’t be enough money to create so many bidding wars.[2]</p><p>Bidding wars aren’t the only evidence of capital abundance. The VCs are changing their businesses because of this abundance, whether or not they admit the reason. The evidence is in the new funds that seem to launch on a daily basis, the multi-billion dollar growth funds that have become increasingly common, and the ownership targets at various rounds that continue to drop.</p><p>At the same time that capital has become more abundant, founders have become smarter about fundraising. There are now a huge number of blogs, classes, essays, guides, and advisers ready to help founders navigate the previously opaque world of fundraising. As a result, founders can approach each funding event with a clear plan of how to run a process. Running an orderly process further increases the chances that a company will see competitive bids.</p><p>As a thought experiment, assume that the abundance model is here to stay. It is also safe to assume that founders will not suddenly forget their newfound knowledge about process. I think this should encourage founders to think about changing fundraising in a few major ways:</p><ol>
<li><p>Founders should approach every fundraising as an auction. This is what each process already is, but the auction is inefficient. There’s lots of language and pseudo-moral arguments about why this is bad, but most of those fall apart if capital is abundant.</p></li>
<li><p>Founders should expand their funnels beyond the traditional VCs. These VCs hold a marketing and branding advantage, much of which is built around the signal to later rounds. If, however, each round is an auction, this benefit evaporates. YC’s demo day proved this funnel expansion works at seed, and there’s no logical reason it should fail at later rounds.</p></li>
<li><p>Once a founder has the information produced by this process, she can decide whether to minimize dilution, maximize price, or optimize around the partner. The answer will change based on the situation, but having access to the choice is important.</p></li>
</ol><p>Founders are hesitant to run this model because they fear that running an auction will create a negative quality signal. Investors encourage this belief because it allows them to keep deal flow proprietary. This is flawed logic. The quality of a company can’t be determined by the investors to whom that company talks when raising money. The quality of a company is determined by whether or not the company is good, and good companies should take advantage of abundant capital markets.[3]</p><p><i>Thanks to Adora Cheung, Janelle Tam, Ilya Sukhar, and Nabeel Hyatt for helping me think this through, even though our conclusions might differ.<br></i></p><p>__</p><p>[1] Perhaps more importantly to the investors’ business model is that this dynamic creates a reason for the existence of VCs. If founders and LPs both internalized how non-scarce capital actually is, they could find one another directly, bypassing VCs.</p><p>[2] It’s important to remember that, even though capital is abundant, it remains unevenly distributed. There are companies that struggle to raise money - some of these may be bad investments, but many are good. This is a problem of access rather than capacity, which is a whole different issue.</p><p>[3] When a company IPOs, it opens ownership up to anyone who can afford a share. Imagine, for a second, an investor arguing that this is a sign of low quality.</p></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.aaronkharris.com/abundant-capital</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226723</guid>
            <pubDate>Mon, 22 Feb 2021 16:54:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a reader for HN with Angular]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26226439">thread link</a>) | @izquiratops
<br/>
February 22, 2021 | https://izquiratops.github.io/hacker-reader/ | <a href="https://web.archive.org/web/*/https://izquiratops.github.io/hacker-reader/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://izquiratops.github.io/hacker-reader/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226439</guid>
            <pubDate>Mon, 22 Feb 2021 16:33:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an interpretable Covid mortality prediction model failed in the real world]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26225784">thread link</a>) | @stuartbman
<br/>
February 22, 2021 | https://explainthispaper.com/ai-covid-prognosis-predictor/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/ai-covid-prognosis-predictor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><i>article</i></p>
<div>
<p>An interpretable mortality prediction model for COVID-19 patients</p>
<p>May 14, 2020</p>
<p>Li Yan, Hai-Tao Zhang, Jorge Goncalves, Yang Xiao, Maolin Wang, Yuqi Guo, Chuan Sun, Xiuchuan Tang, Liang Jing, Mingyang Zhang ... Yong Zhang, Ailin Luo, Laurent Mombaerts, Junyang Jin, Zhiguo Cao, Shusheng Li*, Hui Xu* &amp; Ye Yuan</p>
<p><a href="https://www.nature.com/articles/s42256-020-0180-7">Nature Machine Intelligence</a>
</p></div>
</div><div>
<div data-contentpath-field="block">
<h3>Clinical Need</h3><p>COVID-19 is overwhelming healthcare systems worldwide. One reason for this is that COVID-19 causes a spectrum of disease ranging from mild infection to critical illness, and its hard for doctors to anticipate which COVID-19 patients will need more immediate medical attention.</p><p>Having a prediction tool would allow hospitals to quickly triage coronavirus patients into high and low risk levels. In this way, hospital resources can be more adequately allocated to the higher risk coronavirus patients.</p><h3>What did they do?</h3><p>They looked back at blood test results from coronavirus patients in Tangji Hospital in Wuhan, China. They used the latest blood tests to train a machine learning model to predict one of two outcomes: death or survival.</p>
</div>
<div data-contentpath-field="block">
<section>
<div>
<p><span data-contentpath-field="block">
<h3>How was the model made?</h3><p>The group used a popular <sample>classification model</sample> called XGBoost 🤖</p>
</span>
</p>
<div data-contentpath-field="right">

<p>In machine learning, classification is a technique that categorises data into a given number of classes. These classes can have any sort of label e.g. cancer or no cancer. A classification model attempts to reach a conclusion about the input values during training by assigning the input to one of the classes.</p>
<p><img alt="omermohamed.jpg" height="170" src="https://explainthispaper.s3.amazonaws.com/images/image.2e16d0ba.fill-200x200.jpg" width="169">
</p>

</div>
</div>
</section>
</div>
<div data-contentpath-field="block">
<section>
<div>
<p><span data-contentpath-field="block">
<p>This is a type of <sample>decision tree ensemble</sample>.</p>
</span>
</p>
<div data-contentpath-field="right">

<p>Ensemble Learning is a powerful method of Machine Learning that trains and predicts with many models (ie many decision trees) at once to produce a single superior output.</p><p>Think of it as trying out a few different routes to a single location you’ve never been to; as you use all of the routes, you begin to learn which traffic lights take longer, when and how the time of day impacts one route over the other — allowing you to craft the perfect route. You experimented with and combined a few different models to reach an optimal conclusion. Ensemble learning is similar!</p>
<p><img alt="omermohamed.jpg" height="170" src="https://explainthispaper.s3.amazonaws.com/images/image.2e16d0ba.fill-200x200.jpg" width="169">
</p>
<p><span><b>
Omer Mohamed</b>
</span><br>
<span>Medical Student</span>
</p>
</div>
</div>
</section>
</div>
<div data-contentpath-field="block">
<p>The model output was set as either class 0 (death) or class 1 (survival).</p><p>As is usual for training classification models, the model was trained by comparing its predictions to the true outcomes of over 300 respective patients and then altering its decision steps accordingly.</p><p>Eventually, the trained model was tested on a separate set of patient data (the test set), from 110 new patients.</p>
</div>
<div data-contentpath-field="block">
<section>
<div>
<p><span data-contentpath-field="block">
<h3>How did the model do?</h3><p>The algorithm performed well 🎯. On the test set, it achieved an <sample>F1 score of 0.98</sample> for predicting survival and 0.90 for predicting death.</p>
</span>
</p>
<div data-contentpath-field="right">

<p>This is a score for assessing how well the model is making the correct prediction, ranging from 0 (really bad) to 1 (really good). It balances precision (if the algorithm makes a prediction, how confident can we be?) with sensitivity (of the outcome of interest, how many did it pick up correctly?)</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor and Data Scientist</span>
</p>
</div>
</div>
</section>
</div>
<div data-contentpath-field="block">
<section>
<div>
<p><span data-contentpath-field="block">
<p>The algorithm revealed that three key biomarkers in the blood had the biggest influence on predictions: <sample>LDH, hs-CRP and lymphocyte counts</sample>.</p>
</span>
</p>
<div data-contentpath-field="right">

<p>LDH and hs-CRP are proteins while lymphocytes are a type of immune cell. Basically, when the level of these go up, the more likely it is that the infection is serious.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor and Data Scientist</span>
</p>
</div>
</div>
</section>
</div>
<div data-contentpath-field="block">
<p>They found F1 scores were highest when blood tests were taken close to the day of final outcome (death or survival). Even as far as 18 days before final outcome, the cumulative F1 scores were over 0.90.</p><h3>Want the nitty gritty? 🧐</h3><p>XGBoost is a type of tree ensembling method. It generates many different 'decision trees' then aggregates them together.</p><p>An advantage is that this can be very interpretable. The team produced two simple rules that would predict death in this population:</p><ol><li>LDH &gt; 365 or</li><li>hs-CRP &gt;41.2 and Lymphocyte &lt;14.7%</li></ol>
</div>
<div data-contentpath-field="block">
<h3>Where it all went wrong 😬</h3><p>The group didn't validate their model externally i.e. in another hospital. This is crucial when developing a model as it reduces overfitting of the model to one specific dataset. <a href="https://www.nature.com/articles/s42256-020-00254-2">Another group</a> tested the model in New York and the F1 score for predicting death was 0.41. Similarly low accuracy was reported in <a href="https://www.nature.com/articles/s42256-020-00252-4">France</a> and the <a href="https://www.nature.com/articles/s42256-020-00253-3">Netherlands</a>.</p><p>Also, this model's accuracy depended on how close to the final outcome it was applied. In real-life, doctors wouldn't know when the final outcome will happen.</p><p>The group didn't make it clear whether the model can be used as a triage tool at the first point of presentation to hospital. When the New York group applied the model at initial triage point, the F1 score for predicting death was still low, at 0.56.</p><p>(These performance issues are not confined to this particular model. A <a href="https://erj.ersjournals.com/content/56/6/2003498">review</a> of existing predictive models for COVID-19 found that none of them met the standard of accuracy that you get from simpler measures like oxygen levels. The review recommended that, in future, model developers must always externally validate their models.)</p><h3>So what?</h3><p>This paper made a lot of waves in the few months after it came out, with several direct replies and over 90 citations. There's clearly a lot of interest in predictive models for COVID-19. However, with the limitations highlighted above, it's unlikely that this exactly model will be used on a widespread scale.</p>
</div>
</div></div>]]>
            </description>
            <link>https://explainthispaper.com/ai-covid-prognosis-predictor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225784</guid>
            <pubDate>Mon, 22 Feb 2021 15:44:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A paypal.me clone using Stripe]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26225504">thread link</a>) | @thomasisaac
<br/>
February 22, 2021 | https://tillypay.com/blog/open-payment-link-with-stripe/ | <a href="https://web.archive.org/web/*/https://tillypay.com/blog/open-payment-link-with-stripe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>TL;dr If you wish to create your own Stripe Open Payment Link, like Paypal.me, you can use <a href="https://tillypay.com/">tillypay.com</a></p><p>One killer feature that Stripe hasn't made is a response to PayPal.me, this would be when the end client or user could enter the amount and continue to pay that amount.</p><p>It would be great if you could have the option to do this, so we built it! TillyPay is a verified Stripe Partner, this means we can control your Stripe platform on your behalf adding this much needed <strong>Open Pay Link</strong>. We call it OpenPay.</p><h3 id="introducing-openpay">Introducing OpenPay</h3><p>OpenPay will allow your customers to write in exactly <strong>amount</strong> they wish to pay and in the <strong>currency</strong> they wish to pay in.</p><p>You also operate this under your <strong>own domain</strong> rather than using ours.<br><strong>pay.yourcompany.com/open</strong> could lead to the page like below:</p><figure><img src="https://tillypay.com/blog/content/images/2020/11/Screenshot-2020-11-05-at-12.21.12.png"><figcaption>Example of an Open Payment Link for Stripe</figcaption></figure><p>The payment will be entered and created into your existing Stripe dashboard.</p><p><strong>Payment Methods</strong><br>We allow any payment method that Stripe uses, including Apple &amp; Google Pay, you can see this above under the "Pay Now&gt;" button will lead them to any system that they currently have installed on their system.</p><p>This is a lot more variety than PayPal's system, under business transactions this solution is cheaper.</p><h2 id="free-to-try-out">Free to try out</h2><p>To get started with TillyPay's OpenPay system, head over to our web app and get started</p><!--kg-card-begin: html--><a href="https://app.tillypay.com/signup?utm_source=blog-openpay">
  <svg width="309px" height="68px" viewBox="0 0 309 68" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
      <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
          <g id="Artboard" transform="translate(-31.000000, -46.000000)">
              <g id="Group-31" transform="translate(31.000000, 46.000000)">
                  <rect id="Rectangle" fill="#0F24CE" x="0" y="0" width="309" height="68" rx="4"></rect>
                  <text id="Create-an-Account" font-family="KohinoorBangla-Bold, Kohinoor Bangla" font-size="30" font-weight="bold" fill="#FFFFFF">
                      <tspan x="23.305" y="44">Create an Account</tspan>
                  </text>
              </g>
          </g>
      </g>
  </svg>
</a><!--kg-card-end: html-->
    </section></div>]]>
            </description>
            <link>https://tillypay.com/blog/open-payment-link-with-stripe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225504</guid>
            <pubDate>Mon, 22 Feb 2021 15:21:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical Color Theory for People Who Code (2016)]]>
            </title>
            <description>
<![CDATA[
Score 194 | Comments 49 (<a href="https://news.ycombinator.com/item?id=26225339">thread link</a>) | @martinlaz
<br/>
February 22, 2021 | http://tallys.github.io/color-theory/ | <a href="https://web.archive.org/web/*/http://tallys.github.io/color-theory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
	
	<h3>Natalya Shelburne
		<br>
		<a href="https://twitter.com/natalyathree">@natalyathree</a>
	</h3>
</header>
	
		<div>
			<div>
				<div>
					

					<div><p>
						Hi! I'm Natalya! <img src="http://tallys.github.io/color-theory/images/tally-pic.jpg" title="natalya-profile" description="vector art self portrait">I'm a classically trained fine artist who spent 6 years teaching people how to paint, draw, and grow their creativity. I am now a front end developer, and I love writing code as much as I love painting. </p><p>I have a degree in Studio Art, a bachelor's in Developmental Psychology, and a master's degree in Creativity and Talent Development. But, most importantly, I have mixed gallons and gallons of paint. </p><p>I abstracted my domain knowledge as a fine artist into variables and functions in order to reveal color selection as being logical, predictable, and driven by principles anyone can learn. Sass color functions give you the same creative power as owning a set of paints, brushes, and canvas. </p><p>This is a demo of my functions for a complementary color scheme - pick any color on the color wheel and the functions will make sure that the scheme will still work! 🎨</p></div>
					</div>
					<div>
						
					
					<h4>Completely new to this? Check out these resources first:</h4>
					
				</div>
			</div>
		</div>
		<a href="#" name="start"></a>
<section>
	<h2>Let's build a Complementary Color Scheme!</h2>
	<img src="http://tallys.github.io/color-theory/images/color-circle.png" alt="color-wheel" title="color wheel" description="the color wheel with corresponding hsl degrees">
	<p>This is the color wheel, consider this the documentation for using color. <br> Notice that the degrees on the color wheel correspond to colors.</p>
	
</section>

<section>
	<h2>Pick a color <span> hsl($hue, $saturation, $lightness)</span></h2>
	<div>
		
		<p>Pick any color by selecting its hue (0-360) on the color wheel at full saturation (100%) and at half lightness (50%) - this way you start with the 'most colorful color' you can get.</p>
		<p>This is what your website will look like if you set every element to this one color. Notice how you can't tell one item from another. Color is information.</p>
	</div>
	<div>

		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>


	</div>
	<div>
		
		<div>
			<p>Why pick a fully saturated color, but only half lightness?</p>
			<p>Ever mix up a bunch of colors only to end up with a gray blob? In the real world, you can't mix a color to be more saturated - you only "lose" color information as you mix. So, the practice is to start with the most saturated colors at their most chromatic so you can still have a full range of mixing opportunities.</p>
		</div>
		
	</div>
</section>


<section>
	<h2>Generate Complementary Color<span>complement( );</span></h2>
	<div>
		
		<p>Generate your second color without having to guess what will work. Thanks to science and wavelengths, we know that this works. The opposition of these two colors stimulate your photoreceptor cells in a good way!</p>
		<p>Finally! A different color - now hue separates elements from each other and a layout can be seen.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		<p>The complement to any color is always 180 degrees across on the other side of the color wheel. If you've ever wondered why it's the color wheel instead of a color line, this is part of that answer. Remember that the color wheel is our visual documentation for color relationships. <br> Fun fact, if you mix complementary colors, they'll cancel each other out and you'll end up with a neutral gray.</p>
		
	</div>
</section>

<section>
	<h2>Color Relationship Established by Mixing<span>harmonious-mix( );</span></h2>
	<div>
		
		
		<p>Establish a color relationship by mixing them together. This makes the colors look like they're under similar lighting conditions.</p>
		<p>Here, you see less saturated hues, with a clear relationship between each other.</p>
		</div>
		<div>
			<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

		</div>
		<div>
			
			<div>
				<p>Our eyes may be legacy systems, but they are really good at spotting patterns, especially things that look like they don't belong in a set.</p>
				<p>This mixing method is another way we can simulate lighting and color found in nature. It's a bit more complicated, but my favorite way of explaining it is this: Everything outside has some "yellow" mixed in from the sunshine during the day. Same thing happens when everyone and everything looks bad in photos taken under the glow of green flourescent lights - there is green added to all of the colors you're looking at, including adding a green glow to your skin if you're standing under the flourescent light yourself. Whether it looks good or bad, this color (light) mixing creates a visual harmony. We don't really notice it when it's there, but we really notice its absence.</p>
				<p>When you're painting, you want to simulate similar lighting conditions for a scene, and that effect is accomplished mixing a bit of one color into the other. Mixing different ratios of the same colors will usually generate a matching color palette.</p>
				<p>How do I decide what to do? Thanks to art school and science, I know that cool colors have lower luminosity than warm colors, and will dominate in mixes, with yellow being the lightest color. For example, a touch of blue will really affect yellow, whereas you can add a lot of yellow to blue before it is affected. So, here is this decision making in function form - I am weighing different colors differently when mixing.</p>
	</div>
		
		
		
</div>
</section>

<section>
	<h2>Create Neutrals<span>mix-neutral( ); lighten( ); darken( );</span></h2>
	<div>
		
		
		
		<p>Let your chosen color pop (in other words, don't exhaust your eyes by making them process non-stop intense chromatic colors!) by surrounding it with neutrals. Desaturate the painter way: by mixing complementary colors! Then, vary that neutral's lightness to create a highlight and a shadow.</p>
		<p>Making the complementary color neutrals will help the 'call to action' color you selected stand out - notice how much the button in the top right "pops" all of a sudden. Make things "pop" by making other things around them not pop.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		
		
		<p>We can do the same for our primary color too. More neutrals to work with.</p>
		<p>Doesn't it seem like we went too far with this whole making things neutral? Now, nothing "pops"! But, on the plus side, none of this seems to be irritating any eyeballs, either. Remember that our eyes don't like to handle seeing everything our computers are capable of rendering.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		<div>
			<p>The colors are way too intense at their full saturation for our eyes to handle. If all the colors are bright, none of the colors are bright.</p>
			<p>I picked my starting color for a reason -  I want that to be the heart of my design! That means the complementary color should support the chosen color, and we do that by mixing neutrals. Our eyes don't really handle saturated colors very well next to other saturated colors. Our eyes get confused at the edges - is it this color or the other one? Ahh both! We end up seeing optical illusions. Just give your eyes a break between super strong saturated colors with neutrals so they don't stress out about that much visual information. At the very minimum a rule of thumb is that your viewport should have 33% neutral space (white, desaturated, or black colors) so your poor eyes can have a break and process the information right. Otherwise you get eye strain!</p>
		</div>
		
	</div>
</section>

<section>
	<h2>Why not just desaturate?<span>mix-neutral( ); lighten( ); darken( );</span></h2>
		<p>You totally can! Desaturate does a great job. But, I think not only is it important to understand what "desaturate" means. How would you desaturate a real color in the real world? Remember, you want "ugly" colors for your neutrals! You want to create bland and forgettable colors that recede into the background. These ugly duckling colors are how you get those other call to actions and buttons "pop"!</p>

		<h3>Primary and complementary Colors</h3>
			
			
		<h3>Mixed neutrals</h3>
			
			


		<h3>Desaturated neutrals</h3>
			
			

		<div>
			
			<p>Even though these may look "ugly", neutral colors are the heart of any painting, and that is the case on the web, too. Notice that the same decisions are …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tallys.github.io/color-theory/">http://tallys.github.io/color-theory/</a></em></p>]]>
            </description>
            <link>http://tallys.github.io/color-theory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225339</guid>
            <pubDate>Mon, 22 Feb 2021 15:07:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public stocks like Tesla and Square gain $5B on their Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26225267">thread link</a>) | @senor_lecce
<br/>
February 22, 2021 | https://protos.com/bitcoin-treasuries-tesla-square-crypto-stocks-investment/ | <a href="https://web.archive.org/web/*/https://protos.com/bitcoin-treasuries-tesla-square-crypto-stocks-investment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2694">
<header>


</header>
<figure>
<img width="889" height="500" src="https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50.jpg" alt="stocks, bitcoin" loading="lazy" srcset="https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50.jpg 1920w, https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50-300x169.jpg 300w, https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50-1024x576.jpg 1024w, https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50-768x432.jpg 768w, https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50-1536x864.jpg 1536w" sizes="(max-width: 889px) 100vw, 889px">

</figure>
<main>
<div>
<p>Publicly traded stocks like Tesla and Square are <strong>up over $5 billion</strong> on their Bitcoin investments.</p>
<p>According to <a href="https://bitcointreasuries.org/" target="_blank" rel="noreferrer noopener">Bitcoin Treasuries</a>, public companies have so far together spent $3 billion to acquire 151,919 BTC — worth $8 billion at current prices.</p>
<ul><li>Michael Saylor’s <a href="https://www.protos.com/microstrategy-grows-bitcoin-holding/" target="_blank" rel="noreferrer noopener">MicroStrategy</a> <strong>spent $1.15 billion</strong> on 71,079 BTC (now worth $3.9 billion).</li><li><strong>Tesla’s up 70%</strong> on its 48,000 BTC (bought for $1.5 billion, now worth $2.5 billion).</li><li>Canada’s Galaxy Digital is third, having bought <strong>16,402 BTC for $134 million</strong> — now worth just under $900 million.</li></ul>
<p>Jack Dorsey’s <a href="https://protos.com/square-bitcoin-jack-dorsey-whitepaper-craig-wright-crypto/" target="_blank" rel="noreferrer noopener">fintech Square</a> gets a notable mention. The firm behind Cash App <strong>spent $50 million</strong> on 4,709 BTC <a href="https://www.theverge.com/2020/10/8/21507533/square-50-million-bitcoin-dorsey-cryptocurrency" target="_blank" rel="noreferrer noopener">last October</a> — now it’s worth $250 million, a 400% increase in five months.</p>
<p><a href="https://public.flourish.studio/visualisation/5364437/?utm_source=embed&amp;utm_campaign=visualisation/5364437" target="_top" rel="noopener"><img alt="Made with Flourish" src="https://public.flourish.studio/resources/made_with_flourish.svg"> </a></p>
<p>It should be noted these figures only make sense if the companies <strong>have held their Bitcoin</strong>. Public stocks often disclose asset sales months after the fact.</p>
<p>In any case, investors in <strong>crypto-specific stocks</strong> like Voyager Digital, Riot Blockchain, and Marathon Patent Group are even better off. </p>
<p>Bitcoin’s historic rallies have pushed their <strong>share prices up thousands of percent</strong> over the past year.</p>
<p>For scale, Bitcoin itself is up around 480% while the S&amp;P 500 has gained 15%.</p>
<p><a href="https://public.flourish.studio/visualisation/5364733/?utm_source=embed&amp;utm_campaign=visualisation/5364733" target="_top" rel="noopener"><img alt="Made with Flourish" src="https://public.flourish.studio/resources/made_with_flourish.svg"> </a></p>
<p><em>[Read more: <a href="https://protos.com/bitcoin-price-candles-tesla-crypto-history/" target="_blank" rel="noreferrer noopener">Chasing candles — here’s where Bitcoin’s ‘Tesla pump’ ranks in history</a>]</em></p>
<p>But while Tesla’s Bitcoin buy <a href="https://protos.com/bitcoin-tesla-elon-musk-price-record-crypto-purchase/" target="_blank" rel="noreferrer noopener">captured the world’s attention</a>, the influence of BTC’s volatility <strong>could be more apparent</strong> in MicroStrategy’s share price.</p>
<p>After all, more than <strong>40% of MicroStrategy’s market value</strong> is directly derived from its Bitcoin stash. If Bitcoin corrects — so might MSTR stock.</p>
</div>
</main>
</article></div>]]>
            </description>
            <link>https://protos.com/bitcoin-treasuries-tesla-square-crypto-stocks-investment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225267</guid>
            <pubDate>Mon, 22 Feb 2021 15:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are these online pleas for humanitarian aid or ISIS fundraising?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224980">thread link</a>) | @gbseventeen3331
<br/>
February 22, 2021 | https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>I</span>t’s the kind of picture that most Facebook users would scroll by without pause: the sun hanging low in a blue sky, half-hidden by the silhouette of a tent. “Donate [for the sake of Allah] to free your imprisoned sisters,” a line of embedded text reads, with the hashtag #CampHol. “Contact to help us,” the caption adds, including the name of a Telegram account.</p>



<p>Even a user who did take the time to look closer might assume the post was related to an Islamic charity or perhaps a fundraiser for human trafficking victims, then move on. Its intended audience, however, would immediately recognize the link to ISIS.</p>



<p>Al-Hol refugee camp in Kurdish-controlled northeastern Syria is home to the women and children who lived in ISIS’s last remaining pockets of territory before they were retaken by the Syrian Democratic Forces in March 2019. The majority of residents are Iraqi and Syrian, but there is also a separate annex for women who traveled to live in the so-called caliphate. These women, some of whom emigrated from Europe, Asia, and Africa, are seen by locals as more fanatical than those in other parts of the camp. A United Nations <a href="https://reliefweb.int/report/syrian-arab-republic/syrian-arab-republic-north-east-syria-al-hol-camp-21-november-2019">report</a> from November 2019 found that foreigners made up 15% of the camp’s total population of 70,000, although some have since been repatriated or moved to more secure facilities.</p>



<p>A sprawling mass of dusty tents surrounded by fences and armed guards, al-Hol’s foreigners’ annex has become a place of radicalization and extremism. There, hard-line Islamists have reimposed ISIS’s draconian rules <strong>—</strong> any woman or girl over eight must be fully veiled in black; communication with authorities or journalists is forbidden; daily prayer is mandatory —<strong> </strong>and been known to beat and murder transgressors. With resources already overextended, the camp staff have little ability to intervene.</p>



<p>Last year, online fundraisers began to appear on behalf of al-Hol residents. Many were seeking to finance escapes, others to pay for food and supplies. (While some donations have likely gone toward terrorism, the campaigns are careful to avoid mentioning violence.) The petitions spread via social networks, including Facebook, Instagram, and Twitter, and often involved PayPal and other payment systems as well as messaging apps, like WhatsApp and Telegram. Before long, intelligence and law enforcement agencies began to monitor them.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Screenshot-2020-12-11-at-23.45.57-40x72.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Screenshot-2020-12-11-at-23.45.57-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Screenshot-2020-12-11-at-23.45.57-400x724.png 400w, https://restofworld.org/wp-content/uploads/2021/02/Screenshot-2020-12-11-at-23.45.57-600x1086.png 600w, " sizes="300px" alt="Last year, fundraisers started appearing on social media on behalf of al-Hol residents.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Facebook</span>
			</figcaption>
		</figure>


<p>Media reports followed, and any platform that was not already aware of the campaigns’ existence was soon clued in. Even so, several months later, this kind of content remains relatively easy to find. <em>Rest of World </em>was able to identify dozens of Facebook accounts claiming to be linked to al-Hol, many of which post comments glorifying ISIS or soliciting funds. “Do not fear the imprisonment of the [unbelievers] for helping your sisters,” reads one, inviting supporters to message privately for more information. On Instagram, an account consisting mostly of images and videos from al-Hol included a picture of a figure clad all in black holding up a cardboard sign. It reads, “WE ARE TWO SISTERS FROM CAMP AL HOL AND WE ARE TRYING TO ESCAPE … WE COLLECTED 13,000$ AND WE NEED 3000$ PLEASE WE BEG THE UMMAH TO HELP US AND DONATE AS MUCH AS THEY CAN.” Below, a caption elaborating on the message is translated into Turkish, English, Russian, and French.</p>



<p>Accounts like these often remain active for months. This is possible, in part, because campaigns extend across multiple networks and payment platforms, creating a complex and opaque ecosystem that sometimes mixes illegal payment solicitations with requests for legitimate charitable giving. As major social media companies scramble to figure out policies around hate speech and disinformation, ISIS-related fundraisers have continued to slip through.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-04854-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-04854-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-04854-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-04854-600x401.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-04854-1000x668.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-04854-1600x1069.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-04854-2800x1870.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Women stand at a registration office at al-Hol camp, looking for documents in their phones they need to print to apply for permission to leave the camp.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>In the more</strong> than five years that ISIS held territory in Iraq and Syria, it generated vast sums of money — from oil fields, plundering banks, drug and artifact smuggling, taxing people living under its regime, and taking hostages. The French government alone was <a href="http://www.focus.de/politik/ausland/krise-in-der-arabischen-welt/syrien/paris-zahlt-loesegeld-18-millionen-dollar-fuer-entfuehrte-journalisten_id_3800633.html">reported</a> to have paid an $18 million ransom to secure the release of four journalists. (A government spokesman denied this account.)</p>



<p>Although the revenues generated by online campaigns are minuscule in comparison, they are not insignificant — Audrey L. Alexander, a researcher and instructor at West Point’s Combating Terrorism Center, told <em>Rest of World</em> that she regularly encounters crowdfunding efforts by terrorists, some of which bring in as much as $2,000 — and this income likely helps keep ISIS activities going. It’s impossible to say with any certainty how much ISIS receives in online donations, but the money has been linked to escapes, weapons purchases, and propaganda produced by al-Hol-linked accounts, which have replaced the high-production-value videos once released by ISIS’s media arm.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG_1496-40x87.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG_1496-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG_1496-400x866.png 400w, https://restofworld.org/wp-content/uploads/2021/02/IMG_1496-600x1299.png 600w, " sizes="(max-width: 640px) 100vw, 300px" alt="As major social media companies scramble to figure out policies around hate speech and disinformation, ISIS-related fundraisers have continued to slip through.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Instagram</span>
			</figcaption>
		</figure>


<p>In a March <a href="https://media.defense.gov/2020/May/13/2002298979/-1/-1/1/LIG_OIR_Q2_MAR2020_GOLD_508_0513.PDF">report</a> to Congress, the American-led coalition against ISIS, Operation Inherent Resolve, detailed how women within the camps, and particularly al-Hol, have built up a network for smuggling people and supplies, while simultaneously recruiting and indoctrinating new members. “Using funds received via wire transfers,” the authors noted, “female ISIS members continued to conduct operations — such as attacks against camp security personnel.” While this amplified existing pressure on social media companies to better monitor their platforms, it didn’t appear to have any major policy impacts.</p>



<p>The architects of these networks tailor their messages and methods to geography, specific donors and goals, and national laws and platform regulations. Of the Facebook accounts identified by <em>Rest of World</em> that claim links to al-Hol, only some explicitly asked for donations. Others disseminated pictures or news from the camp in different languages, alongside Islamic scripture and memes. A few users fondly reminisced about their time in the caliphate. Facebook disables and deletes accounts that share terrorist propaganda, so ISIS was never explicitly mentioned. Instead, references to the organization were camouflaged by alternative spellings. “I miss the Dawl@,” one said, with a crying emoji, referencing the Arabic word for “state” in ISIS’s full name.</p>



<p>Facebook says it has been making major investments to combat the proliferation of terrorist content on its platform. Much of that relies on AI and on media-matching software that finds images, text, or videos that are either identical or near identical to content that has already been taken down. Once identified, they are removed nearly instantly.</p>



<p>“Facebook has no tolerance for terrorist propaganda or content fundraising for terrorist groups. We take this extremely seriously and we are investing heavily to keep people safe,” a spokesperson told <em>Rest of World</em> in an emailed statement. “Over the last few years we’ve tripled the size of our safety and security team to 35,000 and built artificial intelligence technology to find and remove this content before people see it and report it to us. From June to September 2020, we removed over 9.7 million pieces of terrorist content on Facebook, 99% of which we detected proactively.”</p>



<p>While undoubtedly effective, aggressive AI-based content removal isn’t perfect. Journalists across the Middle East and North Africa regularly have their Facebook and Twitter accounts <a href="https://www.nbcnews.com/tech/tech-news/facebook-doesn-t-care-activists-say-accounts-removed-despite-zuckerberg-n1231110">suspended</a> after posting material related to conflicts or human rights abuses. Charities working with Syrian refugees have for years complained about <a href="https://slate.com/technology/2020/02/paypal-venmo-iran-syria-sanctions-crime-detection-system.html">PayPal’s keyword filters</a> blocking donations. And as social media companies get faster at taking down content, often without anyone having seen it, <a href="https://www.hrw.org/report/2020/09/10/video-unavailable/social-media-platforms-remove-evidence-war-crimes">human rights groups</a> and activists worry that they may be erasing vital evidence of war crimes that could be of use in future trials.</p>



<p>AI has other weaknesses too. Accounts that are more subtle about illegal affiliations may go unnoticed, allowing disguised ISIS content to slip through. Of the more than 40 apparently al-Hol-linked Facebook accounts found by <em>Rest of World</em> in October, only around half had been removed by December. Additionally, account administrators often maintain a network of duplicate or backup accounts, so that if one is blocked or removed, others are ready to take its place.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-05136-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-05136-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-05136-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-05136-600x401.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-05136-1000x668.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-05136-1600x1069.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-05136-2800x1870.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="Women and children walk through al-Hol camp.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>In contrast to</strong> Facebook, Telegram has relatively few safeguards against terrorist content. Launched in 2013 by Russians Nikolai and Pavel Durov, the Dubai-based company is <a href="https://restofworld.org/2020/silk-road-is-dead-long-live-silk-road/">known for prioritizing privacy and free speech over nearly all other concerns.</a> This stance has made it popular among people living in authoritarian regimes, and it has also made it the app of choice for violent extremists. The company has conducted coordinated sweeps to remove ISIS content, but channels openly devoted to ISIS news and propaganda still regularly appear — including ones that raise money for escape attempts from al-Hol. (Telegram did not respond to requests for comment.)</p>



<p>While many jurisdictions hold the person who posts illegal content — rather than the platform itself — accountable, that may be changing in the U.K. and the E.U., where new draft legislation being considered would place responsibility on platforms to police themselves.</p>



<p>Vera Mironova, a visiting fellow at Harvard University who has extensively monitored online terrorist fundraising campaigns, notes that posts follow the mores of their host platform. “So secretive campaigns would not be posted on Facebook, or if they were, they would sound more humanitarian and not use words like ‘ISIS.’ But the ones on Telegram go full hurrah,” she explained. This same dynamic plays out on a country-by-country level, Mironova added, and is especially apparent on payment platforms. “Some countries — let’s say Russia or parts of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/">https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224980</guid>
            <pubDate>Mon, 22 Feb 2021 14:36:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft joins forces with European news publishers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224860">thread link</a>) | @samizdis
<br/>
February 22, 2021 | https://www.techregister.co.uk/microsoft-joins-forces-with-european-news-publishers/ | <a href="https://web.archive.org/web/*/https://www.techregister.co.uk/microsoft-joins-forces-with-european-news-publishers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Microsoft has joined forces with Europe’s publishers to deepen the troubles of Google and Facebook, launching a project to develop an Australian-style arbitration system for the EU that would force Big Tech to pay for news.</p>
<p>The move by the Seattle-based company is one of its most brazen yet to align with the press industry, exploit the difficulties of its Silicon Valley rivals and promote its own search engine Bing as a copyright-friendly alternative for news. </p>
<p>The project announced on Monday will involve Microsoft working with Europe’s four leading lobby groups for news publishers to develop a legal solution to “mandate payments” for the use of content by “gatekeepers that have dominant market power”. </p>
<p>The informal coalition, which will propose that the plan is added to upcoming EU legislation on Big Tech, includes the European Publishers Council, News Media Europe, and the associations for European magazine and newspaper publishers, which together represent thousands of news outlets.</p>
<p>Microsoft and the publishers said on Monday that they will support a form of arbitration, and will look closely at the model developed in Australia, which has prompted Google to strike a flurry of licensing deals and Facebook to stop sharing Australian news on its service.</p>
<p>Christian Van Thillo, a Belgian media executive who is chair of the European Publishers Council, welcomed “Microsoft’s recognition” of the value “our content brings to the core business of search engines and social networks”.</p>
<p>“It is crucial that our regulators recognise this key point, and don’t get misled into thinking that side deals on the basis of a standalone product are the same thing,” he said, adding: “All publishers should get an agreement — no one should be left out.”</p>
<p>Microsoft has offered vocal public support for the Australian reforms and has urged other governments to follow suit, much to the chagrin of its rivals. </p>
<p>Unveiling the project with European publishers, Casper Klynge, a vice-president of Microsoft, said access to quality news was “critical to the success of our democracies”. </p>
<p>The Australian system has caught the eye of regulators around the world, who are also looking for ways to empower publishers in licensing negotiations with Google and Facebook. </p>
<p>Canada is preparing Australia-style laws, and the EU and UK are looking at importing elements of the system into upcoming laws. It remains unclear whether the calculations of lawmakers have been changed by Facebook’s decision to boycott news in Australia.</p>
<p>EU governments are in the process of implementing a recent overhaul of copyright law, which strengthened the claim of publishers to seek compensation for the use of news snippets by Google. </p>
<p>But industry executives and some MEPs are concerned that the provisions, which do not include any arbitration system to resolve disputes, are too easy for Big Tech groups to sidestep. Google recently reached a licensing deal with French publishers, but paid much smaller sums than the settlements agreed with Australian publishers.</p>
<p>Fernando de Yarza, president of News Media Europe, said: “The experiences in France and Australia have shown us that there’s a real need for a binding instrument.”</p>
<p>The Financial Times has reached commercial agreements for news with both Google and Facebook. The FT is not a member of any of the associations involved in the Microsoft initiative.</p>
<p>Google and Facebook both strongly criticise the Australian reforms as unworkable and unfair. Neither company had commented on Microsoft’s initiative in Europe by the time of publication. </p>
</div></div>]]>
            </description>
            <link>https://www.techregister.co.uk/microsoft-joins-forces-with-european-news-publishers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224860</guid>
            <pubDate>Mon, 22 Feb 2021 14:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Do We Talk About When We Talk About Dashboards? (2018)]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26224846">thread link</a>) | @sebg
<br/>
February 22, 2021 | https://alper.datav.is/publications/dashboards/ | <a href="https://web.archive.org/web/*/https://alper.datav.is/publications/dashboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Dashboards have long been the much maligned visualization vehicle of choice for decision-making in commercial and governmental situations.  While the visualization research community has concentrated much of its effort on visual analytics, the commercial success and widespread use of dashboards begs more attention.  Critically, dashboards are becoming many peoples’ direct connection to “big data” sources, enabling data democratization and wider access to data.</p>

<p>In this paper, we explore the genre of dashboards through a two-prong approach.  We survey the existing literature in business, marketing, and related fields to capture the relevant factors to consider when designing appropriate dashboards and their tools for consumption by different parties, all of which have differing levels of visualization literacy, data literacy, and decision agency.  We also collect examples of dashboard designs based on the dimensions derived from our literature search, and identify different clusters of dashboard designs with similar analysis goals, audiences, and decision support.</p>

<p>We call ourselves the “dashboard conspiracy:” a truly diverse collection of authors across Tableau Research, Microsoft Research, and Simon Fraiser University.</p>

<p><em>This work was presented at <a href="http://ieeevis.org/year/2018/welcome">IEEE VIS 2018</a> in Berlin, Germany.</em></p>

<p><em>This work was discussed in an half-hour datastori.es podcast, <a href="https://datastori.es/135-the-dashboard-conspiracy-with-lyn-bartram-and-alper-sarikaya/">give it a listen</a>!</em></p>

    </div></div>]]>
            </description>
            <link>https://alper.datav.is/publications/dashboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224846</guid>
            <pubDate>Mon, 22 Feb 2021 14:22:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of GraphQL 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224536">thread link</a>) | @lukzar
<br/>
February 22, 2021 | https://blog.graphqleditor.com/state-of-graphql-2020 | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/state-of-graphql-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The State of JavaScript is an annual survey that collects data from JS professionals from across the globe. This year’s edition questioned  23,765 developers in 137 countries about development areas such as:</p>
<ul>
<li>Front-end frameworks,</li>
<li>Back-end framework</li>
<li>JavaScript flavors,</li>
<li>Testing libraries,</li>
<li>Build tools,</li>
<li><em>Data layer</em>.</li>
</ul>
<p>Let’s take a look at GraphQL data concluded in the Data layer part of the survey.</p>
<h2>Data layer report</h2>
<p>The data layer part covers technologies used to transmit and manage data. The users were asked about their awareness, interest, usage experience, and satisfaction with various data layer libraries (including GraphQ) and here are the results.</p>
<h4>The awareness and interest</h4>
<p>Since becoming publicly available in 2015 GraphQL has received a lot of coverage on the Internet, both positive and negative. The awareness of GraphQL is constantly growing (from 97% to 98% comparing to the previous year) while the interest graph shows a little decline (from 90% to 87%), which seems to be pretty natural for maturing technology.</p>
<h4>The usage of GraphQL</h4>
<p>The growth of GraphQL usage among survey responders was the biggest between 2018 and 2019 and it amounted to 40% (from 22%) so it’s unrealistic to expect the same pace of growth. <strong>In 2020 the usage of GraphQL has gained 6%</strong> which seems to be a fine result, especially when thinking about GraphQL as a somehow mature technology.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/52ab5/usage.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Usage" title="Usage" src="https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/fcda8/usage.png" srcset="https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/12f09/usage.png 148w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/e4a3f/usage.png 295w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/fcda8/usage.png 590w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/efc66/usage.png 885w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/c83ae/usage.png 1180w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/52ab5/usage.png 1420w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h4>The satisfaction of GraphQL</h4>
<p>The satisfaction of GraphQL remains and nearly the same level.
The advantages and flaws of GraphQL are factually described in various articles, blog posts and talks so users deciding to give GraphQL know what they are signing for. GraphQL has a great community standing behind it, working hard every day to provide solutions, tools and different ways to overcome all its shortcomings. </p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/6b95e/satisfaction.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Satisfaction" title="Satisfaction" src="https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/fcda8/satisfaction.png" srcset="https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/12f09/satisfaction.png 148w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/e4a3f/satisfaction.png 295w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/fcda8/satisfaction.png 590w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/efc66/satisfaction.png 885w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/c83ae/satisfaction.png 1180w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/6b95e/satisfaction.png 1458w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h4>The GraphQL Experience</h4>
<p>The general experience observed in past years shows a positive tone. The number of people that never heard, are not interested or wound not use GraphQL has decreased significantly and the latest results show that 88.1% of respondents are either interested in GraphQL or declares that they have already worked with and would do it again.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/82b28/graphql.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL Experience over time" title="GraphQL Experience over time" src="https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/fcda8/graphql.png" srcset="https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/12f09/graphql.png 148w,
https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/e4a3f/graphql.png 295w,
https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/fcda8/graphql.png 590w,
https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/efc66/graphql.png 885w,
https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/82b28/graphql.png 931w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The below chart presents the Positive vs Negative responses split and the GraphQL results come out very positive. The GraphQL wins significantly in the data layer category.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/c0566/posneg.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Positive vs Negative split" title="Positive vs Negative split" src="https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/fcda8/posneg.png" srcset="https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/12f09/posneg.png 148w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/e4a3f/posneg.png 295w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/fcda8/posneg.png 590w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/efc66/posneg.png 885w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/c83ae/posneg.png 1180w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/c0566/posneg.png 1544w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>The summary</h2>
<p>The data layer space is still in constant movement which makes selecting the right technology for your needs a bit tricky. The survey administrators decided to prepare a data graph that could possibly really help you decide if the technology you are looking into is going in the right direction and ease the process of the decision if you should start seriously thinking about adopting it.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/8733b/change-ot.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL over last years graph" title="GraphQL over last years graph" src="https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/fcda8/change-ot.png" srcset="https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/12f09/change-ot.png 148w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/e4a3f/change-ot.png 295w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/fcda8/change-ot.png 590w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/efc66/change-ot.png 885w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/c83ae/change-ot.png 1180w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/8733b/change-ot.png 1495w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Each of the lines represents different technology and is filled by the data from 2016 to 2020. The higher position on the Y-axis means that the technology has been used by more people, and a point further to the right on the X-axis means more users have used it and would use it again or are interested in learning more about it.</p>
<p>Over a couple of last years, GraphQL has ranked up from technology worth keeping an eye on (with low usage, but high satisfaction) to a date later characterizing in high usage and satisfaction which makes it a safe technology to adopt. The general conclusion is that GraphQL and all the technologies, libraries, tools its fuelling are here to stay. </p>
<hr>
<p><em>All graphs and data comes from the StateofJs.com, if you are interested in more details regarding data layer or other JS aspects make sure to visit <a href="https://2020.stateofjs.com/en-US/technologies/datalayer/">2020.stateofjs.com</a></em></p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/state-of-graphql-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224536</guid>
            <pubDate>Mon, 22 Feb 2021 13:57:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Monitor the services you use, from your menu bar]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224534">thread link</a>) | @alollou
<br/>
February 22, 2021 | https://instatus.com/out | <a href="https://web.archive.org/web/*/https://instatus.com/out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><a href="https://instatus.com/out/download/mac"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M376 160H272v153.37l52.69-52.68a16 16 0 0122.62 22.62l-80 80a16 16 0 01-22.62 0l-80-80a16 16 0 0122.62-22.62L240 313.37V160H136a56.06 56.06 0 00-56 56v208a56.06 56.06 0 0056 56h240a56.06 56.06 0 0056-56V216a56.06 56.06 0 00-56-56zM272 48a16 16 0 00-32 0v112h32z"></path></svg>Get on mac OS</a><a href="https://instatus.com/out/video" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M464 384.39a32 32 0 01-13-2.77 15.77 15.77 0 01-2.71-1.54l-82.71-58.22A32 32 0 01352 295.7v-79.4a32 32 0 0113.58-26.16l82.71-58.22a15.77 15.77 0 012.71-1.54 32 32 0 0145 29.24v192.76a32 32 0 01-32 32zM268 400H84a68.07 68.07 0 01-68-68V180a68.07 68.07 0 0168-68h184.48A67.6 67.6 0 01336 179.52V332a68.07 68.07 0 01-68 68z"></path></svg>Watch intro video</a><div><p>Select services you depend on</p><p>Check their status in your menu bar</p><p>Get notified when they change their status</p></div></div></div>]]>
            </description>
            <link>https://instatus.com/out</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224534</guid>
            <pubDate>Mon, 22 Feb 2021 13:57:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JSON with Commas and Comments]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 242 (<a href="https://news.ycombinator.com/item?id=26224255">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | https://nigeltao.github.io/blog/2021/json-with-commas-comments.html | <a href="https://web.archive.org/web/*/https://nigeltao.github.io/blog/2021/json-with-commas-comments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p><em>Summary: JWCC is a minimal extension to the widely used JSON file format with
(1) optional commas after the final element of arrays and objects and (2) C/C++
style comments. These two features make it more suitable for human-editable
configuration files, without adding so many features that it’s incompatible
with numerous other (deliberate and accidental) existing JSON extensions.</em></p>

<h2 id="extensibility">Extensibility</h2>

<p>The Peter Principle is the half-joking, half-serious observation that people
get promoted to their level of incompetence, because being competent at level
<code>N</code> leads to being promoted to level <code>N+1</code>.</p>

<p>My colleague Simon Morris made a similar observation about software complexity:</p>

<blockquote>
  <p>Software has a Peter Principle. If a piece of code is comprehensible, someone
will extend it, so they can apply it to their own problem. If it’s
incomprehensible, they’ll write their own code instead. Code tends to be
extended to its level of incomprehensibility.</p>
</blockquote>

<h3 id="the-many-json-extensions">The Many JSON Extensions</h3>

<p>There’s a similar story with file formats. If they’re comprehensible, they’ll
get extended. JSON (JavaScript Object Notation) is this article’s example. The
<a href="https://json.org/">original specification</a> fits on a single page, either as
text or diagrams. The file format is simple and ubiquitous. Therefore, there
are many extensions - supersets of JSON. Here’s just a few (including two
slightly different extensions both called “JSONC”):</p>

<ul>
  <li><a href="https://json5.org/">JSON5</a></li>
  <li><a href="https://komkom.github.io/">JSONC</a> #1</li>
  <li><a href="https://code.visualstudio.com/docs/languages/json#_json-with-comments">JSONC</a> #2</li>
  <li><a href="https://hjson.github.io/">HJSON</a></li>
  <li><a href="https://github.com/lightbend/config/blob/master/HOCON.md">HOCON</a></li>
</ul>

<p>Suprisingly, <a href="https://yaml.org/">YAML</a> is also a superset of JSON. Not just
conceptually, but also in the sense that valid JSON files are also valid YAML
files (although there’s some divergence about whether duplicate keys are
legitimate). As a bonus, if you use YAML, then to paraphrase <a href="http://regex.info/blog/2006-09-15/247">Jamie
Zawinski</a>: now you have <a href="https://noyaml.com/">NO
problems</a>.</p>

<h3 id="wandering-off-the-specification">Wandering Off the Specification</h3>

<p>There are also informal supersets-of-JSON in widespread use, sometimes more by
accident than by design. The Chromium web browser’s <a href="https://source.chromium.org/chromium/chromium/src/+/master:base/json/json_reader.h;l=27;drc=d0919138b7951c1a154cf802a68aad7904b6f4c9">JSON parser goes
off-spec</a>
in a number of ways. The timeline could have been:</p>

<ol>
  <li>Some developer long ago (perhaps in a yak-shaving hurry) wrote or
copy/pasted some parsing code that was accidentally too lenient, allowing a
superset-of-JSON. Perhaps they re-used existing code that handled C-style
string escapes, like the <code>"\n"</code> in <code>"line\nbreak"</code>, without realizing that
it also unescaped <code>"\v"</code>, valid in a C string but not a JSON string.</li>
  <li>People use the software. They write first-party and third-party JSON for it.
Some of it is actually malformed (e.g. they have <code>"\v"</code> inside strings) but
tests (manual and automatic) usually check that new features work, not that
all the slightly-incorrect things are rejected. Nobody notices at the time.</li>
  <li>Years pass. <a href="https://www.hyrumslaw.com/">Hyrum’s Law</a> slowly kicks in. We
can no longer tighten this custom JSON parser implementation to follow the
spec more strictly because too many things (in unknown places) will break.</li>
</ol>

<p>This also affects our ability to replace one JSON library with another. For
example, we might want to switch from a C++-based JSON parser to a Rust-based
one, because of its security benefits. If the upstream Rust library chooses to
follow the spec diligently (which is a perfectly reasonable position) then it
would ‘break’ our apps that have inadvertently relied on the previous
looser-than-the-spec implementation.</p>

<p>We could carry local patches, but that isn’t free. Upstream fuzz-testing
infrastructure only exercises the unmodified library, not our patched flavor.
Future upstream changes may also invalidate the downstream patch, possibly in
subtle ways. An upstream “this new unsafe block is OK because it’s a private
implementation detail and nothing in this crate does X” comment might not be
aware that our out-of-tree patch does X to its internals.</p>

<h3 id="quirks">Quirks</h3>

<p>The Wuffs library approach is to expose
<a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/doc/note/quirks.md">quirks</a>: runtime
configuration options to go off-spec in various ways so that Wuffs’
implementation can be a drop-in replacement for other implementations, without
the need for downstream patches.</p>

<p>Wuffs has <a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/std/json/decode_quirks.wuffs">20 JSON
quirks</a>
so far. As always, there are trade-offs. They’re not free (in terms of
maintenance cost) and have super-linear complexity: that file’s comments also
has 12 call-outs to the subtleties of combining two particular quirks.</p>

<p>Here’s an example of the emergent complexity when combining two simple-sounding
JSON extensions. The first one adds C++-style <code>/* slash-star block comments */</code>
and <code>// double-slash line comments</code>. The second one packs multiple top-level
values in a single stream, separated by line breaks.</p>

<p>That second extension - by itself and when holding minified, whitespace-free
‘vanilla’ (non-extended) JSON - plays well with Unix’s traditional
line-oriented tools. It is sometimes known as Line-Delimited JSON
(<a href="https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON">LDJSON</a>),
Newline-Delimited JSON (<a href="http://ndjson.org/">NDJSON</a>) and JSON Lines
(<a href="http://jsonlines.org/">JSONL</a>). But “one value per line” tools’ assumptions
can break if slash-star comments can also contain blank lines.</p>

<p>Here’s another question (let’s call it the ‘end of comment’ question). Is the
<code>'\n'</code> at the end of of a <code>// double-slash line comment</code> actually part of the
comment? At first, this sounds merely philosophical. Comments are ignored and,
in ‘vanilla’ JSON, all whitespace is ignored, so why the distinction?</p>

<p>The ‘right’ answer to that ‘end of comment’ question isn’t obvious, but it can
affect whether a line comment at the end of a multi-value stream should end in
1 or 2 <code>'\n'</code> bytes. Ideally the answer should be self-consistent with whether
a line comment at the end of file must end with the <code>'\n'</code> or whether the
implicit EOF (end-of-file) alone suffices. See also the <a href="http://seriot.ch/parsing_json.php">“Parsing JSON is a
Minefield”</a> and <a href="https://nullprogram.com/blog/2019/12/28/">“Unintuitive JSON
Parsing”</a> articles for how subtle a
‘simple’ format like JSON can be.</p>

<p>Wuffs makes one particular choice for that ‘end of comment’ question. Its
particular choice probably isn’t that important, more that it made a concious
and documented choice.</p>

<h3 id="clarity-not-terseness">Clarity, not Terseness</h3>

<p>Some general advice, when designing a new file format or extending an existing
one, is keep some room for future extensions. For example, allowing unquoted
strings (writing <code>foo</code> instead of <code>"foo"</code>), is certainly convenient, but
re-defining <code>undefined</code> or <code>datetime</code> without quotes, from invalid JSON syntax
to valid some-extension-of-JSON strings, rules out a future extension adding
new ‘keywords’.</p>

<p><a href="https://cbor.io/">CBOR</a> is binary at the wire format level (unlike textual
JSON) but naturally extends JSON at the object model level. It also has an
<code>undefined</code> concept separate from <code>null</code>, and <code>undefined</code> can be a map key. We
couldn’t do the ‘obvious’ CBOR-to-some-extended-JSON conversion if <code>undefined</code>,
without quotes, was already repurposed to mean a string.</p>

<p>I find it suprising that, <a href="https://github.com/lightbend/config/blob/master/HOCON.md#unquoted-strings">in
HOCON</a>,
“<code>truefoo</code> parses as the boolean token <code>true</code> followed by the unquoted string
<code>foo</code>. However, <code>footrue</code> parses as the unquoted string <code>footrue</code>”.</p>

<p>It can also be helpful for a <a href="https://github.com/search?q=return.flase+extension%3Apy">typo like
<code>flase</code></a> to be picked
up early as a syntax error (without needing schemas or type checking) instead
of silently accepted (as a string, not a bool). This can otherwise be
especially dangerous if further processed in a weakly-typed programming
language where any non-empty string is ‘truthy’.</p>

<p><code>[a b c]</code> is invalid ‘vanilla’ JSON syntax, but in the various extended-JSON
variants, is it a list with three 1-byte strings or one 5-byte string? Or is it
one 3-byte string because three 1-byte strings are implicitly
whitespace-delimited and also then implicitly concatenated? Any particular
answer can be consistent in its own world, but different JSON extensions make
different choices. This can be confusing when software grows large enough (or
gains enough transitive dependencies) to have to speak multiple JSON
extensions.</p>

<p>These days, when I’m programming in C/C++ or Go, I often add unnecessary
parentheses in expressions like <code>(a * b) + c</code>. Even though they’re redundant
because of well-defined operator precedence rules, different programming
languages have different precedence rules and getting the precedence wrong can
lead to <a href="https://github.com/jbangert/nail/issues/7">hard-to-spot bugs</a>. The
Wuffs language actually <a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/doc/wuffs-the-language.md#operators">rejects a bare <code>a * b +
c</code></a>
and you have to parenthesize the multiplication or the addition.</p>

<p>Similarly, for JSON-like documents, I prefer the clarity of either <code>["a", "b",
"c"]</code> or <code>["a b c"]</code>, even if it means a little extra typing. Reading is more
important than writing for code and configuration, especially when multiple
people or long periods of time are involved.</p>

<h2 id="introducing-jwcc">Introducing JWCC</h2>

<p>Having said all of that, here is yet another superset-of-JSON, called JWCC
(JSON With Commas and Comments). It is a minimal extension. As its name
suggests, there are only two new features:</p>

<ul>
  <li>“Commas” lets you optionally have a comma after the final element of an array
or an object: <code>[1,2,3,]</code>. When you format one element per line, it’s easier
to insert and remove elements (and eyeball the diffs) when you don’t have to
fiddle with any commas (or lack of commas) on adjacent but otherwise
unrelated lines.</li>
  <li>“Comments” lets you have C++-style <code>/* slash-star block comments */</code> and <code>//
double-slash line comments</code>, anywhere where ‘vanilla’ JSON allows whitespace.
Line comments must end with a <code>'\n'</code> byte, even at the end of the file.</li>
</ul>

<p>To be clear, while every JSON file is valid JWCC, this is a new file format. It
just happens to be very familiar if you (or your software) already speak JSON.
Yes, Doug Crockford <a href="https://web.archive.org/web/20150105080225if_/https://plus.google.com/+DouglasCrockfordEsq/posts/RK8qyGVaGSr">deliberately removed comments from
JSON</a>
but people keep putting them back in. If we’re going to have comment-enriched
JSON (e.g. for human-editable configuration files), we might as well have a
standard one. Cue <a href="https://xkcd.com/927/">XKCD #927 “Standards”</a>.</p>

<h3 id="cc-implementation">C/C++ Implementation</h3>

<p><a href="https://github.com/google/wuffs">Wuffs</a>’ JSON library (availble as a C or C++
API) can decode either ‘vanilla’ JSON or JWCC, using its quirks mechanism.
<a href="https://github.com/google/wuffs/tree/3d6c609dc12de3c81e1b8079ceecf96370b086a2/example/jsonptr"><code>jsonptr</code></a>
is a command line tool (a JSON formatter) that uses this library. By default,
it speaks spec-compliant ‘vanilla’ JSON:</p>

<div><div><pre><code>$ echo '[1,2,/*hello*/3,]' | jsonptr
[
    1,
    2
json: bad input
</code></pre></div></div>

<p>It has a JWCC mode:</p>

<div><div><pre><code>$ echo '[1,2,/*hello*/3,]' | jsonptr -jwcc
[
    1,
    2,
    /*hello*/
    3,
]
</code></pre></div></div>

<p>It can also convert from JWCC syntax to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nigeltao.github.io/blog/2021/json-with-commas-comments.html">https://nigeltao.github.io/blog/2021/json-with-commas-comments.html</a></em></p>]]>
            </description>
            <link>https://nigeltao.github.io/blog/2021/json-with-commas-comments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224255</guid>
            <pubDate>Mon, 22 Feb 2021 13:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SubstackDB: Exploiting Lax Upload Validation to Create Parasitic File Servers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224143">thread link</a>) | @dgaff
<br/>
February 22, 2021 | http://devingaffney.com/substackdb-exploiting-lax-upload-validation-to-create-parasitic-file-servers/ | <a href="https://web.archive.org/web/*/http://devingaffney.com/substackdb-exploiting-lax-upload-validation-to-create-parasitic-file-servers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
    <article itemtype="http://schema.org/BlogPosting">
        <section>
            <p>For the past year, I've been increasingly focusing on what I have come to call "sociotechnical security" - whereas "technical security" seeks to identify and remove unintended flaws in the architecture of platforms, "sociotechnical security" is all about identifying and removing the incentives for how worst-faith users may abuse the explicit intent of platform affordances. Making this "sociotechnical" distinction brings into the frame a lot of issues not typically considered to be security issues, but are proving to become existential threats to a bunch of different businesses. Social platforms have misinformation problems due (in part) to fake accounts spreading it, online marketplaces face algorithmic manipulation challenges from sellers jockeying for position, and platforms with weak security around analytics face all sorts of ad and impression count fraud.</p>

<p>Today I want to share an exploit that I spent the last week investigating, and am calling "SubstackDB," after Substack, where I first identified the problem. Specifically, platforms tend to prefer low-friction interfaces, and tend to afford users increasing flexibility in affordances provided. Substack's WYSIWYG editor for drafting posts is overly optimistic in assuming good faith in user behavior, and is exposed to a huge flaw - because there is no validation for the input of files uploaded into the editor, and because their upload functionality has no verification scheme beyond requiring an active user session, their file server can be hijacked for any arbitrary use case. Far from being the only company facing this issue, Discord also suffers from a nearly identical problem. As a proof of concept, I used the unpublished APIs for both Substack and Discord's file uploading capabilities to store copies of GPT2 on their servers, and I provide the necessary scripts for loading and verifying the execution of those models. Additionally, I am providing a ruby implementation of <code>SubstackDB</code> which, given a valid username and password allows a user to upload and download any file of any size.</p>

<h2 id="substackvulnerability">Substack Vulnerability</h2>

<p><img src="https://i.imgur.com/VQhkAow.png" alt="Substack Editor"></p>

<p>This is a picture of Substack's WYSIWYG post editor with an example image uploaded. Here's a look at the <code>cURL</code> request that uploaded the image, and the response back from the server:</p>



<p>And the response:  </p>



<p>It turns out that this "bucketeer" name refers to a Heroku file server plugin, which presumably also indicates that Substack is at least partially hosted there. Regardless, through trial and error, I determined that only a very small portion of the above <code>cURL</code> is required to send a file:</p>

<p>Here, the <code>[BASE 64 BYTES]</code> refers to literally any content that is Base64 encoded. In our case it is an image, but it turns out that any data encoded in Base64 will be treated as valid input. Through more trial and error, I determined that while there seems to be no upper limit to the size of an uploaded file, though it is in practice limited by timeout errors that ultimately invalidate the request. Further, this "image" upload functionality actually returns the original file byte-for-byte, so no compression occurs between upload and receiving the final URL - because of this, we can store any other data relatively easily and just declare the "type" of the content to be one of the valid types required by the upload endpoint.</p>

<p>To prove that any arbitrary content could be uploaded, I downloaded a copy of the GPT2 "medium" model via <code>aitextgen</code>, split the <code>.bin</code> file containing the model into several hundred smaller files of equal size, and then uploaded those to Substack's endpoint. Finally, I wrote a script that reconstructs the model using a final "manifest" JSON file stored on Substack as well:</p>



<h2 id="discordvulnerability">Discord Vulnerability</h2>

<p>Discord's vulnerability seems a bit more intentional as a feature than as a bug per se, but is still ripe for abuse. Using a throwaway account and throwaway server, I was granted a set of credentials - using those credentials, I was able to slightly alter the script I used to upload GPT2.</p>

<p><img src="https://i.imgur.com/rdwMF5D.png" alt="Uploaded 6mb slices of GPT2"></p>

<p>Discord appears to treat non-image uploads as more of a first-order object in their system - clearly, there is some form of intent to allow users to upload files of some nature. What is likely outside the intent, however, is automating this affordance to send gigabytes of content through their platform in a relatively short time frame. Ultimately, I was able to generate a nearly identical script as was deployed in the Substack case.</p>



<h2 id="substackdbscript">SubstackDB Script</h2>

<p>Finally, to prove out the concept of truly using this type of vulnerability as an arbitrary file server, I wrote a generalized <code>SubstackDB</code> class which, in this version of the script, takes as input the username, password, and filepath, and returns a print-out of whether or not the contents of that filepath, once read, uploaded, and downloaded, is identical to the original source file. In practice, one could use this script to be a literal drop-in replacement for many classic file store APIs. </p>



<h2 id="endnote">Endnote</h2>

<p>This is just two examples of a general problem with upload validation. Of note, I also explored exploits like this on Meetup, Indiegogo, Gumroad, and a few others, and while it was still likely <em>technically</em> possible to pull off a similar stunt, it was in no way worth the investment in time that it would take to fully reverse engineer their implementations - generally, the issue was that one-time-use tokens were being employed to validate uploads on a per-upload basis, which proved to be too much of a pain to solve. The point, however, is that this is a demonstration of a systemic issue - by assuming best-faith use, platforms allow worst-faith users the unintended "sociotechnical" affordance of a free fileserver at the cost of the platform. </p>
            
            
            
        </section>
        
    </article>
</div></div>]]>
            </description>
            <link>http://devingaffney.com/substackdb-exploiting-lax-upload-validation-to-create-parasitic-file-servers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224143</guid>
            <pubDate>Mon, 22 Feb 2021 13:18:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The birth of Prolog (1992) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 36 (<a href="https://news.ycombinator.com/item?id=26223906">thread link</a>) | @alokrai
<br/>
February 22, 2021 | http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf | <a href="https://web.archive.org/web/*/http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223906</guid>
            <pubDate>Mon, 22 Feb 2021 12:51:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Sculpt Wired Conversion Mod]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26223805">thread link</a>) | @yuribro
<br/>
February 22, 2021 | https://chadaustin.me/2021/02/wired-sculpt/ | <a href="https://web.archive.org/web/*/https://chadaustin.me/2021/02/wired-sculpt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I made a control board for the Microsoft Sculpt wireless keyboard that converts it to wired USB, and now my favorite keyboard is even better.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/finished-board.jpeg"><img src="https://chadaustin.me/images/sculpt/finished-board.jpeg" alt="The finished and installed board."></a>
<figcaption>The finished and installed board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/messy-desk.jpeg"><img src="https://chadaustin.me/images/sculpt/messy-desk.jpeg" alt="Wired keyboard and the resulting project mess!"></a>
<figcaption>Wired keyboard and the resulting project mess!</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/underside.jpeg"><img src="https://chadaustin.me/images/sculpt/underside.jpeg" alt="USB cable and reset button."></a>
<figcaption>USB cable and reset button.</figcaption>
</figure>

<p>The QMK config is available at <a href="https://github.com/chadaustin/qmk_firmware">@chadaustin/qmk_firmware</a> (<a href="https://github.com/chadaustin/qmk_firmware/tree/master/keyboards/handwired/sculpt">keyboards/handwired/sculpt/</a>), and the PCB design files at <a href="https://github.com/chadaustin/wired-sculpt-pcb">@chadaustin/wired-sculpt-pcb</a>.</p>

<p>I’m planning on making at least one more, so if you’d like one, maybe I can help.</p>

<p>It’s a huge improvement. Latency is reduced by about 13 milliseconds, and with full control over the microcontroller’s firmware, you can customize keymaps and layers, and actually use the keyboard’s built-in LEDs.</p>

<h2 id="why">Why?</h2>

<p>Feel free to stop reading here — I am going to tell the sequence of events that led to this project. Besides some exposure to basic voltage and resistance circuits in college, I have very little electronics background. But, in a short time, I went from only barely knowing what a capacitor was to having a working PCB manufactured and assembled, and maybe this will inspire someone else to give it a try.</p>

<p>Since developing RSI in college, I’ve exclusively used Microsoft’s ergonomic keyboards. And when I first tried the Sculpt, I instantly knew it was the best yet. The soft actuation, short key travel, and rigid frame are perfect for my hands. And because the number pad is a separate device, the distance to my mouse is shortened.</p>

<p>My brother went out and bought one too. Not much later, he gave it to me, saying the latency was inconsistent and high, and it was unacceptable for gaming. I thought he was being uniquely sensitive, since I had no problem in either Linux, Windows 7, or macOS. But then I updated to Windows 10 and saw exactly what he meant.</p>

<p>It was like the keyboard would go to sleep if a key wasn’t pressed for a few seconds, and the first keypress after a wake would be delayed or, worse, dropped.</p>

<p>And heaven forbid I use my USB 3 hub, whose EMI would disrupt the 2.4 GHz signal, and <em>every other</em> keypress would be unreliable. I’d gone as far as mounting the wireless transceiver directly under my keyboard, on the underside of my desk, and keys were still dropped.</p>

<p>So, best keyboard ever. But wireless sucks. (But mostly in Windows 10? No idea about that.)</p>

<h2 id="over-the-hump">Over the Hump</h2>

<p>What started this whole thing is that the <a href="https://github.com/facebookexperimental/eden/#edenfs">EdenFS</a> team was a bunch of keyboard enthusiasts. During the pandemic, as we’re all at home burning out and missing each other, we were trying to think of some virtual team offsites. Wez offered to walk everyone through building a <a href="https://www.1upkeyboards.com/instructions-downloads/sweet-16-instructions/">Sweet 16 Macro Pad</a>.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/sweet-16.jpeg"><img src="https://chadaustin.me/images/sculpt/sweet-16.jpeg" alt="Assembled Sweet 16 underside"></a>
<figcaption>Assembled Sweet 16 underside. This is take two, after resoldering and cleaning the whole thing. Take one was a bit of a mess.</figcaption>
</figure>

<p>So, okay, a keyboard is a matrix, with some diodes used to disambiguate the signalling, and a microcontroller that rapidly polls the matrix and reports events over USB…</p>

<p>So maybe I could fix the Sculpt! I bought a transceiver-less Sculpt off eBay for cheap and <a href="http://emmanuelcontreras.com/how-to/how-to-disassemble-microsoft-sculpt-ergonomic-keyboard-and-make-it-wired/">popped it open (thanks Emmanuel Contreras!)</a>, thinking maybe its controller could be flashed with new firmware that speaks USB. The Sculpt uses a <a href="https://infocenter.nordicsemi.com/pdf/nRF24LE1_PS_v1.6.pdf">Nordic Semiconductor nRF24LE1</a>, but I was nowhere near capable of making use of that information at the time, though it did point me to Samy Kamkar’s horrifying guide on <a href="https://samy.pl/keysweeper/">surreptitiously sniffing keystrokes from nearby (older) Microsoft wireless keyboards</a>.</p>

<p>I almost gave up here, but Per Vognsen <a href="https://twitter.com/pervognsen/status/1322422385174220800">suggested I scan the matrix myself</a> and it turns out Michael Fincham had already <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/bhkgnp/modification_photos_qmk_wired_microsoft_sculpt/">mapped out the matrix and soldered a Teensy 2.0++ board onto the Sculpt’s test pads</a>, showing this was doable!</p>

<p>So I ordered my own microcontroller to try the same thing.</p>

<p>First, I bought an Arduino Pro Micro, like the Sweet 16 uses. Oh hey, 18 GPIO pins isn’t enough to drive the Sculpt’s 26-pin matrix. I looked at using an I2C GPIO expander, but it felt like taking on too much.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pro-micro.jpeg"><img src="https://chadaustin.me/images/sculpt/pro-micro.jpeg" alt="Arduino Pro Micro"></a>
<figcaption>Arduino Pro Micro. Wait, you need pins to scan a matrix?</figcaption>
</figure>

<p>More pins? QMK’s Proton C has more pins! So I carefully soldered onto the test pads as Michael had shown was possible… and it worked!</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/proton-c.jpeg"><img src="https://chadaustin.me/images/sculpt/proton-c.jpeg" alt="QMK Proton C"></a>
<figcaption>QMK Proton C. It's a beautiful board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/test-pads.jpeg" alt="Soldering test pads to Proton C."></a>
<figcaption>Soldering test pads to Proton C.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/all-test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/all-test-pads.jpeg" alt="All test pads connected to Proton C. It works!"></a>
<figcaption>All test pads connected to Proton C. It works!</figcaption>
</figure>

<p>Getting those wires to stick to the pads without shorting was tricky. (I hadn’t yet discovered how magical flux is.)</p>

<p>The keyboard worked, but I couldn’t fit the board, its wires, and the new microcontroller into the case, and I wasn’t <em>really</em> happy leaving it in this state, even if I could pack it in somehow.</p>

<p>I thought, all I <em>really</em> need is the ribbon cable connector, so I ordered a 30 pin, 1.0 mm pitch ribbon breakout and the pricier (but tons of pins!) <a href="https://www.pjrc.com/store/teensypp.html">Teensy 2.0++</a>. Looking back, it’s cute that I was trying to save $10 on the microcontroller… You just have to get used to spending money on whatever saves you time.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg"><img src="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg" alt="Ribbon cable breakout and Teensy 2.0++"></a>
<figcaption>Ribbon cable breakout and Teensy 2.0++</figcaption>
</figure>

<p>Well, it was almost as annoying to solder, and still didn’t fit. So much for saving money on microcontrollers.</p>

<p>I thought about giving up. Is it really that bad that my keys don’t always register in games? Can I just tolerate some flakiness and latency?</p>

<p>But Jon Watte offered to spend an entire day showing me how to use KiCad, design circuits, layout PCBs, select components on Digi-Key, scan datasheets for the important information, and how to work with a PCB manufacturing house. Of course you never turn down opportunities like that.</p>

<h2 id="designing-the-final-board---schematic">Designing the Final Board - Schematic</h2>

<p>Assuming, like me, you’ve never done this, I’ll summarize the steps.</p>

<p>First you sketch out the circuit schematic.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/schematic.png"><img src="https://chadaustin.me/images/sculpt/schematic.png" alt="Schematic"></a>
<figcaption>Schematic in KiCad. Most of this was informed by the datasheet and Atmel's design guides.</figcaption>
</figure>

<p>Jon showed me several tricks in KiCad, like global labels, and starting with some standard resistor and capacitor values, but it’s very important that you go through the datasheets, because details can matter a ton.</p>

<p>I knew I wanted the main processor to be the AT90USB1286 controller, and fortunately KiCad already had a symbol for it. Atmel has a comprehensive and accessible data sheet, which showed me I needed some 22 Ω resistors on the USB data lines, which of the ISP programmer lines needed resistors (and appropriate values), and that I needed to either pull HWB low, or provide a physical switch that pulls it low, in order to allow rebooting the device into USB firmware update mode.</p>

<p>There are a bunch of things that are implicitly known to electrical engineers but that were new to me. You want:</p>

<ul>
  <li>a ground plane under the data lines and most of the microcontroller if possible.</li>
  <li>an electrolytic or tantalum bypass capacitor on the main 5V power from USB.</li>
  <li>ceramic filter capacitors on each power pin.</li>
  <li>appropriate values for the resonance capacitors on your crystal.</li>
  <li>electrostatic discharge protection! Turns out transients are common and it’s easy to fry a chip just by plugging it in.</li>
</ul>

<p>And then when you get into concerns like EMI and high-frequency signal integrity, the rabbit hole goes deep.</p>

<p>I kept having to tell myself “it’s just a keyboard”, but it also helped that there are a great number of high-quality resources on these topics just a click away. I spent lots of time on <a href="https://www.eevblog.com/">EEVBlog</a>.</p>

<p>Before finishing the circuit design, Jon had me do a couple smart things. In case the factory-supplied USB bootloader didn’t work out, he suggested I add the footprint (but not a connector!) for an ISP programmer and a debug LED to prove code would work at all.</p>

<h2 id="designing-the-final-board---physical-layout">Designing the Final Board - Physical Layout</h2>

<p>After arranging the schematic and ensuring it passed the electrical rules check, it was time to pick specific components. That is, the reference to a 220 Ω resistor is replaced with the Panasonic ERJ-3EKF2200V, 0603 surface mount.</p>

<p>There are a couple things to keep in mind. For common components, like resistors and ceramic capacitors, there is a huge amount of choice. For example, I see over 1400 surface-mount 220 Ω resistors on digikey. I tried to just stick with one high-quality brand like Panasonic or Samsung for all of that stuff.</p>

<p>The important thing is the physical form factor, which determines the footprint on the board. Once you pick a part, it has a size, and you need to tell KiCad which physical footprint should be assigned to that component. I used 0603 resistors, so I assigned each resistor in the schematic the “Resistor_SMD:R_0603_1608Metric” footprint.</p>

<p>Same for everything else. Jon showed me how to draw my own footprints, but to avoid complexity, I was able to find appropriate footprints in KiCad’s standard libraries for every component I needed.</p>

<p>When you import the schematic into Pcbnew, it’s time to figure out where things go. Where are the edges of the board? Make careful measurements here. Where do the mounting holes go? Where do you want 
the microcontroller? Where do you want the USB port?</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/dimensions.jpeg"><img src="https://chadaustin.me/images/sculpt/dimensions.jpeg" alt="Measuring dimensions and mounting holes"></a>
<figcaption>Measuring dimensions and mounting holes</figcaption>
</figure>

<p>Also, you have to pick through-hole sizes and trace widths. Jon had me use .250 mm for the narrow traces and .500 mm for the wider ones, presumably from experience. I used the narrow traces for signalling and wide traces for power, though I’ve since heard it’s a good idea to use narrow traces between filter capacitors and VBUS.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pcb-layout.svg"><img src="https://chadaustin.me/images/sculpt/pcb-layout.svg" alt="Schematic"></a>
<figcaption>PCB layout in KiCad</figcaption>
</figure>

<p>Of course, there’s some iteration between the schematic and the PCB. After physically placing the ribbon cable connector and MCU, the traces all crossed over each other, so I had to reassign all the pins so it made sense physically.</p>

<p>There are also physical constraints about how USB data lines are run, and how the electrostatic protection chip wants to be placed for the most protection.</p>

<p>So, as simple as this board is, I spent a fair amount of time getting all of that right.</p>

<p>I found myself getting lost in the abstractness of holes and traces and footprints, so it was helpful to ground myself by occasionally loading the PCB in KiCad’s 3D viewer.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/3d-view.png"><img src="https://chadaustin.me/images/sculpt/3d-view.png" alt="Schematic"></a>
<figcaption>3D View</figcaption>
</figure>

<h2 id="designing-the-final-board---manufacturing-and-testing-physical-fit">Designing the Final Board - Manufacturing and Testing Physical Fit</h2>

<p>I tried to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chadaustin.me/2021/02/wired-sculpt/">https://chadaustin.me/2021/02/wired-sculpt/</a></em></p>]]>
            </description>
            <link>https://chadaustin.me/2021/02/wired-sculpt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223805</guid>
            <pubDate>Mon, 22 Feb 2021 12:39:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I’m Losing Trust in Open Source]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 31 (<a href="https://news.ycombinator.com/item?id=26223575">thread link</a>) | @bodegajed
<br/>
February 22, 2021 | https://gibson.ws/why-im-losing-trust-in-open-source/ | <a href="https://web.archive.org/web/*/https://gibson.ws/why-im-losing-trust-in-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

		
					<!-- Image banner -->
					
					<!-- Image banner -->

					<div id="content">
						<div>
							<div>

	<div id="primary">
		<main id="main">

		
<article id="post-146">
			<!-- .entry-header -->

	<div>
		<p>Back when I was starting to code several years ago. I picked up The Cathedral and the Bazaar by Eric Raymond and I was blown away at the idea of free software. Just in case you are not familiar, free software as in freedom and not free beer. Free software back then was this super radical and idealistic concept where as you make a software product commercial or not, but when you distribute it you include the source code of it. The person who got your product would eventually continue to develop it and it will evolve and continually improve as it gets to many users. You then will be looking at their version of your product and will see how it has grown further. Think of it has a community garden where everyone grows their vegetable and anyone would then take pointers on some of your crops and grow their improved version. Eventually you’ll see where you are doing it wrong by looking at how they tend their garden. This is not necessarily free food for everyone – although it’s common. It’s freedom to copy and use my garden setup so we have bigger crops next harvest time.</p>
<p>This what happened to Linux, nodejs, Ruby etc.. I’ve believed in it much so I joined sourceforge joined a team, also started a project myself even. I followed this radical concept through the years and publish my projects openly on github. It was fun and there is some sort of social acceptance when people see your ugly looking code yet they accept it and submit their own ugly looking code as well.</p>
<p>Facebook, Apple, Google these companies are worth trillions of dollars and they all at one point when they are still small companies depended on open source. Their founders built an MVP and took money from VCs and then had to responsibly return their money 10x. They eventually all cashed out and now driving luxury sports cars. Meanwhile present day Linux desktop is still dead. Open source maintainers abandoning projects due to lack of time and interest. They say why not just use GPL but if you license your code using GPL you will not have users. Developers can’t even share the name of the software they are putting your code into because of these NDA they signed. Sometimes it’s just a simple request like attribution and compliance is still uncommon.</p>
<p>Life as a open source maintainer is sometimes a <a href="https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/">life threatening endeavor</a></p>
<p>Society, Conglomerates, and Capitalism killed free software and nobody cared. It’s all about 10x ROI and taking advantage of some poor idiot programmer clueless in business.</p>

			</div><!-- .entry-content -->
</article><!-- #post-146 -->

<!-- #comments -->

		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
</div>
</div><!-- #content -->
</div>
</div></div>]]>
            </description>
            <link>https://gibson.ws/why-im-losing-trust-in-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223575</guid>
            <pubDate>Mon, 22 Feb 2021 12:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Minesweeper]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26223504">thread link</a>) | @madprops
<br/>
February 22, 2021 | https://madprops.github.io/minesweeper/ | <a href="https://web.archive.org/web/*/https://madprops.github.io/minesweeper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://madprops.github.io/minesweeper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223504</guid>
            <pubDate>Mon, 22 Feb 2021 11:58:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual passport app presents real data risk, experts warn]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 97 (<a href="https://news.ycombinator.com/item?id=26223347">thread link</a>) | @pseudolus
<br/>
February 22, 2021 | https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Canadian privacy experts are concerned the federal government's plan to develop an online passport application process could put&nbsp;personal information at risk and open a new angle of attack for fraudsters.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4612031.1536417303!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/passport.jpg"></p></div><figcaption>IBM Canada's digital passport application platform is expected to begin testing in three months, and could be ready for use as early as 2022.<!-- --> <!-- -->(John Badcock/CBC)</figcaption></figure><p><span><p>Canadian privacy experts are concerned the federal government's plan to develop an online passport application process could put&nbsp;personal information at risk and open a new angle of attack for fraudsters.</p>  <p>IBM Canada has been awarded the&nbsp;$1.5-million contract to create software that would allow Canadians to apply for a passport using their&nbsp;smartphones, tablets or&nbsp;computers.</p>  <p>The new platform would also allow applicants to&nbsp;pay fees and upload their passport photos securely, according to a statement from Immigration, Refugees and Citizenship Canada (IRCC).</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>They will attempt to&nbsp;exploit the program very quickly, very intensely to obtain the most fraudulent passports they can in the least amount of time.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Benoît&nbsp;Dupont, l'Université de Montréal</cite></span></blockquote>    <p>But privacy and data protection experts worry that personal information may be stored on foreign servers, providing an appealing target to criminals.</p>  <p>Sébastien Gambs, a professor in the information technology department of l'Université de Québec à Montréal&nbsp;and Canada Research Chair on privacy and data protection, said there are real&nbsp;concerns about&nbsp;where the data will be stored, a detail neither the government nor IBM Canada has divulged, though the tender identifies Amazon Web Services (AWS), the cloud computing branch of the American online retail giant.</p>  <p>"Even when we do business with an American company that agrees to store data within Canada, under the [U.S.] CLOUD Act, data could eventually be transferred out of the country," Gambs said in French.</p>  <p>In a statement, AWS said its clients retain full ownership and control of their data, including who may access that information.</p>  <p>In a separate statement, IRCC said "the privacy of Canadians and the safety of their personal information will be an absolute priority."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/tech-cloud.JPG 300w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/tech-cloud.JPG 460w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/tech-cloud.JPG 620w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tech-cloud.JPG 780w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/tech-cloud.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tech-cloud.JPG"></p></div><figcaption>Amazon Web Services (AWS) says its clients retain full control over the data it stores.<!-- --> <!-- -->(Ivan Alvarado/Reuters)</figcaption></figure></span></p>  <h2>Canadian passports highly valued</h2>  <p>Benoît Dupont, a criminology professor at l'Université de Montréal and Canada Research Chair in cybersecurity, said the passport app will likely be a major target for fraudsters&nbsp;eager to get their hands on&nbsp;Canadian passports and the mobility that comes with them.</p>  <p>"That's very attractive for organized crime groups who specialize in human trafficking," Dupont said in French. "They will attempt to&nbsp;exploit the program very quickly, very intensely to obtain the most fraudulent passports they can in the least amount of time."</p>  <p>But&nbsp;Gambs said any virtual application will likely have extra&nbsp;steps built in to protect against hackers.</p>  <p>"As soon as we're doing things remotely, verifying somebody's identity becomes much more difficult," he said. "The government will definitely need to collect more personal information in order to verify an applicant's identity."</p>  <h2>'Vicious cycle': PIPSC</h2>  <p>The Professional Institute of the Public Services (PIPSC) said this tender should never have gone out to the private sector when it could have been developed in-house by public servants, as was done with the online tax portal.</p>  <p>"It's a vicious cycle. Instead of developing resources internally, we go externally," said&nbsp;Stéphane Aubry, vice-president of PIPSC. "Then we don't have the needed expertise internally,&nbsp;which&nbsp;unfortunately, over the years, fades and makes it so we need to contract out."</p>  <p>PIPSC said the project raises <a href="https://www.cbc.ca/news/canada/ottawa/phoenix-pay-system-cost-report-1.5138036">the spectre of the Phoenix pay system fiasco</a>, which also involved IBM.&nbsp;IBM Canada will be required to train and support IRCC employees in running the new passport system, according to the tender documents.</p>  <p>In 2020, the government issued just 897,401 passports, compared to 2.6 million the year before. For the first four months of the pandemic, Service Canada was only providing critical passport services for urgent travel.&nbsp;</p>  <p>Nevertheless, the Canadian Anti-Fraud Centre received 1,806 reports of passport-related fraud last year.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223347</guid>
            <pubDate>Mon, 22 Feb 2021 11:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[web3 is a Stupid Idea]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26222849">thread link</a>) | @Bluestein
<br/>
February 22, 2021 | https://timdaub.github.io/2020/09/08/web3/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/09/08/web3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>A long time ago, I gave a talk in front of a full audience talking about
BigchainDB, a company I worked for to create a (scalable) decentralized
database. As we just had released our browser-compatible JavaScript driver,
enthusiastically, I told the audience: “… and so by using our driver from
within the browser, your app won’t need a backend anymore”!</p>
<p>That must have been around 2017 when I first discovered Metamask, and started
drinking Ethereum’s web3 cool-aid. Arguably, web3 quickly became
something extraordinary. All of a sudden, users could download a browser
extension and directly interact with a public network. In a sense, it still
is extraordinary.</p>
<p>If you have an extension like Metamask installed in your browser today, you can
visit sites on the web that allow you to do the craziest things with your
digital money. An excellent recent example of this are DeFi (short for
“Decentralized Finance”) websites. They allow a user to engage in trading
cryptocurrencies, providing liquidity, and peer to peer lending.  With the
click of a button and no mandatory signups, you’re able to pool thousands of
dollars. That is super cool and confirms the viability of the web3 vision.</p>
<p>But actually, what is the web3 vision? It may be that there never was such a
thing in the first place. All I know is that someone named a library “web3.js”.
Developers use it to talk to remote or local Ethereum nodes when working in a
browser environment (JavaScript).</p>
<p>On a web3-enabled website, when a user now clicks a button to, e.g., pool ether
in a smart contract, most calculations are supported by the web3.js library
that periodically talks to an Ethereum node. Ultimately web3.js allows the user
to send the transaction to the node to transfer the user’s money.</p>
<p>Often, a key-management program, like Metamask, is running on the user’s
browser. It allows the user to sign transactions with the same key on different
websites.</p>
<p>In a nutshell, that’s web3. It’s supposed to be a play on words regarding “web
2.0”. Web 2.0 is the upgrade of web standards that gave us modern single-page
applications and dynamic AJAX loading. And Web3? An advancement towards what
exactly? Money websites?</p>
<p>Indeed, if you were capable of cleaning your mind of specific memories,
specifically, let’s say you could do <code>grep -l web3 brain | xargs rm</code>. And then
someone asked you how you’d envision a blockchain-based and
smart-contract-enabled web3; you’d likely describe an ecosystem vastly
different to what it is today. You’d think about peer-2-peer networks, light
clients, and renewed web standards. That’s precisely not web3.</p>
<p>In today’s experience it will instead be mostly shitty react websites that
crash or stop working when you’ve neglected to install Metamask (or other
key-management plugins). Opening a web3 website’s network console, you’ll see
that it’s making an excessive amount of RPC request to an Ethereum full node.
Sorry, I meant to say Infura node, a hugely-popular cloud provider hosting
Ethereum full nodes. That’s kinda stupid.</p>
<p>And since Metamask allows developers to prompt the user for specific contract
calls, what’s even more stupid, is that all your money may be at the risk of
continually getting stolen with the accidential click of a button. Either by
someone hacking the website’s server. Or by the website provider
becoming corrupt themselves. Or simply because a website pretends to do X when
it does Y (stealing all your money).</p>
<p>But instead of continuing to rant, I’d now like to now point out what I think
should change about web3:</p>
<ul>
<li>We should stop building key-management plugins and start thinking about a
standardizable web API. We must stop training our users to install shitty
browser plugins!</li>
<li>We need to make light clients work as soon as possible and become independent
from third-party services like thegraph and Infura.</li>
<li>We need to improve our client libraries (ethers.js and web3.js) by
dramatically simplifying them and making them bug-free (god damn it!)!</li>
<li>We need to take advantage of some of the blockchain’s fundamental properties.
Most data is immutable so let’s start caching things.</li>
</ul>
<p>And finally, I think we should stop focusing all of our attention on bumping
the web’s version number. Maybe we should reconsider writing more backends. We
should promote more work on permissionless networks like Open Gas Station
Network that allow developers to upgrade a user’s experience. And, we should
start thinking of a machine network of blockchains more often. In many ways,
web3 was just a cool demo. But let’s come up with something better. Just
imagine what happens once there’s a deeper integration of money into computer
systems!</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/09/08/web3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222849</guid>
            <pubDate>Mon, 22 Feb 2021 10:24:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Philosophical Roots of Sweden’s Pandemic Strategy]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26222756">thread link</a>) | @imartin2k
<br/>
February 22, 2021 | https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/ | <a href="https://web.archive.org/web/*/https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="6d6ca2c" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p>The year is 1911. The setting, the Swedish university of Uppsala’s <em>aula magna, </em>bursting with listeners. The occasion is the installation of the Swedish philosopher Axel Hägerström as chair professor of practical philosophy.</p>
<p>As part of the ceremony Hägerström was to hold a public lecture. Not long into the address, Hägerström’s explosive philosophy managed to spark a riot in the lecture-hall: vegetables were hurled, doors slammed. At the end of the lecture, the archbishop of the Swedish Lutheran church, the Reverend Nathan Söderblom, stood up and asked how anyone who harbored such views could ever behave decently towards his wife and kids.</p>
<p>Whether or not this is an accurate portrayal of the event, this is the form the story was handed down to me by one of my professors at Uppsala University, a proud inheritor of the tradition of Hägerström. The anecdote was delivered with an air of disbelief over the naiveté of the archbishop’s question. How could anyone believe that such abstract and abstruse doctrines on the semantics of ethical sentences could have any concrete repercussions on practical issues like how one treats one’s family?</p>
<p>More than a century after Hägerström’s lecture, Sweden’s response in the global COVID-19 pandemic has cast long shadows, drawing attention from all over the globe. Unlike the vast majority of other countries, Sweden has taken scant measures to hinder the spread of the virus. No lockdown. No closure of schools or public means of transport. No obligatory face masks. The infection was left to spread as quickly and widely as possible, in an attempt to achieve “herd immunity” among the population. As a result of this, Sweden is among the countries with the highest death toll per capita, more than twenty times as much as other comparable Nordic countries, all of which have taken considerably stronger measures.</p>
<p>At bottom, the Swedish strategy rests on a set of ethical positions that the government has chosen to adopt. These positions, in turn, look surprisingly like those staked out in Hägerström’s 1911 lecture. There is a clear line of influence running from the marmoreal halls of the university’s <em>aula </em>to the halls of power today. Although the materialism of our present society may suggest otherwise, ideas leave deep marks – a good example being precisely the materialism of our present society.</p>
<p>The title of the Hägerström’s historic 1911 lecture was “On the Truth of Ethical Utterances.” In it, the philosopher laid out something of a manifesto for the ethical position known as ethical non-cognitivism. He argued that any sentence expressing an ethical stance – any statement about what is good and what is bad – is necessarily nonsense. Asking whether an action is right or wrong, Hägerström assures us, is analogous to wondering about the amount of “justice” contained in a bar of gold, or how heavy a color happens to be. Ethical opinions are simply the reflection of personal emotions, and as such cannot be subject to either truth or falsehood.</p>
<p><em>Pace</em> my professor, Hägerström did, in fact, see his non-cognitivism as the cornerstone for a radical programme for political change. In “On the Truth of Ethical Utterances,” he describes his vision of a new ethics spawning to life from the ashes of the old one. This phoenix-like morality, having shed the fetters of metaphysics and superstition, would thereafter follow a single ethical lodestar: <em>functionality</em>. The effect of this approach was a practical utilitarianism: the goal of ethics in practice became to maximize the amount of utility for the greatest possible number. The scientific veneer of utilitarian ethics made it the perfect candidate for Hägerström’s post-metaphysical ethics of functionality. While it is nonsense to measure the “justice” of a gold ingot, it certainly makes a lot of sense to ask how much “utility” that gold can buy. Functionality is measurable; measurability is functional. Hägerström thus embodies the widely celebrated Swedish value of functionality. Indeed, it is no hyperbole to say that functionality is the country’s most cherished value. It also happens, slightly more worryingly, to be the only one.</p>
<p>The shockwaves of influence of Hägerström’s double-barreled approach of theoretical non-cognitivism coupled with a practical utilitarianism are too insidious to fully map. The ideas wormed their way into the official ideology of the Social-Democratic Party, which held an iron grip on Swedish politics for the better part of a century. Several of Hägerström’s students clambered up the party hierarchy and served long terms as ministers. The minister and economist Gunnar Myrdal, a disciple of Hägerström, described his master’s influence as ripples in water, expanding indefinitely until nobody was left unaffected. Hägerström’s students also became the architects behind Sweden’s “social engineering” programmes in the 1950s – government initiatives to streamline the population in order to increase its utility and functionality. “Social engineering” – or the project of shaping the “human-material”, as it was called – was (naturally) linked to comprehensive eugenic programmes. The Swedish pandemic strategy of achieving “herd immunity” (weeding out weaker individuals for the sake of “herd’s” utility) has a venerable history.</p>
<p>With this historical background in mind the reasoning behind the Swedish strategy becomes clearer, and, if anything, more appalling. At bottom, it is founded on a utilitarian calculus. Swedish authorities made no secret of the evaluation that needed to take place: one had to choose between the economy and the elderly, the unfettered functioning of society versus the health of its citizens – either justice or gold. The outcome of the calculations was clear: Sweden would opt for the alternative that maximizes utility across the board, even if in the process – as the euphemism goes – some eggs would need to be broken.</p>
<p>No wonder, then, that utilitarian philosophers came out in force in defense of the Swedish strategy. As the Swedish ethicist Olle Torpman bluntly wrote back in April: “Can we really put a price tag on people’s lives? Can we really compare somebody’s death with another person’s happiness or lack thereof? The answer is: yes.”<sup><a href="#footnote_0_2556" id="identifier_0_2556" title="Olle Torpman, “Moralfilosofin som ger Sverige rätt” (“The Ethical Philosophy that Supports the Swedish Strategy”), Kvartal.">1</a></sup></p>
<p>Likewise, the internationally acclaimed utilitarian ethicist Torbjörn Tännsjö publicly defended the “Swedish strategy” precisely on the grounds of its palpably utilitarian texture. As he said in an interview: “It sounds as if the government is prepared to sacrifice a number of individuals – at any rate in the short term – to save as many human lives as possible on the whole, partly by indirectly saving the economy.”<sup><a href="#footnote_1_2556" id="identifier_1_2556" title="Åke Gavfelin and Lapo Lappin, “Interview with Torbjörn Tännsjö”, Metafysiskalaboratoriet.">2</a></sup> There is a more than a hint of triumphalism in Tännsjö’s defense: he cannot help but note that ethical boards across the country are spangled with his former doctoral students, who, he claims, do their best to dress up their utilitarianism enough to get away with it, while following it religiously in practice.<sup><a href="#footnote_2_2556" id="identifier_2_2556" title="Ibid.">3</a></sup></p>
<p>With all due respect to Tännsjö, if the utilitarianism is meant to be covert, his students are the least subtle players of hide-and-seek in the history of philosophy. Only a cursory glance at the ethical reports drawn up under the pandemic betrays an explicit utilitarianism. In a report on the Swedish approach, the Ethical Board of State laid out the ethical foundations to defend the strategy. This document follows through a rigorous utilitarian calculation, tallying up the greatest possible well-being for the greatest possible number. As the board writes in one official document: “To address the question [of which strategy should be chosen] we need to focus on the possible and relevant <em>consequences</em>.”<sup><a href="#footnote_3_2556" id="identifier_3_2556" title="The Swedish National Council on Medical Ethics, Etiska vägval i pandemin, 44.">4</a></sup> From the very outset, the question is formulated within a consequentialist ethical framework. The board goes on to list which such “relevant” consequences to be weighed against each other: they begin by noticing that one of these is the loss of lives, but are quick to dilute it with a much longer list, including social and psychological factors, proximate and remote economic factors, freedom, feelings of alienation. The cost of the state intervening to save lives, they suggest in one passage, must be weighed against the cost of the “support” for the government ebbing among the population.<sup><a href="#footnote_4_2556" id="identifier_4_2556" title="SMER, Etiska vägval i pandemin, 43-44.">5</a></sup></p>
<p>This calculation is, after all, perfectly in line with the pronouncements of the Ministry of Public Health; the strategy was repeatedly justified on the grounds that it allowed things to run smoothly: it was “sustainable” in the long run, as “effective” as possible.</p>
<p>A century after the Lutheran archbishop’s question to Hägerström, we are perhaps ready to suggest an answer. Whether or not we think a non-cognitivist and utilitarian father can be a decent father, it is certainly the case that a non-cognitivist and utilitarian state cannot be a decent state. We have yet to see any form of genuine remorse over the shedding of lives from those in positions of power. We may have a long wait ahead. After all, there can be no remorse for something one believes is entirely justified, even mandated, by an objective standard.</p>
<p>Perhaps the bottom line is that the cynicism of the Swedish strategy ought to raise as few eyebrows abroad as it does here in Sweden. In a society where the only value is utility, where vulnerable groups are expendable as long as the pay-off is high enough, where the values of human dignity and the holiness of life are regarded as metaphysical mumbo-jumbo, where gold will always trump justice, really – what else could one expect?<a href="#_ftnref1" name="_ftn1"></a></p>

<p><em>[Photo Attribution: Joakim Emanuelson, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons]</em></p>
<ol><li id="footnote_0_2556">Olle Torpman, “Moralfilosofin som ger Sverige rätt” (“The Ethical Philosophy that Supports the Swedish Strategy”), <em>Kvartal</em>.<span>[<a href="#identifier_0_2556">↩</a>]</span></li><li id="footnote_1_2556">Åke Gavfelin and Lapo Lappin, “Interview with Torbjörn Tännsjö”, Metafysiskalaboratoriet.<span>[<a href="#identifier_1_2556">↩</a>]</span></li><li id="footnote_2_2556">Ibid.<span>[<a href="#identifier_2_2556">↩</a>]</span></li><li id="footnote_3_2556">The Swedish National Council on Medical Ethics, <em>Etiska vägval i pandemin</em>, 44.<span>[<a href="#identifier_3_2556">↩</a>]</span></li><li id="footnote_4_2556">SMER, <em>Etiska…</em></li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/">https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/</a></em></p>]]>
            </description>
            <link>https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222756</guid>
            <pubDate>Mon, 22 Feb 2021 10:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ethereum Isn't Fun Anymore]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 619 (<a href="https://news.ycombinator.com/item?id=26222709">thread link</a>) | @timdaub
<br/>
February 22, 2021 | https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><strong>Ethereum isn’t fun anymore. There I said it.</strong> And although, the last
time I developed an app using it has been more than a year ago, I stand by
my word. <strong>Developing dapps on Ethereum has become annoying</strong>.  Here’s why:</p>
<p><img src="https://timdaub.github.io/assets/images/pedro.gif" alt=""></p>
<h2 id="I-used-Ethereum-before-it-was-cool">I used Ethereum before it was cool.</h2>
<p>I know; it’s such a hipster statement. But it’s true. Ethereum has stopped
being edgy. It has transitioned out of its niche to build a world computer.
Its community has become huge, and I stopped knowing most faces. Where there
was a feeling of revolution and new beginnings, now there are people in suits
talking corporate. Within just a few years, it went from <a target="_blank" rel="noopener" href="https://github.com/DaddyDeFi/DaiDaddy">DAI
daddys</a> and only <a target="_blank" rel="noopener" href="https://www.molochdao.com/">half-ironic satanist
cults</a> to lending, insurance, and trade protocols.</p>
<p>“What’s Ethereum’s killer app?” we asked ourselves not long ago.  Now we know.
It’s the world’s best publicly-accessible settlement platform for financial
transactions.  In a way, that’s exciting. The markets think so too. But for
anyone else that worked with Ethereum but outside of financial applications,
it’s somewhat of a letdown.</p>
<p><img src="https://timdaub.github.io/assets/images/homer.gif" alt=""></p>
<h2 id="How-do-you-do-fellow-Ethereans">How do you do, fellow Ethereans?</h2>
<p>I think it must have been around the time of the last big crypto bubble
when Monero enthusiasts called for “Making Monero cheap again.”</p>
<p>Monero, being the anonymous digital currency that had indeed just legit use
cases apart from the occasional rumors that entangled it in drug
trafficking, had suddenly become too expensive for everyday use. Realizing
the glaring threat of becoming too valuable, its core developers went on to
fix the problem by campaigning at CoinDesk’s yearly industry gathering
Consensus.</p>
<p>They announced the “Monero Enterprise Alliance.” An inside joke,
supposed to piss off other projects that had started to take themselves too
seriously. Being slightly confused that day myself, I now can’t recall if
the effort had ever been successful. But in any case, I can’t recommend
buying Monero. It’s useless.</p>
<h2 id="Gas-prices-are-too-damn-high">Gas prices are too damn high!</h2>
<p><img src="https://timdaub.github.io/assets/images/deepfried_high_rents.jpg" alt=""></p>
<p>There was a phase in my short career as an Ethereum developer where I looked at
Etherscan’s “<a target="_blank" rel="noopener" href="https://etherscan.io/contractsVerified">Verified Contracts</a>” page
all day long to find vulnerabilities in newly uploaded contracts. “My name’s Tim
and I’m an etherholic!”</p>
<p>It was addictive. I ended up calling a few of those contracts, failing to cause
any havoc, sadly. But it was so much fun! Back when transaction fees were still
affordable on Ethereum, building projects was great. We started up Ganache and
our favorite text editor (vim).  The only choice we had was Solidity. And off
we went.</p>
<p>Now, building Ethereum applications has become painful. <a href="https://timdaub.github.io/2020/09/08/web3/">web3 is a stupid
idea</a>. Layer 2 isn’t ready. Neither
is Eth 2.0. And there are still <a href="https://timdaub.github.io/2019/02/28/poa/">many reasons to NOT ship to a Proof of
Authority network</a>. Finally, gas
prices are too damn high!</p>
<p>How do we move on from here?</p>
<h2 id="I-need-a-hero">I need a hero.</h2>
<p><strong>I need a hero, and by that, I mean that I need a usable methodology for
building scaleable decentralized apps.</strong> Yes, you’ve heard that right. We don’t
need more “Ethereum killers” that can do 10x more tx/s than Ethereum.  Those
are useless.</p>
<p>Instead, we need an approach for the average Joe developer to create their idea
within the Ethereum ecosystem without the need for hardcore unproven
technologies. I know, you Vitalik will say: “Oh, it’s not a problem, we can has
‘<a target="_blank" rel="noopener" href="https://vitalik.ca/general/2020/03/21/garbled.html">Garbled Circuits</a>’ and
zkrollups.” But I’m telling you that no sane Joe will touch that shit without a
serious cryptographic specialist by their side.</p>
<p>We want what we stayed for initially: Good ol smart contracts. But right now,
they’re too damn expensive to innovate.</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222709</guid>
            <pubDate>Mon, 22 Feb 2021 10:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I sold my Raspberry Pi 4 for a Rock Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222704">thread link</a>) | @voxadam
<br/>
February 22, 2021 | https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/ | <a href="https://web.archive.org/web/*/https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://ikarus.sg/content/images/size/w300/2021/02/rpi-rockpi.png 300w,
                            https://ikarus.sg/content/images/size/w600/2021/02/rpi-rockpi.png 600w,
                            https://ikarus.sg/content/images/size/w1000/2021/02/rpi-rockpi.png 1000w,
                            https://ikarus.sg/content/images/size/w2000/2021/02/rpi-rockpi.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://ikarus.sg/content/images/size/w2000/2021/02/rpi-rockpi.png" alt="Why I sold my Raspberry Pi 4 for a Rock Pi 4">
            </figure>

            <section>
                <div>
                    <p>I sold my Raspberry Pi 4B 4GB recently and replaced it with a Rock Pi 4A. I had owned it for about 6 months before finally letting it go at a significant loss and honestly, that decision was not as hard as I thought. On this piece, I document my anticipations, disappointments, and epiphanies over the course of 6 months owning the Raspberry Pi 4B.</p><blockquote>Disclaimer: I'm not affiliated with nor sponsored by Radxa/Allnet, the manufacturers of Rock Pi. I'm writing this piece purely to share my experiences with both the Raspberry Pi 4B 4GB and the Rock Pi 4A 4GB.</blockquote><h2 id="i-need-more-memory-">I. Need. More. Memory.</h2><p>It was February 2020, I was running my self-hosted apps all on the <a href="https://ikarus.sg/how-i-built-kraken/">Kraken</a> cluster then. At that point in time I wanted to run a metric-monitoring stack (<em>Prometheus</em> + <em>Grafana</em>) for the cluster but after reviewing the memory requirements, I quickly realized that not even all the memory on a single Raspberry Pi 3B node was enough (although I'm cognizant that 1GB isn't much in the grander scheme of things). </p><p>Browsing around, the most obvious choice was the next model in the Raspberry Pi line that was just released a few weeks earlier then, the Raspberry Pi 4B 4GB.</p><h2 id="the-shiny-raspberry-pi-4b">The Shiny Raspberry Pi 4B</h2><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Aspect</th>
<th>Raspberry Pi 3B</th>
<th>Raspberry Pi 4B 4GB</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>Broadcom BCM2837 (Quad core)</td>
<td>Broadcom BCM2711 (Quad core)</td>
</tr>
<tr>
<td>Cores</td>
<td>4x Cortex-A53 1.2GHz</td>
<td>4x Cortex-A72 @ 1.5GHz</td>
</tr>
<tr>
<td>Memory</td>
<td>1GB LPDDR2</td>
<td>4GB LPDDR4-3200</td>
</tr>
<tr>
<td>Ethernet</td>
<td>100Mbps</td>
<td>1000Mbps</td>
</tr>
<tr>
<td>Storage</td>
<td>Micro-SD Card</td>
<td>Micro-SD Card</td>
</tr>
<tr>
<td>USB</td>
<td>4x USB2.0</td>
<td>- 2x USB 3.0<br>- 2x USB 2.0</td>
</tr>
<tr>
<td>Power</td>
<td>5V 2A Micro-USB</td>
<td>5V via USB-C connector (&gt;=3A)</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>There were quite a few aspects about the Raspberry Pi 4B 4GB that got me excited: 4GB Memory, Gigabit Ethernet, yada yada. But what I anticipated the most was the long-overdue elimination of the <u>painful</u> <a href="https://ikarus.sg/how-i-built-kraken/#some-caveats">USB 2.0 bus bottleneck</a> that plagued all Raspberry Pi models from Zero to 3B+. </p><p>In the Raspberry Pi 4, the ethernet is built directly into the SoC and no longer shares a bottlenecked bus with USB devices. This means we can unleash the full potential of the gigabit ethernet port without worrying about performance degradation of the micro-SD card or external drives, and vice-versa. </p><p>On top of all those changes, the Raspberry Pi 4B doubled the micro-SD card slot bandwidth from 20MB/s to 40MB/s. While this is still not cutting-edge performance, it's still a significant and welcome improvement, especially for tasks that have high demands for sequential I/O.</p><blockquote>Delay no more!</blockquote><p>With those specs, I made a trip down to Amicus @ Sim Lim Tower to snag one from the shelves.</p><h2 id="what-belies-the-shine">What Belies the Shine</h2><p>At the point of purchase and over 6 months of usage, I've uncovered many issues that really made me second-guess my purchase. </p><p>These are the pain points I've identified, each of which I will cover in detail in dedicated sections:</p><ol><li>Power concerns</li><li>Heat dissipation issues</li><li>No official cooling solutions</li><li>32-bit Operating System</li><li>Operating Systems Available and Compatibility with k8s</li><li>Storage performance</li><li>Storage longevity</li></ol><h3 id="power-concerns">Power Concerns</h3><p>Interestingly, a red flag had already surfaced prior to purchase, but I conveniently ignored it in favor of my excitement; the power supply. There were many complaints online that <a href="https://hackaday.com/2019/07/16/exploring-the-raspberry-pi-4-usb-c-issue-in-depth/">electronically-marked USB-C cables did not work</a> due to a flaw with the Raspberry Pi 4 hardware design that caused it to detect the charging cable as an audio accessory. </p><figure><img src="https://ikarus.sg/content/images/2021/02/image.png" alt=""><figcaption>Electronic market in USB-C cables (<a href="https://www.elinfor.com/market/how-to-identify-the-usb-c-cables-with-or-without-e-maker-m-27">Source</a>)</figcaption></figure><p>For context, <em>standards-compliant</em> USB-C cables that support <em>more than 3.0A </em>(Thanks <a href="https://www.reddit.com/user/ferrybig/">ferrybig</a> from <a href="https://www.reddit.com/r/selfhosted/comments/loykcd/why_i_sold_my_raspberry_pi_4_for_a_rock_pi_4_at/">/r/selfhosted</a> for correcting me with the <a href="https://www.usb.org/sites/default/files/USB%20Type-C%20Spec%20R2.0%20-%20August%202019.pdf#%5B%7B%22num%22%3A82%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C87%2C421%2C0%5D">USB C spec</a>) current have a tiny microchip embedded within it that enables smart features such as voltage and USB protocol negotiation which provides information on supported voltages and data transfer rates to the other end. The microchip also doubles as protection for your device from over-voltage and other electrical risks. We have seen from the sacrifices of Benson Leung, full-time Google engineer and part-time USB-C vigilante, going around on Amazon testing USB-C cables and <a href="https://www.slashgear.com/beware-usb-c-cables-that-could-seriously-fry-your-device-03425324/">frying his Chromebook Pixel in the process</a>, what kind of damage non-compliant cables can potentially do to your devices.</p><figure><a href="https://www.engadget.com/2016-02-03-benson-leung-chromebook-pixel-usb-type-c-test.html"><div><p>Google engineer fries Pixel testing USB Type-C cable | Engadget</p><p>You might not remember Benson Leung, the Google engineer that tasked himself with examining USB Type-C cables. He’s been diligently doing so for months, but he’s calling his tests to a halt after one went horribly wrong. Leung bought a USB 3.1 Type-C SuperSpeed cable (it’s since been removed) from S…</p><p><img src="https://s.yimg.com/kw/assets/favicon-160x160.png"></p></div><p><img src="https://s.yimg.com/uu/api/res/1.2/.1w_EgFevrhtuAoC8AytLw--~B/aD05NDI7dz0xNDAwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/uu/api/res/1.2/0I.gp7wz7N1ofOUfCVBLwQ--~B/aD05NDI7dz0xNDAwO2FwcGlkPXl0YWNoeW9u/https://o.aolcdn.com/hss/storage/midas/9bdc1aa766dc7bc1bc964f8a9f843dc8/203351772/chromebookpixelport.jpg.cf.jpg"></p></a></figure><p>I find it rather ridiculous that in order to power the Raspberry Pi 4B, one had to source for cables that did not have the embedded microchip and hence potentially unsafe.</p><p>Other than that issue, I also had concerns that my existing power supply, the <em>Anker PowerPort 10</em>, would not be sufficient for the Raspberry Pi 4, given that it only supports up to <em>5V 2.0A</em>. The official page states that the Raspberry Pi 4B needs <em>at least 5V 3.0A</em> to work, which means I'd need to get something like a <em>Qualcomm QuickCharge 3.0</em> brick specifically for it. </p><p>In the end, out of an abundance of caution I bought the <em>extortionately priced</em> official Raspberry Pi 4B power supply at <strong>S$18 (US$13.40)</strong>. To put things into perspective, that power brick costed<strong> 20.93% of a Raspberry Pi 4B 4GB</strong> priced at <strong>S$84.99 (US$64.03)</strong>!</p><h3 id="heat-dissipation-issues">Heat Dissipation Issues</h3><p>Heat was a real problem with the Raspberry Pi 4B. With an ambient temperature in Singapore at around <em>31°C</em>, the Raspberry Pi &nbsp;4B idles at around <strong>52°C</strong>, and quickly hits a toasty <strong>80°C </strong>on medium load, after which it thermal-throttles itself to oblivion. </p><figure><pre><code>$ sudo vcgencmd measure_temp
temp=81.2'C</code></pre><figcaption>Command to measure temperature on Raspberry Pi OS</figcaption></figure><p>I realized this when I tried running hardware-accelerated transcode of videos from HEVC to H.264 in <a href="https://jellyfin.org/">Jellyfin</a>. The first few seconds would render perfect in real-time, beyond that the CPU/GPU throttles and the video renders at <strong>0.25x</strong> speed. At this speed, I'd have to wait 4 seconds just to watch 1 second. </p><p>To demonstrate what <em>0.25x</em> means, here's an example: to render a full <em>40-minute</em> episode, I'd have to wait for a whole <strong>2h 40m</strong> for it to render. This pretty much <em>renders</em> the video unwatchable on the Raspberry Pi 4 (pun intended). Shockingly, this performance actually comparable to that of software transcode on the Raspberry Pi 3B without any cooling.</p><p>Besides video transcoding, I've tried applications that do not generate as much load, such as running <em>PostgreSQL</em> and <em>MariaDB</em>. I thought running databases on the Raspberry Pi 4 was the obvious choice since it has double the I/O bandwidth of a Raspberry Pi 3. However, even that pushed the Raspberry Pi 4 to its thermal throttling limits, and though I did not run precise database performance benchmarks, I did measure an average of <em>1.2s longer load times</em> on my Nextcloud home page, over 10 refreshes with browser caching disabled, during which the CPU utilization on the Raspberry Pi 4 would peak.</p><p>If this trend holds true, it means I've spent more money to purchase a device with poorer performance than my existing Raspberry Pi 3Bs (at least without investment on cooling solutions) 🤦‍♂️.</p><h3 id="no-official-cooling-solutions">No Official Cooling Solutions</h3><p>I searched far and wide for a solution to the heat problem. I've came across solutions on both ends of the price spectrum.</p><figure><div><div><p><img src="https://ikarus.sg/content/images/2021/02/Raspberry_Pi_4_Heat_Sinks_1_Copper_2_Aluminium_-_BC-01_1200x-1.jpg" width="1200" height="1200" alt=""></p><p><img src="https://ikarus.sg/content/images/2021/02/Raspberry_Pi_4_Heat_Sinks_1_Copper_2_Aluminium_-_BC-88_1200x.jpg" width="1200" height="1200" alt=""></p></div></div><figcaption>Affordable generic heatsinks (<a href="https://www.makersupplies.sg/products/raspberry-pi-4-heat-sinks-1-copper-2-aluminium">Source</a>)</figcaption></figure><p>The cheapest ones are those generic, colored heatsinks that cost around S$6 (US$4.61) for a set.</p><figure><div><div><p><img src="https://ikarus.sg/content/images/2021/02/ar_one_pi4_01.jpg" width="1000" height="1000" alt=""></p><p><img src="https://ikarus.sg/content/images/2021/02/ar_one_pi4_03.jpg" width="1000" height="1000" alt=""></p></div></div><figcaption>ArgonOne heatsink-case for the Raspberry Pi 4 (<a href="https://www.argon40.com/catalog/product/view/id/52/s/argon-one-raspberry-pi-4-case/">Source</a>)</figcaption></figure><p>Unsurprisingly, the pricier cases are from reputable Raspberry Pi accessory manufacturers. The most pricey one was the <a href="https://www.argon40.com/catalog/product/view/id/52/s/argon-one-raspberry-pi-4-case/"><em>ArgonOne</em> from ArgonForty</a> at S$32.50 (US$25), an intricately designed heatsink-case combo with a software-controlled PWM-fan for active-cooling. </p><p>Personally, I'm very sensitive to background noise and am easily distracted by it so I was looking for passive-cooling solutions. However, upon doing a cursory search, there were quite a number of users out there facing issues with passive cooling. </p><figure><a href="https://downey.io/blog/raspberry-pi-4-heatsinks-and-fans/#important-update"><div><p>The Great Raspberry Pi Cooling Bake-Off: Comparing Passive Heatsinks and Active Cooling for the Raspberry Pi 4|downey.io</p><p>Why is my Raspberry Pi 4 running so hot? You may know you need something to cool it down, but what? In this post we compare the performance of various Raspberry Pi coolers. All the way from the humble heatsink to a massive cooling tower complete with RGB fans.</p><p><span>Tim Downey</span></p></div><p><img src="https://images.downey.io/raspi/raspi-cooler-tower.jpg"></p></a></figure><p>Tim Downey has written a <a href="https://downey.io/blog/raspberry-pi-4-heatsinks-and-fans/#important-update">fantastic piece</a> on different cooling solutions he tested for the Raspberry Pi 4. In particular, in one of his tests, he had the <em>ArgonNEO</em> which was essentially an <em>ArgonOne</em> without a fan. On running CPU-intensive tasks, his case reached temperatures above <strong>80°C</strong>! The <em>ArgonNEO</em> is not a low-quality case by any standards, it's a pretty chunky aluminum case that can hold and dissipate quite a lot of heat! These temperatures on the surfaces of the case are not just potentially damaging for the furniture but also dangerous for kids and pets. It seems like cooling has become a matter of safety as well, and not just performance.</p><figure><div><div><p><img src="https://ikarus.sg/content/images/2021/02/dual-fan-heatsink-raspberry-pi4-A-600x600-1.jpg" width="600" height="600" alt=""></p><p><img src="https://ikarus.sg/content/images/2021/02/dual-fan-heatsink-raspberry-pi4-B-600x600.jpg" width="600" height="600" alt=""></p></div></div><figcaption>Generic dual-fan heatsink from Shopee (Source no longer exists, others available)</figcaption></figure><p>I went for an active cooling solution in the end after having doubts on the adequacy of passive cooling and bought a generic cheap dual-fan heatsink off <a href="https://shopee.sg/Cooler-Internal-Dual-Fan-With-Heat-Sink-Easy-Install-Ultimate-Durable-Accessories-Lightweight-For-Raspberry-Pi-3B-4B-i.38963929.3204455009">Shopee</a> at <strong>S$6.09 (US$4.68)</strong>.</p><p>At that point, I was rather disappointed that the Raspberry Pi 4 is <em>practically unusable out-of-the-box</em> for anything more than lightweight applications and simple shell scripts even though it has so much performance headroom. With that kind of performance impact, I had hoped that the Raspberry Pi foundation at least provided some semblance of an official add-on cooling solution instead of forcing the user to go out of his/her way to get it to work as it was designed to.</p><h3 id="32-bit-operating-system">32-bit Operating System</h3><p>The official/recommended operating system for the Raspberry Pi 4B is <em>Raspbian</em> (now known as <em>Raspberry Pi OS</em>). It's a <em>32-bit</em> Debian-based operating system, and the problem lies in this number of bits.</p><p>The Raspberry Pi 3B …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/">https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/</a></em></p>]]>
            </description>
            <link>https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222704</guid>
            <pubDate>Mon, 22 Feb 2021 10:04:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F2PY: Calling Fortran Routines from Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222664">thread link</a>) | @optimalsolver
<br/>
February 22, 2021 | https://www.numfys.net/howto/F2PY/ | <a href="https://web.archive.org/web/*/https://www.numfys.net/howto/F2PY/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
        <p>Last edited: September 5th, 2019</p>
<hr>
<p>This tutorial gives a quick introduction to the F2PY package and how to use it as a command line tool. F2PY is a part of NumPy (<code>numpy.f2py</code>) and can also be used as a Python module. Check out <a href="https://docs.scipy.org/doc/numpy/f2py/">F2PY's user guide</a> for a more complete reference and installation procedures. 
From the documentation:</p>
<p><em>The purpose of the F2PY –Fortran to Python interface generator– is to provide a connection between Python and Fortran languages. F2PY is a part of <a href="https://numpy.org/">NumPy</a> (<code>numpy.f2py</code>) and also available as a standalone command line tool f2py when numpy is installed that facilitates creating/building Python C/API extension modules that make it possible</em></p>
<ul>
<li>
<p><em>to call Fortran 77/90/95 external subroutines and Fortran 90/95 module subroutines as well as C functions;</em></p>
</li>
<li>
<p><em>to access Fortran 77 COMMON blocks and Fortran 90/95 module data, including allocatable arrays.</em></p>
</li>
</ul>
<h2 id="how-does-f2py-work">How does F2PY work?</h2>
<p>F2PY works by creating an extension module that can be imported in Python using the <code>import</code> keyword. The module contains automatically generated wrapper functions that can be called from Python, acting as an interface between Python and the compiled Fortran routines.
First, F2PY reads the Fortran source file and creates a so-called signature file that contains all the necessary information about the Fortran routines needed to make the wrapper functions.
The signature file is then read and the source code of the extension module is generated in C, using the Python C API. In the last step, F2PY compiles all the source code and builds the extension module containing the wrappers and the compiled Fortran routines.</p>
<hr>
<h2 id="why-should-you-use-f2py">Why should you use F2PY?</h2>
<p>The choice of programming language can be challenging at times, especially when it comes to finding a balance between computational efficiency and implementation time and effort. While scripting languages like MATLAB and Python may provide intuitive code which is fast to implement, compiled languages like C/C++ and Fortran yield superior computational speed. By wrapping a compiled code for Python, we can get the best of both worlds!  Our notebook <a href="https://nbviewer.jupyter.org/urls/www.numfys.net/media/notebooks/fortran_to_python.ipynb">Calling Fortran(95) routines from a Python Script</a> shows an example of the usage and the gain in computational time.</p>
<h2 id="when-should-you-use-f2py">When should you use F2PY?</h2>
<p>This is perhaps the ultimate question, and unfortunately, there is no definite answer. A good rule of
thumb however, is to use F2PY, or compiled languages in general, when performing multiple operations/-
computations within (nested) loops. Possibly, the most typical example would be operations on elements
in multidimensional matrices. That is, linear algebra in general. Other good examples could be programs
calculating integrals or conducting Monte Carlo simulations.
At this point, you might wonder if anyone has already made F2PY-modules fitting your particular
problem. The answer is most likely yes! Most of the functions and routines found in NumPy and SciPy
are actually compiled Fortran (or C/C++) routines which provide highly efficient and fast solvers for
multiple problems. We thus advice you to always check if one of these two packages/libraries already
provide a routine in which may be suitable for your problem. If not, you should first implement your
solver in a pure Python script to investigate whether or not computational efficiency really is an issue. If
it is, then F2PY may possibly provide the best solution strategy for your problem.</p>
<h2 id="getting-started">Getting started</h2>
<p>We will be considering a simple example in which the <a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">sieve of Eratosthenes</a> algorithm is used to compute prime numbers. The Fortran code is saved in <code>primes.f95</code>. <strong>Note</strong> that the code only includes <code>subroutines</code> and that the variables are defined with a new keyword <code>intent</code>. The latter is explained in the next section.</p>
<div><pre><span></span><span>subroutine </span><span>sieve</span><span>(</span><span>is_prime</span><span>,</span> <span>n_max</span><span>)</span>
<span>! =====================================================</span>
<span>! Uses the sieve of Eratosthenes to compute a logical</span>
<span>! array of size n_max, where .true. in element i</span>
<span>! indicates that i is a prime.</span>
<span>! =====================================================</span>
    <span>integer</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>   <span>::</span> <span>n_max</span>
    <span>logical</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span>  <span>::</span> <span>is_prime</span><span>(</span><span>n_max</span><span>)</span>
    <span>integer</span> <span>::</span> <span>i</span>
    <span>is_prime</span> <span>=</span> <span>.</span><span>true</span><span>.</span>
    <span>is_prime</span><span>(</span><span>1</span><span>)</span> <span>=</span> <span>.</span><span>false</span><span>.</span>
    <span>do </span><span>i</span> <span>=</span> <span>2</span><span>,</span> <span>int</span><span>(</span><span>sqrt</span><span>(</span><span>real</span><span>(</span><span>n_max</span><span>)))</span>
        <span>if</span> <span>(</span><span>is_prime</span> <span>(</span><span>i</span><span>))</span> <span>is_prime</span> <span>(</span><span>i</span> <span>*</span> <span>i</span> <span>:</span> <span>n_max</span> <span>:</span> <span>i</span><span>)</span> <span>=</span> <span>.</span><span>false</span><span>.</span>
    <span>end do</span>
<span>    return</span>
<span>end subroutine</span>

<span>subroutine </span><span>logical_to_integer</span><span>(</span><span>prime_numbers</span><span>,</span> <span>is_prime</span><span>,</span> <span>num_primes</span><span>,</span> <span>n</span><span>)</span>
<span>! =====================================================</span>
<span>! Translates the logical array from sieve to an array</span>
<span>! of size num_primes of prime numbers.</span>
<span>! =====================================================</span>
    <span>integer</span>                 <span>::</span> <span>i</span><span>,</span> <span>j</span><span>=</span><span>0</span>
    <span>integer</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>     <span>::</span> <span>n</span>
    <span>logical</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>     <span>::</span> <span>is_prime</span><span>(</span><span>n</span><span>)</span>
    <span>integer</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>     <span>::</span> <span>num_primes</span>
    <span>integer</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span>    <span>::</span> <span>prime_numbers</span><span>(</span><span>num_primes</span><span>)</span>
    <span>do </span><span>i</span> <span>=</span> <span>1</span><span>,</span> <span>size</span><span>(</span><span>is_prime</span><span>)</span>
        <span>if</span> <span>(</span><span>is_prime</span><span>(</span><span>i</span><span>))</span> <span>then</span>
<span>            </span><span>j</span> <span>=</span> <span>j</span> <span>+</span> <span>1</span>
            <span>prime_numbers</span><span>(</span><span>j</span><span>)</span> <span>=</span> <span>i</span>
        <span>end if</span>
<span>    end do</span>
<span>end subroutine</span>
</pre></div>


<p>The simplest way to wrap this subroutine to python is to run </p>
<div><pre><span></span>f2py -c primes.f95 -m primes
</pre></div>


<p>Now that F2PY is a part of Numpy, an equivalent way to wrap this subroutine is to run</p>
<div><pre><span></span>python -m numpy.f2py -c primes.f95 -m primes
</pre></div>


<p><strong>Note</strong> that you might need to run <code>f2py3</code> to use Python 3! This command builds (<code>-c</code> flag) an extension module <code>primes.so</code> to the current directory. If the <code>-m</code> flag is excluded, the extension module will be named <code>untitled.so</code>. </p>
<p>We can now access these subroutines from Python:</p>
<div><pre><span></span><span>&gt;&gt;&gt; </span><span>import</span> <span>primes</span>
<span>&gt;&gt;&gt; </span><span>print</span><span>(</span><span>primes</span><span>.</span><span>__doc__</span><span>)</span>
<span>This module 'primes' is auto-generated with f2py (version:2).</span>
<span>Functions:</span>
<span>  is_prime = sieve(n_max)</span>
<span>  prime_numbers = logical_to_integer(is_prime,num_primes,n=len(is_prime))</span>
<span>.</span>
<span>&gt;&gt;&gt; </span><span>print</span><span>(</span><span>primes</span><span>.</span><span>logical_to_integer</span><span>.</span><span>__doc__</span><span>)</span>
<span>prime_numbers = logical_to_integer(is_prime,num_primes,[n])</span>

<span>Wrapper for ``logical_to_integer``.</span>

<span>Parameters</span>
<span>----------</span>
<span>is_prime : input rank-1 array('i') with bounds (n)</span>
<span>num_primes : input int</span>

<span>Other Parameters</span>
<span>----------------</span>
<span>n : input int, optional</span>
<span>    Default: len(is_prime)</span>

<span>Returns</span>
<span>-------</span>
<span>prime_numbers : rank-1 array('i') with bounds (num_primes)</span>

<span>&gt;&gt;&gt; </span><span>sieve_array</span> <span>=</span> <span>primes</span><span>.</span><span>sieve</span><span>(</span><span>100</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>prime_numbers</span> <span>=</span> <span>primes</span><span>.</span><span>logical_to_integer</span><span>(</span><span>sieve_array</span><span>,</span> <span>sum</span><span>(</span><span>sieve_array</span><span>))</span>
<span>&gt;&gt;&gt; </span><span>print</span><span>(</span><span>prime_numbers</span><span>)</span>
<span>[ 2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97]</span>
</pre></div>


<p>Note that F2PY automatically found that the last argument (<code>n</code>) of the <code>logical_to_integer</code> subroutine was the dimension of the input array <code>is_prime</code>. F2PY concluded that <code>n</code> can be optional, with the default value <code>len(is_prime)</code>! One can use different values for the optional argument <code>n</code>. However, an exception is raised when it is incompatible with <code>is_prime</code>.</p>
<h2 id="specifying-input-and-output-arguments">Specifying input and output arguments</h2>
<p>In the example above, the different arguments of the subroutine were defined as input or output using the <code>intent()</code> attribute. The three most useful are:</p>
<ul>
<li><code>intent(in)</code> specifies that the variable is an input argument. It cannot be changed within the subroutine.</li>
<li><code>intent(out)</code> specifies that the variable is an output argument. The values stored in the variable before the routine is called is irrelevant!</li>
<li><code>intent(inout)</code> specifies that the variable is an input argument and can be changed in the subroutine.</li>
</ul>
<p>If <code>intent</code> is excluded, the arguments become input-only arguments (same as using <code>intent(inout)</code>) by default. It is considered good practice to specify all arguments using the <code>intent</code> attribute. It is also preferred to use <code>intent(out)</code> (and not <code>intent(inout)</code>) to have a returned value.</p>
<p>The intent and optionality of the arguments can also be edited manually in the signature file <code>primes.pyf</code> generated by running</p>
<div><pre><span></span>f2py primes.f95 -m primes -h primes.pyf
</pre></div>


<p>The final module is built from the signature file by running</p>
<div><pre><span></span>f2py -c primes.pyf primes.f95
</pre></div>


<p>The attributes can also be specified as comments, which is done in our <a href="https://nbviewer.jupyter.org/urls/www.numfys.net/media/notebooks/fortran_to_python.ipynb">Calling Fortran(95) routines from a Python Script</a> notebook.</p>
<p>Check out the <a href="https://docs.scipy.org/doc/numpy/f2py/signature-file.html">documentation for the signature file</a> for more options.</p>
<h2 id="pitfalls">Pitfalls</h2>
<ul>
<li>F2PY is compatible with the allocatable arrays in Fortran 90 and above. However, all output arguments must be given dimensions explicitly! In other words, output arguments cannot be of assumed size or allocatable.
For example:</li>
</ul>
<div><pre><span></span><span>integer</span><span>,</span> <span>allocatable</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span> <span>::</span> <span>array1</span><span>(:)</span>  <span>! Not valid</span>
<span>integer</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span>              <span>::</span> <span>array2</span><span>(:)</span>  <span>! Not valid</span>
<span>integer</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span>              <span>::</span> <span>array3</span><span>(</span><span>10</span><span>)</span> <span>! Valid</span>
<span>integer</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>               <span>::</span> <span>array4</span><span>(:)</span>  <span>! Valid</span>
</pre></div>


<ul>
<li>Derived types are not supported.</li>
<li>It should be noted that it, in general, is easier to run F2PY from a UNIX based computer system. There is a lot of troubleshooting on Windows available online, but from our experience getting F2PY to work as intended was way easier using Linux or MacOS.</li>
</ul>
<h2 id="custom-docstrings">Custom docstrings</h2>
<p>As we have seen, F2PY creates a default documentation for the module and functions which can be reached using e.g. <code>help()</code> or <code>.__doc__</code>. As far as we know, there are no options in F2PY in which we can modify this documentation. However, it can be changed upon import (<code>&lt;module&gt;.__doc__=&lt;string&gt;</code>)
or one create a python function with its own (custom) docstring which calls the module. Many of <a href="https://www.scipy.org/">SciPy's</a> modules are built using F2PY, and their docstring are created using the latter method.</p>
    </div></div>]]>
            </description>
            <link>https://www.numfys.net/howto/F2PY/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222664</guid>
            <pubDate>Mon, 22 Feb 2021 09:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make a Production Checklist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222608">thread link</a>) | @vinnyglennon
<br/>
February 22, 2021 | Https://www.blameless.com/blog/4-things-you-need-to-know-about-writing-better-production-readiness-checklists | <a href="https://web.archive.org/web/*/Https://www.blameless.com/blog/4-things-you-need-to-know-about-writing-better-production-readiness-checklists">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When we think of reliability tools, we may overlook the humble checklist. While tools like <a href="https://www.blameless.com/blog/service-level-objectives-slos-lessons-learned">SLOs</a> represent the cutting edge of SRE, checklists have been recommended in many industries such as <a href="https://dash.harvard.edu/handle/1/38846186">surgery</a> and <a href="https://www.flightsafetyaustralia.com/2018/11/one-thing-at-a-time-a-brief-history-of-the-checklist/">aviation</a> for almost a century. But checklists owe this long and widespread adoption to their usefulness.<br></p><p>Checklists can also help limit errors when deploying code to production. In this blog post, we’ll cover:</p><ul role="list"><li>How to make a production checklist</li><li>Why production checklists are helpful</li><li>Keeping your checklist up to date</li><li>How Blameless can help integrate your checklists</li></ul><h2>How to make a production checklist</h2><p>Production checklists should be holistic. They should cover everything from launch logistics to contingency plans for failure. Let’s break down what you’ll need for a thorough checklist.</p><ol role="list"><li><strong>Determine the service level of what you’re launching</strong></li></ol><p>To determine <em>how thorough</em> your checklist should be, consider what level of reliability your customers need.. You may be tempted to be as comprehensive as possible with every checklist, but that costs time and may be unnecessary. At Mercari, <a href="https://github.com/mercari/production-readiness-checklist/blob/master/docs/references/production-readiness-level.md">the service level is determined based on the service’s SLO</a>. Services that are critical to business success are scrutinized more than niche services.</p><ol start="2" role="list"><li><strong>Map out all the checklist areas</strong></li></ol><p>List all major components of your service. These components may be under the ownership of various teams. For example, you’ll likely need to consult server management teams, testing teams, and many others. It’s important to know as soon as possible whom you’ll need to consult. Some areas to consider include:<br></p><ul role="list"><li><strong>Server-side:</strong> What machines will this service run on? If you’re cloud-based, will your plan cover the new service’s load?</li><li><strong>Client-side:</strong> Is your service usable for all potential clients?</li><li><strong>Monitoring:</strong> Do you have ways of collecting data from your new service?&nbsp;</li><li><strong>Growth:</strong> Do you have a roadmap for how you will maintain or improve the service going forward? What if usage increases? What if you need to expand functionality?</li><li><strong>Dependencies:</strong> What other in-house and third party services does your service depend on? Will they integrate smoothly?</li><li><strong>Testing:</strong> Has the new service been tested in an environment mirroring production?</li><li><strong>Security: </strong>Will your new service pass your security audits?</li><li><strong>Reliability: </strong>What level of reliability will your users expect? Do you have a plan for when you are unable to meet these expectations?</li><li><strong>Incident response:</strong> What will you do if an incident causes service interruption or degradation? Do you have runbooks to cover these incidents?</li><li><strong>Legal:</strong> Do you have an SLA that guarantees availability? Does this service deal with personal information that must be kept secure?</li><li><strong>Logistics:</strong> What is the launch schedule? What resources will you need?<br></li></ul><p>For more examples of areas to consider, check out Google’s <a href="https://sre.google/sre-book/launch-checklist/">Launch Coordination Checklist</a>, <a href="https://gruntwork.io/devops-checklist/">gruntwork.io’s AWS checklist</a>, or <a href="https://github.com/mercari/production-readiness-checklist/blob/master/docs/references/production-readiness-checklist.md">Mercari’s checklists</a>.</p><ol start="3" role="list"><li><strong>Prepare the checklist items</strong></li></ol><p>Each of these areas contains many issues, and requires data to answer. Your checklist should ask for each piece of data. Here’s an example of how certain sections could be broken down:<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5ec0224560bd6a6ef89a51ae/60258a189045532048064bce_GXLhui7pRZ_R7zLCqUunWS6CCU7PBwExUev_Aayj1ioz3UDZtZHnvyMOZNAsbRp1eugg8OC6Wjyl38autUOS0tlRm_wJkM3HjmEehUg3V1jnHf5gmUg-1ZX0DM0Z2G5dNlksxcM.png" alt="example areas, issues, and corresponding checklist items for a production readiness checklist."></p></figure><p>You may also want to include information on who to consult to check off each item, and the timeframe for being able to check it. Build your checklist and check items off as development progresses. Double check to ensure that items are ready to go. Right before launch, do a final check through the whole list, just in case.</p><h3>Keeping the checklist in check</h3><p>As you develop, you’ll likely find more areas you want to vet prior to launch. To keep your checklist from becoming too long, you’ll need a system to make sure new additions are helpful. <a href="https://sre.google/sre-book/reliable-product-launches/">At Google</a>, teams have two criteria for adding an item to the checklist:<br></p><ul role="list"><li>“Every question’s importance must be substantiated, ideally by a previous launch disaster.”</li><li>“Every instruction must be concrete, practical, and reasonable for developers to accomplish.”<br></li></ul><p>You can determine criteria based on the service level you’ve assigned. It’s better to have an unnecessary item than to lack one you need. It’s okay to start with a big checklist, then remove items after each launch that proved to not be useful.</p><h2>Why are production checklists helpful?</h2><p>Production checklists can seemingly add overhead to engineers’ jobs. However, the upfront work can save teams from future problems and ensure a successful launch. Production checklists help:<br></p><ul role="list"><li>Remove the cognitive toil of having to remember everything</li><li>Identify possible problems ahead of time</li><li>Prepare resources ahead of time</li><li>Motivate development to complete necessary items</li><li>Prioritize key requirements vs unnecessary additions</li><li>Ensure contingency planning, improving reliability</li><li>Keep everyone in the loop throughout development as a centralized progress meter</li></ul><h2>How to keep your production checklist up to date</h2><p>You will need to review and revise your checklists periodically to keep them useful. Be sure to revisit them at these times:<br></p><p><strong>When development on a new service starts. </strong>When mapping out a new service, consider which production checklist to use when it launches. Based on the type of service and service level, find the closest checklist you have. Review it to make sure it follows the processes and architecture you currently use. Add any service-specific requirements as you develop.<br></p><p><strong>After a launch.</strong> Take a look at the production checklist after you launch the new service. Were there any problems with the launch? Could they have been checked for beforehand? Look for checklist items that were misunderstood and filled out incorrectly. Revise these items to ensure the checklist lines up with the reality of development.<br></p><p><strong>After an incident. </strong>If an incident impacts the new service, see if any of the contributing factors could have been addressed with the checklist If so, try to capture those items on future checklists. This task can be incorporated into your <a href="https://www.blameless.com/blog/incident-retrospective-postmortem-template">incident retrospectives</a>.<br></p><p><strong>As part of regular review cycles.</strong> Set a schedule to review tools like runbooks and production checklists. Make sure to invite all team members who will be required to use these runbooks or checklists. Each of these people can provide insight on what to improve moving forward.</p><h2>How Blameless can help integrate checklists</h2><p>To get the most from your checklists, you need to integrate them into your workflows. Here’s how Blameless can help:<br></p><ul role="list"><li><a href="https://www.blameless.com/product/incident-resolution">Blameless Incident Resolution</a> allows teams to treat each deploy like an incident and assign roles and checklists.</li><li><a href="https://www.blameless.com/product/incident-retrospectives">Blameless Incident Retrospectives</a> provide a hub of learning for future checklist development.</li><li><a href="https://www.blameless.com/blog/introducing-blameless-runbook-documentation">Blameless Runbook Documentation</a> helps richly document processes, allowing you to dive into the information behind each checklist item.<br></li></ul><p>To see more of how Blameless helps you be your most reliable, check out a <a href="https://www.blameless.com/schedule-demo">demo</a>.<br></p><p>If you enjoyed this blog post, check out these resources:</p><ul role="list"><li><a href="https://www.blameless.com/blog/how-mercari-scales-vision-culture-reliability">How Mercari Scales Vision, Culture, &amp; Reliability</a></li><li><a href="https://www.blameless.com/blog/use-blameless-power-remote-work">How We Use Blameless to Power Remote Deploys</a></li><li><a href="https://www.blameless.com/resources/webinar-how-slos-enable-fast-reliable-application-delivery">Webinar: How SLOs Enable Fast, Reliable Application Delivery</a></li></ul></div></div>]]>
            </description>
            <link>Https://www.blameless.com/blog/4-things-you-need-to-know-about-writing-better-production-readiness-checklists</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222608</guid>
            <pubDate>Mon, 22 Feb 2021 09:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoid the Most Dangerous Word in Software Development]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222529">thread link</a>) | @pawurb
<br/>
February 22, 2021 | https://pawelurbanek.com/dangerous-word-slack | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/dangerous-word-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div role="main">
<div>

<p><span>Share</span>
<a href="https://twitter.com/intent/tweet?text=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development&amp;url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Twitter" src="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png" srcset="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png 1x, https://pawelurbanek.com/assets/twitter@2x-bb4de08ef7390cb0e6bc0e4c74d50e098821cd7c55f1c6b20560a7a325d29164.png 2x">
</a>
<a href="https://facebook.com/sharer.php?u=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Facebook" alt="Share on Facebook" src="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png" srcset="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png 1x, https://pawelurbanek.com/assets/facebook@2x-0d1abc87e5ffdc544fa8f0f4282d2c01706bf15a814d794080aff2f7a87a0ffb.png 2x">
</a>
<a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack&amp;title=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development" rel="nofollow" target="_blank">
<img title="Share on LinkedIn" alt="Share on LinkedIn" src="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png" srcset="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png 1x, https://pawelurbanek.com/assets/linkedin@2x-b89a20f8fc3d0a82f9fe54137fbbbf4029dcc189f4dec6b9a3964b9350833e1f.png 2x">
</a>
</p>
<p><span>Share</span>
<br>
<a href="https://twitter.com/intent/tweet?text=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development&amp;url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Twitter" alt="Share on Twitter" src="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png" srcset="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png 1x, https://pawelurbanek.com/assets/twitter@2x-bb4de08ef7390cb0e6bc0e4c74d50e098821cd7c55f1c6b20560a7a325d29164.png 2x">
</a>
<br>
<a href="https://facebook.com/sharer.php?u=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Facebook" alt="Share on Facebook" src="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png" srcset="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png 1x, https://pawelurbanek.com/assets/facebook@2x-0d1abc87e5ffdc544fa8f0f4282d2c01706bf15a814d794080aff2f7a87a0ffb.png 2x">
</a>
<br>
<a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack&amp;title=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on LinkedIn" alt="Share on LinkedIn" src="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png" srcset="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png 1x, https://pawelurbanek.com/assets/linkedin@2x-b89a20f8fc3d0a82f9fe54137fbbbf4029dcc189f4dec6b9a3964b9350833e1f.png 2x">
</a>
<br>
</p>



<article>
<p><img title="Unhealthy communication on Slack is represented by a mousetrap Photo by Skitterphoto from Pexels" alt="Unhealthy communication on Slack is represented by a mousetrap Photo by Skitterphoto from Pexels" data-src="https://pawelurbanek.com/assets/slack-communication-trap-eeafc54866148ef1e14021e31975e1a8cfdab1478039b1a0685c1ea63600ef22.jpg" src="https://pawelurbanek.com/assets/slack-communication-trap-thumb-c4922c24466c80938315ab6fda7ae65192a488f1a643ccc4728839c6027bee1e.jpg">
</p>
<br>


<p><em>J-U-S-T</em>. Those four characters can be significantly detrimental to a software development process. In this blog post, I’ll describe how the <em>“just keyword”</em> can affect team’s communication and how to avoid misusing it on Slack.</p>
<h2 id="lets-just-do-it">Let’s “just” do it</h2>
<p>You’ve probably been there. Your product manager shares his brand new plan on the Slack channel:</p>
<p><em>“Why don’t we</em> <strong>just</strong> <em>add this cool new feature to our application?”</em></p>
<p>or your colleague got the wrong idea about scaling after reading a HackerNews story:</p>
<p><em>“Let’s</em> <strong>just</strong> <em>migrate our infrastructure to Kubernetes…“</em></p>
<p><em>“Just”</em> is toxic and dangerous. It implicitly suggests that the proposed task is straightforward. It undermines the discussion about the issues that might pop-up during the implementation.</p>
<p>There’s no <em>“just”</em> in software development. Most of the tasks turn out to be more complex than anticipated. <em>“Just tickets”</em> tend to drag, evolve into epics, miss deadlines and hurt the team’s motivation.</p>
<p>I’ve seen this topic discussed many times before. Make sure to check out <a href="https://alistapart.com/blog/post/the-most-dangerous-word-in-software-development/" target="_blank" rel="noopener noreferrer">these two</a> <a href="https://the-pastry-box-project.net/brad-frost/2014-january-28" target="_blank" rel="noopener noreferrer">blog posts</a> for a more in-depth description of it.</p>
<h2 id="how-to-use-slack-to-get-rid-of-just-tickets">How to use Slack to get rid of “Just tickets”</h2>
<p>I want to propose a solution to the <em>“Just”</em> problem. Lexically there’s never a need to include the word <em>“just”</em> in a sentence. You can always omit it without altering the core meaning of your message.</p>
<p>You could discourage using the word <em>“just”</em> in communication. Slack offers a simple feature that will let you automate it. Introducing Slackbot triggers:</p>
<p><img alt="Slack keyword trigger in action" title="Slack keyword trigger in action" loading="lazy" src="https://pawelurbanek.com/assets/slack-keyword-trigger-40d3219d92fe2bee0932a832ff7c80608c9b99a067f704347ed564dec917bc1e.png"></p>
<p>Slack trigger in action</p>

<p>You can configure Slack to automatically send a custom message whenever a <em>trigger</em> keyword is detected. In settings, go to <strong>Customize &gt; Slackbot</strong> and enter your desired trigger and response.
<br></p>
<p><img alt="Slack trigger settings" title="Slack trigger settings" loading="lazy" src="https://pawelurbanek.com/assets/slack-trigger-settings-3456bc59b61b75a27c245690b2d0a5d57afd8e2ac535027c9d01e3a87c54cffb.png"></p>
<p>Slack trigger settings</p>

<p>It could be pretty spammy to start with, but your team should quickly adjust and stop using the <em>forbidden</em> keyword. If someone does use it, the alert message will be a fun reminder to stop and think twice if the <em>“just”</em> idea is really that simple.</p>
<p>So why won’t you just give this communication experiment a try?</p>
<p>BTW if you’re looking for more creative ways to enhance your communication on Slack, you can check out <a href="https://abot.app/" target="_blank" rel="noopener noreferrer">Abot for anonymous messaging and polls</a>. It’s highly configurable and supports various <a href="https://abot.app/scenarios" target="_blank" rel="noopener noreferrer">usage scenarios</a>.</p>
<p><img alt="Anonymous poll conducted using Abot for Slack" title="Anonymous poll conducted using Abot for Slack" loading="lazy" src="https://pawelurbanek.com/assets/slack-anonymous-poll-bda619f03336795730c69705f61eddc8f4bac6a6bcd8deb65e83bf3ff880156d.png"></p>
<p>Abot anonymous poll with private answers</p>

</article>

<p><a href="https://twitter.com/_pawurb" target="_blank" rel="nofollow">
<img loading="lazy" alt="Pawel Urbanek Twitter account" title="Pawel Urbanek Twitter account" src="https://pawelurbanek.com/assets/pawel-circle-eafe4e7f9c98c20c753dcba1f1b1a16ed8bc384cdf2da91d272dd2291d8e7a4d.jpg" srcset="https://pawelurbanek.com/assets/pawel-circle-eafe4e7f9c98c20c753dcba1f1b1a16ed8bc384cdf2da91d272dd2291d8e7a4d.jpg 1x, https://pawelurbanek.com/assets/pawel-circle@2x-352753604906054aa864cc5f3916317be7c2b7db8f8703243a0447d06187c641.jpg 2x">
</a>
</p>

<br>

<br>

<br>


<br>





</div>
</div>
</div></div>]]>
            </description>
            <link>https://pawelurbanek.com/dangerous-word-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222529</guid>
            <pubDate>Mon, 22 Feb 2021 09:41:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with a Niche]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26222313">thread link</a>) | @tablet
<br/>
February 22, 2021 | https://fibery.io/blog/start-with-a-niche/ | <a href="https://web.archive.org/web/*/https://fibery.io/blog/start-with-a-niche/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>The most popular products don’t become mass popular overnight. It’s a process. Usually, their popularity is uneven, they are unknown in some niches, but very popular in other niches.</p><p>When you start a product, sometimes you know the niche already and can easily define target customers. However, in many cases, you just don’t and try to find the niche and this miraculous niche-market-fit. </p><p>One of the most common mistakes is to ignore niches and just try to attract all kinds of customers. It’s essential to find 1-2 ponds to start from and then expand to the other, larger, and more promising lakes and oceans 🚰 → 🛁 → 🌊.</p><p>Here are a couple, maybe surprising examples, that demonstrate how popular products took off. </p><h4>Electrical telegraph (1837)</h4><p>Its adoption was not easy, since it was not clear what are the benefits for commercial institutions. Stockbrokers and reporters got the benefits first. They understood that fast information transition increases efficiency and helps to get an edge. In a short term, all major news agencies and major stock markets were connected to the telegraph. </p><h4>Telephone (1876)</h4><p>Telephones were adopted by police departments and fire stations. Fast reaction to crime reports and fires was great, but the telegraph was not enough. You have to have two-ways communication to get some details that the sender maybe is not expecting to report initially. </p><h4>Phonograph (1877)</h4><p>Try to guess the first niche market for the phonograph. Rich music lovers? Nope. First phonographs were coin-machines in bars. Throw a nickel and enjoy Stephen Foster ballads.</p><h4>Car (1886)</h4><p>Cars are almost among the lucky exception to the niche rule. However, there was still one group of people in the USA that moved from horses to cars enormously fast — farmers. Cars just expanded the borders of farmers’ social life and business activities. Suddenly you can buy goods, not from a local dealer, but a dealer in a remote town (much cheaper). Suddenly you can visit a town and watch a movie. These benefits were not important for the urban population, for they were life-changers for the rural population. Nevertheless, cars were adopted in cities quite fast as well.</p><blockquote><p>In addition, the car delivered you to the door and was faster than a horse-and-buggy, thus allowing longer trips in shorter time. Farmers had traditionally felt guilty about taking such trips, even when the time was available. </p></blockquote><h4>Radio (1895)</h4><p>Radio was immediately adopted by the British Royal Navy, they thought that radio can speed up communication between ships and were right. Fun fact: in 1912 Titanic sent CQD (distress signal), however, <a href="https://www.nationalgeographic.com/history/article/why-titanic-first-call-help-not-sos-signal">radio receiver was turned off on the closest ship</a>:</p><blockquote><p>Meanwhile, the closest ship, Californian, didn’t receive Titanic’s distress calls at all. Its wireless operator had switched off his receiver and gone to bed after Phillips told him to shut up.</p></blockquote><h4>VisiCalc (Excel predecessor, 1979)</h4><p>First, it was adopted by accountants. Businessmen and analysts joined the party much later. Accountants just saw the value right away (and quite many people pirchased Apple II just to get <a href="https://thenewstack.io/how-visicalcs-spreadsheets-changed-the-world/">VisiCalc</a>):</p><blockquote><p>Like an accountant, I remember showing it to one around here and he started shaking and said, “That’s what I do all week. I could do it in an hour.” … I meet these people now, they come up to me and say, “I gotta tell you, you changed my life. You made accounting fun.”</p></blockquote><h4>Facebook (2004)</h4><p>Everybody knows that Facebook got its popularity in universities first. Everybody knows the rest of the story.</p><blockquote><p>Within 24 hours, 1,200 Harvard students had signed up, and after one month, over half of the undergraduate population had a profile. The network was promptly extended to other Boston universities, the Ivy League and eventually all US universities</p></blockquote><hr><p>Can you start without any niche in mind? Yes, you can, but this is just hard. The most problematic part is marketing. Who are your ideal customers? How to reach them? How to target your message? <strong>Product is the message</strong>, so without proper marketing startup success chances are low. </p><h4>My experience</h4><p>In Fibery we did our first release in April 2020 as a general work management tool. We were not sure in what types of companies it will work better and what use cases will be more valuable. In just a month it became clear that we had all kinds of leads from all kinds of companies. Leads demanded all kinds of improvements that just didn’t form a sane strategy. </p><p>We quickly <a href="https://fibery.io/blog/chronicles-21/">decided to select a single niche and focus on it</a>. The niche we choose was product companies from 20 to 200 people. And it made everything much simpler. Finally, we can quite accurately say what features are important and what features are not so important, what is our value proposition, who is our ideal lead (Product Ops or CPO). It took us 9 months to prepare the <a href="https://fibery.io/product-management">second release</a>, but in this niche Fibery can fly much better, I believe. </p><p>OK, niche strategy looks convincing, but how to find the niche? We used <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s law</a>, and it’s just partially a joke. We’ve reviewed a couple of alternatives and selected one we knew best and were confident that our product will provide a significant value boost. There were other alternatives, like education space or digital agencies space, but our knowledge here was not deep enough. It means we should rely on some domain experts, etc. It’s not a huge problem, but we also did not feel that these niches are better.</p><p>A startup should be an experimentation facility that hypothesizes, executes, and measures the results. The faster you can do it, the faster you find your niche. Why it took us 9 months to make this niche release? In fact we spend time to create a niche-probing framework. Now we can asseble solutions for various niches in 1-2 weeks and check initial response in 1-2 months. If the first niche will not be successful, we at least have a decent experimentation framework 🧬.</p></section></div>]]>
            </description>
            <link>https://fibery.io/blog/start-with-a-niche/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222313</guid>
            <pubDate>Mon, 22 Feb 2021 09:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practiced Humility in Retrospectives]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222018">thread link</a>) | @kiyanwang
<br/>
February 22, 2021 | https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/ | <a href="https://web.archive.org/web/*/https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    
<p>One of the fallacies about our collective approach to retrospectives, incident reviews, and post mortems is the belief that the entire process is a rational machine. Pour in a curated series of events, turn the handle, and out pop all of the action items that need completing to fix the world. I can’t speak to every industry that practices Resilience Engineering, but as for Software Engineering it stems strongly from our belief that we’re fully in control of our environment. We’ve built our tooling, architected our systems, and we’re running the retro. Why wouldn’t we be able to simply apply the calculus to our knowledge and change things for the better?</p>



<p>This all speaks to a distinct lack of humility in what we do as a practice. If we want to better understand the risks we undertake every day and to learn from failures in that work, we need to first accept that failures are in part due to our incomplete understanding, great and small, of our socio-technical systems. Even with a complete working knowledge of everything, we would be unable to act on everything needed to perfect our system, and that underlying system will change despite these efforts. Being comfortable with being wrong means we can change.</p>



<p>This reluctance to accept that things continually fail despite our best efforts, is a common reaction. It’s hard to assume that our systems are continuously in need of tweaks because it’s also hard to accept that they will always run in some form of a degraded state<sup><a rel="noreferrer noopener" href="#complex-systems-run-in-degraded-mode" target="_blank">1</a></sup>. That said, we can fall into the adjacent trap with people being the adaptable element in the system<sup><a rel="noreferrer noopener" href="#human-practitioners-are-the-adaptable-element" target="_blank">2</a></sup> that we are then in the best position to understand the entirety of our system and how best to course correct. The sharp end can be a powerful, if not perilous, position to sit in but it doesn’t guarantee omniscience in the scope of understanding an incident. This is why I frequently suggest that practitioners of retrospectives be folks who weren’t involved in the incident, to help mitigate this failing.</p>



<h2>Hubris as Facilitator</h2>



<p>It’s easy to understand the desire to sit in the facilitator chair. You’re taking the reins of the situation and you’re going to get to the bottom of things. You ask the questions, you drive the conversation and schedule the meeting, but most importantly you’re going to be there to get answers. That would be true if you held a made up title like investigation commander or retrospective captain, but you’re don’t. A facilitator is less the spike and more the bump/set. You’re there to position other folks to learn, not wear the badge.</p>



<p>Retros also come in various shapes and sizes, which makes for another tempting place to be in control. If I’m running the retro, then it can follow my guidelines and my preferred flow. This lesson I learned the hard way, having felt as though I knew “the one true way” to run it. I was there at Etsy watching John Allspaw, Morgan Evans, and Daniel Schauenberg develop and put ink to paper with the <a rel="noreferrer noopener" href="https://extfiles.etsy.com/DebriefingFacilitationGuide.pdf" target="_blank">Etsy Debriefing Guide</a>. In doing so, though, I failed to recognize the microcosm that was Etsy, that what worked for us there didn’t apply universally. Maybe folks had other tools worth surfacing and we should continually look to that to see how we can improve the production of our retros.</p>



<p>Facilitators should instead be the support for everyone else to do the talking and ask questions of their own. We can only share that deep empathy with one another when we put ourselves in one another’s shoes and that can only be done with the understanding of our own fallibility. We too know how awful it feels to be at the center of an incident, that it could have easily been us, which allows us to help recreate the scene and ditch concepts like “human error” as an easy solution to a complex problem.</p>



<p>A singular view of the problem, from that up on high as facilitator, will produce a singular set of answers constrained by our myopic vantage point.</p>



<h2>Top Down Misunderstanding of Retrospectives</h2>



<p>Another failure in our work running retrospectives is senior leadership (individual contributors and management both) using them to impart the illusion of work being done. You’ll see this often in email chains that include a CC list that races its way up the reporting structure. This incident was unacceptable, but don’t worry, <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=9AKTBHuRv9U" target="_blank">we have top men working on it right now</a>. Similarly, you’ll see public facing reports sent out by companies to reassure customers, the board of directors, and investors that all is well. It’s worth noting that there is value in shared perception being a useful tool for a business to leverage, but it still doesn’t impart learning to folks on either side of the boundaries of a company. The learning review is downgraded for the sake of making an org, at the macro or micro level, appear to be invulnerable to failure. The company cannot tolerate failure because vulnerability must be made an impossibility.</p>



<p>It’s also why so many existing tools are marketed with a primary focus on action items as the work. Going into a retro with the principal desire to create a ToDo list is problematic because the learning becomes a secondary function by nature of prioritization. It has roots in humility such that we’re going into our discussions and interviews believing we can simply solve all the problems in tech and then everything will be perfect from here on, the deeper understanding a “nice to have”.</p>



<p>This is not to give individual contributors in senior positions a pass. How often do we rely on “This is the way we’ve always done it” and our use of best practices<sup><a href="#can-we-trust-best-practices">4</a></sup> as a crutch for decision making rather than challenge established methods? We give folks in senior positions more time for questions during discussions and put them at the front to answer for the sake of expedience. Equally, holding a blameless post mortem can fail if an org values engineers who prioritize their place in the pecking order rather than risk losing face in front of others. Giving less experienced folks time to explore ideas tests the validity of our mental models.</p>



<p>Most importantly, for us to build and revise adaptive capacity<a href="#building-and-revising-adaptive-capacity"><sup>3</sup></a> we have to first acknowledge that the map of our system is potentially inaccurate, a map that is heavily influenced top down. Until we can move towards an acceptance of inaccuracies in our understanding, our assumption stands that we must be right and the view should not change. All of these concepts, and our own journey to them, are themselves a <em>work in progress</em>. There are soft boundaries and holes in the middle where our language and understanding fails us. This does not inherently diminish our work, but can in fact enhance it.</p>



<h2>Humility In Practice</h2>



<p>It’s a fairly given criticism that a lot of our work in applying Resilience Engineering and Human Factors concepts to Software Engineering fail to give concrete examples of putting theory to practice, often leaving it as an exercise to the reader. With that in mind, what does humility first in a retro look like?</p>



<ul><li><strong>A retrospective is a safe place to say “I don’t know”.</strong> A facilitator can and should actively say just that while encouraging others who exhibit similar misgivings about what they can safely hold true. By doing so, it establishes a pattern of being ok with the discomfort of uncertainty.</li><li><strong>Retros should prioritize learning before fixing.</strong> This is not infrequently stated, but bears repeating. As said elsewhere, it also doesn’t exclude action items. Rather, allow folks to freely express what they don’t understand without shame and for improvements to extend from these learning experiences.</li><li><strong>A generosity of spirit is key.</strong> Participants should hold a respect to time shared for other folks to learn, with a particular emphasis on the facilitator. As invaluable as your time is, the up front cost of interviewing folks, organizing meetings, and gathering information is paramount. Put in the extra effort to interview before a retro meeting and follow up after to tie up loose ends.</li><li><strong>There should be a reduction (not an absence) on our use of hindsight.</strong> Acknowledging that we’re all fallible means we can resist the inclination to “fix” an error with counterfactuals when we review past events. Look backwards not as a way to save face but to explore why ideas previously made sense.</li><li><strong>The malleable nature of a retrospective is to review what is assumed to be true.</strong> Confirm or refute assumptions on the narrative as it is assumed to exist regardless of who shares it. Some folks may not be in a position to share, internal pressures against them. Insights often comes from the sharp end, which isn’t always the most tenured engineer.</li><li><strong>All participants should be on equal footing.</strong> Retros are akin to a round table discussion where folks come to share events and ask questions, rather than seniority or management directing the events as to how it may best serve their own interests or those assumed to be of the organization. Don’t let titles dictate who gets to speak.</li><li><strong>Our work in retrospectives is ongoing and adaptable.</strong> Before practitioners get too set in their ways, we should remember that Resilience is a verb<sup><a rel="noreferrer noopener" href="https://willgallego.com/wp-admin/post.php?post=529&amp;action=edit#resilience-is-a-verb" target="_blank">5</a></sup>. Templates are more rigid and predefined, but allowing ourselves the chance to break out of molds, to make mistakes, and explore the boundaries with the assurance that failure is ok, we can practice new ways of pulling out sources of information from our incidents. Our meta discussions surrounding incidents should themselves be challenged.</li></ul>



<p id="complex-systems-run-in-degraded-mode">1. Cook (2002) – <a rel="noreferrer noopener" href="https://how.complexsystems.fail/#5" target="_blank"><em>How Complex Systems Fail: Complex systems run in degraded mode</em></a></p>



<p id="human-practitioners-are-the-adaptable-element">2. Cook (2002) – <a rel="noreferrer noopener" href="https://how.complexsystems.fail/#12" target="_blank"><em>How Complex Systems Fail: Human practitioners are the adaptable element of complex systems</em></a></p>



<p id="building-and-revising-adaptive-capacity">3. Cook, Long (2020) – <a rel="noreferrer noopener" href="https://www.sciencedirect.com/science/article/pii/S0003687020301903" target="_blank"><em>Building and revising adaptive capacity sharing for technical incident response: A case of resilience engineering</em></a></p>



<p id="can-we-trust-best-practices">4. Klein et al (2016) – <a href="https://www.researchgate.net/publication/300343833_Can_We_Trust_Best_Practices_Six_Cognitive_Challenges_of_Evidence-Based_Approaches" target="_blank" rel="noreferrer noopener"><em>Can We Trust Best Practices? Six Cognitive Challenges of Evidence-Based Approaches</em></a></p>



<p id="resilience-is-a-verb">5. Woods (2018) – <a rel="noreferrer noopener" href="https://www.researchgate.net/publication/329035477_Resilience_is_a_Verb" target="_blank"><em>Resilience is a Verb</em></a></p>



<p><em>Photo: <a href="https://www.flickr.com/photos/eyesplash/5307049124" target="_blank" rel="noreferrer noopener">https://www.flickr.com/photos/eyesplash/53070…</a></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/">https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/</a></em></p>]]>
            </description>
            <link>https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222018</guid>
            <pubDate>Mon, 22 Feb 2021 08:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parler Is Back Online]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26221640">thread link</a>) | @jhabdas
<br/>
February 21, 2021 | https://www.ptnewsnetwork.com/parler-is-back-online/ | <a href="https://web.archive.org/web/*/https://www.ptnewsnetwork.com/parler-is-back-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_83_a69">

<div>
<p>After big-tech censorship silenced social media company Parler on January 11, 2020, they are back online with new servers as well as new leadership.</p>



<p>Over one month ago Amazon Web Services removed Parler from their servers, taking them offline.&nbsp; Google and Apple also removed them from their app stores. &nbsp; They claimed that the platform was used to “incite, organize, and coordinate the January 6 attack on the US Capitol.”</p>



<p>Defense and National Guard officials, including now former Army Secretary Ryan McCarthy, have stated in interviews that federal law enforcement authorities indicated there was activity relating to the organizing of the Capitol attack on Twitter also.</p>



<p>Parler execs said it was a war on free speech, and Amazon stated that requests to remove violent content, including death threats against public figures were ignored.</p>



<p>In addition, their co-founder and CEO, John Matze was terminated by their board on January 29 over differences in company visions.&nbsp;</p>



<p>Parler’s interim CEO Mark Meckler told<a href="https://justthenews.com/nation/culture/welcome-back-parler-resumes-social-media-app-after-securing-new-computer-servers?utm_source=breaking-newsletter&amp;utm_medium=email&amp;utm_campaign=newsletter#article"> Just the News</a> that “20 million users who were already using the app can begin logging back in on Monday, and new users should be able to sign up in approximately one week.”</p>



<p>“He also said the platform is using artificial intelligence and human editors to police for illegal speech that violates its service agreement but otherwise is remaining true to its free speech, no censorship roots.”</p>



<p>According to his<a href="https://twitter.com/MarkMeckler?s=20"> Twitter</a> account, Meckler is the President of the Convention of States Project, Co-Founder and former National Coordinator of Tea Party Patriots, Constitutional Revolutionary, Husband, Father, and Son.</p>



<p>“Parler is being run by an experienced team and is here to stay,” Meckler said in a statement. “We will thrive as the premier social media platform dedicated to free speech, privacy and civil dialogue.”</p>



<p>There are still some issues with the platform as many people are reporting the site is still not accessible, but it seems their return is imminent.&nbsp;&nbsp;</p>



</div></div></div>]]>
            </description>
            <link>https://www.ptnewsnetwork.com/parler-is-back-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221640</guid>
            <pubDate>Mon, 22 Feb 2021 07:04:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indian Government Breached, Massive Amount of Critical Vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 299 | Comments 67 (<a href="https://news.ycombinator.com/item?id=26221607">thread link</a>) | @astroanax
<br/>
February 21, 2021 | https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A writeup detailing the vulnerability reporting process that took place after Sakura Samurai had breached the Indian Government</p><p>Reading time: 6 minutes.</p><div>
      

<p>Sakura Samurai knew that the Indian Government operated an RVDP (Responsible Vulnerability Disclosure Program). <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> put a list together of initial assets in scope for Sakura Samurai to legally test. <a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a> reported that he had found sensitive data and was able to breach police assets. <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> was working in the enumeration processes with his friend, <a href="https://twitter.com/orpheus9001" title="https://twitter.com/orpheus9001">Zultan Holder</a> [not an active Sakura Samurai member] and identified a slew of various attack vectors, immediately resulting in the exposure of many pairs of credentials for databases and other pertinent applications.</p>
<p>The team was informed of the initial enumeration results as they continued to work on the list of assets within scope, while also further jumping into the research and began performing analysis on the sensitive data, identifying additional vectors of attack, exposed PII, and even more credentials.</p>
<p>Sakura Samurai team members included <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a>, <a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a>, <a href="https://twitter.com/Kirtaner" title="https://twitter.com/Kirtaner">Aubrey Cottle</a>, and<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking"> John Jackson</a></p>
<p>In total, the following vulnerabilities were identified, in no specific order:</p>
<ul>
<li>35 Separate Instances of Exposed Credential Pairs (Servers, Important Applications, etc)</li>
<li>3 Instances of Sensitive File Disclosure</li>
<li>5 Exposed private-key pairs for servers</li>
<li>13K+ PII Records [and those are only the records that we were inadvertently exposed to]</li>
<li>Dozens of Exposed Sensitive Police Reports</li>
<li>Session Hijacking Chained via Multiple Vulnerabilities, resulting in the compromise of extremely sensitive government systems</li>
<li>Remote Code Execution on a sensitive financial server; a server that contained large backups of Financial Records</li>
</ul>

<p>First and foremost, it is important to note that so many Critical findings had been identified during our testing that we cannot possibly include all of the vulnerabilities without making this writeup unnecessarily heavy. Therefore, we have opted to include small snippets of repetitive findings in this section. Many variations of application and server credentials also were obtained but the point has already been made.</p>
<p><strong>Exposed Database Credentials</strong></p>
<p><img src="https://johnjhacking.com/uploads/db-creds.png" alt=""><br>
<strong>Private SSH Keys</strong></p>
<p><img src="https://johnjhacking.com/uploads/priv-ssh.png" alt=""></p>
<p><strong>Sensitive File Exposure</strong></p>
<p><img src="https://johnjhacking.com/uploads/sens-file-exp.png" alt=""><br>
<strong>Exposed PHP Mailer Credentials</strong></p>
<p><img src="https://johnjhacking.com/uploads/mailer.png" alt=""></p>

<p><a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a> identified an application that resulted in a vulnerability that allowed him to access Sensitive Police Records, containing PII of individuals listed on the report. In addition, sample forensic reports and forensic tooling that is used by the police department was identified by Willis. The exposure of citizen’s sensitive information, some being victims, is a sensitive subject within itself and highly alarming.</p>
<p><img src="https://johnjhacking.com/uploads/police.png" alt=""><br>
<img src="https://johnjhacking.com/uploads/police2.png" alt=""><br>
Shortly after, <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> found a vulnerability that resulted in the exposure of 14,000+ user records. The records included a wide range of sensitive information, including full name, contact info, employee’s department, date of birth, etc. These exposed records along with other various SQL server dumps and Rob’s Police Record Exposure is enough to constitute a data breach without even logging into any of the servers.</p>
<p>Henry identified many credential pairs which could have resulted in even more exploitation of many other people. The PII identified is a small sample of a much larger issue.</p>
<p><img src="https://johnjhacking.com/uploads/14k-records.png" alt=""><br>
<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">John Jackson</a> was able to identify a relevant Remote Code Execution Vulnerability, affecting an out-of-date application residing on one of the government servers. The remote code execution vulnerability allowed for complete access to sensitive files on the server, including the ability to exfiltrate complete backups of financial records [although data exfiltration wasn’t performed to avoid unnecessary action]</p>
<p><img src="https://johnjhacking.com/uploads/rce1.png" alt=""><br>
<img src="https://johnjhacking.com/uploads/rce2.png" alt=""><br>
Finally, <a href="https://www.twitter.com/Kirtaner" title="https://www.twitter.com/Kirtaner">Aubrey Cottle</a> identified the presence of what appeared to be an extremely important application being hosted by the same server that John had achieved successful Remote Code Execution on. Cottle then chained together multiple vulnerabilities in conjunction with the Remote Code Execution vulnerability, resulting in the ability to hijack any user’s session on the web application. The application contained troves of sensitive government data and could have given a threat actor the ability to perform highly-critical, admin-based government actions.</p>
<p><img src="https://johnjhacking.com/uploads/session-chained.png" alt=""></p>

<p>Even though the Indian Government has a RVDP in place, we didn’t feel comfortable disclosing the vulnerabilities right away. The hacking process was far from the standard situation of business-as-usual security research. In total, our report compounded to a massive 34 page report worth of vulnerabilities. We knew that our intent was good, but we wanted to ensure that the US Government had eyes on the situation. Sakura Samurai coordinated with the <a href="https://twitter.com/DC3VDP" title="https://twitter.com/DC3VDP">U.S. DoD Vulnerability Disclosure Program (VDP)</a> to assist in facilitating initial conversations of disclosure. <a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">John Jackson</a> spoke with DC3’s Program Manager via email and coordinated on a plan of action.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-1.png" alt=""><br>
Roughly 4 days later, after further communication with the DC3, we felt safe to begin our initial reveal of research on the NCIIPC’s RVDP program.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-2.png" alt=""></p>
<p>In addition, the DC3 also commended the hacking that we did in support of making the cyberspace a better place for everyone.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-3.png" alt=""></p>
<p>Unfortunately, what seemed like a done deal turned out to be quite the unprofessional ride. Any organization knows that fixing breach-worthy vulnerabilities is extremely time sensitive. Once threat actors catch wind of major vulnerabilities against an organization they begin poking on their own, looking for more vectors of attack. Immediately upon revealing that Sakura Samurai was the group responsible for hacking the Indian Government, we followed up with them via Email.</p>
<p><strong>Timeline</strong></p>
<p><strong>2021/02/04</strong> - DC3 begins initial contact with the Indian Government.<br>
<strong>2021/02/08</strong> - Sakura Samurai informs the public that they breached the Government.<br>
<strong>2021/02/08</strong> - Sakura Samurai makes contact with the NCIIPC, noting that the report that they received was a result of their research.<br>
<strong>2021/02/09</strong> - The NCIIPC responds, with a basic acknowledgement and thank you for the research.<br>
<strong>2021/02/09</strong> - Sakura Samurai asks for clarification on patching and the responsibility of breach disclosure to the public.<br>
<strong>2021/02/10</strong> - Sakura Samurai, having received no response, asks for an update on the involved remediation and breach notification processes.<br>
<strong>2021/02/16</strong> - Sakura Samurai once again asks for NCIIPC’s plans for remediation and disclosure.<br>
<strong>2021/02/17</strong> - The NCIIPC makes contact, 7-days later, stating that they will follow up in a short time. Again, we ask about plans of anticipated patching and breach notification to the affected citizens.<br>
<strong>2021/02/19</strong> - In the morning, we ask again about patching and disclosure, 8-hours later and still no response on the matter.<br>
<strong>2021/02/19</strong> - Sakura Samurai reviews the submitted vulnerability report and notes that only about an eighth or less of the submitted Critical Vulnerabilities have been resolved within a two-week period. No notification of breach has occurred even though Government Employees and Indian Citizens are at risk of exploitation from threat actors.</p>

<p>Governments have an obligation to protect the private data of its employees and citizens. In addition, the exposure of proprietary government data can be used for great means of manipulation and for other destructive purposes. While the NCIIPC operates a Responsible Vulnerability Disclosure Program, the recklessness and avoidance of communication represents the complete opposite of a responsible program. A failure to release notification of breach to affected citizens and to patch highly-critical vulnerabilities in a timely manner reflects poorly on the state of their Information Security posture. The clock to patch vulnerabilities began immediately when the DC3 contacted the NCIIPC via Twitter, as it is a highly visible space - one which threat actors avidly monitor.</p>
<p>Sakura Samurai urge the NCIIPC to patch the remainder of the vulnerabilities. The criticality of some of the issues cannot wait weeks or months for adequate resolution.</p>
<hr>
<p><strong>Check out our website</strong><br>
<a href="https://sakurasamurai.org/" title="https://sakurasamurai.org">https://sakurasamurai.org</a></p>
<p><strong><em>Twitter Links:</em></strong><br>
Main Page<br>
<a href="https://twitter.com/SakuraSamuraii" title="https://twitter.com/SakuraSamuraii">https://twitter.com/SakuraSamuraii</a><br>
Founders<br>
<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">https://twitter.com/johnjhacking</a><br>
<a href="https://twitter.com/nicksahler" title="https://twitter.com/nicksahler">https://twitter.com/nicksahler</a><br>
Members<br>
<a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">https://twitter.com/JacksonHHax</a><br>
<a href="https://twitter.com/Kirtaner" title="https://twitter.com/Kirtaner">https://twitter.com/Kirtaner</a><br>
<a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">https://twitter.com/rej_ex</a><br>
<a href="https://twitter.com/endingwithali" title="https://twitter.com/endingwithali">https://twitter.com/endingwithali</a><br>
Collaborator<br>
<a href="https://twitter.com/orpheus9001" title="https://twitter.com/orpheus9001">https://twitter.com/orpheus9001</a></p>

    </div></div>]]>
            </description>
            <link>https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221607</guid>
            <pubDate>Mon, 22 Feb 2021 06:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Immutability, Verifiability and Integrity Without the Blockchain Overhead]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26221324">thread link</a>) | @sidcool
<br/>
February 21, 2021 | https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/ | <a href="https://web.archive.org/web/*/https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Whenever a software project needs to implement immutable records, people often start thinking of Blockchain or <strong>D</strong>istributed <strong>L</strong>edger <strong>T</strong>echnology like Hyperledger. Blockchain and DLT make use of cryptographic techniques that enable immutability, verifiability and integrity checks. However, Blockchain and DLT need much more than just these checks. It needs to prevent all the attempts of a double-spend by potential malicious users. In a trust-less environment it needs implementation of complex protocols which leads to consumption of huge amount of electricity. This makes writing data on Blockchain costly. DLTs like Hyperledger make use of simpler consensus algorithms between a “set of trusted nodes”, which reduces the cost. However, it still incurs significant costs if nothing more than immutability, verifiability and integrity were the concern.</p>



<p>This post is about how to implement data immutability, verifiability and integrity without using a Blockchain or a DLT in industrial strength software applications.</p>



<ul><li><a href="#foundation">Foundational technique</a><ul><li><a href="#hash-function">Cryptographic hash function</a></li></ul></li><li><a href="#verifiability">Verifiability</a><ul><li><a href="#verify-id">Deterministic and Verifiable IDs</a></li><li><a href="#data-format">Data format and ID Generation</a></li></ul></li><li><a href="#immutability">Immutability and Verifiability</a><ul><li><a href="#merkel-dag">Merkel DAG and immutable data structures</a></li><li><a href="#mutation">Mutation</a></li></ul></li><li><a href="#integrity">Immutability, Verifiability and Integrity</a><ul><li><a href="#application">More applications</a></li></ul></li><li><a href="#future-proof">Future-proofing</a><ul><li><a href="#multi-hash">Multihash</a></li></ul></li></ul>



<h2 id="foundation">Foundational technique – Cryptographic Hashing</h2>



<p>To understand the solution, some foundational techniques must be understood. This section describes what is cryptographic hashing. Those who are already aware of cryptographic hashing, they may skip to the next section.</p>



<h4 id="hash-function">Cryptographic hash function</h4>



<p>If you provide a stream of bytes to a cryptographic hash function, it generates a number called hash (also referred to as digest). The following properties make it a very useful tool:</p>



<ol><li>It is impossible to guess the generated hash value for a stream of bytes. To get the hash value, one has to run the algorithm, there is no shortcut.</li><li>For a given input it always generates the same hash value.</li><li>It is infeasible to deduce the input based on the hash value. That means it is an irreversible mathematical function.</li><li>No two different stream of bytes result in the same hash value. Even a small change in the input stream generates a totally different number.&nbsp;<em>(When two different stream of bytes produce the same hash value, we say the cryptographic hash function is broken. It is also referred to as there is a collision in the cryptographic hash function.)</em></li><li>Any size of input stream will always result in the same size of hash value. Some hash functions generate hash values that are 256 bits long. If those functions are used, the result will always be 256 bits long.</li></ol>



<p>Examples of commonly used cryptographic hash functions include:</p>



<ul><li>SHA-256 (returns 256 bit&nbsp;unsigned integers)</li><li>RIPEMD-160 (returns 160 bit unsigned integers)</li></ul>



<p>Sample hash values:</p>



<figure><table><tbody><tr><td><strong>Input</strong></td><td><strong>SHA-256</strong></td><td><strong>RIPEMD-160</strong></td></tr><tr><td>Hello world</td><td>0x64ec88ca00b268e5ba1a35678a1b5316d212f4f366b2477232534a8aeca37f3c</td><td>0xdbea7bd24eef40a2e79387542e36dd408b77b21a</td></tr><tr><td>Hello world.</td><td>0xaa3ec16e6acc809d8b2818662276256abfd2f1b441cb51574933f3d4bd115d11</td><td>0x6ad34a17d22d67a7ab02710ae9eb6f282cb1d787</td></tr><tr><td>Unrelated, totally.</td><td>0x2bd72f5c4300444890325b3363ef2027f30ed38797c3133dbc62a90564976458</td><td>0x51cb1844d22a00d5f659795e0b1c339c6fa1a8bc</td></tr></tbody></table><figcaption>Hex representation of SHA-256 and RIPEMD-160 hash values for different inputs</figcaption></figure>



<p>There are two things we observe from the table above:</p>



<ol><li>With a slight change in input, the hash values change dramatically and by looking only at the hash values, one cannot conclude&nbsp;that&nbsp;the first and second are&nbsp;even closely related. This is also referred to as <a href="https://en.wikipedia.org/wiki/Avalanche_effect" target="_blank" rel="noreferrer noopener">avalanche effect</a>. It is one of requirements of a cryptographic algorithms to have the avalanche effect.</li><li>The values mentioned are actually text strings and do not look like numbers, although we expected them to be numbers.</li></ol>



<p>They are actually numbers, represented this way to reduce the size of the presented text. For example, binary representation of the number 255&nbsp;is ‘11111111’. Decimal representation is ‘255’. Hexadecimal representation is ‘ff’ or ‘FF’. The representations in the table above are hexadecimal representations of 32 byte and 20 byte numbers. <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Base64" target="_blank">base64encoding</a> is commonly used to represent the hash values in cryptographic applications.</p>



<h2 id="verifiability">Verifiability</h2>



<p>For quite some time, open source software has been distributed through various mirror sites so that downloads are sped up. Any user could download the software package quickly from a nearby mirror site. These nearby sites could be malicious and could provide compromised open source software packages. In order to overcome this problem, open source software builds would publish a checksum file on their website. This checksum file is used to verify that the downloaded package from a nearby mirror site is authentic. The checksum file actually contains a cryptographic hash of the software package.</p>



<p>For example: <a rel="noreferrer noopener" href="https://www.openoffice.org/download/checksums/3.4.1_checksums.html" target="_blank">Apache OpenOffice – Download checksum files</a>.</p>



<pre>e08f9c8acecba1ee0046f820b0abed97dfe90511bd733a65936fdf0ea9c22540  Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz</pre>



<p>This is the content from SHA256 checksum file for <a href="http://archive.apache.org/dist/incubator/ooo/files/stable/3.4.1/Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz.sha256" target="_blank" rel="noreferrer noopener">Apache Open Office SDK for Linux x86-64</a> build.</p>



<p>It would not matter which mirror site the SDK is downloaded from. A user can easily verify the authenticity of the download using a simple command like:</p>



<pre><code>$ sha256sum Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz
e08f9c8acecba1ee0046f820b0abed97dfe90511bd733a65936fdf0ea9c22540  Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz</code></pre>



<p>If the generated SHA256 does not match with the checksum file, the user knows that the software package has been tampered.</p>



<p>We will use the same technique to verify data objects. The data object we are interested in would have an ID. Any application or service asks for objects using IDs. If the data that the application gets does not generate the same hash value as the ID, then the application can easily conclude that the data is not what was asked for or the data has mutated. On a typical hardware the cryptographic hash function would take a few microseconds to generate the hash value. So, this is not costly and offers good verifiability.</p>



<p>In the context of this post, the verifiability that we are seeking is not because we operate in a trust-less or adversarial environment like Blockchains, but mainly because data can become corrupt or can be deliberately changed by hackers / attackers. This is for companies to verify that the data they hold has not been modified undesirably.</p>



<h4 id="verify-id">Application: Deterministic and Verifiable IDs</h4>



<p>In a typical RESTful request, a client posts a request to a service, and the service returns back an ID. The service uses the ID to index the object that got created due to the request. However, with a predetermined ID generation technique, it is possible for the client to know the ID even before the service receives the request. This is done even in blockchains. The transactionID (also referred as <a href="https://wiki.bitcoinsv.io/index.php/TXID" target="_blank" rel="noreferrer noopener">TXID</a>) is a hash computed from certain fields of a transaction request.</p>



<p>To be able to know the ID of an object that will be returned by a service even before the object is created in a service has significant benefits. </p>



<ol><li>Just by computing the ID from the fields of an object, and comparing it with the ID provided in the object, one can determine if the object is the right object. Housekeeping processes can easily determine data corruption or software bugs or potential attacks.</li><li>Request need not be processed synchronously.</li><li>The client can fire a batch of requests in just one call. Each individual request can easily be identified by the request id which will be deterministic for both the client and the service. This eliminates the need to create IDs on the client side, and map them to the server side IDs.</li><li>Non-idempotent requests such as HTTP POST requests can achieve deterministic behaviour. Multiple POST requests (which could be because of software bug or infrastructural replays) will not cause harm, as the request ID is predetermined. The server can easily identify a duplicate request.</li></ol>



<p>Example: To generate an OrderID, one could take the sha256 of a series of bytes of the quantity, price, dateTime of the order, clientID, and the assetID or assetSymbol.</p>



<pre><code>OrderID = sha256(bytes(qty)||bytes(price)||bytes(dateTime)||bytes(clientID)||bytes(assetID))</code></pre>



<h4 id="data-format">Data format and ID Generation</h4>



<p>While the scheme above for ID generation works, it has a certain drawback. For every type of objects, a developer would have to write an ID generator. This is not desirable. For a majority of the types of objects, the id generator should just be available easily. For this, the object itself can be serialised and the serialised stream of bytes can be hashed.</p>



<p>It is important to note that text based data structures like JSON, XML are not very well suited for this. The main reason behind this is that adding a space or TAB within the document will not alter the data for JSON or XML, however will yield a totally different hash value and therefore a totally different object ID. Hence, it is better to use serialisation formats designed for cross platform, multiple language environments and are deterministic. Compact data serialisation like <a rel="noreferrer noopener" href="https://developers.google.com/protocol-buffers" target="_blank">protocol buffers</a>, <a rel="noreferrer noopener" href="https://google.github.io/flatbuffers/" target="_blank">FlatBuffers</a>, <a rel="noreferrer noopener" href="https://avro.apache.org/" target="_blank">Apache Avro</a> and even <a rel="noreferrer noopener" href="https://tools.ietf.org/html/rfc7049" target="_blank">CBOR</a> are much better suited for this.</p>



<h2 id="immutability">Immutability and Verifiability</h2>



<p>Software professionals often jump to Blockchain to achieve immutability even in a non-adversarial environment like most business applications. Any party explicitly trying to cheat would face the court, and fraudulent transactions can be reverted in the most common business applications seen throughout the world. Therefore, there is no need for all the complexity and consensus algorithms like proof-of-work or proof-of-stake. Even on DLTs there are algorithms like Raft which are used to achieve consensus. Although much lesser in the power consumption, raft could still be an overkill for some …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/">https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/</a></em></p>]]>
            </description>
            <link>https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221324</guid>
            <pubDate>Mon, 22 Feb 2021 05:55:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worlds Beyond Ours: Extending human habitability to outer space]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26221303">thread link</a>) | @brandonlc
<br/>
February 21, 2021 | https://www.noemamag.com/worlds-beyond-ours/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/worlds-beyond-ours/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				<div>
  <p>Credits</p>
  <p>Claire Isabel Webb is a historian and anthropologist of science, and a 2020-21 Berggruen Institute fellow.</p>
</div>


<p>Consider a trio of moments of entangled spacetime:</p>



<p>Jan. 7, 2021, cyberspace and Washington, D.C.: A staggering 4,112 people <a href="https://www.nytimes.com/2021/01/18/us/coronavirus-deaths.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">die</a> of the coronavirus in America, a new record. Elon Musk becomes the richest person in the world and reiterates his plan to leave Earth and start a colony on Mars.</p>



<p>Dec. 7, 1972, near-Earth orbit: The crew of <a href="https://svs.gsfc.nasa.gov/vis/a000000/a002600/a002680/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Apollo 17</a>, 18,000 miles from home and on their way to the moon, snap a photograph of Earth. Illuminated by the sun and nestled in the sable sea of outer space, the “Blue Marble” image becomes a resonant icon of humans’ dear and fragile life-filled planet. Earth’s denizens wonder: Are there other worlds beyond? Or is this the only example of life in the universe?</p>



<p>Nov. 7, 1957, Calcutta, India: Two prominent biologists, Joshua Lederberg and J.B.S. Haldane, meet for dinner. A month earlier, the Soviet Union had launched Sputnik I, the first artificial satellite to orbit Earth. Lederberg and Haldane <a href="https://profiles.nlm.nih.gov/spotlight/bb/catalog/nlm:nlmuid-101584906X13253-doc" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">determine</a> that a thermonuclear bomb detonated on the moon would be visible to Earthlings, and it would be so destructive it would spoil the possibility of finding traces of lunar life.</p>



<p>Lifted from three interspaced epochs of the ongoing Space Age — the COVID-19 pandemic, the environmental movement and the Cold War — those moments reveal how terrestrial troubles are entwined with hopes of discovering life, and of living, beyond Earth. As dreams to explore the cosmos curl skyward, fears and anxieties particular to each moment raise doubts not only about humans’ longevity on our home planet, but also about how we might inhabit and sustain life on other worlds as space-faring explorers. If humans self-destruct through nuclear war, poison the planet by churning out carbon into the atmosphere or fail to control a deadly virus, such events would preclude us from existing on Earth, living long enough to communicate with possible extraterrestrial beings and venturing to other worlds we might discover to be habitable.</p>



<p>Thus, fears of terrestrial apocalypse animate pursuits for life and living beyond Earth. But conversely, imagining how life (including human life) might exist in an extraterrestrial context, and seeing the planet from outer space, has driven imaginations of Earth’s possible futures — both hopeful, course-correcting pathways, but also escapist fantasies of extraplanetary colonization.</p>



<p>Anticipations of worlds <em>beyond</em> Earth — places that might be (or might be made to be) habitable — are made possible by conceiving <em>of</em> Earth as both threatened and interconnected: The coronavirus’s march across the world reveals the viruses’ disregard for political borders, the environmental movement highlighted the fragility of the planet’s entangled life and the Cold War ushered in the concept of global nuclear disaster.</p>



<p>These threats have, in different ways, revealed how actions are never self-contained in global, networked systems. Each moment’s particular planetary anxieties — pathogenic, climate, nuclear — have animated and informed scientists’ pursuit of extraterrestrial life.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Information on whether a complete lifecycle can occur in space would also have obvious implications for the feasibility of eventual colonization of space.”    </p>

          
    
    
  </div>
</div>




<h5><strong>Annihilation</strong></h5>



<p>On Oct. 4, 1957, Sputnik I streaked across the sky. Touching off the “space race” between the United States and the Soviet Union, the satellite represented the opposition between democracy and communism. “Artificial earth satellites will pave the way to interplanetary travel,” the Communist Party’s official newspaper <a href="https://history.nasa.gov/sputnik/14.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">announced</a> the following day, and “our contemporaries will witness how the freed and conscientious labor of the people of the new socialist society makes the most daring dreams of mankind a reality.”</p>



<p>Sputnik I was particularly visible from the southern hemisphere, where Nobel Prize-winning microbiologist Joshua Lederberg happened to be traveling. A month later, on his way back to Stanford University, where he taught and researched, Lederberg passed through Calcutta to visit his friend and collaborator J.B.S. Haldane. Haldane had formulated the “<a href="https://www.uv.es/~orilife/textos/Haldane.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">primordial soup</a>” model — how life could have originated from <span data-note="Abiogenic means not produced by the activity of living organisms; abiogenesis is the process by which life could have evolved from non-living materials.">abiogenic</span> materials on an ancient Earth. Both scientists looked forward to that night’s lunar eclipse.</p>



<p>Over dinner, Haldane — a “confirmed Communist” and “radical alternativist,” according to Lederberg — “gloated” that it was also the 40<sup>th</sup> anniversary of the October Revolution, the event that had precipitated the formation of the Soviet Union. As a thought experiment, the two scientists wondered: What if the Soviets leveraged the symbolic occasion to plant a “red star” — a nuclear bomb — on the moon? Their back-of-the-napkin calculation revealed that it would be visible from Earth.</p>



<p>Of course, there was no “red star” that evening, and the U.S. astronauts of the Apollo 11 mission, not Soviet cosmonauts, would be the first to land on the moon twelve years later, in 1969. But the conversation with Haldane about the possibility for off-Earth atomic destruction spurred Lederberg toward the study of “exobiology,” the search to detect and preserve life beyond Earth. As the U.S. and the Soviet Union’s space race accelerated during the Cold War, the National Academy of Sciences established the Space Science Board (SSB) to research outer space and to recommend policies to NASA. That group, which included Lederberg and other prominent scientists (among them a young Carl Sagan), worked to protect the moon and other extraterrestrial sites as scientific laboratories.</p>



<p>Looking ahead to possible NASA missions that would explore Mars and Venus for traces of life, a 1959 SSB report that Lederberg chaired transported Cold War fears of nuclear war on Earth to celestial bodies beyond. It warned that “the effect of introducing radioactivity on another planet where there may be entirely different levels of background radiation from those found on Earth could greatly influence any form of life found there.” Planetary concerns of atomic fallout migrated to unexplored sites beyond our planet.</p>



<p>In addition to nuclear radiation on other planets, the possibility of microbial contamination presented risks in the search for life beyond Earth. A spacecraft landing on Mars, for example, might bring terrestrial hitchhikers, risking a false detection of organic biochemistry that would muddle attempts to theorize the origin of life in the solar system and possibly the cosmos beyond. Throughout the late 1950s and the 60s, exobiologists’ reports urged sterilization protocols be taken so as to preserve possible “planetary biota” on Mars.</p>



<p>At the same time, exobiologists worried that possible Martian microbes might infect Earth; through incautious activity by either the U.S. or the Soviet Union, a “dramatic hazard would be the introduction of a new disease, imperiling human health,” as Lederberg wrote in 1960. This particular threat took center stage in Michael Crichton’s 1969 science fiction book (and subsequent film) “The Andromeda Strain,” in which a mysterious and fatal extraterrestrial microorganism appears in Arizona and threatens to end life on Earth. Merging apocalypses, the characters consider annihilating the infected laboratory with a nuclear bomb.</p>



<p>Civilian scientists’ goals to detect extraterrestrials were often <a href="https://www.jstor.org/stable/10.1086/344962?seq=1" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">at odds</a> with those of the national agencies they answered to. While John F. Kennedy’s 1962 “<a href="https://er.jsc.nasa.gov/seh/ricetalk.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">We choose to go to the moon</a>” speech mandated the priority of manned missions to outer space that would showcase national prestige, exobiologists advocated for international efforts to preserve (extra)terrestrial life forms. A 1961 SSB report suggested that the U.S. and the Soviet Union work together on sterilization protocols to “simplify the problem of protection against possible contamination of the planets and of the Earth.” The planetary struggle for political dominance, which threatened to plunge Earth into a nuclear apocalypse, was thus shaping extraplanetary pursuits.</p>



<p>As they considered Earth and extraterrestrial sites of possible life (Mars’s subsurface, Venus’s atmosphere and even, possibly, the moon’s dust) in tandem, exobiologists began to imagine interconnected, but distinct, planetary wholes. Linking Earth to planets beyond, two exobiologists wrote in a 1961 <a href="https://www.nap.edu/read/12425/chapter/1" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">report</a>, “The planets of the solar system are part of a whole — in their origins, in their present states and in their futures.” Such exercises that forecasted other worlds soon came to intersect with growing concerns about the fragility of our own planet.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Musk has reshuffled space exploration: individualism over nationalism, money power over patriotism, the adventure or even salvation of the few over the many.”    </p>

    
    
  </div>
</div>




<h5><strong>Interconnection</strong></h5>



<p>Amid the persistent threat of nuclear apocalypse that defined the Cold War era, exobiologists began to call for planetary protection protocols for both Earth and extraterrestrial sites — concerns that became increasingly aligned with a burgeoning consciousness about humans’ harmful activities on Earth. Rachel Carson’s 1962 book “Silent Spring” introduced the idea that synthetic chemicals, especially pesticides — which she <a href="https://archive.nytimes.com/www.nytimes.com/books/97/10/05/reviews/carson-obit.html?_r=2" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">argued</a> should be called “biocides” — were fundamentally altering life on Earth. The ensuing environmental movement of the 1960s and 70s culminated in the creation of the U.S. Environmental Protection Agency and made “the environment” a widespread public concern, fortifying the concept that life systems were interconnected, malleable and fragile.</p>



<p>Stewart Brand’s “Whole Earth Catalog” often advocated for ecological issues and <a href="https://www.noemamag.com/the-origins-of-planetary-realism-and-whole-earth-thinking/" data-wpel-link="internal">featured</a> images of Earth from space on its early covers, from a mosaic made of satellite photos to Apollo 8’s “Earthrise.” Images of Earth from outer space cast it as a planetary …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/worlds-beyond-ours/">https://www.noemamag.com/worlds-beyond-ours/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/worlds-beyond-ours/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221303</guid>
            <pubDate>Mon, 22 Feb 2021 05:50:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multiplexing Multipath P2P Mobile Transports]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220942">thread link</a>) | @bigfish24
<br/>
February 21, 2021 | https://www.ditto.live/blog/posts/the-new-network-multiplexer | <a href="https://web.archive.org/web/*/https://www.ditto.live/blog/posts/the-new-network-multiplexer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><nav aria-label="breadcrumb"><ol><li><a href="https://www.ditto.live/">Home</a></li><li><a href="https://www.ditto.live/blog/posts">Blog</a></li><li><a href="https://www.ditto.live/blog/posts/the-new-network-multiplexer">The New Network Multiplexer </a></li></ol></nav><p>Since the first versions of Ditto, devices always made multiple connections to other peers. For example, two iOS devices will try to connect simultaneously over WiFi, Apple Wireless Direct Link (AWDL), and Bluetooth Low Energy (BLE). We make multiple connections because each transport has different characteristics such as throughput and distance. For example, Bluetooth Low Energy works over long distances but has little bandwidth. AWDL has much more bandwidth but the devices need to be close together.</p>
<p>In the example below we see two iPhones syncing over AWDL and BLE. As one device gets further from the other, the AWDL connection will degrade and disconnect while the BLE connection sustains longer distances.</p>

<h2 id="pre-version-1.0.0">Pre-Version 1.0.0</h2>
<p>Before version 1.0.0, Ditto created a unique replication session for every transport. This is the software component which tracks queries and data changes and ensures that every Ditto device stays in sync. These separate replication pathways can appear or disappear as connections come and go, without disrupting sibling sessions.</p>
<p>When there is new data to sync, a session packs that data into an update file. With multiple concurrent sessions, all of them would then race against each other to transmit that update file as quickly as possible, regardless of duplication between transports. Transactional locking on the internal database made sure that only one session at a time could modify the update file, which prevented race conditions. Since any session is able to maintain the update file, any individual session can fail and replication will always continue, providing a high level of reliability.</p>
<p><img src="https://www.ditto.live/assets/blog/posts/the-new-network-multiplexer/old-way.svg" alt="old-way-sessions"></p>
<p>In this benchmark we see the consequences of each session sending data eagerly over every transport. In an attempt to send a document with about 2 megabytes of data, all five connected modes of transport aggressively sent data as fast as they could. We can see that the highly efficient AWDL transports could send all bytes first, and the remote peer quickly notified the slower connections that they could stop. However, the slower transports had already sent duplicate bytes. In the end, the peer had sent 5.4 megabytes even though the document size was about 2 megabytes. This was 2.6 times larger than the initial payload. Furthermore, this fully occupied the BLE radio, consuming bandwidth that could have been better used by a Bluetooth-only peer.</p>
<div>
  <table>
    <thead>
      <tr>
        <th>Transport</th>
        <th>Bytes Sent</th>
        <th>Packets Sent</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>AWDL Client</td>
        <td>2097944</td>
        <td>33</td>
      </tr>
      <tr>
        <td>AWDL Server</td>
        <td>2097944</td>
        <td>33</td>
      </tr>
      <tr>
        <td>BLE Client</td>
        <td>12288</td>
        <td>16</td>
      </tr>
      <tr>
        <td>BLE Server</td>
        <td>12288</td>
        <td>16</td>
      </tr>
      <tr>
        <td>TCP Server</td>
        <td>1170432</td>
        <td>36</td>
      </tr>
      <tr>
        <td>Grand Total</td>
        <td>5390896</td>
        <td>134</td>
      </tr>
    </tbody>
  </table>
</div>


<p>In version 1.0.0, we’ve introduced a completely new system for creating sync sessions between peers we call the multiplexer. Our first order of business was to reduce the duplication of sessions to the same peer over multiple transport types. We’ve introduced the concept of a virtual connection between two peers. No matter how many transport connections are active, there will only be one virtual connection and only one session. Now incoming data is buffered and intermediated from the transport layer to a single virtual connection.</p>
<p><img src="https://www.ditto.live/assets/blog/posts/the-new-network-multiplexer/new-way.svg" alt="new-way-multiplexer"></p>
<p>This new architecture allows each virtual connection to intelligently send data over multiple physical transports with fine-grained control. For example, the multiplexer can switch active transports on the fly without unnecessary duplication.</p>
<p>In this example:</p>
<ol>
<li>The multiplexer on the left device deemed that TCP (WiFi) was the best transport to start sending data.</li>
<li>Suddenly, the infastructure WiFi goes out, and the multiplexer switches to AWDL.</li>
<li>As the device moves away from its peer, AWDL is lost and the multiplexer switches to BLE.</li>
<li>The devices move closer together and the multiplexer finishes the rest of the transmission over AWDL.</li>
</ol>

<p>Now the total bytes sent is equal to the size of the update file.</p>
<div>
  <table>
    <thead>
      <tr>
        <th>Transport</th>
        <th>Bytes Sent</th>
        <th>Packets Sent</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>AWDL Client</td>
        <td>524288</td>
        <td>8</td>
      </tr>
      <tr>
        <td>AWDL Server</td>
        <td>234264</td>
        <td>4</td>
      </tr>
      <tr>
        <td>BLE Client</td>
        <td>0</td>
        <td>0</td>
      </tr>
      <tr>
        <td>BLE Server</td>
        <td>421888</td>
        <td>206</td>
      </tr>
      <tr>
        <td>TCP Server</td>
        <td>917504</td>
        <td>28</td>
      </tr>
      <tr>
        <td>Grand Total</td>
        <td>2097944</td>
        <td>246</td>
      </tr>
    </tbody>
  </table>
</div>

<p>The introduction of the multiplexer is a gigantic step forward for Ditto's networking capabilities. Today, it focuses on using one transport at a time but this new foundation allows us to build even more powerful, dynamic and flexible replication techniques such as using multiple transports at a time over unreliable connections, streaming use cases, and decentralized data sync techniques reminiscent of BitTorrent.</p>
</div></div></div>]]>
            </description>
            <link>https://www.ditto.live/blog/posts/the-new-network-multiplexer</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220942</guid>
            <pubDate>Mon, 22 Feb 2021 04:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API vs. SDK explained in restaurant terms]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26220862">thread link</a>) | @alexander_kir
<br/>
February 21, 2021 | https://www.amity.co/blog/api-vs-sdk-which-is-which | <a href="https://web.archive.org/web/*/https://www.amity.co/blog/api-vs-sdk-which-is-which">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Software Development Kits (SDK) and Application Programming Interface (API) are critical components of your app’s development. However, these two terms sometimes overlap, often leading to confusion.&nbsp;<br></p><p>Knowing their differences and how you can take advantage of them can significantly help you improve your application. This piece tackles their distinct features and outlines how you can utilize them to supercharge your app.&nbsp;<br></p><h3><strong>What is an API?&nbsp;&nbsp;</strong></h3><p>By definition, APIs are sets of instructions and protocols used to integrate specific functionalities into an application. An API can help connect your apps or projects to external services, enabling seamless data transfer and adding a new feature altogether.&nbsp;<br></p><p>Let’s take a look at this example from software company <a href="https://www.mulesoft.com/resources/api/what-is-an-api">Mulesoft</a> explaining the function of an API:&nbsp;&nbsp;</p><blockquote><em>Imagine you’re sitting at a table in a restaurant with a menu of choices to order from. The kitchen is the part of the “system” that will prepare your order. What is missing is the critical link to communicate your order to the kitchen and deliver your food back to your table. That’s where the waiter or API comes in. The waiter is the messenger – or API – that takes your request or order and tells the kitchen – the system – what to do. Then the waiter delivers the response back to you; in this case, it is the food.</em><br></blockquote><p>With an API, developers don’t have to worry about creating lots of custom code to enable functionalities, as various APIs exist to fulfill a specific function. As <a href="https://www.ibm.com/cloud/learn/api?utm_medium=OSocial&amp;utm_source=Youtube&amp;utm_content=000023UA&amp;utm_term=10010608&amp;utm_id=YTDescription-101-API-vs-SDK-LH-API-Guide&amp;cm_mmc=OSocial_Youtube-_-Cloud+and+Data+Platform_SFT+Cloud+Platform+Digital-_-WW_WW-_-YTDescription-101-API-vs-SDK-LH-API-Guide&amp;cm_mmca1=000023UA&amp;cm_mmca2=10010608">IBM</a> mentioned, APIs allow companies to open up their applications’ data and functionality for third-party developers to use. So if you have a food delivery app and want to verify your user’s number, provide the location, and enable payment without leaving the platform, there’s an available phone, maps, and payment API to perform these actions.&nbsp;<br></p><h3><strong>What is an SDK?&nbsp;</strong></h3><p>On the other hand, SDKs are a set of tools used to develop applications for a specific platform. <a href="https://www.redhat.com/en/topics/cloud-native-apps/what-is-SDK">Red Hat</a> mentioned that a typical SDK contains a compiler, debugger, as well as APIs, and any of the following:<br></p><ul role="list"><li>Documentation</li><li>Libraries</li><li>Editors</li><li>Runtime/development environments</li><li>Testing/analysis tools</li><li>Drivers</li><li>Network protocols<br></li></ul><p>Let’s take the restaurant scenario again. For example, you are a chef. When you’re cooking a dish, you will need ingredients for your recipe; you need the kitchen utensils so you can cook, you need a copy of a recipe to put the meal together, and so on. In the same way, SDK provides all the things you need to create your intended application.&nbsp;<br></p><p>SDKs are crucial when developing an app for a specific platform. For instance, Apple provides iOS SDKs to developers so they can create applications specifically for iOS. An SDK should add value to a developer. Hence it should be easy to use, provides a thorough explanation of the code used, and adds functionality to an existing app.&nbsp;<br></p><h4><strong>Things to remember&nbsp;</strong></h4><p>Now that we defined both, let us recap:&nbsp;<br></p><ul role="list"><li>APIs facilitates the communication and integration of software</li></ul><ul role="list"><li>SDK provides the foundation to build an application specifically for a platform</li></ul><ul role="list"><li>SDKs contain APIs; APIs don’t contain SDKs<br></li></ul><p>API, as a part of an SDK, is lightweight and specialized based on the function intended. Meanwhile, SDKs have a collection of utilities to create a new application or add new functionalities.&nbsp;<br></p><h3><strong>API and SDK can elevate your app&nbsp;</strong></h3><p>Now that we know the differences, how can you take advantage of both to improve your app?&nbsp;<br></p><p>Utilizing SDKs with the APIs that meet your needs can significantly enhance your application’s functionality. According to <a href="https://marketfinder.thinkwithgoogle.com/intl/en/guide/improve-ux-ui-of-app/#overview">Google</a>, mobile users spend nine out of ten minutes using only their top five favorite apps. So how can your app be one of their top five?&nbsp;&nbsp;<br></p><p>SDKs can enable powerful in-app features with the corresponding APIs that will substantially affect your app’s user experience. With so many apps out there, you would want yours to stand out in the app market.&nbsp;<br></p><p>And of course, you just don’t want users to download your app; you would like them to keep and share it with their peers, creating a loyal fanbase for your application.&nbsp;<br></p><p>If you are a brand and you aim to engage and retain your users, adding <a href="https://www.amity.co/blog/remain-competitive-by-adding-social-features-to-your-app">social features with an SDK </a>to your app can help raise user engagement through <a href="https://www.amity.co/blog/building-your-in-app-community-why-it-matters">in-app groups.</a> Meanwhile, integrating chat SDK into your application can facilitate 1-on-1 conversations or group interactions, allowing you to host online communities.&nbsp;<br></p><p><a href="https://www.amity.co/products/amity-video">Video SDKs</a> can help you integrate in-app live streaming and stories to your product if you have an entertainment application.&nbsp; So whether it’s a sports event or a concert broadcasted in your app, this solution can help bring throngs of fans to use your application. On the other hand, if your SDK has a <a href="https://www.amity.co/products/amity-bots">chatbot</a> API that can collect user data, you can use the information you have to create a more personalized user experience, push tailored notifications, and deliver the right content to your users.<br></p><p>In conclusion, API and SDK, regardless of their differences, can both be beneficial for your application. Using SDK with the right APIs can create numerous possibilities to improve your application. Now is the time to find the best SDKs to enhance your in-app user experience, engagement, and retention.&nbsp;<br></p></div></div>]]>
            </description>
            <link>https://www.amity.co/blog/api-vs-sdk-which-is-which</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220862</guid>
            <pubDate>Mon, 22 Feb 2021 04:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning a wireless keyboard into a wired keyboard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220556">thread link</a>) | @todsacerdoti
<br/>
February 21, 2021 | https://chadaustin.me/2021/02/wired-sculpt/ | <a href="https://web.archive.org/web/*/https://chadaustin.me/2021/02/wired-sculpt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I made a control board for the Microsoft Sculpt wireless keyboard that converts it to wired USB, and now my favorite keyboard is even better.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/finished-board.jpeg"><img src="https://chadaustin.me/images/sculpt/finished-board.jpeg" alt="The finished and installed board."></a>
<figcaption>The finished and installed board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/messy-desk.jpeg"><img src="https://chadaustin.me/images/sculpt/messy-desk.jpeg" alt="Wired keyboard and the resulting project mess!"></a>
<figcaption>Wired keyboard and the resulting project mess!</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/underside.jpeg"><img src="https://chadaustin.me/images/sculpt/underside.jpeg" alt="USB cable and reset button."></a>
<figcaption>USB cable and reset button.</figcaption>
</figure>

<p>The QMK config is available at <a href="https://github.com/chadaustin/qmk_firmware">@chadaustin/qmk_firmware</a> (<a href="https://github.com/chadaustin/qmk_firmware/tree/master/keyboards/handwired/sculpt">keyboards/handwired/sculpt/</a>), and the PCB design files at <a href="https://github.com/chadaustin/wired-sculpt-pcb">@chadaustin/wired-sculpt-pcb</a>.</p>

<p>I’m planning on making at least one more, so if you’d like one, maybe I can help.</p>

<p>It’s a huge improvement. Latency is reduced by about 13 milliseconds, and with full control over the microcontroller’s firmware, you can customize keymaps and layers, and actually use the keyboard’s built-in LEDs.</p>

<h2 id="why">Why?</h2>

<p>Feel free to stop reading here — I am going to tell the sequence of events that led to this project. Besides some exposure to basic voltage and resistance circuits in college, I have very little electronics background. But, in a short time, I went from only barely knowing what a capacitor was to having a working PCB manufactured and assembled, and maybe this will inspire someone else to give it a try.</p>

<p>Since developing RSI in college, I’ve exclusively used Microsoft’s ergonomic keyboards. And when I first tried the Sculpt, I instantly knew it was the best yet. The soft actuation, short key travel, and rigid frame are perfect for my hands. And because the number pad is a separate device, the distance to my mouse is shortened.</p>

<p>My brother went out and bought one too. Not much later, he gave it to me, saying the latency was inconsistent and high, and it was unacceptable for gaming. I thought he was being uniquely sensitive, since I had no problem in either Linux, Windows 7, or macOS. But then I updated to Windows 10 and saw exactly what he meant.</p>

<p>It was like the keyboard would go to sleep if a key wasn’t pressed for a few seconds, and the first keypress after a wake would be delayed or, worse, dropped.</p>

<p>And heaven forbid I use my USB 3 hub, whose EMI would disrupt the 2.4 GHz signal, and <em>every other</em> keypress would be unreliable. I’d gone as far as mounting the wireless transceiver directly under my keyboard, on the underside of my desk, and keys were still dropped.</p>

<p>So, best keyboard ever. But wireless sucks. (But mostly in Windows 10? No idea about that.)</p>

<h2 id="over-the-hump">Over the Hump</h2>

<p>What started this whole thing is that the <a href="https://github.com/facebookexperimental/eden/#edenfs">EdenFS</a> team was a bunch of keyboard enthusiasts. During the pandemic, as we’re all at home burning out and missing each other, we were trying to think of some virtual team offsites. Wez offered to walk everyone through building a <a href="https://www.1upkeyboards.com/instructions-downloads/sweet-16-instructions/">Sweet 16 Macro Pad</a>.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/sweet-16.jpeg"><img src="https://chadaustin.me/images/sculpt/sweet-16.jpeg" alt="Assembled Sweet 16 underside"></a>
<figcaption>Assembled Sweet 16 underside. This is take two, after resoldering and cleaning the whole thing. Take one was a bit of a mess.</figcaption>
</figure>

<p>So, okay, a keyboard is a matrix, with some diodes used to disambiguate the signalling, and a microcontroller that rapidly polls the matrix and reports events over USB…</p>

<p>So maybe I could fix the Sculpt! I bought a transceiver-less Sculpt off eBay for cheap and <a href="http://emmanuelcontreras.com/how-to/how-to-disassemble-microsoft-sculpt-ergonomic-keyboard-and-make-it-wired/">popped it open (thanks Emmanuel Contreras!)</a>, thinking maybe its controller could be flashed with new firmware that speaks USB. The Sculpt uses a <a href="https://infocenter.nordicsemi.com/pdf/nRF24LE1_PS_v1.6.pdf">Nordic Semiconductor nRF24LE1</a>, but I was nowhere near capable of making use of that information at the time, though it did point me to Samy Kamkar’s horrifying guide on <a href="https://samy.pl/keysweeper/">surreptitiously sniffing keystrokes from nearby (older) Microsoft wireless keyboards</a>.</p>

<p>I almost gave up here, but Per Vognsen <a href="https://twitter.com/pervognsen/status/1322422385174220800">suggested I scan the matrix myself</a> and it turns out Michael Fincham had already <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/bhkgnp/modification_photos_qmk_wired_microsoft_sculpt/">mapped out the matrix and soldered a Teensy 2.0++ board onto the Sculpt’s test pads</a>, showing this was doable!</p>

<p>So I ordered my own microcontroller to try the same thing.</p>

<p>First, I bought an Arduino Pro Micro, like the Sweet 16 uses. Oh hey, 18 GPIO pins isn’t enough to drive the Sculpt’s 26-pin matrix. I looked at using an I2C GPIO expander, but it felt like taking on too much.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pro-micro.jpeg"><img src="https://chadaustin.me/images/sculpt/pro-micro.jpeg" alt="Arduino Pro Micro"></a>
<figcaption>Arduino Pro Micro. Wait, you need pins to scan a matrix?</figcaption>
</figure>

<p>More pins? QMK’s Proton C has more pins! So I carefully soldered onto the test pads as Michael had shown was possible… and it worked!</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/proton-c.jpeg"><img src="https://chadaustin.me/images/sculpt/proton-c.jpeg" alt="QMK Proton C"></a>
<figcaption>QMK Proton C. It's a beautiful board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/test-pads.jpeg" alt="Soldering test pads to Proton C."></a>
<figcaption>Soldering test pads to Proton C.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/all-test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/all-test-pads.jpeg" alt="All test pads connected to Proton C. It works!"></a>
<figcaption>All test pads connected to Proton C. It works!</figcaption>
</figure>

<p>Getting those wires to stick to the pads without shorting was tricky. (I hadn’t yet discovered how magical flux is.)</p>

<p>The keyboard worked, but I couldn’t fit the board, its wires, and the new microcontroller into the case, and I wasn’t <em>really</em> happy leaving it in this state, even if I could pack it in somehow.</p>

<p>I thought, all I <em>really</em> need is the ribbon cable connector, so I ordered a 30 pin, 1.0 mm pitch ribbon breakout and the pricier (but tons of pins!) <a href="https://www.pjrc.com/store/teensypp.html">Teensy 2.0++</a>. Looking back, it’s cute that I was trying to save $10 on the microcontroller… You just have to get used to spending money on whatever saves you time.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg"><img src="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg" alt="Ribbon cable breakout and Teensy 2.0++"></a>
<figcaption>Ribbon cable breakout and Teensy 2.0++</figcaption>
</figure>

<p>Well, it was almost as annoying to solder, and still didn’t fit. So much for saving money on microcontrollers.</p>

<p>I thought about giving up. Is it really that bad that my keys don’t always register in games? Can I just tolerate some flakiness and latency?</p>

<p>But Jon Watte offered to spend an entire day showing me how to use KiCad, design circuits, layout PCBs, select components on Digi-Key, scan datasheets for the important information, and how to work with a PCB manufacturing house. Of course you never turn down opportunities like that.</p>

<h2 id="designing-the-final-board---schematic">Designing the Final Board - Schematic</h2>

<p>Assuming, like me, you’ve never done this, I’ll summarize the steps.</p>

<p>First you sketch out the circuit schematic.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/schematic.png"><img src="https://chadaustin.me/images/sculpt/schematic.png" alt="Schematic"></a>
<figcaption>Schematic in KiCad. Most of this was informed by the datasheet and Atmel's design guides.</figcaption>
</figure>

<p>Jon showed me several tricks in KiCad, like global labels, and starting with some standard resistor and capacitor values, but it’s very important that you go through the datasheets, because details can matter a ton.</p>

<p>I knew I wanted the main processor to be the AT90USB1286 controller, and fortunately KiCad already had a symbol for it. Atmel has a comprehensive and accessible data sheet, which showed me I needed some 22 Ω resistors on the USB data lines, which of the ISP programmer lines needed resistors (and appropriate values), and that I needed to either pull HWB low, or provide a physical switch that pulls it low, in order to allow rebooting the device into USB firmware update mode.</p>

<p>There are a bunch of things that are implicitly known to electrical engineers but that were new to me. You want:</p>

<ul>
  <li>a ground plane under the data lines and most of the microcontroller if possible.</li>
  <li>an electrolytic or tantalum bypass capacitor on the main 5V power from USB.</li>
  <li>ceramic filter capacitors on each power pin.</li>
  <li>appropriate values for the resonance capacitors on your crystal.</li>
  <li>electrostatic discharge protection! Turns out transients are common and it’s easy to fry a chip just by plugging it in.</li>
</ul>

<p>And then when you get into concerns like EMI and high-frequency signal integrity, the rabbit hole goes deep.</p>

<p>I kept having to tell myself “it’s just a keyboard”, but it also helped that there are a great number of high-quality resources on these topics just a click away. I spent lots of time on <a href="https://www.eevblog.com/">EEVBlog</a>.</p>

<p>Before finishing the circuit design, Jon had me do a couple smart things. In case the factory-supplied USB bootloader didn’t work out, he suggested I add the footprint (but not a connector!) for an ISP programmer and a debug LED to prove code would work at all.</p>

<h2 id="designing-the-final-board---physical-layout">Designing the Final Board - Physical Layout</h2>

<p>After arranging the schematic and ensuring it passed the electrical rules check, it was time to pick specific components. That is, the reference to a 220 Ω resistor is replaced with the Panasonic ERJ-3EKF2200V, 0603 surface mount.</p>

<p>There are a couple things to keep in mind. For common components, like resistors and ceramic capacitors, there is a huge amount of choice. For example, I see over 1400 surface-mount 220 Ω resistors on digikey. I tried to just stick with one high-quality brand like Panasonic or Samsung for all of that stuff.</p>

<p>The important thing is the physical form factor, which determines the footprint on the board. Once you pick a part, it has a size, and you need to tell KiCad which physical footprint should be assigned to that component. I used 0603 resistors, so I assigned each resistor in the schematic the “Resistor_SMD:R_0603_1608Metric” footprint.</p>

<p>Same for everything else. Jon showed me how to draw my own footprints, but to avoid complexity, I was able to find appropriate footprints in KiCad’s standard libraries for every component I needed.</p>

<p>When you import the schematic into Pcbnew, it’s time to figure out where things go. Where are the edges of the board? Make careful measurements here. Where do the mounting holes go? Where do you want 
the microcontroller? Where do you want the USB port?</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/dimensions.jpeg"><img src="https://chadaustin.me/images/sculpt/dimensions.jpeg" alt="Measuring dimensions and mounting holes"></a>
<figcaption>Measuring dimensions and mounting holes</figcaption>
</figure>

<p>Also, you have to pick through-hole sizes and trace widths. Jon had me use .250 mm for the narrow traces and .500 mm for the wider ones, presumably from experience. I used the narrow traces for signalling and wide traces for power, though I’ve since heard it’s a good idea to use narrow traces between filter capacitors and VBUS.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pcb-layout.svg"><img src="https://chadaustin.me/images/sculpt/pcb-layout.svg" alt="Schematic"></a>
<figcaption>PCB layout in KiCad</figcaption>
</figure>

<p>Of course, there’s some iteration between the schematic and the PCB. After physically placing the ribbon cable connector and MCU, the traces all crossed over each other, so I had to reassign all the pins so it made sense physically.</p>

<p>There are also physical constraints about how USB data lines are run, and how the electrostatic protection chip wants to be placed for the most protection.</p>

<p>So, as simple as this board is, I spent a fair amount of time getting all of that right.</p>

<p>I found myself getting lost in the abstractness of holes and traces and footprints, so it was helpful to ground myself by occasionally loading the PCB in KiCad’s 3D viewer.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/3d-view.png"><img src="https://chadaustin.me/images/sculpt/3d-view.png" alt="Schematic"></a>
<figcaption>3D View</figcaption>
</figure>

<h2 id="designing-the-final-board---manufacturing-and-testing-physical-fit">Designing the Final Board - Manufacturing and Testing Physical Fit</h2>

<p>I tried to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chadaustin.me/2021/02/wired-sculpt/">https://chadaustin.me/2021/02/wired-sculpt/</a></em></p>]]>
            </description>
            <link>https://chadaustin.me/2021/02/wired-sculpt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220556</guid>
            <pubDate>Mon, 22 Feb 2021 03:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres regex search over 10k GitHub repositories (using only a MacBook)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220446">thread link</a>) | @randomdrake
<br/>
February 21, 2021 | https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories | <a href="https://web.archive.org/web/*/https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In this article, we share empirical measurements from our experiments in using Postgres to index and search over 10,000 top GitHub repositories using <code>pg_trgm</code> on only a Macbook.</p>

<p>This is a follow up to <a href="https://devlog.hexops.com/2021/postgres-trigram-search-learnings">“Postgres Trigram search learnings”</a>, in which we shared several learnings and beliefs about trying to use Postgres Trigram indexes as an alterative to Google’s <a href="https://github.com/google/zoekt">Zoekt</a> (“Fast trigram based code search”).</p>

<p>We share our results, as well as <a href="https://github.com/hexops/pgtrgm_emperical_measurements">the exact steps we performed, scripts, and lists of the top 20,000 repositories by stars/language on GitHub</a> so you can reproduce the results yourself should you desire.</p>

<h2 id="tldr">TL;DR</h2>

<p><strong>This article is extensive and more akin to a research paper than a blog post.</strong> If you’re interested in our conclusions, see <a href="#conclusions">conclusions</a> instead.</p>

<h2 id="goals">Goals</h2>

<p>We wanted to get empirical measurements for how suitable Postgres is in providing regexp search over documents, e.g. as an alterative to Google’s <a href="https://github.com/google/zoekt">Zoekt</a> (“Fast trigram based code search”). In specific:</p>

<ul>
  <li>How many repositories can we index on just a 2019 Macbook Pro?</li>
  <li>How fast are different regexp searches over the corpus?</li>
  <li>What Postgres 13 configuration gives best results?</li>
  <li>What other operational effects need consideration if seriously attempting to use Postgres as the backend for a regexp search engine?</li>
  <li>What is the best database schema to use?</li>
</ul>

<h2 id="hardware">Hardware</h2>

<p>We ran all tests on a 2019 Macbook Pro with:</p>

<ul>
  <li>2.3 GHz 8-Core Intel Core i9</li>
  <li>16 GB 2667 MHz DDR4</li>
</ul>

<p>During test execution, few other Mac applications were in use such that effectively all CPU/memory was available to Postgres.</p>

<h2 id="corpus">Corpus</h2>

<p>We scraped <a href="https://github.com/hexops/pgtrgm_emperical_measurements/tree/main/top_repos">lists of the top 1,000 repositories from the GitHub search API</a> ranked by stars for each of the following languages (~20.5k repositories in total):</p>

<ul>
  <li>C++, C#, CSS, Go, HTML, Java, JavaScript, MatLab, ObjC, Perl, PHP, Python, Ruby, Rust, Shell, Solidity, Swift, TypeScript, VB .NET, and Zig.</li>
</ul>

<p>Cloning all ~20.5k repositories in parallel took ~14 hours with a fast ~100 Mbps connection to GitHub’s servers.</p>

<h3 id="dataset-reduction">Dataset reduction</h3>

<p>We found the amount of disk space required by <code>git clone --depth 1</code> on these repositories to be a sizable ~412G for just 12,148 repositories - and so we put in place several processes for further reduce the dataset size by about 66%:</p>

<ul>
  <li>Removing <code>.git</code> directories resulted in a 30% reduction (412G -&gt; 290G, for 12,148 repositories)</li>
  <li>Removing files &gt; 1 MiB resulted in another 51% reduction (290G -&gt; 142G, for 12,148 repositories - note GitHub does not index files &gt; 384 KiB in their search engine)</li>
</ul>

<h2 id="database-insertion">Database insertion</h2>

<p>We <a href="https://github.com/hexops/pgtrgm_emperical_measurements/blob/main/cmd/corpusindex/main.go">concurrently inserted</a> the entire corpus into Postgres, with the following DB schema:</p>

<div><div><pre><code><span>CREATE</span> <span>EXTENSION</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>pg_trgm</span><span>;</span>
<span>CREATE</span> <span>TABLE</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>files</span> <span>(</span>
    <span>id</span> <span>bigserial</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
    <span>contents</span> <span>text</span> <span>NOT</span> <span>NULL</span><span>,</span>
    <span>filepath</span> <span>text</span> <span>NOT</span> <span>NULL</span>
<span>);</span>
</code></pre></div></div>

<p>In total, this took around ~8 hours to complete and Postgres’s entire on-disk utilization was 101G.</p>

<h2 id="creating-the-trigram-index">Creating the Trigram index</h2>

<p>We tried three separate times to index the dataset using the following GIN Trigram index:</p>

<div><div><pre><code>CREATE INDEX IF NOT EXISTS files_contents_trgm_idx ON files USING GIN (contents gin_trgm_ops);
</code></pre></div></div>

<ul>
  <li><strong>In the first attempt, we hit an OOM after 11 hours and 34 minutes.</strong> This was due to a rapid spike in memory usage at the very end of indexing. We used a <a href="https://github.com/hexops/pgtrgm_emperical_measurements#configuration-attempt-1-indexing-failure-oom">fairly aggressive</a> Postgres configuration with a very large max WAL size, so it was not entirely unexpected.</li>
  <li><strong>In the second attempt, we ran out of SSD disk space after ~27 hours</strong>. Notable is that the disk space largely grew towards the end of indexing, similar to when we faced an OOM - it was not a gradual increase over time. For this attempt, we used the excellent <a href="https://pgtune.leopard.in.ua/#/">pgtune</a> tool to reduce our first Postgres configuration as follows:</li>
</ul>

<div><div><pre><code>shared_buffers = 4GB → 2560MB
effective_cache_size = 12GB → 7680MB
maintenance_work_mem = 16GB → 1280MB
default_statistics_target = 100 → 500
work_mem = 5242kB → 16MB
min_wal_size = 50GB → 4GB
max_wal_size = 4GB → 16GB
max_parallel_workers_per_gather = 8 → 4
max_parallel_maintenance_workers = 8 → 4
</code></pre></div></div>
<ul>
  <li><strong>In our third and final attempt, we cut the dataset in half and indexing succeeded after 22 hours.</strong> In specific, we deleted half of the files in the database (from 19,441,820 files / 178GiB of data to 9,720,910 files / 82 GiB of data.) The Postgres configuration used was the same as in attempt 2.</li>
</ul>

<h2 id="indexing-performance-memory-usage">Indexing performance: Memory usage</h2>

<p>In our first attempt, we see the reported <code>docker stats</code> memory usage of the container grow up to 12 GiB (chart shows MiB of memory used over time):</p>

<p><img width="981" alt="image" src="https://user-images.githubusercontent.com/3173176/107313722-56bbac80-6a50-11eb-94c7-8e13ea095053.png"></p>

<p>In our second and third attempts, we see far less memory usage (~1.6 GiB consistently):</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107314104-350ef500-6a51-11eb-909f-2f1b524d29b2.png"></p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107315387-ce3f0b00-6a53-11eb-886c-410f000f73bd.png"></p>

<h2 id="indexing-performance-cpu-usage">Indexing performance: CPU usage</h2>

<p>Postgres’ Trigram indexing appears to be mostly single-threaded (at least when indexing <em>a single table</em>, we test multiple tables later.)</p>

<p>In our first attempt, CPU usage for the container did not rise above 156% (one and a half virtual CPU cores):</p>

<p><img width="982" alt="image" src="https://user-images.githubusercontent.com/3173176/107313915-cc277d00-6a50-11eb-9282-62159a127966.png"></p>

<p>Our second attempt was around 150-200% CPU usage on average:</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107314168-507a0000-6a51-11eb-8a18-ec18752f7f16.png"></p>

<p>Our third attempt similarly saw an average of 150-200%, but with a brief spike towards the end to ~350% CPU:</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107315239-8324f800-6a53-11eb-9a5b-fcc61d1a7b59.png"></p>

<h2 id="indexing-performance-disk-io">Indexing performance: Disk IO</h2>

<p>Disk reads/writes during indexing averaged about ~250 MB/s for reads (blue) and writes (red). Native in-software tests show the same Macbook able to achieve read/write speeds of ~860 MB/s with &lt;5% affect on CPU utilization.</p>

<p><small>Addition made Feb 20, 2021:</small> We ran tests using native Postgres as well (instead of in Docker with a bind mount) and found better indexing and query performance, more on this below.</p>

<p><img width="599" alt="image" src="https://user-images.githubusercontent.com/3173176/106507903-ec6f9e80-6488-11eb-88a8-78e5b7aacfd6.png"></p>

<h2 id="indexing-performance-disk-space">Indexing performance: Disk space</h2>

<p>The database contains 9,720,910 files totalling 82.07 GiB:</p>

<div><div><pre><code>postgres=# select count(filepath) from files;
  count  
---------
 9720910
(1 row)

postgres=# select SUM(octet_length(contents)) from files;
     sum     
-------------
 88123563320
(1 row)
</code></pre></div></div>

<p><strong>Before indexing</strong>, we find that all of Postgres is consuming 54G:</p>

<div><div><pre><code>$ du -sh .postgres/
 54G	.postgres/
</code></pre></div></div>

<p>After <code>CREATE INDEX</code>, Postgres uses:</p>

<div><div><pre><code>$ du -sh .postgres/
 73G	.postgres/
</code></pre></div></div>

<p>Thus, the index size for 82 GiB of text is 19 GiB (or 23% of the data size.)</p>

<h2 id="database-startup-times">Database startup times</h2>

<p>From an operational standpoint, it is worth noting that if Postgres is starting clean (i.e. previous shutdown was graceful) then startup time is almost instantaneous: it begins accepting connections immediately and loads the index as needed.</p>

<p>However, if Postgres experienced a non-graceful termination during e.g. startup, it can take a hefty ~10 minutes with this dataset to start as it goes through an automated recovery process.</p>

<h2 id="queries-executed">Queries executed</h2>

<p>In total, we executed 19,936 search queries against the index. We chose queries which we expect give reasonably varying amounts of coverage over the trigram index (that is, queries whose trigrams are more or less likely to occur in many files):</p>

<table>
  <thead>
    <tr>
      <th>Regexp query</th>
      <th>Matching # files in entire dataset</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>var</code></td>
      <td>unknown (2m+ suspected)</td>
    </tr>
    <tr>
      <td><code>error</code></td>
      <td>1,479,452</td>
    </tr>
    <tr>
      <td><code>123456789</code></td>
      <td>59,841</td>
    </tr>
    <tr>
      <td><code>fmt\.Error</code></td>
      <td>127,895</td>
    </tr>
    <tr>
      <td><code>fmt\.Println</code></td>
      <td>22,876</td>
    </tr>
    <tr>
      <td><code>bytes.Buffer</code></td>
      <td>34,554</td>
    </tr>
    <tr>
      <td><code>fmt\.Print.*</code></td>
      <td>37,319</td>
    </tr>
    <tr>
      <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
      <td>0</td>
    </tr>
    <tr>
      <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<details>
<summary>Detailed breakdown</summary>
<div>

    <table>
      <thead>
        <tr>
          <th>Query</th>
          <th>Result Limit</th>
          <th>Times executed</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>var</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>unlimited</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>10</td>
          <td>2000</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>100</td>
          <td>2000</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>1000</td>
          <td>200</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>unlimited</td>
          <td>18</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>10</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>100</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>1000</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
      </tbody>
    </table>

  </div>
</details>

<h2 id="query-performance">Query performance</h2>

<p>In total, we executed 19,936 search queries against the database (linearly, not in parallel) which completed in the following times:</p>

<table>
  <thead>
    <tr>
      <th>Time bucket</th>
      <th>Percentage of queries</th>
      <th>Number of queries</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Under 50ms</td>
      <td>30%</td>
      <td>5,933</td>
    </tr>
    <tr>
      <td>Under 250ms</td>
      <td>41%</td>
      <td>8,088</td>
    </tr>
    <tr>
      <td>Under 500ms</td>
      <td>52%</td>
      <td>10,275</td>
    </tr>
    <tr>
      <td>Under 750ms</td>
      <td>63%</td>
      <td>12,473</td>
    </tr>
    <tr>
      <td>Under 1s</td>
      <td>68%</td>
      <td>13,481</td>
    </tr>
    <tr>
      <td>Under 1.5s</td>
      <td>74%</td>
      <td>14,697</td>
    </tr>
    <tr>
      <td>Under 3s</td>
      <td>79%</td>
      <td>15,706</td>
    </tr>
    <tr>
      <td>Under 25s</td>
      <td>79%</td>
      <td>15,708</td>
    </tr>
    <tr>
      <td>Under 30s</td>
      <td>99%</td>
      <td>19,788</td>
    </tr>
  </tbody>
</table>

<h2 id="query-performance-vs-planning-time">Query performance vs. planning time</h2>

<p>The following scatter plot shows how 79% of queries executed in under 3s (Y axis, in ms), while Postgres’s query planner had planned them for execution in under 100-250ms generally (X axis, in ms):</p>

<p><img width="1252" alt="image" src="https://user-images.githubusercontent.com/3173176/107848471-ef379100-6db0-11eb-8396-4d156a179aae.png"></p>

<p>If we expand the view to include all queries, we start to get a picture of just how outlier these 21% of queries are (note that the small block of dots in the bottom left represents the same diagram shown above):</p>

<p><img width="1250" alt="image" src="https://user-images.githubusercontent.com/3173176/107848517-3cb3fe00-6db1-11eb-9652-e65d7d88fe36.png"></p>

<h2 id="query-time-vs-cpu--memory-usage">Query time vs. CPU &amp; Memory usage</h2>

<p>The following image shows:</p>

<ul>
  <li>(top) Query time in milliseconds</li>
  <li>(middle) CPU usage percentage (e.g. 801% refers to 8 out of 16 virtual CPU cores being consumed)</li>
  <li>(bottom) Memory usage in MiB.</li>
</ul>

<p><img width="1255" alt="image" src="https://user-images.githubusercontent.com/3173176/107848716-efd12700-6db2-11eb-8e8b-a8141a6bdb0b.png"></p>

<p>Notable insights from this are:</p>

<ul>
  <li>The large increase in resource usage towards the end is when we began executing queries with no <code>LIMIT</code>.</li>
  <li>CPU usage does not exceed 138%, until the spike at the end.</li>
  <li>Memory usage does not exceed 42 MiB, until the spike at the end.</li>
</ul>

<p>We suspect <code>pg_trgm</code> is single-threaded within the scope of a single table, but with <a href="https://www.postgresql.org/docs/10/ddl-partitioning.html">table data partitioning</a> (or splitting data into multiple tables with subsets of the data), we suspect better parallelism could be achieved.</p>

<h2 id="investigating-slow-queries">Investigating slow queries</h2>

<p>If we plot the number of index rechecks (X axis) vs. execution time (Y axis), we can clearly see one of the most significant aspects of slow queries is that they have many more index rechecks:</p>

<p><img width="1036" alt="image" src="https://user-images.githubusercontent.com/3173176/107849660-fc0cb280-6db9-11eb-9c10-cb7e74366ab7.png"></p>

<p>And if we look at <a href="https://github.com/hexops/pgtrgm_emperical_measurements/blob/main/query_logs/query-run-3.log#L3-L24">the <code>EXPLAIN ANALYZE</code> output for one of these queries</a> we can also confirm <code>Parallel Bitmap Heap Scan</code> is slow due to <code>Rows Removed by Index Recheck</code>.</p>

<h2 id="table-splitting">Table splitting</h2>

<p>Splitting up the search index into multiple smaller tables seems like an obvious approach to getting <code>pg_trgm</code> to use multiple CPU cores. We tried this by taking the same exact data set and splitting it into 200 tables, and found …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories">https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories</a></em></p>]]>
            </description>
            <link>https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220446</guid>
            <pubDate>Mon, 22 Feb 2021 03:15:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Building a Binary Counter]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26219601">thread link</a>) | @lowdanie
<br/>
February 21, 2021 | https://www.daniellowengrub.com/blog/2021/02/08/binary-counter | <a href="https://web.archive.org/web/*/https://www.daniellowengrub.com/blog/2021/02/08/binary-counter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>A binary counter is an electronic component that records the number of times it has received a pulse. It is called <em>binary</em> because it stores the number in its binary representation. Counters are absolutely ubiquitous in electronics and can be used to make circuits ranging from memory chips to FM radio decoders.</p>

<p>Since counters are so useful, I thought it would be fun to implement one using only basic logic gates like NAND and OR. As a practical application, I hooked up a 1-bit counter to a clock and a pair of LEDs to create a random bit generator:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/random_breadboard.jpeg" alt="Random Generator"></p>

<p>The output of the counter is connected to two LEDs. One of them lights up when the counter is in the 0 state and the other lights up in the 1 state. When the button is pressed down, the clock starts sending out around 100 pulses per second causing the counter to oscillate between 0 and 1. When the button is released the timer stops and the the counter remains in its most recent state as indicated by the corresponding LED. The state is maintained until the next time the button is pressed.</p>

<p>Since the oscillations are very fast relative to human reflexes, the LED that remains lit after each button release appears to be chosen randomly with each LED appearing with equal probability. In other words, one can think of this circuit as simulating a coin flip where one of the LEDs represents heads and the other tails. At the end of the post I will provide some evidence that two outcomes are indeed equally likely.</p>

<p>The primary goal of this post is to explain how to make a 1 bit counter out of basic logic gates. After that weâ€™ll get into the details of the complete random bit generator circuit shown above. Weâ€™ll conclude by showing how multiple 1 bit counters can easily be chained together to produce larger counters such as the useful 8 bit counter.</p>


<p>Here is a high level schematic of the one bit binary counter we want to build:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/one_bit_counter.png" alt="One Bit Counter"></p>

<p>We now turn to the design requirements.</p>

<p>The counter has a single input which is labelled â€œClockâ€� and two outputs labelled $Q$ and $\overline{Q}$. The input and output wires can either have a â€œhighâ€� voltage or a â€œlowâ€� voltage. In our case, we will be using a 5 volt power supply so a â€œhighâ€� wire will be close to 5 volts and a â€œlowâ€� wire will be close to 0 volts.</p>

<p>The overline on the bottom output represents the fact that its state is always opposite to $Q$. I.e, if $Q$ is high then $\overline{Q}$ is low and vice versa. It may seem redundant to include both $Q$ and $\overline{Q}$ but later we will see why it is useful. We summarize the state of the counter by writing $Q=1$ if $Q$ is high and $Q=0$ if $Q$ is low.</p>

<p>As long as the clock input is low the output state should remain fixed. But each time the the clock receives a pulse (explained below) the values of the outputs should flip.</p>

<p>In more detail, a â€œpulseâ€� means that the clock input rises from low to high, and then quickly falls back to low. Since the output should only change one time per pulse, we would like the outputs to flip whenever the clock input <em>rises</em> from low to high. This special behavior is indicated by the triangle next to the clock input.</p>

<p>You may be wondering why we need this fancy pulse behavior. Why canâ€™t we simply demand that the outputs flip whenever the input is high? The issue with that design is that every pulse has some non-zero duration. So even a short pulse would cause the outputs to start rapidly flipping back and forth from the moment the clock input went high until the end of the pulse when it went low again. This would make the final state undefined!</p>

<p>In contrast, the input voltage rises from low to high exactly once per pulse so our design guarantees that the outputs will flip exactly once whenever the input receives a pulse.</p>

<p>Now that weâ€™ve specified the counterâ€™s behavior we turn to the implementation.</p>

<p>There are two main implementation challenges. First, how does the counter maintain its state between pulses? Second of all, how is it possible to detect the low to high transition exactly once per pulse?</p>

<p>In the next section we focus on the first issue by considering a simpler type of component that has two separate â€œonâ€� and â€œoffâ€� inputs rather than the complex clock input. We will then solve the pulse problem by chaining two of these simpler components to each other!</p>

<h2 id="the-sr-flip-flop">The SR Flip-flop</h2>
<p>In this section weâ€™ll build a component called the <a href="https://en.wikipedia.org/wiki/Flip-flop_(electronics)#Simple_set-reset_latches">Set Reset Flip-flop</a> or <em>SR Flip-flop</em> for short.</p>

<p>Here is a diagram of the SR flip-flop:
<img src="https://www.daniellowengrub.com/assets/binary_counter/sr_flipflop.png" alt="SR Flip-flop"></p>

<p>This flip-flop has two inputs: $S$ (â€œsetâ€�) and $R$ (â€œresetâ€�) and two outputs: $Q$ and $\overline{Q}$. As before, $\overline{Q}$ always has the opposite value of $Q$. So if $Q$ is high then $\overline{Q}$ is low and vice versa.</p>

<p>In its default state, both inputs $S$ and $R$ are high and the output $Q$ is low. If $S$ is pulled low (i.e $S=0$) this <em>sets</em> the gate and causes the output $Q$ to be high (and therefore $\overline{Q}$ to be low). The output will stay in this state even when $S$ goes high again. On the other hand, pulling $R$ low <em>resets</em> the gate which means that $Q$ will go low. As before, $Q$ will remain low even when $R$ goes back to being high.</p>

<p>In summary, we can flip between the two possible output states by lowering either $S$ or $R$. Furthermore, the SR flip-flop maintains its state until the next set or reset operation.</p>

<p>It turns out that it is possible to build an SR latch out of just two <a href="https://en.wikipedia.org/wiki/NAND_gate">NAND gates</a> via an ingenious mechanism called the <a href="https://en.wikipedia.org/wiki/Flip-flop_(electronics)#SR_NAND_latch">NAND latch</a> as shown in the following diagram:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/nand_latch_circuit.png" alt="NAND Latch"></p>

<p>We are using the convention that an â€œXâ€� intersection of wires means that the wires do not touch but rather cross over each other.</p>

<p>How does this circuit work? Lets see what happens if we start in the defaults state ($S=R=\overline{Q}=1$, $Q=0$) and perform a <em>set</em> operation:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/nand_latch_states.png" alt="NAND Latch"></p>

<p>In the initial state the input to the top NAND is $(1, 1)$ and so its output is $Q=0$. The input to the bottom NAND is $(0, 1)$ so its output is $\overline{Q}=1$. Since everything is consistent, the gates will stay in this configuration until we change one of the the inputs.</p>

<p>Now lets perform a â€œsetâ€� operation by pulling down $S$ to a low state to get $S=0$. Since one of the inputs to the top NAND is $0$, its output will be $Q=1$ regardless of the other input. This means that the input to the bottom NAND is $(1, 1)$ causing its output to be $\overline{Q}=0$.</p>

<p>Finally, lets see what happens if we release $S$ and let it go back to the default high state $S=1$. The input to the top NAND is now $(1, 0)$ which means that its output is still $Q=1$. Therefore the output to the bottom NAND is still $(1, 1)$ causing its output to stay at $\overline{Q}=0$.</p>

<p>In summary, we can see that one cycle of $S=0 \Rightarrow S=1$ <em>sets</em> the output to $Q=1,\,\overline{Q}=0$. A similar analysis shows that a cycle of $R=0 \Rightarrow R=1$ <em>resets</em> the output to $Q=0,\,\overline{Q}=1$.</p>

<h2 id="a-1-bit-counter-implementation">A 1-Bit Counter Implementation</h2>
<p>We now return to the problem of building a one bit counter. The SR flip-flop from the last section gets us pretty close: It has the outputs $Q$ and $\overline{Q}$ and allows us to toggle between them by pulling down $S$ or $R$. To turn this into a counter we need to replace the set/reset inputs with a single <em>clock</em> input.</p>

<p>The general logic should be:</p>
<ul>
  <li>If the clock is low then then the SR inputs should be in their default state of $S=R=1$. This will result in $Q$ maintaining its current state.</li>
  <li>If the clock is high and $Q=1$, <em>reset</em> the SR flip-flop by setting $R=0$. This will result in $Q=0$.</li>
  <li>If the clock is high and $Q=0$, <em>set</em> the SR flip-flop by setting $S=0$. This will result in $Q=1$.</li>
</ul>

<p>We can implement this logic by wiring up an SR flip-flop with two NAND gates like so:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/one_bit_circuit_simple.png" alt="One Bit Counter Circuit"></p>

<p>As before, wires that meet in an X intersection do not touch each other. Weâ€™ve connected the $Q$ output to the bottom NAND and the $\overline{Q}$ output to the top NAND.</p>

<p>Letâ€™s verify that this circuit follows the logic outlined above. Indeed, if $\mathrm{Clock}=0$ then both of the NANDs will have a $0$ input and so their outputs will always both be $1$. This means that the two inputs to the SR flip-flop will be in their default $1$ state as desired.</p>

<p>What happens when the clock goes high ($\mathrm{Clock}=1$)? Suppose that $Q=1,\,\overline{Q}=0$. Then the inputs to the top NAND will be $(\overline{Q}=0, \mathrm{Clock}=1)$ and so its output will be $1$. On the other hand, the inputs to the bottom NAND will be $(\mathrm{Clock}=1, Q=1)$ so its output will be $0$. Together this means that the input to the SR flip-flop will be $S=1$, $R=0$ which by definition will <em>reset</em> the flip-flop to $Q=0,\,\overline{Q}=1$.</p>

<p>If the clock goes high again it is not hard to see that the SR inputs will now be $(S=0,\,R=1)$ causing it to <em>set</em> the output back to $Q=0,\,\overline{Q}=1$.</p>

<p>The only problem with this setup is that the outputs will keep flipping as long as the clock is high! Since each clock pulse has some non-zero duration, this version of the counter will flip many times per pulse rather than just once.</p>

<p>The solution is to use <em>two</em> SR flip-flops. One will record the current output and the other will record the output for the next pulse. The trick is that the â€œcurrentâ€� flip-flop is activated when the clock goes high as above, but the â€œnextâ€� flip-flop will be activated when the clock goes low. The effect is that the counter is only updated after a complete cycle $\mathrm{Clock}=0 \Rightarrow \mathrm{Clock}=1$, preventing the oscillations in our first version.</p>

<p>Here is an implementation of this idea:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/one_bit_circuit.png" alt="One Bit Counter Circuit"></p>

<p>When the clock is <em>low</em> it is easy to see that $S_{cur}=R_{cur}=1$ meaning that the â€œcurrentâ€� flip-flop will not be updated. In contrast, when the clock is <em>high</em> $S_{next}=R_{next}=1$ and so the â€œnextâ€� clock will not be updated. It is not hard to verify that with this version the outputs $Q,\,\overline{Q}$ flip exactly once when the clock receives a pulse.</p>


<p>In this section we will use a 1 bit counter to build the random bit generator we described in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.daniellowengrub.com/blog/2021/02/08/binary-counter">https://www.daniellowengrub.com/blog/2021/02/08/binary-counter</a></em></p>]]>
            </description>
            <link>https://www.daniellowengrub.com/blog/2021/02/08/binary-counter</link>
            <guid isPermaLink="false">hacker-news-small-sites-26219601</guid>
            <pubDate>Mon, 22 Feb 2021 01:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frustrated with Parler deplatforming, I am building a service no one can silence]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 192 (<a href="https://news.ycombinator.com/item?id=26218900">thread link</a>) | @anon20190221
<br/>
February 21, 2021 | https://1b677b8f8bb20100.github.io/introduction/ | <a href="https://web.archive.org/web/*/https://1b677b8f8bb20100.github.io/introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p>This is the first post in this blog, it was published on February 19, 2021.</p>

<h2 id="motivation">Motivation</h2>

<h3 id="censorship">Censorship</h3>

<p>The year of 2020 will be remembered for the pandemic, the BLM movement, and the U.S. elections among other billion of things around the globe. It is funny I even mention the third one considering how little I give a damn about U.S. politics, yet this whole story begins with <a href="https://en.wikipedia.org/wiki/Parler">Parler</a> deplatforming that happened about a month ago. Let me remind you: Apple, Google, Amazon, and a few other companies terminated their service to the free speech social network for insufficient moderation effectively destroying the platform in a matter of just a couple of days. What the fuck?</p>

<p>OK, let me be clear with my position: I believe every private company has a right to refuse service to anyone, whether an individual or a business, but I also have my own right to despise them for exercising that. What they did was probably legal, but screw them anyway, they failed us. Regardless what these psychopathic corporations like to tell the public, they are only concerned with maximizing shareholder value, and if there is anything  even remotely resembling an image liability (through pressure by political radicals, cancel culture SJWs, you name it), they will not think twice. What disgusts me the most here is neither greed nor hypocrisy but their unwillingness to grow a pair of balls and stand up for freedom of speech.</p>

<p>You see, freedom of speech and expression must be absolute. You cannot have censorship-resistance with exceptions; otherwise, these exceptions could be used to remove or block anything unwanted, not only offensive. This way, the Chinese cannot access Wikipedia because of what originally started as a counter-terrorism measure, and the Russians cannot access LinkedIn because of what originally started as a children protection measure. We cannot deprive humanity of their freedom just because some small fraction of users might, unfortunately, use that freedom to spread offensive content. In the same way, you do not ban electricity because people get electrocuted.</p>

<p>Let us now switch from corporates to governments. Ooh, wee! Do not even get me started on that. And I am not even talking about cases like Google happily not letting people disable <a href="https://en.wikipedia.org/wiki/SafeSearch">SafeSearch</a> in Indonesia because its government knows best, that is just the tip of the iceberg. I am talking about political censorship which includes silencing people with torture, gulags, and bullets. Here is the world map of the freedom of the press status:</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/press-freedom.png" alt="2020 Press Freedom Index"></p>

<p>Just look at this mess. Blue tones mean OK-ish, others not so much. This map is <a href="https://de.wikipedia.org/wiki/User:NordNordWest">NordNordWest</a>’s work based on the <a href="https://rsf.org/en/ranking">2020 Press Freedom Index</a> and is distributed under <a href="https://creativecommons.org/licenses/by-sa/3.0/de/legalcode">CC BY-SA 3.0 de</a>. Keep in mind population densities, e.g. there are about 90 times more people per unit area living in Vietnam than Australia. I am actually surprised the U.S. did so well in 2020 considering how badly they wanted <a href="https://en.wikipedia.org/wiki/Julian_Assange">Mr. Assange</a> to be extradited and executed.</p>

<p>What would you answer your children if they asked you how in the world North Korea still exists in its current form with 25 million Koreans suffering for over 70 years and no one is doing anything about that? Or how about 28 million people in Venezuela? Or 82 million people in Iran? Giving voice to all whistleblowers and activists, especially the ones risking their lives and freedom in hostile environments is the fundamental goal of Pepe.</p>

<h3 id="darknets">Darknets</h3>

<p>There is already <a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)">Tor</a>, <a href="https://en.wikipedia.org/wiki/I2P">I2P</a>, <a href="https://en.wikipedia.org/wiki/Freenet">Freenet</a>, <a href="https://en.wikipedia.org/wiki/GNUnet">GNUnet</a> etc. We can run emails, message boards, <a href="https://en.wikipedia.org/wiki/BitTorrent">BitTorrent</a>, <a href="https://en.wikipedia.org/wiki/Kad_network">Kad</a>, and <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> on top of them, maybe even use <a href="https://en.wikipedia.org/wiki/Ethereum">Ethereum</a> smart contracts for decentralized computing. All the technology is there, why bother with something new? Well, first of all, these are all amazing projects, there is nothing wrong with them. The peculiar thing, however, is none of them except BitTorrent (and perhaps Tor) gained much popularity, neither do we see any readily available censorship-resistant communication platforms. Why is that?</p>

<p>I claim there are 2 main reasons for that:</p>

<ul>
  <li>
    <p>They are hard to use. The “Unix is user-friendly, it is just picky about who its friends are.” aphorism still lives in most them: you may need to install a bunch of additional software (such as <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">JVM</a> or shared libraries) potentially dealing with a dependency hell on some platforms; read through sparse documentation and dead forums on optimal network, security, and sharing settings; carefully configure your router, computer, and client; install, study, and configure applications running on top of the darknet, i.e. repeat the steps. The reason why Tor became popular outside of research was not because it was first, but because of the hacky all-in-one Tor Browser Bundle with sane defaults.</p>
  </li>
  <li>
    <p>They prefer purity to practicality. Instead of concentrating manpower on few specific use cases, most existing tools try to conquer the world: a new internet, interplanetary, infrastructure, an application framework, APIs, a Turing-complete language on the blockchain etc. This is great and all, it is general, conceptual, modular, extensible, and stackable—everything we like—but sometimes overengineering is just overengineering given the goal. And our goal here is not to make a technical revolution, but to help as many people as we can communicate without fear of retribution.</p>
  </li>
</ul>

<p>BitTorrent evolved into something that is used by 150 million people worldwide, it seamlessly adopted <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a>, <a href="https://en.wikipedia.org/wiki/Peer_exchange">PEX</a>, <a href="https://en.wikipedia.org/wiki/Micro_Transport_Protocol">µTP</a>, trackerless <a href="https://en.wikipedia.org/wiki/Magnet_URI_scheme">magnet links</a>, and people do not even know what the hell it all means. Even though proprietary, <a href="https://en.wikipedia.org/wiki/Skype">Skype</a> thrived very similarly (at least before it was crippled by Microsoft), millions of its users did not even know what peer-to-peer meant, not to mention how it worked under the hood, it just did. These two systems succeeded not because of luck but rather as a result of some excellent product decisions. We need to learn from that and reiterate.</p>

<h2 id="pepe-overview">Pepe overview</h2>

<h3 id="user-level">User level</h3>

<p>For the messaging platform, I chose to use an <a href="https://en.wikipedia.org/wiki/Imageboard">imageboard</a> similar to <a href="https://en.wikipedia.org/wiki/4chan">4chan</a> or <a href="https://en.wikipedia.org/wiki/Futaba_Channel">Futaba Channel</a>. While not the most popular type of forum, imageboards are extremely flexible and free of junk like authentication or karma, they promote anonymity in a very practical way, and over 30 million people are already familiar with them. Perhaps, I am not a big fan of their crowded old-school design, but the initial user traction is more important than my sense of beauty, we will refine the looks through time.</p>

<p>That is, the Pepe imageboard is going to be the only application running on top the Pepe darknet, they are in fact inseparable. This way, we can design the network specifically for this one use case. This brings both security and performance benefits. Joining the darknet can be as simple as double clicking the application, and users do not need to install or configure any third-party browsers or proxy servers, they can just go to <a href="http://localhost:8666/">localhost:8666</a> using Chrome, Safari, or whatever they like, and it is going to be safe without any third-party extensions.</p>

<p>Once online, users may browse existing or create new message boards about various topics in any language such as <code>/en/food/</code> or <code>/ja/math/</code>. A board is a collection of threads about something more specific, would it be an idea or a question. A thread has a collection of posts that people send replying to each other. Each post may have one or multiple attachments such as photos, videos, you name it. So that you have an idea of what it looks like, here is a screenshot of a random thread on the 4chan DIY board:</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/4chan-thread.png" alt="4chan thread"></p>

<p>What is fundamentally different with Pepe is moderation. Instead of relying on a centralized entity with a banhammer, each board and thread owner may anonymously moderate their spaces on their own. However, nothing can actually be deleted, it can only be shadowed, and each user decides whether they want to see the light or the full version of the page at any moment in time. People can still reply to shadowed posts inside their own shadowed posts, so no one cannot silence anyone, only maintain order on the light side.</p>

<p>If people are no longer interested in particular threads, they will eventually become forgotten by the network and naturally disappear from their board. But if there is at least one person who is subscribed to or has archived some thread, no one in the world (even Pepe creators) can censor or somehow shut it down without hurting most of the network Pepe is running on top of.</p>

<h3 id="network-level">Network level</h3>

<p>The three biggest problems with 4chan and similar communication platforms are:</p>

<ul>
  <li>They use closed source software so no one can tell how secure everything is and what is really going on there.</li>
  <li>They are centralized, i.e. some individual or business owns the servers and fully controls the whole infrastructure.</li>
  <li>They collect lots of metadata including but not limited to “someone with this <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> posted this at this moment in time”.</li>
</ul>

<p>Mitigating the first problem is the easiest: just use open-source software whenever possible. Regarding the centralization issue, we could switch to a decentralized solution like BitTorrent (imagine each torrent containing a thread with its posts and attachments), but that itself does not help with privacy, people can still see what others are doing. Similarly, we could tackle the privacy issue with a <a href="https://en.wikipedia.org/wiki/Virtual_private_network">VPN</a> or a darknet like Tor or I2P, but that, contrary to popular belief, does not solve the centralization issue in any way. Clearly, we need the best of the two worlds. Let us fuse them together!</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/pepe-routing.png" alt="Pepe routing"></p>

<p>Here is an very simplified walk through how the network works. Imagine Bob is an undercover journalist who wants to anonymously share his report and Alice is a political activist who is interested in the investigation Bob had been doing. It all starts with Bob announcing he has the report:</p>

<ol>
  <li>
    <p>Bob joins the network and gathers information about random peers on it through the <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a>. This way, Bob discovers hundreds of participants including X and Y. Similarly, Bob registers himself on the network through the DHT so that others …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://1b677b8f8bb20100.github.io/introduction/">https://1b677b8f8bb20100.github.io/introduction/</a></em></p>]]>
            </description>
            <link>https://1b677b8f8bb20100.github.io/introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218900</guid>
            <pubDate>Mon, 22 Feb 2021 00:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TransferWise changes name to Wise]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 226 (<a href="https://news.ycombinator.com/item?id=26218693">thread link</a>) | @watbe
<br/>
February 21, 2021 | https://wise.com/gb/blog/world-meet-wise | <a href="https://web.archive.org/web/*/https://wise.com/gb/blog/world-meet-wise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<p>Today, we’re changing our name from TransferWise to Wise.</p>
<p>Our customers now need us for more than money transfers. Sending, spending, and receiving money internationally is too expensive, slow, and inconvenient. We’re fixing that for people and businesses.</p>
<p>You can <a href="https://transferwise.com/gb/blog/world-meet-wise#transferwise-is-now-wise">skip ahead to see what changes for you</a> (spoiler: not much, right away), but first, let’s go back a bit.</p>
<h2><a href="#a-decade-into-our-mission" id="a-decade-into-our-mission"></a>A decade into our mission</h2>
<p>Ten years ago, Taavet and I set out to fix international money transfers for all of us who’d been overcharged and underserved by banks. We named our idea ‘TransferWise’ — because our early customers were ‘wise’ to know their banks were charging hidden fees in exchange rate markups.</p>
<p>We set ourselves a mission to make money work without borders — to make money move instantly, transparently, conveniently, and — eventually — for free.</p>
<p>Now, we’re a community of 10 million like-minded people and businesses managing money all over the world, saving billions and fighting as hard as ever against hidden fees.</p>
<p>Our multi-currency account and the clever debit card is replacing international banking for many of you. By building this infrastructure for you, we’ve created a platform that more than a dozen banks use today.</p>
<p>You’ve told us for years the problem is bigger than money transfers. Any time money moves into another currency, it’s still a maze of hidden exchange rate markups, high fees, delays, and small print.</p>
<h2><a href="#well-fix-international-banking-together" id="well-fix-international-banking-together"></a>We’ll fix international banking together</h2>
<p>Sending, spending, receiving, and holding money internationally doesn’t work like it should, because the international banking system was built for the past.</p>
<p>For generations, banks have been defined by borders. Traditional bank accounts trap our money in one country, making international lives more difficult and expensive than they need to be. We shouldn’t have to accept this status quo.</p>
<p>Today, we don’t. We’ll fix it with Wise — the world’s most international account. It makes your money borderless — with instant, super-cheap money transfers, a debit card to spend in any currency, account details to get paid in 30+ countries, balances to hold your money safely in 50+ different currencies, multi-currency direct debits, and other revolutionary features.</p>
<h2><a href="#transferwise-is-now-wise" id="transferwise-is-now-wise"></a>TransferWise is now Wise</h2>
<p>Today our name catches up with who we’re already building for — a community of people and businesses with multi-currency lives. Wise is for all of us who live, work, travel, or support family around the world. It’s for those of us who want to cut out the middlemen that hold us back from being truly borderless.</p>
<p>For customers, not too much will change right away. We become “Wise” or “Wise Business” — depending how you use us. You can access your exact same account via <a href="http://wise.com/">wise.com</a>, using your current email and password. You won't need a new account. In a few weeks we will start to redirect transferwise.com to wise.com.</p>
<p>Our logo has changed, and our apps will be renamed. But our icon — the fast flag — remains as a symbol for money without borders. Beyond that, you’ll notice some new colours, words, and designs.</p>
<p>The core experience of using Wise will remain faster, cheaper, and more convenient than anything else. Our mission remains the same. We’re still making — and always will be making — money work without borders.</p>
<p>We’re humbled that 10 million of you already rely on us to help you lead your international lives. We can’t wait to bring the next 100 million of you with us as we continue to build a new, fair, and transparent world of money.</p>
<p>Onwards.</p>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://wise.com/gb/blog/world-meet-wise</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218693</guid>
            <pubDate>Mon, 22 Feb 2021 00:02:25 GMT</pubDate>
        </item>
    </channel>
</rss>
