<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 12 Jan 2021 17:24:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 12 Jan 2021 17:24:45 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[To $4m ARR in 3 years, bootstrapped (7 secrets revealed)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25727141">thread link</a>) | @Ilyazovtsev
<br/>
January 11, 2021 | https://ilya.today/gh-from-0-to-4mln | <a href="https://web.archive.org/web/*/https://ilya.today/gh-from-0-to-4mln">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ilya.today/gh-from-0-to-4mln</link>
            <guid isPermaLink="false">hacker-news-small-sites-25727141</guid>
            <pubDate>Mon, 11 Jan 2021 10:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing a new macOS System Release]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25727100">thread link</a>) | @kaendfinger
<br/>
January 11, 2021 | https://blog.endfinger.io/apple/macos/technical/jolk/2021/01/10/jolk.html | <a href="https://web.archive.org/web/*/https://blog.endfinger.io/apple/macos/technical/jolk/2021/01/10/jolk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Perhaps my favorite time of the year is when the annual Apple <a href="https://en.wikipedia.org/wiki/Apple_Worldwide_Developers_Conference">WWDC</a> conference occurs. I am heavily inspired by Apple’s Software and Hardware meld, and I truly enjoy nearly every ounce of the conference. But nothing compares to the love I have for the macOS operating system. With it’s deep history and Unix origins, it brings an interesting take on a consumer operating system.</p>

<p>But macOS has one central problem, it’s almost entirely proprietary. macOS consists of <a href="https://opensource.apple.com/">a few open source components</a>, and a majority proprietary components. As someone with a strong Open Source origin and a professional grounding in software companies, it can be hard for me to sympathize with the belief that all software should be Open Source, but at the same time, I’m a curious developer, and I love knowing how things work.</p>

<p>This is what excites me every time a new macOS release is announced. I want to understand the technical foundations and changes on an entusiast level!</p>

<p>That’s why I’ve built a macOS system analysis tool called <a href="https://github.com/kendfinger/jolk">jolk</a>. jolk aims to scan and analyze all the executables found on a macOS installation and reports results about interesting findings.</p>

<p>First, let me dive into the most important note in this entire post. I am doing this purely as an enthusiest. I want to understand what makes up the macOS operating system. For example, I want to understand what daemons run when I use my FaceTime HD Camera on my MacBook Pro, or how the boot process on Apple M1 devices work. There is no intention of malicious use in this tool.</p>

<h2 id="what-is-jolk">What is jolk?</h2>

<p><a href="https://github.com/kendfinger/jolk">jolk</a> is a tool which will scan, analyze, and report the executables installed on a macOS system, providing useful details which can help whittle down to interesting aspects of the system. jolk is portmanteau of the words jog and walk. This is an personal inside joke to the time in which I owned the domain <code>idont.run</code>.</p>

<p>jolk combines a system executable finder and an executable analyzer. Using various built-in macOS development tools, you can discover a lot about what is installed on a system. jolk automates that task.</p>

<p>jolk currently supports the following analyzer passes:</p>

<ul>
  <li>lipo: discovers what architectures an executable supports using, you guessed it, the <code>lipo</code> tool.</li>
  <li>dynamic linker: determines frameworks and libraries that the executable links to.</li>
  <li>launchd: finds launchd services which reference the executable.</li>
  <li>strings: scans the executable for interesting strings.</li>
  <li>man page: backsearches man pages for mentions of the executable.</li>
</ul>

<h2 id="how-can-i-use-jolk">How can I use jolk?</h2>

<p>jolk can be ran by cloning the repository and building the jolk tool with Xcode.</p>

<p>Let’s start with an example usage of jolk to discover what the <code>/usr/libexec/remotectl</code> executable does.</p>

<div><div><pre><code><span>$ </span>jolk <span>-o</span> remotectl.json <span>-i</span> <span>'/usr/libexec/remotectl'</span>
analyze /usr/libexec/remotectl
<span>complete</span> /usr/libexec/remotectl 253.41ms
</code></pre></div></div>

<p>This will produce a JSON report in the file <code>remotectl.json</code> which contains relevant information about the <code>remotectl</code> utility.</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"/usr/libexec/remotectl"</span><span> </span><span>:</span><span> </span><span>{</span><span>
    </span><span>"dynamic-linker.linked-files"</span><span> </span><span>:</span><span> </span><span>[</span><span>
      </span><span>"/System/Library/Frameworks/Foundation.framework/Versions/C/Foundation"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/BridgeXPC.framework/Versions/A/BridgeXPC"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/RemoteXPC.framework/Versions/A/RemoteXPC"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/RemoteServiceDiscovery.framework/Versions/A/RemoteServiceDiscovery"</span><span>,</span><span>
      </span><span>"/usr/lib/libobjc.A.dylib"</span><span>,</span><span>
      </span><span>"/usr/lib/libSystem.B.dylib"</span><span>,</span><span>
      </span><span>"/System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation"</span><span>
    </span><span>],</span><span>
    </span><span>"dynamic-linker.linked-frameworks"</span><span> </span><span>:</span><span> </span><span>[</span><span>
      </span><span>"/System/Library/Frameworks/Foundation.framework"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/BridgeXPC.framework"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/RemoteXPC.framework"</span><span>,</span><span>
      </span><span>"/System/Library/PrivateFrameworks/RemoteServiceDiscovery.framework"</span><span>,</span><span>
      </span><span>"/System/Library/Frameworks/CoreFoundation.framework"</span><span>
    </span><span>],</span><span>
    </span><span>"lipo.architectures"</span><span> </span><span>:</span><span> </span><span>[</span><span>
      </span><span>"x86_64"</span><span>,</span><span>
      </span><span>"arm64e"</span><span>
    </span><span>],</span><span>
    </span><span>"man-page.exists"</span><span> </span><span>:</span><span> </span><span>false</span><span>,</span><span>
    </span><span>"strings.likely.has-help-flag"</span><span> </span><span>:</span><span> </span><span>false</span><span>,</span><span>
    </span><span>"strings.likely.has-usage"</span><span> </span><span>:</span><span> </span><span>true</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>Hmm, it appears from the entry <code>"strings.likely.has-usage" : true</code> that this command has a usage message, lets run the tool to see if we can capture the usage.</p>

<div><div><pre><code><span>$ </span>/usr/libexec/remotectl
usage: remotectl list
usage: remotectl show <span>(</span><span>type</span>|name|uuid|trait<span>)</span>
usage: remotectl get-property <span>(</span><span>type</span>|name|uuid|trait<span>)</span> <span>[</span>service] property
usage: remotectl dumpstate
usage: remotectl browse
usage: remotectl <span>echo</span> <span>[</span><span>-v</span> service_version] <span>[</span><span>-d</span> <span>(</span><span>type</span>|name|uuid|trait<span>)]</span>
usage: remotectl echo-file <span>(</span><span>type</span>|name|uuid|trait<span>)</span> path
usage: remotectl eos-echo
usage: remotectl netcat <span>(</span><span>type</span>|name|uuid|trait<span>)</span> service
usage: remotectl relay <span>(</span><span>type</span>|name|uuid|trait<span>)</span> service
usage: remotectl loopback <span>(</span>attach|connect|detach|suspend|resume<span>)</span>
usage: remotectl bonjour <span>((</span><span>enable</span>|enable-loopback interface_name<span>)</span>|<span>(</span>disable<span>))</span>
usage: remotectl convert-bridge-version plist-in-path bin-out-path
usage: remotectl heartbeat <span>(</span><span>type</span>|name|uuid|trait<span>)</span>
usage: remotectl trampoline <span>[</span><span>-2</span> fd] service_name <span>command </span>args ... <span>[</span> <span>--</span> <span>[</span><span>-2</span> fd] service_name <span>command </span>args ... <span>]</span>
usage: remotectl reset <span>(</span><span>type</span>|name|uuid|trait<span>)</span>
usage: remotectl <span>alias</span> <span>(</span><span>type</span>|name|uuid|trait<span>)</span> <span>alias</span>
</code></pre></div></div>

<p>It also appears that <code>remotectl</code> links to the framework <code>/System/Library/PrivateFrameworks/RemoteServiceDiscovery.framework</code>, I bet that’s got some interesting uses. Maybe I will investigate other executables later that use this framework. By running jolk without an <code>include</code> flag, we can scan the entire system, and find any executables that link this framework.</p>

<h2 id="future-improvements">Future Improvements</h2>

<p>My ultimate goal is for jolk is to be able to scan, diff, and analyze multiple macOS releases to discover what has truly changed about the system between releases. Please don’t hesitate to create issues on the repository for suggestions or improvements.</p>

<h2 id="conclusion">Conclusion</h2>

<p>jolk is intended to be used for enthusiast analysis of a macOS system. I hope other enthusiasts find this tool interesting and useful.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.endfinger.io/apple/macos/technical/jolk/2021/01/10/jolk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25727100</guid>
            <pubDate>Mon, 11 Jan 2021 10:36:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web apps are too complex. This is how we can simplify them]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726700">thread link</a>) | @pietmichal
<br/>
January 11, 2021 | https://michalpietraszko.com/web-apps-are-too-complex-this-is-how-we-can-simplify-them/ | <a href="https://web.archive.org/web/*/https://michalpietraszko.com/web-apps-are-too-complex-this-is-how-we-can-simplify-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody"><p>I believe that we can do a better job of managing the complexity of our apps.</p>
<p>Not many of us realize how many second-order effects our decisions have caused.</p>
<p>Let’s see how complexity had grown over time.</p>
<h2>The Static era</h2>
<p>Simple times. We had a MySQL database, business logic and HTML + CSS views.</p>
<p>All content was static, the browser’s job was to display content, navigate and submit forms.</p>
<p><span>
      <a href="https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/23296/simple.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Simple web app architecture diagram" title="Simple web app architecture diagram" src="https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/f058b/simple.png" srcset="https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/c26ae/simple.png 158w,
https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/6bdcf/simple.png 315w,
https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/f058b/simple.png 630w,
https://michalpietraszko.com/static/5a46cad524761cec773ff2212a339f3b/23296/simple.png 675w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>I like to think about test effort as a benchmark for simplicity. There were 3 layers.</p>
<p>Business logic and persistence layer can be easily integrated and view layer can be browser tested.</p>
<p>You may need a tester, developer, and a designer to maintain something like this. It is realistic to have one person responsible for all of this.</p>
<h2>The AJAX era</h2>
<p>JavaScript opened a door for more considerations in user experience. Adding a dynamic menu, forms, or calendar to a WordPress website was the coolest thing you could do.</p>
<p><span>
      <a href="https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/23296/ajax.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="web app with javascript architecture diagram" title="web app with javascript architecture diagram" src="https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/f058b/ajax.png" srcset="https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/c26ae/ajax.png 158w,
https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/6bdcf/ajax.png 315w,
https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/f058b/ajax.png 630w,
https://michalpietraszko.com/static/e4346edb319dee1705e11e6dd38791a4/23296/ajax.png 675w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>We have a complexity spike on the client-side.</p>
<p>Many browsers differed in JS implementation, which required jQuery to come into existence.</p>
<p>This gave a lot of power to designers and has moved more engineering effort into the front end. JavaScript made the browser extensible.</p>
<p>Did the testing complexity increase? Yes. Each new JavaScript bit could only be tested in a browser.</p>
<p>This requires testing, backend programming, JavaScript, and design expertise in your team. Jumping between server-side and client-side languages became frustrating. There was a trend to have different people responsible for each side.</p>
<h2>The Single-page era</h2>
<p>Remember the first example of the Angular.js app? The input field that automatically updated the content of the div? Good times.</p>
<p>Welcome to the single-page era where front-end development became even more complex than back-end development - mostly due to relevant logic moving to the client. As a result, the divide has increased and <a href="https://medium.com/@ericclemmons/javascript-fatigue-48d4011b6fc4">JavaScript fatigue</a> became a thing.</p>
<p><span>
      <a href="https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/cd138/spa.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="single-page application architecture diagram" title="single-page application architecture diagram" src="https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/f058b/spa.png" srcset="https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/c26ae/spa.png 158w,
https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/6bdcf/spa.png 315w,
https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/f058b/spa.png 630w,
https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/40601/spa.png 945w,
https://michalpietraszko.com/static/1e77454e6a0f33cdde1452c823e55b4f/cd138/spa.png 1220w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>We have ended up with two apps that are tightly coupled.</p>
<p>To maintain this, you need at least someone experienced in testing, backend, frontend development (extensive framework, tooling, and browser knowledge), and design.</p>
<p>Now, two apps have to be maintained, and there is much more code than ever. You have to maintain unit, integration, and end to end tests on both sides. Now business logic is not directly accessible due to security concerns.
Frontend and backend now have to maintain layers that are responsible for communication.</p>
<p>Client code needs lots of API mocks to be tested on lower levels - DOM tests are resource-heavy.</p>
<p>Orchestration becomes difficult because you have to make sure that deployments are synchronized. It is even more difficult if you have separate teams for the backend and frontend.</p>
<p>Don’t forget about browser testing that also can have a lot of overlap with client-side integration tests. Even more, things to consider in terms of complexity and trade-offs.</p>
<p>That resulted in more code, which contributed to - again - increased complexity.</p>
<p>SEO became problematic, but thankfully this problem has been addressed by the ecosystem through <a href="https://reactjs.org/docs/react-dom-server.html">server-side rendering</a> and <a href="https://reactjs.org/docs/react-dom.html#hydrate">hydration</a>.</p>
<p>Good patterns have emerged too. UX became better and more creative. We are finally capable of defining client-side logic in a manageable and scalable way.</p>
<p>We all know now that we want to have components and avoid excessive side effects, together with uncontrollable state mutation.</p>
<p>React de facto became a standard.</p>
<h2>Simplicity renaissance</h2>
<p>The remedy to complexity is embracing the coupling and making the developer experience unified.</p>
<p><span>
      <a href="https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/9cea8/how-it-feels.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="how it feels" title="how it feels" src="https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/f058b/how-it-feels.png" srcset="https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/c26ae/how-it-feels.png 158w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/6bdcf/how-it-feels.png 315w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/f058b/how-it-feels.png 630w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/40601/how-it-feels.png 945w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/78612/how-it-feels.png 1260w,
https://michalpietraszko.com/static/101dc9780084c3b29106640f8ea67894/9cea8/how-it-feels.png 1278w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<h3>Simplicity through innovation in older frameworks.</h3>
<p>Ruby on Rails and Laravel are relevant.</p>
<p>Consider them. Their maturity will allow you to move very fast.</p>
<p>They have recently innovated in many interesting ways.</p>
<p>Take a look at <a href="https://laravel.com/docs/8.x/blade#components">Laravel’s components</a> or RoR’s <a href="https://hotwire.dev/">Hotwire</a>!</p>
<p>You can have an SPA experience while still writing a unified app!</p>
<h3>Simplicity through new generation of React frameworks.</h3>
<p>People who want to stay in JavaScript land should consider the following.</p>
<p><a href="https://nextjs.org/">Next.js</a> started a good trend by putting React and server logic next to each other.</p>
<p><a href="https://blitzjs.com/">Blitz.js</a>, which is based on Next, is a good ruby on rails equivalent. It brings the right amount of abstraction that makes you treat your app as a unified whole. Using it sometimes feels like cheating - in a good way. It inspired me to talk about the complexity issue in our ecosystem.</p>
<p><a href="https://remix.run/">Remix</a> with a fresh take on the problem domain and bringing a lot of good and forgotten patterns.</p>
<h3>React’s Server Components to make everything even better.</h3>
<p>Recently, the React team has presented a new idea that can make our component-driven world better.</p>
<p><a href="https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html">Consider reading the article and watching their presentation</a>.</p>
<p>When they are released, then we will end up in the best-case scenario where web apps are only dynamic in
places that require it without having to jump between server-side and client-side paradigms.</p>
<p>All of the frameworks above will benefit from them.</p>
<h2>In conclusion</h2>
<p>We should start asking ourselves if our standard approach is something we still want to maintain.</p>
<p>Suggested frameworks reduce complexity and allow us to experience the simplicity of older approaches while having the benefits of the modern approach.</p>
<p>They embrace the fact that both backend and frontend are tightly coupled and make the developer experience unified.</p>
<p>This is an opportunity to write less code, spend less time testing, simplify orchestration, spend less money on more people having to maintain the complexity, and put more effort into products we are trying to create.</p></section></div>]]>
            </description>
            <link>https://michalpietraszko.com/web-apps-are-too-complex-this-is-how-we-can-simplify-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726700</guid>
            <pubDate>Mon, 11 Jan 2021 09:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Haskell is our first choice for building production software systems]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25726588">thread link</a>) | @Albert_Camus
<br/>
January 11, 2021 | https://www.foxhound.systems/blog/why-haskell-for-production/ | <a href="https://web.archive.org/web/*/https://www.foxhound.systems/blog/why-haskell-for-production/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Haskell is the first programming language we reach for when we build production software systems. This likely seems unusual to anyone who only has a passing familiarity with the language. Haskell has a reputation for being an advanced language with a steep learning curve. It is also often thought of as a research language with limited practical utility.</p>
<p>While Haskell does have a very large surface area, with many concepts and a syntax that will feel unfamiliar to programmers coming from most other languages, it is unrivaled in the combination of developer productivity, code maintainability, software reliability, and performance that it offers. In this post I will cover some of the defining features of Haskell that make it an excellent, industrial-strength language that is well-suited for building commercial software, and why it is usually the first tool we consider using for new projects.</p>
<!--more-->
<h3 id="haskell-has-a-strong-static-type-system-that-prevents-errors-and-reduces-cognitive-load">Haskell has a strong static type system that prevents errors and reduces cognitive load</h3>
<p>Haskell has a very powerful static type system which serves as a programmer aid that catches and prevents many errors before code ever even runs. Many programmers encounter statically typed languages like Java or C++ and find that the compiler feels like an annoyance. By contrast, Haskell’s static type system, in conjunction with compile-time type checking, acts as an invaluable pair-programming buddy that gives instantaneous feedback during development.</p>
<p>There’s a far smaller cognitive load that needs to be maintained when writing Haskell than when writing in languages like Python, JavaScript, or PHP. Many concerns can be completely offloaded to the compiler rather than needing to be remembered by the programmer. For example, when writing Haskell, there’s no need to preemptively ask questions like:</p>
<ul>
<li>Do I need to check whether this field is null?</li>
<li>What if fields are missing from the request payload?</li>
<li>Has this string already been decoded to an integer?</li>
<li>What if this string can’t be decoded to an integer?</li>
<li>Will this operator implicitly convert this integer to a string?</li>
<li>Are these two values comparable?</li>
</ul>
<p>This is not to say that these are questions that never need answering in Haskell; it’s to say that the compiler will throw an error when you need to address one of these issues. For example, it’s possible that a Haskell program needs to handle values that are sometimes not present, but instead of setting any value to <code>NULL</code>, a Haskell programmer must use a <code>Maybe</code> type, which indicates that the value may not be there, and the compiler forces the programmer to explicitly handle the <code>Nothing</code> value; the case where the value is not present.</p>
<p>Haskell’s static type system also leads to other benefits. Haskell code uses type signatures that precede its functions and describe the types of each parameter and return value. For example, a signature like <code>Int -&gt; Int -&gt; Bool</code> indicates that a function takes two integers and returns a boolean value. Since these type signatures are checked and enforced by the compiler, this allows a programmer reading Haskell code to look only at type signatures when getting a sense of what a certain piece of code does. For example, one would not use the type signature above when looking for a function that manipulates strings, decodes JSON, or queries a database.</p>
<p>Type signatures can even be used to search through the entire corpus of Haskell code for a relevant function. Using <a href="https://hoogle.haskell.org/" target="_blank" rel="noopener">Hoogle</a>, Haskell’s API search, we can search for a type signature based off of functionality we know that we need. For example, if we need to convert an <code>Int</code> to a <code>Float</code>, we can search Hoogle for <code>Int -&gt; Float</code> (<a href="https://hoogle.haskell.org/?hoogle=Int+-%3E+Float" target="_blank" rel="noopener">search results</a>), which will point us to the aptly named <code>int2Float</code> function.</p>
<p>Haskell also lets us create polymorphic type signatures through the use of type variables, represented by lowercase type names. For example, a signature of <code>a -&gt; b -&gt; a</code> tells us that that the function takes two parameters of two arbitrary types, and returns a value that whose type is the same as the first parameter. Suppose we want to check whether an element is in a list. We’re looking for a function that takes an item to search for, a list of items, and returns a boolean. We don’t care about the type of the item, so long as the search item and the items in the list are of the same type. So we can search Hoogle for <code>a -&gt; [a] -&gt; Bool</code> (<a href="https://hoogle.haskell.org/?hoogle=a%20-%3E%20%5Ba%5D%20-%3E%20Bool" target="_blank" rel="noopener">search results</a>), which will point us to the <code>elem</code> function. Parametric types are an extremely powerful feature in Haskell and are what enable writing reusable code.</p>
<h3 id="haskell-enables-writing-code-that-is-composable-testable-and-has-predictable-side-effects">Haskell enables writing code that is composable, testable, and has predictable side-effects</h3>
<p>In addition to being statically typed, Haskell is a pure functional programming language. This is one of Haskell’s defining features and what the language is well known for, even amongst programmers that have only heard of Haskell but never used it. Writing in a pure functional style has many benefits, and is conducive to a well-organized code base.</p>
<p>The word “pure” in “pure functional programming” is significant. Purity in this sense means that the code we write is pure, or free of side-effects. Another term that describes this is <a href="https://en.wikipedia.org/wiki/Referential_transparency" target="_blank" rel="noopener">referential transparency</a>, or the property where any expression (e.g.&nbsp;a function call with a given list of parameters) can be replaced with its return value without changing the functionality of the code. This is only possible when such pure functions do not have side effects, such as creating files on the host system, running database queries, or making HTTP requests. Haskell’s type system imposes this sort of purity.</p>
<p>So does being pure mean that Haskell programs cannot have side effects? Certainly not—but it does mean that effects are pushed to the edge of our system. Any functions that perform I/O actions (such as querying a database or receiving HTTP requests) must have a return type that captures this. This means that type signatures like the ones we saw in the previous section (e.g.&nbsp;<code>Int -&gt; Float</code> or <code>a -&gt; [a] -&gt; Bool</code>) are indicators that the corresponding functions do not produce side effects, since <code>Float</code> and <code>Bool</code> are just primitive return types. For a contrasting example that includes a side effect, a function signature of <code>FilePath -&gt; IO String</code> indicates that the function takes a file path and performs an I/O action that returns a string (which is exactly what the <code>readFile</code> function does).</p>
<p>Another feature of a pure functional programming paradigm is higher-order functions, which are functions that take functions as parameters. One of the most commonly used higher-order functions is <code>fmap</code>, which applies a function to each value in a container (such as a list). For example, we can apply a function named <code>square</code>, which takes an integer and returns that integer multiplied by itself, to a list of integers to turn it into a list of squared integers:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>square ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span></span>
<span id="cb1-2">square x <span>=</span> x <span>*</span> x</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span>fmap</span> square [<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>,<span>5</span>] <span>-- returns [1,4,9,16,25]</span></span></code></pre></div>
<p>Code written in this style tends to be both composable and testable. This above example is trivial, but there are many applications of higher-order functions. For example, we can write a function like <code>renderPost</code> which takes a record of post data and returns the version of the post rendered in HTML. If we have a list of posts, we can run <code>fmap renderPost postList</code> to produce a list of rendered posts. Our <code>renderPost</code> function can be used in both the single case and the multi-post case without any changes, because composing it with <code>fmap</code> changes how we can apply it. We can also write tests for the <code>renderPost</code> function and compose it with <code>fmap</code> in our tests when validating the behavior for a list of posts.</p>
<h3 id="haskell-facilitates-rapid-development-worry-free-refactoring-and-excellent-maintainability">Haskell facilitates rapid development, worry-free refactoring, and excellent maintainability</h3>
<p>Through the combination of the aforementioned static types and pure functional style that Haskell has, developing software in Haskell tends to be very fast. One of the common development workflows we employ is relies on a tool called <a href="https://github.com/ndmitchell/ghcid" target="_blank" rel="noopener"><code>ghcid</code></a>, a simple command line tool that relies on the Haskell repl to automatically watch code for changes and incrementally recompile. This allows us to see any compiler errors in our code immediately after saving changes to a file. It’s not uncommon for us to open only a terminal with a text editor and <code>ghcid</code> while developing applications in Haskell.</p>
<p>While manually validating the results of our code is eventually necessary by refreshing a page in a browser or using a tool to validate a JSON endpoint, a lot of this can be deferred until the end of a programming session. Many of the would-be runtime errors a programmer would encounter when writing a web service in a language like Python or PHP are caught immediately and displayed as compiler errors by <code>ghcid</code>. This is a far cry from the need to switch to a browser window and refresh the page after making a change to some code, a development workflow that everyone who has worked on a web application is intimately familiar with.</p>
<p>Beyond the tight feedback loop during development, Haskell code is easy to refactor and modify. Like real world code written in any other language, such code written in Haskell is not write-only. It eventually will need to be maintained, updated, and extended, often by developers that are not the original authors of the code. With the aid of compile-time checking, many code refactors in Haskell become easy; a common refactoring workflow is to make a desired change in one location and then fix one compiler error at a time until the program compiles again. This is far easier than the equivalent changes in dynamically typed languages that offer no such assistance to the programmer.</p>
<p>Proponents of dynamically typed languages will often argue that automated tests supplant the need for compile-time type checking, and can help prevent errors as well. However, tests are not as powerful as type constraints. For tests to be effective, they must:</p>
<ol type="1">
<li>Actually be written, yet many real world code bases have limited testing</li>
<li>Make correct assertions</li>
<li>Be comprehensive (test a variety of inputs) …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.foxhound.systems/blog/why-haskell-for-production/">https://www.foxhound.systems/blog/why-haskell-for-production/</a></em></p>]]>
            </description>
            <link>https://www.foxhound.systems/blog/why-haskell-for-production/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726588</guid>
            <pubDate>Mon, 11 Jan 2021 09:24:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a Windows installer for your Haskell project]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726367">thread link</a>) | @unhammer
<br/>
January 11, 2021 | https://blog.patchgirl.io/haskell/2020/10/30/windows-installer-for-haskell-software.html | <a href="https://web.archive.org/web/*/https://blog.patchgirl.io/haskell/2020/10/30/windows-installer-for-haskell-software.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>30 Oct 2020</span></p><p>In this blog post, I’ll try to explain how you can create a really simple installer for your Haskell software on Windows and how to deal with external dependencies.</p>



<p>Alright, let’s get started. We are going to build a simple installer. It will install a desktop shortcut as well as a link shortcut in the start menu.
We will be using <a href="https://docs.haskellstack.org/en/stable/README/">Stack</a> to build our Haskell project and <a href="https://nsis.sourceforge.io/Main_Page">NSIS</a> to write the installer.</p>

<blockquote>
  <p>Note: GHC 8.8.[2|3|4] as well as 8.10.[1|2] are broken on windows so while we wait for 8.10.3 to fix everything, we will have to use 8.6.5 for now.</p>
</blockquote>

<p>Distributing software with external dependencies is slightly more complicated but not uncommon. We will make our project use <a href="https://github.com/lpsmith/postgresql-simple/">postgresql-simple</a> so we can learn how to deal with dependencies <img title=":books:" alt=":books:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4da.png" height="20" width="20"></p>

<p>I will assume you have Postgresql, Stack, and NSIS installed already! Also, I’ll be using Powershell as a terminal.</p>



<p>So let’s start by creating a simple dummy project: <code>stack new hello-world-app</code></p>

<p>As said before we want to use GHC 8.6.5 so let’s fix the resolver in <code>stack.yml</code>:</p>

<div><div><pre><code><span>resolver</span><span>:</span> <span>lts-14.27</span> <span># use ghc 8.6.5</span>

<span>packages</span><span>:</span>
<span>-</span> <span>.</span>
</code></pre></div></div>

<p>We also want to use postgresql-simple so let’s add a dependency in <code>package.yml</code>:</p>

<div><div><pre><code><span>dependencies</span><span>:</span>
<span>-</span> <span>base &gt;= 4.7 &amp;&amp; &lt; </span><span>5</span>
<span>-</span> <span>postgresql-simple</span>

<span>...</span>
</code></pre></div></div>

<p>Finally, we make our software use only one function which query our postgres DB just to make sure it’s running:</p>

<div><div><pre><code><span>{-# LANGUAGE OverloadedStrings   #-}</span>
<span>{-# LANGUAGE QuasiQuotes         #-}</span>
<span>{-# LANGUAGE ScopedTypeVariables #-}</span>

<span>module</span> <span>Lib</span>
    <span>(</span> <span>isPostgresRunning</span>
    <span>)</span> <span>where</span>

<span>import</span> <span>qualified</span> <span>Database.PostgreSQL.Simple</span>       <span>as</span> <span>PG</span>
<span>import</span>           <span>Database.PostgreSQL.Simple.SqlQQ</span>

<span>isPostgresRunning</span> <span>::</span> <span>IO</span> <span>()</span>
<span>isPostgresRunning</span> <span>=</span> <span>do</span>
  <span>password</span> <span>&lt;-</span> <span>getLine</span>
  <span>connection</span> <span>&lt;-</span> <span>PG</span><span>.</span><span>connect</span> <span>PG</span><span>.</span><span>defaultConnectInfo</span> <span>{</span> <span>PG</span><span>.</span><span>connectDatabase</span> <span>=</span> <span>""</span>
                                                 <span>,</span> <span>PG</span><span>.</span><span>connectUser</span> <span>=</span> <span>"postgres"</span>
                                                 <span>,</span> <span>PG</span><span>.</span><span>connectPort</span> <span>=</span> <span>5432</span>
                                                 <span>,</span> <span>PG</span><span>.</span><span>connectPassword</span> <span>=</span> <span>password</span>
                                                 <span>}</span>
  <span>_</span> <span>::</span> <span>[</span><span>PG</span><span>.</span><span>Only</span> <span>Int</span><span>]</span> <span>&lt;-</span> <span>PG</span><span>.</span><span>query_</span> <span>connection</span> <span>[</span><span>sql</span><span>|</span> SELECT 1 <span>|]</span>
  <span>return</span> <span>()</span>

</code></pre></div></div>

<p>Alright, next we build it with <code>stack build</code> and it should… not work…
Indeed, stack will fail something like:</p>
<div><div><pre><code>&lt;command line&gt;: can't load .so/.DLL for: C:/PROGRA~1/POSTGR~1/13/lib\libpq.dll (addDLL: C:\PROGRA~1\POSTGR~1\13\lib\libpq or dependencies not loaded. (Win32 er)

--  While building package hello-world-app-0.0.0 (scroll up to its section to see the error) using:
      C:\sr\setup-exe-cache\x86_64-windows\Cabal-simple_Z6RU0evB_2.4.0.1_ghc-8.6.5.exe --builddir=.stack-work\dist\e626a42b build lib:hello-world-app exe:hello-world-app-exe --ghc-options " -fdiagnostics-color=always"
    Process exited with code: ExitFailure 1
</code></pre></div></div>

<p>To build our project, stack is telling us that it needs <code>libpq.dll</code>. So let’s add the missing dependencies path to our path.
with Powershell you can use this command: <code>$env:Path += ";C:\Program Files\PostgreSQL\13\bin"</code>. It will temporarily modify the path variable for the current terminal.</p>

<blockquote>
  <p>Note: You can use <code>$env:path.split(";")</code> to print the current value for the PATH variable.</p>
</blockquote>

<p>Ok, now it should build without errors! We can try to execute it as well with: <code>stack exec hello-world-app-exe</code> and… tadaaa <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20">, our project is running! We can save our work and call it a day? <img title=":blush:" alt=":blush:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f60a.png" height="20" width="20"></p>

<p>Well, not really no. We still need to build our installer…</p>



<p>I picked NSIS but you might want to investigate other tools as well (<a href="https://jrsoftware.org/isinfo.php">Inno Setup</a> to name one). NSIS documentation felt nice and the fact that it came with examples, tutorials and a simple compiler convinced me into using it.</p>

<p>The idea behind an installer is that you write a script that will explain how to install software. The syntax is quite low level but it’s not that hard either.</p>

<p>So let’s write a simple installer in <code>installer.nsi</code>:</p>

<div><div><pre><code><span># we start by defining variables</span>
<span>!</span><span>define</span> <span>APPNAME</span> <span>"Hello World"</span>
<span>!</span><span>define</span> <span>COMPANYNAME</span> <span>"BestCompanyEver"</span>

<span>!</span><span>define</span> <span>EXECUTABLE_NAME</span> <span>"hello-world-app-exe.exe"</span>
<span>!</span><span>define</span> <span>ICON_NAME</span> <span>"icon.ico"</span>

<span>!</span><span>define</span> <span>VERSIONMAJOR</span> <span>1</span>
<span>!</span><span>define</span> <span>VERSIONMINOR</span> <span>0</span>
<span>!</span><span>define</span> <span>VERSIONPATCH</span> <span>0</span>

<span># create a directory where we will put our assets (eg: image, executable, uninstaller, dependencies...)</span>
<span>InstallDir</span> <span>"$PROGRAMFILES</span><span>\$</span><span>{COMPANYNAME}</span><span>\$</span><span>{VERSIONMAJOR}.${VERSIONMINOR}.${VERSIONPATCH}"</span> <span>#(ie: C:\Program Files\BestCompanyEver\1.0.0\)</span>

<span># Define the installer name</span>
<span>outFile</span> <span>"hello-world-app-installer.exe"</span>

<span>section</span> <span>"install"</span>
	<span>setOutPath</span> <span>$INSTDIR</span>

    <span># copy the executable in the installation directory</span>
    <span>file</span> <span>$</span><span>{</span><span>EXECUTABLE_NAME</span><span>}</span>

	<span># create a start menu shortcut</span>
	<span>createShortCut</span> <span>"$SMPROGRAMS</span><span>\$</span><span>{COMPANYNAME}</span><span>\$</span><span>{APPNAME}.lnk"</span> <span>"$INSTDIR</span><span>\$</span><span>{EXECUTABLE_NAME}"</span> <span>""</span> <span>"$INSTDIR</span><span>\$</span><span>{ICON_NAME}"</span>
	<span># create a desktop shortcut</span>
    <span>createShortCut</span> <span>"$DESKTOP</span><span>\$</span><span>{APPNAME}.lnk"</span> <span>"$INSTDIR</span><span>\$</span><span>{EXECUTABLE_NAME}"</span> <span>""</span> <span>"$INSTDIR</span><span>\$</span><span>{ICON_NAME}"</span>
<span>sectionEnd</span>
</code></pre></div></div>

<p>Quite concise indeed! We only need to compile it now. We can use the NSIS compiler that will create a <code>hello-world-app-installer.exe</code>.
We can now run the installer and check that our shortcut has been created in the Desktop folder.</p>

<p>Is it done now?</p>

<p><img title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> shortcuts have been created<br>
<img title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> Installation directory has been created and our executable has been paste inside it<br>
<img title=":x:" alt=":x:" src="https://github.githubassets.com/images/icons/emoji/unicode/274c.png" height="20" width="20"> It doesn’t run<br></p>

<p>Indeed, if you try to run the executable, a window should popup with a message like <code>The code execution cannot proceed because LIBPQ.dll was not found. Reinstalling the program may fix the problem.</code>. Which means it’s time to dive into the world of DLLs.</p>

<p>But wait something’s strange. When we executed our program earlier, it was working fine. So what happened meanwhile?<br>
Well, the reason it worked before was that we prefixed the command with <code>stack exec</code> which made sure the executable would find its required dependencies.</p>

<p>We can verify this quite easily.
Let’s copy our executable in a place we can access more easily first: <code>stack install</code>. <br>
For me it copied the executable here: <code>C:\Users\iori\AppData\Roaming\local\bin</code>.<br></p>

<p>Let’s cd inside this folder and run our executable without prefixing it with <code>stack exec</code>. We should see the same error message popping up.</p>

<p>Time to fix this by making sure our executable knows where to find the DLLs it depends on.</p>



<p><code>DLL</code> (dynamic link library) is our runtime dependencies. In our case, because we use <code>postgresql-simple</code>, our project requires some postgresql DLLs that we need to find.</p>

<h2 id="finding-the-required-dll">Finding the required DLL</h2>

<p>Many tools can help you list dependencies on windows like <a href="https://github.com/lucasg/Dependencies">Dependencies</a> or even <code>ldd</code> if you have <a href="https://cygwin.com/">cygwin</a> installed.
I chose to go with <a href="https://docs.microsoft.com/en-us/sysinternals/downloads/process-explorer">Process explorer</a> which can show the dependency of a running process.</p>

<p>So let’s run our project with: <code>stack exec hello-world-app-exe</code>
Then we should find our instance in Process explorer.</p>

<p><img src="https://blog.patchgirl.io/assets/img/process-explorer.png" alt="test"></p>

<p>By clicking <strong>View</strong> -&gt; <strong>DLL</strong>, we can list our program DLLs. We don’t need to take care of the DLLs that are in the <code>C:\Windows\System32</code>.
On the other hand, we see that our executable requires 5 postgresql DLL: <em>libpq</em>, <em>libcrypto</em>, <em>libiconv</em>, <em>libintl</em> and <em>libssl</em>.
Those are the DLLs we want for our program. So we can simply copy them into the root folder of our executable and now, running our program without prefixing with <code>stack exec</code> should work fine! <img title=":fireworks:" alt=":fireworks:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f386.png" height="20" width="20"></p>

<p>So are we done now? Not quite so, we still need to update the installer to take the DLLs into account.</p>

<h2 id="copying-dlls-with-nsis">Copying DLLs with NSIS</h2>

<p>We could copy them one by one with <code>File myDll.dll</code> but because we might have a lot of them, let’s just put all our assets into a folder and copy that folder:</p>

<pre><code>section "install"
	setOutPath $INSTDIR

    file "assets\"

    ...
sectionEnd
</code></pre>

<p>We can then, put our DLLs, icon, and executable into the assets/ folder and Now we are truly done! <img title=":sparkler:" alt=":sparkler:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f387.png" height="20" width="20"></p>

<h2 id="really-is-this-the-end">Really? Is this the end?</h2>

<p>Well, this post was intended to be simple but actually, you shouldn’t stop here. You should add to your installer an uninstaller that will take care of removing all the folders/files, shortcuts, and whatnot.</p>

<p>I invite you to read NSIS documentation for that <img title=":blue_book:" alt=":blue_book:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d8.png" height="20" width="20"></p>

<p>This example is available in the repo <a href="https://github.com/patchgirl/windows-haskell-installer-example">patchgirl/windows-haskell-installer-example</a></p>



<p>For a simple case like this one, writing an installer isn’t too hard. If you don’t need shortcuts/icons and would satisfy with a simple executable that you can run from a terminal, you might want to investigate:</p>
<ul>
  <li>
<a href="https://hackage.haskell.org/package/file-embed">file-embed</a> to embed any files (picture, documentation,…) within your executable</li>
  <li>
<a href="https://vrom911.github.io/blog/github-actions-releases">Vrom911 blog post</a> to generate executable from Github Action for MacOS/Windows/Linux</li>
  <li>
<a href="https://input-output-hk.github.io/haskell.nix/">Haskell.nix</a> to cross-compile your Haskell project with Nix</li>
</ul>

<p>Also, I haven’t tried it but there exists a Haskell package called <a href="https://hackage.haskell.org/package/nsis">nsis</a> which provides a more concise DSL to build your script.</p>

<p>I hope this article helps you write more Haskell on Windows!!</p>

<p><img title=":cactus:" alt=":cactus:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f335.png" height="20" width="20"></p>

</div>



    </div></div>]]>
            </description>
            <link>https://blog.patchgirl.io/haskell/2020/10/30/windows-installer-for-haskell-software.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726367</guid>
            <pubDate>Mon, 11 Jan 2021 08:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running a Blog with iPad]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25726147">thread link</a>) | @prof18
<br/>
January 11, 2021 | https://www.marcogomiero.com/posts/2021/running-blog-ipad/ | <a href="https://web.archive.org/web/*/https://www.marcogomiero.com/posts/2021/running-blog-ipad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It’s been a few years since I started writing this blog, and I quite like sharing my thoughts and experiences. After a short while spent on Medium, I decided I wanted to be the sole owner of my content, so I started experimenting with different solutions and ideas. After I finally landed on the “perfect” tech architecture (I know, I’m lying. There’s no perfect solution and Future Me will most likely refactor and (over)re-engineer the current solution), I started to seek the “perfect” writing setup.</p><p>I’m pretty confident I’ve ended up with something worth sharing.</p><h2>A bit about tech stack</h2><p>Before speaking about the setup, I want to spend some words about the tech stack. The site is built with <a href="https://gohugo.io/"><strong>Hugo</strong></a>, one of the most popular static site generator. It is a powerful tool that lets you have a website up and running in just a few minutes. With Hugo, you can write articles or content with <strong>Markdown</strong>, and then Markdown pages are automatically transformed into HTML and CSS pages when you build the website. But how Hugo works is not the topic of this article, so if you are interested to know a bit more, I suggest you look over the <a href="https://gohugo.io/documentation/">documentation</a>.</p><p>As mentioned above, the final output of Hugo is a static website and there are many free solutions to host it. To name a few: <a href="https://pages.github.com/">GitHub Pages</a> or <a href="https://www.netlify.com/">Netlify</a> or <a href="https://firebase.google.com/docs/hosting">Firebase Hosting</a>. Personally, I’ve always used <strong>GitHub Pages</strong> and I’m still using it. If you have trouble choosing, there is <a href="https://gohugo.io/hosting-and-deployment/">an entire section on the Hugo doc</a> there to help you.</p><p>For handling the publications, I’ve set up a little <strong>GitHub action</strong> (you can give a look at it <a href="https://github.com/prof18/marcogomiero.com/blob/master/.github/workflows/gh-pages.yml">on my GitHub</a>) that builds the website and pushes all the changes to a special branch reserved for GitHub Pages. This action is triggered every time I push something on the master branch.</p><p>That’s it for the tech stack. It was a quick but necessary overview to better introduce the context but if you have any kind of question, feel free to reach me out on Twitter <a href="https://twitter.com/marcoGomier">@marcoGomier</a>.</p><h2>Writing Setup</h2><p>My main machine is a 15” MacBook Pro - a fantastic tool for my day-to-day job. But after using it for writing some articles, I’ve discovered that a 15” machine is way too heavy, big, and overkill just for blogging.</p><p>When I’m writing something, I like to stay outside in the courtyard, sitting in the deckchair or in the hammock or in a simple chair. And when the weather does not allow it, I prefer to stay on the couch or in bed rather than in my work setup. And in all of these scenarios, my MacBook is too uncomfortable to use. So I started to think about alternatives.</p><p>First of all, I’ve tried to resurrect my old Asus T100HA with a lightweight Linux distro, but in the end I had to drop it due to issues with some drivers and a battery not at its glory anymore. So, after some thinking, I’ve decided to give <strong>iPad</strong> a try: blogging doesn’t require a big screen and CPU power, whereas it does ask for a reliable and comfortable machine, with decent autonomy.</p><p>After some research, I found out that the best compromise between my needs and my budget was the <strong>iPad Air 3</strong> (I made this choice back in May 2020. If it was today, I would choose the new iPad Air 4). For the keyboard, I decided to go with the <a href="https://www.logitech.com/en-us/products/ipad-keyboards/combo-touch.html">Logitech Combo Touch</a>.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/ipad-overview.jpeg"><img src="https://www.marcogomiero.com/img/blogging-ipad/ipad-overview.jpeg"></a></figure><p>To be honest, I quickly fell in love with this Logitech solution. With this keyboard-cover, you will transform the iPad into a notebook. With the kickstand, you can tilt the iPad up to 40 degrees. Then you have a very good trackpad (better than some Window notebooks!), a row of function keys (brightness and volume controls, home button, lock button, spotlight, etc), and backlit keys.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/keyboard-detail.jpeg"><img src="https://www.marcogomiero.com/img/blogging-ipad/keyboard-detail.jpeg"></a></figure><p>The only compromise is the fact that it makes the iPad a bit heavier and thicker.</p><h3>Applications</h3><p>As I mentioned above, the website is stored in a git repository and I manage all “the git lifecycle” through <a href="https://apps.apple.com/it/app/working-copy-git-client/id896694807?l=en"><strong>Working Copy</strong></a> that I think is the best git client that you can find in the AppStore.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/working-copy-screen.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/working-copy-screen.png" alt="Working Copy"></a><figcaption><p>Working Copy</p></figcaption></figure><p>With Working Copy you can browse the content of the repo but you can also make edits with a built-in editor that also provides the user with syntax highlighting. However, the feature that made me choose this client is the support of the File iOs app, that makes the repositories browsable from other apps too.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/working-copy-files-app.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/working-copy-files-app.png" alt="iOs File app"></a><figcaption><p>iOs File app</p></figcaption></figure><p>In this way, I can open and edit an article directly from any Markdown editor - for for the time being my go-to choice is <a href="https://apps.apple.com/it/app/mweb-powerful-markdown-app/id1183407767?l=en"><strong>MWeb</strong></a>.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/mweb-screen.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/mweb-screen.png" alt="MWeb"></a><figcaption><p>MWeb</p></figcaption></figure><p>I like it because it provides themes, a powerful preview, a useful toolbar with plenty of quick actions, and a lot of keyboard shortcuts.</p><p>In the past, I’ve used <a href="https://apps.apple.com/it/app/pretext/id1347707000?l=en">Pretext</a>, a little bit more basic. In the future, I would like to try <a href="https://apps.apple.com/it/app/ia-writer/id775737172?l=en">iA Writer</a> but it is quite expensive and I don’t know if it’s worth the investment (maybe if there will be a demo or a trial version in the future I can finally make a decision).</p><p>And that’s it! I write an article in MWeb and when I finish it, I publish it on the master branch of the Github repo through Working Client. Then, the GitHub Action is triggered and the article is live.</p><p>Bonus. If I have to edit or prepare an image for an article (like the ones below), I use <a href="https://apps.apple.com/it/app/pixelmator/id924695435?l=en"><strong>Pixelmator</strong></a>, a very good image editor for iOs.</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/pixelmator-screen.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/pixelmator-screen.png" alt="Pixelmator"></a><figcaption><p>Pixelmator</p></figcaption></figure><h3>Automations</h3><p>After writing some articles, I’ve discovered that there are some boring activities to achieve on iPad, like creating a new article, adding a new image for an article, etc. So, during one of the “its-blogging-time-but-i-dont-want-to-write” sessions (procrastination FTW) I decided to automate some of these boring things.</p><h4>Add an image to an article</h4><p>To show an image on a Hugo Markdown page, it is necessary to write a shortcode; for example, for the Pixelmator’s screen posted above the corresponding shortcode is the following:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="markdown">{{<span>&lt;</span> <span>figure</span> <span>src</span><span>=</span><span>"/img/blogging-ipad/pixelmator-screen.png"</span>  <span>link</span><span>=</span><span>"/img/blogging-ipad/pixelmator-screen.png"</span> <span>caption</span><span>=</span><span>"Pixelmator"</span> <span>&gt;</span>}}
</code></pre></td></tr></tbody></table></div></div><p>So, every time I need to add an image to an article, I need to:</p><ol><li>Create a folder into the img folder of the website (if not present. I create a folder for every article just to keep things clean);</li><li>Move the image from the iPad gallery to the folder created above;</li><li>Rename the image with a more readable format;</li><li>Write the shortcode for the image in the article.</li></ol><p>Way too many steps for a lazy person like me!</p><p>To try to automate these steps, I started playing with the <strong>Apple Shortcuts iOS app</strong>. If you’ve never heard about it, I suggest you take a peek. It’s really powerful and it can greatly simplify your life.</p><blockquote><p>A shortcut is a quick way to get one or more tasks done with your apps. The Shortcuts app lets you create your own shortcuts with multiple steps. For example, build a “Surf Time” shortcut that grabs the surf report, gives an ETA to the beach, and launches your surf music playlist. <em><a href="https://support.apple.com/guide/shortcuts/welcome/ios">Shortcuts user guide</a></em></p></blockquote><p>After some trials, I was able to achieve my goal and, as you can see in the video, when I need to add an image to an article I can launch a shortcut that does all the job for me.</p><p><iframe src="https://www.youtube-nocookie.com/embed/MdSv-PwC5N8" allowfullscreen="" title="YouTube Video"></iframe></p><p>Here’s the “source code” of the shortcut:</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/new-image-shortcut.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/new-image-shortcut.png" alt="iOs shortcut to move an image from the camera roll to the repo of the site and generate the Hugo shortcode"></a><figcaption><p>iOs shortcut to move an image from the camera roll to the repo of the site and generate the Hugo shortcode</p></figcaption></figure><p>As you can see in the image above, it is possible to ask for input and then store it in a variable. So, first of all, I receive as input the name of the image and the folder, then I open the system image picker and I store the chosen image in a variable. Then, before moving the image, I extract the file extension of the image and store it in another variable.
And now finally, it is time to move the image to the specific folder with the new name. This action is performed with the shortcut support provided by Working Copy. And at the end, I create the shortcode for the specific image and I store it in the clipboard ready to be pasted in the article.</p><h4>Create a new article draft</h4><p>Another boring activity is the creation of a new article. That’s because for every article I need to write some metadata at the top, like the date, the title, etc.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td><td><pre><code data-lang="markdown">---
layout: post
title:  "Running a blog with iPad"
date:   2021-01-01
show_in_homepage: false
draft: true
tags: [Blogging]
---
</code></pre></td></tr></tbody></table></div></div><p>So, I made another shortcut!</p><p><iframe src="https://www.youtube-nocookie.com/embed/v18imNIwgyc" allowfullscreen="" title="YouTube Video"></iframe></p><p>And here’s the “source code” of this shortcut:</p><figure><a href="https://www.marcogomiero.com/img/blogging-ipad/new-article-draft-shortcut.png"><img src="https://www.marcogomiero.com/img/blogging-ipad/new-article-draft-shortcut.png" alt="iOs shortcut to create a new article draft with some metadata"></a><figcaption><p>iOs shortcut to create a new article draft with some metadata</p></figcaption></figure><p>The structure is very similar to the other shortcut. First of all, I make sure that I’m in the develop branch of the website where I make all the draft work. Next, I ask for some input that I store in some variables. As you can see it is also possible to do some if/else statements.
And at the end, I create the metadata that will be placed inside the new article.</p><h2>Conclusions</h2><p>And that’s how I write in my blog. I’m very happy with this setup because it let me only focus on writing. Every “boring” activity is completely automated and in this way, I have “just” to write. And by using an iPad I’m not tempted to re-open my IDE to procrastinate writing.</p><p>If you have any kind of suggestions about apps, accessories, whatever, feel free to reach me out on Twitter <a href="https://twitter.com/marcoGomier">@marcoGomier</a>.</p></div></div>]]>
            </description>
            <link>https://www.marcogomiero.com/posts/2021/running-blog-ipad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726147</guid>
            <pubDate>Mon, 11 Jan 2021 08:16:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recommended Engineering Management Books]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25726109">thread link</a>) | @kiyanwang
<br/>
January 11, 2021 | https://caitiem.com/2020/12/28/recommended-engineering-management-books/ | <a href="https://web.archive.org/web/*/https://caitiem.com/2020/12/28/recommended-engineering-management-books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main" role="main">

			
<article id="post-2053">

	

	
			<figure>
				<img width="1019" height="501" src="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=1019" alt="" loading="lazy" srcset="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg 1019w, https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=150 150w, https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=300 300w, https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=768 768w" sizes="(max-width: 1019px) 100vw, 1019px" data-attachment-id="2109" data-permalink="https://caitiem.com/2020/12/28/recommended-engineering-management-books/books20130912-2/" data-orig-file="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg" data-orig-size="1019,501" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="books20130912" data-image-description="" data-medium-file="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=300" data-large-file="https://caitiem20.files.wordpress.com/2020/12/books20130912-1.jpg?w=782">			</figure><!-- .post-thumbnail -->

			
	<div>
		
<p>Over the past 3.5 years my career has grown and transformed from Individual Contributor (IC) to an Engineering Manager of multiple teams, and all the roles in between as I built the Azure Sphere Security Services (AS3) Team from 2 people to 20 people.&nbsp; I undertook this journey in the Summer of 2017 to help transform a <a href="https://www.wired.com/story/project-sopris-iot-security/">Microsoft Research project, Project Sopri</a>s, into a Generally Available (GA) product <a href="https://azure.microsoft.com/en-us/services/azure-sphere/">Azure Sphere</a>.&nbsp;</p>



<p>As the AS3 Team grew, I went through a massive amount of personal growth and learning as well.&nbsp; In December 2017 I stepped into a manager role for the first time in my career.&nbsp; I had been a professional software engineer for over a decade at this point, and was up for a totally new challenge.&nbsp; I knew that the skills and job of growing and managing a team and then an organization were totally different than what I had been actively developing over the last decade of my career.&nbsp; As I went through this period of growth I was lucky enough to have several friends, coaches, and mentors share their experiences with me, and recommend some great books to help me along my learning journey.&nbsp; </p>



<p>Below is my curated list of the most influential and impactful books that helped me along the way, and that I highly recommend to Engineering Managers&nbsp;</p>



<h2>The Manager’s Path: A Guide for Tech Leaders Navigating Growth &amp; Change by Camille Fournier</h2>



<div><figure><img src="https://m.media-amazon.com/images/I/51BHEtpF4eL._SY346_.jpg" alt="" width="299" height="450"></figure></div>



<p>This is a must read for anyone considering managing engineering teams, it is as good as or better than the hype surrounding it.&nbsp; The book starts off from the individual contributor perspective and then each subsequent chapter explores the next level of management complexity.&nbsp; Each chapter focuses on an engineering management role, like technical lead, manager of people, or manager of multiple teams, and manager of managers.</p>



<p>Over the past 3.5 years I’ve come back to this book several times, re-reading the chapters around my newest role.&nbsp; For instance when I transitioned into a manager of managers role, I re-read that chapter and the one before and after it.&nbsp; These were great reminders on what I should be focused on, what challenges my directs were facing, and what challenges and motivations my boss was focused on.&nbsp;</p>



<p>One of the sections I really loved was on debugging dysfunctional teams.&nbsp; As an engineer I am a great debugger, often able to piece together logs, metrics, and weird behavior to diagnose what’s going wrong in a system.&nbsp; This was the first time I had seen the term debugging applied to people and organizations, and it helped frame the work of how to start investigating dysfunction in a team, and how to discover the source of the problem.&nbsp;</p>



<p>Honestly I recommend this book to every engineer, solely for the chapter on how to be managed, and what you should and can expect from your manager.&nbsp; Even if you never plan on taking on a management role this book provides an excellent overview of the challenges and motivations of folks in varying levels of an engineering organization and will help you better navigate your org.&nbsp;</p>



<h2>Thanks for the Feedback by Douglas Stone &amp; Sheila Heen</h2>



<p>Prior to managing I had given peer feedback as part of performance reviews at various companies, but I did not consider this a strength of mine.&nbsp; Now giving feedback was a critical skill for my role as a manager.&nbsp; Early on I sought out several resources on how to give and receive feedback well, and found “Thanks for the Feedback” to be an tremendous resource.</p>



<div><figure><img src="https://blackwells.co.uk/jacket/l/9780670922635.jpg" alt="" width="336" height="512"></figure></div>



<p>Thanks for the Feedback is framed as a resource for receiving and processing the multitudes of feedback you receive.&nbsp; However, any one who reads this book, will also learn how to be a more skilled feedback giver.&nbsp;</p>



<p>I highly recommend reading the book in its entirety, but I wanted to share one of the fundamental ideas in this book that resonated with me.&nbsp; Feedback is really three different things, with three different purposes:</p>



<ul><li><strong>Appreciation</strong>,&nbsp; the goal is to help people feel appreciated.&nbsp; Sometimes they may just need motivation and encouragement to keep going when tackling tough problems</li><li><strong>Coaching</strong>, the goal is to help the receiver expand their knowledge, sharpen skills, and increase confidence.&nbsp;</li><li><strong>Evaluation,</strong> the goal here is to rate or rank the receiver’s work against a set of standards to align expectations and inform decision making.&nbsp;</li></ul>



<p>This idea that feedback serves a variety of different purposes was eye opening, and help me more clearly think about how and when to provide feedback.&nbsp; Taking this perspective along with the multitude of lessons learned from this book was tremendously helpful to me.</p>



<h2>The Hard Thing About Hard Things: Building a Business When There are No Easy Answers by Ben Horowitz</h2>



<div><figure><a href="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg"><img loading="lazy" data-attachment-id="2057" data-permalink="https://caitiem.com/image-1/" data-orig-file="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg" data-orig-size="1752,2560" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-medium-file="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=205" data-large-file="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=701" src="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=701" alt="" width="251" height="367" srcset="https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=251 251w, https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=502 502w, https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=103 103w, https://caitiem20.files.wordpress.com/2020/12/image-1.jpeg?w=205 205w" sizes="(max-width: 251px) 100vw, 251px"></a></figure></div>



<p>The book starts off acknowledging a problem with most management books “they attempt to provide a recipe for challenges that have no recipes.&nbsp; There’s no recipe for really complicated, dynamic situations.”&nbsp; This instantly resonated with me as I was reading it in November 2019.&nbsp; I had been a manager for about two years, and had grown the AS3 team from 2 to 15 people.&nbsp; We’d spent the past two years turning a research project into what would soon be a GA’d product in February 2020.&nbsp; There is no recipe for how to do this, what I was doing was a hard thing.&nbsp;</p>



<p>Horowitz packs the book with a variety of entertaining stories from his career as a venture capitalist and entrepreneur to emphasize his message and points on leadership and various challenges.&nbsp; In addition there are a few key takeaways that have stayed with me.</p>



<ul><li><strong>Take care of the people, the product, and the profits in that order</strong>.&nbsp; This quote resonated with me and the kind of organization I want to build and run.&nbsp; Chapter 5, which bears this quote as a title goes into some of the challenges that can arise when setting out with this mission and how to overcome them, like hiring, training, and management debt.&nbsp;</li><li><strong>Part of Management is training your people.</strong> In big companies this is often neglected as it’s the role of HR or corporate to produce training programs.&nbsp; These can sometimes be valuable but are often overly generic.&nbsp; As a manager make sure you are training your people for the specific job they are doing.&nbsp; Things like how to work in your specific code base, what are the architectural standards and guidelines, what makes a good design doc, etc…Make sure you are intentionally designing on boarding programs, meetings, and workshops to facilitate learning.</li></ul>



<h2>Accelerate: Building and Scaling High Performing Technology Organizations by Nicole Forsgren, PhD, Jez Humble, and Gene Kim</h2>



<div><figure><img src="https://itrevolution.com/wp-content/uploads/2017/09/Accelerate_3D_Shingo-e1567716184319.jpg" alt="" width="331" height="473"></figure></div>



<p>Accelerate is a summary of the research and learnings discovered by Dr Forsgren and her colleagues from the 2014-2017 State of DevOps report.&nbsp; This book is a must read for any engineering leader, as it gives you a clear outline on how to set your team up for success by investing in 24 key capabilities which will drive improvement in your teams software delivery performance.&nbsp;</p>



<p>There are some non-surprising findings like using version control is important to team performance, and other not so obvious ones like focusing on continuous integration and software delivery performance positively impacts culture.</p>



<p>This book and the ongoing research released by Dr. Forsgren, et. Al has had a huge influence on the priorities of my team.&nbsp; We embraced Accelerate principles early on in the development of the Azure Sphere Security Services, and that investment has paid huge dividends over time.&nbsp;</p>



<h2>Dare to Lead: Brave Work.&nbsp; Tough Conversations.&nbsp; Whole Hearts. by Brene Brown</h2>



<p>I’m a huge fan of Brene Brown’s work as a shame and vulnerability researcher.&nbsp; In October 2018 she released Dare to Lead applying her research to Leadership.&nbsp; This quote sums up why this book is important</p>



<div><figure><img src="https://pictures.abebooks.com/isbn/9780399592522-us.jpg" alt="" width="343" height="520"></figure></div>



<p>“There’s an old saying that I lead by now: “People don’t care how much you know until they know how much you care.” Brene Brown</p>



<p>This book dives into what it takes to become a brave and courageous leader.&nbsp; Spoiler a lot of it involves embracing vulnerability and living authentically, something that is far easier to say than do.&nbsp; The book defines vulnerability as “the emotion we experience during times of uncertainty, risk, and emotional exposure…Vulnerability is not winning or losing.&nbsp; It’s having the courage to show up when you can’t control the outcome.”</p>



<p>One section I continually return to is the definitions of the two leadership styles: armored leadership and daring leadership.&nbsp; Brown’s research uncovered 16 traits for each of these leadership styles and breaks each one of them down.&nbsp; I highly recommend going through these periodically and checking in on your own leadership style and where there is room for growth and improvement.&nbsp;</p>



<p>Another great exercise that Brown presents in the book is one around values.&nbsp; She challenges readers to pick one to two core values, not ten or fifteen, because as Jim Collins said “If you have more than three priorities, you have no priorities.”&nbsp; Having clarity around your core values allows you to live and lead more authentically.&nbsp;</p>



<p>Overall this book is one of the best for dealing with the “soft skills” of leadership.&nbsp; How do you show up whole heartedly and help create a team that can do the same is one of the biggest challenges of taking on a management role.&nbsp;</p>



<h2>Switch: How to Change Things When Change is Hard</h2>



<div><figure><img src="https://images-na.ssl-images-amazon.com/images/I/81QxTfW8-PL.jpg" alt="" width="356" height="511"></figure></div>



<p>This book is an awesome resource for understanding the psychology and sociology behind what motivates people and how to be successful enacting change from small to epic scale.  I loved this book as it provides real practical tips for how to enact change across a team or organization through researched principles and real world examples.&nbsp;</p>



<p>The book starts by acknowledging that people have both emotional and rational sides, and motivating each is important for effective change.&nbsp; In engineering orgs we often only motivate the rationale side, because the analytical brain is all important.&nbsp; Sometimes …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://caitiem.com/2020/12/28/recommended-engineering-management-books/">https://caitiem.com/2020/12/28/recommended-engineering-management-books/</a></em></p>]]>
            </description>
            <link>https://caitiem.com/2020/12/28/recommended-engineering-management-books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726109</guid>
            <pubDate>Mon, 11 Jan 2021 08:10:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The clipboard history feature is the best thing since sliced bread]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25726043">thread link</a>) | @madewulf
<br/>
January 11, 2021 | https://multitasked.net/2021/01/11/the-clipboard-history.html | <a href="https://web.archive.org/web/*/https://multitasked.net/2021/01/11/the-clipboard-history.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>For those who do not know, having a clipboard history is the best thing since sliced bread.</p>

<p>It is that little feature that allows you, after you made a few copy actions (ctrl+c on Windows or command-c on Mac), to choose any of the copied texts to paste it.</p>

<p>It looks like this when I use <a href="https://www.alfredapp.com/">Alfred</a>, a productivity tool on Mac, by pression option-command-c (the three buttons at once).</p>

<p><img src="https://multitasked.net/uploads/2021/302b4c92a6.png" width="480" height="451" alt=""></p>

<p>Just click on the text you want, and it will be copied wherever your cursor happened to be.</p>

<p>You can even search in your clipboard history for something you copied a few days before, as in this screenshot.
<img src="https://multitasked.net/uploads/2021/394bad9b53.png" width="480" height="451" alt=""></p>

<p>This feature is a huge time saver. There is a lot of alternative apps providing this feature and apparently, it’s now a standard part of <a href="https://www.howtogeek.com/671222/how-to-enable-and-use-clipboard-history-on-windows-10/">Windows 10 too</a>.</p>

<p>Remember all these times where you have to copy a few distinct cells from an Excel file to insert them in a report, and how you switch constantly between the documents? With this feature, you can just copy one by one all the cells that you want, switch to your report (only once!), and paste one by one the values you needed.</p>

<p>Or, are you looking for that email address you sent yesterday? Just open your clipboard history, type a few letters of the name of the person, and there you go, it’s here. You don’t have to open your emails, perform a search, it is just right there, and it very often allows you to stay focused on your current task.</p>

<p>So, you get it, I love it. You should use it. I know I sound like a cheesy salesman here, but that is how convinced I am.</p>

    </div></div>]]>
            </description>
            <link>https://multitasked.net/2021/01/11/the-clipboard-history.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25726043</guid>
            <pubDate>Mon, 11 Jan 2021 08:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding the spellchecker, pt.2: Just look in the dictionary, they said]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25725583">thread link</a>) | @zverok
<br/>
January 10, 2021 | https://zverok.github.io/blog/2021-01-09-spellchecker-2.html | <a href="https://web.archive.org/web/*/https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p><strong><em>This is the second part of the “Rebuilding the spellchecker” series, dedicated to the explanation of how the world’s most popular spellchecker Hunspell works.</em></strong></p>

<p><strong>Quick recap:</strong> <a href="https://zverok.github.io/blog/2021-01-05-spellchecker-1.html">In the first part</a>, I’ve described what Hunspell is; and why I decided to rewrite it in Python. It is an <strong>explanatory rewrite</strong> dedicated to uncovering the knowledge behind the Hunspell by “translating” it into a high-level language, with a lot of comments.</p>

<p>Now, let’s dive into how the stuff really works!</p>

<p>There are two main parts of word-by-word spellchecker algorithms:</p>

<ol>
  <li>Check if a word is correct: <strong>“lookup”</strong> part</li>
  <li>Propose the correction for incorrect words: <strong>“suggest”</strong> part</li>
</ol>

<blockquote>
  <p>Hunspell also implements several other algorithms to be useful as standalone software. It can extract plain text from numerous formats, like HTML or TeX, split it into words (tokenize), correctly handling punctuation—but at the end of the day, a word-by-word correctness check is applied. I excused myself from implementing “wrapper” algorithms: text extraction and tokenization are thoroughly investigated topics, and there are numerous libraries in any language solving it with decent speed and quality.</p>
</blockquote>

<p>Hunspell works on a word-by-word basis (no context is taken into account). Each word is just <strong>looked up</strong> in the <strong>dictionary</strong> loaded from the plaintext  <code>&lt;langname&gt;.dic</code> file in Hunspell-specific format. If it is not considered correct by dictionary lookup (which, as we’ll see soon, is more complex than “is it present in the dictionary”), several algorithms of <strong>suggest</strong> are applied sequentially, trying to find correct words similar to the given one.</p>

<h2 id="hunspells-lookup-algorithm-or-just-look-in-the-dictionary-they-said">Hunspell’s lookup algorithm, or, Just look in the dictionary, they said!</h2>

<p>When coming from English-only spellchecking, the developers tend to perceive the “lookup” part as trivial (e.g., the famous <a href="https://norvig.com/spell-correct.html">Peter Norvig’s article</a> starts from the assumption that only the correction—”suggest”—part deserves some explanations). But that’s not quite so.</p>

<p>The first and most straightforward idea<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> for the lookup would be: we’ll just take the dictionary (presumably, the flat list of all correct words) and look for our candidate word in this list: if it is there, it is correct. End of story.</p>

<p>Now, Hunspell’s dictionaries exist for many languages and have a plaintext format, which, at the first sight is quite close to a plain word list—so, probably it would be easy to reuse them? Let’s take a look into the <a href="https://github.com/LibreOffice/dictionaries/blob/master/en/en_US.dic"><code>en_US.dic</code></a> in the LibreOffice dictionary repository. You’ll see a list of words in the following format:</p>

<div><div><pre><code>...
acetyl
acetylene/M
ache/DSMG
achene/MS
achievable/U
achieve/BLZGDRS
achievement/SM
...
</code></pre></div></div>

<p>The line <code>ache/DSMG</code> specifies the <em>stem</em> <code>ache</code>, having <code>D</code>, <code>S</code>, <code>M</code>, <code>G</code> <em>flags</em> associated with it. The meaning of flags is defined by <a href="https://github.com/LibreOffice/dictionaries/blob/master/en/en_US.aff"><code>en_US.aff</code></a> (called “affix file”, or just aff-file; every Hunspell dictionary is distributed as a pair of <code>.dic</code> and <code>.aff</code> files).</p>

<h3 id="affix-compression">Affix compression</h3>

<p>In this particular case, all four flags are associated with word <em>suffixes</em>. Here’s the definition of <code>D</code> suffix:</p>

<div><div><pre><code>SFX D Y 4                    # Suffix header: suffix (SFX), with flag D, combinable with prefixes (Y), 4 entries:
SFX D   0  d    e            # * if the stem ends is "e", strip nothing (0), and add "d"
SFX D   y  ied  [^aeiou]y    # * if the stem ends with "y", preceded by non-vowel, strip "y" and add "ied"
SFX D   0  ed   [^ey]        # * if the stem ends with not "e", and not "y", strip nothing, add "ed"
SFX D   0  ed   [aeiou]y     # * "y" with preceding vowel: strip nothing, add "ed"
</code></pre></div></div>

<p>For our <code>ache</code> stem, this definition says that form <code>ached</code> exists. In the similar fashion, <code>S</code> flag defines that word <code>aches</code> exists, <code>G</code> flag defines <code>aching</code>, <code>M</code> flag defines <code>ache's</code>. So, the <code>ache/DSMG</code> line in <code>.dic</code> file specifies 5 correct words: “ache”, “ached”, “aches”, “aching”, “ache’s”.</p>

<blockquote>
  <p>Note: the fact that flags are similar to the suffixes they define (<code>S</code> flag defines suffix <code>-s</code> and so on) is just a convention. It is rather a handy mnemonics that creators of <code>en_US</code> dictionary used, and there could be any other symbol.</p>
</blockquote>

<p>In the similar fashion, word prefixes might be defined (specified with flags in dic-file, and described with <code>PFX</code> directive in aff-file). Say, this definition:</p>



<p>…defines these forms: <em>advantage, advantage’s, advantaging, advantaged, advantages, disadvantage’s, disadvantaging, disadvantaged, disadvantages, disadvantage</em> (all combinations of four suffixes and a prefix “dis-“).</p>

<p>This technique of “packing” dictionaries is called <strong>affix compression</strong>, and its primary goal is to optimize dictionary size: on disk and in memory. It becomes extremely important for languages with rich inflection. For example, in English one stem might produce no more than ten forms, but in Ukrainian it could easily be dozens or even hundreds, so the amount of possible correct forms quickly grows to tens of millions. “Just a flat list of all known words” <em>might</em> become impractical (not on today’s top MacBook, probably, but still), and that’s where the affix compression comes in handy.</p>

<blockquote>
  <p>This is not the only possible approach to make dictionary storage more effective: for example, <a href="https://github.com/morfologik/morfologik-stemming">morfologik</a> (the default internal spellchecker of the most widely used open-source proofreading software <a href="https://languagetool.org/">LanguageTool</a>) codes <em>all</em> possible forms in binary files, using finite-state automata. And this approach is very efficient by speed and memory, but very hard for humans to edit and review, and thus, to keep dictionary up-to-date.</p>
</blockquote>

<p>Another benefit of splitting words into stems and affixes: when Hunspell’s user wants to add a new word to their personal dictionary, Hunspell allows to just specify “it is inflected the same way as (some other word)”, thus sparing the user of teaching the dictionary “‘monad’ is a word, and ‘monads’ too, as well as ‘monad’s’…”.</p>

<p>Note, though, that “suffixes” and “prefixes” specified in some language’s dictionary not necessarily correspond to <em>grammatical</em> suffixes/prefixes of the language. The splitting into stems and affixes is deduced automatically by dictionary authoring tools from flat word lists, so it is up to probabilities whether “common endings” deduced have any grammatical meaning. Actually, Hunspell’s format has a rich <a href="https://manpages.debian.org/experimental/libhunspell-dev/hunspell.5.en.html#Optional_data_fields">sub-language to specify grammatical information</a>, but of all LibreOffice and Firefox dictionaries I’ve checked, only a few (Latvian, Slovak, Galician, Breton) made use of this feature.</p>

<blockquote>
  <p>One important factor to mention is Hunspell’s limitation for the amount of suffixes/prefixes a word may have. Currently, the software understands no more than 2 suffixes and 2 prefixes in a word, which is lower than the common number of grammatical suffixes a lot of languages allow. Most of the dictionaries solve this by “linearizing” the word list: Ukrainian word “громадянство” (citizenship) grammatically consists of the stem “громад-“ and suffixes “-ян-“, “-ств-“, “-о” (the latter is called an ending in grammatically correct terms), but Hunspell’s Ukrainian dictionary includes the full word “громадянство”. For other languages, the suffix number limitation makes Hunspell totally unusable, so to spellcheck the Finnish, you need to install <a href="https://voikko.puimula.org/">Voikko</a> spellchecker.</p>
</blockquote>

<p><strong>Affix compression comes with a price</strong> paid in lookup algorithm complexity and performance. Instead of just a quick lookup through a hashtable or other lookup-optimized structure, we now have to:</p>

<ol>
  <li>Check if the whole word is in the list of stems. If yes, it is correct,
    <ul>
      <li>…unless it has a flag corresponding to the aff-file directive “this stem <em>requires</em> prefixes or suffixes”.</li>
    </ul>
  </li>
  <li>If no, check if the word has some of the known suffixes; and if so, whether the stem without one of those suffixes is in the stem list, <em>and</em> has a flag corresponding to this suffix.</li>
  <li>If no, check if one more suffix can be found in the stem (then we’ll have a stem and two suffixes, and need to check the compatibility of their flags).</li>
  <li>Repeat with prefixes (up to two), and with all possible suffix-prefix combination (taking into account whether suffix and prefix both have “cross-product” allowed).</li>
  <li>Consider that suffixes and prefixes can have flags of their own, specifying “suffixes with this flag might be attached after me”, or “if used, this suffix requires that at least one other affix would be present” and … many other things.</li>
  <li>And there are funny cases like <code>CIRCUMFIX</code> flag: if the suffix has it, this means that this suffix is only allowed in words having a prefix with the same flag.</li>
</ol>

<blockquote>
  <p>It is <em>still</em> a simplified description. To follow the algorithm in full, you can read Spylls docs starting from <a href="https://spylls.readthedocs.io/en/latest/hunspell/algo_lookup.html#spylls.hunspell.algo.lookup.Lookup.affix_forms"><code>Lookup.affix_forms</code></a>, follow the links to methods it invokes, and read inline comments under “Show code”.</p>
</blockquote>

<p>Performance-wise, for each word correctness check, there could be many lookups through known suffixes and prefixes lists, and quite a few dictionary lookups (as consecutive chopping off of suffixes and prefixes produces new stems we need to check).</p>

<p>And once you tackle the affixes problem, it is all uphill from there!</p>

<p><strong>Stay tuned for the next installment about the Hunspell lookup, where we’ll cover word compounding problem, and some other important edge cases of the word correctness check.</strong> Follow me <a href="https://twitter.com/zverok">on Twitter</a> or <a href="https://zverok.github.io/subscribe.html">subscribe to my mailing list</a> if you don’t want to miss the follow-up!</p>


  </article></div>]]>
            </description>
            <link>https://zverok.github.io/blog/2021-01-09-spellchecker-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25725583</guid>
            <pubDate>Mon, 11 Jan 2021 06:54:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Import Assertions Coming to JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25725187">thread link</a>) | @franciscop
<br/>
January 10, 2021 | https://2ality.com/2021/01/import-assertions.html#upcoming-features-based-on-import-assertions | <a href="https://web.archive.org/web/*/https://2ality.com/2021/01/import-assertions.html#upcoming-features-based-on-import-assertions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://github.com/tc39/proposal-import-assertions">The ECMAScript proposal “Import assertions”</a> (by Myles Borins, Sven Sauleau, Dan Clark, and Daniel Ehrenberg) introduces syntax for associating metadata with import statements. In this blog post, we examine what that looks like and why it’s useful.</p>
<!--more-->
<hr>
<p><strong>Table of contents:</strong></p>
<nav><ul><li><a href="#import-assertions">Import assertions&nbsp;&nbsp;</a></li><li><a href="#history%3A-importing-non-javascript-artifacts-as-modules">History: importing non-JavaScript artifacts as modules&nbsp;&nbsp;</a></li><li><a href="#use-cases-for-importing-non-javascript-artifacts">Use cases for importing non-JavaScript artifacts&nbsp;&nbsp;</a></li><li><a href="#the-syntax-of-import-assertions">The syntax of import assertions&nbsp;&nbsp;</a><ul><li><a href="#static-import-statements">Static import statements&nbsp;&nbsp;</a></li><li><a href="#dynamic-imports">Dynamic imports&nbsp;&nbsp;</a></li><li><a href="#re-export-statements">Re-export statements&nbsp;&nbsp;</a></li></ul></li><li><a href="#upcoming-features-based-on-import-assertions">Upcoming features based on import assertions&nbsp;&nbsp;</a><ul><li><a href="#importing-webassembly">Importing WebAssembly&nbsp;&nbsp;</a></li></ul></li><li><a href="#further-reading-on-modules">Further reading on modules&nbsp;&nbsp;</a></li></ul></nav><hr>
<h2 id="import-assertions">Import assertions&nbsp;&nbsp;</h2>
<p>The motivating use case for import assertions was importing JSON data as a module. That looks as follows (and is further specified in <a href="https://github.com/tc39/proposal-json-modules">a separate proposal</a>):</p>
<pre><code><span>import</span> config <span>from</span> <span>'./data/config.json'</span> assert { <span>type</span>: <span>'json'</span> };
</code></pre>
<p>You may wonder why a JavaScript engine can’t use the filename extension <code>.json</code> to determine that this is JSON data. However, a core architectural principle of the web is to never use the filename extension to determine what’s inside a file. Instead, content types are used.</p>
<p>Therefore, there is a risk of doing importing wrong if a server has incorrectly configured content types. Specifying the necessary metadata at the import location solves this issue.</p>
<p>Before we take a more detailed look at how import assertions work, let’s examine the history of importing non-JavaScript artifacts in the world of JavaScript.</p>
<h2 id="history%3A-importing-non-javascript-artifacts-as-modules">History: importing non-JavaScript artifacts as modules&nbsp;&nbsp;</h2>
<p>Importing artifacts that are not JavaScript code as modules, has a long tradition in the JavaScript ecosystem.</p>
<p>For example, the JavaScript module loader RequireJS has support for so-called <a href="https://requirejs.org/docs/plugins.html"><em>plugins</em></a>. To give you a feeling for how old RequireJS is: Version 1.0.0 was released in 2009. Specifiers of modules that are imported via a plugin look like this:</p>
<pre><code>'«specifier-of-plugin-module»!«specifier-of-artifact»'
</code></pre>
<p>For example, the following module specifier imports a file as JSON:</p>
<pre><code>'json!./data/config.json'
</code></pre>
<p>Inspired by RequireJS, webpack supports the same module specifier syntax for its <a href="https://webpack.js.org/loaders/"><em>loaders</em></a>.</p>
<h2 id="use-cases-for-importing-non-javascript-artifacts">Use cases for importing non-JavaScript artifacts&nbsp;&nbsp;</h2>
<p>These are a few use cases for importing non-JavaScript artifacts:</p>
<ul>
<li>Importing JSON configuration data</li>
<li>Importing WebAssembly code as if it were a JavaScript module</li>
<li>Importing CSS to build user interfaces</li>
</ul>
<p>For more use cases, you can take a look at <a href="https://webpack.js.org/loaders/">the list of webpack’s loaders</a>.</p>
<h2 id="the-syntax-of-import-assertions">The syntax of import assertions&nbsp;&nbsp;</h2>
<p>Let’s examine in more detail what import assertions look like.</p>
<h3 id="static-import-statements">Static import statements&nbsp;&nbsp;</h3>
<p>We have already seen a normal (static) import statement:</p>
<pre><code><span>import</span> config <span>from</span> <span>'./data/config.json'</span> assert { <span>type</span>: <span>'json'</span> };
</code></pre>
<p>The import assertions start with the keyword <code>assert</code>. That keyword is followed by an object literal. For now, the following object literal features are supported:</p>
<ul>
<li>Unquoted keys and quoted keys</li>
<li>The values must be strings</li>
</ul>
<p>There are no other syntactic restrictions placed on the keys and the values, but engines are encouraged to throw an exception if they don’t support a key and/or a value. That makes it easier to add more features in the future because no one will use keys and values in unexpected ways.</p>
<h3 id="dynamic-imports">Dynamic imports&nbsp;&nbsp;</h3>
<p>To support import assertions, <a href="https://exploringjs.com/impatient-js/ch_modules.html#import-operator">dynamic imports</a> get a second parameter – an object with configuration data:</p>
<pre><code><span>import</span>(<span>'./data/config.json'</span>, { <span>assert</span>: { <span>type</span>: <span>'json'</span> } })
</code></pre>
<p>The import assertions don’t exist at the top level; they are specified via the property <code>assert</code>. That makes it possible to add more configuration options in the future.</p>
<h3 id="re-export-statements">Re-export statements&nbsp;&nbsp;</h3>
<p>A re-export imports and exports in a single step. For the former, we need assertions:</p>
<pre><code><span>export</span> { <span>default</span> <span>as</span> config } <span>from</span> <span>'./data/config.json'</span> assert { <span>type</span>: <span>'json'</span> };
</code></pre>
<h2 id="upcoming-features-based-on-import-assertions">Upcoming features based on import assertions&nbsp;&nbsp;</h2>
<p>Import assertions are really just syntax. They lay the foundation for actual features that make use of that syntax.</p>
<p>The first feature based on import assertions is probably going to be <a href="https://github.com/tc39/proposal-json-modules">JSON modules</a>.</p>
<h3 id="importing-webassembly">Importing WebAssembly&nbsp;&nbsp;</h3>
<p>Whether or not import assertions will be used to support directly importing WebAssembly from JavaScript is currently under <a href="https://github.com/tc39/proposal-import-assertions/issues/19">discussion</a>. If they are used, we’ll probably be able to create web workers like this:</p>
<pre><code><span>new</span> Worker(<span>'my-app.wasm'</span>, { <span>type</span>: <span>'module'</span>, <span>assert</span>: { <span>type</span>: <span>'webassembly'</span> } })
</code></pre>
<p>And we’d also need import assertions in HTML script elements:</p>
<pre><code><span>&lt;<span>script</span> <span>src</span>=<span>"my-app.wasm"</span> <span>type</span>=<span>"module"</span> <span>asserttype</span>=<span>"webassembly"</span>&gt;</span><span>&lt;/<span>script</span>&gt;</span>
</code></pre>
<h2 id="further-reading-on-modules">Further reading on modules&nbsp;&nbsp;</h2>
<p><a href="https://exploringjs.com/impatient-js/ch_modules.html">The chapter on “Modules”</a> in “JavaScript for impatient programmers” is an in-depth introduction to ECMAScript modules.</p>
</div></div>]]>
            </description>
            <link>https://2ality.com/2021/01/import-assertions.html#upcoming-features-based-on-import-assertions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25725187</guid>
            <pubDate>Mon, 11 Jan 2021 06:03:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The ABCs of Cryptocurrencies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25724824">thread link</a>) | @hgarg
<br/>
January 10, 2021 | https://flurly.com/s/harishgarg/ABCsofCrypto | <a href="https://web.archive.org/web/*/https://flurly.com/s/harishgarg/ABCsofCrypto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h2>Do you remember Bitcoin breaking records with how fast it was gaining in value?

Do you remember wanting to join in on the profits, but didn't know where to start?

The ABCs of Cryptocurrency takes you through my experience of becoming an investor in the Blockchain and Cryptocurrency market, as well as instructions on how you can get started investing in Bitcoin, Ethereum, Ripple, and other hot cryptocurrencies TODAY. The window to get invested early in this market won't last forever. Find out how you can get involved with your purchase of The ABCs of Cryptocurrency.

This book will teach you:

💰How to invest in Bitcoin and other cryptocurrencies

💰How to stake your cryptocurrency for passive, residual income

💰The proper and safe way to hold cryptocurrency

Don’t get left behind the next time Bitcoin goes to $20,000...or more 👀

Let’s hit the moon together 🚀

© 2020 Mashfik Ahmed</h2></p></div></div>]]>
            </description>
            <link>https://flurly.com/s/harishgarg/ABCsofCrypto</link>
            <guid isPermaLink="false">hacker-news-small-sites-25724824</guid>
            <pubDate>Mon, 11 Jan 2021 05:10:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pylon – Your new favorite discussion platform]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25724076">thread link</a>) | @hastes
<br/>
January 10, 2021 | https://pylon.gg/p/27dec919-16e9-46d7-b245-28b565ad3bf9 | <a href="https://web.archive.org/web/*/https://pylon.gg/p/27dec919-16e9-46d7-b245-28b565ad3bf9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-405e5d70=""><p>
                Greetings, traveler
            </p> <p>
                Staying a while? Registered users can customize their
                profile, create Shards, and join the discussion.
            </p> </div></div>]]>
            </description>
            <link>https://pylon.gg/p/27dec919-16e9-46d7-b245-28b565ad3bf9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25724076</guid>
            <pubDate>Mon, 11 Jan 2021 03:32:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cheap FPGA Development Boards]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25723893">thread link</a>) | @neurotech1
<br/>
January 10, 2021 | https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards | <a href="https://web.archive.org/web/*/https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">

<p>I bought Avnet's $49 Spartan 3A development board but it was discontinued not long afterward - right about the time when I decided I needed a few dozen more. I've since done some extensive research (thanks, Google!) to find a comparable thrifty thrill.
</p>
<p>When choosing a development board, consider what you get with it and what you want to use it for. FPGAs are ideal for use with high speed peripherals, and in general it is much easier to buy a board that contains the part you want, rather than trying to add one on later (and inevitably giving up and upgrading to a more capable board). Examples of things you might want, and are quite difficult to add yourself:
</p>
<ul><li>Gigabit Ethernet
</li><li>HDMI/DVI
</li><li>PCI/PCI Express
</li><li>External non-serial memory (DDR/Flash etc.)
</li></ul><p>Things that are relatively easy to add, and are not so much of a big deal to wire up yourself.
</p>
<ul><li>MMC/SD cards
</li><li>Character (e.g. 16x2) LCDs
</li><li>Anything I2C/SPI and relatively low speed
</li><li>VGA (with low colour depth)
</li></ul><p>I like having a board with many (at least 8) SPST switches and LEDs, and momentary buttons. Unlike a microcontroller where it's relatively easy to spit debug information out of a serial port or to an LCD with a single C function call, debugging FPGA designs is a bit harder. LEDs  provide a zero fuss way to break out internal signals for visualisation - if you're tracking the progress of a complex state machine, you can light up an LED when it gets to a certain point without adding any extra logic. While these are easy enough to add yourself, I find that it's better to get a board that has them so that you don't waste valuable user IOs or waste time investigating failures caused by your terrible soldering skills.
</p>
<p>Some manufacturers promote a standard form factor for add-ons, notably Digilent with their very wide range of <a href="https://store.digilentinc.com/pmod-modules-connectors/">Pmods</a>, the Papilio One's <a href="http://papilio.cc/index.php?n=Papilio.Wings">Wings</a>, and Arduino shields.
</p>
<p>If you would like to connect high speed devices (above 10-20 MHz) to your FPGA, make sure your board has an interface connector that supports the speeds you'll be using. Look for ground wires interspersed regularly between signal wires, high speed connectors (not just 0.1" headers), PCB trace length equalisation, and impedance control. Few of the cheap boards bother with any of these.
</p>
<p>FPGAs can be a bit daunting, so check that the manufacturer provides:
</p>
<ul><li>Schematic diagram
</li><li>A reference manual, describing all of the on-board peripherals
</li><li>A guide to getting started, if you've never used an FPGA before
</li><li>A reference design that exercises all on-board peripherals.
</li></ul><p>Reference designs can either be HDL or microcontroller-based, but in recent boards, most manufacturers seem to be moving to the latter. Bear this in mind if you don't have a license for the microcontroller and environment (e.g. Xilinx EDK/SDK is not free), as the code will be difficult to port to HDL.
</p>
<p>If you're a beginner, you may benefit from buying a board that has a companion textbook which has been written specifically for the board in mind, and describes each of the peripherals and how to interface with them. Popular boards with larger user communities may also be worth considering above cheaper options. The most popular Xilinx boards are those made by Xilinx (none of them cheap enough to be listed here), Digilent and Avnet. Terasic seem to make the most popular Altera boards.
</p>

<p>A long-standing complaint with vendor FPGA design tools is that they are generally enormous, complicated, slow, buggy, closed source, and are either expensive or have annoying license requirements. The open source community has made great progress in recent years to reimplement parts or all of the FPGA design toolchain and to address all of these concerns.
</p>
<p>FPGA devices which are currently either partially or fully supported by open source tools include:
</p>
<ul><li>Xilinx Spartan 6
</li><li>Xilinx Series 7 (Artix 7, Kintex 7, Virtex 7, Zynq with Series 7 Fabric)
</li><li>Xilinx Ultrascale(+)
</li><li>Lattice iCE40
</li><li>Lattice ECP5
</li><li>QuickLogic EOS S3 and PolarPro3
</li></ul><p>Some tools to check out include:
</p>
<ul><li><a href="https://github.com/enjoy-digital/litex">LiteX</a> - A Python-based SoC builder
<ul><li><a href="https://github.com/litex-hub">LiteX Hub</a> - collaborative FPGA projects based on LiteX
</li><li><a href="https://github.com/timvideos/litex-buildenv">LiteX-BuildEnv</a> - An environment for building LiteX-based FPGA designs
</li></ul></li><li><a href="http://www.clifford.at/yosys/">Yosys</a> - Verilog synthesis tool
</li><li><a href="https://github.com/YosysHQ/nextpnr">nextpnr</a> - a vendor neutral, timing driven place and route tool
</li><li><a href="https://symbiflow.github.io/">SymbiFlow</a> - an umbrella project for FPGA architecture definitions
</li><li><a href="https://icestudio.io/">Icestudio</a> - an visual editor/IDE for Lattice FPGAs
</li></ul><p><a href="https://twitter.com/mithro">Tim 'mithro' Ansell</a> has an open offer to send FPGA hardware to anyone who has time to to contribute to open source FPGA projects but doesn't have any hardware.
</p>

<h4>Xilinx</h4>
<h5>Zynq</h5>
<p>Xilinx's Zynq parts are supported by their Vivado high level synthesis design suite and include a dual-core ARM Cortex-A9, USB 2.0, and Gigabit Ethernet.
</p>

<table><tbody><tr><th>Name</th><th>Price</th><th>Device</th><th>Notes</th></tr>
<tr><td><a href="https://www.aliexpress.com/item/4000042572307.html">Zynq 7000 ZYNQ7010 development board</a></td><td>$42</td><td>Zynq 7010</td><td>A no-name board, apparently pulled from some equipment, which provides 256MB DDR, 128M NAND flash, SD card, optocoupled inputs, 1 button, 2 LEDs, and 42 I/Os. Some more information is available in this <a href="https://www.eevblog.com/forum/fpga/anyone-played-with-these-cheap-$50-zynq-boards/">EEVBlog thread</a>.</td></tr>
<tr><td><a href="https://www.aliexpress.com/item/4000323573953.html">QMTECH Zynq7000 Starter Kit</a></td><td>$56</td><td>Zynq 7010</td><td>512MB DDR3, micro SD slot, 100 Mbit Ethernet, two LEDs, 62 length-matched and paired FPGA I/Os and 15 processor I/Os. Some documentation is available at <a href="http://www.chinaqmtech.com/xilinx_zynq_soc">QMTech's site</a> and there are some observations in this <a href="https://www.eevblog.com/forum/fpga/anyone-played-with-these-cheap-$50-zynq-boards/">EEVBlog thread</a>, where there are some complaints about a lack of decoupling.</td></tr>
<tr><td><a href="http://shop.trenz-electronic.de/en/TE0722-01-DIPFORTy1-Soft-Propeller">DIPFORTy1 "Soft Propeller"</a></td><td>EUR 59</td><td>Zynq 7010</td><td>A DIP-40 sized board that is designed to be pin-compatible with the Parallax Propeller chip. It has 16MB of flash, 46 I/Os, one RGB LED, one user LED, micro SD socket, and a proximity/light sensor.</td></tr>
<tr><td><a href="https://world.taobao.com/item/607165559105.htm?spm=a21wu.11804641-tw.0.0.4263253ekAFbba">Sipeed Tang Hex</a></td><td>$70-90</td><td>Zynq 7020</td><td>1 GB LPDDR3, 2Gb Flash NAND, 100Mbit Ethernet, four USB 2.0 ports, a TF slot, and 15 GPIOs.</td></tr>
<tr><td><a href="http://zedboard.org/product/minized">MiniZed</a></td><td>$89</td><td>Zynq 7Z007S</td><td>Includes a single ARM A9, 512MB DDR3L, 128Mb flash and 8GB eMMC, USB host, USB-JTAG, and USB-UART, 802.11b/g/n Wi-Fi, Bluetooth 4.1, and BLE, Arduino shield connector and two PMODs (38 total I/Os), accelerometer, temperature, and MEMS microphone sensors, one button, one switch, and two bi-color LEDs</td></tr>
<tr><td><a href="http://www.myirtech.com/list.asp?id=502">MYIR Z-turn Board</a></td><td>$99/$119</td><td>Zynq 7010/ 7020</td><td>1GB DDR, 16MB flash, TF socket, gigabit Ethernet, CAN, USB2.0 OTG, USB-UART, HDMI output, 90 or 106 user I/Os (with 39 LVDS pairs), accelerometer and temperature sensor, JTGA, two buttons, 4 switches, four LEDs, and a buzzer. An "IO Cape" breakout board ($35) provides three Pmod connectors, camera and LCD connectors, and 0.1" header I/O pins.</td></tr>
<tr><td><a href="https://www.crowdsupply.com/krtkl/snickerdoodle">snickerdoodle</a></td><td>$115/$245</td><td>Zynq 7010/7020</td><td>A Zynq board with 155-180 I/Os, 512MB-1GB DDR, 16MB flash, micro SD, 802.11n WiFi, and Bluetooth 4.0. A range of base-boards and add-on boards are also available, providing gigabit Ethernet, HDMI in/out, USB, JTAG, 0.1" I/Os, and more.</td></tr>
<tr><td><a href="http://www.tul.com.tw/ProductsPYNQ-Z2.html">PYNQ Z2</a></td><td>$119</td><td>Zynq 7020</td><td>512MB DDR3, 128 Mb flash, microSD, gigabit Ethernet, HDMI source and sink, USB for JTAG, UART and OTG host, I2S audio I/O, 4 SPST buttons, 2 SPDT switches, 4 LEDs and 2 RGB LEDs, two PMODs, and Arduino and Raspberry Pi connectors (around 60 I/Os, plus 6 analog inputs)</td></tr>
<tr><td><a href="http://www.parallella.org/buy/">Parallella-16 Micro-Server</a></td><td>$126</td><td>Zynq 7010</td><td>Includes a dual ARM A9. Also available on the board are the Epiphany 16-core CPU Accelerator, 1GB RAM, 126 Mb flash, micro SD, and gigabit Ethernet.</td></tr>
<tr><td><a href="http://www.parallella.org/buy/">Parallella-16 Desktop</a></td><td>$158</td><td>Zynq 7010</td><td>Expands on the Micro-Server and adds high speed expansion ports with 24 GPIOs (and other Epiphany signals), HDMI, and USB 2.0 host.</td></tr>
<tr><td><a href="https://store.digilentinc.com/zybo-z7-zynq-7000-arm-fpga-soc-development-board/">Digilent ZYBO Z7</a></td><td>$199/299</td><td>Zynq 7010/7020</td><td>1GB DDR3 RAM, HDMI source/sink with CEC, VGA, gigabit Ethernet, USB JTAG, UART and 2.0 host/OTG, MIPI CSI-2, audio I/O, 6 buttons, 4 switches, 6 or 7 LEDs, and 40 I/Os (5 PMODs), including analogue inputs, and microSD</td></tr>
<tr><td><a href="http://www.zedboard.org/product/microzed">MicroZed</a></td><td>$199</td><td>Zynq 7010</td><td>1GB, 128 Mb flash, SD card, gigabit Ethernet, USB 2.0, 100 I/Os (48 LVDS pairs) and 2 PMODs, 1 LED and 1 switch</td></tr>
<tr><td><a href="https://allaboutfpga.com/product/edge-zynq-soc-fpga-development-board/">EDGE ZYNQ</a></td><td>$214</td><td>Zynq 7010</td><td>512MB, 128 Mb flash, micro SD, gigabit Ethernet, 802.11/b/g/n WiFi and Bluetooth 4.2/LE, USB for JTAG, UART, and OTG, HDMI Tx/Rx, VGA, stereo audio output, light and temperature sensors, 4*7 Seg LEDs, 5 LEDs, 4 slide switches, 31 PL I/Os and 4 PS I/Os. A 2x16 LCD module is included, and camera and TFT LCD modules are available.</td></tr>
</tbody></table>
<h5>Artix-7</h5>
<p>Artix parts are becoming increasingly common in inexpensive development boards, taking the position previously occupied by the Spartan-6 in Xilinx's lineup, though they are only supplied in BGA packages.
</p>

<table><tbody><tr><th>Name</th><th>Price</th><th>Device</th><th>Notes</th></tr>
<tr><td>QMTECH Artix 7 DDR3 Core Board</td><td>$50/80</td><td><a href="https://www.aliexpress.com/item/1000006630084.html">Artix 35T</a>/<a href="https://www.aliexpress.com/item/4000170003461.html">100T</a></td><td>256MB DDR3, 16MB SPI flash, 2 switches, 3 LEDs, JTAG header, and 108 length-matched I/Os. It's also compatible with a daughterboard which provides PMODs, USB-UART, camera interface, VGA, gigabit Ethernet, and more. There are reports that decoupling is insufficient, so beware.</td></tr>
<tr><td><a href="http://store.digilentinc.com/cmod-a7-breadboardable-artix-7-fpga-module/">Digilent Cmod A7</a></td><td>$75/89</td><td>Artix 15T/45T</td><td>A breadboardable module with 512KB SRAM, 4MB SPI flash, USB-JTAG and USB-Serial, 3 LEDs, 2 buttons, 52 digital I/Os, and 2 analog inputs.</td></tr>
<tr><td><a href="https://perfv.org/">Perf-V</a></td><td>$79</td><td>Artix 35T</td><td>4 switches, 5 buttons, 7 LEDs, JTAG 256MB DDR3, 16MB flash, Arduino shield connector, one PMOD, and some sort of high speed connector which supports expansion boards with HDMI and VGA. Larger FPGA sizes will apparently be available too.</td></tr>
<tr><td><a href="https://rhsresearch.com/collections/all/products/litefury">LiteFury</a></td><td>$99</td><td>Artix 100T</td><td>A PCIe x4 gen 2 development board with an NVMe (2280 Key M) connector. It has 256MB DDR3, 128 Mb flash, 4 LEDs, and 12 I/Os (including four LVDS pairs).</td></tr>
<tr><td><a href="https://alchitry.com/collections/all/products/alchitry-au-fpga-development-board">Alchitry Au</a></td><td>$99.99</td><td>Artix 35T</td><td>256MB DDR3, 102 digital I/Os, 9 differential analog inputs (8 shared with digital I/O), 8 LEDs, 1 button, USB-UART, and USB-C for power and programming. It has high density I/O connectors, but companion prototype/breaking ($10) and I/O with switches, LEDs, 7-Segs ($25) boards.</td></tr>
<tr><td><a href="https://www.aliexpress.com/item/4000170042795.html">QMTECH Artix-7 Wukong Board</a></td><td>$100</td><td>Artix 100T</td><td>16MB flash, 256MB DDR3, 3 switches, 4 LEDs, gigabit Ethernet, HDMI output, USB-UART, GTP transceiver interface, 2 PMODs, and 40 I/IOs. There are reports that decoupling is insufficient, so beware.</td></tr>
<tr><td><a href="https://store.digilentinc.com/arty-a7-artix-7-fpga-development-board-for-makers-and-hobbyists/">Arty A7</a></td><td>$129/249</td><td>Artix 35T/100T</td><td>An inexpensive way to get into the Artix parts. It provides 256 MB DDR, 16MB flash, 10/100 Ethernet, USB-UART/JTAG, four PMODs, an Arduino shield connector (a total of 62 I/Os?), 4 switches, 4 buttons, 8 LEDs (4 of them RGB), and a one year licence for Vivado Design Edition.</td></tr>
<tr><td><a href="https://numato.com/product/mimas-a7-artix-7-fpga-development-board-with-ddr-sdram-and-gigabit-ethernet">N…</a></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards">https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards</a></em></p>]]>
            </description>
            <link>https://www.joelw.id.au/FPGA/CheapFPGADevelopmentBoards</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723893</guid>
            <pubDate>Mon, 11 Jan 2021 03:09:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working Off-Grid Efficiently]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25723819">thread link</a>) | @zdw
<br/>
January 10, 2021 | https://100r.co/site/working_offgrid_efficiently.html | <a href="https://web.archive.org/web/*/https://100r.co/site/working_offgrid_efficiently.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
        
        <ul>
            <li><a href="#intro">Introduction</a></li>
            <li><a href="#power">Power management</a></li>
            <li><a href="#internet">Internet</a></li>
            <li><a href="#data">Data storage</a></li>
            <li><a href="#software">Software</a></li>
            <li><a href="#hardware">Hardware</a></li>
            <li><a href="#conscientious">Conscientious living</a></li>
        </ul>
<h2 id="intro">Introduction</h2>

<img src="https://100r.co/media/blog/working/dworking5.jpg" loading="lazy">

<p>Our traveling studio has operated off-the-grid since 2016.</p>

<p>For the first 3 years we tested the limits of our space, and at first, it was difficult to create new things, as we had to make time to learn how to solve the underlying problems. Our boat was not just an office, it was also our house and transport. As for us, we were artists, but also had to be plumbers, deckhands, electricians, captains, janitors and accountants.</p>

<p>Our main problems as a studio were <b>internet scarcity</b>, <b>power management</b>, <b>data storage</b> as well as <b>hardware</b> and <b>software failures</b>. Overtime we found ways to balance work, pleasure and maintenance. Here are some of the lessons we learnt.</p>

<h2 id="power">Power management</h2>

<img src="https://100r.co/media/blog/working/dworking6.jpg" loading="lazy">

<p>Our work schedule is tied to the weather, as we depend on solar energy to power our computers. By looking at the forecast, we can determine when we will get the most work done: consecutive days of sun grant us enough power for video-editing, while overcast days are reserved for low-power work, like writing, coding and planning.</p>

<p>There are times when we must resort to secondary power sources, like our small generator or our engine's alternator, but we tend to prefer to <a href="https://www.youtube.com/watch?v=9ua_qxjbBTc">wait for the sun to return</a>. Waiting hasn’t affected our productivity, as we don't adhere to strict 8-hour workdays.</p>

<p>We tend to work only in the morning, leaving us time to pursue other interests in the afternoon. In our old life, we found that the 40-hour workweek ﻿<a href="https://www.raptitude.com/2010/07/your-lifestyle-has-already-been-designed/" target="_blank">kept free-time scarce</a>, resulting in us spending more for convenience, gratification and distraction.</p>

<p>Computers are generally power-sucking vampires. Choosing different softwares, operating systems, or working from machines with a lower draw (ARM) or even throttling the CPU, are some of the many things we do to lower our power requirements. The way that software is built has a substantial impact on the power consumption of a system, it is shocking how cpu-intensive modern programs can be.</p>

<p>Choosing software designed for low-end PCs is a good solution, it is also possible to throttle processes on your machine by using a ‘throttling controller’. The basic idea is like the throttle in a car, it allows to set the rate at which your system will operate and consume power. Another sure way to save battery is to limit multitasking. Disabling notifications, <a href="https://addons.mozilla.org/en-CA/firefox/addon/noscript/">scripts</a>, auto-playing videos or using internet browsers without opening multiple tabs at once are some of the many ways to achieve this.</p>

<p>Power consumption is also something to consider when choosing a computer. In evenings, if we need to work on light tasks, we switch to our low-power machines like the <a href="https://100r.co/site/raspberry_pi.html">Raspberry Pi</a>. To illustrate the difference in power draw, a Pi4 uses 2.85 W when idle, while a Macbook Pro uses 6-12 W. Raspberry Pis are backups to our main computers, as they are inexpensive and can run off small batteries.</p>

<h2 id="internet">Internet</h2>

<img src="https://100r.co/media/blog/working/dworking1.jpg" loading="lazy">

<p>Internet access is the woe of any working nomad. Internet is sometimes spotty, and data in some countries is slow, expensive, or limited to small blocks at a time. While circumnavigating the Pacific, we amassed sim cards, pocket WiFis, and have often used connections from businesses on land. Overtime, we found ways to lessen our dependence on internet, and to save on bandwidth.</p>

<p>With limited access, it is important to use online time wisely. Prior to connecting we make a list of tasks that we must do, such as pushing updates and making backups of our data online. It’s easy to get side-tracked on the internet, with websites designed to grab and keep our attention. When checking social media, we disable auto-playing videos and image previews to save bandwidth.</p>

<p>When we have a reliable internet connection, we gather copies of all the online material we will need. We keep offline versions of entire websites, writing guides, articles and even whole sections of Wikipedia. If we find ourselves without a connection, we can still solve our problems by using our offline mirrors. By the way, you can <a href="https://github.com/hundredrabbits/100r.co/archive/master.zip">download our entire website</a>.</p>

<p>We research our destinations ahead of time to make sure we’ll have a reliable connection when we need it. This means we’ll be spending less time in secluded areas, and more time in city centers near a cell tower or WiFi signal. With some planning it is possible to have both paradise and connectivity, we found such a place in <a href="https://100r.co/site/internet_in_paradise.html#internet">Huahine</a> in French Polynesia, and again in Fiji. Internet access will only get better as far-flung island nations gain purchasing power.</p>

<h2 id="data">Data storage</h2>

<img src="https://100r.co/media/blog/working/dworking2.jpg" loading="lazy">

<p>Hardware failure is common on boats due to the hostile environment. Saltwater is the kryptonite of electronics. This is why it is important to backup data often to avoid losing work. There are advantages and disadvantages with all methods of data storage, but I’ll outline the most useful ones for sailors:</p>

<p><b>Cloud storage:</b> For a fee, you can back up your data online and sync files from your desktop. This method doesn’t eliminate physical storage as data can’t be synced to the cloud without a connection. Offloading data storage to a centralized service is problematic in other ways, because services have rules and owners and processes which can complicate things. For instance, country politics have made it that Google restricts access to some of its business services in certain countries or regions, such as China, Crimea, Cuba, Iran, Sudan, and Syria. Whatever data you have stored with Google Drive, if traveling to any of these countries will not be accessible. As conflicts arise, more countries can end up on that list. We keep documents we don’t need regular access to on the cloud, with copies on hard disks.</p>

<p><b>Hard copies:</b> Paper is a stable and widely accessible material, unlike digital devices which are subject to breakages and obsolescence. There’s a good reason books and other documents from centuries ago are still readable today. We like to keep printed copies of websites and other online reference materials, such as grammar guides for writing, or language manuals for coding. Keeping data like this means we always have access and aren’t limited to our computer’s battery.</p>

<p><b>External hard drives:</b> A hard drive is the the best balance of practical and reliable for storage. However, hard drives are rated for a limited number of read/write cycles, and can be expected to fail eventually. To prevent data loss due to HD failure, it’s a good idea to store the same data across multiple hard drives.</p>

<p><b>Offline databases:</b> Keeping an offline collection of websites on computers or HD ensures constant access, and reduces the energy associated with re-loading them repeatedly. It’s possible to save web pages with most browser by selecting File &gt; Save Page As. To access the page offline, click on the HTML file. Another option is to mirror entire web sites using <a href="https://www.gnu.org/software/wget/" target="_blank">command-line tools</a>. We keep offline databases full of notes on a variety of subjects to refer to when there’s no internet.</p>

<p>Keeping files on the cloud, on hard drives and hard copies gives our floating studio the redundancy required to ensure reliability.</p>

<h2 id="software">Software</h2>

<p>Software has a big impact on productivity, they need to be reliable and fast. Those that require heavy updates, that have a high CPU usage and that need frequent connectivity to function are problematic for working sailors.</p>

<p>Much of the software on the market is designed by people living on the grid with unlimited access to internet. Tools locking up at sea, asking for a connection to continue working don’t float on a boat. Adobe products are a good example, as they require an internet connection periodically for subscription validation. If away from big cities, you may open your computer in an atoll to find that you no longer have access to the tool you need to get things done. Choosing a tool that doesn’t require a subscription is <b>essential</b> for working nomads that don’t have a reliable connection.</p>

<p>In our first year, we struggled to download the frequent and mandatory 10GB software updates from Apple to release our software on their platform, while on slow Polynesian internet. Processor-intensive software or apps is a strain on limited power and bandwidth, but it doesn’t have to be that way. The way developers write them can affect the power consumption of the resulting product. Chat rooms and bare bones text editors aren’t supposed to be process-heavy, and yet the popular communication platform Slack requires <a href="https://josephg.com/blog/electron-is-flash-for-the-desktop/" target="_blank">outrageous amounts of ram and CPU</a> to function. This is because Slack is embedding the entirety of Google Chrome in their app. Making software this way is costly to off-grid users, or those on slow connections, but luckily there are <a href="https://github.com/mayfrost/guides/blob/master/ALTERNATIVES.md" target="_blank">many alternatives</a>.</p>

<p>Our computer batteries should not need to grow ever larger only to support these bloatwares, nor should we need to add extra solar to power them. Just as you would look at the nutritional content of food products at the grocery store, find out how much energy your apps are consuming.</p>

<h2 id="hardware">Hardware</h2>

<img src="https://100r.co/media/blog/working/working3.jpg" loading="lazy">

<p>Computers are subject to water intrusion and saltwater corrosion, but with some care they can survive in a normal marine environment. We solved most of the problems by cleaning external connections often, and by storing them in a sealed box with some desiccants after each use. The main issue with computers on boats, is that it is difficult to source parts when they break. To make matters worse, many modern machines have non-replaceable batteries, proprietary storage, and soldered-in RAM. The parts that fail the most are power connectors, external connections and batteries.</p>

<p>Leaving a port with spare parts is a good tactic, but leaving with backup PCs is even better. There are many good inexpensive computers on the market, like notebook processors (Pinebook, EeeBook) and single-board computers (Raspberry Pis, Pine64). We carry 3 extra Raspberry Pi computers as backups to our main laptops, as they are inexpensive and small. These computers run on lower voltage, which lower overall …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://100r.co/site/working_offgrid_efficiently.html">https://100r.co/site/working_offgrid_efficiently.html</a></em></p>]]>
            </description>
            <link>https://100r.co/site/working_offgrid_efficiently.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723819</guid>
            <pubDate>Mon, 11 Jan 2021 02:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Go is my favorite programming language (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25723749">thread link</a>) | @psxuaw
<br/>
January 10, 2021 | https://michael.stapelberg.ch/posts/2017-08-19-golang_favorite/ | <a href="https://web.archive.org/web/*/https://michael.stapelberg.ch/posts/2017-08-19-golang_favorite/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
  
  <details>
    <summary>Table of contents</summary>
    <nav>
<ul>
<li>
<ul>
<li><a href="#my-background">My background</a></li>
<li><a href="#1-clarity">1. Clarity</a>
<ul>
<li><a href="#formatting">Formatting</a></li>
<li><a href="#high-quality-code">High-quality code</a></li>
<li><a href="#opinions">Opinions</a></li>
<li><a href="#few-keywords-and-abstraction-layers">Few keywords and abstraction layers</a></li>
</ul></li>
<li><a href="#2-speed">2. Speed</a>
<ul>
<li><a href="#quick-feedback-low-latency">Quick feedback / low latency</a></li>
<li><a href="#maximum-resource-usage">Maximum resource usage</a></li>
</ul></li>
<li><a href="#3-rich-standard-library">3. Rich standard library</a></li>
<li><a href="#4-tooling">4. Tooling</a></li>
<li><a href="#getting-started">Getting started</a></li>
<li><a href="#caveats">Caveats</a></li>
</ul></li>
</ul>
</nav>
  </details>
  

<p>I strive to respect everybody’s personal preferences, so I usually steer clear
of debates about which is the best programming language, text editor or
operating system.</p>

<p>However, recently I was asked a couple of times why I like and use a lot of <a href="https://golang.org/">Go</a>, so here is a coherent article to fill in the
blanks of my ad-hoc in-person ramblings :-).</p>

<h2 id="my-background">My background</h2>

<p>I have used C and Perl for a number of decently sized projects. I have written
programs in Python, Ruby, C++, CHICKEN Scheme, Emacs Lisp, Rust and Java (for
Android only). I understand a bit of Lua, PHP, Erlang and Haskell. In a previous
life, I developed a number of programs using
<a href="https://en.wikipedia.org/wiki/Delphi_(programming_language)">Delphi</a>.</p>

<p>I had a brief look at Go in 2009, when it was first released. I seriously
started using the language when Go 1.0 was released in 2012, featuring the <a href="https://golang.org/doc/go1compat">Go 1
compatibility guarantee</a>. I still have
<a href="https://github.com/stapelberg/greetbot">code</a> running in production which I
authored in 2012, largely untouched.</p>

<h2 id="1-clarity">1. Clarity</h2>

<h3 id="formatting">Formatting</h3>

<p>Go code, by convention, is formatted using the
<a href="https://golang.org/cmd/gofmt/"><code>gofmt</code></a> tool. Programmatically formatting code
is not a new idea, but contrary to its predecessors, <code>gofmt</code> supports precisely
one canonical style.</p>

<p>Having all code formatted the same way makes reading code easier; the code feels
familiar. This helps not only when reading the standard library or Go compiler,
but also when working with many code bases — think Open Source, or big
companies.</p>

<p>Further, auto-formatting is a huge time-saver during code reviews, as it
eliminates an entire dimension in which code could be reviewed before: now, you
can just let your continuous integration system verify that <code>gofmt</code> produces no
diffs.</p>

<p>Interestingly enough, having my editor apply <code>gofmt</code> when saving a file has
changed the way I write code. I used to attempt to match what the formatter
would enforce, then have it correct my mistakes. Nowadays, I express my thought
as quickly as possible and trust <code>gofmt</code> to make it pretty
(<a href="https://play.golang.org/p/I6GJwiT77v">example</a> of what I would type, click
Format).</p>

<h3 id="high-quality-code">High-quality code</h3>

<p>I use the standard library (<a href="https://golang.org/pkg/">docs</a>,
<a href="https://github.com/golang/go/tree/master/src">source</a>) quite a bit, see below.</p>

<p>All standard library code which I have read so far was of extremely high quality.</p>

<p>One example is the <a href="https://golang.org/pkg/image/jpeg/"><code>image/jpeg</code></a> package: I
didn’t know how JPEG worked at the time, but it was easy to pick up by switching
between the <a href="https://en.wikipedia.org/wiki/JPEG">Wikipedia JPEG article</a> and the
<code>image/jpeg</code> code. If the package had a few more comments, I would qualify it as
a teaching implementation.</p>

<h3 id="opinions">Opinions</h3>

<p>I have come to agree with many opinions the Go community holds, such as:</p>

<ul>
<li><a href="https://github.com/golang/go/wiki/CodeReviewComments#variable-names">Variable names</a> should be short by default, and become more descriptive the further from its declaration a name is used.</li>
<li>Keep the dependency tree small (to a reasonable degree): <a href="https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s">a little copying is better than a little dependency</a></li>
<li>There is a cost to introducing an abstraction layer. Go code is usually rather clear, at the cost of being a bit repetitive at times.</li>
<li>See <a href="https://github.com/golang/go/wiki/CodeReviewComments">CodeReviewComments</a> and <a href="https://go-proverbs.github.io/">Go Proverbs</a> for more.</li>
</ul>

<h3 id="few-keywords-and-abstraction-layers">Few keywords and abstraction layers</h3>

<p>The Go specification lists only <a href="https://golang.org/ref/spec#Keywords">25
keywords</a>, which I can easily keep in my
head.</p>

<p>The same is true for <a href="https://golang.org/pkg/builtin/">builtin functions</a> and
<a href="https://golang.org/ref/spec#Types">types</a>.</p>

<p>In my experience, the small number of abstraction layers and concepts makes the
language easy to pick up and quickly feel comfortable in.</p>

<p>While we’re talking about it: I was surprised about how readable the <a href="https://golang.org/ref/spec">Go
specification</a> is. It really seems to target
programmers (rather than standards committees?).</p>

<h2 id="2-speed">2. Speed</h2>

<h3 id="quick-feedback-low-latency">Quick feedback / low latency</h3>

<p>I love quick feedback: I appreciate websites which load quickly, I prefer fluent
User Interfaces which don’t lag, and I will choose a quick tool over a more
powerful tool any day. <a href="https://blog.gigaspaces.com/amazon-found-every-100ms-of-latency-cost-them-1-in-sales/">The
findings</a>
of large web properties confirm that this behavior is shared by many.</p>

<p>The authors of the Go compiler respect my desire for low latency: compilation
speed matters to them, and new optimizations are carefully weighed against
whether they will slow down compilation.</p>

<p>A friend of mine had not used Go before. After installing the
<a href="https://robustirc.net/">RobustIRC</a> bridge using <code>go get</code>, they concluded that Go
must be an interpreted language and I had to correct them: no, the Go compiler
just is that fast.</p>

<p>Most Go tools are no exception, e.g. <code>gofmt</code> or <code>goimports</code> are blazingly fast.</p>

<h3 id="maximum-resource-usage">Maximum resource usage</h3>

<p>For batch applications (as opposed to interactive applications), utilizing the
available resources to their fullest is usually more important than low latency.</p>

<p>It is delightfully easy to profile and change a Go program to utilize all
available IOPS, network bandwidth or compute. As an example, I wrote about
<a href="https://people.debian.org/~stapelberg/2014/01/17/debmirror-rackspace.html">filling a 1 Gbps
link</a>,
and optimized <a href="https://github.com/Debian/debiman/">debiman</a> to utilize all
available resources, reducing its runtime by hours.</p>

<h2 id="3-rich-standard-library">3. Rich standard library</h2>

<p>The <a href="https://golang.org/pkg">Go standard library</a> provides means to effectively
use common communications protocols and data storage formats/mechanisms, such as
TCP/IP, HTTP, JPEG, SQL, …</p>

<p>Go’s standard library is the best one I have ever seen. I perceive it as
well-organized, clean, small, yet comprehensive: I often find it possible to
write reasonably sized programs with just the standard library, plus one or two
external packages.</p>

<p>Domain-specific data types and algorithms are (in general) not included and live
outside the standard library,
e.g. <a href="https://godoc.org/golang.org/x/net/html"><code>golang.org/x/net/html</code></a>. The
<code>golang.org/x</code> namespace also serves as a staging area for new code before it
enters the standard library: the Go 1 compatibility guarantee precludes any
breaking changes, even if they are clearly worthwhile. A prominent example is
<code>golang.org/x/crypto/ssh</code>, which had to break existing code to <a href="https://github.com/golang/crypto/commit/e4e2799dd7aab89f583e1d898300d96367750991">establish a more
secure
default</a>.</p>



<p>To download, compile, install and update Go packages, I use the <code>go get</code> tool.</p>

<p>All Go code bases I have worked with use the built-in
<a href="https://golang.org/pkg/testing/"><code>testing</code></a> facilities. This results not only
in easy and fast testing, but also in <a href="https://blog.golang.org/cover">coverage
reports</a> being readily available.</p>

<p>Whenever a program uses more resources than expected, I fire up <code>pprof</code>. See
this <a href="https://blog.golang.org/profiling-go-programs">golang.org blog post about
<code>pprof</code></a> for an introduction, or
<a href="https://people.debian.org/~stapelberg/2014/12/23/code-search-taming-the-latency-tail.html">my blog post about optimizing Debian Code
Search</a>. After
importing the <a href="https://golang.org/pkg/net/http/pprof/"><code>net/http/pprof</code>
package</a>, you can profile your server
while it’s running, without recompilation or restarting.</p>

<p>Cross-compilation is as easy as setting the <code>GOARCH</code> environment variable,
e.g. <code>GOARCH=arm64</code> for targeting the Raspberry Pi 3. Notably, tools just work
cross-platform, too! For example, I can profile <a href="https://gokrazy.org/">gokrazy</a>
from my amd64 computer: <code>go tool pprof ~/go/bin/linux_arm64/dhcp
http://gokrazy:3112/debug/pprof/heap</code>.</p>

<p><a href="https://godoc.org/golang.org/x/tools/cmd/godoc">godoc</a> displays documentation
as plain text or serves it via HTTP. <a href="https://godoc.org/">godoc.org</a> is a public
instance, but I run a local one to use while offline or for not yet published
packages.</p>

<p>Note that these are standard tools coming with the language. Coming from C, each
of the above would be a significant feat to accomplish. In Go, we take them for
granted.</p>

<h2 id="getting-started">Getting started</h2>

<p>Hopefully I was able to convey why I’m happy working with Go.</p>

<p>If you’re interested in getting started with Go, check out <a href="https://github.com/gopheracademy/gopher/blob/1cdbcd9fc3ba58efd628d4a6a552befc8e3912be/bot/bot.go#L516">the beginner’s
resources</a>
we point people to when they join the Gophers slack channel. See
<a href="https://golang.org/help/">https://golang.org/help/</a>.</p>

<h2 id="caveats">Caveats</h2>

<p>Of course, no programming tool is entirely free of problems. Given that this
article explains why Go is my favorite programming language, it focuses on the
positives. I will mention a few issues in passing, though:</p>

<ul>
<li>If you use Go packages which don’t offer a stable API, you might want to use a specific, known-working version. Your best bet is the <a href="https://github.com/golang/dep">dep</a> tool, which is not part of the language at the time of writing.</li>
<li>Idiomatic Go code does not necessarily translate to the highest performance machine code, and the runtime comes at a (small) cost. In the rare cases where I found performance lacking, I successfully resorted to <a href="https://golang.org/cmd/cgo/">cgo</a> or assembler. If your domain is hard-realtime applications or otherwise extremely performance-critical code, your mileage may vary, though.</li>
<li>I wrote that the Go standard library is the best I have ever seen, but that doesn’t mean it doesn’t have any problems. One example is <a href="https://golang.org/issues/20744">complicated handling of comments</a> when modifying Go code programmatically via one of the standard library’s oldest packages, <code>go/ast</code>.</li>
</ul>

</div></div>]]>
            </description>
            <link>https://michael.stapelberg.ch/posts/2017-08-19-golang_favorite/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25723749</guid>
            <pubDate>Mon, 11 Jan 2021 02:49:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Electron with FFmpeg and Webpack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25722231">thread link</a>) | @cryogenicplanet
<br/>
January 10, 2021 | https://blog.modfy.video/Building-Electron-with-FFmpeg | <a href="https://web.archive.org/web/*/https://blog.modfy.video/Building-Electron-with-FFmpeg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>At Modfy, we are developing a desktop wrapper for <a href="http://modfy.video/" target="_blank" rel="noreferrer">modfy.video</a> and I wanted to share how to package FFmpeg with Electron using Webpack. I think there is a lot of good work based around this, but it wasn’t very clearly documented, and I ran into a lot of issues, so I thought I’d document what I used here.</p><h2 id="the-groundwork">The groundwork</h2><h2 id="electron">Electron</h2><p>I really like typescript and react, so I’d recommend using this boilerplate, as it does a lot of the heavy lifting in that regard.</p><p><a href="https://github.com/diego3g/electron-typescript-react" target="_blank" rel="noreferrer">https://github.com/diego3g/electron-typescript-react</a></p><div><pre><p><span>1</span><span>git</span><span> clone https://github.com/diego3g/electron-typescript-react.git project</span></p></pre></div><h2 id="ffmpeg">FFmpeg</h2><p>To ship a binary like FFmpeg with an application, we need to use the concept of static binaries. These are essentially binaries compiled with all their dependencies into one file that can be directly executed. Thankfully we don’t need to make these binaries ourselves, as other people have done the great work of compiling these binaries.</p><p>For example, the linux binaries are compiled here: <a href="https://johnvansickle.com/ffmpeg/" target="_blank" rel="noreferrer">https://johnvansickle.com/ffmpeg/</a></p><p>These binaries can be used wherever you’d like inside any ffmpeg wrapper, such as <em>fluent-ffmpeg</em>, or calling them yourself inside a <em>child.spawn</em> . For the rest of the tutorial we are going to demo this using <em>fluent-ffmpeg</em>, but it shouldn’t really change anything.</p><p>We can find all these static binaries bundled together for us in this repo: <a href="https://github.com/pietrop/ffmpeg-static-electron" target="_blank" rel="noreferrer">https://github.com/pietrop/ffmpeg-static-electron</a></p><p>It does a great job setting things up, but can be improved for the final compile step to actually import the files into electron correctly.</p><h2 id="building">Building</h2><h2 id="electron-builder">Electron-builder</h2><p>The boilerplate uses <code>electron-builder</code> to build out electron, which simplifies quite a bit but can still be a lot to learn and figure out. The documentation on <a href="http://electron.build/" target="_blank" rel="noreferrer">electron.build</a> is a good place to start.</p><p>The boilerplate will give you this within your build step in <code>package.json</code>, which is where all the electron build configs will go.</p><div><pre><p><span>1</span><span>"build"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>"appId"</span><span>:</span><span> </span><span>"your.id"</span><span>,</span><span></span></p><p><span>3</span><span>    </span><span>"mac"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>      </span><span>"category"</span><span>:</span><span> </span><span>"public.app-category.video"</span><span></span></p><p><span>5</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>6</span><span>    </span><span>"directories"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>      </span><span>"output"</span><span>:</span><span> </span><span>"packages"</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>9</span><span>    </span><span>"files"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>10</span><span>      </span><span>"package.json"</span><span>,</span><span></span></p><p><span>11</span><span>      </span><span>"dist/**"</span><span></span></p><p><span>12</span><span>    </span><span>]</span><span></span></p><p><span>13</span><span>  </span><span>}</span><span>,</span></p></pre></div><p>While this is a very basic starting point, there is a lot more to add here to actually get the build working. There are tons of good tutorials on this, but I’ll still go over it here briefly for posterity.</p><p>For each operating system you want to build to, you must choose your targets. For example, for Linux we want a build target as <code>.deb</code>, for debain operation systems. (<a href="https://www.electron.build/configuration/linux" target="_blank" rel="noreferrer">https://www.electron.build/configuration/linux</a>)</p><p>Within each target, we can add more changes and customization specific to that target.</p><p>For <code>.dmg</code> on MacOS, we need to make a few customizations to get the current dmg installer.</p><p>The contents determine how the <code>dmg</code> looks on MacOS when mounted.</p><div><pre><p><span>1</span><span>"dmg"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>      </span><span>"icon"</span><span>:</span><span> </span><span>"build/icon.icns"</span><span>,</span><span></span></p><p><span>3</span><span>      </span><span>"iconSize"</span><span>:</span><span> </span><span>100</span><span>,</span><span></span></p><p><span>4</span><span>      </span><span>"contents"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>5</span><span>        </span><span>{</span><span></span></p><p><span>6</span><span>          </span><span>"x"</span><span>:</span><span> </span><span>380</span><span>,</span><span></span></p><p><span>7</span><span>          </span><span>"y"</span><span>:</span><span> </span><span>280</span><span>,</span><span></span></p><p><span>8</span><span>          </span><span>"type"</span><span>:</span><span> </span><span>"link"</span><span>,</span><span></span></p><p><span>9</span><span>          </span><span>"path"</span><span>:</span><span> </span><span>"/Applications"</span><span></span></p><p><span>10</span><span>        </span><span>}</span><span>,</span><span></span></p><p><span>11</span><span>        </span><span>{</span><span></span></p><p><span>12</span><span>          </span><span>"x"</span><span>:</span><span> </span><span>110</span><span>,</span><span></span></p><p><span>13</span><span>          </span><span>"y"</span><span>:</span><span> </span><span>280</span><span>,</span><span></span></p><p><span>14</span><span>          </span><span>"type"</span><span>:</span><span> </span><span>"file"</span><span></span></p><p><span>15</span><span>        </span><span>}</span><span></span></p><p><span>16</span><span>      </span><span>]</span><span></span></p><p><span>17</span><span>    </span><span>}</span><span>,</span></p></pre></div><h3 id="build-resources">Build resources</h3><p>For extra resources related to the build itself, we need to make a folder called <code>build</code> at the root of our project, where we can store these files.</p><p>We can add this directory to the build like this:</p><div><pre><p><span>1</span><span>"directories"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>      </span><span>"output"</span><span>:</span><span> </span><span>"packages"</span><span>,</span><span></span></p><p><span>3</span><span>      </span><span>"buildResources"</span><span>:</span><span> </span><span>"build"</span><span></span></p><p><span>4</span><span>    </span><span>}</span><span>,</span></p></pre></div><p>This <code>build</code> folder will contain icons and other build assets.</p><h3 id="generating-icons">Generating icons</h3><p>For the <code>build</code> to work correctly we need two icon files; one <code>.icns</code>, and one <code>.ico</code>, for MacOS and Windows respectively. The Linux icon is generated from the MacOS icon.</p><p>The image should be square to make these icons. For me, making these icons was quite a bit of a pain, and I had to try various tools, so you may have to experiment a bit.</p><p>For <code>icns</code> I would recommend <a href="https://www.npmjs.com/package/make-icns" target="_blank" rel="noreferrer">https://www.npmjs.com/package/make-icns</a></p><div><pre><p><span>1</span><span>npx mk-icns </span><span>&lt;</span><span>png-file-path</span><span>&gt;</span><span> </span><span>&lt;</span><span>destination-directory</span><span>&gt;</span></p></pre></div><p>Other options: <a href="https://www.electron.build/icons" target="_blank" rel="noreferrer">https://www.electron.build/icons</a></p><p>A template of a final build config (not the exact config for modfy)</p><div><pre><p><span>1</span><span>"build"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>"appId"</span><span>:</span><span> </span><span>"com.app.id"</span><span>,</span><span></span></p><p><span>3</span><span>    </span><span>"productName"</span><span>:</span><span> </span><span>"Modfy"</span><span>,</span><span></span></p><p><span>4</span><span>    </span><span>"copyright"</span><span>:</span><span> </span><span>"Copyright © 2020 Modfy Inc"</span><span>,</span><span></span></p><p><span>5</span><span>    </span><span>"mac"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>      </span><span>"category"</span><span>:</span><span> </span><span>"public.app-category.video"</span><span>,</span><span></span></p><p><span>7</span><span>      </span><span>"artifactName"</span><span>:</span><span> </span><span>"${productName}-${version}-${arch}.${ext}"</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>9</span><span>    </span><span>"linux"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>10</span><span>      </span><span>"category"</span><span>:</span><span> </span><span>"Chat;GNOME;GTK;Network;InstantMessaging"</span><span>,</span><span></span></p><p><span>11</span><span>      </span><span>"packageCategory"</span><span>:</span><span> </span><span>"GNOME;GTK;Network;InstantMessaging"</span><span>,</span><span></span></p><p><span>12</span><span>      </span><span>"description"</span><span>:</span><span> </span><span>"Your app description"</span><span>,</span><span></span></p><p><span>13</span><span>      </span><span>"target"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>14</span><span>        </span><span>"deb"</span><span>,</span><span></span></p><p><span>15</span><span>        </span><span>"AppImage"</span><span>,</span><span></span></p><p><span>16</span><span>        </span><span>"snap"</span><span></span></p><p><span>17</span><span>      </span><span>]</span><span>,</span><span></span></p><p><span>19</span><span>      </span><span>"artifactName"</span><span>:</span><span> </span><span>"${productName}-${version}-${arch}.${ext}"</span><span></span></p><p><span>20</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>21</span><span>    </span><span>"deb"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>22</span><span>      </span><span>"synopsis"</span><span>:</span><span> </span><span>"Modfy Desktop App"</span><span></span></p><p><span>23</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>24</span><span>    </span><span>"snap"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>25</span><span>      </span><span>"synopsis"</span><span>:</span><span> </span><span>"Modfy Desktop App"</span><span></span></p><p><span>26</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>27</span><span>    </span><span>"dmg"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>28</span><span>      </span><span>"icon"</span><span>:</span><span> </span><span>"build/icon.icns"</span><span>,</span><span></span></p><p><span>29</span><span>      </span><span>"iconSize"</span><span>:</span><span> </span><span>100</span><span>,</span><span></span></p><p><span>30</span><span>      </span><span>"contents"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>31</span><span>        </span><span>{</span><span></span></p><p><span>32</span><span>          </span><span>"x"</span><span>:</span><span> </span><span>380</span><span>,</span><span></span></p><p><span>33</span><span>          </span><span>"y"</span><span>:</span><span> </span><span>280</span><span>,</span><span></span></p><p><span>34</span><span>          </span><span>"type"</span><span>:</span><span> </span><span>"link"</span><span>,</span><span></span></p><p><span>35</span><span>          </span><span>"path"</span><span>:</span><span> </span><span>"/Applications"</span><span></span></p><p><span>36</span><span>        </span><span>}</span><span>,</span><span></span></p><p><span>37</span><span>        </span><span>{</span><span></span></p><p><span>38</span><span>          </span><span>"x"</span><span>:</span><span> </span><span>110</span><span>,</span><span></span></p><p><span>39</span><span>          </span><span>"y"</span><span>:</span><span> </span><span>280</span><span>,</span><span></span></p><p><span>40</span><span>          </span><span>"type"</span><span>:</span><span> </span><span>"file"</span><span></span></p><p><span>41</span><span>        </span><span>}</span><span></span></p><p><span>42</span><span>      </span><span>]</span><span></span></p><p><span>43</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>44</span><span>    </span><span>"win"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>45</span><span>      </span><span>"target"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>46</span><span>        </span><span>{</span><span></span></p><p><span>47</span><span>          </span><span>"target"</span><span>:</span><span> </span><span>"nsis"</span><span>,</span><span></span></p><p><span>48</span><span>          </span><span>"arch"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>49</span><span>            </span><span>"x64"</span><span>,</span><span></span></p><p><span>50</span><span>            </span><span>"ia32"</span><span></span></p><p><span>51</span><span>          </span><span>]</span><span></span></p><p><span>52</span><span>        </span><span>}</span><span></span></p><p><span>53</span><span>      </span><span>]</span><span>,</span><span></span></p><p><span>54</span><span>      </span><span>"icon"</span><span>:</span><span> </span><span>"build/icon.ico"</span><span>,</span><span></span></p><p><span>55</span><span>      </span><span>"artifactName"</span><span>:</span><span> </span><span>"${productName}-${version}.${ext}"</span><span>,</span><span></span></p><p><span>56</span><span>      </span><span>"publisherName"</span><span>:</span><span> </span><span>"Modfy Inc."</span><span></span></p><p><span>57</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>58</span><span>    </span><span>"directories"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>59</span><span>      </span><span>"output"</span><span>:</span><span> </span><span>"packages"</span><span>,</span><span></span></p><p><span>60</span><span>      </span><span>"buildResources"</span><span>:</span><span> </span><span>"build"</span><span></span></p><p><span>61</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>62</span><span>    </span><span>"files"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>63</span><span>      </span><span>"package.json"</span><span>,</span><span></span></p><p><span>64</span><span>      </span><span>"dist/**/*"</span><span>,</span><span></span></p><p><span>65</span><span>    </span><span>]</span><span>,</span><span></span></p><p><span>66</span><span>  </span><span>}</span><span>,</span></p></pre></div><h2 id="webpack">Webpack</h2><p>The boilerplate comes with a good base webpack config, but we need to modify it to deal with <code>ffmpeg</code> correctly.</p><p>The base webpack config in <code>webpack/electron.config.js</code>:</p><div><pre><p><span>1</span><span>const</span><span> path </span><span>=</span><span> </span><span>require</span><span>(</span><span>"path"</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> rootPath </span><span>=</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>__dirname</span><span>,</span><span> </span><span>".."</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>module</span><span>.</span><span>exports </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>  resolve</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>    extensions</span><span>:</span><span> </span><span>[</span><span>".tsx"</span><span>,</span><span> </span><span>".ts"</span><span>,</span><span> </span><span>".js"</span><span>]</span><span></span></p><p><span>8</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>9</span><span>  devtool</span><span>:</span><span> </span><span>"source-map"</span><span>,</span><span></span></p><p><span>10</span><span>  entry</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>rootPath</span><span>,</span><span> </span><span>"electron"</span><span>,</span><span> </span><span>"main.ts"</span><span>)</span><span>,</span><span></span></p><p><span>11</span><span>  target</span><span>:</span><span> </span><span>"electron-main"</span><span>,</span><span></span></p><p><span>12</span><span>  module</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>    rules</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>14</span><span>      </span><span>{</span><span></span></p><p><span>15</span><span>        test</span><span>:</span><span> </span><span>/\.(js|ts|tsx)$/</span><span>,</span><span></span></p><p><span>16</span><span>        exclude</span><span>:</span><span> </span><span>/node_modules/</span><span>,</span><span></span></p><p><span>17</span><span>        use</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>18</span><span>          loader</span><span>:</span><span> </span><span>"babel-loader"</span><span></span></p><p><span>19</span><span>        </span><span>}</span><span></span></p><p><span>20</span><span>      </span><span>}</span><span></span></p><p><span>21</span><span>    </span><span>]</span><span></span></p><p><span>22</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>23</span><span>  node</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>24</span><span>    __dirname</span><span>:</span><span> </span><span>false</span><span></span></p><p><span>25</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>26</span><span>  output</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>27</span><span>    path</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>rootPath</span><span>,</span><span> </span><span>"dist"</span><span>)</span><span>,</span><span></span></p><p><span>28</span><span>    filename</span><span>:</span><span> </span><span>"[name].js"</span><span></span></p><p><span>29</span><span>  </span><span>}</span><span></span></p><p><span>30</span><span></span><span>}</span><span>;</span></p></pre></div><p>First the obvious step, change the entry point to whatever your main process file is. If you are using a preload, then that should be its only entry point.</p><div><pre><p><span>1</span><span>entry</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    main</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>rootPath</span><span>,</span><span> </span><span>'src'</span><span>,</span><span> </span><span>'mainProcess'</span><span>,</span><span> </span><span>'main.ts'</span><span>)</span><span>,</span><span></span></p><p><span>3</span><span>    preload</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>rootPath</span><span>,</span><span> </span><span>'src'</span><span>,</span><span> </span><span>'mainProcess'</span><span>,</span><span> </span><span>'preload.ts'</span><span>)</span><span></span></p><p><span>4</span><span>  </span><span>}</span><span>,</span></p></pre></div><h2 id="webpack--ffmpeg-static">Webpack + FFmpeg Static</h2><p>Now we can move on to the meat of how to configure <code>ffmpeg-static-electron</code> and webpack correctly!</p><p>First, we need to make the <code>ffmpeg-static-electron</code> package an ‘external’, which means it will not be bundled into the files itself.</p><div><pre><p><span>1</span><span>externals</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>'ffmpeg-static-electron'</span><span>:</span><span> </span><span>'commonjs2 ffmpeg-static-electron'</span><span></span></p><p><span>3</span><span>  </span><span>}</span><span>,</span></p></pre></div><p>Now that we have configured the package to be an ‘external’, we should copy over the package files into the <code>dist</code> folder. We can be smart here, and only copy over the corresponding OS files, rather than copy of all of them. We can use this kind of selective copying in a few places, which will be highlighted later on.</p><p>To copy files in webpack, we have to use <code>copy-webpack-plugin</code>.</p><p>Let’s find the paths of the files we want first; we want the <code>index.js, package.json</code> files regardless, but we also want <code>/bin/{os}/{arch}/ffmpeg</code>.</p><div><pre><p><span>1</span><span>const</span><span> ffmpegStaticModulePath </span><span>=</span><span> path</span><span>.</span><span>join</span><span>(</span><span></span></p><p><span>2</span><span>  </span><span>"node_modules"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>"ffmpeg-static-electron"</span><span></span></p><p><span>4</span><span></span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>let</span><span> platform </span><span>=</span><span> os</span><span>.</span><span>platform</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span></span><span></span></p><p><span>8</span><span></span><span>if</span><span> </span><span>(</span><span>platform </span><span>==</span><span> </span><span>"darwin"</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>  platform </span><span>=</span><span> </span><span>"mac"</span><span>;</span><span></span></p><p><span>10</span><span></span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>platform </span><span>==</span><span> </span><span>"win32"</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>11</span><span>  platform </span><span>=</span><span> </span><span>"win"</span><span>;</span><span></span></p><p><span>12</span><span></span><span>}</span><span></span></p><p><span>13</span><span></span></p><p><span>14</span><span></span><span>const</span><span> platformArchPath </span><span>=</span><span> path</span><span>.</span><span>join</span><span>(</span><span></span></p><p><span>15</span><span>  ffmpegStaticModulePath</span><span>,</span><span></span></p><p><span>16</span><span>  </span><span>"bin"</span><span>,</span><span></span></p><p><span>17</span><span>  platform</span><span>,</span><span></span></p><p><span>18</span><span>  os</span><span>.</span><span>arch</span><span>(</span><span>)</span><span></span></p><p><span>19</span><span></span><span>)</span><span>;</span></p></pre></div><p>This will create the file paths we need to copy over our files.</p><div><pre><p><span>1</span><span>plugins</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>2</span><span>  </span><span>new</span><span> </span><span>CopyPlugin</span><span>(</span><span>{</span><span></span></p><p><span>3</span><span>    patterns</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>4</span><span>      </span><span>{</span><span></span></p><p><span>5</span><span>        </span><span>from</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>ffmpegStaticModulePath</span><span>,</span><span> </span><span>"index.js"</span><span>)</span><span>,</span><span></span></p><p><span>6</span><span>        to</span><span>:</span><span> ffmpegStaticModulePath</span></p><p><span>7</span><span>      </span><span>}</span><span>,</span><span></span></p><p><span>8</span><span>      </span><span>{</span><span></span></p><p><span>9</span><span>        </span><span>from</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>ffmpegStaticModulePath</span><span>,</span><span> </span><span>"package.json"</span><span>)</span><span>,</span><span></span></p><p><span>10</span><span>        to</span><span>:</span><span> ffmpegStaticModulePath</span></p><p><span>11</span><span>      </span><span>}</span><span>,</span><span></span></p><p><span>12</span><span>      </span><span>{</span><span></span></p><p><span>13</span><span>        </span><span>from</span><span>:</span><span> platformArchPath</span><span>,</span><span></span></p><p><span>14</span><span>        to</span><span>:</span><span> platformArchPath</span></p><p><span>15</span><span>      </span><span>}</span><span></span></p><p><span>16</span><span>    </span><span>]</span><span></span></p><p><span>17</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>18</span><span></span><span>]</span><span>;</span></p></pre></div><p>Now we have created a <code>dist/node_modules/</code> folder with FFmpeg. <strong>This is very important, as this is the folder we will be using for development.</strong></p><p>The last step with webpack is to make the copied files an executable file.</p><p>For this, we need to add a build hook (yes webpack has hooks now). So we can use <code>webpack-hook-plugin</code> to create this build hook.</p><div><pre><p><span>1</span><span>new</span><span> </span><span>WebpackHookPlugin</span><span>(</span><span>{</span><span></span></p><p><span>2</span><span>  onBuildStart</span><span>:</span><span> </span><span>[</span><span>'echo "Webpack Start"'</span><span>]</span><span>,</span><span></span></p><p><span>3</span><span>  onBuildExit</span><span>:</span><span> </span><span>[</span><span>`chmod a+x </span><span>${</span><span>path</span><span>.</span><span>resolve</span><span>(</span><span>"dist"</span><span>,</span><span> platformArchPath</span><span>,</span><span> </span><span>"ffmpeg"</span><span>)</span><span>}</span><span>`</span><span>]</span><span></span></p><p><span>4</span><span></span><span>}</span><span>)</span><span>;</span></p></pre></div><p>This command should make the files executable.</p><h2 id="moving-ffmpeg-into-electron-bundle">Moving FFmpeg into electron bundle</h2><p>Now the final step and this one is a bit weird.</p><p>Electron builder by default will not put any folder called <code>node_modules</code> inside the <code>app</code> or <code>app.asar</code> unless they are listed as <code>dependencies</code> (This is a good time to move all the dependencies to <code>dev-dependencies</code>, as they are compiled with webpack)</p><p>I was able to work around this by using <code>extraResources</code> instead of <code>files</code> in the build config (<a href="https://www.electron.build/configuration/contents.html#extraresources" target="_blank" rel="noreferrer">https://www.electron.build/configuration/contents.html#extraresources</a>).</p><p>This will put the files in the <code>Contents/Resources</code> folder for MacOS, and the <code>resources</code> folder for Linux and Windows.</p><p>As package resolution will check <code>../node_modules/</code>, this will not cause a problem and you will be able to use your app.</p><div><pre><p><span>1</span><span>extraResources"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>2</span><span>      </span><span>{</span><span></span></p><p><span>3</span><span>        </span><span>"from"</span><span>:</span><span> </span><span>"dist/node_modules/ffmpeg-static-electron/"</span><span>,</span><span></span></p><p><span>4</span><span>        </span><span>"to"</span><span>:</span><span> </span><span>"node_modules/ffmpeg-static-electron"</span><span></span></p><p><span>5</span><span>      </span><span>}</span><span></span></p><p><span>6</span><span>    </span><span>]</span></p></pre></div><p>At this point, you should be good to go with your app, and you can use <code>electron-builder --dir</code> to check and <code>electron-builder</code> to compile for the current operating system.</p><hr><p>If you want to use <a href="http://modfy.video/" target="_blank" rel="noreferrer">modfy.video</a>’s desktop app (which is currently an early alpha preview), then join our <a href="https://discord.gg/ffDZnMR" target="_blank" rel="noreferrer">discord server</a> to get access.</p><p>At the end I wanted to add, I am by no means an Electron expert. …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.modfy.video/Building-Electron-with-FFmpeg">https://blog.modfy.video/Building-Electron-with-FFmpeg</a></em></p>]]>
            </description>
            <link>https://blog.modfy.video/Building-Electron-with-FFmpeg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25722231</guid>
            <pubDate>Mon, 11 Jan 2021 00:23:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using old Mini PCIE WLAN cards in modern laptops]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25722095">thread link</a>) | @kamaraju
<br/>
January 10, 2021 | https://gsid.in/using-old-mini-pcie-wlan-cards-in-modern-laptops/ | <a href="https://web.archive.org/web/*/https://gsid.in/using-old-mini-pcie-wlan-cards-in-modern-laptops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div id="content"><div id="primary"><main id="main"><article id="post-31" itemtype="https://schema.org/CreativeWork" itemscope=""><div><div itemprop="text"><figure><img width="640" height="480" src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?resize=640%2C480&amp;ssl=1" alt="Dell 1501 half mini PCI-E 802.11n WiFi card" srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?w=640&amp;ssl=1 640w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?w=640&amp;ssl=1 640w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?resize=300%2C225&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/dell-1501-1.jpg?resize=640%2C480&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption> <br>Dell 1501 half mini PCI-E 802.11n WiFi card</figcaption></figure><p>So i was trying to install a WiFi card(Dell 1501 half mini PCI-E 802.11n card) which i had lying around from 7 years ago in my laptop. Everything worked perfectly until i tried to query the networks available. I saw that the wireless connection was turned off. I went through the usual exercise of checking the drivers, then the antenna and checking if the card was seated right in the PCI-E slot. The card would never turn on. Since it was a re-branded Broadcom chipset i tried installing the Broadcom drivers as well as the dell drivers, no dice. Then i started reading up on the Mini PCI-E specifications for the WiFi card.</p><p>Older generation of WiFi mini PCI-E cards from a while ago usually have a hardware kill switch. This RF kill switch was usually connected to one of the pins on the Mini PCI-E header. Modern laptops are unable to turn on the WLAN card. Modern laptops can read and initialize the PCI-E card, but the radio part of the card is turned off.&nbsp;</p><p>From reading up on the spec sheet of several WLAN Mini-PCIE card from 7 years ago i found that that Mini-PCIE pin 20 which according to the specs was reserved for vendor specific purposes was being utilized as a RF kill switch.Similarly in cards with WiFi and Bluetooth, pin 51 is set for Bluetooth disable along with the pin 20 for WLAN disable.</p><figure><img width="658" height="273" src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?resize=658%2C273&amp;ssl=1" alt="Mini PCI Express" srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?w=658&amp;ssl=1 658w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?resize=300%2C124&amp;ssl=1 300w" sizes="(max-width: 658px) 100vw, 658px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?w=658&amp;ssl=1 658w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?resize=300%2C124&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/Mini_PCI_express.jpg?resize=658%2C273&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Mini PCI Express</figcaption></figure><p> Now i have to identify the pins in my Mini PCI-E card. Luckily the mini PCI-E pins 1,2,51,52 were marked in my card. Mini PCI-E cards have the first pin on the front side and the second pin on the reverse. They alternate with odd pins on the front side of the card and the even pins on the reverse side.</p><figure><img width="399" height="350" src="https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?resize=399%2C350&amp;ssl=1" alt="" srcset="https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?w=399&amp;ssl=1 399w, https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?resize=300%2C263&amp;ssl=1 300w" sizes="(max-width: 399px) 100vw, 399px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?w=399&amp;ssl=1 399w, https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?resize=300%2C263&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501.jpg?resize=399%2C350&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Dell 1501 Front</figcaption></figure><figure><img width="457" height="374" src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?resize=457%2C374&amp;ssl=1" alt="" srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?w=457&amp;ssl=1 457w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?resize=300%2C246&amp;ssl=1 300w" sizes="(max-width: 457px) 100vw, 457px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?w=457&amp;ssl=1 457w, https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?resize=300%2C246&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/gsid.in/wp-content/uploads/2019/05/DELL1501-rev.jpg?resize=457%2C374&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure><p> So to make the card work i masked pin 20 carefully with an electrical tape to isolate it. And PCI-E card started working normally. You can use any type of tape that is non conductive. PVC tapes work best. One has to be very careful while cutting and pasting the masking as it should not mask any other pin. &nbsp;</p><figure><img src="https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=567%2C567&amp;ssl=1" alt="" width="567" height="567" srcset="https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?w=756&amp;ssl=1 756w, https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=300%2C300&amp;ssl=1 300w" sizes="(max-width: 567px) 100vw, 567px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?w=756&amp;ssl=1 756w, https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=300%2C300&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/gsid.in/wp-content/uploads/2019/05/pin20mask.jpg?resize=567%2C567&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Pin 20 masked with Electrical tape</figcaption></figure><p>When a PCI-E pin is not connected it may start bouncing.and hence in newer PCI-E card this pin is driven with a 1 or 0 to enable or disable the card. Older generation cards just kept the pin open and hence when connected to a modern laptop without the masking think that RF is always disabled.</p><p>This has worked for me. The author cannot be held responsible for any loss or injury if you decide to follow my lead.</p></div></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://gsid.in/using-old-mini-pcie-wlan-cards-in-modern-laptops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25722095</guid>
            <pubDate>Mon, 11 Jan 2021 00:11:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TV Tuner History]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25721804">thread link</a>) | @parsecs
<br/>
January 10, 2021 | https://www.maximus-randd.com/tv-tuner-history-pt5.html | <a href="https://web.archive.org/web/*/https://www.maximus-randd.com/tv-tuner-history-pt5.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.maximus-randd.com/tv-tuner-history-pt5.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25721804</guid>
            <pubDate>Sun, 10 Jan 2021 23:48:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hackers Do Wiretapping Using MitM]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25720776">thread link</a>) | @janso
<br/>
January 10, 2021 | https://www.skillonpage.com/wiretapping-using-man-in-the-middle-attack/ | <a href="https://web.archive.org/web/*/https://www.skillonpage.com/wiretapping-using-man-in-the-middle-attack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div itemprop="articleBody">
					<p><strong>Man in the Middle</strong> attack (MITM) is an extremely dangerous hacking and can happen anywhere. This can occur whether on a website, mobile phone, or in conventional communication tool such as correspondence. Therefore, it’s important to discuss MITM attack regardless of anything and wherever its technical implementation.</p>
<h2>What is Man in the Middle Attack?</h2>
<p>Man In The Middle attack is a hacking technique where hackers put themselves in the middle of two devices that communicate with each other. As in this type of hacking an attacker is overtaking in the middle of a communication, the attacker can read, hear, modify, or block the communication packet that is going to be sent or received in both devices.</p>
<p>The most severe outcome of a Man in the Middle attack hacking technique is that the hacker is wiretapping the information and steal passwords. This kind of attack is really effective, more dangerous and harder to avoid that <a href="https://skillonpage.com/what-is-phishing-scam-and-how-to-avoid-it/">how to avoid phishing</a>.</p>
<h2>MITM Isn’t Just Sniffing</h2>
<p>Perhaps, many people think that the aim of a Man in the Middle attack is to do wiretapping into a confidential <a href="https://skillonpage.com/data-communication-definition-and-types/">data communication</a> like a sniffing practice. Sniffing is a passive attack as the sniffing attacker doesn’t do anything, but monitor the passing data. Definitely, an attacker would be able to wiretap a communication between two parties using “Man in the Middle Attack” technique. But actually, the greatest strength of the MITM attack is not its sniffing ability. The MITM main ability is to intercept and alter the communication. So, the Man in the Middle Attack is also called as an active attack.</p>
<h2>How MITM Works</h2>
<p>MITM works by exploiting <strong>ARP</strong> (<em>Address Resolution Protocol</em>). ARP is a protocol that is in charge of translating the IP address to the MAC Address.</p>
<p>Basically, the lowest communication network is using a Mac Address as an identity between two devices. So, if an ARP table is modified by hackers, they can manipulate the data transmission for wrong purposes.</p>
<p>If you are using Windows computer, you can check the ARP table by typing “arp – a” in your command prompt (cmd). There you can find an IP address record line and Mac Address of all connected computers.</p>
<p>Let’s late a look at the picture below to consider the difference between data delivery routes before a MITM attack.</p>
<p><img loading="lazy" title="MITM" src="https://skillonpage.com/wp-content/uploads/2018/02/before-mitm-attack.jpg" alt="Before MITM attack" width="594" height="386" srcset="https://www.skillonpage.com/wp-content/uploads/2018/02/before-mitm-attack.jpg 594w, https://www.skillonpage.com/wp-content/uploads/2018/02/before-mitm-attack-300x195.jpg 300w" sizes="(max-width: 594px) 100vw, 594px"></p>
<p>The client device will send and receive data directly from the wifi router without an intermediary when in an under normal condition. The normal condition here means before MITM attack. But after the MITM attacks the client device, the hacker is wiretapping the communication where the router works as you can see in the picture below.</p>
<p><img loading="lazy" title="Man in the Middle Attack" src="https://skillonpage.com/wp-content/uploads/2018/02/man-in-the-middle-attack.jpg" alt="After atarget get hacked using MITM technique" width="594" height="386" srcset="https://www.skillonpage.com/wp-content/uploads/2018/02/man-in-the-middle-attack.jpg 594w, https://www.skillonpage.com/wp-content/uploads/2018/02/man-in-the-middle-attack-300x195.jpg 300w" sizes="(max-width: 594px) 100vw, 594px"></p>
<p>Hackers can wiretap a communication as an ARP has two exploitable weaknesses, namely:</p>
<ul>
<li>Every ARP Request or ARP Response is always Trusted;</li>
<li>Clients may receive a response even if they don’t send a request.</li>
</ul>
<p>Every device that freshly connects to a network always tries to find which one is the right router. Then the router will respond. Along with that, the router records the IP and Mac Address in the ARP Table.</p>
<p>To create a Man In The Middle condition, the hacker can send a response to a client computer by taking over as the router “if the client computer doesn’t verify” whether or not a connecting router is the right one. To illustrate this scheme, take a look at the following illustration.</p>
<p><img loading="lazy" title="Hacker Decepts Client" src="https://skillonpage.com/wp-content/uploads/2018/02/hacker-decepts-client.jpg" alt="The illustration how a hacker decepts a client in MITM" width="594" height="386" srcset="https://www.skillonpage.com/wp-content/uploads/2018/02/hacker-decepts-client.jpg 594w, https://www.skillonpage.com/wp-content/uploads/2018/02/hacker-decepts-client-300x195.jpg 300w" sizes="(max-width: 594px) 100vw, 594px"></p>
<p>For every request and response is always trusted, the client device will believe that the right router is that hacker device. Over here, the hacker also managed to deceive the client device in wiretapping as a router. Next, the hacker will also masquerades as the right client to the router as explained at the picture below.</p>
<p><img loading="lazy" title="Hacker Decepts Router" src="https://skillonpage.com/wp-content/uploads/2018/02/hacker-decepts-router.jpg" alt="The illustration how a hacker decepts a router" width="594" height="386" srcset="https://www.skillonpage.com/wp-content/uploads/2018/02/hacker-decepts-router.jpg 594w, https://www.skillonpage.com/wp-content/uploads/2018/02/hacker-decepts-router-300x195.jpg 300w" sizes="(max-width: 594px) 100vw, 594px"></p>
<p>The router will originally deem that the hacker is the client and the client deems that the hacker is the router. That way, the hacker device is in the middle between the client and router. Every requested and received package done by the client device will be passing through the hacker’s device first. This is why such wiretapping is called as Man in the Middle attack.</p>
<h2>Tools That are Used by Hackers to Do MITM Attack</h2>
<p>Hackers require a Kali Linux operating system to do a MITM attack. They are also able to use Kali Linux on Windows using a virtual box or one of the best Kali Linux emulators for Windows.</p>
<p>One of the most popular MITM tools is <strong>MITMf</strong> (Man in the Middle Framework), which is a complete one with features for wiretapping. But when a hacker wants to practice a MITM attack, must first be in the same network with the target victim.</p>
<p>The following is the hacking command in MITMf:</p>
<p><em>mitmf -arp -spoof -gateway [target router ip] -targets [ target client ip]</em></p>
<p>That command will deceive both target router and client at once. Then the hacker enables an IP forward by editing file/proc/sys/net/ipv4 /ip_forward which initially 0 (inactive) becomes 1 (active). This is done so that packets which are not addressed to the hacker’s device can be forwarded to the target client’s device.</p>
<p>When the hacker runs MITMf, it will automatically perform an attack as described above (deceive the client and its router) as well as running sniffing packet. A bugged package will be listed directly in the terminal.</p>
<p>All sensitive information such as username and password will be visible in a bare text (without encryption) if the accessed site does not use SSL (https).</p>
<p>For example, in a Google Chrome browser, the victim is accessing a login page on a membership site and fills his credentials to the login form. Because the site doesn’t use https, the username and password will be sent without encryption. Then, the package containing that username and password is going through the hacker’s tool first and can be read on the hacker’s device.</p>
<p>Most large websites use SSL for security. The main function of SSL is to encrypt all data so it cannot be tapped. Remarkably, MITMf runs an SSLstrip program automatically. SSLstrip is a program that can downgrade https to http. Even so, large sites like Facebook, Google, Twitter, etc. use another security that forces their users to keep using https.</p>
<p>But what happens when a target uses a “remember me” feature?. Using the “remember me” feature allows us to automatically log in using cookies on the browser. Such condition, the password and username are not sent to the server so Hackers cannot read the password.</p>
<p>Login using cookies on browsers is still dangerous as it still can be stolen. Instead of tapping passwords, hackers can also steal cookies and then use them on their browsers. This way, hackers can log in without knowing the targets’ username and password. Stealing cookies is more practical in wiretapping.</p>
<p>So, hackers need&nbsp; MITMf for Man in the Middle, Farred for stealing cookies, and Hamsters for injecting cookies to Linux Kali’s browser. Hacking techniques vary as there are many hacking tools with similar functions.</p>
<p>However, here we are not giving a deeper tutorial on how to hack using MITM. But at least knowing how such tools work would be useful for you to avoid hacking attacks.</p>
<h2>The Bad Things Caused by Man in the Middle Attack</h2>
<p>Given that in a Man in the Middle attack a hacker is wiretapping a communication path, the sent or received information can be changed, removed, or faked. Hackers can do such bad things by using a Man in the Middle techniques.</p>
<h3>Wiretapping</h3>
<p>Whatever you write on blogs or other <a href="https://skillonpage.com/types-of-websites/">types of websites</a>, including super sensitive information like “password”, will be passing through hacker’s tool first. So, the hacker can peep your password and other credentials. MITM can also integrate with the Wireshark. This integration is useful for hackers in doing wiretapping activities as through Wireshark hackers can better record and display the stolen data.</p>
<h3>JavaScript Injection</h3>
<p>This is the most dangerous thing in MITM attack. JavaScript injection makes a MITM attack become infinite as long as hackers are good JavaScript skills. The MITMf tool supports practical plugins for javascript. For example, hackers can capture the victims’ browser screenshot with repetitive frequencies that can be determined. Besides, Javascript also helps hackers to remotely enable <a href="https://skillonpage.com/check-if-keylogger-runs-on-computer/">keylogger</a>, webcam, fake pop-up login form on victims’ browser and so forth. Hackers can also integrate Man in the Middle attack with a BEef program. The BEbeef program can help hackers to totally hack the victims’ browser by way of a Javascript provided by BEef is executed in the victims’ browser.</p>
<h3><a href="https://skillonpage.com/how-dns-works/">DNS</a> Deception</h3>
<p>Every time you type a website address, actually you are going to access to a web server in the form of IP address. So, hackers can apply a fake DNS using the Man in the Middle technique. For example, when you type Google, the opened site is a fake Google. Even that you are pretty sure you are typing a correct address. By using a DNS spoofing, Hackers can change a site to an IP address such as to a local website that resides in a hacker’s computer.</p>
<h3>Cookie Theft</h3>
<p>Your browser stores your login data to cookies. It’s why can directly login to Facebook without filling your username and password when you simply type in facebook address. That’s one of the functions of cookies. The bad thing is that using a MITM technique, hackers can steal your cookies.</p>
<h2>How to Avoid MITM Attack</h2>
<p>You will not realize any Man in the Middle attack until you feel something really odd. Because there is no notification when you are being attacked. Unless when you see suddenly a from popping up on your browser to ask you to re-login which makes you suspicious. That’s an example of a javascript injection from MITM hackers.</p>
<p>Therefore, when you suspicious enough, immediately check the ARP table by typing <em>arp –</em>a at the command prompt (cmd). Make sure there are no two different IPs with the same network using same Mac Address.</p>
<p>Now you should be knowing how dangerous it is when you are on the same network with a hacker. Therefore, increase your internet security, always double checking site addresses that use https. When it turns automatically to http, you should have been suspicious. If …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skillonpage.com/wiretapping-using-man-in-the-middle-attack/">https://www.skillonpage.com/wiretapping-using-man-in-the-middle-attack/</a></em></p>]]>
            </description>
            <link>https://www.skillonpage.com/wiretapping-using-man-in-the-middle-attack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720776</guid>
            <pubDate>Sun, 10 Jan 2021 22:25:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discovering and exploring mmap using Go]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25720731">thread link</a>) | @brunoac
<br/>
January 10, 2021 | https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/ | <a href="https://web.archive.org/web/*/https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Recently I've come to know the concept of <strong>memory-mapped files</strong> while watching a lecture of the course <a href="https://15445.courses.cs.cmu.edu/fall2019/">Intro to Database Systems</a> of <a href="https://twitter.com/andy_pavlo">Andy Pavlo</a> on database storage. One of the main problems a database storage engine has to solve is <strong>how to deal with data in disk that is bigger than the available memory</strong>. At a higher level, the main purpose of a disk-oriented storage engine is to manipulate data files in a disk. But if we assume that the data in the disk will eventually get bigger than the available memory, we cannot simply load the whole data file into memory, do the change, and write it back to disk.</p><p>This is not a new problem in Computer Science. When operational systems were being developed in the early 1960s, a similar problem was faced: <strong>how can we run programs stored in disk that are larger than the available memory?</strong> A solution to this problem was made by a group in Manchester, implemented on the <a href="https://en.wikipedia.org/wiki/Atlas_(computer)">Atlas Computer</a>, in 1961. It was called <em>virtual memory</em>. The <em>virtual memory</em> gives a running program the illusion that it has big enough memory, despite the fact that the computer does not have enough.</p><p>We are not going to go deep on how <em>virtual memory</em> works. Just have in mind that when a program is accessing memory it is accessing the <em>virtual memory</em>. And maybe the data the program is trying to access is not actually in memory, but it does not matter. The operational system will make pretend that it is by going to disk, and putting it there, and replace an old chunk of memory that is not going to be used.</p><p>So, one of the ways a database storage engine can solve the larger than memory problem is to make use of <em>virtual memory</em> and the concept of <strong>memory-mapped files</strong>.</p><p>In Linux, we can make this use by using the system call <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a> that lets you map a file, no matter how big, directly into memory. If your program needs to manipulate the file, all it needs is to manipulate the memory. The operating system handles the writes to disk for you.</p><p>In some occasions, programmers find this method more convenient than the usual system calls: <a href="https://man7.org/linux/man-pages/man2/open.2.html">open</a>, <a href="https://man7.org/linux/man-pages/man2/read.2.html">read</a>, <a href="https://man7.org/linux/man-pages/man2/write.2.html">write</a>, <a href="https://man7.org/linux/man-pages/man2/lseek.2.html">lseek</a> and <a href="https://man7.org/linux/man-pages/man2/close.2.html">close</a>.</p><h3 id="a-simple-demonstration">A simple demonstration</h3><p>Here is a small example of how you can take advantage of this in Go using the package <a href="https://github.com/edsrzf/mmap-go">mmap-go</a>:</p><pre><code>package main

import (
	"os"
	"fmt"
	"github.com/edsrzf/mmap-go"
)

func main() {
	f, _ := os.OpenFile("./file", os.O_RDWR, 0644)
	defer f.Close()
	
	mmap, _ := mmap.Map(f, mmap.RDWR, 0 )
	defer mmap.Unmap()
	fmt.Println(string(mmap))
	
	mmap[0] = 'X'
	mmap.Flush()
}</code></pre><figure><img src="https://asciinema.org/a/pRS8PvTRHksnCVQgSOWvPBF3a.svg" alt="asciicast"></figure><p>The beauty is that we could have a much bigger file, and the solution would still work. We would not have to worry about managing memory in order to avoid it filling up.</p><h3 id="detailing-mmap-capabilites">Detailing <em>mmap</em> capabilites</h3><p>We're going to explore more <em>mmap</em> functionalities from the point of view of the API provided by <a href="https://github.com/edsrzf/mmap-go">mmap-go</a>. There are probably more features that the <a href="https://godoc.org/golang.org/x/sys/unix#Mmap">native syscall</a> provides that this library does not implement.</p><h4 id="the-prot-argument">The <code>prot</code> argument</h4><p>Here is the <code>mmap.Map</code> signature</p><pre><code>func Map(f *os.File, prot, flags int) (MMap, error) 
</code></pre><p>Let's look at <code>prot</code> first. The <code>prot</code> argument lets you specify the protection levels of your mapping: <code>RDONLY</code>, <code>RDWR</code>, <code>EXEC</code> are the options provided for <code>mmap-go</code>. These levels are pretty straightforward, <code>RDONLY</code> means you can only read from the mapping, <code>RDWR</code> means you can also write, and <code>EXEC</code> means you can execute code on that mapping. &nbsp;Here is the description of <code>prot</code> from the Linux <code>man</code>:</p><pre><code>The prot argument describes the desired memory protection of the
mapping (and must not conflict with the open mode of the file).
It is either PROT_NONE or the bitwise OR of one or more of the
following flags:

PROT_EXEC
    Pages may be executed.

PROT_READ
    Pages may be read.

PROT_WRITE
    Pages may be written.

PROT_NONE
    Pages may not be accessed.
</code></pre><p>In the <a href="https://godoc.org/golang.org/x/sys/unix">unix package</a>, those flags are: <code>unix.PROT_EXEC</code>, <code>unix.PROT_READ</code>, <code>unix.PROT_WRITE</code> and <code>unix.PROT_NONE</code>.</p><h4 id="experimenting-with-prot_exec-flag">Experimenting with <code>PROT_EXEC</code> flag</h4><p>I've become intrigued by the <code>EXEC</code> flag and wanted to see an example of how that works. I've Google and could not find any example. So I tried a search in Github by <code>PROT_EXEC</code> and found a good example in <code>C</code>: <a href="https://github.com/onesmash/MMapExecDemo">MMapExecDemo</a>. I replicated this example in <code>Go</code> using <code>mmap-go</code>.</p><p>The first step was to create a function that I wanted to be put in memory by <code>mmap</code> allocation, compile it, and get its assembly opcodes.</p><p>I created the <code>inc</code> function in <code>inc.go</code> file</p><pre><code>package inc

func inc(n int) int {
	return n + 1
}

</code></pre><p>compiled it with <code>go tool compile -S -N inc.go</code>, then got its assembly by calling <code>go tool objdump -S inc.o</code>.</p><pre><code>func inc(n int) int {
  0x22b                 48c744241000000000      MOVQ $0x0, 0x10(SP)
        return n + 1
  0x234                 488b442408              MOVQ 0x8(SP), AX
  0x239                 48ffc0                  INCQ AX
  0x23c                 4889442410              MOVQ AX, 0x10(SP)
  0x241                 c3                      RET
</code></pre><p>With this, we can build represent our function in bytes on our code</p><pre><code>code := []byte{
        0x48, 0xc7, 0x44, 0x24, 0x10, 0x00, 0x00, 0x00, 0x00,
		0x48, 0x8b, 0x44, 0x24, 0x08,
		0x48, 0xff, 0xc0,
		0x48, 0x89, 0x44, 0x24, 0x10,
		0xc3,
}
</code></pre><p>We allocate our memory with <code>mmap</code>.</p><pre><code>memory, err := mmap.MapRegion(nil, len(code), mmap.EXEC|mmap.RDWR, mmap.ANON, 0)
if err != nil {
    panic(err)
}
</code></pre><p>In this call, we're using a more complete function called <code>MapRegion</code> that lets you specify how much memory you are allocating (<code>Map</code> allocates the size of the underlying file) and the offset of the file.</p><p>In the beginning, we said that the main purpose of <code>mmap</code> was to create a mapping between a file and memory. But in this call we are not indicating any file. <code>mmap</code> can be used just a regular memory allocater by setting <code>nil</code> to the <code>*os.File</code> argument and <code>mmap.ANON</code> to the <code>flags</code> argument. We will talk about more <code>mmap.ANON</code>. Since we are not mapping any file, the offset is <code>0</code>.</p><p>So we have memory allocated with the same size of our code <code>len(code)</code>. Since we set the flag <code>mmap.RDWR</code>, we can copy our <code>code</code> to <code>memory</code>.</p><pre><code>copy(memory, code)
</code></pre><p>We have the code of our <code>inc</code> function in memory. In order to execute it, we have to cast that memory address to a function with a signature that matches the signature of our compiled <code>inc</code>.</p><pre><code>memory_ptr := &amp;memory
ptr := unsafe.Pointer(&amp;memory_ptr)
inc := *(*func(int) int)(ptr)
</code></pre><p>When we call <code>inc</code>, we are executing the code we put in memory. That only works because of the flag <code>mmap.EXEC</code>. If that flag was not set, a <code>segmentation violation</code> would occur.</p><pre><code>fmt.Println(inc(10)) // Prints 11
</code></pre><p>I don't know if this is a real use case. I just wanted to see what it meant to execute code that you put in memory. And there are probably other ways of achieving the same with regular memory allocation and calls to <a href="https://man7.org/linux/man-pages/man2/mprotect.2.html">mprotect</a>.</p><p>One question that may come up is: but the code is already in the <code>code</code> variable, can't we just execute it? No, because the memory static allocated to <code>code</code> is not executable. Can we make it executable? I've tried to use <a href="https://man7.org/linux/man-pages/man2/mprotect.2.html">mprotect</a> on it but still got <code>segmentation violation</code>.</p><p>Here is the full working <a href="https://gist.github.com/brunoac/b9ff4ad46c27926e5e4f078133d0de79">gist</a>.</p><h4 id="the-flags-argument">The <code>flags</code> argument</h4><p>We can have many processes mapping the same memory region. This argument lets us decide about the visibility of the updates happening in the mapping. There are many flags, and you can check them out at <a href="https://man7.org/linux/man-pages/man2/mmap.2.html">mmap</a>. The important ones are <code>unix.MAP_SHARED</code>, <code>unix.MAP_PRIVATE</code> and <code>unix.MAP_ANON</code>.</p><p><code>MAP_SHARED</code> means that changes to the mapping are visible to all processes and will also occur at the underlying mapped file, although we cannot control when.</p><p><code>MAP_PRIVATE</code> means the changes are private and other processes will not see them. And also, they are not carried through to the underlying file.</p><p><code>MAP_ANON</code> means that there is not going to be a mapped file. It is useful for sub-processes communication with shared memory.</p><p>I've got confused about the <code>mmap-go</code> library implementation. It only provides the <code>mmap.ANON</code> flag, that we used in the above example. If you want your mapping to be private, you can set the <code>mmap.COPY</code> flag to the <code>prot</code> argument. Anyways, you can always use the flags provided by the <code>unix</code> package implementation.</p><h4 id="locking-and-flushing">Locking and flushing</h4><p>Two other nice methods, <code>Lock</code> and <code>Flush</code>, are provided by the API of <code>mmap-go</code>. The <code>Lock</code> method calls the <a href="https://man7.org/linux/man-pages/man2/mlock.2.html">mlock</a> system call that prevents the mapping to be paged out to disk. And the <code>Flush</code> method calls the <a href="https://man7.org/linux/man-pages/man2/msync.2.html">msync</a> system call that forces the data in memory to be written to disk. This is a good way to trying to have more control over how and when data is flushed to disk.</p><h3 id="wrapping-up">Wrapping up</h3><p>I felt kind of stupid of knowing about <code>mmap</code> after so long. I don't remember it being brought in my college class. For some reason, I felt amazed by it and its capabilities and decided to dig deeper. I like databases and I'm aiming to get a better grasp of them. This means that <code>mmap</code> cannot go unnoticed from my learning. For future posts, I'll try to bring about the benefits and drawbacks of using <code>mmap</code>, which projects use it, and what kind of problems it is suited for.</p><p>Even though the <code>mmap</code> can be used to solve that database problem we stated in the beginning, and many modern databases use it, <a href="https://twitter.com/andy_pavlo">Andy Pavlo</a> advocates against it and have three lecture on how to databases, that don't use <code>mmap</code>, manage data.</p><p>If you like this kind of content, follow me on <a href="https://twitter.com/brunocalza">twitter</a>. You may find more related stuff there.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://brunocalza.me/2021/01/10/discovering-and-exploring-mmap-using-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720731</guid>
            <pubDate>Sun, 10 Jan 2021 22:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Build a wall of testimonials with videos/tweets/text. Here is mine]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25720322">thread link</a>) | @damechen
<br/>
January 10, 2021 | https://testimonial.to/testimonial/all | <a href="https://web.archive.org/web/*/https://testimonial.to/testimonial/all">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://testimonial.to/testimonial/all</link>
            <guid isPermaLink="false">hacker-news-small-sites-25720322</guid>
            <pubDate>Sun, 10 Jan 2021 21:47:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Overview of Julia language [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25719454">thread link</a>) | @gurjeet
<br/>
January 10, 2021 | http://algorithmsbook.com/files/appendix-g.pdf | <a href="https://web.archive.org/web/*/http://algorithmsbook.com/files/appendix-g.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://algorithmsbook.com/files/appendix-g.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719454</guid>
            <pubDate>Sun, 10 Jan 2021 20:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cooking for Founders]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25719188">thread link</a>) | @tylertringas
<br/>
January 10, 2021 | https://tylertringas.com/cooking-for-founders/ | <a href="https://web.archive.org/web/*/https://tylertringas.com/cooking-for-founders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>With COVID-19 forcing many of us indoors and cooking more (yes, this post took a little longer to go live than I planned), there’s never been a better time to really learn how to cook. I grew up not learning much about how to cook and taught myself as an adult. Over the last 5-7 years I went from someone who could do the absolute bare minimum (boil pasta, cook chicken breast, etc) to genuinely quite a decent cook. I can easily whip up dinner for 4-6 friends without stressing, cook healthy dinners at home most nights of the week, run a barbecue for 12 people, and have a small quiver of fancy dishes to impress friends, family, and my wife from time to time. This post is mostly about what works for me, but I’m calling it Cooking For Founders because I think it will resonate with a lot of entrepreneurs who think like me.</p>
<p>The goal of this post is not to teach you how to cook but to provide fairly comprehensive, but also minimum viable, roadmap for going from a cooking noob to solid home chef.</p>
<h2>Why you should cook</h2>
<p>Until I was about 25 or so I really didn’t cook much. I lived in places like NYC and London where restaurants were always open and ubiquitous and especially in these cities, it’s a perfectly reasonable position to just not bother learning to cook well. But I want to make the case that even if you have world class restaurants and food delivery services on demand, you should learn to cook.</p>
<p><strong>Social: </strong>Home cooked meals are an awesome offer that people are very likely to take you up on and really appreciate. Cooking well is sexy and makes for an awesome date night. Dinner parties are fantastic well to meet new people and create a vibrant personal and professional network. Taking charge of a meal is a great way to bring your family together or impress your in-laws.</p>
<p><strong>Physical Health: </strong>Even if you aren’t bothering with any particular diet (low carb, paleo, etc), cooking at home is almost always going to be more nutritious than food from restaurants. Getting actually healthy food from restaurants/delivery is almost always expensive. Cooking at home is an affordable way to get great nutrition.</p>
<p><strong>Mental Health:&nbsp;</strong>This may be more specific to me, but I find cooking to be fantastic for my mental health. In my house I’m the one cooking about 90% of the time and I’m not into the mega meal prep strategies where you cook food for the whole week. So, most days, I’m cooking something fresh for dinner. The need to start cooking prep in time for a reasonable dinner puts a natural stopping point in my work day and then I get to switch to a very focused mono-tasking activity. This routine is, for me, a kind of meditation that separates the work day and let’s my brain process the events of the day.</p>
<h2>Meta-learning Tips for Learning to Cook</h2>
<p>Learning to cook is not exactly easy. There is an infinite amount of recipes, techniques, resources, diets, and on and on to consume. It can be overwhelming. Learning to cook is almost always laden with failures along the way. You’ll screw up some recipes, ruin some dishes, and get halfway through a complex recipe before realizing you’re missing some essential ingredient. Here are some lessons I’ve learned on how to learn.</p>
<p><strong>Find your YouTube &amp; TikTok muses</strong></p>
<p>There is an infinite amount of cooking content on the internet, but when you find a particular chef or channel that really speaks your language, subscribe and binge their entire backlog. Lots of channels out there will skip essential explanations, use overly exotic ingredients, or complex unnecessary techniques so when you find one that consistently speaks to you, lock it in. Some ones I like:</p>
<ul>
<li><a href="https://www.youtube.com/user/helenrennie">Helen Rennie (YouTube)</a></li>
<li><a href="https://www.youtube.com/user/foodwishes">Food Wishes (YouTube)</a></li>
<li><a href="https://www.youtube.com/user/SeriousEats">Serious Eats (YouTube)</a></li>
<li><a href="https://www.tiktok.com/@thatdudecancook?lang=en">@thatdudecancook (TikTok)</a></li>
<li><a href="https://www.tiktok.com/@sad_papi?lang=en">@sad_papi (TikTok)</a></li>
</ul>
<p><strong>Have a backup plan</strong></p>
<p>Learning to cook and feeding yourself can be two different things, especially when you are first starting out and failure rates are high. If you are going to try a new recipe for the first time on a busy week night that’s supposed to be your dinner that night (1) go for it! (2) have a frozen pizza or some other quick and easy back up plan ready in case you end up ruining the dish. It’s a really negative feedback loop to mess up a recipe and having to end up eating cereal for dinner, so have a backup plan.</p>
<p><strong>Read/watch the recipe several times well before cooking</strong></p>
<p>Read or watch your recipes <em>carefully,&nbsp;</em>several times, in preparation for trying a new recipe. It’s easy to miss, especially at first, that the recipe actually requires marinating over night, or needs buttermilk or some other ingredient you don’t typically have on hand. Don’t just plop open the recipe book at 7p and start with Step #1.</p>
<p><strong>Stick to a few core cookbooks</strong></p>
<p>Again, it’s easy to get overwhelmed by the millions of cookbooks out there. Like YouTube channels, I recommend finding a few comprehensive cookbooks that work for you and sticking to them for years until you get very confident with a wide variety of techniques. With cookbooks, Kindle will work but having the physical copy can also be really helpful (or honestly I usually get both). Here are some that I recommend:</p>
<ul>
<li><a href="https://amzn.to/3seCIbQ">How To Cook Everything, Mark Bittman</a></li>
<li><a href="https://amzn.to/3oyrCwn">Cooking For Geeks, Jeff Potter</a></li>
<li><a href="https://amzn.to/3sfvapE">Salt, Fat, Acid, Heat, Samin Nosrat</a></li>
<li><a href="https://amzn.to/38wzSre">The Four Hour Chef, Tim Ferriss</a></li>
</ul>
<h2>Essential Concepts</h2>
<p>The books and channels above all have great introductions to all of these concepts so I’m not going to try to actually cover them here, but I think it’s useful have a few simple concepts to check off as you read/watch through the first few.</p>
<p><strong>What heat does (chemistry)</strong></p>
<p>Make sure you pay attention to the sections on the basic chemistry of heat. The vast majority of cooking is just different ways applying heat to food and it’s critical to understand what heat is doing to different kinds of foods. For the most part heat is either (1) denaturing proteins or (2) producing a Maillard Reaction. Denaturing proteins is the slow gradual cooking process that turns eggs from runny to scrambled or steak from rare to well done. Different foods have different kinds of proteins which denature at different temperatures and in different ways. The Maillard Reaction is browning (mostly on on meats and vegetables) and happens at very high heat and low moisture environments. Read up on these carefully. Cooking for Geeks covers these the best in my opinion.</p>
<p><strong>Different kinds of heat transfer (physics)</strong></p>
<p>Similarly to understanding what heat does, it’s really important to have a basic grasp of the various methods of applying heat to food. Baking, broiling, roasting, sautéing, braising, searing, sous vide, boiling, and so on, are all just different methods for applying heat. Some, like baking, use convection where the air is heated up around the food, and others, like searing in a pan, use conduction where the heat is transferred directly surface to surface. A cast iron pan takes a very long time to heat up and stays hot for a long time, whereas the air in your oven can dissipate its heat quickly. Understanding these basic concepts will give you the architecture for understanding for why you should keep the oven door closed as much as possible, dry your meat before searing, and pre-heat your heavy pans for longer than your light ones.</p>
<p><strong>Keep it simple</strong></p>
<p>When you are first learning to cook I recommend avoiding complex recipes in favor of simple two or three-part meals where each component is cooked individually. The vast majority of our home-cooked meals involve cooking (a) a protein like fish or meat (b) a vegetable cooked simply, like roasted in olive oil and (c) a starch like rice, potatoes, simple pasta. This let’s you build a healthy meal with simple individual components, master the same techniques with repeat practice, and minimize the risk of blowing up the whole dish.</p>
<p><strong>Make it taste good</strong></p>
<p>This may seem obvious, but it’s important that the food you cook actually taste good. Home-cooked food is almost always healthier than restaurant food, so don’t try to learn to cook and cook the healthiest possible version of each dish. Most veggies taste better roasted in a generous amount of olive oil than they do steamed, so roast them! Baste your chicken in butter. Salt your food generously. Learning to cook by producing dishes that just aren’t that tasty is a very bad feedback loop, so do what you need to to make it taste good.</p>
<p><strong>Don’t cook everything evenly</strong></p>
<p>This is a little more specific but I feel like it needs to be specifically counter-programmed. For some dumb reason a lot people (including myself 10 years ago) got the notion that food needs to be cooked&nbsp;<em>evenly</em>. That it’s really important to constantly turn and shake and rotate your food so that it’s cooked the same all the around and through. This is a great way to make gross food. Stop touching and turning your food. Most dishes are better with a substantial amount of difference in how cooked different sides of the food are: steak with a crunchy sear and medium rare inside, roasted potatoes with a waxy crust and fluffy inside, carrots or asparagus charred on side are all much tastier and mostly produced by having uneven cooking.</p>
<p><strong>Baking is really hard</strong></p>
<p>Really. Baking is much harder and less forgiving than any other kind of cooking. If you’re just starting to get into cooking, don’t start with baking.</p>
<h2>Essential Gear</h2>
<p>Okay, obviously you can spend and absolute fortune and fill a kitchen with mountains of cooking gear. That’s part of the fun of getting into cooking, let’s be honest. But if all you’ve got is a crappy 10-piece Wal-mart cooking set you got as a wedding gift or a hodge podge you inherited from your roommates, and you need to build your kitchen from scratch, this is the minimum kit I think you need. <em>(Disclosure: most of these are Amazon affiliates links. Don’t click them if that’s a thing that will make you mad).</em></p>
<p><strong>Pots and Pans</strong></p>
<p>The essential workhorses of cooking. Different kinds of pots and pans provide really different value for money, so I’ll specifically recommend below which ones I think it makes sense to invest in something …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tylertringas.com/cooking-for-founders/">https://tylertringas.com/cooking-for-founders/</a></em></p>]]>
            </description>
            <link>https://tylertringas.com/cooking-for-founders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719188</guid>
            <pubDate>Sun, 10 Jan 2021 20:17:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vuejs rejects close to 75% of outside contributions]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25719116">thread link</a>) | @gieksosz
<br/>
January 10, 2021 | https://merge-chance.info/target?repo=vuejs/vue | <a href="https://web.archive.org/web/*/https://merge-chance.info/target?repo=vuejs/vue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    
    <p><a></a>
        <span> of the PRs made by outsiders (not owners/members) get merged.</span>
    </p>
    
    
    <p><a></a>
        <i> * Based on most recent <strong> 272 </strong> outsiders' PRs </i>
    </p>
    <p><a></a>
        <i> * PRs open but not merged within 90 days are also treated as rejected </i>
    </p>
    
    
    <p><a></a>
        <span>
            Copy Markdown below to your README.md to get a Merge-Chance badge
        </span>
    </p>
<div>
    <pre>        <code>
            ![Custom badge](https://img.shields.io/endpoint?url=https%3A%2F%2Fmerge-chance.info%2Fbadge%3Frepo%3Dvuejs/vue)
        </code>
    </pre>
</div>
<p><a></a>
    <span> Like this one</span>
    <img alt="Custom badge" src="https://img.shields.io/endpoint?url=https%3A%2F%2Fmerge-chance.info%2Fbadge%3Frepo%3Dvuejs/vue">
</p>
<br>

<br>
<hr>




</div>]]>
            </description>
            <link>https://merge-chance.info/target?repo=vuejs/vue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25719116</guid>
            <pubDate>Sun, 10 Jan 2021 20:10:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The M1 MacBook Air is the best computer I've ever owned]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 318 (<a href="https://news.ycombinator.com/item?id=25717727">thread link</a>) | @bouk
<br/>
January 10, 2021 | https://bou.ke/blog/macbouk-air/ | <a href="https://web.archive.org/web/*/https://bou.ke/blog/macbouk-air/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
  
  <p><span>Jan 2021</span></p>
  <p>I started a new job recently so I had the opportunity to get one of the new M1 MacBooks, I decided to go with the Air. The reviews have been very positive and I’m here to tell you: it is indeed an amazing device. The performance feels a lot better than my MacBook Pro 16”, which is only a year old and about 3x the price.</p>

<p>When I got the Mac I set out with the goal of avoiding Intel builds of software as much as possible and using native whenever possible unless it’s absolutely impossible.</p>

<h2 id="nix">Nix</h2>

<p>I have my <a href="https://github.com/bouk/b" target="_blank">whole system configuration</a> stored in <a href="https://bou.ke/blog/nix/">Nix</a>, which was the thing that I least expected to work and arm64 support is still a <a href="https://github.com/NixOS/nixpkgs/issues/95903" target="_blank">work in progress</a>. I could install the <code>x86_64</code> build of Nix and run it under Rosetta but wanted to avoid that, so I went back to my old pal;</p>

<h2 id="homebrew">Homebrew</h2>

<p>This was one of the first things I installed and got working, when I did it I had to install it into <code>/opt/homebrew</code> manually and install everything with the <code>--source</code> flag but… everything mostly worked? Lots of props to the Homebrew team for getting everything running so quickly, with some amazing <a href="https://github.com/Homebrew/brew/issues/7857" target="_blank">open-source project management</a> the community worked together very quickly to support most of the software that Homebrew offers. There’s still some software that doesn’t work—notably neovim. But I’m sure that will be fixed soon.</p>

<p>The installer now installs into <code>/opt/homebrew</code> by default and there’s prebuilt bottles of most packages, so the Homebrew experience is great.</p>

<h2 id="go">Go</h2>

<p>A lot of my work involves Go, and I depend on a lot of tools written in Go. I was happy to see that the <a href="https://blog.golang.org/ports" target="_blank">Go team was on top of it</a> and released the 1.16 beta quite quickly, which is what is installed right now when you do <code>brew install go</code>. I’ve had no issues with it and am enjoying some of the new features like <a href="https://github.com/golang/go/issues/41191" target="_blank">file embedding</a>. GoLand was also <a href="https://blog.jetbrains.com/go/2020/12/30/goland-2020-3-1-is-out/" target="_blank">updated</a> to support M1 pretty quickly.</p>

<h2 id="terraform">Terraform</h2>

<p>Terraform I had the most issues with since using it depends on a bunch of plugins, which are generally only available for x86_64. This won’t change until Go 1.16 has been released. So here I had to resort to building for x86_64, which is easy to do:</p>

<div><div><pre><code>curl -L 'https://github.com/hashicorp/terraform/archive/v0.14.4.tar.gz' | tar -xzf-
cd terraform-0.14.4/
GOARCH=amd64 go build -o ~/bin/terraform
</code></pre></div></div>

<p>And now Terraform will just use plugin built for Intel. I assume that most Terraform plugins will support arm64 very quickly after Go 1.16 is out.</p>

<h2 id="rust-and-universal-binaries">Rust and Universal Binaries</h2>

<p>I use <a href="https://github.com/alacritty/alacritty" target="_blank">Alacritty</a> as my terminal. It supported <code>arm64</code> pretty quickly but the current build for it doesn’t include it, so I <a href="https://github.com/alacritty/alacritty/pull/4683" target="_blank">made a PR</a> that will build a universal binary. Creating a universal binary for Rust is quite easy:</p>

<div><div><pre><code>rustup target add x86_64-apple-darwin aarch64-apple-darwin
cargo build <span>--release</span> <span>--target</span><span>=</span>x86_64-apple-darwin
cargo build <span>--release</span> <span>--target</span><span>=</span>aarch64-apple-darwin
lipo target/<span>{</span>x86_64,aarch64<span>}</span><span>-apple-darwin</span>/release/alacritty <span>-create</span> <span>-output</span> alacritty
</code></pre></div></div>

<p>Running <code>file alacritty</code> will now show you something like:</p>

<div><div><pre><code>alacritty: Mach-O universal binary with 2 architectures: [x86_64:Mach-O 64-bit executable x86_64] [arm64]
alacritty (for architecture x86_64):    Mach-O 64-bit executable x86_64
alacritty (for architecture arm64):     Mach-O 64-bit executable arm64
</code></pre></div></div>

<p>Now you can run it in either <code>x86_64</code> mode with <code>arch -x86_64 alacritty</code> or natively with <code>arch -arm64 alacritty</code> and the OS will automatically select the right binary.</p>

<p>Building a universal binary for a Go application is similarly easy:</p>

<div><div><pre><code>GOARCH=amd64 go build -o app_amd64 main.go
GOARCH=arm64 go build -o app_arm64 main.go
lipo app_{amd64,arm64} -create -output app
</code></pre></div></div>

<h2 id="windows-and-games">Windows and Games</h2>

<p>There’s a couple of <a href="https://en.wikipedia.org/wiki/Age_of_Mythology" target="_blank">games</a> I’ve been playing for a long time that I still need on any computer I get, but they’re 32-bit Windows-only. This was something that was surprisingly easy to get working:</p>

<ol>
  <li>Install the <a href="https://www.parallels.com/blogs/parallels-desktop-apple-silicon-mac/" target="_blank">Parallels Technical Preview</a></li>
  <li>Sign up for Windows Insider and download the <a href="https://www.microsoft.com/en-us/software-download/windowsinsiderpreviewARM64" target="_blank">Windows 10 on ARM Insider Preview</a></li>
  <li>Install it into Parallels</li>
  <li>Done</li>
</ol>

<p>Now you can download Steam and basically install anything and it will probably work. Microsoft really did some amazing magic in getting both 32-bit and 64-bit x86 programs running on <code>arm64</code>.</p>

<p><img src="https://bou.ke/images/windows-solitaire.png" alt="" loading="lazy"></p><h2 id="conclusion">Conclusion</h2>

<p>Somehow Apple has created the best PC in every category at once. It is even the best Windows PC, despite the multiple layers of emulation that are happening. The battery life is incredible, I haven’t experienced any slowdowns, I don’t hear any fans spin up (because there are none). It’s hard not to be excited about this.</p>

<p>If Apple chose to go down this path, they could dominate the server space if they took their magic chips, put it in a <a href="https://en.wikipedia.org/wiki/Rack_unit" target="_blank">rack unit</a> and made it easy to install Linux onto it. Intel is completely screwed unless they come up with something better, fast.</p>

  <hr>
  <p>You should follow me on <a href="https://twitter.com/BvdBijl">Twitter</a>!</p>
</div>
</div></div>]]>
            </description>
            <link>https://bou.ke/blog/macbouk-air/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717727</guid>
            <pubDate>Sun, 10 Jan 2021 18:24:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ranked Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25717646">thread link</a>) | @Elzear
<br/>
January 10, 2021 | https://www.elzear.de/posts/2021-01-10-polls | <a href="https://web.archive.org/web/*/https://www.elzear.de/posts/2021-01-10-polls">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The <a href="https://ncase.me/ballot/">spoiler effect</a> in elections frustrates me.
I wish my preferred candidates would not <em>“<!-- -->steal<!-- -->”</em> votes from each other.
And I wish I would never have to lie about my preferences for my vote to count.</p><p>Elections are unfair.<br><span>🗳️ 😠 📊 <span>😤</span></span><br>How to prevent dishonesty as a winning strategy?</p><p>Let's discover several election systems which
better reflect the voters' opinions.
This article partially answers the
question: <strong>how to fairly gather the preferences
of a group of voters to select a winner?</strong></p><p>No information from this post is new.
Most of the content is heavily
inspired from the following sources:</p><ul><li>the <a href="https://en.wikipedia.org/wiki/Electoral_system">Wikipedia article on electoral systems</a>,</li><li>the <a href="http://dss.in.tum.de/files/brandt-research/voting_slides.pdf">presentation of Practical Voting Rules</a>
and other online documents from <a href="https://dss.in.tum.de/staff/brandt.html">Dr Felix Brandt</a>,</li><li>YouTube videos: <a href="http://www.cgpgrey.com/politics-in-the-animal-kingdom/">Politics In The Animal Kingdom</a> from CGP Grey and
<a href="https://www.youtube.com/playlist?list=PLtzmb84AoqRSmv5o-eFNb3i9z64IuOjdX">La démocratie sous l'angle de la théorie des jeux</a>
(yes, it is in French) by Science4All,</li></ul><p>This blog post is a simple introduction to ranked voting systems and a presentation of a few voting methods:</p><p>Discover<br>ranked 🥇🥈🥉<br>election systems</p><h2><p><a href="#the-problem-space"><span role="img" aria-label="link"></span></a>The problem space</p></h2><figure><div><p><img alt="xkcd voting referendum (https://xkcd.com/2225/)" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><figcaption><a href="https://xkcd.com/2225/">xkcd: Voting Referendum</a></figcaption></figure><p>In real-world elections, we are generally unable to express our entire preference order. Most of the time, we are
only able to select one single candidate with our ballot. This leads us to lie about our preferences,
for example when a vote would be <em>“wasted”</em> on an underdog (this is the spoiler effect).
Elections could be fairer if voters would be able to indicate their full preference order!
It could then be taken into account and better reflect people's opinions.
Also, entering all preferences in one ballot allows us to compute elections of multiple rounds at once,
without having to force the voters to cast multiple ballots for the same election.</p><p>There are 2 main ways to record voters' opinion:</p><ul><li><p><strong>ranked voting</strong>: each voter can submit an order of preference between the candidates</p></li><li><p><strong>cardinal voting</strong>: each voter grades the candidates on a scale. For example rating all candidates
between 0 and 5.</p></li></ul><figure>Number the boxes in order of your choice<ul><li><span><span>4</span></span> <!-- -->Hayden Kelly</li><li><span><span>&nbsp;</span></span> <!-- -->Lesley Poole</li><li><span><span>4</span></span> <!-- -->Marley Bennett</li><li><span><span>3</span></span> <!-- -->Lesley Mills</li><li><span><span>&nbsp;</span></span> <!-- -->Erin Fraser</li><li><span><span>1</span></span> <!-- -->Brett Nielsen</li><li><span><span>4</span></span> <!-- -->Noel Curry</li><li><span><span>2</span></span> <!-- -->Vic Levy</li><li><span><span>&nbsp;</span></span> <!-- -->Tanner Fleming</li><li><span><span>2</span></span> <!-- -->Glen Hoffman</li></ul><figcaption>Example of a ranked ballot. The preferred candidate of this voter is Brett Nielsen</figcaption></figure><p>Even though cardinal voting has many supporters,
I dislike it for enabling voters to vote tactically: one can benefit from lying.
For example, by only giving extreme grades, a voter can have more impact than
others. Therefore this article will only focus on <strong>ranked voting</strong>.</p><ul><li><p>Voters can rank alternatives in a sequence, possibly with ties. Ballots contain ranked (not rated!) candidates.
The ballots accept ties: if voters are indifferent between two candidates, they can put them in
the same rank in their ballots.</p></li><li><p>The goal of the vote is to compute a hierarchy among the alternatives along with a winner.
This means the vote can select options like a restaurant for the evening, a president<!-- -->…<!-- -->
Proportional representation, like electing a parliament, is not a subject of this article.</p></li><li><p>For the sake of simplicity, ties and tie-breakers are ignored in this article. The
examples were chosen not to result in tied situations.</p></li></ul><h2><p><a href="#5-simple-voting-systems"><span role="img" aria-label="link"></span></a>5 simple voting systems</p></h2><p>Let<!-- -->'<!-- -->s consider an election in the animal world
(copying CGP Grey's videos) with a
particular voting scenario invented by Michel Balinski,
a mathematician, economist and political scientist.</p><p>This is a virtual election with <strong>100 voters</strong> and <strong>5
candidates</strong>: <span><span><span>🐸</span> <!-- -->Frog</span></span>, <span><span><span>🐷</span> <!-- -->Pig</span></span>, <span><span><span>🦁</span> <!-- -->Lion</span></span>, <span><span><span>🐻</span> <!-- -->Bear</span></span> and <span><span><span>🐭</span> <!-- -->Mouse</span></span></p><p>The voters can be gathered in 6 groups, each having the same preference order.
The preferences of all the voters are represented in this array
(which must be read as <em>“33 voters (first column) rank Frog first, then Pig,
then Lion, then Bear and finally Mouse is their least favourite;
16 voters (second column) rank Pig first, then Bear, then Lion; etc.”</em>):</p><p>We can compare some voting systems using this preference profile as an input.</p><h3><p><a href="#first-past-the-post"><span role="img" aria-label="link"></span></a>First past the post</p></h3><p>Probably the most basic voting method. Only the first choice of each voter matters
and we simply count the votes.
It is used in elections in many countries (the USA, the UK, Canada...).</p><p>With the voting system <strong>first past the post</strong>: Frog gets
33 votes, which is better than any other candidates. <span><span><span>🐸</span> <!-- -->Frog</span></span> wins.</p><p>This result can feel unfair because voters'
preferences are hardly taken into account. Frog won because it is ranked first by the biggest
group (33%), but it is also ranked last by the majority of voters (56%)!
That 56% (who ranked Frog last) could potentially come together before the start of the vote and agree on their
preferred candidate — which would be Mouse — to prevent Frog from being elected.</p><h3><p><a href="#contingent-vote-two-round-run-off"><span role="img" aria-label="link"></span></a>Contingent vote / Two-round run-off</p></h3><p>With these methods,
if no candidate receives 50% of the votes in the first round,
a second round of voting is held with only the top two candidates.</p><p>The Contingent vote lets voters cast their preference order at once and the winner can be computed
without needing another vote.</p><p>In two-round run-off elections, voters are only asked about their preferred candidate. They
have to vote again in the second round.
47 countries (Finland, France, Russia, Turkey...) use this system for their presidential elections.</p><p>A candidate
ranked last by more than 50%
of the voters cannot be elected by these methods.</p><p>With the voting system <strong>two-round run-off</strong>:
Frog and Mouse compete in the second round
and <span><span><span>🐭</span> <!-- -->Mouse</span></span> wins with 64% of the votes.</p><p>But Mouse is still the second most disliked candidate:
if we remove the most disliked candidate (Frog),
we are left with 52% of the voters ranking Mouse last!
Those voters can understandably be unsatisfied and ask
for a different system to be used.</p><h3><p><a href="#instant-run-off"><span role="img" aria-label="link"></span></a>Instant Run-off</p></h3><p>Counting only the first choices of the voters,
the candidate with the fewest votes is eliminated.
The election repeats until there is a winner.
It is used for example to elect members of the Australian House of Representatives,
the president of India and the president of Ireland.</p><p>Lion is eliminated first, then Pig, then Mouse,
then Frog. The final winner of the instant run-off vote is <span><span><span>🐻</span> <!-- -->Bear</span></span>.</p><p>Knowing the outcome of that vote, some groups could have
changed their ballots to prevent Bear's election. For
example, the 33%-group could decide to rank Pig first, and provoke
the election of Pig instead of Bear!</p><p>Coombs' rule is a similar voting method where the candidate ranked last by most voters gets eliminated
each round.
This rule would elect Pig.</p><h3></h3><p>For each voter, every candidate is given points
corresponding to their rank in the voter's preferences.
In our case: the first position gets 5 points, the second position gets
4 points<!-- -->…<!-- -->
It is currently used to elect members of the Parliament of Nauru
and two ethnic minority members of the National Assembly of Slovenia.</p><p>With <strong>Borda<!-- -->'<!-- -->s rule</strong>: <span><span><span>🐷</span> <!-- -->Pig</span></span> wins
with 347 points, and Lion is second with 344 points.</p><p>If the voters knew that the race would be so close between Pig and Lion,
they probably would have tried to influence the election by ranking them
as the first or the last in their ballots. Since 51% of the voters prefer Lion to Pig,
they can change the outcome of the election.
This kind of phenomenon often leads political systems to be bipartisan.</p><h3><p><a href="#copelands-method"><span role="img" aria-label="link"></span></a>Copeland's method</p></h3><p>Finally, someone found the perfect voting system for this election!
Copeland's method considers all duels between the candidates and
counts the number of victories, similarly to a tournament.</p><p>(Click on the array cells to show the duels)</p><p>Wins count:<br><span><span><span>🐸</span> Frog: 0</span></span> <span><span><span>🐷</span> Pig: 3</span></span> <span><span><span>🦁</span> Lion: 4</span></span> <span><span><span>🐻</span> Bear: 2</span></span> <span><span><span>🐭</span> Mouse: 1</span></span></p><p>Using <strong>Copeland<!-- -->'<!-- -->s method</strong>: <span><span><span>🦁</span> <!-- -->Lion</span></span> wins.
In fact, Lion wins all the duels, this is called a <em><strong>Condorcet winner</strong></em>.
Interestingly, this candidate was never selected as a winner
by the other real-world voting methods even though it wins all duels!
The voters of this election are finally happy thanks to Copeland<!-- -->'<!-- -->s method:
the winner of all duels wins the election, everything is perfectly logical.</p><p><strong>Did you notice? The 5 voting systems gave 5 different winners while the electors
did not change their preferences! <span>🤯</span></strong></p><h2><p><a href="#condorcet"><span role="img" aria-label="link"></span></a>Just pick the candidate winning all duels?! — Condorcet winners and Condorcet paradox</p></h2><h3><p><a href="#preference-graphs"><span role="img" aria-label="link"></span></a>Preferences graph helps to visualize duels</p></h3><p>To visualize the duels, it is helpful to simplify the representation of the input by
using a graph instead of an array of preferences.</p><p>The preference of the first group of voters (33%: Frog → Pig → Lion → Bear → Mouse) can be represented like this:</p><p>Adding the preferences of all the voters, we get the full graph:</p><p>Did I say <em>simplify</em>? 😬<br>
We can still combine opposed edges, which makes it way more readable:</p><p><span><span><span>🦁</span> <!-- -->Lion</span></span>, with all edges going outwards, is the <strong>Condorcet winner</strong> (winner of all duels).</p><h3><p><a href="#condorcet-paradox"><span role="img" aria-label="link"></span></a>Condorcet paradox</p></h3><p>After seeing Copeland<!-- -->'<!-- -->s method, you may think
<em>“Just pick the candidate that wins all duels!”</em>.
It would be great if this was always possible, but unfortunately,
there are situations where no candidate wins all duels and
a cycle appears.</p><figure><div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"></p></div><p>“<strong>Transitive</strong> preference order” means: if I prefer <em>a</em> to <em>b</em> and <em>b</em> to <em>c</em>, then I also prefer <em>a</em> to <em>c</em>.</p></figure><p>Using a ranked voting method, each voter submits a ballot with
a transitive preference of the candidates.
Given that voters submit a clear hierarchical order,
why can<!-- -->'<!-- -->t voting systems simply agree on a winner?
Why is it so hard to aggregate voters<!-- -->'<!-- --> preference orders?
Can<!-- -->'<!-- -->t Copeland's method always be used?</p><p>With 3 candidates or more, problems may start to arise since
some collective preferences can be cyclic. Here is an example
of a vote for the best food. 15 voters
are deciding between the following candidates: <span><span><span>🌯</span> <!-- -->Burrito</span></span>, <span><span><span>🍔</span> <!-- -->Burger</span></span>, <span><span><span>🍕</span> <!-- -->Pizza</span></span>, <span><span><span>🍪</span> <!-- -->Cookie</span></span>.</p><p>This preference profile can also be represented in the below form, as we
saw previously:</p><p>Or as an array of duels:</p><p>Or as a graph of duels:</p><p>It shows that no alternative wins all pairwise duels:
There is a cycle between <span><span><span>🍔</span> <!-- -->Burger</span></span>, <span><span><span>🍕</span> <!-- -->Pizza</span></span> and <span><span><span>🍪</span> <!-- -->Cookie</span></span>,
this vote has no Condorcet winner.
In this kind of scenario, it is not obvious who should win.</p><h2><p><a href="#4-condorcet-voting-systems"><span role="img" aria-label="link"></span></a>4 Condorcet voting systems</p></h2><p>The <strong>Copeland</strong> voting system, which we saw above, validates the Condorcet criteria.
Some more complex voting systems can  validate the Condorcet criterion
and also score better on …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elzear.de/posts/2021-01-10-polls">https://www.elzear.de/posts/2021-01-10-polls</a></em></p>]]>
            </description>
            <link>https://www.elzear.de/posts/2021-01-10-polls</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717646</guid>
            <pubDate>Sun, 10 Jan 2021 18:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research-Based Methods for Learning Japanese]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25717393">thread link</a>) | @sova
<br/>
January 10, 2021 | https://japanesecomplete.com/articles/?p=1282 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/articles/?p=1282">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h3><strong>Conclusions</strong> from the Academic Research</h3>



<p>We looked at research papers from the last 30 years to evaluate our set of teaching strategies undertaken in our Japanese language learning application called <a href="https://japanesecomplete.com/">Japanese Complete</a>.  We found that the scholarly and academic studies referred to confirm:</p>



<ol><li><strong>Kanji [logographs of mainland Asian origin] are categorized as the main impediment in acquisition of the Japanese language</strong> and anything to ease their acquisition from rote-memorization will help learners greatly.</li><li><strong>Computer aided learning of Japanese is superior to textbook-based</strong> learning <strong>when</strong> <strong>paired with timely and useful feedback</strong> for the learner, with politeness language, grammar, kanji, and more. [4, 5, 7, 12, 17]</li><li><strong>Kanji are processed by different parts of the brain compared to English letters and Hiragana mora,</strong> suggesting that placing special emphasis on learning Kanji as glyphs or <em>graphics with associated meanings <strong>first</strong></em> establishes a firm foundation upon which to then learn readings and pronunciations. [2, 6]</li><li>Kanji have <em>logographic</em> as well as <em>phonographic</em> value; <strong>cultural, etymological, and mnemonic strategies are not only more effective than rote-memorization strategies for learning, they also remove a lot of anxiety and perceived inscrutability of kanji, making kanji learning fun and intriguing</strong> instead of a chore.  The main techniques presented in these papers include component-analysis of kanji [what we call subkanji learning], and pairing kanji with graphical and mnemonic aides such as stories or imaginal scenes. [6, 7, 10, 11, 14, 15]</li><li>It is very likely that native speakers of languages featuring kanji create <em>some sort</em> of meaning-word associated with each kanji, whether able to give voice to it or not (“unconscious knowledge”), suggesting strongly that <strong>by teaching kanji meaning-words first one is creating a very helpful and direct shortcut to their successful assimilation.</strong> [6, 9, 10]</li><li>One paper suggests the use of an “orthographic gradient” where terms are first shown as color-coded Hiragana, and later instances are shown as color-coded kanji using the same coloration, allowing learners to make an implied association of equality.  <strong>This idea of “orthographic gradient” confirms the efficacy of our innovative approach “Kanji in English Context” where we t取ke kanji and pl置ce them in an 英ngl語sh c文nt脈xt [take, place, English, context] to expedite acquisition</strong> and increase familiarity with the plurality of [English] words kanji can represent. [11, 16]</li><li><strong>Acquisition of Japanese grammar and sequence continues to be the most challenging part of learning the language for 1st, 2nd, and 3rd year students,</strong> suggesting that the focus for the first several semesters of learning ought be grammar-focused.  Nouns are acquired at a linear rate no matter the level of grammar competency, and thus it would suggest that the learning of nouns can actually be greatly delayed without any negative impact on comprehension; rather, focus on grammar first would result in greatly improved comprehension when nouns are later added to one’s cogent grammar understanding. </li><li><strong>Very Accurate Japanese Pitch Accent</strong> can be trained and learned swiftly with the right learning materials (showing pitch contours on screen and having learners listen and repeat). [17]</li><li><strong>One’s native language shapes how one acquires second+ languages.</strong> [3, 13]</li></ol>



<figure><img src="http://jpc0.b-cdn.net/img/lake-onami.jpg" alt=""><figcaption>Lake Onami</figcaption></figure>



<h3><br><strong>Scholarly and Academic Works Cited</strong></h3>



<hr>



<p>[1] <em><strong>Phonological processing of Japanese Kanji and Chinese characters in bilingual Japanese : An fMRI study (2017)</strong></em></p>



<p><a href="https://ieeexplore.ieee.org/document/8015970" target="_blank" rel="noreferrer noopener">https://ieeexplore.ieee.org/document/8015970</a></p>



<p>“The result showed that our bilingual Japanese subjects have large overlaps in the neural substrates for phonological processing of both native and second language.  Our finding supports the idea that the neural systems of second language reading are shaped by native language.” </p>



<hr>



<p>[2] <em><strong>Japanese and English sentence reading comprehension and writing systems: An fMRI study of first and second language effects on brain activation. (2009)</strong></em></p>



<p><a href="https://pubmed.ncbi.nlm.nih.gov/19946611/" target="_blank" rel="noreferrer noopener">https://pubmed.ncbi.nlm.nih.gov/19946611/</a></p>



<p>Parts of the brain that are engaged when native Japanese readers process English, Hiragana, and Kanji:</p>



<figure><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/instance/2782536/bin/nihms120575f4.jpg" alt=""><figcaption>Activation regions for native Japanese speakers decoding written language.</figcaption></figure>



<p>“Functional magnetic resonance imaging (fMRI) was used to compare brain activation from Japanese readers reading hiragana (syllabic) and kanji (logographic) sentences, and English as a second language (L2). Kanji showed more activation than hiragana in right-hemisphere occipito-temporal lobe areas associated with visuospatial processing; hiragana, in turn, showed more activation than kanji in areas of the brain associated with phonological processing. L1 results underscore the difference in visuospatial and phonological processing demands between the systems. Reading in English as compared to either of the Japanese systems showed more activation in inferior frontal gyrus, medial frontal gyrus, and angular gyrus. The additional activation in English in these areas may have been associated with an increased cognitive demand for phonological processing and verbal working memory.”</p>



<hr>



<p>[3] <em><strong>Comparative Spatial Semantics and Language Acquisition:Evidence from Danish, English, and Japanese (1994)</strong></em></p>



<p><a href="https://www.researchgate.net/profile/Chris-Sinha/publication/249234936_Comparative_Spatial_Semantics_and_Language_Acquisition_Evidence_from_Danish_English_and_Japanese/links/57da79a508ae72d72ea2b8b8/Comparative-Spatial-Semantics-and-Language-Acquisition-Evidence-from-Danish-English-and-Japanese.pdf" target="_blank" rel="noreferrer noopener">https://www.researchgate.net/profile/Chris-Sinha/publication/249234936_Comparative_Spatial_Semantics_and_Language_Acquisition_Evidence_from_Danish_English_and_Japanese/links/57da79a508ae72d72ea2b8b8/Comparative-Spatial-Semantics-and-Language-Acquisition-Evidence-from-Danish-English-and-Japanese.pdf</a></p>



<p>“Perhaps the most important finding is that in all three languages that we have analysed acquisition appears to take place in two phases, during the first of which the child gradually acquires six to eight simple forms corresponding to ‘basic’ spatial meanings encoded in the target language.”</p>



<p>“In the second phase of acquisition, the child’s productive repertoire and the frequency of its use increase in a way that is reminiscent of (though perhaps less dramatic than) the ‘vocabulary explosion’ in nominal usage. The extension of the repertoire takes different courses, depending on the structure of the target language. In all languages it can be expected that the repertoire within the form class which is dominant in expressing spatial relational meaning will continue to expand, and that this will remain the most frequently employed vehicle for the child’s expression of spatial relational meaning throughout and perhaps beyond the third year of life.”</p>



<p>“In languages, such as Japanese, in which spatial relational meaning is overtly distributed over different form classes, the second phase will involve both an increase in the range of types controlled in the dominant form class (in this case,verbs), and the extension of the acquisition process to the other form classes (in this case, particles and nouns). Both the slow pace of acquisition in the non-dominant forms classes, and the fact that the meanings initially expressed using nouns are cognate with those already expressed using verbs, suggest that, in Japanese too, the learning process continues to be governed in the second phase by a conservative strategy. It can perhaps be seen as follows: the child employs the already acquired meanings as clues for the establishment of new centres in new form classes for the repetition with respect to these new form classes of the radial strategy already successfully employed with respect to the dominant form class.”</p>



<hr>



<p>[4] <strong><em>Supporting the acquisition of Japanese polite expressions in context-aware ubiquitous learning</em> <em>(2010)</em></strong></p>



<p><a href="http://www.academia.edu/download/50315553/ijmlo.2010.03263720161114-19604-1c5exmp.pdf">http://www.academia.edu/download/50315553/ijmlo.2010.03263720161114-19604-1c5exmp.pdf</a></p>



<p>“To support the foreigners learning JPE [Japanese Politeness Expressions], a PDA-based context-aware language learning support environment was proposed. This environment supports the learners to learn JPE according to the different situations in the real world. There are two version of the prototype system for this environment. In this paper, design, implementation and evaluation of JAPELAS2 are presented. From the experiment, we found the system provides the correct polite-expression based on hyponymy, social distance and situation through the identification of the target user and the location. The experiment showed that the system was quite useful and using this system made understanding the appropriate level of politeness easy by changing roles and situations.”</p>



<figure><img loading="lazy" width="645" height="641" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/Screen-Shot-2021-01-06-at-4.13.32-PM.png" alt=""></figure>



<hr>



<p>[5] <em><strong>COMPUTER VS. WORKBOOK INSTRUCTION IN SECOND LANGUAGE ACQUISITION (1996)</strong></em></p>



<p><a href="https://journals.equinoxpub.com/CALICO/article/viewFile/23393/19398">https://journals.equinoxpub.com/CALICO/article/viewFile/23393/19398</a></p>



<p>“The results of the study show that given the same grammar notes and exercises, <strong>ongoing intelligent computer feedback is more effective than simple workbook answer sheets for developing learners’ grammatical skill in producing Japanese particles and sentences.</strong> A significant difference between Nihongo-CALI and the workbook instruction was observed in the production tests but not in the comprehension tests. This is consistent with Flynn’s hypothesis that grammatical competence is less critical in comprehension than in production. As suggested by Pederson and Dunkel, the present study also confirms that the use of a medium (i.e., computer) alone does not bring better effects; rather the quality of the messages produced by the medium affects the result. This is based on the fact that the intelligent version of Nihongo-CALI is significantly more effective than the workbook instruction”</p>



<div><figure><img loading="lazy" width="411" height="333" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/Screen-Shot-2021-01-06-at-4.19.44-PM.png" alt=""></figure></div>



<hr>



<p>[6] <em><strong>L2 learners’ attitudes toward, and use of, mnemonic strategies when learning Japanese Kanji (2013)</strong></em></p>



<p><a href="https://www.researchgate.net/publication/259551232_L2_learners%27_attitudes_toward_and_use_of_mnemonic_strategies_when_learning_Japanese_Kanji">https://www.researchgate.net/publication/259551232_L2_learners%27_attitudes_toward_and_use_of_mnemonic_strategies_when_learning_Japanese_Kanji</a></p>



<p>“This study investigated kanji learning (the memorization of Japanese written characters) of university students of Japanese, in order to evaluate students’ use of mnemonic strategies. The study applied …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japanesecomplete.com/articles/?p=1282">https://japanesecomplete.com/articles/?p=1282</a></em></p>]]>
            </description>
            <link>https://japanesecomplete.com/articles/?p=1282</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717393</guid>
            <pubDate>Sun, 10 Jan 2021 18:01:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Cargo Cult (2017)]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25717075">thread link</a>) | @dredmorbius
<br/>
January 10, 2021 | https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/ | <a href="https://web.archive.org/web/*/https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					<p>Trump administration lies constantly but doesn’t even attempt to make it seem like they aren’t lying.</p>
<p>After the collapse of the Soviet Union, this kind of cynicism was referred to as the “reverse cargo cult” effect.</p>
<p>In a regular cargo cult, you have people who see an airstrip, and the cargo drops, so they build one out of straw, hoping for the same outcome. They don’t know the difference between a straw airstrip and a real one, they just want the cargo.</p>
<p>In a reverse cargo cult, you have people who see an airstrip, and the cargo drops, so they build one out of straw. But there’s a twist:</p>
<p>When they build the straw airstrip, it <em>isn’t</em> because they are hoping for the same outcome. They know the difference, and know that because their airstrip is made of straw, it certainly won’t yield any cargo, but it serves another purpose. They don’t lie to the rubes and tell them that an airstrip made of straw will bring them cargo. That’s an easy lie to dismantle. Instead, what they do is make it clear that the airstrip is made of straw, and doesn’t work, but then tell you that the other guy’s airstrip doesn’t work either. They tell you that <strong>no airstrips yield cargo</strong>. The whole <em>idea of cargo</em> is a lie, and those fools, with their fancy airstrip made out of wood, concrete, and metal is just as wasteful and silly as one made of straw.</p>
<p>1980s Soviets knew that their government was lying to them about the strength and power of their society, the Communist Party couldn’t hide all of the dysfunctions people saw on a daily basis. This didn’t stop the Soviet leadership from lying. Instead, they just accused the West of being equally deceptive. <em>“Sure, things might be bad here, but they are just as bad in America, and in America people are actually foolish enough to believe in the lie! Not like you, clever people. You get it. You know it is a lie.”</em></p>
<p>Trump’s supporters don’t care about being lied to. You can point out the lies until you’re blue in the face, but it makes no difference to them. Why? Because it is just a game to them. The media lies, bloggers lie, politicians lie, it’s just all a bunch of lies. Facts don’t matter because those are lies also. Those trolls on Twitter, 4Chan, T_D, etc. are just having a good laugh. They are congratulating each other for being so smart. We are fools for still believing in anything. There is no cargo, and probably never was.</p>
<p>Source: <a href="https://np.reddit.com/r/politics/comments/5rru7g/kellyanne_conway_made_up_a_fake_terrorist_attack/dd9vxo2/">https://np.reddit.com/r/politics/comments/5rru7g/kellyanne_conway_made_up_a_fake_terrorist_attack/dd9vxo2/</a></p>
					
					<p>
						Filed under: <a href="https://hanshowe.org/category/1100733/" rel="category tag">#!!#</a> |					</p>

				</div></div>]]>
            </description>
            <link>https://hanshowe.org/2017/02/04/trump-and-the-reverse-cargo-cult/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717075</guid>
            <pubDate>Sun, 10 Jan 2021 17:36:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Apple M1, ARM/x86 Linux Virtualization, and Boinc]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25717019">thread link</a>) | @jseliger
<br/>
January 10, 2021 | https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/ | <a href="https://web.archive.org/web/*/https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>About <a href="https://www.sevarg.net/2020/06/21/apple-and-arm-transition/">six months ago</a>, I speculated a bit on what Apple might do with their upcoming (rumored at the time) ARM transition.  Apple did it, has shipped hardware, and I’ve had a chance to play with for a while now.  I’ve also, as is usual for me, gone down some weird paths - like ARM Linux virtualization, x86 Linux emulation, and BOINC in an ARM VM!</p>

<p>The fastest Linux machine I’ve <em>ever</em> used is a hardware virtualized install on the Apple M1 - and this post covers how to do it!</p>

<picture><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-400-1c323509d.webp 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-800-1c323509d.webp 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-1600-1c323509d.webp 1600w" type="image/webp"><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-400-1c323509d.png 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-800-1c323509d.png 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-1600-1c323509d.png 1600w" type="image/png"><img src="https://www.sevarg.net/generated/images/2021-qemu-m1/mac_m1_virtualization-1600-1c323509d.png" width="4096" height="2304"></picture>



<h2 id="the-short-2020-m1-mac-mini-review">The Short 2020 M1 Mac Mini Review</h2>

<p>While I don’t generally <a href="https://www.sevarg.net/2020/02/01/finances-technology-repair-and-enough/">make a habit</a> of buying brand new, just-released hardware, I made an exception for the M1 and bought a M1 Mac Mini to replace an Intel Mac Mini (which had replaced a perfectly function 2014 iMac I’d still be running if the monitor hadn’t failed - the display assembly, used, cost $600 in not-cracked condition).  The Intel one wasn’t doing most of what I wanted (to say the GPU sucked would be an understatement), I’ve been lusting after a mid-range ARM desktop for a long while, and the fact that things would be broken on it doesn’t bother me - it’s not a production machine for me, so I’m happy to run on the bleeding, slightly broken edge.  It’s a common theme with ARM desktop use, especially 64-bit, so this is no different.</p>

<p>How is it?  It’s <em>fast.</em>  It’s <em>really, really fast.</em>  Not just for the power - that’s amazing too, but simple, flat out, using it for stuff.  It’s amazing.  I figured it would be really good, but it’s beyond good, crossing into the “Yeah, I’ll call this magical…” realm.  The fan almost never comes off idle, power consumption (I work in a solar office, remember?) is a rounding error, and it just does what I ask of it in a real hurry.</p>

<p>I mean, it’ll even play Kerbal Space Program with pretty darn good graphics!  That’s an x86 game with no native port yet, and it’s not exactly a CPU sipper!</p>

<picture><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-400-b017715f9.webp 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-800-b017715f9.webp 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-863-b017715f9.webp 863w" type="image/webp"><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-400-b017715f9.png 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-800-b017715f9.png 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-863-b017715f9.png 863w" type="image/png"><img src="https://www.sevarg.net/generated/images/2021-qemu-m1/ksp_m1_settings-863-b017715f9.png" width="863" height="757"></picture>



<p>This does mean that, once again, Jeb ends up stuck places he’d probably rather not be stuck.  Lock your staging, or a thumb twitch might just leave you 100m above Mun with no descent (or ascent!) stage left attached…</p>

<picture><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-400-976018ace.webp 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-800-976018ace.webp 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-1299-976018ace.webp 1299w" type="image/webp"><source srcset="https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-400-976018ace.png 400w, https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-800-976018ace.png 800w, https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-1299-976018ace.png 1299w" type="image/png"><img src="https://www.sevarg.net/generated/images/2021-qemu-m1/sad_jeb-1299-976018ace.png" width="1299" height="756"></picture>



<p>Should you buy one of Apple’s M1 devices?  Probably not - wait 6 months for the next round of hardware, and buy then.  Most of the software ecosystem quirks will be worked out by then, and just about everything will work.  For now, there are enough weird little broken corner cases that I’d suggest holding off unless you’re OK with that and want legitimately insane battery life and performance.</p>

<p>But an awful lot does work, and it works really well.</p>

<p>Yes, yes, I <em>know,</em> your overclocked AMD ThreadBlaster 7970XP, with enough threads, will build the kernel faster on 400W.  All this performance is on about 30W, and this is their first pass at it.  Just wait…</p>

<h2 id="rosetta-2-they-did-what">Rosetta 2: They Did WHAT?</h2>

<p>We also have an answer now to the insane x86 translation performance (around 80% of native performance, give or take - and, yes, this does mean that the M1 runs x86 binaries faster than an awful lot of x86 hardware out there).  I’ve messed around with running x86 binaries in emulation on ARM before, and got about 10% of native performance on a Rpi4.  Painful.  Apple’s Rosetta 2 gets a lot of benefit from being a pre-compiling translator (for most cases - it still has to interpret JIT type workloads), but most people figured that would get you to 50% - at best.  The ARM memory model is so radically different from x86 that you end up sprinkling memory barriers everywhere to guarantee cross threaded consistency, and that really hurts performance.</p>

<p>The issue is that on x86, if you write memory addresses in a certain sequence, <em>all other cores</em> will see the writes in the same sequence. If you write some blob of data and then write the “Ready!” flag, by the time other cores see the flag change value, you can be certain that the blob of data has been written.  ARM has no such guarantees without explicit (and slow) memory barrier instructions, and this is why the x86 emulation on ARM Windows was painful - guaranteeing correctness of a translated binary on a weaker memory model is slow.</p>

<p>As it turns out, Apple <em>isn’t</em> doing it purely in software - they have <a href="https://github.com/saagarjha/TSOEnabler">Total Store Ordering</a> support in their hardware!  When the M1 runs a translated x86 binary, the OS just tells the chip, “Hey, use x86 memory ordering for this thread.”  Things built natively for ARM can take advantage of the performance gains of the memory reordering, and things that requires strict ordering get strict ordering.  It’s a very, very clever way to totally bypass the memory ordering issues with translated binaries, and it’s not a thing in any other ARM chip on the planet (I’d say yet, but I really don’t think this will become a popular thing to implement - perks of Apple building their own silicon).</p>

<h2 id="onto-virtual-machines-lets-build-qemu">Onto Virtual Machines: Let’s Build qemu!</h2>

<p>Now, to the core of the post: Building qemu to run hardware virtualized ARM Linux!  I’m starting with <a href="https://gist.github.com/niw/e4313b9c14e968764a52375da41b4278">these excellent instructions</a> as a guide, but I’ve got some extra patches thrown in (because it doesn’t run x86 emulation my M1 with 11.1), and I’m doing a few other things in the process.</p>

<p>You’ll need XCode installed, and we’ll be using <a href="https://brew.sh/">homebrew</a> to install  some of the prerequisites for building qemu.  Plus some patches to the source, and… it’s all good fun, I promise!  What I don’t promise is that this will work perfectly for you, though I’ll try!</p>

<p>Yes, I know Parallels has a tech preview out, and you still can’t change the resolution of a Linux guest.  If you’re fine with 1024x768, it certainly works, but… we can do better with open source!</p>

<h4 id="installing-the-prerequisites-homebrew-and-xcode">Installing the Prerequisites: Homebrew and XCode</h4>

<p>You’ll need the XCode command line tools (gcc and such) to build this, so if you don’t already have those installed, go ahead and install XCode from the App Store.  It’s huge.</p>

<p>I understand you can also install them from the command line, if you don’t want the full install, by running <code>xcode-select --install</code>.  That’s the first thing I do with any Mac, so I had them laying around.  You may have to agree to some license terms as well - it’s been a while since I had a clean install.</p>

<p>If you use the normal Homebrew install path, you’ll get x86 Homebrew, running under Rosetta.  This is fine for most use cases, and it certainly <em>works</em> better than the ARM Homebrew (half the code won’t build under ARM), but it’s no good for ARM native dependencies, and we’re going to be building ARM native qemu.</p>

<p>If you rely on x86 homebrew, well… uh… fix the ARM stuff that doesn’t build?  Or install to a different directory, I suppose.  I have no great advice on parallel Homebrew installs, sorry.</p>

<div><div><pre><code>cd ~
mkdir homebrew &amp;&amp; curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew
sudo mv homebrew /opt/homebrew
echo 'export PATH="/opt/homebrew/bin:$PATH"' &gt;&gt; ~/.zshrc
source ~/.zshrc
brew update
</code></pre></div></div>

<p>This will run some git fetches, some builds, and you should generally have a working brew install.  Like XCode, this may take a while, depending on your internet connection.  My ISPs have been sucking more than usual lately, and I don’t keep a local mirror of Homebrew, so… coffee time.</p>

<p>You should then be able to install the dependencies for qemu:</p>

<div><div><pre><code>brew install ninja pkgconfig glib pixman
</code></pre></div></div>

<h4 id="fetching-patching-and-building-qemu">Fetching, Patching, and Building qemu</h4>

<p>Next step: we’re going to download the qemu source, check out the proper version, apply a couple patches, and build it!</p>

<p>The <a href="https://patchwork.kernel.org/project/qemu-devel/list/?series=400619">first patch series</a> is the core of the updates - it adds <a href="https://developer.apple.com/documentation/hypervisor">Hypervisor.framework</a> support (Apple’s recent “So, you wanna do hardware virtualization without a kernel module…” framework), adds the ability to sign the output binary to allow it to use that, and various other things related to Apple Silicon support.</p>

<p>The <a href="https://patchwork.kernel.org/project/qemu-devel/patch/20210103145055.11074-1-r.bolshakov@yadro.com/">second patch series</a> isn’t actually required to run hardware virtualization, but if you wanted to mess around with the (somewhat awful, but still usable) performance of x86 VMs on the M1, you’ll need this.  Apple Silicon prevents memory pages from being both writable and executable at the same time, and this adds the toggles to handle things properly so the JIT engine can work.</p>

<p>If you <em>don’t</em> apply the second patches, and you try to run x86 system emulation, you’ll get the exceedingly unhelpful error “Could not allocate dynamic translator buffer” when you try to run it.</p>

<p>And, of course, if you’re not interested in x86 emulation, you can skip the <code>x86_64-softmmu</code> and <code>i386-softmmu</code> options in the target-list for configure.</p>

<div><div><pre><code>git clone https://git.qemu.org/git/qemu.git
git checkout master -b wip/hvf
curl 'https://patchwork.kernel.org/series/400619/mbox/'|git am --3way
curl 'https://patchwork.kernel.org/project/qemu-devel/patch/<a href="https://www.sevarg.net/cdn-cgi/l/email-protection" data-cfemail="3200020003020302010306070207071c03030205061f031f401c505d5e415a53595d44724b5356405d1c515d5f">[email&nbsp;protected]</a>/mbox/'|git am --3way
mkdir build
cd build
../configure --target-list=aarch64-softmmu,x86_64-softmmu,i386-softmmu --enable-cocoa
make -j 8
</code></pre></div></div>

<p>Sit back, relax, wait… actually, not very long, this system is blazing fast on all 8 cores, and you should have some qemu binaries!</p>

<h4 id="grab-an-arm-ubuntu-iso-and-an-efi-blob-create-a-disk-image">Grab an ARM Ubuntu ISO and an EFI blob, Create a Disk Image</h4>

<p>There are plenty of ways to install the ARM version of Ubuntu, but there’s a convenient desktop build now at <a href="https://cdimage.ubuntu.com/focal/daily-live/current/">https://cdimage.ubuntu.com/focal/daily-live/current/</a> - grab <code>focal-desktop-arm64.iso</code>.  You do NOT want the ‘amd64’ version - make sure you get ‘arm64’ or it won’t work!</p>

<p>You also need a EFI blob built for ARM.  The instructions I’m working from cover how to build it with your own ARM VM (and include a link to some built ones), but I’ve also uploaded one for you, if you happen to want it: <a href="https://www.sevarg.net/images/2021-qemu-m1/QEMU_EFI.fd">QEMU_EFI.fd</a></p>

<p>While you could just run the live ISO, there’s no fun in that - create a disk image for the install (you’ll be doing this from the qemu/build directory you were just in, and stick the image somewhere fast).  I’ll assume you’ve put the QEMU_EFI.fd file in the same directory.</p>

<div><div><pre><code>./qemu-img create -f qcow2 /path/to/Ubuntu.qcow2 40G
</code></pre></div></div>

<h2 id="the-fun-part-launch-the-vm">The Fun Part: Launch the VM!</h2>

<p>Now, let’s light up a VM from the installer CD!  It’s Linux, so we’re just using <em>all the virtio devices.</em>  Virtio is a way for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/">https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/</a></em></p>]]>
            </description>
            <link>https://www.sevarg.net/2021/01/09/arm-mac-mini-and-boinc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717019</guid>
            <pubDate>Sun, 10 Jan 2021 17:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We've been running a bootstrapped startup for a year]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25717006">thread link</a>) | @artembugara
<br/>
January 10, 2021 | https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways | <a href="https://web.archive.org/web/*/https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><h3>What is the value of this article? </h3><p>We are young, inexperienced, prone to fail: <strong>we’re 2 first time founders</strong>. I always prefer to learn from people who are just a few steps ahead of me. </p><h3>Who is this article for? </h3><p>If you’re a multi-time entrepreneur then you might not find this article interesting. <strong>If you’ve been thinking about starting your own startup then I’d recommend reading as many similar articles as possible.</strong></p><h2>Our Team</h2><p>Artem (author of this article):</p><ul><li><p>First-time founder </p></li><li><p>Technical with no CS degree</p></li><li><p>24 years old</p></li><li><p>~2 years of work experience (data-oriented job)</p></li><li><p>Quit the University after Masters 1 to get a job</p></li><li><p>Full-time since April 2020</p></li><li><p>CEO</p></li></ul><p>Maksym:</p><ul><li><p>First-time founder </p></li><li><p>Technical with no CS degree</p></li><li><p>24 years old</p></li><li><p>~2 years of work experience (data-oriented job)</p></li><li><p>Full-time since December 2020</p></li><li><p>CTO</p></li></ul><h2>Our Product - News API</h2><p>We provide instant access to news article data for hedge funds, market researchers, and PR software. </p><p><strong>In simple words: </strong></p><ol><li><p><strong>we crawl news websites, </strong></p></li><li><p><strong>detect news article URLs, </strong></p></li><li><p><strong>extract all possible information (title, published date, author, content, etc.), </strong></p></li><li><p><strong>index this data</strong></p></li></ol><p>Our main product is <a href="https://newscatcherapi.com/news-api">News API</a> which allows our clients to find structured news articles by any topic, country, language, website, or keyword. </p><p><a href="https://www.notion.so/newscatcherapi/News-API-46632a5cd61548919ff0132b15b0f0fa?p=2eff4d9b6e6b4a87a8e2230424aee4be">Example of News API JSON response</a>.</p><p>We’re B2B Data-as-a-Service.</p><h3>What I and my co-founder could achieve in 12 months</h3><ul><li><p>Monthly Recurring Revenue ~$3,000</p></li><li><p>Both co-founders work full-time</p></li></ul><blockquote>All things mentioned are purely personal. </blockquote><p><strong>1. Talk to your potential clients</strong></p><p>Talk to them even if you do not have a product. </p><p>Imagine you have the very best version of what you’re building. Go ahead and see what people say. </p><p>One more thing: <strong>CLIENTS</strong>. Not your friends, or some random people. Yeah, your friends will say “Great idea”. All of them. </p><p>What you really want to hear is “I like it. What’s the price? How can I buy it?”</p><p>People only vote with their pockets.</p><p><a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users">More read</a></p><p><strong></strong><a href="https://www.ycombinator.com/library/6g-how-to-talk-to-users"><strong></strong></a><strong>2. Do not think you/your product/your team/your approach are any different or unique</strong></p><p>We all want to be special. We all want to work for a company that will soon cost millions of dollars. We all want to be the first of our kind. </p><p>But, most likely, you, your team, your product is (below) average.</p><p>So, if you hear experienced people repeating the same thing to you then you should act. </p><blockquote><strong>Do not try to be “Yeah, but we’re…”</strong> </blockquote><p><strong>3. It’s almost impossible to raise money when you don’t have anything to show</strong></p><p>Do not expect investors to come and give you money. It’s a big gamble for you to start raising. Also, raising money is a full-time job!</p><p><strong>4. Start pitching investors as soon as possible</strong></p><p>Yes, do not expect them to give you money. However, there is a lot of things to do to raise money. You have to be prepared for when you’re ready. </p><blockquote>Pitch deck.  Pitching. Answering the questions. </blockquote><p>Do not spend much time on it. However, I would recommend to do it consistently. It will take months to come up with something consistent. So, you’d better start early.</p><p>Also, some investors will tell you why they will not give you money. Iterate, and work on these problems.</p><p><strong>5. Start small. Do things that do not scale. Be a consulting company</strong></p><p>Believe me or not but the only way to sell your scalable solution to millions of clients is to start by selling it one-by-one. In a non-scalable way. </p><p><a href="http://paulgraham.com/ds.html">More read</a></p><p><strong></strong><a href="http://paulgraham.com/ds.html"><strong></strong></a><strong>6. Do not be afraid to charge </strong></p><p>Charge for your service/product at a fair price. Yeah, you might lose some clients. But, how will you survive if you cannot get fair pay for your service? </p><p><strong>7. It’s a grind. Consistent one</strong></p><p>You have to repeat a lot of boring things over and over again. </p><p><strong>8. Only those who pay you money have to decide which features to add</strong></p><p>Do you think adding this feature is cool? Go ahead, and ask those who pay you. </p><p>Listen to what they say, and make a better product. </p><p><strong>9. Carefully choose co-founders</strong></p><p>We know each other for over 14 years. We knew well what to expect from each other.</p><p><strong>10. Help others &amp; Ask others for help</strong></p><p><strong>11. Things that no one actually cares about at the beginning</strong></p><ul><li>Logo</li><li>Name, website domain</li><li>Your background</li></ul><p><strong>12. Things that everyone cares about</strong></p><ul><li>Your value proposition</li></ul><p><strong>13. What is the definition of a “startup” for you? </strong></p><p>Can you give it? Maybe what you want to start is a small business. There’s nothing wrong with it. </p><p><strong>14. Do not afraid to take a step back</strong></p><p><strong>15. This list misses the other 100 points which we did not figure out yet! So, do not overlay on it</strong></p><p>All I’ve written here might be wrong/not applicable to you. But like I said, most likely you’re not different at all.</p></div></div></div></div>]]>
            </description>
            <link>https://newscatcherapi.com/blog/we-ve-been-running-a-bootstrapped-startup-for-1-year-our-top-15-takeaways</link>
            <guid isPermaLink="false">hacker-news-small-sites-25717006</guid>
            <pubDate>Sun, 10 Jan 2021 17:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Powerful Life Skills for the New Decade]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25716764">thread link</a>) | @neilkakkar
<br/>
January 10, 2021 | https://neilkakkar.com/powerful-life-skills.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/powerful-life-skills.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Over the past few years, I’ve noticed certain skills in people I admire, from Paul Graham, Vitalik Buterin, to Ender Wiggin.</p>

<p>These are rare skills, responsible for making them who they are. Most normal people, including me, don’t realise it. This makes the skills powerful - not everyone can see them, and very few people have mastered them.</p>

<p>However, I aim to change that. What follows below are 10 skills sourced from admirable people that I want to develop.</p>




<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<h2 id="learn-to-take-compounding-seriously">Learn to take compounding seriously</h2>

<p>It’s not just your wealth that compounds, but life experience and knowledge, too.</p>

<p>So, learn the most basic, most useful skills first. The longer you wait to learn skills like these, the less time there is for compounding magic. That’s what this entire list is about: powerful skills to learn and use for the rest of your life.</p>

<p>And even though you’ve heard about compounding, this item is first on the list, because <a href="https://neilkakkar.com/taking-ideas-seriously.html">taking ideas seriously is hard</a>.</p>

<p>A good way to figure out what compounds is <a href="https://neilkakkar.com/year-in-review-2019.html#compounding-is-powerful-building-intuition-for-compounding-even-more-so">to figure out what’s a platform</a>.</p>

<h2 id="learn-to-develop-taste">Learn to develop taste</h2>

<p>Despite prevalent beliefs, taste isn’t subjective.</p>

<p>While it may seem like it on the outside, when you say “I just love this painting” or “I just love this coffee machine” - all it means is that the defining characteristics are illegible to you. And noticing this is the first step.</p>

<p>Let’s take a specific example. Say you’re designing a high quality clay pot - and you’ve never done this before.</p>

<p>What’s a good way to develop taste for quality here?</p>

<p>If you’ve heard this claypot parable, you know the answer: start by making lots of crap pots.</p>

<blockquote>
  <div><p>The ceramics teacher announced on opening day that he was dividing the class into two groups. All those on the left side of the studio, he said, would be graded solely on the quantity of work they produced, all those on the right solely on its quality. His procedure was simple: on the final day of class he would bring in his bathroom scales and weigh the work of the “quantity” group: fifty pound of pots rated an “A,” forty pounds a “B,” and so on. Those being graded on “quality,” however, needed to produce only one pot—albeit a perfect one—to get an “A.”</p><p>

Well, came grading time and a curious fact emerged: the works of highest quality were all produced by the group being graded for quantity. It seems that while the “quantity” group was busily churning out piles of work—and learning from their mistakes—the “quality” group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay. - <a href="https://amzn.to/3o9o17A" target="_blank" rel="noopener">Art and Fear</a><sup id="fnref:2"><a href="#fn:2">1</a></sup></p></div>
</blockquote>

<p>Let others tell you what you’ve made is crap. Learn why. Notice when they tell you something is great. Figure out why.</p>

<p>This transfers to writing as well: Popular advice to get better is to write a lot of junk, do it a 100 times, and pay particular attention to what is received well. Here’s <a href="http://www.paulgraham.com/taste.html" target="_blank" rel="noopener">another example - developing taste for design</a>.</p>

<p>In effect, you bootstrap good taste by first learning what others consider good. Then, <a href="#learn-to-see-systems">you see the system behind it</a>. Then you break the rules and still manage to awe.</p>

<p>Then you’ve developed taste.</p>

<h2 id="learn-to-sequence-things-well">Learn to sequence things well</h2>

<p>Waking up when others are asleep and getting lots done is a super power. It’s born out of a system of <a href="https://neilkakkar.com/sequencing-things-in-the-right-order.html">learning to sequence things well</a>.</p>

<p>It means choosing the right time for that Netflix binge.</p>

<p>It means being prepared before the meeting, not scrambling to get things done after.</p>

<p>It means reading the coursebook before the lecture, not after.</p>

<h2 id="learn-to-see-what-others-see">Learn to see what others see</h2>

<p>How well can you understand other people? Can you sense their desires, their concerns, and what events lead to those desires and concerns?</p>

<p>If you can do this, you can understand them. But not before.</p>

<blockquote>
  <p>In the moment when I truly understand my enemy, understand him well enough to defeat him, then in that very moment I also love him. I think it’s impossible to really understand somebody, what they want, what they believe, and not love them the way they love themselves. - <a href="https://amzn.to/2KKe8Px" target="_blank" rel="noopener">Ender’s Game</a><sup id="fnref:1"><a href="#fn:1">2</a></sup></p>
</blockquote>

<p>It’s worth going this far because understanding is powerful. It helps you empathise. It helps you negotiate. It helps you figure out why you don’t have product-market fit. It helps you learn quickly: you can switch through personas and see what will and won’t work.</p>

<p>How do you do learn to see? I know no better way than to practice. Try it a 100 times. <a href="https://neilkakkar.com/subscribe">Come back next year</a>, and maybe I’ll have a better way once I’ve done it a 100 times.</p>

<h2 id="learn-to-make-and-execute-decisions-quickly">Learn to make and execute decisions quickly</h2>

<p>Most people have a bias towards analysis-paralysis versus getting shit done.</p>

<p>When decisions are reversible - and they mostly are - speed is a super power. Cultivating a habit of making decisions quickly, and then executing them is better than just thinking about it.</p>

<p>Training this skill begins as easily as deciding what to eat on a huge menu. It’s a small step, but over time, <a href="#learn-to-take-compounding-seriously">even the smallest steps compound</a>.</p>

<blockquote>
  <p>“Hesitation is always easy, rarely useful” - Prof. Quirrel alterego, <a href="http://www.hpmor.com/" target="_blank" rel="noopener">HPMOR</a></p>
</blockquote>

<p>Here’s an <a href="https://firstround.com/review/speed-as-a-habit/" target="_blank" rel="noopener">example in the context of business</a>. And a <a href="https://twitter.com/sama/status/1345140364995227648" target="_blank" rel="noopener">tweet from Sam Altman</a>.</p>

<h2 id="learn-to-spot-a-convex-or-concave-world">Learn to spot a convex or concave world</h2>

<p>In the world of viral infections, a 50% lockdown is worse than a 0% and a 100% lockdown, both. The virus isn’t contained, and businesses have to shut down, too.</p>

<p>In the world of immigration policies, letting some specific people in is better than letting no one or everyone in. The middle ground is better than the extremes.</p>

<p>When the best of both worlds is great, you’re in a concave disposition.</p>

<p>When the best of both worlds is worse than either, you’re in a convex disposition.</p>

<p>The world is sometimes concave, and sometimes convex. Knowing your topology can help you make better decisions.</p>

<p>I first noted this when <a href="https://vitalik.ca/general/2020/11/08/concave.html" target="_blank" rel="noopener">Vitalik Buterin explained it</a>. Read it for more concrete examples.</p>

<!-- ## Learn to do obvious things -->

<h2 id="learn-to-tell-stories">Learn to tell stories</h2>

<p>People donate more to charity when they know a single victim’s story, versus statistics of a thousand deaths. It’s called the <a href="https://en.wikipedia.org/wiki/Identifiable_victim_effect" target="_blank" rel="noopener">Identifiable Victim Effect</a>, but it’s the power of stories over facts. The right framing gets you further than all the facts combined.</p>

<blockquote>
  <p>“A single death is a tragedy; a million deaths is a statistic.”</p>
</blockquote>

<p>Ideas &amp; facts contextualised by stories are more powerful than either alone.</p>

<p><i></i><b>The Skill of Storytelling</b><br>
There’s lots to unpack here, and this is the first skill I’ve been working on for the past few months. Watch out for a long blogpost in 2 weeks!</p>

<h2 id="learn-to-dive-into-the-source-code-when-documentation-isnt-enough">Learn to dive into the source code when documentation isn’t enough</h2>

<p>Sometimes, there’s no precedent for what you want to do. Or the people who did it before didn’t write a manual.</p>

<p>In cases like these, figuring things out for yourself is powerful. Research papers and obscure books aren’t just for scientists. They’re freely available on the internet* for all of humanity to use. Learn to use it. Learn about resources like <a href="https://sci-hub.do/" target="_blank" rel="noopener">SciHub</a>, <a href="https://libgen.xyz/" target="_blank" rel="noopener">LibGen</a>, and hiring researchers. You’re allowed to hire people (specially graduate students!) to satisfy your research concerns.</p>

<p>… and when you’re done, <a href="https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html#writing-code">preserve context for future you</a>.</p>

<p>It’s a lot like trying to use an API that has no documentation. Would’ve been easy if there was documentation, but there isn’t. So you got to do it the hard way: read the source code and figure out what you need to make things work.</p>

<p>It’s also like <a href="https://neilkakkar.com/A-framework-for-First-Principles-Thinking.html">figuring out what you need to build rockets yourself</a> when existing ones are too expensive.</p>

<p><a href="https://www.lesswrong.com/posts/37sHjeisS9uJufi4u/scholarship-how-to-do-it-efficiently" target="_blank" rel="noopener">More resources here</a>.</p>

<h2 id="learn-to-be-specific">Learn to be specific</h2>

<p>Every time I gave an example above, I was training my specificity muscles.</p>

<p>Most of the time, most people don’t know what they’re talking about. Not being specific is a sign of that. The more abstract the word, the harder it is to pin down a meaning.</p>

<p>For example, “negative ramifications” doesn’t tell you what exactly happened, while “the sonic boom from the new supersonic jet destroyed windows in a 100m radius” is a lot more specific.</p>

<p>Learn to be specific, and learn to spot when others aren’t. <a href="https://www.lesswrong.com/posts/NgtYDP3ZtLJaM248W/sotw-be-specific" target="_blank" rel="noopener">Here’s how</a>.</p>

<h2 id="learn-to-see-systems">Learn to see systems</h2>

<p>There’s two kinds of people.</p>

<ul>
  <li>Bob, who will see this list, find some skills very interesting, and then go about honing those skills</li>
  <li>Alice, who will see this list, and wonder how I came up with these
<!-- - The Inspiration-Junkie, who will lurk and move on to the next inspiring post without changing anything -->
</li>
</ul>

<p>Alice would then try to understand the system that generated these ideas. Then, she’ll adopt the system, and come up with skills possibly more relevant to herself.</p>

<p>Having the option to do both is powerful. Since Bob is the default, <a href="https://neilkakkar.com/How-to-see-Systems-in-everyday-life.html">learn to be like Alice</a>. Choose <a href="https://neilkakkar.com/understanding-systems.html">systems when things are important</a> to you. Choose hacks when you need a quickfix.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>



    
  </div></div>]]>
            </description>
            <link>https://neilkakkar.com/powerful-life-skills.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716764</guid>
            <pubDate>Sun, 10 Jan 2021 17:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Weirdness of Kentucky Route Zero (2016)]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25716686">thread link</a>) | @olvy0
<br/>
January 10, 2021 | http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/ | <a href="https://web.archive.org/web/*/http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>In <a href="http://blog.joshhaas.com/2016/10/mr-robot-is-not-weird-enough/">my last post</a>, I took issue with the TV show <i>Mr. Robot</i> for not being weird enough. Although imaginative and compelling, its universe is well-ordered: everything happens for a reason.</p>
<div>

<p>If you’re looking for media to consume that doesn’t suffer from that problem, I recommend <a href="http://kentuckyroutezero.com/"><i>Kentucky Route Zero</i>.</a></p>
</div>

<p>I <a href="http://blog.joshhaas.com/2016/10/yet-another-review-of-the-trump-clinton-debate/">previously discussed</a> <i>Kentucky Route Zero</i> (<i>KR0</i> for short) in the context of the first Trump-Clinton debate. It’s relevant to that because it’s a tour through coal-country America, and it engages with the desolation there that’s fueling Trump’s support.</p>

<p>As a portrait of the region, it’s a Picasso or maybe a Goya, not a Velázquez. It has moments where it approaches documentary realism, but it mostly traverses an imaginary landscape reflecting its creators’ perceptions, inspired by their real-life travels in Kentucky.</p>

<p><i>KR0</i>’s medium is a computer game, but “game” is misleading. There’s no element of skill. It has the interface of an adventure game, but unlike other games in that genre, your progression through the story isn’t blocked by puzzles to solve. Rather, it’s more like a work of interactive fiction. The story is mainly told through dialogue, though the soundtrack and visuals are important pieces of the experience.</p>
<div>

<p>The medium is appropriate: it makes a better game than it would a book or a tv show. The ambition seems to be to create a world, and the ability to explore it freely is important. There’s a narrative, but the world is alive beyond the narrative, and there’s a lot to discover outside the main plot.</p>

</div>
<p>The three-person studio that produced <i>KR0</i>, Cardboard Computer, has been trying to erase the lines between their fictional universe and the real one. They’ve released a number of companion pieces to the game, including <a href="http://kentuckyroutezero.com/the-entertainment/">an experience for Occulus Rift or Mac / PC</a> where you participate as a cast member of a fictional 1973 production of a one-act play. The play appears to depict events that occur in a bar a few hours before the character you play in <i>KR0</i> visits the bar in the game, but the fictional set designer for the 1973 production — ie, a real person in the production’s fictional reality — is also a character in <i>KR0</i>. In case that wasn’t confusing enough, you can buy a <a href="http://www.lulu.com/shop/http://www.lulu.com/shop/lem-doolittle/the-entertainment/paperback/product-21312732.html">print copy of the script</a>, published under the name of the fictional author.</p>

<p>It’s not a bad play, either. As the script advertises, “The one-act play “A Reckoning,” set in a tavern in central Kentucky, is Doolittle’s take on the sort of barroom tragedy made popular by O’Neill, Gorky, etc.”, and I would say it stands on its own as a piece of theater, although the ending will have more resonance if you’ve played through <i>KR0</i>.</p>

<p>This almost pedantic accumulation of fictional detail, both inside and outside the game — names, biographies, places, events — lends believability and power to <i>KR0</i>’s magical realist plot-line. Because the production team took such great pains to create verisimilitude, the more fantastic elements of the game feel justified: hauntings, strange and implausible creatures, a whiskey company whose employees are all glowing skeletons, and the titular Route 0, a hidden underground highway through non-euclidean space.</p>

<p>The game’s plot is simple and unobtrusive compared to the sprawling, strange world it is set in. Conway, a truck driver for an antiques store, is trying to make a delivery to Dogwood Drive, a street that doesn’t show up on his maps. As he looks for it, he picks up some traveling companions, and we learn more about his and their pasts. <i>KR0</i> isn’t complete yet —the game is divided into five acts, and final one hasn’t been released — so I don’t know yet if Conway ever makes it to his destination.  In fact, I still don’t know what he’s delivering, or to whom.</p>

<p>As a player, the main way you exert agency is through your choice of dialogue options. Unusually for adventure-style games, your dialogue choices don’t seem to affect the plot. Rather, they affect the past: you can give the characters different backstories, influence their temperaments, change how they see the world and treat each other. It’s a limited degree of freedom: I haven’t flexed the game aggressively to see how divergent you can make it, but my understanding is that the basic outline of who the characters are always remains the same. It’s more of a matter of altering the shadings.</p>

<p>The net effect of the simple plot, the strange, expansive world, and the freedom to emphasize and explore different aspects of the characters is that playing the game doesn’t feel like you’re being told a story, with themes and a moral. Rather, it feels more like an invitation to you, the player, to interpret what you’re confronted with. The game gives you a lot of details to work with, and powerful images and emotions, but leaves you to decide what to think about it all.</p>

<p>At its heart, I think <i>Kentucky Route Zero</i> is a meditation on entropy. Certainly, entropy is the unifying characteristic of the game world. <i>KR0</i>’s setting is a Kentucky that’s been devastated by the collapse of the coal industry and by the 2008 housing crisis. Everything you encounter is in some state of falling apart. The gas station you refuel at has overdue electric bills. The bar can’t buy alcohol any more. The coal mine is abandoned. Conway’s dog looks like she’s seen better days. All the characters have various stories of poverty, alcoholism, loss, and debt.</p>

<p>Entropy has different facets. There are many different stances that one can take towards it. <i>KR0</i> seems to explore each of them in turn, weighing them, inviting you to partake.</p>

<p>The most basic stances are the emotional ones: despair, grief, and anger. There’s certainly plenty of that throughout the game. In one particularly powerful moment, you come across a memorial for coal miners who drowned when some tunnels were flooded in an accident a decade or so ago.  The memorial is a collection of hard-hats floating in an underground lake, accompanied by an angry, hand-written sign accusing the mining company of negligence. In another moment, you meet a team of engineers who spent their lives trying to build a computer system (called Xanadu, presumably a reference to the <a href="https://www.wired.com/1995/06/xanadu/">real world could-have-been internet competitor</a>), who are now just sitting around hopelessly, having given up on ever completing their lives’ work.</p>

<p>Another stance is simple momentum: keeping going on as long as you can. One character you meet is a switchboard technician, the last one on her team after all her coworkers were laid off by the phone company automating the systems. They couldn’t quite automate her, so she keeps plugging away, alone in a tunnel, connecting call after call. There’s also a church, relocated to a warehouse by some beauracrats, where the congregation all drifted away, the preacher left, and now it’s just a janitor who puts on pre-recorded sermons every Sunday.</p>

<p>Entropy and grief can also give rise to beauty. <i>KR0</i> has plenty of beautiful moments too. The game has a gorgeous soundtrack, mixing electronic music and ambience with bluegrass classics. The bluegrass pieces, performed by a mysterious wandering trio who occasionally wander across your path, are all explorations of loss and hardship, transmuted into folk songs and hymns. The visual palette of the game is mixture of blues and oranges, mostly subdued and minimalist, but occasionally spectacular. Everything has a satisfying organic, analog feel. Radio systems crackle, televisions hum, computers react to strange magnetic fluctuations.</p>

<p>Yet another approach to entropy is to consume and exploit it. At various points in the game, you encounter modern, structured institutions, that are in the process of channeling the breakdown toward their own ends. There’s a whiskey distillery that’s steadily acquiring the balance sheets and souls of the folks you meet. You get to take a tour of its expansive, industrially-clean factory in an amazing descent-into-hell sequence that feels like Dante meets OSHA. The local power company also seems to be on the march. There are also more highbrow institutions consuming the entropy. For instance, you visit the “Bureau of Reclaimed Space”, which seems to represent government, taking in weirdness and outputting paperwork. In another interlude, you find an entire town that’s been transplanted to be inside a museum, the residents still living in their houses, enclosed in a giant glass warehouse.</p>

<p>Somewhat related to high-brow consumption, there’s intellectualization of entropy. <i>KR0</i> has a steady stream of references to academia. You meet a number of characters who have spent time in the grad student / post-doc limbo space, and there’s a lot of art and math jargon. From an academic perspective, entropy is a source of phenomena to record, analyze, and write papers about — hopefully publishable ones. This content is a reflection of the game itself, which in many ways feels like a modern art project. <i>KR0</i> is obsessed with topology and imaginary spaces. Characters muse about space aloud, and as you move around the game, you explore a number of different spaces and means of navigating them: a driving map of Kentucky as navigated by truck, the same map as navigated by a bird, a bureaucratic office building where you ride an elevator up and down, a pure mathematical abstraction that you traverse by turning around at certain symbols, an endless underground river where you are swept along on a boat, among others. This self-conscious exploration invites you to see the entropy in <i>KR0’s</i> world as something to think about and study.</p>

<p>Finally, entropy gives rise to newness: the inadvertent creativity of random processes. Two of the more memorable characters you meet are a pair of androids that, in their telling, emerged from the mines as shapeless lumps, and transformed themselves into a pair of motorcycle-riding musicians, who are now <a href="https://killscreen.com/articles/kentucky-route-zeros-junebug-set-release-tktk-album-androids/">releasing an album outside the game</a>. Abandoned things in <i>KR0</i> tend to take on a life of their own.  A hobo sets up shop as an organist in a church converted into an office …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/">http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/</a></em></p>]]>
            </description>
            <link>http://blog.joshhaas.com/2016/10/the-weirdness-of-kentucky-route-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716686</guid>
            <pubDate>Sun, 10 Jan 2021 17:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure and blinded medical data analysis with OpenSAFELY]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25716685">thread link</a>) | @stuartbman
<br/>
January 10, 2021 | https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<p><span>
<div><h3>Clinical Need</h3><p>When COVID-19 first hit, governments across the globe had to make tough public health decisions with little information. The measures they put in place to reduce spread can prevent COVID-19-related deaths but can also have <i>negative</i> consequences on physical and mental health😷.</p><p>Understanding what factors determine risk of serious outcomes from COVID-19 can help guide these policies. For example, people who are high risk may be advised to shield at home.</p><p>To understand these risk factors, there was a need to analyse large volumes of medical records. Unfortunately, getting access to these records and <sample>linking them appropriately</sample> typically requires lots of regulatory approvals and takes a long time.</p></div>
</span>
</p>
<div>

<div><p>To really understand COVID, we need to link up clinical appointment notes with test results, death records, etc.</p><p>However, this information is typically kept in different locations.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>

</div>
</div>
</section>
<section>
<div>
<p><span>
<div><p>As a result, it’s hard to get really big datasets but <sample>the bigger, the better</sample>.</p><p>So what could we do? This research team came up with a great solution…</p></div>
</span>
</p>
<div>

<div><p>The larger the dataset, the greater statistical strength you have for the analysis.</p><p>In a smaller dataset, you might see trends - but then not have enough data to confidently say it is not due to random variation.</p><p>This is really important when looking at lots of different variables contributing to an outcome, as they did in this study.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<div><h3>What did they do?</h3><p>They assembled a team of clinicians👨‍⚕️, programmers👩‍💻, data scientists👨‍🔬 and epidemiologists🧑‍💼 and came up with a new way of extracting and analysing health data. They called this platform OpenSAFELY.</p><p>The traditional approach is to: (i) clean data and <sample>pseudonymise it</sample> (ii) download it, then (iii) run an analysis.</p></div>
</span>
</p>
<div>

<p>This is a bit like anonymisation, but not as strict. Information that could enable the individual to be identified (such as date of birth or home address) is modified, but can still be re-identified by those (ie. the researchers) using a ‘de-identification key’.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<div><p>However, this isn’t particularly secure (what if someone’s laptop gets stolen?), pseudonymisation isn’t fail-safe and it allows <sample>repeated analyses which risks identifying false relationships</sample>.</p><p>This team’s new approach is to upload the code for analysing the data to the electronic health record directly. The code is then run and returns the results. The data never leaves the health record. This maintains privacy and prevents repeated analyses 💯</p><p>They used this to look at the factors affecting risk of dying from COVID-19, in a GP health record dataset of 17 million individuals.</p></div>
</span>
</p>
<div>

<div><p>There’s always a possibility that patterns identified in the data are down to chance.</p><p>If a test has “95% confidence” it means there’s a 5% chance it happened by chance.</p><p>We can bear this in mind when interpreting results. However, what happens if we run multiple analyses, looking for a true result?</p><p>We give the data lots of chances to fall into that 5% that is due to chance.</p><p>With a pressure to publish interesting findings, this can incentivise researchers to run multiple tests in order to find these relationships – which may not be true. These may seem interesting, but they’re bad science.</p><p>This is known as ‘data dredging’ or ‘p-hacking’.</p></div>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<div><h3>How does it work?</h3><p>1️⃣ First, after the researcher decides which data they want to analyse (e.g. all patients with diabetes) — they write some code to extract that from the health records.</p><p>2️⃣ When that code is run, they receive data to download. However, the data is a placeholder. It looks like the real data - but all the values are made up! Knowing the structure of the data helps the researchers write the code.</p><p>3️⃣ The working code is sent over to the health record (packaged up in a wrapper called <a href="https://www.docker.com/">Docker</a>) where it performs the analysis. Only the results are returned to the researchers - the patient data never leaves the health records. So no-one (not even the researchers) see the raw patient data.</p></div>
<div><h3>What did they find?</h3><p>They looked at data from 17 million people and found COVID-19-related death is increased by:</p><ul><li>Being male</li><li>Being older</li><li>Higher deprivation</li><li>BAME ethnicity (part of this explained by higher prevalence of medical problems and higher levels of deprivation)</li><li>Obesity</li><li>Various other medical conditions (such as diabetes, severe asthma, cancer and dementia)</li></ul></div>
<section>
<div>
<p><span>
<div><h3>Any limitations?</h3><p>This analysis was done in the early days of the pandemic. This meant we didn’t have the testing capacity we have now🧪. To circumvent this, the researchers included ‘<sample>clinically suspected’ cases</sample> of COVID-19 – and not just ones where it had been confirmed by a COVID-19 test. Some of these ‘positive’ cases may not have actually had COVID-19.</p><p>There were other common issues seen in data analysis on this scale: Some patients had missing data, like obesity, smoking status and ethnicity. Also, health record availability varies between region. They used data from a single GP electronic record company (TPP), whereas some regions (such as Scotland and North-East England use an alternative called EMIS). This means the sample population for the study may not represent the whole population (or indeed populations outside of England).</p></div>
</span>
</p>
<div>

<p>They don't include their definition here, but from the UK Government, this includes: new continuous cough or temperature ≥37.8°C or loss of, or change in, normal sense of smell (anosmia) or taste (ageusia)</p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>
<div><p>It was a great feat to get this platform up-and-running and publish the analysis in such a short space of time. This type of research doesn’t usually happen that fast.</p><p>The study helped public health teams and researchers make decisions. For example, in the UK this provided support for advising at-risk populations to shield🛡.</p><p>This also presents a new paradigm for data analysis of health data, that could enable faster, more secure and more reproducible research going forward. All the code is <a href="https://github.com/opensafely/risk-factors-research">open-source and freely available</a>. This means anybody can inspect the code and other researchers are free to use it.</p><p>Since this paper, the same research group have used this platform to look at the impact on COVID-19 risk of (i) living with school-age children, (ii) HIV, (iii) ethnicity, (iv) taking hydroxychloroquine and (v) steroids with asthma or COPD.</p></div>
</div></div>]]>
            </description>
            <link>https://explainthispaper.com/identifying-covid-risk-factors-new-secure-analytics-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716685</guid>
            <pubDate>Sun, 10 Jan 2021 17:01:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying Apple's Framework for Avoiding Mediocrity]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25716652">thread link</a>) | @sarthakjain
<br/>
January 10, 2021 | https://www.sarthakjain.com/p/apples-framework-for-escaping-mediocrity?r=86tsj | <a href="https://web.archive.org/web/*/https://www.sarthakjain.com/p/apples-framework-for-escaping-mediocrity?r=86tsj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Note this isn't an official framework Apple uses internally. Neither this post nor the author are in any way affiliated with Apple. It is however a framework you can use to understand how Apple prioritizes building products and the closest outside guess to Apples product prioritization framework.</strong></p><h3>Mental Framework</h3><p>Every task or product decision should be put into one of 4 buckets:</p><p><strong>1. Not important.</strong></p><p>Don't do it. </p><p><strong>2. Not important. But needs to be done.</strong></p><p>Do the bare minimum</p><p><strong>3. Important</strong></p><p>As good as the best. Copy the best.</p><p><strong>4. Most important</strong>.</p><p>Innovate to make sure it’s better than the best.</p><h3>Isnt this obvious?</h3><p>It is mostly. However there is one notable exception. Average. If it's looking like what you are going to do is average you are better off doing the bare minimum.</p><p>If a task is between important and not important go either way do as good as best or bare minimum. Don't do average.</p><h3>Apple&nbsp;as an example:</h3><p>Apple is probably the most intense when using this framework. A great example is their history with headphones. For years Apple shipped below average headphones with their iPhones and iPods. Apple's headphones never competed with the likes of Bose. There was nothing new, nothing innovative about them. They needed to be there for Apple's core products to function and they were. They fell into the bucket of ‘2. Not important, but needs to be done.’ Apple even encouraged you to buy third party headphones.</p><p>Once Apple noticed a new innovative product that was gaining traction (the Bragi Dash on kickstarter, and possibly before this) they created a best in class product the Apple Air Pods. This suddenly took their headphone offering from below average to best in class. You could say they were copies of the best or they were better than the best but they certainly weren't average. This had become a category that was now important to Apple. Once the Air Pods took off Apple pushed it&nbsp;to the next level moving it to most important creating the Air Pods Pro leaving everyone in their dust.</p><p><strong>Other examples of products from Apple in each category</strong></p><ol><li><p>Search - Don't care, won't do </p></li><li><p>iCloud/Safari- I'd argue it's the bare minimum they can get away with </p></li><li><p>Airpods Max - as good as the best </p></li><li><p>MacBook/iPad - better than the best </p></li></ol><p>Even if you don't agree with the categorisation you'll probably still agree that Apple has below average products and best in class products but they don't create average products. That is why they have the market dominance they do.</p><p><strong>Even Apple fails occasionally:</strong></p><p>One example of Apple failing to follow this philosophy is in their maps product. Apple Maps really is a very “average” product which came nowhere close to competing with Google Maps. It's very existence necessitates doing more than the bare minimum which would have been to show Google Maps pre-installed. Word is that they are taking this shortcoming seriously and looking to launch a new redesigned Maps soon.</p><h3>Using this framework daily </h3><p>This was originally a slack post shared with the team at <a href="https://nanonets.com/">Nanonets</a>. We use this on a daily basis when scoping tasks. We ask ourselves:</p><p><strong>Do we need to do the bare minimum or best in class?</strong></p><p>Depending on the the answer:</p><p>A) If bare minimum then the follow up question is do we even need to do it? </p><p>B) If best in class should we copy the best or be better than the best?</p><p>If you don't hold yourself to this standard you will mostly end up shipping average features that lead to average products.</p><p><strong>Note</strong>: everything about your product need not be best in class. Only the the features that you matter to your customers and to you as a product/company, which also depends on and will change with the stage you are at.</p><p>I'm the CEO at <a href="https://nanonets.com/">Nanonets</a>, we are building AI to help machines see the world - starting with documents. </p><p>I write about startups, products and technology.</p></div></div>]]>
            </description>
            <link>https://www.sarthakjain.com/p/apples-framework-for-escaping-mediocrity?r=86tsj</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716652</guid>
            <pubDate>Sun, 10 Jan 2021 16:58:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I ignored my mental health, and got hit hard by OCD (a cautionary tale)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25716477">thread link</a>) | @coolvision
<br/>
January 10, 2021 | https://grgv.xyz/ocd_story | <a href="https://web.archive.org/web/*/https://grgv.xyz/ocd_story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Have you seen “Aviator”, a movie with Leonardo DiCaprio about Howard Hughes? Then you might recall what an OCD is.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/2fXF8G50BPQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><strong><a href="https://en.wikipedia.org/wiki/Obsessive%E2%80%93compulsive_disorder">Obsessive–compulsive disorder</a>&nbsp;(OCD) is a&nbsp;mental disorder&nbsp;in which a person has&nbsp;certain thoughts ”repeatedly&nbsp;(called "obsessions") or feels the need to perform&nbsp;certain routines repeatedly&nbsp;(called ”compulsions") to an extent which generates distress or impairs general functioning</strong></p>
<p>I have a mild form of OCD. Had it since teenage years. But rarely bothered me, and I mainly did not care about it much. It manifested itself maybe few times per year, where I would have to re-check few times if the door is locked, for example (which does not seem like a huge burden).</p>
<p>And so, I felt great in autumn and in the first half of December. Everything was fine, I have a job that I love, great family, and hobbies that I enjoy.</p>
<p>Then, this winter came, and It got worse. I live in a northern country (Estonia), daylight time is very short, and although I don’t suffer from SAD too much usually, it might have been a factor. And I usually try to get some vacation in warmer countries, but this year did not do it because of COVID. I also started to work from home, and it probably added to the feeling of isolation and brought me down more.</p>
<p>All in all, I don’t know what were that main factors, but probably the whole combination was too much. Occasional obsessions and compulsions started to show up more, but I mainly just shrugged them off. Then, closer to the new year, it stared to get even worse.</p>
<p><strong>And now it’s at a point where I strongly need professional help, I barely can work, lost lots of weight, have horrible anxiety all the time, and all the obsessions make my behaviour erratic at times.</strong> And this is yet another problem — its actually hard to find professional help quickly! It can be weeks or months until finding a therapist.</p>
<p><em>My main mistake was not looking for warning signs of illness.</em> It was “today it’s fine, then all will be fine” attitude, which is a big mistake.</p>
<p>Yes, my case is slightly exotic, but it relates to all other mental health issues: depression, anxiety, panic attacks, etc… <a href="https://www.nimh.nih.gov/health/statistics/mental-illness.shtml">Nearly 20% of people have some form of mental illness</a>, and some of the issues might not seem like a big deal until they hit hard.</p>
<p>As a tale of caution, I have some advice, which I will follow religiously in future. This is relatively obvious and simple, but let my example be a bit of a motivation to take it more seriously.</p>
<ul>
<li>Maintain mood logging, and journal regularly. It would help to notice any anomalies and problems before they become serious. Don’t shrug off warning signs!</li>
<li>Find mental health checklists, like <a href="https://www.beyondblue.org.au/the-facts/anxiety-and-depression-checklist-k10">https://www.beyondblue.org.au/the-facts/anxiety-and-depression-checklist-k10</a>, check yourself time from time,</li>
<li>Therapy is important, especially in this times. I never did therapy, and now regret it.</li>
<li>Fitness, meditation, good diet and all kinds of self care — in this time of increased isolation it’s not just some random good habits, treating this seriously is a very important part of well-being.</li>
</ul>


			</div></div>]]>
            </description>
            <link>https://grgv.xyz/ocd_story</link>
            <guid isPermaLink="false">hacker-news-small-sites-25716477</guid>
            <pubDate>Sun, 10 Jan 2021 16:43:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A hook for handling large lists with Phoenix Live View]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715878">thread link</a>) | @mpweiher
<br/>
January 10, 2021 | https://alex-min.fr/phoenix-live-view-very-large-list-hook/ | <a href="https://web.archive.org/web/*/https://alex-min.fr/phoenix-live-view-very-large-list-hook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    

    




    


  </header>

  <section>
    <p>I’m currently building a web version of my personal finance application, for that, I’ve chosen to use <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/phoenixframework/phoenix_live_view">Phoenix Live View</a>, it’s the perfect tech for my use case.</p>

<p>In this finance web application, you have a lot of very large lists to display like the list of transactions for example.
Each wallet can have between 2k and 20k transactions and it’s unreasonable to load everything at once. 
Loading everything slows down the initial page load with those large queries and then it also slows down the browser.</p>

<p>The solution is to build a list of transactions which is streamed as you go like on Fastmail or Gmail. 
The user has the impression that they can scroll down and that the full list is already there but in reality, everything is being streamed in chunks and loads as they scroll.</p>

<p>I’ve use <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/fulmicoton/fattable/">Fattable.js</a> for that purpose, it’s a small library which is making handling those large tables easier.</p>

<p>First, here is a preview of the end result:</p>

<video src="https://d33wubrfki0l68.cloudfront.net/e08e4212f821ef079db66ab61ab59b0e574fcc9a/fa8f0/videos/infinitescroll.mp4" muted="" autoplay="" loop="" controls="">
  <p>Video preview of the infinite scrolling where I scroll anywhere and you can see the list loading as I scroll dynamically</p>
</video>

<p>Now let’s dive into the code!</p>

<h2 id="the-live-view">The Live View</h2>

<p>Here is first what the live view looks like, it’s pretty straightforward and does not change much from a normal list.</p>

<p><code>@records</code> here only contains the first page of records (so a maximum of 40 records in my case), this is used to display data when loading the page so that the user can interact directly with the list without waiting for the first page to load.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td><pre><span>&lt;div</span> <span>class=</span><span>"bg-white flex-1 h-100 lg:block x-space-y-2 overflow-auto relative h-full"</span>
         <span>id=</span><span>"scroll-</span><span>&lt;%=</span> <span>@wallet</span><span>.</span><span>id</span> <span>%&gt;</span><span>"</span>
         <span>phx-hook=</span><span>"InfiniteScroll"</span>
         <span>data-count=</span><span>"</span><span>&lt;%=</span> <span>@records_count</span> <span>%&gt;</span><span>"</span>
         <span>data-page-size=</span><span>"</span><span>&lt;%=</span> <span>@records_per_page</span> <span>%&gt;</span><span>"</span>
         <span>data-row-height=</span><span>"</span><span>&lt;%=</span> <span>@row_height</span> <span>%&gt;</span><span>"</span>
         <span>data-loading-block-id=</span><span>"loading-block"</span><span>&gt;</span>
        <span>&lt;%=</span> <span>for</span> <span>record</span> <span>&lt;-</span> <span>@records</span> <span>do</span> <span>%&gt;</span>
          <span>&lt;%=</span> <span>render</span><span>(</span><span>MavioWeb</span><span>.</span><span>LayoutView</span><span>,</span> <span>"record.html"</span><span>,</span>
               <span>conn:</span> <span>@socket</span><span>,</span>
               <span>record:</span> <span>record</span><span>,</span>
               <span>locale:</span> <span>@locale</span><span>,</span>
               <span>timezone:</span> <span>@timezone</span><span>,</span>
               <span>wallet:</span> <span>@wallet</span><span>,</span>
               <span>row_height:</span> <span>@row_height</span>
             <span>)</span> <span>%&gt;</span>
        <span>&lt;%</span> <span>end</span> <span>%&gt;</span>
    <span>&lt;/div&gt;</span>

    <span>&lt;!-- 
        here is the loading block, this is the block which is used when the data is still loading.
        This is the "pulse" animation you can see on the video when scrolling.
     --&gt;</span>
    <span>&lt;div</span> <span>id=</span><span>"loading-block"</span> <span>class=</span><span>"hidden"</span> <span>aria-hidden=</span><span>"true"</span><span>&gt;</span>
      <span>&lt;div</span> <span>class=</span><span>"animate-pulse rounded p-5 bg-white"</span> <span>style=</span><span>"height: </span><span>&lt;%=</span> <span>@row_height</span> <span>%&gt;</span><span>px"</span><span>&gt;</span>
           <span>&lt;div</span> <span>class=</span><span>"flex space-x-3"</span><span>&gt;</span>

              <span>&lt;svg</span> <span>xmlns=</span><span>"http://www.w3.org/2000/svg"</span> <span>viewBox=</span><span>"0 0 24 24"</span> <span>class=</span><span>"w-8 mr-2 icon-receipt"</span><span>&gt;&lt;path</span> <span>class=</span><span>"primary"</span> <span>d=</span><span>"M9 18.41l-2.3 2.3a1 1 0 0 1-1.4 0l-2-2A1 1 0 0 1 3 18V5c0-1.1.9-2 2-2h14a2 2 0 0 1 2 2v13a1 1 0 0 1-.3.7l-2 2a1 1 0 0 1-1.4 0L15 18.42l-2.3 2.3a1 1 0 0 1-1.4 0L9 18.4z"</span><span>&gt;&lt;/path&gt;&lt;path</span> <span>class=</span><span>"secondary"</span> <span>d=</span><span>"M7 7h10a1 1 0 0 1 0 2H7a1 1 0 1 1 0-2zm0 4h10a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2z"</span><span>&gt;&lt;/path&gt;</span>
              <span>&lt;/svg&gt;</span>
              <span>&lt;div</span> <span>class=</span><span>"flex flex-col w-56"</span><span>&gt;</span>
                <span>&lt;div</span> <span>class=</span><span>"h-4 bg-blue-100 rounded mb-1"</span><span>&gt;&lt;/div&gt;</span>
                <span>&lt;div</span> <span>class=</span><span>"h-4 bg-blue-100 rounded w-5/6"</span><span>&gt;&lt;/div&gt;</span>
              <span>&lt;/div&gt;</span>
          <span>&lt;/div&gt;</span>
       <span>&lt;/div&gt;</span>
      <span>&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, I’ve kept the live view as simple as possible, I’ve created a bunch of additional attributes that are used in the javascript:</p>

<ul>
  <li><code>data-count</code> contains the total number of items, this is helpfull for <em>fattable.js</em> to calculate the total height of the div.</li>
  <li><code>data-page-size</code> is the chunk size which we’re loading the items with, I’m setting it to 40 for my use case but it depends of what you are building, you might want a lower page size if retreiving the data is very expensive.</li>
  <li><code>data-row-height</code> is the row height in pixels. Unlike a traditional list, with this method, we need to have every row at the exact same height.</li>
  <li><code>data-loading-block-id</code> is an id linking to the HTML which is used when loading the data, it’s what’s using the “pulse” animation in the video.</li>
</ul>



<p>The main chunk of the code is in the new <a rel="nofollow noopener noreferrer" target="_blank" href="https://gist.github.com/alex-min/7c3f008f1614fc3448717b32e122bad7">InfiniteScroll Hook</a>, it handles the link between the fattable.js library and the Live View. I’ve commented every part to make it easier to follow:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
</pre></td><td><pre><span>require</span><span>(</span><span>'</span><span>fattable/fattable.js</span><span>'</span><span>);</span>


<span>/* 
 * This variable is used to keep the scroll position when the live view navigation changes.
 * This is useful for modals.
*/</span>
<span>let</span> <span>keepScroll</span> <span>=</span> <span>{};</span>

<span>export</span> <span>default</span> <span>{</span>
    <span>mounted</span><span>()</span> <span>{</span>
        <span>/*
         * Here we're loading the first page which is already rendered in the HTML 
         */</span>
        <span>var</span> <span>firstBlock</span> <span>=</span> <span>[];</span>
        <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>this</span><span>.</span><span>el</span><span>.</span><span>children</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
            <span>firstBlock</span><span>.</span><span>push</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>children</span><span>[</span><span>i</span><span>].</span><span>outerHTML</span><span>);</span>
        <span>}</span>

        <span>/* 
         *  All the attributes are mapped from what we sent in the live view 
         */</span>
        <span>const</span> <span>numberOfRows</span> <span>=</span> <span>parseInt</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>data-count</span><span>'</span><span>));</span>
        <span>const</span> <span>pageSize</span> <span>=</span> <span>parseInt</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>data-page-size</span><span>'</span><span>));</span>
        <span>const</span> <span>rowHeight</span> <span>=</span> <span>parseInt</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>data-row-height</span><span>'</span><span>));</span>
        <span>const</span> <span>loadingBlock</span> <span>=</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>data-loading-block-id</span><span>'</span><span>)).</span><span>innerHTML</span><span>;</span>

        <span>let</span> <span>painter</span> <span>=</span> <span>new</span> <span>fattable</span><span>.</span><span>Painter</span><span>();</span>

        <span>painter</span><span>.</span><span>fillCell</span> <span>=</span> <span>(</span><span>cellDiv</span><span>,</span> <span>data</span><span>)</span> <span>=&gt;</span> <span>cellDiv</span><span>.</span><span>innerHTML</span> <span>=</span> <span>data</span><span>.</span><span>content</span><span>;</span>   <span>// filling the data when it's received</span>
        <span>painter</span><span>.</span><span>fillCellPending</span> <span>=</span> <span>(</span><span>cellDiv</span><span>)</span> <span>=&gt;</span> <span>cellDiv</span><span>.</span><span>innerHTML</span> <span>=</span> <span>loadingBlock</span><span>;</span>  <span>// the loading block when there's no data</span>

        <span>let</span> <span>tableModel</span> <span>=</span> <span>new</span> <span>fattable</span><span>.</span><span>PagedAsyncTableModel</span><span>();</span>

        <span>tableModel</span><span>.</span><span>cellPageName</span> <span>=</span> <span>(</span><span>i</span><span>)</span> <span>=&gt;</span> <span>(</span><span>i</span> <span>/</span> <span>pageSize</span><span>)</span> <span>|</span> <span>0</span><span>;</span>
        <span>tableModel</span><span>.</span><span>hasColumn</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>true</span><span>;</span>
        <span>tableModel</span><span>.</span><span>columnHeaders</span> <span>=</span> <span>[</span><span>"</span><span>Transaction</span><span>"</span><span>];</span> 
        <span>tableModel</span><span>.</span><span>getHeader</span> <span>=</span> <span>(</span><span>i</span><span>,</span> <span>cb</span><span>)</span> <span>=&gt;</span> <span>cb</span><span>(</span><span>tableModel</span><span>.</span><span>columnHeaders</span><span>[</span><span>i</span><span>]);</span>


        <span>/*
         * This is where we fetch the current page to render the header
         * We're using Live View events instead of HTTP requests since the socket is already opened
         * If it's the first page, we render the elements we gathered already from the server side rendering, no need to fetch them again
         */</span>
        <span>tableModel</span><span>.</span><span>fetchCellPage</span> <span>=</span> <span>(</span><span>offset</span><span>,</span> <span>cb</span><span>)</span> <span>=&gt;</span> <span>{</span>
            <span>if</span> <span>(</span><span>offset</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
                <span>cb</span><span>(</span><span>function</span> <span>(</span><span>i</span><span>)</span> <span>{</span>
                    <span>return</span> <span>{</span>
                        <span>rowId</span><span>:</span> <span>i</span><span>,</span>
                        <span>content</span><span>:</span> <span>firstBlock</span><span>[</span><span>i</span><span>]</span>
                    <span>}</span>
                <span>});</span>
            <span>}</span> <span>else</span> <span>{</span>
                <span>this</span><span>.</span><span>pushEventTo</span><span>(</span><span>`#</span><span>${</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>}</span><span>`</span><span>,</span> <span>"</span><span>load-table</span><span>"</span><span>,</span> <span>{</span> <span>offset</span><span>:</span> <span>offset</span> <span>});</span>
                <span>this</span><span>.</span><span>handleEvent</span><span>(</span><span>`</span><span>${</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>}</span><span>-receive-table-</span><span>${</span><span>offset</span><span>}</span><span>`</span><span>,</span> <span>payload</span> <span>=&gt;</span> <span>{</span>
                    <span>cb</span><span>(</span><span>function</span> <span>(</span><span>i</span><span>)</span> <span>{</span>
                        <span>return</span> <span>{</span>
                            <span>rowId</span><span>:</span> <span>i</span><span>,</span>
                            <span>content</span><span>:</span> <span>payload</span><span>.</span><span>html</span><span>[</span><span>i</span> <span>-</span> <span>payload</span><span>.</span><span>offset</span> <span>*</span> <span>pageSize</span><span>]</span>
                        <span>}</span>
                    <span>});</span>
                <span>});</span>
            <span>}</span>
        <span>}</span>

        <span>/* 
         * This is used to resize the list if the window size changes 
         */</span>
        <span>let</span> <span>getColumnWidth</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
            <span>return</span> <span>[</span><span>this</span><span>.</span><span>el</span><span>.</span><span>getClientRects</span><span>()[</span><span>0</span><span>].</span><span>width</span><span>];</span>
        <span>}</span>

        <span>this</span><span>.</span><span>table</span> <span>=</span> <span>fattable</span><span>({</span>
            <span>container</span><span>:</span> <span>`#</span><span>${</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>}</span><span>`</span><span>,</span>
            <span>model</span><span>:</span> <span>tableModel</span><span>,</span>
            <span>nbRows</span><span>:</span> <span>numberOfRows</span><span>,</span>
            <span>rowHeight</span><span>,</span>
            <span>headerHeight</span><span>:</span> <span>0</span><span>,</span>
            <span>painter</span><span>,</span>
            <span>columnWidths</span><span>:</span> <span>getColumnWidth</span><span>()</span>
        <span>});</span>

        <span>window</span><span>.</span><span>addEventListener</span><span>(</span><span>'</span><span>resize</span><span>'</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>{</span>
            <span>this</span><span>.</span><span>table</span><span>.</span><span>columnWidths</span> <span>=</span> <span>getColumnWidth</span><span>()</span>
        <span>});</span>

        <span>/*
         * We set the scroll to where it was before, this object isn't stored in the localStorage,
         * this is by design, we want the list to be scrolled top when the user actually reloads the page, same as an actual list.
         */</span>
        <span>if</span> <span>(</span><span>keepScroll</span><span>[</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>])</span> <span>{</span>
            <span>this</span><span>.</span><span>table</span><span>.</span><span>scroll</span><span>.</span><span>setScrollXY</span><span>(</span><span>0</span><span>,</span> <span>keepScroll</span><span>[</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>]);</span>
        <span>}</span>
    <span>},</span>

    <span>/*
     * This will be called before the table is destroyed to save the scroll position, this is very useful for modals.
     */</span>
    <span>beforeDestroy</span><span>()</span> <span>{</span>
        <span>keepScroll</span><span>[</span><span>this</span><span>.</span><span>el</span><span>.</span><span>id</span><span>]</span> <span>=</span> <span>this</span><span>.</span><span>table</span><span>.</span><span>scroll</span><span>.</span><span>scrollTop</span><span>;</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>And we load the hook in the LiveSocket, like any other Live View hook:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td><pre><span>import</span> <span>{</span> <span>LiveSocket</span> <span>}</span> <span>from</span> <span>"</span><span>phoenix_live_view</span><span>"</span><span>;</span>
<span>import</span> <span>InfiniteScroll</span> <span>from</span> <span>'</span><span>./hooks/InfiniteScroll</span><span>'</span><span>;</span>

<span>/* ... */</span>

<span>let</span> <span>csrfToken</span> <span>=</span> <span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"</span><span>meta[name='csrf-token']</span><span>"</span><span>).</span><span>getAttribute</span><span>(</span><span>"</span><span>content</span><span>"</span><span>)</span>
<span>let</span> <span>liveSocket</span> <span>=</span> <span>new</span> <span>LiveSocket</span><span>(</span><span>"</span><span>/live</span><span>"</span><span>,</span> <span>Socket</span><span>,</span> <span>{</span>
    <span>hooks</span><span>:</span> <span>{</span>
        <span>InfiniteScroll</span>
    <span>},</span>
    <span>params</span><span>:</span> <span>{</span>
        <span>_csrf_token</span><span>:</span> <span>csrfToken</span><span>,</span>
    <span>}</span>
<span>});</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="the-elixir-side-of-things">The Elixir side of things</h2>

<p>Most of the code being on the hook, the Elixir side is very simple, we just listen to the hook event asking for data and we reply with what is needed.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td><pre>  <span>def</span> <span>handle_event</span><span>(</span>
        <span>"load-table"</span><span>,</span>
        <span>%{</span><span>"offset"</span> <span>=&gt;</span> <span>offset</span><span>},</span>
        <span>%{</span><span>assigns:</span> <span>%{</span><span>user:</span> <span>user</span><span>,</span> <span>wallet:</span> <span>wallet</span><span>,</span> <span>locale:</span> <span>locale</span><span>,</span> <span>timezone:</span> <span>timezone</span><span>}}</span> <span>=</span> <span>socket</span>
      <span>)</span> <span>do</span>
    <span>{</span><span>:noreply</span><span>,</span>
     <span>socket</span>
     <span>|&gt;</span> <span>push_event</span><span>(</span>
       <span>"scroll-</span><span>#{</span><span>wallet</span><span>.</span><span>id</span><span>}</span><span>-receive-table-</span><span>#{</span><span>offset</span><span>}</span><span>"</span><span>,</span>
       <span>%{</span>
         <span>offset:</span> <span>offset</span><span>,</span>
         <span>html:</span>
           <span>list_records_from_wallet</span><span>(</span>
             <span>user:</span> <span>user</span><span>,</span>
             <span>wallet_id:</span> <span>wallet</span><span>.</span><span>id</span><span>,</span>
             <span>page:</span> <span>offset</span> <span>+</span> <span>1</span><span>,</span>
             <span>per_page:</span> <span>@records_per_page</span>
           <span>)</span>
           <span>|&gt;</span> <span>Enum</span><span>.</span><span>map</span><span>(</span><span>fn</span> <span>record</span> <span>-&gt;</span>
             <span>render_to_string</span><span>(</span><span>MavioWeb</span><span>.</span><span>LayoutView</span><span>,</span> <span>"record.html"</span><span>,</span>
               <span>conn:</span> <span>socket</span><span>,</span>
               <span>record:</span> <span>record</span><span>,</span>
               <span>locale:</span> <span>locale</span><span>,</span>
               <span>timezone:</span> <span>timezone</span><span>,</span>
               <span>wallet:</span> <span>wallet</span><span>,</span>
               <span>row_height:</span> <span>@row_height</span>
    …</pre></td></tr></tbody></table></code></pre></div></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alex-min.fr/phoenix-live-view-very-large-list-hook/">https://alex-min.fr/phoenix-live-view-very-large-list-hook/</a></em></p>]]>
            </description>
            <link>https://alex-min.fr/phoenix-live-view-very-large-list-hook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715878</guid>
            <pubDate>Sun, 10 Jan 2021 15:54:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Automatically Generating Algorithmic Art]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715850">thread link</a>) | @coolvision
<br/>
January 10, 2021 | https://grgv.xyz/creative_code_synthesis/ | <a href="https://web.archive.org/web/*/https://grgv.xyz/creative_code_synthesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://grgv.xyz/creative_code_synthesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715850</guid>
            <pubDate>Sun, 10 Jan 2021 15:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning's Most Important Ideas – A Brief Historical Review]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25715318">thread link</a>) | @coolvision
<br/>
January 10, 2021 | https://dennybritz.com/blog/deep-learning-most-important-ideas/ | <a href="https://web.archive.org/web/*/https://dennybritz.com/blog/deep-learning-most-important-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The goal of this post is to review well-adopted ideas that have stood the test of time. I will present a small set of techniques that cover a lot of basic knowledge necessary to understand modern Deep Learning research. If you're new to the field, these are a great starting point.</p><div id="post-content"><p>Deep Learning is an extremely fast-moving field and the huge number of research papers and ideas can be overwhelming. Even seasoned researchers have a hard time telling company PR from real breakthroughs. The goal of this post is to review those ideas that have <strong>stood the test of time</strong>, which is perhaps the only significance test one should rely on. These ideas, or improvements of them, have been used over and over again. They're known to work.</p> <p>If you were to start in Deep Learning today, understanding and implementing each of these techniques would give you an excellent foundation for understanding recent research and working on your own projects. It's what I believe the best way to get started. Working through papers in historical order is also a useful exercise to understand where the current techniques come from and why they were invented in the first place. <strong><strong>Put another way, I will try to present a <em>minimal set</em> of ideas that most of the basic knowledge necessary to understand modern Deep Learning research.</strong></strong></p> <p>A rather unique thing about Deep Learning is that its application domains (Vision, Natural Language, Speech, RL, etc) share the majority of techniques. For example, someone who has worked in Deep Learning for Computer Vision his whole career could quickly be productive in NLP research. The specific network architectures may differ, but the concepts, approaches and code are mostly the same. I will try to present ideas from various fields, but there are a few caveats about this list:</p> <ul> <li>My goal is not to give in-depth explanations or code examples for these techniques. It's not easily possible to summarize long complex papers into a single paragraph. Instead, I will give a brief overview of each technique, its historical context, and links to papers and implementations. If you want to learn something, I <em>highly recommend</em> trying to re-produce some of these paper results from scratch in raw <a href="https://pytorch.org/">PyTorch</a> without using existing code bases or high-level libraries.</li> <li>The list is biased towards my own knowledge and the fields I am familiar with. There are many exciting subfields that I don't have experience with. I will stick to what most people would consider the popular mainstream domains of Vision, Natural Language, Speech, and Reinforcement Learning / Games.</li> <li>I will only discuss research that has official or semi-official open source implementations that are known to work well. Some research isn't easily reproducible because it involves huge engineering challenges, for example <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">DeepMind's AlphaGo</a> or <a href="https://openai.com/projects/five/">OpenAI's Dota 2 AI</a>, so I won't highlight it here.</li> <li>Some choices are arbitrary. Often, rather similar techniques are published at around the same time. The goal of this post is not be a comprehensive review, but to to expose someone new to the field to a cross-section of ideas that cover a lot of ground. For example, there may be hundreds of GAN variations, but to understand the general concept of GANs, it really doesn't matter which one you study.</li> </ul>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep Convolutional Neural Networks (2012)</a> <span data-cites="krizhevsky_imagenet_2012">Krizhevsky, Sutskever, and Hinton (2012)</span></li> <li><a href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature detectors (2012)</a> <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span></li> <li><a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks (2014)</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/hub/pytorch_vision_alexnet">AlexNet in PyTorch</a></li> <li><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/alexnet.py">AlexNet in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/alexnet-full.png" alt=""><figcaption>Source: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a></figcaption> </figure> <p>AlexNet is often considered the algorithm responsible for the recent boom in Deep Learning and Artificial Intelligence research. It is a Deep Convolutional Neural Network based on the earlier LeNet developed by Yann LeCun. AlexNet beat previous methods at classifying images from the <a href="http://image-net.org/index">ImageNet dataset</a> by a significant margin through a combination of GPU power and algorithmic advances. It demonstrated that neural networks actually work! AlexNet was also one of the first times Dropout <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span> was used, which has since become a crucial component for improving the generalization ability of all kinds of Deep Learning models.</p> <p>The architecture used by AlexNet, a sequence of Convolutional layers, ReLU nonlinearity, and max-pooling, became the accepted standard that future Computer Vision architectures would extend and built upon. These days, software libraries such as PyTorch are so powerful, and compared to more recent architectures AlexNet is so simple, that it can be implemented in only a few lines of code. Note that many implementations of AlexNet, such as those linked above, use the slight variation of the network described in <a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span>.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning (2013)</a> <span data-cites="mnih_playing_2013">Mnih et al. (2013)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html">DQN in PyTorch</a></li> <li><a href="https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial">DQN in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/deep-q-learning-value.png" alt=""><figcaption>Source: <a href="https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning">https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning</a></figcaption> </figure> <p>Building on top of the recent breakthroughs in image recognition and GPUs, a team at DeepMind managed to train a network to <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">play Atari Games</a> from raw pixel inputs. What's more, the <em>same</em> neural network architecture learned to play seven different games without being told any game-specific rules, demonstrating the generality of the approach.</p> <p>Reinforcement Learning differs from Supervised Learning, such as image classification, in that an agent must learn maximize to the sum of rewards over multiple time steps, such as winning a game, instead of just predicting a label. Because the agent interacts directly with the environment and each action affects the next, the training data is not independent and identically distributed (iid), which makes the training of many Machine Learning models quite unstable. This was solved by using techniques such as experience replay <span data-cites="lin_self-improving_1992">Lin (1992)</span>.</p> <p>While there was no obvious algorithmic innovation that made this work, the research cleverly combined existing techniques, convolutional neural networks trained on GPUs and experience replay, with a few data processing tricks to achieve impressive results that most people would not have expected. This gave people confidence in extending Deep Reinforcement Learning techniques to tackle even more complex tasks such as <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">Go</a>, <a href="https://openai.com/projects/five/">Dota 2</a>, <a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">Starcraft 2</a>, and others.</p> <p>Atari Games <span data-cites="bellemare_arcade_2013">Bellemare et al. (2013)</span> have since become a standard benchmark in Reinforcement Learning research. The initial approach only solved (beat human baselines on) seven games, but over the coming years advances built on top of these ideas would start beating humans on an ever increasing number of games. One particular game, Montezuma’s Revenge, was famous for requiring long-term planning and was considered to be among the most difficult to solve. It was only recently <span data-cites="badia_agent57_2020">Badia et al. (2020)</span> <span data-cites="ecoffet_first_2020">Ecoffet et al. (2020)</span> that techniques managed to beat human baselines on all 57 games.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a> <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span></li> <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#">Seq2Seq with Attention in PyTorch</a></li> <li><a href="https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt">Seq2Seq with Attention in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/seq2seq-cn.gif" alt=""><figcaption>Source: <a href="https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html">https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html</a></figcaption> </figure> <p>Deep Learning's most impressive results had largely been on vision-related tasks and was driven by Convolutional Neural Networks. While the NLP community had success with <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Language Modeling</a> and Translation using LSTM networks <span data-cites="hochreiter_long_1997">Hochreiter and Schmidhuber (1997)</span> and Encoder-Decoder architectures <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span>, it was not until the invention of the <strong>attention</strong> mechanism <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span> that things started to work spectacularly well.</p> <p>When processing language, each token, which could be a character, a word, or something in between, is fed into a recurrent network, such as an LSTM, which maintains a kind of memory of previously processed inputs. In other words, a sentence is very similar to a time series with each token being a time step. These recurrent models often had difficulty dealing with dependencies over long time horizons. When they process a sequence, they would easily "forget" earlier inputs because their gradients needed to propagate through many time steps. Optimizing these models with gradient descent was hard.</p> <p>The new attention mechanism helped alleviate the problem. It gave the network an option to adaptively "look back" at earlier time steps by introducing shortcut connections. These connections allowed the network to decide which inputs are important when producing a specific output. The canonical example is translation: When producing an output word, it typically maps to one or more specific input words.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a> <span data-cites="kingma_adam_2017">Kingma and Ba (2017)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://d2l.ai/chapter_optimization/adam.html">Implementing Adam in Python</a></li> <li><a href="https://pytorch.org/docs/master/_modules/torch/optim/adam.html">PyTorch Adam implementation</a></li> <li><a href="https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/optimizer_v2/adam.py#L32-L281">TensorFlow Adam implementation</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/optimizer-benchmark.png" alt=""><figcaption>Source: <a href="http://arxiv.org/abs/1910.11758">http://arxiv.org/abs/1910.11758</a></figcaption> </figure> <p>Neural networks are trained by minimizing a loss function, such as the average classification error, using an optimizer. The optimizer is responsible for figuring out how to adjust the parameters of the network to make it learn the objective. Most optimizers are <a href="https://ruder.io/optimizing-gradient-descent/">based on variations of Stochastic Gradient Descent (SGD)</a>. However, many of these optimizers contain tunable parameters such as a learning rate themselves. Finding the right settings for a specific problem not only reduces training time, but can also lead to better results due to finding a better local minimum of the loss function.</p> <p>Big resarch labs often ran expensive hyperparameter searches that came up with complex learning rate schedules to get the best out of simple but hyperparameter-sensitive optimizers such as SGD. When they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dennybritz.com/blog/deep-learning-most-important-ideas/">https://dennybritz.com/blog/deep-learning-most-important-ideas/</a></em></p>]]>
            </description>
            <link>https://dennybritz.com/blog/deep-learning-most-important-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715318</guid>
            <pubDate>Sun, 10 Jan 2021 15:09:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Socialist Calculation Debate: Reckoning with Mises]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25715114">thread link</a>) | @bwestergard
<br/>
January 10, 2021 | http://socialistplanning.org/posts/reckoning-with-mises | <a href="https://web.archive.org/web/*/http://socialistplanning.org/posts/reckoning-with-mises">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<header>


</header>
<p>Have you heard of the “<a href="https://en.wikipedia.org/wiki/Socialist_calculation_debate">socialist calculation debate</a>”? There are many brief essays intended to introduce a general audience to it, often expressly written to vindicate the doctrines of one political tendency or another. If you read a few of these, you will quickly notice they tend to repeat one of three stories about the debate:</p>
<ol type="1">
<li><p>Austrian economists like <a href="https://en.wikipedia.org/wiki/Ludwig_von_Mises">Mises</a> and <a href="https://en.wikipedia.org/wiki/Friedrich_Hayek">Hayek</a> foresaw the problems a socialist society would encounter. In a few short years, the Soviet Union and its imitators in fact encountered precisely these problems. Despite this confirmation of the essentially validity of the Austrian perspective, many today persist in pursuing socialism (or policies tantamount to socialism) out of ignorance<a href="#fn1" id="fnref1"><sup>1</sup></a>.</p></li>
<li><p>Late nineteenth and early twentieth century Marxist theorists had an interesting critiques of capitalist society, but no institutional blueprint to guide socialist construction. Austrian economists came along and pointed out this embarassing absence, at which point it fell to economists of a neoclassical bent and progressive sympathies (like <a href="https://en.wikipedia.org/wiki/Oskar_R._Lange">Lange</a>, <a href="https://en.wikipedia.org/wiki/Abba_P._Lerner">Lerner</a>, and <a href="https://en.wikipedia.org/wiki/Fred_M._Taylor">Taylor</a>) to fill the gap. They showed, in varying ways, that the conceptual resources of neoclassical economics are not only useful for analyzing any society regardless of its political character, property relations, etc. but can be drawn upon to devise planning institutions for socialism. Socialism was and remains entirely possible in principle. Economists cannot claim any special authority in evaluating its desirability.<a href="#fn2" id="fnref2"><sup>2</sup></a></p></li>
<li><p>Austrian economists argued that only capitalist institutions could support rational economic decision making through the price mechanism. Neoclassical economists (e.g.&nbsp;Lange, Lerner, Taylor) showed that this was not the case, and that with the right kind of institutional design, prices could be discovered that were at least as good, if not better, than those arising in contemporary capitalism. Austrians rightly pointed out that such planning bodies would have to gather and process immense amounts of information, which was a practical impossibility in the twenties and thirties. But thanks to twenty-first century information technologies, socialism has become a practical possibility.<a href="#fn3" id="fnref3"><sup>3</sup></a></p></li>
</ol>
<p>These stories about the debate substantially contradict one another, and cannot all be accurate. At best they neglect interesting arguments<a href="#fn4" id="fnref4"><sup>4</sup></a>.</p>
<p>Rather than immediately add my own “take” to the pile, I’d like to use this series of blog posts to do a close reading of the primary texts of the debate<a href="#fn5" id="fnref5"><sup>5</sup></a> in the order they were published.</p>
<p>The obvious place to start is Ludwig von Mises’ 1920 essay, <em>Die Wirtschaftsrechnung im sozialistischen Gemeinwesen</em><span data-cites="Mises_1920"><a href="#fn6" id="fnref6"><sup>6</sup></a></span>, which is agreed by all commentators to be the start of the debate as it we know it today.</p>
<p>The title is generally translated as “Economic Calculation in the Socialist Commonwealth”, but “Wirtschaftsrechnung” might just as well be translated as “economic reckoning”. This is supported by the shared etymology of “rechnung” and “reckon”, but I also prefer it because “reckoning”, unlike “calculation”, seems more inclusive of the humdrum, ad hoc, non-expert, a relatively atheoretical kinds of quantitative reasoning that Mises often seems to have in mind (e.g.&nbsp;the “reckoning” of a farmer deciding whether to replace a tractor).</p>
<p>In this post, I’ll summarize the essay and provide a bit of context. I’ll refrain from discussing anticipations of Mises’ arguments by other writers, his later work, or critical responses. I hope to discuss each of these topics in future posts.</p>
<h2 id="historical-context">Historical context</h2>
<p>First, a note on the context in which Mises wrote.</p>
<p>A little over a century ago, the first world war triggered a working class rebellion. For decades, socialist, communist, and anarchist workers across globe had been organizing to free themselves from the domination of the owning classes and their political representatives. It appeared they might be on the cusp of doing so in Germany and Russia.</p>
<p>A minority among these militants called for the immediate expropriation of the fields, factories, and workshops by democratically elected councils of workers, soldiers, and sailors. It appeared for a fleeting moment that this tendency would achieve a breakthrough in Germany, as many had predicted. But those hopes fizzled as the <a href="https://en.wikipedia.org/wiki/German_Revolution_of_1918%E2%80%931919">German uprisings were suppressed and the ill-fated Weimar Republic was founded</a> with the backing of socialists committed to a more gradual path away from capitalism.</p>
<p>Instead, the breakthrough came under Bolshevik leadership in Russia in October of 1917. Contrary to all expectations, the Bolsheviks prevailed in the ruinous civil war that followed and went on to found the Union of Soviet Socialist Republics in 1921. “soviet” being the Russian term for “[worker] council”, this was the first state nominally committed to the principle that the mass of working people could not only democratically govern their places of work, but the entire “economic” apparatus of their society. Many politically conscious workers and professional intellectuals the world over viewed the Soviet experiment sympathetically, as an extension of their own political projects<span data-cites="Foner_1967"><a href="#fn7" id="fnref7"><sup>7</sup></a></span>. Mises felt socialism was on the rise<span data-cites="Mises_1920"><a href="#fn8" id="fnref8"><sup>8</sup></a></span>:</p>
<blockquote>
<p>In an age in which we are getting nearer and nearer to socialism, and even in a certain sense are already there, research into the problems of the socialist economy acquires added importance for explaining what is going on around us. Analyses of the exchange economy no longer suffice for understanding economic developments in Germany and its eastern neighbors today. Our task here is to discuss elements of a socialist commonwealth with a considerably wide scope. Under these circumstances, an attempt to explain the nature of socialist society needs no special justification.</p>
</blockquote>
<h2 id="mises-intervention">Mises’ intervention</h2>
<p>In 1920, it was not hard to find journalists, politicians, and religious leaders who were decrying Bolshevik efforts to abolish private property in the means of production as profoundly unjust.</p>
<p>For Mises, to leave the argument there was to miss a more fundamental issue. In his view, the radical workers’ program wasn’t <em>just</em> ethically objectionable and fraught with practical difficulties. It was incoherent, a wish born of deep confusion about how capitalist societies managed to deliver the goods. To abolish private property was to the undermine the institutional prerequisites for rational coordination of industrial production and stewardship of natural resources. The pursuit of socialism was likely to lead to the decline of rational thought as such<a href="#fn9" id="fnref9"><sup>9</sup></a>:</p>
<blockquote>
<p>There would be no means of determining what is rational, and hence production could never deliberately be focused on economic efficiency. The impact of this is clear, even beyond the implications for the provision of goods to men: the purpose of the market would be driven out of the very ground that is its proper domain. Would there be any such thing as a rational market at all, or indeed would thought be rational and logical? Historically, human reason developed out of economic life. Could it then hold on at all when driven away of this?</p>
</blockquote>
<h2 id="die-wirtschaftsrechnung-summarized"><em>Die Wirtschaftsrechnung…</em> summarized</h2>
<p>This gist of Mises’ essay is as follows<a href="#fn10" id="fnref10"><sup>10</sup></a>.</p>
<p>In capitalist societies, those who wish to make money by producing goods or services can only acquire the specific means of production they require to do so (e.g.&nbsp;land, buildings, raw materials, machinery) by offering their current owners more than rivals<a href="#fn11" id="fnref11"><sup>11</sup></a> who have alternative money-making plans for them.</p>
<p>By competing with one another for access to the means of production, and for market-share among consumers (who may themselves be businesses), the principals of private enterprises or their agents are constantly altering prevailing prices. They do so on the basis of their reckoning of productive possibilities (e.g. “maybe we could make the body of a mid-sized car out of injection-molded plastic”), specifics of time and place (e.g. “the market is glutted with moulding machines right now due to the failure of a few firms that used them”), and consumer preferences (e.g. “over the next decade, tens of millions of Americans will buy a mid-sized car and just want something cheap that won’t rust”).</p>
<p>On the basis of these reckonings they make decisions about which means of production to purchase and how to make use of them to turn a profit. Put another way, they are continuously formulating and revising business plans. These plans invariably conflict, in the sense that for some to be realized others must not be; it would be quite surprising if the annual sales targets of all auto manufacturers taken together summed to exactly the number sold in the year in question. The clash of plans in producer and consumer good markets continuously selects for profitable enterpises and tends to produce more or less stable prices for most important means of production (so-called “higher order” goods). These prices are both a product of, and influence upon, uncountable myraids of producer evaluations. They are an <em>indispensible precondition</em> for rational economic decision making.</p>
<p>Mises argues that in a socialist society in which private property has been abolished, the rivalrous clash of producer plans would necessarily cease, and thus prices <em>as we know them</em> would not be available to those organizing particular production processes. Without prices for production goods, those organizing these processes (e.g.&nbsp;making cars) could formulate plenty of technically feasible plans so long as they were assured access to the necessary inputs. But the number of such plans would be overwhelming.</p>
<p>When all production goods have a price in some common unit, anticipated marginal costs can be summed and compared with anticipated marginal revenues. If costs exceed revenues, the plan can be rejected immediately (“sure, we can make the body of the car out of titanium and be sure it won’t rust, but it would triple the cost of the car and the number of buyers would plummet to basically zilch!”). Reckonings in terms of monetary cost do not uniquely …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://socialistplanning.org/posts/reckoning-with-mises">http://socialistplanning.org/posts/reckoning-with-mises</a></em></p>]]>
            </description>
            <link>http://socialistplanning.org/posts/reckoning-with-mises</link>
            <guid isPermaLink="false">hacker-news-small-sites-25715114</guid>
            <pubDate>Sun, 10 Jan 2021 14:53:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The many lies about reducing complexity part 2: Cloud]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 115 (<a href="https://news.ycombinator.com/item?id=25714822">thread link</a>) | @rapnie
<br/>
January 10, 2021 | https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/ | <a href="https://web.archive.org/web/*/https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The world has been getting a lot more complex, most people will agree to that. A major element in that rising complexity has been the <a href="https://ea.rna.nl/2020/02/11/a-tipping-point-in-the-information-revolution/">insanely huge amounts of machine logic we human species have been adding to the world</a>. Both that logic itself, as what it enables — think globalisation of trade and communication — has made most of our lives more complex and complicated in one way or another. And while it has brought us much, it also has a serious <a href="https://ea.rna.nl/2020/03/04/gossip-trust-and-the-information-revolution/">number of unwanted side-effects</a>.</p>



<p>We run into the boundaries of our ability to handle that complexity on a daily basis. Be it the large IT projects that invariably run late, cost too much, maybe even straight out fail. Or how we must try to stay secure in a digital world full of brittleness of logic and the weaknesses of humans.</p>



<p>[Note 1: This article is meant to be understandable (with a bit of effort) by non-specialists. There is quite a bit of jargon in it, but I try my best to explain all of it, including a table below with extensive explanation of a number of key terms. If I don’t explain a term, it is safe to ignore it if you don’t know what it is (e.g. when I mention a ‘tomcat server’ as an example), it is helpful for those that know, but not really necessary to know what it is to follow the story]</p>



<p>So, it isn’t a surprise that in IT, a constant drive over the last decennia has been the drive to reduce complexity. <em>‘Reducing complexity’ sells.</em> Especially managers in IT are sensitive to it as complexity generally is their biggest headache. Hence, in IT, people are in a perennial fight to make the complexity bearable. One method that has been popular for decennia has been standardisation and rationalisation of the digital tools we use, a basic “let’s minimise the number of applications we use”. This was actually part 1 of this story: <a href="https://ea.rna.nl/2016/01/10/a-tale-of-application-rationalization-not/">A tale of application rationalisation (not)</a>. That story from 2015 explains how many rationalisation efforts were partly lies. (And while we’re at it: enjoy <a rel="noreferrer noopener" href="http://dilbert.com/strip/2011-01-07" target="_blank">this Dilbert cartoon</a> that is referenced therein.) Most of the time multiple <em>applications</em> were replaced by a single <em>platform</em> (in short: a platform is software that can run other software) and the <em>applications</em> had to be ‘rewritten’ to work ‘inside’ that platform. So you ended up with one <em>extra</em> platform, the <em>same</em> number of applications and generally a few new <em>extra</em> ways of ‘programming’, specific for that platform. That doesn’t mean it is <em>all</em> lies. The new platform is generally dedicated to a certain type of application, which makes programming these applications simpler. But the situation is not as simple as the platform vendors argue. As Frederick Brooks had already told us in 1986: <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">There Is No Silver Bullet</a>.</p>



<p>Another drive has been to encapsulate (hide) complexity and access it through simpler interfaces. And a third has been to automate IT itself, creating complex ‘management IT’. All three play a role when we start to outsource IT to cloud services like Microsoft Azure or AWS.</p>



<p>[Note 2: This article has gotten out of hand. Totally. Quite long while I don’t digress a lot — as I often do. But exposing hidden complexity cannot be done by not presenting it to you. And not understanding how complex the real IT world is leads to bad outcomes. When the software for supporting the Covid-19 vaccination campaign was a few weeks(!) late because testing wasn’t done yet, I read about a leading politician state something like “Come on, a bit of testing, how hard can it be?”. That is a cringeworthy display of not understanding how complex IT is. And that is partly why I write this. Because until our leaders actually start to understand this, they will create more and more disasters out of ignorance. Back to the story.]</p>



<p>Cloud services have generally been explained (sold) to us with a graphic like this:</p>



<figure><img data-attachment-id="172827" data-permalink="https://ea.rna.nl/xaas-orthodox-1/" data-orig-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg" data-orig-size="2519,1755" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xaas-orthodox-1" data-image-description="" data-medium-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=300" data-large-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=720" src="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=1024" alt="" srcset="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=1024 1024w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=2048 2048w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=150 150w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=300 300w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-1.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Typical depiction of what is being outsourced when you move to the cloud</figcaption></figure>



<div>
<div>
<p>For non-technical people,  here is a basic explanation of terms used in the above figure and in the text.</p>



<p><span><strong>On Premises</strong></span>: Using your own hardware<br><span><strong>Application</strong></span>: Software that you use, e.g. Microsoft Word.<br><span><strong>Data</strong></span>: The data in your program, say your text in Word.<br><strong><span>Runtime</span>:</strong> Software that is required for other software to run, e.g. basic functionality for Java programs (‘Java runtime’). (Java is a programming language.)<br><span><strong>Middleware</strong></span>: More complex software that is required for other software to run but may also have its own function. E.g. a database.<br><span><strong>Operating System</strong></span>: The lowest layer of software that sits between the machine and all other software. Like Windows or macOS at home.<br><span><strong>Virtualisation</strong></span>: A way to turn one very big real ‘machine’ (computer) into many <em>virtual machines</em> by arranging multiple operating systems to share the big machine. Sharing increases efficiency because not all operating systems are busy at the same time. It also has other advantages.<br><span><strong>Server</strong></span>: The big ‘real’ machine. Like your computer at home but much bigger with multiple processors and lots of memory so it can be shared.<br><span><strong>Storage</strong></span>: Separate machine that is optimised to provide storage (disks), can be used by multiple servers. At home people sometimes have this too in the form of a NAS. These are generally ‘appliances’, that is specialised hardware (in this case with a lot of disks) with specialised software to manage them.<br><span><strong>Networking</strong></span>: Separate machine that enables data traffic between systems. Like your modem, router and Wifi Access Point at home. Again, an appliance with specialised hardware (in this case network interfaces such as wifi antennas and sockets for network cables) that has specialised software to manage these.</p>
</div>



<div>
<p>The suggestion is this: as we move away from our own IT ‘on-premises’ (which includes whatever co-hosting data center you use, in. this context it just means you own your own IT hardware) to more and more in the cloud, we are outsourcing more and more, we are responsible for less, <em>our life simplifies</em>. More cloud is cheaper, simpler and more flexible. What is there not to like?</p>



<p>What there is not to like is that this suggestion is for a large part a lie. And a nasty one.</p>



<p>Take for instance networking. According to the graphic, as soon as you move to the cloud, it’s no longer your responsibility. But that is a lie, except for the rightmost option (SAAS — more about this later). If you set up your IAAS or PAAS in the public cloud — say Microsoft Azure — you have to manage quite a bit of networking. In fact, while Microsoft runs the underlying <em>hardware</em>, much of what has to be managed, will be managed by you. You decide on segmenting, networking, VPNs (virtual private networks — a way to protect traffic between networks), routing firewalls, etc., you’re just using Azure tooling to set it up. It’s easier, but it’s far from all gone.</p>



<p>It is best explained by using an example. Suppose you open up some of your cloud-based systems to access from the public internet? You can do that. And suppose you shouldn’t have, because these systems contain sensitive data? And suppose this data is stolen in a very public breach? Who is to blame? Microsoft for providing you with enough rope to hang yourself, or you? It is clear that if this is a big news story, the heading will not be “Microsoft was lax with its security and management”, but “Company X was lax with its security and management <em>in the cloud</em>“.</p>








</div>
</div>



<p>So, the reality of the situation is therefore more like this:</p>



<figure><img data-attachment-id="172832" data-permalink="https://ea.rna.nl/xaas-orthodox-morerealistic-5/" data-orig-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg" data-orig-size="2541,1766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="xaas-orthodox-morerealistic-5" data-image-description="" data-medium-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=300" data-large-file="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=720" src="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=1024" alt="" srcset="https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=1024 1024w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=2048 2048w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=150 150w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=300 300w, https://rnaea.files.wordpress.com/2021/01/xaas-orthodox-morerealistic-5.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A slightly more realistic depiction of self-sourcing versus cloud outsourcing</figcaption></figure>



<p>The hardware — the iron — is indeed something that is completely handled by a cloud provider. This includes things like connecting the server to networks, power, etc., and replacing disk drives, fans, etc. In a fully self-sourced setup this actually turns out to be a limited affair. Most of the work is not hardware these days, it is software. Companies that run their own on-premises data centers don’t have a lot of data center hardware operators. Take the networking engineers. They may lay a few cables to a switch, but after that it is quickly moving to the management console and manage the appliance throughputs management interface — in other words: software work. Networking engineers, storage engineers, and compute engineers alike, their main tool is not a screwdriver, their main tool is a <em>keyboard</em>. Only the basic servers for virtual machines have little in terms of configuration. Networking and storage are <em>appliances</em>, specialised hardware with specialised software. The cloud provider has an interface on top of these that gives you that ‘enough rope to hang yourself with’, i.e. much of this is actually set up and maintained by you. Microsoft doesn’t create or manage your firewall settings, it only offers you an interface to create a virtual firewall running on their appliances and manage that <em>yourself</em>.  So it is a shared responsibility, and especially in networking: you do most of the work in much of the same way you would have to do when you were running your own appliances. Using a firewall in Azure is Microsoft spinning up a virtual appliance for you. And from that moment on, the work is all yours.</p>



<p>The only form of cloud where you really get rid of a lot of responsibility is Software-as-a-Service, or SAAS. That is because SAAS actually simplifies matters… …for the vendor. As explained in the EAPJ article <a href="http://eapj.org/vertical-integration-versus-horizontal-standardisation/">Vertical Integration versus (horizontal) standardisation</a>, the big advantage of SAAS is that the vendor of an application doesn’t need to support a myriad of technical landscapes out there, no myriad of different Linux versions, Java versions, as well as their configurations (security baselines, anyone?), just a single stack they fully manage themselves. That brings a huge standardisation for the vendor, and the advantage of that can be sold (in part) to the customer. Your responsibility is generally limited to a bit of Application tinkering (maybe add plugins, do some configuration) and of course your content. (And even the almost total outsourcing of SAAS is a little lie …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/">https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/</a></em></p>]]>
            </description>
            <link>https://ea.rna.nl/2021/01/10/the-many-lies-about-reducing-complexity-part-2-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714822</guid>
            <pubDate>Sun, 10 Jan 2021 14:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I ignored my slowly worsening mental health, and got hit hard by OCD (a caution)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25714408">thread link</a>) | @coolvision
<br/>
January 10, 2021 | https://grgv.xyz/ocd/ | <a href="https://web.archive.org/web/*/https://grgv.xyz/ocd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Have you seen “Aviator”, a movie with Leonardo DiCaprio about Howard Hughes? Then you might recall what an OCD is.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/2fXF8G50BPQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><strong><a href="https://en.wikipedia.org/wiki/Obsessive%E2%80%93compulsive_disorder">Obsessive–compulsive disorder</a>&nbsp;(OCD) is a&nbsp;mental disorder&nbsp;in which a person has&nbsp;certain thoughts ”repeatedly&nbsp;(called "obsessions") or feels the need to perform&nbsp;certain routines repeatedly&nbsp;(called ”compulsions") to an extent which generates distress or impairs general functioning</strong></p>
<p>I have a mild form of OCD. Had it since teenage years. It rarely bothered me, and I mainly did not care about it much. It manifested itself maybe few times per year, where I would have to re-check if the door is locked few times, for example (which does not seem like a huge burden).</p>
<p>And so, I felt great in autumn and in the first half of December. Everything was fine, I have a job that I love, great family, and hobbies that I enjoy.</p>
<p>Then, this winter came, and It got worse. I live in a northern country (Estonia), daylight time is very short, and although I don’t suffer from SAD too much usually, it might have been a factor. And I usually try to get some vacation in warmer countries, but this year did not do it because of COVID. I also started to work from home, and it probably added to the feeling of isolation and brought me down more.</p>
<p>All in all, I don’t know what were that main factors, but probably the whole combination was just a bit  too much. Occasional obsessions and compulsions started to show up more, but I mainly just shrugged them off. Then, closer to the new year, it stared to get even worse.</p>
<p><strong>And now it’s at a point where I need professional help, It's hard to work, I lost lots of weight, have bad anxiety all the time, and all the obsessions make my behaviour erratic at times.</strong> And yet another problem — its actually hard to find professional help quickly! It can be weeks or months until finding a therapist. Thakfully, I was able to secure an appointment within a weel, but not all people are as lucky.</p>
<p><em>My main mistake was not looking for warning signs of illness.</em> It was “today it’s fine, then all will be fine” attitude, which is a big mistake.</p>
<p>Yes, my case is slightly exotic, but it relates to all other mental health issues: depression, anxiety, panic attacks, etc… <a href="https://www.nimh.nih.gov/health/statistics/mental-illness.shtml">Nearly 20% of people have some form of mental illness</a>, and some of the issues might not seem like a big deal until they hit hard.</p>
<p>As a tale of caution, I have some advice, which I will follow religiously in future. This is relatively obvious and simple, but let my example be a bit of a motivation to take it more seriously.</p>
<ul>
<li>Maintain mood logging, and journal regularly. It would help to notice any anomalies and problems before they become serious. Don’t shrug off warning signs!</li>
<li>Find mental health checklists, like <a href="https://www.beyondblue.org.au/the-facts/anxiety-and-depression-checklist-k10">https://www.beyondblue.org.au/the-facts/anxiety-and-depression-checklist-k10</a>, check yourself time from time,</li>
<li>Therapy is important, especially in this times. I never did therapy, and now regret it.</li>
<li>Fitness, meditation, good diet and all kinds of self care — in this time of increased isolation it’s not just some random good habits, treating this seriously is a very important part of well-being.</li>
</ul>


			</div></div>]]>
            </description>
            <link>https://grgv.xyz/ocd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714408</guid>
            <pubDate>Sun, 10 Jan 2021 13:21:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chinese Red Flag Linux 11.0]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25714006">thread link</a>) | @schaum
<br/>
January 10, 2021 | http://pan.chinaredflag.cn/d/b16eaefee1c845bc853f/ | <a href="https://web.archive.org/web/*/http://pan.chinaredflag.cn/d/b16eaefee1c845bc853f/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://pan.chinaredflag.cn/d/b16eaefee1c845bc853f/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25714006</guid>
            <pubDate>Sun, 10 Jan 2021 12:25:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teacher creates ingenious exam question to find cheaters and catches 14 students]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25713861">thread link</a>) | @ColinWright
<br/>
January 10, 2021 | https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848 | <a href="https://web.archive.org/web/*/https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><form data-mod="skinnySignup" data-json="{&quot;mailingListId&quot;:&quot;37995&quot;,&quot;displayName&quot;:&quot;daily&quot;,&quot;callToAction&quot;:&quot;<p>Get all the very latest news in Ireland straight to your email every single day</p>&quot;,&quot;buttonText&quot;:&quot;Sign up!&quot;,&quot;contentId&quot;:6321963,&quot;newsletterImage&quot;:&quot;https://i2-prod.irishmirror.ie/incoming/article22352084.ece/BINARY/1_Covid-19-Scenes90466558.jpg&quot;,&quot;endpointUrl&quot;:&quot;https://response.pure360.com/interface/list.php&quot;,&quot;profile&quot;:&quot;Irish_Mirror&quot;,&quot;isPure360NewsLetter&quot;:true,&quot;pure360MailingListId&quot;:&quot;Irish Mirror - Daily Newsletter&quot;,&quot;newsletterSiteName&quot;:&quot;Irish Mirror&quot;}"><div><div><div><p><span><span>When you subscribe we will use the information you provide to send you these newsletters. Sometimes theyâ€™ll include recommendations for other related newsletters or services we offer. Our</span><a href="https://www.irishmirror.ie/privacy-notice/">Privacy Notice</a><span>explains more about how we use your data, and your rights. You can unsubscribe at any time.</span></span></p></div></div><p><span>Invalid Email</span></p></div></form><!-- Article Start--><p>Students who assumed their teacher 'on the older side' wouldn't be familiar with the latest cheating methods were caught red handed when he devised a brilliant method to catch them out.</p> <p>A pupil in the engineering class explained that when they all sat down to take their final exam, about half the class left the room to use the bathroom during the test - far more than the usual.</p> <p>The student said they assumed the vast majority were looking up answers on their phone, which 'irritated me' but they stayed focused and made their way through the paper.</p> <p>After leaving the exam hall, the pupil remembered there was one particular question that wasn't related to what they had all been taught in class, which had two parts - the Mirror UK reports.</p> <p>Part A was 'fairly easy' but they had no idea how to do part B, so they simply left it blank as it only accounted for 5 marks out of 100.</p> <figure data-mod="image" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="410">
<div>

<p><img data-src="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg" alt="" content="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg" src="https://i2-prod.mirror.co.uk/incoming/article11553649.ece/ALTERNATES/s615b/0_Tests-on-table.jpg">
</p>
</div>
<figcaption>
<span itemprop="author"> (Image: Tetra images RF)</span>
</figcaption>
</figure> <p>When all the exams had been marked, their teacher sent all the university students an email to explain his diabolical plan to catch out those who had given themselves some outside help.</p> <p>Many of the pupils used the internet to find answers to exam and homework questions.</p> <p>Their teacher decided to use it against them after becoming fed up with students using the bathroom as an excuse to look up answers on their phones.</p> <section data-embed-group="read-more" data-embed-items="2" data-ad-dockable="true">   </section> <p>The student wrote on Reddit: "He purposely made part B impossible to solve, and about a month before the final he got a teaching assistant to ask the exact question [online], which was distinctly worded to be unique.</p> <p>"He then created his own account and answered the question with a bulls*** solution that seems right at first glance but is actually fundamentally flawed and very unlikely that someone would make the same assumptions and mistakes independently."</p> <p>From the 99 exams handed in, 14 of them fell for the trick and gave the exact answer their own teacher had posted online.</p> <p>All were given an overall score of zero and reported to the university for violating the academic honor pledge they had signed.</p> <p>Their names were also circulated to all the other teachers in the department as known cheaters - and all the other students who hadn't cheated were given full marks for the bogus question.</p> <p>Others were impressed with cunning plan, with one replying: "This is Amazing! I've seen some stories like this and it always makes me glad I don't use [the internet] for tests.</p> <p>"Honestly if you're cheating on a proctored test you deserve to get caught. Study like everyone else."</p> <p>A second wrote: "Honey pot the cheating site. Genius!"</p><!-- Article End--></div></div>]]>
            </description>
            <link>https://www.irishmirror.ie/news/weird-news/teacher-creates-ingenious-exam-question-23228848</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713861</guid>
            <pubDate>Sun, 10 Jan 2021 12:03:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Using flamegraphs to read big HN threads]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25713858">thread link</a>) | @trungdq88
<br/>
January 10, 2021 | https://trungdq88.github.io/hn-big-threads/index.html | <a href="https://web.archive.org/web/*/https://trungdq88.github.io/hn-big-threads/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        Loading... https://news.ycombinator.com/item?id=25706993
      </p>
    </div></div>]]>
            </description>
            <link>https://trungdq88.github.io/hn-big-threads/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713858</guid>
            <pubDate>Sun, 10 Jan 2021 12:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Polar Vortex collapse sequence has begun]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 184 (<a href="https://news.ycombinator.com/item?id=25713704">thread link</a>) | @makepanic
<br/>
January 10, 2021 | https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/ | <a href="https://web.archive.org/web/*/https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><strong>A Polar Vortex collapse sequence has begun in late December 2020, with a major Sudden Stratospheric Warming event on January 5th, 2021. We will look at the sequence of these events, and how they can change the weather in Europe and the United States in the coming weeks.</strong></p>
<p>The main “player” in these weather events, is of course the <strong>Polar Vortex</strong>. It connects the bottom of the atmosphere (our weather) with the stratosphere above it. A strong exchange of energy between these two layers can heavily disrupt the weather development across the Northern Hemisphere.</p>
<h5><span><strong>WHAT IS THE POLAR VORTEX?</strong></span></h5>
<p>Since knowledge is the key, we will do a quick recap of what exactly is the Polar Vortex.</p>
<p>All of the clouds (and the weather that we feel) are found in the lowest part of the atmosphere called the <span><strong>troposphere</strong></span>. It reaches up to around 8 km (5 miles) altitude over the polar regions and up to around 14-16 km (9-10 miles) over the tropics.</p>
<p>Above it, there is a much deeper layer called the <span><strong>stratosphere</strong></span>. This layer is around 30 km thick and is very dry. We can see the layers of the atmosphere on the image below, with the <span>stratosphere</span> in green hues, and the <span>troposphere</span> in blue at the bottom.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg" data-image-id="21664" data-title="polar-vortex-stratosphere-weather-warming-atmospheric-layers" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg-nggid0521664-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-stratosphere-weather-warming-atmospheric-layers" title="polar-vortex-stratosphere-weather-warming-atmospheric-layers" width="475" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20475%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-stratosphere-weather-warming-atmospheric-layers.jpg-nggid0521664-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Every year as we head into autumn, the north pole starts to cool. But the atmosphere further south is still relatively warm as it is still receiving energy from the Sun. The north pole receives very little sunlight and thermal energy, cooling at a faster rate.</p>
<p>The reduction in temperature also means a gradual pressure drop over the north pole. In the stratosphere, the process is the same. As the temperature drops over the pole and the temperature difference towards the south increases, a low-pressure area starts to develop across the stratosphere.</p>
<p>The image below shows a typical example of the Polar Vortex at around 30km altitude (10mb level) in the middle stratosphere.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-over-north-pole-winter.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-over-north-pole-winter.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-over-north-pole-winter.jpg" data-image-id="21663" data-title="polar-vortex-over-north-pole-winter" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-over-north-pole-winter.jpg-nggid0521663-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-over-north-pole-winter" title="polar-vortex-over-north-pole-winter" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-over-north-pole-winter.jpg-nggid0521663-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>It is almost like a very large cyclone, covering the whole north pole, down to the mid-latitudes. The polar vortex is present at all levels, almost from the ground up. The image below shows the polar vortex at different altitudes. The closer to the ground we get, the more deformed it gets, due to the complex terrain and the many weather fronts and systems.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-winter-weather-warming-north-hemisphere.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-winter-weather-warming-north-hemisphere.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-winter-weather-warming-north-hemisphere.png" data-image-id="21666" data-title="polar-vortex-winter-weather-warming-north-hemisphere" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-winter-weather-warming-north-hemisphere.png-nggid0521666-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-winter-weather-warming-north-hemisphere" title="polar-vortex-winter-weather-warming-north-hemisphere" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-winter-weather-warming-north-hemisphere.png-nggid0521666-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We produced a high-resolution video for you below, which very nicely shows the Polar Vortex spinning over the Northern Hemisphere. It covers the period from December 2020 to January 2021, made from NASA GEOS-5 data.</p>
<p>Video shows the 10mb level (30km altitude) potential vorticity parameter, which overly simplified means, that it shows the energy of the polar vortex. Be aware of how the energy is being taken away from the polar vortex by the invisible polar Anticyclones (having a different kind of power), spinning in the opposite direction.</p>


<h5><span><strong>SUDDEN STRATOSPHERIC WARMING</strong></span></h5>
<p>&nbsp;<br>
As a general reference, we usually look at the polar vortex in the stratosphere at the 10mb level. That is around 28-32km (17-20 miles) altitude. This is considered to be around the middle stratosphere, and thus a good representation of the general dynamics of the polar vortex.</p>
<p>The strength of the polar vortex is most often measured by the power of the winds inside it. Usually, this is done is by measuring the zonal (west to east) wind speeds around the polar circle (60°N latitude).</p>
<p>Below we have an analysis from the NASA monitoring system, where we can see a very interesting progression. In early December, the polar vortex was at a quite strong level, reaching 40m/s zonal wind speeds. Problems began towards the mid-month, and especially towards late December when the stratospheric warming began. All graphics below are at the 10mb level (~30km altitude).</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg" data-image-id="21665" data-title="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg-nggid0521665-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-zonal-wind-forecast.jpg-nggid0521665-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Below is an image from the video we showed you earlier in the article, and it shows a quite healthy polar vortex in early December. It has a nice shape and a healthy spinning core.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-early-december.png" data-image-id="21669" data-title="polar-vortex-splitting-weather-winter-united-states-europe-early-december" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png-nggid0521669-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-early-december" title="polar-vortex-splitting-weather-winter-united-states-europe-early-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-early-december.png-nggid0521669-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Towards mid-December, the pressure from the North Pacific was rising, with an Anticyclonic presence there gaining strength. The anticyclonic circulation was slowly getting stronger, starting to drain some energy away from the polar vortex, and changing its shape.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png" data-image-id="21672" data-title="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png-nggid0521672-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" title="polar-vortex-splitting-weather-winter-united-states-europe-mid-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-mid-december.png-nggid0521672-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>By late December, the Pacific/East Asian Anticyclone became quite a force, now draining a lot of energy from the Polar Vortex and actually becoming visible.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-late-december.png" data-image-id="21670" data-title="polar-vortex-splitting-weather-winter-united-states-europe-late-december" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png-nggid0521670-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-late-december" title="polar-vortex-splitting-weather-winter-united-states-europe-late-december" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-late-december.png-nggid0521670-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>At a similar time in late December, a warming sequence began, from Europe over into central Asia. It was starting to engulf the outside layers of the polar vortex. The cold-core of the polar vortex is still rather intact at this point, holding temperatures colder than -80°C in the center over Greenland.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png" data-image-id="21673" data-title="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png-nggid0521673-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" title="polar-vortex-splitting-weather-winter-united-states-europe-warming-start" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-warming-start.png-nggid0521673-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Just two days later, the warming wave reached a local peak over Siberia, with maximum temperatures in the wave reaching up to +5°C or higher.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png" data-image-id="21674" data-title="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png-nggid0521674-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" title="polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-peak-stratospheric-warming.png-nggid0521674-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>On January 5th, the preliminary date of the Sudden Stratospheric Warming event was marked, as the winds around the polar circle have reversed. We can see how massive and strong the Anticyclone has now become, pushing strongly against the polar vortex (bright white). Together with the warming wave, the strong Anticyclonic system has deformed the once circular polar vortex into a banana-shaped feature.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png" data-image-id="21668" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png-nggid0521668-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021.png-nggid0521668-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>The warming wave has crawled over the entire North Pole in the stratosphere, effectively splitting the cold-core of the polar vortex into two parts. One over North America and one over the European sector. At this point, this does not have much to do directly with the weather on the surface, as it is at 30km altitude, but we will get to weather effects soon.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png" data-image-id="21675" data-title="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png-nggid0521675-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" title="polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-major-warming-event.png-nggid0521675-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Looking quickly at the forecast, we can see that the stratospheric Anticyclone will hold stable and move further over the North Pole. It will continue pushing against the very broken polar vortex.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png" data-image-id="21671" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png-nggid0521671-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2021-forecast.png-nggid0521671-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>At this point, a new warming wave is also forecasted to start, which should temporarily prevent any quick reorganization and strengthening of the stratospheric circulation.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png" data-image-id="21676" data-title="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png-nggid0521676-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" title="polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-stratosphere-forecast.png-nggid0521676-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Taking a look at the <a href="https://ozonewatch.gsfc.nasa.gov/meteorology/NH.html">NASA</a> temperature analysis for the stratosphere, we can see the large temperature spike at the 10mb (30km) level, which is in the middle stratosphere. The second image shows the temperature analysis in the lower stratosphere at 50mb (20km) level, also having a very clear temperature spike.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg" data-image-id="21679" data-title="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg-nggid0521679-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-middle-stratosphere-temperature-analysis.jpg-nggid0521679-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg" data-image-id="21678" data-title="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg-nggid0521678-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-lower-stratosphere-temperature-analysis.jpg-nggid0521678-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>Looking even lower, we have the 150mb level, which is kinda the boundary or the “buffer zone” between the stratosphere and the troposphere. Here we can also see the temperature spike, meaning the warming event was fairly robust and fast.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg" data-image-id="21677" data-title="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg-nggid0521677-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" title="polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-buffer-zone-temperature-analysis.jpg-nggid0521677-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<h5><span><strong>HISTORICAL WEATHER, FOR THE FUTURE</strong></span></h5>
<p>&nbsp;<br>
Before looking closer at the weather forecasts and their relation to the polar vortex, we need to look at some historic examples of similar events. History can sometimes be the best teacher for the future, and in science, this can be true more often than not.</p>
<p>Below we have 2 images, which both are quite simple to read and understand. They show time from left to right, and altitude from bottom to top. Colors show the temperature anomaly, with red being warmer than normal and blue was colder than normal. We can nicely track the progress of stratospheric warming events over time and altitude.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png" data-image-id="21683" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png-nggid0521683-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2004-ssw-event.png-nggid0521683-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png" data-image-id="21681" data-title="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png-nggid0521681-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" title="polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-january-2013-ssw-event.png-nggid0521681-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We can see the progression of warming from the top of the stratosphere, going downwards over time. The first image shows the 2004 stratospheric warming event and the second graphic shows the 2013 event.</p>
<p>The important takeaway is that the warming progresses quite fast down into the troposphere and can start to quickly affect our weather. But it usually stops around 100mb or 150mb level (12-15km). That is normal, due to the fact that we can see a lot of strong weather systems in our troposphere, which can in some cases deflect/reverse any incoming effects from the stratosphere.</p>
<p>Below we have similar two images, but with pressure anomalies instead of temperature. But here you can actually see the connecting points between high pressure coming downwards and the surface layer in the polar region. In both cases, the final effect was seen as individual connections to the bottom levels over time, interfering with the weather development. This indicates that the influence from the Polar Vortex collapse events is periodically interfering with the weather development on a sub-seasonal scale, kinda like waving or resonating.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png" data-image-id="21680" data-title="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png-nggid0521680-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" title="polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2004-atmospheric-pressure-evolution.png-nggid0521680-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png" data-image-id="21682" data-title="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png-nggid0521682-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" title="polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-2013-atmospheric-pressure-evolution.png-nggid0521682-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We don’t yet have the same graphic for 2021, for obvious reasons, since we still need more data to be gathered. But we can look at the forecast data in a similar image below.</p>
<p>What we are seeing is a very similar pattern as in 2004 and 2013. The negative values in this image represent higher pressure. So we can see the descending high-pressure, making individual contacts with the lower layers. This means that the influence is not a constant every time, but rather periodic.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG" data-image-id="21689" data-title="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG-nggid0521689-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.PNG" alt="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" title="polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-splitting-weather-winter-united-states-europe-pressure-anomaly-over-time.PNG-nggid0521689-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.PNG">
</a>
</p>
<p>We also decided to look at the weather patterns prior to the 2004 and 2013 events. And we can see in the images below. We can see on the first image for 2004, that the pattern was already positioned for colder weather over Europe, thanks to the strong high-pressure system in the North Atlantic. The United States was generally milder, with southerly flow dominating much of the CONUS.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif" data-image-id="21688" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event.gif-nggid0521688-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2004-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>In 2013, the picture was kinda the opposite. The pattern over the United States was generally colder than in 2004, while Europe was mild to warm even at this point.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif" data-image-id="21686" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event.gif-nggid0521686-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2013-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>This winter, the pattern is kinda a combination of both. We have another cooler/colder episode over Europe like in 2004, thanks to the high-pressure systems in the North Atlantic. At the same time, we also heed a few decent cold episodes over the United States as well.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif" data-image-id="21692" data-title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event.gif-nggid0521692-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" title="polar-vortex-weather-winter-united-states-europe-pressure-pattern-before-2021-ssw-event" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>But after the Polar Vortex breakdown and the stratospheric warming event, the pressure patterns changed quite importantly in 2004 and also in 2013. The image below is the pressure pattern one month after the Polar Vortex collapse in 2004. The strong high pressure in the North Atlantic has been replaced by a strong deep low-pressure system, and the high-pressure has moved into the Arctic …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/">https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/</a></em></p>]]>
            </description>
            <link>https://www.severe-weather.eu/global-weather/polar-vortex-collapse-winter-weather-europe-united-states-2021-fa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713704</guid>
            <pubDate>Sun, 10 Jan 2021 11:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CI/CD Workflow for AWS ECS via Terragrunt and GitHub Actions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713700">thread link</a>) | @kiyanwang
<br/>
January 10, 2021 | https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/ | <a href="https://web.archive.org/web/*/https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-3d5c50e8=""><p data-v-3d5c50e8="">This project leverages <a href="https://github.com/gruntwork-io/terragrunt" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Terragrunt</a>, <a href="https://www.terraform.io/" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Terraform</a>, and <a href="https://github.com/features/actions" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">GitHub Actions</a> to deploy a basic web app (dockerized JS frontend and dockerized Python API) to <a href="https://aws.amazon.com/ecs/" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">AWS ECS</a>.</p>

<h2 id="initial-setup" data-v-3d5c50e8="">Initial Setup</h2>
<p data-v-3d5c50e8=""><a href="https://github.com/gruntwork-io/terragrunt" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Terragrunt</a> is a thin wrapper for Terraform that provides extra tools for working with multiple Terraform modules, remote state, and locking. It also provides a powerful and flexible way to hierarchically provide configuration to Terraform, without duplicating code across environments, AWS regions, and AWS accounts – <a href="https://blog.gruntwork.io/terragrunt-how-to-keep-your-terraform-code-dry-and-maintainable-f61ae06959d8?gi=703957a5f669" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">keeping your Terraform config DRY</a>.</p>
<div data-v-220acfa8="" data-v-3d5c50e8=""><p><img src="https://d33wubrfki0l68.cloudfront.net/d33f961cd6f8b89afbde2972798eb3c42f1eb5db/e349a/_nuxt/img/structure.b39ebef.jpg" width="100%" height="" alt="Managing Terraform config across accounts, regions, and environments with Terragrunt" data-v-220acfa8=""></p><p data-v-220acfa8="">Managing Terraform config across accounts, regions, and environments with Terragrunt</p></div>
<p data-v-3d5c50e8="">The following hierarchy is proposed (aligned with directory structure):</p>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">terragrunt.hcl</code> with configuration for remote_state and AWS provider</li>
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">common.terragrunt.hcl</code> defining common, project-specific variables
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">account.terragrunt.hcl</code> for each account
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">region.terragrunt.hcl</code> for each region within an account
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">environment.terragrunt.hcl</code> for each environment within a region</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p data-v-3d5c50e8="">This allows flexible configuration, just add additional folders and adjust the configuration files, for instance configuring...</p>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8="">Accounts <code data-v-3d5c50e8="">main</code> and <code data-v-3d5c50e8="">secondary</code></li>
<li data-v-3d5c50e8="">Regions <code data-v-3d5c50e8="">eu-west-1</code> and <code data-v-3d5c50e8="">us-east-1</code> in <code data-v-3d5c50e8="">main</code> vs. <code data-v-3d5c50e8="">us-east-1</code> in <code data-v-3d5c50e8="">secondary</code></li>
<li data-v-3d5c50e8="">Environments <code data-v-3d5c50e8="">prod</code> in <code data-v-3d5c50e8="">main</code> regions vs. <code data-v-3d5c50e8="">stage</code> and <code data-v-3d5c50e8="">dev</code> in <code data-v-3d5c50e8="">secondary</code> regions</li>
</ul>
<h2 id="workflow-via-github-flow" data-v-3d5c50e8="">Workflow via GitHub Flow</h2>
<p data-v-3d5c50e8="">This project leverages <a href="https://guides.github.com/introduction/flow/" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">GitHub Flow</a> for gradually merging changes existing on experimental branches and deployed to experimental environments, towards more mature branches and environments.</p>
<div data-v-220acfa8="" data-v-3d5c50e8=""><p><img src="https://d33wubrfki0l68.cloudfront.net/33cb4fb2f8dc6f32e90c06e48e4086caaf8eec8e/6b65e/_nuxt/img/branches.4c960fb.jpg" width="100%" height="" alt="Workflow and Deployment – GitHub Flow" data-v-220acfa8=""></p><p data-v-220acfa8="">Workflow and Deployment – GitHub Flow</p></div>
<p data-v-3d5c50e8="">The <a href="https://github.com/visini/terragrunt-github-actions-aws-ecs" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">companion repository</a> contains functionality to deploy code to AWS ECS simply by adopting GitHub Flow principles. All integration and deployment steps are managed by GitHub Actions workflows, including: Unit testing, building and pushing Docker images, and releasing new images to the correct ECS cluster via Terraform and Terragrunt. Create a branch, push, create a pull-request, and, after verifying checks, merge all changes - these are the only steps needed to deploy new features by adopting this approach.</p>
<p data-v-3d5c50e8="">Assuming a running staging and production environment, here's how to deploy changes made for a recent feature "foo" to staging and production environments:</p>
<p data-v-3d5c50e8=""><strong data-v-3d5c50e8="">Step 1</strong> → Deployment to staging environment <code data-v-3d5c50e8="">stage</code> via branch <code data-v-3d5c50e8="">dev</code></p>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8="">Create a new branch <code data-v-3d5c50e8="">feature/foo</code> and check it out
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">git checkout -b feature/foo</code></li>
</ul>
</li>
<li data-v-3d5c50e8="">Push to remote and set up to track remote branch <code data-v-3d5c50e8="">feature/foo</code> from <code data-v-3d5c50e8="">origin</code>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8=""><code data-v-3d5c50e8="">git push --set-upstream origin feature/foo</code></li>
</ul>
</li>
<li data-v-3d5c50e8="">Open pull request from branch <code data-v-3d5c50e8="">feature/foo</code> to branch <code data-v-3d5c50e8="">dev</code> to plan deployment to <code data-v-3d5c50e8="">stage</code> environment</li>
<li data-v-3d5c50e8="">Wait for checks to complete: Workflow <code data-v-3d5c50e8="">terragrunt</code> will post terraform <code data-v-3d5c50e8="">plan</code> as a comment to pull request</li>
<li data-v-3d5c50e8="">Additional checks may include unit tests: See <code data-v-3d5c50e8="">pytest-api.yml</code></li>
<li data-v-3d5c50e8="">After verifying terraform <code data-v-3d5c50e8="">plan</code>, merge pull request into branch <code data-v-3d5c50e8="">dev</code></li>
<li data-v-3d5c50e8="">Workflow <code data-v-3d5c50e8="">terragrunt</code> will run again and <code data-v-3d5c50e8="">apply</code> deployment for <code data-v-3d5c50e8="">stage</code> environment</li>
<li data-v-3d5c50e8="">Code (and infrastructure) changes to branch <code data-v-3d5c50e8="">feature/foo</code> are now released to <code data-v-3d5c50e8="">stage</code> environment</li>
</ul>
<p data-v-3d5c50e8=""><strong data-v-3d5c50e8="">Step 2</strong> → Deployment to production environment <code data-v-3d5c50e8="">prod</code> via branch <code data-v-3d5c50e8="">main</code></p>
<ul data-v-3d5c50e8="">
<li data-v-3d5c50e8="">After verifying deployment to <code data-v-3d5c50e8="">stage</code> environment (e.g., e2e-testing), open pull request from branch <code data-v-3d5c50e8="">dev</code> to branch <code data-v-3d5c50e8="">main</code> to plan deployment to <code data-v-3d5c50e8="">prod</code> environment</li>
<li data-v-3d5c50e8="">Wait for checks to complete: Workflow <code data-v-3d5c50e8="">terragrunt</code> will post terraform <code data-v-3d5c50e8="">plan</code> as a comment to pull request</li>
<li data-v-3d5c50e8="">After verifying terraform <code data-v-3d5c50e8="">plan</code>, merge pull request into branch <code data-v-3d5c50e8="">main</code></li>
<li data-v-3d5c50e8="">Workflow <code data-v-3d5c50e8="">terragrunt</code> will run again and <code data-v-3d5c50e8="">apply</code> deployment for <code data-v-3d5c50e8="">prod</code> environment</li>
<li data-v-3d5c50e8="">Code (and infrastructure) changes to branch <code data-v-3d5c50e8="">dev</code> originating from branch <code data-v-3d5c50e8="">feature/foo</code> are now released to <code data-v-3d5c50e8="">prod</code> environment</li>
</ul>
<h2 id="configure-infrastructure-and-deployment-targets" data-v-3d5c50e8="">Configure Infrastructure and Deployment Targets</h2>
<p data-v-3d5c50e8="">The hierarchical configuration via Terragrunt is enabled by a main configuration file in which all other more granular configuration files are imported. In <code data-v-3d5c50e8="">terragrunt.hcl</code>, both remote state and AWS provider are defined according to values in more specific configuration files.</p>
<p data-v-3d5c50e8="">Both remote state and provider are dynamically defined for each deployment target (e.g., <code data-v-3d5c50e8="">prod</code> vs. <code data-v-3d5c50e8="">stage</code> environment) and AWS account ID (e.g., <code data-v-3d5c50e8="">main</code> vs. <code data-v-3d5c50e8="">secondary</code> account). This means, <code data-v-3d5c50e8="">prod</code> and <code data-v-3d5c50e8="">stage</code> environments (which may even be residing on two separate AWS accounts) adopt separate remote state backend configurations, depending on which environment subfolder <code data-v-3d5c50e8="">terragrunt</code> commands are executed from. Review this file and the nested Terragrunt configuration files in the <a href="https://github.com/visini/terragrunt-github-actions-aws-ecs" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">companion repository</a> for the detailed implementation.</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    common </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"common.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">    account </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"account.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">    region </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"region.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    environment </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"environment.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">}</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">remote_state</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">    backend </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"s3"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># remote_state dynamically configured based on:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.region.locals.aws_region</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">11</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.account.locals.aws_account_id</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">12</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.common.locals.app_name</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">13</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">14</span><span data-v-3d5c50e8="">}</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">15</span><span data-v-3d5c50e8="">generate</span><span data-v-3d5c50e8=""> "provider"</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">16</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># AWS provider dynamically configured based on:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">17</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.region.locals.aws_region</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">18</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># local.account.locals.aws_account_id</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">19</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">20</span><span data-v-3d5c50e8="">}</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">21</span><span data-v-3d5c50e8=""># The following variables apply to all configurations in this subfolder</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">22</span><span data-v-3d5c50e8=""># and are automatically merged into the child `terragrunt.hcl` config</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">23</span><span data-v-3d5c50e8=""># via the include block.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">24</span><span data-v-3d5c50e8="">inputs </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> merge(</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">25</span><span data-v-3d5c50e8="">    local.common.locals,</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">26</span><span data-v-3d5c50e8="">    local.account.locals,</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">27</span><span data-v-3d5c50e8="">    local.region.locals,</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">28</span><span data-v-3d5c50e8="">    local.environment.locals</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">29</span><span data-v-3d5c50e8="">)</span></span></code></pre></div>
<p data-v-3d5c50e8="">Common variables, such as the app name, base domain name and hosted zone name, which apply to the project are configured in a separate file:</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf ›</span></span><span data-v-594b4fde="">common.terragrunt.hcl</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># The following define common variables for the project.</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8=""># They are automatically pulled in in the root terragrunt.hcl</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8=""># configuration to feed forward to the child modules.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    app_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"example-app"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">    app_domain_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"app.example.com"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">    route53_hosted_zone_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"example.com"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">    use_existing_route53_hosted_zone </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">true</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">    github_sha </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"will_be_automatically_set_by_github_actions_or_manual_script"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<p data-v-3d5c50e8="">One or any number of AWS accounts may be configured, each related to any number of regions and environments to be deployed via this AWS account:</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main ›</span></span><span data-v-594b4fde="">account.terragrunt.hcl</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># Set account-specific variables. They are automatically</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8=""># pulled in to configure the remote state bucket in the root</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8=""># terragrunt.hcl configuration.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">  account_name   </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"main"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">  aws_account_id </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"123456789000"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">  aws_profile    </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"default"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<p data-v-3d5c50e8="">Similarly, the region configuration is provided in the nested level:</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main › eu-west-1 ›</span></span><span data-v-594b4fde="">region.terragrunt.hcl</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># Set region-specific variables. They are automatically</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8=""># pulled in to the root terragrunt.hcl configuration to</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8=""># feed forward to the child modules.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    aws_region </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"eu-west-1"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<p data-v-3d5c50e8="">Environment configuration regarding both infrastructure and containers are provided in the nested level. To illustrate a common use case: The <code data-v-3d5c50e8="">stage</code> environment may override variables previously defined in the parent-hierarchy, in <code data-v-3d5c50e8="">tf/common.terragrunt.hcl</code>, and for instance add a prefix <code data-v-3d5c50e8="">stage.*</code> to <code data-v-3d5c50e8="">app_domain_name</code>.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main › eu-west-1 › stage ›</span></span><span data-v-594b4fde="">environment.terragrunt.hcl</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># Set environment-specific variables. They are automatically</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8=""># pulled in to the root terragrunt.hcl configuration to</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8=""># feed forward to the child modules.</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    common </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"common.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">    account </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"account.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">    region </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> read_terragrunt_config(find_in_parent_folders(</span><span data-v-3d5c50e8="">"region.terragrunt.hcl"</span><span data-v-3d5c50e8="">))</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8=""># Configure environment</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">    environment </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"stage"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">    app_domain_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"stage.</span><span data-v-3d5c50e8="">${local</span><span data-v-3d5c50e8="">.common.locals.app_domain_name</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">"</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">11</span><span data-v-3d5c50e8="">    app_name </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> local</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">common</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">app_name</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">12</span><span data-v-3d5c50e8="">    aws_account_id </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> local</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">account</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">aws_account_id</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">13</span><span data-v-3d5c50e8="">    aws_region </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> local</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">region</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">locals</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">aws_region</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">14</span><span data-v-3d5c50e8="">    parameter_group </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"</span><span data-v-3d5c50e8="">${local</span><span data-v-3d5c50e8="">.app_name</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">/</span><span data-v-3d5c50e8="">${local</span><span data-v-3d5c50e8="">.environment</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">"</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">15</span><span data-v-3d5c50e8="">    service_configuration </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">16</span><span data-v-3d5c50e8="">        # ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">17</span><span data-v-3d5c50e8="">    }</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">18</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<h2 id="configure-container-environment-and-secrets" data-v-3d5c50e8="">Configure Container Environment and Secrets</h2>
<p data-v-3d5c50e8="">Environment variables for the respective deployment target (e.g., for <code data-v-3d5c50e8="">stage</code> environment) are provided alongside terragrunt configuration in JSON files, following the naming <code data-v-3d5c50e8="">.service.environment.json</code>, and by specifying both keys and values. These files are committed to source control, since they do not contain any sensitive data. Adding a description key-value pair will inform development and ensure consistency of variable assignment.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main › eu-west-1 › stage ›</span></span><span data-v-594b4fde="">.api.environment.json</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">{</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">"DEBUG"</span><span data-v-3d5c50e8="">: {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">"value"</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">"true"</span><span data-v-3d5c50e8="">,</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">"description"</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">"API debug environment"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">  }</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">// ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<p data-v-3d5c50e8="">Similarly, JSON files following the naming <code data-v-3d5c50e8="">.service.secrets.json</code> provide <em data-v-3d5c50e8="">keys</em> (not values) for all container secrets, which are injected by AWS Systems Manager Parameter Store into the service's ECS tasks (containers) as <em data-v-3d5c50e8="">environment variables</em>. Adding a description key-value pair will inform development and ensure consistency of variable assignment.</p>
<p data-v-3d5c50e8="">No secrets are present in code or source control — secrets such as database passwords or secret keys are generated as terraform resources, and stored within Systems Manager Parameter Store. Following the <a href="https://www.terraform.io/docs/state/sensitive-data.html" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">design of terraform state</a>, they are additionally stored within remote state backend. While S3 backend supports encryption at rest, remote state is to be considered sensitive data.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">tf › main › eu-west-1 › stage ›</span></span><span data-v-594b4fde="">.api.secrets.json</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">{</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">"SECRET_KEY"</span><span data-v-3d5c50e8="">: {</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">"description"</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">"Secret key required for API JWT authentication"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">  }</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">// ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">}</span></span></code></pre></div>
<h2 id="integration-via-github-actions--pytest" data-v-3d5c50e8="">Integration via GitHub Actions – Pytest</h2>
<p data-v-3d5c50e8="">Easily add continuous integration workflows for unit, integration, and e2e tests by adding a GitHub Action workflow. The <a href="https://github.com/visini/terragrunt-github-actions-aws-ecs" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">companion repository</a> includes an example for testing the API service via Pytest.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">.github › workflows ›</span></span><span data-v-594b4fde="">pytest-api.yml</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">name</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">Pytest API</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">on</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8="">pull_request</span><span data-v-3d5c50e8="">:</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">jobs</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8=""># ----------------------------------------------------------------</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">  </span><span data-v-3d5c50e8=""># …</span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/">https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/</a></em></p>]]>
            </description>
            <link>https://camillovisini.com/article/terragrunt-github-actions-aws-ecs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713700</guid>
            <pubDate>Sun, 10 Jan 2021 11:40:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Prosody developers spent 2020]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25713679">thread link</a>) | @upofadown
<br/>
January 10, 2021 | https://blog.prosody.im/2020-retrospective/ | <a href="https://web.archive.org/web/*/https://blog.prosody.im/2020-retrospective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
  


  <div>

    

    
    <div>
      <p><small>
        <p><time datetime="2021-01-08T00:00:00Z">
          2021-01-08
        </time> by The Prosody Team
         
        <br>
        
        </p>
        

        
        
        <br>

      </small></p>
    </div>
    <p>Nobody here knew quite what a year 2020 was going to be! However despite
pandemics and lockdowns, we have continued to work on Prosody. This post
is a summary of how the project is doing, and what we’ve been up to in
the past year.</p>

<p>One quick note before we begin… Prosody is an independent open-source
project and exists only because the developers have been fortunate enough
to be in a position to work on it. A couple of core team members are
currently looking for freelance work. If you have projects in need of a
Prosody expert, check the bottom of this post for more details!</p>

<h2 id="more-users-than-ever-before">More users than ever before</h2>

<p>Prosody does not “phone home” in any way, which means we do not have a
lot of insight into how many people are using Prosody. But there are
some indicators that we can use to see at least the growth of the project.</p>

<p>Many years ago, circa 2014, I was filling out a form that asked how
many users the project had. I thought long and hard, but with no idea how
to measure, I wrote down an estimate of “500” based on nothing but a gut
feeling. Only a few weeks later I learned that the <a href="https://xmpp.net/">XMPP Observatory</a>
had already seen <strong>over 2200 domains</strong> submitted that were running Prosody.
As most deployments were unlikely to have been submitted to xmpp.net, my
estimate was clearly far out. These days I jump at any chance for even a
vague estimate of our userbase. It helps us to know that people are out
there!</p>

<p>One useful tool is <a href="https://shodan.io/">Shodan</a>. This project scans the
entire internet, just to see what it can find, and it records the results.
Often used by academics and security researchers, a free account can also
be used by anyone to run simple queries over the data they collect.</p>

<p>A Shodan search in 2017 turned up nearly 7000 Prosody deployments. The
same search 8 months later returned over 16000. Today we’re at <strong>over 52000
Prosody servers!</strong> And this only counts instances using port 5269 and
accessible to the internet. There are also many private/internal deployments
of Prosody that are not included in these numbers. Unfortunately we
didn’t run a report in 2019, but here’s a graph of the previous
reports we have run:</p>

<p><img src="https://blog.prosody.im/2020-retrospective/prosody-shodan-2020.svg" alt="Graph of Prosody server counts in previous paragraph"></p>

<p>Shodan reports over 85000 federating XMPP servers on port 5269 in total.
Based on this, Prosody makes up 44% of the public XMPP network. That’s
quite an achievement!</p>

<p>Another handy insight into one sector of Prosody deployments is via Debian’s
<a href="https://popcon.debian.org/">“popularity contest”</a> service. This is an
automated survey that administrators of Debian servers can choose to opt
into. It reports anonymously to Debian what software packages are installed
and in use. Although it reflects only a small slice of even Debian
installations, it is useful to see trends.</p>

<p>March 2020 marked an unprecedented spike in Prosody installations!</p>

<p><img src="https://blog.prosody.im/2020-retrospective/prosody-popcon-20201231.png" alt="Graph of Debian popularity contest data for prosody"></p>

<p>Although we don’t know for certain, we suspect this was caused by an surge
of interest in the self-hosted video conferencing software, <a href="https://jitsi.org/jitsi-meet/">Jitsi Meet</a>. Jitsi Meet integrates with Prosody, which is used to power the
authentication, signaling and chat of the video conferences. Jitsi’s <a href="https://jitsi.org/jitsi-videobridge/">Videobridge</a> component handles the media routing. Together they make
a very powerful and flexible communication system, and it is hardly surprising
that interest has spiked this year when there has been a massive shift to
remote work, and online meetings have replaced physical ones.</p>

<h2 id="the-code-counts">The code counts</h2>

<p>Now let’s look at some stats about the Prosody codebase itself.</p>

<table>
<thead>
<tr>
<th>Language</th>
<th>Files</th>
<th>Code</th>
<th>Comment</th>
<th>Comment %</th>
<th>Blank</th>
<th>Total</th>
</tr>
</thead>

<tbody>
<tr>
<td>Lua</td>
<td>295</td>
<td>48358</td>
<td>3536</td>
<td>6.8%</td>
<td>6483</td>
<td>58377</td>
</tr>

<tr>
<td>C</td>
<td>13</td>
<td>2613</td>
<td>346</td>
<td>11.7%</td>
<td>643</td>
<td>3602</td>
</tr>

<tr>
<td>Other (build tools, etc.)</td>
<td>11</td>
<td>1551</td>
<td>22</td>
<td>6.3%</td>
<td>138</td>
<td>1711</td>
</tr>

<tr>
<td>————————-</td>
<td>——</td>
<td>———-</td>
<td>———-</td>
<td>———-</td>
<td>———-</td>
<td>———</td>
</tr>

<tr>
<td>Total</td>
<td>323</td>
<td>54760</td>
<td>3909</td>
<td>6.7%</td>
<td>7265</td>
<td>65934</td>
</tr>
</tbody>
</table>

<h3 id="changes-in-2020">Changes in 2020</h3>

<p>In 2020 (looking at the development branch) we added 597 commits, changing
191 files. The changes added 9872 lines of code, and 3637 lines of code
were removed.</p>

<p>A significant portion of the new lines were in our unit and integration
tests (2200 lines, about 22%) which we have been working hard to expand
over the past couple of years.</p>



<p>If you use Prosody, you know we have an emphasis on modularity and
extensibility. We like to make <a href="https://prosody.im/doc/developers/modules">developing plugins for Prosody</a> as easy as possible, whether it’s for integration with other
systems or crazy experiments.</p>

<p>Here’s a random selection of the 363 modules currently in the repository:</p>

<dl>
<dt><a href="https://modules.prosody.im/mod_muc_eventsource">mod_muc_eventsource</a></dt>
<dd>Receive messages from MUC rooms with 4 lines of Javascript</dd>
<dt><a href="https://modules.prosody.im/mod_log_ringbuffer.html">mod_log_ringbuffer</a></dt>
<dd>Send debug logs to RAM unless they are needed.</dd>
<dt><a href="https://modules.prosody.im/mod_component_client">mod_component_client</a></dt>
<dd>Allow a Prosody server to run as a (XEP-0114) external component of
another (Prosody or not) XMPP server.</dd>
<dt><a href="https://modules.prosody.im/mod_firewall">mod_firewall</a></dt>
<dd>Powerful rules-based scripts for filtering and redirecting XMPP traffic.</dd>
<dt><a href="https://modules.prosody.im/mod_minimix">mod_minimix</a></dt>
<dd>An <strong>experiment</strong> in making MUC joins persistent (like MIX).</dd>
</dl>

<p>During 2020 we saw 37 new modules published in the <a href="https://modules.prosody.im/">community repository</a>,
and 499 commits from 19 contributors. Together they added over 10,000
lines of code (and removed 728 lines). This makes it our most active
year apart from 2018!</p>

<p>Outside of the Prosody dev team, the most active contributor was
<a href="https://wiki.xmpp.org/web/Severino_Ferrer_de_la_Pe%C3%B1ita_Application_2020">Seve</a>, who also made their first contribution this year and added a total of four new modules.
Welcome aboard!</p>

<h2 id="features">Features</h2>

<p>But the most important part… what features have we been working on? All
these things are scheduled for the 0.12 release (more on that in a bit).</p>

<h3 id="plugin-installer">Plugin installer</h3>

<p>We have been applying further polish to, and setting up the infrastructure
for the plugin installer. This was a Google Summer of Code project by
<a href="https://gsoc-prosody-2019.blogspot.com/">João Duarte</a>. It utilizes the
Lua package manager, LuaRocks, to download, install and manage community
modules.</p>

<p>Although the the installer was completed in 2019, to make it generally
usable we also had to ensure every module in the <a href="https://modules.prosody.im/">community repository</a>
could be packaged and served in an automated way by our server. We now
have this working.</p>

<h3 id="bye-bye-telnet-hello-prosodyctl-shell">Bye bye telnet, hello prosodyctl shell!</h3>

<p>The telnet console is one of the best things about Prosody, and we’ve
been working on its successor. An early version of <code>prosodyctl shell</code> is
already available to try out in trunk nightly builds.</p>

<p>Using prosodyctl allows us to more easily support advanced features such
as line editing and history (previously attainable using a third-party
utility, rlwrap). It also allows for some richer UIs and is more secure
on shared servers (it uses a unix socket instead of TCP).</p>

<h3 id="dns-improvements">DNS improvements</h3>

<p>Since Prosody needs to resolve special DNS record types (such as SRV
records) and in an asynchronous manner, the built-in operating system APIs
are generally inadequate.</p>

<p>For a long time we’ve been using an adopted library simply known as
‘dns.lua’ combined with our own asynchronous wrapper around it. Although
it hasn’t been terrible, it has a few issues, especially in some uncommon
environments. It also doesn’t support many advanced features such as DNSSEC.</p>

<p>Now we are migrating to libunbound, part of the <a href="https://github.com/coredns/unbound">unbound</a>
project. This is one of the leading DNS implementations, and will be a
big improvement over our current DNS library. To try it out, you can
simply install <a href="https://www.zash.se/luaunbound.html">luaunbound</a> (already
available in luarocks, Debian testing, AUR and others - poke your distro
maintainers if you don’t have it yet!).</p>

<h3 id="http-server-upload-performance">HTTP server upload performance</h3>

<p>We didn’t set out to write a HTTP server, but we ended up with one anyway!
Originally added so that we could natively support BOSH (XMPP over HTTP)
clients, it grew to support websockets, and various modules now provide
HTTP APIs for integration between Prosody and other systems.</p>

<p>One big problem is that the original implementation was designed for only
small amounts of data. Since the widespread of adoption of
<a href="https://xmpp.org/extensions/xep-0363.html">XEP-0363</a> people now want to
be able to upload files, pictures and videos using Prosody’s internal
HTTP server. We have limits in place to protect against denial of service
attacks, but those same limits prevent large uploads from trusted users.</p>

<p>We’ve put some work into supporting “streaming uploads”, where incoming
data can be saved directly to disk instead of RAM. This means it will be
safe to increase file upload limits without opening up your server to
increase RAM usage and denial of service attacks.</p>

<p>In general though, we do recommend using a real external HTTP server in
a production or high traffic deployment (using <a href="https://modules.prosody.im/mod_http_upload_external">mod_http_upload_external</a>).</p>

<h3 id="beyond-passwords">Beyond passwords</h3>

<p>Passwords are the fundamental means of authenticating to your server in
XMPP today. XMPP is quite good at this, adopting strong standard authentication
mechanisms such as SCRAM far earlier than the rest of the industry. But
the rest of the industry is also moving away from passwords in many places.
We’re aiming to follow this movement also. Not that we are scrapping passwords
entirely, but making it easier to offer alternatives.</p>

<p>Prosody actually has a number of non-password authentication modules already,
such as <a href="https://modules.prosody.im/mod_auth_oauthbearer">mod_auth_oauthbearer</a> (OAuth2 tokens),
 <a href="https://modules.prosody.im/mod_auth_ccert">mod_auth_ccert</a> (client certificates) and
 <a href="https://modules.prosody.im/mod_auth_token">mod_auth_token</a> (HMAC-based
 tokens).
But most of the modules have limitations and are not well integrated
(e.g. you can set up Prosody to accept passwords, or set it up to accept
tokens, but you can’t offer both methods at the same time).</p>

<p>An important related aspect is authorization. In most systems authentication
via a token also provides <em>limited access to the account</em> (e.g. if a password
is associated with an account, a session that logged in using a token
should not be allowed to reset the password).</p>

<p>We’ve been working on two things. Firstly, a built-in authorization system
(more flexible than the current <code>admins</code> configuration option) where users
and sessions can be associated with specific permissions and roles.</p>

<p>Secondly we’re using this authorization layer to add built-in support
for OAuth2-style authentication and authorization.</p>

<p>This is exciting for a number of reasons. It will allow, for example,
specialized clients to request and receive (when granted by the user)
limited …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.prosody.im/2020-retrospective/">https://blog.prosody.im/2020-retrospective/</a></em></p>]]>
            </description>
            <link>https://blog.prosody.im/2020-retrospective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713679</guid>
            <pubDate>Sun, 10 Jan 2021 11:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Campaigns: A long-running effort to enact global change safely]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25713656">thread link</a>) | @kiyanwang
<br/>
January 10, 2021 | https://kellysutton.com/2021/01/06/campaigns.html | <a href="https://web.archive.org/web/*/https://kellysutton.com/2021/01/06/campaigns.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Sometimes it can take years to make a single-line code change.</p>

<p>As engineering organizations grow, the problems and their solutions become more intricate. What might have taken an afternoon now takes months of coordinated effort. The system (both the technology and the people) are larger, more complex, and more difficult to change than ever before.</p>

<p>But change is necessary.</p>

<p>We might be looking to pay off some technical debt or tee up an architectural change to unlock a better customer experience, cost savings, etc. What is a tool we can use to coordinate many groups of people, hold groups accountable, and eventually succeed?</p>

<p>Enter what I call the <strong>Campaign</strong>.</p>

<h2 id="elements-of-a-campaign">Elements of a Campaign</h2>

<p>A Campaign is a long-running effort to enact global change safely within a sociotechnical system.</p>

<p><strong>Every campaign needs the following:</strong></p>

<ul>
  <li>A Goal</li>
  <li>Metrics toward that goal</li>
  <li>Buy-in</li>
  <li>Method of Accountability</li>
  <li>A “Window”</li>
  <li>A Target Date</li>
</ul>

<p><strong>Campaigns work well to address:</strong></p>

<ul>
  <li>Technical changes with large social components.</li>
  <li>Technical changes that require everyone to do a little bit of work.</li>
  <li>High-value or inevitable future worlds</li>
</ul>

<p><strong>Campaigns don’t work with:</strong></p>

<ul>
  <li>Efforts that avoid measurement, or where measurement is likely actively harmful. Examples include “We should improve the design of our code.”</li>
  <li>Organizations that cannot buy-in to the effort for one reason or another.</li>
  <li>Low-value Campaigns. No need to coordinate many teams if efforts can be localized.</li>
</ul>

<p>Many campaigns have a trivial technical goal. My favorite example: The request timeout value is likely one line in a configuration file. Safely changing that to a lower value can be months of work.</p>

<p>Let’s step through the individal components in greater detail.</p>

<h2 id="the-goal">The Goal</h2>

<p>Every campaign needs a goal that can be expressed in a single sentence. The goal should be separate from the metric. It may or may not include implementation details. I usually recommend they include some hint of implementation so that the scope of effort can be limited a bit.</p>

<p>Here are a few examples:</p>

<ul>
  <li>“We want to improve the resiliency and throughput of our background processes by making all jobs idempotent.”</li>
  <li>“We want to improve the customer experience and resiliency of our system by limiting the amount of time a web request can take.”</li>
  <li>“We want to improve the health of our database by enforcing a timeout on all queries.”</li>
</ul>

<p>If the goal feels a bit too open, consider adding non-goals as well to keep the effort focused.</p>

<h2 id="focus-on-impact">Focus on Impact</h2>

<p>Before beginning a Campaign, you need to convice a lot of people that this is a valuable effort and that now is the right time to tackle such an effort. A crisp articulation of “Why this Campaign?” and “Why now?” is required.</p>

<p>Write these down, but expect to repeat them in other media often.</p>

<p>Focus on the benefits of achieving the goal. The more we can ground the impact in objective truths (e.g. “our system is more resilient to failure”) and less in personal preference for technology (e.g. “we were using Tech X but now we use Tech Y”), the better.</p>

<h2 id="metrics">Metrics</h2>

<p>Every Campaign needs a metric or two to enable tracking progress and accountability.</p>

<p>Each metric should be able to be assigned to a given team or individual. Once the metrics go green, we should have <em>ipso facto</em> achieved our goal.<sup id="fnref:okrs" role="doc-noteref"><a href="#fn:okrs">1</a></sup></p>

<p>Choosing a metric can be difficult. It should not be succeptible to <a href="https://brownfield.dev/post/2020-02-18-trap-rule-beating/">Rule Beating</a>, where the metric will be green but the intent of the goal will be missed.</p>

<p>Metrics need to be incremental and as fine-grained as necessary. We should see the slow march of progress, rather than a sudden “Okay, we’re done!”</p>

<p>There should be many ways to achieve a metric. In the example of global request timeouts, we can hit that timeout by reducing the total number of database queries, speeding up serialization of JSON, caching, loading less data, etc.</p>

<p>A few examples derived from the above examples goals:</p>

<ul>
  <li>Number of background jobs that are not idempotent.</li>
  <li>Endpoints that are over the threshold of request length.</li>
  <li>Database queries that are over the threshold of query length.</li>
</ul>

<p>Metrics should be easy to grok and able to be sliced a few different ways. In our request threshold example, we might want to surface both “number of endpoints remaining” and “total percentage of endpoints.”</p>

<h2 id="buy-in">Buy-in</h2>

<p>A Campaign by definition reaches across the organization and touches many teams. Every team, mission, individual, and sub-org has different priorities and different worries.</p>

<p>For a Campaign to be successful, it needs global participation of those involved. Buy-in will look different in different organizations, but will generally be a mix of <a href="https://en.wikipedia.org/wiki/Carrot_and_stick">Carrot and Stick</a> (choosing to do something vs. being coerced to do something).</p>

<p>Leading with the benefits (i.e. the Carrot) can go a long way here:</p>

<ul>
  <li>“If we are able to make jobs idempotent, the Infrastructure team can take over responsibility of background jobs and reduce costs by 90%.”</li>
  <li>“If we are able to make all requests take less than 2 seconds, the customer experience will improve and we will be able to reduce costs.”</li>
</ul>

<p>The benefits may not be convincing enough or still might not meet the priority threshold for some teams. If many teams do not find the benefits convincing enough, you might not have a Campaign worth pursuing.</p>

<h2 id="a-method-of-holding-teams-accountable">A Method of Holding Teams Accountable</h2>

<p>How much further do we have to go? Where might we need to invest more?</p>

<p>Most Campaigns will have a central place to answer questions like these. Speadsheets here work just fine. Dashboards are even better. They might be automatically populated or populated by hand, usually with the help of a script. Whatever it is, it should quickly answer a few questions:</p>

<ul>
  <li>How far along are we?</li>
  <li>Which teams are doing well? (We should follow up with these teams to see what’s working for them.)</li>
  <li>Which teams are falling behind? (We should follow up with these team to see if they need more help, resources, etc.)</li>
</ul>

<p>This should be passively available, but also circulated on some regular cadence. Weekly, monthly, or quarterly, everyone involved should get an update in their inbox.</p>

<h2 id="a-window">A “Window”</h2>

<p>The Window is a method of prioritizing work to be done while ensuring that progress is permanent. It moves. It is optional but helpful in most Campaigns.</p>

<p>A Window usually defines two threshold: Warning and Not Allowed. In a Campaign to enforce a global request timeout, here’s how the Window might look at the start and evolve:</p>

<ol>
  <li>The Goal is to make no web request take longer than 5 seconds, 99.9% of the time.</li>
  <li>The Window is set to Warn: 30 seconds, Not Allowed: 60 seconds. 60 seconds is the current limit set by our load balancer and the behavior that exists today.</li>
  <li>Teams tackle all requests that fall between Warn and Not Allowed until there are no more in the Window.</li>
  <li>We move the Window down to Warn: 15 seconds, Not Allowed: 30 seconds.</li>
  <li>GOTO Step 3.</li>
</ol>

<figure>
  <img srcset="https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=100 100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=200 200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=300 300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=320 320w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=400 400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=500 500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=600 600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=640 640w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=700 700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=750 750w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=768 768w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=800 800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=900 900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1000 1000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1024 1024w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1080 1080w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1100 1100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1152 1152w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1200 1200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1242 1242w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1300 1300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1400 1400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1440 1440w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1442 1442w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1500 1500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1536 1536w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1600 1600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1700 1700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1800 1800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1880 1880w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1900 1900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=1920 1920w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2000 2000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2048 2048w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2100 2100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2200 2200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2208 2208w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2280 2280w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2300 2300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2400 2400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2415 2415w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2500 2500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2560 2560w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2600 2600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2700 2700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2732 2732w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2800 2800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=2900 2900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3000 3000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3100 3100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3200 3200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3300 3300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3400 3400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3500 3500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3600 3600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3700 3700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3800 3800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=3900 3900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4000 4000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4100 4100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4200 4200w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4300 4300w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4400 4400w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4500 4500w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4600 4600w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4700 4700w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4800 4800w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=4900 4900w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=5000 5000w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=5100 5100w, https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=5120 5120w" src="https://kellysutton-blog.imgix.net/images/campaign-windows.png?ixlib=jekyll-4.2.0&amp;w=5120" sizes="(min-width: 700px) 700px, 100vw">
</figure>

<p>Using this approach yields a few benefits:</p>

<ul>
  <li>Organizers of the campaign provide a default prioritization approach. Team do not have to develop their own.</li>
  <li>By setting and enforcing “Not Allowed,” we ensure that progress is permanent. A team cannot introduce a new request that takes longer than a given amount of time.</li>
  <li>Teams are warned in advance of a future change. They might receive a weekly email report, an exception, or a Slack message notifying them of something that is okay today but not okay in the future.</li>
  <li>Incremental value is delivered. If we stop the Campaign for whatever reason, lasting value will remain.</li>
</ul>

<h2 id="an-example-global-request-timeouts">An Example: Global Request Timeouts</h2>

<p>I’ve threaded an example throughout this post, but let’s look at a specific example compiled together.</p>

<p>One that I’ve seen in a few organizations is the need to set and/or reduce the total amount of time a web request can take. This is the type of thing that can be easy to ignore, especially in applications serving industries with high switching costs or a <a href="https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem">Principal-agent problem</a>. (High switching costs or principle-agent problem mean a slow degredation of performance will never bubble up as a priority.) Many Campaigns take the form of “If we knew to have this limit in the first place, this would be a lot easier.”</p>

<p>Let’s put it all together.</p>

<div>

<p><strong>Goal:</strong></p>

<p>We want to improve the customer experience and resiliency of our system by limiting the amount of time a request can take.</p>

<p>We want to eventually get to 2 seconds for the 99th percentile of requests, with a hard cutoff of 5 seconds.</p>

<p>We talk more about this Goal, why it was chosen, and it’s urgency in <em>this longer document</em>. (Link to something convincing.)</p>

<p><strong>Metrics:</strong></p>

<ul>
<li>Number of endpoints not adhering to the Goal.</li>
<li>Number of endpoints within the Window.</li>
</ul>

<p><strong>Window:</strong></p>

<p>At the start, we’ll set the Window to:</p>

<ul>
<li>Warn: 30 seconds.</li>
<li>Not Allowed: 60 seconds (this is the current timeout setting).</li>
</ul>

<p>From there, we’ll look to increment the Warn threshold by 15 seconds, or N/2 each time.</p>

<p><strong>Campaign Manager:</strong></p>

<p>Jane Smith will be in charge of tracking progress and reporting on this Campaign.</p>

<p>Jane and Team X will be available to help teams get their requests to the goal. Team X is also responsible for unowned code in the system.</p>

<p><strong>Target Date:</strong></p>

<p>We’d like to be complete with this effort on January 1, 2021.</p>

</div>

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><a href="https://lethain.com/migrations/">“Migrations: The sole scalable fix to tech debt,” Will Lethain.</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Project_management">Project Management</a></li>
  <li><a href="https://en.wikipedia.org/wiki/OKR">Objectives and Key Results</a></li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>This post is a generalization of an effort I find myself doing more and more at Gusto. Every campaign is a little bit different, and needs to be adapted accordingly.</p>

<p>Hopefully this framework helps you and your teams make complicated technical changes that require large-scale behavioral or process changes.</p>

<hr>

<p>Special thanks to <a href="https://www.linkedin.com/in/tonirib/">Toni Rib</a>, <a href="https://mxstbr.com/">Max Stoiber</a>, <a href="http://www.dannyzlobinsky.com/">Danny Zlobinsky</a>, <a href="https://www.estebanpastorino.com/">Kito Pastorino</a>, and <a href="https://www.shayon.dev/">Shayon Mukherjee</a> for reading early drafts of this post and providing feedback.</p>





  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://kellysutton.com/2021/01/06/campaigns.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713656</guid>
            <pubDate>Sun, 10 Jan 2021 11:34:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Is Drowning the World]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25713631">thread link</a>) | @kiyanwang
<br/>
January 10, 2021 | https://jamesabley.com/software-is-drowning-the-world/ | <a href="https://web.archive.org/web/*/https://jamesabley.com/software-is-drowning-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>One of the many upsides I’ve had from working at lots of organisations
is that you get to see what’s common. Are things like this everywhere?
Frequently, the answer is yes!</p>

<p>An example of this is tech debt.</p>

<p>I see organisations which are running to stand still, and I’m not
sure they realised they’re doing that.</p>

<p>What do I mean by this?</p>

<p>Every time you decide to solve a problem with code, you are committing
part of your future capacity to maintaining and operating that code.
Software is never done.</p>

<p>Here’s a few examples of demonstrating what I mean:</p>

<h2 id="security">Security</h2>

<ol>
  <li>You write a networked service to solve a business problem. Say
it has an HTML web UI</li>
  <li>It has no known security issues</li>
  <li>Time passes</li>
  <li>You now have security issues with your code, and you should assess
 whether you need to do work to address these.</li>
</ol>

<p>WAT?</p>

<p>Humans are terri-bad at writing secure code. And given enough time,
other humans will discover the security holes in your service.</p>

<p>This applies both to code your organisation writes, and the libraries
they use, or the operating systems, or web servers, or …</p>

<h3 id="security-examples">Security Examples</h3>

<p>Take your pick from browsing a CVE database, or use
<a href="https://snyk.io/">Snyk</a> or similar to look at your current codebases.</p>

<ul>
  <li>TLS / SSL issues:
    <ul>
      <li><a href="https://en.wikipedia.org/wiki/POODLE">POODLE</a></li>
      <li><a href="https://blog.zoller.lu/2011/09/beast-summary-tls-cbc-countermeasures.html">BEAST</a></li>
      <li><a href="https://en.wikipedia.org/wiki/CRIME">CRIME</a></li>
      <li><a href="https://en.wikipedia.org/wiki/BREACH">BREACH</a></li>
      <li><a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a></li>
    </ul>
  </li>
  <li><a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=15183&amp;product_id=31286&amp;version_id=&amp;page=1&amp;hasexp=0&amp;opdos=0&amp;opec=0&amp;opov=0&amp;opcsrf=0&amp;opgpriv=0&amp;opsqli=0&amp;opxss=0&amp;opdirt=0&amp;opmemc=0&amp;ophttprs=0&amp;opbyp=0&amp;opfileinc=0&amp;opginf=0&amp;cvssscoremin=6&amp;cvssscoremax=0&amp;year=0&amp;month=0&amp;cweid=0&amp;order=1&amp;trc=20&amp;sha=97513f3fa07a803c5507b2cf550af9877acd90f2">Spring</a></li>
  <li><a href="https://www.cvedetails.com/vulnerability-list.php?vendor_id=45&amp;product_id=6117&amp;version_id=&amp;page=1&amp;hasexp=0&amp;opdos=0&amp;opec=0&amp;opov=0&amp;opcsrf=0&amp;opgpriv=0&amp;opsqli=0&amp;opxss=0&amp;opdirt=0&amp;opmemc=0&amp;ophttprs=0&amp;opbyp=0&amp;opfileinc=0&amp;opginf=0&amp;cvssscoremin=6&amp;cvssscoremax=0&amp;year=0&amp;month=0&amp;cweid=0&amp;order=1&amp;trc=70&amp;sha=5369e34293062ebe460c99e6878e0792ac23944c">Struts</a></li>
</ul>

<h3 id="legislation">Legislation</h3>

<ol>
  <li>You write a networked service to solve a business problem. Say
 it has an HTML web UI</li>
  <li>It has no known legal compliance issues</li>
  <li>Time passes</li>
  <li>You now have legal compliance issues with your code, and you should
 assess whether you need to do work to address these.</li>
</ol>

<p>WAT?</p>

<p>The <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation">General Data Protection Regulation</a>
addressed organisations not handling data very well.</p>

<p>Privacy and Electronic Communications Regulations – mostly known
for mandating cookie policy.</p>

<p>The Equality Act 2010 (UK) and the Americans with Disabilities Act
1990 (2010 update) for website accessibility. Yes, there was a time
when people didn’t consider accessibility when building web sites.</p>

<p>Brexit has meant a lot of changes for businesses in the EU and UK.
Software has been rewritten to manage the new trading relationships.
This will continue to happen for a while countries establish new
relationships.</p>

<h3 id="3rd-parties">3rd parties</h3>

<ol>
  <li>You write a service to solve a business problem</li>
  <li>You can build and release it when necessary</li>
  <li>Time passes</li>
  <li>You are now unable to build and release the service</li>
</ol>

<p>WAT?</p>

<p>3rd parties will change their APIs, or how things work. They may
do this for any number of reasons: performance, or security among
them. Older versions become deprecated, and unsupported. And these
older versions will still have new security issues reported against
them. So you need to upgrade, and adapt your code to use the new
API.</p>

<p>People building code libraries will strive to maintain backward
compatibility. But we still get <a href="https://semver.org/">semver</a> major
version changes, and breaking API changes.</p>

<h2 id="implications">Implications</h2>

<p>Most software needs constant maintenance. Building and operating
software has a cost which you should always factor in when deciding
to solve problems in that way.</p>

<p>A team working in a particular way can only be responsible for a
fixed amount of software. The amount of software should be managed,
otherwise the team will grind to a halt.</p>

<h2 id="proposition">Proposition</h2>

<blockquote>
  <p>A team working in a particular way</p>
</blockquote>

<p>What if we change how they work?</p>

<p>Well yes, there are options there.</p>

<p>I’ve got a separate post (currently brewing) about Dunbar’s numbers,
but for this post, different sized organisations might have different
options. At a certain size, it makes sense to have people dedicated
to developer productivity and creating tools which improve the
capacity of other teams.</p>

<p>You can choose higher-level languages, and use technology stacks
from SaaS vendors which need less time from your people.</p>

<p>There is one option I had planned to spend researching last year
(but I ended up getting a job instead). This feels like potentially
a big market. I’ve seen lots of organisations with decade-old
codebases which are still running unsupported versions of dependencies
or frameworks.</p>

<p>As a developer, I’m familiar with a hammer, and was curious if I
could use it.</p>

<p>Can we have tooling that automates keeping software up-to-date?</p>

<p>I see this problem in every organisation I’ve ever worked in, with
all aspects.</p>

<p>Web applications/APIs written in any language. As mentioned above,
there are many reasons that software rots if left unattended. Mobile
apps also have this. Migrating versions of Android, or iOS, or …</p>

<p>Configuration/manifests for Infrastructure as Code aslo suffer from
this. Terraform hasn’t yet released 1.x, but there have been many
changes over the years. If you’re using Cloud Foundry or Kubernetes,
you’ll <a href="https://github.com/doitintl/kube-no-trouble">have experienced
changes</a> which mean
you need to do work.</p>

<p>Automating the changes needed in YAML for upgrading from Kubernetes
<code>n</code> to <code>n+1</code> feels like a widely useful tool.</p>

<h2 id="current-state">Current State</h2>

<p>There are some commercial things which do related work.</p>

<p>Snyk, <a href="https://github.com/renovatebot/renovate">Renovate</a>,
<a href="https://dependabot.com/">Dependabot</a> and other things exist which
can make pull requests to update dependencies. Mpost languages have
a package tool and bumping numbers is pretty straightforward. These
things tend to not be able to manage breaking API changes though.
Bumping a patch or minor dependency upgrade is fine, but a major
one with breaking API changes tends to need a human to get involved.</p>

<p>Why? Could we have a tool that solves this? When a new version of
<a href="https://spring.io/">Spring</a> is released, could it include an
accompanying set of transformations which will allow the entire
ecosystem to safely and rapidly upgrade?</p>

<p>Having a minor interest in compilers (and having worked on a
commercial interpreter), I tend to think of code editing operations
as transformations, rather than characters. There’s been <a href="https://www.facebook.com/notes/kent-beck/prune-a-code-editor-that-is-not-a-text-editor/1012061842160013">some
research in transformation-based
editors</a>,
but I’ve not seen a lot else.</p>

<p>Major version upgrades could potentially be similarly expressed in
terms of transformations, which similarly might be composed. So if
a class has been removed between major versions of a dependency,
the required transformation might be composed of:</p>

<ol>
  <li>Insert new class <code>my.Y</code></li>
  <li>Implement interface <code>spring.new.Z</code></li>
  <li>Adapt method <code>A</code> from old class <code>my.Z</code> onto method <code>B</code> in new
 class <code>my.Y</code></li>
  <li>Adapt parameters from adapted method – a <code>Context</code>
 used to be obtained from <code>ApplicationSingleton</code> but is now passed
 in explicity</li>
  <li>etc</li>
</ol>

<p>And then you would need a serialisation format and publishing
mechanism for these sets of transformations.</p>

<p>The closest I’ve seen to this is where Google actually did that in
the same target langauge. They <a href="https://blog.golang.org/introducing-gofix">published a tool with for the
language Go</a>, named
<a href="https://golang.org/cmd/fix/"><code>fix</code></a>. It automated upgrades of
existing code before 1.x was released, and since then, they’ve had
<a href="https://golang.org/doc/go1compat">the Go 1 compatibility document</a>.</p>

<p>Sadly, <code>fix</code> appears to have been mostly inactive since then?</p>

<p>I’m interested (academically as well as commercially) in producing
a tool which looked something similar, but much more widely applicable.</p>

<p>So having something that can take code/configuration, generate an
Abstract Syntax Tree (AST), and then apply a set of transformations.
Transformations compose. A large one might be <strong>Upgrade Framework
<code>n</code> to <code>n+1</code></strong> involvings lots of smaller transformations. For each
transformation, you’d need to query the AST for usages of the old
API, then try to apply the transformation which maps the old API
to the new API.</p>

<p>I’ve found one related paper. Given that it’s not gone further, was
it too hard, or not viable, or the wrong time?</p>

<h2 id="summary">Summary</h2>

<p>So I think this would be the next evolution in automated upgrades.
It’s seems like a big market – how many companies would pay for you
to solve this problem for them and allow them to concentrate on
business logic rather than plumbing concerns?</p>

<p>But I didn’t take the time off I planned to confirm the potential
market and see how hard a problem it would be solve :)</p>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://jamesabley.com/software-is-drowning-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713631</guid>
            <pubDate>Sun, 10 Jan 2021 11:31:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Merpeople Say About Us]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25713617">thread link</a>) | @dnetesn
<br/>
January 10, 2021 | http://oceans.nautil.us/feature/660/what-merpeople-say-about-us | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/660/what-merpeople-say-about-us">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>M</span>erpeopleâ€™s hybridity has helped them maintain a presence in both scientific and mythological camps. In many peopleâ€™s minds, mermaids and mermen remain mythical creatures more suitable for bedtime stories than scientific tracts. Yet for others merpeople symbolize the outer limits of our scientific and mythological investigations.&nbsp;</p>

<p>Just as the evolution of science has not done away with lingering notions of wonder and myth, so too has our innate need to push boundaries of knowledge led humanity into strange—often mind-blowing—frontiers of research and self-reflection. Humanityâ€™s interaction with merpeople demonstrates our ongoing need for discovery as much as our attempts at regulation and classification. Like the hybrid monstrosities with which humankind has always grappled, humanity maintains a tenuous balance between wonder and order, civilization and savagery.&nbsp;<br></p>
<p>Perhaps nowhere is this fragile equilibrium more obvious than in the early Christian Churchâ€™s myriad representations of mermaids and tritons. Murky ideologies of mermaids and mermen originated in ancient gods and goddesses of the sea; although mermaids now rule as the more popular of the two, merpeopleâ€™s predominance began with mermen. The Babylonians had their fish-god Oannes dating back to 5,000 BCE, while the Philistines, Assyrians and Israelites created the â€˜female prototypeâ€™ for the mermaid with Atargatis, a fertility goddess who was the female counterpart to Oannes. Importantly, Atargatis also symbolized the danger of love and lust, an association which Christians would later embrace wholeheartedly.</p>
<p>A spate of pagan representations of merpeople followed Oannes and Atargatis, ranging from Greek and Roman depictions of Aphrodite and Venus, respectively, to Pliny the Elderâ€™s descriptions of mysterious human-fish sea creatures in 80 CE, to the Greeksâ€™ incorporation of Triton (the origin for the merman) and his wife Amphitrite, to Odysseusâ€™ fateful encounter with the harpies (airborne daughters of sea-goddesses) on his famous voyage. Oddly, harpies and the Greek â€˜Scyllaâ€™—hybrid monstrosities with little resemblance to half-fish, half-women mermaids—would ultimately spawn modern interpretations of mermaids. Over time, artists and writers took the helm in transforming the monstrous representations of Scylla and Homerâ€™s harpies into our modern interpretations of mermaids, replete with sexual overtones, siren songs and the overtly feminine (often naked) form. Thus, while mermen found their origins in a Greek god, mermaids largely originated from hideous beasts who only intended to bring man to destruction through his own lust for sex and power. As would be demonstrated by the early Christian Church, such connotations of sex, lust and power were no coincidence.</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_1dc26359e27a167f1bd1825f1abacd2e.jpg" alt="Screen Shot 2021-01-07 at 2.19.08 AM"><figcaption><span>â€˜Derceto [or Atargatis] Dominating the Seaâ€™, from Athanasius Kircher, Oedipus Aegyptiacus (1652). </span></figcaption></figure>
<p>Beginning in the third to fifth centuries CE, Church leaders simultaneously adopted, transformed and harnessed ancient pagan symbols of merpeople to assert notions of piety, faith and self- control. Although mermen had long been associated with rape and violence, the early Christian Church was on a mission to dethrone femininity, and had little use for these male monstrosities. Rather, churchmen hoped to transform notions of the Homerian harpy to fit their own means, and in doing so adopted more sexual connotations and imagery in their representations of mermaids.<br></p>
<p>Physical representations of merpeople were critical to this process. Our modern conception of the mermaid stems directly from early churchmenâ€™s depictions of these mysterious creatures. Traditionally shown as human females above the waist, with long, flowing hair and bare breasts, a mirror in one hand and a comb in the other, these half-women, half-fish served as ideal symbols of wonder and danger for Church leaders. Beyond utilizing such â€˜monstersâ€™ to demonstrate Godâ€™s ability to â€˜alter his own laws of natureâ€™, churchmen especially adopted these pagan creatures in an effort to depreciate the feminine—hence the overtly sexual representation of mermaids in church carvings, bestiaries, illuminated texts and artwork. Nakedness—especially as a vehicle for sexual lust—was rare in early Christian and medieval art. Thus, as topless women (who also boasted scaly fish-tails), mermaids would have harnessed a shock factor through image alone.</p>
<blockquote>Church leaders simultaneously adopted, transformed and harnessed ancient pagan symbols of merpeople.</blockquote>

<p>Oftentimes, in fact, church sculptors portrayed mermaids â€˜spreadingâ€™ their tails apart, thereby exposing their reproductive area—or <em>vesica piscis</em> (Latin for â€˜vessel of the fishâ€™)—in graphic detail. A mermaidâ€™s accessories also revealed deeper symbolism, with her mirror and comb representing vanity (not to mention the duality of oneâ€™s soul outside the body) and her flowing hair signifying fertility. Sometimes, mermaids would hold a fish instead of a comb, which probably further symbolized her link to the fish as an early symbol of Christianity. By the medieval period (the fifth to fifteenth centuries CE), churchgoers throughout Europe worshipped in spaces decorated with overtly sexualized mermaid imagery. Church leaders, meanwhile, cultivated an intimate knowledge of these strange creatures through myriad texts, art and sculpture. Such ubiquity helped to facilitate general acceptance of, and belief in, mermaids.&nbsp;</p>
<p>In symbolism used by the early Christian Church, mermen were not as popular as mermaids. When mermen occasionally appeared in church carvings, they were almost always paired with mermaids. This representation correlated with early Christian and medieval imagery—especially cultivated in illuminated texts and bestiaries—which generally depicted mermen as partners of mermaids. Mermaids were much more likely to appear alone than were mermen. In contrast to the beautiful (and dangerous) female form of the mermaid, moreover, authors and illustrators represented mermen either as ugly creatures intended to oppose the mermaidâ€™s striking femininity and sexuality, or as symbolic of Christian piety.&nbsp;</p>

<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_048a295d789994cc78e70cb5e3516b0a.jpg" alt="Screen Shot 2021-01-07 at 2.21.52 AM"><figcaption><span>Mermaid in the Luttrell Psalter (1325â€“40). </span></figcaption></figure>
<p>Ultimately, mermaids—hybrid creatures of myth and lore—symbolized the early Christian Churchâ€™s willingness to hybridize itself (that is, embrace a mix of pagan and Christian belief systems) in its larger attempts to cultivate the largest following possible. Here, the Christian Church deliberately adopted and adapted pagan symbols in its holy spaces, thereby bridging the gap between the supposedly â€˜savageâ€™ and the civilized; the past and the present. And it largely worked, as Christian doctrine steadily decentered symbols of the sacred feminine by the medieval period. However, such efforts had unexpected side effects, as by utilizing these hybrid monstrosities to support religious tenets the Christian Church legitimatized such creatures, which in turn created the foundation for belief and acceptance for generations to come.&nbsp;<br></p>
<p>The â€˜Age of Discoveryâ€™ (roughly 1500 to 1700 CE) only solidified Westernersâ€™ long-standing beliefs and cultural traditions surrounding merpeople. By 1492 Westerners had long lived in a world of merpeople: especially in wealthy, sea-faring societies like Venice or Genoa, merpeople became almost ubiquitous mainstays of art, ranging from tombs to tomes, sculptures to tableware. Unsurprisingly, by the time Westerners pushed further east and west into what were, for them, uncharted territories, they fully expected to find mermaids and tritons. They had, after all, lived their lives surrounded by these mysterious creatures. Importantly, before the â€˜Age of Discoveryâ€™, Europeans placed Jerusalem in the centre of the globe in terms of religious tradition. The further one got from Jerusalem, the stranger and more dangerous the world became. If merpeople lived anywhere, many early modern Westerners believed, it must be at the ends of the Earth, where monstrosities and curiosities thrived.&nbsp;</p>
<blockquote>The&nbsp;â€˜Age of Discoveryâ€™&nbsp;only solidified Westernersâ€™&nbsp;long-standing beliefs surrounding merpeople.<br></blockquote>
<p>As Westerners heightened their interactions with the Pacific and Atlantic worlds in a search for monetary, religious and imperial power, recorded sightings of merpeople multiplied exponentially. The Atlantic Ocean and its â€˜New Worldâ€™ shores were especially rife with such interactions, as famed explorers integrated merpeople into their understandings of strange—and potentially lucrative—environments. Yet, where in the medieval period interactions with mermaids and tritons usually uncovered a deeper lesson over lust, vanity or religion, early modern explorers transformed such contact beyond manifestations of the Christian creed and instead began to reflect in their â€˜mer-sightingsâ€™ emerging notions of exploration, growth and national prowess. Each Western country had its own stories of merpeople, and in each of these interactions the nation tried to assert its understanding of the globe. Monstrosities abounded in the New World, and Europeans were intent on uncovering their secrets. This was a period of legitimization for merpeople.&nbsp;</p>
<p>As sightings proliferated and European Christians steadily colonized the Americas, Western mapmakers began in earnest to chart these strange new worlds. Of course, such cartographic creations were as much about Europeâ€™s effort to position itself as a world power as they were about accurately recreating the New World topography. These maps were also, importantly, intended to demonstrate the exotic opportunity of the world, while also shrinking its size to suit Europeansâ€™ imperialist efforts. Therefore â€˜strangeâ€™ or â€˜foreignâ€™ lands like the Americas and the â€˜Far Eastâ€™ were often depicted with merpeople in their surrounding seas.This was no mistake, nor can it be boiled down to a temporary flight of fancy. Mapmakers intentionally included merpeople …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/660/what-merpeople-say-about-us">http://oceans.nautil.us/feature/660/what-merpeople-say-about-us</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/660/what-merpeople-say-about-us</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713617</guid>
            <pubDate>Sun, 10 Jan 2021 11:29:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Acquisition of Handwriting in the UK]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25713526">thread link</a>) | @dcminter
<br/>
January 10, 2021 | http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm | <a href="https://web.archive.org/web/*/http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

The information in this paper is based on research done by Frances Brown
under my supervision; many of the ideas in it are hers, and many come from
collaborative discussion. The paper was originally given at the Criminalistic
Institute in Prague, and was written to be presented there. 

<p>


<strong>1. Introduction and theoretical base.</strong>This paper reports on a project that was undertaken in 1982-3,
funded by the Home Office. It came from the fact that while document examiners
in the UK know a great deal about what the handwriting of UK citizens is
like, and know in general terms how that handwriting was learned, they in
fact know very little about the way in which the learning of handwriting
actually goes on in schools. So the project began with a very general remit:
to investigate the way in which handwriting is taught and learned in the
UK. What it turned into was an investigation into the whole issue of the
relationship between the taught style of handwriting and the way in which
that handwriting is actually done.</p><p>

It was clear from the outset that there are two sources from which handwriting
is learned: from copybooks, and from teachers. The investigation thus split
into two: we used surveys and sampling investigation to find out how handwriting
is actually taught in schools, and we conducted an extensive examination
and analysis of a large sample of the copybooks used in the UK in the lifetime
of any contemporary adult. </p><p>

In general what the project showed was this. Handwriting of UK citizens
is, compared with that of those educated elsewhere in Europe or in America,
very various. No uniformity is imposed centrally, at the governmental level,
or locally, by Local Educational Authorities. There are several different
handwriting systems to be found in the available copybooks, and each copybook
may present its own version of the system it derives from. Individual schools
may favour particular systems or particular copybooks, but often it is left
to the individual teacher of handwriting to adopt whatever method they feel
comfortable with. Moreover, even at the beginning of learning to write it
is not usually expected or demanded that the child should faithfully copy
the learned system, and, later in life, it is common for teenagers who to
change their writing style to make it look beautiful. This is true for both
boys and girls, but the evidence is that girls spend a lot more time at
it. In fact handwriting that follows a copybook style closely is commonly
seen as 'immature', or 'naive', or 'lacking in personality'; and idiosyncratic
or unusual or even messy handwriting is seen as showing valuable personality
traits: individuality, creativity, and so on. As a result, the handwriting
of mature adults can vary considerably from the learned system, containing
a mixture of elements deriving from any combination of (1) the system itself,
(2) the particular copybook version of that system, (3) a school-teacher's
version of the copybook, (4) the individual's own idiosyncratic variation,
and (5) curious features that occur in no copybook but are nonetheless commonly
found, presumably having spread through the culture by some form of osmosis.
This means that when someone says: 'how would you characterize the handwriting
of the UK?' they are asking a question that is very hard to answer; in fact,
it is a question that no-one <cite>could</cite> answer before this project
was undertaken.</p><p>

So: the situation that we discovered is complex, but it is not chaotic.
General patterns were discovered, and interesting sub-patterns. Before giving
the detail of the findings, however, it is necessary to establish some terminology.</p><center><a href="http://www.unask.com/website/handwriting/new_web_pages/terms.htm"><strong>Summary of Terminology</strong></a>
</center>
<div><p>Handwriting in the UK is learned at school, usually beginning at the
age of 5 or so, by copying. What is copied is a formal <strong>system. </strong>We
discovered from a close analysis of some 50 handwriting copybooks, which
we believe represent all of the published styles available in the lifetime
of any adult, that their apparent diversity can be reduced to four basic
systems: <strong>Print Script, Round Hand, Looped Cursive, </strong>and<strong>
Italic.</strong> However the actual version of the system that the child
copies will normally come from a particular copybook, which may have its
own variation or dialect of the basic system; or what a child actually copies
may be work materials prepared by a teacher, with the teacher's own variations
added. If a child moves from one school or even one teacher to another,
he or she may be exposed to two different copybooks or even two different
systems. Nonetheless, it is usually possible to detect traces of the system,
though not the actual copy book version of it, that a given person has been
taught.</p><p>

By repeated attempts to copy this basic pattern the child learns the necessary
skills of motor-co-ordination. The child first learns Print Script, a simple
unjoined alphabet, and then learns a joined style based one of the other
three main systems. As the mature hand develops, eventually by the end of
the teenage years evolving into the stable final hand that will (usually)
serve the individual for the rest of his or her life, two kinds of characteristic
can be ascertained. We call these <strong>individual characteristics</strong>
and <strong>style characteristics</strong> . Individual characteristics
are those components of a given hand that make it unique: they are what
document examiners are mainly interested in. But in each hand there will
also be a residual set of style characteristics: those elements which are
shared with other members of a group or groups. Style characteristics come
in three kinds: <strong>system characteristics</strong> , that serve to
identify which of the four general classes or systems the learned style
derives from; <strong>copybook characteristics</strong> , that can definitely
be linked to a particular copybook version of the basic system; and, finally,
what we call <strong>underground characteristics</strong> , which are those
features which are shared with other writers, but which do not occur in
any copybook. So for example the following letter-forms, familiar to all
UK handwriting examiners, are not as far as we know part of any of the basic
systems or their copybook dialects:</p></div><center><a href="http://www.unask.com/website/handwriting/new_web_pages/underground.htm"><strong>Underground characteristics</strong></a><strong>.</strong>
</center>
<div><p>Some underground characteristics may actually be learned at the stage
when handwriting is initially acquired, deriving from the practice of teachers
who modify the copybook system that they teach, for whatever reason, thus
incorporating underground characteristics at this early stage. Normally,
however, they seem to be picked up later, presumably by imitation.</p><p>

Since in the UK (and in other countries too) the normal process of teaching
handwriting is to teach first one system, the unjoined Print Script, and
then a second, cursive or joined up system, it is the latter that normally
is the basis of the set of system characteristics in the mature hand. Rather
confusingly, however, the original Print Script is not seen as being a system
at all, but as 'basic writing', which is then 'joined up', under the influence
of some taught system, to form a cursive style. In fact what happens is
that two successive <cite>systems</cite> are learned, the latter superseding
the former: Print Script is as much a copybook system, with a history and
a designer, as any other. But because of the misconception that Print Script
is not a system, this form is not often seen in adult handwriting. It is
widely associated with semi-literacy, where the writer is assumed not to
have progressed on to the 'joined up' writing.</p><p>

The case of capitals is also curious. The child learns two forms: Print
Script is taught in a lower and upper case form. The cursive scripts that
follow it also have their own particular kind of capitals, and these are
learned; but they are only used when the writer is doing their normal writing.
When an adult is required to fill in a form and asked to write in capitals
for the purpose of clarity, they will usually produce Print Script capitals.
(The practice found elsewhere in Europe of producing a print script lower
case form when asked to write clearly--to 'print'--is rare in the UK.) These
Print Script capitals are known as <strong>block capitals</strong> , and
considered (incorrectly) to be a separate style: they are not associated
in most people's minds with the 'childish' style of Print Script. Since
for most people filling in forms is only a small part of the writing that
they do, block capitals are not much practiced and therefore retain quite
purely their Print Script style: they are less embellished than cursive
writing with individual or underground characteristics. Therefore block
capitals are commonly used in writing that wishes to remain anonymous. However,
some writers have more practice than others in writing block capitals, and
they have evolved styles of their own. All of these styles are underground:
no style of block capitals other than Print Script is taught or published.</p></div><center><a href="http://www.unask.com/website/handwriting/new_web_pages/caps.htm"><strong>Styled Block Capitals</strong> </a></center>
<div><p>As far as document examiners are concerned the relevance of this outline
of handwriting acquisition is as follows. The part of their job that concerns
handwriting examination can be said to have two aspects: <strong>identification</strong>
and <strong>categorization</strong> . Identification deals with those tasks
that involve stating whether or not a particular piece of writing was, or
was not, written by a particular individual. Categorization deals with the
problem of anonymous writing, and involves saying whatever can be said to
describe the anonymous writer. For example: was this writing done by someone
who was left-handed? At the moment the former is far more important, partly
because relatively little proper research has been done on the latter. </p><p>

Categorization deals entirely--by definition--with style characteristics:
those characteristics that are shared with other writers. Identification
deals with both: with individual characteristics--again, by definition--but
also with style characteristics, since in particular cases the appearance
of certain of these in a particular hand may serve to distinguish the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm">http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm</a></em></p>]]>
            </description>
            <link>http://www.unask.com/website/handwriting/new_web_pages/acquisition.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25713526</guid>
            <pubDate>Sun, 10 Jan 2021 11:18:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Hacker Space (2007) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712952">thread link</a>) | @Tomte
<br/>
January 10, 2021 | https://events.ccc.de/congress/2007/Fahrplan/attachments/1003_Building%20a%20Hacker%20Space.pdf | <a href="https://web.archive.org/web/*/https://events.ccc.de/congress/2007/Fahrplan/attachments/1003_Building%20a%20Hacker%20Space.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://events.ccc.de/congress/2007/Fahrplan/attachments/1003_Building%20a%20Hacker%20Space.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712952</guid>
            <pubDate>Sun, 10 Jan 2021 09:52:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CTO day 2: downsizing the team]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25712771">thread link</a>) | @delebe
<br/>
January 10, 2021 | https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/ | <a href="https://web.archive.org/web/*/https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="entry-summary">On your first day as newly appointed CTO you are working on your hiring strategy, the second day your organization asks you to downsize the team.</p><div><p>A very important project that was a done deal, and that will secure the organization’s future for the next five years, failed to happen.</p><p>Not winning this project meant that the organization was forced to <em>“focus”</em> and reduce costs.</p><p>It never crossed my mind that one of the first things that I would be asked to do as an inexperienced CTO would be to fire part of the team.</p>
<p>when such bad news becomes public, host an open door day where the team can openly talk about the situation, share their feelings, see each other, feel connected, and be listened to. It would not stop the gossiping but it will help.</p><h2>Cuts and team principles</h2><p>The Dev team slice of the <em>“focus”</em> meant cutting cost by 10 to 15%. In human terms, firing two to four people (out of 17).</p><p>After some failed attempts to approach this task, this is what worked for me.</p><p>I started by listing some principles: </p>
<ul>
  <li>For each product, we need to cover the following disciplines: Frontend, Backend, Architecture, Operations, Mobile, UX, Design, QA, Leadership, and Product Management.</li>
  <li>There are broadly 3 experience levels:
  <ul>
    <li>Senior: creates the plan.</li>
    <li>Mid-level: follows the plan.</li>
    <li>Junior: needs to be taught to follow the plan.</li>
  </ul></li>
  <li>No number of junior people can do some work a senior person can do.</li>
  <li>Not having a senior person in a discipline will mean that the product quality will suffer:
  <ul>
    <li>If a senior creates a plan, a team of mid-level+juniors can follow the plan for some time (2-3 years?) before the product becomes a big mess.</li>
    <li>To get out of a big mess, we need senior people.
    <ul>
      <li>We are already in a big mess with Product A and Product B.</li>
      <li>With the current team, it feels Product A is getting out of the mess.</li>
    </ul></li>
  </ul></li>
  <li>Independent (cross-functional) teams are more efficient:
  <ul>
    <li>More focus.</li>
    <li>No handoffs, faster feedback.</li>
    <li>No shared “resource” contention.</li>
  </ul></li>
  <li>People working in multiple products/teams are less efficient.</li>
  <li>Multidisciplinary (generalist) people:
  <ul>
    <li>Can cover the need for several of the disciplines.</li>
    <li>They can be junior in one discipline and senior in another.</li>
    <li>Allow focusing on any priority, without creating artificially important work for single-disciplined members.</li>
  </ul></li>
  <li>Max team size: 2 pizza teams 6-8.</li>
</ul><p>The ideal team would be one that has all disciplines covered at a senior level with multidisciplinary people working in just one team, and with enough overlap to avoid a <a href="https://en.wikipedia.org/wiki/Bus_factor">bus factor</a> of one. Additional people will bring additional capacity.</p><h2>Inverse Conway’s maneuver</h2><p>We have been working on bringing three of the products together for some time. They were already under the same product manager, but they were still three teams working on their own priorities. Merging them into one team, in a classic <a href="https://danlebrero.com/2020/01/08/do-i-need-a-gateway-api-team-dynamics/#content">inverse Conway’s maneuver</a> would hopefully accelerate the integration between the products.</p><p>One of the other products was small enough that for this task I decided to temporarily ignore it.</p><p>Following the principles above and the product considerations, the plan was to move the previous team setup from:</p><p><img src="https://danlebrero.com/images/blog/cto/day2/old-team-structure.jpg" alt="old team structure"> </p><p>To something like (boxes represent skills, not people):</p><p><img src="https://danlebrero.com/images/blog/cto/day2/new-team-structure.jpg" alt="new team structure"> </p><p>So two products, two cross-functional teams. Platforms and design teams will be reshuffled inside those two teams.</p><h2>Which parent do you love most? A computer will tell</h2><p>With a clear plan for the team, the next step was to <em>“just”</em> pick up who will work on each team, and who we will need to let go. The most painful decision in my career. </p>
<blockquote><p><a href="https://danlebrero.com/2019/11/27/becoming-a-technical-leader-book-notes/#content">People with a strong technical background can convert any task into a technical task, thus avoiding work they don’t want to do.</a> <cite>Jerry Weinberg, Becoming a Technical Leader</cite></p>
</blockquote><p>And I didn’t want to do the task so, consciously ignoring Mr. Weinberg, I transformed the ordeal into an optimization problem, for which I wrote an application to help me with.</p><h3>The app</h3><p>The application took as input the amount of $$$ to cut, the list of people, their salary, and the skill level on each discipline mentioned above, and outputted the possible two teams that would be within budget and match the minimum requirements, sorted by a scoring system.</p><p>The minimum requirements and scoring system configuration looked like:</p>
<pre><code>{
"FE" [at-least-senior sum-skills]
"PM" [senior-plus-somebody-else (fix-points 5)]
"Design" [two-mid-or-senior (senior-better 6 2)]
...
}
</code></pre><p>The first function filters out invalid teams while the second scores the valid ones.</p><p>In the example we say that the team has to have:</p>
<ul>
  <li>At least one senior FE developer. The more FE developers, the better team score.</li>
  <li>At least one senior product manager and one mid or junior one. Only one senior is not enough. No matter how many PMs the team has, the score for this discipline is 5. A team with loads of FE devs will score higher than one with loads of PMs.</li>
  <li>At least a senior designer or two mid-level designers, but we prefer one senior designer (6 points) instead of two mid-level ones (2 points).</li>
</ul><h3>The result</h3><p>As heartless as this may seem:</p>
<ul>
  <li>It removed some bias. There is still bias on the skill level evaluation and in the team scoring system.</li>
  <li>I was part of the people on that list. To be honest, little consolation here. Big bias.</li>
  <li>It forced me to be very very precise on what a “functioning team” meant.</li>
  <li>It allowed me to see what different scoring systems would output.</li>
  <li>I noticed some people would never show in the output, and had to dig into why. It was enlightening.</li>
  <li>It allowed me to analyze tens of thousands of different team combinations, with different scoring systems.</li>
  <li>Programming gave me a respite from the task. This was the first time, but now I embrace more regularly “keep my sanity” programming days.</li>
</ul><p>Most important, the application gave me a few starting points. Of those, I still had to consider the team dynamics, existing teams, personalities, seniority, potential, personal situation, future needs, …</p>
<p>yes, I still have the code. No, I am not going to share it publicly. It would kill me to find there is a bug.</p><h2>Delivering the bad news</h2><p>Once the decision was made, it was time to swallow the last bitter pill.</p><p>Some tips:</p>
<ul>
  <li>Ensure that the people affected are the first ones to know.</li>
  <li>Warn beforehand:
  <ul>
    <li>Do not use your regular one-to-one meeting slot.</li>
    <li>In your message, give a strong hint: “HR person will be in the meeting”, “Really bad news”.</li>
    <li>Give them time to get ready for the meeting.</li>
  </ul></li>
  <li>You don’t need to do it alone. Our HR manager was present and was a huge support for both of us.</li>
  <li>Treat people like adults.</li>
  <li>At the meeting, follow Nadia van der Vlies’ <a href="https://danlebrero.com/2020/04/01/no-nonsense-leadership-summary/#bad-news">advice</a>:
  <ul>
    <li>Deliver the blow:
    <ul>
      <li>Go straight to the bad news.</li>
      <li>Give one or two reasons.</li>
    </ul></li>
    <li>Manage the reaction:
    <ul>
      <li>Be understanding. Do not justify yourself.</li>
      <li>Give space. Do not fill silences.</li>
    </ul></li>
    <li>Solution, explanation, follow-up appointment:
    <ul>
      <li>Wait for the employee to be ready. When she starts asking “why” or “what now”.</li>
      <li>Reiterate reasons.</li>
    </ul></li>
  </ul></li>
  <li>In a couple of days follow up with another more informal meeting. The news would have sunk, and the conversation would be more forward-thinking and productive.</li>
</ul>
<hr><p>A slap in the face to awaken me from the dream that a CTO role is mostly about technology.</p></div></div>]]>
            </description>
            <link>https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712771</guid>
            <pubDate>Sun, 10 Jan 2021 09:27:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Noise Planets]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25712767">thread link</a>) | @atulvi
<br/>
January 10, 2021 | https://avinayak.github.io/art/2021/01/09/noise-planets.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/art/2021/01/09/noise-planets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://avinayak.github.io/uploads/erporydxmaarwcd.png" alt=""></p>

<p>I recently found this piece of art (LINES 2A (2017)) created by <a href="https://twitter.com/tylerxhobbs">Tyler Hobbs</a>. This picture kinda looked very hand drawn, but it’s completely generative. Something about this drawing and it’s texture kind of resonated with me, so I wanted to try to study and replicate (or make something inspired by this work) using p5js.</p>

<p>I started out by plotting a bunch of random points within a circle like so.</p>

<div><div><pre><code>w = 1000
function setup() {
  createCanvas(w, w);
  background('#F9F8F4');
}

function draw() {
  x = random(w)
  y = random(w)
  if (pow(w/2 - x, 2) + pow(w/2 - y, 2) &lt; 7e4) {
    point(x,y)
  }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-25.png" alt=""></p>

<p>This is a painfully slow process to generate random points in a circle. I found a better way to do this later. What I wanted to do next was to generate flow fields, but restricted to the circular region.</p>

<p>It’s super easy to generate flow field patterns using perlin noise.</p>

<ol>
  <li>Choose a random point <code>&lt;x,y&gt;</code></li>
  <li>Plot <code>&lt;x,y&gt;</code></li>
  <li>Calculate <code>n = noise(x,y)</code></li>
  <li>Do <code>x+=cos(n * 2 * PI)</code> and <code>y+=sin(n * 2 * PI)</code></li>
  <li>Repeat 2.</li>
</ol>

<p>We’re going to plot flow fields inside the circle. Let’s try this.</p>

<div><div><pre><code>const is_in_circle = (x, y) =&gt; 
  (pow(w / 2 - x, 2) + pow(w / 2 - y, 2) &lt; 7e4)

function draw() {
  if (is_in_circle(x = random(w), y = random(w)))
    while (is_in_circle(x, y)) {
      n = noise(x, y)
      x += sin(n * TAU)
      y += cos(n * TAU)
      point(x, y)
    }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-28.png" alt=""></p>

<p>OK, not very good. The noise at this level is pretty rough. we’re going to zoom in to the noise function (by dividing the <code>x,y</code> inputs by some constant value) and probably use <code>circle(x ,y ,0.3)</code> to plot points instead if point function, because I feel it looks way smoother. Also, I’m adding a <code>random() &gt; 0.01</code> condition in the loop so that we also get short lines that are not trimmed away by the edge of the circle.</p>

<div><div><pre><code>function draw() {
  if (is_in_circle(x = random(w), y = random(w)))
    while (is_in_circle(x, y) &amp;&amp; random() &gt; 0.01) {
      n = noise(x / 500, y / 500)
      x += sin(n * TAU)
      y += cos(n * TAU)
      circle(x, y, .3)
    }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-27.png" alt=""></p>

<p>Actually.. not bad. I think we manage almost replicate the original texture. The inverted version also looks pretty good.</p>

<p><img src="https://avinayak.github.io/uploads/download-19.png" alt=""></p>

<p><img src="https://avinayak.github.io/uploads/ppanets.png" alt=""></p>

<p>I went ahead and made a つぶやきProcessing version of this.</p>

<blockquote><p lang="en" dir="ltr">function setup(){createCanvas(w=1e3,w),background("<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a>")}function draw(){if(g(x=random(w),y=random(w)))for(;g(x,y)&amp;&amp;random()&gt;.01;)n=noise(x/500,y/500),x+=sin(n_TAU),y+=cos(n_TAU),circle(x,y,.3)}g=((n,o)=&gt;pow(w/2-n,2)+pow(w/2-o,2)&lt;w*w/16); <a href="https://t.co/iVZTMtCn3i">pic.twitter.com/iVZTMtCn3i</a></p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1347903013042622467?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>


<h2 id="going-further-animations">Going Further: Animations</h2>

<p>The code we wrote right now technically is animated. The animation however is not very smooth.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_03-52-31.mp4" type="video/mp4"> </video>

<p>To make smooth animations, we need to generate new points in the circle, keep track of these points outside the <code>draw()</code> function. I found this neat <a href="https://stackoverflow.com/a/50746409">technique</a>, to find random points in a circle where a random radius <code>r</code> and angle <code>theta</code> are chosen and the <code>x,y</code> points are obtained as <code>x = centerX + r * cos(theta)</code> and <code>y = centerY + r * sin(theta)</code></p>

<p>Let’s try that first.</p>

<div><div><pre><code>function random_point() {
  r = random(w / 4)
  t = random(TAU)
  return [
    w/2 + cos(t) * r, 
    w/2 + sin(t) * r
  ]
}

function setup() {
  createCanvas((w = 1e3), w);
  background(255)
  k = w / 2
  m = (Array(w).fill(0)).map(random_point)
}

function draw() {
  for (i = k; --i;) {
    [x, y] = m[i]
    circle(x, y, .3);
  }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-01-10-04-51-20.png" alt=""></p>

<p>and now we apply flow fields and try to move these points.</p>

<div><div><pre><code>function random_point() {
  r = random(w / 4)
  t = random(TAU)
  return [
    w/2 + cos(t) * r, 
    w/2 + sin(t) * r
  ]
}

const w = 1000
function setup() {
  createCanvas(w, w);
  background('#F9F8F4')
  k = w / 2
  points = (Array(k).fill(0)).map(random_point)
}

function draw() {
  for (i = k; --i;) {
    [x, y] = m[i]
    x += sin(n = noise(x / 400, y / 400) * TAU) * h
    y += cos(n) * h
    stroke(i%255)
    circle(x, y,.3)
    if (pow(k - x, 2) + pow(k - y, 2) &lt; 7e4)  // if point is in circle
      points[i] = [x, y, t]
    else points[i] = random_point() // replace with new point if not
  }
}
</code></pre></div></div>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_04-56-11.mp4" type="video/mp4"> </video>

<p>And a つぶやきProcessing version of course..</p>

<blockquote><p lang="cy" dir="ltr">t=0,p=i=&gt;\[k+(r=random(w/4))_cos(t+=.1),k+r_sin(t)\],setup=i=&gt;{createCanvas(w=1e3,w),m=Array(k=w/2).fill(0).map(p)},draw=r=&gt;{for(i=k;--i;)\[x,y\]=m\[i\],x+=sin(n=noise(x/k,y/k)_TAU),y+=cos(n),stroke(i%4_85),point(x,y),k_w+x_x+y_y-w_(x+y)&lt;7e4?m\[i\]=\[x,y\]:m\[i\]=p()};//<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a> <a href="https://t.co/xVhCBNUltL">pic.twitter.com/xVhCBNUltL</a></p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1347930637227855874?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>


<h2 id="adding-colors">Adding Colors</h2>

<p>There are many strategies to colorizing this sketch. One is by just giving each particle a random initial color.</p>

<p><img src="https://avinayak.github.io/uploads/download-21.png" alt=""></p>

<p>However, I found that maintaining the initial x or y position in the particle array and using that to derive the hue information gives us some nice Jupiter/gaseous planet vibes.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_05-18-19.mp4" type="video/mp4"> </video>

<p>The fringing at the sides can be avoided by moving 50% of the points in the reverse direction.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_05-28-03.mp4" type="video/mp4"> </video>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_08-43-25.mp4" type="video/mp4"> </video>

<p>More color variations</p>

<p><img src="https://avinayak.github.io/uploads/untitled.png" alt=""></p>

<p>And that’s it. Hope this was educational!</p>

</div></div>]]>
            </description>
            <link>https://avinayak.github.io/art/2021/01/09/noise-planets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712767</guid>
            <pubDate>Sun, 10 Jan 2021 09:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blocks Courtesy of Konrad Zuse (2014)]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25712727">thread link</a>) | @todsacerdoti
<br/>
January 10, 2021 | https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse | <a href="https://web.archive.org/web/*/https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apparently, I've got a theme going of Weird Syntax. Let's run with it.</p>

<p>Konrad Zuse was an early pioneer in computer science, although his name is perhaps somewhat less well-known than others. Zuse holds the honor of having built the first programmable computer—-the Z3—-back in the 40's, as well as several other computing firsts<sup id="fnref:1"><a href="#fn:1" rel="nofollow">1</a></sup>. Of particular interest to this blog post is his early unimplemented programming language, Plankalkül.</p>

<p>Plankalkül was, like the Z3, in many respects ahead of its time. Zuse's explicit goal was to be able to describe programs at a high level, which meant he included control structures and datatype definitions<sup id="fnref:2"><a href="#fn:2" rel="nofollow">2</a></sup> and other high-level constructs that were often missing in languages of the early years of computing. Zuse was working on Plankalkül at a time when his machines were not useable, which meant that his language work was more theoretical than it was technical, and consequently he allowed features that he wasn't entirely sure how to program. Despite his notes on it having been written in the mid-40's, they were not published until the 70's, and it was not implemented until the year 2000.</p>

<p>One thing that struck me, as I read programs in this notation that had been set down on a typewriter<sup id="fnref:3"><a href="#fn:3" rel="nofollow">3</a></sup>, is that certain kinds of grouping were handled by explicit indication of scope: not via matched delimiters as in ALGOL-style languages, or via indentation in languages such as Python and Haskell, but by formatting the code so that a line bordered on the left of the scoped parts of the code:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-01.png" alt=""></p>

<p>This is meant to capture the way grouping works in the hand-written or typeset notation, with brackets spanning multiple lines:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-02.png" alt=""></p>

<p>I think this is notationally interesting: it's like Python's significant whitespace, but not, uh, whitespace. It would be incredibly tedious to type out, but still entirely compatible with current programming notation:</p>

<pre><code>class Tet
 | @staticmethod
 | def new_tet()
 |  | n = randint(0, len(Tet.Tets) - 1)
 |  | for p in Tet.Tets[n]
 |  |  | if p in Board.permanent
 |  |  |  | Game.lose()
 |  | Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 |
 | def __init__(self, points, color)
 |  | self.points = points
 |  | self.color = color
</code></pre>

<p>and would be entirely amenable to beautifying via judicious application of Unicode:</p>

<pre><code>class Tet
 ┃ @staticmethod
 ┃ def new_tet()
 ┃  ┃ n = randint(0, len(Tet.Tets) - 1)
 ┃  ┃ for p in Tet.Tets[n]
 ┃  ┃  ┃ if p in Board.permanent
 ┃  ┃  ┗  ┗ Game.lose()
 ┃  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ┃
 ┃ def __init__(self, points, color)
 ┃  ┃ self.points = points
 ┃  ┗ self.color = color
</code></pre>

<p>Looking at this notation, however, an interesting possibility struck me: a programmer could explicit annotate information about the <em>kind of scope</em> involved in a given line. In this Python-like example, I could, for example, distinguish class scope using double lines, function scope with thick lines, and control structure scope with thin lines:</p>

<pre><code>class Tet
 ║ @staticmethod
 ║ def new_tet()
 ║  ┃ n = randint(0, len(Tet.Tets) - 1)
 ║  ┃ for p in Tet.Tets[n]
 ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
 ║  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ║
 ║ def __init__(self, points, color)
 ║  ┃ self.points = points
 ║  ┗ self.color = color
</code></pre>

<p>One advantage of this scheme is that a handful of lines, viewed in isolation, still give you a clear view of what surrounds them. For example, I can view these two lines in isolation and still tell that they are within a control structure used within a function declared within a class:</p>

<pre><code> ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
</code></pre>

<p>You could also imagine a hypothetical language in which choice of scope delimiter is important. In Python, <code>for</code> and <code>if</code> do not form a new lexical scope. What if instead we could stipulate the kind of scope they form by this notational convention?</p>

<pre><code>def okay()
 ┃ if True
 ┃  └ n = 5   # n is declared in function scope
 ┗ return n   # n leaks out of the if-scope

def not_okay()
 ┃ if True
 ┃  ┗ n = 5   # n is declared in the if's scope
 ┗ return n   # error: no n in scope here
</code></pre>

<p>That being said, there are a number of reasons that this notation is in inferior to existing notations:</p>
<ul><li>It makes refactoring code <em>much</em> more difficult.</li>
<li>It requires that the programmer <em>pay attention</em> to the sequence of enclosing scopes on a <em>line-by-line</em> basis, which is generally too pedantic and not particularly useful for a programmer.</li>
<li>The ability to select “which kind of scope” is by no means only expressible by this notation, as other syntactic features such as keywords and delimiters could express the same thing.</li>
<li>There are only so many line-like characters which can serve as a scope marker, so this scheme is not very extensible.</li>
<li>It complicates parsing (especially by introducing an entirely new class of parse errors in which adjacent lines feature incompatible sequences of delimiting lines), and so it also...</li>
<li>Complicates parse <em>error messages</em>, which are an important part of a language's UI and should be considered seriously.</li></ul>

<p>So, as in my previous post on <a href="https://journal.infinitenegativeutility.com/2014/8/noun-case" rel="nofollow">grammatical case in programming languages</a>, I urge readers <em>not</em> to use this notation as the concrete syntax for a programming language. This is merely an entertaining peek through the looking glass at a curious notational convention which was never adopted.</p>

<p>That said: this makes a very nice notation for <em>viewing</em> code, where the programmer does not have to explicitly draw ASCII art around their code; indeed, it bears more than a passing similarity to the graphical interface used in <a href="http://scratch.mit.edu/" rel="nofollow">Scratch</a>, and Sean McDirmid's <a href="http://research.microsoft.com/en-us/projects/liveprogramming/typography.aspx" rel="nofollow">Experiments in Code Typography</a> features this very convention as an interactive ornament on code in a Python-like language.</p>

</div></div>]]>
            </description>
            <link>https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712727</guid>
            <pubDate>Sun, 10 Jan 2021 09:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gekko: OS software used by the Danish gov. for economic forecasting]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712719">thread link</a>) | @stilisstuk
<br/>
January 10, 2021 | http://t-t.dk/gekko/ | <a href="https://web.archive.org/web/*/http://t-t.dk/gekko/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Instead of Gekko, why not use for instance Python, or R, or GAMS, or MATLAB, or SAS, or Excel, or … ?</p>
<p>Software packages are typically aimed at some purpose, and this is reflected in, among other things, the underlying data structures and the syntax of the command language.</p>
<p>Since Gekko is timeseries-oriented, the syntax for handling and analyzing timeseries and timeseries-based models is concise and natural. Gekko does not try to do everything, but tries to focus on its strong points, while simultaneously providing good interfaces to other software packages.</p>

			</div></div>]]>
            </description>
            <link>http://t-t.dk/gekko/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712719</guid>
            <pubDate>Sun, 10 Jan 2021 09:20:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Humans Have Rights and So Should Nature]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712528">thread link</a>) | @CapitalistCartr
<br/>
January 10, 2021 | http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>H</span>umans once lived in harmony with the natural world. Consider timekeeping. Until relatively recently, the human notion of time was based on the natural rhythms of nature. Time was measured by a new moon, the first snow, a migrating bird, or the ebb and flow of a river. Time meant situating ourselves as part of a larger web of life.</p><p>Western society has since lost its connection to nature. Human-created days, hours, minutes, seconds meticulously dictate our lives. Our sense of time is now detached from the world around us. Modern clocks provide many important services by establishing predictability in a complex and fast-paced world. But the loss of our interconnectivity with nature’s timekeepers has diminished our relationship with nature.</p><figure data-alt="Wilson_BREAKER"><img src="http://static.nautil.us/18075_0bbe3f9c489c409d1d6e229ccd23ab00.png" width="733" alt=""><figcaption><span><strong>OF TIME AND THE RIVER:</strong> The Anchorage Museum displays “Alaska River Time,” an art project by Jonathon Keats, which uses the natural flow of a river as a timekeeping standard. Keats’ project exemplifies the growing cultural awareness of our interrelationship with nature.</span><span>Courtesy of the Anchorage Museum</span></figcaption></figure><p>Timekeeping is not the only way in which we have lost touch with nature. Many elements of Western society treat humans as separate from and superior to the natural world. Nature was once perceived as living—even sacred. Now it is treated as a human commodity. Under Western legal systems, humans possess rights while the rest of nature does not. Entire cities have been built over once wondrous ecosystems that we sparsely acknowledge. Few people realize that entombed rivers still flow invisibly below cities such as New York, London, and Paris. Nature is still here, but it is often subjugated and ignored.<br></p><p>We can reclaim our deep relationship with nature, essential to solving the environmental crisis. It begins with two movements: cultural and legal. The cultural one arises from artists, writers, and other creatives whose work reshapes our thinking by underscoring that humans are part of nature, not separate from it. The legal one involves harmonizing human laws with the laws of the Earth. This means rewriting the legal system so it represents nature’s rights and interests directly alongside our own. A new generation of “Earth lawyers,” including me, have taken up this challenging task.</p><p><span>T</span>he illusion of separation between humans and nature began about 11,000 years ago, when the first agriculture-based societies emerged. From 800 to 300 B.C., philosophers and religions began to champion human superiority and dominion over nature. Scientists like Francis Bacon and philosophers like René Descartes popularized their conceptions of Earth as a machine or giant clock that was possible to control and exploit as long as we pulled the right levers.</p><p>Midway through the 18th century, the Industrial Revolution catalyzed the development of an economic system that viewed nature as a form of natural capital rather than a life source. New economic paradigms encouraged industry to incessantly exploit nature to fuel monetary growth without limits. Modern democracy and human rights also emerged during this period, but they focused on the well-being of individuals rather than the larger community of life. In accordance with the dominant systems of law and economics, society came to normalize the separation of humans and nature.</p><blockquote><p>The law establishes a legal duty for humans to protect and restore ecosystems to health because that is their right.</p> </blockquote><p>The next period, from post-World War II through the present, is sometimes called the “Great Acceleration.” Measures of human growth and impact, such as population, GDP, water and energy use, ocean acidification, and forest loss, began to increase nearly exponentially during this time.<sup>1</sup> New economic policies commodified nearly all aspects of life, including air, water, forests, countless plant and animal species, and food, among others. Corporations began to exploit unprotected ecosystems until they reached total collapse. Consumerism became a way of life.<br></p><p>We have killed off 68 percent of vertebrate animal populations over the last 50 years.<sup>2</sup> Nearly one in six species faces extinction due to climate change.<sup>3</sup> Humans felled 46 percent of all trees, as well as 20 percent of the Amazon in the last 50 years alone.<sup>4</sup> We destroyed half of the world’s coral reefs and are well on our way to a world where they are totally wiped out.<sup>5</sup> Humans suffer, as well, from the precipitous decline of nature. Some 7 million humans die each year due to air pollution, including 100,000 annually in the United States.<sup>6</sup>&nbsp;</p><p><span>A</span>lthough most of the world largely continues with business as usual, a growing number of governments have embraced cutting-edge legal solutions that would allow humans to live in harmony with nature.</p><p>One of the most promising legal solutions is “rights of nature.” It recognizes that nature is a “legal entity” or “persons” with fundamental rights. This movement received global attention when Ecuador recognized the rights of nature in its 2008 Constitution. Now, rights of nature is recognized in some 12 countries through a combination of national and local legislation, landmark court decisions, treaty agreements, and other legal developments.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/51/Limits/this-ecologist-wants-to-tell-you-what-matters-in-science" data-trval="this-ecologist-wants-to-tell-you-what-matters-in-science" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/13013_0079e3e6d496ad07cee7fd63d3d7c9b2.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>


</article>
</div><p>Rights of nature corrects shortcomings of modern environmental laws. Environmental laws operate as a tourniquet, creating rules to prevent nature’s loss but doing little to address root causes—such as an economy that incentivizes the maximum exploitation of nature for profit. By contrast, rights of nature establishes a legal duty for humans to protect and restore ecosystems to health because that is their right.</p><p>The rights of nature, although still in its early stages, is gaining momentum. In 2017, the Constitutional Court of Colombia declared the Atrato River—one of Colombia’s largest rivers—to be a “subject of rights,” with rights to protection, conservation, maintenance, and restoration. The Court also created a guardianship body to serve as the voice of the river, just as a child might have a legal guardian. Finally, the Court ordered state authorities to create a plan—a blueprint is in the works—to decontaminate waterways in the Atrato River basin, to end illegal mining, and take other actions to uphold the rights of rivers.</p><blockquote><p>Two forces, law and culture, will converge to create transformative change. In the meantime, go meet your local river.</p> </blockquote><p>In New Zealand, the Te Awa Tupua (Whanganui River Claims Settlement) Act 2017 recognized the Whanganui River as a living entity and legal person, solidifying a 2012 treaty agreement between the Whanganui Iwi (a Maori tribe) and New Zealand’s crown government. It establishes a guardianship body to promote the river’s health and well-being and serve as its “human face.” Already, the legislation is being put into practice. In 2020, a new governance structure for a port revitalization project on the Whanganui River announced that the river’s indivisible nature and the community’s collective obligation to benefit the river will guide its decision-making.<sup>7</sup><br></p><p>There are other instances of ecosystems being recognized as having rights or personhood. In 2019, the highest court in Bangladesh recognized the rights of all rivers and instituted a plan to address illegal river encroachment. In the United States, the Klamath and Snake Rivers are recognized as having rights by the Yurok and Nez Perce Tribes, respectively. In Mexico, three states have amended their constitutions to recognize the rights of nature, and lawmakers in Oaxaca, Mexico, are proposing to establish the rights of rivers and create a robust legal guardianship body for implementation.</p><p>Granting legal rights to nature could become society’s next major rights-based milestone as part of a larger movement toward the implementation of “Earth law” (like “human rights law” but for the planet). Establishing the rights of nature is an essential piece of the solution to the ecological crisis.</p><p><span>N</span>ot only does the rights of nature give ecosystems a voice in our legal system, it influences our culture. In the case of the Whanganui River, tens of thousands of people have learned how the Maori tribes that live along the Whanganui treat the river as their ancestor and see themselves as its guardians. Numerous global gatherings have celebrated the Whanganui River and other waterways that are now “persons.” A 2019 law journal article in <i>Ecology Law Quarterly</i> writes metaphorically about the “songs” of the Whanganui river and others—songs that are sad, discordant, muted, loving, trusting, or inspiring—and suggests to its predominantly legal readers, “Let us sit beside the river and wait patiently for its song.”<sup>7</sup> A new mindset is emerging in which humans learn to listen to and guard rivers rather than exploit them. The law influences culture, and culture influences the law.</p><p>Many varieties of cultural changes will accelerate the legal movement toward rights of nature. We can reinvent our language so that we no longer describe nature as our “property” or a “resource,” but rather refer to nature as persons, family members, kin, or co-inhabitants of the planet. Movies, songs, TV shows, books, and other artworks that showcase nature being alive and having its own rights can galvanize culture and will help fuel legal battles.</p><p>Timekeeping, too, can become part of the cultural movement toward the rights of nature. Specifically, we can create new standards of time that recognize our deep relationship with the natural world. Experimental philosopher, artist, and writer <a href="http://nautil.us/issue/79/catalysts/philosophy-is-a-public-service" target="_blank">Jonathon Keats</a> has collaborated with the Anchorage Museum to create <a href="http://alaskarivertime.org/" target="_blank">Alaska River Time</a>, which uses the natural flow of a river as a timekeeping standard. The speed of a clock increases or decreases based on the flow of a network of rivers. The clock speeds up when river flows are greatest, such as during spring runoff, then will slow nearly to a halt during low-flow periods, such as late-summer when much of the snowmelt has been depleted. Keats’ thought-experiment is a stark reminder that the natural world is indifferent …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature">http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/94/evolving/humans-have-rights-and-so-should-nature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712528</guid>
            <pubDate>Sun, 10 Jan 2021 08:55:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Ranked Tweets on Hacker News 2020]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25712499">thread link</a>) | @hgarg
<br/>
January 10, 2021 | https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/ | <a href="https://web.archive.org/web/*/https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <ul>
<li>Data curated from <a target="_blank" rel="noopener" href="http://explorehackernews.xyz/?ref=harishgarg.com">Hacker News Front Page Explorer</a></li>
</ul>
<p>1.Every Google result now looks like an ad </p><p>2.macOS unable to open any non-Apple application </p><p>3.John Conway has died </p><p>4.iOS14 reveals that TikTok may snoop clipboard contents every few keystrokes </p><p>5.This electrical transmission tower has a problem </p><p>6.Apple does not keep the 30% commission on a refund </p><p>7.AWS forked my project and launched it as its own service </p><p>8.Google no longer providing original URL in AMP for image search results </p><p>9.Guido van Rossum joins Microsoft </p><p>10.When a customer refunds your paid app, Apple refunds its 30% cut </p>
<p>Get the Full list (162 records) <a target="_blank" rel="noopener" href="https://gum.co/hacker-news-tweets-2020">here for FREE</a></p>
<p>Want to run this and other kind of analysis on your own? Get the Full Database <a target="_blank" rel="noopener" href="http://explorehackernews.xyz/?ref=harishgarg.com">here</a></p>

  </div></div>]]>
            </description>
            <link>https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712499</guid>
            <pubDate>Sun, 10 Jan 2021 08:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Breakthrough in Measuring the Building Blocks of Nature]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25712475">thread link</a>) | @CapitalistCartr
<br/>
January 10, 2021 | http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature | <a href="https://web.archive.org/web/*/http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

			<figure data-alt=""><img src="http://static.nautil.us/18082_ad5db5924e3e97ed8a387a499efa9fa0.jpg" width="733" alt=""><figcaption><span><i>An artistic rendering of the quarks and gluons that make up a proton.</i></span><span>Illustration by D. Dominguez / CERN</span></figcaption></figure><p><span>I</span>n a recent experiment done at the Max Planck Institute for Quantum Optics, in Germany, physicist Alexey Grinin and his colleagues came a step closer to resolving one of the more significant puzzles to have arisen in particle physics over the past decade. The puzzle is this: Ordinarily, when you set about measuring the size of something, you’d expect to get the same answer no matter what you use to measure it—a soda can has the diameter it does whether you measure it with a tape measure or callipers (provided these are properly calibrated, of course). Something must be amiss if your attempts to measure the can return different answers depending on the equipment, yet this is precisely what’s happened over multiple attempts to measure the spatial extent of a proton. What’s potentially at stake is our understanding of the building blocks of reality: the <a href="https://science.sciencemag.org/content/370/6520/1061.abstract" target="_blank">differing measurements</a> could be heralding the existence of new forces or particles.</p><p>What does it mean for a subatomic particle to have a measurable “size”? Mathematically, fundamental particles are idealized as point particles, which is to say that, as far as we can tell, they have no meaningfully discernible spatial extent, or substructure, at all. True, all fundamental particles are associated with a quantum mechanical wave packet, which does have a spatial extent that depends on the energy of the particle. Yet these basic bits of Lego are entities whose wave packets you can, in principle, pack into as small a region as you’d like before the very notion of continuum geometry starts, at the Planck scale, to lose meaning. Fundamental particles organize into something analogous to a mini periodic table—consisting of the various force carrying particles, such as photons and gluons (the carrier particles of the strong nuclear force), along with three generations of quarks and leptons and the mass-generating Higgs boson—and can stack together in different combinations to form a zoo of so-called composite particles.</p><blockquote><p>There is less than one in about a trillion chance that the discrepancy could be a statistical fluke.</p> </blockquote><p>Perhaps the most familiar and ubiquitous of these is the proton. With at least one in every kind of element, it’s made up of two up quarks and a down quark that dance around each other in a tightly bound orbit maintained by exchanging gluons. This exchange process is so energetic that most of the mass of the proton (or for that matter, most of the material that makes us up) derives from the energy contained in these gluons—a consequence, as Einstein informed us, of <i>E</i> being equal to <i>mc</i><sup>2</sup>.&nbsp;<br></p><figure data-alt=""><img src="http://static.nautil.us/18083_78b8d6620afcd434a4b7fb41b22e595b.png" width="733" alt=""><figcaption><span><i>Fundamental particles organize into something analogous to a mini periodic table (above).</i></span><span>CERN</span></figcaption></figure><p>So it’s not meaningless to ask what the “size” of the proton is. The study by Grinin’s team highlights the fact that defining this notion remains a rather tricky affair. And, as we’ll see, their results serve to sharpen the mystery as to why other measurement methods researchers have used previously disagree.<br></p><p>A physicist can reasonably infer a proton’s size from the “charge radius”—roughly the averaged spatial extent of quark orbits inside. This quantity is probed in slightly different ways by electrons and muons (another sort of fundamental particle), when you probe their orbital configurations as they form “bound states” with the proton—atomic hydrogen in the case of electrons, muonic hydrogen in the case of muons. Because muons are about 200 times heavier than electrons, their lowest energy orbital configurations are much more tightly bound around the proton than are electrons in atomic hydrogen. Consequently, the differences in the energies of various orbitals in muonic hydrogen are much more sensitive to the proton’s size as well as being more “high pitched” than that of regular atomic hydrogen.&nbsp;</p><p>In other words, similar to how plucking a guitar string at a given tension produces a much higher note were we to fret it open, or at 1/200th its open length, the typical frequencies of the radiation emitted by transitions in muonic hydrogen are about 200 times higher than that in atomic hydrogen. These frequencies relate to something called the Rydberg constant—the tension of the guitar string in the analogy—which appears to be one of the potentially more significant sources of uncertainty proton size-wise. Orbital energy levels depend on both this constant and the charge radius of the proton.</p><p>Proton-size measurements didn’t conflict for decades. Different methods—like measuring the radius by observing electrons orbit within hydrogen atoms, or by scattering energetic electrons off of unbound protons—had converged on a value of 0.875 (give or take 0.006) femtometers. That’s a little less than a trillionth of a millimeter. That convergence was disrupted in 2010, when a paper came out titled, “The size of the proton.” As the researchers reported, <a href="http://www.quantum.physik.uni-potsdam.de/teaching/ss2015/pqt/Pohl2010.pdf" target="_blank">measurements</a> involving orbital configurations in muonic hydrogen returned a value of 0.842, give or take 0.001 femtometers. This may not seem like much of a difference, but it’s the accompanying error bars that matter. The measurements are, individually, so precise that their disagreement is over seven standard deviations—there is less than one in about a trillion chance that the discrepancy could be a statistical fluke.</p><p>There are only two possibilities for the anomalous result if the equipment used in the experiments and their calibrations all check out after careful scrutiny. Either some combination of physical constants, which researchers assume in order to experimentally infer the proton charge radius, isn’t known as accurately as we thought, or there is something different about the way muons interact with protons, compared to electrons, that renders particle physics incomplete.</p><p>The latter possibility, if substantiated, would, of course, cause a flurry of excitement among theoretical physicists to say the least, as it could imply the existence of new forces and particles. Not only would it reshape our understanding of the universe, it would represent a throwback to the days when physicists discovered particles (<a href="https://timeline.web.cern.ch/anderson-and-neddermeyer-discover-muon" target="_blank">such as the muon itself</a>) using equipment that could fit on a proverbial tabletop.</p><div id="inpagesub">
	<p>Get the <span>Nautilus</span> newsletter</p>
<p>
	The newest and most popular articles delivered right to your inbox!
</p>
			<!-- Begin MailChimp Signup Form -->
			




</div><p>Over the past few years, various teams have been attempting to get to the bottom of the matter by looking at different orbital transitions in atomic hydrogen that are sensitive to different combinations of the Rydberg constant and the charge radius. A 2019 <a href="https://science.sciencemag.org/content/365/6457/1007" target="_blank">measurement</a> by a group of researchers at York University in Canada looked at a particular orbital transition that was independent of the value of this constant, finding a value of 0.833 ± 0.010 femtometers, consistent with the smaller value obtained in muonic hydrogen.&nbsp;</p><p>Grinin’s team went a step further. They used a technique known as frequency comb spectroscopy. It involves pulses of laser light that are a superposition of equally spaced frequencies—a ruler in frequency space if you will—that allowed them to look at two different orbital transitions in atomic hydrogen sensitive to two different combinations of the proton size and the Rydberg constant. This permitted them to determine both with unprecedented accuracy. The technique reduced, to only about one part in ten trillion, the observational uncertainties in the frequency of light these transitions emitted—a staggering degree of accuracy by any standard.&nbsp;</p><p>Not only did Grinin’s team find a value for the charge radius of the proton consistent with the value obtained in muonic hydrogen, they inferred a much more precise value for the Rydberg constant. This accounted for some part of the discrepancy seen in other measurements in atomic hydrogen (which presumed a less accurate value).</p><p>It thus appears that the experimental value of the proton charge radius Grinin’s team obtained in atomic hydrogen is converging on the smaller values for the proton charge radius other researchers initially obtained in muonic hydrogen. The smaller value has by now even been adopted as the <a href="https://physics.nist.gov/cgi-bin/cuu/Value?rp" target="_blank">official value</a> on the National Institute of Standards and Technology <a href="https://www.nist.gov/programs-projects/codata-values-fundamental-physical-constants" target="_blank">CODATA</a> list of recommended physical constants—the official almanac for nuclear and atomic chemists and physicists.&nbsp;</p><p>Although this convergence, based on the continued refinement of experimental techniques, did not deliver the new physics some may have been hoping for, even the most despondent theoretical physicist can acknowledge the experimental artistry that seems to be bringing the matter closer to conclusion. What remains unresolved is the reason why measurements, relying on different spectroscopic methods in atomic hydrogen, return different values for the charge radius of the proton. The mystery, and along with it, the diminishing hope of particle physicists, endures for the time being.&nbsp;</p><p>This was enough motivation for a team of theoretical physicists, led by Cliff Burgess at the Perimeter Institute, in Canada, to systematically catalogue all possible sources of theoretical uncertainty in atomic spectroscopy over a <a href="https://inspirehep.net/literature?sort=mostrecent&amp;size=25&amp;page=1&amp;q=find%20a%20burgess,%20c%20and%20a%20zalavari" target="_blank">series of papers</a>. By isolating the ways in which new forces and particles might leave a tell-tale signature, they’ve thrown the gauntlet firmly back to the experimentalists. Future experiments, as always, will be the ultimate arbiter in this matter.&nbsp;</p><p><i>Subodh Patil is an assistant professor at the Lorentz Institute for Theoretical Physics at Leiden University. He tweets on occasion at @_subodhpatil.</i></p>

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712475</guid>
            <pubDate>Sun, 10 Jan 2021 08:48:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Web Has No Design Standards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25711575">thread link</a>) | @WoodenChair
<br/>
January 9, 2021 | http://www.observationalhazard.com/2021/01/the-web-has-no-design-standards.html | <a href="https://web.archive.org/web/*/http://www.observationalhazard.com/2021/01/the-web-has-no-design-standards.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-8752676873929759179">
<p>A reader recently complained to me about the hyperlinks on this blog. The reader thought the links were too hard to distinguish from the rest of the text. And the reader’s right. The Swedish Greys desktop theme that I thought looked cool eight years ago, while attractive in an aesthetic sense (to me at least), is not the most usable or accessible. I’ll be looking for another theme.</p>

<p>I was able to style my blog however I wanted to and it looks the same in all browsers. That’s the flexibility of good HTML/CSS standards. Every site can look and behave exactly as the creator envisioned. It’s also why the Web’s a usability nightmare. We have to learn to use every site we visit because every site is designed differently. How come when we talk about Web standards the focus is almost entirely on technical standards? Where is the worry about design standards?</p>

<p>I recently finished reading the classic book <em><a href="https://amzn.to/2JZgkSD">The Design of Everyday Things</a></em> by Don Norman and it talks about standards. Normans says “When all else fails, standardize.” Basically when you have no other way of implementing good design, you turn to standardization so at least every user only needs to learn how to use the similar things (in this case web pages) once. And I think we have no other way, because if we did, we would have figured it out in the past 30 years.</p>

<p>It wasn’t always this way. I remember using the pre-CSS and pre-JavaScript Web as a little kid on Mosaic. You knew there that the blue underlined text was always a hyperlink. And you knew that the back button always took you back a page. And you didn’t have to worry what different actions buttons did, because there was no JavaScript. I’m not saying we should go back there, but in many ways having the constraints made pages easier to use. There was no need to think. Now we have no constraints, but that’s why we need standards.</p>

<p>Every other major consumer computing platform but the Web has design standards. Apple’s platforms are famous for their Human Interface Guidelines. They are an attempt to ensure all apps follow some standard design conventions. Not every app does, but Apple has some ability to enforce them through its app stores, and some users even demand developers follow them. So, they are at least kinda sorta followed by most major apps. If the Web had design standards, maybe users would demand developers follow them too. Google and Microsoft have design suggestions and guidelines for their developers. This is why a good app for each platform feels “at home.”</p>

<p>But we have no design guidelines for the Web that are widely accepted. Sure, people have tried. But the only way we’re going to get something that’s actually followed is if we have a standard. And a standard needs to come from a standards body (Apple, Microsoft, and Google are the standards bodies for their respective platforms). W3C, please put some focus on a design standard. Not everybody will be forced to follow it, but it could do a lot of good in terms of usability.</p>


</div></div>]]>
            </description>
            <link>http://www.observationalhazard.com/2021/01/the-web-has-no-design-standards.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25711575</guid>
            <pubDate>Sun, 10 Jan 2021 06:47:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using (neo)vim for C++ development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25711091">thread link</a>) | @jubnzv
<br/>
January 9, 2021 | https://idie.ru/posts/vim-modern-cpp | <a href="https://web.archive.org/web/*/https://idie.ru/posts/vim-modern-cpp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <main>
    <h2 id="background">Background</h2>
<p>I’ve been writing code in vim for the past several years, and in this post I’d like to share some tips on configuring a development environment. This post contains some notes on configuration that would have helped me when I first started using vim and working on my own config. I hope that as a result of reading this, you will be able to improve your workflow with some new features and make the development process easier and more convenient.</p>
<p>In this article, we will look at common tasks that occur when editing code and try to automate and improve them using vim. Each section contains a brief description of the problem, a proposed solution, overview of alternatives, a full code listing for the configuration, and a screenshot or animated screencast with a demonstration. At the end, additional links to useful plugins and resources will be provided.</p>
<p>Most of the tasks come down to installing and properly configuring one or more plugins. I assume that you are an experienced vim user and already use one of the plugin managers.</p>
<p>All of these tips are applicable in both vim and neovim. Also, despite the title, some of these tips can be applied not only to C++, but also to any other language.</p>
<h2 id="removing-trailing-whitespaces">Removing trailing whitespaces</h2>
<p>Let’s start with a very simple problem. Some code conventions restrict the leaving of trailing whitespaces. For example, the Linux Kernel <a href="https://www.kernel.org/doc/html/v4.10/process/coding-style.html#spaces">prohibits</a> from doing this.</p>
<p>So we’d like to see when we accidentally leave a space at the end of a line. Let’s add the following lines in your vim configuration file:</p>
<div><pre><code data-lang="vim"><span>highlight</span> <span>ExtraWhitespace</span> <span>ctermbg</span>=<span>red</span> <span>guibg</span>=<span>red</span><span>
</span><span></span><span>match</span> <span>ExtraWhitespace</span> <span>/\s\+$/</span><span>
</span><span></span><span>au</span> <span>BufWinEnter</span> * <span>match</span> <span>ExtraWhitespace</span> <span>/\s\+$/</span><span>
</span><span></span><span>au</span> <span>InsertEnter</span> * <span>match</span> <span>ExtraWhitespace</span> <span>/\s\+\%#\@&lt;!$/</span><span>
</span><span></span><span>au</span> <span>InsertLeave</span> * <span>match</span> <span>ExtraWhitespace</span> <span>/\s\+$/</span><span>
</span><span></span><span>au</span> <span>BufWinLeave</span> * <span>call</span> <span>clearmatches</span>()<span>
</span></code></pre></div><p>As a result, extra whitespaces will be highlighted as follows:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/trailing-ws.png" alt=""></p>
<p>We also want to remove extra spaces by the single key binding. Let’s define it:</p>
<div><pre><code data-lang="vim"><span>" Remove all trailing whitespaces</span><span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>leader</span>&gt;<span>rs</span> :<span>let</span> <span>_s</span>=@<span>/ &lt;Bar&gt; :%s/</span>\<span>s</span>\+$<span>//</span><span>e</span> &lt;<span>Bar</span>&gt; :<span>let</span> @/=<span>_s</span> &lt;<span>Bar</span>&gt; :<span>nohl</span> &lt;<span>Bar</span>&gt; :<span>unlet</span> <span>_s</span> &lt;<span>CR</span>&gt;<span>
</span></code></pre></div><p>So we can solve this simple problem.</p>
<p>Alternatives:</p>
<ul>
<li>You <a href="https://www.reddit.com/r/vim/comments/82yv3p/anyone_know_how_to_get_the_dots_for_leading/dveznas?utm_source=share&amp;utm_medium=web2x&amp;context=3">can show</a> all whitespaces and line breaks in the source code.</li>
<li>There is <a href="https://editorconfig.org/">editorconfig</a> <a href="https://github.com/editorconfig/editorconfig-vim">plugin</a> for vim that supports the <code>trim_trailing_whitespace</code> option. When it is set to <code>true</code> the plugin will remove any whitespace characters preceding newline characters.</li>
<li>See <a href="##formatting-source-code-with-clang-format">clang-format</a> section below.</li>
</ul>
<h2 id="accessing-standard-library-documentation-using-cppman">Accessing Standard Library documentation using <code>cppman</code></h2>
<p>Vim ships with a man page viewer that works out of the box on any modern *nix via <a href="https://vimhelp.org/filetype.txt.html#ft-man-plugin">:Man</a> command. But the system man pages do not contain the definitions for C++. Let’s fix it by installing <a href="https://github.com/aitjcize/cppman">Cppman</a>.</p>
<p>Cppman is a set of C++ 98/11/14/17/20 manual pages for Linux, with source from <a href="https://cplusplus.com/">cplusplus.com</a> and <a href="https://cppreference.com/">cppreference.com</a>. You can easily install using <code>pip</code> or the package manager for your distribution according to their <a href="https://github.com/aitjcize/cppman#installation">Installation guide</a>. Next, let’s configure vim.</p>
<p>By default, when you press <code>K</code>, vim grabs the keyword under the cursor, separated by <a href="https://vimhelp.org/options.txt.html#%27iskeyword%27">iskeyword</a> symbols. There is one problem. The <code>:</code> symbol often found in C++ definitions is not included in the <code>iskeyword</code> array. So, for example, when you press <code>K</code> under the keyword <code>std::string</code>, vim will try to find the man page for <code>std</code>, instead of the full identifier. Let’s fix it with this small function:</p>
<div><pre><code data-lang="vim"><span>function</span>! <span>s</span>:<span>JbzCppMan</span>()<span>
</span><span></span>    <span>let</span> <span>old_isk</span> = &amp;<span>iskeyword</span><span>
</span><span></span>    <span>setl</span> <span>iskeyword</span>+=:<span>
</span><span></span>    <span>let</span> <span>str</span> = <span>expand</span>(<span>"&lt;cword&gt;"</span>)<span>
</span><span></span>    <span>let</span> &amp;<span>l</span>:<span>iskeyword</span> = <span>old_isk</span><span>
</span><span></span>    <span>execute</span> <span>'Man '</span> . <span>str</span><span>
</span><span></span><span>endfunction</span><span>
</span><span></span><span>command</span>! <span>JbzCppMan</span> :<span>call</span> <span>s</span>:<span>JbzCppMan</span>()<span>
</span></code></pre></div><p>We also need to remap the default <code>K</code> key binding to use our function in C++:</p>
<div><pre><code data-lang="vim"><span>au</span> <span>FileType</span> <span>cpp</span> <span>nnoremap</span> &lt;<span>buffer</span>&gt;<span>K</span> :<span>JbzCppMan</span>&lt;<span>CR</span>&gt;<span>
</span></code></pre></div><p>Here is a result:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/cppman.png" alt=""></p>
<h2 id="browsing-online-documentation-from-vim">Browsing online documentation from vim</h2>
<p>But what if you also want to quickly access online documentation for your favorite library or framework? Or may be search for unknown keywords on StackOverflow, Google or similar sites? And it is desirable to make a solution that can be easily extended to support more search engines.</p>
<p><a href="https://github.com/tyru/open-browser.vim">open-browser.vim</a> can help us. This is a plugin that allows you open URLs in your favorite browser using vim.</p>
<p>Install it using your package manager. Then let’s add a simple configuration to access cppreference and Qt documentation pages:</p>
<div><pre><code data-lang="vim"><span>let</span> <span>g</span>:<span>openbrowser_search_engines</span> = <span>extend</span>(<span>
</span><span></span>\ <span>get</span>(<span>g</span>:, <span>'openbrowser_search_engines'</span>, {}),<span>
</span><span></span>\ {<span>
</span><span></span>\   <span>'cppreference'</span>: <span>'https://en.cppreference.com/mwiki/index.php?title=Special%3ASearch&amp;search={query}'</span>,<span>
</span><span></span>\   <span>'qt'</span>: <span>'https://doc.qt.io/qt-5/search-results.html?q={query}'</span>,<span>
</span><span></span>\ },<span>
</span><span></span>\ <span>'keep'</span><span>
</span><span></span>\)<span>
</span></code></pre></div><p>And add some convenient key bindings by this way:</p>
<div><pre><code data-lang="vim"><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>leader</span>&gt;<span>osx</span> :<span>call</span> <span>openbrowser</span>#<span>smart_search</span>(<span>expand</span>(<span>'&lt;cword&gt;'</span>), <span>"cppreference"</span>)&lt;<span>CR</span>&gt;<span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>leader</span>&gt;<span>osq</span> :<span>call</span> <span>openbrowser</span>#<span>smart_search</span>(<span>expand</span>(<span>'&lt;cword&gt;'</span>), <span>"qt"</span>)&lt;<span>CR</span>&gt;<span>
</span></code></pre></div><p>As a result we can quickly browse online documentation for the word under the cursor:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/openbrowser.gif" alt=""></p>
<p>Further use of this plugin is limited only by your imagination. For example, you can use it to search for similar C++ snippets in open source projects on GitHub:</p>
<div><pre><code data-lang="vim"><span>'github-cpp'</span>: <span>'http://github.com/search?l=C%2B%2B&amp;q=fork%3Afalse+language%3AC%2B%2B+{query}&amp;type=Code'</span>,<span>
</span></code></pre></div><p>Or integrate it with <a href="https://grep.app/">grep.app</a> or <a href="https://codesearch.debian.net/">Debian Code Search</a>. Or add integration with your favorite online translation service, if you work with multiple languages. You get the idea. The main thing is to write the configuration correctly.</p>
<p>Alternatives:</p>
<ul>
<li><a href="https://github.com/KabbAmine/zeavim.vim">zeavim.vim</a> is a plugin that implements the integration with <a href="https://zealdocs.org/">Zeal</a> – free and open source offline documentation browser. In fact, it solves the same problem. You may want to use it if you don’t have an internet connection, or you need access to documentation for a specific version of the framework that isn’t available online.</li>
<li><a href="https://github.com/rhysd/devdocs.vim">devdocs.vim</a> is a plugin for <a href="https://devdocs.io/">devdocs</a> which also provides multiple API documentations.</li>
</ul>
<h2 id="switching-between-source-and-header-file">Switching between source and header file</h2>
<p>Switching between source and header files is another common operation when working with C++.</p>
<p>After searching and trying many solutions, I settled on <a href="https://github.com/derekwyatt/vim-fswitch">vim-fswitch</a> plugin. Personally, I like this plugin for its simple configuration for various file types and the absence of third-party dependencies.</p>
<p>Install it with your favorite package manager. It will perfectly works out of the box, but sometimes you want to configure switch destination files like this:</p>
<div><pre><code data-lang="vim"><span>au</span> <span>BufEnter</span> *.<span>h</span>  <span>let</span> <span>b</span>:<span>fswitchdst</span> = <span>"c,cpp,cc,m"</span><span>
</span><span></span><span>au</span> <span>BufEnter</span> *.<span>cc</span> <span>let</span> <span>b</span>:<span>fswitchdst</span> = <span>"h,hpp"</span><span>
</span></code></pre></div><p>It also will be convenient to set up some key bindings:</p>
<div><pre><code data-lang="vim"><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>A</span>-<span>o</span>&gt; :<span>FSHere</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>" Extra hotkeys to open header/source in the split</span><span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>localleader</span>&gt;<span>oh</span> :<span>FSSplitLeft</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>localleader</span>&gt;<span>oj</span> :<span>FSSplitBelow</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>localleader</span>&gt;<span>ok</span> :<span>FSSplitAbove</span>&lt;<span>cr</span>&gt;<span>
</span><span></span><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>localleader</span>&gt;<span>ol</span> :<span>FSSplitRight</span>&lt;<span>cr</span>&gt;<span>
</span></code></pre></div><p>Alternatives:</p>
<ul>
<li>There are many other options described in this <a href="https://vim.fandom.com/wiki/Easily_switch_between_source_and_header_file">vimwiki article</a>. You can try them or write your own solution.</li>
</ul>

<p><code>ctags</code> is a convenient indexing tool that allows you to go to symbol definition from your project using <code>tags</code> database. This is an old and reliable tool, that is <a href="https://kernelnewbies.org/FAQ/CodeBrowsing">recommended</a> <a href="https://stackoverflow.com/a/33682137/8541499">to use</a> for large code bases like Linux Kernel where other tools like LSP may get stuck.</p>
<p>The most actual and maintained implementation of ctags is <a href="https://github.com/universal-ctags/ctags">universal-ctags</a>. It is available in all popular distributions.</p>
<p>Vim has integrated ctags support. But here is one annoying thing. We need to generate <code>tags</code> database for each project using something like <code>ctags -R .</code>. Moreover, we need re-generate <code>tags</code> when editing the project.</p>
<p>This of course can be automated. Install <a href="https://github.com/ludovicchabant/vim-gutentags">vim-guttentags</a> is a plugin that will asynchronously (re)generate tag files as you work. I also suggest adding a simple configuration to avoid indexing of some unwanted files:</p>
<div><pre><code data-lang="vim"><span>set</span> <span>tags</span>=./<span>tags</span>;<span>
</span><span></span><span>let</span> <span>g</span>:<span>gutentags_ctags_exclude_wildignore</span> = <span>1</span><span>
</span><span></span><span>let</span> <span>g</span>:<span>gutentags_ctags_exclude</span> = [<span>
</span><span></span>  \<span>'node_modules'</span>, <span>'_build'</span>, <span>'build'</span>, <span>'CMakeFiles'</span>, <span>'.mypy_cache'</span>, <span>'venv'</span>,<span>
</span><span></span>  \<span>'*.md'</span>, <span>'*.tex'</span>, <span>'*.css'</span>, <span>'*.html'</span>, <span>'*.json'</span>, <span>'*.xml'</span>, <span>'*.xmls'</span>, <span>'*.ui'</span>]<span>
</span></code></pre></div><p>This makes your workflow simpler and more convenient. See also <a href="https://vim.fandom.com/wiki/Browsing_programs_with_tags">this</a> detailed vimwiki article if you need more information about using ctags.</p>
<h2 id="exploring-source-file-structure-with-vistavim">Exploring source file structure with <code>vista.vim</code></h2>
<p>When you are working with unfamiliar source code, it may be convenient to browse the structure of the current source file. What classes, functions, macroses are defined here?</p>
<p><a href="https://github.com/liuchengxu/vista.vim">vista.vim</a> is a plugin that helps us. It opens a split with the current file definitions. Here is what it looks like:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/vista.png" alt=""></p>
<p>This plugin shows both LSP and ctags symbols. The LSP configuration is beyond the scope of this post, but it is a very useful feature that can give more accurate information.</p>
<p>To use it, install <a href="https://github.com/liuchengxu/vista.vim">vista.vim</a> with your favorite package manager and add a convenient key binding to toggle Vista split:</p>
<div><pre><code data-lang="vim"><span>nnoremap</span> &lt;<span>silent</span>&gt; &lt;<span>A</span><span>-6</span>&gt; :<span>Vista</span>!!&lt;<span>CR</span>&gt;<span>
</span></code></pre></div><p>Alternatives:</p>
<ul>
<li><a href="https://github.com/preservim/tagbar">tagbar</a> is another plugin that provides a way to get the overview of the file structure. Unlike vista.vim, it doesn’t support LSP symbols and doesn’t provide useful utility functions for retrieving the information about the symbol under the cursor. But it’s simpler and more reliable.</li>
</ul>
<h2 id="display-the-current-function-in-the-status-line">Display the current function in the status line</h2>
<p>Another feature of <a href="https://github.com/liuchengxu/vista.vim">vista.vim</a> is that it shares information of the symbol under the cursor. Using this we can display the current function name in the status line. This helps us navigate when moving through a large file.</p>
<p>Bellow is an example of configuration for the <a href="https://github.com/itchyny/lightline.vim">lightline</a>, but you can easily adapt it to your status bar:</p>
<div><pre><code data-lang="vim"><span>function</span>! <span>LightlineCurrentFunctionVista</span>() <span>abort</span><span>
</span><span></span>  <span>let</span> <span>l</span>:<span>method</span> = <span>get</span>(<span>b</span>:, <span>'vista_nearest_method_or_function'</span>, <span>''</span>)<span>
</span><span></span>  <span>if</span> <span>l</span>:<span>method</span> != <span>''</span><span>
</span><span></span>    <span>let</span> <span>l</span>:<span>method</span> = <span>'['</span> . <span>l</span>:<span>method</span> . <span>']'</span><span>
</span><span></span>  <span>endif</span><span>
</span><span></span>  <span>return</span> <span>l</span>:<span>method</span><span>
</span><span></span><span>endfunction</span><span>
</span><span></span><span>au</span> <span>VimEnter</span> * <span>call</span> <span>vista</span>#<span>RunForNearestMethodOrFunction</span>()<span>
</span></code></pre></div><p>Here’s what it looks like:</p>
<p><img src="https://idie.ru/static/posts/vim-modern-cpp/current-function.gif" alt=""></p>
<p>Is you need the complete lightline configuration, see <a href="https://github.com/jubnzv/dotfiles/blob/dd46c2d940c13a0db8d94b02934659018358579a/.config/nvim/init.vim#L435-L462">this snippet</a> and take a look at lightline documentation.</p>
<p>Alternatives:</p>
<ul>
<li>There are many alternatives provided by popular LSP plugins. For example, <a href="https://github.com/nvim-lua/lsp-status.nvim">lsp-status.nvim</a> can provide the same information for Neovim’s built-in LSP server.</li>
</ul>
<h2 id="vimspector-interactive-debugging-inside-vim">vimspector: Interactive …</h2></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://idie.ru/posts/vim-modern-cpp">https://idie.ru/posts/vim-modern-cpp</a></em></p>]]>
            </description>
            <link>https://idie.ru/posts/vim-modern-cpp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25711091</guid>
            <pubDate>Sun, 10 Jan 2021 05:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[System split registered in the synchronous area of Continental Europe]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25711075">thread link</a>) | @nip
<br/>
January 9, 2021 | https://www.entsoe.eu/news/2021/01/08/system-split-registered-in-the-synchronous-area-of-continental-europe-incident-now-resolved | <a href="https://web.archive.org/web/*/https://www.entsoe.eu/news/2021/01/08/system-split-registered-in-the-synchronous-area-of-continental-europe-incident-now-resolved">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>The synchronous area of Continental Europe was split into two separated grid regions between 14h05 CET and 15h08 CET when it was reconnected on 8 January 2021.</p><p>An area in the south east region of the interconnected grid was during that period separated from the rest of Continental Europe. A temporary frequency drop of approximately 250 mHz was registered. Coordinated actions and an immediate response taken by the Continental European Transmission System Operators ensured that the system stability was not affected in most European countries.</p><p>An investigation is ongoing on the cause of this system split and further information on this incident will be made in due course.</p><p>Should you have questions, send them at <a href="https://www.entsoe.eu/news/2021/01/08/media@entsoe.eu">media@entsoe.eu</a> or contact us at the following telephone number: +32 476 97 50 93.</p></div></div></div></div>]]>
            </description>
            <link>https://www.entsoe.eu/news/2021/01/08/system-split-registered-in-the-synchronous-area-of-continental-europe-incident-now-resolved</link>
            <guid isPermaLink="false">hacker-news-small-sites-25711075</guid>
            <pubDate>Sun, 10 Jan 2021 05:57:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Log Pattern Recognition: LogMine]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25710991">thread link</a>) | @trungdq88
<br/>
January 9, 2021 | https://sayr.us/log-pattern-recognition/logmine/ | <a href="https://web.archive.org/web/*/https://sayr.us/log-pattern-recognition/logmine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>When retrieving logs from an application, you are often looking for outliers
(such as a unique error) or what pattern occurs the most. However, defining
patterns manually is time-consuming and requires rigour across projects. In
this series of blog posts, we are going to explore automated Log Pattern
Recognition.</p>

<h2 id="why">Why</h2>

<p>I recently began using <a href="https://docs.datadoghq.com/logs/explorer/patterns/">Datadog Log Pattern</a>
and became addicted to it. Unfortunately, I was not able to find such a feature on
Kibana or a query proxy able to do this analysis. If that does not exist, I
might as well learn more about it and make one!</p>

<p>To my surprise, I did not find as many papers as I thought I would. And the
number of papers with public implementations is even lower. Our series begins
with a paper called <a href="https://www.cs.unm.edu/~mueen/Papers/LogMine.pdf">LogMine: Fast Pattern Recognition for Log Analytics</a>
and <a href="https://github.com/trungdq88/logmine">an implementation made by Tony Dinh</a>
that helped me a lot to study LogMine’s behavior.</p>

<p>To my surprise, I searched for anything related to LogMine on Hacker News
and only found Tony Dinh’s submission.</p>

<h2 id="defining-the-terms-used-in-this-article">Defining the terms used in this article</h2>

<p>Some terms used in this article can have several meanings. In Logmine’s context,
the terms I use mean:</p>
<ul>
  <li><code>log</code>: a log line (<code>string</code>)
    <div><div><pre><code>12:00:00 - My awesome log
</code></pre></div>    </div>
  </li>
  <li><code>pattern</code>: Expression extracted by the algorithm (array of <code>field</code>)
    <div><div><pre><code>[&lt;date&gt;, "-", "My", "awesome", "log"]
</code></pre></div>    </div>
  </li>
  <li><code>field</code>: Part of a <code>pattern</code> / Word from a <code>log</code> (Either a fixed value, a wildcard or a <code>variable</code>)</li>
  <li><code>cluster</code>: represents a group of logs that were identified as close to each
others</li>
  <li><code>variable</code>: a user-provided regex used to identify a known format
    <div><div><pre><code>number = \d+
time = \d{2}:\d{2}:\d{2}
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="an-introduction-to-logmine">An introduction to LogMine</h2>

<p>The LogMine paper describes a method to parse logs, group them into clusters and
extract patterns without any prior knowledge or supervision. LogMine can be
implemented using MapReduce and works in a single pass over the dataset.</p>

<p>LogMine’s approach to grouping logs roughly works by:</p>
<ol>
  <li>Parsing logs into patterns</li>
  <li>Grouping patterns into clusters if the <a href="#clustering">distance</a> between them is small</li>
  <li>Merging clusters into a single pattern</li>
  <li>Repeat from step 2 until you are satisfied</li>
</ol>

<p>LogMine classifies fields into three categories:</p>
<ul>
  <li><code>Fixed value</code>, a field that is constant across all logs in a cluster. This is
detected at the pattern extraction step.</li>
  <li><code>Variable</code>, a field that matches a pattern provided by the user. This is
detected at the pre-processing step.</li>
  <li><code>Wildcard</code>, a field that is not constant across all logs in a cluster. This is
detected at the pattern extraction step.</li>
</ul>

<p>Let’s illustrate how it works, step by step, using three simple logs:</p>

<div><div><pre><code>10:00:00 - [DEBUG] - User 123 disconnected
10:30:00 - [DEBUG] - User 123 disconnected
11:11:11 - [ERROR] - An error occurred while disconnecting user 456
12:12:12 - [DEBUG] - User 789 disconnected
</code></pre></div></div>

<p>We will also define a variable <code>&lt;time&gt;</code> that follows the pattern
<code>\d{2}:\d{2}:\d{2}</code>.</p>

<div>
  <p><strong>Note</strong></p>

  <p>A good practice would be to define more variables to avoid forming two clusters
from logs with low similarity. For instance, we <strong>should</strong> define <code>&lt;number&gt;</code>
as <code>\d+</code>.</p>

  <p>Depending on the pattern of your logs, defining a common field like <code>&lt;log-level&gt;</code>
as <code>[(DEBUG|INFO|WARNING|ERROR)]</code> might end up hiding information. This is
because a <code>WARNING</code> log with an error message might not be that important yet
the same log message with an <code>ERROR</code> level might have the exact information
you would like to highlight.</p>
</div>

<h3 id="log-parsing-and-dense-clusters-identification">Log parsing and dense clusters identification</h3>

<p>The first step is to parse logs into patterns and identify dense clusters. Dense
clusters are clusters where <strong>raw logs are almost identical</strong>.</p>

<p>To do this, we begin by splitting logs into patterns (an array of field). The
separator used by default is any whitespace character.</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Field_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Field_2</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Field_3</annotation></semantics></math></span></span></th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">Field_n</annotation></semantics></math></span></span></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10:00:00</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>10:30:00</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>11:11:11</td>
      <td>-</td>
      <td>[ERROR]</td>
      <td>-</td>
      <td>An</td>
      <td>error</td>
      <td>occurred</td>
      <td>while</td>
      <td>…</td>
    </tr>
    <tr>
      <td>12:12:12</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>789</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<p>Next, we will tokenize the logs and identify variables (regex provided by the
user).</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Field_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Field_2</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Field_3</annotation></semantics></math></span></span></th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">Field_n</annotation></semantics></math></span></span></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[ERROR]</td>
      <td>-</td>
      <td>An</td>
      <td>error</td>
      <td>occurred</td>
      <td>while</td>
      <td>…</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>789</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<p>I stopped at the word <code>while</code> for readability reasons, but there’s no limit to
the number of fields.</p>

<h4 id="identifying-dense-clusters">Identifying dense clusters</h4>

<p>Once this transformation is done, we will reduce these patterns into dense
clusters. Identifying dense clusters can be seen as a special use-case of the
clustering algorithm: we identify clusters but <strong>we skip the pattern extraction
step as these patterns are nearly identical</strong>.</p>

<p>As such, I’ll first introduce the clustering algorithm and the notion of
distance between patterns.</p>

<h3 id="grouping-patterns-into-clusters">Grouping patterns into clusters</h3>

<p>The clustering algorithm takes a list of patterns and identifies patterns that
are close to each other. Both the Tony Dinh’s implementation and the paper uses
the distance defined as:</p>

<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Dist</mtext><mo stretchy="false">(</mo><mi>P</mi><mo separator="true">,</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mtext>Min</mtext><mo stretchy="false">(</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></munderover><mfrac><mrow><mtext>Score</mtext><mo stretchy="false">(</mo><msub><mi>P</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mtext>Max</mtext><mo stretchy="false">(</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{Dist}(P,Q) = 1 -
\sum_{i=1}^{\text{Min}(\text{len}(P),\text{len}(Q))}{\frac{\text{Score}(P_i,Q_i)}{\text{Max}(\text{len}(P),\text{len}(Q))}}</annotation></semantics></math></span></span></span></p><p>With P and Q, two patterns.</p>

<p>If the distance between the two patterns is inferior to a threshold <code>MaxDist</code>
defined internally, then the two patterns are considered a member of the same
cluster.</p>

<div>
  <p>This comparison process can be optimized by skipping unnecessary work if the
sum is already greater than our <code>MaxDist</code>.</p>

  <p>This is valid because the elements inside the sum can’t be negative.</p>
</div>

<p>The scoring function proposed in the paper allows for tweaking weights depending
on the field type.</p>

<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Score</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>k</mi><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>=</mo><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>and&nbsp;both&nbsp;are&nbsp;fixed&nbsp;values</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>k</mi><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>=</mo><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>and&nbsp;both&nbsp;are&nbsp;variable</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{Score}(x, y) =
\begin{cases}
  k1 &amp;\text{if } x=y &amp;\text{and both are fixed values}\\
  k2 &amp;\text{if } x=y &amp;\text{and both are variable} \\
  0 &amp;\text{otherwise}
\end{cases}</annotation></semantics></math></span></span></span></p><p>In order to keep performance, the scoring function can’t return a negative
value. Therefore <code>k1</code> and <code>k2</code> can’t be negative.</p>

<div>
  <p><strong>Note</strong></p>

  <p>The definition of this scoring function seems to have left some place for interpretation:</p>
  <ul>
    <li>Tony Dinh’s implementation <a href="https://github.com/trungdq88/logmine/blob/a7595c6a0b313b43969199c18465cc8bec3b57d1/src/line_scorer.py#L29">checks for equality</a>
if both value are fixed values.</li>
    <li><a href="https://github.com/logpai/logparser/blob/master/logparser/LogMine/LogMine.py">LogPai’s LogParser</a> dropped the concept of variables and uses k2 to tune wildcards weight</li>
  </ul>

</div>

<p>Let’s define <code>k1=1</code> and <code>k2=1</code>, these are the weight used by Tony Dinh’s
implementation and recommended by the original paper.</p>

<h4 id="applying-the-clustering-algorithm">Applying the clustering algorithm</h4>

<p>For this example, I will use the original paper recommendation (<code>MaxDist=0.01</code>).
The MaxDist parameter is used to tune the algorithm sensitivity: the higher
<code>MaxDist</code>, the more patterns are detected.
If <code>MaxDist</code> is too high, patterns are grouped into very large clusters and
pattern extraction become meaningless.</p>

<table>
  <thead>
    <tr>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Log_2</annotation></semantics></math></span></span></th>
      <th>Score</th>
      <th>Sum (Total)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[DEBUG]</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>4</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{4}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>User</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>5</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{5}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>123</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>6</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{6}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>disconnected</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>7</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{7}{7}</annotation></semantics></math></span></span></td>
    </tr>
  </tbody>
</table>

<p>The two logs belong to the same cluster as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mfrac><mn>7</mn><mn>7</mn></mfrac><mo>&lt;</mo><mtext>MaxDist</mtext></mrow><annotation encoding="application/x-tex">1 - \frac{7}{7} &lt; \text{MaxDist}</annotation></semantics></math></span></span>.</p>

<table>
  <thead>
    <tr>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Log_3</annotation></semantics></math></span></span></th>
      <th>Score</th>
      <th>Sum (Total)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[ERROR]</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>An</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>error</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>occurred</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
  </tbody>
</table>

<p>The two logs do not belong to the same cluster as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mfrac><mn>3</mn><mn>11</mn></mfrac><mo>&gt;</mo><mtext>MaxDist</mtext></mrow><annotation encoding="application/x-tex">1 - \frac{3}{11} &gt; \text{MaxDist}</annotation></semantics></math></span></span>.</p>

<div>
  <p><strong>Note</strong></p>

  <p>As we are using <code>MaxDist=0.01</code>, and since the logs in my example are very short,
we will only identify logs that are identical. For this reason, <strong>we can use the
clustering algorithm to identify dense clusters</strong> by skipping the pattern
recognition step.</p>
</div>

<h3 id="pattern-detection">Pattern detection</h3>

<p>In sequential (as opposed to MapReduce) mode, each time a pattern is inserted
in a cluster, LogMine will try to extract patterns from them. LogMine knows
only how to identify two types:</p>
<ul>
  <li>Fixed values</li>
  <li>Wildcards</li>
</ul>

<p>While it seems rather strict, remember that the early pattern detection during
tokenization already took care of identifying user-defined patterns.</p>

<div>
  <p>Generating the pattern each time a new pattern is added allows LogMine to only
keep one representative for each cluster. This is a very important factor to
reduce memory usage.</p>

  <p><strong>MapReduce behavior is described later in this article.</strong></p>
</div>

<p>As patterns in the same cluster can have a different number of fields, the paper
uses the <a href="https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm">Smith-Waterman</a>
algorithm to align them. The Smith-Waterman is mainly used in Bioinformatics to
align sequences. It is interesting to see an algorithm like this applied to
log pattern recognition.</p>

<p>Once the two patterns are aligned, we compare one by one the field:</p>
<ul>
  <li>If the value is equal, we assign a fixed value</li>
  <li>If the value is different, we assign a wildcard pattern</li>
</ul>

<p>The Smith-Waterman algorithm adds placeholders to align logs. These placeholders
are <strong>never equal</strong> to a field value. This means that aligned parts of a log are
always identified as wildcards.</p>

<p>The output of the pattern detection algorithm is a <strong>new list of patterns</strong>.</p>



<p>Let’s assume that the previous algorithm identified a cluster with two patterns:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 789 disconnected
</code></pre></div></div>

<p>To stay consistent with how they were presented earlier, we will call them
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">Log_4</annotation></semantics></math></span></span>.</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">Log_4</annotation></semantics></math></span></span></th>
      <th>Result</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[DEBUG]</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>User</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>456</code></td>
      <td><code>Wildcard</code></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>disconnected</code></td>
      <td><code>Fixed value</code></td>
    </tr>
  </tbody>
</table>

<h4 id="result-of-applying-the-smith-waterman-algorithm">Result of applying the Smith-Waterman algorithm</h4>

<p>Because examples in this article would have gotten very complex, I decided to
not use non-aligned logs in my examples. However, you might be curious as to how
the Smith-Waterman works.</p>

<p>On the implementation, LogMine would have aligned the two following patterns by
adding a <code>None</code> value in a field. For instance:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 123 has disconnected
</code></pre></div></div>
<p>would become:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 &lt;None&gt; disconnected
&lt;time&gt; - [DEBUG] - User 123 has disconnected
</code></pre></div></div>

<div>
  <p><strong>The Smith-Waterman does not understand patterns</strong>. The Smith-Waterman uses
the same scoring function as the clustering algorithm. As such, if two fields
are not equal, there is no guarantee that the placeholder will be inserted
properly.</p>

  <p>If we tweak our previous example to:</p>
  <div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 456 has disconnected
</code></pre></div>  </div>

  <p>The Smith-Waterman algorithm would transform it to:</p>
  <div><div><pre><code>&lt;time&gt; - [DEBUG] - User &lt;None&gt; 123 disconnected
&lt;time&gt; - [DEBUG] - User 456 has disconnected
</code></pre></div>  </div>

  <p>The alignment was added <strong>before</strong> the user identifier.</p>
</div>

<h3 id="repeat-until-satisfied">Repeat until satisfied</h3>

<p>As the pattern extraction algorithm returns a list of patterns, we can relax
<code>MaxDist</code> and feed this list back into the clustering algorithm.</p>

<p>In <strong>3.4 Hierarchy of Patterns</strong>, the paper describes a process to generate a
hierarchy of possible patterns from very strict to …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sayr.us/log-pattern-recognition/logmine/">https://sayr.us/log-pattern-recognition/logmine/</a></em></p>]]>
            </description>
            <link>https://sayr.us/log-pattern-recognition/logmine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25710991</guid>
            <pubDate>Sun, 10 Jan 2021 05:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A guide to SQL interview questions]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25709870">thread link</a>) | @data4lyfe
<br/>
January 9, 2021 | https://www.interviewquery.com/blog-sql-interview-questions/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-sql-interview-questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p><strong>Table of Contents</strong></p><!--kg-card-begin: html-->
<!--kg-card-end: html--><h3 id="introduction">Introduction</h3><p>SQL is the good old friend that has always worked. It’s something you always come back to, even as Pandas, Julia, Spark, Hadoop, and NoSql attempt to dethrone and replace SQL as the new de-facto data tool.</p><p>Eventually though, they all fail in the face of the consistently reliable SQL. And that's why SQL continues to get asked in interviews. </p><blockquote><strong>A note before we start...</strong></blockquote><blockquote>This guide should be used for anyone who is preparing for an interview in which they know SQL will show up. This guide<strong> is not</strong> a search engine optimized listacle (top 50 sql questions for 2021...really?).</blockquote><blockquote>Rather, this is <strong>real advice and REAL interview questions and exercises </strong>gathered from hundreds of data scientists, engineers, and analysts. We sprinkle exercises throughout this post after learning concepts. Be sure to try attempting the questions first before we walk through solving them. &nbsp;</blockquote><blockquote>Lastly, if you enjoy this article, <strong>please give us a share</strong> and check out our <a href="https://www.interviewquery.com/courses/data-science-course">SQL course</a> that goes a little deeper with more exercises and problems. </blockquote><h2 id="1-why-does-sql-show-up-on-the-interview">1. Why does SQL show up on the interview?</h2><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-6.png" alt="" srcset="https://blog.interviewquery.com/content/images/2021/01/image-6.png 600w"></figure><p>SQL allows data scientists and engineers to do a couple of important things.</p><p>One is to <strong>effectively store and retrieve information at scale for analytics</strong>. Even though Google Sheets allows users to easily manipulate and visualize data, it cannot store and scale like a SQL database can. Other popular programs –namely Hadoop and Spark– can scale much further than SQL, but still don’t have a clean and easy-to-use language like SQL to retrieve data efficiently.</p><p>Another great thing about SQL is that understanding the fundamentals bridges the gap between <strong>engineering and data science</strong>. Knowing SQL well gives you a competitive edge over any other candidate, whether you're competing for a position as a product manager, software engineer, or even as a business analyst. Having the skillset to write and pull your own queries is like being a magician that can come up with analyses out of thin air. </p><p>And at the end of the day, you could just be really good at SQL if you wanted to and make tons of money creating ETL jobs or pulling dashboards with efficiency. That's how valued SQL is. </p><h3 id="how-often-does-sql-show-up-in-interviews">How often does SQL show up in interviews?</h3><p>One prevailing question is how often SQL shows up in interviews. </p><p>At Interview Query, we analyzed a dataset of Glassdoor data science interview experiences and responses submitted by our users. The analysis came back that SQL was asked:</p><ul><li><a href="https://www.interviewquery.com/interview-experiences/facebook/data-scientist" rel="nofollow">70% of the time during Facebook’s data science interviews</a></li><li><a href="https://www.interviewquery.com/interview-experiences/Amazon/business-analyst" rel="nofollow">94% of the time during Amazon’s business intelligence and analyst interviews</a></li></ul><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-7.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-7.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-7.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image-7.png 1262w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.interviewquery.com/interview-experiences/facebook/data-scientist">Skills tested in Facebook's Data Science Interview as of 2021</a></figcaption></figure><p>Due to its nature in being able to get and manipulate your own data, this is by far the most important skill now towards nabbing a data science position. And while pandas and other languages are useful, note that <a href="https://www.interviewquery.com/blog-why-your-data-scientist-interviewer-wont-ask-pandas-questions/" rel="nofollow">SQL will always be the one that matters</a>.</p><h2 id="2-strategies-for-the-live-sql-interview">2. Strategies for the live SQL interview</h2><p>Let's go over the common strategies when tackling SQL interview questions. </p><p><strong>1.Repeat the problem statement</strong></p><p>When presented with a SQL question, listen carefully to the problem description and repeat back what you think the crux of the problem is. The interviewer can then help verify if your understanding is correct.</p><p><strong>2. Understand the edge cases</strong></p><p>If time permits, write out a base case and an edge case to show that you understand the problem. For example: if the interviewer asks you to pull the average number of events per user per day, write out an example scenario where you're verifying this metric. </p><p>Do duplicate events matter? Are we looking at distinct users? These are questions we need to clarify. </p><p><strong>3. Try working backwards if the problem is tricky</strong></p><p>Sketching out what the output of the SQL question will look like is a great strategy towards solving the problem. Usually, if I know what the end output table is supposed to look like, I can work backwards from there on what functions need to be applied before. </p><p>For example, if the output looks like this:</p><pre><code>date        | average events per user
------------+-----------------------
2021-12-01  |  3.5
2021-12-02  |  4.0</code></pre><p>I know that the table before this aggregation would have to look something like this.</p><pre><code>date       | event | user_id
-----------+-------+--------
2021-12-01 | click | 1
2021-12-01 | view  | 1
......</code></pre><p>And then, I can figure out what functions I should use to get to my desired output!</p><p><strong>4. Pattern match to different functions</strong></p><p>As you practice more and more SQL exercises, what you'll find is that many SQL problems follow similar patterns. There are techniques we can use in SQL, like utilizing <code>HAVING</code> on aggregations, self-joins and cross-joins, and applying window functions. But, additionally, we'll see problems that run in a similar vein. </p><p>For example, writing a query to get the second highest salary or writing a query to isolate every fifth purchase by a user utilizes the same <code>RANK</code> function in SQL. </p><p>Understanding the commonalities between questions will help you understand the first step to solving SQL questions faster because you can re-use similar code and stitch together techniques on top of each other. </p><p><strong>5. Start writing SQL</strong></p><p>Finally, it's important to just start writing SQL. It's better to start writing an imperfect solution vs trying to perfectly understand the problem or trying to perfect the solution on the first try. </p><p>Verbalize your assumptions and what you're doing as you write SQL and your interviewer can then be put on the same page as you. </p><h2 id="3-the-7-different-sql-interview-questions">3. The 7 different SQL interview questions</h2><p>SQL questions asked during interviews can vary widely across companies, but even more so across positions. You won't see data scientists asked the same SQL questions as software engineers, and that's because data scientists have to write different types of queries compared to software engineers. </p><p>Generally, each SQL interview question can be bucketed into these categories:</p><ul><li>Definition based SQL questions</li><li>Basic SQL questions</li><li>Reporting and metrics SQL questions</li><li>Analytics SQL questions</li><li>ETL SQL questions</li><li>Database design questions</li><li>Logic based SQL questions</li></ul><p>In this next section, we'll go over which types of SQL questions are expected for different roles and what those different kinds of SQL questions are in detail. </p><h2 id="4-sql-questions-for-data-scientists-and-analysts">4. SQL questions for data scientists and analysts</h2><p>SQL interview questions for data scientists and data analysts will likely show up in three parts of the interview process: the technical round, the take-home challenge, and the onsite interview. </p><p>The technical round and take-home challenge will usually consist of SQL questions <strong>designed to filter out candidates</strong>. Since SQL is commonly used as a filter mechanism for data scientists, it's important to perform well on this part of the interview in order to demonstrate competence. </p><p>Depending on what type of data science role you're interviewing for, you'll find that most SQL questions will be split into these three types:</p><ul><li>Basic SQL Interview Questions</li><li>Reporting and Metrics SQL Interview Questions</li><li>Analytics SQL Interview Questions</li></ul><h3 id="basic-sql-interview-questions">Basic SQL Interview Questions</h3><p>Basic SQL questions are what they sound like. These questions will be generally easy and focus on assessing if you know the basics. </p><p><strong>Definition based SQL questions </strong>are grouped into this category because they're super easy to learn. All you have to do is study a list of definitions of SQL terms and applications. These questions will include understanding the differences between joins, what kinds of aggregations exist, and knowing the basic functions like <code>CASE WHEN</code> or <code>HAVING</code>. </p><p>Basic SQL interview questions that involve a user actually writing a query are slightly different. These will involve getting the <code>COUNT</code> of a table, knowing what the <code>HAVING</code> clause does, and figuring out how to utilize <code>LEFT JOIN</code> versus <code>INNER JOIN</code> to give you the values that you need.</p><blockquote>Read more on the the <a href="https://www.interviewquery.com/blog-three-sql-questions-you-must-know-to-pass/">basic concepts you need to know to pass your data science interview</a> here. </blockquote><figure><a href="https://www.interviewquery.com/blog-three-sql-questions-you-must-know-to-pass/"><div><p>Three SQL Concepts for your Data Scientist Interview</p><p>I’ve interviewed a lot of data scientist candidates and have found there are a a lot of SQL interview questions for data science that eventually boil down to three generalized types of conceptual understandings.</p><p><img src="https://blog.interviewquery.com/favicon.ico"><span>Interview Query Blog</span></p></div><p><img src="https://blog.interviewquery.com/content/images/2020/02/sql_join.jpeg"></p></a></figure><p><strong>Basic SQL Concepts to Review</strong></p><ul><li>What's the difference between a <code>LEFT JOIN</code> and an <code>INNER JOIN</code>?</li><li>When would you use <code>UNION</code> vs <code>UNION ALL</code>? What if there were no duplicates?</li><li>What's the difference between <code>COUNT</code>and <code>COUNT DISTINCT</code>?</li><li>When would you use a <code>HAVING</code> clause versus a <code>WHERE</code> clause?</li></ul><p><strong>Basic SQL Question Example:</strong></p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image.png 1306w" sizes="(min-width: 720px) 720px"></figure><blockquote><em>We're given two tables, a <code>users</code> table with demographic information and the neighborhood they live in and a <code>neighborhoods</code> table.</em></blockquote><blockquote><em>Write a query that returns all of the neighborhoods that have 0 users.</em></blockquote><p>Try answering this question with our <a href="https://www.interviewquery.com/questions/empty-neighborhoods">interactive SQL editor</a>.</p><p><strong>Here's a hint:</strong></p><p><em>Our predicament is to find all the neighborhoods without users that live in them. This means we have to introduce a <strong>concept of existence of a field in one table, while not existing in another.</strong></em></p><p><em>For example, let's say we generate some fake data of user's and the neighborhoods they live in. We would expect it to look something like this. </em></p><pre><code>neighborhoods.name  | users.id
____________________|__________
castro              | 1
castro              | 2
cole valley         | null
castro heights      | 3
sunset heights      | 4</code></pre><p><em>We see each user from one to four is appropriately placed in their respective neighborhood except for the neighborhood of Cole Valley. That's the neighborhood we're targeting for returning in our query. </em></p><p><em>Strategies: whenever the question asks about finding values with 0 something (users, employees, posts, etc..), immediately think of the concept of <strong><code>LEFT JOIN</code></strong>! An inner join finds any values that are in both tables, <strong>a left join keeps only the values in the left table</strong>.</em></p><p><em>Our predicament is to find all the neighborhoods without users. To do this, we must do a left join from the <code>neighborhoods</code> table to the <code>users</code> table.</em></p><p><em>If we then add in a where condition of <strong><code>WHERE users.id IS NULL</code></strong>, we will get every single neighborhood …</em></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-sql-interview-questions/">https://www.interviewquery.com/blog-sql-interview-questions/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-sql-interview-questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25709870</guid>
            <pubDate>Sun, 10 Jan 2021 04:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Platform Is the Enemy]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 77 (<a href="https://news.ycombinator.com/item?id=25708099">thread link</a>) | @nomdep
<br/>
January 9, 2021 | https://danielbmarkham.com/the-platform-is-the-enemy/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/the-platform-is-the-enemy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>The premise of the movie "Idiocracy" is simple: in the future mankind has de-evolved into morons. Technology does so much for everybody that nobody knows how it all works anymore. &nbsp;If we can't fix it, we're all going to die.</p><p>One character asks the other what he likes, The answer is money.</p><p>"I can't believe you like money too!" the first character says without irony, "We should hang out!"</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/JRJcXbeoSOlkRRzbC7HJ_idiocracy.jpg" alt=""></figure><p>The gag here is that of course, most everybody likes money. If you reduce all of your life enough, it's just food, sex, money, and looking cool. But who would want to do that? Over the centuries, humans have created massively-complex societies because everybody has different things they like doing and thinking about, but all of that complexity can be reduced to, well, an idiocracy if you try hard enough.</p><p>The movie, however, is just a joke, right? We would never allow that to happen, of course, because that's not the goal of technology. Technology's goal is to make us better, not dumber.</p><p>Wait one. Is that true? What <em>is</em> the goal of technology, anyway? Has anybody ever clearly stated it?</p><p>Recently I've heard two goals:</p><ol><li>The goal of technology is to become a <strong>brain extension</strong>, <em>helping you to decide what to do</em> and then helping you get it done.</li><li>The goal of technology is to become a <strong>hand-held power tool</strong>, helping you accomplish the things you've <em>already decided to do</em></li></ol><p>That's not the same thing. It turns out the difference is critical.</p><p>The old goal was much simpler: make something people want. I like that goal! It boils down the job of creating technology to the most important parts, need and ability. But was that sustainable? At the end of the day, don't we always end up making some combination of stuff that either helps us <em>make decisions</em> or helps us <em>implement decisions</em> we've already made? And aren't the two fundamentally incompatible in a future society?</p><p>Yelp tells you which restaurant to go to. Your GPS automatically takes you there. These are not just different problems, they're different <em>kinds of problems</em>. Getting from point A to point B is a matter of math and geometry. Which restaurant is the best tonight? You could spend hours debating that with friends.</p><p>If you reduce anything down enough it becomes idiotic. Each piece of technology we deploy can have the goal of helping us do what we've already decided or helping us decide what to do. The first option leaves the thinking up to us. The second option "helps" us think.</p><figure><iframe width="267" height="200" src="https://www.youtube.com/embed/sZHCVyllnck?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>You like money too? Wow! I like money! We should hang out!</p><p>Human brains are not computers. Brains are designed to help us survive and pass on our genes using the minimum amount of energy available. If the GPS takes me where I'm going, I don't need to know how to use maps anymore. So I stop knowing how to use maps. Dump those neurons, they're not needed. If Yelp picks the restaurants for me enough, I stop having nuanced preferences about restaurants. That energy expenditure is no longer needed for survival and reproduction. Dump those neurons. Over time people stop caring about the tiny details of what the difference is between a good and a great restaurant. Yelp handles that.</p><p>For some folks, who cares? It's food. Go eat it. For other folks, picking the right place can be a serious undertaking, worthy of heavy thought and consideration. But if over the years apps like Yelp boil all of that down to four or five stars, then our collective brain is not going to bother with it. Human brains are not computers. If computers do the work for us, we turn off those neurons and save energy.</p><p>Meanwhile, on social media there's currently this huge discussion. One bunch of folks says that social media is being overbearing in its censorship of fringe and sometimes hateful opinions. The other bunch of folks says social media is a festering sore full of people who are ugly, hateful, and abusive to those weakest among us. The community has to set standards.</p><p>There doesn't have to be a right and wrong here. I think the crucial thing to to understand that both sides can be entirely correct. We are dealing with the same kind of question.</p><p>All three of these topics -- whether humanity is becoming idiots or not, what the ultimate goal of technology is or should be, and how social media should work -- are intricately related. They're related because of this: <em>the platform is the enemy</em>.</p><p>The minute we create a platform for something, whether it's rating movies, tracking projects, or chatting with friends about work, as that platform takes over mindshare, <em>the assumption becomes that this is a solved problem</em>.</p><p>The telephone was great. Once we had the telephone, people didn't have to worry about how to talk to people far away anymore. Just pick up the phone. Solved problem.</p><p>Facebook is great. Once we had Facebook, people didn't have to worry about how to interact with their friends in a social setting anymore. Just click on the little FB notification (Which seems to be always flashing for some reason to get my attention) Solved problem?</p><p>But these are entirely different things! With the phone, I know who I want to call and why. I push buttons and we are connected. The tech helps me do what I've already decided to do. With Facebook, on the other hand, they get paid to show me things in a certain order. The premise is that I'm waiting (or "exploring" if you prefer) until I find something to interact with. The phone is a tool for me to use. I am the tool Facebook is using. I am no longer acting. I am reacting.</p><p>And even if they weren't paid, interacting with friends socially is an extremely complex affair. What kind of mood are they in? What's their life history? What things are bad to bring up? How does their body language look? Facebook's gimmick is "Hey, we've reduced all of this to bits and bytes, and we'll even show you what bits and bytes to look at next!"</p><p>Solved problem.</p><p>Many, many people do not use the internet, the internet uses them. And this percentage is constantly growing.</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/9EBNeUmSy6TMDUpKTLL6_terminator-robot.jpg" alt=""></figure><p>Just like the restaurant example, maybe that's fine. I have friends, I have opinions, who cares? It's all idle chat anyway.</p><p>That logic can be true for a bunch of things, but can't be true for <em>everything</em>. Otherwise, at some point 100 years from now, we're comparing our life values and end up saying something like "I like money too". Everything can't all be reduced down to the lowest common denominator. If it does, we all die.</p><p>Life is not a bit or byte, a number to be optimized. It's meaning we define ourselves, in ways we should not quantize.</p><p>Platforms, by their very nature, constantly send out the subtle message: <em>This is a solved problem. No further effort on your part is required here. No thinking needed.</em> Platforms resist change. They resist their own evolution by subtly poisoning the discussion before it even starts.</p><p>Are restaurant choices more or less important than which movie to watch tonight? There's no right or wrong answer to these questions. We have nice categories like restaurants and movies because currently people consider those things to be different kinds of choices. But why? If the algorithm is king, why shouldn't an algorithm determine both of those things for me? And if it does, why should I bother with worrying about which category is which?</p><p>Human brains are not computers. Let the platform decide. Energy not needed. Dump those neurons.</p><p>This is the more important point. It's not that the platforms turn what might be complex things into simple numbers, or even that they monetize attention. It's that by turning everything into numbers, over time they destroy the distinction between the categories entirely. Platforms are the enemy because they resist analysis in the areas they dominate.</p><p>Platforms turn into settled fact things that should be open for debate, like whether or not Taco Bell is a Mexican restaurant, or whether Milo is an artist with something useful to tell us. (I'm going with "no" and "no" for both of these.) More dangerously, they do the work of deciding <em>what categories various things go into</em>. This category over here is important. That category over there is not. We all make these decisions, and they're all different, and the categories each of us pays careful attention to and loves obsessing about are all different, and because we all have different viewpoints and priorities humankind advances in thousands of directions simultaneously. We survive. We evolve.</p><p>Twitter has to decide whether PERSON_X can speak or not because on the Twitter platform, that question has to have a yes or no answer based on the person. Twitter's category for deciding who can speak is "who is that?" Is that the right category for social conversations? For political conversations? For conversations about philosophy? Math? Who knows? Who cares? Twitter has decided. Solved problem.</p><p>Everybody has different things they like doing and thinking about. Different conversations and audiences have different criteria. Some problems should never be solved. Or rather more directly, some problems should never have a universal answer.</p><p>An aside: We see the same thing in programming. One bunch of folks creates various platforms in order to do the thinking for another bunch of folks. Sometimes these platforms take off and become industry standards. That's quite rare, however. Most of the time we end up training morons who can weakly code against the platform but can't reason effectively about the underlying architecture or reason for the platform to exist in the first place. In our desire to help, we harm the very people we're trying to assist -- by subtly giving them the impression that this is a solved problem. Programmers are just a decade or so ahead of the rest of us.</p><p>Popular platforms aren't just a danger economically because they control commerce. They're not just a danger politically because they selectively control and amplify political discourse. They're an extinction-level, existential danger to humans because they prevent people from seriously considering what kinds of categories are important in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danielbmarkham.com/the-platform-is-the-enemy/">https://danielbmarkham.com/the-platform-is-the-enemy/</a></em></p>]]>
            </description>
            <link>https://danielbmarkham.com/the-platform-is-the-enemy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25708099</guid>
            <pubDate>Sun, 10 Jan 2021 02:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Podcast on innovation systems, with Ben Reinhardt]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25707442">thread link</a>) | @willbobaggins
<br/>
January 9, 2021 | https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/ | <a href="https://web.archive.org/web/*/https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1985">

                    
                    <div>
                        
<p>In this episode, we talk with Ben Reinhardt about different innovation systems, how to create more sci-fi technology a reality, and why our research institutions are not as effective as they used to be. You can check out Ben’s work at https://benjaminreinhardt.com/about/.</p>



<div><p>Some things mentioned in the episode: </p><p><a href="https://slatestarcodex.com/2020/05/12/studies-on-slack/">Studies on Slack</a></p></div>



<p><a href="https://en.wikipedia.org/wiki/Donald_Braben">Don Braben</a></p>



<p><a href="https://en.wikipedia.org/wiki/DARPA">DARPA</a></p>



<p>Ben’s <a href="https://twitter.com/ben_reinhardt?lang=en">Twitter</a></p>



<figure></figure>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25707442</guid>
            <pubDate>Sun, 10 Jan 2021 01:30:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Hangouts: A Eulogy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25707127">thread link</a>) | @dredmorbius
<br/>
January 9, 2021 | http://decafbad.net/2021/01/09/google-hangouts-a-eulogy/ | <a href="https://web.archive.org/web/*/http://decafbad.net/2021/01/09/google-hangouts-a-eulogy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      <p>This year Google will stop supporting and remove Google Hangouts. Google Hangouts, if you're not aware, was Google's replacement for their chat program Google Talk. Google Talk was a XMPP-based chat client that was available for all users of Google services. Google Hangouts was rolled out around the same time as Google+, and was a wrapper for many different Google services (phone, video chats, and Hangouts on Air). What was nice about it was that anyone that you knew the GMail address of had access to Google Hangouts. This meant that many of my friends had Hangouts access. JoDee and I used Hangouts for much of our IM communication. Unfortunately for whatever reason Google decided to remove yet another of the things that I liked about Google services, and proves once again that Google can't be trusted with any social platform.</p>
<p>Today I downloaded the "Google Takeout" of Hangouts and removed all of the old chats. There were a lot of nice memories in there, and now they can live in a collection of photos and one long JSON dump file that I'll probably never read again.</p>
<p>If you want to find me I'm on Signal and Quicksy (an XMPP-based service using phone numbers and OMEMO for encryption). If you have my phone number you can use these services to get a hold of me. I'm still on IRC and have accounts on other platforms. But what seems a constant is that communication will be fractured over multiple platforms and the dream of having one application doing everything well dies on July, 2021. And the irritation of having yet-another-platform to talk to that one person is the reality we'll all have to deal with until something better comes along. Nothing is perfect and everything is terrible.</p>
<p>RIP Hangouts. You helped me not have to think about messaging.</p>
    </div></div>]]>
            </description>
            <link>http://decafbad.net/2021/01/09/google-hangouts-a-eulogy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25707127</guid>
            <pubDate>Sun, 10 Jan 2021 01:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook and Twitter Promote Propaganda and Disinformation. We Can Do Better]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25706694">thread link</a>) | @dyoder
<br/>
January 9, 2021 | https://byline.dashkite.com/post/dashkite/w_ljVZkIbMtrtkekpwUnBg/facebook-and-twitter-promote-propaganda-and-disinformation | <a href="https://web.archive.org/web/*/https://byline.dashkite.com/post/dashkite/w_ljVZkIbMtrtkekpwUnBg/facebook-and-twitter-promote-propaganda-and-disinformation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://byline.dashkite.com/post/dashkite/w_ljVZkIbMtrtkekpwUnBg/facebook-and-twitter-promote-propaganda-and-disinformation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25706694</guid>
            <pubDate>Sun, 10 Jan 2021 00:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weather Data API with historical weather and 15-day forecast data]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25706592">thread link</a>) | @Leftium
<br/>
January 9, 2021 | https://www.visualcrossing.com/weather-api | <a href="https://web.archive.org/web/*/https://www.visualcrossing.com/weather-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="posts">
					
					
						<div id="">
								
								<p><a href="https://github.com/visualcrossing/WeatherApi/" title="Weather API Samples"><img src="https://www.visualcrossing.com/images/excel-weather/coder_300x200.png" alt="Weather API for JavaScript and web development"></a>
								</p>
								<div>
									
									
									<div>
										<p>
											Visual Crossing Weather API requests are RESTful calls that you can make easily from both client and server.  
											You can incorporate weather data into your application, website or weather app in a matter of minutes. 
											Simply follow our tutorials and sample code. Need a free weather api? Our weather data API is free up to 1000 results/day.
										</p>

										<ul>
											<li><i></i>Easy integration with <a href="https://www.visualcrossing.com/resources/documentation/weather-api/how-to-load-weather-data-in-javascript/" title="How to load weather data in JavaScript">JavaScript, D3 &amp; jQuery</a></li>
											<li><i></i>HTTPS encryption for security and compliance</li>
											<li><i></i>Cross-Origin Resource Sharing (<a href="https://enable-cors.org/" `rel="noopener" title="enable cross-origin resource sharing" target="_blank">CORS</a> ) for secure cross-domain requests</li>
											<li><i></i>Secure API Key for account protection &amp; tracking</li>
											<li><i></i>Compatible for both client and server usage</li>
											<li><i></i>Enable weather in your application in minutes</li>
										</ul>
									</div>

								</div>
						</div>
					
						
						
						
						<div id="">
								
								<p><a href="https://www.visualcrossing.com/resources/documentation/weather-api" title="Weather API Documentation"><img src="https://www.visualcrossing.com/images/excel-weather/coder_300x200.jpg" alt="Historical Weather Data for Java, Python, Perl"></a>
								</p>
								<div>
									
									
									<div>
											<p>
										RESTful APIs are ideal for integration in all programming languages including Java, .NET, Python &amp; Perl.  
										Access the entire Visual Crossing Weather database including weather history data, weather forecasts, real time conditions to power any application.
										</p>
										
										<p>
										Results are available in common data formats including JSON and CSV.
										Integrating the data into your application is straightforward.
										</p>
										<ul>
											<li><i></i>Full access to historical weather, forecasts, and climate statistics</li>
											<li><i></i>Data formats include JSON and CSV</li>
											<li><i></i>Support for multiple locations and dates in a single request</li>
											<li><i></i>Documentation and samples available</li>
										</ul>
									</div>
								</div>
						</div>
						
						
						
					
						<p id="">
							<h2>Weather Data for Data Science</h2>
						</p>
						<div id="">
								
								
								<div>
									
									
									<div>
										<p>
											R has become an essential environment for statistical computing and data science.  
											It is widely used among analysts and data miners for developing statistical software and data analysis including weather. 
											Visual Crossing API can be used to load data into your R code quickly and easily.

										</p>
										<ul>
											<li><i></i>Load weather information with a single call</li>
											<li><i></i>Use R to calculate statistics, do analysis &amp; make graphics</li>
											<li><i></i>Build queries using the Query Builder page or in your code</li>
											<li><i></i>Join weather data with other business data</li>
											<li><i></i>Videos and tutorials show the process step-by-step</li>
										</ul>
									</div>

								</div>
						</div>
						

						<div id="">
								
								
								<div>
									
									
									<div>
										<p>
										
										Excel is used by corporate analysts and home users alike because it is powerful, intuitive. 
										It provides a simple weather analysis platform business and for students and data hobbyists.  
										Our unique CSV output mode allows the results of weather queries to be consumed directly in any Excel workbook.

										</p>
										<ul>
											<li><i></i>Load weather query results directly via an API URL</li>
											<li><i></i>Save and share your weather analysis</li>
											<li><i></i>Make and test queries using our Weather Query Builder</li>
											<li><i></i>Automatically update weather conditions via live queries within Excel</li>
											<li><i></i>Sample workbooks available to use directly and build upon</li>
										</ul>
									</div>

								</div>
						</div>
						
						<div id="">
								
								
								<div>
									
									
									<div>
										<p>
										
									Power BI is an interactive business intelligence tool designed to be simple enough for end users create their own analyses while being powerful enough for business-wide use.  
									Weather data fits naturally into this analysis framework, and Visual Crossing Weather makes the integration easy.  
									Our API query URLs can return CSV results that import directly into any Power BI report or dashboard.

										</p>
										<ul>
											<li><i></i>Find valuable correlations between any data and weather</li>
											<li><i></i>Load weather data directly from our cloud-based servers</li>
											<li><i></i>Save and share weather reports and dashboard across your team</li>
											<li><i></i>Samples get you up and running quickly</li>
										</ul>
									</div>

								</div>
						</div>
	

	
	

						<div id="">
								
								<p><a href="https://www.visualcrossing.com/resources/documentation/weather-api" title="Weather API Documentation">
									<img src="https://www.visualcrossing.com/images/excel-weather/bi_300x200.png" alt="Loading weather data into your Business Intelligence System"></a>
								</p>
								<div>
									
									
									<div>
									<p>
										High-end BI platforms represent the backbone of data analysis within many large and mid-sized companies.  
										These powerful tools can crunch decades of business and external data to find patterns and make recommendations.  
										Visual Crossing Weather can be easily embedded directly into every BI application.


										</p>
										<ul>
											<li><i></i>Find valuable correlations between your business data and weather</li>
											<li><i></i>ETL scripts, plug-ins, and sample dashboards available</li>
											<li><i></i>Import weather data into your corporate warehouse</li>
											<li><i></i>Get added value from your existing BI investment</li>
										</ul>
									</div>

								</div>
						</div>
						
						<div id="">
								
								
								<div>
									
									
									<div>
										<p>
											Google Sheets has become the most universally accessible data analysis application due to the global reach of its web-based platform.  
											That same web platform powers instant data sharing in schools, companies, and around the world.  
											Visual Crossing Weather data can be integrated easily into any Google Sheet application using a single API call.

										</p>
										<ul>
											<li><i></i>Directly load history and forecast weather data into any Sheet</li>
											<li><i></i>Update live weather results directly in Google Sheets</li>
											<li><i></i>Share weather data analysis instantly</li>
											<li><i></i>Ideal for academic and education users</li>
										</ul>
									</div>

								</div>
						</div>
						
	
						<p id="">
							<h2>Databases</h2>
						</p>
						<div id="">
								
								<p><a href="https://www.visualcrossing.com/weather/weather-data-services" title="Weather Data Query Builder"><img src="https://www.visualcrossing.com/images/excel-weather/server_300x200.png" alt="Weather Data for Databases - Data Loading, Live Updates, Enterprise Access"></a>
							
								</p>
								<div>
									
									
									<div>
										<p>
											An enterprise data warehouse is the heart of data science for nearly every large and mid-sized corporation.  
											The power to store vast amounts of business data enable analysts across an organization make intelligent business decisions.
											Visual Crossing Weather allows historical weather data to be matched directly to existing business records.
										</p>
										<p>											
											Many business activities are affected by weather.
											Adding Visual Crossing data to an enterprise data warehouse bring immediate inside and ROI.
										</p>
										<ul>
											<li><i></i>Easily load weather data using ETL and embedded queries</li>
											<li><i></i>Dynamic queries load fresh weather data automatically</li>
											<li><i></i>Compatible with application across the enterprise</li>
											<li><i></i>Every part of the organization can find new insight</li>
										</ul>
									</div>

								</div>
						</div>
						
					</div></div>]]>
            </description>
            <link>https://www.visualcrossing.com/weather-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-25706592</guid>
            <pubDate>Sun, 10 Jan 2021 00:05:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Why I, as a black man, attend KKK rallies.’ [video]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25705798">thread link</a>) | @boogies
<br/>
January 9, 2021 | https://invidious.site/watch?v=ORp3q1Oaezw&dark_mode=true&autoplay=1 | <a href="https://web.archive.org/web/*/https://invidious.site/watch?v=ORp3q1Oaezw&dark_mode=true&autoplay=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://invidious.site/watch?v=ORp3q1Oaezw&amp;dark_mode=true&amp;autoplay=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705798</guid>
            <pubDate>Sat, 09 Jan 2021 22:44:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Putting Mental Models to Practice Part 4: Expert Decision Making]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25705441">thread link</a>) | @gHeadphone
<br/>
January 9, 2021 | https://commoncog.com/blog/putting-mental-models-to-practice/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/putting-mental-models-to-practice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p><em>This is Part 4 of a <a href="https://commoncog.com/blog/a-framework-for-putting-mental-models-to-practice/">series of posts</a> on putting mental models to practice. In <a href="https://commoncog.com/blog/a-framework-for-putting-mental-models-to-practice-part-1/">Part 1</a> I described my problem with Munger’s approach to mental models after I applied it to my life. In <a href="https://commoncog.com/blog/putting-mental-models-to-practice-part-2-introduction-to-rationality/">Part 2</a> I argued that the study of rationality is a good place to start for a framework of practice. We learnt that <a href="https://fs.blog/mental-models/">Farnam Street’s list of mental models</a> consists of three types of models: descriptive models, thinking models concerned with judgment (epistemic rationality), and thinking models concerned with decision making (instrumental rationality). In <a href="https://commoncog.com/blog/putting-mental-models-to-practice-part-3-better-trial-and-error/">Part 3</a>, we were introduced to the search-inference framework for thinking, and discussed how mental models from instrumental rationality may help prevent the three errors of thinking as prescribed by the search-inference framework. We also took a quick detour to look at optimal trial and error through the eyes of Marlie Chunger. In Part 4, we will explore the idea that expertise leads to its own form of decision making. This is where my views begin to diverge from Farnam Street’s.</em></p><p>Many experts, in many fields, don’t do the sort of thinking we have explored in our previous part. They don’t do rational choice analysis. They don’t do expected utility calculations. &nbsp;They don’t adjust for biases, they don’t do appropriate search-inference thinking and they don’t use a ‘latticework of mental models from other fields’ to draw inferences.</p><p>And yet, despite a lack of grounding in the ‘best practices’ of decision science, they appear to perform remarkably well in the real world.</p><p>So what do they do?</p><p>They do <a href="https://en.wikipedia.org/wiki/Recognition_primed_decision">recognition-primed decision making</a>.</p><p>Recognition-primed decision making (henceforth called RPD) is a <em>descriptive</em> model of decision-making: that is, it describes how humans make decisions in real world environments. RPD is one of the thinking models from the field of <a href="https://en.wikipedia.org/wiki/Naturalistic_decision-making">Naturalistic Decision Making</a> (NDM), which is concerned with how practitioners <em>actually</em> make decisions on the job. NDM researchers eschew the lab and embed themselves in organisational settings, and take an almost anthropological approach to research. They follow firefighters on calls, sit in tanks during military exercises, and interview interface designers and programmers in the office, during work tasks. The way the researchers do this is to use an interviewing technique they call Cognitive Task Analysis, which is designed to draw out <em>tacit mental models of expertise</em>.</p><p>NDM is interesting to us because it represents an alternative school of thought to conventional decision analysis. The growth of the cognitive biases and heuristics research program has created a number of prescriptive models — rooted in expected utility theory — designed to help us make more ‘rational’ decisions. We’ve covered the basics of that approach in <a href="https://commoncog.com/blog/putting-mental-models-to-practice-part-3-better-trial-and-error/">Part 3</a>. But the cognitive biases and heuristics program has also sucked up a lot of attention in recent years. We continually hear endless stories about the fallibility of human judgment and the errors and biases that systematically cloud our thinking. Whatever popular science books have to say about NDM is limited to the sort of ‘magical intuition’ as portrayed by Malcolm Gladwell in <em>Blink</em>.</p><p>This is a terrible portrayal. Because expert intuition is often portrayed as ‘magical’, we ignore it and turn to more rational, deliberative modes of decision making. We do not believe that intuition can be trained, or replicated. We think that rational choice analysis is the answer to everything, and that amassing a large collection of mental models in service of the search-inference framework is the ‘best’ way to make decisions.</p><p>It is telling, however, that the US military uses RPD models for training and analysis of battlefield decision-making situations. The field of NDM arose out of psychologist Gary Klein’s work, done in the 90s, for the US Army Research Institute for the Behavioural and Social Sciences. In the 70s and the 80s, the US Government had spent millions on decision science research — that is, on <em>conventional</em> models rooted in rational choice analysis — and used these findings to develop expensive decision aids for battle commanders.</p><p>The problem they discovered was that nobody actually used these aids in the real world. The army had spent ten years worth of time and money on research that didn’t work at all. It needed a new approach. <em>(Chapter 2, Gary Klein, Sources of Power)</em>.</p><h2 id="how-experts-make-decisions">How Experts Make Decisions</h2><p>RPD describes the decision making that emerges from expertise. This is a huge differentiating factor; the majority of results in classical decision science was built on behavioural experiments performed on ordinary people. The model goes as follows:</p><p>Let’s say that an expert encounters a problem in the real world. The first step in the RPD model is recognition: that is, the expert perceives the situation in a changing environment and pattern matches it against a collection of prototypes. The more experience she has, the more prototypes or analogues she has stored in her <a href="https://en.wikipedia.org/wiki/Implicit_memory">implicit memory</a>.</p><p>This instantly generates four things. The first is a set of ‘expectancies’ — the expert has some expectations for happens next. For instance, in a firefighting environment, an experienced firefighter can tell where a fire would travel, and how a bad situation might develop. An experienced computer programmer can glance at some code and tell if the chosen abstraction would lead to problems months down the road. A manager can hear two pieces of information during lunch and predict production delays two months in the future.</p><p>The second thing this recognition generates is a set of <em>plausible goals</em> — that is, priorities of what needs to be accomplished. In a life-or-death situation, a platoon commander has to prioritise between keeping his troop alive, getting to advantageous cover, and achieving mission objectives. His recognised prototype instantly tells him where his priorities lie in a given situation, freeing cognitive resources to conduct other forms of thinking.</p><p>The third thing that is generated is a set of relevant cues. A novice looking at a chaotic situation will not notice the same things that the expert does. Noticing cues to evaluate a changing environment is one of the benefits of experience — and it is necessary in order to prevent information overload. Think of driving a car: in the beginning, you find yourself overwhelmed with the number of dials and knobs and mirrors you have to keep track of. After a few months, you do these things intuitively and notice only select cues in your environment as you drive.</p><p>Last, but not least, a sequence of actions is generated by the expert, sometimes called an ‘action script’ — and it presents itself, fully formed, in the expert’s head.</p><figure><img src="https://commoncog.com/blog/content/images/2019/01/Paper.Commonplace.42.png" alt=""></figure><p>The fact that RPD depends so much on implicit memory means that this entire process happens in a blink of an eye. Consider how you might recognise a person walking into the room as your friend ‘Mary’ or ‘Joe’. Facial recognition is an implicit memory task: the information ‘magically’ makes itself known to you. Similarly, an expert confronted with a work-related problem will perform the recognition and generate the four by-products instantaneously. When initially interviewing firefighters, Klein’s researchers found that the firefighters would often assert that they were <em>not</em> decision making: instead, they arrived at the scene of a fire and knew immediately what to do.</p><p>This is, of course, not a complete picture. What happens when the situation is unclear, or when the initial diagnosis is flawed? Here’s a story from <em>Sources of Power</em> to demonstrate what happens next:</p><blockquote>“The initial report is of flames in the basement of a four-story apartment building: a one-alarm fire. The commander arrives quickly and does not see anything. There are no signs of smoke anywhere. He finds the door to the basement, around the side of the building, enters, and sees flames spreading up the laundry chute. That’s simple: a vertical fire that will spread straight up. Since there are no external signs of smoke, it must just be starting.<p>The way to fight a vertical fire is to get above it and spray water down, so he sends one crew up to the first floor and another to the second floor. Both report that the fire has gotten past them. The commander goes outside and walks around to the front of the building. Now he can see smoke coming out from under the eaves of the roof. It is obvious what has happened: the fire has gone straight up to the fourth floor, has hit the ceiling there, and is pushing smoke down the hall. Since there was no smoke when he arrived just a minute earlier, this must have just happened.</p><p>It is obvious to him how to proceed now that the chance to put out the fire quickly is gone. He needs to switch to search and rescue, to get everyone out of the building, and he calls in a second alarm. The side staircase near the laundry chute had been the focus of activity before. Now the attention shifts to the front stairway as the evacuation route.”</p></blockquote><p>Where were the decisions here? The firefighter sees a situation — a vertical fire — and immediately knows what to do. But a few seconds later, he cancels that diagnosis because he recognises a different situation, and orders a different set of actions.</p><p>In rational choice theory, the firefighter is not making any decisions at all because he is not comparing between possibilities. He is simply reading the environment and taking action. Klein and co argue that decisions are still made, however: at multiple points in the story, the firefighter could have chosen from an array of options. The fact that he merely considers one option at each decision point doesn’t mean he <em>didn’t</em> make a decision — it is simply that he considers his options in linear fashion, finds the first that is satisfactory, and then acts on it.</p><p>There are two conclusions from looking at this process. The first is to conclude that when we make decisions, we naturally <em>look at our options one at a time.</em> It just so happens that the first option an expert practitioner generates is …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/putting-mental-models-to-practice/">https://commoncog.com/blog/putting-mental-models-to-practice/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/putting-mental-models-to-practice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705441</guid>
            <pubDate>Sat, 09 Jan 2021 22:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blocks Courtesy of Konrad Zuse (2014)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25705391">thread link</a>) | @Tomte
<br/>
January 9, 2021 | https://blog.infinitenegativeutility.com/2014/9/blocks-courtesy-of-konrad-zuse | <a href="https://web.archive.org/web/*/https://blog.infinitenegativeutility.com/2014/9/blocks-courtesy-of-konrad-zuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apparently, I've got a theme going of Weird Syntax. Let's run with it.</p>

<p>Konrad Zuse was an early pioneer in computer science, although his name is perhaps somewhat less well-known than others. Zuse holds the honor of having built the first programmable computer—-the Z3—-back in the 40's, as well as several other computing firsts<sup id="fnref:1"><a href="#fn:1" rel="nofollow">1</a></sup>. Of particular interest to this blog post is his early unimplemented programming language, Plankalkül.</p>

<p>Plankalkül was, like the Z3, in many respects ahead of its time. Zuse's explicit goal was to be able to describe programs at a high level, which meant he included control structures and datatype definitions<sup id="fnref:2"><a href="#fn:2" rel="nofollow">2</a></sup> and other high-level constructs that were often missing in languages of the early years of computing. Zuse was working on Plankalkül at a time when his machines were not useable, which meant that his language work was more theoretical than it was technical, and consequently he allowed features that he wasn't entirely sure how to program. Despite his notes on it having been written in the mid-40's, they were not published until the 70's, and it was not implemented until the year 2000.</p>

<p>One thing that struck me, as I read programs in this notation that had been set down on a typewriter<sup id="fnref:3"><a href="#fn:3" rel="nofollow">3</a></sup>, is that certain kinds of grouping were handled by explicit indication of scope: not via matched delimiters as in ALGOL-style languages, or via indentation in languages such as Python and Haskell, but by formatting the code so that a line bordered on the left of the scoped parts of the code:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-01.png" alt=""></p>

<p>This is meant to capture the way grouping works in the hand-written or typeset notation, with brackets spanning multiple lines:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-02.png" alt=""></p>

<p>I think this is notationally interesting: it's like Python's significant whitespace, but not, uh, whitespace. It would be incredibly tedious to type out, but still entirely compatible with current programming notation:</p>

<pre><code>class Tet
 | @staticmethod
 | def new_tet()
 |  | n = randint(0, len(Tet.Tets) - 1)
 |  | for p in Tet.Tets[n]
 |  |  | if p in Board.permanent
 |  |  |  | Game.lose()
 |  | Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 |
 | def __init__(self, points, color)
 |  | self.points = points
 |  | self.color = color
</code></pre>

<p>and would be entirely amenable to beautifying via judicious application of Unicode:</p>

<pre><code>class Tet
 ┃ @staticmethod
 ┃ def new_tet()
 ┃  ┃ n = randint(0, len(Tet.Tets) - 1)
 ┃  ┃ for p in Tet.Tets[n]
 ┃  ┃  ┃ if p in Board.permanent
 ┃  ┃  ┗  ┗ Game.lose()
 ┃  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ┃
 ┃ def __init__(self, points, color)
 ┃  ┃ self.points = points
 ┃  ┗ self.color = color
</code></pre>

<p>Looking at this notation, however, an interesting possibility struck me: a programmer could explicit annotate information about the <em>kind of scope</em> involved in a given line. In this Python-like example, I could, for example, distinguish class scope using double lines, function scope with thick lines, and control structure scope with thin lines:</p>

<pre><code>class Tet
 ║ @staticmethod
 ║ def new_tet()
 ║  ┃ n = randint(0, len(Tet.Tets) - 1)
 ║  ┃ for p in Tet.Tets[n]
 ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
 ║  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ║
 ║ def __init__(self, points, color)
 ║  ┃ self.points = points
 ║  ┗ self.color = color
</code></pre>

<p>One advantage of this scheme is that a handful of lines, viewed in isolation, still give you a clear view of what surrounds them. For example, I can view these two lines in isolation and still tell that they are within a control structure used within a function declared within a class:</p>

<pre><code> ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
</code></pre>

<p>You could also imagine a hypothetical language in which choice of scope delimiter is important. In Python, <code>for</code> and <code>if</code> do not form a new lexical scope. What if instead we could stipulate the kind of scope they form by this notational convention?</p>

<pre><code>def okay()
 ┃ if True
 ┃  └ n = 5   # n is declared in function scope
 ┗ return n   # n leaks out of the if-scope

def not_okay()
 ┃ if True
 ┃  ┗ n = 5   # n is declared in the if's scope
 ┗ return n   # error: no n in scope here
</code></pre>

<p>That being said, there are a number of reasons that this notation is in inferior to existing notations:</p>
<ul><li>It makes refactoring code <em>much</em> more difficult.</li>
<li>It requires that the programmer <em>pay attention</em> to the sequence of enclosing scopes on a <em>line-by-line</em> basis, which is generally too pedantic and not particularly useful for a programmer.</li>
<li>The ability to select “which kind of scope” is by no means only expressible by this notation, as other syntactic features such as keywords and delimiters could express the same thing.</li>
<li>There are only so many line-like characters which can serve as a scope marker, so this scheme is not very extensible.</li>
<li>It complicates parsing (especially by introducing an entirely new class of parse errors in which adjacent lines feature incompatible sequences of delimiting lines), and so it also...</li>
<li>Complicates parse <em>error messages</em>, which are an important part of a language's UI and should be considered seriously.</li></ul>

<p>So, as in my previous post on <a href="https://blog.infinitenegativeutility.com/2014/8/noun-case" rel="nofollow">grammatical case in programming languages</a>, I urge readers <em>not</em> to use this notation as the concrete syntax for a programming language. This is merely an entertaining peek through the looking glass at a curious notational convention which was never adopted.</p>

<p>That said: this makes a very nice notation for <em>viewing</em> code, where the programmer does not have to explicitly draw ASCII art around their code; indeed, it bears more than a passing similarity to the graphical interface used in <a href="http://scratch.mit.edu/" rel="nofollow">Scratch</a>, and Sean McDirmid's <a href="http://research.microsoft.com/en-us/projects/liveprogramming/typography.aspx" rel="nofollow">Experiments in Code Typography</a> features this very convention as an interactive ornament on code in a Python-like language.</p>

</div></div>]]>
            </description>
            <link>https://blog.infinitenegativeutility.com/2014/9/blocks-courtesy-of-konrad-zuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705391</guid>
            <pubDate>Sat, 09 Jan 2021 22:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Movie in the World]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25705332">thread link</a>) | @Lindaz
<br/>
January 9, 2021 | http://www.the-classic-movies.com/the-arrival-of-a-train-1896/ | <a href="https://web.archive.org/web/*/http://www.the-classic-movies.com/the-arrival-of-a-train-1896/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h2>The Arrival of a Train</h2>

<p>Release date: January 25, 1896<br>
Directed by: Auguste Lumière, Louis Lumière<br>
Stars: Madeleine Koehler, Marcel Koehler, Mrs. Auguste Lumiere, etc.<br>
Running time: 50 seconds<br>
Country: France<br>
Language: Silent</p>
<p><img loading="lazy" src="http://www.the-classic-movies.com/wp-content/uploads/2021/01/The-Arrival-of-a-Train-1896-200x300.jpg" alt="The-Arrival-of-a-Train-(1896)" width="200" height="300" srcset="https://www.the-classic-movies.com/wp-content/uploads/2021/01/The-Arrival-of-a-Train-1896-200x300.jpg 200w, https://www.the-classic-movies.com/wp-content/uploads/2021/01/The-Arrival-of-a-Train-1896.jpg 350w" sizes="(max-width: 200px) 100vw, 200px"></p>
<p>There is nothing exciting about an arriving train, but somehow it became an iconic scene in cinematic history. Produced by pioneering French filmmakers Auguste and Louis Lumière, it was the first scene that was ever shown to public. Arrival of a Train at La Ciotat was filmed in France at the end of 1895 and was shown in 1896. The 50-second long film captures the gradual approach of a train, its slow stop and the disembarking of its passengers. The arrival of a train produces little of interest in terms of actual content but it has more of interest in its historical and cultural context.</p>
<p>It is interesting that this scene, that is really simple and casual for us today, made a great affect on people, they said it was all realistic and it was a great power of illusion. Almost everyone heard the story about people who was watching that scene for the first time back then in 1896, they was scared and ran out. In fact, there was no real mass panic. But French scientist Henri de Parville, who attended an early screening, wrote: «One of my neighbors was so much captivated that she sprung to her feet… and waited until the car disappeared before she sat down again.» It shows us that it was a miracle alive for people back then and it is hard to imagine what they were felling during the screening of «The arrival of a train» in January, 1896.</p>
<p>Auguste and Louis Lumière obviously recognized the power of illusion that they had. In order to maximize the affect of the approaching train they mounted their camera as close as possible to the edge of platform, so that the audience feels as if they stand right on the locomotive’s path. People in the scene are just normal citizens that stand on the platform, so it makes us believe that all of that is real. So since we have nothing in common with the first audiences, we may understand that it was something magical for people back then.</p>
<p>Moreover, this scene makes a great affect today, but not as a cinematic miracle, but as a history. On a surface level we watch a train arrives but what we are really witnessing is the arrival of cinema. Nowadays we understand what cinematography is and, in fact, it is not a film in our today comprehension, but it is always interesting to see how it all started and to trace its development.</p>
<p>«The arrival of a train» is not just a short scene or a film, but it is a window between past and present. It is a possibility to see what people looked like, because photos and pictures are good things, but when we look at this scene we feel that we are with that people, that they are alive and we understand what they were wearing in those days, we can see their appearance.</p>
<p>Summing up, we can say that Auguste and Louis Lumière weren’t really artists. Their early films don’t stand up to the highly imaginative movies of George Méliès for example. But they still remain very important cinema giants. Not for the content of their films but for the fact that they kicked things off in the first place and produced the first iconic moment in cinema history. And for this reason «L’arrivée d’un train a La Ciotat» will always be remembered. Everyone who has a love of cinema should really take a minute of their time to pay attention to the first moment in an amazing thing called cinematography.</p>


</div></div>]]>
            </description>
            <link>http://www.the-classic-movies.com/the-arrival-of-a-train-1896/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705332</guid>
            <pubDate>Sat, 09 Jan 2021 22:04:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Replicated State Machines with Compartmentalization]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25705234">thread link</a>) | @cpufry
<br/>
January 9, 2021 | https://mwhittaker.github.io/publications/compartmentalized_paxos.html | <a href="https://web.archive.org/web/*/https://mwhittaker.github.io/publications/compartmentalized_paxos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    <center>
      
    </center>

    <p><span>
      <a href="https://mwhittaker.github.io/publications/compartmentalized_paxos.pdf">
        "Scaling Replicated State Machines with Compartmentalization"
      </a>
    </span>
    <span>
      Michael Whittaker,
      Ailidani Ailijiang,
      Aleksey Charapko,
      Murat Demirbas,
      Neil Giridharan,
      Joseph M. Hellerstein,
      Heidi Howard,
      Ion Stoica,
      Adriana Szekeres
    </span></p><h2>Links</h2>
    <ul>
      <li>
        <a href="https://mwhittaker.github.io/publications/compartmentalized_paxos.pdf">A pre-print of the paper</a>
      </li>
      <li>
        <a href="https://arxiv.org/abs/2012.15762">The technical report on arXiv</a>
      </li>
      <li>
        <a href="https://github.com/mwhittaker/frankenpaxos">The source code on GitHub</a>
      </li>
      <li>
        <a href="https://mwhittaker.github.io/frankenpaxos/js/src/main/js/multipaxos/multipaxos.html">A JavaScript visualization of Compartmentalized MultiPaxos</a>
      </li>
      <li>
        <a href="https://mwhittaker.github.io/">More publications on similar topics</a>
      </li>
    </ul>

    <h2>Abstract</h2>
    <p>
    State machine replication protocols, like MultiPaxos and Raft, are a
    critical component of many distributed systems and databases. However,
    these protocols offer relatively low throughput due to several bottlenecked
    components. Numerous existing protocols fix different bottlenecks in
    isolation but fall short of a complete solution. When you fix one
    bottleneck, another arises. In this paper, we introduce
    compartmentalization, the first comprehensive technique to eliminate state
    machine replication bottlenecks. Compartmentalization involves decoupling
    individual bottlenecks into distinct components and scaling these
    components independently. Compartmentalization has two key strengths.
    First, compartmentalization leads to strong performance. In this paper, we
    demonstrate how to compartmentalize MultiPaxos to increase its throughput
    by 6x on a write-only workload and 16x on a mixed read-write workload.
    Unlike other approaches, we achieve this performance without the need for
    specialized hardware. Second, compartmentalization is a technique, not a
    protocol. Industry practitioners can apply compartmentalization to their
    protocols incrementally without having to adopt a completely new protocol.
    </p>
  </div></div>]]>
            </description>
            <link>https://mwhittaker.github.io/publications/compartmentalized_paxos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705234</guid>
            <pubDate>Sat, 09 Jan 2021 21:54:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Research-Based Methods for Learning Japanese]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25705070">thread link</a>) | @sova
<br/>
January 9, 2021 | https://japanesecomplete.com/articles/?p=1282 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/articles/?p=1282">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h3><strong>Conclusions</strong> from the Academic Research</h3>



<p>We looked at research papers from the last 30 years to evaluate our set of teaching strategies undertaken in our Japanese language learning application called <a href="https://japanesecomplete.com/">Japanese Complete</a>.  We found that the scholarly and academic studies referred to confirm:</p>



<ol><li><strong>Kanji [logographs of mainland Asian origin] are categorized as the main impediment in acquisition of the Japanese language</strong> and anything to ease their acquisition from rote-memorization will help learners greatly.</li><li><strong>Computer aided learning of Japanese is superior to textbook-based</strong> learning <strong>when</strong> <strong>paired with timely and useful feedback</strong> for the learner, with politeness language, grammar, kanji, and more. [4, 5, 7, 12, 17]</li><li><strong>Kanji are processed by different parts of the brain compared to English letters and Hiragana mora,</strong> suggesting that placing special emphasis on learning Kanji as glyphs or <em>graphics with associated meanings <strong>first</strong></em> establishes a firm foundation upon which to then learn readings and pronunciations. [2, 6]</li><li>Kanji have <em>logographic</em> as well as <em>phonographic</em> value; <strong>cultural, etymological, and mnemonic strategies are not only more effective than rote-memorization strategies for learning, they also remove a lot of anxiety and perceived inscrutability of kanji, making kanji learning fun and intriguing</strong> instead of a chore.  The main techniques presented in these papers include component-analysis of kanji [what we call subkanji learning], and pairing kanji with graphical and mnemonic aides such as stories or imaginal scenes. [6, 7, 10, 11, 14, 15]</li><li>It is very likely that native speakers of languages featuring kanji create <em>some sort</em> of meaning-word associated with each kanji, whether able to give voice to it or not (“unconscious knowledge”), suggesting strongly that <strong>by teaching kanji meaning-words first one is creating a very helpful and direct shortcut to their successful assimilation.</strong> [6, 9, 10]</li><li>One paper suggests the use of an “orthographic gradient” where terms are first shown as color-coded Hiragana, and later instances are shown as color-coded kanji using the same coloration, allowing learners to make an implied association of equality.  <strong>This idea of “orthographic gradient” confirms the efficacy of our innovative approach “Kanji in English Context” where we t取ke kanji and pl置ce them in an 英ngl語sh c文nt脈xt [take, place, English, context] to expedite acquisition</strong> and increase familiarity with the plurality of [English] words kanji can represent. [11, 16]</li><li><strong>Acquisition of Japanese grammar and sequence continues to be the most challenging part of learning the language for 1st, 2nd, and 3rd year students,</strong> suggesting that the focus for the first several semesters of learning ought be grammar-focused.  Nouns are acquired at a linear rate no matter the level of grammar competency, and thus it would suggest that the learning of nouns can actually be greatly delayed without any negative impact on comprehension; rather, focus on grammar first would result in greatly improved comprehension when nouns are later added to one’s cogent grammar understanding. </li><li><strong>Very Accurate Japanese Pitch Accent</strong> can be trained and learned swiftly with the right learning materials (showing pitch contours on screen and having learners listen and repeat). [17]</li><li><strong>One’s native language shapes how one acquires second+ languages.</strong> [3, 13]</li></ol>



<figure><img src="http://jpc0.b-cdn.net/img/lake-onami.jpg" alt=""><figcaption>Lake Onami</figcaption></figure>



<h3><br><strong>Scholarly and Academic Works Cited</strong></h3>



<hr>



<p>[1] <em><strong>Phonological processing of Japanese Kanji and Chinese characters in bilingual Japanese : An fMRI study (2017)</strong></em></p>



<p><a href="https://ieeexplore.ieee.org/document/8015970" target="_blank" rel="noreferrer noopener">https://ieeexplore.ieee.org/document/8015970</a></p>



<p>“The result showed that our bilingual Japanese subjects have large overlaps in the neural substrates for phonological processing of both native and second language.  Our finding supports the idea that the neural systems of second language reading are shaped by native language.” </p>



<hr>



<p>[2] <em><strong>Japanese and English sentence reading comprehension and writing systems: An fMRI study of first and second language effects on brain activation. (2009)</strong></em></p>



<p><a href="https://pubmed.ncbi.nlm.nih.gov/19946611/" target="_blank" rel="noreferrer noopener">https://pubmed.ncbi.nlm.nih.gov/19946611/</a></p>



<p>Parts of the brain that are engaged when native Japanese readers process English, Hiragana, and Kanji:</p>



<figure><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/instance/2782536/bin/nihms120575f4.jpg" alt=""><figcaption>Activation regions for native Japanese speakers decoding written language.</figcaption></figure>



<p>“Functional magnetic resonance imaging (fMRI) was used to compare brain activation from Japanese readers reading hiragana (syllabic) and kanji (logographic) sentences, and English as a second language (L2). Kanji showed more activation than hiragana in right-hemisphere occipito-temporal lobe areas associated with visuospatial processing; hiragana, in turn, showed more activation than kanji in areas of the brain associated with phonological processing. L1 results underscore the difference in visuospatial and phonological processing demands between the systems. Reading in English as compared to either of the Japanese systems showed more activation in inferior frontal gyrus, medial frontal gyrus, and angular gyrus. The additional activation in English in these areas may have been associated with an increased cognitive demand for phonological processing and verbal working memory.”</p>



<hr>



<p>[3] <em><strong>Comparative Spatial Semantics and Language Acquisition:Evidence from Danish, English, and Japanese (1994)</strong></em></p>



<p><a href="https://www.researchgate.net/profile/Chris-Sinha/publication/249234936_Comparative_Spatial_Semantics_and_Language_Acquisition_Evidence_from_Danish_English_and_Japanese/links/57da79a508ae72d72ea2b8b8/Comparative-Spatial-Semantics-and-Language-Acquisition-Evidence-from-Danish-English-and-Japanese.pdf" target="_blank" rel="noreferrer noopener">https://www.researchgate.net/profile/Chris-Sinha/publication/249234936_Comparative_Spatial_Semantics_and_Language_Acquisition_Evidence_from_Danish_English_and_Japanese/links/57da79a508ae72d72ea2b8b8/Comparative-Spatial-Semantics-and-Language-Acquisition-Evidence-from-Danish-English-and-Japanese.pdf</a></p>



<p>“Perhaps the most important finding is that in all three languages that we have analysed acquisition appears to take place in two phases, during the first of which the child gradually acquires six to eight simple forms corresponding to ‘basic’ spatial meanings encoded in the target language.”</p>



<p>“In the second phase of acquisition, the child’s productive repertoire and the frequency of its use increase in a way that is reminiscent of (though perhaps less dramatic than) the ‘vocabulary explosion’ in nominal usage. The extension of the repertoire takes different courses, depending on the structure of the target language. In all languages it can be expected that the repertoire within the form class which is dominant in expressing spatial relational meaning will continue to expand, and that this will remain the most frequently employed vehicle for the child’s expression of spatial relational meaning throughout and perhaps beyond the third year of life.”</p>



<p>“In languages, such as Japanese, in which spatial relational meaning is overtly distributed over different form classes, the second phase will involve both an increase in the range of types controlled in the dominant form class (in this case,verbs), and the extension of the acquisition process to the other form classes (in this case, particles and nouns). Both the slow pace of acquisition in the non-dominant forms classes, and the fact that the meanings initially expressed using nouns are cognate with those already expressed using verbs, suggest that, in Japanese too, the learning process continues to be governed in the second phase by a conservative strategy. It can perhaps be seen as follows: the child employs the already acquired meanings as clues for the establishment of new centres in new form classes for the repetition with respect to these new form classes of the radial strategy already successfully employed with respect to the dominant form class.”</p>



<hr>



<p>[4] <strong><em>Supporting the acquisition of Japanese polite expressions in context-aware ubiquitous learning</em> <em>(2010)</em></strong></p>



<p><a href="http://www.academia.edu/download/50315553/ijmlo.2010.03263720161114-19604-1c5exmp.pdf">http://www.academia.edu/download/50315553/ijmlo.2010.03263720161114-19604-1c5exmp.pdf</a></p>



<p>“To support the foreigners learning JPE [Japanese Politeness Expressions], a PDA-based context-aware language learning support environment was proposed. This environment supports the learners to learn JPE according to the different situations in the real world. There are two version of the prototype system for this environment. In this paper, design, implementation and evaluation of JAPELAS2 are presented. From the experiment, we found the system provides the correct polite-expression based on hyponymy, social distance and situation through the identification of the target user and the location. The experiment showed that the system was quite useful and using this system made understanding the appropriate level of politeness easy by changing roles and situations.”</p>



<figure><img loading="lazy" width="645" height="641" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/Screen-Shot-2021-01-06-at-4.13.32-PM.png" alt=""></figure>



<hr>



<p>[5] <em><strong>COMPUTER VS. WORKBOOK INSTRUCTION IN SECOND LANGUAGE ACQUISITION (1996)</strong></em></p>



<p><a href="https://journals.equinoxpub.com/CALICO/article/viewFile/23393/19398">https://journals.equinoxpub.com/CALICO/article/viewFile/23393/19398</a></p>



<p>“The results of the study show that given the same grammar notes and exercises, <strong>ongoing intelligent computer feedback is more effective than simple workbook answer sheets for developing learners’ grammatical skill in producing Japanese particles and sentences.</strong> A significant difference between Nihongo-CALI and the workbook instruction was observed in the production tests but not in the comprehension tests. This is consistent with Flynn’s hypothesis that grammatical competence is less critical in comprehension than in production. As suggested by Pederson and Dunkel, the present study also confirms that the use of a medium (i.e., computer) alone does not bring better effects; rather the quality of the messages produced by the medium affects the result. This is based on the fact that the intelligent version of Nihongo-CALI is significantly more effective than the workbook instruction”</p>



<div><figure><img loading="lazy" width="411" height="333" src="https://japanesecomplete.com/articles/wp-content/uploads/2021/01/Screen-Shot-2021-01-06-at-4.19.44-PM.png" alt=""></figure></div>



<hr>



<p>[6] <em><strong>L2 learners’ attitudes toward, and use of, mnemonic strategies when learning Japanese Kanji (2013)</strong></em></p>



<p><a href="https://www.researchgate.net/publication/259551232_L2_learners%27_attitudes_toward_and_use_of_mnemonic_strategies_when_learning_Japanese_Kanji">https://www.researchgate.net/publication/259551232_L2_learners%27_attitudes_toward_and_use_of_mnemonic_strategies_when_learning_Japanese_Kanji</a></p>



<p>“This study investigated kanji learning (the memorization of Japanese written characters) of university students of Japanese, in order to evaluate students’ use of mnemonic strategies. The study applied …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://japanesecomplete.com/articles/?p=1282">https://japanesecomplete.com/articles/?p=1282</a></em></p>]]>
            </description>
            <link>https://japanesecomplete.com/articles/?p=1282</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705070</guid>
            <pubDate>Sat, 09 Jan 2021 21:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: JavaScript Program Synthesis]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25705059">thread link</a>) | @coolvision
<br/>
January 9, 2021 | https://grgv.xyz/inductive_program_synthesis/ | <a href="https://web.archive.org/web/*/https://grgv.xyz/inductive_program_synthesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Any compiler or transpiler is doing some form of program synthesis. But “proper” program synthesis usually means generation of high level programs from scratch, given only high level problem descriptions.</p>
<p>This post is about one of the most simple and straightforward methods of automatic program synthesis: inductive synthesis based on <strong>input-output examples</strong> specification and <strong>brute-force enumerative</strong> search.</p>
<h3>Synthesis task specification</h3>
<p>Let's start with a simple example. Suppose that we want to automatically generate a program that reverses an array.</p>
<p>How to formulate this task for the automatic program generator? One option is to just describe it in natural language. But it would be quite hard to automatically parse and understand. A simpler way is to provide examples of inputs and expected outputs:</p>
<p>[1, 2, 3, 4, 5, 6] → [6, 5, 4, 3, 2, 1]</p>
<p>[5, 2, 7, 6] → [6, 7, 2, 5]</p>
<p>It's similar to a programmer working on a task using test-driven development, with a set of self-explanatory tescases.</p>
<h3>Brute-force search</h3>
<p>How to find a program that satisfies some input-output examples? There are several possible search strategies, but the simplest one is just with a brute force enumeration.</p>
<p>The idea is to generate all programs (within some size liimts and a limited language subset), and pick the first one that works correctly for all specified examples.</p>
<p>This is probably the least efficient approach of all, but with some additional optimizations and heuristics for reducing the search space it can actually be practical.</p>
<p>For example, an algorithm that won last year's synthesis competition <a href="https://sygus.org/comp/2019/">SyGuS-Comp 2019</a> in programming-by-examples track, is based on brute-force enumerative search strategy. As well as some previous years winners (<a href="#examples" id="ref1">EUSOLVER, Enumerative CEGIS Solver</a>). There are even some practical applications, for example brute-force search can be used for <a href="http://dl.acm.org/citation.cfm?id=2462174">synthesising distributed systems protocols</a>.</p>
<h3>Generating Javascript</h3>
<p>For generating and manipulating programs, code has to be represented as a data structure. This is not a problem in homoiconic languages like Lisp, but in Javascript it’s harder.</p>
<p>One simple idea (used, for example in miniMAL project <a href="https://github.com/kanaka/miniMAL">https://github.com/kanaka/miniMAL</a>), is to use JSON for representing programs. In this case, JSON arrays are serving as an analog of Lisp s-expressions.</p>
<p>Similar to an s-expression, each JavaScript expression is represented as a JSON array. First element is a function name, and the rest of elements are for function arguments.</p>
<p>For example:</p>
<table>
  <thead>
  <tr>
   <td><strong>Javascript</strong></td>
   <td><strong>JSON</strong></td>
  </tr>
  </thead>
  <tbody><tr>
   <td>Math.pow(x, 2)</td>
   <td>["Math.pow", "x", 2]</td>
  </tr>
  <tr>
   <td>Math.pow(Math.sin(x), 2)</td>
   <td>[“Math.pow”, [“Math.sin”,  “x”], 2]</td>
  </tr>
</tbody></table>
<p>For operators, can use prefix notation:</p>
<table>
  <tbody><tr>
   <td>x = 2 + 2</td>
   <td>["=", x, ["+", 2, 2]]</td>
  </tr>
</tbody></table>
<p>There are some special expressions formats: control flow, variables declaration.</p>
<table>
  <tbody><tr>
   <td><strong>Javascript</strong>
   </td>
   <td><strong>JSON</strong>
   </td>
  </tr>
  <tr>
   <td>let x = 1
   </td>
   <td> ["let", "x", 1]
   </td>
  </tr>
  <tr>
   <td>for (let i = 0; i &lt; 10; i += 1) { console.log(i) }
   </td>
   <td>["for”, ”i”, ”0”, ”10”, ”1”,["block", [“console.log”, “i”]]]
   </td>
  </tr>
  <tr>
   <td>if (i &gt; 1) { i = 1; }
   </td>
   <td>["if", [“&gt;“, “i”, 1], ["block", [“=“, “i”, 1]]]
   </td>
  </tr>
</tbody></table>
<p>Also need syntax conventions for calling methods, accessing properties, and indexing arrays:</p>
<table>
  <tbody><tr>
   <td>let a = new Array(0, 1, 2)
   </td>
   <td>["let", "a", ["new Array", 0, 1, 2]]
   </td>
  </tr>
  <tr>
   <td>a.shift()
   </td>
   <td>[".shift", "a"]
   </td>
  </tr>
  <tr>
   <td>let n1 = a.length
   </td>
   <td>["let",  "n1", [".length_", "a"]]
   </td>
  </tr>
  <tr>
   <td>let n2 = a[1]
   </td>
   <td>["let",  "n2", ["get_index", a, 1]
   </td>
  </tr>
  <tr>
   <td>a[1] = 2
   </td>
   <td>["set_index", a, 0, 0]
   </td>
  </tr>
</tbody></table>
<p>This allows to represent a wide range of possible JavaScript expressions, and covers all language features needed for a simple demo.</p>
<p>Code for transforming from JSON representation to Javascript is fairly simple. It just has to traverse arrays, print out expressions elements in correct order, and deal with code formatting.</p>
<h3>Simple DSL</h3>
<p>For brute-force search to be feasible, search space has to be limited to some restricted domain-specific language subset, which depends on the kind of the target problem.</p>
<p>For example, can design a simple DSL targeted for simple array processing. It should have functions for array access and manipulation, simple arithmetics, and control flow functions.</p>
<table>
  <tbody><tr>
   <td><strong>function</strong>
   </td>
   <td><strong>Javascript</strong>
   </td>
   <td><strong>JSON</strong>
   </td>
  </tr>
  <tr>
   <td>subtract
   </td>
   <td>number = number?? - number??
   </td>
   <td>["-", "number??", "number??", "number"]
   </td>
  </tr>
  <tr>
   <td>add
   </td>
   <td>number = number?? + number??
   </td>
   <td>["+", "number??", "number??", "number"]
   </td>
  </tr>
  <tr>
   <td>greater than
   </td>
   <td>boolean = number?? &gt; number??
   </td>
   <td>["&gt;", "number??", "number??", "boolean"]
   </td>
  </tr>
  <tr>
   <td>less than
   </td>
   <td>boolean = number?? &lt; number??
   </td>
   <td>["&lt;", "number??", "number??", "boolean"]
   </td>
  </tr>
  <tr>
   <td>equal
   </td>
   <td>boolean = number?? == number??
   </td>
   <td>["==", "number??", "number??", "boolean"]
   </td>
  </tr>
  <tr>
   <td>array length
   </td>
   <td>number = array??.length
   </td>
   <td>[".length_", "array??", "number"]
   </td>
  </tr>
  <tr>
   <td>get array element at index
   </td>
   <td>number = array??[number??]
   </td>
   <td>["get_index", "array??", "number??", "number"]
   </td>
  </tr>
  <tr>
   <td>set array element at index
   </td>
   <td>array??[number??] = number
   </td>
   <td>["set_index", "output", "number??", "number??", ""]
   </td>
  </tr>
  <tr>
   <td>for loop
   </td>
   <td>for (let i in array??) { ?? }
   </td>
   <td>["for", "i", ["block", "??"], "in", "array??", ""]
   </td>
  </tr>
  <tr>
   <td>If condition
   </td>
   <td>if (boolean??) { ?? }
   </td>
   <td>["if", "boolean??", ["block", "??"], ""],
   </td>
  </tr>
</tbody></table>
<p>In the DSL description, "??" stands for an undefined value, that can be replaced with an expression or a variable. This notation is taken from <a href="#sketch" id="ref2">SKETCH language</a>, where "??" represents a <em>hole,</em> a placeholder that the synthesizer can replace with an integer constant.</p>
<p>Some undefined values have annotated types. For example "number??" means that the argument should be replaced with an expression that has "number" return value. This allows for additional limitations on the search space.</p>
<h3>Algorithm for program generation</h3>
<p>How to generate all programs that can be represented with the DSL? The algorithm is fairly simple: start with some undefined values, and iteratively replace them with all possible options picked from the list of DSL expressions. Selected and pasted expressions would contain some undefined values of their own, so the process is repeated until all the options are used, or until expressions tree depth reaches some limit.</p>
<p>It’s like iterative template rewriting, and it’s easier to demonstrate with an example:</p>
<table>
<tbody><tr>
	<td>1. Start with an empty/undefined program </td>
	<td>["??", "??", "??", "??"] </td>
</tr>
<tr>
	<td>2. Traverse the expressions tree, and pick the first occurring undefined value </td>
	<td>[<span>"??"</span>, "??", "??", "??"] </td>
</tr>
<tr>
	<td>3. List all options for replacing this value (expressions that have an empty return type) </td>
	<td><span>["set_index", "output", "number??", "number??", ""]</span><br>
		["if", "boolean??", ["block", "??"], ""]<br>
		["if", "boolean??", ["block", "??"], ""]
	</td>
</tr>
<tr>
	<td>4. Repace undefined value with the first option </td>
	<td>[<span>["set_index", "output", "number??", "number??", ""]</span>, "??", "??" ,"??"] </td>
</tr>
</tbody></table>
<p>Steps 2-4 are repeated iteratively. Expressions tree is traversed depth-first, and each found leaf corresponds to a unique program. Press “next” button in the demo below, to see next iterations.</p>


<div id="demo2">

	<p>
		Demo: iterative program generation
	</p>

	<p>step</p>
	<p>reset</p>

	
</div>

<p>Generated programs are verified with the given input-output examples:</p>
<ol>
<li>Translate from JSON represenation to Javascript</li>
<li>Fill pre-defined input array variable with an example</li>
<li>Evaluate the program with eval()</li>
<li>Check if contents of the pre-defined output variable correspond to the output example.</li>
</ol>
<p>The demo below shows program generation for "array reversal" problem. Press “generate” button to see continuous generation, or use “next” to see generation steps. It generates and checks around a million of short programs per minute, and is able so solve the problem in ~10-20s. I tweaked the DSL to have a bare minimum of available expressions, for search to be faster. Size of the program is also limited by number of used varialbes (limited to 4). It would still work with larger more generic DSL, just would take more time.</p>

<div id="demo5">

	<p>
		Demo: generate a program for reversing an array.
	</p>

	<p>step</p>
	<p>generate</p>
	<p>stop</p>
	<p>reset</p>

	<div>

		<div>

			<p>Input/output examples</p>
			

			<p>Generated program</p>
			

			<p>Evaluation result</p>
			
		</div>

		

	</div>
</div>

<p>Some more examples are show below. They also have custom DSLs tuned for each problem, so that it does not take too much time (~10-20s).</p>


<h3> Example: generate a program that finds sum of array elements</h3>

<div id="demo3">

	<p>
		Demo: generate a program that finds sum of array elements
	</p>

	<p>step</p>
	<p>generate</p>
	<p>stop</p>
	<p>reset</p>

	<div>

		<div>

			<p>Input/output examples</p>
			

			<p>Generated program</p>
			

			<p>Evaluation result</p>
			
		</div>

		

	</div>
</div>



<h3> Example: generate a program that finds max element in an array</h3>

<div id="demo4">

	<p>
		Demo: generate a program that finds max element in an array
	</p>

	<p>step</p>
	<p>generate</p>
	<p>stop</p>
	<p>reset</p>

	<div>

		<div>

			<p>Input/output examples</p>
			

			<p>Generated program</p>
			

			<p>Evaluation result</p>
			
		</div>

		

	</div>
</div>

<h2>Refenences &amp; links</h2>
<p>(book) <a href="https://rishabhmit.bitbucket.io/papers/program_synthesis_now.pdf">Program Synthesis</a><br>
Sumit Gulwani, Oleksandr Polozov, Rishabh Singh</p>
<p>(course materials) Introduction to Program Synthesis<br>
<a href="http://people.csail.mit.edu/asolar/SynthesisCourse/Lecture2.htm">http://people.csail.mit.edu/asolar/SynthesisCourse/Lecture2.htm</a></p>
<h3>Papers</h3>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.367.9604&amp;rep=rep1&amp;type=pdf">Dimensions in Program Synthesis</a><br>
Sumit Gulwani</p>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=7EC748B93DCDCE0DABC810450BD07AE1?doi=10.1.1.180.1237&amp;rep=rep1&amp;type=pdf">Inductive Programming (A Survey of Program Synthesis Techniques)</a><br>
Emanuel Kitzelmann</p>
<p><span id="examples"><a href="#ref1">↑</a></span><br>
Scaling Enumerative Program Synthesis via Divide and Conquer<br>
Rajeev Alur, Arjun Radhakrishna, and Abhishek Udupa</p>
<p>CVC4SY for SyGuS-COMP 2019<br>
Andrew Reynolds, Haniel Barbosa, Andres Nötzli, Clark Barrett, Cesare Tinelli</p>
<p><span id="sketch"><a href="#ref2">↑</a></span><br>
The Sketching Approach to Program Synthesis<br>
Armando Solar-Lezama</p>
<h3>Blog posts</h3>
<p><a href="https://thegradient.pub/p/577a122d-df49-4e1f-8dc3-324f5c784236/">Software that writes software: on program synthesis</a><br>
Adithya Ganesh</p>
<p><a href="https://barghouthi.github.io/2017/04/24/synthesis-primer/">A Program Synthesis Primer </a><br>
Aws Albarghouthi</p>
<p><a href="https://alexpolozov.com/blog/program-synthesis-2018/">Program Synthesis in 2017-18</a><br>
Alex Polozov</p>
<p><a href="https://www.cs.cornell.edu/~asampson/blog/minisynth.html">Program Synthesis is Possible</a><br>
Adrian Sampson</p>
<p><a href="https://blog.sigplan.org/2020/03/25/homoiconicity-lisp-and-program-synthesis/">Homoiconicity, Lisp, and Program Synthesis</a><br>
Rajesh Jayaprakash</p>
<p><a href="https://blog.sigplan.org/2019/07/31/program-synthesis-in-2019/">Program Synthesis in 2019</a><br>
<a href="https://www.cs.utexas.edu/~bornholt/post/synthesis-explained.html">Program Synthesis Explained</a><br>
<a href="https://www.cs.utexas.edu/~bornholt/post/building-synthesizer.html">Building a Program Synthesizer</a><br>
<a href="https://blog.sigplan.org/2019/11/26/building-your-first-program-synthesizer/">Building Your First Program Synthesizer</a><br>
James Bornholt</p>


			</div></div>]]>
            </description>
            <link>https://grgv.xyz/inductive_program_synthesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705059</guid>
            <pubDate>Sat, 09 Jan 2021 21:38:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Lambda vs. Azure Functions: 10 Major Differences]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25704936">thread link</a>) | @tacon
<br/>
January 9, 2021 | https://iamondemand.com/blog/aws-lambda-vs-azure-functions-ten-major-differences/ | <a href="https://web.archive.org/web/*/https://iamondemand.com/blog/aws-lambda-vs-azure-functions-ten-major-differences/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="15b005c9" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="4344" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="54feab4" data-element_type="section">
						<div>
							<div>
					<div data-id="e39972b" data-element_type="column">
			<div>
							<div>
						<div data-id="fddd529" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Forget about managing virtual machines or paying for idle hardware! Serverless compute brings unlimited scale and high availability to every company in the world, from small startups to multinational corporations. At least, that’s the vision of Amazon and Microsoft, today’s biggest cloud vendors.</span></p><p><span>AWS Lambda pioneered the Function as a Service (FaaS) application model in 2014. With Faas, a small piece of code—called a function—is deployed as a ZIP file and linked to a specific type of event, such as a queue or an HTTP endpoint. AWS runs this function every time a matching event occurs, be it once per day or a thousand times per second.</span></p><p><span>Since 2014, the serverless model has taken off, and every major cloud provider has introduced its flavor of an FaaS service: Azure Functions, Google Cloud Functions, and IBM Cloud Functions, to name a few. While the basic idea behind all the offerings is the same, there are many differences between these implementations.</span></p><p><span>Today, I’ll compare AWS Lambda with Azure Functions (Lambda’s equivalent in Azure cloud), focusing on their unique features and limitations. Here are the ten major differences between the two options.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="7d8498c" data-element_type="section">
						<div>
							<div>
					<div data-id="e80d08f" data-element_type="column">
			<div>
							<div>
						<div data-id="d24e788" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>To put it simply, there is one way to run a serverless function in AWS: <a href="https://iamondemand.com/blog/how-i-simplified-my-lambda-deployments/" target="_blank" rel="noopener noreferrer">deploy it</a> to the AWS Lambda service. Amazon’s strategy here is to make sure that this service covers as many customer scenarios as possible, ranging from hobby websites to enterprise-grade data processing systems.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="b6360b3" data-element_type="section">
						<div>
							<div>
					<div data-id="b7d9665" data-element_type="column">
			<div>
							<div>
						<div data-id="fd4d1bf" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span><strong>Microsoft takes a different approach.</strong> They separated the notion of the Azure Functions programming model from the serverless operational model. </span></p><p><span>With Azure Functions, I can deploy my functions to a pay-per-use, fully-managed Consumption plan. However, I can also use </span><a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-scale" target="_blank" rel="noopener noreferrer"><span>other hosting options</span></a><span> to run the same code:</span></p><ul><li><ul><li><ul><li><span><strong>App Service plan</strong>: provides a predictable pay-per-hour price, but has limited auto-scaling behavior</span></li><li><span><strong>Premium plan (preview)</strong>: gives reserved capacity </span><i><span>and</span></i><span> elastic scaling, combined with advanced networking options, for a higher price</span></li><li><span><strong>A Docker container</strong>: can run anywhere on self-managed infrastructure</span></li><li><span><strong>Kubernetes-based event-driven architecture (KEDA, experimental)</strong>: brings functions to Kubernetes, running in any cloud or on-premises</span></li></ul></li></ul></li></ul><p><span>The Consumption plan has the lowest management overhead and no fixed-cost component, which makes it the most serverless hosting option on the list. For that reason, I’m going to focus on AWS Lambda vs. Azure Functions Consumption plan for the rest of this article.</span></p><p><span>When deploying an </span><a href="https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html" target="_blank" rel="noopener noreferrer"><span>AWS Lambda function</span></a><span>, I need to define the maximum memory allocation, which has to be between 128MB and 3GB. The CPU power and cost of running the function are proportional to the allocated memory. It takes a bit of experimentation to define the optimal size, depending on the workload profile. Regardless of size, all instances run on Amazon Linux.</span></p><p><span>On the other hand, Azure Functions Consumption plan is one-size-fits-all. It comes with 1.5GB of memory and one low-profile virtual core. You can choose between Windows and Linux as a host operating system.</span></p><p><a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-premium-plan#plan-and-sku-settings" target="_blank" rel="noopener noreferrer"><span>Azure Functions Premium plan</span></a><span> comes with multiple instance sizes, up to 14GB of memory, and four vCPUs. However, you have to pay a fixed per-hour fee for the reserved capacity.</span></p><p><span>AWS Lambda natively supports JavaScript, Java, Python, Go, C#, F#, PowerShell, and Ruby code.</span></p><p><span>Azure Functions has runtimes for JavaScript, Java, Python, C#, F#, and PowerShell (preview). Azure lacks Go and Ruby—otherwise, the language options are very similar.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="5e255a2" data-element_type="section">
						<div>
							<div>
					<div data-id="17c9936" data-element_type="column">
			<div>
							<div>
						<div data-id="24ac72d" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span><em>IOD is a content creation agency. Our tech experts create tech content that leads people to your tech blog. <a href="https://iamondemand.com/success-stories/" target="_blank" rel="noopener"><span>Learn</span> <span>more</span></a>.</em></span></p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="9f5ad03" data-element_type="section">
						<div>
							<div>
					<div data-id="aef234e" data-element_type="column">
			<div>
							<div>
						<div data-id="686f22b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Specifics vary between runtimes, but, overall, AWS Lambda has a </span><a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-services.html" target="_blank" rel="noopener noreferrer"><span>straightforward programming model</span></a><span>. A function receives a JSON object as input and may return another JSON as output. The event type defines the schema of those objects, which are documented and defined in language SDKs.</span></p><p><span>Azure Functions has a more sophisticated model based on </span><a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-triggers-bindings" target="_blank" rel="noopener noreferrer"><span>triggers and bindings</span></a><span>. A trigger is an event that the function listens to. The function may have any number of input and output bindings to pull and/or push extra data at the time of processing. For example, an HTTP-triggered function can also read a document from Azure Cosmos DB and send a queue message, all done declaratively via binding configuration.</span></p><p><span>The implementation details differ per language runtime. The binding system provides extra flexibility, but it also brings some complexity, in terms of both API and configuration.</span></p><p><span>One drawback of all FaaS services on the market is the limited set of supported event types. For example, if you want to trigger your functions from a Kafka topic, you are out of luck on both AWS and Azure.</span></p><p><span>Other aspects of serverless functions are more customizable. AWS Lambda defines a </span><a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html" target="_blank" rel="noopener noreferrer"><span>concept of layers</span></a><span>: a distribution mechanism for libraries, custom runtimes to support other languages, and other dependencies. </span></p><p><span>Azure Functions enables open </span><a href="https://github.com/Azure/azure-webjobs-sdk-extensions/wiki/Binding-Extensions-Overview" target="_blank" rel="noopener noreferrer"><span>binding extensions</span></a><span> so that the community can create new types of bindings and bring them into Function Apps.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="da33380" data-element_type="section">
						
		</section>
				<section data-id="509f65d" data-element_type="section">
						
		</section>
				<section data-id="cc4cd47" data-element_type="section">
						
		</section>
				<section data-id="49d6d240" data-element_type="section">
						<div>
							<div>
					<div data-id="6c138dd2" data-element_type="column">
			<div>
							<div>
						<div data-id="1ae1cb03" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Both services can run multiple (potentially thousands) executions of the same function simultaneously, each handling one incoming event.</span></p><p><span>AWS Lambda always reserves a separate instance for a single execution. Each execution has its exclusive pool of memory and CPU cycles. Therefore, the performance is entirely predictable and stable.</span></p><p><span>Azure Functions allocates multiple concurrent executions to the same virtual node. If one execution is idle waiting for a response from the network, other executions may use resources which would otherwise be wasted. However, resource-hungry executions may fight for the pool of shared resources, harming the overall performance and processing time.</span></p><p><span>Serverless pricing is based on a pay-per-usage model. Both services have two cost components: pay-per-call and pay-per-GB*seconds. The latter is a metric combining execution time and consumed memory.</span></p><p><span>Moreover, the price tag for both services is almost exactly the same: $0.20 per million requests and $16 per million GB*seconds ($16.67 for AWS). One million executions running for 100 ms each and consuming 1GB of memory cost less than $2. Since AWS Lambda was the first on the market, I assume Microsoft just copied the numbers.</span></p><p><span>There are some differences in the details, though:</span></p><ul><li><span>AWS Lambda charges for full provisioned memory capacity, while Azure Functions measures the actual average memory consumption of executions.</span></li><li><span>If Azure Function’s executions share the instance, the memory cost isn’t charged multiple times, but shared between executions, which may lead to noticeable reductions.</span></li><li><span>Both services charge for at least 100 ms and 128MB for each execution. AWS rounds the time up to the nearest 100 ms, while Azure rounds up to 1 ms.</span></li><li><span>CPU profiles are different for Lambda and Functions, which may lead to different durations for comparable workloads.</span></li></ul><p><span>I wrote more on how to measure the cost of Azure Functions&nbsp;</span><a href="https://mikhail.io/2019/08/how-to-measure-the-cost-of-azure-functions/" target="_blank" rel="noopener noreferrer"><span>here</span></a><span>.</span></p><p><span>AWS Lambda used to require Amazon API Gateway to listen to HTTP traffic, which came at a massive additional cost. Recently, Amazon introduced&nbsp;</span><a href="https://aws.amazon.com/about-aws/whats-new/2018/11/alb-can-now-invoke-lambda-functions-to-serve-https-requests/" target="_blank" rel="noopener noreferrer"><span>integration with Elastic Load Balancing</span></a><span>, which may be more cost efficient for high-load scenarios. However, the pricing is per hour, so good judgment is required.</span></p><p><span>Azure Functions comes with HTTP endpoint integration out of the box, and there is no additional cost for this integration.</span></p><p><span>AWS Lambda has been on the market longer than Azure Functions, and has a laser focus on the single-hosting model. Although there are no established industry-wide benchmarks, many claim that AWS Lambda is better for rapid scale-out and handling massive workloads, both for web APIs and queue-based applications. The bootstrapping delay effect—cold starts—are also less significant with Lambda.</span></p><p><span>Azure Functions has improved significantly in the last year or two, but Microsoft is still playing catch-up.</span></p><p><span>Serverless functions are nanoservices: small blocks of code doing just one thing. The question of how to build large applications and systems out of those tiny pieces is still open, but some composition patterns already exist.</span></p><p><span>Both AWS and Azure have dedicated services for workflow orchestration: AWS Step Functions and Azure Logic Apps. Quite often, functions are used as steps in those workflows, allowing them to stay independent but still solve significant tasks.</span></p><p><span>In addition, </span><a href="https://docs.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview" target="_blank" rel="noopener noreferrer"><span>Azure Durable Functions</span></a><span> is a library that brings workflow orchestration abstractions to code. It comes with several patterns to combine multiple serverless functions into stateful long-running flows. The library handles communication and state management robustly and transparently, while keeping the API surface simple.&nbsp;</span></p><p><span>AWS Lambda and Azure Functions are similar services, but the devil is in the details—and virtually every angle shows some essential distinctions between the two. My list of ten differences is certainly not exhaustive, and each aspect would need a separate article to cover it in full.</span></p><p><span>It’s unlikely that your choice will be driven purely by these differences. At the same time, whenever you have to choose one option over the other, or when <a href="https://iamondemand.com/blog/azure-user-heres-what-you-must-know-about-aws/" target="_blank" rel="noopener noreferrer">you switch between providers</a>, it’s crucial to adjust your thinking and practices to match the peculiarities.</span></p><p><span>In short, choose the option that fits you best!</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="1d70780" data-element_type="section">
						<div>
							<div>
					<div data-id="d4c56cf" data-element_type="column">
			<div>
							<div>
						<div data-id="7626217" data-element_type="widget" data-widget_type="call-to-action.default">
				<div>
					<div>
					
							<div>
				
									<h2>
						Are you a tech …</h2></div></div></div></div></div></div></div></div></div></section></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iamondemand.com/blog/aws-lambda-vs-azure-functions-ten-major-differences/">https://iamondemand.com/blog/aws-lambda-vs-azure-functions-ten-major-differences/</a></em></p>]]>
            </description>
            <link>https://iamondemand.com/blog/aws-lambda-vs-azure-functions-ten-major-differences/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25704936</guid>
            <pubDate>Sat, 09 Jan 2021 21:25:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generic associated types encode higher-order functions on types]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25704895">thread link</a>) | @lukastyrychtr
<br/>
January 9, 2021 | https://willcrichton.net/notes/gats-are-hofs/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/gats-are-hofs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; — &nbsp;
    January 4, 2021
  </p>
  <p>GATs allow type parameters to associated types in traits. This feature enables total type-level functions to be associated to structs. I show how to use this pattern to implement higher-order type-level functions, and how to use specialization to make partial functions into total functions.</p>
  <p><em>Part of an ongoing series about type-level programming in Rust. Read <a href="http://willcrichton.net/notes/type-level-programming/">part one</a> first!<br></em></p>

<p>With <a href="https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md">generic associated types</a> landing recently in Rust nightly, I’ve been wondering: what expressive power does this feature add to type-level programming? The answer is <strong>higher-order functions on types</strong>, and in this post I’ll explain what that means and how it works.</p>

<h2 id="a-refresher-on-type-level-programming">A refresher on type-level programming</h2>

<p>Using a pure functional programming style, we can define objects like a list of types. For example, using <a href="https://github.com/willcrichton/tyrade">tyrade</a>, my type-level programming language:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>enum</span> <span>TList</span> <span>{</span>
    <span>TNil</span><span>,</span>
    <span>TCons</span><span>(</span><span>Type</span><span>,</span> <span>TList</span><span>)</span>
  <span>}</span>

  <span>enum</span> <span>TOption</span> <span>{</span>
    <span>TNone</span><span>,</span>
    <span>TSome</span><span>(</span><span>Type</span><span>)</span>
  <span>}</span>

  <span>// Get the Nth item from the list, where Index is either Z or S&lt;N&gt;</span>
  <span>fn</span> <span>Nth</span><span>&lt;</span><span>List</span><span>,</span> <span>Index</span><span>&gt;</span><span>()</span> <span>{</span>
    <span>match</span> <span>List</span> <span>{</span>
      <span>TNil</span> <span>=&gt;</span> <span>TNone</span><span>,</span>
      <span>TCons</span><span>(</span><span>X</span><span>,</span> <span>XS</span><span>)</span> <span>=&gt;</span> <span>match</span> <span>Index</span> <span>{</span>
        <span>Z</span> <span>=&gt;</span> <span>TSome</span><span>(</span><span>X</span><span>),</span>
        <span>S</span><span>(</span><span>IMinusOne</span><span>)</span> <span>=&gt;</span> <span>Nth</span><span>(</span><span>XS</span><span>,</span> <span>IMinusOne</span><span>)</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>// checks that Nth([i32, f32], 1) == Some(f32)</span>
  <span>assert_type_eq</span><span>::</span><span>&lt;</span>
    <span>Nth</span><span>&lt;</span><span>TCons</span><span>&lt;</span><span>i32</span><span>,</span> <span>TCons</span><span>&lt;</span><span>f32</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span><span>,</span> <span>S</span><span>&lt;</span><span>Z</span><span>&gt;&gt;</span><span>,</span>
    <span>TSome</span><span>&lt;</span><span>f32</span><span>&gt;</span>
  <span>&gt;</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>The <code>tyrade!</code> procedural macro compiles the pseudo-Rust notation into a series of structs, traits, and impls. For example:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>TNil</span><span>;</span>
<span>pub</span> <span>struct</span> <span>TCons</span><span>&lt;</span><span>T0</span><span>,</span> <span>T1</span><span>&gt;</span><span>(</span><span>...</span><span>);</span>

<span>pub</span> <span>trait</span> <span>ComputeNth</span><span>&lt;</span><span>Index</span><span>&gt;</span> <span>{</span>
    <span>type</span> <span>Output</span><span>;</span>
<span>}</span>
<span>pub</span> <span>type</span> <span>Nth</span><span>&lt;</span><span>List</span><span>,</span> <span>Index</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>List</span> <span>as</span> <span>ComputeNth</span><span>&lt;</span><span>Index</span><span>&gt;&gt;</span><span>::</span><span>Output</span><span>;</span>

<span>impl</span><span>&lt;</span><span>Index</span><span>&gt;</span> <span>ComputeNth</span><span>&lt;</span><span>Index</span><span>&gt;</span> <span>for</span> <span>TNil</span> <span>{</span>
    <span>type</span> <span>Output</span> <span>=</span> <span>TNone</span><span>;</span>
<span>}</span>
<span>impl</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span> <span>ComputeNth</span><span>&lt;</span><span>Z</span><span>&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span> <span>X</span><span>:</span> <span>ComputeTSome</span> <span>{</span>
    <span>type</span> <span>Output</span> <span>=</span> <span>TSome</span><span>&lt;</span><span>X</span><span>&gt;</span><span>;</span>
<span>}</span>
<span>impl</span><span>&lt;</span><span>IMinusOne</span><span>,</span> <span>X</span><span>,</span> <span>XS</span><span>&gt;</span> <span>ComputeNth</span><span>&lt;</span><span>S</span><span>&lt;</span><span>IMinusOne</span><span>&gt;&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span> <span>XS</span><span>:</span> <span>ComputeNth</span><span>&lt;</span><span>IMinusOne</span><span>&gt;</span> <span>{</span>
    <span>type</span> <span>Output</span> <span>=</span> <span>Nth</span><span>&lt;</span><span>XS</span><span>,</span> <span>IMinusOne</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>See my explainer on <a href="https://willcrichton.net/notes/type-level-programming/">type-level programming</a> if you are confused about the correspondence between these programs.</p>
</blockquote>

<h2 id="higher-order-functions-on-types">Higher-order functions on types</h2>

<p>For me, Tyrade is a explicit representation of my mental model for type-level programming. Once I conceptually understood the correspondences between type-level enums and structs, or between type-level functions and traits, then I reified that understanding into the Tyrade compiler.</p>

<p>However, trait/function correspondence only worked when the arguments to type-level functions were types. To explain, we’ll use the running example of a list map function. The goal is to write it in Tyrade like this:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>Map</span><span>&lt;</span><span>List</span><span>,</span> <span>Func</span><span>&gt;</span><span>()</span> <span>{</span>
    <span>match</span> <span>List</span> <span>{</span>
      <span>TNil</span> <span>=&gt;</span> <span>TNil</span><span>,</span>
      <span>TCons</span><span>(</span><span>X</span><span>,</span> <span>XS</span><span>)</span> <span>=&gt;</span> <span>TCons</span><span>(</span><span>Func</span><span>(</span><span>X</span><span>),</span> <span>Map</span><span>(</span><span>XS</span><span>,</span> <span>Func</span><span>))</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Then we could use the <code>Map</code> type function like this:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>TIsZero</span><span>&lt;</span><span>N</span><span>&gt;</span><span>()</span> <span>{</span>
    <span>match</span> <span>N</span> <span>{</span>
      <span>Z</span> <span>=&gt;</span> <span>TTrue</span><span>,</span>
      <span>S</span><span>(</span><span>N1</span><span>)</span> <span>=&gt;</span> <span>TFalse</span>
    <span>}</span>
  <span>}</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>assert_type_eq</span><span>::</span><span>&lt;</span>
    <span>Map</span><span>&lt;</span>
      <span>TCons</span><span>&lt;</span><span>Z</span><span>,</span> <span>TCons</span><span>&lt;</span><span>S</span><span>&lt;</span><span>Z</span><span>&gt;</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span><span>,</span>
      <span>TIsZero</span>
    <span>&gt;</span><span>,</span>
    <span>TCons</span><span>&lt;</span><span>TTrue</span><span>,</span> <span>TCons</span><span>&lt;</span><span>TFalse</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span>
  <span>&gt;</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>However, the existing translation of <code>Map</code> doesn’t work. It would become:</p>

<div><div><pre><code><span>pub</span> <span>trait</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Output</span><span>;</span>
<span>}</span>
<span>pub</span> <span>type</span> <span>Map</span><span>&lt;</span><span>List</span><span>,</span> <span>Func</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>List</span> <span>as</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;&gt;</span><span>::</span><span>Output</span><span>;</span>

<span>impl</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>for</span> <span>TNil</span> <span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TNil</span><span>;</span>
<span>}</span>
<span>impl</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>,</span> <span>Func</span><span>&gt;</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span> <span>XS</span><span>:</span> <span>ComputeMap</span><span>&lt;</span><span>Func</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TCons</span><span>&lt;</span><span>Func</span><span>&lt;</span><span>X</span><span>&gt;</span><span>,</span> <span>Map</span><span>&lt;</span><span>XS</span><span>,</span> <span>Func</span><span>&gt;&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>And this code fails to compile because <code>Func</code> can’t be invoked with a parameter:</p>

<div><div><pre><code>error[E0109]: type arguments are not allowed for this type
    |
    |     type Output = TCons&lt;Func&lt;X&gt;, Map&lt;XS, Func&gt;&gt;;
    |                              ^ type argument not allowed
</code></pre></div></div>

<p>Herein lies the crux of the issue: type variables (i.e. impl quantifiers) are only allowed to be of kind <code>type</code>, and not of kind <code>type -&gt; type</code>. To get higher-order type functions, we need Rust to support higher-kinded types (HKT). While Rust doesn’t support HKT directly, the addition of generic associated types (GATs) enables a pseudo-HKT pattern. See <a href="http://smallcultfollowing.com/babysteps/blog/2016/11/03/associated-type-constructors-part-2-family-traits/">Niko’s extended discussion</a> for the gory details.</p>

<h2 id="implementing-hofs-with-hkts-with-gats">Implementing HOFs with HKTs with GATs</h2>

<p><code>TIsZero</code> cannot be passed directly into <code>ComputeMap</code>, so the key idea is to create a proxy object <code>TIsZeroProxy</code> which can be passed in. Using GATs, we associate the <code>TIsZeroProxy</code> back to <code>TIsZero</code> in a way that can be referenced within <code>ComputeMap</code>. First, the proxy:</p>

<div><div><pre><code><span>pub</span> <span>trait</span> <span>FuncProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>
<span>}</span>

<span>pub</span> <span>struct</span> <span>TIsZeroProxy</span><span>;</span>
<span>impl</span> <span>FuncProxy</span> <span>for</span> <span>TIsZeroProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>TIsZero</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Then the implementation of <code>ComputeMap</code> can be parameterized by any type implementing <code>FuncProxy</code>:</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>,</span> <span>Proxy</span><span>&gt;</span> <span>ComputeMap</span><span>&lt;</span><span>Proxy</span><span>&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span>
  <span>Proxy</span><span>:</span> <span>FuncProxy</span><span>,</span>
  <span>XS</span><span>:</span> <span>ComputeMap</span><span>&lt;</span><span>Proxy</span><span>&gt;</span>
<span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TCons</span><span>&lt;</span><span>Proxy</span><span>::</span><span>Func</span><span>&lt;</span><span>X</span><span>&gt;</span><span>,</span> <span>Map</span><span>&lt;</span><span>XS</span><span>,</span> <span>Proxy</span><span>&gt;&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>However, this attempt still doesn’t quite work. We get an error in the implementation of <code>FuncProxy</code> for <code>TIsZeroProxy</code>:</p>

<div><div><pre><code>error[E0277]: the trait bound `T: ComputeTIsZero` is not satisfied
    |
    |   type Func&lt;T&gt; = TIsZero&lt;T&gt;;
    |   ^^^^^^^^^^^^^^^^^^^^^^^^ the trait `ComputeTIsZero` is not implemented for `T`
    |
</code></pre></div></div>

<p>Why do we get this? Recall that <code>TIsZero&lt;T&gt;</code> is an alias for <code>&lt;T as ComputeTIsZero&gt;::Output</code>. This means that <code>T</code> must implement the <code>ComputeTIsZero</code> trait, which isn’t guaranteed by our general <code>FuncProxy</code> trait definition. We could theoretically change <code>FuncProxy</code> to include this bound, something like:</p>

<div><div><pre><code><span>trait</span> <span>FuncProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>:</span> <span>ComputeTIsZero</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>However, our goal is for <code>Map</code> to take as input any type-level function. This definition of <code>FuncProxy</code> would restrict the implement to only functions mentioned in the trait bounds.</p>

<h2 id="dealing-with-partial-functions">Dealing with partial functions</h2>

<p>Let’s back up to understand the conceptual issue. In Rust, type-level functions are partial functions, meaning they may not be implemented for all types. For example, <code>TIsZero</code> is only implemented for the types <code>Z</code> and <code>S&lt;N&gt;</code>, but not e.g. for the type <code>String</code>. However, to define <code>Map</code>, we have to ensure that <code>Proxy::Func&lt;X&gt;</code> is defined for all <code>X</code> in a type list.</p>

<p>Previously, we could ensure this condition via a trait bound. For example, if <code>Proxy::Func</code> was <code>ComputeTIsZero</code>, then we could add <code>X: ComputeTIsZero</code> to the implementation. But for any generic <code>Proxy::Func</code>, there is no way to say <code>X: Proxy::Func</code> because <code>Proxy::Func</code> is a type, not a trait. Hypothetically, if Rust supported <a href="https://github.com/rust-lang/rfcs/issues/2190">associated traits</a>, we could do something like:</p>

<div><div><pre><code><span>trait</span> <span>FuncProxy</span> <span>{</span>
  <span>trait</span> <span>Func</span> <span>{</span> <span>type</span> <span>Output</span><span>;</span> <span>};</span>
<span>}</span>

<span>impl</span> <span>FuncProxy</span> <span>for</span> <span>TIsZeroProxy</span> <span>{</span>
  <span>trait</span> <span>Func</span> <span>=</span> <span>ComputeTIsZero</span><span>;</span>
<span>}</span>

<span>type</span> <span>CallProxy</span><span>&lt;</span><span>Proxy</span><span>,</span> <span>T</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>T</span> <span>as</span> <span>Proxy</span><span>::</span><span>Func</span><span>&gt;</span><span>::</span><span>Output</span><span>;</span>

<span>impl</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>,</span> <span>Proxy</span><span>&gt;</span> <span>ComputeMap</span><span>&lt;</span><span>Proxy</span><span>&gt;</span> <span>for</span> <span>TCons</span><span>&lt;</span><span>X</span><span>,</span> <span>XS</span><span>&gt;</span>
<span>where</span>
  <span>Proxy</span><span>:</span> <span>FuncProxy</span><span>,</span>
  <span>XS</span><span>:</span> <span>ComputeMap</span><span>&lt;</span><span>Proxy</span><span>&gt;</span><span>,</span>
  <span>X</span><span>:</span> <span>Proxy</span><span>::</span><span>Func</span>
<span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TCons</span><span>&lt;</span><span>CallProxy</span><span>&lt;</span><span>Proxy</span><span>,</span> <span>X</span><span>&gt;</span><span>,</span> <span>Map</span><span>&lt;</span><span>XS</span><span>,</span> <span>Proxy</span><span>&gt;&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>However, Rust doesn’t have such a feature. Instead, we can use <a href="https://github.com/rust-lang/rust/issues/31844">specialization</a> to make all type functions total. We can define a base case where a type function returns an error if it’s not implemented, but as a type rather than a compiler error. To compile <code>TIsZero</code>, this solution looks like:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Error</span><span>;</span>

<span>pub</span> <span>trait</span> <span>FuncProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>
<span>}</span>

<span>pub</span> <span>trait</span> <span>ComputeTIsZero</span> <span>{</span>
  <span>type</span> <span>Output</span><span>;</span>
<span>}</span>

<span>type</span> <span>TIsZero</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>T</span> <span>as</span> <span>ComputeTIsZero</span><span>&gt;</span><span>::</span><span>Output</span><span>;</span>

<span>impl</span> <span>ComputeTIsZero</span> <span>for</span> <span>Z</span> <span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TTrue</span><span>;</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>N</span><span>&gt;</span> <span>ComputeTIsZero</span> <span>for</span> <span>S</span><span>&lt;</span><span>N</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Output</span> <span>=</span> <span>TFalse</span><span>;</span>
<span>}</span>

<span>/* key addition */</span>
<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>ComputeTIsZero</span> <span>for</span> <span>T</span> <span>{</span>
  <span>default</span> <span>type</span> <span>Output</span> <span>=</span> <span>Error</span><span>;</span>
<span>}</span>

<span>struct</span> <span>TIsZeroProxy</span><span>;</span>
<span>impl</span> <span>FuncProxy</span> <span>for</span> <span>TIsZeroProxy</span> <span>{</span>
  <span>type</span> <span>Func</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>TIsZero</span><span>&lt;</span><span>T</span><span>&gt;</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>With this addition, the <code>TIsZeroProxy</code> implementation no longer errors, because <code>ComputeTIsZero</code> is guaranteed to be implemented for all types <code>T</code>. And now, at long last, our <code>Map</code> program will execute correctly if we replace <code>TIsZero</code> with <code>TIsZeroProxy</code>:</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
  <span>assert_type_eq</span><span>::</span><span>&lt;</span>
    <span>Map</span><span>&lt;</span>
      <span>TCons</span><span>&lt;</span><span>Z</span><span>,</span> <span>TCons</span><span>&lt;</span><span>S</span><span>&lt;</span><span>Z</span><span>&gt;</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span><span>,</span>
      <span>TIsZeroProxy</span>
    <span>&gt;</span><span>,</span>
    <span>TCons</span><span>&lt;</span><span>TTrue</span><span>,</span> <span>TCons</span><span>&lt;</span><span>TFalse</span><span>,</span> <span>TNil</span><span>&gt;&gt;</span>
  <span>&gt;</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>Note: as of January 2021, this pattern is theoretically sound, but seems to have ongoing performance or correctness issues in the compiler. Specialization combined with recursive trait bounds will occassionally cause the compiler to stack overflow  — see my <a href="https://github.com/rust-lang/rust/issues/80700">Github issue</a>.</p>
</blockquote>

<h2 id="dynamically-kinded-type-level-programming">Dynamically-kinded type-level programming</h2>

<p>To add support for higher-order type functions, I had to remove support for type annotations (actually kind annotations) from Tyrade. Previously, you could write functions like this:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>TIsZero</span><span>(</span><span>N</span><span>:</span> <span>TNum</span><span>)</span> <span>-&gt;</span> <span>TBool</span> <span>{</span>
    <span>match</span> <span>N</span> <span>{</span>
      <span>Z</span> <span>=&gt;</span> <span>TTrue</span><span>,</span>
      <span>S</span><span>(</span><span>N1</span> <span>@</span> <span>TNum</span><span>)</span> <span>=&gt;</span> <span>TFalse</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This program would compile into the trait definition:</p>

<div><div><pre><code><span>trait</span> <span>ComputeTIsZero</span><span>:</span> <span>TNum</span> <span>{</span>
  <span>type</span> <span>Output</span><span>:</span> <span>TBool</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>This ensures, for example, that a function’s return value matches its return kind. If you wrote a function with a mismatch:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>TIsZero</span><span>(</span><span>N</span><span>:</span> <span>TNum</span><span>)</span> <span>-&gt;</span> <span>TBool</span> <span>{</span>
    <span>Z</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Then the compiler raises an error at the point of <em>definition</em> for <code>TIsZero</code> rather than the point of <em>use</em>. Hence, this language is statically-kinded. However, to kind-check a higher-order function like <code>Map</code>, we need a polymorphic kind system. Ideally, we could write in Tyrade:</p>

<div><div><pre><code><span>tyrade!</span> <span>{</span>
  <span>fn</span> <span>Map</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span><span>(</span><span>L</span><span>:</span> <span>List</span><span>&lt;</span><span>A</span><span>&gt;</span><span>,</span> <span>F</span><span>:</span> <span>A</span> <span>-&gt;</span> <span>B</span><span>)</span> <span>-&gt;</span> <span>List</span><span>&lt;</span><span>B</span><span>&gt;</span> <span>{</span>
    <span>...</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>I don’t believe it’s possible to encode this concept into Rust’s trait system. So to add higher-order functions, our type-level programming language had to become dynamically-kinded. A sad trade-off, but perhaps more acceptable for type-level programming than value-level. Although errors are caught by the users and not the definers, at least they’re still caught at compile-time!</p>

</div></div>]]>
            </description>
            <link>https://willcrichton.net/notes/gats-are-hofs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25704895</guid>
            <pubDate>Sat, 09 Jan 2021 21:22:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a runtime reflection system for Rust (Part 3)]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25704707">thread link</a>) | @lukastyrychtr
<br/>
January 9, 2021 | https://www.osohq.com/post/runtime-reflection-pt-3 | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/runtime-reflection-pt-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><strong>Part 3: <code>dyn Method</code></strong></h2>
<h3>Introduction</h3>
<p>Welcome to the third and final installment of our series on how we implemented a runtime reflection system in Rust.</p>
<p>So far, we've shown how we came up with a fairly simple <code>Class</code> and <code>Instance</code> model for thinking about runtime Rust classes. In <a href="https://www.osohq.com/post/rust-reflection-pt-1">Part 1</a>, we used these for type checking, and in <a href="https://www.osohq.com/post/runtime-reflection-pt-2">Part 2</a> we added support for reading attributes off of a struct.</p>
<p>In this post, we pick up where we left off with attribute getters, and expand into <strong>method calls</strong>. In some ways, the same techniques we used for attributes work just as well here. We can store a map from method name to functions implementing them. However, there's a curveball: the Rust <code>Fn*</code> traits. We'll talk through the wrong turns we took, and the tidbits of Rust knowledge we picked up along the way.</p>
<h2>Method Calls</h2>
<p>Now that we have classes, instances, and attributes, the next obvious step is to add methods.</p>
<p>In oso policies, it is possible to call both class and instance methods, with and without arguments.</p>
<p>So given the struct:</p>
<pre><code>struct Cat;

impl Cat {
    /// A class method (note lack of `self`).
    fn meow() -&gt; String {
       "meowww".to_string()
    }

    /// An instance method.
    fn feed(&amp;self, food: &amp;str) -&gt; String {
        if food == "tuna" { "purr".to_string() } else { Self::meow() }
    }
}
</code></pre>

<p>We should be able to write policy logic:</p>
<pre><code>favourite_food(cat: Cat, food) if cat.feed(food) != Cat.meow();
</code></pre>

<p>Which says that the input <code>food</code> is the cat's favourite food if the result of feeding the cat is not the same as the result of the cat meowing.</p>
<h3>Step 1: Zero arguments</h3>
<p>Let's start with a simple implementation for methods that take <em>zero</em> arguments. The approach for implementing zero-argument methods is extremely similar to how we'd implement attribute getters, and we've actually done this already in Part 2:</p>
<pre><code>/// Class definitions
struct Class {
    ...

    /// Map from attribute name to the attribute lookup
    methods: HashMap&lt;&amp;'static str, InstanceMethod&gt;
}

struct InstanceMethod(Arc&lt;dyn Fn(&amp;Instance) -&gt; PolarValue);
</code></pre>

<p>Similarly, we need to add a method onto our <code>ClassBuilder</code> struct to allow us to register new methods:</p>
<pre><code>pub fn add_method&lt;F, R&gt;(mut self, name: &amp;'static str, f: F) -&gt; Self
where
    F: Fn(&amp;T) -&gt; R,
    R: crate::ToPolar,
{
    self.class.methods.insert(name, InstanceMethod::new(f));
    self
}
</code></pre>

<p>Super easy! End of blog post. See you next time 😎 </p>
<p>But wait, what about methods with multiple arguments?</p>
<h3>Step 2: Multiple Arguments and the <code>Fn*</code> traits</h3>
<p>Let's take what we have above and add in support for multiple arguments.</p>
<pre><code>struct InstanceMethod(Arc&lt;dyn Fn(&amp;Instance, Vec&lt;PolarValue&gt;) -&gt; PolarValue&gt;);
</code></pre>

<p>This mostly works for what we need! Polar doesn't care about method arities (how many arguments the method accepts) – it will send over however many arguments it has as a vector. Polar supports both variable number of arguments (varargs) and keyword arguments (kwargs). The latter is only supported for host languages that also have that concept, and Rust does not.</p>
<p>But this isn't the end of the story. The crucial part of the <code>AttributeGetter</code> interface was that you could pass in any method or closure for the attribute getter, and the <code>AttributeGetter::new</code> method handled all the type-conversions transparently. This hid the messy, error-prone details from the user and kept the interface clean.</p>
<p>So let's do the same for <code>InstanceMethod</code>!</p>
<pre><code>impl InstanceMethod {
    pub fn new&lt;T, F, ???&gt;(f: F) -&gt; Self
    where
        F: Fn(&amp;T, ???)
        F::Result: ToPolarResult,
        T: 'static,
    {
        Self(Arc::new(
            move |receiver: &amp;Instance, args: Vec&lt;PolarValue&gt;| {
                let receiver = receiver
                    .downcast()
                    .map_err(|e| e.invariant().into());
                // ermm.... what next?
            },
        ))
    }
}
</code></pre>

<p>We've hit our first problem.</p>
<p>The input to an attribute getter never accepted any arguments, and we only needed it to work for all <code>Fn(&amp;T)</code>. In order to support <em>multiple arguments</em>, we now need to cover <code>Fn(&amp;T)</code>, <code>Fn(&amp;T, A)</code>, <code>Fn(&amp;T, A, B)</code>, and so on.</p>
<p>The first problem is how to convert <code>A</code>, <code>B</code>, etc. into <code>PolarValue</code>s.</p>
<p>The second problem is that these are all <em>completely distinct traits</em>. There is no trait capturing "functions of arity 2, 3, 4...". –&nbsp;at least not until the feature is available in stable Rust. In the future, this <em>might</em> be represented with the syntax <code>Fn&lt;Args, Output=T&gt;</code>, but right now using this syntax results in:</p>
<pre><code>error[E0658]: the precise format of `Fn`-family traits' type parameters is subject to change
 --&gt; src/main.rs:2:14
  |
2 |     where F: Fn&lt;(u32,), Output=u32&gt; {
  |              ^^^^^^^^^^^^^^^^^^^^^^ help: use parenthetical notation instead: `Fn(u32) -&gt; u32`
  |
  = note: see issue #29625 &lt;https://github.com/rust-lang/rust/issues/29625&gt; for more information
</code></pre>

<p>We could opt to use Rust nightly to get these features, but it's not a huge stretch to implement them ourselves.</p>
<h3>Implementing our own <code>Method</code> trait</h3>
<p>This is where as the writer it's tempting to unveil my newly-created trait, perfectly matching what we needed, and make it look like I just put fingers to keyboard to get to the definition.</p>
<p>In reality, we spent a sizeable chunk of our engineering effort for this project on this one trait. We made mistakes. We wrote code that we threw out. And a lot of that is because we didn't understand some of the nuances of Rust functions and the trait resolution system. Instead of papering over all of that, we thought it would be more interesting to show you what we tried. </p>
<p><strong>Attempt #1</strong></p>
<p>The first thing we tried was, in hindsight, a little greedy. Why not just skip straight to writing a trait to encapsulate precisely what we need?</p>
<pre><code>pub trait Method {
   fn invoke(&amp;self, receiver: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue;
}
</code></pre>

<p>This looks great, let's try implementing it for one of our <code>Fn</code> variants:</p>
<pre><code>impl&lt;F, T, R&gt; Method for F
where
   F: Fn(&amp;T) -&gt; R,
   T: 'static,
   R: ToPolarValue,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;T&gt;().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Results in:</p>
<pre><code>impl&lt;F, T, R&gt; Method for F
        ^ unconstrained type parameter
the type parameter `T` is not constrained by the impl trait, self type, or predicates

impl&lt;F, T, R&gt; Method for F
           ^ unconstrained type parameter
the type parameter `R` is not constrained by the impl trait, self type, or predicates
</code></pre>

<p>It's likely that most people have hit some variation of this error in their Rust adventures! What is going on here? <code>T</code> and <code>R</code> <em>look</em> pretty constrained to me? They are right there inside the definition of <code>F: Fn(&amp;T) -&gt; R</code>. </p>
<p>Our mistake was reading those trait bounds as: <code>F</code> is a function from <code>&amp;T</code> to <code>R</code>, whereas in reality this is a regular old trait bound with slightly different syntax for the trait itself. And one function might implement multiple of these trait bounds.</p>
<p>E.g.</p>
<pre><code>// do nothing
fn ident&lt;T&gt;(t: T) -&gt; T { t }

let _ = &amp;ident as &amp;dyn Fn(u32) -&gt; u32;
let _ = &amp;ident as &amp;dyn Fn(String) -&gt; String;
</code></pre>

<p>So which trait should we use for the implementation of <code>Method</code> for <code>ident</code>?</p>
<p>Here's another way of looking at this problem. Suppose instead we decided to exhaustively implement our <code>Method</code> trait for all types we care about:</p>
<pre><code>impl&lt;F&gt; Method for F
where
   F: Fn(&amp;u32) -&gt; u32,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;u32&gt;().unwrap();
        self(receiver).to_polar()
    }
}

impl&lt;F&gt; Method for F
where
   F: Fn(&amp;String) -&gt; String,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;String&gt;().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Ignoring for now just how bad an idea this is, it doesn't even work! We get:</p>
<pre><code>conflicting implementations of trait `Method`:
</code></pre>

<p>Look back to <code>ident</code>. That one function implements both <code>Fn(String) -&gt; String</code> and <code>Fn(u32) -&gt; u32</code> traits. Similarly, in the above case, a function that implements both <code>Fn(&amp;String) -&gt; String</code> and <code>Fn(&amp;u32) -&gt; u32</code> would have two possible implementations for <code>Method</code>. So we get conflicting implementations.  </p>
<p><em>Actually</em>, it goes even further than that. Implementing a blanket trait implementation over <em>any</em> two function trait bounds results in conflicting implementations. Even though such a function couldn't exist:</p>
<pre><code>trait Test {}

impl&lt;F: Fn()&gt; Test for F { }
impl&lt;F: Fn(String) -&gt; String&gt; Test for F { }
</code></pre>

<p>Results in:</p>
<pre><code>error[E0119]: conflicting implementations of trait `Test`:
  |
4 | impl&lt;F: Fn()&gt; Test for F { }
  | ------------------------ first implementation here
5 | impl&lt;F: Fn(String) -&gt; String&gt; Test for F { }
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ conflicting implementation
</code></pre>

<p>One day (or today, if you're on Rust nightly), Rust might let you implement <code>Fn</code> for your own types, support variadic functions (what do you mean Rust already supports <a href="https://doc.rust-lang.org/nomicon/ffi.html#variadic-functions">variadic functions</a>?), and do all kinds of fun things of the sort. But for now we're not going to get much farther with this approach.</p>
<p><strong>Attempt #2</strong></p>
<p>This <code>Method</code> trait looks too convenient to throw away entirely at the first sign of complication. Let's try something different. If our original mistake was thinking of <code>Fn</code> as a function instead of a trait, perhaps we can heed the wisdom of the Rust docs and use <code>fn</code> instead.</p>
<p><img alt="Building%20a%20runtime%20reflection%20system%20for%20Rust%20(Par%20e9d46e4c771847e7ba119df92cf2a8b9/Untitled.png" src="https://images.osohq.com/runtime-reflection-pt-3/Building%20a%20runtime%20reflection%20system%20for%20Rust%20%28Par%20e9d46e4c771847e7ba119df92cf2a8b9/Untitled.png"></p>
<p>Based on the docs, we can use <code>fn</code> with both regular functions and closures! Great, let's do just that:</p>
<pre><code>impl&lt;T, R&gt; Method for fn(&amp;T) -&gt; R
where
    T: 'static,
    R: ToPolarValue,
{
     fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Works fine! Let's try it out:</p>
<pre><code>let clone = |receiver: &amp;String| -&gt; String { receiver.clone() };
let clone_method: Box&lt;dyn Method&gt; = Box::new(clone);
let …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.osohq.com/post/runtime-reflection-pt-3">https://www.osohq.com/post/runtime-reflection-pt-3</a></em></p>]]>
            </description>
            <link>https://www.osohq.com/post/runtime-reflection-pt-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25704707</guid>
            <pubDate>Sat, 09 Jan 2021 21:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chess Fundamentals, by Jose Raul Capablanca]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25704484">thread link</a>) | @sharjeelsayed
<br/>
January 9, 2021 | https://madnessserial.com/mdash/chess-fundamentals-jose-raul-capablanca | <a href="https://web.archive.org/web/*/https://madnessserial.com/mdash/chess-fundamentals-jose-raul-capablanca">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://madnessserial.com/mdash/chess-fundamentals-jose-raul-capablanca</link>
            <guid isPermaLink="false">hacker-news-small-sites-25704484</guid>
            <pubDate>Sat, 09 Jan 2021 20:39:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reversing Qcrack.exe]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25704432">thread link</a>) | @fabiensanglard
<br/>
January 9, 2021 | http://rmolina.co/p/qcrack.html | <a href="https://web.archive.org/web/*/http://rmolina.co/p/qcrack.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://rmolina.co/p/qcrack.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25704432</guid>
            <pubDate>Sat, 09 Jan 2021 20:34:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic Flashlight Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25704336">thread link</a>) | @Tomte
<br/>
January 9, 2021 | http://www.asos1.com/flashlight/flashlight01.htm | <a href="https://web.archive.org/web/*/http://www.asos1.com/flashlight/flashlight01.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.asos1.com/flashlight/flashlight01.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25704336</guid>
            <pubDate>Sat, 09 Jan 2021 20:24:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assemblers and Loaders (1993) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25703581">thread link</a>) | @Tomte
<br/>
January 9, 2021 | http://www.davidsalomon.name/assem.advertis/asl.pdf | <a href="https://web.archive.org/web/*/http://www.davidsalomon.name/assem.advertis/asl.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div endstream="" endobj="" obj="" type="" page="" parent="" r="" resources="" contents="" mediabox="" cropbox="" rotate="">&gt; 
endobj
8 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F1 67 0 R /F5 77 0 R /F9 26 0 R /F10 27 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 83 0 R &gt;&gt; 
&gt;&gt; 
endobj
9 0 obj
&lt;&lt; /Length 1140 /Filter /FlateDecode &gt;&gt; 
stream
H‰´WmoÛ6*É¶`[­,'¶ÛØÑ`¯¥´Š)ê-èÞ²­öuþV÷SÑ°X‹íïï(Še;ž7&nbsp;àPï¹»çž;]n·ãøeåûn\â*Ï™ŸÀOs$4ÇI’d~ARÌŠ"ó·¿�ÿý8þùWâ¿ÿçíþñ÷øúëîî.ˆÜG?üñáÓÛŸ&gt;¯·¿&gt;ø€Ò¼ÆoŽ„e¸¢Yéçe�Ó<aÿzõ×ýeeÃ8Ž¤n8ˆÒ2Å)"Ñ…<Úx¤�à™"o—�Ì†jzâ™«e@dýˆ`våÅ�5üf‚?joøçµ„dîÜñäÃ ÿÓÓ©11¼i\�°y×¸t�öm="" {qÉÍ$ÆÄq¯k�—Ç'¾¥hÈ¯l.¹'žÜµ†¾ªÑ·a«¨ð¹i&È¨ÿú[:éÀ•¸¸×sÌ="" [†¦ÞdÄ+mÂÕ="Ä™KiLfÃ¡ë`™�·C2’+&nbsp;kÛy€ÜcšÝÔ" þùxå3q`Î–~Üéµd½âuÊs0þ‚ß›olÍm|¤@¦ÙvèÀx¢®="" ³phu£mkqÂ~q`¿Ìd="" &ËhÝò¬z,Ëè="" fe¬Ásnq†.”urwŽ½Ï_:3!ÃŸ¶câßùcÊ€!"prŸÒç,õœv¥ÿçÛñ»ñíöt3²¼Ä%au'Èalg)ÃŒp:‹Š6Œ†-�jjñz¹”õ‹¸Ãg\òš¸€”xteÒÕv¨u¼û6="" ´�1¾;="" åŽ5u…gÎ„iÝ±Ñ!v="" bªÆÂÕ÷ÿ…µÐ!ÂÏ$m+<�68;cÙ¡rv‹rž2Àå´l¦ós©Ìga‚×ó&efßéÍ„.zžyÁg�e—3Ó¨¿Ä-‚úât7‚³'%l«="" Ójø‚ @Œy^ýõêÁbžÖ}ê�[Ê¾2vÁåÚlwzÏÖvt§h`Ûü«¡l#yyg{ÕxÖauÀaëây4="" Á]Üö´*¬[Åðëíx¡½x›šk³{¯×ÞÍx»×ëÞs2.e9à©½ˆ´ÛÇ§|Ü†¡†¼lsët¬~ù¸‡|Ñ#lû0*ÊÃvošò6º©j²Ôñlû<ÿ�²éð¦nÝ¬Žh"="">£Sc½S”ó:•V9´MQ‰N}&amp;;u&gt;ì�LCµ©†jóËüW^aÒ´ZõŸZM÷�†÷µš¥½(Ž•æÉµoQÏ½ÞWË&amp;&gt;öÂ°´ÆÈ®W¿ÙD_»&nbsp;xáµ†³ZýRcúÌ˜î‚“¦Ýtµ·ê5‹n"8c@eZcu¤Œ ãÓÐ´zýîF¾2yKù”*»1!C[ù+‹¥ˆ'*pÁÀ×7¡žZ�3äî‚–†"ØH=-½…iêé©–¸ÁCwjÌ1Š(e·Ðí,å¶›MŠRØŸ¡æ“z‰É4ûžn¿nÃ9j½L‘ïÍ&amp;à—w¢fºÒMÕNÿP£‹3˜¹Ü1Ö
CÝ°Ýiïõlbhïv©‡fKŸ»â™ÓL$µ§Ø…¹‘­ö�“¢_w
endstream
endobj
10 0 obj
&lt;&lt; 
/Type /Page 
/Parent 105 0 R 
/Resources 11 0 R 
/Contents 12 0 R 
/MediaBox [ 0 0 612 792 ] 
/CropBox [ 0 0 612 792 ] 
/Rotate 0 
&gt;&gt; 
endobj
11 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F1 67 0 R /F5 77 0 R /F9 26 0 R /F12 28 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 83 0 R &gt;&gt; 
&gt;&gt; 
endobj
12 0 obj
&lt;&lt; /Length 1352 /Filter /FlateDecode &gt;&gt; 
stream
H‰œWmoÛ6"Y± [±$'¶ÛFVë`&nbsp;Œ™–H‰’:Ûú
ìëü­Ù§¡-:`°Ø~þø"R¤l%m ¡ÝswÏ=w<!--?;L÷¯š$Oï¦5l)’Œþ´Ç#˜×NªÃ¢ªÊäð×4KÞO÷¯Ë“÷Ÿèùðûõïô
xþ÷ÇÏo?~þ”îrTU°þK?üJñs�ßPPD8~{Ì�Y–•	©+ˆIV0ü7`tnÛé®¬

RGéçô…nè3ú©ÆëÛ,G¾KýÕ¨†¬V×Üa–ìrX4y•^´•DÏ¥ý÷ÏmyÖkŸA¹®|2v]öÀK¹ç	=—Ü×CåUsjs§‡­påHW	{¯´Øï—,¸ŸÐŠæ­/‚ùZðÈ§ÉL�³÷–¡Ì­¢nbî±Ü�JÌ9WDKÔQekÑnÛš”¢&9M°,/Š<wUÁ¬æUße0Ã9¥¾Ô+A°ÔKU‚£ÈJì¹øè�ÚÇÞ¥-NO<^F&¶åŠGQd_2†spµ°­ˆöò0Í“ÉW–XD�'Tˆà$ƒ¸©“ÞNßMŸîÒUAjjV4F\¦”�›ôðçt‡XäŒÌªÆXð¹éÈ¼¼bÊ²ÖÒ�Üè„²hE°dt‚;µ M+ÒøE1Î‹—]!�ë£BRÇC®7×g›½üðƒþt#?x,º™/ûd)¤ùî‘O®QæLõ‹MâD³V—R+ŽmZ9§¬xá©¢ç·©fé˜–ñ)K7ZøK=W57ž€È÷‚PK¤¼=¼¶|ÑVÉJÂù†Ød…ÎfíTÐXaö±i?:eï1}èF¢ív¨MD~uºìuÄ|—j6`p™6%¬ÁÂŸÈyx<¬ŽåW€­aO„Û"\u"Ìg­N¤0X‰È ³Å_Â…¯s]S7{�«•–­
J/¾’°æOü'˜hñ°:·#Ó‰’éxFT=ÖR"=^x³‡®õcO¬={%Ö'"ÈÈÀ¨
|5§yš"i~œ/Û¼ÅpÕdXÊŒÖzqµª®ƒ0Ð2Ù˜‘(uãˆ»(\‹¯¨ESŠ¿rnL‹ý0ÁG’ì™ŽN+±á¡ñXVHæ¤hìám†C¹»Aãk³W*©Oçt„?¥tß`Òü,7$®zo”»8Ä™•"D-ìû‹€cî'V¤iäËCm%µ-Ãl`†èb¤7’sO#™1X“Ú}Yˆ§ûN£0Ï ÁUÓNuáS®-->!Õ�å	)…3^\NptLã6pºj&nbsp;oh[ÆßJâq¸˜ÝÊ)6¸þ
V*ùê=ÚNwV…7yé.½U¨´cÇL]uÙXmŽb¤÷Ç1ÊñlÁÒš³ÂÈ½RýrßÜW¹:'f|ÜI³PÃi!­u¦¶zÎq'¤n{ÆwÒxØVI%ç:H=&gt;4yjº ö¦•¢e×»‰{Ë_Bž|Ð»ú�ªÂOu•H�Þ½&amp;Ó/G¢K**è¡Î[2Ámj�lËvÏíˆ)šî³(+!bü-úrY3í}Ã.k¸YÅ7¢a¾d�G¨„Y^ ñíêBíî“‰eGtQ¼á9ÝÃµ-]­ãˆÐšaPÞhíL’óð›¯_¬¶ñÐ&gt;îÚÌEqB¿“ê’-©]¡¶±ñ•�HŒU'žÀ›iúnw]ö
¦í(ãŽÖ4°ÝõÏXß‘ÌnUŠºû–ÜjŠ‘�–È�hsL!ÓÁ¬‚¦g³ù¶#ÓÃÀ­Ùx¼×Vv�‘ˆZÛXTÜ=Ô�™ÕÌ¹ÝÙ=$l¤¸þ`©¿é/
endstream
endobj
13 0 obj
&lt;&lt; 
/Type /Page 
/Parent 104 0 R 
/Resources 14 0 R 
/Contents 15 0 R 
/MediaBox [ 0 0 612 792 ] 
/CropBox [ 0 0 612 792 ] 
/Rotate 0 
&gt;&gt; 
endobj
14 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F1 67 0 R /F5 77 0 R /F9 26 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 83 0 R &gt;&gt; 
&gt;&gt; 
endobj
15 0 obj
&lt;&lt; /Length 742 /Filter /FlateDecode &gt;&gt; 
stream
H‰œ•]OÛ0†/h£’²$-M'X-�„Ó­nì8±ƒvÅ&gt;�v»ÜÁ®&amp;@›4&amp;
¤íçïØŽÓ´k�N•"×±Ÿ÷ø=&gt;'ç•?ÿX"Šª_’²(8JáW)+Hš¦94#\ˆU?üÝúó‹ÏÝÞÃ¸úª¿ýKü'™QXŒßý¼{¸¾{¸O¾TŸN
¼"+4¼Rž“’åR�¬H¹‚_ângÜ™&amp;³\pRâáÁUJY2ËdF2\&amp;N_MÄ¡™b¸Áˆá‰YF%“DàñôD‹§hF	CÕû;·X&gt;‚õyè¨§Ú™'#«¡š2pŽ£¾UŽ/´ÈÄN9í`¬ðüHWÓZqÇ*î‡ú$
0˜LôfÏsWÉºÓx›©Ç–z¡™‘…Â1pp•,&lt;ãIaíŠE«ÌËÌF}ÙÀxZÀf	Ÿá³å„d2w—ÕÜ#+Wö^(Ë�ØiÛíË%ãŸ©àZ…n�zÊ�ô \à×zS¬a�-‹†A¬P§
"IqŒžiw#Ù«„ŽºŒ¸íñV¯¬†A&amp;Ž¶.Þ¦‚™�W0Ó'0ÿ”âÚ¼kÈMvGa´ÀÅšÖ³7‡çg¿:ý,SŒæŒ©úÏmý7îËÀkÛ»rBo“+�³ou4zq°h5¨ôOÛˆi±ìª¹×/m�#]ö¡
¼–;uÍM¥p_óœéFjÇM›æ%„¦“‚ZÁHŽCwº»çvúÃÝˆ‰Êúµ
|¨J:Ãº
v�Hk}¨|Š¾!ŸIU(¨ø(¤JIVJôëÚ¿ñÏ«Çú;/$‘”—KQÁ�Ž“ê»?Ë8áTåGšüÈŽ»½9;GÛ˜SÀMK©ñæ�õfß‹fÆuüÚ�Hý“©ëtú‘ÛXÃðJM£Qøv	Éµ+åv®,Â�ƒ¸Ê”ÇÏíX°<c¾›¬�lïìz{p«°w% boõû1)="" Ï‹ÿÉw[`|ìÖø¿="" �¤z="" endstream="" endobj="" 16="" 0="" obj="" <<="" type="" page="" parent="" 104="" r="" resources="" 17="" contents="" 18="" mediabox="" [="" 612="" 792="" ]="" cropbox="" rotate="">&gt; 
endobj
17 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F3 79 0 R /F10 27 0 R /F14 29 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 83 0 R &gt;&gt; 
&gt;&gt; 
endobj
18 0 obj
&lt;&lt; /Length 1840 /Filter /FlateDecode &gt;&gt; 
stream
H‰„ËnÛF¨´2	J!—¶˜Ô�ˆnÚ„Jk†\&gt;D^‹&gt;€^«[ÜSÑ-ÐK{èïw;Ë¥"76`ÏÎÎÌÎ{†ß7ï~hò:?~Ø4]9ô]—Wð+pmú²ªª.ïú¶lÇÁäÇ¿6UþûæÝ�?×ùïÿ|üÿü»)‚põXÕ&amp;Z¯öÇ?7ß7uþG¾©MWŽ‡¼ëÀŸ×U_vð¿*Ç±Ïÿþmóaó-ªP·¬ÃXŽ½éIÖ-ð›nÈ›±+ûÊt¨Áûâ³ÅþÁ@S,Õê"ùeÀ�Up÷ìàCy&nbsp;CŒ·DKüËT‰F¦.åÓ¥^î�~(®øî«BYp;1!¤ãlÁ§ç/&gt;¿NoÊ¾¸%ºˆ¯6kÂÄwþ{‰òG’�MY™Žîö¿Ú&lt;˜ü¡.Á»ßmª²5èÏ÷Å:ÐkQ±¯JSÜ²ŠbR'ø�Æ×X-@4E„··ù}(¼OåÀ‘„�š	Š”ÐØ§T”íÄª�ÌÕž¼f
ãÂXY÷'Á’b£"'B	ƒ‹\§ä…ã[N¥÷…Ž¤}*Ž/ãôJÔI«Xë-ëB§)Þ®Ø„ËÌY€¬àrñë†¾HýdÁ1¯–:w
HÇäºD A÷_~&amp;àW×¯¯–ÇïœEeßŒl•S¥�„©}Uò7»Ð»3ÅE¬Ö±^­Änæ`Ó¡yÊLGÙ=[f’˜—{gæ¿ðÈN¶Ê\n™šYuJ®'w&lt;î=›:3°Q�Bû‡¶2Àº’lÂã“%’+-ÀbÊaƒk[ƒ©p/&lt;¯"r¼=¥a�Hí&amp;"á-†¥-TÆ:Ê¿V,ðv²J÷¥W)îë©…Ê,«GìÔý†KJÎ·xÏÈuzw’°gBõÖt]±Õ@P–J|ìÕJ@Æ�’
Ekƒ|÷ÂåÛ²à»‡€‚b;V¶RrVºüØ®Øz�É$‘QTÆ�ï€�Ï
¼·³Wd4±ë0ˆ'IÃI˜™
¸&lt;Ô
ûä%\’ßcÍ/
©/CAL‰!Ó‹-¡�Š9¬G1”0ŒM:"¦¶+¾Ø
V‹Š\bcKW�5kÿ¬vB{Ö`¾¢z"CCÐÂ+ƒ¦fcO¢d3Œ†Ù”Z#çƒn,Ø1%øK¯Ù™bÓ0f�ôwÐÙŽ�º¤�¨„È{Í]=ÍK.Cx&gt;:ŽwÏoª›úæó×æ´=K2°y¸t:`[båÙR¦Q‘•ÌÇ«H±Ý·‘ðaÐù’z;Ì÷ÎŽ¦!µÓ%yÁGî¹x)”B�¦î�­¯ô	!ƒÍEæ)×PBXh¶Eh¯§·öòÅ4Þ†'æŽ¡y4F/ö–&amp;�^&lt;Þ&lt;1ºH´7/E™ð,”„QÖ'êjz‡BÕˆZXRAL�4ó”�G
o¥"BÓ€·.ƒ�ÁÖºqÁGpQ”98ÔÙ•ÀZâ£€eÃ’Wñ’Wwe?°ãÁºSØÙŽ;ã´š²éŒaŠ÷Oæ5+”(§f¤Â“÷çÞ‡M«­öýpœ¾]¹—OŒM”@T‡¹ÝÝÆ²ê†7¸Ã8ÌÙF’m#(AAÐ©Š1pcP¨=ÒØ
íòŠÑ3¬	4z¬Á~OÔJGnÆ1f6nÓf«•è4Õ±RŸ”»ç/ºëé5ufGí¤Ë;1ðÍÐMbàÔƒ˜¯®Óæ©B`opÇ¾$2DDõ±¤vJ~Í{ïU{í¥s¦.VþJ#t2Üè0Û#É„‰íž&lt;}W·v“ûÔzßt=öT°)ã†iv"Á4ˆ{$žæx+A&nbsp;Ë33=ÝêÄß~Ù~‘p¾p&amp;çÑ:!¸àØ×v'ýàS·¦›/×)ãjQMƒ^ê«IáH°—Ó~Fg?›Y¾–+o=¦±ÉR•@TCkX%ÝÕV†9Š¡t¡LM'tí

JöÛóÙ‹ÕußO›acð#ÐEN¶ìÓ §kž#íyÝv'A$âÉÞGt	=%„N¦À2kâ-^)ð¶ˆÒª299h«÷1ÇÛAªb×p5|xqÅ`S„rïnä°Ôl’»ÕØè&lt;òw–_£ÄÇ:oí–æämGàéEŸÛ±±}xä&gt;|ÉRgä“®-Hhív×w*‘?'øf‹Pœ,¥B&nbsp;¥B;j$D¡9`î½T	õ,ƒ�¨hy%t¤.5ø™Ùæ¼)7‡fö¥IiZ÷öïå¬æšZ–&nbsp;•óÐìK	ìÚÆ‰Eó�O(˜¨#o\	“ð &amp;tF‹="3­�B”áDàwÇM8BYhÍÁ§ø5…otÓyÞJ]˜Ž~SÅ3N¶×ä–ªr}!öôìd{Ð¡Xæ£è³\Ídç¢/$4¨]mYóPfN!«*Þ¸¬F³ˆs{×Í#�ÄT&amp;ÖS³PâUËAaª3_|Añ^“ÌeÈMå€ºÆïŒ½HuŸeÂ‘ª]è
¡ƒçÀFVö§FóX„¢\ºHé½•³äê‰ñýqóŸ2u�Å
endstream
endobj
19 0 obj
&lt;&lt; 
/Type /Page 
/Parent 104 0 R 
/Resources 20 0 R 
/Contents 21 0 R 
/MediaBox [ 0 0 612 792 ] 
/CropBox [ 0 0 612 792 ] 
/Rotate 0 
&gt;&gt; 
endobj
20 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F9 26 0 R /F14 29 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 83 0 R &gt;&gt; 
&gt;&gt; 
endobj
21 0 obj
&lt;&lt; /Length 3116 /Filter /FlateDecode &gt;&gt; 
stream
H‰|WK�#¹
ÖUvÊ3e©Ç5™îž±‹ì$í©÷#¯M6Aä }›É!Xì.ö�KrH~~¤�¤¤òcÑ€»DQI‘Éo^^}üó´¯ö/ß¿OSß·ûÒüñgU÷§²,»ýP5§vºýË¿^•û^}üËß«ýÿ1ß/ßÚŸÿ¾útøß�?Ÿ+Ã~øÛ¿¿ûþØ”§úðÏo¿;þãå¯æŽª¥K&amp;#¹îq	ºKúq85}Ùâ’SÛô	ÞÅùñ¹)G#oŸëá46ŸËªË3¢7‡(^®’4-¼fUgQ‘€Uˆ*s_ZÛ�åòî
Þ÷Û÷5-—B°Žr{Ñôì¥ÝF&nbsp;�È·ûcex¦ÃäÄç¸Ì:¨Ü?W§zÿò'ñfJw.VVH¤
s¦iÈªîµZ®&nbsp;‹Þãpm÷]3àü©­’q²&lt;;(m²gŽÏ†áð±ûÕW5}ZQµN±8U‡tnòƒÝÿõûéž¾nùƒæI–Áä5q'½’ì�¿ùíû§Œ65KÝ-f?ÞÁšçÚûâÔ—zXniÆñÔâ;CH{0âÊvØåB¸ØÙ¼ZK ¹€’�¹ƒÝ;új$§ IþUßp@ÝÐB…|êT¥.^~.a`ïm«ÉHL92Ûº4RRkf[�ºbF¤REwÓ¹éö›9éV¥"_'«•ø$OåôREyÌÜ*Û9Šñ¶x¿:Îlx^¿mqã´½3ëÔWõøÓáÙŒ“qÈÇîá]-Uè˜¾»‹¼1œ½ñ�b¬6³gÐá‘›É�]¨ô;û¥¢…<a Ç1™:#l9kÛ¶nÈrƒtþ!íj’‹¾á`b²¹"ä›§g«Ê‹…°n÷z?&9ù“ k…w•»="" �¦:ÎõƒÝ´oóÖ©r,úú�Óýëé]¨²3x¨y|°v†é�9r="" ‹�zzƒð`Ð‘<rp±ÊÎµã!ñ‚Æ3±i®Â="" Ü3dpf:Á:^m="" ãlsfis;a°ë1Úg¥"ÞÇ®;õ{\Ú5�m'*z}É:ëpïÖkô½="" ka_z¨èlb%zj–@)Ø‘Ù�úÃ˜,xÓ×y›{×¹z.]¤c›Çm,Ÿ™�¿{tƒ@+x="" �öµèÐ4(º¡¿…*Ñj-Ù—§*="" 6çæo’üj-ë="" ÿ»ªc´p•¹³µf§‰â·'r}xy+\�„‚0ndÏ="" =�qôíqlë^ÿbmtñh=""  ÄÛ”9¸á¬hu™œâçtåá¼ðqœi´�?#kgk?•ví6ŽînÔy;ð“¯¿="" ÆÖ,“tø(ŠíÙœä$Ú©æœj8ëcçks×îd®2½rç�d{Æwq�˜ý0Îñ£i«yÔúÍ¿êpù,¹z‡="" ³ÃbÜª|c="" vf]©="`Hg—" ×~p�¢ÓhÀäcíá="" ,�="À&quot;" –Ætåósr§{½*Âl="" Šx="" Å‚ÞÈ~lí¤;,�Ò$o^="" Å›a�^g]é&9ï,kÝ´6d8¢]ÿôfv‚lrÜ»<^Ê·Â«‹þ–èwÒ"Ø“%›d÷2~c¶p="" ™çv7Ég#¶y¸èaÇ©£—\*)jª0)ÒÕate¦Ëéåz»pia;¸–è¦Ê*fr…@vyik¹i!mžyú3t%–ÿËÈñ_wm*['”¦ÿ¦(vaÝË®÷�ŠÕ´kÌ‹¦Õ“È)g="" í[Øµ_a]}#¯^gb#="" �Õ„Úëe="" ËyüÎ¾u¡!="" 4|oéyÍÖ:y²þu�®�"†¿98{{¥ƒl="" dÛ*-Ÿ:^†Üo²˜÷šmÖ~“¬="" ¶ùŒj»Ð�¶çqhÂ«kÛp{z�–õt±ip©:kbú&†d‘="" &="">
á–k­ºz<!--¤Dy<ò¨ðÆô]vx´'`ì8j©�%¸
ÌúÕN\–n��U?±�P¦³.YÒ}øÆ�æ+€Ða}0ÅUê©ã�gº
X�ÚV`Ià�Ärãh³Þ¾ECý‹gâ|œì‚ä0	ÇY[4�ÓsÍM+hƒ\°¼¯’÷%`O6Ê[ÃžÈ4Ðr�ŒŽF¦�*dµ”:ôÇËP‹ê¢V®�õL�|¶*8Lf½‘]Óñ’Ñz4JmÔýAR­)íÌµve‡ÿoh§§”½6Lâuãæs�«ÎP”„Ürdœ¹Âœ¹8þÑ†BSµ&-->ÞñW{øÊÑÞVŽX¾;ïJð¡W÷þó­ÿ,ýgç?ƒc?{�òþöþm}¥�‹ùÔÌ’X(„røÜ¸UœÐ
D&lt;=±©äÃ¥Íg?Á¥V­ÒTSÏ†wz”ÕÂwo*wªuÌ+j¡lóL[KWi­ÓdVí7TÎÃÞEUo§‘ƒÏ3ã$·¦I¯l[t'æ&nbsp;&amp;}´Ò‰
èÄ@‘N|×;1ðIþbá;1,ö…‰{0Eá±§Ùù¨H6áî- çÝlso3D*ß Ú…éR
ÈÛ­TK°&gt;9"Í÷¶NRg|ñÁÏ!ùBNhW÷©ÉQélñ~’ã4ºPÊ6Ü(‘?ÔÒ»ÁPÄ+yEb€)²&nbsp;v_†M¸n¢;c¸0Ðº
‡©&lt;äS™p&nbsp;À":j’„M'!Ðs-È=±{}¬ÄÖ:—R�	éÌ×|ÁÒ=‰¤ƒÕªþ'Q{v€}5�¾üdq²¶L•±|I!ýQud@Å'&lt;Vj9äÝP"ÓØ&gt;=m¯T½î|ìÎ»ZºNLúuVçoÕéYRàÈ“|ð;aÌÅñ4(Är—èE°;Ï)@1W[ó«!¿Ìª»bÈô¤ø4Z/©QcöQjãfèK’MiJ½ÂÂ7yã/™lìâÄ_"ˆÇ/váU|&nbsp;PÁz‡Ä·×ÄL˜š‡Ö±­¾&gt;·-O&gt;a¡&nbsp;jã
»­è2UÎ”wkÎ
1­)rÀ¯„væVSõe&nbsp;�)‰Câ\7Ôú)6“ñéÃñæàê²”otB$G&gt;.gÝyQPIÈC®²6eË£ /4¬ÅB¶”�MÇ¿#l&nbsp;—Av�åòbt¥+ØE^:t¤“Üè´ßÜ¼!»—7:ÅKXP;þþ²höfæõ8�^ý¹­&amp;™SÚ²&amp;Û»Ë†NÖÄ-í§iÇ„[v|¡Í`²ƒÜ/d¸
0r^[œ$&amp;²¸DŸw�.ro¢ÙoÄ¢øúÎ&gt;k–¬ÞŸƒÄ•©ø6T´Ýë”–n¼&nbsp;…¦Ð^Úš~D5OŸËþü!$Î×
½Ê×AV3;bSN•IÕte¯8¯›WÆq«VrwÛõÆ?oéƒ"EŽÈcöò&amp;‘ÞÛòõ.åèTŒYâý
j…ñÊxJá?g»ÚáØÇîÜ”éoç.?�åOT·ì›iL,±N«M÷ÅTkV©nL÷…w¨îÙÏ;ô@ïå(|æÔ”p&amp;G*U¤:Ž©ÆõRãˆú%
�ˆ¡&amp;GG(ÂwTjÿž7†O:ôÜ‡:¼f£&amp;ÅÐçàÜ wçÀ‰=Ô&nbsp;ððe!˜ß()�+±—°Yâ$
b¢8lYlî_¢í§Ã�í‰Ú�æIZe‰\`j.ˆËó¤�¨#Bª�Ë×»Ò‰0Âå¡p¼þõp™±;�Á�0¹
dyxjòŠè%Y[ÞÎ?Oã¡¢�‰;‚"²1-›Kwæ…b9…˜ýü@Ž¿�ÇÅ,³©d…’— GT±åS¥èlG»†�QLÜì1+$CÙº:rõ‰$8öÔžkÆƒóãuk$!˜G†*ƒÁr×—ÊDÈŒ~ž&nbsp;uè&lt;eBÌ†?¯nZ®&gt;œ
4Zu��2¤ÁÁð‰VÐþ&lt;ÌúßÚDqQx{%eê&nbsp;iùiŸ\é–ž“Ï2¡þŸíj×a†�CS$†
�Ä\ºt/Ð?àÿ¿…Ø—‹\7[lC”øq¹3ñô~i·Gu‹rÚv
ƒÝàê60»{˜Åla&nbsp;C/¥«¦Ý=ûcnÐM´M€*œ[Ãœð�«Î�[•A-‡"‹òW¥[ãò1íš²?Q”åß(Ãÿž˜Ømøý!
¼<iðÂ°r½Äx•¡Èjq-ãã1c�à\Ùk8ùcãn †ÇtŒŠ•t|ÏÇ%À�Ïc‰x="" endstream="" endobj="" 22="" 0="" obj="" <<="" type="" page="" parent="" 104="" r="" resources="" 23="" contents="" 24="" mediabox="" [="" 612="" 792="" ]="" cropbox="" rotate="">&gt; 
endobj
23 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F1 67 0 R /F7 25 0 R /F9 26 0 R /F14 29 0 R /F16 30 0 R /F18 31 0 R 
/T1 32 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 83 0 R &gt;&gt; 
&gt;&gt; 
endobj
24 0 obj
&lt;&lt; /Length 2845 /Filter /FlateDecode &gt;&gt; 
stream
H‰|WÝ�Ü¶²’V‚öN"ïViì³w
»9mŠ[ë‹Ò
ÐÔpœ¤Oºowy‚8p�¼´íŸßùàPÔÞžax�GÃáof~|w¼xûaÜÖÛãÇ‹Ã~ìûn[Á?;ìÚvß™Ál‡Ž\TÛß/ÞþðÏzûû`|üþ{q_þãß¿}ÜµUùË¯¿íîêf8”ÿûôéÓîçãßáuÇßÁpÓÓ7ì°nú}UUfÛ†}ÛW~ã¾L²‡ªnà¿Éwwè˜2	yÔ—¸”Eœã:š—»fØh˜-D{¹»éP†ZãÆ«bÚÕ—œ¨$Î|a¸‘Q¤‚,Ô2Si.Ãdío¸ÙÑ~áû¹«Êäd®ýy´$"üIyBÇ~N¡«¶wõ¾Ùß_Tû¡ïŽµÆPtÕ¾f?-Ó€-¬Õ’Œd,oÊ@¥¢¢iÁ‹”è(ëZWÁÐ*¯b4ŸOj5_�–™
ð3M&nbsp;
‘QÀØÈS§S´'L··µdvCÇ&gt;~#°Ò*â¯·UocÓ�ä9ˆê¶½’µõ®’+˜Ïîô…¢¡LÃÄ­†"Â4ðÝÍÈ_g&amp;LEQ Àr{pžÌP¥EJðá¡^¸h\Š=D�(
�l, ‚b´ˆþ5¯P‡mKEÀ6ob|g[ÚÛ |Ÿûò›Ý²¸<q­zûm9`Ãìp„. zº•×Å¤ Ïü="" aœÐžÔbøÎtß ,yË\¼tÚj�œ×bé="" ”inœú="" a¿p ¹k\²ÜŸÙÞŽ(øŠ£—Œ¼ d°¢Û§mˆkr="" è€0´´�–5º¸qð!aòeò­ÙŠ”�õén¶ßhÿ&g¹iŒox´�"ïýoÒÌrgß5Ãhóçpðp="" @Š'àÂà;Êqa•&ž="" åy÷¶ý:Ô|nk6\ru@Ç›±åbg´ÿ="" ëh±�="”Ò‰zqËÚ9€à!Ýýjý¢puŸ®ÔSL?Â“qmRB" Üê="" …vè@ñœË¤e‘:ukÎ¦„©–àßµ3[ªüåÎèbŠ«kÎbÚ§rÎØžôvÃä“­s8@Ù�óû*nnªåil¥dpÂÍÀ(xœÜ!eÀì*sq$qgi39ƒ„ÀºÃÅiëãŒ"[*Ý” �Êd·+¬ÄaŠnË@¸«m·;øiÜøìŸyÐa–w�qòÀïýš×Û²mpµ�®„vmëdsj'$‚usÆ§+8¹gc*e"$ÑÈa€l_)¢="" �Ìc?93õâ´ŒÙ[uõ¡Ï¹Ï#åd©$`w.í"çz|-õ…‡)(6?¡_…eò±ov~ÈÙä•#6lö´¿yor«.-t™¸5œ|ëÉw[fº2_¤="" •`jxÖipû¹€íÊâ7”¿‰†î¼”eÿxŒ­ðÈ="" ª~.€äªÊøº�-�»'9c%‹Ú(Æ®?×¥{Ê‘d'¤Ó“Í="ÝièØgcÓ-ÓhÆ™Œ#9<5µnèDXÊ|óDTY®²Äî8_h·�)ç" úŽégfbÅ¶só4à\+Ë¹¸0k´h¹b3¿Ÿ^yu="" )cÛ÷xzÜn’eÁÂÁ[~d¶hš¬uâÌ±b´z="éqð6Y" ¤’ÙÙ"e.¥ˆæaÏÁb|="">=£;Ã¡ôGêzFQIøàÞ&lt;âå‚‹–±’Z¬gòµ?»’3×²‹H:Êm¥b–Ìóö^#©ð�@¡–û–mg¨–;Ž–‰^f\‹lù&lt;­t{x1v\î\‡‘TX2L-˜KÔâ0bö"$PÑÀ«¨ð)gq'¬’uÔÒï‚)!ãRÞ“„÷ºìK&amp;uv)Çhß•C¹–å3•�”¿Y§2ÿ+4y)ýùÆ'u¦áA—f0DXN€µØ·)—ø18zGÄ%‘æ'
§_°â»˜Ywg™ˆæïB$œ"²:ë–,¤€èÅg
„`VH”¾ÖÞA[s°��³¸ä5™j¤”�|z‡
‚$Î™úP»±»á&amp;‰)ØÉk~‰áP‡Ñ´½sÜUæRèÈö,?üœÒ¢®Ä0;²ðÍ$îXöøšNÈœƒEOÅ`bfÜË{Îb*
«4r‡†&lt;æô¨ˆ¹e*]I&gt;Ð{{4¦ÍŽ¼°Œ®¥ÇV3û~Z½Kk¼¶·ãÜ“Ì²¯�é:ëÖ^§ƒ!!F$tõS/Øi•&nbsp;
ÃÎãs²HÞÒÈo#¢ï/òQA™7Ðë0.Ü§ä–}s¹ãY´A*­¹RAKafÛ„ê¡}êIöÚµ¾ºGL’áÀ‚¥n ÔQH¯»¬×ºHì‘tRb¨Ò™µË;ÜewÓõùÝ�DT¤M.Ž­C s9R7|h ^q�ÀÚ	dm«æ8rƒ|=Ñ«'Š/Ó°Û‰¶¹g‹ÊsîêZPÏò9Òn'wÂM\&lt;~N˜º·Ï‰=é¸"Ìq&amp;Þ0øoAãÒŸü˜`å¼b<jÌšú.ö·‚b&-ÁëôtŠykÑ|ûå×�û gÆìèvwqihëa'kÙtgráüûá="²u¤ÒïÝëì,3&nbsp;•ÂÑ¥é](u�®ÊU\ZÊÎÅS5—6F" ßÊÛc½­·Ç�à(xi?àjïŽÿºxû¡îx±1$�½¼a´—g)k¬Âõv;1“[´¤’Ä="" ‰ö="" Åªzq%p\§Ø¾jÎz]*�pø|‚w¡˜Êd="„N³‘" Ðae{¹v.Û–6µz¿¥�¿¿Çc!®="" r‡sÇ¤j2�¥�‘&ç¶öµei§¹šuù@ï?æØ,#”Ö|ósùÁÙ»8—®Ãª\‰sy¢r¡zó'–myÒ="" cjc³ú`1ty;þÓ®mÊÛë+üóljÛæag7†?×¸¢?ˆ="" µºÚwcpc°uÂ²^ë¥ÇÜ¬ªÁ2gÈŒÀ£Ôr="" ÜÃÏ[Éÿ4ä³Þ0÷]ÉÔÐòŒ&Å’íe®="" ãçæÔ–Õ¹•óøÍöÖ¾Þä<·îjcøl˜Ý05…z@í«6£Ökd(ÿayl!"xô­­`Í…Ñ-|§\qÉt‡…,¸f‰“Óu-}û—é3¶nl°dÍbè+‘@i$="">�tÌï˜‹‹)Œ¿ýÎ|ù
¡½QñX­_Ð=¼ä
@…³D`oàõc|»&nbsp;ûæöÍ›[V|ÿ#
‘ÁÉV±¢vÛˆ¿ðß³iÓ×Ïž=›ˆBß¶=ŸgC9ÙØdF¹$EÓÈËb~bhŠ)•.RºaØ!�ÌI6˜NÆöpjý8háES�	:çKò¬ö9�²]©—4	Â¢˜ZutúÆÈ£J�MA°[üÕ©V�_æiÆX&nbsp;ÖÃU¤½-%“:Å„¦�·ÛŸÂušNíœÔúÝ�êyëÑÐVÜ¹åN]Ë{v#Î¢Y±{�(PL½ó6�­ôBAGBc¡C·§t”d³ŠÍß&nbsp;È;°šï½–&gt;È_&nbsp;¬‡‘�I[[Ç½�Fe#zX./³<u:¿šwk³¯šÆvÐ{yªÈgð¡ó>U™Ë§Ñ%˜Û† o„"Vœ¶)v{Ó»’vï’Ö¶¶%¿+&amp;š8ç)'ŒØË!6ŽîGKé–'kÍgø“kM
Xª‚Rmí°PõUe¶õ«; 5ÀY¾€BÄ(˜Ì&lt;1@ˆîÚNnv‰§By_Š÷ÔešÐ‹•’êRöF——Ig9Ïé`FÉ6m
ÓÉituÅYâÖ³ ŒÙöI§÷ÐWz:‘¶‡Ã¾íáfêC³¯ú¶Á•­EGoq´7�/\¯Ü‡l,Ó˜‘¬ä(ôáï�ÿ`ÖW©#
endstream
endobj
25 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/FirstChar 1 
/LastChar 19 
/Widths [ 525 525 525 525 525 525 525 525 525 525 525 525 525 525 525 525 525 
525 525 ] 
/Encoding 49 0 R 
/BaseFont /CEDOBL+CMTT10 
/FontDescriptor 33 0 R 
/ToUnicode 50 0 R 
&gt;&gt; 
endobj
26 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/Encoding /WinAnsiEncoding 
/BaseFont /Helvetica 
&gt;&gt; 
endobj
27 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/FirstChar 1 
/LastChar 11 
/Widths [ 358 897 511 511 307 307 486 664 511 511 332 ] 
/Encoding 51 0 R 
/BaseFont /CEEBEP+CMTI10 
/FontDescriptor 35 0 R 
/ToUnicode 52 0 R 
&gt;&gt; 
endobj
28 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/FirstChar 1 
/LastChar 6 
/Widths [ 378 989 613 591 602 636 ] 
/Encoding 53 0 R 
/BaseFont /CEECOC+CMCSC10 
/FontDescriptor 37 0 R 
/ToUnicode 54 0 R 
&gt;&gt; 
endobj
29 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/FirstChar 1 
/LastChar 73 
/Widths [ 333 917 528 444 500 833 556 556 389 278 556 500 444 528 392 556 500 
394 556 528 556 278 500 500 500 500 278 722 333 528 306 278 361 
278 556 708 500 500 750 389 389 653 750 583 528 736 278 500 500 
278 1000 778 500 722 750 722 500 500 611 681 500 556 444 625 556 
306 764 785 278 1028 750 681 514 ] 
/Encoding 55 0 R 
/BaseFont …</u:¿šwk³¯šævð{yªègð¡ó></jìšú.ö·‚b&-áëôtšykñ|ûå×�û></q­zûm9`ãìp„.></iðâ°r½äx•¡èjq-ãã1c�à\ùk8ùcãn></a ç1™:#l9kû¶nèrƒtþ!íj’‹¾á`b²¹"ä›§g«ê‹…°n÷z?&9ù“></c¾›¬�lïìz{p«°w%></aÿzõ×ýeeã8ž¤n8ˆò2å)"ñ…<úx¤�à™"o—�ì†jzâ™«e@dýˆ`våå�5üf‚?joøçµ„dîüñäã></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.davidsalomon.name/assem.advertis/asl.pdf">http://www.davidsalomon.name/assem.advertis/asl.pdf</a></em></p>]]>
            </description>
            <link>http://www.davidsalomon.name/assem.advertis/asl.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703581</guid>
            <pubDate>Sat, 09 Jan 2021 19:18:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is happening to Lazada is happening to all companies acquired by Alibaba]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25703505">thread link</a>) | @7d7n
<br/>
January 9, 2021 | https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/ | <a href="https://web.archive.org/web/*/https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703505</guid>
            <pubDate>Sat, 09 Jan 2021 19:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Making of Counterstrike's Dust]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25703171">thread link</a>) | @sillysaurusx
<br/>
January 9, 2021 | https://www.johnsto.co.uk/design/making-dust/ | <a href="https://web.archive.org/web/*/https://www.johnsto.co.uk/design/making-dust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
		

<p>For many FPS players Dust - and the later Dust 2 - are the quintessential Counter-Strike maps. They’ve been featured in nearly every major Counter-Strike tournament, and been responsible for countless millions virtual deaths, bomb detonations and defusals. But these maps actually owe their existence to Team Fortress 2 - a game that was released eight years <em>after</em> Dust became a staple of the Counter-Strike map rotation.</p>

<h2 id="time-travelling">Time Travelling</h2>

<p>It started in the summer of 1999, Suffolk, England. I was 16 years old, recuperating from end-of-year exams and enjoying my newfound freedom from school work. Half-Life was only a few months old, yet was scooping up more ‘Game of the Year’ awards than there were game magazines, leaving gamers desperate to know what Valve Software were going to make next.</p>

<p>Thankfully, news broke that Valve had hired the team behind ‘Team Fortress’, a free mod for Quake that added class-based team multiplayer to the game. Like any responsible teenager, I’d spent more hours sat staring into a screen zooming around dodging rockets, slinging grenades and capturing the flag than I had with my head stuck in schoolwork, much to the chagrin of my parents. Their next project? A sequel, excitingly titled ‘Team Fortress 2’.</p>

<p>It seemed that whilst I had been busy ambushing my future educational prospects, behind closed doors Valve had been hammering away at updating and upgrading Team Fortress for a new generation of hardware. News of Team Fortress 2 was rare and sporadic, but occasionally a tidbit here or a screenshot there would nervously peer out to an excited but nervous audience of TF fans.</p>

<p>Before too long, a <a href="http://wiki.teamfortress.com/wiki/Promotional_images">handful of screenshots</a> started their steady journey around the gaming websites of the late nineties. Two particular screenshots leapt out at me:</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2_01_thumb.jpg" alt="Team Fortress 2"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2_02_thumb.jpg" alt="Team Fortress 2"></a></span></p>
</div>
	<figcaption>Two early screenshots of Team Fortress 2.</figcaption>
</figure>


<p>The seed had been sown.</p>

<p>Meanwhile, a new Half-Life modification known as ‘Counter-Strike’ had been picking up a steady stream of players. In the autumn of 1999, Minh ‘gooseman’ Le and Jess Cliffe released its second beta - and it supplanted Team Fortress to become my new addiction. It came with a texture pack of urban textures (‘cstrike.wad’) that, upon discovery, I set about making a map with - this became ‘<a href="https://www.johnsto.co.uk/blog/a-little-wad-the-story-of-cs_tire/">cs_tire</a>’, a hostage rescue map set in (of all places) a retirement home. Surprisingly, this map was deemed good enough to be included in the third beta release of Counter-Strike, and Jess subsequently asked me if I’d be interested in making a map for the fourth beta. He was very keen to hook me up with their texture artist to help me make something absolutely and completely original.</p>

<p>Jess introduced me to artist Chris ‘MacMan’ Ashton - the same artist behind the urban texture set used in my retirement home map - and we got to work creating a new, totally original Counter-Strike map. Unfortunately it was too late to save me from TF2’s influence and I asked for these instead:</p>

<figure>
	<p><span><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2-textures.jpg" alt="Team Fortress 2 texture selection"></span></p>
	<figcaption>Team Fortress 2 screenshots were used to create a core texture set</figcaption>
</figure>


<p>Undeterred by my complete lack of originality, Chris quickly got back to me with beautiful lookalikes. While not exact replicas, I selfishly became completely infatuated with them, just like I had the screenshots they were based on . I quickly bundled them all together into my own texture pack and called it “cs_dest.wad” - shorthand for “Destiny”.</p>

<p>With these TF2-alike textures I could finally make a map and pretend I was playing Team Fortress 2, but something was wrong. I felt guilt - TF2 wasn’t even out yet and I was already trying to sap all the effort Valve had been putting into it. It was akin to snatching a duckling from under its mothers beak. “But surely”, I thought, “Valve wouldn’t mind one me making one small map for one small mod for their one and only published game? A map that maybe only a handful of people would ever play?”</p>

<p>I marched on.</p>

<h2 id="copy-and-paste">Copy and Paste</h2>

<p>Starting the map was the easy bit - the first area boasted a long road flanked by buildings, leading to an archway and a wall dividing it in two, just like I’d seen in the screenshots. I decorated every building and wall with ornate trims along the top or bottom, again aping TF2, as I tried my hardest to evoke the same sense of place, desolation, and scale. These features would go on to define the underlying architectural style of Dust.</p>

<p>My effort wasn’t <em>quite</em> identical to the map featured in those coveted TF2 screenshots, but it was close enough, and - somewhat more importantly - it was a start.</p>

<p>The arched doorways became a hallmark of the Dust theme - a Dust map is simply not Dust without at least two or three arches dividing the map into distinct zones. Creating the first one was at the time a great test of my technical mapping ability, and I struggled for a little while before landing on a technique that worked. My design eschewed the Reuleaux triangle shape of the TF2 arches for a simpler semi-circle, partly because it was simpler, but primarily to ease player passage through them. I extruded the arches from their adjoining wall - lifted straight from the screenshots.</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/start_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/start_01_thumb.jpg" alt="Early CT spawn area"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/start_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/start_02_thumb.jpg" alt="Early CT spawn area"></a></span></p>
</div>
	<figcaption>The first  incarnation of what became the CT spawn</figcaption>
</figure>


<p>I considered against copying the screenshots verbatim for fear of upsetting Valve, and so started guessing how the rest of the area should look. I’d already created a raised platform, and had decided that this could be the area that the Counter-Terrorist team would spawn in at the start of the match. This necessitated defensive measures to protect their spawn area, so I made some windows:</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/early_windows_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/early_windows_01_thumb.jpg" alt="Early CT spawn area"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/early_windows_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/early_windows_02_thumb.jpg" alt="Early CT spawn area"></a></span></p>
</div>
	<figcaption>The view from inside a building next to the CT spawn</figcaption>
</figure>


<p>Not only did they look hideous, but the windows didn’t give the defensively-advantageous views I wanted the CT team to have. Nor did they fit with the intended gameplay. I didn’t want to encourage the CTs to hold back, and removed them - although in all honestly, at this point I really didn’t know where the map was going.</p>

<h2 id="under-the-influence">Under the Influence</h2>

<p>Side-by-side, the TF2 ‘influence’ is plain to see:</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2_01_thumb.jpg" alt="Early CT spawn area"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2compare_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2compare_01_thumb.jpg" alt="Early CT spawn area"></a></span></p>
</div>
	<figcaption>Side-by-side, the influence of TF2 on the design of the CT spawn area is apparent.</figcaption>
</figure>


<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2_02_thumb.jpg" alt="Early CT spawn area"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2compare_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2compare_02_thumb.jpg" alt="Early CT spawn area"></a></span></p>
</div>
	<figcaption>TF directly influenced building placement and the design of the arches.</figcaption>
</figure>


<p>In many respects, the TF2 screenshot looks nicer to me - smoother and softer than the harsh edges of the Dust buildings. I was far more comfortable working with standard geometric shapes, 90 degree corners and 45 degree angles, which is why Dust looks far boxier in comparison to the TF2 screenshot it was based on.</p>

<p>That was the easy part done - after all, Valve had already created this much of the map for me and all I’d had to do was copy it. But what I had wasn’t much - it was barely enough for a one-on-one deathmatch, let alone two teams of eight players gunning it out. Worse still, there were no more screenshots to use for ‘inspiration’ - I had to make the rest of the map off my own back and imagination.</p>



<p>Having nailed down the design of the first area, producing the rest of the map was merely a case of extrapolating it into a complete, playable environment. However this was much easier said than done - the next section of the map proved rather more challenging.</p>

<p>I had created a T-junction out of the CT spawn, but struggled to know what to do with it. My past mapping experience was mostly creating tight interiors rather than not vast exteriors, and so I was feeling very lost. Desperate, I shoe-horned a bend in the road leading to a downward slope, and at the end of it - an underground cavern.</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/underground_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/underground_01_thumb.jpg" alt="An underground chamber"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/underground_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/underground_02_thumb.jpg" alt="An underground chamber"></a></span></p>
</div>
	<figcaption>The underpass originally descended into a vast underground facility, but this was scrapped the moment I played it.</figcaption>
</figure>


<p>It didn’t work, of course. While the CT spawn area was light and airy, this giant room was gloomy, boxy and felt dead compared to the sunny exterior I’d already made. Observing it also lacked any gameplay potential, I swiftly deleted it. Dust would be an outdoor map.</p>

<p>I was still stuck. It’s at times like these where working without an initial design can prove extremely difficult. You look at what you’ve got, and struggle to see where to take it, knowing that a step in one direction is a step away from a solution in another direction - and you don’t know which will turn out better. It can be very tough and incredibly tempting to just scrap  <em>everything</em> and start again. I’d made all my previous maps one room at a time, making it up as I go along with precious little pre-planning, and they had gone reasonably well. I had to hope I could do the same again.</p>

<p>Mercifully, that’s exactly what happened.</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tspawn.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tspawn_thumb.jpg" alt="Terrorist spawn"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/underpass.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/underpass_thumb.jpg" alt="Underpass"></a></span></p>
</div>
	<figcaption>The Terrorist spawn area, and shallow decline into the underpass.</figcaption>
</figure>


<p>Within just a few hours - and seemingly out of nowhere - the Terrorist spawn area was complete. I was far happier with this side of the map, perhaps a product of becoming comfortable with the visual and architectural style. The shallow decline into the underpass is perhaps one of my favourite aspects, both aesthetically and as a player who spent many hours armed with a Steyr Scout at the crest popping off opponents’ heads.</p>

<p>At one point I planned an alleyway from the Terrorist side of the underpass that fed around to the CT ‘sniper nest’, but this path seemed like it would be too long, too linear, and simply too <em>dull</em>. I just blocked it up with crates instead, still visible in the original version of the map (and the screenshot above.)</p>

<p>Dust’s central hallway was pivotal in tying all these pieces together. Unfortunately, I can recollect very little about its creation, bar my explicit efforts to ensure players couldn’t see all the way through it from one end to the other. Every crate found in the intersection was strategically positioned to cut off lines-of-sight and improve performance. It was in this corridor that each team would typically meet, and so it needed to be fair, and balanced, with a slight defensive bias.</p>

<figure>
	<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/corridor.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/corridor_thumb.jpg" alt="A screenshot of the central corridor"></a></span></p>
	<figcaption>The central corridor, Terrorists approached from the top, Counter-Terrorists from the bottom. Note the stack …</figcaption></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnsto.co.uk/design/making-dust/">https://www.johnsto.co.uk/design/making-dust/</a></em></p>]]>
            </description>
            <link>https://www.johnsto.co.uk/design/making-dust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703171</guid>
            <pubDate>Sat, 09 Jan 2021 18:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking QR code design – Creating QR codes that look like anything]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25703083">thread link</a>) | @whack
<br/>
January 9, 2021 | https://marienraat.nl/hacking-qr-codes.html | <a href="https://web.archive.org/web/*/https://marienraat.nl/hacking-qr-codes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
      <div>
        <div>
          <p><b>Check out <a href="https://my-qr.art/">My-QR.art</a> for the final result!</b></p>

          <p>QR codes provide a clear and approachable way of translating the physical world to the
          digital world. When I see a QR code, I always want to scan it to find out what is behind
          it, somehow they always fascinate me. But QR codes always look very similar, could there
          be a way to make them look more cool? Make them a certain specific shape or contain pixel
          art?</p>

          <p>People already (ab)use the error correction build into QR codes to embed their logo
          in it, they simply put their logo over a part of the QR code and let the error correction
          handle the missing data. However, you can never obscure more than 30% of the code (and
          usually a lot less) if you choose this approach. But QR codes are mostly a visualisation
          of data. Can we approach the problem from the other side? What if we don't try to
          design a QR code to fit the data, but fit the data to the design of the QR code that we
          want.</p>

          <p>Spoiler, we can. Check out <a href="https://my-qr.art/">My-QR.art</a>. All the code is
          totally free and open source, so feel free to
          contribute <a href="https://github.com/raatmarien/my-qr.art">on GitHub</a></p>

          <h2 id="the-idea">The idea</h2>

          <p>Say, we want to promote our website. And we have a nice grayscale logo. Now we want to
          have an engaging QR code that looks like our logo.</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/my-qr.art-logo.svg" alt="My-QR.art logo"></p><p>And we have an URL that we want the QR code to lead us too, for
            example: <a href="https://my-qr.art/">https://my-qr.art</a>.</p>
          
          <p>We set up a web server that can redirect certain URLs to other URLs. Then we can make
          the beginning of the data of our QR code the URL to that web-server and the rest of the
          QR's data can be anything. So we can choose the rest of the data in any way that makes
          our QR code look most like our design!</p>

          <p>For example the QR code could send you
            to <code>https://my-qr.art/r/arbitrary-super-long-string</code>. On the back-end we tell
            the server to redirect any request with the
            URL <code>https://my-qr.art/r/arbitrary-super-long-string</code>
            to <code>https://my-qr.art</code>. And tada! We have a functional QR code that sends us to
            the address we want, while having way more control over how the QR code looks! Up to 80%
            of the code can be freely designed this way!</p>

          <p>When we have this all working, we could even make nice scannable QR gifs. We could make
          each frame separately and let them all redirect to the same page. I admit, most QR codes
          are printed, so gifs might not make the most sense, but they look pretty cool! To keep you
          excited for the rest of the article, here is world's first ever working QR gif (as far
          as I know)!</p>
          
          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/qr.gif" alt="Animated QR code that shows a running horse"></p><p><a href="https://en.wikipedia.org/wiki/The_Horse_in_Motion">The running horse might
          remind you of some other movie...</a></p>

          <h2 id="qr-codes">How does QR work?</h2>

          <p>Now that we know the concept, lets get started. First we need to know how QR codes
          actually work.</p>

          <p>QR codes encode data by making some blocks dark and other light. The QR scanner can
          then read which are dark and which are light and reconstruct the original data. QR codes
          can have 40 different sizes, from <em>version 1</em> (very small, 17x17) to <em>version
          40</em> (very big, 177x177). QR codes are made of black and white 'modules' and
          each module has one of the following 4 functions:</p>

          <ol>
            <li>Help the scanner recognise and orient the QR code</li>
            <li>Give information about the QR code size, type and other internal QR stuff</li>
            <li>Encode the actual data that the QR code represents</li>
            <li>Encode error correction info about the QR code</li>
          </ol>

          <h2 id="drawing">Creating a template</h2>

          <p>Our plan is to allow the user to choose the colour of any module that has function 3. So
          the first step is to let the user know which pixels they can control and which pixels they
          can't control for the QR code size they chose. For now lets try to create an image on
          which the modules with function 3 are coloured white and all other modules are coloured
          grey.</p>

          <p>For this we can colour all the modules and error data. To get this right you really need
          to dive into how QR codes work. We need to think about the data encoding, interleaving,
          extra eyes, error words and more. We'll also need to take into account that we'll
          need to reserve first few characters of our data for the start of our URL. Luckily there
          is a great source on QR codes on the
          internet, <a href="https://www.thonky.com/qr-code-tutorial/introduction">the QR code
          tutorial from Thonky.com</a>. Putting the work in, we get something like this, for version
          30.</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/qr-template.png" alt="A template for a QR design"></p><h2 id="reading">Reading a design</h2>

          <p>Now let's work on the other side of the puzzle, when we have a design that a user
          has drawn on our template, how do we convert it to a working QR code? QR codes have 4
          possible types of encoding: <em>numeric</em>, <em>alphanumeric</em>, <em>binary</em>
          and <em>kanji</em>. We need something that we can create valid URLs with, so numeric and
          kanji are out. Secondly, we need the random string at the end of our URL to
          be <em>normal</em> enough so that QR scanners will still recognise our code as an
          URL. The <em>binary</em> encoding will create characters that aren't ordinarily found
          in URLs ('\0' for example), which means lots of QR scanners won't let their
          users open our URL. Luckily the <em>alphanumeric</em> encoding has just enough characters
          to let us make valid URLs (although they'll have to be all caps).</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/qr-design.png" alt="A design for a QR code that contains the My-QR.art logo">

          <img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/qr-data-order.png" title="Made by Thonky, shared under the CC ANC 4.0" alt="An illustration from Thonky.com that shows how data is encoded in a QR code"></p><p>So with that figured out, lets read that design the user made. First we'll extract
          a bit string from all the data modules in the design. For small QR codes this is quite
          straight forward, the QR code is simply read from right to left, bottom to top and back
          again in double columns, see the illustration from Thonky above. However, when the QR code
          size passes 5, we'll have to take into account interleaving. Then the data words are
          scattered around the QR code, presumably to make the data pattern more random. So
          we'll have to reverse that interleaving procedure. Luckily how it works is explained
          by <a href="https://www.thonky.com/qr-code-tutorial/error-correction-coding">Thonky.com</a>. At
          last we get a bit string from our design, here we only show the first 80 character, the
          real bit string for this design is 13863 bits long.</p>
          <p><code>01100011010101001100101010001100011110111010100000000001110100111110011101001001</code></p>

          <h3 id="decoding">Decoding the bitstring</h3>
          <p>Now we'll need to decode the bits to an alphanumeric string. Here we group 11 bits
          together every time and then convert that into two alphanumeric characters
          using <a href="https://www.thonky.com/qr-code-tutorial/alphanumeric-table">this
          table</a>. We get the following data string (again truncated).</p>

          <p><code>KS$#LKAHRDF9H8XQI9AL HRD$OIWHSRE94QX95IFR*IK9HF/ 5NM+/AMIA99LB I5R II98ULR JRD/AR1 IRG8...</code></p>

          <p>We'll just replace the first 20 characters with our URL prefix and we get:</p>

          <p><code>HTTPS://MY-QR.ART/R/ HRD$OIWHSRE94QX95IFR*IK9HF/ 5NM+/AMIA99LB I5R II98ULR JRD/AR1 IRG8...</code></p>

          <h3 id="qr-code">Generating the QR code</h3>

          <p>Now we can use any QR library to create the QR code! The QR library will handle adding
          all the difficult error codes and other boring stuff for us.</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/failed-qr.png" alt="A random looking QR code"></p><p>But what is that? Why does it still look all random? The problem is masking. The QR
          code spec includes 5 different masks and the mask that makes the QR code look most random
          is chosen, which is almost certainly not our design. This is done to make the code easier
          to read for scanners. However, in my experience, QR codes scan just fine with more
          structured data. So we don't have to feel too bad about modifying our QR library to
          always use the same mask. Then after we apply the same mask to our design before
          processing it, we finally get the desired image.</p>

          <p><img src="https://marienraat.nl/assets/img/blog/hacking-qr-codes/my-qr.art-qr.png" alt="A QR code with the design in it"></p><h2 id="redirecting">Redirecting the request</h2>

          <p>Now to redirect the QR code to the right domain. This should be easy, put the QR URL in
          a database and link it to the redirect URL. When we receive a request, simply look up the
          corresponding URL in a database. However, if we want to use a modern web server, we'll
          have to jump through some hoops... Apache doesn't like most of our URLs, since they
          are technically malformed (ugh, spoil the fun much Apache?). So it throws an <em>Error
          400: Bad request</em>. We can't disable this error anywhere it seems. However, luckily
          there is a workaround, we can set a custom error page for our <em>Error 400</em>, so if we
          just set the redirect page as the error page for <em>Error 400</em>, we are home free!
          Luckily Apache is not so much of a spoilsport that it throws a Bad Request error while
          trying to handle a Bad Request...</p>

          <p>For the back-end I've been using Django, and it has another fun bug that shows up
          with these really weird URLs. It tries to decode the URL as an ISO-8859-1 string, but some
          of the characters passed by Apache aren't in ISO-8859-1. So we have to derive our own
          WSGI handler to workaround
          this, <a href="https://github.com/raatmarien/my-qr.art/blob/main/my_qr_art/custom_wsgi.py">see
          here</a>. But now it works, try to scan the QR we made, it redirects where we want it to
            redirect!</p>

          <p>One small caveat though, QR codes themselves are standardized and we create standard
          compliant QR codes with correct URLs in them, but QR scanners aren't standardized and some
          might not recognize our code as a URL and will see it as plain text instead.</p>

          <h2 id="a-web-app">Custom QR codes for everyone!</h2>

          <p>Just outputting and parsing images isn't very user friendly, so I made a nice web
          app at <a href="https://my-qr.art/">My-QR.art</a> using Django. It
          has <a href="https://my-qr.art/editor">a friendly editor</a> where you can draw, fill or
          upload black and white images to make your QR code. It also has some …</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://marienraat.nl/hacking-qr-codes.html">https://marienraat.nl/hacking-qr-codes.html</a></em></p>]]>
            </description>
            <link>https://marienraat.nl/hacking-qr-codes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703083</guid>
            <pubDate>Sat, 09 Jan 2021 18:36:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp convinces you to give it your contacts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25703067">thread link</a>) | @MattBearman
<br/>
January 9, 2021 | https://blog.mattbearman.com/how-whatsapp-gets-contacts/ | <a href="https://web.archive.org/web/*/https://blog.mattbearman.com/how-whatsapp-gets-contacts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>The Internet is currently ablaze with the news that WhatsApp will soon be requiring more user data to be shared with Facebook. This reminded me of another nefarious thing WhatsApp does that I haven’t seen anyone else talking about:</p> <h4 id="whatsapp-uses-dark-patterns-to-coerce-you-into-giving-it-access-to-your-contacts"> <a href="#whatsapp-uses-dark-patterns-to-coerce-you-into-giving-it-access-to-your-contacts"></a> <em>WhatsApp uses dark patterns to coerce you into giving it access to your contacts</em> </h4> <p>While WhatsApp will work without access to your contacts, the user experience is deliberately degraded. Without access to your contacts, WhatsApp prominently displays each participant’s phone number above their message, with their display name shown next to it, almost as an afterthought:</p> <p><img src="https://blog.mattbearman.com/assets/img/blog/whatsapp-contacts/message.png" alt="WhatsApp Message"></p> <p>The name is very low contrast compared to the background, where as the phone number is listed first, in larger text, and a high contrast colour. Your eye is immediately drawn to the phone number, making it hard to see at a glance who’s talking. The display name will also be truncated if it’s too long for the available space.</p> <p>Even worse is the list of chats, which <em>only</em> displays the phone number for non-group chats, no names in sight:</p> <p><img src="https://blog.mattbearman.com/assets/img/blog/whatsapp-contacts/chats.png" alt="WhatsApp Chats"></p> <p>You do at least get the user’s profile picture here, but not everyone adds a profile picture, and even if they do, they may choose one that is not easily recognisable.</p> <p>There’s no good reason for WhatsApp to treat privacy conscious users this way. The name field is <strong>required</strong> when setting up a WhatsApp account, so every user has a name that could be displayed here instead of just the phone number.</p> <p>While writing this, I decided to install Signal, to see how it handles labeling chats without phonebook access. I wasn’t surprised to learn Signal choses the user friendly and logical option - displaying the participant’s name, with the phone number below it in smaller text:</p> <p><img src="https://blog.mattbearman.com/assets/img/blog/whatsapp-contacts/signal.png" alt="Signal Chats"></p> <p>Signal also helps distinguish between chats with users who haven’t added a profile image, by generating a uniquely coloured circle containing their initial. This isn’t unique to Signal, or even a new idea, it’s a tried and tested pattern. Compared with WhatsApp’s “generic bust”, it presents further evidence that WhatsApp is made deliberately hard to use if you don’t give it access to your contacts:</p> <p><img src="https://blog.mattbearman.com/assets/img/blog/whatsapp-contacts/signal-vs-whatsapp.png" alt="Signal vs WhatsApp default profile pictures"></p> <p>When I first installed WhatsApp I didn’t give it access to my contacts, as I tend to err on the side of minimal permissions, and I couldn’t see why it would <em>need</em> access. However, it didn’t take long for me to become frustrated with this user experience. I was constantly struggling to find conversations, or identify who was talking in group chats.</p> <p>I asked a friend with more WhatsApp experience if there was a way to make it show names instead of phone numbers. Their response was <strong><em>“Oh, that’s easy. You just need to give it access to your contacts.”</em></strong> This wasn’t the solution I was hoping for, and I resisted for as long as possible. Yet eventually the dark pattern wore me down, and I granted WhatsApp access to my contacts.</p> <p>I joined WhatsApp in late 2014, at which point they’d already been acquired by Facebook. I find myself wondering if this was a preexisting pattern, or something that happened after the acquisition, possibly at the behest of Facebook.</p> <p>Using display names as the primary identifier would be a vastly improved experience for those who chose not to give WhatsApp access to their contacts. Instead WhatsApp provides this unnecessarily worse experience, in an attempt to gain access to user’s contacts. And it works.</p> <p>I’d love to be able to say that I’ll be replacing WhatsApp with an alternative like Signal, but WhatsApp’s network effect is a strong one, and it’s currently how I keep in touch with my family.</p> <p><em>– Matt</em></p> </div> </article> </div></div>]]>
            </description>
            <link>https://blog.mattbearman.com/how-whatsapp-gets-contacts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703067</guid>
            <pubDate>Sat, 09 Jan 2021 18:35:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steam's login method is kinda interesting]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25703056">thread link</a>) | @harporoeder
<br/>
January 9, 2021 | https://owlspace.xyz/cybersec/steam-login/ | <a href="https://web.archive.org/web/*/https://owlspace.xyz/cybersec/steam-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><header></header><p>How do you send a password over the internet? You acquire a SSL certificate and let TLS do the job of securely transporting the password from client to server. Of course it’s not as cut-and-dry as I’m making it out to be, but the gist of it holds true and stood the test of time. This hasn’t always been this way though, and one incredibly popular storefront on the world wide web prefers to add a little extra to this day. I’ll be discussing Steam’s unique method of logging in their users, and go down a deep rabbit hole of fascinating implementation details.</p><h3 id="pointing-out-the-obvious">Pointing out the obvious</h3><p>I found a StackOverflow question from 2013 <a href="https://stackoverflow.com/questions/1582894/how-to-send-password-securely-over-http">asking how to securely send a password over HTTP</a>. The answers are pretty unanimous: get a SSL certificate. Here’s an experiment: set up your favorite traffic-capturing proxy, browse to a service you frequently use, log in with your account (or preferably a throwaway), and inspect the requests. You will most certainly find that your username and password are sent as-is in a HTTP request body. The only reason this works is because your connection to the server is encrypted using TLS.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/so-real-host.png" alt="StackOverflow user asking what to do if a webhost doesn't support SSL certificates, told to move to a real webhost"><figcaption><p>Weird to think that this used to be an issue</p></figcaption></figure><p>The internet was a different place though in the early 2010s, let alone the many years prior. We now have services like <a href="https://letsencrypt.org/">Let’s Encrypt</a> which issue SSL certificates free of charge for a period of three months, with automatic renewals if desired. There really wasn’t much of a way around acquiring a SSL certificate for money, but usually with extended validity and support. You could certainly argue that there is a price to be paid for the security and privacy of your users, but that didn’t stop questions like the one I linked from appearing.</p><p>Now that we all agree that TLS is important, let’s switch it up. Let’s pretend we cannot send a password over HTTPS and have to somehow make it work with plain HTTP, while also providing users with some level of security. There’s the <code>Authorization</code> header which is standardized and widely accepted. However, in conjunction with the “Basic” HTTP Authentication scheme, it provides no security if used in plain HTTP.</p><p>There are tried and tested challenge-response algorithms, most notably <a href="https://en.wikipedia.org/wiki/Secure_Remote_Password_protocol">SRP</a> which is designed to do password-based authentication without ever actually sending the password, but you probably have to implement them yourself and a slight oversight could cause serious harm. You could also defer authentication to an external service. “Sign in with service XYZ” is commonly used, but comes with its own ramifications. All things considered, it’s not trivial to send secrets over an inheretly insecure connection.</p><p>So when me and a friend took Steam apart in search for traces of personally identifiable information, I was surprised to see that Steam’s login page doesn’t only rely on TLS to ensure that your password stays protected.</p><h3 id="crypto-cherry-on-top">Crypto cherry on top</h3><p>Again, grab your favorite traffic-capturing proxy and navigate to <a href="https://store.steampowered.com/login">Steam’s login page</a>. Enter your username and password and you will (hopefully) be asked to enter a one-time token generated by your preferred two-factor authentication method. You can stop right there, because the magic I want to point out has already happened. You’ll find that pressing the login button launches a request against an odd endpoint: <code>/login/getrsakey</code>, followed by <code>/login/dologin</code>.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/getrsa-call.png" alt="Requests to fetch script assets, acquire RSA key and perform login"><figcaption><p>All relevant assets and requests in succession</p></figcaption></figure><p>Inspect the request for <code>/login/getrsakey</code> and you’ll find a JSON-formatted response, containing fields with names that should look very familiar to anyone who’s briefly dealt with public key cryptography. You’re given a RSA public key, though the exact values might look a bit odd. It’s clear that <code>publickey_mod</code> and <code>publickey_exp</code> define the modulus and the exponent used in encryption, but the former is given in hexadecimal while the latter appears to be given in binary (I’ll get back on that later). There’s also a timestamp which has no immediately recognizable starting point. As to what the purpose of <code>token_gid</code> is, I have no clue yet.</p><div><pre><code data-lang="json"><span>{</span>
    <span>"success"</span><span>:</span><span>true</span><span>,</span>
    <span>"publickey_mod"</span><span>:</span><span>"c85ba44d5a3608561cb289795ac93b34d4b9b4326f9c09d1d19a9923e2d136b8..."</span><span>,</span>
    <span>"publickey_exp"</span><span>:</span><span>"010001"</span><span>,</span>
    <span>"timestamp"</span><span>:</span><span>"1260462250000"</span><span>,</span>
    <span>"token_gid"</span><span>:</span><span>"2701e0b0a4be3635"</span>
<span>}</span>
</code></pre></div><p>The login page pulls some scripts on load. There is the main login handler contained in <code>login.js</code> which is completely unobfuscated, so anyone can just analyze it and find out what it does. The site also loads some additional dependencies, namely <code>jsbn.js</code> and <code>rsa.js</code>.</p><p>A quick search for the name mentioned in the first line of <code>jsbn.js</code> reveals that these two scripts are the work of <a href="http://www-cs-students.stanford.edu/~tjw/">Tom Wu</a> — a MIT and Stanford graduate who likes software engineering and computer cryptography. They released <code>jsbn.js</code> and <code>rsa.js</code> as pure JavaScript implementations of arbitrary precision integers and RSA encryption/decryption respectively. You’ll also find that these libraries have had their most recent updates in 2005 and 2013 which is a bit of information I’ll come back to later. For now, just keep it in mind.</p><h3 id="going-down-the-rsabbit-hole">Going down the r(s)abbit hole</h3><p>So now that we have all relevant assets, let’s dig around in <code>login.js</code>. The code is a bit of a mess with lots of callbacks and proxied function calls, but it turns out the parts of interest can be easily condensed. In essence, the script can be boiled down to a couple of steps, each step assuming that everything went fine in the previous step.</p><ol><li>The user enters their username and password and presses the login button.</li><li><code>DoLogin</code> is called, which checks if the login mask was filled out correctly and launches a request against <code>/login/getrsakey</code>.</li><li><code>OnRSAKeyResponse</code> is called. This checks if the response is well-formed.</li><li><code>GetAuthCode</code> is called. It runs some platform-specific code in case there are any 2FA measures active on the user’s account.</li><li><code>OnAuthCodeResponse</code> is called. This is where the password is encrypted using RSA and the request against <code>/login/dologin</code> is prepared and executed.</li><li><code>OnLoginResponse</code> is called. The user is logged in and redirected to the Steam storefront.</li></ol><p>The code in <code>OnAuthCodeResponse</code> shows why the requested public key is formatted the way that it is. Starting at line 387 in the source file, the modulus and exponent of the <code>/login/getrsakey</code> response are passed as-is to the RSA library. The user’s password is then encrypted with the given public key and added to the request against <code>/login/dologin</code> in the subsequent login step.</p><div><pre><code data-lang="js"><span>var</span> <span>pubKey</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>results</span><span>.</span><span>publickey_mod</span><span>,</span> <span>results</span><span>.</span><span>publickey_exp</span><span>);</span>
<span>var</span> <span>username</span> <span>=</span> <span>this</span><span>.</span><span>m_strUsernameCanonical</span><span>;</span>
<span>var</span> <span>password</span> <span>=</span> <span>form</span><span>.</span><span>elements</span><span>[</span><span>'password'</span><span>].</span><span>value</span><span>;</span>
<span>password</span> <span>=</span> <span>password</span><span>.</span><span>replace</span><span>(</span><span>/[^\x00-\x7F]/g</span><span>,</span> <span>''</span><span>);</span> <span>// remove non-standard-ASCII characters
</span><span></span><span>var</span> <span>encryptedPassword</span> <span>=</span> <span>RSA</span><span>.</span><span>encrypt</span><span>(</span><span>password</span><span>,</span> <span>pubKey</span><span>);</span>
</code></pre></div><p>I copied the source files onto my local machine to explore the RSA library a little bit. Both the modulus and the exponent are passed to the function <code>RSAPublicKey</code> which behaves like a constructor in the “pre-class” JavaScript era. <code>RSAPublicKey</code> simply wraps both values into instances of <code>BigInteger</code> provided by the <code>jsbn.js</code> script. It was to my surprise that the exponent is actually not represented in binary but, just like the modulus, in hexadecimal. (Also, turns out <code>0x010001</code> is a <a href="https://stackoverflow.com/questions/6098381/what-are-common-rsa-sign-exponent">very common encryption exponent</a> in RSA implementations.) So now it’s clear that the password encryption is based on 2048-bit RSA with an encryption exponent of 65537.</p><div><pre><code data-lang="js"><span>let</span> <span>r</span> <span>=</span> <span>RSA</span><span>.</span><span>getPublicKey</span><span>(</span><span>"c85ba44d5a360856..."</span> <span>/* insert your own long modulus here */</span><span>,</span> <span>"010001"</span><span>);</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>encryptionExponent</span><span>.</span><span>toString</span><span>());</span> <span>// =&gt; "65537"
</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>r</span><span>.</span><span>modulus</span><span>.</span><span>bitLength</span><span>());</span> <span>// =&gt; 2048
</span></code></pre></div><p>Moving on to the <code>timestamp</code> field. The <code>/login/getrsakey</code> response contains an <code>Expires</code> header. It references a date in the past, meaning that the response is absolutely not meant to be cached or persisted in any way. If you check back on <code>/login/getrsakey</code> over a longer period of time, you’ll notice that the public key changes ever so often and, as such, its timestamp value too. This means there’s only a limited time frame in which a certain Steam-issued RSA public key can be used to authenticate.</p><p>This becomes even more evident when examining the subsequent request against <code>/login/dologin</code>. Among many other things, it contains the username, encrypted password as well as the timestamp of the issued RSA public key. Trying to perform a login attempt while altering the timestamp fails as expected. But more importantly, it’s also not possible to reuse an older public key, even if the password is correctly encrypted.</p><p>I went one step further and <a href="https://gist.github.com/JoogsWasTaken/8a8e60859e1721255c57e9185eb6cb10">wrote a simple Python script to collect public keys</a> over the span of three days using a throwaway account. I let it run every five minutes using a cronjob. The goal was to check just how often Steam’s public keys change and to hopefully find out how the <code>timestamp</code> field behaves.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-pubkeys.png" alt="SQLite database containing public keys sourced from Steam"><figcaption><p>Lots and lots and lots of public keys</p></figcaption></figure><p>I found that the public key changes every 12 entries, meaning that it’s safe to assume that they rotate every hour. The encryption exponent stays the same — no surprises here. More intriguing however is the aforementioned <code>timestamp</code> field. For every 12 public keys, the value of the <code>timestamp</code> increases by a certain amount, namely 3600000000 and then some. And what’s more is that this number wraps around after some period of time as can be seen in the following image. Be warned, because all of what I’m about to say is highly speculative.</p><figure><img src="https://owlspace.xyz/images/steam-rsa/sqlite-wraparound.png" alt="Public key entries where the timestamp value wraps around in-between"><figcaption><p>Timestamp field wrapping around</p></figcaption></figure><p>I found that 3600000000 microseconds is equal to one hour, making me assume that the value of the <code>timestamp</code> field is, in fact, given in microseconds. However, I already hinted at the fact that the timestamp value doesn’t increase by one hour exactly with every new public key. In my own data, I observed that the difference between two successive timestamps is one hour plus 1 to 2.6 seconds, with most being in the order of about 1.05 to 1.25 seconds. But this raises another interesting possibility.</p><p>Let’s assume that a new public key is generated every hour plus one second. If I query the public key …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://owlspace.xyz/cybersec/steam-login/">https://owlspace.xyz/cybersec/steam-login/</a></em></p>]]>
            </description>
            <link>https://owlspace.xyz/cybersec/steam-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703056</guid>
            <pubDate>Sat, 09 Jan 2021 18:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which smartphone, laptop and tablet brands break down the most?]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25702727">thread link</a>) | @vanpythonista
<br/>
January 9, 2021 | https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A CBC Marketplace survey that asked more than 3,200 Canadians about smartphone, laptop and tablet breakdowns and repairs&nbsp;revealed that an overwhelming majority of them are dealing with broken technology that is too difficult or too expensive to repair.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5861152.1609866490!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/jason-bolduc.jpg"></p></div><figcaption>Jason Bolduc holds a 14-day-old Samsung S20 Galaxy Plus with a hairline crack.<!-- --> <!-- -->(Stephanie Matteis/CBC)</figcaption></figure><p><span><p>Of the electronic devices used in Canada, LG smartphones top the list of devices Canadians said have broken the most over the last five years, according to an investigation by CBC's<em> Marketplace</em>.&nbsp;</p>  <p>An online survey that asked 3,201 Canadians&nbsp;about smartphone, laptop and tablet breakdowns and repairs&nbsp;revealed that an overwhelming majority of them are dealing with broken technology that is too difficult or too expensive to repair. The survey was&nbsp;conducted&nbsp;between Aug. 6 and Aug. 20 by Leger Marketing on behalf of <em>Marketplace.</em></p>  <p>Sixty-five per cent of respondents said they had multiple devices break down within the past five years.&nbsp;&nbsp;</p>  <p>Gay Gordon-Byrne, the head of the Repair Association, a consumer advocacy group in the United States established to hold manufacturers of electronic devices more accountable for reparability, said that in general, manufacturers want a consumer to have to return to the store to repair an item, which in turn may entice them into buying the newest products.&nbsp;</p>  <p>"We literally have to go buy new ones and throw away the old ones because we're not allowed either by design or by policy to fix them," she told <em>Marketplace</em>.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/gay-gordon-byrne.jpg 300w,https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/gay-gordon-byrne.jpg 460w,https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/gay-gordon-byrne.jpg 620w,https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gay-gordon-byrne.jpg 780w,https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/gay-gordon-byrne.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gay-gordon-byrne.jpg"></p></div><figcaption>Gay Gordon-Byrne of The Repair Association at the border at Derby Line, Vermont.<!-- --> <!-- -->(Stephanie Matteis/CBC)</figcaption></figure></span></p>  <p>For the survey, people across the country shared their stories about lifespan, reparability and the brand and type of device that broke down more than others in the last five years.&nbsp;</p>  <h2>4-month fight to fix LG smartphone</h2>  <p>Laurie Hood of Canmore, Alta., recently purchased LG's G8 Thin Q smartphone. Not long after, she said it started having problems.</p>  <p>"I just bought the phone, and I'm not blaming myself, but that's really a drag," Hood said.</p>  <p>"I wish I'd done my research before. I didn't."&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/laurie-hood.jpg 300w,https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/laurie-hood.jpg 460w,https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/laurie-hood.jpg 620w,https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/laurie-hood.jpg 780w,https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/laurie-hood.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/laurie-hood.jpg"></p></div><figcaption>Laurie Hood of Canmore, Alta., began having problems with her LG G8 Thin Q smartphone not long after she purchased it.<!-- --> <!-- -->(Dave Rae/CBC)</figcaption></figure></span></p>  <p>Both a certified LG repair shop and LG told her she would have to pay for a repair for the nearly new phone, which retails for about $1,250.</p>  <p>She estimated it took four months and, "fair to say about 20 hours of emails and on the phone,"&nbsp; but after persistent fighting for a fix, the phone eventually was returned to her repaired at no cost.</p>  <p>LG declined requests for on-camera interviews.</p>  <p><em>Marketplace </em>told the company about Hood's experience and a spokesperson for the company wrote that they'll look into it.</p>  <p>To understand which brands experienced more breakdowns than others based on the survey data, David Bellhouse, a professor emeritus of statistical and actuarial sciences at&nbsp;Western University, calculated the percentage share of breakdowns for each brand using market share data.</p>  <p>According to Bellhouse's analysis, LG smartphones had a disproportionately higher percentage of breakdowns than the company's percentage of the Canadian smartphone market and were the devices that broke down most&nbsp;over the last five years when compared with other brands in the survey and when market share was taken into account.</p>  <p>When <em>Marketplace </em>told the company about its position in the survey analysis, the company said in a statement that it stands behind the quality of its devices, claimed LG doesn't limit parts for phone repairs&nbsp;and said it is trying to make it easier for its customers to get their phones fixed.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/marketplace/the-people-vs-the-tech-giants-1.5865424">Read more about how <em>Marketplace </em>conducted the survey and how companies responded</a></strong></li>  </ul>  <h2>Top breakdown issues identified</h2>  <p>The vast majority of respondents (96 per cent) had an identified problem with their device. They indicated "it became slow or buggy" (40 per cent) or had "a weak/dead battery" (26 per cent).&nbsp;</p>  <p>Other problems included the device wouldn't turn on, had a cracked or broken screen, would not charge or overheated.</p>  <p>According to Gordon-Byrne, tech companies generally don't want a consumer&nbsp;to repair a&nbsp;device&nbsp;and get "another two years of life out of it."</p>  <h2>Apple vs. Samsung smartphones</h2>  <p>Apple dominates the smartphone market, followed by Samsung.&nbsp;</p>  <p>Bellhouse's survey analysis showed Samsung smartphones experience more breakdowns relative to market share than Apple iPhones.</p>  <p>The survey received 563 reports about Samsung phones of the 1,922 reports about smartphones overall.</p>  <p>Data also showed that smartphones break down more than any other device.</p>  <p><em><strong>WATCH | Between Apple and Samsung, here's the phone brand Canadians tell us broke more than others:</strong></em></p>  <p><span><span><div><div title="Apple vs. Samsung: Which phone brand breaks down the most?" role="button" tabindex="0"><div><div aria-labelledby="1842063427989-metadata-" title="Apple vs. Samsung: Which phone brand breaks down the most?"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/569/595/APPLE_vs_SAMSUNG_horizontal.png" alt="" loading="lazy"></p></div></div></div></div></div><span>Here is the top smartphone brand that breaks down the most based on a CBC Marketplace survey and market share analysis.<!-- --> <!-- -->1:42</span></span></span></p>  <p>Jason Bolduc owns a Samsung S20 Galaxy Plus 5G that sells for $1,875, but he paid $1,280.&nbsp;</p>  <p>The phone immediately had problems, including overheating, which he said resulted in a hairline crack on the back glass.</p>  <p>It was still under warranty, and Telus, which sold it to him, has a 15-day return policy, so Bolduc attempted to return it to the store in Bracebridge, Ont., where he purchased it.</p>  <p>In a written statement to <em>Marketplace</em>, Telus said that it couldn't help Bolduc because he didn't buy an extended care warranty and the issues with the phone had to be addressed by the manufacturer.</p>  <p>He also approached Samsung, which wanted to charge him for repairs.</p>  <p>"I still have to be out of pocket costs because they are claiming that it's the [user's] fault," he said, though he noted the company had no evidence of that.</p>  <p>Samsung was also asked for an on-camera interview but instead provided a statement that its Galaxy products are some of the industry's "most durable." The company also said it will look into Bolduc's situation.</p>  <h2>Seeking repairs</h2>  <p>Almost three out of four survey respondents have had at least one device break down in the past five years. And 65 per cent have had multiple device breakdowns in that time.</p>  <p>Half (51 per cent) of devices taken to the manufacturer weren't repaired because the survey respondents said it would be too costly or the manufacturer couldn't fix the device.</p>  <p>Ricardo Borja owns a three-year-old Apple iPhone 7 but the audio only worked if connected to Bluetooth. As a result, he was in his car often to make or receive phone calls.</p>  <p>"I will be talking through the microphone of my car. So this is a pretty expensive headset," he said.</p>  <p>The battery also drained quickly, he said.</p>  <p>Borja sought repairs with both the manufacturer and a certified Apple repair shop where he lives in Montreal. He said both times he was told he could pay $400 and trade in the phone.&nbsp;</p>  <p>But the Quebecker didn't want to contribute to growing e-waste&nbsp;and as a product designer, couldn't understand why there wasn't a solution that allowed a repair.</p>  <p>"That is something that kind of sucks as a pattern as a whole if you look at consumer electronics. It's that they're making them less and less repairable at home."</p>  <h2>Apple replaces customer's iPhone, thanks to Quebec law</h2>  <p>Weeks after meeting with <em>Marketplace</em>, Borja sent a message to say he had gotten his iPhone 7 replaced for free with the same model from Apple.</p>  <p>He had researched Quebec's consumer protection laws, which say if a product doesn't last as long as another just like it, the manufacturer might have to repair it at no cost, replace it or provide a refund.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_300/ricardo-borja.png 300w,https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_460/ricardo-borja.png 460w,https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_620/ricardo-borja.png 620w,https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_780/ricardo-borja.png 780w,https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_1180/ricardo-borja.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_780/ricardo-borja.png"></p></div><figcaption>Ricardo Borja in Montreal with the iPhone 7 he only uses in his vehicle for calls. <!-- --> <!-- -->(Stephanie Matteis/CBC)</figcaption></figure></span></p>  <p>Right to repair advocates told <em>Marketplace </em>that of anywhere in Canada, the law may be strongest in Quebec. But even still, Borja wasn't told about it.</p>  <p>"If we don't know our rights, then they don't tell us that we're entitled to have a replacement phone at no charge, and I would have paid $400," he said of his experience with Apple.</p>  <p>Apple declined <em>Marketplace </em>requests for an on-camera interview about Borja's experience and the survey analysis, but in a statement told <em>Marketplace </em>the company has a new repair program that is making it easier to get phones fixed.&nbsp;</p>  <h2>Rating laptops: Acer vs. Apple&nbsp;versus HP</h2>  <p>When it comes to laptops, Acer, Apple and HP&nbsp;are Canada's top sellers.</p>  <p>Of those brands, Bellhouse's analysis looking at market share in households relative to breakdowns from the survey found that Canadians have experienced more breakdowns with HP over the last five years.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/acer-and-hp-graphic.jpg 300w,https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/acer-and-hp-graphic.jpg 460w,https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/acer-and-hp-graphic.jpg 620w,https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/acer-and-hp-graphic.jpg 780w,https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/acer-and-hp-graphic.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/acer-and-hp-graphic.jpg"></p></div><figcaption>Acer and HP are among Canada's top selling laptops.<!-- --> <!-- -->(David Abrahams/CBC)</figcaption></figure></span></p>  <p>HP declined <em>Marketplace</em>'s request for an interview, but wrote that in the past five years, its line of notebooks "have realized a 30 per cent reduction in&nbsp;[failure] rates as measured by the industry standard metric of Annualized Failure Rates (AFR)."</p>  <p>And by that same metric, the failure rate is "the lowest it has been in the company's history."</p>  <p>As for repairability, the company noted that some of its products are highly rated on iFixit's reparability scale. The California company is a well-known advocate for the right to repair.</p>  <h2>Tablets are a 'bad investment,' says expert</h2>  <p>When it comes to tablets, Gordon-Byrne said people should save their money.&nbsp;</p>  <p>She said they're often made with a lot of glue, which makes them difficult to take apart and repair. Add to that, right to repair advocates say manufacturers usually don't grant consumers and most repair shops, other than certified dealers,&nbsp;access to parts, repair instructions and software. Both impede successful repair, making them "a bad investment," Gordon-Byrne said.</p>  <p>When it comes to market share of tablets, Apple dominates the market at more than 75 per cent of sales, followed by Samsung at 17 per cent.</p>  <p>Bellhouse said iPads have broken down the least compared to all other brands.</p>  <p>The survey, which has a 1.7 per cent margin of error 19 out of 20 times, also had 201 respondents from Canada's North, which is also one of the toughest spots …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881">https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881</link>
            <guid isPermaLink="false">hacker-news-small-sites-25702727</guid>
            <pubDate>Sat, 09 Jan 2021 18:05:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Log Pattern Recognition: LogMine]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25702314">thread link</a>) | @Sayrus
<br/>
January 9, 2021 | https://sayr.us/log-pattern-recognition/logmine/ | <a href="https://web.archive.org/web/*/https://sayr.us/log-pattern-recognition/logmine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>When retrieving logs from an application, you are often looking for outliers
(such as a unique error) or what pattern occurs the most. However, defining
patterns manually is time-consuming and requires rigour across projects. In
this series of blog posts, we are going to explore automated Log Pattern
Recognition.</p>

<h2 id="why">Why</h2>

<p>I recently began using <a href="https://docs.datadoghq.com/logs/explorer/patterns/">Datadog Log Pattern</a>
and became addicted to it. Unfortunately, I was not able to find such a feature on
Kibana or a query proxy able to do this analysis. If that does not exist, I
might as well learn more about it and make one!</p>

<p>To my surprise, I did not find as many papers as I thought I would. And the
number of papers with public implementations is even lower. Our series begins
with a paper called <a href="https://www.cs.unm.edu/~mueen/Papers/LogMine.pdf">LogMine: Fast Pattern Recognition for Log Analytics</a>
and <a href="https://github.com/trungdq88/logmine">an implementation made by Tony Dinh</a>
that helped me a lot to study LogMine’s behavior.</p>

<p>To my surprise, I searched for anything related to LogMine on Hacker News
and only found Tony Dinh’s submission.</p>

<h2 id="defining-the-terms-used-in-this-article">Defining the terms used in this article</h2>

<p>Some terms used in this article can have several meanings. In Logmine’s context,
the terms I use mean:</p>
<ul>
  <li><code>log</code>: a log line (<code>string</code>)
    <div><div><pre><code>12:00:00 - My awesome log
</code></pre></div>    </div>
  </li>
  <li><code>pattern</code>: Expression extracted by the algorithm (array of <code>field</code>)
    <div><div><pre><code>[&lt;date&gt;, "-", "My", "awesome", "log"]
</code></pre></div>    </div>
  </li>
  <li><code>field</code>: Part of a <code>pattern</code> / Word from a <code>log</code> (Either a fixed value, a wildcard or a <code>variable</code>)</li>
  <li><code>cluster</code>: represents a group of logs that were identified as close to each
others</li>
  <li><code>variable</code>: a user-provided regex used to identify a known format
    <div><div><pre><code>number = \d+
time = \d{2}:\d{2}:\d{2}
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="an-introduction-to-logmine">An introduction to LogMine</h2>

<p>The LogMine paper describes a method to parse logs, group them into clusters and
extract patterns without any prior knowledge or supervision. LogMine can be
implemented using MapReduce and works in a single pass over the dataset.</p>

<p>LogMine’s approach to grouping logs roughly works by:</p>
<ol>
  <li>Parsing logs into patterns</li>
  <li>Grouping patterns into clusters if the <a href="#clustering">distance</a> between them is small</li>
  <li>Merging clusters into a single pattern</li>
  <li>Repeat from step 2 until you are satisfied</li>
</ol>

<p>LogMine classifies fields into three categories:</p>
<ul>
  <li><code>Fixed value</code>, a field that is constant across all logs in a cluster. This is
detected at the pattern extraction step.</li>
  <li><code>Variable</code>, a field that matches a pattern provided by the user. This is
detected at the pre-processing step.</li>
  <li><code>Wildcard</code>, a field that is not constant across all logs in a cluster. This is
detected at the pattern extraction step.</li>
</ul>

<p>Let’s illustrate how it works, step by step, using three simple logs:</p>

<div><div><pre><code>10:00:00 - [DEBUG] - User 123 disconnected
10:30:00 - [DEBUG] - User 123 disconnected
11:11:11 - [ERROR] - An error occurred while disconnecting user 456
12:12:12 - [DEBUG] - User 789 disconnected
</code></pre></div></div>

<p>We will also define a variable <code>&lt;time&gt;</code> that follows the pattern
<code>\d{2}:\d{2}:\d{2}</code>.</p>

<div>
  <p><strong>Note</strong></p>

  <p>A good practice would be to define more variables to avoid forming two clusters
from logs with low similarity. For instance, we <strong>should</strong> define <code>&lt;number&gt;</code>
as <code>\d+</code>.</p>

  <p>Depending on the pattern of your logs, defining a common field like <code>&lt;log-level&gt;</code>
as <code>[(DEBUG|INFO|WARNING|ERROR)]</code> might end up hiding information. This is
because a <code>WARNING</code> log with an error message might not be that important yet
the same log message with an <code>ERROR</code> level might have the exact information
you would like to highlight.</p>
</div>

<h3 id="log-parsing-and-dense-clusters-identification">Log parsing and dense clusters identification</h3>

<p>The first step is to parse logs into patterns and identify dense clusters. Dense
clusters are clusters where <strong>raw logs are almost identical</strong>.</p>

<p>To do this, we begin by splitting logs into patterns (an array of field). The
separator used by default is any whitespace character.</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Field_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Field_2</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Field_3</annotation></semantics></math></span></span></th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">Field_n</annotation></semantics></math></span></span></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10:00:00</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>10:30:00</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>11:11:11</td>
      <td>-</td>
      <td>[ERROR]</td>
      <td>-</td>
      <td>An</td>
      <td>error</td>
      <td>occurred</td>
      <td>while</td>
      <td>…</td>
    </tr>
    <tr>
      <td>12:12:12</td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>789</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<p>Next, we will tokenize the logs and identify variables (regex provided by the
user).</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Field_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Field_2</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Field_3</annotation></semantics></math></span></span></th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mi>i</mi><mi>e</mi><mi>l</mi><msub><mi>d</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">Field_n</annotation></semantics></math></span></span></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>123</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[ERROR]</td>
      <td>-</td>
      <td>An</td>
      <td>error</td>
      <td>occurred</td>
      <td>while</td>
      <td>…</td>
    </tr>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td>-</td>
      <td>[DEBUG]</td>
      <td>-</td>
      <td>User</td>
      <td>789</td>
      <td>disconnected</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<p>I stopped at the word <code>while</code> for readability reasons, but there’s no limit to
the number of fields.</p>

<h4 id="identifying-dense-clusters">Identifying dense clusters</h4>

<p>Once this transformation is done, we will reduce these patterns into dense
clusters. Identifying dense clusters can be seen as a special use-case of the
clustering algorithm: we identify clusters but <strong>we skip the pattern extraction
step as these patterns are nearly identical</strong>.</p>

<p>As such, I’ll first introduce the clustering algorithm and the notion of
distance between patterns.</p>

<h3 id="grouping-patterns-into-clusters">Grouping patterns into clusters</h3>

<p>The clustering algorithm takes a list of patterns and identifies patterns that
are close to each other. Both the Tony Dinh’s implementation and the paper uses
the distance defined as:</p>

<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Dist</mtext><mo stretchy="false">(</mo><mi>P</mi><mo separator="true">,</mo><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mtext>Min</mtext><mo stretchy="false">(</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></munderover><mfrac><mrow><mtext>Score</mtext><mo stretchy="false">(</mo><msub><mi>P</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>Q</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mtext>Max</mtext><mo stretchy="false">(</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>P</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>len</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{Dist}(P,Q) = 1 -
\sum_{i=1}^{\text{Min}(\text{len}(P),\text{len}(Q))}{\frac{\text{Score}(P_i,Q_i)}{\text{Max}(\text{len}(P),\text{len}(Q))}}</annotation></semantics></math></span></span></span></p><p>With P and Q, two patterns.</p>

<p>If the distance between the two patterns is inferior to a threshold <code>MaxDist</code>
defined internally, then the two patterns are considered a member of the same
cluster.</p>

<div>
  <p>This comparison process can be optimized by skipping unnecessary work if the
sum is already greater than our <code>MaxDist</code>.</p>

  <p>This is valid because the elements inside the sum can’t be negative.</p>
</div>

<p>The scoring function proposed in the paper allows for tweaking weights depending
on the field type.</p>

<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Score</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.3599999999999999em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>k</mi><mn>1</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>=</mo><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>and&nbsp;both&nbsp;are&nbsp;fixed&nbsp;values</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>k</mi><mn>2</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if&nbsp;</mtext><mi>x</mi><mo>=</mo><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>and&nbsp;both&nbsp;are&nbsp;variable</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{Score}(x, y) =
\begin{cases}
  k1 &amp;\text{if } x=y &amp;\text{and both are fixed values}\\
  k2 &amp;\text{if } x=y &amp;\text{and both are variable} \\
  0 &amp;\text{otherwise}
\end{cases}</annotation></semantics></math></span></span></span></p><p>In order to keep performance, the scoring function can’t return a negative
value. Therefore <code>k1</code> and <code>k2</code> can’t be negative.</p>

<div>
  <p><strong>Note</strong></p>

  <p>The definition of this scoring function seems to have left some place for interpretation:</p>
  <ul>
    <li>Tony Dinh’s implementation <a href="https://github.com/trungdq88/logmine/blob/a7595c6a0b313b43969199c18465cc8bec3b57d1/src/line_scorer.py#L29">checks for equality</a>
if both value are fixed values.</li>
    <li><a href="https://github.com/logpai/logparser/blob/master/logparser/LogMine/LogMine.py">LogPai’s LogParser</a> dropped the concept of variables and uses k2 to tune wildcards weight</li>
  </ul>

</div>

<p>Let’s define <code>k1=1</code> and <code>k2=1</code>, these are the weight used by Tony Dinh’s
implementation and recommended by the original paper.</p>

<h4 id="applying-the-clustering-algorithm">Applying the clustering algorithm</h4>

<p>For this example, I will use the original paper recommendation (<code>MaxDist=0.01</code>).
The MaxDist parameter is used to tune the algorithm sensitivity: the higher
<code>MaxDist</code>, the more patterns are detected.
If <code>MaxDist</code> is too high, patterns are grouped into very large clusters and
pattern extraction become meaningless.</p>

<table>
  <thead>
    <tr>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">Log_2</annotation></semantics></math></span></span></th>
      <th>Score</th>
      <th>Sum (Total)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[DEBUG]</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>4</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{4}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>User</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>5</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{5}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>123</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>6</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{6}{7}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>disconnected</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{7}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>7</mn><mn>7</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{7}{7}</annotation></semantics></math></span></span></td>
    </tr>
  </tbody>
</table>

<p>The two logs belong to the same cluster as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mfrac><mn>7</mn><mn>7</mn></mfrac><mo>&lt;</mo><mtext>MaxDist</mtext></mrow><annotation encoding="application/x-tex">1 - \frac{7}{7} &lt; \text{MaxDist}</annotation></semantics></math></span></span>.</p>

<table>
  <thead>
    <tr>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th>Fields from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">Log_3</annotation></semantics></math></span></span></th>
      <th>Score</th>
      <th>Sum (Total)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[ERROR]</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>2</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{2}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{11}</annotation></semantics></math></span></span></td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>An</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>error</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>occurred</code></td>
      <td>0</td>
      <td><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>3</mn><mn>11</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{3}{11}</annotation></semantics></math></span></span></td>
    </tr>
  </tbody>
</table>

<p>The two logs do not belong to the same cluster as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mfrac><mn>3</mn><mn>11</mn></mfrac><mo>&gt;</mo><mtext>MaxDist</mtext></mrow><annotation encoding="application/x-tex">1 - \frac{3}{11} &gt; \text{MaxDist}</annotation></semantics></math></span></span>.</p>

<div>
  <p><strong>Note</strong></p>

  <p>As we are using <code>MaxDist=0.01</code>, and since the logs in my example are very short,
we will only identify logs that are identical. For this reason, <strong>we can use the
clustering algorithm to identify dense clusters</strong> by skipping the pattern
recognition step.</p>
</div>

<h3 id="pattern-detection">Pattern detection</h3>

<p>In sequential (as opposed to MapReduce) mode, each time a pattern is inserted
in a cluster, LogMine will try to extract patterns from them. LogMine knows
only how to identify two types:</p>
<ul>
  <li>Fixed values</li>
  <li>Wildcards</li>
</ul>

<p>While it seems rather strict, remember that the early pattern detection during
tokenization already took care of identifying user-defined patterns.</p>

<div>
  <p>Generating the pattern each time a new pattern is added allows LogMine to only
keep one representative for each cluster. This is a very important factor to
reduce memory usage.</p>

  <p><strong>MapReduce behavior is described later in this article.</strong></p>
</div>

<p>As patterns in the same cluster can have a different number of fields, the paper
uses the <a href="https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm">Smith-Waterman</a>
algorithm to align them. The Smith-Waterman is mainly used in Bioinformatics to
align sequences. It is interesting to see an algorithm like this applied to
log pattern recognition.</p>

<p>Once the two patterns are aligned, we compare one by one the field:</p>
<ul>
  <li>If the value is equal, we assign a fixed value</li>
  <li>If the value is different, we assign a wildcard pattern</li>
</ul>

<p>The Smith-Waterman algorithm adds placeholders to align logs. These placeholders
are <strong>never equal</strong> to a field value. This means that aligned parts of a log are
always identified as wildcards.</p>

<p>The output of the pattern detection algorithm is a <strong>new list of patterns</strong>.</p>



<p>Let’s assume that the previous algorithm identified a cluster with two patterns:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 789 disconnected
</code></pre></div></div>

<p>To stay consistent with how they were presented earlier, we will call them
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">Log_4</annotation></semantics></math></span></span>.</p>

<table>
  <thead>
    <tr>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">Log_1</annotation></semantics></math></span></span></th>
      <th><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>o</mi><msub><mi>g</mi><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">Log_4</annotation></semantics></math></span></span></th>
      <th>Result</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
      <td><code>&lt;time&gt;</code></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>[DEBUG]</code></td>
      <td><code>[DEBUG]</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>-</code></td>
      <td><code>-</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>User</code></td>
      <td><code>User</code></td>
      <td><code>Fixed value</code></td>
    </tr>
    <tr>
      <td><code>123</code></td>
      <td><code>456</code></td>
      <td><code>Wildcard</code></td>
    </tr>
    <tr>
      <td><code>disconnected</code></td>
      <td><code>disconnected</code></td>
      <td><code>Fixed value</code></td>
    </tr>
  </tbody>
</table>

<h4 id="result-of-applying-the-smith-waterman-algorithm">Result of applying the Smith-Waterman algorithm</h4>

<p>Because examples in this article would have gotten very complex, I decided to
not use non-aligned logs in my examples. However, you might be curious as to how
the Smith-Waterman works.</p>

<p>On the implementation, LogMine would have aligned the two following patterns by
adding a <code>None</code> value in a field. For instance:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 123 has disconnected
</code></pre></div></div>
<p>would become:</p>
<div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 &lt;None&gt; disconnected
&lt;time&gt; - [DEBUG] - User 123 has disconnected
</code></pre></div></div>

<div>
  <p><strong>The Smith-Waterman does not understand patterns</strong>. The Smith-Waterman uses
the same scoring function as the clustering algorithm. As such, if two fields
are not equal, there is no guarantee that the placeholder will be inserted
properly.</p>

  <p>If we tweak our previous example to:</p>
  <div><div><pre><code>&lt;time&gt; - [DEBUG] - User 123 disconnected
&lt;time&gt; - [DEBUG] - User 456 has disconnected
</code></pre></div>  </div>

  <p>The Smith-Waterman algorithm would transform it to:</p>
  <div><div><pre><code>&lt;time&gt; - [DEBUG] - User &lt;None&gt; 123 disconnected
&lt;time&gt; - [DEBUG] - User 456 has disconnected
</code></pre></div>  </div>

  <p>The alignment was added <strong>before</strong> the user identifier.</p>
</div>

<h3 id="repeat-until-satisfied">Repeat until satisfied</h3>

<p>As the pattern extraction algorithm returns a list of patterns, we can relax
<code>MaxDist</code> and feed this list back into the clustering algorithm.</p>

<p>In <strong>3.4 Hierarchy of Patterns</strong>, the paper describes a process to generate a
hierarchy of possible patterns from very strict to …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sayr.us/log-pattern-recognition/logmine/">https://sayr.us/log-pattern-recognition/logmine/</a></em></p>]]>
            </description>
            <link>https://sayr.us/log-pattern-recognition/logmine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25702314</guid>
            <pubDate>Sat, 09 Jan 2021 17:30:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Readable Bash Scripts]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25702062">thread link</a>) | @mooreds
<br/>
January 9, 2021 | https://brianschiller.com/blog/2021/01/07/readable-bash-scripts | <a href="https://web.archive.org/web/*/https://brianschiller.com/blog/2021/01/07/readable-bash-scripts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <div>
        <article>
          <p>I really love the feeling of writing a bash pipeline. It’s fun to string commands together, peek at the output, add another couple pipes to massage the data closer to my goal. I even gave a short class on them: <a href="https://github.com/bgschiller/shell-challenges">bgschiller/shell-challenges</a>.</p>

<p>But it’s easy to find that a pipeline that was delightful to write is painful to maintain. Even if you’re the one reading it a month later, it’s difficult to remember what the purpose of each piece is. This is a trick I learned to break pipelines into intermediate files for more readable scripts.</p>

<h3 id="the-task">The task</h3>

<p>The product I’m working on has a list of “Alarms”—conditions that the end user needs to be alerted to. We also have a localization file for each supported language that maps Alarm names to human-readable names, descriptions, etc. There are a lot of alarms, enough to make it difficult to keep track of which ones are already translated. This calls for a script!</p>

<p>The Alarms file looks something like this:</p>

<div><div><pre><code><span>&lt;!-- Alarms.xml --&gt;</span>
<span>&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span>&lt;config</span> <span>name=</span><span>"AlarmConfig"</span><span>&gt;</span>
   <span>&lt;AlarmList</span> <span>name=</span><span>"IngredientAlarms"</span> <span>version=</span><span>"1.0"</span><span>&gt;</span>
      <span>&lt;Alarm</span> <span>name=</span><span>"MozzarellaTooWarm"</span><span>&gt;</span>
        <span>&lt;!-- some alarm-specific stuff here --&gt;</span>
      <span>&lt;/Alarm&gt;</span>
      <span>&lt;Alarm</span> <span>name=</span><span>"PizzaTooCold"</span><span>&gt;</span>
      <span>&lt;/Alarm&gt;</span>
      <span>&lt;!-- ... --&gt;</span>
</code></pre></div></div>

<p>And the localization something like this:</p>

<!-- prettier-ignore -->
<div><div><pre><code><span>[{</span> <span>stringId</span><span>:</span> <span>"</span><span>alarm_id_MozzarellaTooWarm</span><span>"</span><span>,</span>
   <span>localString</span><span>:</span> <span>"</span><span>MozzarellaTooWarm</span><span>"</span> <span>},</span>
 <span>{</span> <span>stringId</span><span>:</span> <span>"</span><span>alarm_title_MozzarellaTooWarm</span><span>"</span><span>,</span>
   <span>localString</span><span>:</span> <span>"</span><span>Mozzarella Too Warm</span><span>"</span> <span>},</span>
 <span>{</span> <span>stringId</span><span>:</span> <span>"</span><span>alarm_description_MozzarellaTooWarm</span><span>"</span><span>,</span>
   <span>localString</span><span>:</span> <span>"</span><span>The mozzarella has become too warm and must be used within the next five minutes</span><span>"</span> <span>},</span>
  <span>//...</span>
<span>]</span>
</code></pre></div></div>

<h3 id="make-a-plan">Make a plan</h3>

<ol>
  <li>Extract the alarms names from Alarms.xml using <code>xpath</code>.</li>
  <li>Each alarm needs to be prefixed with <code>alarm_id_</code>, <code>alarm_title_</code>, <code>alarm_description_</code>, <code>alarm_operator_actions_</code> in order to match the localization file. Figure out some way to do that.</li>
  <li>Extract the <code>"stringId"</code> from each entry in the localization file. Oh, but there are other entries for things that need to be localized, and aren’t alarms at all. Figure out a way to filter those out. Probably use <code>jq</code> for that.</li>
  <li>Use <code>diff</code> to compare the expected keys with the actual keys.</li>
</ol>

<p>This isn’t a post on how to make bash pipelines, so I’ll gloss over that piece. Here’s what I came up with:</p>

<div><div><pre><code>diff <span>\</span>
  &lt;<span>(</span><span>join</span> <span>-j</span> 99999 <span>\</span>
    &lt;<span>(</span><span>echo</span> <span>'alarm_id_
alarm_title_
alarm_description_
alarm_operator_actions_'</span><span>)</span> <span>\</span>
    &lt;<span>(</span>xpath <span>-q</span> <span>-e</span> config/AlarmList/Alarm/@name Alarms.xml |
      <span>cut</span> <span>-d</span><span>=</span> <span>-f2</span> | <span>tr</span> <span>-d</span> <span>'"'</span><span>)</span> <span>\</span>
    | <span>tr</span> <span>-d</span> <span>' '</span> | <span>sort</span><span>)</span> <span>\</span>
  &lt;<span>(</span>jq <span>'.[] | select(.stringId | startswith("alarm_")) |
        .stringId '</span> i18n/en.json | <span>sort</span><span>)</span>
</code></pre></div></div>

<p>It’s convoluted and kinda impressive in that way. But not code you’d be happy to maintain.</p>

<h3 id="one-step-at-a-time">One step at a time</h3>

<p>The prior step accomplished what we needed, but it was pretty difficult to see what was going on. In my opinion, that’s because</p>

<ul>
  <li>Nothing has a name. Because each process substitution is fed directly into a parent, nothing ever receives a name. We need to name our intermediates!</li>
  <li>No comments. It’s difficult to add comments because every line ends in a backslash, meaning “continue this line as if I hadn’t pressed enter”. Bash doesn’t allow you to say “continue this line” and also add a comment.</li>
</ul>

<p>Let’s see if we can tease out each part using intermediate files.</p>

<div><div><pre><code><span>cat</span> <span>&gt;</span> alarm_attrs <span>&lt;&lt;</span> <span>EOF</span><span>
alarm_id_
alarm_title_
alarm_description_
alarm_operator_actions_
</span><span>EOF

</span>xpath <span>-q</span> <span>-e</span> config/AlarmList/Alarm/@name Alarms.xml |
  <span>cut</span> <span>-d</span><span>=</span> <span>-f2</span> | <span>tr</span> <span>-d</span> <span>'"'</span> <span>&gt;</span> expected_alarm_names

<span>join</span> <span>-j</span> 999 alarm_attrs expected_alarm_names |
  <span>tr</span> <span>-d</span> <span>' '</span> | <span>sort</span> <span>&gt;</span> expected_localization_keys

jq <span>-r</span> <span>'.[] | select(.stringId | startswith("alarm_")) |
       .stringId'</span> en.json | <span>sort</span> <span>&gt;</span> actual_localization_keys
</code></pre></div></div>

<p>This is better! Each piece can be understood in isolation, and the dependencies between steps are explictly tracked with named files. All that’s left is to add comments and some error checking, and clean up our intermediate files.</p>

<p>Cleaning up after ourselves is a little tricky. Ideally, we’d like to avoid leaving the intermediate results files laying around regardless of whether the script exits normally, crashes, or is cancelled with ctrl-c. We can use <code>trap</code> to handle this. <code>trap</code> sets up a command to run when a “signal” occurs. We’ll put all our intermediate files into a directory and use <code>trap</code> to delete that directory when a signal that indicates our script is ending fires.</p>

<div><div><pre><code><span>#!/bin/bash</span>

<span>set</span> <span>-ef</span> <span>-o</span> pipefail

<span>readonly </span><span>script_name</span><span>=</span><span>`</span><span>basename</span> <span>"</span><span>$0</span><span>"</span><span>`</span>
usage<span>()</span> <span>{</span>
  <span>cat</span> <span>&gt;</span>&amp;2 <span>&lt;&lt;</span> <span>EOF</span><span>
Usage: </span><span>$script_name</span><span> &lt;path-to-Alarms.xml&gt; &lt;path-to-en.json&gt;

  Compare the alarms specified in Alarms.xml against the
  localizations keys provided in a [language-code].json file
  (eg, en.json). Warn if any keys are missing or unexpected.
</span><span>EOF
</span>  <span>exit </span>2
<span>}</span>

<span>if</span> <span>[[</span> <span>$# </span><span>!=</span> 2 <span>]]</span><span>;</span> <span>then
   </span><span>echo</span> <span>"error: expected 2 arguments, received $#"</span> 1&gt;&amp;2
   usage
<span>fi

</span><span>readonly </span><span>ALARM_CONFIG_XML</span><span>=</span><span>$1</span>
<span>if</span> <span>[[</span> <span>${</span><span>ALARM_CONFIG_XML</span>:<span> -4</span><span>}</span> <span>!=</span> <span>".xml"</span> <span>||</span> <span>!</span> <span>-e</span> <span>$ALARM_CONFIG_XML</span> <span>]]</span><span>;</span> <span>then
   </span><span>echo</span> <span>"error: unable to find XML file at </span><span>$ALARM_CONFIG_XML</span><span>"</span> 1&gt;&amp;2
   usage
<span>fi
</span><span>readonly </span><span>LOCALIZATION_JSON</span><span>=</span><span>$2</span>
<span>if</span> <span>[[</span> <span>${</span><span>LOCALIZATION_JSON</span>:<span> -5</span><span>}</span> <span>!=</span> <span>".json"</span> <span>||</span> <span>!</span> <span>-e</span> <span>$LOCALIZATION_JSON</span> <span>]]</span><span>;</span> <span>then
   </span><span>echo</span> <span>"error: unable to find JSON file at </span><span>$LOCALIZATION_JSON</span><span>"</span> 1&gt;&amp;2
   usage
<span>fi</span>

<span># Make a directory for intermediate results</span>
<span>tmpdir</span><span>=</span><span>$(</span><span>mktemp</span> <span>-d</span> <span>-p</span> .<span>)</span>
<span># ensure it's removed when this script exits</span>
<span>trap</span> <span>"rm -rf </span><span>$tmpdir</span><span>"</span> EXIT HUP INT TERM
<span># note: when debugging, turn off that `trap` line to keep</span>
<span># intermediate results around</span>

<span># The plan is ultimately to use diff to compare names between</span>
<span># Alarms.xml and en.json. diff will tell us if any names</span>
<span># appear in one file but are missing in the other (checks</span>
<span># both directions for a mismatch).In pursuit of this, we need</span>
<span># to create a couple of temporary files:</span>
<span>#  1) all the alarm names we expect to find (based on Alarms.xml)</span>
<span>#  2) all the names actually present in the localization file.</span>
<span># A complication: the location file uses a flat format to</span>
<span># store the id, title, description, and operator_actions:</span>
<span>#   { "stringId": "alarm_id_MozzarellaTooWarm", ... },</span>
<span>#   { "stringId": "alarm_title_MozzarellaTooWarm", ... },</span>
<span>#   { "stringId": "alarm_description_MozzarellaTooWarm", ... },</span>
<span>#   { "stringId": "alarm_operator_actions_MozzarellaTooWarm", ... },</span>
<span># We want to check that *all* of these keys are present, so</span>
<span># we use a cross product of (alarm names) X (those attributes)</span>

<span>cat</span> <span>&gt;</span> <span>$tmpdir</span>/alarm_attrs <span>&lt;&lt;</span> <span>EOF</span><span>
alarm_id_
alarm_title_
alarm_description_
alarm_operator_actions_
</span><span>EOF

</span>xpath <span>-q</span> <span>-e</span> config/AlarmList/Alarm/@name <span>$ALARM_CONFIG_XML</span> |
 <span>cut</span> <span>-d</span><span>=</span> <span>-f2</span> | <span>tr</span> <span>-d</span> <span>'"'</span> <span>&gt;</span> <span>$tmpdir</span>/expected_alarm_names

<span># trick to compute cross product: use `join` with a join</span>
<span># field that doesn't exist (999). since both files lack a</span>
<span># field at 999, they will compare equal for every key, and</span>
<span># each line of the left file will be joined with each line</span>
<span># of the right file--a cross product.</span>
<span>join</span> <span>-j</span> 999 <span>$tmpdir</span>/alarm_attrs <span>$tmpdir</span>/expected_alarm_names |
<span>tr</span> <span>-d</span> <span>' '</span> | <span>sort</span> <span>&gt;</span> <span>$tmpdir</span>/expected_localization_keys

jq <span>-r</span> <span>'.[] | select(.stringId | startswith("alarm_")) |
       .stringId'</span> <span>$LOCALIZATION_JSON</span> |
  <span>sort</span> <span>&gt;</span> <span>$tmpdir</span>/actual_localization_keys

<span>if </span>diff <span>$tmpdir</span>/expected_localization_keys <span>$tmpdir</span>/actual_localization_keys<span>;</span> <span>then
   </span><span>echo</span> <span>"Success! Found all"</span> <span>$(</span><span>wc</span> <span>-l</span> <span>$tmpdir</span>/expected_localization_keys<span>)</span> <span>"expected localization keys"</span>  1&gt;&amp;2
<span>else
   </span><span>echo</span> <span>"Failure. Found discrepancies between expected alarm names and actual localization keys"</span> 1&gt;&amp;2
   <span>exit </span>1
<span>fi</span>
</code></pre></div></div>

        </article>

        
        
        
        

      </div>
    </div></div>]]>
            </description>
            <link>https://brianschiller.com/blog/2021/01/07/readable-bash-scripts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25702062</guid>
            <pubDate>Sat, 09 Jan 2021 17:03:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Marxist Analysis of the iPhone (2019)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25702019">thread link</a>) | @moigagoo
<br/>
January 9, 2021 | http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html | <a href="https://web.archive.org/web/*/http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><b>Workers who make iPhones in the 21st century</b>, are twenty-five times more exploited than textile workers in England in the 19th century. Based on a marxist analysis, the current&nbsp;<i>rate of exploitation </i>is&nbsp;2458%.</span></p><div>
<p><span><span><b>W</b></span></span>e are interested in looking at the production
of the iPhone – a commodity – through the
framework of a Marxist analysis. We are interested not in being angry at Apple and Foxconn
alone, but in being able to measure how much
workers are exploited to produce this commodity. In other words, we are interested in measuring <b>the rate of exploitation</b>.</p><p>

The rate of exploitation is one of the most
important concepts in Marx’s theory. This
measurement allows us to show how much the
worker contributes to the increase of value in
the production process. It shows that even if the
worker is paid more, by the special magic of
mechanisation and of efficient management of
the production process, the rate of exploitation
increases. The rate expresses quantitatively the
contradictory interests of the capitalists and of
the workers. There is a radical politics implicit in
the analysis of the rate of exploitation. It enables workers to see how much of the share of
the value produced is appropriated from them
by the capitalists, and to therefore make the
case for a different way to organise production
and to end exploitation.</p><p>

To understand the rate of exploitation, we have
to first grasp what Marx means by the commodity itself and what he means by value, a key term
in the Marxist system of economic thought.</p><p><a href="https://1.bp.blogspot.com/-C5uknsT1Qo8/XZCEHtKcdVI/AAAAAAAAFRU/ske4yAP-_xY8lyclVj_QI14X31w008uqQCLcBGAsYHQ/s1600/book2.png" imageanchor="1"><img data-original-height="536" data-original-width="542" height="316" src="https://1.bp.blogspot.com/-C5uknsT1Qo8/XZCEHtKcdVI/AAAAAAAAFRU/ske4yAP-_xY8lyclVj_QI14X31w008uqQCLcBGAsYHQ/s320/book2.png" width="320"></a></p>
<p>
What is a commodity? Marx begins his epic
work Capital (1867) with a discussion of the
commodity. ‘A commodity’, he notes, ‘is an object outside us, a thing that by its properties
satisfies human wants of some sort or another.
The nature of such wants, whether, for instance,
they spring from the stomach or from fancy,
makes no difference. Neither are we concerned
to know how the object satisfies these wants,
whether directly as a means of subsistence, or
indirectly as means of production’. The commodity is a useful object. But it is more than a
useful thing that serves a purpose to a consumer. It is also something that can be sold – something that enables the person who has it made
to realise a profit. Inside the commodity, then, is
both <b>use value</b> and <b>value</b>.</p><p>

The use value of the commodity is merely its
utility, something that is left to the consumer.
An iPhone is a good example, because it can
be used for many things: to make a phone call,
to watch a video, to use as a compass, to hold
onto when you are feeling awkward (or even to
improve your image).</p><p><a href="https://1.bp.blogspot.com/-XSTB0AJ3dE8/XZCEcFG4l8I/AAAAAAAAFRc/zQgbE9cGZ20opRyyiarpiQQVm8vlXer2QCLcBGAsYHQ/s1600/values.png" imageanchor="1"><img data-original-height="595" data-original-width="465" src="https://1.bp.blogspot.com/-XSTB0AJ3dE8/XZCEcFG4l8I/AAAAAAAAFRc/zQgbE9cGZ20opRyyiarpiQQVm8vlXer2QCLcBGAsYHQ/s1600/values.png"></a></p>
<p>
The expression of the value of the commodity
(i.e. exchange value) is the price of the commodity. We are aware that there is a rich and
long debate amongst Marxists over the relationship between prices and the value of a
commodity. This debate is known as the transformation problem – namely the problem of the
transformation of values to prices of production. Nevertheless, for our iPhone example, we
believe that this level of concreteness need not
detain us. We are still able to capture something
significant. In the case of the iPhone X, the expression of its value is $999. The value is merely
what the commodity is able to command in
the market. But behind that price is a mass of
crystallised values, which can be grouped into
three parts of the total value: <b>constant capital</b>,
<b>variable capital,</b> and <b>surplus value</b>. These are
key concepts for Marxist analysis.</p><p>

<b><span>Constant capital</span></b></p><p>

Various raw materials are brought on to the
factory floor that are to be transformed by the
actions of labour and machines into commodities. These raw materials – and other auxiliary
materials, including the instruments of labour
(machines, tools, etc.) – have already been
fashioned from nature elsewhere. Inside these
raw materials, which are not really ‘raw’ any
longer, is embodied labour. The values of the
various raw materials and instruments of labour
are quantitatively fixed in terms of their labour
content. This fixed amount of value is now
transferred to the newly produced commodities
in the process of production. Its value enters
into the new commodities. Karl Marx calls the
values of the raw materials and the instruments
of labour <b>constant capital</b>.</p><p>

The constant capital for the iPhone includes
all of those minerals and metals that appear on the assembly line as well as the depreciated
parts of machines that work those raw materials.
These are then collectively transformed into
the iPhone. In the process of transformation,
the minerals, metals, and machines do not
alter their value. Their value is preserved in the
iPhone. The value remains constant.</p><p>

At the end of the process of production, the
total transferred value of those means of production – the raw materials, the machines, the
buildings – cannot be more than what they
originally contained in themselves. Their value,
which remains constant, is preserved in the
iPhone.</p><p><a href="https://1.bp.blogspot.com/-Q_pB4fCgz5I/XZCFCPeC69I/AAAAAAAAFRo/PocXIl65lesBDVnMU7IPnoRo6THryPOjwCLcBGAsYHQ/s1600/capital.png" imageanchor="1"><img data-original-height="579" data-original-width="378" src="https://1.bp.blogspot.com/-Q_pB4fCgz5I/XZCFCPeC69I/AAAAAAAAFRo/PocXIl65lesBDVnMU7IPnoRo6THryPOjwCLcBGAsYHQ/s1600/capital.png"></a></p>
<p>

<b><span>Variable capital.</span></b></p><p>

The capitalist firm makes an initial investment in
the production process:</p><ul>
<li>Wages and salaries for workers.</li>
<li>Expenses on all non-human inputs, notably
tools, machinery, buildings, energy, and so
on.</li>
</ul><p>
The latter expense – the expense on all non-human inputs – is known as <b>constant capital</b>, as
explained above.</p><p>

The former expense – the expense on wages
and salaries – is known as variable capital.
To simplify our calculation, we assume that all
workers are productive in the Marxist sense
(namely, that they produce surplus value and
do not merely distribute surplus value – as do
‘unproductive’ workers, such as those who are
involved in trade).</p><p>

In the capitalist system, people are ‘free’ in two
ways. They are free from bondage and free to
starve. The freedom from bondage and from
the means to feed themselves forces people to sell their capacity to labour to those with capital
(land or money). What the person sells is not
themselves (since they are free from bondage),
but they sell their labour power in exchange
for wages. The wages correspond to a certain
amount of money – representing a certain
amount of value – that is necessary to satisfy the
consumption needs of the workers.</p><p>

Marx called labour power <i>a peculiar commodity</i>. Like other commodities, this one must have
two aspects – a use value and a value. Wages
are the <b>exchange value</b> of labour power,
whereas labour is the use value of labour power. This distinction between the use value of
labour power and the exchange value of labour
power is fundamental to a Marxist understanding of surplus value and its production.</p><p>

In a given working day, workers transform
their capacity to labour into an act of labour.
Their various skills are utilised to transform raw materials and machines into commodities.</p><blockquote>
 Workers produce more value than they are paid in wages. This extra value is called&nbsp;<b>surplus value</b>.</blockquote><p>
During the working day and given the conditions of work, the total amount of value produced by the workers exceeds what is needed
for their own consumption and reproduction.
The value they require for their consumption
and reproduction – represented in wages – is
only a part of the value that they make during
the working day.</p><p>

Workers produce more value than they are
paid in wages. This extra value is called
<b>surplus value</b>. If the management of labour
changes or if the machines work at a different
speed, then either more or less value is produced in a day, which means that the surplus
value can be increased (or decreased). The fact
that labour power – this peculiar commodity –
has the quality of producing an extra amount of
value than what is needed for its own reproduction makes it <b>variable capital</b>.</p><p>

<b><span>Surplus Value</span></b></p><p>

The various raw materials that are on the assembly line, the machines, and the electricity that
help fashion the raw materials, would all be idle
without the necessary work of the labour power
put into the system by the workers. The workers
take the raw materials and the tools and shape
them into a commodity. It is the input of the
labour power that is crucial. Unlike any other
commodity, the labour power purchased from
the worker has to produce these new values.
When the workers tire, they go home and reproduce their labour power to be sold again.</p><p><a href="https://1.bp.blogspot.com/-JPwsXDRUiDU/XZCFarXi6jI/AAAAAAAAFRw/luib4DD_tPkBGGIdJ0FOfSFmS-HNhJOmACLcBGAsYHQ/s1600/SV.png" imageanchor="1"><img data-original-height="595" data-original-width="566" src="https://1.bp.blogspot.com/-JPwsXDRUiDU/XZCFarXi6jI/AAAAAAAAFRw/luib4DD_tPkBGGIdJ0FOfSFmS-HNhJOmACLcBGAsYHQ/s1600/SV.png"></a></p>
<p>
The workers sell their labour power for a set
amount of money. When they start to work on
the production of commodities, it takes them
only a fraction of their working day to make
enough commodities to cover their own wages.
Marx called that the <b>necessary labour time</b>. It
was ‘necessary’ because in different epochs and in different countries it takes different amounts
of goods and services to reproduce the worker’s depleted labour power. In some countries,
the standard of living is lower than that of
others, which means the necessary labour time
is also shorter. The remainder of the working
day – after the necessary labour time – is the
<b>surplus labour time</b>. It is the time that the
worker spends producing commodities that are
above and beyond the amount needed to be
produced to pay the wage bill of the worker.</p><p>

<b><span>Rate of Surplus Value</span></b></p><p>

Marx’s concept – the rate of exploitation – is
measured by using the categories of variable
capital and surplus value. Variable capital is
the share of the values produced in the process of production that goes to the workers.
Surplus value, on the other hand, is the share
of the values that goes to the capitalist. The ratio of surplus value to variable capital – or
s/v – can be seen as a quantitative expression
of the exploitation of workers, also called the
<b>rate of surplus value</b>.</p><p>

Take a hypothetical commodity whose total
value is $1,000. The constant capital is worth
$500. That capital – raw material, tools and energy – goes into the process of production and
remerges in a different form but with the value
intact. There is no change in its value. The variable capital – what the worker earns – is $250.
The surplus value – what the capitalist appropriates – is the amount of value created during
the surplus labour time, which in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html">http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html</a></em></p>]]>
            </description>
            <link>http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25702019</guid>
            <pubDate>Sat, 09 Jan 2021 16:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: End of Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25701758">thread link</a>) | @h4kor
<br/>
January 9, 2021 | https://h4kor.github.io/end-of-covid/ | <a href="https://web.archive.org/web/*/https://h4kor.github.io/end-of-covid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://h4kor.github.io/end-of-covid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25701758</guid>
            <pubDate>Sat, 09 Jan 2021 16:35:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chinese FM welcomes Elon Musk statement praising Chinese government]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25701603">thread link</a>) | @jimmy2020
<br/>
January 9, 2021 | https://www.globaltimes.cn/page/202101/1212242.shtml#.X_nTsdClAgQ.twitter | <a href="https://web.archive.org/web/*/https://www.globaltimes.cn/page/202101/1212242.shtml#.X_nTsdClAgQ.twitter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          <p>Elon Musk's praise of China's government for being 'very responsible' to its people's needs and happiness is objective: Chinese FM</p>
          
          
        </div><div>
          <div> <center><img src="https://www.globaltimes.cn/Portals/0/attachment/2021/2021-01-08/acc29ac0-e6f1-4707-acc9-d248a6631a80.jpeg"></center>
<p>Elon Musk. Photo: VCG</p><p>Chinese FM said the praise from Elon Musk to China's government for being "very responsible" to its people's needs and happiness is objective, and it is a conclusion that reflects the real situation, adding that China welcomes more foreign friends to visit and get a comprehensive, correct impression of the nation.&nbsp;</p><p>The remarks came after Elon Musk hailed China as "more responsible" than the US in an interview with Business Insider, according to express.co.uk on January 4.&nbsp;</p><p>Musk said he had a positive experience when talking to Chinese government officials during his visits to the country and said they could "possibly" be "more responsible" to their people's happiness than the US.</p><p>Anyone who is unbiased and hopes to understand the real China objectively will come to such a conclusion, which reflects the reality of China's development history over the past 100 years, and the rapid changes that are currently taking place across Chinese land, Hua Chunying, spokesperson of China's Foreign Ministry, said on Friday.&nbsp;&nbsp;</p><p>We welcome more foreign friends to visit China and gain an accurate impression of the country through close contact with Chinese people, she added.&nbsp;&nbsp;</p><p>Hua noted that, during the fight against the pandemic, everyone has also seen that the Chinese government insisted on putting people and their livelihoods first and spared no effort in protecting everyone's life, health, value and dignity.</p><p>We have also implemented the largest and most powerful battle against poverty in human history and successfully lifted 850 million people out of poverty, she added.</p><p>"This year, we have embarked on a new journey of building a modern socialist country in an all-round way. I think our Chinese people's growing needs or yearning for a better life will be further satisfied," Hua said.&nbsp;</p></div>
        </div></div>]]>
            </description>
            <link>https://www.globaltimes.cn/page/202101/1212242.shtml#.X_nTsdClAgQ.twitter</link>
            <guid isPermaLink="false">hacker-news-small-sites-25701603</guid>
            <pubDate>Sat, 09 Jan 2021 16:20:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generational References 2.3x faster than reference counting, unoptimized]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25701111">thread link</a>) | @harporoeder
<br/>
January 9, 2021 | https://vale.dev/blog/generational-references | <a href="https://web.archive.org/web/*/https://vale.dev/blog/generational-references">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
    <div>
  

        <div>
          <div>
  

          <div>
            
    
<p>2.3x faster than reference counting, unoptimized!</p>

              <p><span>Jan 5 2021</span> </p>
      
</div>
<section>
<p>
<b>Generational references</b> are a new memory management technique that's easy, deterministic, and <i>very</i> fast.
</p>

</section>
<section>
<p>
This technique is the first ingredient in Vale's final <a href="https://vale.dev/blog/hybrid-generational-memory">hybrid-generational memory</a> design, which is even faster. Our eventual goal is to be as fast as Rust, and perhaps even as fast as C++, while being safer than both. <a href="#note0" data-noteid="0">0</a>
</p>
<p>
This article explains how generational references work, how they compare to reference counting, and what makes it all so fast. <a href="#note1" data-noteid="1">1</a>
</p>

</section>
<section>
<h2 id="built-on-single-ownership">
 Built on Single Ownership</h2>
<p>
Recall that in Vale, an object is freed when its <b>owning reference</b> goes out of scope. An object always has exactly one owning reference pointing to it.
</p>
<p>
We can have as many <b>non-owning</b> references as we want. <a href="#note2" data-noteid="2">2</a>
</p>
<p>
In other languages, when a programmer frees an object and then accidentally dereferences a non-owning reference to it, it can cause memory unsafety and vulnerabilities. <a href="#note3" data-noteid="3">3</a>
</p>
<p>
Our goal is to detect this situation and react to it safely. <a href="#note4" data-noteid="4">4</a>
</p>

</section>
<section>
<h2 id="generational-malloc-and-the-sacred-integer">
 Generational Malloc and the Sacred Integer</h2>
<p>
Generational references use <b>generational malloc</b>, which is like regular malloc, except at the top of every allocation is a <b>generation number</b>, which tracks how many objects have previously been at this memory location.
</p>
<p>
One could also think of it as describing "I am the <b>n</b>th inhabitant of this memory location".
</p>
<p>
Freeing an object will increment its generation number. Nobody else ever modifies it.
</p>

</section>
<section>
<p>
Later on, we use this number to see if a particular object is still alive, explained further below.
</p>

</section>
<section>
<p>
Generational malloc would normally be an adjustment to mimalloc or jemalloc, but we can simulate it with our own <span>genMalloc</span> and <span>genFree</span> functions:
</p>
<ul>
<li>
<span>genFree</span> increments the generation number, and instead of calling <span>free</span> <a href="#note5" data-noteid="5">5</a><a href="#note6" data-noteid="6">6</a>, remembers the allocation in a free-list. There's a free-list for every size class (16b, 24b, 32b, &lt;=48b, &lt;=64b, &lt;=128b, etc).
</li>
<li>
<span>genMalloc</span> pulls from a free-list if possible. If it's empty, it calls <span>malloc</span> and initializes the generation number to 1.
</li>
</ul>
<p>
You can find our experimental implementation in <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a>.
</p>

</section>

      </div>
  
<div>

      <nav>
      <p>Generational References</p>
    


      </nav>
      
    

      <div>
        <div>
    
<div id="note0" data-noteid="0">
<p><span>0</span></p><section>
<p>
See <a href="https://vale.dev/blog/hybrid-generational-memory">HGM</a>'s afterword for a hypothetical comparison with Rust!
</p>

</section>
</div>
<div id="note1" data-noteid="1">
<p><span>1</span></p><section>
<p>
 Vale has three release modes:
</p>
<ul>
<li>
<b>Resilient:</b> Fast and 100% safe.
</li>
<li>
<b>Assist:</b> for development, detects logic problems.
</li>
<li>
<b>Unsafe:</b> turns off all safety.
</li>
</ul>
<p>
Resilient mode uses hybrid-generational memory.
</p>

</section>
</div>
<div id="note2" data-noteid="2">
<p><span>2</span></p><section>
<p>
This distinction is similar to C++'s <span>unique_ptr&lt;T&gt;</span> and <span>T*</span>.
</p>

</section>
</div>
<div id="note3" data-noteid="3">
<p><span>3</span></p><section>
<p>
Rust partially solves this, but forces complexity on the programmer and doesn't solve the <a href="https://en.wikipedia.org/wiki/ABA_problem">ABA problem</a>. We'd like a solution that's simpler, solves the whole problem, with as little <a href="https://vale.dev/blog/hybrid-generational-memory#afterword-how-might-it-compare-to-rust">run-time overhead as Rust</a>.
</p>

</section>
</div>
<div id="note4" data-noteid="4">
<p><span>4</span></p><section>
<p>
Such as by halting or stack unwinding.
</p>

</section>
</div>
<div id="note5" data-noteid="5">
<p><span>5</span></p><section>
<p>
 Our experimental implementation doesn't release memory back to the OS until exit, but when a page is empty, the final version will release the page back to the operating system and map its virtual memory to a read-only page containing all 0xFF.
</p>

</section>
</div>
<div id="note6" data-noteid="6">
<p><span>6</span></p><section>
<p>
 When an allocation's generation can't be incremented any more, it's not used again (at least until we can re-map the page).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="generational-reference-more-than-just-a-pointer">
 Generational Reference: More than just a pointer!</h2>

</section>
<section>
<p>
Vale's references are <b>generational references</b>. A generational reference has two things:
</p>
<ul>
<li>
A pointer to the object.
</li>
<li>
A "target generation" integer.
</li>
</ul>
<p>
To create a reference to an object, we get its allocation's generation number, and include it in the reference.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="dereferencing">
 Dereferencing</h3>

</section>
<section>
<p>
To dereference a generational reference, we do a "liveness check" to see whether the allocation's generation number <b>still matches</b> our reference's target generation. <a href="#note7" data-noteid="7">7</a>
</p>
<p>
This prevents use-after-free problems, and makes Vale completely memory safe.
</p>

</section>
<section>
<p>
It's as if the reference is saying:
</p>
<p><b>"Hello! I'm looking for the 11th inhabitant of this house, are they still around?"</b>
</p>

</section>
<section>
<p>
and the person who opens the door says:
</p>
<p><b>"No, sorry, I'm the 12th inhabitant of this house, the 11th inhabitant is no more."</b> <a href="#note8" data-noteid="8">8</a>
</p>
<p>
or instead:
</p>
<p><b>"Yes! That is me. Which of my fields would you like to access?"</b>
</p>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note7" data-noteid="7">
<p><span>7</span></p><section>
<p>
 This is similar to the "generational indices" technique from C++ and Rust, but applied to the entire world instead of just a specific vector.
</p>

</section>
</div>
<div id="note8" data-noteid="8">
<p><span>8</span></p><section>
<p>
 This will safely halt the program, unless the user is explicitly checking whether something is alive (such as for a weak reference).

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="speed">
 Speed</h2>

</section>
<section>
<p>
Generational references are only the first steps towards hybrid-generational memory, but we decided to run some early experiments to see how it compares to existing memory models.
</p>
<p>
For this experiment, we benchmarked <a href="#note9" data-noteid="9">9</a> <a href="#note10" data-noteid="10">10</a> three flavors of Vale:
</p>
<ul>
<li>
<b>Unsafe</b>, with no memory safety, the equivalent of C++ (minus caveats, see below!)
</li>
<li>
<b>RC</b>, where we use naive reference counting for all our objects.
</li>
<li>
<b>GM</b>, which uses generational references.
</li>
</ul>

</section>
<section>
<div>
  <table>
    <thead>
      <tr>
        <th>Mode</th>
        <th>Speed&nbsp;(seconds)</th>
        <th>Overhead Compared to Unsafe (seconds)</th>
        <th>Overhead Compared to Unsafe (%)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th>Unsafe</th>
        <td>43.82&nbsp;seconds</td>
        <td>n/a</td>
        <td>n/a</td>
      </tr>
      <tr>
        <th>RC</th>
        <td>54.90&nbsp;seconds</td>
        <td>+11.08&nbsp;seconds</td>
        <td>+25.29%</td>
      </tr>
      <tr>
        <th>GM</th>
        <td>48.57&nbsp;seconds</td>
        <td>+4.75&nbsp;seconds</td>
        <td>+10.84%</td>
      </tr>
    </tbody>
  </table>
</div>


</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note9" data-noteid="9">
<p><span>9</span></p><section>
<p>
 We used the <a href="https://github.com/ValeLang/Vale/tree/master/benchmarks/BenchmarkRL/vale">BenchmarkRL</a> terrain generator to gather these numbers, with different values for the <span>--region-override</span> flag: <span>unsafe-fast</span>, <span>naive-rc</span>, and <span>resilient-v3</span> respectively.
</p>

</section>
</div>
<div id="note10" data-noteid="10">
<p><span>10</span></p><section>
<p>
 Here, we benchmarked against other flavors of Vale, to isolate the differences between unsafe, reference-counting, and generational references.
</p>
<p>
Once we implement full hybrid-generational memory, we'll be benchmarking against C++ and Rust, stay tuned!

</p>

</section>
</div>

        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
Generational references have only 10.84% overhead, <b>less than half the cost of reference counting!</b> These are very promising results, and suggest that full hybrid-generational memory could be incredibly fast.
</p>

</section>
<section>
<p>
Try it out! In the Vale release, you can find a benchmark folder with scripts to run the benchmarks. You can find the source code for the various approaches <a href="https://github.com/ValeLang/Vale/tree/master/Midas/src/c-compiler/region">here</a> (feel free to swing by the <a href="https://discord.gg/SNB8yGH">discord server</a> and we can point you to the right files).
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
<b>Note these caveats!</b> To isolate the difference between generational references and the other approaches:
</p>
<ul>
<li>
In all flavors, we only allocate objects on the heap, except for primitives. Future versions will add stack allocations.
</li>
<li>
We used <a href="https://github.com/ValeLang/Vale/blob/master/Midas/src/builtins/genHeap.c">genHeap.c</a> for all versions, though only GM ever touches the generation number, the other versions ignore it. Future versions will integrate generational malloc into jemalloc or mimalloc directly.
</li>
</ul>
<p>
Once we address these limitations, we can get more precise benchmarks against the other approaches.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h2 id="why-is-this-so-fast">
 Why is this so fast?</h2>

</section>
<section>
<p>
Generational references are much easier for the CPU to handle than reference-counted references, because:
</p>
<ul>
<li>
Generational references have no aliasing/dealiasing overhead, just on dereference.
</li>
<li>
Generational references cause less cache misses.
</li>
<li>
Liveness checks' branching is easier to predict than RC decrements' branching.
</li>
</ul>

</section>
<section>
<p>
We explain these two differences more below.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<h3 id="no-aliasing-costs">
 No Aliasing Costs</h3>

</section>
<section>
<p>
Reference counting is costly:
</p>
<ul>
<li>
Whenever we "alias" (make a new reference to an object), we have to dereference the object to increment its counter.
</li>
<li>
Whenever we "dealias" (throw away a reference), we have to:
</li>
<ul>
<li>
Dereference the object to decrement its counter,
</li>
<li>
If the counter is zero, deallocate it.
</li>
</ul>
</ul>
<p>
For example:
</p>

    <div>
      
      <p><span><span>fn <span>launchShip</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>, <span><span><span>armada</span></span> <span>&amp;<span><span>List</span>&lt;<span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>)</span> <span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<br>    <p>  <span><span>armada</span><span>.</span><span>add</span>(<span>ship</span>)</span>;</p><p>  <br>  <br>  <br>  <br>  <br>  <br>}</p></span></span></span></p>
    </div>
  
<p>
As you can see, reference counting incurs a cost whenever we alias or dealias. <b>Generational references don't have that cost.</b> The above snippet would have zero overhead if it used generational references.
</p>

</section>

      </div>
  


    </div>
    <div>
      <div>
  
<section>
<p>
Instead, generational references incur a cost whenever we dereference an object:
</p>

    <div>
      
      <p><span><span>fn <span>getShipName</span><span>(<span><span><span>ships</span></span> <span>&amp;<span><span>Map</span>&lt;<span>int</span>, <span>&amp;<span>Spaceship</span></span>&gt;</span></span></span>, <span><span><span>id</span></span> <span>int</span></span>)</span> <span><span>str</span> </span><span>{<br>  <span><span><span><span>ship</span></span></span> = <span><span>ships</span><span>.</span><span>get</span>(<span>id</span>)</span></span>;<p>  <br>  <br>  <span>ret <span><span>ship</span><span>.</span><span>name</span></span>;</span><br>}</p></span></span></span></p>
    </div>
  

</section>
<section>
<p>
This is cheaper because <b>programs dereference less than they alias and dealias:</b> our sample program had 4.7 million counter adjustments, but only 1.3 million liveness checks. <a href="#note11" data-noteid="11">11</a> <a href="#note12" data-noteid="12">12</a>
</p>

</section>
<section>
<h3 id="more-cache-friendly">
 More Cache Friendly</h3>
<p>
Reference counting is not very "cache friendly". Adding and subtracting integers is basically free on modern CPUs, but the real bottleneck in modern programs is how <i>far</i> those integers are: if it's been recently accessed, it's in the nearby cache, and only takes a few CPU cycles to fetch. Otherwise the CPU will "cache miss" and have to bring it in all the way from RAM, which could take <b>hundreds</b> of cycles. <a href="#note13" data-noteid="13">13</a>
</p>
<p>
In our reference-counted <span>launchShip</span> example, the <span>ship.__ref_count++</span> could take a few cycles if <span>ship</span> is already in the cache, or hundreds of cycles if it's not.
</p>

</section>
<section>
<p>
Generational references are more cache friendly:
</p>
<ul>
<li>
When a generational reference goes away, we don't need to reach into memory (unlike RC, where we have to decrement a counter).
</li>
<li>
We don't need to increment when aliasing (see previous section); we don't need to reach into memory to increment.
</li>
</ul>

</section>

      </div>
  
<div>

      <div>
        <div>
    
<div id="note11" data-noteid="11">
<p><span>11</span></p><section>
<p>
 Half of these are aliasings and half are dealiasings. Aliasing happens whenever we access a member (e.g. <span>person.name</span>) or make a new reference (e.g. <span>&amp;person</span>).
</p>

</section>
</div>
<div id="note12" data-noteid="12">
<p><span>12</span></p><section>
<p>
 Many languages are able to skip a lot of the adjustments, using static analysis. For example, Lobster can remove up to 95%. Our experiment doesn't have those optimizations; it compares naive RC to naive generational references.
</p>

</section>
</div>


        </div>
      </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h3 id="better-branch-prediction">
 Better Branch Prediction</h3>
<p>
For a given if-statement, CPUs will predict whether we'll go down the "then" branch or the "else" branch. This is called …</p></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vale.dev/blog/generational-references">https://vale.dev/blog/generational-references</a></em></p>]]>
            </description>
            <link>https://vale.dev/blog/generational-references</link>
            <guid isPermaLink="false">hacker-news-small-sites-25701111</guid>
            <pubDate>Sat, 09 Jan 2021 15:31:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next Gen Static Blogging]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 174 (<a href="https://news.ycombinator.com/item?id=25701053">thread link</a>) | @mmackh
<br/>
January 9, 2021 | https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging | <a href="https://web.archive.org/web/*/https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging</link>
            <guid isPermaLink="false">hacker-news-small-sites-25701053</guid>
            <pubDate>Sat, 09 Jan 2021 15:25:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Holiday Hacking – Tracking my heart rate while playing Call of Duty]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25700872">thread link</a>) | @lukastyrychtr
<br/>
January 9, 2021 | https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/ | <a href="https://web.archive.org/web/*/https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>04 Jan 2021</span></p><p>Over the holidays, I got a <a href="https://www.polar.com/us-en/products/accessories/oh1-optical-heart-rate-sensor">Polar OH1+</a> as a Christmas present. Its an optical heart rate monitor with similar tech to those found in smart watches (including my Garmin running watch), but much more accurate (at least for running) due to being smaller &amp; lighter, as well as fitting against the fleshier upper arm:</p>

<p><img src="https://jcdav.is/public/oh1-small.jpg" alt="Polar OH1"></p>

<p>Like any modern gadget these days, it supports Bluetooth (specifically Bluetooth Low Energy, or BLE/BTLE) for talking to your phone and/or smart watch. Which got me wondering, will it pair with a computer?</p>

<p><img src="https://jcdav.is/public/bluetooth.jpg" alt="It pairs"></p>

<p>This piqued my curiosity. I had long been at least somewhat curious about tracking my heart rate while say playing video games, if nothing else for curiosity. So how easy is it to grab data from this thing? As with the last few years, I had spent a bit of December doing a bunch of <a href="https://adventofcode.com/">Advent of Code</a> in rust, only to forget and have to re-learn everything the next year. So figured I could maybe try my hand at a “real” project.</p>

<p>Some quick googling later, I found the promising-looking <a href="https://crates.io/crates/btleplug">btleplug</a> crate. Lets dump data from all nearby devices…</p>

<div><div><pre><code><span>extern</span> <span>crate</span> <span>btleplug</span><span>;</span>

<span>use</span> <span>std</span><span>::</span><span>thread</span><span>;</span>
<span>use</span> <span>std</span><span>::</span><span>time</span><span>::</span><span>Duration</span><span>;</span>

<span>#[cfg(target_os</span> <span>=</span> <span>"linux"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>bluez</span><span>::{</span><span>adapter</span><span>::</span><span>ConnectedAdapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>#[cfg(target_os</span> <span>=</span> <span>"windows"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>winrtble</span><span>::{</span><span>adapter</span><span>::</span><span>Adapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>#[cfg(target_os</span> <span>=</span> <span>"macos"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>corebluetooth</span><span>::{</span><span>adapter</span><span>::</span><span>Adapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>use</span> <span>btleplug</span><span>::</span><span>api</span><span>::{</span><span>UUID</span><span>,</span> <span>Central</span><span>,</span> <span>Peripheral</span><span>};</span>

<span>#[cfg(any(target_os</span> <span>=</span> <span>"windows"</span><span>,</span> <span>target_os</span> <span>=</span> <span>"macos"</span><span>))]</span>
<span>fn</span> <span>get_central</span><span>(</span><span>manager</span><span>:</span> <span>&amp;</span><span>Manager</span><span>)</span> <span>-&gt;</span> <span>Adapter</span> <span>{</span>
    <span>let</span> <span>adapters</span> <span>=</span> <span>manager</span><span>.adapters</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>adapters</span><span>.into_iter</span><span>()</span><span>.nth</span><span>(</span><span>0</span><span>)</span><span>.unwrap</span><span>()</span>
<span>}</span>

<span>#[cfg(target_os</span> <span>=</span> <span>"linux"</span><span>)]</span>
<span>fn</span> <span>get_central</span><span>(</span><span>manager</span><span>:</span> <span>&amp;</span><span>Manager</span><span>)</span> <span>-&gt;</span> <span>ConnectedAdapter</span> <span>{</span>
    <span>let</span> <span>adapters</span> <span>=</span> <span>manager</span><span>.adapters</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>let</span> <span>adapter</span> <span>=</span> <span>adapters</span><span>.into_iter</span><span>()</span><span>.nth</span><span>(</span><span>0</span><span>)</span><span>.unwrap</span><span>();</span>
    <span>adapter</span><span>.connect</span><span>()</span><span>.unwrap</span><span>()</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>manager</span> <span>=</span> <span>Manager</span><span>::</span><span>new</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>let</span> <span>central</span> <span>=</span> <span>get_central</span><span>(</span><span>&amp;</span><span>manager</span><span>);</span>

    <span>central</span><span>.start_scan</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>thread</span><span>::</span><span>sleep</span><span>(</span><span>Duration</span><span>::</span><span>from_secs</span><span>(</span><span>2</span><span>));</span>

    <span>for</span> <span>per</span> <span>in</span> <span>&amp;</span><span>central</span><span>.peripherals</span><span>()</span> <span>{</span>
        <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>per</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>(Note that though this part should work cross-platform, I couldn’t get bluetooth working from WSL, so this was all done natively on Windows).</p>

<p>Sure enough, among the shockingly large list of nearby devices is my new toy:</p>

<div><div><pre><code>A0:9E:1A:XX:XX:XX properties: PeripheralProperties { address: A0:9E:1A:XX:XX:XX, address_type: Public, local_name: Some("Polar OH1 XXXXXXXX"), tx_power_level: Some(-64), manufacturer_data: Some([]), discovery_count: 6, has_scan_response: true }, characteristics: {}
</code></pre></div></div>

<p>Let’s see what characteristics it supports:</p>

<div><div><pre><code>    <span>let</span> <span>ohr</span> <span>=</span> <span>central</span><span>.peripherals</span><span>()</span><span>.into_iter</span><span>()</span><span>.find</span><span>(|</span><span>p</span><span>|</span> <span>{</span>
        <span>p</span><span>.properties</span><span>()</span><span>.local_name</span><span>.map</span><span>(|</span><span>n</span><span>|</span> <span>n</span><span>.starts_with</span><span>(</span><span>"Polar OH1"</span><span>))</span>
            <span>.unwrap_or</span><span>(</span><span>false</span><span>)</span>
    <span>})</span><span>.unwrap</span><span>();</span>

    <span>ohr</span><span>.connect</span><span>();</span>
    <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>ohr</span><span>.discover_characteristics</span><span>()</span><span>.unwrap</span><span>());</span>
</code></pre></div></div>

<p>Turns out..a lot?</p>

<div><div><pre><code>[Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:00:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:01:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:04:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:A6:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:05:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:29:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:24:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:25:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:27:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:26:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:28:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:23:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:51:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE_WITHOUT_RESPONSE | WRITE | NOTIFY },
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:52:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:53:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE_WITHOUT_RESPONSE | WRITE },
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:37:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:19:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ | NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:21:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:22:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:26:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 62:17:FF:4C:C8:EC:B1:FB:13:80:3A:D9:86:70:8E:2D, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 62:17:FF:4D:91:BB:91:D0:7E:2A:7C:D3:BD:A8:A1:F3, properties: WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:81:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: READ | WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:82:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }]
</code></pre></div></div>

<p>Which of these do I want? The <a href="https://btprodspecificationrefs.blob.core.windows.net/assigned-values/16-bit%20UUID%20Numbers%20Document.pdf">Bluetooth UUID specifications</a> lists a bunch of different potentially interesting IDs, but they are all 16 bits, whereas are 128 bit. Making matters more confusing, <code>btleplug</code> ‘s UUID definition seems to allow for either:</p>

<div><div><pre><code><span>pub</span> <span>enum</span> <span>UUID</span> <span>{</span>
    <span>B16</span><span>(</span><span>u16</span><span>),</span>
    <span>B128</span><span>([</span><span>u8</span><span>;</span> <span>16</span><span>]),</span>
<span>}</span>
</code></pre></div></div>

<p>However it seems like a lot of them seem to only differ in the 3rd and 4th bytes <sup><a href="#suff1">1</a></sup>, and those to roughly correspond to GATT Characteristic Ids, and in there is a <code>2A:37</code>, which represents Heart Rate Measurement - sounds promising. Lets see if we can listen &amp; dump that data:</p>

<div><div><pre><code>    <span>let</span> <span>mut</span> <span>bytes</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>16</span><span>]</span> <span>=</span> <span>[</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x2A</span><span>,</span><span>0x37</span><span>,</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x10</span><span>,</span><span>0x00</span><span>,</span><span>0x80</span><span>,</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x80</span><span>,</span><span>0x5F</span><span>,</span><span>0x9B</span><span>,</span><span>0x34</span><span>,</span><span>0xFB</span><span>];</span>
    <span>bytes</span><span>.reverse</span><span>();</span>
    <span>let</span> <span>uuid</span> <span>=</span> <span>UUID</span><span>::</span><span>B128</span><span>(</span><span>bytes</span><span>);</span>
    <span>let</span> <span>chars</span> <span>=</span> <span>ohr</span><span>.discover_characteristics</span><span>()</span>
        <span>.expect</span><span>(</span><span>"Couldn't discover characteristics"</span><span>);</span>
    <span>let</span> <span>hr_char</span> <span>=</span> <span>chars</span><span>.iter</span><span>()</span><span>.find</span><span>(|</span><span>c</span><span>|</span> <span>c</span><span>.uuid</span> <span>==</span> <span>uuid</span><span>)</span>
        <span>.expect</span><span>(</span><span>"couldn't find HR characteristic"</span><span>);</span>

    <span>ohr</span><span>.on_notification</span><span>(</span><span>Box</span><span>::</span><span>new</span><span>(|</span><span>not</span><span>|</span> <span>{</span>
        <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>not</span><span>.value</span><span>);</span>
    <span>}));</span>
    <span>ohr</span><span>.subscribe</span><span>(</span><span>hr_char</span><span>)</span><span>.expect</span><span>(</span><span>"Couldn't subscribe"</span><span>);</span>
    <span>loop</span> <span>{</span>
    <span>}</span>
</code></pre></div></div>

<p>Endianness issues out of the way this….seems to be working?</p>

<div><div><pre><code>C:\Users\jackson\Dev\hroverlay&gt;cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.14s
     Running `target\debug\hroverlay.exe`
[0, 59]
[0, 58]
[0, 58]
[0, 59]
[0, 60]
[0, 61]
[0, 62]
</code></pre></div></div>

<p>At least that second number sure looks like a heart rate reading. To confirm this, I hopped over to the technical specifications for the Heart Rate Service (downloadable <a href="https://www.bluetooth.com/specifications/gatt/">here</a>). Sure enough, byte 0 represents various flags and byte 1 is a heart rate measurement. The spec authors have even figured out support for heart rates &gt;255 on off chance you ever slap one of these bad boys on a hummingbird:</p>

<blockquote>
  <p>3.1.1.2Heart Rate Measurement Value Field</p>

  <p>The Heart Rate Measurement Value field shall be included in the Heart Rate Measurement characteristic. While most human applications require support for only 255 bpm or less, special applications (e.g. animals) may require support for higher bpm values. If the Heart Rate Measurement Value is less than or equal to 255 bpm a UINT8 format should be used for power savings. If the Heart Rate Measurement Value exceeds 255 bpm a UINT16 format shall be used. See 3.1.1.1.1for additional requirements on the Heart Rate Value format change.</p>
</blockquote>

<p>Other potentially interesting bit flags include a way to indicate if the sensor thinks it has lost skin contact.</p>

<h2 id="displaying-things">Displaying things</h2>

<p>Now its time to figure out a UI. Faced with a <a href="https://www.areweguiyet.com/">large number of different options</a>, I ended up settling on the not-even-listed-there <a href="https://crates.io/crates/native-windows-gui">native-windows-gui crate</a> , throwing cross-platform support into the wind on the suspicion I would need easy access to the underlying win32 APIs, since it is largely just a series of nice convenience abstractions over those. Using the associated native-windows-derive macro crate, I had a basic UI setup working fairly quickly:</p>

<div><div><pre><code><span>#[derive(Default,</span> <span>NwgUi)]</span>
<span>pub</span> <span>struct</span> <span>BasicApp</span> <span>{</span>
    <span>#[nwg_control(size:</span> <span>(</span><span>300</span><span>,</span> <span>115</span><span>),</span> <span>flags:</span> <span>"WINDOW|VISIBLE"</span><span>)]</span>
    <span>#[nwg_events(OnWindowClose:</span> <span>[</span><span>BasicApp::exit]</span><span>)]</span>
    <span>window</span><span>:</span> <span>nwg</span><span>::</span><span>Window</span><span>,</span>

    <span>#[nwg_layout(parent:</span> <span>window)]</span>
    <span>grid</span><span>:</span> <span>nwg</span><span>::</span><span>GridLayout</span><span>,</span>

    <span>#[nwg_control(text:</span> <span>"--"</span><span>,</span> <span>readonly:</span> <span>true</span><span>)]</span>
    <span>#[nwg_layout_item(layout:</span> <span>grid,</span> <span>row:</span> <span>0</span><span>,</span> <span>col:</span> <span>0</span><span>)]</span>
    <span>hr</span><span>:</span> <span>nwg</span><span>::</span><span>TextInput</span><span>,</span>

    <span>#[nwg_control(parent:</span> <span>window,</span> <span>interval:</span> <span>500</span><span>,</span> <span>stopped:</span> <span>false</span><span>)]</span>
    <span>#[nwg_events(OnTimerTick:</span> <span>[</span><span>BasicApp::draw_hr]</span><span>)]</span>
    <span>timer</span><span>:</span> <span>nwg</span><span>::</span><span>Timer</span><span>,</span>
<span>}</span>

<span>impl</span> <span>BasicA…</span></code></pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/">https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/</a></em></p>]]>
            </description>
            <link>https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25700872</guid>
            <pubDate>Sat, 09 Jan 2021 15:03:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Have a Reality Problem]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25700603">thread link</a>) | @sgwil
<br/>
January 9, 2021 | https://www.chrbutler.com/we-have-a-reality-problem | <a href="https://web.archive.org/web/*/https://www.chrbutler.com/we-have-a-reality-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>
In the early 1990s, when the internet was still in its structural infancy, and its influence on broader culture was widely underestimated if not entirely unknown, Howard Rheingold already knew enough to predict where this newest technology would — and wouldn’t — take us.
</p>
<p>
These lines from Rheingold’s nearly thirty-year-old book, The Virtual Community, have been on my mind for over a decade:
</p>
<blockquote>
“What does it mean that the same hopes, described in the same words, for a decentralization of power, a deeper and more widespread citizen involvement in matters of state, a great equalizer for ordinary citizens to counter the forces of central control, have been voiced in the popular press for two centuries in reference to steam, electricity, and television? We’ve had enough time to live with steam, electricity, and television to recognize that they did indeed change the world, and to recognize that the utopia of technological millenarians has not yet materialized. An entire worldview and sales job are packed into the word progress, which links the notion of improvement with the notion of innovation, highlights the benefits of innovation while hiding the toxic side-effects of extractive and lucrative technologies, and then sells more of it to people via television as a cure for the stress of living in a technology-dominated world. The hope that the next technology will solve the problems created by the way the last technology was used is a kind of millennial, even messianic, hope, apparently ever-latent in the breasts of the citizenry. The myth of technological progress emerged out of the same Age of Reason that gave us the myth of representative democracy, a new organizing vision that still works pretty well, despite the decline in vigor of the old democratic institutions. It’s hard to give up on one Enlightenment ideal while clinging to another.” — Howard Rheingold, <a href="http://www.rheingold.com/vc/book/" target="_blank">The Virtual Community</a>
</blockquote>
<p>
When I say I’ve been thinking about this passage for over a decade, I mean that literally. <a href="https://www.chrbutler.com/ethical-technology-3">Ten years ago</a>, I reflected upon how Rheingold’s perspective had aged after, then, almost two decades. What stood out to me in 2011 was his connection between progress and economics. I noted that ideas of progress are carried by economic activity, which means that ideas that don’t easily bind to wealth-building don’t easily bind to culture. Or in other words, capitalism promotes technological change more than technology changes capitalism. That is not a good thing. And, it was as true ten years ago as it is today.
</p>
<p>
What strikes me now is how that same idea plays out within a much more developed technological culture. In 1993, Rheingold’s assessment would have probably struck the average person as <i>academic</i>. Intellectually persuasive, perhaps, but not especially relevant to day-to-day life. After all, in the year Rheingold’s book was published, there were an estimated 15 million internet users <i>worldwide</i>. That was less than half of one percent of the world’s population. Back then, they measured internet usage by file requests — that alone tells you a lot. But to be specific, those file requests had increased to an average of 400,000 a month. Total. In case you’re not sure, that is not a big number by today’s standards. It’s tiny. Today, there’d be as much point in measuring the internet in file requests as there would be in measuring a life in blinks.
</p>
<p><span>
1993</span> also happened to be the same year that the New York Times published <a href="https://www.nytimes.com/1993/12/08/business/business-technology-a-free-and-simple-computer-link.html?pagewanted=all&amp;src=pm" target="_blank">its very first story on the World Wide Web</a>! In it, Mitch Kapor (the creator of Lotus), offered this somewhat ironic quote: “For me Mosaic was a turning point. It’s like C-Span for everyone.” C-Span, of course, is “famous” for providing every American with unfettered access to governmental proceedings or, in other words, revealing how boring running a country can be.
</p>
<p>
That’s where Rheingold’s thirty-year-old assessment of the internet takes me now. We have gorged at the table of technology for long enough to be bored by even the notion of a new technological layer, but our addict’s muscle memory has us loading up our plates still. We understand the connection between technology and economy — now better than ever — and yet we see bizarre signs of dissonance everywhere. The person who virtue signals about one thing while keeping the other technological conveniences they enjoy — the ones that put neighbors out of work, fatten oligarchs, and erode meaningful boundaries throughout the world — very much in their blind spot. The person who rants about tearing down the system on a video recorded, processed, and uploaded to the system. The person who rebels against the government and shares the pictures of them doing it.
</p>
<p>
Unlike the tea party of 1773, where a hundred men dumped £9,659 worth of tea overnight so the city would wake up (literally) to see the symbol of their discontent floating in the harbor, 2021’s sedition was performed for a rapt audience in real time, with a tatooed QAnon shaman draped in animal pelts ransacking and shit-smearing the Capitol alongside wealthy Instagram influencers who flew in for the spree on their private jet. Whether they saw the rebellion as a historical act of defiance or just another batch of content for the feed is not so easy to parse. There is evidently a pretty wide and messy spectrum of participation, with those who drove in vans full of explosives, ready to zip-tie hostages and execute the Vice President on one end, and those who loitered nearby while flooding the internet with the same-old <span>MAGA</span> hat kissieface selfies on the other. And <i>somewhere</i> in there are the people who went to the trouble of printing up “Civil War” hoodies, the people who erected a massive cross and a gallows — a truly spectacular unforced error of irony — and sadly, the people who died in the brawl.
</p>
<p>
Who was rebelling and who was vlogging? Legally, it doesn’t really matter. They were one and the same this week. But when we place this moment within the longer narrative of culture, progress, and technology, I think it does and will matter quite a bit.
</p>
<p>
Rheingold lamented the common hope (“ever-latent in the breasts of the citizenry”) that technology will solve past problems without creating new ones. Of course it can’t do that. And in some respects, new problems signal progress as much as new solutions do. But when I re-read his words — “ever-latent in the breasts of the citizenry” — I think not of a hidden, concealed, existing-but-not-yet-manifest <i>hope</i>, but a hidden, concealed, existing-but-not-yet-manifest <i>reality</i> made possible by thirty years of the internet. And not just one latent reality, but as many of them as there are people who express them and agree. A clustering of <span>ID</span> and ego-born realities legitimized by the shine of a technological package and the easy endorsement of a like or share.
</p>
<p>
I wonder what sorts of defenses will be mounted in courts on behalf of the YouTubers, Twitchers, and Instagrammers who stormed the Capitol. Will it be that they didn’t know that what they were doing was wrong? That they didn’t know they were committing treason and not just creating content? Or will it be that they actually were not able to know the difference? As far-fetched as insanity pleas typically are, I wonder about future defenses that the increasing density of our filter bubbles may afford. Time will tell.
</p>
<p>
The internet has been the object of every kind of criticism and blame you can imagine. Certain corners of it more so than others. Sometimes the complaint has been that the technology gives voice to the profane. Sometimes it’s that the technology worsens inequality. Sometimes it’s our humanity we are worried about, and how using technology rewires our brains in the image of the machine. All these have had their time in the critical conversation. But what of the role technology has in simulating a reality within a reality? When it does this, it does it <i>invisibly</i> — wrapping itself around a person — without an edge or boundary that anyone can see or trace. These simulated realities create and shape minds just as the outer — the real — reality does.
</p>
<p>
It is often said that “there are two Americas,” a metaphor highlighting cultural and economic divides. But there aren’t just two Americas. There are thousands, if not millions, of Americas. Sorting the real from the simulated, the legitimate from the illegitimate, the American from the seditious, is, in theory, a job for a kind of technology. And yet, what strange, metastatic chaos future would such a technology create?
</p>
<p>
We now have a reality problem, created by a culture which has irrevocably fused with its technology. And just like any symbiosis, one cannot survive without the other.
</p>
      
  
        
      
       

       
        
     
        
    



</div></div>]]>
            </description>
            <link>https://www.chrbutler.com/we-have-a-reality-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-25700603</guid>
            <pubDate>Sat, 09 Jan 2021 14:24:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ray Tracing in pure CMake]]>
            </title>
            <description>
<![CDATA[
Score 283 | Comments 161 (<a href="https://news.ycombinator.com/item?id=25700038">thread link</a>) | @networked
<br/>
January 9, 2021 | https://64.github.io/cmake-raytracer/ | <a href="https://web.archive.org/web/*/https://64.github.io/cmake-raytracer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p>Without further ado, I present: a basic whitted ray tracer, complete with multicore rendering, written in 100% pure CMake. If you don't care about the details, and just want to see the code, you can <a href="https://github.com/64/cmake-raytracer">find it here</a>.</p>
<figure>
    <img src="https://github.com/64/cmake-raytracer/raw/master/render.png">
    <figcaption><i>Rendered in 7m23s on a i5-10210U, 8 processes</i> </figcaption>
</figure>
<p>At this point, those familiar with CMake may have some questions, so keep reading to find out how it all works.</p>

<p><strong>Good news:</strong> CMake has a <a href="https://cmake.org/cmake/help/latest/command/math.html?highlight=math"><code>math</code></a> command. <strong>Bad news:</strong> it only supports integers. If you've written a ray tracer before, you probably did it with floating point numbers. So how do you go from representing signed integers to representing something-resembling-floating-point numbers? One answer is to use <a href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic"><strong>fixed-point arithmetic</strong></a>.</p>
<p>The basic idea with fixed point is simple. We define some large integer to represent the number 1.0; let's choose <strong>1000</strong>. Then we can represent 2.0 as 2000, 0.5 as 500, -3.0 as -3000 etc. When we want to add two numbers, we simply add their fixed-point representations. Here's how that looks in CMake:</p>
<pre><span>function(add a b res)
    math(EXPR tmp </span><span>"(${</span><span>a</span><span>}) + (${</span><span>b</span><span>})"</span><span>)
    set(</span><span>"${</span><span>res</span><span>}" "${</span><span>tmp</span><span>}" </span><span>PARENT_SCOPE)
endfunction()
</span></pre>
<p>This takes two values <code>a</code> and <code>b</code> to be added and stored in the variable <code>res</code>. I use <code>PARENT_SCOPE</code> so that the variable we create is actually visible from the calling function, otherwise CMake will destroy it when the function ends.</p>
<p>To multiply two numbers, we simply multiply their fixed-point representations, and then divide by the thing we chose to represent 1.0:
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn><mo>×</mo><mn>4.0</mn><mo>↦</mo><mfrac><mrow><mn>1500</mn><mo>×</mo><mn>4000</mn></mrow><mn>1000</mn></mfrac><mo>=</mo><mn>6000</mn><mo>↦</mo><mn>6.0</mn></mrow><annotation encoding="application/x-tex">1.5 \times 4.0 \mapsto \frac{1500 \times 4000}{1000} = 6000 \mapsto 6.0</annotation></semantics></math></span></span></span></p>
<p>Division is similar:
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn><mo>÷</mo><mn>4.0</mn><mo>↦</mo><mfrac><mrow><mn>1500</mn><mo>×</mo><mn>1000</mn></mrow><mn>4000</mn></mfrac><mo>=</mo><mn>375</mn><mo>↦</mo><mn>0.375</mn></mrow><annotation encoding="application/x-tex">1.5 \div 4.0 \mapsto \frac{1500 \times 1000}{4000} = 375 \mapsto 0.375</annotation></semantics></math></span></span></span>
We could have multiplied by 1000 after doing the division, but as integer division rounds towards zero this would wipe out all our precision (as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1500</mn><mn>4000</mn></mfrac><mo>×</mo><mn>1000</mn><mo>=</mo><mn>0</mn><mo>×</mo><mn>1000</mn><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\frac{1500}{4000}\times 1000 = 0 \times 1000 = 0</annotation></semantics></math></span></span>). Multiplying first gives us better results, as long as the dividend isn't too huge (which would cause overflow).</p>
<p>CMake's <code>math</code> command only supports basic integer arithmetic. For more complicated operations, like square root, we use <a href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton-Raphson iteration</a>. You can read more about this <a href="https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method">here</a>, but the basic idea is to make a 'guess' as to what the output should be then iteratively refine the guess towards the answer. This gives a surprisingly accurate result within only three or four iterations, subject to the quality of the initial guess:</p>
<pre><span>function(sqrt x res)
    div_by_2(${x} guess)

    </span><span>foreach</span><span>(counter RANGE 4)
        </span><span>if</span><span>(${guess} EQUAL 0)
            set(</span><span>"${</span><span>res</span><span>}" </span><span>0 PARENT_SCOPE)
            return()
        </span><span>endif</span><span>()

        div(${x} ${guess} tmp)
        add(${tmp} ${guess} tmp)
        div_by_2(${tmp} guess)
    </span><span>endforeach</span><span>()

    set(</span><span>"${</span><span>res</span><span>}" "${</span><span>guess</span><span>}" </span><span>PARENT_SCOPE)
endfunction()

</span><span># sqrt(123) = 11.09072626, actual answer is 11.0905365064
</span></pre>
<p>I also implemented a similar function for computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><mi>x</mi></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{x}}</annotation></semantics></math></span></span> separately as I found that it lead to better numerical stability, as opposed to computing the square root as above and then doing the reciprocal. This comes in handy when we need to normalize vectors.</p>
<p>Almost everything in computer graphics is done with vectors, so I started implementing vector operations: <code>vec3_add</code>, <code>vec3_mul</code>, <code>vec3_div</code>, <code>vec3_dot</code> etc. These make use of CMake built-in lists, which are pretty horrible, but save me from having to use three separate variables to keep track of the individual components of each vector. For example, here's what the dot product looks like:</p>
<pre><span>function(vec3_dot x y res)
    list(GET ${x} 0 x_0)
    list(GET ${x} 1 x_1)
    list(GET ${x} 2 x_2)
    list(GET ${y} 0 y_0)
    list(GET ${y} 1 y_1)
    list(GET ${y} 2 y_2)
    mul(${x_0} ${y_0} z_0)
    mul(${x_1} ${y_1} z_1)
    mul(${x_2} ${y_2} z_2)
    add(${z_0} ${z_1} tmp)
    add(${tmp} ${z_2} tmp)
    set(</span><span>"${</span><span>res</span><span>}" </span><span>${tmp} PARENT_SCOPE)
endfunction()
</span></pre>
<p>And here's how we'd use it to normalize a vector:</p>
<pre><span>function(vec3_normalize x res)
    vec3_dot(${x} ${x} x_2)
    rsqrt(${x_2} one_over_length)
    vec3_mulf(${x} ${one_over_length} tmp)
    set(</span><span>"${</span><span>res</span><span>}" </span><span>${tmp} PARENT_SCOPE)
endfunction()
</span></pre>
<p>As well a few other bits and bobs, like <code>clamp</code> and <code>truncate</code>, that's all the arithmetic that's needed.</p>

<p>If you're new to ray tracing, I'd refer you to <a href="https://twitter.com/peter_shirley">Peter Shirley's</a> wonderful book series '<a href="https://raytracing.github.io/">Ray Tracing in One Weekend</a>', which my code is loosely based on. The general intuition is to trace rays out from the camera into the scene and see what they intersect. Since we represent all our scene geometry and rays as mathematical objects, computing intersections between rays and geometry is just a case of solving equations. Once we have found an intersection, we compute the color of the point we intersected with, which may itself be computed by tracing rays towards light sources or towards other scene geometry.</p>
<figure>
    <img src="https://developer.nvidia.com/sites/default/files/pictures/2018/RayTracing/ray-tracing-image-1.jpg">
    <figcaption><i>The ray tracing algorithm.</i>  Credit: <a href="https://developer.nvidia.com/discover/ray-tracing">https://developer.nvidia.com</a></figcaption>
</figure> 
<p>To keep it simply I went with a simple scene consisting of a sphere sitting atop an infinite plane in a checkerboard color. I also ended up faking the shadow underneath the sphere, simply drawing a black circle (well done if you spotted it from the image). I had implemented whitted ray tracing and even path tracing at one point, but they were much more complicated and performed a lot worse for the same result. In theory, though, there's no reason why I couldn't do it properly, it would just require some additional effort and patience.</p>
<p>Here's what the main 'trace' function looks like, with some of the unnecessary bits stripped out for clarity:</p>
<pre><span># Traces a ray into the scene, computes the color returned along the ray
</span><span>function(trace ray_origin ray_dir depth color)
    </span><span># Base case for recursion
    </span><span>if</span><span>(${depth} GREATER_EQUAL 3)
        return()
    </span><span>else</span><span>()
        math(EXPR depth </span><span>"${</span><span>depth</span><span>} + 1"</span><span>)
    </span><span>endif</span><span>()

    </span><span># Calculate intersection points with the sphere and plane
    </span><span>sphere_intersect(${ray_origin} ${ray_dir} hit_t_1 hit_point_1 hit_normal_1)
    plane_intersect(${ray_origin} ${ray_dir} hit_t_2 hit_point_2 hit_normal_2)

    </span><span># Did we hit the sphere?
    </span><span>if</span><span>(${hit_t_1} GREATER ${ray_epsilon})
        </span><span># Calculate reflected ray direction
        </span><span>offset_origin(hit_point_1 hit_normal_1 new_origin)
        vec3_dot(hit_normal_1 ${ray_dir} scalar)
        mul_by_2(${scalar} scalar)
        vec3_mulf(hit_normal_1 ${scalar} refl_a)
        vec3_sub(${ray_dir} refl_a new_dir)

        </span><span># Recursively trace the new ray into the scene
        </span><span>trace(new_origin new_dir ${depth} traced_col)

        </span><span># Calculate contribution from lights
        </span><span>set(col 0 0 0)
        light_contrib(hit_point_1 hit_normal_1 light1_pos light1_col out_col1)
        light_contrib(hit_point_1 hit_normal_1 light2_pos light2_col out_col2)
        vec3_add(col out_col1 col)
        vec3_add(col out_col2 col)
        vec3_add(col traced_col col)

        set(base_col ${sphere_color})
        vec3_mul(base_col col col)

    </span><span># Did we hit the plane?
    </span><span>elseif</span><span>(${hit_t_2} GREATER ${ray_epsilon})
        </span><span># ...snip: Use equation of a circle to fake shadow, if we're within range
        # ...snip: Calculate checkerboard pattern
    </span><span>else</span><span>()
        </span><span># We hit nothing, return black
        </span><span>set(col 0 0 0)
    </span><span>endif</span><span>()

    set(</span><span>"${</span><span>color</span><span>}" </span><span>${col} PARENT_SCOPE)
endfunction()
</span></pre>
<p>When I started, I wouldn't sure if it would be possible to do in pure CMake, but with a little trickery we can manage it.</p>
<p>For <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> processes, the basic plan is to divide up the image vertically and let each sub-process render a few rows. We can invoke sub-processes with the <a href="https://cmake.org/cmake/help/v3.0/command/execute_process.html"><code>execute_process</code></a> command, passing arguments (such as the worker index) via <code>-D</code>. Each process then spits their row data into a text file, which gets merged together by the master process once they've all finished.</p>
<p>One subtlety is that as we need all the sub-processes to run in parallel, we can't simply call <code>execute_process</code> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> times, as it would run them sequentially. Luckily, we can specify multiple processes to run simultaneously in one command (I think this is intended to be used for long chains where one program is piped into the next), but in order to avoid hardcoding <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> we have to programmatically construct the call to <code>execute_process</code> with CMake's <a href="https://cmake.org/cmake/help/git-stage/command/cmake_language.html"><code>EVAL CODE</code></a> feature (thanks to <a href="https://github.com/martty/vuk">martty</a> for this idea):</p>
<pre><span>message(STATUS </span><span>"Launching ray tracer with ${</span><span>num_procs</span><span>} processes, ${</span><span>image_width</span><span>}x${</span><span>image_height</span><span>} image..."</span><span>)

set(exec_command </span><span>"execute_process(</span><span>\n</span><span>"</span><span>)
</span><span>foreach</span><span>(worker_index RANGE 1 ${num_procs})
    set(exec_command </span><span>"${</span><span>exec_command</span><span>}COMMAND cmake . -Wno-dev -Dworker_index=${</span><span>worker_index</span><span>} -Dimage_width=${</span><span>image_width</span><span>} -Dimage_height=${</span><span>image_height</span><span>} -Dnum_procs=${</span><span>num_procs</span><span>}</span><span>\n</span><span>"</span><span>)
</span><span>endforeach</span><span>()
set(exec_command </span><span>"${</span><span>exec_command</span><span>} )"</span><span>)

</span><span># Begin the worker processes
</span><span>cmake_language(EVAL CODE ${exec_command})

message(STATUS </span><span>"Finished ray tracing, gathering results..."</span><span>)
</span></pre>
<p>As per <a href="https://raytracing.github.io/">Ray Tracing in One Weekend</a>, I use the <a href="https://en.wikipedia.org/wiki/Netpbm#PPM_example">PPM image format</a>. This is a really simple text-based format which is perfect for my purposes as I don't have to bother with compression. Once we're done rendering we simply read all the data that the workers have spat out, write the PPM header, and print everything to <code>stderr</code>:</p>
<pre><span>set(image_contents </span><span>"P3 ${</span><span>image_width</span><span>} ${</span><span>image_height</span><span>}</span><span>\n</span><span>255</span><span>\n\n</span><span>"</span><span>)

</span><span>foreach</span><span>(worker_index RANGE 1 ${num_procs})
    file(READ </span><span>"worker-${</span><span>worker_index</span><span>}.txt" </span><span>file_contents)
    set(image_contents </span><span>"${</span><span>image_contents</span><span>}${</span><span>file_contents</span><span>}"</span><span>)
</span><span>endforeach</span><span>()

message(</span><span>"${</span><span>image_contents</span><span>}"</span><span>)
</span></pre>
<p>The division of work among the worker processes is pretty sub-optimal as the rows towards the top of the image are mostly empty whereas the rows at the bottom are entirely full, which means that some processes finish very fast while others take much longer. Fixing this problem is left as an exercise to the reader.</p>

<p>If you made it this far, thanks for reading! Feel free to create issues, send pull requests or star <a href="https://github.com/64/cmake-raytracer">the code on GitHub</a>.</p>

    </div>

    
    

    

    
        
            
              
        
    
</article></div>]]>
            </description>
            <link>https://64.github.io/cmake-raytracer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25700038</guid>
            <pubDate>Sat, 09 Jan 2021 13:04:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Masks Off for TheDonald.win]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25700030">thread link</a>) | @some_furry
<br/>
January 9, 2021 | https://soatok.blog/2021/01/09/masks-off-for-thedonald-win/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2021/01/09/masks-off-for-thedonald-win/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>In 2015, a subreddit called /r/The_Donald was created. This has made a lot of people very angry and widely been regarded as a bad move.</p>



<p>Roughly 5 years after its inception, the Reddit staff banned /r/The_Donald because it was a cesspool of hateful content and harmful conspiracy theories. You can learn more about it <a href="https://www.vikingsecblog.com/dumping-the-donald/">here</a>.</p>



<h2>Why are we talking about this in 2021?</h2>



<p>Well, <em>a lot has happened</em> in the first week of the new year. A lot of words have been written about the fascist insurrection that attempted a coup on the U.S. legislature, so I won’t belabor the point more than I have to.</p>



<p>But as it turns out: The shitty people who ran /r/The_Donald didn’t leave well enough alone when they got shit-canned.</p>



<div><figure><img loading="lazy" data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" width="512" height="512" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Remember: You can’t recycle fash.<br>(Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>Instead, they spun up a Reddit clone under the domain <code>thedonald.win</code> and hid it behind CloudFlare.</p>



<p>Even worse: Without Reddit rules to keep them in check, they’ve gone all in on political violence and terrorism.</p>



<p>(<strong>Content Warning</strong>: Fascism, political violence, and a myriad of other nastiness in the Twitter thread below.)</p>



<figure><div>

</div></figure>



<p>If you remember last year, I published a blog post about <a href="https://soatok.blog/2020/05/09/how-to-de-anonymize-scam-knock-off-sites-hiding-behind-cloudflare/">identifying the real server IP address from email headers</a>. This is far from a sophisticated technique, but if simple solutions work, why not use them?</p>



<p>(Related, I wrote a post in 2020 about <a href="https://soatok.blog/2020/11/12/deplatforming-hate-and-harassment/">more effectively deplatforming hate and harassment</a>. This knowledge will come in handy if you find yourself needing to stop the spread of political violence, but is strictly speaking not relevant to the techniques discussed on this page.)</p>



<h2 id="unmasking-thedonald.win">Unmasking TheDonald.win</h2>



<p>The technique I outlined in <a href="https://soatok.blog/2020/05/09/how-to-de-anonymize-scam-knock-off-sites-hiding-behind-cloudflare/">my previous post</a> doesn’t work on their Reddit clone software: Although it asks you for an (optional) email address at the time of account registration, it never actually emails you, and there is no account recovery feature (a.k.a. “I forgot my password”).</p>



<div><figure><img data-attachment-id="1388" data-permalink="https://soatok.blog/soatoktelegrams2020-12/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-12.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-12" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-12.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-12.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-12.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-12.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-12.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-12.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Foiled immediately! What’s a furry to do?<br>(Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p><strong>However, their software is still a Reddit clone!</strong></p>



<p>Reddit has this feature where you can submit links and it will helpfully fetch the page title for you. It looks like this:</p>



<div><figure><img data-attachment-id="2387" data-permalink="https://soatok.blog/2021/01/09/masks-off-for-thedonald-win/reddit-post/" data-orig-file="https://soatok.files.wordpress.com/2021/01/reddit-post.png" data-orig-size="566,655" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="reddit-post" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2021/01/reddit-post.png?w=259" data-large-file="https://soatok.files.wordpress.com/2021/01/reddit-post.png?w=566" src="https://soatok.files.wordpress.com/2021/01/reddit-post.png?w=566" alt="" srcset="https://soatok.files.wordpress.com/2021/01/reddit-post.png 566w, https://soatok.files.wordpress.com/2021/01/reddit-post.png?w=130 130w, https://soatok.files.wordpress.com/2021/01/reddit-post.png?w=259 259w" sizes="(max-width: 566px) 100vw, 566px"><figcaption>When I paste a URL into this form, it automatically fetches the title.</figcaption></figure></div>



<p>How this feature works is simple: They initiate an HTTP request server-side to fetch the web page, parse out the title tag, and return it.</p>



<p>So what happens if you control the server that their request is being routed to, and provide a unique URL?</p>



<div><figure><img data-attachment-id="2389" data-permalink="https://soatok.blog/thedonald-access-logs/" data-orig-file="https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png" data-orig-size="1044,239" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="thedonald-access-logs" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png?w=300" data-large-file="https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png?w=580" src="https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png?w=1024" alt="" srcset="https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png?w=1024 1024w, https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png?w=150 150w, https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png?w=300 300w, https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png?w=768 768w, https://soatok.files.wordpress.com/2021/01/thedonald-access-logs.png 1044w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Leaking TheDonald.win’s true IP address from behind CloudFlare.</figcaption></figure></div>



<p>Well, that was easy! To eliminate false positives, I performed all of this sampling with Tor Browser and manually rebuilt the Tor Circuit multiple times, and always got the same IP address: <strong><code>167.114.145.140</code></strong>.</p>



<h4>An Even Lazier Technique</h4>



<p><strong><a href="https://www.shodan.io/search?query=thedonald.win">Just use Shodan</a>, lol</strong></p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">more redteam tricks: <a href="https://twitter.com/shodanhq?ref_src=twsrc%5Etfw">@shodanhq</a> results usually hold TLS cert information and HTTP-&gt;HTTPS redirect Location headers that can disclose information about a server hiding behind CF's network. most admins do not use the protections that exist at cloudflare to avoid that</p>— ʀǟʀɛƈօɨʟ (@_rarecoil) <a href="https://twitter.com/_rarecoil/status/1347768188017143808?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote></div>
</div></figure>



<p>Apparently chuds are really bad at OpSec, and their IP was exposed on Shodan this whole time.</p>



<div><figure><img data-attachment-id="121" data-permalink="https://soatok.blog/soatok_stickerpack-snicker/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-snicker.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Hehe" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-snicker.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-snicker.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-snicker.png?w=512" alt="Soatok Laughing" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-snicker.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-snicker.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-snicker.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>You can’t help but laugh at their incompetence.<br>(Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<h3>The Road to Accountability</h3>



<p>Okay, so we have their real IP address. What can we do with it?</p>



<p>The easiest thing to do is find out who’s hosting their servers, with a simple WHOIS lookup on their IP address.</p>



<div><figure><img data-attachment-id="2403" data-permalink="https://soatok.blog/2021/01/09/masks-off-for-thedonald-win/thedonald-whois/" data-orig-file="https://soatok.files.wordpress.com/2021/01/thedonald-whois.png" data-orig-size="468,229" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="thedonald-whois" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2021/01/thedonald-whois.png?w=300" data-large-file="https://soatok.files.wordpress.com/2021/01/thedonald-whois.png?w=468" src="https://soatok.files.wordpress.com/2021/01/thedonald-whois.png?w=468" alt="" srcset="https://soatok.files.wordpress.com/2021/01/thedonald-whois.png 468w, https://soatok.files.wordpress.com/2021/01/thedonald-whois.png?w=150 150w, https://soatok.files.wordpress.com/2021/01/thedonald-whois.png?w=300 300w" sizes="(max-width: 468px) 100vw, 468px"></figure></div>



<p>Hosted by OVH Canada, eh? After all, nothing screams “Proud American” like hosting your website with a French company in a Canadian datacenter.</p>



<div><figure><img data-attachment-id="1389" data-permalink="https://soatok.blog/soatoktelegrams2020-13/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-13.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-13" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-13.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-13.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-13.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-13.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-13.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-13.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Dunking on these fools for the inconsistencies in their worldview is self-care and I recommend it, even though I know they don’t care one iota about hypocrisy.</figcaption></figure></div>



<p>I immediately wondered if their ISP was aware they were hosting right-wing terrorists, so I filed an innocent <a href="https://www.ovh.com/world/abuse/">abuse report</a> with details about how I obtained their IP address and the kind of behavior they’re engaging in. Canada’s laws about hate speech and inciting violence are <a href="https://www.cbc.ca/news/canada/toronto/your-ward-news-james-sears-sentenced-1.5256452">comparably strict</a>, after all.</p>



<p>I’ll update this post later if OVH decides to take action.</p>



<h2>Lessons to Learn</h2>



<p>First, don’t tolerate violent political extremists, or you’ll end up with political violence on your hands. <strong><a href="https://www.vice.com/en/article/bjbp9d/do-social-media-bans-work">Deplatforming works</a>.</strong></p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Bringing back this gem:</p><p>If you're a Nazi, and you're fired, it's your fault. 👏👏<br>If you're a Nazi, and you're fired, it's your fault. 👏👏<br>If you were spotted in the mob, and you lost your fucking job. <br>You're a Nazi, you've been fired, it's your fault. 👏👏</p></div>— 🐰Witchie 🧶💜 (@witchiebunny) <a href="https://twitter.com/witchiebunny/status/1347624481318166528?ref_src=twsrc%5Etfw">January 8, 2021</a></blockquote></div>
</div><figcaption>It’s catchy!</figcaption></figure>



<p>Second, and most important: Online privacy is hard. Hard enough that bigots, terrorists, and seditious insurrectionists can’t do it right.</p>



<p>This bears emphasizing: None of the techniques I’ve shared on the history of my blog are particularly clever or novel. But they work extremely well, and they’re useful for exposing shitty people.</p>



<p>Remember: Sunlight is the best disinfectant.</p>



<p>Conversely: Basic OSINT isn’t hard; merely tedious.</p>



<h3>Other Techniques (from Twitter)</h3>



<p>Subdomain leaks (via @z3dster):</p>



<figure><div>

</div></figure>



<p>Exploiting CloudFlare workers (via @4dwins):</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">When they limit the origin to the CDN range you can sometimes get around it using a proxy in a Cloudflare worker. For Akamai you can spin up a distribution on Azure for cheap they resell.</p>— Jack Nutt (@4dwins) <a href="https://twitter.com/4dwins/status/1347809701291937792?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote></div>
</div></figure>



<p>DNS enumeration (via @JoshFarwell):</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">DNS enumeration is also your friend. The main DNS record might point to cloudflare but there may be other domain names that point directly to the origin. Dev versions of the site, etc</p>— ジョシュさん (@JoshFarwell) <a href="https://twitter.com/JoshFarwell/status/1347840751720304641?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote></div>
</div></figure>



<p>If the site in question is running WordPress, you <a href="https://blog.nem.ec/2020/01/22/discover-cloudflare-wordpress-ip/">can use Pingbacks to get WordPress to cough up the server IP address</a>. If you aren’t sure if something runs WordPress, here’s the lazy way to detect that: view any page’s source code and see if the string <code>/wp-content</code> shows up in any URLs (especially for CSS). If it’s found, you’re probably dealing with WordPress.</p>



<p>Gab’s (another platform favored by right-wing extremists) IP address discovered through their Image Proxy feature to be <code>216.66.0.222</code> (via @kubeworm):</p>



<figure><div>

</div></figure>



<h2 id="noticed">The Alt-Right Notices this Blog Post</h2>



<p>Shortly after I posted this online, some users from thedonald.win noticed this blog post and hilarity ensued.</p>



<figure><div>

</div><figcaption>The <a href="https://twitter.com/SoatokDhole/status/1348204577154326528">entire Twitter thread</a> is worth a read.</figcaption></figure>



<p>I want to make something clear in case anyone (especially members of toxic Trump-supporting communities) is confused:</p>



<p>What’s published on this page <em>isn’t</em> doxing, nor do I have any interest in doxing people. That’s the job of law enforcement, not furry bloggers who sometimes write about computer topics. And law enforcement definitely doesn’t need my help: When you create an account, you must solve a ReCAPTCHA challenge, which sends an HTTP request directly to Google servers–which means law enforcement could just subpoena Google for the IP address of the server, even if the above leaks were all patched.</p>



<p>This also isn’t the sort of thing I’d ever <em>brag</em> about, since the entire point I’ve been making is <strong>what I’ve done here isn’t technically challenging</strong>. If I wanted to /flex, I’d just talk more about my work on <a href="https://github.com/soatok/constant-time-js">constant-time algorithm implementations</a>.</p>



<p>If, in response to my abuse report, OVH Canada determines that their website isn’t violating OVH’s terms of service, then y’all have nothing to worry about.</p>



<p>But given the amount of rampant hate speech being hosted in Canadian jurisdiction, I wouldn’t make that bet.</p>



<hr>



<p>Header art by <a href="https://twitter.com/kazunekomori">Kyume</a>.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2021/01/09/masks-off-for-thedonald-win/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25700030</guid>
            <pubDate>Sat, 09 Jan 2021 13:02:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Authoritarianism Through Coding: Signal]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25699993">thread link</a>) | @m3rcury
<br/>
January 9, 2021 | https://www.oyd.org.tr/en/articles/signal/ | <a href="https://web.archive.org/web/*/https://www.oyd.org.tr/en/articles/signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>
    
     
      
    <p>This isn’t a theoretical piece about freedom and digital technologies. This is a real ongoing trend that is at best observed around secure messaging application Signal by Open Whisper Systems and it’s founder Moxie Merlinspike. His view and management of Signal reflects a wider trend that jepordises world’s freedom.</p>
<p>Signal is a secure messaging software that has changed the field a lot. Signal is built upon propriety software Textsecure and RedPhone applications that had been developed by Merlinspike and his co-founder Stuart Anderson. When Twitter acquired Whisper Systems, it releases both software under free software licenses. Merlinspike left Twitter acquired Whisper Systems, founded Open Whisper Systems and merged -once the private property of himself- TextSecure and Redphone into Signal.</p>
<p>Signal is free software. “Free as in freedom”, their client and server code is licenced under GPLv3 and AGPLv3. This makes the code and only the code itself pro-freedom. Just because the code it self free does not necessarily make the coder “free” as well and that is the problem we face today!</p>
<p>Open Whisper Systems led by Moxie Merlinspike, who is behind Signal, is and was never behind freedom. This has been seen in the light of LibreSignal (<a href="https://github.com/LibreSignal/LibreSignal/issues/37#issuecomment-217211165">https://github.com/LibreSignal/LibreSignal/issues/37#issuecomment-217211165</a>) debate where a fork of Signal client is build without unfree dependencies and published on the F-droid free software repository on Android. After much debate about federation, the claimed server resources and freedom, followed by legal trademark threats Libresignal has been removed from F-droid and so was anybody’s chance of using Signal as a secure messenger who doesn’t use Google services. <a href="https://wire.com/en/blog/axolotl-proteus-encryption-protocols/">Wire</a> case is just another example.</p>
<p>This approach is not only a threat to free software it is a recurring threat to human kind!</p>
<p>To prove this bold claim one needs to look at one recent blog post from Open Whisper Systems and a presentation made in 36C3 by Merlinspike.</p>
<p><a href="https://signal.org/blog/the-ecosystem-is-moving/">Signal’s blog post</a>
<a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">Matrix’s blog Post</a></p>
<p>The main points of his claims can be listed as follows:</p>
<ul>
<li>Decentralized systems are harder to build</li>
<li>Decentralized systems are harder to evolve</li>
<li>Decentralized systems are harder to secure</li>
<li>Decentralized systems are becoming concentrated in predominant provider anyways</li>
<li>If users don’t trust their app provider they have the freedom to use something else</li>
</ul>
<p>While his claims are true up to a certain point they are only superficial. Through these points Merlinspike claims that, centralized services are superior in modern times!</p>
<p><a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">anyone who is interested in the depth of this debate can start reading Martix’s answer to Merlinspike at the link here</a></p>
<p>It is really unnecessary to explain in depth why this type of thinking is dangerous when a simple change in words can tell more than 1000 page work. Let’s rename the object and compare his digital dystopia with one that has occured several times through-out analog human history and which once again recures today;</p>
<ul>
<li>Democracies are harder to build</li>
<li>Democracies are harder to improve</li>
<li>Democracies are harder to secure</li>
<li>In democracies power is becoming concentrated in predominant hands anyways</li>
<li>If people do not like their democracy provider (country) they have the freedom to leave and go another provider.</li>
</ul>
<p>One doesn’t need to think hard to see what Merlinspike is advising. He claims democracies suck because of the hardships of human organization and proposes autocracy to manage the world in favour of the helpless people occupying it. Why? Because democracies are inefficient and people don’t want that!</p>
<p>If he had given the same statement about democracies and governmental politics as he gave about federative systems it would have provoked outrage! People died for freedom, they are still dying and struggling around the globe. Then someone comes and stomps over every ideal which human society ever build up until this point in history and proclaims themselves the world leader! Think about it!</p>
<p>The example given is bad but why are Merlinspike’s claims about decentralized systems not considered bad as well? Because digital freedom has not yet been lost and won by blood or are we still asleep? Just because code is free, it doesn’t necessarily mean that the coders mind is also free! Freedom is not just a license, it is an ideal in any condition that we must stand for!</p>

    
        <hr>



    
  </article>
  
</div></div>]]>
            </description>
            <link>https://www.oyd.org.tr/en/articles/signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699993</guid>
            <pubDate>Sat, 09 Jan 2021 12:56:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell is a Bad Programming Language (2020)]]>
            </title>
            <description>
<![CDATA[
Score 337 | Comments 297 (<a href="https://news.ycombinator.com/item?id=25699574">thread link</a>) | @fpoling
<br/>
January 9, 2021 | https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#👾 | <a href="https://web.archive.org/web/*/https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#👾">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#👾</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699574</guid>
            <pubDate>Sat, 09 Jan 2021 11:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Source for Helm chart that uses Ansible to set up a hardened WordPress]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25699544">thread link</a>) | @jhabdas
<br/>
January 9, 2021 | https://code.habd.as/comfusion/WordPress | <a href="https://web.archive.org/web/*/https://code.habd.as/comfusion/WordPress">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="count_prompt">You can not select more than 25 topics</span>
			<span id="format_prompt">Topics must start with a letter or number, can include dashes ('-') and can be up to 35 characters long.</span>
		</p><div>
	
	<div>
		<div>
			
				
<p>This is a WordPress repository configured to run on the <a href="https://kubernetes.io/" rel="nofollow">Kubernetes platform</a>. It's a fork of Pantheon's WordPress fork modified to remove the Pantheon-specific source code. Use it as a base for a hardened WordPress installation created via Ansible using <a href="https://code.habd.as/mirrors/wordpress-helm" rel="nofollow">wordpress-helm</a>.</p>
<p>Pantheon is a website platform optimized and configured to run high performance sites and then ransom those sites back to their customers when traffic rises due to popularity. This fork is intended to empower Pantheon <a href="https://www.chicagoganghistory.com/announcements/im-back/" rel="nofollow">customers stuck with a ransom note</a> to self-host instead.</p>
<p><a href="https://code.habd.as/comfusion/WordPress/media/branch/default/grafana.png" rel="nofollow"><img src="https://code.habd.as/comfusion/WordPress/media/branch/default/grafana.png" alt="grafana"></a></p>
<h2 id="user-content-comparisons">Comparisons</h2>
<p>Comparing Pantheon and Kubernetes.</p>
<h3 id="user-content-monthly-price">Monthly price</h3>
<p>Pantheon is a good value when visitor count is under 25K per month. After that value quickly diminishes:</p>
<table>
<thead>
<tr>
<th>Monthly Visitors</th>
<th>Pantheon</th>
<th>Kubernetes</th>
</tr>
</thead>
<tbody>
<tr>
<td>25K–50K</td>
<td>$160†</td>
<td>$30‡</td>
</tr>
<tr>
<td>50K–150K</td>
<td>$275†</td>
<td>$30‡</td>
</tr>
<tr>
<td>150K–300K</td>
<td>$550†</td>
<td>Unknown</td>
</tr>
<tr>
<td>300K+</td>
<td>$916†</td>
<td>Unknown</td>
</tr>
</tbody>
</table>
<p>† Pantheon offers preferred pricing when paid annually. The charges are $114, $206, $412 and $687 respectively.</p>
<p>‡ Beware of monthly bandwidth limitations imposed by cloud-hosting providers such as <a href="https://habd.as/go/digitalocean" rel="nofollow">DigitalOcean</a> and <a href="https://habd.as/go/vultr" rel="nofollow">Vultr</a>. Some providers offer unlimited bandwidth while others do not. Choosing the right one for you will depend on your specific requirements.</p>
<h3 id="user-content-features">Features</h3>
<p>Comparison of features between Pantheon starter plan and wordpress-helm:</p>
<table>
<thead>
<tr>
<th>Pantheon</th>
<th>Kubernetes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Varnish</td>
<td>—</td>
</tr>
<tr>
<td>–</td>
<td>Redis</td>
</tr>
<tr>
<td>Apache Solr</td>
<td>—</td>
</tr>
<tr>
<td>Nginx</td>
<td>Apache</td>
</tr>
<tr>
<td>PHP-FPM</td>
<td>PHP Redis</td>
</tr>
<tr>
<td>MySQL</td>
<td>MariaDB (Replicated)</td>
</tr>
<tr>
<td>PhantomJS</td>
<td>—</td>
</tr>
<tr>
<td>—</td>
<td>Ansible</td>
</tr>
<tr>
<td>WP Cron</td>
<td>K8s CronJob + MU Cron</td>
</tr>
<tr>
<td>WP Mail</td>
<td>—</td>
</tr>
<tr>
<td>Easy backups</td>
<td>Backups automated</td>
</tr>
<tr>
<td>Drush API</td>
<td>Root shell</td>
</tr>
</tbody>
</table>
<p>As you can see you need to give up some things in order to migrate to Kubernetes. What you lose you gain back in the form of control. Items may be added to or removed from the stack as needed.</p>
<h2 id="user-content-getting-started">Getting Started</h2>
<h3 id="user-content-1-spin-up-a-free-site-on-pantheon">1. Spin-up a free site on Pantheon</h3>
<p>If you do not yet have a Pantheon account, you can create one for free. Once you've verified your email address, you will be able to add sites from your dashboard. Choose "WordPress" to use the upstream distribution of this fork.</p>
<h3 id="user-content-2-load-up-the-site">2. Load up the site</h3>
<p>When the spin-up process is complete, you will be redirected to the site's dashboard. Click on the link under the site's name to access the Dev environment.</p>
<h3 id="user-content-3-run-the-wordpress-installer">3. Run the WordPress installer</h3>
<p>How about the WordPress database config screen? No need to worry about database connection information as that is taken care of in the background. The only step that you need to complete is the site information and the installation process will be complete.</p>
<h3 id="user-content-4-wait-for-ransom-note">4. Wait for ransom note</h3>
<p>Pantheon has a tendency to change their pricing model every couple of years. When you eventually get a ransom note after getting backed into a corner begin your migration to Kubernetes.</p>
<h3 id="user-content-5-begin-migration-to-kubernetes">5. Begin migration to Kubernetes</h3>
<p>The entire migration process should take about a week or so for an experienced developer. Full migration instructions <a href="https://habd.as/post/move-pantheon-wordpress-site-kubernetes/" rel="nofollow">are available</a> without fee.</p>
<h3 id="user-content-6-profit">6. Profit!</h3>
<p><a href="https://source.unsplash.com/rwfISioESQM" rel="nofollow"><img src="https://source.unsplash.com/rwfISioESQM" alt="profit"></a></p>

			
		</div>
	</div>
</div></div>]]>
            </description>
            <link>https://code.habd.as/comfusion/WordPress</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699544</guid>
            <pubDate>Sat, 09 Jan 2021 11:33:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep neck flexor exercises – Back and neck]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 116 (<a href="https://news.ycombinator.com/item?id=25699510">thread link</a>) | @whereistimbo
<br/>
January 9, 2021 | https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html | <a href="https://web.archive.org/web/*/https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainContent">
	<div>
        <div id="leftCol_normal">

<h2>Deep neck flexor exercises</h2>
<br>
<h3>Why train them?</h3>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_1.jpg"></p><p>The deep neck flexor muscles sit deep in the front of the neck, behind the trachea (windpipe). Because of their close proximity to the vertebrae (spine) and their short length, they have an important role in providing stability to the neck. People with a history of neck or upper back injury, such as whiplash, can show great improvement in pain and function if they strengthen these muscles. Those with postural neck pain often have weakness in these muscles and overuse in the muscles on the top of the shoulders. They too can show a great response to retraining the deep neck flexor muscle group.
</p><br>

<h3>How do I exercise them?</h3>
<h5>Exercise 1</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_2.jpg"></p><ul>
<li>Lie on your back with knees comfortably bent. Find your neutral spine position, as explained by your physiotherapist. Use a small rolled towel under the head if needed.</li>
<li>Lift your head off the towel and feel the muscles on the front of the neck. These are NOT the deep neck flexor muscles - these muscles often overwork to try and help with stability, they are not designed for this purpose.</li>
<li>Perform a small nodding movement, as if to look towards your toes. Don't lift your head up. You should not feel the muscles on the front of the neck moving, but rather you should be using the muscles deep behind them.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 2</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_3.jpg"></p><ul>
<li>Position as above.</li>
<li>Place your hand on the side of your head and provide gentle resistance, as if you are bending your head to one side.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
<li>Use hand to resist small rotation movement.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 3</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_4.jpg"></p><ul>
<li>Lie on your tummy with hands supporting the forehead.</li>
<li>Perform the small nodding movement and float the head and breastbone off the floor.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 4a:</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_5.jpg"></p><ul>
<li>Stand with your back to the wall and your feet slightly in front, hip width apart. Perform the small nodding movement, while sliding the base of the skull up the wall. You should feel the neck lengthen.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 4b:</h5>

<ul>
<li>Same as exercise above.</li>
<li>From the lengthened position, move your head away from the wall so that you're looking at the floor.</li>
<li>Then return to the starting position.</li>
<li>Do not allow your chin to poke forward through either movement.</li>
</ul>

<h5>Exercise 4c:</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_8.jpg"></p><ul>
<li>Sitting in a chair, look up at the ceiling.</li>
<li>When returning the head back to the neutral position, do not let the chin poke forward.</li>
<li>Curl forward one level at a time, starting from the top.</li>
<li>Do not allow your chin to poke forward.</li>
</ul>
<br>

<h3>Where do I go from here?</h3>
<p>
Once you have mastered these exercises, you should feel more aware of your neck posture and how to position yourself correctly. You can use this knowledge:</p>
<ul>
<li>When sitting at your desk/computer or on the couch.</li>
<li>Performing any weights in the gym or doing exercise classes.</li>
</ul>

<p>

Please <a href="https://www.sprintphysio.co.uk/contact-us/index.html">contact us</a> to book an appointment or for more information on any of the services available at our clinic in Kensington.</p>
<p>
<a href="#top" title="Back To Top">↑ Back To Top</a></p>






        </div>
        
		



				
				<p><b>Insurance providers...</b></p><p><img src="https://www.sprintphysio.co.uk/images/insurance-logos.png">
				</p>
				<br>


	</div>
</div><div id="jumpsContainer">
	<div>
			<div id="j1">
				<p><a>Physiotherapy</a></p><p><a href="https://www.sprintphysio.co.uk/services/physiotherapy.html"><img src="https://www.sprintphysio.co.uk/images/physiotherapy-jump.jpg" alt="Physiotherapy" title="Physiotherapy"></a></p>
				<div><p>
					Our physiotherapists specialise in restoring your normal function and movement patterns so you can get on with everyday life. </p></div>
				<p>Read more »</p>
			</div>
			<div id="j2">
 				<p><a>Pilates</a></p><p><a href="https://www.sprintphysio.co.uk/services/pilates.html"><img src="https://www.sprintphysio.co.uk/images/pilates-jump.jpg" alt="Pilates" title="Pilates"></a></p>
				<div><p>
					Pilates focuses on building the body???s core strength and improving posture through a series of low repetition, low impact stretching and conditioning exercises. </p></div>
				<p>Read more »</p>
			</div>

            <div id="j3">
            	<p><a>Sports injuries</a></p><p><a href="https://www.sprintphysio.co.uk/services/sports-assessments.html"><img src="https://www.sprintphysio.co.uk/images/sports-injuries-jump.jpg" alt="Sports injuries" title="Sports injuries"></a></p>
				<div><p>
					At Sprint Physiotherapy we are experts at treating a variety of sporting injuries, including; swimming, running, golfing, etc.</p></div>
				<p>Read more »</p>
			</div>

            <div id="j4">
				<p><a>Massage Therapy</a></p><p><a href="https://www.sprintphysio.co.uk/services/massage.html"><img src="https://www.sprintphysio.co.uk/images/massage-therapy-jump.jpg" alt="Massage Therapy" title="Massage Therapy"></a></p>
				<div><p>
					Our massage therapists specalise in a range of massage techniques; remedial, sports, pregnancy, etc.</p></div>
				<p>Read more »</p>
			</div>
			

	</div>
</div></div>]]>
            </description>
            <link>https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699510</guid>
            <pubDate>Sat, 09 Jan 2021 11:27:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: DevBooks – Help Developers find indy books]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25698707">thread link</a>) | @simon-holdorf
<br/>
January 9, 2021 | https://thesmartcoder.dev/books/ | <a href="https://web.archive.org/web/*/https://thesmartcoder.dev/books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div data-app="true" id="app" data-v-8b44678a=""><div> <main data-v-8b44678a=""><div><div data-v-405cec28="" data-v-8b44678a=""><div><div data-v-405cec28=""><div data-v-405cec28=""><div> <p data-v-405cec28="">
        Find the best books for developers.
      </p></div></div></div></div></div> <div data-v-8b44678a=""><div data-v-58ecdbbb="" data-v-8b44678a=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><h2>What is DevBooks?</h2> <p>DevBooks helps developers to find the best books for developers and authors to showcase their amazing work. </p></div></div> </div> <div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div xs="12"><div> <div><h2>
        A React Developer’s Guide to Hooks
      </h2> <p>by Sebastien Castiel</p> <p>
        React Hooks are awesome, but they are not easy to use every day.
In my experience with React and hooks, I have faced a lot of issues, spent some time debugging to understand where these issues came fr...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Bootstrap
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Learn to use one of the most popular CSS frameworks and build mobile-friendly web pages. Used for numerous websites and applications, Bootstrap is a key tool for modern web development.
      </p></div>  </div></div><div xs="12"><div> <div><h2>
        The Coding Career Handbook
      </h2> <p>by Shawn Swyx Wang</p> <p>
        10 hours of audio. 40 chapters. 450+ pages. 1,400+ links to original sources curated over 3 years. Priceless insights from dozens of developers at the top of their fields. Proven ideas, tested by pers...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Jest Handbook
      </h2> <p>by Hugo Di Francesco</p> <p>
        Learn Advanced JavaScript Testing patterns with Jest.

Take your JavaScript testing to the next level by learning the ins and outs of Jest, the top JavaScript testing library.
      </p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Test Automation
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Learn the principles behind test-driven development (TDD) and behavior-driven development (BDD) and see how Jasmine, RSpec and Cucumber can be used to your advantage. This book examines some of the le...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Tech Resume Inside Out
      </h2> <p>by Gergely Orosz</p> <p>
        What a good developer resume looks like, and how to write one. I've reviewed hundreds of developer resumes at tech companies like Microsoft, Skype, and Uber. This guide helps you craft a developer res...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Lean from the Trenches
      </h2> <p>by Henrik Kniberg</p> <p>
        You know the Agile and Lean development buzzwords, you’ve read the books. But when systems need a serious overhaul, you need to see how it works in real life, with real situations and people. Lean fro...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Code Your Way Up
      </h2> <p>by Greg Thomas</p> <p>
        Code Your Way Up is the book for new developers looking to get started in software and asks the hard questions on growth, delivery, and initiative and what you need to think of in order to succeed.  I...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Master HTML &amp; CSS
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Want to become a Web developer? HTML and CSS are a must for your foundation. And this book takes you from zero to advanced level. From classical hello world things to how you can position elements on ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        How To Host, Secure, and Deliver Static Websites on Amazon Web Services
      </h2> <p>by Kyle Galbraith</p> <p>
        "How To Host, Secure, and Deliver Static Websites on Amazon Web Services" is a book and video course that cuts through the sea of information to accelerate your learning of AWS. Giving you a learning ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to GraphQL
      </h2> <p>by Robin Wieruch</p> <p>
        The Road to GraphQL is your personal journey to master pragmatic GraphQL in JavaScript. The book is full with applications you are going to build along the way with React.js and Node.js. Afterward, yo...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Letters To a New Developer
      </h2> <p>by Dan Moore</p> <p>
        Learn what you need to succeed as a developer beyond the code. The lessons in this book will supercharge your career by sharing lessons and mistakes from real developers. 

Wouldn’t it be nice to lear...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        How to Get a Job in Web Development
      </h2> <p>by RealToughCandy</p> <p>
        "How to Get a Job in Web Development" is designed for junior web developers. 
In this book, you will learn how to:

• Expertly craft the ‘holy clover’ of application materials: your resume, cover lett...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Portfolio Surgery
      </h2> <p>by RealToughCandy</p> <p>
         In Portfolio Surgery, you'll start with a massive upgrade of the look and feel of your portfolio. You'll learn about common pitfalls, dos and don'ts, and portfolio optimization techniques. Then, in t...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Case of IBM 386 PC: A Detective Story for Techies
      </h2> <p>by Jim Grep</p> <p>
        Take a break, have some fun reading a tech mystery story on programming--a first of its kind. A nostalgic story from the early days of IBM PC when some programmers get together to play detective and h...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Freelance Newbie
      </h2> <p>by RealToughCandy</p> <p>
        Are you ready to jump-start your freelance web development career? Freelance Newbie has you covered! In this book, you’ll learn practical, actionable steps you can start using TODAY to get your first ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Your First Year in Code
      </h2> <p>by Isaac Lyman</p> <p>
        Starting a career in programming can be intimidating. Whether you're switching careers, joining a boot camp, starting a C.S. degree, or learning on your own, Your First Year in Code can help, with pra...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Good Parts of AWS
      </h2> <p>by Daniel Vassallo</p> <p>
        This is a book by Daniel Vassallo and Josh Pschorr. Between us, we have worked with AWS for 15 years, including 11 years working inside AWS. We have worked on all sorts of web applications, from small...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Pure React
      </h2> <p>by Dave Ceddia</p> <p>
        Learning new skills is one of the best ways to invest in yourself.

Knowing React can be the deciding factor in getting hired for a new job, or set you up for a promotion at your current one.

You cou...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Vavr
      </h2> <p>by Alexandre Grison</p> <p>
        Practical Vavr is all about making you want to use Vavr in your day to day Java programming.

If you want to improve the quality of your code by using a well-thought and beautifully designed functiona...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Programming Interview Problems: Dynamic Programming (with solutions in Python)
      </h2> <p>by L. Rossi</p> <p>
        The most common dynamic programming problems asked in programming interviews, with detailed solutions in Python. The solutions consist of cleanly written code, with plenty of comments, accompanied by ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Building an Effective Dev Portfolio
      </h2> <p>by Josh Comeau</p> <p>
        I got so many replies! A couple hundred developers were willing to share their portfolios with me, and I went through as many as I could over the next couple of weeks. I found I kept giving the same f...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        PHP Mentors - Advice from PHP Experts around the world
      </h2> <p>by Flávio Silveira</p> <p>
        Answers from PHP masters around the world for your questions.
Code, Career, Team work, Working environment, Logs, Tests, Future and much more.

PHP Mentors Book is a set of questions with topics that ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Content for Developers
      </h2> <p>by Maedah Batool</p> <p>
        A whole new workflow to Write. Publish. Market. Authentic &amp; professional content writing meant for developers. Zero bull-shit and to-the-point tips to improve your technical content writing skills. Le...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        14 Habits of Highly  Productive Developers
      </h2> <p>by Zeno Rocha</p> <p>
        You can learn the most popular frameworks, use the best programming languages, and work at the biggest tech companies, but if you cultivate bad habits, it will be hard for you to become a top develope...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Outstanding Developer
      </h2> <p>by Sebastien Castiel</p> <p>
        Being a developer is not only about writing code. And improving as a developer is not only about improving in writing code. This book explores how to become an outstanding developer through several ax...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        A Smart Guide for Your Career as a Software Engineer
      </h2> <p>by Mike Nikles</p> <p>
        I started my software engineer career 20 years ago. Since then, I have interviewed hundreds of candidates and reviewed even more resumes. This book is a guide for your own career, whether you are new ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        5 Little Potions
      </h2> <p>by Mark Wilbur</p> <p>
        In 5 Little Potions, you'll begin your journey into Elixir programming by creating increasingly complex games.

You'll start with a simple guessing game. Next you'll work with Elixir Structs in a boar...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Data Analysis with Rust Notebooks
      </h2> <p>by Dr. Shahin Rostami</p> <p>
        A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.

- All code examples in Rust,
- Rust (Jupyter) Notebooks for each Section,
...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Distributed Systems with Node.js
      </h2> <p>by Thomas Hunter II</p> <p>
        In this hands-on guide, author Thomas Hunter II proves that Node.js is just as capable as traditional enterprise platforms for building services that are observable, scalable, and resilient. Intermedi...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Python re(gex)?
      </h2> <p>by Sundeep Agarwal</p> <p>
        This book will help you learn Python Regular Expressions, a mini-programming language for all sorts of text processing needs.

The book heavily leans on examples to present features of regular express...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to React
      </h2> <p>by Robin Wieruch</p> <p>
        In "The Road to React" you will learn about all the fundamentals of React.js with Hooks while building a full-blown React application step by step. While you create the React application, every chapte...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Cloud Native Web Development
      </h2> <p>by Mike Nikles</p> <p>
        In this book, we will walk through the end-to-end process of developing a cloud-native web application. You will learn technologies, processes, tips &amp; tricks and gain hands-on experience. You will fin...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to Firebase
      </h2> <p>by Robin Wieruch</p> <p>
        The Road to React with Firebase is your personal journey to master advanced React for business web applications in JavaScript whereas Firebase is used to …</p></div></div></div></div></div></div></div></div></div></div></div></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesmartcoder.dev/books/">https://thesmartcoder.dev/books/</a></em></p>]]>
            </description>
            <link>https://thesmartcoder.dev/books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25698707</guid>
            <pubDate>Sat, 09 Jan 2021 08:43:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning Elixir's GenServer with a real-world example]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25698520">thread link</a>) | @kimi
<br/>
January 8, 2021 | https://papercups.io/blog/genserver | <a href="https://web.archive.org/web/*/https://papercups.io/blog/genserver">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://papercups.io/blog/genserver</link>
            <guid isPermaLink="false">hacker-news-small-sites-25698520</guid>
            <pubDate>Sat, 09 Jan 2021 07:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over: Board – Raspberry Pi CM4 ITX Motherboard]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25697993">thread link</a>) | @todsacerdoti
<br/>
January 8, 2021 | https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3401">

	

	<div>
		
<p>The Over:Board is an IO board for the Raspberry Pi Compute Module 4. It is designed to use a standard PC ATX power connector and features a full size PCI-E 16x slot although its only running at 1x bandwidth and unfortunately it is not compatible with a GPU.   <br></p>



<figure><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201%201'%3E%3C/svg%3E" data-src="https://c0.iggcdn.com/indiegogo-media-prod-cld/image/upload/c_fill,w_762,g_center,q_auto:best,dpr_1.6,f_auto,h_506/fjlirebv3qpqd7xdlsek" alt="The Over:Board" data-old-src="https://c0.iggcdn.com/indiegogo-media-prod-cld/image/upload/c_fill,w_762,g_center,q_auto:best,dpr_1.6,f_auto,h_506/fjlirebv3qpqd7xdlsek" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The Over:Board</figcaption></figure>



<p><br>It breaks out the following ports: <br></p>



<ul><li>24-pin ATX Power</li><li>40-pin GPIO</li><li>Full Size PCI-E @ 1x bandwidth</li><li>SATA Controller (Powered by USB)</li><li>Front Panel Header</li><li>CPU Fan Header</li><li>UART Header</li><li>Micro USB</li><li>RS232 Com Port</li><li>2x USB 2.0 Ports</li><li>Micro SD card slot</li><li>3.5mm Audio</li></ul>



<p>The Over:Board costs £199 for an early prototype or £99 for the Final Production board and is available to back now on indiegogo. <br></p>



<div><p>Whilst £99 is expensive for a IO board this is likely down to the limited production and it is likely still the cheapest ARM based ITX motherboard on the market even when factoring in the cost of a RPI CM4. </p><p>You can back the Over:Board on indiegogo <a rel="noreferrer noopener" href="https://www.indiegogo.com/projects/over-board-raspberry-pi-4-mini-itx-motherboard#/" target="_blank">here</a></p><p>For another ARM IO board with SATA check out my Nano Pi Neo2 NAS review <a rel="noreferrer noopener" href="https://blog.jmdawson.co.uk/nano-pi-neo2-nas-enclosure-a-small-linux-home-server-nas/" target="_blank">here</a></p><p>The project currently has £1654 in backing from 11 backers. With 28 days left it is looking likely to hit its £5000 target. </p><p>Ross Nicoholls is leading the campaign: </p></div>



<blockquote><p>I’ve lost count exactly how many, but this will be about my 35th commercial electronics PCB to be manufactured, so I am no stranger to getting these things to market. That said however, this will be the first of my own venture so represents my most exciting project to date and something I feel very passionate about.</p><cite>Ross has lots of experience in this field</cite></blockquote>



<p>I wish Ross good luck and hope to see the Over:Board available soon! </p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25697993</guid>
            <pubDate>Sat, 09 Jan 2021 06:31:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer vaccine appears effective against mutation in new coronavirus variants]]>
            </title>
            <description>
<![CDATA[
Score 648 | Comments 230 (<a href="https://news.ycombinator.com/item?id=25696577">thread link</a>) | @awnird
<br/>
January 8, 2021 | https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5852149.1608672062!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/covid-vaccinations-toronto.jpg"></p></div><figcaption>A nurse prepares a dose of the Pfizer-BioNTech COVID-19 vaccine for care home workers at St. Michael’s Hospital in Toronto on Dec. 22, 2020.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p>  <p>The study by Pfizer and scientists from the University of Texas Medical Branch, which has not yet been peer-reviewed, indicated the vaccine was effective in neutralizing virus with the so-called N501Y mutation of the spike protein.</p>  <p>The mutation could be responsible for greater transmissibility and there had been concern it could also make the virus escape antibody neutralization elicited by the vaccine, said Phil Dormitzer, one of Pfizer's top viral vaccine scientists.</p>  <p>The first results of tests on the variants offer a glimmer of hope while more studies are carried out as Britain and other countries try to tame the more infectious variants that&nbsp;authorities believe are driving a surge in infections that could overwhelm health-care systems.</p>  <p>The Pfizer-BioNTech study was conducted on blood taken from people who had been given the vaccine. Its findings are limited because it does not look at the full set of mutations found in either of the new variants of the rapidly spreading virus.</p>  <p>Dormitzer said it was encouraging that the vaccine appears effective against the mutation, as well as 15 other mutations the company has previously tested against.</p>  <p>"So we've now tested 16 different mutations, and none of them have really had any significant impact. That's the good news," he said. "That doesn't mean that the 17th won't."</p>  <p><em><strong>WATCH | What scientists know about the new coronavirus variant:</strong></em></p>  <p><span><span><div><div title="What scientists know about the new coronavirus variant" role="button" tabindex="0"><div><div aria-labelledby="1842141251676-metadata-" title="What scientists know about the new coronavirus variant"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/643/819/COVID-VARIANT-SCI-BIRAK-080121.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>The B1-17 coronavirus variant, first discovered in the U.K., is now in at least 40 countries, including Canada. It has 23 mutations, including one that attaches to healthy cells like a key going into a lock.<!-- --> <!-- -->1:56</span></span></span></p>  <p>Dormitzer said another mutation found in the South African variant, called the E484K mutation, was also concerning.</p>  <p>The researchers plan to run similar tests to establish whether the vaccine is effective against other mutations found in the British and South African variants and hope to have more data within weeks.</p>  <p>The variants are said by scientists to be more transmissible than previously dominant ones, but they are not thought to cause more serious illness.</p>  <p>The virus's spikes act as a key that must unlock our cells to cause the infection.&nbsp;The variant first identified in the U.K. has a mutation that appears to make it easier for the coronavirus to grab hold of the lock more tightly, scientists say.</p>    <p>Scientists said the results of the study would help calm concerns that people will not be protected by vaccines being given to millions of people around the world in the fight against the pandemic, which has killed more than 1.8 million people and roiled economies.</p>  <p>But they cautioned that more clinical tests and data are still needed to come to a definitive conclusion.</p>  <p>"This is good news, mainly because it is not bad news," said Stephen Evans, professor of pharmacoepidemiology at the&nbsp;London School of Hygiene &amp; Tropical Medicine.</p>  <p>"So, yes this is good news, but it does not yet give us total confidence that the Pfizer (or other) vaccines will definitely give protection."</p>  <h2>AstraZeneca, Moderna, CureVac testing against variants</h2>  <p>AstraZeneca, Moderna and CureVac are also testing whether their shots work against the fast-spreading variants. They have said they expect them to be effective, but the timing of those studies is not known.</p>  <p>A senior British lawmaker expressed concerns in an interview on Friday that COVID-19 vaccines might not work properly against the South African variant. He was not responding to questions about Friday's data.</p>  <p>The Pfizer-BioNTech vaccine and the one from Moderna Inc., which use synthetic messenger RNA technology, can be quickly tweaked to address new mutations of a virus if necessary. Scientists have suggested the changes could be made in as little as six weeks.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-new-variants.jpg 300w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-new-variants.jpg 460w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-new-variants.jpg 620w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg 780w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-new-variants.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg"></p></div><figcaption>Graphic shows a diagram of the COVID-19 virus.<!-- --> <!-- -->(AP)</figcaption></figure></span></p>  <p>Some other vaccines to protect against COVID-19 also use the spike protein to show our immune system what the enemy looks like.</p>  <p>Canadian microbiologist Benjamin tenOever, a professor at the&nbsp;Icahn School of Medicine at Mount Sinai in New York,&nbsp;said our immune system learns to recognize and attack the viral attachment protein at many different sites.</p>  <p>"It would require many many mutations to render our vaccines non-effective,"&nbsp;tenOever&nbsp;said.</p>  <p>The variant is also not the first of the pandemic to emerge and Eleanor Riley, professor of immunology and infectious disease at the University of Edinburgh, said these types of studies&nbsp;will be needed as they appear.</p>  <p>"It may be necessary to tweak the vaccine over time," she said.</p>  <p>Dr. Theresa Tam, Canada's chief public health officer, said Friday that 14 cases of the variant first reported in the U.K. have been reported in Canada.</p>  <p>Researchers in Ontario have developed a faster test to identify variants.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696577</guid>
            <pubDate>Sat, 09 Jan 2021 03:48:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an iRacing SDK Implementation in F#]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25696493">thread link</a>) | @sanesmith
<br/>
January 8, 2021 | https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/ | <a href="https://web.archive.org/web/*/https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>In my <a href="https://markjames.dev/2021-01-04-why-learning-fsharp-2021/">previous post</a>, I discussed how I’ve decided to learn F# in 2021 for a number of reasons. Around the same time, I also happened to setup my Sim Racing rig so that I could continue to play <a href="https://www.iracing.com/" target="_blank">iRacing</a> with my VR headset (HTC Vive). Its been several years since I’ve last played, but with COVID-related curfews being implemented here in Montreal tomorrow, I’ve been increasingly taking up home-based pursuits which I didn’t always have the time for pre-lockdown. Since the last time I played iRacing, I’m running a PC with a much better processor, motherboard, and only SSDs. The VR performance has been a huge leap forward since I used to play with my old machine and I was quite impressed. After spending a couple of hours setting up, here’s what my current humble racing setup looks like:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/racing-rig.jpg" width="650" height="488" alt="Photo of my current iRacing VR setup"></p>

<p>Having a dedicated table really helps, as in my old apartment it was fairly difficult to setup a station with limited space, but now I can fortunately just jump in. Despite the past limitations, I was able to get fairly competitive and still remember the thrill of my first win agaisnt a field of real racers in a Mazda MX-5:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/iracing-win.jpg" width="500" height="279" alt="Photo of my iRacing first win certificate"></p>

<p>Inspired by setting everything up and doing some laps to practice for an eventual return to comeptition, I started thinking about how I once experimented with using the <a href="https://github.com/kutu/pyirsdk" target="_blank">Python implementation</a> of the iRacing SDK to connect to an arduino and display a speedometer readout in realtime on a small screen. In reminiscing about the experience, I thought about how I could look into writing an F# implementation of the SDK as a learning project. In addition to learning through the project, it also has the benefit of being of use in a future project involving an iRacing stats tracker web app that I’ve been thinking about writing as a project for my upcoming <a href="https://markjames.dev/2020-12-09-back-to-school/">cloud computing courses</a>.</p>

<h2 id="getting-started">Getting Started</h2>

<p>I tend to learn best when projects are slightly outside of my comfort zone, and this would be both my first time writing a library, as well as writing one in a functional language! Having used an array of libraries at this point, I had some confidence in choosing an organizational structure, and the Python implementation is only <a href="https://github.com/kutu/pyirsdk/blob/master/irsdk.py" target="_blank">739 lines of code</a> which felt doable compared to some of the larger libraries out there.</p>

<p>Moreover, the python implementation of the SDK has the ability to:</p>

<ul>
  <li>Get session data (WeekendInfo, SessionInfo, etc…)</li>
  <li>Get live telemetry data (Speed, FuelLevel, etc…)</li>
  <li>Broadcast messages (camera, replay, chat, pit and telemetry commands)</li>
</ul>

<p>and I figured that this would be a good featureset to aim for in the final version of the F# SDK. Out of these features, the session data and live telemetry data would be the ones I plan to implement first.</p>

<h2 id="creating-the-library">Creating the Library</h2>

<p>After coming up with some desired features, the first step was to create a new FSharp solution called iRacingFSharp. Inside the solution, I created two projects. One was our actual library, called iRacingFSharp, and the other was a basic console app called SDKReader (located in the Examples Folder) to test the functionality of the library as I worked on it. Note, if you’d like to see the full codebase you can <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">here on github</a>.</p>

<h2 id="the-first-function">The First Function</h2>

<p>Starting small, I decided that a good first function would be to find out the state of the simulator. Fortunately, the iRacing SDK allows you to check if the sim is running using the following URL which points to a localhost server:</p>

<div><div><pre><code>http://127.0.0.1:32034/get_sim_status?object=simStatus
</code></pre></div></div>
<p>Getting this URL in Postman returns a JSON object which looks like this:</p>

<div><div><pre><code>var simStatus={
   running:0 // 1 if the sim is running
};
</code></pre></div></div>

<p>I decided to make use of the <a href="https://fsharp.github.io/FSharp.Data/library/Http.html" target="_blank">F# Data HTTP library</a> in order to download the response and so I installed it from NuGet at this point.</p>

<p>Next, inside my iRacingFSharp project I created a file called Irsdk.fs and wrote the following code:</p>

<div><div><pre><code><span>namespace</span> <span>IrsdkFS</span>

<span>open</span> <span>FSharp</span><span>.</span><span>Data</span>

<span>///&lt;summary&gt;F# implementation of the iRacing SDK.&lt;/summary&gt;</span>
<span>module</span> <span>IrsdkFS</span> <span>=</span>

    <span>///&lt;summary&gt;Returns the simStatus in string format&lt;/summary&gt;</span>
    <span>let</span> <span>SimStatus</span><span>()</span> <span>=</span>
        <span>let</span> <span>simStatusURL</span> <span>=</span> <span>"http://127.0.0.1:32034/get_sim_status?object=simStatus"</span>
        <span>let</span> <span>simStatusObject</span> <span>=</span> <span>Http</span><span>.</span><span>RequestString</span><span>(</span><span>simStatusURL</span><span>)</span>
        <span>simStatusObject</span>
</code></pre></div></div>

<p>In the above code, I’ve created a module which contains a function called SimStatus that takes no parameters. It then binds the JSON response to simStatusURL and passes it to the HTTP library via Http.RequestString(). Finally, simStatusObject is returned in string format which can be parsed further by another function in a later step.</p>



<p>With this simple function in place, the next step was to create SDKReader.fs inside my SDKReader console app. This file contained code to call the SimStatus() function and print the output:</p>

<div><div><pre><code><span>[&lt;</span><span>EntryPoint</span><span>&gt;]</span>
<span>let</span> <span>main</span> <span>argv</span> <span>=</span>
    <span>let</span> <span>test</span> <span>=</span> <span>IrsdkFS</span><span>.</span><span>SimStatus</span><span>()</span>
    <span>printf</span> <span>"%s"</span> <span>test</span>
    <span>0</span> <span>// return an integer exit code</span>
</code></pre></div></div>

<p>Running dotnet build inside the SDKReader folder displayed the following output while iRacing was running:</p>

<div><div><pre><code><span>"var simStatus={
   running:1
};
"</span><span>
</span></code></pre></div></div>

<p>Success! With this method working, we now have the very beginnings of an F# implementation of the iRacing SDK! Although it is a small step, we were also able to create and structure the project. Lastly, I also setup a a basic .NET build through Github Actions for CI.</p>



<p>iRacing’s API telemetry comes in three variations; data written to a .ibt file 60 times a second, live data exposed to the telemetry API 60 times per second, and a session string in YAML format that contains more or less static information about the session. The YAML string is appended to the end of the .ibt file but only a small portion of that data is exposed. This means that going forward, I’ll need to look into parsing the YAML as well as mapping more of the API endpoints. The iRacing API appears to be nonstandard and so it may take a little more work than just a typical REST API.</p>

<p>Stay tuned for Part Two where I plan to implement some telemetry functions and look into parsing the aforementioned YAML. In addition, be sure to follow along with the <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">Github Repo here</a> if you’re interested in seeing how to project progresses (or would like to contribute)!</p>

      </article></div>]]>
            </description>
            <link>https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696493</guid>
            <pubDate>Sat, 09 Jan 2021 03:42:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ad-Tech Is a Bezzle]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25695482">thread link</a>) | @freediver
<br/>
January 8, 2021 | https://pluralistic.net/2021/01/04/how-to-truth/#adfraud | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1719">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
reviews, damon knight, science fiction, statistics, statistical literacy, gift guide,books, uk, dsa, democratic socialists of america, elections, california, ads, at-tech, fraud, google, labor, unions, alphabet, alphabet workers union, cwa,

Summary:
Ad-tech is a bezzle; Google's unionizing; The Data Detective; Damon Knight's Why Do Birds is back; Endorsing the Forward 43 slate

URL:
https://pluralistic.net/2021/01/04/how-to-truth/

Title:
Pluralistic: 04 Jan 2021

Bullet:
🎬

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Ken Snider (https://twitter.com/orenwolf), Slashdot (https://slashdot.org/), Margo Rowder (https://twitter.com/margorowder).

--><br>
<a href="https://pluralistic.net/2021/01/04/how-to-truth/"><img src="https://i0.wp.com/craphound.com/images/04Jan2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/04Jan2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">Ad-tech is a bezzle</a>: The subprime attention crisis is upon us.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#awu">Google's unionizing</a>: Solidarity vs worker misclassification.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#harford">The Data Detective</a>: How to truth with statistics.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#an-oval">Damon Knight's Why Do Birds is back</a>: Reviving a grand master's comic masterpiece.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#fwd-43">Endorsing the Forward 43 slate</a>: For my California comrades.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#retro">This day in history</a>: 2016
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="adfraud"></a><br>
<img src="https://i1.wp.com/craphound.com/images/ad-3242595_960_720.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/ad-3242595_960_720.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>There are lots of problems with ad-tech:</p>
<ul>
<li>being spied on all the time means that the people of the 21st century are less able to be their authentic selves;
</li>
<li>
<p>any data that is collected and retained will eventually breach, creating untold harms;</p>
</li>
<li>
<p>data-collection enables for discriminatory business practices ("digital redlining");</p>
</li>
<li>
<p>the huge, tangled hairball of adtech companies siphons lots (maybe even most) of the money that should go creators and media orgs; and</p>
</li>
<li>
<p>anti-adblock demands browsers and devices that thwart their owners' wishes, a capability that can be exploited for even more nefarious purposes;</p>
</li>
</ul>
<p>That's all terrible, but it's also <em>ironic</em>, since it appears that, in addition to everything else, ad-tech is a fraud, a bezzle.</p>
<p>Bezzle was John Kenneth Galbraith's term for "the magic interval when a confidence trickster knows he has the money he has appropriated but the victim does not yet understand that he has lost it." That is, a rotten log that has yet to be turned over.</p>
<p>Bezzles unwind slowly, then all at once. We've had some important peeks under ad-tech's rotten log, and they're increasing in both intensity and velocity. If you follow Aram Zucker-Scharff, you've had a front-row seat to the fraud.</p>
<p><a href="https://twitter.com/Chronotope/status/1078003966863200256">https://twitter.com/Chronotope/status/1078003966863200256</a></p>
<p>Time and again, everything in the ad-tech stack has been demonstrated to be fraudulent: fake audiences firing fake clicks at fake videos on fake sites that suck real dollars out of advertisers' accounts.</p>
<p>This was masterfully elucidated in Tim Hwang's short 2020 book SUBPRIME ATTENTION CRISIS, whose thesis is: we must deflate the ad-tech bubble intentionally, lest we get a messy rupture that destroys many of the good things the parasite has colonized.</p>
<p><a href="https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost">https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost</a></p>
<p>The ad-tech fraud is many-layered. On the surface, there's the counting frauds: fake clicks, fake sites, fake videos, etc. But there's a deeper fraud, a theory fraud, the fraud that with enough surveillance data and machine learning, ad-tech can sell anyone anything.</p>
<p>That is: even if we count accurately, ads are still overvalued and underperforming. This is also a lesson whose examples are coming with increasing tempo, as when Ebay simply stopped buying Google search ads and saw <em>no</em> decrease in sales.</p>
<p><a href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble</a></p>
<p>In a piece for Forbes, marketer-turned-antifraud-auditor Dr Augustine Fou rounds up some of the grossest things festering under the ad-tech log.</p>
<p><a href="https://www.forbes.com/sites/augustinefou/2021/01/02/when-big-brands-stopped-spending-on-digital-ads-nothing-happened-why/?sh=5a4f9c9a1166">https://www.forbes.com/sites/augustinefou/2021/01/02/when-big-brands-stopped-spending-on-digital-ads-nothing-happened-why/?sh=5a4f9c9a1166</a></p>
<p>Like that time in 2018 when Procter and Gamble – inventors of "brand marketing" – turned off $200m worth of ad-tech buys and saw no change to their sales. Or when Chase killed 95% of its advertising and kept all of its business.</p>
<p>Most interesting is the tale of how Uber allowed itself to be defrauded of $150m/year, for years, by ad-tech intermediaries. It's a story told in detail by former Uber head of "performance marketing" Kevin Frisch on the Marketing Today podcast:</p>
<p><a href="https://www.marketingtodaypodcast.com/194-historic-ad-fraud-at-uber-with-kevin-frisch/">https://www.marketingtodaypodcast.com/194-historic-ad-fraud-at-uber-with-kevin-frisch/</a></p>
<p>It starts with the revelation that $50m of its annual spend on customer acquisitions – money paid when an ad leads to a new Uber customer downloading the app, entering payment details and taking their first ride – was fraudulent.</p>
<p>Here's how that worked: scummy marketers fielded low-quality apps (like battery monitors) that requested root access. These apps spied on every app you installed. If you installed Uber, they "fired a click" to the system to report you as having been "converted" by an ad.</p>
<p>After clearing $50m of fraud, Frisch continued to dig into the system. In the end, about $120m of the $150m was being stolen, pocketed for fake clicks on fake sites by fake users.</p>
<p>In a fascinating turn, Frisch describes how his colleagues were indifferent or actively hostile to his efforts. Uber was in "growth mode," trying to beef up its numbers prior to the IPO where suckers would relieve its Saudi royal investors.</p>
<p>Uber is a company that will never, ever be profitable. It, too, is a bezzle. It only "works" if outside investors – marks – can somehow be convinced to buy the insiders' stock, which requires the appearance of growth – AKA "A pile of shit this big <em>must</em> have a pony under it!"</p>
<p>So execs like Frisch were required to "spend to budget" – to maintain the appearance of growth, including (especially) the growth of its "precision analytics" marketing, where ad-tech spends turned into directly attributable customer acquisitions.</p>
<p>This is the story that keeps on giving, because it all starts with Sleeping Giant's campaign to force Uber to stop advertising on Breitbart, and Uber's inability to get its ad-tech "partners" to definitively switch off Breitbart ads.</p>
<p><a href="https://twitter.com/nandoodles/status/1345774768746852353">https://twitter.com/nandoodles/status/1345774768746852353</a></p>
<p>The system's layers of misdirection – there to hide the fraud – meant that it behaved nondeterministically and couldn't fulfil simple requests, which triggered the search.</p>
<p>There's a theory that the reason Big Tech spies on us so much is that they're really good at turning data into sales (and, by extension, influence, as in elections, referenda, etc). But it is increasingly apparent that Big Tech's spying is part of a bezzle.</p>
<p>That is, we're being surveilled, doxed, placed under automated suspicion and digitally discriminated against all to put on a show that separates marks from their dollars.</p>
<p>This is the theme of my 2020 book HOW TO DESTROY SURVEILLANCE CAPITALISM:</p>
<p><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
<p>Namely, that we are under constant surveillane because monopolies can get away with obviously fraudulent and dangerous conduct by mobilizing their monopoly profits to buy political outcomes that serve their ends.</p>
<p>This is also what happened with California's Proposition 22, the most expensive ballot initiative in US history: Uber didn't spearhead a $200m campaign to legalize worker misclassification to become profitable.</p>
<p>Uber will never be profitable.</p>
<p>All that money was spent to maintain the fiction, the fraud, the bezzle – it was an appeal to rescue the wholly fictional pony underneath that gigantic pile of shit.</p>
<hr>
<p><a name="awu"></a><br>
<img src="https://i1.wp.com/craphound.com/images/Homestead_Strike_-_Mob_attacking_Pinkerton_men-1-1-9.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/Homestead_Strike_-_Mob_attacking_Pinkerton_men-1-1-9.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Google workers have announced their intention to form a union, under the auspices of CWA Local 1440. The union is called The Alphabet Workers Union (Google maintains the legal and accounting fiction that it is a division of a holding company called "Alphabet").</p>
<p>Speaking of legal fictions, the union is opening membership to "TVCs" – temps, vendors and contractors – employees who have been deliberately misclassified so as to avoid paying them benefits or extending normal workplace protections to them.</p>
<p>It's a bold move, a countermeasure to thwart the other commercial advantage from worker misclassification: by creating multiple categories of workers, bosses can pit employees against one another, by dangling privileges in front of one group but not the other.</p>
<p>But it comes at a high price: to gain official legal recognition, more than 50% of eligible workers must join the union. By including more workers, the union is setting a higher bar for official status.</p>
<p><a href="https://www.vice.com/en/article/3an5q9/google-workers-publicly-launch-union">https://www.vice.com/en/article/3an5q9/google-workers-publicly-launch-union</a></p>
<p>But the union has momentum: a series of high-profile googler uprisings – driven by official tolerance for sexual misconduct, complicity in US military drone programs, secret collaboration with Chinese surveillance and censorship, and more – show how radicalized googlers are.</p>
<p>Google's management – who cultivated an air of participatory, cuddly collaboration – have arrived at a point where the contradictions between their "values" and the company's profits can no longer be reconciled.</p>
<p>In Dec 2020, Google fired Timnit Gebru, an eminent Black AI scientist who refused to retract a paper critical of its profitable Big Data research. Management compounded their sins by making false claims about Gebru's dismissal.</p>
<p>The unionization drive is under the CWA's #CODE (Coalition to Organize Digital Employees) project. Though CODE is no stranger to conflict, Google represents a serious challenge, thanks to its partnership with notorious union-busters IRI Consultants.</p>
<p>(IRI's tactics pale in comparison to the mercenaries that Amazon has hired to bust its unions: the Pinkerton company, who have spilled rivers of workers' blood in their murderous history):</p>
<p><a href="https://www.vice.com/en/article/5dp3yn/amazon-leaked-reports-expose-spying-warehouse-workers-labor-union-environmental-groups-social-movements">https://www.vice.com/en/article/5dp3yn/amazon-leaked-reports-expose-spying-warehouse-workers-labor-union-environmental-groups-social-movements</a></p>
<p>For important context on the drive, check out Collective Action in Tech's article on the announcement, which explains why googlers have formed a "non-contract union" that does not yet have official recognition.</p>
<p><a href="https://collectiveaction.tech/2021/the-abcs-of-googles-new-union/">https://collectiveaction.tech/2021/the-abcs-of-googles-new-union/</a></p>
<p>"Non-contract unions embody the idea that worker power does not come from legal processes, but rather through building power through solidarity."</p>
<hr>
<p><a name="harford"></a><br>
<img src="https://i0.wp.com/craphound.com/images/data-detective.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/data-detective.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Publishing works on long schedules, which means that long-planned books can be overtaken by events…like covid.</p>
<p>2020 was tough for those of us with books in trail, especially nonfiction. But for a few lucky writers, covid imparted a terrible salience to their books.</p>
<p>One such writer is Tim Harford, host of BBC Radio 4's More or less, which is hands-down the greatest statistical literacy program in the world, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">https://pluralistic.net/2021/01/04/how-to-truth/#adfraud</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/01/04/how-to-truth/#adfraud</link>
            <guid isPermaLink="false">hacker-news-small-sites-25695482</guid>
            <pubDate>Sat, 09 Jan 2021 02:19:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archive of 43k+ Donald Trump Twitter Screenshots]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25693054">thread link</a>) | @soheilpro
<br/>
January 8, 2021 | https://pikaso.me/blog/donald-trump-twitter-archive | <a href="https://web.archive.org/web/*/https://pikaso.me/blog/donald-trump-twitter-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>


    <section>
      <p>
        <h2>Donald Trump Twitter Screenshot Archive</h2>
      </p>
      
        
      

      <div><p>Donald Trump loves to tweet and everyone knows that.
Twitter is his favorite medium to express his ideas and to communicate with the world.
He has been an active Twitter user since 2009. Much longer than many other world leaders.</p>
<p>Last month (May 2020) he tweeted 845 times â€” that's 28 tweets per day on average!</p>
<center>
  <a href="https://twitter.com/realDonaldTrump/status/491324429184823296"><img src="https://pikaso.me/blog/files/pikaso.me-realDonaldTrump-20140721_205046-491324429184823296.png" alt="Trump Tweet" width="500" height="244"></a>
</center>
<p>A while ago we received a request from one of our users who was looking for a way to screenshot all Donald Trump tweets.
We realized that's a good opportunity to put <a href="https://pikaso.me/">Pikaso</a> into test and see if it can perform such a task without any problems.
It went smoothly and there was only an issue with one of his tweets which included a deleted image.</p>
<p>Today, we are releasing the resulting files to the public.
This archive contains screenshots of 43,475 Donald Trump tweets from May 2009 to May 2020.
Whether you are pro- or anti- Trump, this is an important part of Internet history that we believe should be preserved.</p>
<h3 id="download">Download</h3>
<p>The Donald Trump Twitter Screenshot Archive can be downloaded through the following links:</p>
<ul>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.zip">trump_twitter_archive_v1.zip</a> (Direct download, 2.6 GB)</li>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.torrent">trump_twitter_archive_v1.torrent</a> (Torrent download, 28.2 KB)</li>
</ul>
<h3 id="howthiswasmade">How This Was Made?</h3>
<p>To create this archive, we first extracted all tweet ids from the realDonaldTrump.csv file that was provided to us.
That file only contained Donald Trump tweets up to March 29, 2020. To get the later tweets, we used <a href="http://trumptwitterarchive.com/">trumptwitterarchive.com</a>.</p>
<p>We then used the <a href="https://pikaso.me/api">Pikaso API</a> to screenshot each individual tweet.</p>
<h3 id="updates">Updates</h3>
<p>We have no plans to keep this archive up to date after the initial release.
However, if you are interested in doing so, you can use <a href="https://pikaso.me/">Pikaso</a>.
You can even <a href="https://pikaso.me/automate">automate</a> it so that each time he tweets, an automatic screenshot is taken.</p>
<h3 id="credit">Credit</h3>
<p>All the tweets are copyright https://twitter.com/realdonaldtrump.<br>
All the media embedded in tweets are copyright their respective owners.<br>
Original tweets data provided by <a href="https://twitter.com/twentysox">@twentysox</a>.</p>
<h3 id="copyrightlicense">Copyright &amp; License</h3>
<p>Copyright © 2020 https://pikaso.me.<br>
This work by https://pikaso.me is licensed under <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a>.</p>
<h3 id="contact">Contact</h3>
<p>If you have any feedback or questions regarding this work, please <a href="https://pikaso.me/contact">contact us</a>.</p></div>
    </section>

    

    
      <section>
        <h2>More from the Blog</h2>

        
      </section>
    

      </div>
  
</div></div>]]>
            </description>
            <link>https://pikaso.me/blog/donald-trump-twitter-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-25693054</guid>
            <pubDate>Sat, 09 Jan 2021 00:14:05 GMT</pubDate>
        </item>
    </channel>
</rss>
