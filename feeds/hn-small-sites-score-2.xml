<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 27 Jun 2020 04:16:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 27 Jun 2020 04:16:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Big Sur on Unsupported Macs]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23650031">thread link</a>) | @todsacerdoti
<br/>
June 26, 2020 | https://parrotgeek.com/bigsur/ | <a href="https://web.archive.org/web/*/https://parrotgeek.com/bigsur/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span face="Helvetica, Arial, sans-serif"><b><u>Compatibility
            status</u></b> <br>
        Note: these instructions only support computers<b> </b>that
        have a Metal-capable GPU <i>and</i> native APFS boot support.<br>
      </span></p><div>
      <tbody>
        <tr>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Model Identifier</b><br>
            </span></td>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Human-Readable Name</b><br>
            </span></td>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Status</b><br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookAir5,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook








              Air (11-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookAir5,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook








              Air (13-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro9,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook








              Pro (15-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro9,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook








              Pro (13-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro10,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook








              Pro (Retina, 15-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro10,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook








              Pro (Retina, 13-inch, Early 2013)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">Macmini6,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Mac
              mini (Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything








              except Wi-Fi works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">Macmini6,2<br>
            </span></td>
          <td>
            <meta charset="utf-8">
            <span face="Helvetica, Arial, sans-serif">Mac mini (Late
              2012) quad-core<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac13,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac








              (21.5-inch, Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac13,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac








              (27-inch, Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac








              (21.5-inch, Late 2013) integrated GPU<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything





              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,2<br>
            </span></td>
          <td>
            <meta charset="utf-8">
            <span face="Helvetica, Arial, sans-serif">iMac (27-inch,
              Late 2013)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything





              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,3<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac








              (21.5-inch, Late 2013) discrete GPU</span><br>
          </td>
          <td><span face="Helvetica, Arial, sans-serif">Everything





              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacPro5,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Mac
              Pro (Mid 2010/Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">WiFi

              does not work; sleep issues<br>
            </span></td>
        </tr>
      </tbody>
    </div></div>]]>
            </description>
            <link>https://parrotgeek.com/bigsur/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650031</guid>
            <pubDate>Fri, 26 Jun 2020 08:56:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Tap the Back of Your iPhone to Open Your Garage]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23649963">thread link</a>) | @eshtocof
<br/>
June 26, 2020 | https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b613">WWDC20</h2><h2 id="299f">Learn how accessibility has changed for the better in iOS 14</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@vhanagwal?source=post_page-----33e0f144e075----------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div><div><div><p><img src="https://miro.medium.com/max/60/1*9wSXSk7Fua06okhjIeQbtw.jpeg?q=20" width="2500" height="1031" role="presentation"></p><p><img src="https://miro.medium.com/max/5000/1*9wSXSk7Fua06okhjIeQbtw.jpeg" width="2500" height="1031" srcset="https://miro.medium.com/max/552/1*9wSXSk7Fua06okhjIeQbtw.jpeg 276w, https://miro.medium.com/max/1104/1*9wSXSk7Fua06okhjIeQbtw.jpeg 552w, https://miro.medium.com/max/1280/1*9wSXSk7Fua06okhjIeQbtw.jpeg 640w, https://miro.medium.com/max/1456/1*9wSXSk7Fua06okhjIeQbtw.jpeg 728w, https://miro.medium.com/max/1632/1*9wSXSk7Fua06okhjIeQbtw.jpeg 816w, https://miro.medium.com/max/1808/1*9wSXSk7Fua06okhjIeQbtw.jpeg 904w, https://miro.medium.com/max/1984/1*9wSXSk7Fua06okhjIeQbtw.jpeg 992w, https://miro.medium.com/max/2160/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1080w, https://miro.medium.com/max/2700/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1350w, https://miro.medium.com/max/3240/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1620w, https://miro.medium.com/max/3780/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1890w, https://miro.medium.com/max/4320/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2160w, https://miro.medium.com/max/4800/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2400w" sizes="100vw" role="presentation"></p></div></div></div></figure></div><div><div><p id="90e1">Apple has long integrated accessibility features into their software — and for good reason. By using accessibility features in your app, you’re allowing your app to reach a wider audience.</p><p id="d948">Sticking with their commitment to accessibility, Apple has introduced several new features at WWDC20 which help developers make their apps easier and more entertaining for users with disabilities. By making apps more accessible, developers eliminate the need for users to purchase clunky, expensive devices in order to use their apps — everything they need to interact with the app is built right into the device.</p><p id="df0d">In this article, you’ll learn about some of the biggest and best upgrades to accessibility, announced at this year’s WWDC.</p></div></div></section><hr><section><div><div><p id="ecb9">The first on the list is an interesting feature — which didn’t get talked about on stage. As the name suggests, Back Tap allows users to set single, double, or triple taps on the back of their iPhones and link them to certain tasks. For example, you could double tap on the back of your iPhone to open the weather app.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*-mtu69eu445jv1BwH76CoQ.jpeg?q=20" width="1200" height="732" role="presentation"></p><p><img src="https://miro.medium.com/max/2400/1*-mtu69eu445jv1BwH76CoQ.jpeg" width="1200" height="732" srcset="https://miro.medium.com/max/552/1*-mtu69eu445jv1BwH76CoQ.jpeg 276w, https://miro.medium.com/max/1104/1*-mtu69eu445jv1BwH76CoQ.jpeg 552w, https://miro.medium.com/max/1280/1*-mtu69eu445jv1BwH76CoQ.jpeg 640w, https://miro.medium.com/max/1400/1*-mtu69eu445jv1BwH76CoQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Setting up Back Tap on iOS 14.</figcaption></figure><p id="91c1">And since the tapping feature can be linked to Shortcuts, it opens up a whole range of possibilities with home automation and more! As seen in the example above, you could triple tap the back of your phone to quickly take notes, or you could use it to unlock your door when you’re about to enter the house. Easy, right?</p><p id="563c">For users with hearing impairments, Apple has added the ability to adjust sound frequencies on supported headphones. By doing this, users can now set their own preferences on what they want to hear more of and what they want to hear less of.</p><p id="dc81">The new feature also comes with pre-set profiles for specific outdoor situations, in case the user doesn’t want to manually configure the sound frequencies.</p><blockquote><p id="dba7">This new accessibility feature is designed to amplify soft sounds and adjust certain frequencies for an individual’s hearing, to help music, movies, phone calls, and podcasts sound more crisp and clear. Headphone Accommodations also supports Transparency mode on AirPods Pro, making quiet voices more audible and tuning the sounds of your environment to your hearing needs.</p><p id="8aab">— Apple Documentation</p></blockquote><p id="6a9f">Further, the new feature also supports Transparency Mode on AirPods Pro, which allows users to adjust how much of the surroundings they want to hear. If they want to amplify soft voices or listen to the environment in more detail, they now have that autonomy.</p><p id="d5d2">In the same vein, a new feature called <strong>Sound Recognition</strong> can pick up important sounds in the environment, such as Sirens, Fire Alarms, or Car Horns and alert the user of them. Through machine learning models built into the operating system, these sounds can be picked up and transmitted to the user in any way that they wish.</p></div></div></section><hr><section></section><hr><section><div><div><figure><div><div><div><div><p><img src="https://miro.medium.com/max/38/1*3WhAhhK1A2LktugVV3KGHw.png?q=20" width="700" height="1110" role="presentation"></p><p><img src="https://miro.medium.com/max/1400/1*3WhAhhK1A2LktugVV3KGHw.png" width="700" height="1110" srcset="https://miro.medium.com/max/552/1*3WhAhhK1A2LktugVV3KGHw.png 276w, https://miro.medium.com/max/1000/1*3WhAhhK1A2LktugVV3KGHw.png 500w" sizes="500px" role="presentation"></p></div></div></div></div><figcaption>Real-Time Text on the iPhone.</figcaption></figure><p id="2bf5">Group FaceTime calls have become more important than ever during the global pandemic, and Apple has added a small but important accessibility feature to them. Now, if a member of a group FaceTime call is using sign language to communicate, their video will be automatically pinned.</p><p id="ab6c">Using computer vision to detect this can be a boon to those with hearing loss, since reading sign language while the screen is moving around can be frustrating.</p><p id="43b4">In addition to this, Apple has made further improvements to its Real-Time Text feature, which is used for text based communication during phone calls. Previously, it was difficult for RTT users to multitask during phone calls, but it no longer requires the full screen.</p><p id="0458">When we think of accessibility on iOS, VoiceOver is often the first to come to mind. This year, VoiceOver received several significant updates, making it even more useful than before. If you aren’t familiar with it, VoiceOver is Apple’s screen reader, available on all platforms, including iOS, macOS, tvOS, and watchOS.</p><h2 id="ae54">VoiceOver Recognition</h2><p id="aa80">In the past, VoiceOver would require developers to adopt it inside their apps to work well on third-party apps.</p><blockquote><p id="210b">On-device intelligence recognizes key elements displayed on your screen to add VoiceOver support for app and web experiences that don’t have accessibility support built in. — Apple</p></blockquote><p id="2717">This year, Apple is tapping into their machine learning technology to semantically detect where and how to use VoiceOver on unsupported apps. This makes virtually all apps natively supported by VoiceOver and increases their accessibility for those with visual impairments.</p><h2 id="6119">Image Descriptions</h2><p id="6f0d">To make VoiceOver even more useful, Apple has used its computer vision library with <em>even more</em> machine learning to detect the contents of an image.</p><blockquote><p id="2f5f">VoiceOver reads complete-sentence descriptions of images and photos within apps and on the web. VoiceOver speaks the text it identifies within images and photos. — Apple</p></blockquote><p id="f5ed">Instead of simply stating that an image is present, VoiceOver can now provide detailed descriptions of what’s pictured in an image for more useful information to VoiceOver users. It can also detect text in an image through optical character recognition — another great way that machine learning is being used in the iOS 14 update!</p></div></div></section><hr><section><div><div><p id="d6f7">Evidently, there have been plenty of great updates at WWDC20 in accessibility, with even more that weren’t listed here. By releasing a large number of small features, Apple has made their devices more accessible than ever. And, they’ve supercharged many of their flagship accessibility solutions by coupling machine learning technology with them.</p><p id="ab7f">Be sure to <strong>smash that “clap” button</strong> as many times as you can, <strong>share this tutorial</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><hr><section><div><div><p id="08a6"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="7676"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="7977"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649963</guid>
            <pubDate>Fri, 26 Jun 2020 08:42:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3K, 60fps, 130ms: achieving it with Rust]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23649534">thread link</a>) | @lukastyrychtr
<br/>
June 26, 2020 | https://blog.tonari.no/why-we-love-rust?ref=twtr | <a href="https://web.archive.org/web/*/https://blog.tonari.no/why-we-love-rust?ref=twtr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>How we chose the Rust programming language to advance the state-of-the-art in real-time communication</p><div><p><i>T</i><m><i>his post was written collectively with Ryo Kawaguchi, </i></m><m><m><i>Andrea Law, Brian Schwind</i></m></m><m><i>.</i></m></p><p><m>Our goal for tonari is to build a virtual doorway to another space that allows for truly natural human interactions. Nearly two years in development, tonari is, to the best of our knowledge, the lowest-latency high resolution production-ready "teleconferencing" (we are truly not fond of that word) product available. </m></p><ul><li><b>130ms</b> glass-to-glass latency (the time from light hitting the camera to when it appears on-screen on the other side)</li><li><b>3K, 60fps</b> video transmission</li><li>High-bitrate 48kHz stereo audio</li></ul><p>Compare this to the typical <b>315-500ms</b> latency for Zoom and <m>WebRTC</m>, as measured between two laptops (X1 Carbon and MacBook Pro) on the same network at our office. It's a huge difference. It's the difference between constantly interrupting each other versus having a natural flow of conversation. It's the difference between a blurry face from a camera seemingly pointed up someone's nose versus a wide-view high fidelity image that smoothly transfers all the subtle body language of an in-person conversation.</p><div><picture><source srcset="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.jpg"><img src="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.jpg"></picture></div><p>Since launching <a href="https://blog.tonari.no/changing-communication-and-culture-in-an-organization" rel="noopener" target="_blank">our first pilot</a> in February, we've experienced no software-related downtime (tripping over ethernet cables is a different story). A<m>nd as much as we would love to think we're infallible engineers, we truly don't believe we could have achieved these numbers with this level of stability without Rust.</m></p><a href="#in-the-beginning-(or-why-we're-not-webrtc)" id="in-the-beginning-(or-why-we're-not-webrtc)"><h2>In the beginning (or: why we're not WebRTC)</h2></a><p>The <m>very</m> first tonari proof-of-concept used a basic projector, bluetooth speakers, and a website running on top of vanilla WebRTC (JavaScript). We've come a long way since those days.</p><p>While that prototype (and our opinionated vision of the future) got us grant funding, we knew that tonari would be dead on arrival unless we could<m> achieve </m><i>significantly</i> lower latency and higher fidelity than <m>WebRTC</m>—two things that aren't currently associated with video chat in 2020.</p><p>We figured, “Okay<i>, so we can just </i><m><i>modify</i></m><i> WebRTC directly and wrap it up with a slick UI in C++ and launch it in no time</i>.”</p><p>A week of struggling with WebRTC’s nearly 750,000 LoC <i>behemoth</i> of a codebase revealed just how painful a single small change could be — how hard it was to test, and feel truly <i>safe,</i> with the code you were dealing with.</p><a href="#let-there-be-light...weight-code" id="let-there-be-light...weight-code"><h3>Let there be light...weight code</h3></a><p>So in a furious (read: calm and thoroughly-discussed) rage quit we decided it was easier to re-implement the whole stack from scratch. We wanted to <i>know and understand every line of code</i> being run on our hardware, and it should be designed for the <i>exact</i> hardware we wanted.</p><p>Thus began our journey to the depths beyond high-level interfaces like a browser or existing RTC project, and into the world of low-level systems and hardware interaction from scratch.</p><p>We needed it to <m>be inherently </m><b><m><i>secure</i></m></b><m> to </m>protect the privacy of those who use tonari.  We needed it to be <b><i>performant</i></b> to make it feel as human and real-time as possible.  And we needed it to be <b><i>maintainable</i></b> as the code becomes more mature, as new brains show up and have to learn our work and expand on it.</p><p><m>We discussed and ruled out a handful of alternative approaches:</m></p><ul><li><b><i>Security: </i></b>C and C++ are memory- and concurrency-unsafe, and their disparate and seemingly infinite build systems make it hard to have a consistent and simple development experience.</li><li><i><b>Performance: </b></i>Java, <m>C#, and Go'</m>s memory management is opaque and can be difficult to work with in latency-sensitive applications where you want full control over your memory.</li><li><i><b>Maintainability: </b></i>Haskell, Nim, D, and a handful of other more bespoke languages tend to be more limited in tooling, community, and hire-ability.</li></ul><p>Rust is really the only production-ready language that we found confidently satisfies these needs.</p><a href="#finding-beauty-in-rust" id="finding-beauty-in-rust"><h2>Finding beauty in Rust</h2></a><p>Rust's beauty lies in the countless decisions made by the development community that constantly make you feel like you <m>can have</m> ten cakes and eat all of them too.</p><ul><li>Its build system is opinionated, and cleanly designed. It is itself a complete ecosystem that makes introducing new engineers to your project and setting up dev environments remarkably simple.</li><li>The memory and concurrency safety guarantees cannot be over-appreciated. We're confident that we wouldn't have done our first deployment yet if we had continued this in C++ - we'd still probably be stuck on subtle snags.</li><li>Our ability to interact at the lowest level with hardware via APIs like CUDA, oftentimes through existing <a href="https://crates.io/" rel="noopener" target="_blank"><m>crates</m></a> (Rust's term for a code library), has allowed us to have higher standards about the latency we want from our first production release.</li></ul><p>As tonari is getting more advanced, we're now choosing embedded microcontrollers whose firmware can be written in Rust so we don't have to leave our idyllic utopia into the old world of unsafe system programming.</p><a href="#crates-we-rely-on" id="crates-we-rely-on"><h2>Crates we rely on</h2></a><p>We're not going to <code>cat Cargo.toml</code> here, instead focusing on some select crates that have earned the prestigious award of a lifetime invitation to each of our birthday parties forever.</p><a href="#&quot;better-than-std&quot;-crates" id="&quot;better-than-std&quot;-crates"><h3>"Better-than-std" crates</h3></a><ul><li><a href="https://github.com/crossbeam-rs/crossbeam" rel="noopener" target="_blank"><code>crossbeam</code></a> is better for inter-thread communication than <code>std::sync::mpsc</code> in almost every way, and may be merged into <code>std</code> eventually.</li><li><a href="https://github.com/Amanieu/parking_lot" rel="noopener" target="_blank"><code>parking_lot</code></a> has a mutex implementation better than <code>std::sync::Mutex</code> in almost every way, and may be merged into the standard library (one day). It also provides many other useful synchronization primitives.</li><li><a href="https://github.com/tokio-rs/bytes" rel="noopener" target="_blank"><code>bytes</code></a> is a more robust, and often more performant, way to play with bytes compared to <code>Vec&lt;u8&gt;</code>.</li><li><a href="https://github.com/alexcrichton/socket2-rs" rel="noopener" target="_blank"><code>socket2</code></a> is what you will end up at if you are ever doing lower-level networking optimizations.</li></ul><a href="#beauty-supply" id="beauty-supply"><h3>Beauty supply</h3></a><ul><li><a href="https://github.com/daboross/fern" rel="noopener" target="_blank"><code>fern</code></a> is a dead-simple way to customize and prettify your logging output. We use it to keep our logs readable and internally standardized.</li><li><a href="https://github.com/TeXitoi/structopt" rel="noopener" target="_blank"><code>structopt</code></a> is how you always dreamed CLI arguments would be handled. There's no reason not to use it unless you're going for bare-minimum dependencies.</li></ul><a href="#cargo-cult-classics" id="cargo-cult-classics"><h3>Cargo cult classics</h3></a><ul><li><a href="https://github.com/sunng87/cargo-release" rel="noopener" target="_blank"><code>cargo-release</code></a> allows us to cut internal releases painlessly.</li><li><a href="https://github.com/est31/cargo-udeps" rel="noopener" target="_blank"><code>cargo-udeps</code></a> identifies unused dependencies and allows us to keep our build times minimal.</li><li><code>cargo tree</code> (recently integrated in cargo) shows a dependency tree that's useful in many ways, but <m>mainly</m> in identifying ways to minimize dependencies.</li><li><a href="https://github.com/rust-secure-code/cargo-geiger" rel="noopener" target="_blank"><code>cargo-geiger</code></a> helps us quickly evaluate external dependencies for possible security (or correctness) concerns.</li><li><a href="https://github.com/flamegraph-rs/flamegraph" rel="noopener" target="_blank"><code>cargo-flamegraph</code></a> helps us enormously when tracking down performance hot-spots in our code.</li></ul><a href="#project-structure" id="project-structure"><h2>Project structure</h2></a><p>The tonari codebase is a monorepo. At its root we have a Cargo workspace with a <code>binaries</code> crate, and a number of supporting library crates.</p><p>Having our crates in one repo makes them easy to reference in our <code>binaries</code> crate without needing to publish to <a href="https://crates.io/" rel="noopener" target="_blank">crates.io</a> or get too fancy with specifying git dependencies in our <code>Cargo.toml</code>. When the time comes to publish these libraries as open source, it's trivial to break it out into its own repo.</p><a href="#library,-binary,-why-not-both" id="library,-binary,-why-not-both"><h3>Library, binary, why not both?</h3></a><p>We have one main library crate that contains a unified API for talking to hardware, media codecs, network protocols, etc. Outside of that private API, we also have standalone crates in our workspace that we consider candidates for open-sourcing. For example, we’ve written our own actor framework fit for long-running high-throughput actors, as well as our own network protocol for reliable, high-bandwidth, low-latency media streaming.

We use separate binaries for different parts of the tonari system and each of these lives in <code>binaries</code>, a combination library/binary crate. Its library modules contains a set of reusable actors that combine our private API with our actor system, and then a collection of individual binaries that consume these actors and define the plumbing between them.</p><a href="#flags-as-far-as-the-eye-can-see" id="flags-as-far-as-the-eye-can-see"><h3>Flags as far as the eye can see</h3></a><p>We make extensive use of feature flags to allow development of our project on different OSes (like Brian's 1970s-era MacBook Pro) or different hardware configurations. This allows us to easily swap out camera hardware without extra runtime checks or using awful <code>sed</code> hacks.

For example, Linux uses <code>v4l2</code> (Video For Linux...2) to access most webcams, but other webcams might have their own SDK.  To compile for platforms that don't use <code>v4l2</code> or when an SDK isn't available for a particular OS, we can put those SDKs behind feature flags and export a common interface.

As a (simplified) concrete example, let's say we have a common camera interface defined as a trait:</p><pre><code><span>pub</span> <span>trait</span> Capture <span>{</span>
    
    <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span><span>;</span>
<span>}</span></code></pre><p>Let's also say we have three different camera interfaces - <code>v4l2</code>, <code>corevideo</code>, and <code>polaroid.</code> We can make our binaries work exclusively with this trait to be flexible, and we can swap in different implementations of <code>Capture</code> with feature flags.</p><pre><code><span>#[cfg(feature = "v4l2")]</span>
<span>mod</span> v4l2 <span>{</span>
    <span>pub</span> <span>struct</span> V4l2Capture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> V4l2Capture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "corevideo")]</span>
<span>mod</span> corevideo <span>{</span>
    <span>pub</span> <span>struct</span> CoreVideoCapture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> CoreVideoCapture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "polaroid")]</span>
<span>mod</span> polaroid <span>{</span>
    <span>pub</span> <span>struct</span> PolaroidCapture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> PolaroidCapture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "v4l2")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> v4l2<span>::</span>V4l2Capture<span>;</span>

<span>#[cfg(feature = "corevideo")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> corevideo<span>::</span>CoreVideoCapture<span>;</span>

<span>#[cfg(feature = "polaroid")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> polaroid<span>::</span>PolaroidCapture<span>;</span></code></pre><p>If we make our code work with things which implement the <code>Capture</code> trait instead of concrete types, we can now compile on and target various platforms by simply toggling feature flags. For example, we can have a struct which has a field - <code>video_capture: Box&lt;dyn Capture&gt;</code> which will let us store any type which can <code>Capture</code> from a camera.

An example <code>Cargo.toml</code> file to support the capture implementations we wrote above might look something like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tonari.no/why-we-love-rust?ref=twtr">https://blog.tonari.no/why-we-love-rust?ref=twtr</a></em></p>]]>
            </description>
            <link>https://blog.tonari.no/why-we-love-rust?ref=twtr</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649534</guid>
            <pubDate>Fri, 26 Jun 2020 07:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promote Imperfect People]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23647901">thread link</a>) | @svmanager
<br/>
June 25, 2020 | https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You’ve likely experienced it: “You’re above and beyond everything we’re asking. There’s no promotion this round but all you need to do is <strong>__</strong>_”. Insert a semi-important but not absolutely necessary thing. Even worse if it’s something you’re really not good at.</p>

<p>One of the most demotivating things that an organization or manager can do is requiring “perfection” for a promotion. It’s a problem with two main dimensions:</p>
<ul>
  <li>It’s incommensurate with the value being added to the business.</li>
  <li>Perfection is subjective.</li>
</ul>

<h2 id="incommensurate-with-value-add">Incommensurate with Value-Add</h2>

<p>Ultimately all performance comes down to one thing: how much value are you adding to the business? Examples of where forcing perfection gets things out of whack:</p>
<ul>
  <li>I coded up a feature that brought in $10M to the business this year. I wasn’t promoted because they said I don’t speak enough in meetings.</li>
  <li>I saved the company from collapse because I was the only one who knew how to debug the system when it was melting. I wasn’t promoted because they said I show up too late every day.</li>
  <li>I identified a winning strategy for the entire business that drove us to another echelon of success. I wasn’t promoted because my design docs have typos.</li>
</ul>

<p>All that matters is the value being added to the business. There are nuances where behavior can set bad examples or cause issues for others, but that detracts from value added to the business and should be considered. The unfortunate and unbelievably common case is that some sort of benign missing strength is held against people.</p>

<h2 id="perfection-is-subjective">Perfection is Subjective</h2>

<p>When managers go down the rabbit whole of chasing perfect promotions they’re much more likely to be biased. In reality, most people’s internal picture of a perfect candidate for a promotion is something like “what did I look like when I got promoted?” That’s often the closest image a manager has of what a promotion at that level looks like.</p>

<p>In mild cases you get things like “when I got promoted I had to walk in the snow to work, uphill both ways.”</p>

<p>In more severe cases you get things like:</p>
<ul>
  <li>Men who don’t promote women because they’re not “aggressive enough” or they “don’t speak up enough”</li>
  <li>Extroverts who don’t promote introverts because they don’t like public speaking.</li>
  <li>Non-parents who don’t promote parents because they don’t work until midnight in the office.</li>
</ul>

<p>Promote people based on impact to the business, not their style of delivery.  Don’t hold people down because they deliver value in a way that isn’t comfortable, known, or practiced by you.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In promotions and growth, focus more on amplifying strengths than fixing “weaknesses”.  You’ll find it’s much easier and much more fruitful to have people play to their strengths.</p>

<p>Promote imperfect people - that’s all you’ve got.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647901</guid>
            <pubDate>Fri, 26 Jun 2020 01:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The War on Upstart Fiber Internet Providers]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23647609">thread link</a>) | @joecool1029
<br/>
June 25, 2020 | http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/ | <a href="https://web.archive.org/web/*/http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>                                
                                    <div> 
                                        <p>As someone who grew up throughout the 90's and 00's, some of my fondest memories stem from progressive advancements in internet and computing technologies.  Upgrading from Dial-Up internet to DSL was a grand event in our house.  I remember my brother and I fighting over the computer day in and day out to play games like Wolfenstein - Enemy Territory, which was released in 2003. (I'm convinced that this will be the all-time best FPS game ever created.)  At around the same time, we upgraded to one of the best Dell computer's available at the time. It had 512MB of RAM and a Pentium 4 processor.  This was a major upgrade from our Compaq Celeron, which had something like 64MB of RAM. <br>
<img src="http://chrishacken.com/content/images/2020/03/MV5BOGFmNjMzZTktNDg2ZS00ZjllLTlkMTAtZTAzMzBkN2UyMzk2XkEyXkFqcGdeQXVyMjU3MzI1NzI@._V1_.jpg" alt="Wolfenstein - Enemy Territory"></p>

<p>Eventually, the grandeur of DSL faded as the rest of the world began to adopt Cable and Fiber internet.  It wasn't until I briefly moved to Philadelphia that I was finally able to experienced what I had been missing out on.  In college I lived in a neighborhood that was one of Verizon's first Fios builds.  I was absolutely blown away by the 25 Mbps connection.  This was in 2009. I'm amazed that over a decade later, in 2020, some households still don't have access to cable or fiber internet yet.</p>

<p>Like many of our customers do now, I could never figure out why it was so difficult to get us fiber service.  The cable is cheap, just throw it up on a pole and give me internet! Right?  Well, not so fast... <br>
<img src="http://chrishacken.com/content/images/2020/03/1849761.jpg" alt="Fiber Spaghetti"></p>

<p>A quick overview of how utility services are run and the challenges involved...</p>

<p>As most people know, there are primarily two ways to deliver utility services to a home or business.  Aerial and underground.  Water, gas, and sewer are always serviced underground for obvious reasons.  Electric, telephone, cable, and fiber have the ability to either be above or below ground.</p>

<h3 id="aerial">Aerial.</h3>

<p>As with anything else, aerial has pro's and con's.</p>

<p>The pro's are primarily upfront costs (this is debatable) and speed of deployment (this is also debatable).</p>

<p>The con's are that contrary to it being cheaper to physically deploy, the pole owners generally charge up-front make ready fee's.  These fees can range from $0 to upwards of $50,000/mile.  It's essentially pay to play.  If we want to attach to 50 poles, the pole owner might determine that 10 of those poles are old and need to be replaced before we can attach to them.  Rather than fork up the cash themselves, they'll force us to pay to replace their poles in order to approve the attachment.</p>

<p>In addition to that, there are the annual pole fee's.  Depending on your agreement, we've seen pole fee's ranging anywhere from $7/pole per year all the way up to $43/pole per year with 10% annual increases (I'm looking at you PPL.  This ridiculous rate was purely intended to keep us from attaching to their poles, IMO.  It's impossible to make money with these rates). <br>
<img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-22.04.34.png" alt="Pole Rates"></p>

<p>Another con is that even though installing the cable on poles is faster, it usually takes the pole owner around 6 months just to review applications and to determine make ready requirements and costs.  As an example, if we have fiber on a pole that's 1 pole short from being able to service your house, it would take at least 6 months just to run fiber to that one additional pole. So close, yet so far.</p>

<h3 id="underground">Underground.</h3>

<p>Like aerial, underground has its own list of pro's and con's.</p>

<p>When you install a service underground, you own it for life.  There are no annual fee's.  You pay one time to install it and you're set for life.  This sounds like a pro, but it's also a con.  When we run metro conduit, it generally costs us between $15-25/ft (not including customer drops).  For the sake of argument, let's assume we're at the high-end of our costs.  If we install 1,000ft of conduit, that's $25,000 that we need to pay out of pocket upfront.  Some blocks have upwards of 30 customers, but others have as little as 5.  Let's average it out at 20 customers per block, that's $1,250 upfront per customer, assuming we get every single customer.  Conservatively, we're initially looking at a 50% take rate.  This could grow to 100% overtime, but we never make that assumption. So that's $2,500/customer.  Imagine spending $2,500 per house/building and then have them tell you that your $69/m service is too expensive.  Generally speaking, we won't do a street unless our numbers look better than this, but this is a realistic scenario as we scale and get access to cheaper capital, etc.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/enorthampton01.jpg" alt="Underground Construction">
<img src="http://chrishacken.com/content/images/2020/03/enorthampton02.jpg" alt="Underground Construction Restoration"></p>

<h3 id="politics">Politics</h3>

<p>Cost issues aside, there are a number of other hurdles one needs to get past just to begin the process of building out a network.  You'd think that risking everything you have in an effort to bring your local economy into the 21st Century would be a welcome sight.  That's what I thought too; was I wrong.  While there are plenty of supporters (I truly appreciate you all), there are just as many, if not more, critics.</p>

<p>We've been fortunate enough to have had a handful of people get behind us overtime and give us a shot.  I'm sure others haven't had it so easy.  I know this because even after we've become an established player in our city throughout the past 4 years, neighboring townships and municipalities haven't been as opened armed to welcome us into their communities as I had anticipated or would have liked.</p>

<p>I'll go into more detail on small government policies that really hamper our ability to deploy underground later below.</p>

<h3 id="toomanyopinions">Too Many Opinions</h3>

<p>I'm generally a big fan of individual citizens trying to make an impact in their communities.  However, in too many cases these contributions seem to be made in the form of unproductive complaints rather than productive feedback or action.  Far too many people have a say in things that they probably shouldn't.</p>

<p><strong><em>Case A.</em></strong></p>

<p>A new customer had recently signed an agreement with us to run fiber into their building.  This is a non-profit who's members are selflessly donating their time to restore a landmark in the community.  Upon receiving their signature, I notified the city that we would be pulling a permit to connect the building in question to our underground network.  They said okay; that was that.  Our nearest existing hand hole is approximately 90ft to the right of the new customer's property; in front of another property.  As a courtesy, I notified the manager of that establishment to let her know that we would be performing work over the weekend, from Friday into Saturday.  They're closed Saturday and Sunday so I had assumed they would appreciate the notice and possibly even sign up with us.  The project would involve removing 90ft of sidewalk, running conduit, and then restoring the sidewalk with brand spankin' new concrete.  The total timespan that this would occur, from when our shovel hit the ground to having new sidewalks in place, would be 48 hrs.  The response that I received from a member of their organization made me facepalm.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-18.53.55-copy.png" alt="Sidewalk Issues"></p>

<p>Not long after receiving this email, I became aware that they didn't even own the building in question, nevermind the sidewalk.  They lease it.  This was eventually "resolved" after a series of negotiations between the non-profit's president and the establishment in question.  Often times we aren't as lucky.</p>

<p>We initially planned to have this new customer installed within a week of them signing the contract.  Now it will end up being around 2 months from start to finish.  Long story short, I learned my lesson in trying to be courteous.</p>

<p><strong><em>Case B.</em></strong></p>

<p>Last year we were installing conduit for our fiber optic network.  There were countless instances where people would literally stop their cars, roll down their windows, and yell profanities at us.  In what world is that acceptable behavior for an adult? I can't imagine being so far off my rocker that I would feel the need to yell at a bunch of construction workers trying to build a fiber optic network (not that they had any idea what we were doing).  If these are the types of people influencing decisions, there's something wrong.</p>

<p>City workers have a tough job fielding complaints from people like this and I commend them for it.  It shouldn't affect policy though.</p>

<p><strong><em>Case C.</em></strong></p>

<p>In another incident that took place not long, maybe a day or two, after <em>Case B</em> above.  A local store owner came back to us as we're swinging pick axes in 95 degree heat telling us we need to hurry up and we should hire more workers.  "My customers keep calling saying there's no where to park."  Mind you, we're standing right next to a massive parking lot that is approximately 1/3rd full.  I made my best attempt to kindly explain that paying 3 guys to stand around a hole to watch one person hand-dig to expose a utility isn't going to make our work go any faster.  I don't think he liked my response.</p>

<h3 id="theconsequences">The Consequences</h3>

<p>In many cases, resident complaints are justified.  Utility providers need to be held accountable for shitty restoration work.  However, the way in which bad restoration work is being combated is counter productive.  There has been a huge increase in curb-to-curb restoration requirements by local governments.  Essentially what these rules state is that anytime a utility cuts asphalt beyond a predetermined length, say 100ft, they are then responsible for replacing the entire road surface from the curb on the left side of the street to the curb on the right side of the street.  I believe some municipalities are also trying to introduce these measures to offload the costs of repaving roads themselves, similar to how pole owners force you to replace their aging utility poles under their make-ready requirements.  (One municipality told me as much when I attended a local council meeting in an effort to get them to waive this ridiculous ordinance for us.)</p>

<p>These policies will ultimately do more harm than good.  For us, these are the one and only thing preventing us from providing superior fiber internet services in these areas.  Forcing curb-to-curb asphalt …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</a></em></p>]]>
            </description>
            <link>http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647609</guid>
            <pubDate>Fri, 26 Jun 2020 00:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Santa Cruz bans predictive policing]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23647504">thread link</a>) | @wturner
<br/>
June 25, 2020 | https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing | <a href="https://web.archive.org/web/*/https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-01f39fcbb7868f9a53a1"><div><div><p>As officials mull steps to tackle police brutality and racism, California’s Santa Cruz has become the first&nbsp;U.S. city to ban predictive policing, which digital rights experts said could spark similar moves across the&nbsp;country.&nbsp;</p><p>“Understanding how predictive policing and facial recognition can be disportionately biased against&nbsp;people of color, we officially banned the use of these technologies in the city of Santa Cruz,” Mayor&nbsp;Justin Cummings said on Wednesday.&nbsp;</p><p>His administration will work with the police to “help eliminate racism in policing”, the seaside city’s first&nbsp;male African-American mayor said on his Facebook page, following a vote on Tuesday evening.&nbsp;</p><p>Used by police across the United States for almost a decade, predictive policing relies on algorithms to&nbsp;interpret police records, analyzing arrest or parole data to send officers to target chronic offenders, or&nbsp;identifying places where crime may occur.&nbsp;</p><p>But critics says it reinforces racist patterns of policing - low-income, ethnic minority neighbourhoods&nbsp;have historically been overpoliced so the data shows them as crime hotspots, leading to the deployment&nbsp;of more police to those areas.&nbsp;</p><p>“As Santa Cruz rightly recognized, predictive policing and facial recognition are dangerous, racially&nbsp;biased technologies that should never be used by our government,” said Matt Cagle, a lawyer with the&nbsp;ACLU.</p></div><p>PredPol Inc, the Santa Cruz-headquartered firm that pioneered the technology, said that it supported the city resolution’s requirement that predictive policing “will not perpetuate bias”, among other criteria. </p><p>  “Given the institutionalized state of racial inequality in America, this is a legitimate filter to be applied to any new technology acquired by a public entity, whether used for public safety or not,” it said on Twitter on Tuesday.   </p><p>Boston’s city council on Wednesday voted to ban face surveillance technology, a move also welcomed by digital rights activists.</p><p>Continue reading <a href="https://www.reuters.com/article/us-usa-police-tech-trfn/california-city-bans-predictive-policing-in-u-s-first-idUSKBN23V2XC">here</a></p></div></div></div>]]>
            </description>
            <link>https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647504</guid>
            <pubDate>Fri, 26 Jun 2020 00:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Draft of my perf book is ready – Easyperf]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23647025">thread link</a>) | @todsacerdoti
<br/>
June 25, 2020 | https://easyperf.net/blog/2020/06/24/Draft-Of-Perf-Book | <a href="https://web.archive.org/web/*/https://easyperf.net/blog/2020/06/24/Draft-Of-Perf-Book">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<hr>
<p><strong>Subscribe to my <a href="https://easyperf.net/blog/2020/06/24/Draft-Of-Perf-Book#mc_embed_signup">mailing list</a> and support me on <a href="https://www.patreon.com/dendibakh">Patreon</a>.</strong></p>

<hr>

<p><strong>It has been a long journey!</strong> I was silent for a while, haven’t posted regularly on my blog. But don’t worry, I’m fine. Instead, I took this situation around coronavirus and focused on writing a book “<em>Performance Analysis and Tuning on Modern CPU</em>”. I started writing this book almost a year ago, so I’m happy I finally can show something to the people. Right now, the <strong>early draft is ready and I’m welcoming everybody to review the book and maybe even add something to it</strong>. I know a lot of people are struggling right now, so I decided to make the book <strong>FREE</strong> for all. Eventually, everyone will be able to download PDF version of it.</p>

<p><strong>Why I started it?</strong> I started this book with one simple goal in mind: educate developers to better understand performance of their applications running on modern HW. Most of developers are used to look no further than the source code of their application without trying to understand performance implications of the changes they make. I know for many of us what happens under the hood is sort of black matter. I know it’s hard, but hopefully with this book, performance world of modern HW will become more accessible.</p>

<p><strong>What is the book about?</strong> Have you ever debated with a coworker about performance of a certain piece of code? Then you probably know how hard it is to predict which version is going to work best. With so many moving parts inside the modern processors even a small tweak to the code can trigger significant performance change. Besides all its complexity, HW has many features that support performance analysis. That’s right, CPUs are capable of telling us what performance bottlenecks are and where they occur. Thus, the book focuses on how your code looks like from the CPU perspective and provides recipes for HW specific optimizations. The core of the book is centered around how to find the right place in the code to improve performance.</p>

<p>Below I present the sweetest parts of the book contents:</p>
<div><div><pre><code>1. Introduction
2. Measuring Performance
3. CPU Microarchitecture 101
4. Terminology And Metrics In Performance Analysis
5. Performance Analysis Approaches
  5.1. Code Instrumentation
  5.2. Tracing
  5.3. Workload Characterization
  5.4. Sampling
  5.5. Static Performance Analysis
  5.6. Compiler Optimization Reports
6. CPU Features For Performance Analysis
  6.1. Top-Down Microarchitecture Analysis (TMAM)
  6.2. Last Branch Record (LBR)
  6.3. Processor Event-Based Sampling (PEBS)
  6.4. Intel Processor Traces (PT)
7. Source Code Tuning For CPU
  7.1. Data-Driven Optimizations
  7.2. CPU Front-End Optimizations
  7.3. CPU Back-End Optimizations
  7.4. Optimizing Bad Speculation
  7.5. Other Tuning Areas
8. Optimizing Multithreaded Applications
</code></pre></div></div>

<p><strong>Who is this book for?</strong> Primarily, this book is written for developers working in performance critical projects. This includes the following areas: High performance computing (HPC), High Frequency Trading (HFT), GameDev, Data Centers (Facebook, Google, etc), and other areas. But I hope it will be useful for any C++ developer: you can use this book to learn performance analysis which will stack up nicely with other skills you might have. All examples in the book are written in C/C++, but to the large extent they are applicable to any native programming language (like C, C++, Rust, Go and even Fortran). While this book is fairly low-level, I hope, it will be accessible even to developers that are just starting performance related work.</p>

<p>I gave this book all my knowledge and experience and I’m eager to share it with community. I decided to make this book open to everyone and <strong>I welcome everyone to review and contribute to the book</strong>. I hope, this way we can combine best performance practices and expertise from people in different areas.</p>

<p><strong>Shoot me an email or leave a comment if you are interested.</strong></p>


			</div></div>]]>
            </description>
            <link>https://easyperf.net/blog/2020/06/24/Draft-Of-Perf-Book</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647025</guid>
            <pubDate>Thu, 25 Jun 2020 23:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use ProxyJump with SSH for VMs with No Public IPs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646848">thread link</a>) | @rbekker87
<br/>
June 25, 2020 | https://blog.ruanbekker.com/blog/2020/06/13/using-proxyjump-with-ssh-for-vms-with-no-public-ips/ | <a href="https://web.archive.org/web/*/https://blog.ruanbekker.com/blog/2020/06/13/using-proxyjump-with-ssh-for-vms-with-no-public-ips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://img.sysadmins.co.za/wngib2.png" alt="ssh-proxy-jump"></p>

<p>I have a dedicated server with LXD installed where I have a bunch of system containers running to host a lot of my playground services, and to access the operating system of those lxc containers, I need to SSH to the LXD host, then exec or ssh into that LXC container.</p>

<p>This became tedious and wanted a way to directly ssh to them, as they don’t have public ip addresses, it’s not possible but found its possible to access them using proxyjump.</p>

<figure><div><table><tbody><tr><td><pre><span>1</span>
</pre></td><td><pre><code><span>[you] -&gt; [hypervisor] -&gt; [vm on hypervisor]</span></code></pre></td></tr></tbody></table></div></figure>


<p>First step is to create our ssh key:</p>

<figure><div><table><tbody><tr><td><pre><span>1</span>
</pre></td><td><pre><code><span>$ ssh-keygen -t rsa</span></code></pre></td></tr></tbody></table></div></figure>


<p>Add the created public key (<code>~/.ssh/id_rsa.pub</code>) on the hypervisor and the target vm’s <code>~/.ssh/authorized_key</code> files.</p>

<p>Then create the SSH Config on your local workstation (<code>~/.ssh/config</code>):</p>

<figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
<span>5</span>
<span>6</span>
<span>7</span>
<span>8</span>
<span>9</span>
<span>10</span>
<span>11</span>
<span>12</span>
<span>13</span>
<span>14</span>
</pre></td><td><pre><code><span>Host *
</span><span>  StrictHostKeyChecking no
</span><span>  UserKnownHostsFile=/dev/null
</span><span>
</span><span>Host hypervisor
</span><span>  Hostname hv.domain.com
</span><span>  User myuser
</span><span>  IdentityFile ~/.ssh/id_rsa
</span><span>
</span><span>Host ctr1
</span><span>  Hostname 10.37.117.132
</span><span>  User root
</span><span>  IdentityFile ~/.ssh/id_rsa
</span><span>  ProxyJump hypervisor</span></code></pre></td></tr></tbody></table></div></figure>


<p>Now accessing our lxc container ctr1, is possible by doing:</p>

<figure><div><table><tbody><tr><td><pre><span>1</span>
<span>2</span>
<span>3</span>
<span>4</span>
</pre></td><td><pre><code><span>$ ssh ctr1
</span><span>Warning: Permanently added 'x,x' (ECDSA) to the list of known hosts.
</span><span>Warning: Permanently added '10.37.117.132' (ECDSA) to the list of known hosts.
</span><span>root@ctr1~ $</span></code></pre></td></tr></tbody></table></div></figure>

</div></div>]]>
            </description>
            <link>https://blog.ruanbekker.com/blog/2020/06/13/using-proxyjump-with-ssh-for-vms-with-no-public-ips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646848</guid>
            <pubDate>Thu, 25 Jun 2020 23:11:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Integrity Protection in Presto]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646838">thread link</a>) | @findepi
<br/>
June 25, 2020 | https://prestosql.io/blog/2020/06/25/data-integrity-protection.html | <a href="https://web.archive.org/web/*/https://prestosql.io/blog/2020/06/25/data-integrity-protection.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It all started on an Thursday afternoon in March, when <a href="https://github.com/sopel39">Karol Sobczak</a>
was grilling Presto with heavy rounds of benchmarks, as we were ramping up to Starburst Enterprise
Presto 332-e release. Karol discovered what seemed to be a serious regression, and turned out to be even more
serious Cloud environment issue.</p>

<!--more-->



<p>At the Presto project, we take serious care of stability and efficiency, so releases undergo
rigorous performance benchmarks. The intention is to safe guard against any performance regressions
or stability problems. Usually, the performance improvements are benchmarked separately when they
are being added to the codebase. At Starburst, those benchmarks are even more important, especially
for the Starburst Enterprise Presto LTS releases.</p>

<p>On a side note, we use <a href="https://github.com/prestosql/benchto/">Benchto</a> for organizing
<a href="https://github.com/prestosql/presto/tree/master/presto-benchto-benchmarks">Presto benchmark suites</a>,
executing them and collecting the results. We use managed <a href="https://kubernetes.io/">Kubernetes</a> in a public
cloud for provisioning Presto clusters, along with <a href="https://www.starburstdata.com/presto-on-kubernetes/">Starburst Enterprise Presto Kubernetes</a>.
We use <a href="https://jupyter.org/">Jupyter</a> for producing result reports in HTML and PDF formats.</p>



<p>It all started in March, when <a href="https://github.com/sopel39">Karol Sobczak</a>
was grilling Presto with heavy rounds of benchmarks for the Starburst Enterprise Presto 332-e release.
On one Thursday afternoon he reported stability problems, with few benchmark runs failing with
exceptions similar to:</p>

<div><div><pre><code>Query failed (#20200326_150852_00338_dj225): Unknown block encoding:
LONG_ARRAY� � �� � @@@���� �@  @ � �@@@ @@� @�@D�� @@��@ `� @@� @#�@ � 0�
... (9550 more bytes)
</code></pre></div></div>

<p>In Presto, a block encoding is a way of encoding a particular Block type (here, a <code>LongArrayBlock</code>).
They are used when exchanging blocks of data between Presto nodes, or in spill to disk.
Blocks form a polymorphic class hierarchy, so every time a block is encoded, we need
to also store the encoding identifier. The encoding identifier (here, the <code>LONG_ARRAY</code> string)
is written as <code>&lt;string length&gt;</code> (4-byte, signed integer in little-endian) followed by
<code>&lt;string bytes&gt;</code> containing the UTF-8 representation of the encoding id. Clearly, in the case above,
the receiver read the <code>&lt;encoding id length&gt;</code> as 9623 instead of 10! How could that be ever possible?</p>

<p>Presto 332 brought a lot of good changes and upgrade to Java 11 was one of them.
Therefore, Starburst Enterprise Presto 332-e was the first Starburst release using Java 11 by default.
For earlier releases, we ran benchmarks using AWS EC2 machines orchestrated with <a href="https://www.starburstdata.com/presto-aws-cloud/">Starburst’s Presto
CloudFormation Template (CFT)</a>. This was also the first time we did
Presto release benchmarks running on Kubernetes clusters, with AWS EKS. We could suspect many different factors
as being the cause. We started to sift through the code, search team’s “collective brain” and
the Internet for any ideas. One of the important sources was Vijay Pandurangan’s writeup on <a href="https://tech.vijayp.ca/linux-kernel-bug-delivers-corrupt-tcp-ip-data-to-mesos-kubernetes-docker-containers-4986f88f7a19">data
corruption bug discovered by Twitter in 2015</a>. Of course, we also repeated benchmark runs. Seeing is believing.</p>



<p>On the next day, a customer reported similar problems with their Presto cluster. Of course, they
were not running a yet-to-be-released version that we were still benchmarking. They run into what seemed to
be a very serious regression in a Starburst Enterprise Presto 323-e release line. The customer was also using
the AWS cloud, but not the Kubernetes deployment. They were using <a href="https://www.starburstdata.com/presto-aws-cloud/">CFT-based deployment</a>
– the same stack we were using for all our release benchmarks so far – and we had never run into issues like this before.
As the customer was using a fresh-off-press latest minor release, we decided (in spirit of global health care trend)
to “quarantine” that release and roll back the customer installation to the previous version.</p>

<p>However, the fact that a small bug fix release triggered data problems was unnerving. The fact that we
did not discover any of these problems before, was even more unnerving.</p>



<p>As we were running more and more, and even more test runs, we discovered new failure modes.
For example:</p>
<div><div><pre><code>Query failed (#20200327_001931_00020_8di4r): Cannot cast DECIMAL(7, 2) '18734974449861284.67' to DECIMAL(12, 2)
</code></pre></div></div>
<p>Well, this message is not <em>wrong</em>. It’s not possible to cast <code>18734974449861284.67</code> to <code>DECIMAL(12, 2)</code>.
Except that it is <em>also</em> not possible to have a <code>DECIMAL(7, 2)</code> with such value. Something wrong happened to the
data. At that moment, we realized the problem was very serious, because data could become corrupted.
This corrupted data could lead to a failure (like above), but it could also lead to incorrect query results,
or incorrect data being persisted (in case of <code>INSERT</code> or <code>CREATE TABLE AS</code> queries). We created
a virtual War Room (that is, a Slack channel), got together all Presto experts and our experienced field team
to discuss potential causes, further diagnostics and mitigation strategies.</p>

<p>Since the problem was affecting data exchanges between Presto nodes, we listed the following strategies
to try to dissect the problem:</p>

<ul>
  <li>determining which query (queries) is (are) causing failures,</li>
  <li>running with HTTP/2,</li>
  <li>reverting to running on Java 8,</li>
  <li>enabling exchange compression (as decompression is very sensitive to data corruption),</li>
  <li>trying to upgrade Jetty,</li>
  <li>determining whether failures correlate with JVM GC activity,</li>
  <li>inspecting the source code.</li>
</ul>



<p>We were able to quickly prototype and verify some of the ideas. Switching to HTTP/2 or
upgrading Jetty to the latest version did not help. Nor did downgrading to Jetty version
that had been using for a long time. We also verified that problem was reproducible with Java 8,
so we concluded Java 11 was not the cause of it.</p>



<p>We identified the problem occurs somewhere within exchanges, between one Presto worker
node serializing a <code>Page</code> object (basic unit of data processing in Presto) and another node
deserializing it.</p>

<p>While decimal cast failure didn’t directly point at the data corruption problem (there could
be many other reasons for it), there was no other explanation for the <code>Unknown block encoding</code> exceptions.
The serialization is done in <code>PagesSerde.serialize</code> (used by <code>TaskOutputOperator</code>, the data sender) and
deserialization is done in <code>PagesSerde.deserialize</code> (used by <code>ExchangeOperator</code>, the
receiver of the data). As the logic is nicely encapsulated in <code>PagesSerde</code> class, we
added checksums to the serialized data: <code>&lt;checksum&gt; &lt;serialized page&gt;</code>.
This felt like a smart move – except that it gave us nothing more than a confirmation that
there is a problem (“checksum failure”).
This we already knew.</p>

<p>We considered adding logging to capture data going out from one node and going in on
another node, but that would be huge amount of logs. One run of benchmarks transfers
hundreds of terabytes of data between the nodes.</p>

<p>We went ahead and created a Presto build that added data redundancy to be able to reconstruct
the data on the receiving side.
There are many <a href="https://en.wikipedia.org/wiki/Erasure_code">well-known error-correction codes</a>
(e.g. <a href="https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction">Reed–Solomon error correction</a>
available in Hadoop 3). In our case, speed of <em>implementation</em> (a.k.a. simplicity) was a deciding factor,
so we added data mirroring: <code>&lt;checksum&gt; &lt;serialized page&gt; &lt;serialized page&gt;</code>.
In order to avoid logging of all the data exchanges, we added the deserialized pages (both copies)
to the exceptions being raised.</p>

<div><div><pre><code>java.sql.SQLException: Query failed (#20200401_113622_00676_p7qp7): Hash mismatch, read: 1251072184702746109, calculated: 7591448164918409110
	Suppressed: java.lang.RuntimeException: Slice, first half: 040000000A0000004C4F4E475F415252.... (945 kilobytes)
    Suppressed: java.lang.RuntimeException: Slice, secnd half: 040000000A0000004C4F4E475F415252.... (945 kilobytes)
</code></pre></div></div>

<p>The exception told us the first part was changed, since read checksum did not match the calculated
checksum (it was calculated based on the first copy of the data and was different than the checksum
calculated on the sending side).
Having the encoded data in the exception like that, it was easy to extract the actual data and compare,
so now we could see <em>how</em> the data was changed.</p>

<div><div><pre><code>cat failure.txt | grep 'Slice, first half' | cut -d: -f4- | sed 's/^ *//' | xxd -r -p &gt; changed
cat failure.txt | grep 'Slice, secnd half' | cut -d: -f4- | sed 's/^ *//' | xxd -r -p &gt; original
</code></pre></div></div>

<p>Comparing binary files is fun, but in practice it can be more convenient to compare <code>hexdump</code> output.
The output below was created with <code>vimdiff &lt;(hexdump -Cv original) &lt;(hexdump -Cv changed)</code>.</p>
<div><div><pre><code>++--6064 lines: 00000000  04 00 00 00 0a 00 00 00  4c 4f 4...|+ +--6064 lines: 00000000  04 00 00 00 0a 00 00...
 00017b00  00 cb 6a 25 00 00 00 00  00 cb 6a 25 00 00 00 00  |  00 cb 6a 25 00 00 00 00  00 cb 6a 25 00 00 00 00
 00017b10  00 cb 6a 25 00 00 00 00  00 cb 6a 25 00 00 00 00  |  00 cb 6a 25 00 00 00 00  00 cb 6a 25 00 00 00 00
 00017b20  00 cb 6a 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 cb 6a 25 00 00 00 00  00 e1 67 25 00 00 00 00
 00017b30  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00
 00017b40  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00
 00017b50  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00
 00017b60  00 e1 67 25 00 00 00 00  00 e1 67 25 00 00 00 00  |  00 e1 67 25 00 00 00 00  e1 67 25 00 00 00 00 00
 00017b70  00 e1 67 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  e1 67 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017b80  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017b90  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017ba0  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017bb0  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017bc0  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 00 00 00
 00017bd0  00 fb 69 25 00 00 00 00  00 fb 69 25 00 00 00 00  |  fb 69 25 00 00 00 00 00  fb 69 25 00 00 …</code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prestosql.io/blog/2020/06/25/data-integrity-protection.html">https://prestosql.io/blog/2020/06/25/data-integrity-protection.html</a></em></p>]]>
            </description>
            <link>https://prestosql.io/blog/2020/06/25/data-integrity-protection.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646838</guid>
            <pubDate>Thu, 25 Jun 2020 23:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3D human shape estimation from photo and video]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646602">thread link</a>) | @interweb
<br/>
June 25, 2020 | https://shunsukesaito.github.io/PIFuHD/ | <a href="https://web.archive.org/web/*/https://shunsukesaito.github.io/PIFuHD/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://shunsukesaito.github.io/PIFuHD/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646602</guid>
            <pubDate>Thu, 25 Jun 2020 22:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foam, a personal knowledge management and sharing system for VSCode]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646507">thread link</a>) | @radus
<br/>
June 25, 2020 | https://foambubble.github.io/foam/ | <a href="https://web.archive.org/web/*/https://foambubble.github.io/foam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<p><strong>Foam</strong> is a personal knowledge management and sharing system inspired by <a href="https://roamresearch.com/">Roam Research</a>, built on <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>.</p>

<p>You can use <strong>Foam</strong> for organising your research, keeping re-discoverable notes, writing long-form content and, optionally, publishing it to the web.</p>

<p><strong>Foam</strong> is free, open source, and extremely extensible to suit your personal workflow. You own the information you create with Foam, and you’re free to share it, and collaborate on it with anyone you want.</p>

<blockquote>
  <p><strong>In a rush?</strong> You <em>could</em> jump to <a href="#getting-started">Getting started</a>, but I highly recommend reading the introductory sections first. <strong>Foam</strong> isn’t obvious.</p>
</blockquote>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#foam">Foam</a>
    <ul>
      <li><a href="#table-of-contents">Table of Contents</a></li>
      <li><a href="#how-do-i-use-foam">How do I use Foam?</a></li>
      <li><a href="#whats-in-a-foam">What’s in a Foam?</a></li>
      <li><a href="#getting-started">Getting started</a></li>
      <li><a href="#features">Features</a></li>
      <li><a href="#call-to-adventure">Call To Adventure</a></li>
      <li><a href="#thanks-and-attribution">Thanks and attribution</a></li>
      <li><a href="#license">License</a></li>
    </ul>
  </li>
</ul>

<h2 id="how-do-i-use-foam">How do I use Foam?</h2>

<p><strong>Foam</strong> is a tool that supports creating relationships between thoughts and information to help you think better.</p>

<p><img src="https://foambubble.github.io/foam/assets/images/foam-navigation-demo.gif" alt="Short video of Foam in use"></p>

<p>Whether you want to build a <a href="https://www.buildingasecondbrain.com/">Second Brain</a> or a <a href="https://zettelkasten.de/posts/overview/">Zettelkasten</a>, write a book, or just get better at long-term learning, <strong>Foam</strong> can help you organise your thoughts if you follow these simple rules:</p>

<ol>
  <li><a href="https://github.com/foambubble/foam-template/generate">Create a single <strong>Foam</strong> workspace</a> for all your knowledge and research.</li>
  <li>Write your thoughts in markdown documents (I like to call them <strong>Bubbles</strong>, but that might be more than a little twee). These documents should be atomic: Put things that belong together into a single document, and limit its content to that single topic. (<a href="https://zettelkasten.de/posts/overview/#principles">source</a>)</li>
  <li>Use Foam’s shortcuts and autocompletions to link your thoughts together with <code>[[wiki-links]]</code>, and navigate between them to explore your knowledge graph.</li>
  <li>Get an overview of your <strong>Foam</strong> workspace using a [<a href="https://foambubble.github.io/foam/graph-visualisation" title="Graph visualisation">graph-visualisation</a>] (⚠️ WIP), and discover relationships between your thoughts with the use of [<a href="https://foambubble.github.io/foam/backlinking" title="Backlinking">backlinking</a>].</li>
</ol>

<p>Foam is a like a bathtub: <em>What you get out of it depends on what you put into it.</em></p>

<h2 id="whats-in-a-foam">What’s in a Foam?</h2>

<p>Like the soapy suds it’s named after, <strong>Foam</strong> is mostly air.</p>

<ol>
  <li>The editing experience of <strong>Foam</strong> is powered by VS Code, enhanced by workspace settings that glue together [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] and preferences optimised for writing and navigating information.</li>
  <li>To back up, collaborate on and share your content between devices, Foam pairs well with <a href="http://github.com/">GitHub</a>.</li>
  <li>To publish your content, you can set it up to publish to <a href="https://pages.github.com/">GitHub Pages</a> with zero code and zero config, or to any website hosting platform like <a href="http://netlify.com/">Netlify</a> or <a href="https://foambubble.github.io/foam/vercel">Vercel</a>.</li>
</ol>

<blockquote>
  <p><strong>Fun fact</strong>: This documentation was researched, written and published using <strong>Foam</strong>.</p>
</blockquote>

<h2 id="getting-started">Getting started</h2>

<blockquote>
  <p>⚠️ Foam is still in preview. Expect the experience to be a little rough.</p>
</blockquote>

<p>These instructions assume you have a GitHub account, and you have Visual Studio Code installed.</p>

<ol>
  <li><a href="https://github.com/foambubble/foam-template/generate">Create a GitHub repository from foam-template</a>. If you want to keep your thoughts to yourself, remember to set the repository private.</li>
  <li>Clone the repository and open it in VS Code.</li>
  <li>When prompted to install recommended extensions, click <strong>Install all</strong> (or <strong>Show Recommendations</strong> if you want to review and install them one by one)</li>
</ol>

<p>After setting up the repository, open <a href="https://foambubble.github.io/foam/.vscode/settings.json">.vscode/settings.json</a> and edit, add or remove any settings you’d like for your Foam workspace.</p>

<p>To learn more about how to use <strong>Foam</strong>, read the [<a href="https://foambubble.github.io/foam/recipes" title="Recipes">recipes</a>].</p>

<p>There are [<a href="https://foambubble.github.io/foam/known-issues" title="Known Issues">known-issues</a>], and I’m sure, many unknown issues! Please <a href="http://github.com/foambubble/foam/issues">report them on GitHub</a>!</p>

<h2 id="features">Features</h2>

<p><strong>Foam</strong> doesn’t have features in the traditional sense. Out of the box, you have access to all features of VS Code and all the [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] you choose to install, but it’s up to you to discover what you can do with it!</p>

<p>Head over to [<a href="https://foambubble.github.io/foam/recipes" title="Recipes">recipes</a>] for some useful patterns and ideas, and</p>

<h2 id="call-to-adventure">Call To Adventure</h2>

<p>The goal of <strong>Foam</strong> is to be your personal companion on your quest for knowledge.</p>

<p>It’s is currently about “10% ready” relative to all the features I’ve thought of, but I’ve only thought of ~1% of the features it could have, and I’m excited to learn from others.</p>

<p>I am using it as my personal thinking tool. By making it public, I hope to learn from others not only how to improve Foam, but also to improve how I learn and manage information.</p>

<p>If that sounds like something you’re interested in, I’d love to have you along on the journey.</p>

<ul>
  <li>Check out [<a href="https://foambubble.github.io/foam/roadmap" title="Roadmap">roadmap</a>] to see what’s in the plans</li>
  <li>Read about our [<a href="https://foambubble.github.io/foam/principles" title="Principles">principles</a>] to understand Foam’s philosophy and direction</li>
  <li>Read the [<a href="https://foambubble.github.io/foam/contribution-guide" title="Contribution Guide">contribution-guide</a>] guide to learn how to participate.</li>
  <li>Feel free to open <a href="https://github.com/foambubble/foam/issues">GitHub issues</a> to give me feedback and ideas for new features.</li>
</ul>

<h2 id="thanks-and-attribution">Thanks and attribution</h2>

<p><strong>Foam</strong> is built by <a href="https://github.com/jevakallio">Jani Eväkallio</a> (<a href="https://twitter.com/jevakallio">@jevakallio</a>).</p>

<p><strong>Foam</strong> was inspired by <a href="https://roamresearch.com/">Roam Research</a> and the <a href="https://zettelkasten.de/posts/overview">Zettelkasten methodology</a></p>

<p><strong>Foam</strong> wouldn’t be possible without <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>, and relies heavily on our fantastic open source [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] and all their contributors:</p>

<h2 id="license">License</h2>

<p>Foam is licensed under the <a href="https://foambubble.github.io/foam/license">MIT license</a>.</p>






      
      
      
    </div></div>]]>
            </description>
            <link>https://foambubble.github.io/foam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646507</guid>
            <pubDate>Thu, 25 Jun 2020 22:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Convert CSV to JSON on the Fly with Lambda]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646359">thread link</a>) | @rbekker87
<br/>
June 25, 2020 | http://sysadmins.co.za/convert-csv-to-json-files-with-aws-lambda-and-s3-events/ | <a href="https://web.archive.org/web/*/http://sysadmins.co.za/convert-csv-to-json-files-with-aws-lambda-and-s3-events/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>I am a massive AWS Lambda fan, especially with workflows where you respond to specific events.</p><p>In this tutorial, I will keep it basic to demonstrate the power of how you can trigger a AWS Lambda function on a S3 PUT event, so that this can give the reader a basic demonstration to go further and build amazing things.</p><h2 id="what-will-we-be-doing">What will we be doing?</h2><p>In this tutorial we will be converting CSV files to JSON with the help of Lambda using the Python language.</p><p>The workflow will be like this:</p><ul><li>User uploads his csv file to S3, lets say bucket/input/*.csv</li><li>We then use CloudWatch events to trigger when data is uploaded to the bucket/uploads/input prefix and has a suffix of .csv</li><li>We will then trigger our Lamda function to convert the CSV file and write the JSON file to bucket/uploads/output/{year}/{month}/{day}/{timestamp}.json</li></ul><p>You can go furhter than that by using <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html">S3 Lifecycle Policies</a> to delete objects when they are &nbsp;older than, lets say 30 days.</p><h2 id="create-the-s3-bucket">Create the S3 Bucket</h2><p>Head over to <a href="https://s3.console.aws.amazon.com/s3/home?region=eu-west-1">AWS S3</a> and create a New Bucket (or use an existing one):</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78825295-031ba500-79e0-11ea-8ffc-7b5e23522cc6.png"></figure><!--kg-card-end: image--><p>Use a descriptive name of your choice:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78825341-17f83880-79e0-11ea-8804-c3ab44da35ee.png"></figure><!--kg-card-end: image--><p>Then your S3 bucket should appear in your console:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78825524-6efe0d80-79e0-11ea-8dd5-9869bd9d312c.png"></figure><!--kg-card-end: image--><h2 id="create-your-lambda-function">Create your Lambda Function</h2><p>Head over to <a href="https://eu-west-1.console.aws.amazon.com/lambda/home?region=eu-west-1#/functions">AWS Lambda</a> and create a function. I will be using Python 3.7 and will be calling it <code>csv-to-json-function</code>:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78825757-c603e280-79e0-11ea-9407-806388172dd5.png"></figure><!--kg-card-end: image--><p>You can then save the function as is, we will come back to the code.</p><h2 id="s3-events">S3 Events</h2><p>So what we essentially want to do, when ever someone uploads an object to S3, which <strong>MUST</strong> match the prefix <code>uploads/input</code> and has the suffix of <code>.csv</code> we want to trigger our Lambda function to act on that event to load the CSV and convert that object to JSON.</p><p>Head over to your S3 Bucket:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826033-2a26a680-79e1-11ea-8aa5-40a7ae3dcd49.png"></figure><!--kg-card-end: image--><p>Select properties and and select events:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826079-3b6fb300-79e1-11ea-85ee-4207f8f51a4b.png"></figure><!--kg-card-end: image--><p>and you should see:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826115-49253880-79e1-11ea-90f7-eae542ac15a2.png"></figure><!--kg-card-end: image--><p>click add notification and provide what needs to happen. This step is <strong>very importantand should not be done wrong</strong> as it <strong>could incur in a lot of costs</strong> f done wrong.</p><p>We are configuring this S3 Event to trigger a Lambda Function when a object is created with a prefix for example: <code>uploads/input/data.csv</code> , lets say for example your Lambda &nbsp;function writes a <code>.csv</code> file back to the input prefix, your Lambda will go in a triggering loop and will cost a LOT of money, so we have to make sure that our event only listens for <code>.csv</code> suffixes on a <code>uploads/input</code> prefix.</p><p>Provide a Name, on the PUT event, provide the prefix <code>uploads/input</code> as an example, then provide the suffix <code>.csv</code> as we only want to trigger if csv files are uploaded and trigger your Lambda function:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826304-943f4b80-79e1-11ea-9272-827e61e39bcf.png"></figure><!--kg-card-end: image--><p>it should look like:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826346-a620ee80-79e1-11ea-8004-04a7bacd1d65.png"></figure><!--kg-card-end: image--><h2 id="iam-user">IAM User</h2><p>Now we want to create a IAM user that will be uploading the CSV files to S3.</p><p>Head over to <a href="https://console.aws.amazon.com/iam/home?region=eu-west-1">IAM</a>, select Policies, Create Policy:</p><!--kg-card-begin: code--><pre><code>{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            "Action": [
                "s3:PutObject"
            ],
            "Resource": "arn:aws:s3:::ruanbekker.demo.blogpost/uploads/input/*"
        }
    ]
}
</code></pre><!--kg-card-end: code--><p>I will call this policy <code>s3-uploads-csv-policy</code>, select users, create a new user and tick programmatic access:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826816-73c3c100-79e2-11ea-8987-36a9c974cf01.png"></figure><!--kg-card-end: image--><p>Hit next, assign the policy to the user:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/78826865-8938eb00-79e2-11ea-8e98-34bcc15b5013.png"></figure><!--kg-card-end: image--><p>Hit create user and make note of your aws access and secret key as the secret key is not retrievable after creation:</p><!--kg-card-begin: code--><pre><code>AKIAXXXXXXXXXXXXXXXX
ZCTfXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
</code></pre><!--kg-card-end: code--><p>Head to your terminal and configure the credentials for that user, I will configure it under the profile <code>csv-uploader</code>:</p><!--kg-card-begin: code--><pre><code>$ aws configure --profile csv-uploader
AWS Access Key ID [None]: AKIAXXXXXXXXXXXXXXXX
AWS Secret Access Key [None]: ZCTfXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
Default region name [None]: eu-west-1
Default output format [None]: json
</code></pre><!--kg-card-end: code--><h2 id="lambda-function">Lambda Function</h2><p>Let's head back to Lambda and write some code that will read the CSV file when it arrives onto S3, process the file, convert to JSON and uploads to S3 to a key named: <code>uploads/output/{year}/{month}/{day}/{timestamp}.json</code></p><p>When the S3 event triggers the Lambda function, this is what's passed as the event:</p><!--kg-card-begin: code--><pre><code>{
  "Records": [
    {
      "eventVersion": "2.1",
      "eventSource": "aws:s3",
      "awsRegion": "eu-west-1",
      "eventTime": "2020-04-08T19:50:35.471Z",
      "eventName": "ObjectCreated:Put",
      "userIdentity": {
        "principalId": "AWS:x"
      },
      "requestParameters": {
        "sourceIPAddress": "102.132.218.115"
      },
      "responseElements": {
        "x-amz-request-id": "x",
        "x-amz-id-2": "x/x/x"
      },
      "s3": {
        "s3SchemaVersion": "1.0",
        "configurationId": "TriggerLambdaToConvertCsvToJson",
        "bucket": {
          "name": "ruanbekker.demo.blogpost",
          "ownerIdentity": {
            "principalId": "x"
          },
          "arn": "arn:aws:s3:::ruanbekker.demo.blogpost"
        },
        "object": {
          "key": "uploads/input/foo.csv",
          "size": 0,
          "eTag": "x",
          "sequencer": "x"
        }
      }
    }
  ]
}
</code></pre><!--kg-card-end: code--><p>So we have context on the <strong>key name</strong> as well as the <strong>bucket name</strong>.</p><p>Onto the code of our Lambda Function, there's probably better ways such as streaming to do this, but the focus is on what the task is doing and not really on the code.</p><p>I am reading the CSV file, writing it to the <code>/tmp</code> directory (only path which is writable), processing the data convert to json and write as a json file, then uploads to S3 and remove the files from the disk:</p><!--kg-card-begin: code--><pre><code>import json
import csv
import boto3
import os
import datetime as dt

s3 = boto3.client('s3')

def lambda_handler(event, context):
    
    datestamp = dt.datetime.now().strftime("%Y/%m/%d")
    timestamp = dt.datetime.now().strftime("%s")
    
    filename_json = "/tmp/file_{ts}.json".format(ts=timestamp)
    filename_csv = "/tmp/file_{ts}.csv".format(ts=timestamp)
    keyname_s3 = "uploads/output/{ds}/{ts}.json".format(ds=datestamp, ts=timestamp)
    
    json_data = []

    for record in event['Records']:
        bucket_name = record['s3']['bucket']['name']
        key_name = record['s3']['object']['key']
        
    s3_object = s3.get_object(Bucket=bucket_name, Key=key_name)
    data = s3_object['Body'].read()
    contents = data.decode('utf-8')
    
    with open(filename_csv, 'a') as csv_data:
        csv_data.write(contents)
    
    with open(filename_csv) as csv_data:
        csv_reader = csv.DictReader(csv_data)
        for csv_row in csv_reader:
            json_data.append(csv_row)
            
    with open(filename_json, 'w') as json_file:
        json_file.write(json.dumps(json_data))
    
    with open(filename_json, 'r') as json_file_contents:
        response = s3.put_object(Bucket=bucket_name, Key=keyname_s3, Body=json_file_contents.read())

    os.remove(filename_csv)
    os.remove(filename_json)

    return {
        'statusCode': 200,
        'body': json.dumps('CSV converted to JSON and available at: {bucket}/{key}'.format(bucket=bucket_name,key=keyname_s3))
    }
</code></pre><!--kg-card-end: code--><p>Save the Lambda function.</p><h2 id="upload-csv-to-s3">Upload CSV to S3</h2><p>Back to your terminal, create a CSV file, in my case:</p><!--kg-card-begin: code--><pre><code>$ cat &gt; data.csv &lt;&lt; EOF
name,surname,age,country,city
ruan,bekker,33,south africa,cape town
james,oguya,32,kenya,nairobi
stefan,bester,33,south africa,kroonstad
EOF
</code></pre><!--kg-card-end: code--><p>Now upload the data to S3 <code>uploads/input/foo.csv</code> . The destination filename can be anything, as long as the prefix is <code>uploads/inputs</code> and suffix with <code>.csv</code>:</p><!--kg-card-begin: code--><pre><code>$ aws --profile csv-uploader s3 cp data.csv s3://ruanbekker.demo.blogpost/uploads/input/foo.csv
upload: ./data.csv to s3://ruanbekker.demo.blogpost/uploads/input/foo.csv
</code></pre><!--kg-card-end: code--><p>As we can see from our Lambda Execution Logs on CloudWatch, our execution was successful:</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/79764219-5f0df400-8325-11ea-8987-4d54ca8f3b43.png"></figure><!--kg-card-end: image--><p>Looking at S3, we can see our key was created as <code>bucket/uploads/output/{year}/{month}/{day/{timestamp}.json</code></p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/79763587-90d28b00-8324-11ea-9ecb-7a8f2a680508.png"></figure><!--kg-card-end: image--><p>Selecting our object, hit actions and select open, we can see that our CSV file was converted to JSON (note: I pretty printed the file manually for better readability):</p><!--kg-card-begin: image--><figure><img src="https://user-images.githubusercontent.com/30043398/79763795-d1ca9f80-8324-11ea-977f-bde88391dc95.png"></figure><!--kg-card-end: image--><h2 id="thank-you">Thank You</h2><p>This was a very basic example of what you can do with S3 Events and Lambda, the sky is the limit, you can do awesome things!</p>
		</div></div>]]>
            </description>
            <link>http://sysadmins.co.za/convert-csv-to-json-files-with-aws-lambda-and-s3-events/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646359</guid>
            <pubDate>Thu, 25 Jun 2020 22:13:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polyglot Assembly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23646217">thread link</a>) | @vojtechkral
<br/>
June 25, 2020 | https://vojtechkral.github.io/blag/polyglot-assembly/ | <a href="https://web.archive.org/web/*/https://vojtechkral.github.io/blag/polyglot-assembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p><em>Writing assembly code that runs on multiple architectures.</em></p>
    <p>A few years back, while I worked as a Solaris engineer at Oracle,
I posted an april fools joke to one of our internal mailing lists.
Do you remember <a href="https://en.wikipedia.org/wiki/Solaris_(operating_system)">Solaris</a>?
<a href="https://vojtechkral.github.io/blag/polyglot-assembly/pepperidge-farm.jpg">Pepperidge farm remembers</a>.
Unfortunatelly Solaris 12 was
<a href="https://arstechnica.com/information-technology/2017/01/oracle-sort-of-confirms-demise-of-solaris-12-effort/">never released</a>
(not as such, anyway) and many of the devs were laid off shortly afterwards,
but that's a different story... The april fools e-mail read as follows:</p>
<pre><span>Hi all,
   can I please get a codereview for my new Hello World program?
The purpose of the program is to output a greeting.
As the code is very short, I'm inlining it at the end of this email.
The code has been tested on sparc and x86.
Only 64 bit arch is supported - please compile with cc -m64.
cstyle reports no issues.

Thanks!
Vojtech

$ cat hello.c

const float main[] = {
         -5.0076923e-29, -6.02841476e-21, 1.75860328e-33, -4.3672462e-34,
         -2.03652633e-33, 3.00046579e-32, -6.99961556e-33, -4.36343733e-34,
         -253599.734, 1.87611745e-33, -4.36724253e-34, -2.03652633e-33,
         2.62426763e-32, -4.36343733e-34, -253599.859, -1.05886372e-37,
         -2.84236475e-29, -4.2805483e-28, -7.27646377e-27, -3.28364893e-28,
         -7.3422524e-38, -8.52233404e-38, -7.19531561e-38, -2.84236445e-29,
         -6.02842122e-21, 2.3509887e-38, -7.3422524e-38, -8.52233404e-38,
         -6.02842122e-21, 2.3509887e-38, -7.3422524e-38, -8.52233404e-38,
         1.69276854e-42, 1.58918456e-40, -7.11823707e-31, 3.30286048e-42,
         1.26058568e-39, 6.72382769e-36, 5.90304592e+22, 2.02799612e-19,
         1.17234334e+27, 9.30333261e-40, 1.7976867e-38, 0.0
};
</span></pre>
<p>I expect <code>main()</code> not being a function and instead being an array of numbers
won't be news to many people, this
<a href="http://jroweboy.github.io/c/asm/2015/01/26/when-is-main-not-a-function.html">has been done before</a>.
(If you've never seen this before, have a look at that blogpost, it's pretty good!)</p>
<p>The focus of this post instead is this line:</p>
<blockquote>
<p><strong>The code has been tested on sparc and x86.</strong></p>
</blockquote>
<p>Any code that a Solaris dev looked to push to the core repository
had to be rigorously tested on both architectures targeted by Solaris: x86 and SPARC.
And this code doesn't really look like it could run on multiple architectures, right? ...
But it does. And it does that with a trick I call a <em>polyglot assembly</em> code.
Maybe that's a little too pompous a name for a silly joke, but I didn't know what else to call it...</p>
<h2 id="linux-x86-64-arm">Linux, x86-64 &amp; ARM</h2>
<p>I recently decided to revive the idea and, since both Solaris and SPARC
are fairly obscure nowadays, to port the code over to Linux on x86-64 and ARM.</p>
<p>Here's the new code:</p>
<pre><span>#include </span><span>&lt;stdint.h&gt;

</span><span>const </span><span>uint64_t</span><span> _start[] </span><span>__attribute__</span><span>((section(</span><span>".text"</span><span>))) </span><span>= </span><span>{
    0xe3a00001909032eb, 0xe3a0200ce28f1014,
    0xef000000e3a07004, 0xe3a07001e3a00000,
    0x6c6c6548ef000000, 0x0a214d5241202c6f,
    0x18ec834800000000, 0x4800000045058b48,
    0xa20fc03148240489, 0x0c24548908245c89,
    0x142444c710244c89, 0x01c0c74800000a21,
    0x0001c7c748000000, 0x480124748d480000,
    0x050f00000015c2c7, 0x480000003cc0c748,
    0x6c654820050fff31, 0x00000000202c6f6c,
};
</span></pre>
<p>It's still just a <em>Hello, World!</em> program.</p>
<p>To build it, I recommend <code>gcc -static -nostdlib</code>.
I found out the special section attribute is necessary for gcc to put the code in the right section.</p>
<p>You can also get pre built binaries <a href="https://github.com/vojtechkral/asm-polyglot/releases/tag/0.1">here</a>.</p>
<p>Please keep in mind that the resulting binaries are <strong>still platform-specific</strong>.
The polyglot trick's purpose is to make it possible to build for x86-64 and ARM from the same source file.
While the executable code inside the ELF file is the same bit by bit for both platforms,
the ELF header and section layout is somewhat different and unfortunatelly there seems to be no way around this
(at minimum, the kernel checks the ELF architecture byte and won't load the program unless it matches).</p>
<p>So anyway, how does it work?</p>
<p><img src="https://vojtechkral.github.io/blag/polyglot-assembly/diagram.png#right" alt="diagram"></p>
<p>The basic idea is pretty simple: The code starts with a magical snippet
that gets interpreted by both architectures and basically performs
a conditional jump based on which architecture is runing the code.</p>
<p><em>Architecture #1</em> decodes this bit as a an effective no-op instruction
(in my example it's actually an ALU instruction whose output is ignored)
and simply continues to the area marked blue in the diagram.
<em>Arch-#1</em>-specific code is stored there.</p>
<p><em>Architecture #2</em> decodes the initial part as a jump and proceeds
to jump over to the yellow area where the code for <em>arch #2</em> follows.</p>
<p>How do you come up with the magical architecture-selecting prolog?</p>
<p>It turns out x86 is actually a pretty good choice for <em>arch #2</em>, because it has
a short near-jump instruction, just 2 bytes. Together with 2 <code>NOP</code>s (1 byte each)
this makes up the length of one regular (non-Thumb) ARM instruction.</p>
<p>The three x86 instructions, a <code>JMP</code> and two <code>NOP</code>s, can be arbitrarily reordered
and also the jump distance can be adjusted, and as I found out this is
enough degrees of freedom to find a valid nop-like ARM instruction.</p>
<h2 id="searching-the-instruction-space">Searching the instruction space</h2>
<p>The original Solaris code was a result of basically just hokus-pokus.
In the Linux rewrite I tried to come up with a somewhat more automated way of finding the right combo.
There's a hackish <a href="https://github.com/vojtechkral/asm-polyglot/blob/master/jmps.py">python script</a>
and a Makefile rule that generate <a href="https://vojtechkral.github.io/blag/polyglot-assembly/jmps.txt">a big plaintext list</a> of all <code>NOP</code>/<code>NOP</code>/2-byte <code>JMP</code>
permutations along with their ARM representations.</p>
<p>From the list it's apparent that the <code>JMP</code>, <code>NOP</code>, <code>NOP</code> ordering yields a safe
ARM <code>addsls</code> instruction most of the time, at least as long as the jump distance is small enough
for the <code>addsls</code> to not touch the <code>sp</code> or <code>pc</code> registers...</p>
<p>In my case I only need to <code>JMP</code> 52 bytes ahead. This results in <code>addsls r3, r0, r11, ror #5</code> on ARM,
which is a perfectly harmless instruction. Maybe a bit too complex (a conditional add with a bit rotation), but harmless.</p>
<p>In summary, the magical bytes that make an x86 CPU jump ahead and
an ARM CPU continue are:</p>
<pre><span>eb 32 90 90
</span></pre><h2 id="the-code">The code</h2>
<p>The source code for this mini-project can be found <a href="https://github.com/vojtechkral/asm-polyglot">on my github</a>.</p>
<p>The C file quoted above effectively contains the following two code paths for x86-64 and ARM, respectively:</p>
<div>
<pre><span>x86:
    # create a hello message on the stack
    </span><span>sub     </span><span>$</span><span>24, </span><span>%</span><span>rsp
    </span><span>movq    </span><span>msg(%</span><span>rip</span><span>)</span><span>, </span><span>%</span><span>rax
    </span><span>mov     </span><span>%</span><span>rax, </span><span>(%</span><span>rsp</span><span>)
    </span><span>xor     </span><span>%</span><span>rax, </span><span>%</span><span>rax
    </span><span>cpuid
    mov     </span><span>%</span><span>ebx, 8</span><span>(%</span><span>rsp</span><span>)
    </span><span>mov     </span><span>%</span><span>edx, 12</span><span>(%</span><span>rsp</span><span>)
    </span><span>mov     </span><span>%</span><span>ecx, 16</span><span>(%</span><span>rsp</span><span>)
    movl    </span><span>$</span><span>0x0a21, 20</span><span>(%</span><span>rsp</span><span>)

    # write </span><span>syscall
    mov     </span><span>$</span><span>1, </span><span>%</span><span>rax
    </span><span>mov     </span><span>$</span><span>1, </span><span>%</span><span>rdi
    </span><span>lea     </span><span>1</span><span>(%</span><span>rsp</span><span>)</span><span>, </span><span>%</span><span>rsi
    </span><span>mov     </span><span>$</span><span>21, </span><span>%</span><span>rdx
    </span><span>syscall

    </span><span># exit </span><span>syscall
    mov     </span><span>$</span><span>60, </span><span>%</span><span>rax
    </span><span>xor     </span><span>%</span><span>rdi, </span><span>%</span><span>rdi
    </span><span>syscall

</span><span>msg:
    .ascii  </span><span>" Hello, "
    </span><span>.</span><span>int </span><span>0x0
</span></pre><pre><span>arm:
    # write </span><span>syscall
    mov     </span><span>%r0</span><span>, </span><span>$</span><span>1
    </span><span>adr     %r1</span><span>, </span><span>msg
    </span><span>mov     </span><span>%r2</span><span>, </span><span>$</span><span>len
    </span><span>mov     </span><span>%r7</span><span>, </span><span>$</span><span>4
    </span><span>swi     </span><span>$</span><span>0

    </span><span># exit </span><span>syscall
    mov     </span><span>%r0</span><span>, </span><span>$</span><span>0
    </span><span>mov     </span><span>%r7</span><span>, </span><span>$</span><span>1
    </span><span>swi     </span><span>$</span><span>0

</span><span>msg:
    .ascii  </span><span>"Hello, ARM!\n"
    </span><span>.</span><span>equ </span><span>len</span><span>, </span><span>. </span><span>- </span><span>msg
    .</span><span>int </span><span>0x0
</span></pre></div>
<p>I decided to automate the whole process of generating the C file and the binaries for x86-64 and ARM.
There's a big <code>Makefile</code> that goes through the arduous process of first generating ARM code from the source ARM asm file,
dumping the compiled ARM, feeding that to a Python script with a template of the x86 + compiled ARM code,
compiling that, generating the C source from that, and finally compiling the C source for both x86 and ARM.</p>
<p>Running the Makefile requires having an arm cross-compiling gcc installed along with a matching gdb.</p>
<h2 id="practical-applications">Practical applications</h2>
<p>There are none :-)</p>
<p>At least as far as I know.
As stated earlier, the resulting binary is still platform-specific,
Which means the trick can't be used to make multi-platform ELFs :-|</p>
<p>In theory it could be used to create a multi-platform shellcode,
but I find it unlikely that it would actually be useful in practice.</p>
<p>Multi-platform kernels maybe? But then again boot procedures differ quite a lot
between architectures, so again it's probably not very practical...</p>
<p>So yeah, it's really just a joke done for fun and to perhaps learn something new...</p>

</article></div>]]>
            </description>
            <link>https://vojtechkral.github.io/blag/polyglot-assembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646217</guid>
            <pubDate>Thu, 25 Jun 2020 21:54:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to Docker for Web Developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23646145">thread link</a>) | @bajcmartinez
<br/>
June 25, 2020 | https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/ | <a href="https://web.archive.org/web/*/https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <figure>
            
            <img alt="Feature Image" src="https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/featured_hu3f9d36be24b7ab6ea505a5af15c8496f_133171_680x0_resize_q75_box.jpg">
        </figure>
        <p>Knowing how to use containers in application development is a must for a modern-day developer. One reason for the recent demand for containers has been the emergence of Docker. Docker has not only increased the use of containers, it has had a great impact on the way we approach application development.&nbsp;</p>
<p>If you are a developer who is yet to find a proper introduction to this popular technology, you are in the right place. In this article, we are going to introduce you to the concept of Docker and get a hands-on approach to learning Docker by dockerizing a simple application.&nbsp;</p>
<p>First, let’s clarify what Docker is and why it has become this important.</p>
<hr>
<h2 id="what-is-docker">What is Docker?</h2>
<blockquote>
<p>Docker is a tool developers use to create, deploy, and run applications in an isolated environment through containers.&nbsp;</p>
</blockquote>
<p>Here it is again, containers. Though this term is used a few times since the beginning of the article, you may not have an idea what a container is. In order to fully understand the above statement, we have to first understand what a container is.</p>
<hr>
<h2 id="what-is-a-container-and-why-do-we-need-it">What is a Container and Why Do We Need It?</h2>
<p>A container is a software unit that packs application code and all the dependencies used in the application into a single package. Packaging allows the container to isolate the application from the host environment it is running in. The application sees the container as its environment instead of the host device. This abstraction guarantees that an application running in a development environment is able to run in a production environment without going through significant changes.&nbsp;</p>
<p>Even if several applications are running on the host device, the container isolates the containerized application from interfering with the operation of other applications and sharing their resources.&nbsp;</p>
<p>Before containers, virtual machines were used to isolate applications from the host environment. In virtual machines, each machine uses a separate operating system to run the application. Though this approach also achieves the purpose of isolating the applications, it has a downside of adding too much overhead on top of the application. Containers, on the other hand, share the OS kernel of the host device instead of using an OS of its own, which removes the overhead added by the virtual machines. This makes containers more lightweight and resource-efficient compared to virtual machines.&nbsp;</p>








<figure data-src="/post/2020-06-25-intro-to-docker-for-web-developers/docker.svg">
<img src="https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/docker.svg" alt="Docker vs VM"> <figcaption>
    <p>Docker vs VM</p>
</figcaption>
</figure>

<p>Though containers have been in use long before Docker, it’s safe to say that Docker is the biggest reason for the extreme popularity of containers in the modern programming world. Other than being open-source, Docker’s ease of use, reliability, and efficiency made the programming world instantly fall in love with this technology.</p>
<hr>
<h2 id="what-are-the-dockerfile-docker-image-and-docker-engine">What are the Dockerfile, Docker Image, and Docker Engine?</h2>
<p>Docker comes with its special language. Dockerfile, Docker image, and Docker engine are 3 words commonly used among Docker users. These are also the 3 most important components used when building Docker containers.&nbsp;</p>
<h3 id="dockerfile">Dockerfile</h3>
<p>Dockerfile contains a set of instructions to build a Docker image, which we are going to discuss next. These instructions will be run one after the other when creating the Docker image. Instructions in the Dockerfile contain information such as the host device’s OS, the programming language of the application, application directory location, network ports, and environment variables.&nbsp;</p>
<h3 id="docker-image">Docker Image</h3>
<p>Docker image is a template that is used to create the final Docker container for the application. We can generate the Docker image of an application by running the docker build command with the Dockerfile as a parameter. To create the Docker container, we use the docker run command and the Docker image.&nbsp;</p>
<h3 id="docker-engine">Docker Engine</h3>
<p>Docker engine is where all the Docker containers are running on. Both Windows and Linux based applications can run on Docker engines.</p>
<hr>
<h2 id="how-to-dockerize-a-simple-application">How to Dockerize a Simple Application</h2>
<p>Now we have got to the most interesting part of this tutorial. We are going to dockerize a simple application to get hands-on Docker experience. First, we will create a simple Node.js application and then, create the Dockerfile, Docker image, and finally the Docker container for the application.&nbsp;</p>
<p>Before continuing, however, make sure you have Docker installed on your device. You can follow the official documentation to install Docker on your <a href="https://docs.docker.com/docker-for-windows/install/">Windows</a> or <a href="https://docs.docker.com/engine/install/ubuntu/">Ubuntu OS</a>. Check out the docs for other OS.</p>
<h3 id="create-a-simple-nodejs-application">Create a Simple Node.js Application</h3>
<p>We are going to create a simple Node application that sends a “Hello World” message when we visit the root route.&nbsp;</p>
<p>Follow these steps to set up your application:</p>
<div><pre><code data-lang="shell">npm init
npm install express --save
</code></pre></div><p>Inside the directory, <code>app.js</code> file contains our main application code.&nbsp;
&nbsp;</p>
<div><pre><code data-lang="javascript"><span>const</span>&nbsp;<span>express</span>&nbsp;<span>=</span>&nbsp;<span>require</span>(<span>'express'</span>)
<span>const</span>&nbsp;<span>app</span>&nbsp;<span>=</span>&nbsp;<span>express</span>()
&nbsp;
<span>app</span>.<span>get</span>(<span>'/'</span>,&nbsp;(<span>req</span>,&nbsp;<span>res</span>)&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;<span>res</span>.<span>send</span>(<span>"Hello&nbsp;World!"</span>)
})
&nbsp;
<span>app</span>.<span>listen</span>(<span>process</span>.<span>env</span>.<span>PORT</span>,&nbsp;()&nbsp;=&gt;&nbsp;{
&nbsp;&nbsp;&nbsp;&nbsp;<span>console</span>.<span>log</span>(<span>"Node&nbsp;server&nbsp;has&nbsp;started&nbsp;running"</span>)
})
</code></pre></div>
<h3 id="create-the-dockerfile-for-the-application">Create the Dockerfile for the Application</h3>
<p>Now we can create the Dockerfile with the information that is needed to create the Docker image.&nbsp;</p>
<p>Create a file named <code>Dockerfile</code> inside the application directory. To create the Docker Image for our application, the Dockerfile should contain a set of commands like this.&nbsp;</p>
<div><pre><code data-lang="dockerfile"><span>FROM</span><span> node:latest</span><span>
</span><span></span> <span>
</span><span></span><span>WORKDIR</span><span> /docker-tutorial</span><span>
</span><span></span> <span>
</span><span></span><span>COPY</span> . .<span>
</span><span></span> <span>
</span><span></span><span>ENV</span> PORT <span>3000</span><span>
</span><span></span> <span>
</span><span></span><span>RUN</span> npm install<span>
</span><span></span> <span>
</span><span></span><span>EXPOSE</span><span> $PORT</span><span>
</span><span></span> <span>
</span><span></span><span>ENTRYPOINT</span> [<span>"node"</span>, <span>"app.js"</span>]<span>
</span></code></pre></div><p>Now we will go through what each of these commands means.&nbsp;</p>
<ol>
<li>FROM—This command sets the base image and the new image of the application is built on top of this. In our case, we use an image that contains npm and the latest Node.js version. This image is pulled from Docker Hub which is a public repository of Docker images.&nbsp;</li>
<li>WORKDIR—This command sets the working directory for the application that will be running inside the container.&nbsp;</li>
<li>COPY—This command copies the files in the application directory to the working directory which we set with the previous command. You can pass the path to a specific file name or do as above to copy all the files in the application directory to the Docker image. In the latter case, make sure you have navigated to the application directory on the command line when running the docker build command.</li>
<li>ENV—In the Node application, note how we passed the environment variable, PORT (process.env.PORT), to the app.listen function instead of directly passing the port number the application should listen to. Therefore, we have to set the PORT environment variable in the application environment. For our application that is going to the Docker container. So, we use the ENV command to pass the variables that we want to set as environment variables inside the Docker container.&nbsp;</li>
<li>RUN—This command runs npm install to install the dependencies used in our application, which are saved to package.json file.&nbsp;</li>
<li>EXPOSE—This command exposes the application to listen to the given port. Since we have already set the port number as an environment variable, we pass the variable name, $PORT, &nbsp;in place of the actual port number. However, remember that the application is exposed to the port 3000 inside the container’s environment and not the host device’s environment.&nbsp;</li>
<li>ENTRYPOINT—This command sets how to enter, or how to start, our application. Docker joins the array we pass to create a single command that starts the application, which is node app.js.&nbsp;</li>
</ol>
<h3 id="build-the-docker-image">Build the Docker Image</h3>
<p>We use docker build command to build the Docker image from the Dockerfile. Here is how it works:</p>
<div><pre><code data-lang="shell">docker build -t &lt;image-name&gt; &lt;dockerfile-location&gt;
</code></pre></div><p>Make sure you have navigated to the application directory on your command-line before running the command. You can pass a dot (.) in place of the Dockerfile location to indicate that the Dockerfile is in the current directory.&nbsp;</p>
<p>For our example we will run:</p>
<div><pre><code data-lang="shell">docker build -t docker-tutorial .
</code></pre></div><p>Output:</p>
<div><pre><code data-lang="text">Sending build context to Docker daemon  2.008MB
Step 1/7 : FROM node:latest
latest: Pulling from library/node
81fc19181915: Pull complete 
ee49ee6a23d1: Pull complete 
828510924538: Pull complete 
a8f58c4fcca0: Pull complete 
33699d7df21e: Pull complete 
923705ffa8f8: Pull complete 
ae06f9217656: Pull complete 
39c7f0f9ab3c: Pull complete 
df076510734b: Pull complete 
Digest: sha256:719d5524c7e927c2c3e49338c7dde7fe56cb5fdb3566cdaba5b37cc05ddf15da
Status: Downloaded newer image for node:latest
 ---&gt; dcda6cd5e439
Step 2/7 : WORKDIR /docker-tutorial
 ---&gt; Running in 8797780960e9
Removing intermediate container 8797780960e9
 ---&gt; b80abb69066b
Step 3/7 : COPY . .
 ---&gt; cc9215d75956
Step 4/7 : ENV PORT 3000
 ---&gt; Running in 4bf08e16b94d
Removing intermediate container 4bf08e16b94d
 ---&gt; 95007721d5ee
Step 5/7 : RUN npm install
 ---&gt; Running in d09f45f0bbd7
npm WARN docker-tutorial@1.0.0 No description
npm WARN docker-tutorial@1.0.0 No repository field.

audited 50 packages in 1.146s
found 0 vulnerabilities

Removing intermediate container d09f45f0bbd7
 ---&gt; 292a854f73e2
Step 6/7 : EXPOSE $PORT
 ---&gt; Running in f2ae755655b3
Removing intermediate container f2ae755655b3
 ---&gt; 6d42325fe934
Step 7/7 : ENTRYPOINT ["node", "app.js"]
 ---&gt; Running in d657168980d8
Removing intermediate container d657168980d8
 ---&gt; 0c6df3f042eb
Successfully built 0c6df3f042eb
Successfully tagged docker-tutorial:latest
</code></pre></div><p>Once you run the docker build command, Docker will execute each command in the Dockerfile consecutively. When executing the FROM command, if the Node image hasn’t been pulled to your device before, Docker will pull the image from Docker Hub.&nbsp;</p>
<p>Once all the commands are executed, you will see the message “successfully built” if the image was created without running into an error.&nbsp;</p>
<p>You can use the command, <code>docker images</code>, to see all the images currently in your device.&nbsp;</p>
<p>Output:</p>
<div><pre><code data-lang="text">REPOSITORY       TAG      IMAGE ID        CREATED         SIZE
docker-tutorial  latest   0c6df3f042eb    3 minutes ago   943MB
node             latest   dcda6cd5e439    2 weeks ago     942MB
</code></pre></div><h3 id="create-the-docker-container">Create the Docker Container</h3>
<p>We use …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/">https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/</a></em></p>]]>
            </description>
            <link>https://livecodestream.dev/post/2020-06-25-intro-to-docker-for-web-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23646145</guid>
            <pubDate>Thu, 25 Jun 2020 21:46:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathematical Foundations of Data Sciences [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23645919">thread link</a>) | @memexy
<br/>
June 25, 2020 | https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf | <a href="https://web.archive.org/web/*/https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>K‘„ˆ‰2Aûbªø{ð#	×Ö%KcŽ�(¼ŠXŒ(à8ËhBó™HŽYªÉpð[%ÁsãÏ™
ñ÷DwR<c7Ø€,3n(a^Ò6ôËu`]pÏ ç÷ugÂdfqŒw-Ûi¹¶@®Ø½èŽ«Ïû"ùùq?ídpw<="" ’!› ¢â�—ñh}‹Òu="" šfÃ�­\Œp®ž’™="" Øõ+mƒu1Ô£aŒÀ”¦="" i*«j¸ÓõÑqqÃˆn¢côta1@^Â;%u“˜1vr5Ÿ´ûªìr!u÷c‰6ü¢b7Žhxu¸Ò_(pq§lmôxð�q%iø–oî<ì(rdg2ªcÁ_ï†ÜÙy�nÜ’)ˆ¸“zØqµ&],¾Ú½lÛm�™´‚óÎ“Êh¦_ŸsÃt“…h”|*¡¢®+¾¸n ã¬�£¦kž‰ä#“¥mkì’b›$„m-vÊä|†&µÁ‘guf[td="" ~d�Šà&="" “tiÀ±£lÛ$òþƒ‡�^‚$†*±ÕqÓçlq§m="" ¶%„¨9ò”ü(¼è�É&ÍÄ'="" ‡4b±%sæfb&:ô`+¸ Üµy1…~ƒÝ]l#8ˆäej3�¤ml�[udh="" ²b"ó‰„kå?‡’{Óòjhƒå�Êª!¨¸¿­ükÜÕ¯�ÆÚ¥jc¬n ="" šdiòš*íµc‹;4wq¹bj$f•Ï="" €¹9Å°7Ö¤àÀÛ­du¼+gÀÌ›5?lôÅqìg="" Û³l•-ërð¿*="" š'²&|~pÛkÐ™Œkb�Ëi®+ï8¿¢="" ²l¶®="" < o8o)ä="" w\="" úÁƒŽÊg2cËãäur$7<€¸£Šb†„¨b†á¢¿ŒhÂŠ~="" ahÄæüyä°|©ž0�_[oÚjÎ¶t@ŠÀ÷åud‘i!¾û[´È`›ÛmÌ‡kÃs‡í-¢q·£ùa]òqÕ#&="" %Ãv˜Ä–æ;ŽÊq±¿žŽ#È¾ñtc*öd‘ŒÆ5"õe$ÙÆm]ØØ="" “¶h$‘léª¼ˆˆêùeüzà´n¤j°É4,¿�ëÍ¶¬°="" £§è�<Ñã“�×å_žªx…†$j�xs?\uuÄŽ€ž¢ªê«ˆ"ŠÏ”va.8Ïª~Øz9”ÚfÑlpÑqb\šÝ­l–^4#&Áõ4p•c¸ „�!¶Þ‹¢¥}-[gl8ÀÖêâ’î­Šžùxk‰#Â:£¶±zÇ¶Ölp2fÑîÉhý•hÞèì|ª›n½_Ø_p�·xÓåpÉ–*•bÁ8„l°n,:bdbÄ†­† ¸ô„Ér…qæ<bo`,heÁôÏ‘^o¨~="" ®6m´�´ì’zÕu‡="" f±yÂo•="">0`&nbsp;p&lt;~)8H-6…`ÐáMó�Y:ˆüUž“*Ü`ÜlDÄ�ÁõuU´ypbQ7ÉU
Uý±´ŽBm¢ò�%ld*˜«¾ÀtZx_UHÆƒˆñ‘Šª8J(¢&nbsp;ªj‰ˆ^Èá#¹µÓ&amp;éPEˆÍµŸ9+ÇåÓWc ŠËFÑ×ÕPET&gt;�AŸQ…¤#‘oÜ7rº
²¶RCË0Ñü9?ˆºXRäuÄ°{Ñb<bŽ$rÏÆ�®8°ü¯ë€ ¢*="" ¦gŽ�åÎ¶jrâ*¦ª#�!â~1ÆÐÐØÏÕ="" )ƒ!&(#†-8j­€8ÏÆªú´8ûm8‘p¼¦="" ãþuaqiÔecuÆ"¸â±n™½†ÄˆsŽãªÝr9¡d$²ÓnÙ¶ˆõ—¾{ã="" e„!"3‰À#hÇ„~cÖã±…¡ýa“…˜Êo«1rl_8@Ûhì‡\Æt[9jdµ‰ì="">«ò(‰&amp;*’*&amp;6ú*°~ªÊ›f dVTÑ^Éõ.0J(À‡þÔü�þUW&lt;¢"&nbsp;güax,øÅæÔ(íªH¨ß&nbsp;ª£lš*¡*¨|Ç�ZF!N'�R#�W°ßÆúæî~‚äv”št1HÛI3›p_”¦‚f¸ª(¡îN5K=Q&nbsp;f½\:Ú¡h¾sDm·
BŽJwâW•ôLXÊâ³ëü‘&lt;¤ƒÃÁm[6UÓrQpÈ™Ïûø5&lt;""'òÀ!Ïbðžø…øaMVJÅño©HŒT†­¨DÃf¢³_êMCöFc"Cà›gÝcÀ³ÒCUþ	˜&gt;âÌsÒ&amp;GøCZÁ_È�¶4ÞÈª “Ò±×¦dó”¸_•_tBõió¶QDšLAeq¥mÒ}U=QUWÃ¨&gt;œõ}_\`[ð&gt;d~q¶ÙRdYRUng�gTü"£j¾=‹ÇÿÚxWÑ5ÁŠ¦Ÿ¦G�Ù"‰¨$·s¨ŠÉ!6�ê�ÐGuO9.+-&amp;ã­cMšçÀ„‰Ý†Y˜Ø§ÎéqüaHm´A37¤6Æ$\(•£êH�¤™ÄI¦xAG¬šh½ÅÒõwŸ°°ÁJÐ#º'1Q›ìRe„f¤]¿%|û“&gt; ×“ÄC
‡Z6	öy÷t±²Ab8ò€3dØ8îç;Žem#`(‚9çÆ‰å|y$U‰ï.&nbsp;z:ú&amp;|þU_ð�·óu¸0kÛDØ!E ŠÈ®HŠŠ_„õm{çÂlÐ�~$l•U¨þ˜¬¦$áBpŽV|
²‰¿ûUZm¤p‰übŠM0 “,A„i³{Á¢IBÎ:âÃH¦S-Ž�¸ü±)
GGùæ{äxâ"ÛJxv(Â;ù$Òa&nbsp;&nbsp;%|w%ÌüR*™mã—PÛQÐHÊ$?(sÁ¤7•ÃEÈ0~l‰Z_*¸?ËSÈ9àL“Âûgòñ"ËØUÂq~?F©šÜ0y,Ìã´ÎâóKa°;`q^u•$#R	ð¬ƒ~Aü5&lt;6s³÷�~2#šŠ¢
ö6Â&lt;ñ½•´n8ÔZ†˜¥¶Î=(ÏÀLpÕÁ6]T)$Ò¹	çUûWS6k›yìYìŽ9-
a	[t_så	&gt;TEQöTlS+ª¤I:ZVb,�u§$
|p[âEb) ›²H±¦‘	óþP"+…yð-âÿ%Dþ^ƒî€¥ŠÞ øÏ)æeL˜¸JŠ¢Ò¦fYKÈkäµx¥ŽCðá6žR2x8~ã?_‰uQK¤ˆ
XÛÄ
ò¶ÛCò€§²– «m'˜’ã“d ¦ÿÈ¤à¶«%p\GqwÄ©µ’%á\Ë`�CxÞ$Eyä™ò
©*’E[H•NH)Úû±qå|F³_~JCˆŒ6Â’”ƒü¸&gt;ÞÍ¹›DÉ‚ü¦È“†‘�±Œ	ëçÎ'ŒöU!UÏøÄ__ŒEEOrÏQ�6zûh„J
R½rŽÄ~(Ò€ÐÞEU{È’,¯EýÇ”]q§G",ô2Æ¡:jM	dÑOG
H%!DD&amp;‡ùþÛl¤›C<gÛË*"¦¨ªm(8¯È�jÕjšmµŠò&�£Šê(¯Åø5djpeyrÁ¦%x+ïÐ‚�z¡¸Ä]|¤q½�‹�¼tý²kÑ º7±`uŠ7ipùŽ¨¨ˆ¹ê˜¿Ã¿—…ð="" ¨¢ˆ¨€ª¾sÚ¾õ[px="" µmÈ´î×¬buŒnÈ¼%Ì•y3}q§±¶w4Ép_*`x�¨ÈlwÁ<ª="" ª°×ª|¿«Îkð²Ù="" «q�Éd·wö¨í*9&;�äâyu�_Â¬hÈêéÆbÈãÊzÙ?�="" À�Ùë‡="" ÙÕŸu…räahªˆ3u="" rÅ‚òðŸ�†á]6«�Âq¶šf�\aiÂ.�bbtÏãä”w<à™ch‰ž="" àmºk k#kmñ(àúxkàê-d¨ÎÉcÕÿ�ò¸âühâ™—Ìò#iì^Þ¨�!*§…t="" ££iû="" ²�Øuµa2tþgŸymÀe‘äqqiØ“Ç®z´bqeuup‘¿er½t="" ‰ñÍ|—Ò¾òa”¤ªaÆ¾@id«gî2$6ÎkÚý”Ðd0_öþ¸@´uÅtñì¸¤¨‚žØ="">•p}S<xÁ%ò�¨Ÿ³ùe¡*{7#9rhö,þ)’`Æ�’õd"^yµ8dé hwÂ¦lÇ"Âˆ‹Œ›x²u]³2ðÙ:æ$w m“uaqâtc\ðžj$—Ê6¤n="" �#¬'ÌŠˆ*¸="" q="">ALR/Ú È±$Ë
ÊöÛlXi¤)¾HÉ·IÆ…çDù1Ë]…¶–m²Ø#ä3^TU0‡ñãÂ˜ùAmT¿\%OQ$õöÏ‘p|¦©b¸#‰ü³Àø6„ƒÓ×iÅ*Ë§c»Æ&lt;¢’^¦h©Ÿ„Äð˜ë
:2µH�cº›“)¦ #RÈûcn!“~?h0¤©b»í‘\3ÆE1&amp;‹�,Öëˆ¢‚‡ìå¦º±ÔÝ@7Vke;Œk/8‘µ6€™¬Œ€žEÉ/åÙ–Û*í}Ù	¢wjó’¤&lt;î4Ê9‘¢8Ýc~È˜¤‰ˆ¸nz`ª"!þ<yÂu¡Äutu\ð žup\tÁnû'ë¯†Ü�Ðó€¤Úª�œ="" Êëedi\h="" •‘qø•�| ª!‰.,&È¢†xî°Ó˜æšŠ.if¸Þ¦ú«Ô2§@ä*É‘5g}‹viÌ‰«»ñ·–û="" ¡m-)ƒ]aœn±€_ˆeøâ—œõÄüb�®h˜Ë)g°¨å�É‚ÃÎ£•¤™&–b‚h­™Ž**©q!ùo�wóŽº="" ˆÙùs‚o‘="">Ì0Ä3‚3ÁÜDôURq\pÅ|�¯ÏêÚ´®(CPAgÂHŒÓ«
QW9Ý¹"Ù­#d„(Žzyu¿”’(©BM¢ª"¼+ò*	ù5hUPÀ
¶«É¯EL}°5AEOâ&gt;p½¼®zþ|cm“ŠŽK¹a¡•rNŽ“Ø±™\íxöa¤jbºHÈû4Ê
•Cuß*n¡…ŠEVf¼ò¶çœ“=¶ÆrJZ˜¦#"oÁ�ž2EF3Žà2Ë9[±ZT“çãk4À‘ã
òTURSOÂˆ¢¿!ZÊ�£ÁG’
ÚyO$&nbsp;ê†*yÄòÓ¾£îÊ§�%%hH›Dõ2ùCù\Àiá	Ê§çÛ?çI3ó‚Hƒ�Ëe´—xˆ²-ä:F&amp;ê”ˆí£–æ6ª®~º“Í×I2�N‚ #ì˜ì�}ÆÛi[DeÕq°BÇ§§†	L…öÙ!™-Ä‘(È˜˜Yû:±b8é‘ƒá•·UBöÿ¨	LEsóŠ^PƒÈ¾Š¨ó¢èª¢mÁÂÊËÀš$ñ:ªªˆ«†$ƒê£žÉˆ«ˆ˜ˆ©ŠªªÓ¤Ò£§€J8N	8ãßúz¢cÎ2ÚËE°zc×®.H¹’ê;ó9‚ð·‹0±×Á±#¼DÃf± z,Z¶À•3Âxq›zOÄAÿc’&amp;£mÎ³~PŒol#Cqq°ÁUQŒjj´Ž‰KVQ="‰°gt�Ç[Fþ”¢îz‡&nbsp;ñ’§�Ï‚Oá|"b¯òtS!~Ð¹Y.Ýõp±´GQÛˆa"ÃÈ=/Â=#È&gt;ê/Ê÷¢¼ö|Ò=ã=aŸ&lt;ïD~ÁDÜš¸÷íª—ÉŠOy OUQó$±ßO`'PQ]S aQ†£{Bn:`øD_&amp;h¯;!À¦¸®úÈ‰ä÷’¤©ùÄAòˆß–Æ?»eè’Bª~I¯Æ!¹áåwÙ¿e(þ¾"xð*iŽ)®ywÛÿÚ¤ÒtÆl&nbsp;ÕÌ�b×�GÈº£{V“¨@Ÿem]_+–èÌïÓºŸ5›Îäj=Ì]„4˜ZÓ“¶�g›ÁèÝ;¢]D¨•³êce[´ÿWI·Ûê•¥LÝŠÀ j‘Ý±—s2ÊžŠöLÎoË§=&gt;óÀ¸ÍŸLÚû6ãWÎ¸‡h¿�Aß¾º}SÒuÝ#¼ý×Üo{7×ï«AiÅº†á³ó©�*5íçö2ëë'X3#Æ�ý¾·\µ;%…ñlÕòØÜo/]°·‡\ôg-wS�cuÖ´�^Á«Ùî°æåù½sÔt=+¶}ÕÜú±i€Õ½¦&lt;ÐOjëúŒkß¯&lt;ö«dÞ5š}†îÎÕêÍžÕ]ØÊ‰Îø®‘3IÙïì!ÐÅâ·[Œî©öC`‰OO&nbsp;Vìq¶G÷ß®ßPÒŠÂ)¿¼	n½t;õDÍ¶úª«b¼“f_Ô³þ¿½«¨¬‹²°¨ÓéùÜIE°—®íVšƒëÆ÷Õµ¾gõ‡AäzÙÞ;¨j	­]í�
—¹©­»³Áä]ìúèÅ…e½RWÃÓÖÎµkêæfÉ2Áú8úþÑ*&gt;â“©Ä.	ÄîzVá½õký?]Ý�‡¨vx“”ÙO±Û3ZÖÿ¯vC°÷Oµ•&lt;5¦hçñŽEÆáÙíå-–Ê\’(
ÈrâL˜®6õÓP¢i‘_ºº•ÉWÔÒj·Î¡ÏùD*[íÓ±L¾î7}f™¯ò®AsÜ&gt;Öµ·ý&nbsp;Ô¾»ÅÜz&amp;Ã½XSóšD›×´uZ˜6‰E½ì=õ{ká=¦~‰õ¿f£¢l»½§;Óî­ÏiìaõóJ¯×ªõ»[]ºïl�ÂønïÙ¢ð¯¯¯•Â´±×´`¹‡rýLê�JÃa×«ìæíÏßëqê`ÙoÇaþa³ÿ€íÝsdÜbZnôÐgXov’mõ­‡Ô&nbsp;ÝvÎÝ¼O‡¤sþÓ¿é!½í—&lt;‹�£ŸïÒäö5ŠÛ‹{íçxÿ•¬ÙO‘;X¾fÂ¦ê÷mçÓkv·—«æ¥Û4ýfè½ã§özÂj^¥¾Õ4'iõÎ¥Þ6žs#–q+Ž»ßº·G�Î¾�ö^‘KÏ¾‘qÚÙnn4tÕnéPv	c]:“§t‡Ý`œ	&amp;ô¡�!zŸvÑ8lHgTé² ìw=šDþ©õ«ê»ÛÏsíßhF›ØïÇd¶ä.§{ì�—´Ùj&lt;Ò)U^nòö'õn]³loÄ²×4HO]lÑ¬9ÕýŸX§—ÄyfèÇ9æ\§M°ê±�…ªHØ´¨úÆÕÜ¶�âñ"9W*-.á¶m_þ—«·¢Ssèá&amp;÷s�O
-$	–
²Õ2žoëzÞ¿±‘ªÚÆ²¹‰@×ÅÐÇúï
êÕ®·¯RØ–Í§Z5æ«_¡Qp‰¹M‡»H•eõê¥[ÙcëuŒ@¡©v¢’“ž×Ð×m¶³qÖák{&amp;–›UVù¬UDÔ·ëÍJÖv£«Ð•£C3.Û°f=_×ýr¹‡mþ½TÈèÝÃeÜ�ÐxvèÚgåú;œžÃI¸ý§æÜE©ßo&gt;Á}Š�«\ýk×öšx�ÿv¾ÔºN›Ð¥5{Å³ìz–·´ýñ·�í¦Ñ¿ô=æ&gt;¯Íõ«^Ãö¿°ôÆo`FŽ^ç±SQÙ]3E¯së;8lq79î»«òmó·ö
‡éT]Z³bÙ«maó¾m¹uý�•ð¾yÇß£@^ç0Ñk Î­€÷ØÎÉ²íVÔ–fÆóÒ9æ¥§s^µö¡ÐùÆ£¦jôÖøµ1+^xæ«}&amp;ó`ÖXÜm^ÖÞ³ƒ´µwÝË�Îž©c's�µÿ—î¿Ü5þÒô¿±ßX:®©"ºÇœ³³¹ÈÖS�ms^Ûµ‹N�¾Xó}zÞ;{�Læt»h›­½ŠØ}vÒ¤NèVö0¹^å²ì?àúž§�éúï=rÃi/_-~MÅÅ?ŸÍ"X[hZ´›ËYe`W›„·ëymvÕÔvãßè&gt;·Su¿»ëk±Ø¤ßn·Ü[ê„ëÙ·Ýþ3Ì$_Cû×ö&nbsp;µÊnSõ[Vß&gt;üì[$zÝO°uû]_‰é°l¶�ÿ\�2ça³XŽþŒ9nOb\íJÛfÜ&gt;¹síG«už¹,ø†‡²ÞÇÚ-y&amp;Ã·»¯õ-òM/æšOlêv±RÝ-¥´*˜×bÞÎ&nbsp;Ö[…­K­Ñõ¯Øúíú	}zé»—õcH­¾–µÑ¦³¯É–�šx®Z;òKwü²¡©zåÔ�ƒ]T�µX°ÝîËkªÙêåm�Ó§9W&nbsp;@þºóýg¤öÝ·›IÔöš-Ê“º}dÔúc]L›Ë%UnÚ¾›s±t}Ê§mcì.óÎu¡Þ:ÛögÆ7�±(+yýæÏ±@šÎÓ¿OwX�Ñ®«›]‡k®z¶§•RÈÛ{wIÙtº{9ôVQ$ï›Ì×4ŠHiYÍo÷ét~SScsöBé5]./\éõ\w�røŸÙË&gt;X÷;â_bþÏÜj¿W¾—Uý€û¥·lÉÎyŸGêoÑëß^´‹]ËªoÝ	½¯`•0-ô}¾SwºÇ¯Ôñ=wì{þ«õG—ýuåý
Ú“]³ãS/5]ãmûc¢÷&gt;wë¯c©ŒŸ^{Å~µÆøæ©M§aˆW÷[Î½QÔNs˜ZÅv;-&gt;¿YÚ~Ân7ûæ‘õ[qèú‡(Ô¹~½
2F3•ŠU”áÃ¸q¬¾Õív+)Q'W@bUMÎåS]*S'&gt;%s3$„	šn¶ÍnÏg±Ù½ûLüac¥Õ3Ìú¯OÒ7
cm×7z~ÑÍuž¿rúT„Æï¡é:ý'1è±£Â�Ò+©ÇªKrÓh½Ý¶Ö+ö&amp;"0þ¨çèH×·f5×Ê´dI°¶�Ú$g«´È3nn…ôIÚõoç&lt;”6°;~änm›6Ä�oºG7Íã»u›	_²]Sj‰õk“Dî½“«ì›G÷nœÚê8Ú­¶ÕþÆØ^X[M]�O8Ó+¯hô¸Mìñ5¹[U­¬;o­PäÛ¿Oû—¢Häºé�™§jMãšÑîóÓ¯5¾næ›ª7«C',šÒu
:½z4}~Äd–Í,›�ú�_Ñ¹×i{¯ì:‡$Ð4ç&nbsp;E
ÐgM™±F‹¤kqã
W×ÇÙ62��]¿9rnm¢ÓÕOÚk*¶GŸ?c—U
›Fÿ&amp;·¦›9Z�¾]^•}²FÁ}þ��þ?®B×òuÄ‰6&lt;Ûì6Ë¨lZ6ïGÑ5½£[™«À™C'dØŒéÑ`ïŸO¶+©;/(îÔ­•g¼ëLröoa±Ô_Û¢Ð•üûe¹‡®ýk­Ó&nbsp;M°ú[Ï"¹×ºUþ¯2ò¶Ïk6.(iõ´£©é»d‘é³^N‘S©U_ßê’í5º^“³»]ªé+?“}&amp;éû®to®û'…j›u¥lU¹É�S¡È³¨´®�'q:-¡â•ËhuªŸîèhØçõýox¢åœ)ÂÖaê+ÓZÐ7ºÇk¿½ªf&gt;Å%ÇºWAé:õ6»&amp;4}£¡Âƒ%ÐÙÏGµúí¢ïQèáU@�LvÔ-×6v7�jÏcxuÍ¾nÀ0!Å…¤OÕê«'5³³1ŠþuW7.F•Ìj5X¶Ó!=‹{¡£�P�¸¡SGþÆWÏM;A‡y0°77¶6õëîKo&nbsp;÷=?·hº&amp;ÝÏöz¸3blE­µx«àÎ™&nbsp;r�C&nbsp;eçÕcy5¿¦Ç—Ð´¿‘ánÝÛ&nbsp;ÔD£çtÎG�·ì3·�
þbk‘´ÝF=gQ¥¨†
Bþ›^íœ}cµõ&amp;¤è×J;›B¡€×:©e[ÖºÞ¡¤ê�¹ûø7Û÷G³²sÞ‹£F‘°Ò›»
cÛu~¬Ýåa¬ðáµH¬ÿÆïDÙçòO¢Ü’@¬­«¢®pÕ&nbsp;m¶¬­aU7Ô{þ¥£Wt_¶û†Ú\¿²tx[@L“±ÇJºÚ‡	Ø‰•Ê|ö¨ëdØD‘0ÜmÕUÒë[µÜÎßi�¯TWíû¯I¼…¨Gfu•ÃUMÞ\µ±5GËê/kê(µý†0ív9¼lÔú”m3�ºÔ+‹I.kÍAóšoê?ÛºÛÃ'SêqX½½+jk´XŒêý‘Í6ÓŽt}gìøú~Õ©Õk¶}nªlt–'@ÖÛ•Scâ¸(š‡-‰ã½V©»J¶á&lt;¢‚wDàPn*lþŒëð!Ø}Tîê9Ã¾Ã•žÅÂi4Ùƒ%u‡¡\vÁÒx’ØÈ°ú¿Õ#Æè¿R÷).j{Í?*æöÝ¦H¹ÖtY»¹¶r¯°}IÍSé&lt;(•_UxdZ
SWÖÞ{ÕÓðh¤®!xBÇ¶JDMûíg5Ò]éq÷+É:Ÿ*êý–×Fú]N©õãšiE†„Šl�UršS×(~R‹FÓ—[î·Ug!ØÕµðjfÖTÿA{Ýµýz†«Y¬é[ì�-º-…í¦ËQÒdŒ©ëU‹ùPŸ³´µŸ]UKÕçÅýËÚù÷Úv–Å|»å¿Û��õÛyv’ioç±±l®Xë?Xåí1ï9&amp;ç¢“U}M‰oìÕ6ØÝæ¹gÏYÙ¿®Ùyû÷Öz‡:™ZÌYÆ•S*o@“¬Y%äµ¾ÜÎ™m¶‹
Ÿ]¥²‡­ê7W;N¹KËmgf¡¤³«˜­@ñÒÂÙ­®¯G²×jvÿþ²Œ-D‹'ãf2ƒˆO:&nbsp;ŠÏÄN:óBˆê|bb¹ºt=+�Å½ìôu¬tO¼ýE¦íö;ªuG9ÔN‰ÕÞÕ&gt;�qýEm5=]slEŽÍ‡eæƒ|Ý€óu6oŠVVB;ýÆ‡[“]³ÁÜá³e^Â–ÍS÷6Ñé!ýµþÌíDîûØ8þ„_^®»O\Ø.¯a°åu&gt;Ë=å�Õ¸6;á
×7mÚKúÌ=sR·•¶ÛÜ[þ“ß$)U–6›&amp;¯LÞ»Öû.ÂÒ¿~—[k²nèQ´›wcQÛ˜}©¼æSª�Ó:C6Á#m¶l)áÙ¸Ù+i6[6vÎO®ísfðË}®}Ðuö6:þ»O­VÔôÞ�|æ©ÜÚ÷wÝt
Úûìx»§Ð»þÔ´ßç½jæ§‡ì•ôPþM˜úa'‚_„×ð96îŽöû�]$]ßî�&amp;ÓÝß~ên[tÍw›÷Îí?œý	ÔëbÃÕ&gt;¸ò¦·ïºUÔñÏígbêwû‰µÅÕþ–UPGç\¿YÔá±F±’VÙ­ÓSöÞøz¤Ã‘ßô:­_BÐù]_Bf¯i‘QÖì÷]»GíÌuÝ§ª÷OÇjï�Sª;ºú÷Îí¹„½õú†¨&nbsp;AN¿öçSÔä�›&nbsp;ö›{ýöYVë¿®ÅNÉ­ÖD%]±KnnÑ~Ý�õ–š|æÎ¾ßüh­di¨õß™{÷¬uZwX;'Ó Ô4ßVrÉ9Žùö1«mµh[ÀXÙIæ0©·h“ê?¼¬YPnª¦Íf}|Ö¾7=I[U7\7�À_ku›;4ÝVQK­¬’Ôzºø²¡CÖ5‡c§gnôu¡+ìÖ…XWßy6å÷æÚá‹O·ÝòåæygØ~§'™}¤‡FÞ�ôû†!}ÕÐJ?CêÝŽû]Ø`jŒ–�æ›^ËÇôn•·ÄÓ+é«B3–¤’îR¼OfÙö9¼±—¡Dæ”{Á¥¦ªÝþëóØ·¶=Ré»'\°Ô#�Cû›½ßÓê:†á¿îv·ÖŽ9k¡už›Õ+ÿÛ&lt;»êä�£°v¯±[w=¬ú±õ÷d�¬ý‡Ýb3÷ëG‡¤ôÞƒÑ5ý;¯h¶²ö—ì¡B²ŽÓ©qñ´1Ü™³¤×ÕÙØ¢íÕÓu7­oèõ‡rê[ªm.j®�šêWãv÷±a;¦žÑ8ye¿Ø�k[Ù×¬ùý÷û}½AcíbŒ)Ÿh+õÐÚ&gt;Ê3WCû&lt;ÉWô¯±çùß~Ÿ·n®Í©ï½¤±èaÒ§uèÝ¥äØ7o¹ÜlvŸ|g^ôOÿp£wÇuûFµBZå-ÕÆµ¥ý�QÎ¤ýSÔ¤ô=ÿïÝ«�\~Õ­›qõÉoÈgs‡Ïª#?2ËEæZ9�/Ð(ŒœyÇ1ˆC&nbsp;ª5`Ëmõí«µêlïÚgV·Ñt=‡S‚ÏÙtí³ëñxÎ±e·oºç­�˜ÕkW£Qn&amp;•õj«éß7³û#¶ÿä_g¨‡EÖãëÝû}æŸYwî‡®ò¯µÒ~òZUQ¤&amp;5nm­ñR55Sçì7¬=³¥*oÚ_ë¿ÿÚ?.~ÝÂk¹[ŠjA;;õNKo°Mñ�7«åòpÛ`šˆ#¨³lQ–$°ãÙÂÒ$$}¦wîM,6ì±Zª1ÇÚîJ•ê2^SN‰'yN}–ªoMñÝ8zÛjþ¡a€ïÙi`âÛú- »HöÞŸå &nbsp;å?{l_Ô$r4Q�£Ù8)¨÷·®³$Ô¢×/ Ù”À‚1A�uª¢š™­UýÓ´¯�LLÔasCÒkõü`±�9béÉz­½5|?´vœ7¶w&amp;ÈJÖjf…:I¬^J×Aw²¢b�ãÅ=^é©&gt;6ây
¨´ïE¿’ºiZþÜ`ÈšÍÐÚ´ÕT.G’ÕY‡÷{ãè˜" ð@Õ3‚4Òc4ížv‚:Î‘vvØœ9SmÊns=Ü"~XÑÓ,�¨ÒuT`-„Ê�H{„¶”+3ÎÐÜiÀ�æ¹´S¾ª°n�×•$mN7ìÏì£4åM@‚“3iOŠrôŒOåÂïTi¦.ššM­zóª7‡L!l�tíŸèšŽºˆ”Ïµ¦ˆª&nbsp;2îl¨‚šD–¢`²@ç+“VZž�à´RÕT˜'w©kù«+í’Úœíè¼|�¸-ö&gt;M/=Õ_Êº£úêp0µ¸§¨¶C©ì´ÒCÞnùfÈ¨$íþÛL²´­ª¿n&lt;•?%Átÿ!gâröÚ…4_pµ±¹jù 9-4û­h¬jµ®Î1ZY™7¢E÷ÞSH›Ñxˆµ
¯lS‚èÔXezwŽ´—‘{Zi½úER&gt;OÆ(UAPŽ¨”ÈSºßp¶+[ƒ¡…°¶IÉk[ÔÆÜö‡F.0~»“ÀáßØ«ãž&gt;ëKÚØ"k6ÛlÂñÝíŠrH�·ª‘Ð/RN˜‡)„€ÔP×‚€Di�HüµF•¦�ŒI¦qØ6¶Õúþª¡&gt;®`ûK]`µTVª™óŽà=†ôò™îöä¡&gt;i§k}Ñ&amp;v·GŠŒíÆÎ£+ÃúöçT�x‘uÛ…öm(
bÄ[6ÂH|z‰.CAí+ãÊ;§æzoTž8ïì˜¡IƒZ6âˆ¢kÈ¹É`-rÓKœÌSßvkQæù-`¨
.ãÌLZ-0Ôù³ "°"‰Ü2ÔÖˆ²Ð
ÅÏÙSD4ì÷è©ª˜Â+ÈZßtn¶]ÎÄó·
á‘?¥³L!¹	ìÝý„“Â›m%x‚v½™LÂØ"Ñ9¨H7K‰¾ÌK|d7‰Ä÷™Lìõõ^u
FS&gt;&nbsp;nÞµPKUPâ&nbsp;æÖÉ3Ü{âäÚÝSÔ4¾š`«�~/±XekmL02û-�d”g‰dÀi«ùv´Ô•E”Ë‹`´¼y¦¦EH8³ºÒX&lt;îe¯Vóùƒû"Ì&amp;´ülîgÔãg(”	&amp;bçôZ¡.dª�¢m¸´=�ÿ±òST.…ëN“a;24Ô7ZáÌãõTçvÛ&gt;ÄM2Í1‰å½¦M¡’š.XqB¦p0žå¤&amp;•È�0…FIÃ
Z6àµEñ†–ÿnn&nbsp;)¬†ÄÜµSPcx.:z©¾Ïouø�6{ i83Ãª`GäãºÌoû
«\){Ìzµ¤‰5¼[’r ššX&nbsp;E­ÅGòâvF^‹ñ6ÜËÄtæz¼Îï¼O-‰©è†§|ìßCäÂÒöDÓ,mTõÏ5úÀ”SP5®ÌÛjo”¶Vè
‡sn	À$ZÐZþA-ÂÜRÛ“RhôôÞƒ‡Û`Þ¸¦"WÝmŠ[)”ÕTÌô]mè€xDs¹ªÀ¤“°•A®‘ª£ã=¬ÝëøêïÔÉZª6Ü´‘¸Ý™Ï!+×ë§�3Î
š&gt; 5È?Þõ&nbsp;jÒn±QƒIÃ7?FZk‰2k·ÝÉ×�N0~‹M^Qæ˜")$gšÒbØ‹Ö�â�n™~hì»jÔ_N]Q©&nbsp;Ö‚$Þ`x-,Ÿ	£¤»eÕBH|×gs-?‰�¹(EyÉÓsBÍi¤
ŸdiZås÷NÖõXÛ—%.6õZ„9ð‹zìZ¢H¼Ïv™:ÔO5[zŒíwdòÛfæv-S«Òå}1Ú˜bzð^EËìä=Ö�ZØ]É=o½×•·&amp;•ü’�þÞ¬¡o^¡M»ú&amp;u¦£|ÖhUSÔç#ÇÕò¥—ŒÓ�˜Üœ'dÕEœ;NÎ‰¬°ºòËjÔà�f¹æÐÁ®ÎH×UBL�Êo–ÁgGä©œ…Wëü±DÖQŒÑc&nbsp;{Ñ%¡#~iÄ*áÕQvˆƒ6ô]…mw$ArÀF|„v£I,ci/3fxmº*ªi�â'†kVOŸE	;XQäž–|mÁj�F¿Ž­;-Ñ¨m°)ßÈÝh§ø—ÿL)QÀCÒ&lt;Ó�;mS`¿#É7Æ\á‚Nì]EÍR´Q§ã¥ÿÅÿ#î¼‰97òP¥¶^Šzª;yÿ*…1¶ÔÔ‡Øçœ4äéOa¹ÑßŠ-±`œ!F6É;=­’Õ}öï¸©¢ð7§¡Kž+ÔZE“ü•1Z~8œL:¢~2ïèž²æôN€¹¢)‹Êa¯vtÆ¢xvLþ[ÊÐi¤¼˜q,�®
—ºÐä„båIFõ˜_&amp;‹fTšQþòŒðQ!±F’Í8‹¶ªŒ%tí‚@õªAÀÿ4¶#M*®ç‚Òñf{›uâm™10È}Ó³T/'îˆ!=Ù&gt;äô˜à£’4ü±$Áðâ¢=22ˆîŒ€¾g”2œ½\‡GÞJ€e‚ÂÜôé'9%=DR2�¬8'¨šŒãÙZÛ&gt;ŒT'Ï„Ö{ãbjÞ®C„Ž÷L.GX…·ªªGãfuä&amp;Ÿ~O!odÄZØ:‚däÆßlÔSÒ›â:HŽ&gt;7¨vŽ¨k¾3Ãí$EFqÝ7F‘Ÿ«ˆ-_% paº.s(S7·ªÑñ»›ðÃnx&amp;3ÎÜ&amp;5(}âœÉjÖª&nbsp;ÌÛñÊtfäŸLdö¹@vºG22Z/¸¸ìµU�äµfÝ“Õø	3ÿ²§/¡%…­zp_eº¡
æÝV&nbsp;\ì‡t`\]�²ü¿“Ù¦ƒz!…·&amp;ÅTþ�AŠ`ãjo”½·!û*#`aÅ‰æ�øYÎò©¬Ãi€sÄ„ú‡&nbsp;¶õý8¾àš¨‹Zôð®ÍÍ1/ÁøS4×páØ¦$&gt;ðšjCm‡¿Q­ö@r/Ä¢06eÝèŠ‹&lt;íOÇ¥®à=J¤’Ã	s‡"6"5�‰ßî7¯êT2^ŸNËE©ºiê.˜0	“±ÙÍ1¿�Û—’Ò ðS mMJu«ûI©)‚e8doÚŒ�¯š¥&nbsp;/Nck�q{#LCsZ¯0Í§4ê,ÙmLbp’’7µÃº4üq«�Ìö@×UE£&gt;Ã’×¢¦Øeµyû(×¨åì€¢–káÑÊÒìÖÏÑ¦9—·$ôÈLnU
ƒžä�c†dMešwÀàQmÝÓÕH‰ŒyÇd·¨ÅÐÐHbÖËÔ–ï¶’²û÷'¬ªFÈ)‡ö±Ü…?5,
úŸý0ä�ÕY”©ªùHE÷£új—÷�¥ŽËø§¯æ|„(óZ©¨5°žòˆš‰€=;&nbsp;ô»çvÆ’Óúßû*¨©›(öˆEëìžhO =_rp'‘æW�ZFý“j<sš”j�‡Ô€‰² w7to�Ö.œ†="" (06½1r$Ãzc="" Ýyo°…È�$�ÄeeƒßltÀ¦øy�‡�<™0‚€ä­u–ggpœ—„ÓÕtv-?Þµvàâf¢k„9£="" �5ÃõŠËû×p’:éâ~ëÈÛyè´Ó+\ bhîû:4šfÎÈ“,nz¨˜x]™pwnwÞžƒx#û)gv‹Ï¦£;ÖªcŠmñ3ššÑÜŽ§"éan‘="" ’Ãq�»<Ÿ¨u(pèå'Ù="">Jap™ÿÙšWª|µ
²8ˆTAÞ…D‘¤ÈhƒWåˆ¼gÑ0E©£rŠš‡þ™�xRù—ü�r}~iÍ�I5åFHêwáÂõ¥ÀÈÏšñq2Ü‘}©éÓP ›A00f#EDß·$)1!0¿2}eÅÂ[û­u-4Û°ZŒF{­?å~Äõ¯é�$?joŠ'e»£M@š�·!û–Ö˜iåÆÁVä¨’¢"&nbsp;u‚Å\6Ú”ELw®�Ëñ†¤	7eª€5E˜¦ù!VV¿èõú1
¢9&amp;¤†ç±8.àßŒù­DæÃgL—‰ Þù*š&nbsp;ÒGY–0’�hVø£ª§ÛÑ…</sš”j�‡ô€‰²></yâu¡äutu\ð></xá%ò�¨ÿ³ùe¡*{7#9rhö,þ)’`æ�’õd"^yµ8dé hwâ¦lç"âˆ‹œ›x²u]³2ðù:æ$w></gûë*"¦¨ªm(8¯è�jõjšmµšò&�£šê(¯åø5djpeyrá¦%x+ïð‚�z¡¸ä]|¤q½�‹�¼tý²kñ></bž$rïæ�®8°ü¯ë€></c7ø€,3n(a^ò6ôëu`]pï></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf">https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf</a></em></p>]]>
            </description>
            <link>https://mathematical-tours.github.io/book-sources/chapters-pdf/machine-learning.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645919</guid>
            <pubDate>Thu, 25 Jun 2020 21:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Real-time bandpass filter bank audio spectogram]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23645711">thread link</a>) | @afgho
<br/>
June 25, 2020 | https://grz0zrg.github.io/WABSP2/ | <a href="https://web.archive.org/web/*/https://grz0zrg.github.io/WABSP2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://grz0zrg.github.io/WABSP2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645711</guid>
            <pubDate>Thu, 25 Jun 2020 21:07:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tufte CSS – Inspired by Edward Tufte]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23645691">thread link</a>) | @x32n23nr
<br/>
June 25, 2020 | https://edwardtufte.github.io/tufte-css/ | <a href="https://web.archive.org/web/*/https://edwardtufte.github.io/tufte-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>Dave Liepmann</p>
      <section>
        <p>Tufte CSS provides tools to style web articles using the ideas demonstrated by Edward Tufte’s books and handouts. Tufte’s style is known for its simplicity, extensive use of sidenotes, tight integration of graphics with text, and carefully chosen typography.</p>
        <p>Tufte CSS was created by <a href="http://www.daveliepmann.com/">Dave Liepmann</a> and is now an Edward Tufte project. The original idea was cribbed from <a href="https://tufte-latex.github.io/tufte-latex/">Tufte-<span>L<span>a</span>T<span>e</span>X</span></a> and <a href="http://rmarkdown.rstudio.com/tufte_handout_format.html">R Markdown’s Tufte Handout format</a>. We give hearty thanks to all the people who have contributed to those projects.</p>
        <p>If you see anything that Tufte CSS could improve, we welcome your contribution in the form of an issue or pull request on the GitHub project: <a href="https://github.com/edwardtufte/tufte-css">tufte-css</a>. Please note the <a href="https://github.com/edwardtufte/tufte-css#contributing">contribution guidelines</a>.</p>
        <p>Finally, a reminder about the goal of this project. The web is not print. Webpages are not books. Therefore, the goal of Tufte CSS is not to say “websites should look like this interpretation of Tufte’s books” but rather “here are some techniques Tufte developed that we’ve found useful in print; maybe you can find a way to make them useful on the web”. Tufte CSS is merely a sketch of one way to implement this particular set of ideas. It should be a starting point, not a design goal, because any project should present their information as best suits their particular circumstances.</p>
      </section>

      <section>
        <h2 id="getting-started">Getting Started</h2>
        <p>To use Tufte CSS, copy <code>tufte.css</code> and the <code>et-book</code> directory of font files to your project directory, then add the following to your HTML document’s <code>head</code> block:</p>

        <pre><code>&lt;link rel="stylesheet" href="tufte.css"/&gt;</code></pre>

        <p>Now you just have to use the provided CSS rules, and the Tufte CSS conventions described in this document. For best results, View Source and Inspect Element frequently.</p>
      </section>

      <section>
        <h2 id="fundamentals">Fundamentals</h2>
        <h3 id="fundamentals--sections-and-headers">Sections and Headings</h3>
        <p>Organize your document with an <code>article</code> element inside your <code>body</code> tag. Inside that, use <code>section</code> tags around each logical grouping of text and headings.</p>
        <p>Tufte CSS uses <code>h1</code> for the document title, <code>p</code> with class <code>subtitle</code> for the document subtitle, <code>h2</code> for section headings, and <code>h3</code> for low-level headings. More specific headings are not supported. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:</p>
        <blockquote cite="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB">
          <p>[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of <em>sentences</em> which then cumulate sequentially into <em>paragraphs</em>, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.</p>
          
        </blockquote>
        <p>As a bonus, this excerpt regarding the use of headings provides an example of block quotes. In Tufte CSS they are just lightly styled, semantically correct HTML using <code>blockquote</code> and <code>footer</code> elements. See page 20 of <a href="https://www.edwardtufte.com/tufte/books_vdqi">The Visual Display of Quantitative Information</a> for an example in print.</p>
        <p><span>In his later books<label for="sn-in-his-later-books"></label></span><span><a href="http://www.edwardtufte.com/tufte/books_be"><em>Beautiful Evidence</em></a></span>, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and the first few words of the sentence set in small caps. For this we use a span with the class <code>newthought</code>, as demonstrated at the beginning of this paragraph. Vertical spacing is accomplished separately through <code>&lt;section&gt;</code> tags. Be consistent: though we do so in this paragraph for the purpose of demonstration, do not alternate use of header elements and the <code>newthought</code> technique. Pick one approach and stick to it.</p>

        <h3 id="fundamentals--text">Text</h3>
        <p>Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. Tufte CSS uses <code>#fffff8</code> and <code>#111111</code> because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. We stick to the greyscale for text, reserving color for specific, careful use in figures and images.</p>
        <p>In print, Tufte has used the proprietary Monotype Bembo<label for="sn-proprietary-monotype-bembo"></label><span>See Tufte’s comment in the <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt">Tufte book fonts</a> thread.</span> font. A similar effect is achieved in digital formats with the now open-source <a href="https://github.com/edwardtufte/et-book">ETBook</a>, which Tufte CSS supplies with a <code>@font-face</code> reference to a .ttf file. In case ETBook somehow doesn’t work, Tufte CSS shifts gracefully to other serif fonts like Palatino and Georgia.</p>
        <p>Also notice how Tufte CSS includes separate font files for bold (strong) and italic (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice.</p>
        <p>If you prefer sans-serifs, use the <code>sans</code> class. It relies on Gill Sans, Tufte’s sans-serif font of choice.</p>
        <p>Links in Tufte CSS match the body text in color and do not change on mouseover or when clicked. Here is a <a href="#">dummy example</a> that goes nowhere. These links are underlined, since this is the most widely recognized indicator of clickable text. <label for="mn-blue-links">⊕</label><span>Blue text, while also a widely recognizable clickable-text indicator, is crass and distracting. Luckily, it is also rendered unnecessary by the use of underlining.</span> However, because most browsers’ default underlining does not clear descenders and is so thick and distracting, the underline effect is instead achieved using CSS trickery involving background gradients instead of standard <code>text-decoration</code>. Credit goes to Adam Schwartz for that technique.</p>
        <p>As always, these design choices are merely one approach that Tufte CSS provides by default. Other approaches can also be made to work. The goal is to make sentences readable without interference from links, as well as to make links immediately identifiable even by casual web users.</p>
      </section>

      <section>
        <h2 id="epigraphs">Epigraphs</h2>
        <div>
          <blockquote>
            <p>The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.</p>
            
          </blockquote>
          <blockquote>
            <p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p>
            
          </blockquote>
          <blockquote>I do not paint things, I paint only the differences between things.</blockquote>
        </div>
        <p>If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. Modeled after chapter epigraphs in Tufte’s books (particularly <em>Beautiful Evidence</em>), these are <code>blockquote</code> elements with a bit of specialized styling. Quoted text is italicized. The source goes in a <code>footer</code> element inside the <code>blockquote</code>. We have provided three examples in the epigraph of this section, demonstrating shorter and longer quotes, with and without a paragraph tag, and showing how multiple quotes within an epigraph fit together with the use of a wrapper class.</p>
      </section>

      <section>
        <h2 id="sidenotes">Sidenotes: Footnotes and Marginal Notes</h2>
        <p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<label for="sn-extensive-use-of-sidenotes"></label><span>This is a sidenote.</span> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p>
        <p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p>
        <p>Sidenotes consist of two elements: a superscript reference number that goes inline with the text, and a sidenote with content. To add the former, just put a label and dummy checkbox into the text where you want the reference to go, like so:</p>
        <pre><code>&lt;label for="sn-demo"
       class="margin-toggle sidenote-number"&gt;
&lt;/label&gt;
&lt;input type="checkbox"
       id="sn-demo"
       class="margin-toggle"/&gt;</code></pre>
        <p>You must manually assign a reference <code>id</code> to each side or margin note, replacing “sn-demo” in the <code>for</code> and the <code>id</code> attribute values with an appropriate descriptor. It is useful to use prefixes like <code>sn-</code> for sidenotes and <code>mn-</code> for margin notes.</p>
        <p>Immediately adjacent to that sidenote reference in the main text goes the sidenote content itself, in a <code>span</code> with class <code>sidenote</code>. This tag is also inserted directly in the middle of the body text, but is either pushed into the margin or hidden by default. Make sure to position your sidenotes correctly by keeping the sidenote-number label close to the sidenote itself.</p>
        <p>If you want a sidenote without footnote-style numberings, then you want a margin note.
          <label for="mn-demo">⊕</label>
          
          <span>
            This is a margin note. Notice there isn’t a number preceding the note.
          </span> On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text. However, on small screens, a margin note is like a sidenote except its viewability-toggle is a symbol rather than a reference number. This document currently uses the symbol ⊕ (<code>&amp;#8853;</code>), but it’s up to you.</p>
        <p>Margin notes are created just like sidenotes, but with the <code>marginnote</code> class for the content and the <code>margin-toggle</code> class for the label and dummy checkbox. For instance, here is the code for the margin note used in the previous paragraph:</p>
        <pre><code>&lt;label for="mn-demo" class="margin-toggle"&gt;&amp;#8853;&lt;/label&gt;
&lt;input type="checkbox" id="mn-demo" class="margin-toggle"/&gt;
&lt;span class="marginnote"&gt;
  This is a margin note. Notice there isn’t a number preceding the note.
&lt;/span&gt;</code></pre>
        </section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edwardtufte.github.io/tufte-css/">https://edwardtufte.github.io/tufte-css/</a></em></p>]]>
            </description>
            <link>https://edwardtufte.github.io/tufte-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645691</guid>
            <pubDate>Thu, 25 Jun 2020 21:05:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-creating some of Hey's features using Fastmail]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23645657">thread link</a>) | @nunodonato
<br/>
June 25, 2020 | https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/ | <a href="https://web.archive.org/web/*/https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645657</guid>
            <pubDate>Thu, 25 Jun 2020 21:01:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commenting in Popular Programming Languages]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23645241">thread link</a>) | @sjb_Live
<br/>
June 25, 2020 | https://www.sayham.com/2018/03/commenting-in-popular-programming.html | <a href="https://web.archive.org/web/*/https://www.sayham.com/2018/03/commenting-in-popular-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-5395020165244716099" itemprop="description articleBody">
<p><span> Every main programming language implements comments. Comments are ignored by the compiler and this is how a script generates it's own documentation. We know that Good code is self-documenting. We comment once we delete a chunk of code or to prevent rethink. If we build a library or framework, some sort of API documentation is very important to other developers for easy grasping. Remember to comment as often as possible. It’s important! Here is the list of comment styles of various languages_&nbsp;</span></p><p><img alt="Code commenting on virtualspecies.com" data-original-height="152" data-original-width="400" height="151" src="https://2.bp.blogspot.com/-bWzVJOOaKTY/WzvAjoFDMRI/AAAAAAAB0bo/LhjcDC5ucF8JthxAsEK2wFIe2DwOCDfIgCLcBGAs/s400/CommentPostImg.png" title="Code commenting on virtualspecies.com" width="400"></p><div><p><i></i><span id="lanNmeStl"><b>ActionScript</b></span></p><pre>     <span>// Single line comment in Action Script</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in ActionScript */</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Apple Script</b></span></p><pre>     <span>-- Single line comment in Apple Script</span><br>            </pre><pre>     <span>(* Multi-line comment<br>                in ActionScript *)</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Assembly</b></span></p><pre>     <span># Comment in Assembly Language</span> <br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Basic</b></span></p><pre>     <span>REM Comment in Basic</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Bash Script</b></span></p><pre>     <span># Comment in Bash Script</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>C#</b></span></p><pre>     <span>// Comment in C#</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in C# */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>C</b></span></p><pre>     <span>/* Comment in C. This comment syntax is guaranteed to work on every compiler */</span></pre><pre>     <span>// Comment in C. but it might present portability challenges</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Clojure</b></span></p><pre>     <span>; Comment in Clojure</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>CoffeScript</b></span></p><pre>     <span># Comment in CoffeScript</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>ColdFusion</b></span></p><pre>     <span>&lt;!--- Comment in ColdFusion ---&gt;</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Curl</b></span></p><pre>     <span>| Single Line Comment in Curl<br>            </span></pre><pre>     <span>|# Multi-line comment <br>                in Curl #|</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>D</b></span></p><pre>     <span>// Comment in D</span><br>            </pre><pre>     <span>/+ Multi-line comment<br>                in D +/</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Delphi</b></span></p><pre>     <span>// Single line comment in Delphi </span><br>            </pre><pre>     <span>{ Multi-line comment<br>                in Delphi }</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Elixir</b></span></p><pre>     <span>% Comment in Elixir</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Erlang</b></span></p><pre>     <span>% Comment in Erlang</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Fortran</b></span></p><pre>     <span>! Comment in Fortran</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Go</b></span></p><pre>     <span>// Single line comment in Go</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Go */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Haskell</b></span></p><pre>     <span>-- Single line comment in Haskell</span><br>            </pre><pre>     <span>{- Multi-line comment<br>                in Haskell -}</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>HTML</b></span></p><pre>     <span>&lt;!-- Comment in HTML--&gt;</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Java</b></span></p><pre>     <span>// Single line comment in Java</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Java */</span><br>        </pre><pre>     <span>/** Multi-line documentation comment<br>            in Java */</span><br>       </pre></div><div><p><i></i><span id="lanNmeStl"><b>Javascript</b></span></p><pre>     <span>// Comment in Javascript</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in JavaScript */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Kotlin</b></span></p><pre>     <span>// Comment in Kotlin</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Kotlin */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>LAN</b></span></p><pre>     <span>&lt;!-- Comment in Lan --&gt;</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Lua</b></span></p><pre>     <span>-- Single line comment in Lua</span><br>            </pre></div><pre>     <span>--[[Multi line comment <br>                in Lua--]]</span><br>           </pre><div><p><i></i><span id="lanNmeStl"><b>Matlab</b></span></p><pre>     <span>% Comment in Matlab</span><br>            </pre><pre>     <span>%{ Multi line comment <br>                in Matlab %}<br>           </span></pre></div><div><p><i></i><span id="lanNmeStl"><b>Objective C</b></span></p><pre>     <span>// Comment in Objective C</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Objective C */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Pascal</b></span></p><pre>     <span>{ Single line comment in Pascal }</span><br>            </pre><pre>     <span>{* Multi-line comment<br>                in Pascal *}</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>PowerShell</b></span></p><pre>     <span># Single line comment in PowerShell</span><br>            </pre><pre>     <span>&lt;# Multi-line comment<br>                in PowerShell #&gt;</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Python</b></span></p><pre>     <span># Comment in Python</span><br>            </pre><pre>     <span>""" Multi line comment <br>                in Python """</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>R</b></span></p><pre>     <span># Single line comment in R</span><br>            </pre><pre>     <span>&lt;# Multi-line comment<br>                in R #&gt;</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>Rust</b></span></p><pre>     <span>// Single line comment in Rust </span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in Rust */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>S-Lang</b></span></p><pre>     <span>% Comment in S-Lang</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Scala</b></span></p><pre>     <span>// Single Line Comment in Scala</span><br>            </pre><pre>     <span>/* Multi line comment <br>                in Scala */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>SPARK</b></span></p><pre>     <span>-- Comment in SPARK</span><br>            </pre></div><div><p><i></i><span id="lanNmeStl"><b>Swift</b></span></p><pre>     <span>// Comment in Swift</span><br>            </pre><pre>     <span>/* Multi line comment <br>                in Swift */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>TCL</b></span></p><pre>     <span># Single line comment in TCL</span><br>            </pre><pre>     <span>&lt;# Multi-line comment<br>                in TCL #&gt;</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>TSQL</b></span></p><pre>     <span>-- Comment in TSQL</span><br>            </pre><pre>     <span>/* Multi-line comment<br>                in TSQL */</span><br>           </pre></div><div><p><i></i><span id="lanNmeStl"><b>XML</b></span></p><pre>     <span>&lt;!-- Comment in XML --&gt;</span><br>            </pre></div>

</div></div>]]>
            </description>
            <link>https://www.sayham.com/2018/03/commenting-in-popular-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645241</guid>
            <pubDate>Thu, 25 Jun 2020 20:23:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using NLP to build a sarcasm classifier – Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23644966">thread link</a>) | @JimPD
<br/>
June 25, 2020 | https://techplanet.today/post/machine-learning-foundations-part-10-using-nlp-to-build-a-sarcasm-classifier | <a href="https://web.archive.org/web/*/https://techplanet.today/post/machine-learning-foundations-part-10-using-nlp-to-build-a-sarcasm-classifier">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    <p>Previous: Part 9 - <a href="https://techplanet.today/post/machine-learning-foundations-part-9-using-the-sequencing-apis" rel="nofollow noopener">Using the Sequencing APIs</a></p>
<p>Over the last few parts, we haven't done much machine learning. Instead, we looked at how you can preprocess text data to get it ready for training machine learning models. In this part, you're going to put that knowledge to use in training a text classifier, a model, which, when given a piece of text, will understand the contents of that text.</p>
<p>You'll be working with the Sarcasm in News Headlines data set by Rishabh Misra, which is available on his website <a href="https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection/home" target="_blank" rel="nofollow noopener">here</a>. This is a really fun data set, which collects news headlines from normal news sources, as well as some more comedic ones from spoof news sites.</p>
<p>The data set is a JSON file with three columns. The <code>is_sarcastic</code> one is 1 if the record is sarcastic. Otherwise, it's 0. The <code>headline</code> is the headline of the article, and the <code>article_link</code> is a URL to the text of the article. We're just going to deal with the headlines here. So we have a super easy data set to work with. The headline is our feature, and the <code>is_sarcastic</code> is our label.</p>
<p>The data in JSON looks a bit like this.</p>
<pre>{
    "article_link": "https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5",
    "headline": "former versace store clerk sues over secret 'black code' for minority shoppers",
    "is_sarcastic": 0
}</pre>
<p>Each entry is a JSON field with the name-value pairs showing the column and associated data.</p>
<p>Here's the code to load it in Python when it's structured like that.</p>
<pre>import json

with open("sarcasm.json", 'r') as f:
    datastore = json.load(f)<br>
sentences = [] 
labels = []
urls = []
for item in datastore:
    sentences.append(item['headline'])
    labels.append(item['is_sarcastic'])
    urls.append(item['article_link'])</pre>
<p>I'll go through this piece by piece. First, we'll <code>import json</code> so that we can use the json parsers in Python. Then we'll open the <code>sarcasm.json</code> file.&nbsp; Using <code>json.load()</code>, we can load and parse the entire thing. I'll initialize arrays for the sentences, labels, and URLs. And I can now simply iterate through the datastore. And, for each item, I can append its headline, the sarcasm label, and URL to the appropriate array.</p>
<p>And that's it for loading the data. In previous parts, you may recall that we had hard-coded sentences into an array of strings. We now have exactly the same data structure for the headline sentences, despite that there are now over 25,000 of them. So, for the next code, despite us using this real data set, it will look very familiar. So let's dive in.</p>
<p>So here's the code to tokenize and sequence the sarcasm data set.</p>
<pre>from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
tokenizer = Tokenizer(oov_token="")
tokenizer.fit_on_texts(sentences)
word_index = tokenizer.word_index<br>
print(len(word_index))
print(word_index)<br>
sequences = tokenizer.texts_to_sequences(sentences)
padded = pad_sequences(sequences, padding='post')<br>
print(padded[0])
print(padded.shape)</pre>
<p>We create a tokenizer and fit it on the sentences. In this case, the sentences are the large array of 25,000-plus sentences that we read from the sarcasm data set. We can use the tokenizer to show us the <code>word_index</code> so we can see what words it learned from the data set.&nbsp;And here's an example of some of the words.</p>
<pre>... 'blowing': 4064, 'packed': 4065, 'deficit': 4066, 'essential': 4067, 'explaining': 4068, 'pollution': 4069, 'braces': 4070, 'protester': 4071, 'uncle': 4072 ...</pre>
<p>Remember from earlier that the words with the lower number tokens are the ones that are more common, and the ones with the higher numbers, was less commonly used in the data set. So, of all of the words here, hurting is the one that was found most often.</p>
<p>We can now turn all of our sentences into sequences where, instead of words, we have the tokens representing those words. We'll pad them post, which means that all of the sentences will be the length of whatever the longest one is. And anything shorter than that will be padded with zeros at the end of the sentences in order to keep them all the same length. If we want to inspect them, we can then print out one of them, and we can print out the shape of the entire padded data structure. You'll see output like this.</p>
<pre>[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0     0     0     0     0     0     0     0     0
     0     0     0     0]<p>(26709, 40)</p></pre>
<p>This is the first sentence in our corpus after tokenizing and padding. It's a shorter sentence. So it ends with a bunch of zeros. And this is the shape of the data structure for the padding. This tells us that we have 26,709 padded sentences, and each of these is 40 values long.</p>
<p>With just a few lines of code, you've loaded the data from sarcasm into sentence arrays, tokenized, and padded them.</p>
<p>First, in the code, you'll see a number of commonly used variables. Each of these will be used throughout the code. You've seen many of them so far, but others, like the embedding dimension, will be clear later. The <code>training_size</code> of 20,000 will be used next.</p>
<pre>vocab_size = 10000
embedding_dim = 16
max_length = 100
trunc_type='post'
padding_type='post'
oov_tok = ""
training_size = 20000</pre>
<p>We have a corpus of many thousands of sentences and labels. And, moments ago, we specified 20,000 as the <code>training_size</code>. So that many sentences and labels will be the training set. And we'll hold back the other 6,000 or so as a validation set.</p>
<p>So our <code>training_sentences</code> will be the complete corpus from 0 to the <code>training_size</code>. And our <code>testing_sentences</code> will be from the <code>training_size</code> to the end of the set. We can do similar with the labels. The training will be the first batch, and the testing will be the last ones.</p>
<pre>training_sentences = sentences[0:training_size]
testing_sentences = sentences[training_size:]
training_labels = labels[0:training_size]
testing_labels = labels[training_size:]</pre>
<p>As we've split the data into training and testing sets, we should do the same for the padded sets, instead of having that one large master one that we had earlier on.</p>
<pre>tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(training_sentences)

word_index = tokenizer.word_index

training_sequences = tokenizer.texts_to_sequences(training_sentences)
training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)

testing_sequences = tokenizer.texts_to_sequences(testing_sentences)
testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)</pre>
<p>First, we'll create a tokenizer, and we'll specify the number of words that we want and what the out-of-vocabulary token should be. We'll fit the tokenizer to just the training_sentence corpus. This will help us accurately reflect any real-world usage. Our testing_sentences can be tested against the vocab that was learned from the training set. Now we can create a set of <code>training_sequences</code> from just the <code>training_sentences</code>. And we can pad these to get a set of padded training sentences. And then we can just do the same thing for the <code>testing_sentences</code> and for all the labels.</p>
<p>So before we can train a model with this, let's take a look at the concept of embeddings, which help us turn the sentiment of a word into a number in much the same way as we tokenized words earlier. In this case, an embedding is a vector pointing in a direction, and we can use those directions to establish meanings in words. I know this is all very vague. So let me explain it visually.</p>
<p>For example, consider the words <strong>bad</strong> and <strong>good</strong>. Now we know they have opposite meanings. So we could draw them as arrows pointing in opposite directions.<img src="https://techplanet.today/storage/posts/2020/06/5ef4f49f02367.webp" data-src="/storage/posts/2020/06/5ef4f49f02367.webp" alt="Machine Learning Foundations: Part 10 - Using NLP to build a sarcasm classifier" width="826" height="91"> We could then describe the word <strong>meh</strong> as being sort of bad, but not really that bad. So it might be an arrow like this. <img src="https://techplanet.today/storage/posts/2020/06/5ef4f4c9ea586.webp" data-src="/storage/posts/2020/06/5ef4f4c9ea586.webp" alt="Machine Learning Foundations: Part 10 - Using NLP to build a sarcasm classifier" width="797" height="349">And then the phrase not bad, it's not as strong as good, but it's more or less in the same direction as good. So we could draw it with an arrow like this.<img src="https://techplanet.today/storage/posts/2020/06/5ef4f501a791f.webp" data-src="/storage/posts/2020/06/5ef4f501a791f.webp" alt="Machine Learning Foundations: Part 10 - Using NLP to build a sarcasm classifier" width="800" height="343"> If we then plot these on a chart, we could then get coordinates for these arrows. These coordinates could then be seen as embeddings for the sentiment of those words. <img src="https://techplanet.today/storage/posts/2020/06/5ef4f5343248c.webp" data-src="/storage/posts/2020/06/5ef4f5343248c.webp" alt="Machine Learning Foundations: Part 10 - Using NLP to build a sarcasm classifier" width="969" height="491">There's no absolute meaning, but, relative to each other, we can establish sentiment.</p>
<p>To do this in code, we can simply use a Keras layer called an Embedding.</p>
<pre>model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])</pre>
<p>Our Embedding should be defined as a vector for every word. So we're going to take vocab-sized words and then specify how many dimensions we want the arrow direction to use.&nbsp; In this case, it's 16 that we created earlier. So the Embedding layer will learn 10,016 dimension vectors where the direction of the vector establishes the sentiment of the word. By matching the words to the labels, it'll have a direction that it can then start learning from.</p>
<p>Once we've defined the model, we can then train it like this.</p>
<pre>num_epochs = 30
history = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)</pre>
<p>We simply specify the training_padded features and labels, as well as the validation ones.</p>
<p>Now you can try it for yourself. Here's the <a href="https://www.youtube.com/redirect?q=https%3A%2F%2Fgoo.gle%2F3d6sIJY&amp;redir_token=ONe-_plC_prURgXQYxiQIX-HJVJ8MTU5MzE4OTQ0OEAxNTkzMTAzMDQ4&amp;event=video_description&amp;v=-8XmD2zsFBI" target="_blank" rel="nofollow noopener">URL</a>.</p>
<p>Hopefully that was an interesting exploration for you into the beginnings of NLP with TensorFlow. And that brings us to the end of this 10-part series on foundations of machine learning. I hope you've enjoyed these series, and I hope you've been able to learn from them.</p>
<p><iframe src="https://techplanet.today/storage/settings/April2020/08rLYcVZG5uspJE5KPCf.jpg" data-src="https://www.youtube.com/embed/-8XmD2zsFBI" width="720" height="404" allowfullscreen="allowfullscreen"></iframe></p>
                    
                </article></div>]]>
            </description>
            <link>https://techplanet.today/post/machine-learning-foundations-part-10-using-nlp-to-build-a-sarcasm-classifier</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644966</guid>
            <pubDate>Thu, 25 Jun 2020 20:04:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An illustrated deep dive into the philosophy of money]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23644805">thread link</a>) | @LYeo
<br/>
June 25, 2020 | https://moretothat.com/how-money-forever-changed-us/ | <a href="https://web.archive.org/web/*/https://moretothat.com/how-money-forever-changed-us/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>During my six years of elementary school, many fads came and went.</p>
<p>We had the Tamagotchi, a virtual pet that no one could ever keep alive:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185201/A01-Tamagotchi-v2-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>The Furby, which still gives people nightmares today:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165919/A02-Furby-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>And of course, the Oregon Trail, a game that will forever define a generation:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12185217/A03-Oregon-Trail-v2-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>But there was one fad I remember that not only took our school by storm, but schools all across the country as well. It grew so feverish that after a few months, schools had to actually ban this activity because too many students were getting obsessed with it.</p>
<p>If you were an ‘80s or ‘90s kid, chances are you’ll remember it too.</p>
<p>I’m referring to the infamous world of pogs:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165927/A04-Pogs-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>For those that didn’t get to experience this craze, I’ll briefly break it down for you.</p>
<p>Pogs were these thin, circular discs that were largely made from one of three materials: paper, aluminum, or plastic.<span title="Some kids had crazy titanium ones, but for those of us that weren’t born into extreme wealth, it wasn’t an option.">1</span> Each pog had a “face” side that had some sort of cool, colorful design on it, and a “back” side that was left blank.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165932/A05-Front-and-Back-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>The game itself was super simple, which made it ideal for 2nd graders across the world.</p>
<p>Each round, the players would contribute a few paper pogs, put them face down, and stack them up into one long cylinder. This is the “ante,” or the prize that the players are looking to win.</p>
<p>Then using a special, denser pog that was either made from aluminum or plastic (known as a “slammer” and “pounder,” respectively), each player would try to slam it on the stack, and flip over as many paper pogs as possible. Whichever pogs are successfully turned over would be the prizes they win.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165940/A06-Playing-Pogs-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>That’s the whole game in a nutshell. Essentially, it’s slapping dense discs onto a stack of lesser dense discs, hoping to turn over as much of them as possible before the recess bell rings. Seems pretty harmless, right?</p>
<p>Well… there was one component to the game that made it a bit problematic for child psychology.</p>
<p>Before any game starts, you have to declare whether you’re playing “for fun” or “for keeps.” “For fun” means that you’re not actually keeping the pogs you turn over, and are returning them back to their original owners at the end of each match. “For keeps,” of course, means that you now own the pogs you turn over successfully, meaning that someone must lose something if another person wins.</p>
<p>Basically, a nice little gambling ring was growing amongst us starry-eyed 2nd graders.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165945/A07-Gambling-Pogs-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>Pogs originally started off as a little recess activity, but began morphing into something far greater.</p>
<p>Kids began comparing each other to how many pogs they had, and started forming groups based on the types of pogs that were owned and won. The kids with gold-plated, shiny pounders kept winning, so they needed to up the stakes and play for higher prizes. The kids that only had paper discs would be off in the sandbox being peasants.</p>
<p>Pogs became the shared currency of the school. Kids were trading their fruit rollups for slammers, their Lunchables for pounders. Kids were literally getting into fist fights over them. And of course, if you didn’t play pogs at all, you might as well be an invisible node of society. All that mattered was how many of them you had, and if you had the right equipment to win even more.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/12190140/A08-Pogs-at-School-v2-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>Eventually, the school staff saw enough crazed, disc-slamming kids in the hallways and put an end to the whole thing. They justified the ban by saying it was a form of gambling, but they probably just wanted to see things come back to normal for a bit.</p>
<p>The irony, of course, was that those adults were playing a very similar game in their own lives as well.</p>
<p>It’s interesting how money is accepted as an inevitable force in our lives, yet when we take out the concept and wrap it in unfamiliar packaging, it seems weird and dumb.</p>
<p>To the school staff, the whole pogs phenomenon probably seemed silly because they couldn’t understand what could be so compelling about flipping over paper and metal discs. But they wouldn’t think twice at the thought of coming into an office everyday, flipping over documents, and depositing a bi-weekly paper check in a metal machine.</p>
<p>In essence, the kids were doing the same thing the adults were doing: they were accumulating value in the form of a communal good. But because it took the form of something unrecognizable, it was considered dumb rather than profound. In the eyes of the adults, pogs were shittily constructed paper discs that had no intrinsic value, and only held importance because the kids themselves thought they were.</p>
<p>Well, those kids could say the same thing about the way we regard our own currency as well.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165955/B01-Trading-Money-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>The most fascinating thing about the pogs phenomenon is how closely it mirrors the story of money, and how that concept naturally manifested in children.</p>
<p>On one side you have paper, aluminum, and plastic discs that have no inherent value – they can’t be eaten, worn, or slept on. On their own, they’re useless.</p>
<p>On the other side you have paper bills, metal coins, and digits on a screen that can’t be used as ends in themselves either. They’re just as useless.</p>
<p>Yet in both scenarios, a united story emerged that turned an intrinsically useless thing into the distributor of status, value, and prestige.</p>
<p>How in the world does this happen?</p>
<p>How does something with no intrinsic value become the universal determinant of value? And what are the implications this has on human behavior as a whole?</p>
<p>Discussions of money usually come with the implicit understanding that money is valuable, so they revolve around how one could accumulate more of it, or why it introduces <a href="https://moretothat.com/money/" target="_blank" rel="noopener noreferrer">all kinds of strange behaviors</a>. But in this post, we’re going to take one step back and actually look at the concept of money itself: why we need it to represent value, how it impacts our goals, and how it reconstructs our idea of individuality.</p>
<p>This is a dive into the philosophy of money. It’s a look into humanity’s greatest idea, its greatest paradox, and the story that forever changed human behavior.</p>
<p>Let’s begin.</p>
<h3>Money and The Great Abstraction</h3>
<p>Everything starts with the fact that money has no intrinsic value.</p>
<p>I’m going to explain why this is, but in order to do so, I need to first introduce my favorite game show ever:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10165959/C01-The-Price-Is-Right-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>The Price Is Right is a brilliant TV show where hyped-up contestants play a series of pricing estimation games. Essentially, whoever can guess the price of random shit better than the next person will find their way to a final showcase, where they can win a combination of a potted plant, a trip to Detroit, and a brand… new…. CAR!!!</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170004/C02-Freaking-Out-Over-Car-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>One of my favorite mini-games on the show was the Bonus Game, where the contestant must guess whether or not the real price of an item is higher or lower than what is displayed to the public.</p>
<p>And the best part?</p>
<p>The audience also gets to chime in and scream their opinions at the contestant, who then has to sort through a blend of aggressive commands to get to her final answer.</p>
<p>Here’s an amazing clip of the game in action:</p>
<p><iframe src="https://player.vimeo.com/video/429124077" width="650" height="406" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>First off, Bob Barker had jokes for days.</p>
<p>But second, and more important:</p>
<p>This game is a perfect example of the discrepancy between subjective value and objective reality.</p>
<p>When people in the audience are <em>screaming</em> their opinions of what the price of an alarm clock is, what they are doing is making a <span><strong>value assessment</strong></span> about the object in question. Each person’s idea of that clock’s value is anchored to a personal experience one has with that item, and that could be based on a host of factors.</p>
<p><em>Am I using that alarm clock now? If not, how much is the one I’m currently using? Does that featured clock look like it’d be of better quality? Wait… why do I even care about this damn clock in the first place?</em></p>
<p>From the contestant’s point of view, the audience members sound like this:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170008/C03-Higher-Lower-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>But to each audience member, every shout is guided by a judgment that is formed by personal experience, desire, and need:</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170013/C04-Audience-Members-Value-Assessment-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>Throughout all this, however, the clock simply exists. It is a collection of atoms and molecules that have been assembled to take this form, and there’s no value that is inherent in its chemical makeup. The only function it has is the one we assign it. We would primarily use it to wake up in the morning, but if there was a scary cockroach nearby that we wanted to get rid of, we could use the clock as an anvil too.</p>
<p>This creates a scenario where reality simply is, but the value we assign it will vary based upon the individual that interacts with it. And as illustrated in The Price Is Right, that value is spread across <span><strong>a spectrum of infinite wants and experiences</strong></span>, where one person would be willing to give up more than her neighbor, and vice versa.</p>
<p>For any one item of reality, there will be all kinds of value assessments attached to it, none of which are expected to be the same.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170024/C05-Alarm-Clock-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>So we need to form an intermediary between reality and value that could bridge the gap between the two. A way to standardize infinite value assessments into something understandable and transferable.</p>
<p>That third-party, of course, is money.</p>
<p><a href="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge.png"><img src="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge.png" alt="" width="1500" height="1100" srcset="https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge.png 1500w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge-300x220.png 300w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge-1024x751.png 1024w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge-768x563.png 768w, https://s3-us-west-1.amazonaws.com/moretothat.com/wp-content/uploads/2020/06/10170028/C06-Money-Bridge-610x447.png 610w" sizes="(max-width: 1500px) 100vw, 1500px"></a></p>
<p>Money’s greatest achievement is its ability to standardize value across otherwise incomparable realities. For example, there’s no way I could tell you how many clocks I’d give for your car, or how many clocks I’d give for your house. But communicate those objects of desire through the language of money, and I’ll be able to calculate some relationship between the two.</p>
<p>This ability to create value relationships between every object or service is what allowed money to build a web through every corner of life. Before money, goods stood on their own because they were simply bartered for another object of desire. But after money, the value of goods were always calculated based on a third-party: some currency that was agreed upon by all the members of that society.</p>
<p>The question here then becomes: <em>how was that currency determined?</em></p>
<p>In money’s early history, it needed to have some sort of value inherent in it for people to trust it as an intermediary.</p>
<p>Its first iteration appeared in Sumer around 3,000 BC, where it manifested in the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://moretothat.com/how-money-forever-changed-us/">https://moretothat.com/how-money-forever-changed-us/</a></em></p>]]>
            </description>
            <link>https://moretothat.com/how-money-forever-changed-us/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644805</guid>
            <pubDate>Thu, 25 Jun 2020 19:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Racial Diversity In Tech By The Numbers]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23644796">thread link</a>) | @stephen_greet
<br/>
June 25, 2020 | https://www.beamjobs.com/diversity/racial-diversity-in-tech | <a href="https://web.archive.org/web/*/https://www.beamjobs.com/diversity/racial-diversity-in-tech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.beamjobs.com/diversity/racial-diversity-in-tech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644796</guid>
            <pubDate>Thu, 25 Jun 2020 19:51:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laura Deming, founder of the Longevity Fund, on being homeschooled]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 183 (<a href="https://news.ycombinator.com/item?id=23644762">thread link</a>) | @mksm
<br/>
June 25, 2020 | https://blog.withprimer.com/laura-deming/ | <a href="https://web.archive.org/web/*/https://blog.withprimer.com/laura-deming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>Laura Deming is a biologist and founder of The Longevity Fund, the first VC firm to focus on companies that work on extending healthy human lifespan and addressing age-related diseases through biotechnology. She grew her roots in biology as a homeschooling student in New Zealand, and moved to the US to work in a <a href="https://hillblomcenter.ucsf.edu/#:~:text=The%20mission%20of%20the%20Hillblom,diseases%20have%20similar%20molecular%20causes.">UCSF biology lab</a> at age 12. By age 14, she was a student at MIT, then became a <a href="https://thielfellowship.org/">Thiel Fellow</a>. We asked Laura to share how her education prepared her to lead and build today.</p><figure><img src="https://blog.withprimer.com/content/images/2020/06/Frame-2.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/Frame-2.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/Frame-2.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/Frame-2.png 1600w, https://blog.withprimer.com/content/images/size/w1754/2020/06/Frame-2.png 1754w"><figcaption>Laura Deming. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><h3 id="what-are-you-working-on-and-thinking-about-this-week">What are you working on and thinking about this week?</h3><p>How long do you have? I normally have a few key focuses at work (right now, immune aging from a bunch of different angles), and then a billion other small ideas that float in and out of my cranium. My most persistent focus is something that I can’t talk about yet because it would sound slightly insane, but right now, I’m pursuing these more coherent questions: &nbsp;<br></p><ol><li>Is there a flywheel effect with biological tools? Will biological discoveries become the tools for next-generation discovery? How might we predict progress in biology?</li><li>Why does it normally take about a year for the best proto-entrepreneurs I know to reach full conviction about starting a company? What are ways to accelerate that process?</li><li>Is there an immortal cell that doesn’t replicate anywhere on earth? (We presumably wouldn’t see it if there was.)</li></ol><p>I’m really obsessed with <a href="http://book.bionumbers.org/">Cell Biology by the Numbers</a>. I think quantitative intuitive models of biology are the best thing ever. Also <a href="https://www.cornell.edu/video/nima-arkani-hamed-morality-fundamental-physics">this Nima Arkani-Hamed</a> video is literally the best thing ever.</p><h3 id="what-was-your-education-like">What was your education like?</h3><p>I grew up homeschooled in NZ with a hilariously small amount of context for what the real world was like. In retrospect, it was totally ideal. I had two strong memes deeply implanted in my cranium early in life - <em>I love science </em>and <em>it’s my job to do something really important </em>and<em> I can do it, too. </em>I have no clue who I’d be without those memes, and I’m also not sure that the latter was actually true! My dad just always told me that I was exceptional and could work out a way whatever I wanted to do in the world and I believed him. I still do, in a funny way, despite about a decade of evidence to the contrary and realizing how actually hard it is to make drugs for complex diseases. It’s extraordinarily sad how many otherwise brilliant kids might not do things they could because they don’t have a similarly supportive environment — I’m really excited for things like <a href="https://dcgross.com/">Daniel Gross</a>’s <a href="https://pioneer.app/">Pioneer</a> for that reason. </p><figure><img src="https://blog.withprimer.com/content/images/2020/06/image.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/image.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/image.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/image.png 1600w, https://blog.withprimer.com/content/images/size/w2000/2020/06/image.png 2000w"><figcaption>Laura as a child, drawing DNA on the pavement outside of her house in chalk, an anecdote from a talk that she gave for <a href="https://www.youtube.com/watch?v=YwslKJut8eM">TedxYouth@Tallinn</a>. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><p>I feel like it was a lot of puzzle solving and doing obvious stuff. And then starting to think more independently in college, and to try to figure out what problems I wanted to work on. But I had this moment around that time where a friend and I were driving to a camping site, and I was trying to explain a math concept to him, and he abruptly turned to me and said “I’m feeling very frustrated right now because you honestly have absolutely no idea what you are talking about.”<em> </em></p><p>It’s really hard to explain without context how actually useful that comment was. As he explained it, I was just parroting off the definition of something. The real way to understand things is to be able to see, explore, feel the concept from a bunch of different angles, and to be able to rigorously prove things about it. I still struggle with the latter, but having an intuition for what <em>real, deep </em>understanding of a concept looks like has been a great guidepost. For example, I realized I didn’t understand what entropy was, and now kind of do, after a summer of being in near tears with frustration about it. </p><h3 id="where-and-when-did-your-mission-to-improve-longevity-originate">Where and when did your mission to improve longevity originate?</h3><p>It’s funny, because I get asked that question a lot. I think of it like this: if you were to watch a million people jump off a bridge every day and just suffer in a really extreme way throughout all of it, How would we respond as a society? An overwhelming number of people would be inspired to take action and help. When you think of it in acute, immediate terms, viscerally shocking and moving. But with longevity and other deeply existential problems, the horror of what’s happening has been tragically normalized.</p><p>I really just wanted to work on the biggest problem possible. At first I thought that was cancer, but after a variety of experiences, aging just seemed like a bigger deal.</p><p>I have a much less antagonistic relationship with death now than I did when I was a kid. I understand more that we are a species, that there’s something beyond us as individuals — but despite that, I absolutely cannot square the idea of sobbing when a relative gets cancer and then being totally fine with another debilitating degenerative disease also caused by aging that we somehow have collectively decided is natural and normal.</p><h3 id="how-has-the-way-you-learned-as-a-kid-shaped-the-way-you-learn-and-make-decisions-at-the-helm-of-the-longevity-fund">How has the way you learned as a kid shaped the way you learn and make decisions at the helm of The Longevity Fund?</h3><p>I’ve had to un-learn a bunch of stuff I learned when I first came to the professional world. As a kid, I was deeply joyous about science. I loved it directly and with a passion, and I absolutely believed I was going to grow up to be like Michael Faraday (his story about <a href="https://artsandculture.google.com/exhibit/people-of-science-michael-faraday-the-royal-society/HQLyLIo6MWpoKw?hl=en">getting an apprenticeship with Humphrey Davy</a> is amazing, by the way). When I entered the world of finance with my fund, I was totally scared to seem like I didn’t know what I was doing, and I felt like it was really important to hide who I was to seem more ‘adult’. Now, in retrospect, I think that was both understandable and a bit of a mistake.</p><p>One thing I learned as a kid that I keep on forgetting so easily is how not to care about what anyone else thinks (with a few close exceptions). It’s funny - even in Silicon Valley, hypothetically the vanguard of independent thought, I feel like that’s extremely hard to do. In part, because what other people think constrains your access to resources. So it’s an interesting balance. </p><h3 id="i-ve-heard-you-talk-about-your-dad-telling-you-at-12-years-old-to-make-sure-that-everyone-was-a-little-bit-happier-because-you-were-in-the-lab-each-day-what-role-did-your-parents-play-in-your-life-and-education">I’ve heard you talk about your dad telling you at 12 years old to make sure that everyone was a little bit happier because you were in the lab each day. What role did your parents play in your life and education?</h3><p>Oh, man. My Dad had so much good advice as a kid — I really felt like I got a cheat code to life early on. It was like being Ben Franklin’s daughter or something. I’m probably exaggerating, but it felt that way. </p><p>One thing he told me was ‘action comes before motivation’ - that’s always been an incredibly powerful thing in my life. He taught me a lot about putting your head down and working hard and not believing anyone who tells you you are great, having that come mostly from your own self-judgment. Being extremely humble around people who know more, finding any way on earth to help them. </p><p>My dad also taught me a lot about humor and how ridiculous the world was in so many different ways. Almost too much - I think I take things more seriously now. But it’s kind of the Mark Twain effect - the world and everyone in it is a hilarious, self-sabotaging, foolhardy place that is also one of the most deeply joyous and interesting things going on in the galaxy. He used to say you can either look at what’s going on in the world and cry or laugh. Why not pick the latter?</p><p>My mom taught me about kindness and empathy and wanting to help others. She’s probably the most giving person I know. </p><p>When I first met Cynthia Kenyon, who literally changed my and many other lives – she’s amazing – I had this very extreme mental conceit that I would beg her to scrub floors in her lab and somehow work my way up on the academic ladder. I was 12. She very kindly offered for me to just work in her lab as a normal intern, which was so kind in retrospect. It changed my life, to be taken seriously like that at a young age. </p><h3 id="i-love-how-you-describe-the-way-the-longevity-fund-removes-limits-on-who-can-participate-in-biomedical-entrepreneurship-how-can-we-translate-some-of-what-you-ve-learned-about-diverse-participation-in-science-to-the-way-that-kids-learn">I love how you describe the way The Longevity Fund removes limits on who can participate in biomedical entrepreneurship. How can we translate some of what you’ve learned about diverse participation in science to the way that kids learn?</h3><p>I think there’s something about being absolutely delighted when you meet someone who doesn’t know something. That feeling is the best thing in the world because <em>you get to be the first person to tell them about some incredibly cool natural phenomenon</em>. That’s pretty great. I still remember being a preteen in Cynthia’s lab when Marc McCormick described how SVMs (<a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a>) worked for handwriting recognition in the postal system. He was just so good at explaining things, and that really stuck. Encourage people to own ideas, be skeptical of them, and learn to delight in poking holes in things.<br></p><p>When thinking about diverse participation, it’s funny – before I came to the Valley, I had absolutely no idea that being a girl was in any way a handicap. To me, it was an obvious advantage – in a sea of people who all looked the same way, I’d stick out like a sore thumb! If I could make it, wouldn’t I obviously be an amazing role model? Being in the valley for a while, it kind of wore off, and the more articles I read about how much it sucked to be a girl in science, the more I believed it. I’m not sure what to think about all of that, really. </p><h3 id="what-s-something-you-believe-that-most-people-don-t">What’s something you believe that most people don’t?</h3><p>I can give you a few!</p><ol><li>That we will see the first drug to measurably affect <a href="https://publichealth.wustl.edu/heatlhspan-is-more-important-than-lifespan-so-why-dont-more-people-know-about-it/">human healthspan</a> tested in the next decade, and that this is one of the biggest deals in how we thinking about disease. It’s not just hype and rhetoric.</li><li>That original thinkers are so darn much more rare to find than I thought they’d be growing up. <br></li></ol><hr><p><em>Primer is a new education company whose goal is to help kids engage in limitless learning, starting with homeschoolers. </em><strong>Homeschooled:</strong><em> is a regular series about homeschooling alumni who have gone on to do amazing things. We're just getting started, so we'd love to hear what you think!</em></p><p>Sign up for …</p></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.withprimer.com/laura-deming/">https://blog.withprimer.com/laura-deming/</a></em></p>]]>
            </description>
            <link>https://blog.withprimer.com/laura-deming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644762</guid>
            <pubDate>Thu, 25 Jun 2020 19:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Egui – An experimental immediate mode GUI written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23644730">thread link</a>) | @todsacerdoti
<br/>
June 25, 2020 | https://emilk.github.io/emigui/index.html | <a href="https://web.archive.org/web/*/https://emilk.github.io/emigui/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://emilk.github.io/emigui/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644730</guid>
            <pubDate>Thu, 25 Jun 2020 19:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Query-Based Compiler Architectures]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23644391">thread link</a>) | @matt_d
<br/>
June 25, 2020 | https://ollef.github.io/blog/posts/query-based-compilers.html | <a href="https://web.archive.org/web/*/https://ollef.github.io/blog/posts/query-based-compilers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Note: This is an old post originally from the documentation of the <a href="https://github.com/ollef/sixten">Sixten</a> programming language, that I've touched up and fleshed out. After the time that it was written I've found out about <a href="https://github.com/salsa-rs/salsa">Salsa</a>, a Rust library with very similar goals to my Rock library, which is definitely worth checking out as well!</p>
<h2 id="background">Background</h2>
<p>Compilers are no longer just black boxes that take a bunch of source files and produce assembly code. We expect them to:</p>
<ul>
<li>Be incremental, meaning that if we recompile a project after having made a few changes we only recompile what is affected by the changes.</li>
<li>Provide editor tooling, e.g. through a <a href="https://langserver.org/">language server</a>, supporting functionality like going to definition, finding the type of the expression at a specific location, and showing error messages on the fly.</li>
</ul>
<p>This is what Anders Hejlsberg talks about in <a href="https://www.youtube.com/watch?v=wSdV1M7n4gQ">his video on modern compiler construction</a> that some of you might have seen.</p>
<p>In this post I will cover how this is achieved in <a href="https://github.com/ollef/sixten">Sixten</a> by building the compiler around a query system.</p>
<p>For those of you that don't know, Sixten is an experimental functional programming language created to give the programmer more control over memory layout and boxing than most other high-level languages do. The most recent development of Sixten is being done in the <a href="https://github.com/ollef/sixty">Sixty</a> repository, and is completely query-based. Here's a little video giving a taste of what its language server can do, showing type-based completions:</p>

<h2 id="traditional-pipeline-based-compiler-architectures">Traditional pipeline-based compiler architectures</h2>
<p>A traditional compiler pipeline might look a bit like this:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a>+-----------+            +-----+                +--------+               +--------+</span>
<span id="cb1-2"><a href="#cb1-2"></a>|           |            |     |                |        |               |        |</span>
<span id="cb1-3"><a href="#cb1-3"></a>|source text|---parse---&gt;| AST |---typecheck-+-&gt;|core AST|---generate---&gt;|assembly|</span>
<span id="cb1-4"><a href="#cb1-4"></a>|           |            |     |       ^        |        |               |        |</span>
<span id="cb1-5"><a href="#cb1-5"></a>+-----------+            +-----+       |        +--------+               +---------</span>
<span id="cb1-6"><a href="#cb1-6"></a>                                       |</span>
<span id="cb1-7"><a href="#cb1-7"></a>                                 read and write</span>
<span id="cb1-8"><a href="#cb1-8"></a>                                     types</span>
<span id="cb1-9"><a href="#cb1-9"></a>                                       |</span>
<span id="cb1-10"><a href="#cb1-10"></a>                                       v</span>
<span id="cb1-11"><a href="#cb1-11"></a>                                  +----------+</span>
<span id="cb1-12"><a href="#cb1-12"></a>                                  |          |</span>
<span id="cb1-13"><a href="#cb1-13"></a>                                  |type table|</span>
<span id="cb1-14"><a href="#cb1-14"></a>                                  |          |</span>
<span id="cb1-15"><a href="#cb1-15"></a>                                  +----------+</span></code></pre></div>
<p>There are many variations, and often more steps and intermediate representations than in the illustration, but the idea stays the same:</p>
<p>We push source text down a pipeline and run a fixed set of transformations until we finally output assembly code or some other target language. Along the way we often need to read and update some state. For example, we might update a type table during type checking so we can later look up the type of entities that the code refers to.</p>
<p>Traditional compiler pipelines are probably quite familiar to many of us, but how query-based compilers should be architected might not be as well-known. Here I will describe one way to do it.</p>
<h2 id="going-from-pipeline-to-queries">Going from pipeline to queries</h2>
<p>What does it take to get the type of a qualified name, such as <code>"Data.List.map"</code>? In a pipeline-based architecture we would just look it up in the type table. With queries, we have to think differently. Instead of relying on having updated some piece of state, we do it as if it was done from scratch.</p>
<p>As a first iteration, we do it <em>completely</em> from scratch. It might look a little bit like this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb2-4"><a href="#cb2-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb2-5"><a href="#cb2-5"></a>  parsedModule <span>&lt;-</span> parseModule sourceCode</span>
<span id="cb2-6"><a href="#cb2-6"></a>  resolvedModule <span>&lt;-</span> resolveNames parsedModule</span>
<span id="cb2-7"><a href="#cb2-7"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb2-8"><a href="#cb2-8"></a>  inferDefinitionType definition</span></code></pre></div>
<p>We first find out what file the name comes from, which might be <code>Data/List.vix</code> for <code>Data.List</code>, then read the contents of the file, parse it, perhaps we do name resolution to find out what the names in the code refer to given what is imported, and last we look up the name-resolved definition and type check it, returning its type.</p>
<p>All this for just for getting the type of an identifier? It seems ridiculous because looking up the type of a name is something we'll do loads of times during the type checking of a module. Luckily we're not done yet.</p>
<p>Let's first refactor the code into smaller functions:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>fetchParsedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ParsedModule</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>fetchParsedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb3-4"><a href="#cb3-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb3-5"><a href="#cb3-5"></a>  parseModule moduleName</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a><span>fetchResolvedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ResolvedModule</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>fetchResolvedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>  parsedModule <span>&lt;-</span> fetchParsedModule moduleName</span>
<span id="cb3-10"><a href="#cb3-10"></a>  resolveNames parsedModule</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>  resolvedModule <span>&lt;-</span> fetchResolvedModule moduleName</span>
<span id="cb3-15"><a href="#cb3-15"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb3-16"><a href="#cb3-16"></a>  inferDefinitionType definition</span></code></pre></div>
<p>Note that each of the functions do everything from scratch on their own, i.e. they're each doing a (longer and longer) prefix of the work you'd do in a pipeline. I've found this to be a common pattern in my query-based compilers.</p>
<p>One way to make this efficient would be to add a memoisation layer around each function. That way, we do some expensive work the first time we invoke a function with a specific argument, but subsequent calls are cheap as they can return the cached result.</p>
<p>This is essentially what we'll do, but we won't use a separate cache per function, but instead have a central cache, indexed by the query. This functionality is provided by <a href="https://github.com/ollef/rock">Rock</a>, a library that packages up some functionality for creating query-based compilers.</p>
<h2 id="the-rock-library">The Rock library</h2>
<p><a href="https://github.com/ollef/rock">Rock</a> is an experimental library heavily inspired by <a href="https://github.com/ndmitchell/shake">Shake</a> and the <a href="https://www.microsoft.com/en-us/research/publication/build-systems-la-carte/">Build systems à la carte paper</a>. It essentially implements a build system framework, like <code>make</code>.</p>
<p>Build systems have a lot in common with modern compilers since we want them to be incremental, i.e. to take advantage of previous build results when building anew with few changes. But there's also a difference: Most build systems don't care about the <em>types</em> of their queries since they work at the level of files and file systems.</p>
<p><em>Build systems à la carte</em> is closer to what we want. There the user writes a bunch of computations, <em>tasks</em>, choosing a suitable type for keys and a type for values. The tasks are formulated assuming they're run in an environment where there is a function <code>fetch</code> of type <code>Key -&gt; Task Value</code>, where <code>Task</code> is a type for describing build system rules, that can be used to fetch the value of a dependency with a specific key. In our above example, the key type might look like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>data</span> <span>Key</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span>=</span> <span>ParsedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span>|</span> <span>ResolvedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>  <span>|</span> <span>TypeKey</span> <span>QualifiedName</span></span></code></pre></div>
<p>The build system has control over what code runs when we do a <code>fetch</code>, so by varying that it can do fine-grained dependency tracking, memoisation, and incremental updates.</p>
<p><em>Build systems à la carte</em> is also about exploring what kind of build systems we get when we vary what <code>Task</code> is allowed to do, e.g. if it's a <code>Monad</code> or <code>Applicative</code>. In Rock, we're not exploring <em>that</em>, so our <code>Task</code> is a thin layer on top of <code>IO</code>.</p>
<p>A problem that pops up now, however, is that there's no satisfactory type for <code>Value</code>. We want <code>fetch (ParsedModuleKey "Data.List")</code> to return a <code>ParsedModule</code>, while <code>fetch (TypeKey "Data.List.map")</code> should return something of type <code>Type</code>.</p>
<h3 id="indexed-queries">Indexed queries</h3>
<p>Rock allows us to index the key type by the return type of the query. The <code>Key</code> type in our running example becomes the following <a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>data</span> <span>Key</span> a <span>where</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span>ParsedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ParsedModule</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span>ResolvedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ResolvedModule</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span>TypeKey</span><span> ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>Key</span> <span>Type</span></span></code></pre></div>
<p>The <code>fetch</code> function gets the type <code>forall a. Key a -&gt; Task a</code>, so we get a <code>ParsedModule</code> when we run <code>fetch (ParsedModuleKey "Data.List")</code>, like we wanted, because the return type depends on the key we use.</p>
<p>Now that we know what <code>fetch</code> should look like, it's also worth revealing what the <code>Task</code> type looks like in Rock, more concretely. As mentioned, it's a thin layer around <code>IO</code>, providing a way to <code>fetch</code> <code>key</code>s (like <code>Key</code> above):</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>newtype</span> <span>Task</span> key a <span>=</span> <span>Task</span> {<span> unTask ::</span> <span>ReaderT</span> (<span>Fetch</span> key) <span>IO</span> a }</span>
<span id="cb6-2"><a href="#cb6-2"></a><span>newtype</span> <span>Fetch</span> key <span>=</span> <span>Fetch</span> (<span>forall</span> a<span>.</span> key a <span>-&gt;</span> <span>IO</span> a)</span></code></pre></div>
<p>The rules of our compiler, i.e. its "Makefile", then becomes the following function, reusing the functions from above:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>rules ::</span> <span>Key</span> a <span>-&gt;</span> <span>Task</span> a</span>
<span id="cb7-2"><a href="#cb7-2"></a>rules key <span>=</span> <span>case</span> key <span>of</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span>ParsedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>    fetchParsedModule moduleName</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span>ResolvedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>    fetchResolvedModule moduleName</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a>  <span>TypeKey</span> qualifiedName <span>-&gt;</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>    fetchType qualifiedName</span></code></pre></div>
<h3 id="caching">Caching</h3>
<p>The most basic way to run a <code>Task</code> in Rock is to directly call the <code>rules</code> function when a <code>Task</code> fetches a key. This results in an inefficient build system that recomputes every query from scratch.</p>
<p>But the <code>Rock</code> library lets us layer more functionality onto our <code>rules</code> function, and one thing that we can add is memoisation. If we do that Rock caches the result of each fetched key by storing the key-value pairs of already performed fetches in a <a href="https://hackage.haskell.org/package/dependent-hashmap">dependent hashmap</a>. This way, we perform each query at most once during a single run of the compiler.</p>
<h3 id="verifying-dependencies-and-reusing-state">Verifying dependencies and reusing state</h3>
<p>Another kind of functionality that can be layered onto the <code>rules</code> function is incremental updates. When it's used, Rock keeps track of what dependencies a task used when it was executed (much like Shake) in a table, i.e. what keys it fetched and what the values were. Using this information it's able to determine when it's safe to reuse the cache <em>from a previous run of the compiler</em> even though there might be changes in other parts of the dependency graph.</p>
<p>This fine-grained dependency tracking also allows reusing the cache when a dependency of a task changes in a way that has no effect. For example, whitespace changes might trigger a re-parse, but since the AST is the same, the cache can be reused in queries that depend on the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ollef.github.io/blog/posts/query-based-compilers.html">https://ollef.github.io/blog/posts/query-based-compilers.html</a></em></p>]]>
            </description>
            <link>https://ollef.github.io/blog/posts/query-based-compilers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644391</guid>
            <pubDate>Thu, 25 Jun 2020 19:17:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TPUG – official publication for world's largest Commodore users group (1984) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23644387">thread link</a>) | @halturing
<br/>
June 25, 2020 | https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf | <a href="https://web.archive.org/web/*/https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><b µÕt¶áu„ãýºÓ¿�a‘¡="ÒÜy-—" ädä]ýlp–ƒ �kÂ;i d3Çßäzeq¥Óúÿý6íá„·Ò¶ª“ÿ@Ÿz!_!»tÓïiéÃw'¾­èdrÐ|†¤="ÿúÈ&amp;l/KiûuãUéßA8éWð—N(„ÿ[^Ÿ#LE-jCÖQ£Õš¸ad5Ç=CA×é}HWÿ¥v²$r‡)ÈC•³*»t×ð“¤á¦M?ÿëÕo}2[ÔŠeMBÄ)9Ì&amp;" ÿúÝ$ú–!^[ <'%kÅ²9="" ´„ÿ}÷}[_†)Î9ìƒ–="4ÐA¾8hmþ—Iÿ÷°©:¥á@Á'¿!!Â;,»¤" ¤—'Õ«Óªjÿ""?§ªÁ\‰ŸõÇÿúá‘d`+¶w_¯§c»t“´š"y�´0¤iÈ‹[è~byq…ôÝ„¿m'z±‘8@Ûÿ^—ÿÜgo}u„j="}&nbsp;°äÑÂ„kÖÒAa¹çÓÿ«_ÕÓ·Ý?ú©n�/ÿÿ‹}ª•D’u~“´v" Ó¬8µmÓÚéÓ‡„bücß»�†öûjÕb¥ÿþdf�]-5zõñ.¶Ë)fôî;x[ÓtžÝzÓ´ýï~ëa×ÿk™‚v°avÕÚ�¡4°�nyeØ0ûk¦kÛ¦×nÚá…ö®ƒm;Ø[†j¿ÿ‘¼îÎü­�v(="" pÊ´x!+ÛûkrÜa&aƒó²|0©o½ûtv•¬©Çyr\§;”?Ú{·øí&ê—ý®ˆÌªž="" ÒÆˆcºˆÓÒiù\¬Ó="" ¦="" 3®íÒaý{‹{{jl’¦¤[^"#ðÂºa�·m¡iØiì="" !i7êýa}Ú­þ="" ­àÃ[º¶:ÿt¶Ýÿƒ="" ¶ûì*lp_øk²,v¥q¯vƒ;… ƒc§="" u­Ê§Úv="ÛjÚûûVý7_;€²nF?ñ½öé�jtžÿ†" l†qµš«b5o§_ü–×î4÷ ­{ßac°iª}¨="" äe^ÔÈf–ßÖÖ×ÿ="" �qÎ9nttöa‚¤ƒzm'#f¥uµôìÔï‰ØgnÍ}w="" )kl0º Â„="" òÆé?aáºiÑ¶Õ¾Ädd.Õf©õk„·ÿðá¬íÁ`–½{b†;xÓùß\="" kpšj2Çmbÿ|5qÈqÕ~ˆ="" ç´ÌáwÚýò&0pÙy°ƒ="" †»ÊÊím÷="" ÓÐvÖý¼5=""  Ô*<6‡þ°`³¾ŠÇh‹!²(å9à±Ánl„ä@Øhg§ÒµÖpØ{ÂiõoµÐøa[="" c!£�›i¹¦="" ›="" ûr'ƒáa•p×kÂ–Ü="" `ˆ.”c9Êe;(þãµ�\rc÷p}b="" 0`¯k="" "(ë{="" þƒ+yt¢+†¢@Â¬8ÿ™Üˆˆpd�µga:ì="" Ù!}6;ßñÞÂ§a‘7ø0¸pÃšþ÷ vcÍzû="" (hÿ;u•ªÁ‚ïª;!a½éÖ‚wê="¦Ýá”áïŠ†Z¤»è(þ¶Aù" ¶ÿÓ¶·="" ëpƒ“§ÝÛ¯¿â”ìz*q+%¾="">"¡�û
»àˆ&amp;ÒŠ¼k¯ù\�7AaábœRÃ
ÞŸ‘Pjj‘ùÕ7jU":Ü&gt;4Ý»XdvG280V¯ð@ÿväh"­I=7Ùå¤ðˆ4¨Aß}Dvß	�šË[§kúKT6š¶8kv@Ô†¥
¤ÛKáw}x·…õßAïîíûÕaNÇMÂdÑÔŒ@CI8×knÞ´ü/aO}ïa©nrM¨&amp;›I4ï)Ag6Èhßëï[ÎômiàªëÈq×éã^RÄx5C‡h^Î&nbsp;€ƒ[P˜AÓÖ¿Ú·Ã}9
9\aÍe_ãþûð�µ h Øa;ƒ�øØ|;Ûz¯á²)QÀÏ±W•–þœDDjð_ü„ïªB&nbsp;á+­çzä	°´Ð&amp;]¶;k&amp;a�+øbšw&nbsp;l7ï\2¤€«ø&amp;þè'A:qO
4�`èj¢Ø2íÿk~ü6ÇD?�Wõ&amp;ïõNÓ„ö
�p·TÛÎìÿ¿‡È8o‚eÛéä‹¿ÿ
íÃ
ƒ-Ì¼'Wv&amp;“]µü;J­{Ø5ƒo‚ÃùÙÊƒ×û†þ5Oµ{Q
u¿aììàš]¤M�(aÃY
ŸÒÃ{OMÂþ·î“é?-êäÈð†yh‘¿!-“–?á…�SÚ‚F/­ú÷�Ë42™Û™þööé2Ü”VC@åAP“}99„òNßúÞ†JØXlPo­ºÞKbþÕ¾Ý"“n‡ÏðÚAP7_ÓnV,Âê”‚[ƒþòI,NÖaºïûvû©ynp$¨Rnýaƒ[þÕ;ª�ƒ´•Œ›¶ŽÜ2úôG;[×ÿÛïTô@ÿØÖÿrƒ§û&nbsp;ÁÃ	$ÒvÐ?ý(§Õÿ»~ì$¿…†Þ�l-¥Mÿ#Ø‹~ƒ�k¶�¯Þ“;¬([»ñ*wj°ö¹\P)zwþ¯ä@è@¯Ø4
´˜ ¯íÃñßvÕB½¥Nüi¸M&nbsp;øa¿ÚL ÎÍs´€PDõ°¿»VÕwk®d5ê÷„šoZiXAäò–Õ‚ûQM©z|2|�ÿ¿§ÎõýÝ%"¨'TìÏZ¿Ž›mpJ”4ò5dëgf°†÷ÕÓ]b?Ý®ù
rµoøi…V´íöèaß‚Ml'…½·Þ’ �Ë´ï{ÿÝòÓ.?D†!×Ø30×Zî÷ÿˆè A¦Ep�„þ¶ha¾Ø0T×v;Á?Å¬&amp;N?IÂoè„µõn–� Âè.ƒox¤�;¦&nbsp;ËŠ\;5ÿÚÔ íjÎÕ‡ï
•XN×½¾¨&amp;ía&amp;Õ¿ÂNž¼Eøk¥êœª‘›/‘Ã*¿]¥�ãý+£¹ˆ‚;85;§XiÞÝ$òiÕ'þ&lt;$íUÂz¬‡ÒQ½…v�_cäTà�ieˆìtˆ_'TA"Ðý'­Zö—"Ê÷qO5„!2¦—n¡&lt;�Ì#/¤ÿøVÚ^÷a^má¦'TAsc+NžÝzXxÒ„ÿúX0¿ñÕ0¾„aÖ �ì ÒíB„õ·Ân®C›ˆMéHH²9N¯w¯º"À*†l„™6ë­Ø*ë~¸IÈ‰Âÿ¤ÛZ«|‡oó±P•}ÐµíbNð×ˆÓÿ«p–_ýS÷Âº‘·!ƒt�‚�­°ƒ\Rë÷þKaI“×ÿémZÈš‘®hS„'hì
&amp;ðŽçkétKúêJÿÿ½„¤ËÞšÐrUÞ4“½„šßÂè_é*
÷ÿÚÓ	�¨¤Ûl.Ât
‹vˆ".=S|·DÿëÞõ‡ÿÿIZŽ¶¡4äNƒc¬ Û�”0Èd¨*w`ˆR_þÕw§ÿ–i¤K;Ô4Ò¶!‚M:m5A2;Ð1ròÝ‚¢Ó–N
C?¾@‰’µz¿ÿM†
/ÇÓÃÚpƒ`ƒApx´	ä+“�ô
‡¨ éõ‘ˆ½õ»A5ÿ^)NÍSTì&gt;Úä8æNv
„Á�a?©&gt;qÁþ�z×ØUñ	ÿ½Û¨°¾¦-±øA�ˆ×¬?&nbsp;�{v\%}¥úÿmiZµ`ÖB‘úuL)Ð[þÂ[ vÇ^Ã?ÿV�¯�^µAƒ @þ¿¾wÝið`‘*?×ÿ,ª0“A”²rfn�Z–æÂ¾äR
§iÇíìŠ?Iuoþ0ƒ)ÿ_òË¨bA�Ëøa
iƒ!Rš•Ò&nbsp;™Þ&nbsp;›;Q¯á0¶
WûG�¿RßÝk´™á‚µü4#UÎÇ]Ó_ÓTÁäŠá{ö¤{Vë½ÓA&nbsp;Ûõÿ»†¼ }7ð_‚È|�Š$DäU�ì3@Ç¥Úš§­=¤ÓO°’ÿ&nbsp;Ýƒ/ì[L'Óý~$;l!–»Á�Â
ºÂiS]�ÂBXÌ‚©¶‚&nbsp;ÌÒ „�ÿÔ�Kk……G†vR%6úÈæ§&lt;T®ª0ÙÐÓ~®4Ý‘ìx {Qi·¯ö¼2Ü®jALµµêð‰qp¸N¶ÛþE,„ÜWÖµÓØH]Òÿ&nbsp;pIaS+­ûÁ§ ›�š†UPm°\©ÞŸÒ…¦¿KïMCR;½ïÓÔ&amp;h-¦­Zr[°QÃv“ªí´7Úúcý/\-�\aÈGm×þ�%„Ýµj÷…­¾Á*ÝÝ¸ë;ºÏmm­}ŽTÍ!¦Cþø_ééUÞ­Ztê­7Ó`ˆl¿í}}èzKú�lw¡Ó&nbsp;‚„Ÿá…rßzŽØ0“é¸íõ¦ˆâƒ}†«¾µÐl&lt;ú!ž�(IÈJÈƒ•‡5Âd¢ÂÕNøom!œÿû¥{„GŠµ¯µ»þAÄ1J¹ `„CàÉ7¥†ÆÒS·+L&amp;I¯íºu ‘Ðtü,Š\¢áXS¼¿qô6’H…w]ã!ô!ôpšÚáwM0Ð† …õ2Õé¬‹†²C{KGTþ¿ô6ª~—dÉ§é»T“;€„‚HÊa•¾waun‡O]ú°¾¿ÿ¤ôáz§­Ëqj�›Âh&lt;0»PA¦“µ&nbsp;êÍ‡ØLšRº]ï2-ÿé´ºÚ¤´¾¿`ÂÁ&amp;ƒMA…xH ì+Áiñh{d÷J¯™†?Ò––#ÑÞ·`«ºlU&amp;Ÿ�áxÓ�¯`¸|ˆï*ƒ&amp;RôÃPD›iþ›AR+(´àž‚_ý'Ý¸`º	Å
¯Mâ6`¿
Aÿ§	6•T–ÈjÓ[ø+Zvîa†Sï§ÿÃï	|3‚ÿÕ´ªUj#÷íi§mÃ
8tƒhíD¾¾ZÁ¥ñ§ÿN´”xi×åp°Xk�ö÷ÎøÞ—+JÖB§)È²Óyeìp›î{ÿ¥Z�…ëµÁ2q�–Íƒ·IÒ
VFL/‘yé¦WLôÿéÒh+Xa&gt;–ÂÒpnpé�ÐêA�Ýz×ð�¼²þƒ×I¤ÿû	5ŽW%nØ5�%»i†7a"=Z…óµ0Å­øv»…otý:OáÆÐ`›N©Ý½AÃPHnï�‚ƒÃ÷a{í'þ� ˆDÂQºœ mùTZ~ôö˜qAä]Œ"x$&gt;º@Þ·ÓŒ;`·¿ÿÚI°‡	û‹«¾Ú�K`Õ&lt;Dl²»„ûzxvDÅµmcGÖ‚²YáÜ(Múí¿Ë†Mø»A®ùd&nbsp;jîØ@žÔípoÿÂäÜ&nbsp;=]Ò!È!d ïÚ&nbsp;°pé=^)°×ðžì0‚¨0�‡„
ÿ½$¡‘¨mÔŒº;V£ßoánõµºpÖý=Ã'ct?ÿh,'&amp;Ü›zI²±&amp;µí¶¾olqAÅ0ý?B®ƒý$¦UH:MÚ§íd&amp;5¯ké7µÐ~*ÐOÿª��É„ßx*m5_T#÷Ëu¶e\›PkÝa&nbsp;ÒÐoþô4ûÑ£KuU÷ú«NAèPi|'	„©?ûýªµ7½…îÒJ¼~F1A�¨´B´Çò2ü4%¯þÒÕSz¹	&gt;Ü28OýNà%pÓè6~CêC…	¼0]7ÿ«Á›F�d+¸N¼uÆ—çxïA�ŽžX@Ø`šäjÉ&nbsp;Þ‹Jÿí©nH,F‚»jÝý7_çc‡uAÓl;AÅ®^d]á†µWÿixXz}%‘hmÍé]¨D‘‡„é°Ã†FN
¿í?ƒ „1ßý½î»^¼(MjµLpÁ±¤ø·àÁ¯ÿÚ¿]•(“·öéº‘% .M†7xpßýàÃÿþ_]õ­°´íµ7pÂIáƒªs·/ÿ{ÿØV«wOøiÓ]=è6Ì°oÛov¯Ã×ÿª¿þ%Bô›š†C·~=ål1ÿðv2-•Eý…:~È&lt;ò&amp;ˆC·IÕ•¯ºîv£ð¡ýÿM(!ÿ�”`ƒµŠD‹Åáºgd÷D&gt;SÃÛñMd)Êò®×þÙáPãMö¨6ïKmBdíÚ°ëuõˆŒÿÜEmõîÕ§l[©ÄÇefV¡P}Aƒ‘*!6)zïÞÿòÊjË“Ov—Ý5A²¶!‹réáAQáoi,7j8 ~ÂEm¯ýøˆÛÚ¾ØZð˜A¦Ô*ÛÓ*ù:&amp;Áè;nÂäroMwuÿ-*~&gt;¡¨ho	”±
HìÕ­D$·µj·�†íøñßõþu¼0H0ž„ÊA¦£Xn†ƒï@Ã¦îÈ™~¿kþvßÓ
×	pƒð_ã;ó®ðÁµmèV¸ÿú}ÔŒ&nbsp;(&nbsp;a-]'x-o�¾bÿ ìÿ«	í¥þ™‘íê¸2.Äôœ$õÿýÛÃøû_òÊ¤“µn4=,$á‚`µ¿û@ÃÛY
Œæºä†w*›_òÈ–�ié;TÒ¥!ÝÂã
w�}sµkº„{ä4%ár¦W2Øa/ôôá…
5µè'I&lt;&gt;ü¬Á=Õ
­ì!™·ÉÊæ+µÿµ¸ÄE¢ÜÑÕ+Ò!ã…?ém½d�Ï"¶ÞÈ44d{	ûV%þªˆN&amp;ü0“ÿéì&amp;ßU×aZµ†‘)‚Ÿáuû àÿí……AºiX\-R|*{k!ÃVŸþÃÉh4§Õy‘%òh¿äA…v°ø`”‚á­W¯OÂÉv­Õ
Õ†¤,?…÷jkLWüF–äÌ%b‘u¦7^½€0y„ÛŠ&nbsp;ÜÑ°ÑÓC‚°ÒA¦;R×¬2:	‚
ÿúðƒ&nbsp;@Çõ­%¤ßÓÄFÞ1ÈgQxÉÖ±
¯ûöÂA“a&nbsp;�¶ÒW­‚‚ÓnŸÛª†Äè7Â
ø/°¿úÜ ä›†™@©-¯kR=p†ï¦îëd2º,¥ÖÓkÿý93e¶[‰¬ é8¥ÒX"l$Açn…·nŽÎ©Š{,µ
L|ÈÔ=¯ÿôé2Ü×Nz�ÉÁm%ÃaàŽ¡½èl&amp;PäÌ­28éŸ$7þ¿ëôéSNpÍ��ÑpÎ�+T›ám×NÁ"´�³ÁŸMm6¿°¿ëu¾þ“b";k¥vÃ‚w`´„2¶€É°@oA„œ1¦ƒA�ûA¯ùÛªoD"�ð½ZÝiÎÜ-6at(0�Â
6,‚é5Oßh0·ù6æuIš9
w…¥ðÐÖ8`éÌ“Ü‹RL'!—³ ¬ê.ƒBÕW�µ\ d6¯ý[&nbsp;�Ù=d,7Úi«=ÓX é„JBRÈË¸µù-‚‘›ÿ·H ÙKqÒAÛÁ›càÁ×®
¦�A¶=ÉeVCUÊrÇ*Pÿí®à�Â­¬CKÎðz»gjäÐt‚ê€ïNƒ �õDQ„Dkþ®«Aá×IÝ¡X=ÎÇ†›"m;	æCbÈl§,“åÁt�Ùu„ÿø»Tá:¿\4ÂP¾þˆ8ý¡�1­‚(©7_íÕ6ƒW¾”®*C@½
ü„öƒ/ðƒuÓ�ÿ^›ík“bÏ›R1ëµJO+è&gt;·¦©ÿÃM^�Zgx@¼'Ü*ˆlr‡e~Mv»NÿÄFUOx+U†MŠ	×N“Ž¶ä0�&nbsp;äwÐãÙ’x©ÿãÒü„¢´’°™ÙÁ	6’§¥Öè‡VÉ!¦æa³ë_{_òÊ9ü‰ÛY1�†&amp;˜A„Ä Vºuêí&nbsp;�²
v·`×ûú”¢ÿð@ÉM‡íi—mÖ�¸&nbsp;¤ÛPÔLaj©Â^¾t#NÃ`×!Üî{-×ßàƒ!–¿è4v°°öÃm('&nbsp;Ð&amp;)à^C�£•Ä]�Òl á°Û5#VHoÚGvð�ÿúií¥íáiÞ­4ê#D&gt;®Ojš÷&nbsp;á9
°Ç„×V¡]u–ª×ý&lt;,5Kvý¶¨*i��˜ œ é5ÿ¶ƒƒ¶ÿíƒ;XKÿaX`¾íÓNÑo¨Hj™ß‡
,&amp;ö«½ éÈ7Èþ0ƒµa íÓp²ê¶î†Ã4äÚ`ƒ«è;A…!¬9à&amp;þ§þµa……Á˜G‘´aÈàÇþØV+÷¥ �¢dÝáO­¡’¬ŠŸZíÛcý«&nbsp;Ì‰«’YvæíËp&nbsp;]ÿ-Å§
b}PtAÝ&nbsp;Îæ¤œj}­jvŸ¤Ó!tU"ÿ"t&nbsp;‚µþ"!ƒ”ª°y	ôÁƒ_o&nbsp;ÛvÞAÝ�–o�í'{ûÿôØpZ-æ×NH˜B‚ÛJOlÕeyúMñú!&amp;LyØP-ÌÏßÝ?i$¿þžÂ†·Kµ_þA´ÎÃ$4qÈx*fp^�S·IuG…
A@äQÊÝq´žõ®¿ÿmÁZÓ[^éëº·L;%±2m-þè,892rWÞBy7Ý¾—ÿ»å¸Ø(0Ø+l%fhøZOýªÝAëÎÜ=ãNÝ}m†"”`yd[á¨têÂÿÿü N'Ž#ÎøÓÿëyvøAë÷_NàÁ fªôØaIƒ…†á¨kK¿ÞÛÐ,oÚ;py×ªívÑäÞ­Mp@íWn¿Ý¤CAË&amp;vÅ6–þÕ¯ÿ¿Âë&nbsp;ƒAIã·÷þÝßÓ_·…ô¸n
}5§÷ŒMÒÈl‚,?ûv¬&amp;ëœ*ãÚ¿ÖêÒL'»	ÿÛƒ¿ö“­²±�;‡Þ5JFœ!~ý·ÃWXA×tïÿXl8¶º
ý¦ûmÇö¥ïOÆÂK_þÃ´�†õÚXqþ½-ûISÝDmo~È(
-;ÚÓZßþ!‘ÂÎã$÷ªN»½+úÝØ0Lœ?Ú]n“l7ã/«þ‚ëÿ„(·+;Ën0Š9Ç&lt;Ñ60"~çeŸ
}cOµÖüìTÙ?
üWîÓ¶º_ýXz�Ô&nbsp;‰r†7oVã{	UØCOµ;€�ºjƒ»d3/kêÂízÿô´íNw[’];«†¿òªÚ‚kú ßí”‚Êà©õ­G’Ì4:ÿê&nbsp;Ì%ÜDŸÓßãÚÎËu‚eãá„�=x`”=°l²à6{	¶éòP†ÃX_ÿ‡ ÀämíZ
·ÿºnµ×Jƒ²&lt;¥C(6Òn8¶ÍA&nbsp;²Ì5&lt;|/!\±Ê‡ª˜@Æ¿ý ²
éQtá¿°¯^ïEb»¬7'µ�wþò(°·#¬ áˆUÿ„¶šOé{tÝZ}¯[Ö�…n°íé2p—Ó^šüˆ@ ¶Ý7ü[uu¶º×o´›
+i‘Žü…Ðˆ´“}*Ý;ÿÁ °[NŸ°»´Ý=‚ÙAd9C�`sàUôÕÃ	·L#á±—áäÂi6ééuÕð�X-.íÇ‹ð®*ÑÌ"8e².Æi;
õƒX‡öá'|ý¶šÿ¸ V·&gt;²Ÿ}bí_Âý¦•\%¸L2@z
ô„›ÔŒ…ý¸OÿÂ	�qÌ9ÁmJX¨&amp;]ëoÃL'­¯Ä0¤n÷a9¬…®ºÛ…ˆÖC»4 »†ýÐR`Éëåd…Aµ{¬Fëÿa GP‹BÁ6!öž“n’
×Á
¤Ã
ÿ¼*ò$
Ì…:Ýöën®»Á‚„
¶Iâ|}öÝ…A¿ªw(ÿÆOaè…ƒ¬7ÓuO[O©�¡ÓƒBï¶•m0[ckW„˜_í=PO�o«ÔƒA$Hs'XÞ�ÂlC¾ºM»þú_ø6uëTt×ýáI•¸�i»á—îrÖ�ï¬_WwI¯òÊ�ƒLGa4½ö­0©í2±bP®0ƒðNÿ^í{ÐU&nbsp;Áƒè&gt;›[¶¢4Þ·Œ‡„]IÐ ÎÉSOmå“?KN¶ý?÷ƒ
h”A_ö–ÿ¬˜?&nbsp;Ðµ§õÕ¯è&amp;¿Ô1»
¤CÓü0­&lt;;´è;nŸÿêê¡aœÝ­5ÿ‡`à&nbsp;�BþÁ‚�ÈI’‚µÛn�e)ûì.Ò¾ŠXBØØ;ZkýC†½†{Öø? ¤R:w„¶ºE¹“!lÈ~ðÍY-„•ƒ^,%L/òËc#Œ·%$ß«[š„nMÛtžþeøŽ(*iíGD
ÿ‚‡NÜ0“‚‡•°¤ƒv¡'�‡S]zt{ôáSºÖ‡ü(tÚ¯Ž�ïA„ˆeî1úê�÷ûJ�ÓK_êá1öö‚
oNÜQ!í¯òYþµïÒ¯õp»}4™K¿[áì$�¬ÿL'½¦ºÿV�.›¦¯^“Ò‚ö-¬_ôÑ©+bÂJ¿ÔBî�„škuvV|·Ö§Øa0NÁ_~ƒd+ÉÅ;±Z¯Â[�§W¦–ÂÈ&nbsp;ÉU­Ó´éùqÇ"À?áý6"±U
¿è E¸:íÐa'O%Åi°Ý¤»ásá—ü‚Zá0Â’TŒÑ
È6@Û¤Ý„N[qßºt!¹àö¡RévÉÀÆ¼””í¸A�_ò6A@‚zâÂDþµÃtÌ ¡vä+ž„*ÎÛïê¼'�ýBM´“ n¼%]6ñ^�Wä�×l×­íÿéBAÃMPAÚ­Zo»Ôzl×öõ¿ü:pÂ!�ðƒiâîý(V«
½û¿I¹\§ÿh0ÈrÄtô—ïØ-í7[¼x¶úm'ÿƒµÛj®ß£³¢èíT.¦¼y—;�AÖ2v¾ïLü;D+•Õ&amp;Â�:ÖíÕø&amp;
Ý[r!²²Ï¡ö²½×ÿ
Q§ß²[%&gt;ÕÛÖ�3±ÁdÕ&gt;‰Y!Œï_!í¬6ÿƒòmý&amp;V}»XH&lt;ÿjé�‹üF‚2f/aÐOW{×kG@šÂ&lt;†~ŸM?,ˆ5„	•&nbsp;Îÿ P=&gt;šþ©§‹²oÚ…ê¿OÁH4’Â
2¿‚¶¡÷�"Ë²!µUúô‚ÂMÐ&amp;¬Èª¶¿øA&nbsp;Ö�`¿íØ?ÈÍ‚Á‘Ñ¨-¨­…ZMáh5Î¬*úiÖá4Âÿ°ÕêÚˆÝL’#‡Žµ¨ ª—é…ý;J´Óÿ!+[«×…2º´œ��Àæ„t;^»
ÿw«h4ÁÐ�}îÂAj…~hˆ�ˆ~×½BµûÂélì	ÿ«Zµ¶ªÕHJ°N=Šô¬$ÂõäPÁ=¦š`¿ù7‡ÇtŽì@µPƒi6÷áGì7~@¼5)Vw&nbsp;5ÿÒÚUtÈµ!&nbsp;žœu]®ù	ps¼ª ¸Ç!Èi¦ÿþÓn}B;n›újá~l8 oè‚+Â
êÿµ&amp;ñBxA5…„C:àÁÈö
]®÷l&gt;Ò‚
&nbsp;ƒÚ‚ Ñßü›¤Ã	1tBiqA¥!—³Th'§\0VÂ_·„ÞÕƒÁšƒ‚ïÿÃ
nµ’/ä&amp;Ó’ÙvþîªÐ¦"/õºmZÓtñ‚ÿÈ!º,P îƒiÂ„á=µÂ
ªµa&nbsp;OîúbÃI ôø Oÿ$nžÒ…ÛNéûáx+H0ÁÿÞƒ°´ûx Mµè2Ü;N�P§Õ¨Z‘›’x`Â}·TÙFž»ÿîÒe¿Æ™4Úl·®ö“ûÂaE4…íÞ¬R·úÿí&amp;W4�nÑÎ†þÔUÐkÛôÎÔº¯v&nbsp;¯ú¦“øpRñéëjh0_ÖC‘+m^›ô¡ŒƒPè4ˆ.ïÓK¢û	
¶�©ûTñnö’þ˜_èŽ°„0¤"?ÖßS‰« Šéqšh_¤�zmoòÍ5ÿ8a @Û‘)Jê¡©[Ü ðÖø.‚»pÁpŸ]ý…þË	&amp;��ôœiÿ:ÝÉˆí\“zLRÚ:áƒ)úõIì+^ØUlíÁ?Ë!˜Cª¦ÎõP�íSÿ´éØkL-Za§ýSÃ#ÅãhŒ
» Äh6øP@ü©É«ÈjŽEªu»ktðÁ^í¾•\DF[¶¾?ü Õµ²Ü£¦Ñ‚5†F¿Øu~È?¦ƒ‘ˆÈLK#�É&nbsp;`×ÿ|-&gt;…°dØ'ú	ûzu&nbsp;ƒÆŸö™Ùª	¤ìSGc…LÈ1L@È%ëëñö×;/ü+õUÞ›«þBjŠXjû´5@û-Ö Çü*ÿÚ°È!µá'ö�A}/ÿŒ û„@ÁØAù7kÉl¿ÎãðÝ`ÁÿÒzÆ&nbsp;¿·Rƒ…ê©ôì `Õ&gt;Ãï×éÚ»YÙpOú[]0¿]I$IµTûh Æž�}~×úÁƒÿJC¾×°¶«õW¯z´w©ƒ§¸?íÿ·™Ûÿ¤´¯ÿ…üV›tÂéø&gt;¿k!¡Ês¹ø­—ê«þ«a…è+¥ßO}ú†�ÓÚßJGµ=ÑÚ¹Ô ÿÕ'ƒð[_‘§ôõ]¨0ŽÅ u�"`šoö›XG`@Ñ©ÖÂ„÷þ¶*š
n¡wÝr9h­‡m#²†¤&gt;9�ñ†º¶©ò+—p¿î—ÈbÓ@¬0–�6ôÝHaÍ@¤‰„ ƒµà™và‰°Tª×a‚ZÚ]¡%ÿ}4É”‚†ËÅ]mâÝHö14ƒƒ•ëÚm
h-­«@‚ÿÒÚ¡í…¦Ýé¯	°`¦Cà®–¼uØªÛ_S³ƒOÿ«T�?(âõ^ƒŠA«ÖÛýyd±Xa(èƒiÿl$¡®Z†má~›�¤Ó
Õo
ða.›JÃÐ@¿á¨VTcÄZ}6“P£î:ŠöÕA„ºû·R!ª±ÚM¯
—Ú�&nbsp;«¦ÒL�®�ÿu-Á94 ØiïßÂ¿ê5Ë%á6¤M«rÏðD3M„¥3(E$[§
Âh¬Û¢ë	p_³°n‰&nbsp;P@×E†ŽÉ$r@áþÕ i¨`Á‚jñ�•0×§ýÄi®›íþšª0@¿Ú!¢:	ê0gp«AØGz":/
á/ï	®˜a'Ð}§@¿Ú	•�&lt;0ÄCV¤Ø�¨ì’@ƒ°GhÛ	þºatÁ‚ïaHjŽG†pªà¿Á‚A‚!L˜PÃaC0d|Ä	ÉÄ&amp;Uîw„°D6EôŠP9tGÈáŽÁtÆÖš‘¹VDØ»‚ÿÂÈŽì0¢"&lt; ï%Wb¬0�wjˆä6AG)ê»%ApÂ„&gt;Âÿ°ƒŒ&amp;wZ
õˆA%°œ(a„	®Dtƒ�€tÁ~=ªM°ÿé§…	�	=Biö¡ƒ…¸Ó‚ �Ë1T5ypS¢ˆá­&lt;ÿD3ŽXí&lt;*·P—Ðwµ†!*¤è*!&amp;N!y²K
w*¼š�?ýtí&lt; VµIÆšu¨`Œ”Áïº	UË0´:uû X2¬&nbsp;™Üx2Wÿ�Š)ÐA}-éßàÐA·W‚ÂÃe˜.½Uß¦v2íNø1ÿ&nbsp;�´ð@¡……H‡�¿¢Â ƒzZ	%¹f
�?ÿ°ñDvoMC ÅOþnAp‚Qet¨�8UO§ü„Þ¡&amp;ÝxJ�Âÿ"!Õ-ª1m…;¯ôžDü˜Ìß!M…i?†ß‚Mº‘T·K„®»ò
E–¥&nbsp;Éó€‡u†þ˜h)±ÐmþHØ«_!]‡ú¦ÐaST/ÿàä
HgˆIâ0cÿIë}¶»ZKøAÁ»Z4Óv
±*vûlnEØ�&nbsp;ŸÿOXzw}kKè;ÚàÈpéˆø@¿ú‡©£´�ŸÿÒÝì:üÑÁµý½´°aöø@¿ñëIèþŸì\kQô²{.·†¸2¨‚¸ žÒû¼­D.K&nbsp;õë{&gt;iWoØ.´BVúÿëU§£²¡ÿü2	nGWµ]ì‡:Á¨AÎÉø¥~×mOAÿ÷ÿ4&gt;Á„—wãÃÂl¬É¸ ^²
{5È`s¹œ¨!ðÎÆ¾ïýwø}¾0»v­9�º{&nbsp;»
Èg‚eoòDÉ×«Zy]ÿ÷ò¥(;O´�7í7aÎÆä½D&amp;ã�Â¶_"ì¿ª“’?ÿÚÞé¬aÚµj
HÊïzWB?[
Öƒï¿ÿÕ„�îŽøoQ$Óx{¯ÿXS»ê×‡ÿøaa�†ÞD #»aT’
¨jåkƒÛ‘)…u¾ÿî÷Ž0ëD
†¤=
Ë«âØ&amp;ëiÒOŽ‡ÿVëÊšº46[
#ì7øvëö¿ÿïÝ&gt;ƒaƒ	_®ÛuÐQÚ2%¿ÛVêšµÝ&lt;„ío~MÆÁay®\Sÿþ¨ui´èToë6˜[&amp;íCÿûVê¡™£áÇ´Ÿ}p`Äq°KÎù¤¿öÕáTEZÈƒªÝµ&nbsp;ÃÔ'z}ÿÃ Ó"Wl+Ó&amp;ÊÂÂÚÁÒOTïýµ“6XK ‘U}¥#®i	áI�!&nbsp;&amp;¡ÿÃ	U*!&amp;]°ƒÎÖb³‘®CÈ´=†6MÒaƒ,Á ˆ=ÁA�ÚˆU‡þÃZÖ°pƒÎÔKk"È,ƒ‹dŠƒ�…vM|*E¨�&lt;*ßü¨0Õ,-²ÜÔÓtõ¶�V=†ša†VuWöp�ÁNÇÈì�•ñª­Êé`‰ÿkR
À¯O¸0Â"6yý°š¯
ýˆ¢-””‰¥ýÂ
6­?¨&gt;šm&lt;0šö"
ï}¸*ÁÿÕçu)1Õm„cÎ&lt;
ì)ÔÆC4¡Âáƒ‡þYvÐTºxU‘GþµAÓÒ^ƒ¹2¢eIá`ÛjÎÆ"&gt;|°Á§¦0@Ÿ&nbsp;ž`�‡þ×ÞØkÜ&amp;ˆaðâ#NCWXk$&nbsp;±r‡kÿ°a&gt;›@šàÃÿjÓ$4ÚqßNBy7™PûƒáXe@7¶ÿL…"¨$²‚dÈ�ƒÿ,&nbsp;Pj&nbsp;J/¦7Þœ,»ÔŠ¢ÉY
N†—‹ßõ&amp;…0UiƒÿØQ©½ÿKwá4èœA‚ßÃþMÂ˜PÂ¬&amp;¤)Ê-‡þ¡…ØA¶[Ÿ#¯T÷nûþƒƒ%±_ÈœÁ»ôÂƒÚaP|!ƒÿL0µMK~zÈR0·Nö¿)ÃHiúwý0§j0oÂ!ž.
MÃÿ
¦M†&lt;7µ@�ºÜÈ jÿk�`Ñý6ÿá$ÃŒýÚ	¯øRÜ–ûð�Ã#&nbsp;” ß¶�Dä]­NÆx;Uíÿáp`Õè$Ù¦Â³@Ÿé×jƒ¸ŠA?éÈÕ„ò!…</b></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf">https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf</a></em></p>]]>
            </description>
            <link>https://www.tpug.ca/tpug-media/tpugmag/TPUG_Issue_01_1984_Feb.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644387</guid>
            <pubDate>Thu, 25 Jun 2020 19:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASGI from scratch – Let's build an ASGI web framework]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23644252">thread link</a>) | @lukastyrychtr
<br/>
June 25, 2020 | https://shenli.dev/2020/06/20/asgi-from-scratch.html | <a href="https://web.archive.org/web/*/https://shenli.dev/2020/06/20/asgi-from-scratch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<p>The first time I used <a href="https://asgi.readthedocs.io/">ASGI</a>(<em>Asynchronous Server Gateway Interface</em>) was through <a href="https://github.com/django/channels">Channels</a> 1.0 when ASGI spec was still a draft. It was my first interview project which helped me get my current job at <a href="https://fellow.app/">Fellow</a>. It felt magical at that time how easy it is to add WebSocket functionality to my Django app and handles authentication and other Django related things for me seamlessly.</p>

<p>ASGI specification is now at version 3 at the time of writing and both ASGI and Channels became part of Django Software Foundation. Compared to the draft version, it has matured a lot with added lifecycle calls and better application format, etc. Most excitingly, a healthy and fast-growing community is forming and we are seeing more and more ASGI servers running in production environments. At my company, we are serving a few million requests per day through ASGI running on <a href="https://github.com/django/daphne">Daphne</a>, Netflix’s <a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">Dispatch</a> is based on <a href="https://fastapi.tiangolo.com/">FastAPI</a>, a popular ASGI web application framework, and apparently, Microsoft is <a href="https://github.com/tiangolo/fastapi/pull/26">using it</a> too.</p>

<p>I would humbly advise anyone building web services in Python to learn about ASGI. And the best way to learn something is to built things with it, so in this blog post, I’ll walk through the steps to build a micro web application framework that speaks ASGI. I hope it can help explain how ASGI works.</p>


<p>Before writing the first line of code, we need to have a basic understanding of what ASGI is and what we are building towards.</p>
<h2 id="how-asgi-works">How ASGI works</h2>
<p>Here’s a simple diagram showing how ASGI works at a high level.</p>
<pre><code>graph TD
	A[Client] --&gt;|HTTP, WebSocket, ...| B(ASGI Server)
	B --&gt; |scope, send, receive| C(ASGI application)
</code></pre>
<p>To put it in simple words, A browser(client), establishes a connection to ASGI server with a certain type of request (HTTP or WebSocket), the ASGI server then calls ASGI  application with information about the connection, encapsulated in a python dictionary called <code>scope</code>, and two callbacks, named <code>send</code> and <code>receive</code>, that the application can use to send and receive messages between server and client.</p>

<p>Here’s an example HTTP request scope</p>
<div><div><pre><code><span>{</span>
    <span>"type"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"http_version"</span><span>:</span> <span>"1.1"</span><span>,</span>
    <span>"server"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>8000</span><span>),</span>
    <span>"client"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>60457</span><span>),</span>
    <span>"scheme"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"method"</span><span>:</span> <span>"GET"</span><span>,</span>
    <span>"root_path"</span><span>:</span> <span>""</span><span>,</span>
    <span>"path"</span><span>:</span> <span>"/hello/a"</span><span>,</span>
    <span>"raw_path"</span><span>:</span> <span>b"/hello/a"</span><span>,</span>
    <span>"query_string"</span><span>:</span> <span>b""</span><span>,</span>
    <span>"headers"</span><span>:</span> <span>[</span>
        <span>(</span><span>b"host"</span><span>,</span> <span>b"localhost:8000"</span><span>),</span>
        <span>(</span><span>b"connection"</span><span>,</span> <span>b"keep-alive"</span><span>),</span>
        <span>(</span>
            <span>b"user-agent"</span><span>,</span>
            <span>b"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36"</span><span>,</span>
        <span>),</span>
        <span>(</span>
            <span>b"accept"</span><span>,</span>
            <span>b"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span><span>,</span>
        <span>),</span>
        <span>(</span><span>b"accept-encoding"</span><span>,</span> <span>b"gzip, deflate, br"</span><span>),</span>
        <span>(</span><span>b"accept-language"</span><span>,</span> <span>b"en-US,en;q=0.9"</span><span>),</span>
        <span>(</span>
            <span>b"cookie"</span><span>,</span>
            <span>b'csrftoken=dDA2IAPrvgPc7hkyBSyctxDk78KmhHAzUqR0LUpjXI3Xgki0QrGEWazE3RGZuLGl'</span><span>,</span>
        <span>),</span>
    <span>],</span>
<span>}</span>
</code></pre></div></div>

<p>You might notice that <code>scope</code> is not too different from a WSGI <code>environ</code>. In fact, ASGI interface is very similar to WSGI interface, but instead of getting a <code>environ</code> and <code>start_response</code> to send headers and using the return value of WSGI application as the response body, ASGI interfaces with the connection and allows us to receive and send messages multiple times during the lifecycle of the connection <strong>asynchronously</strong> until the connection is closed.  This allows a nice interface for both WebSocket and HTTP.</p>

<p>It’s also totally possible to wrap a WSGI application inside an ASGI application, just prepare a WSGI <code>environ</code> and <code>start_response</code> based on <code>scope</code>, <code>receive</code>, and <code>send</code> then call the WSGI application and it would work. If you delegate that call into a thread pool or something similar, you just made your WSGI application asynchronous. This is roughly how Channels wraps around Django.</p>

<h2 id="define-asgi-framework">Define ASGI framework</h2>
<p>When I say ASGI framework I refer it as a framework that makes building ASGI application easier and this does not include the ASGI server part. I’m mentioning this because some of the earlier Python asynchronous web frameworks have their own server implementation that also takes over tasks such as parsing  HTTP requests, handles network connections, etc. We are not doing those in ASGI web framework. As a spiritual successor to WSGI, where web servers, such as Gunicorn and uwsgi, and web frameworks, such as Flask and Django, are separated, ASGI has this separation too.</p>

<p>So, what does an ASGI application look like?</p>

<h3 id="asgi-hello-world">ASGI Hello World</h3>
<p>A simple ASGI hello world application can be written as:</p>
<div><div><pre><code><span>async</span> <span>def</span> <span>application</span><span>(</span><span>scope</span><span>,</span> <span>receive</span><span>,</span> <span>send</span><span>):</span>
    <span>name</span> <span>=</span> <span>scope</span><span>[</span><span>"path"</span><span>].</span><span>split</span><span>(</span><span>"/"</span><span>,</span> <span>1</span><span>)[</span><span>-</span><span>1</span><span>]</span> <span>or</span> <span>"world"</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.start"</span><span>,</span>
            <span>"status"</span><span>:</span> <span>200</span><span>,</span>
            <span>"headers"</span><span>:</span> <span>[[</span><span>b"content-type"</span><span>,</span> <span>b"text/plain"</span><span>],],</span>
        <span>}</span>
    <span>)</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.body"</span><span>,</span>
            <span>"body"</span><span>:</span> <span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>!"</span><span>.</span><span>encode</span><span>(),</span>
            <span>"more_body"</span><span>:</span> <span>False</span><span>,</span>
        <span>}</span>
    <span>)</span>
</code></pre></div></div>
<p><code>http.response.start</code> starts an HTTP response sending status code and response headers. In this example, it responds with the 200 OK status code and  has <code>content-type</code> set to <code>text/plain</code> in the headers.  <code>http.response.body</code> sends the response body, the <code>more_body</code> key tells the server if the response is finished. ASGI server might use this to know if a connection should be closed or automatically decide between a <code>content-length</code> header or a chunked encoding.</p>

<p>We can run the application with <a href="https://www.uvicorn.org/">uvicorn</a>:</p>
<div><div><pre><code>uvicorn asgi-hello:application
</code></pre></div></div>
<p>And you should be able to visit <code>http://localhost:8000/</code> and get <code>Hello, world</code>.Visiting <code>http://localhost:8000/tom</code> would get you <code>Hello, tom</code>.</p>

<blockquote>
  <p>By the way, uvicorn is pretty fast, a simple benchmark with <code>wrk -d10s http://localhost:8000/hi</code> on a 2018 lowest spec MacBook Air yields <code>Requests/sec:  27857.87</code>.</p>
</blockquote>

<p>Although this approach works with a simple hello world example, it’s not exactly convenient to write a more complex application this way. For one, it doesn’t do routing, if you want to respond differently for different paths, you’ll probably end up with a huge  <code>if ... else if ... else</code> clause. Secondly, having to write the ASGI message every time in the form of a python dict is quite arduous. Third, in a complex application, it gets harder to track the status of the connection, such as is the response started, is the response ended, should I start the response here, etc.</p>

<h3 id="goal">Goal</h3>
<p>With the new framework, I hope to be able to write an ASGI application like this:</p>
<div><div><pre><code><span>import</span> <span>asyncio</span>
<span>from</span> <span>aaf</span> <span>import</span> <span>aaf</span> <span># Another ASGI framework
</span><span>from</span> <span>aaf.routing</span> <span>import</span> <span>Router</span>
<span>from</span> <span>aaf.response</span> <span>import</span> <span>HttpResponse</span>

<span>router</span> <span>=</span> <span>Router</span><span>()</span>

<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/&lt;name&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>hello</span><span>(</span><span>connection</span><span>,</span> <span>name</span><span>=</span><span>'world'</span><span>):</span>
	<span>return</span> <span>HttpResponse</span><span>(</span><span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>"</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count/&lt;int:number&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>count</span><span>(</span><span>connection</span><span>,</span> <span>number</span><span>=</span><span>10</span><span>):</span>
	<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>number</span><span>):</span>
		<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>f'count </span><span>{</span><span>i</span><span>}</span><span>\n</span><span>'</span><span>,</span> <span>finish</span><span>=</span><span>False</span><span>)</span>
		<span>await</span> <span>asyncio</span><span>.</span><span>sleep</span><span>(</span><span>1</span><span>)</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>''</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/echo'</span><span>)</span>
<span>async</span> <span>def</span> <span>echo</span><span>(</span><span>connection</span><span>):</span>
	<span>body</span> <span>=</span> <span>await</span> <span>connection</span><span>.</span><span>body</span><span>()</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>body</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>app</span> <span>=</span> <span>aaf</span><span>([</span><span>router</span><span>])</span>
</code></pre></div></div>
<p>I hope this snippet of how I want the framework to look like is self-explanatory. But here are some of the key things I want to achieve:</p>
<ol>
  <li>It should be able to handle HTTP response declaratively and imperatively.</li>
  <li>It should support Flask style routing with parameter parsing.</li>
</ol>


<h2 id="connection-class">Connection class</h2>
<p>The <code>Connection</code> class will represent an ASGI HTTP or WebSocket connection. It’s a class that encapsulates the three basic elements in ASGI, namely <code>scope</code>, <code>send</code> and <code>receive</code>, and expose some convenient methods and properties so that users don’t need to verbosely write out all the ASGI messages and parse everything, such as cookies and headers, from <code>scope</code>. But it should allow users to access the original <code>scope</code>, <code>send</code> and <code>receive</code> when they want to, so that the composability of ASGI applications is maintained. For example, it should allow user to delegate certain <code>connection</code>s to another ASGI application by calling <code>another_asgi_app(connection.scope, connectionn.asgi_send, connection.asgi_receive)</code>.</p>

<p>Here’s a simple implementation of the <code>Connection</code> class.</p>
<div><div><pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span>
<span>from</span> <span>functools</span> <span>import</span> <span>cached_property</span>
<span>from</span> <span>http.cookies</span> <span>import</span> <span>SimpleCookie</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Any</span><span>,</span> <span>Awaitable</span><span>,</span> <span>Callable</span><span>,</span> <span>Optional</span><span>,</span> <span>Union</span>
<span>from</span> <span>urllib.parse</span> <span>import</span> <span>parse_qsl</span><span>,</span> <span>unquote_plus</span>

<span>from</span> <span>werkzeug.datastructures</span> <span>import</span> <span>Headers</span><span>,</span> <span>MultiDict</span>

<span>CoroutineFunction</span> <span>=</span> <span>Callable</span><span>[[</span><span>Any</span><span>],</span> <span>Awaitable</span><span>]</span>


<span>class</span> <span>ConnectionType</span><span>(</span><span>Enum</span><span>):</span>
    <span>HTTP</span> <span>=</span> <span>"HTTP"</span>
    <span>WebSocket</span> <span>=</span> <span>"WebSocket"</span>


<span>class</span> <span>Connection</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span> <span>scope</span><span>:</span> <span>dict</span><span>,</span> <span>*</span><span>,</span> <span>send</span><span>:</span> <span>CoroutineFunction</span><span>,</span> <span>receive</span><span>:</span> <span>CoroutineFunction</span>
    <span>):</span>
        <span>self</span><span>.</span><span>scope</span> <span>=</span> <span>scope</span>
        <span>self</span><span>.</span><span>asgi_send</span> <span>=</span> <span>send</span>
        <span>self</span><span>.</span><span>asgi_receive</span> <span>=</span> <span>receive</span>

        <span>self</span><span>.</span><span>started</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>finished</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>resp_headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>self</span><span>.</span><span>resp_cookies</span><span>:</span> <span>SimpleCookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>self</span><span>.</span><span>resp_status_code</span><span>:</span> <span>Optional</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>None</span>

        <span>self</span><span>.</span><span>http_body</span> <span>=</span> <span>b""</span>
        <span>self</span><span>.</span><span>http_has_more_body</span> <span>=</span> <span>True</span>
        <span>self</span><span>.</span><span>http_received_body_length</span> <span>=</span> <span>0</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_headers</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Headers</span><span>:</span>
        <span>headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>for</span> <span>(</span><span>k</span><span>,</span> <span>v</span><span>)</span> <span>in</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"headers"</span><span>]:</span>
            <span>headers</span><span>.</span><span>add</span><span>(</span><span>k</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>),</span> <span>v</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>))</span>
        <span>return</span> <span>headers</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_cookies</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>SimpleCookie</span><span>:</span>
        <span>cookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>cookie</span><span>.</span><span>load</span><span>(</span><span>self</span><span>.</span><span>req_headers</span><span>.</span><span>get</span><span>(</span><span>"cookie"</span><span>,</span> <span>{}))</span>
        <span>return</span> <span>cookie</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>type</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>ConnectionType</span><span>:</span>
        <span>return</span> <span>(</span>
            <span>ConnectionType</span><span>.</span><span>WebSocket</span>
            <span>if</span> <span>self</span><span>.</span><span>scope</span><span>.</span><span>get</span><span>(</span><span>"type"</span><span>)</span> <span>==</span> <span>"websocket"</span>
            <span>else</span> <span>ConnectionType</span><span>.</span><span>HTTP</span>
        <span>)</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>method</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"method"</span><span>]</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>path</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>sc…</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shenli.dev/2020/06/20/asgi-from-scratch.html">https://shenli.dev/2020/06/20/asgi-from-scratch.html</a></em></p>]]>
            </description>
            <link>https://shenli.dev/2020/06/20/asgi-from-scratch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644252</guid>
            <pubDate>Thu, 25 Jun 2020 19:04:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testers vs. TDD]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23644228">thread link</a>) | @ohjeez
<br/>
June 25, 2020 | https://www.functionize.com/blog/testers-vs-tdd | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/testers-vs-tdd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/TDD-vs-Testers2.jpg" alt="Testers vs TDD" srcset="https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>Test-driven development was supposed to eliminate the need for independent testing. Alas, it doesn’t go far enough.</p></blockquote>
<p>Test-driven development (TDD) earned a reputation of making software more robust. Does that mean you can fire all the testers? Spoiler: No.</p>
<p><a href="https://martinfowler.com/bliki/TestDrivenDevelopment.html" target="blank" rel="noopener noreferrer">Test-driven development</a> is a method for writing software in small chunks. You start with a test, then write functional code to make the test pass, and finally refactor the functional code to clean it up. The idea of TDD was proposed by <a href="https://amzn.to/3doabIA" target="blank" rel="noopener noreferrer">Kent Beck</a> in the early 1990s, as part of Extreme Programming, an Agile software development methodology.</p>
<p>TDD is sometimes summarized as “Red, Green, Refactor.” The interfaces on many testing harnesses, such as JUnit (for Java) and NUnit (for .NET), show red lights when tests fail and green lights when tests pass. There’s another step to consider, however. You need to think about the desired behavior and carve out a small chunk of code – typically five lines – to implement next.</p>
<p>As proposed by Beck, in TDD you never write functional code until you have a failing test. Yet, it takes practice to learn to write the tests first (rather than after the fact); developers often have trouble shifting their habitual way of working. Writing the tests before the functional code just feels <em>wrong.</em> You do get used to it, though it may take months; by then it starts feeling <em>right</em>.</p>
<p>The <a href="https://www.functionize.com/blog/what-is-test-driven-development-tdd/">biggest benefit of TDD</a> is that it removes the fear of breaking your code. As you add unit tests and functional code, you also build <a href="https://www.functionize.com/blog/dont-fail-your-next-interview-know-what-differentiates-regression-testing-from-retesting/">a library of regression tests</a> that you run frequently. When you add a new feature, fix a bug, or refactor to clean up your code, running the tests again reassures you that you didn’t break anything. Or at least it confirms that you didn’t break any of the tests that <em>you</em> wrote.</p>
<h3>What do testers bring to the table?</h3>
<p>Software managers are sometimes tempted to eliminate or reduce software QA departments when the coders adopt TDD, on the grounds that the programmers are also writing tests. That decision usually is a mistake, because <a href="https://www.functionize.com/blog/five-must-have-skills-to-look-for-in-a-qa-tester/">testers provide value</a> outside of the developers’ unit tests.</p>
<p>Unit tests are only one of the kinds of tests needed to adequately cover modern code. TDD developers rarely write end-to-end integration tests. They may avoid writing unit tests that require significant setup or that rely on other software components, such as a populated database.</p>
<p>Dedicated testers are more likely than coders to take the time to perform exploratory (ad-hoc) testing, which can find bugs that weren’t imagined during the development of the code. Testers also come to the product with fresh eyes compared to the coders who have been immersed in the software for long hours.</p>
<p>Additionally, software developers often are not interested in setting up CI/CD tooling or in organizing the team’s tests into a master regression test. Testers consider all of that to be part of the job. Developers may not be involved in implementing shift left testing beyond TDD. &nbsp;For shift left testing, testers can gather information, help with requirements management, and help to define the acceptance criteria, before a single test or line of functional code is complete.</p>
<h3>What bugs do testers find that TDD doesn’t?</h3>
<p>Security is one large, important testing area that isn’t normally addressed by writing unit tests. Testers look for security flaws with automated vulnerability testing tools, manual security assessments, penetration tests, security audits, and security reviews.</p>
<p>It’s difficult for developers to write <a href="https://www.functionize.com/blog/the-challenges-of-testing-guis/">unit tests to test GUIs</a>. Instead, testers use automation tools specific to the supported application environments, such as browsers, desktop applications, and mobile apps.</p>
<p>Developers can have a hard time with hardware-dependent bugs, as the dominant way of working is for a coder to work on a single machine. QA departments often collect rooms full of varied computers and devices, as well as images of many operating system versions. An alternative way of testing on many different model devices is to use a crowd-sourced testing service.</p>
<p>While TDD can theoretically catch bugs in edge cases, they are called “edge cases” for a good reason. When a coder designs the tests for a function point, obscure edge cases may escape notice in the heat of the moment. Testers are more likely to find these than are the coders who wrote the software.</p>
<p>Similarly, cross-module flaws can sometimes escape scrutiny in unit tests. They can easily arise when one programmer misunderstands the interface or boundary conditions of another programmer’s module. Cross-module bugs are often found during end-to-end testing and ad-hoc testing.</p>
<p>In summary, while there’s a lot to be said for TDD as a development practice, it doesn’t usually provide complete test coverage of your code. For that, you still need testers.</p>
<blockquote><p>Whoever writes the test cases, it makes sense to follow established guidelines. <a href="https://www.functionize.com/project/best-practices-for-effective-test-case-writing/">These</a> might help.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/author-Martin-Heller.jpg" alt="Martin Heller"></p>
<div>
<p><span>by</span> Martin Heller</p>
<p>Martin Heller is a freelance writer. Formerly a web and Windows programming consultant, he developed databases, software, and websites from 1986 to 2010. More recently, he has served as VP of technology and education at Alpha Software and chairman and CEO at Tubifi.</p>
</div>

</div>
</div>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/testers-vs-tdd</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644228</guid>
            <pubDate>Thu, 25 Jun 2020 19:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Linux Debugger Part 1: Setup (2017)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23643865">thread link</a>) | @memexy
<br/>
June 25, 2020 | https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/ | <a href="https://web.archive.org/web/*/https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span itemprop="articleBody"><p>Anyone who has written more than a hello world program should have used a debugger at some point (if you haven’t, drop what you’re doing and learn how to use one). However, although these tools are in such widespread use, there aren’t a lot of resources which tell you how they work and how to write one<sup id="fnref:1"><a href="#fn:1">1</a></sup>, especially when compared to other toolchain technologies like compilers. In this post series we’ll learn what makes debuggers tick and write one for debugging Linux programs.</p>
<p>We’ll support the following features:</p>
<ul>
<li>Launch, halt, and continue execution</li>
<li>Set breakpoints on
<ul>
<li>Memory addresses</li>
<li>Source code lines</li>
<li>Function entry</li>
</ul>
</li>
<li>Read and write registers and memory</li>
<li>Single stepping
<ul>
<li>Instruction</li>
<li>Step in</li>
<li>Step out</li>
<li>Step over</li>
</ul>
</li>
<li>Print current source location</li>
<li>Print backtrace</li>
<li>Print values of simple variables</li>
</ul>
<p>In the final part I’ll also outline how you could add the following to your debugger:</p>
<ul>
<li>Remote debugging</li>
<li>Shared library and dynamic loading support</li>
<li>Expression evaluation</li>
<li>Multi-threaded debugging support</li>
</ul>
<p>I’ll be focusing on C and C++ for this project, but it should work just as well with any language which compiles down to machine code and outputs standard DWARF debug information (if you don’t know what that is yet, don’t worry, this will be covered soon). Additionally, my focus will be on just getting something up and running which works most of the time, so things like robust error handling will be eschewed in favour of simplicity.</p>
<hr>
<h3 id="series-index">Series index</h3>
<ol>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/">Setup</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-breakpoints/">Breakpoints</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-registers/">Registers and memory</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-elf-dwarf/">Elves and dwarves</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-source-signal/">Source and signals</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-dwarf-step/">Source-level stepping</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-source-break/">Source-level breakpoints</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-unwinding/">Stack unwinding</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-variables/">Handling variables</a></li>
<li><a href="https://blog.tartanllama.xyz/writing-a-linux-debugger-advanced-topics/">Advanced topics</a></li>
</ol>
<hr>
<h3 id="getting-set-up">Getting set up</h3>
<p>Before we jump into things, let’s get our environment set up. I’ll be using two dependencies in this tutorial: <a href="https://github.com/antirez/linenoise">Linenoise</a> for handling our command line input, and <a href="https://github.com/TartanLlama/libelfin/tree/fbreg">libelfin</a> for parsing the debug information. You could use the more traditional libdwarf instead of libelfin, but the interface is nowhere near as nice, and libelfin also provides a mostly complete DWARF expression evaluator, which will save you a lot of time if you want to read variables. Make sure that you use the fbreg branch of my fork of libelfin, as it hacks on some extra support for reading variables on x86.</p>
<p>Once you’ve either installed these on your system, or got them building as dependencies with whatever build system you prefer, it’s time to get started. I just set them to build along with the rest of my code in my CMake files.</p>
<hr>
<h3 id="launching-the-executable">Launching the executable</h3>
<p>Before we actually debug anything, we’ll need to launch the debugee program. We’ll do this with the classic fork/exec pattern.</p>
<figure><pre><code data-lang="cpp"><span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span> <span>{</span>
    <span>if</span> <span>(</span><span>argc</span> <span>&lt;</span> <span>2</span><span>)</span> <span>{</span>
        <span>std</span><span>::</span><span>cerr</span> <span>&lt;&lt;</span> <span>"Program name not specified"</span><span>;</span>
        <span>return</span> <span>-</span><span>1</span><span>;</span>
    <span>}</span>

    <span>auto</span> <span>prog</span> <span>=</span> <span>argv</span><span>[</span><span>1</span><span>];</span>

    <span>auto</span> <span>pid</span> <span>=</span> <span>fork</span><span>();</span>
    <span>if</span> <span>(</span><span>pid</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>//we're in the child process
</span>        <span>//execute debugee
</span>
    <span>}</span>
    <span>else</span> <span>if</span> <span>(</span><span>pid</span> <span>&gt;=</span> <span>1</span><span>)</span>  <span>{</span>
        <span>//we're in the parent process
</span>        <span>//execute debugger
</span>    <span>}</span></code></pre></figure>
<p>We call <code>fork</code> and this causes our program to split into two processes. If we are in the child process, <code>fork</code> returns <code>0</code>, and if we are in the parent process, it returns the process ID of the child process.</p>
<p>If we’re in the child process, we want to replace whatever we’re currently executing with the program we want to debug.</p>
<figure><pre><code data-lang="cpp">   <span>ptrace</span><span>(</span><span>PTRACE_TRACEME</span><span>,</span> <span>0</span><span>,</span> <span>nullptr</span><span>,</span> <span>nullptr</span><span>);</span>
   <span>execl</span><span>(</span><span>prog</span><span>,</span> <span>prog</span><span>,</span> <span>nullptr</span><span>);</span></code></pre></figure>
<p>Here we have our first encounter with <code>ptrace</code>, which is going to become our best friend when writing our debugger. <code>ptrace</code> allows us to observe and control the execution of another process by reading registers, reading memory, single stepping and more. The API is very ugly; it’s a single function which you provide with an enumerator value for what you want to do, and then some arguments which will either be used or ignored depending on which value you supply. The signature looks like this:</p>
<figure><pre><code data-lang="cpp"><span>long</span> <span>ptrace</span><span>(</span><span>enum</span> <span>__ptrace_request</span> <span>request</span><span>,</span> <span>pid_t</span> <span>pid</span><span>,</span>
            <span>void</span> <span>*</span><span>addr</span><span>,</span> <span>void</span> <span>*</span><span>data</span><span>);</span></code></pre></figure>
<p><code>request</code> is what we would like to do to the traced process; <code>pid</code> is the process ID of the traced process; <code>addr</code> is a memory address, which is used in some calls to designate an address in the tracee; and <code>data</code> is some request-specific resource. The return value often gives error information, so you probably want to check that in your real code; I’m just omitting it for brevity. You can have a look at the man pages for more information.</p>
<p>The request we send in the above code, <code>PTRACE_TRACEME</code>, indicates that this process should allow its parent to trace it. All of the other arguments are ignored, because API design isn’t important /s.</p>
<p>Next, we call <code>execl</code>, which is one of the many <code>exec</code> flavours. We execute the given program, passing the name of it as a command-line argument and a <code>nullptr</code> to terminate the list. You can pass any other arguments needed to execute your program here if you like.</p>
<p>After we’ve done this, we’re finished with the child process; we’ll just let it keep running until we’re finished with it.</p>
<hr>
<h3 id="adding-our-debugger-loop">Adding our debugger loop</h3>
<p>Now that we’ve launched the child process, we want to be able to interact with it. For this, we’ll create a <code>debugger</code> class, give it a loop for listening to user input, and launch that from our parent fork of our <code>main</code> function.</p>
<figure><pre><code data-lang="cpp"><span>else</span> <span>if</span> <span>(</span><span>pid</span> <span>&gt;=</span> <span>1</span><span>)</span>  <span>{</span>
    <span>//parent
</span>    <span>debugger</span> <span>dbg</span><span>{</span><span>prog</span><span>,</span> <span>pid</span><span>};</span>
    <span>dbg</span><span>.</span><span>run</span><span>();</span>
<span>}</span></code></pre></figure>
<figure><pre><code data-lang="cpp"><span>class</span> <span>debugger</span> <span>{</span>
<span>public</span><span>:</span>
    <span>debugger</span> <span>(</span><span>std</span><span>::</span><span>string</span> <span>prog_name</span><span>,</span> <span>pid_t</span> <span>pid</span><span>)</span>
        <span>:</span> <span>m_prog_name</span><span>{</span><span>std</span><span>::</span><span>move</span><span>(</span><span>prog_name</span><span>)},</span> <span>m_pid</span><span>{</span><span>pid</span><span>}</span> <span>{}</span>

    <span>void</span> <span>run</span><span>();</span>

<span>private</span><span>:</span>
    <span>std</span><span>::</span><span>string</span> <span>m_prog_name</span><span>;</span>
    <span>pid_t</span> <span>m_pid</span><span>;</span>
<span>};</span></code></pre></figure>
<p>In our <code>run</code> function, we need to wait until the child process has finished launching, then just keep on getting input from linenoise until we get an EOF (ctrl+d).</p>
<figure><pre><code data-lang="cpp"><span>void</span> <span>debugger</span><span>::</span><span>run</span><span>()</span> <span>{</span>
    <span>int</span> <span>wait_status</span><span>;</span>
    <span>auto</span> <span>options</span> <span>=</span> <span>0</span><span>;</span>
    <span>waitpid</span><span>(</span><span>m_pid</span><span>,</span> <span>&amp;</span><span>wait_status</span><span>,</span> <span>options</span><span>);</span>

    <span>char</span><span>*</span> <span>line</span> <span>=</span> <span>nullptr</span><span>;</span>
    <span>while</span><span>((</span><span>line</span> <span>=</span> <span>linenoise</span><span>(</span><span>"minidbg&gt; "</span><span>))</span> <span>!=</span> <span>nullptr</span><span>)</span> <span>{</span>
        <span>handle_command</span><span>(</span><span>line</span><span>);</span>
        <span>linenoiseHistoryAdd</span><span>(</span><span>line</span><span>);</span>
        <span>linenoiseFree</span><span>(</span><span>line</span><span>);</span>
    <span>}</span>
<span>}</span></code></pre></figure>
<p>When the traced process is launched, it will be sent a <code>SIGTRAP</code> signal, which is a trace or breakpoint trap. We can wait until this signal is sent using the <code>waitpid</code> function.</p>
<p>After we know the process is ready to be debugged, we listen for user input. The <code>linenoise</code> function takes a prompt to display and handles user input by itself. This means we get a nice command line with history and navigation commands without doing much work at all. When we get the input, we give the command to a <code>handle_command</code> function which we’ll write shortly, then we add this command to the linenoise history and free the resource.</p>
<hr>
<h3 id="handling-input">Handling input</h3>
<p>Our commands will follow a similar format to gdb and lldb. To continue the program, a user will type <code>continue</code> or <code>cont</code> or even just <code>c</code>. If they want to set a breakpoint on an address, they’ll write <code>break 0xDEADBEEF</code>, where <code>0xDEADBEEF</code> is the desired address in hexadecimal format. Let’s add support for these commands.</p>
<figure><pre><code data-lang="cpp"><span>void</span> <span>debugger</span><span>::</span><span>handle_command</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>line</span><span>)</span> <span>{</span>
    <span>auto</span> <span>args</span> <span>=</span> <span>split</span><span>(</span><span>line</span><span>,</span><span>' '</span><span>);</span>
    <span>auto</span> <span>command</span> <span>=</span> <span>args</span><span>[</span><span>0</span><span>];</span>

    <span>if</span> <span>(</span><span>is_prefix</span><span>(</span><span>command</span><span>,</span> <span>"continue"</span><span>))</span> <span>{</span>
        <span>continue_execution</span><span>();</span>
    <span>}</span>
    <span>else</span> <span>{</span>
        <span>std</span><span>::</span><span>cerr</span> <span>&lt;&lt;</span> <span>"Unknown command</span><span>\n</span><span>"</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre></figure>
<p><code>split</code> and <code>is_prefix</code> are a couple of small helper functions:</p>
<figure><pre><code data-lang="cpp"><span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>std</span><span>::</span><span>string</span><span>&gt;</span> <span>split</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span> <span>&amp;</span><span>s</span><span>,</span> <span>char</span> <span>delimiter</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>std</span><span>::</span><span>string</span><span>&gt;</span> <span>out</span><span>{};</span>
    <span>std</span><span>::</span><span>stringstream</span> <span>ss</span> <span>{</span><span>s</span><span>};</span>
    <span>std</span><span>::</span><span>string</span> <span>item</span><span>;</span>

    <span>while</span> <span>(</span><span>std</span><span>::</span><span>getline</span><span>(</span><span>ss</span><span>,</span><span>item</span><span>,</span><span>delimiter</span><span>))</span> <span>{</span>
        <span>out</span><span>.</span><span>push_back</span><span>(</span><span>item</span><span>);</span>
    <span>}</span>

    <span>return</span> <span>out</span><span>;</span>
<span>}</span>

<span>bool</span> <span>is_prefix</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>s</span><span>,</span> <span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>of</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>s</span><span>.</span><span>size</span><span>()</span> <span>&gt;</span> <span>of</span><span>.</span><span>size</span><span>())</span> <span>return</span> <span>false</span><span>;</span>
    <span>return</span> <span>std</span><span>::</span><span>equal</span><span>(</span><span>s</span><span>.</span><span>begin</span><span>(),</span> <span>s</span><span>.</span><span>end</span><span>(),</span> <span>of</span><span>.</span><span>begin</span><span>());</span>
<span>}</span></code></pre></figure>
<p>We’ll add <code>continue_execution</code> to the <code>debugger</code> class.</p>
<figure><pre><code data-lang="cpp"><span>void</span> <span>debugger</span><span>::</span><span>continue_execution</span><span>()</span> <span>{</span>
    <span>ptrace</span><span>(</span><span>PTRACE_CONT</span><span>,</span> <span>m_pid</span><span>,</span> <span>nullptr</span><span>,</span> <span>nullptr</span><span>);</span>

    <span>int</span> <span>wait_status</span><span>;</span>
    <span>auto</span> <span>options</span> <span>=</span> <span>0</span><span>;</span>
    <span>waitpid</span><span>(</span><span>m_pid</span><span>,</span> <span>&amp;</span><span>wait_status</span><span>,</span> <span>options</span><span>);</span>
<span>}</span></code></pre></figure>
<p>For now our <code>continue_execution</code> function will just use <code>ptrace</code> to tell the process to continue, then <code>waitpid</code> until it’s signalled.</p>
<hr>
<h3 id="finishing-up">Finishing up</h3>
<p>Now you should be able to compile some C or C++ program, run it through your debugger, see it halting on entry, and be able to continue execution from your debugger. In the next part we’ll learn how to get our debugger to set breakpoints. If you come across any issues, please let me know in the comments!</p>
<p>You can find the code for this post <a href="https://github.com/TartanLlama/minidbg/tree/tut_setup">here</a>.</p>
<hr>

</span></p><p><small>
<i></i>
c++
</small>
</p>
</div><p>
I <i></i> feedback.<br>
Let me know what you think of this article on twitter <a href="https://www.twitter.com/TartanLlama">@TartanLlama</a> or leave a comment below!
</p></div>]]>
            </description>
            <link>https://blog.tartanllama.xyz/writing-a-linux-debugger-setup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643865</guid>
            <pubDate>Thu, 25 Jun 2020 18:28:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cluster Analysis]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23643701">thread link</a>) | @tractific
<br/>
June 25, 2020 | https://tractific.com/blog/cluster-analysis-types | <a href="https://web.archive.org/web/*/https://tractific.com/blog/cluster-analysis-types">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Join early Tractific users getting product updates, blog posts, and free access to beta.</p><div><div><p>×</p><h2>Join early Tractific users getting product updates, blog posts, and free access to beta.</h2><ul><li>Early and free access</li><li>SaaS growth tips</li><li>4 minute read</li></ul></div></div></div>]]>
            </description>
            <link>https://tractific.com/blog/cluster-analysis-types</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643701</guid>
            <pubDate>Thu, 25 Jun 2020 18:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GitHub Action for Salus, an open source app security scanner]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23643379">thread link</a>) | @jsulinski
<br/>
June 25, 2020 | https://www.federacy.com/blog/salus-github-action/ | <a href="https://web.archive.org/web/*/https://www.federacy.com/blog/salus-github-action/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.federacy.com/blog/salus-github-action/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643379</guid>
            <pubDate>Thu, 25 Jun 2020 17:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I made $10K in bug bounties from GitHub secret leaks]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23643373">thread link</a>) | @symbolicretail
<br/>
June 25, 2020 | https://tillsongalloway.com/finding-sensitive-information-on-github/ | <a href="https://web.archive.org/web/*/https://tillsongalloway.com/finding-sensitive-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
            </figure>

            <section>
                <div>
                    <p>API keys, passwords, and customer data are accidentally posted to GitHub every day. </p><p>Hackers use these keys to login to servers, steal personal information, and rack up absurd AWS charges. GitHub leaks can cost a company thousands–or even millions–of dollars in damages. Open-source intelligence gathering on GitHub has become a powerful arrow in every security researcher's quiver: researchers from NC State even wrote an <a href="https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_04B-3_Meli_paper.pdf">academic paper</a> on the subject. </p><p>This article, written for both bug bounty hunters and enterprise infosec teams, demonstrates common types of sensitive information (secrets) that users post to public GitHub repositories as well as heuristics for finding them. The techniques in this article can be applied to <a href="https://gist.github.com/">GitHub Gist</a> snippets, too.</p><p>In the last year, I've earned nearly $10,000 from bug bounty programs on <a href="https://hackerone.com/">HackerOne</a> without even visiting programs' websites thanks to these techniques. I've submitted over 30 Coordinated Disclosure reports to vulnerable corporations, including eight Fortune 500 companies. </p><p><strong>I've also released <a href="https://github.com/tillson/git-hound">GitHound</a>, an open-source tool designed to automate the process of finding keys across GitHub.</strong> GitHound isn't limited to a single user or organization: it sifts through all of GitHub, using Code Search queries as an entrypoint into repositories and then using context, regexes, and some other neat tricks to find secrets.</p><h2 id="github-code-search">GitHub Code Search</h2><p>Before we get into the automated tools and bug bounty strategies, let's talk about Code Search. </p><p>GitHub provides <a href="https://github.com/search">rich code searching</a> that scans public GitHub repositories (some content is omitted, <a href="https://help.github.com/en/github/searching-for-information-on-github/searching-code#considerations-for-code-search">like forks and non-default branches</a>). Queries can be simple like <code>uberinternal.com</code> or can contain multi-word strings like &nbsp;<code>"Authorization: Bearer"</code>. Searches can even target specific files (<code>filename: vim_settings.xml</code>) or specific languages (<code>language:SQL</code>). Searches can also contain certain <a href="https://help.github.com/en/github/searching-for-information-on-github/understanding-the-search-syntax">boolean qualifiers</a> like <code>NOT</code> and <code>&gt;</code>. </p><p>Knowing the rules of GitHub code search enables us to craft search dorks: queries that are designed to find sensitive information. GitHub dorks can be found online, but the best dorks are the ones that you create yourself.</p><p>For example, <code>filename: vim_settings.xml</code> (<a href="https://github.com/search?q=filename%3Avim_settings.xml&amp;type=Code">try it!</a>) targets <a href="https://www.jetbrains.com/help/idea/settings-tools-settings-repository.html">IntelliJ settings files</a><a>.</a> Interestingly, the <code>vim_settings.xml</code> file contains recent <strong>copy-pasted strings encoded in Base64</strong>. I recently made $2400 from a bug bounty with this dork: SaaS API keys and customer information were exposed in <code>vim_settings.xml</code>.</p><figure><img src="https://tillsongalloway.com/content/images/2020/05/vim_settings.png"></figure><p><code>vim_settings.xml</code> only contains recently copy-pasted strings, but we can exploit the repository's commit history to find the <strong>entire copy-paste history.</strong> Just clone the repository and run <a href="https://gist.github.com/tillson/620e8ef87bc057f25b0a27c423433fda">this 14-line script</a>, and the user's activity will be at your fingertips. GitHound also finds and scans base64 encoded strings for secrets, even in commit history.</p><p>By the way: with <a href="https://github.com/search?q=%22vim_settings.xml%22&amp;type=Commits">a GitHub commit search dork</a>, we can quickly scan all 500,000 of commits that edit <code>vim_settings.xml</code>.</p><figure><img src="https://tillsongalloway.com/content/images/2020/05/commits.png"></figure><h2 id="search-heuristics-for-bug-bounty-hunters">Search Heuristics for Bug Bounty Hunters</h2><p>GitHub dorks broadly find sensitive information, but<strong> what if we want to look for information about a specific company?</strong> GitHub has millions of repositories and even more files, so we'll need some heuristics to narrow down the search space. </p><p>To start finding sensitive information, identify a target. </p><p>I've found that the best way to start is to <strong>find domains or subdomains that identify corporate infrastructure.</strong> </p><p>Searching for <code>company.com</code> probably won't provide useful results: many companies release audited open-source projects that aren't likely to contain secrets. Less-used domains and subdomains are more interesting. This includes specific hosts like <code>jira.company.com</code> as well as more general second-level and lower-level domains. It's more efficient to find a pattern than a single domain: <code>corp.somecompany.com</code>, <code>somecompany.net</code>, or <code>companycorp.com</code> are more likely to appear only in an employee's configuration files. </p><p>The usual suspects for open-source intelligence and domain reconnaissance help here:</p><ul><li><a href="https://github.com/TheRook/subbrute">Subbrute</a> - Python tool for brute-forcing subdomains</li><li><a href="https://www.threatcrowd.org/">ThreatCrowd</a> - Given a domain, find associated domains through multiple OSINT techniques</li><li><a href="https://censys.io/">Censys.io</a> - Given a domain, find SSL certificates using it</li></ul><p>GitHound can help with subdomain discovery too: add a custom regex <code>\.company\.com</code> and run GitHound with the <code>--regex-file</code> flag.</p><p>After finding a host or pattern to search, play around on GitHub search with it (I always do this before using automated tools). There are a few questions I like to ask myself here:</p><ol><li><strong>How many results came up?</strong> If there are over 100 pages, I'll likely need to find a better query to start with (GitHub limits code search results to 100 pages).</li><li><strong>What kind of results came up?</strong> If the results are mostly (intentionally) open-source projects and people using public APIs, then I may be able to refine the search to eliminate those.</li><li><strong>What happens if I change the language?</strong> <code>language:Shell</code> and <code>language:SQL</code> may have interesting results.</li><li><strong>Do these results reveal any other domains or hosts?</strong> Results in the first few pages will often include a reference to another domain (e.g. searching for <code>jira.uber.com</code> may reveal the existence of another domain entirely, like <code>uberinternal.com</code>).</li></ol><p>I spend most of my time in this step.</p><p>It's crucial that the search space is well-defined and accurate. Automated tools and manual searching will be faster and more accurate with the proper query.</p><p>Once I find results that seem interesting based on the criteria above, I run it through <a href="https://github.com/tillson/git-hound">GitHound</a><a> </a>with <code>--dig-files</code> and <code>--dig-commits</code> to look the entire repository and its history. </p><p><code>echo "uberinternal.com" | ./git-hound --dig-files --dig-commits</code></p><p><code>echo "uber.com" | ./git-hound --dig-files --language-file languages.txt --dig-commits</code></p><p><code>echo "uber.box.net" | ./git-hound --dig-files --dig-commits</code></p><p>GitHound also locates interesting files that simply searching won't find, like <code>.zip</code> or <code>.xlsx</code> files. Importantly, I also manually go through results since automated tools often miss customer information, sensitive code, and username/password combinations. Oftentimes, this will reveal more subdomains or other interesting patterns that will give me ideas for more search queries. It's important to remember that open-source intelligence is a recursive process.</p><p>This process almost always finds results. Leaks usually fall into one of these categories (ranked from most to least impactful):</p><ol><li><strong>SaaS API keys</strong> - Companies rarely impose IP restrictions on APIs. AWS, Slack, Google, and other API keys are liquid gold. These are usually found in config files, bash history files, and scripts.</li><li><strong>Server/database credentials</strong> - These are usually behind a firewall, so they're less impactful. Usually found in config files, bash history files, and scripts.</li><li><strong>Customer/employee information</strong> - These hide in XLSX, CSV, and XML files and range from emails all the way to billing information and employee performance reviews.</li><li><strong>Data science scripts</strong> - SQL queries, R scripts, and Jupyter projects can reveal sensitive information. These repos also tend to have "test data" files hanging around.</li><li><strong>Hostnames/metadata</strong> - The most common result. Most companies don't consider this a vulnerability, but they can help refine future searches</li></ol><h2 id="workflow-for-specific-api-providers">Workflow for Specific API Providers</h2><p>Dorks can also be created to target specific API providers and their endpoints. This is especially useful for companies creating automated checks for their users' API keys. With knowledge of an API key's <strong>context</strong> and <strong>syntax</strong>, the search space can be significantly reduced. </p><p>With knowledge of the specific API provider, we can obtain all of the keys that match the API provider's regex and are in an API call context and then we can check them for validity using an internal database or an API endpoint. </p><figure><img src="https://tillsongalloway.com/content/images/2020/05/graph.png"><figcaption>A workflow for finding secrets for a single API provider</figcaption></figure><p>For example, suppose a company (HalCorp) provides an API for users to read and write to their account. By making our own HalCorp account, we discover that API keys are in the form <code>[a-f]{4}-[a-f]{4}-[a-f]{4}</code>. </p><pre><code># Python
import halapi
api = halapi.API()
api.authenticate_by_key('REDACTED')

# REST API with curl
curl -X POST -H "HALCorp-Key: REDACTED" https://api.halcorp.biz/userinfo
</code></pre><p>Armed with this information, we can compose our own GitHub dorks for HalCorp API responses: </p><pre><code># Python
"authenticate_by_key" "halapi" language:python

# REST API
"HALCorp-Key"
</code></pre><p>With a tool like <a href="https://github.com/tillson/git-hound">GitHound</a><a>,</a> we can use regex matching to find strings that match the API key's regex and output them to a file:</p><p><code>echo "HALCorp-Key" | git-hound --dig-files --dig-commits --many-results --regex-file halcorp-api-keys.txt --results-only &gt; api_tokens.txt </code></p><p>Now that we have a file containing potential &nbsp;API tokens, and we can check these against a database for validity (<strong>do not do this if you don't have written permission from the API provider</strong>).</p><p>In the case of HalCorp, we can write a bash script that reads from stdin, checks the <code>api.halcorp.biz/userinfo</code> endpoint, and outputs the response.</p><p><code>cat api_tokens.txt | bash checktoken.bash</code></p><p>Although awareness of secret exposure on GitHub has increased, more and more sensitive data are published each day. </p><p>Amazon Web Services have begun <a href="https://aws.amazon.com/blogs/security/how-to-receive-notifications-when-your-aws-accounts-root-access-keys-are-used/">notifying users if their API keys are posted online</a>. GitHub has added <a href="https://github.com/features/security">security features</a> that scan public repositories for common keys. These solutions are merely bandaids, however. To limit secret leaks from source code, we must update API frameworks and DevOps methodologies to prevent API keys from being stored in Git/SVN repositories entirely. Software like <a href="https://www.vaultproject.io/">Vault</a> safely stores production keys and some API providers, like Google Cloud Platform, have updated their libraries to force API keys to be stored in a file by default.</p><p>Fully eradicating exposure of sensitive information is a more difficult problem: how can customer information be fully detected? What if it's in a Word, Excel, or compiled file? More research must be conducted in this field to study the extent of the problem and its solution.</p>
                </div>
            </section>


       …</article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tillsongalloway.com/finding-sensitive-information-on-github/">https://tillsongalloway.com/finding-sensitive-information-on-github/</a></em></p>]]>
            </description>
            <link>https://tillsongalloway.com/finding-sensitive-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643373</guid>
            <pubDate>Thu, 25 Jun 2020 17:45:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Culture of Delivery with Lean DevOps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23643341">thread link</a>) | @jacksonpollock
<br/>
June 25, 2020 | https://cto.ai/blog/build-a-culture-of-delivery-with-lean-devops/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/build-a-culture-of-delivery-with-lean-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>You've probably heard of a Lean Startup approach to building a business, but what about a Lean DevOps approach to scaling your development team?</p><p>To explain the difference between traditional DevOps and Lean DevOps, let's start at a cloud's eye view and work our way down.</p><p>The definition of traditional DevOps, as defined by <a href="https://aws.amazon.com/devops/what-is-devops/#:~:text=DevOps%20is%20the%20combination%20of,development%20and%20infrastructure%20management%20processes.">AWS</a>, is:</p><blockquote>DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity: evolving and improving products at a faster pace than organizations using traditional software development and infrastructure management processes.</blockquote><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/traditional-devopscycle-cto.ai.png"></figure><!--kg-card-end: image--><p>Lean DevOps makes a key distinction in the fact that it aims to not just bring velocity to the surface, but also simplicity. As such, Lean DevOps is defined as:</p><blockquote><em>Lean DevOps is a development philosophy that focuses on both velocity and simplicity via a combination of culture, best practices, and workflow automation tools.</em></blockquote><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/lean-devops-cto.ai.png"></figure><!--kg-card-end: image--><p>Not only is traditional DevOps a major challenge for small companies trying to compete for skilled people, but those same startups also have the most promising opportunity to scale DevOps as part of their organizational structure and culture. In doing so, DevOps can be optimized using a lattice-style team philosophy where generalists and specialists are both leveraged and nurtured.</p><p>And Lean DevOps works. The <a href="https://puppet.com/resources/report/state-of-devops-report/">2019 State of DevOps Report</a> showed that companies who have high performing DevOps programs deploy software not only <strong>200 times more frequently</strong>, but also have <strong>2,555 times faster lead times</strong> for their projects. In addition, they also <strong>recover 24 times faster from failed changes</strong>, with <strong>three times lower change fail rates</strong>.</p><p>That equates to not just faster development, but faster business. You’ll reach milestones, OKRs, and goals earlier, and before your competition does. Thus, bringing developer tools into the realm of revenue generation and not just cost savings.</p><h2 id="-300b-in-lost-developer-productivity">$300B in Lost Developer Productivity</h2><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/dev-productivity_cto.ai-2.png"></figure><!--kg-card-end: image--><p>Currently, DevOps is fragmented across innumerable tools and technologies. Developers have also been tasked with workflow automation, but this burns valuable time that could be used to build features for paying customers.</p><h3 id="often-you-ll-see-two-main-devops-challenges-">Often you’ll see two main DevOps challenges:</h3><ol><li><strong>Many companies struggle to adopt DevOps practices.</strong></li><li><strong>DevOps tools are far more complex than ever before.</strong></li></ol><p>That’s why <a href="https://stripe.com/reports/developer-coefficient-2018">$300 billion in developer productivity is lost every single year</a> within growing development teams.</p><p>Technical leaders know that, as their teams grow, it is critical to invest in the workflows that their teams require to work. However, it can be too time-consuming to allocate their critical internal resources.</p><p>That’s why a Lean DevOps approach is so important. It allows teams to remain lean, automate repeated workflows, and use tools and behaviors that increase simplicity and velocity.</p><h2 id="the-10x-engineer-is-dead">The 10X Engineer Is Dead</h2><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/10x-engineer-cto.ai.png"></figure><!--kg-card-end: image--><p>And that’s why the 10X engineer is dead. Or, more appropriately, they never existed. However, a team’s ability to have a 10X impact is still very much alive.</p><p>Taking a Lean DevOps philosophy can work the same magic, but instead, focus on making a team of five engineers 2X as productive.</p><p>All they need to do is build the right culture, utilize industry best practices, and implement the best tools.</p><p>You can also consider building an organizational structure that unblocks your team like a lattice formation (pictured above) or holocracy-style team makeup that promotes a flat organization with limited bureaucracy and decentralized management.</p><p>These are frameworks for encoding autonomy, agility, and purpose-alignment into your organization's DNA.</p><h2 id="5-ways-to-build-a-culture-of-delivery">5 Ways to Build a Culture of Delivery</h2><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/teamvelocity-process-cto.ai.png"></figure><!--kg-card-end: image--><p>So, how do I move to the Lean DevOps light, you ask? Well, here are five steps to follow while implementing and scaling your lean culture.</p><ol><li><strong>Stick with lean process for as long as possible.</strong> Don’t give in until it’s the right moment. Stay lean allows you to move quickly in the early stages of a company.</li><li><strong><strong><strong>Choose boring technology, invest wisely. </strong></strong></strong>Take time to pick the tools that increase simplicity in your workflows.</li><li><strong><strong><strong>Onboarding sets expectations. </strong></strong></strong>Don’t just drop a new tool at your team’s feet. Implement a rollout plan and lay out the education with it.</li><li><strong><strong><strong>Create a platform for success. </strong></strong></strong>Lead by example to live and breath your new-found Lean DevOps philosophy.</li><li><strong><strong><strong>ICE: Impact + Confidence / Effort. </strong></strong></strong>Balance your workload by debating with data and leveraging your highest value initiatives.</li></ol><p>Take the time necessary to get buy-in for a culture shift from your team. It's never easy, but if you do it right in the beginning the effects will become much more ingrained in your sprints.</p><h2 id="scaling-with-lean-devops">Scaling with Lean DevOps</h2><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2020/06/devops-over-time-cto.ai.png"></figure><!--kg-card-end: image--><p>Remember, as your team scales you’ll move from a flatter organization to an Agile matrix one.</p><p>This will also affect your team velocity as process complexity increases.</p><p>So, as you scale, here are ways to stay within the Lean DevOps methodology:</p><ul><li><strong><strong><strong>Stay flat, fewer managers. </strong></strong></strong>Maintain accountability through transparency via tools like Slack and its companion app marketplace.</li><li><strong><strong><strong>Strategic vertical workstreams. </strong></strong></strong>Track product milestones in tools like Jira to provide visibility and a longer-term vision.</li><li><strong><strong><strong>Holistic horizontal specialization. </strong></strong></strong>Think about research and development, security, and codebase specialization as wide thoughts that span business functions.</li><li><strong><strong><strong>Don’t lose the ability to build a generalist culture. </strong></strong></strong>A team of polymaths will aide your problem solving and creative thinking.</li></ul><p>At the end of the day, there is no perfect process, but a combination of assets.</p><p>Tools with bottom-up adoption, a flat organizational structure to speed things up, adaptability, and a balance between velocity and stability are your targets.</p><p>Welcome to the delivery culture of Lean DevOps. Your team will thank you.</p><p>***</p><p><em>To learn about Lean DevOps in video form press play below.</em></p><!--kg-card-begin: embed--><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/-4Q6xEeVYSY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-end: embed-->
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/build-a-culture-of-delivery-with-lean-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643341</guid>
            <pubDate>Thu, 25 Jun 2020 17:43:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A mathematical formula that predicts US elections with 87.5% accuracy]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 27 (<a href="https://news.ycombinator.com/item?id=23643050">thread link</a>) | @bnveg
<br/>
June 25, 2020 | https://turingbotsoftware.com/posts/us-election-prediction.html | <a href="https://web.archive.org/web/*/https://turingbotsoftware.com/posts/us-election-prediction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>              <p>ceil(cos(0.996479*x*((-0.0830122)*(log(x)*(1.58953e-05-x)))))</p>              <p>The formula above, obtained using a Symbolic Regression procedure, has an out-of-sample accuracy of 87.5% in predicting which party will win the US presidential elections in a given year.</p>              </div><div>              <h2>How it was generated</h2><p>The rationale behind this formula was to try to obtain a mathematical expression that classifies which party (Democrat or Republican) will win the US presidential elections in a given election year.</p><p>To train the model, we looked at all the US elections in the last 100 years, and generated a table where at each row the first column is the year, and the second is 0 if the winning candidate was a Democrat and 1 if the candidate was a Republican. These are the last rows in that table:</p><pre>1992 0
1996 0
2000 1
2004 1
2008 0
2012 0
2016 1
</pre><p>The full table can be found <a href="https://turingbotsoftware.com/data/presidents_numbers.txt">here</a>.</p><p>Then, to generate the model, we used the Symbolic Regression software TuringBot. The chosen search metric was classification accuracy, and a 70/30 train/test split was used to reduce the chance of overfitting. The split was sequential: the oldest years were used for the training, and the most recent ones were used for the cross-validation.</p><p>These are the models that were found, along with their corresponding out-of-sample classification accuracies:</p>              <p><img src="https://turingbotsoftware.com/images/president_model.png"></p><p>In these formulas, x is the election year (2012, 2016, 2020, etc). The best formula turned out to be <span>ceil(cos(0.996479*x*((-0.0830122)*(log(x)*(1.58953e-05-x)))))</span>. Its accuracy in the training split is 94.11%, and in the test split 87.5%.</p>              <h2>The prediction for 2020</h2><p>Calculating the formula above at x = 2020, we find that the result is 1. This means that the formula predicts that a Republican is likely to win the elections.</p>              <h2>The prediction for the next elections</h2><p>We can also calculate the formula for the next elections. These are the results:</p><pre>2024: Democrat
2028: Republican
2032: Republican
</pre><p>It should be noted that the accuracy of the model is expected to degrade the further you go into the future.</p>              </div></div>]]>
            </description>
            <link>https://turingbotsoftware.com/posts/us-election-prediction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23643050</guid>
            <pubDate>Thu, 25 Jun 2020 17:22:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XMPP in Go]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642896">thread link</a>) | @SamWhited
<br/>
June 25, 2020 | https://blog.samwhited.com/2020/06/xmpp-in-go/ | <a href="https://web.archive.org/web/*/https://blog.samwhited.com/2020/06/xmpp-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<p><strong>Note:</strong> This post is about the <a href="https://pkg.go.dev/mellium.im/xmpp"><code>mellium.im/xmpp</code></a> project, an XMPP library
for <a href="https://golang.org/">Go</a>.
Some parts of this post may apply exclusively to <a href="https://pkg.go.dev/mellium.im/xmpp@v0.16.0">v0.16.0</a>.
Because this version is pre-1.0, things may change by the time you read this.
The most up-to-date version of this document can always be found at
<a href="https://mellium.im/docs/overview"><code>mellium.im/docs/overview</code></a>.</p>
<hr>
<p>Go is a great language if you need to get a project off the ground quickly. It
has its confusing aspects, and its type system allows for lots of abuse thanks
to <a href="https://blog.samwhited.com/2017/08/the-case-for-interface/">optional dynamic typing</a>, but overall it’s easy to read and easy to quickly
build projects that require clear code over absolute type safety.
Similarly, <!-- raw HTML omitted -->XMPP<!-- raw HTML omitted --><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> has its warts, but overall is the best choice to get a
chat product off the ground quickly if you want a system that’s well understood
and has a robust ecosystem and sustainable standards body.</p>
<p>Since Go shines at handling I/O bound services (like asynchronous network
protocols used for instant messaging), an XMPP library in Go seems like a great
fit.
There are a handful of libraries to handle XMPP already in existence, but most
of them are small high-level libraries designed only to work with the legacy
version of XMPP that was supported by Google Talk, or don’t follow Go idioms and
best practices.
When I started looking into a Go XMPP implementation around 5 years ago, there
wasn’t a low-level library meant to act as a building block from which higher
level systems could be created, and that’s what I wanted: the equivalent of the
standard libraries <a href="https://golang.org/pkg/net/http/"><code>net/http</code></a> but for XMPP.
This is why I created <a href="https://pkg.go.dev/mellium.im/xmpp"><code>mellium.im/xmpp</code></a>.
This post will be about some of the design decisions I made while building the
library, and about some of the trade offs made along the way.</p>
<h2 id="stream-features">Stream Features</h2>
<p>Let’s start by talking about feature negotiation.
An XMPP session can broadly be divided up into two parts: the synchronous
initial handshake, and the actual asynchronous session.
Within this initial handshake, a series of common features are negotiated in a
certain order.
For example, if TLS isn’t already in use, opportunistic TLS (StartTLS) might be
negotiated, followed by authentication.
This ends up being a loop where the server sends any features it wants to
advertise at the current moment (eg. just TLS) then the client chooses one to
negotiate and proceeds with that features specific negotiation steps.
Then the server sends another list (possibly with new features, eg. now that we
have TLS negotiated the server might advertise that authentication is now ready
to proceed) and the client selects one and moves forward.
This loop is easy enough to write in Go, but representing the features
themselves was tricky.
Features need to be able to encode the name they go by when the server lists
them and any information that should be included in that listing, they need to
be able to parse that payload from the clients side, and the actual negotiation
from the server and clients side needs to happen.
To handle this a struct containing three functions for listing features, parsing
the features list, and negotiating the features was created.
This means less boilerplate and more type safety than using an interface to
represent a stream feature.
It also makes it less likely that a user of this API will get confused and write
stateful stream features, but if necessary the functions can still close over
external state or resources (but don’t do this, you may think you need it, but
you’re almost certainly wrong).</p>
<pre><code>type StreamFeature struct {
	Name xml.Name

	Necessary SessionState
	Prohibited SessionState

	List func(ctx context.Context, e xmlstream.TokenWriter, start xml.StartElement) (req bool, err error)
	Parse func(ctx context.Context, r xml.TokenReader, start *xml.StartElement) (req bool, data interface{}, err error)
	Negotiate func(ctx context.Context, session *Session, data interface{}) (mask SessionState, rw io.ReadWriter, err error)
}
</code></pre><p>We also need to have a way to encode the order features should appear in (eg.
auth should not be attempted before TLS).
I decided that features would order themselves based on the state of the
session at the moment when feature negotiation happens.
The feature would say what properties of the session are or are not allowed, and
the thing doing negotiation can determine whether the session currently meets
those criteria.
Session state information only has 4 properties that are useful for session
negotiation:</p>
<ul>
<li>Is a security layer in place (eg. TLS),</li>
<li>has authentication been performed,</li>
<li>is feature negotiation complete, and</li>
<li>was the session initiated by a remote entity?</li>
</ul>
<p>These are part of the <a href="https://pkg.go.dev/mellium.im/xmpp#SessionState"><code>SessionState</code></a> bits, so in the stream features we can
encode what bits are <a href="https://pkg.go.dev/mellium.im/xmpp#StreamFeature.Necessary">necessary</a> and what bits are <a href="https://pkg.go.dev/mellium.im/xmpp#StreamFeature.Necessary">prohibited</a> and the state
machine that handles session negotiation will be able to figure out when to
advertise or negotiate the feature using simple bit math.</p>
<pre><code>const (
	// Secure indicates that the underlying connection has been secured. For
	// instance, after STARTTLS has been performed or if a pre-secured connection
	// is being used such as websockets over HTTPS.
	Secure SessionState = 1 &lt;&lt; iota

	// Authn indicates that the session has been authenticated (probably with
	// SASL).
	Authn

	// Ready indicates that the session is fully negotiated and that XMPP stanzas
	// may be sent and received.
	Ready

	// Received indicates that the session was initiated by a foreign entity.
	Received

	…
)
</code></pre><h2 id="session-negotiation">Session Negotiation</h2>
<p>Once we have a set of features that we can negotiate, we need to do the actual
session negotiation.
Normally, XMPP negotiates a session over TCP using the features loop that we
already described, however, sometimes an alternative mechanism might be required
for negotiation such as the websocket subprotocol defined in <a href="https://tools.ietf.org/html/rfc7395">RFC 7395</a> or the
legacy <a href="https://xmpp.org/extensions/xep-0114.html">XEP-0114: Jabber Component Protocol</a>.
Generalizing session negotiation meant allowing the user to provide a special
negotiator function and writing a default one for the basic XMPP stream
negotiation protocol.</p>
<pre><code>type Negotiator func(ctx context.Context, session *Session, data interface{})
  (mask SessionState, rw io.ReadWriter, cache interface{}, err error)
</code></pre><p>Because the negotiator can’t change the session state if it’s written in another
package (since the session state bits aren’t exported), it returns any changes
it wants to be made to the session such as the new session state mask, or any
changes to the underlying reader and writer (eg. if we negotiate StartTLS it
might return a new reader and writer that speak TLS).
The internal code that calls the negotiator function can then create a new
session with the requested changes.</p>
<p>The builtin negotiator can be created with <a href="https://pkg.go.dev/mellium.im/xmpp#NewNegotiator"><code>NewNegotiator</code></a> and supports
various options such as setting the stream language and copying the input and
output streams somewhere else (such as an XML console):</p>
<pre><code>// StreamConfig contains options for configuring the default Negotiator. 
type StreamConfig struct {
	// The native language of the stream.
	Lang string

	// S2S causes the negotiator to negotiate a server-to-server (s2s) connection.
	S2S bool

	// A list of stream features to attempt to negotiate.
	Features []StreamFeature

	// If set a copy of any reads from the session will be written to TeeIn and
	// any writes to the session will be written to TeeOut (similar to the tee(1)
	// command).
	// This can be used to build an "XML console", but users should be careful
	// since this bypasses TLS and could expose passwords and other sensitve data.
	TeeIn, TeeOut io.Writer
}

// NewNegotiator creates a Negotiator that uses a collection of StreamFeatures
// to negotiate an XMPP client-to-server (c2s) or server-to-server (s2s)
// session.
// If StartTLS is one of the supported stream features, the Negotiator attempts
// to negotiate it whether the server advertises support or not.
func NewNegotiator(cfg StreamConfig) Negotiator
</code></pre><p>It uses stream features as discussed in the previous
section, but custom negotiators could be written that use a different type for
stream features, making session negotiation and stream features entirely
modular.
You could replace them with your own implementations, and still use the <code>xmpp</code>
package to handle the lower level XMPP protocol.</p>
<p>An example of a custom stream negotiator can be found in the <a href="https://pkg.go.dev/mellium.im/xmpp/component"><code>xmpp/component</code></a>
package which negotiates a <a href="https://xmpp.org/extensions/xep-0114.html">XEP-0114: Jabber Component Protocol</a>
connection.</p>
<h2 id="receiving-data">Receiving Data</h2>
<p>Once the session is negotiated, we need to be able to receive stanzas (the
primitive types of XMPP) and other top level XML elements over the session.
Because the main <code>xmpp</code> package is meant to be lower level than many other XMPP
libraries written for Go, it does not contain callbacks or any way to register
handlers for different types of top level XML element.</p>
<p>Instead, it contains a single <a href="https://pkg.go.dev/mellium.im/xmpp#Session.Serve"><code>Session.Serve</code></a> method that decodes all incoming
XML tokens and delegates handling them to a single <a href="https://pkg.go.dev/mellium.im/xmpp#Handler"><code>Handler</code></a>.</p>
<pre><code>// A Handler triggers events or responds to incoming elements in an XML stream.
type Handler interface {
	HandleXMPP(t xmlstream.TokenReadEncoder, start *xml.StartElement) error
}
</code></pre><p>The <code>Serve</code> method also handles stanza semantics such as always responding to
IQs as required to be compliant with the XMPP protocol.
Because the handler is provided with a stream to use when writing back to the
session, the underlying library can man-in-the-middle the token stream and check
if an IQ response was written and automatically send one if not, or add required
IDs to stanzas that are missing them.</p>
<p>This design also keeps the number of methods on the session relatively low and
keeps the entire library more modular because we can delegate multiplexing
elements to more specific handlers to other packages such as the builtin
<a href="https://pkg.go.dev/mellium.im/xmpp/mux"><code>xmpp/mux</code></a> package.
If a user wants a more advanced multiplexer that buffers the stream and matches
stream elements based on <a href="https://relaxng.org/">RELAX NG</a>, <a href="https://web.archive.org/web/20200320131503/http://www.jclark.com/xml/xmlns.htm">Clark notation</a>, or <a href="https://www.w3.org/TR/xpath/all/">XPath</a>, they could
write it themselves and it would have all the same powers and access as the
built in muxer!
The <code>mux</code> package also provides more specific handlers for the basic XMPP stanza
types: <a href="https://pkg.go.dev/mellium.im/xmpp/mux#IQHandler"><code>IQHandler</code></a>, …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.samwhited.com/2020/06/xmpp-in-go/">https://blog.samwhited.com/2020/06/xmpp-in-go/</a></em></p>]]>
            </description>
            <link>https://blog.samwhited.com/2020/06/xmpp-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642896</guid>
            <pubDate>Thu, 25 Jun 2020 17:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Real-time uptime monitor of Let's Encrypt]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23642758">thread link</a>) | @enigmabridge
<br/>
June 25, 2020 | https://keychest.net/letsencrypt | <a href="https://web.archive.org/web/*/https://keychest.net/letsencrypt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://keychest.net/letsencrypt</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642758</guid>
            <pubDate>Thu, 25 Jun 2020 16:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A UX approach to video meeting fatigue]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642756">thread link</a>) | @dxchester
<br/>
June 25, 2020 | https://team.video/blog/camera | <a href="https://web.archive.org/web/*/https://team.video/blog/camera">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://team.video/uploads/camera-on-or-off.jpg" alt=""></p>

<section data-level="1" id="camera-on-or-off-a-ux-approach-to-video-meeting-fatigue">

<section data-level="3" id="video-conferencing-is-the-new-office-living-room-dinner-table-doctors-office-"><h3>Video conferencing is the new office / living room / dinner table / doctors office...</h3>
<p>As the spaces of our social lives have transitioned to a limited number of software interfaces, fatigue and burnout has skyrocketed taxing our mental health and productivity. While video conferencing apps are keeping us employed and connected, they are not prepared to handle this mass shift in our daily routines and social interactions. </p>

</section>
<section data-level="3" id="what-makes-video-conferencing-so-different-"><h3>What makes video conferencing so different?</h3>
<p>When we spend our days sitting in our makeshift offices and personal spaces staring at our coworkers, friends, doctors, teachers and families (and don’t forget ourselves!) in little boxes on our screens we miss so much of the social experience of real face to face interactions. We’re unable to read body language, engage in normal social rituals, have serendipitous conversations—to move!</p>
<p>We’re also responding to a unending amount of new information that our brains need to process—our personal lives surrounding us at home, the apartments and houses of our coworkers and their personal lives happening around them, the host of distractions on our desktops and the lure of almost unnoticeable multitasking. </p>
<p><img src="https://team.video/uploads/camera-ui.jpg" alt=""></p>

</section>
<section data-level="3" id="can-the-design-of-our-meeting-software-help-"><h3>Can the design of our meeting software help?</h3>
<p>As a UX designer working to build a video conferencing platform, it’s been crucial to acknowledge the limitations of the medium in hopes of easing some of the fatigue with features designed not to replicate in person communication but to uncover and build on the strengths of a relatively new space.    </p>

</section>
<section data-level="3" id="improving-our-new-space-the-meeting-room"><h3>Improving our new space - The meeting room</h3>
<p>We spend so much care and effort creating the physical spaces we occupy, and these spaces have a known effect on our mental health as well as our productivity, creativity and sociablility. A black box filled with poor quality images littered with icons can feel like spending all day in a messy room with no windows—of course we’re exhausted after a day of video meetings! But what can we do to make these new rooms feel like  sleek, light filled rooms with all the personal touches that we invest so much thought into? </p>
<p><img src="https://team.video/uploads/camera-meetingroom.jpg" alt=""></p>
<p>The furniture, if you will, of these new spaces is entirely different. Instead of tables, whiteboards and light switches we have new furniture that has to replicate everything else missing from in person interaction—all those icons littered about. Unmute is the desk of a virtual meeting room.</p>
<p>Designing meetings rooms for Team.video has strived to take into account interior design principles as well as UX best practices. Does a glaring red mute icon create more stress and visual clutter than it provides important functional information? Our process has been one of many iterations, focusing on light colors, subtle gradients and subdued accents.</p>

</section>
<section data-level="3" id="camera-on-or-off-"><h3>Camera on or off?</h3>
<p>We’ve never been more aware of the green light at the top of our screens. In almost daily research sessions over the past few months I've yet to encounter a team that has found the golden solution to the camera on or off question. </p>
<p>Companies that had a camera on policy have switched to camera optional and those with a camera optional approach have switched to camera on. Some teams use cameras only for smaller meetings or only require those speaking to use video. </p>
<p>Camera off can feel less personal but also removes the need to process so many different faces and backgrounds at once. While being on camera for the majority of a day is incredibly exhausting and not always necessary for productive work meetings. </p>
<ul>
<li>There is probably no golden solution, but some design attention can greatly improve both sides of the coin. </li>
<li>A more aesthetically pleasing camera off view that still includes the face of a coworker and a signal when/that they are speaking. </li>
<li>Flexible layouts for different scenarios—one speaker, a handful of speakers, screenshare brainstorm etc. </li>
<li>The option to hide or minimize your own video. </li>
<li>Blurred or custom backgrounds for camera on mode—which can be a lot of fun and also a potential new distraction. </li>
</ul>
<p><img src="https://team.video/uploads/cameraonoroff.png" alt=""></p>

</section>

<section data-level="3" id="meetings-start-very-abruptly"><h3>Meetings start VERY abruptly</h3>
<p>All of a sudden you’re face to face with an unfamiliar coworker, from your bedroom...and the person who called the meeting is running late. This scenario is unique to telecommuting. Maybe you regularly walk to the conference room with a coworker, or you introduce yourself politely and take the first few minutes of a meeting to fill your water bottle while everyone else arrives. </p>
<p>All of this is much more awkward over video. Small talk is less natural with mute/unmute issues, lack of non verbal cues and often bandwidth time delays. Widespread goals to keep meetings efficient encourage us to get straight to the point, which can be jarring. </p>
<p>How can UX help those first few meeting minutes? </p>
<ul>
<li>It’s important to know who is already in the meeting before you join so you can decide if you want to be one on one with a C level you’ve never met. </li>
<li>Arrive looking (and sounding!) your best with a pre-meeting ‘haircheck’ where meeting goers can check their audio/video before entering the meeting</li>
<li>Low effort social interaction built in to the welcome minutes. At team.video we’ve implemented an optional word game that early arrivers can play against each other in lieu of or in addition to any amount of small talk. </li>
</ul>
<p><img src="https://team.video/uploads/camera-haircheck.jpg" alt=""></p>
<p><img src="https://team.video/uploads/camera-game.jpg" alt=""></p>

</section>
<section data-level="3" id="keep-trying-new-things-"><h3>Keep trying new things!</h3>
<p>Design is always about observing, trying and testing. With team.video we’ve been able to explore some ideas larger companies have not and we’d love to hear any thoughts or issues that you’ve encountered in our software or others! </p>
<p>Try us out at <a href="https://team.video/">Team.Video</a></p>

</section>
</section>
    </div></div>]]>
            </description>
            <link>https://team.video/blog/camera</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642756</guid>
            <pubDate>Thu, 25 Jun 2020 16:57:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we launched our MVP in 3 weeks]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23642739">thread link</a>) | @adamthewan
<br/>
June 25, 2020 | https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/ | <a href="https://web.archive.org/web/*/https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsSAAALEgHS3X78AAADWElEQVQozxWT21MaBxTG95/oUx/71ulDM2msjk2nLRgcjZHEiRgpiQmiIVgUlmyAhb3Ccr8srMsdFpQFuQaQBBMTBLWY6Ux0Js3UNu3YPnQy0z+gY966fT5n5vu+8/0OwFLNsK2hVyQQTRTTciGy7oWr61TTj1Rdxi2WapXS/Q12l7E1AkgtHewkfU8rmX4+8iIV6AAhok7jda8lGiJZy4OkDaRJXQJfzbtNJQrkfZZKxNGMOBsvW697nZO3x2cnr/4Ikw27ng+Rj4EG/9PZu9edWoWyriLmzw0qC41vMfaWx1wWlClD3gmVaWyXYwYJ/0GW2a9m+x64LFiLedpA98mbEldDtTYYvIpaP7FocYeh7oG3PHCpmOim/AcRdymfflDM3SznZ7z4HUjJuYxFO8iTujwA3UuszUdtIFPJ/vh8e4exR2mkJYzNy1wx1X1cdpz9Lvpw/umT9se7ux9tcJ9ZNSmTKmPTbzJkAyBBXnbNu3I/W6gfRJotjXtdrvLoFtMRdysT/eHD+Y3zf794//fUu9+g/R7pd/jvSZ3626xwlKT/KbB4NykWuS9esI4pLTMO83Uc/k6KjYzYKaLFsZk4q0jHR/Z7NyNeBlri0sHa4Yt+LJiGV9ij7ikwLnVMLhBDw8jQEDqxiImniWkJI5Xio5ehWalFPg7Lpx7JJbBiGuYjeVSNbwbT/5z+lVnnc+wOcG3RNqnEL11Ev5lCpXp88j4qvkWMjC6Pjq2JrtogZUqnYMHbybSv0Mm1VPNzQYQ4qh52O2Wt3A+IRc4vL+CiWcTMs9ZCTBawyGn0soicGA/eWYiZVnJZ+plBGSfU4Vq48ufR4dnhyUErx4a/tmpigEjkGL6Ea/F4utlRm6LXH2FXZomvJEgmt/fr6ftB75ds+BlLbRuX44a7bo8p4rPGQKXdrA4L/ACjI6T4BoFns1AgNSdjr4y5hoexGQPZe3s8eHXqs1Yx7UZ/503M1V6S0msKtrk1IHS8eYn7v2cpiMoo9JYXlUGUZNw1MW9XOXxC+NUQAy7FoYWEQFIAqyOarLAdc7f56EujMomscDHPNjDnxGROdM6FyezYtxJC/3Bzp3+sUIeU39OW5Qz1sOgylgT+C4luMbknPAON1e1gIeFrD/Z+/g9UCcPcvxQNXAAAAABJRU5ErkJggg==" alt="Cover"></p></div><div><div><div><p>This should be </p><!-- --><p>an</p><!-- --> <!-- --><p>11 min read</p><p>June 12, 2020</p></div></div><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><p>Usually, when people think about building and launching a startup, they plan it out a few weeks in advance. In my experience doing software consulting, I’ve seen and worked on some projects where the founders take 2 - 3 months to launch the first version of their product. That’s too much time and effort sunk into a project that may not work.</p><h2>Why you need to get your Minimum Viable Product out ASAP</h2><p>The problem is that most people are not comfortable with launching a minimum viable product. Founders are often creative people who love to explore and dive into “wouldn’t it be cool if”s. This habit can result in a continuous loop of adding features, even before the first version of your product is released.</p><p>Perfectionism can often get in the way of execution, and I’ve fallen for this trap many times. My first product (SideQuest) took me four months to build and launch. To continue developing an untested product is, to put it bluntly, arrogant. Here’s why: it assumes that what you are making is vital for your customer. It assumes that you know what’s best for your user. You don’t.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c1b63/reiterations.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Image: What your startup journey will probably look like" title="Image: What your startup journey will probably look like" src="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/fcda8/reiterations.png" srcset="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/12f09/reiterations.png 148w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/e4a3f/reiterations.png 295w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/fcda8/reiterations.png 590w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/efc66/reiterations.png 885w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c83ae/reiterations.png 1180w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c1b63/reiterations.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Image: What your startup journey will probably look like</figcaption>
  </figure><p>No founder knows until they launch their startup and get feedback from people. Your first version is likely going to suck; it might even miss the mark or be utterly irrelevant to the market. You need to get any negative and positive signals from your target market as soon as possible.</p><p>That was what we tried to do with MeetButter. Everyone on our team has had experience getting burnt by wasting time, runway, effort, and emotion building products or features that were inconsequential in the larger picture.</p><p>Here’s the story of how we managed to build and ship MeetButter in three weeks.</p><h3>Step 1 - Identification</h3><figure>
    <span>
      <a href="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c1b63/slack-discussion.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="It started with a thread" title="It started with a thread" src="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/fcda8/slack-discussion.png" srcset="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/12f09/slack-discussion.png 148w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/e4a3f/slack-discussion.png 295w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/fcda8/slack-discussion.png 590w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/efc66/slack-discussion.png 885w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c83ae/slack-discussion.png 1180w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c1b63/slack-discussion.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>It started with a thread</figcaption>
  </figure><p>The first spark for MeetButter was a Slack thread discussing the pains teachers and educators were dealing with transitioning their classrooms from offline to online. We found that there was a very human problem with online video conferencing - they only allowed the focus to one speaker at a time. It was awkward interrupting the speaker, and this caused some participants to feel reluctant to engage. The discussion thread grew, with more anecdotes and feedback from our friends and family.</p><p>Identifying the problem is the first step. It’s crucial to figure out the groups of people that are facing the same issues and gathering feedback from them. </p><h3>Step 2 - Investigation</h3><p>We decided to take this asynchronous discussion and organize a synchronous brainstorm session. During this particular session, we discussed three significant problems that we had identified and were interested in solving. On the list was the aforementioned “video conferencing” - which eventually became MeetButter.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c1b63/brainstorm.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Breaking down the current video conferencing experience" title="Breaking down the current video conferencing experience" src="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/fcda8/brainstorm.png" srcset="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/12f09/brainstorm.png 148w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/e4a3f/brainstorm.png 295w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/fcda8/brainstorm.png 590w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/efc66/brainstorm.png 885w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c83ae/brainstorm.png 1180w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c1b63/brainstorm.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Breaking down the current video conferencing experience</figcaption>
  </figure><p>Some significant points were brought up by everyone on the team, and we found that these were problems that each one of us had faced while doing online video conferencing:</p><ol><li>It’s difficult to indicate an interest in speaking, reply to the current conversation, or add to the discussion without feeling like you’re interrupting the current speaker.</li><li>It’s impossible to transition smoothly between one speaker to the next. Sometimes mid-sentence pauses are met with several speakers trying to enter into the conversation at once. Combined with lag, this can get quite awkward.</li><li>The avoidance of awkwardness causes some people to remain quiet.</li><li>The loudest voice in the room problem - some people naturally dominated discussions.</li><li>Social cues are almost non-existent when your entire team gets boxed into tiny windows on-screen and are only visible from their shoulder up.</li></ol><p>The purpose of this brainstorm was not to narrow down into solutions, but it was to dive deep into the problems.</p><div><p>Adam is typing something... (Click to reveal)</p><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><h3>Step 3 - Sketching</h3><p>After the brainstorm session, we discussed some ideas on how to tackle the problem. Solutions can seem pretty vague, and usually, what happens is that several keywords get thrown around. For us, it was “queue,” “overlay,” and “polls.” It’s good to note that people often visualize keywords differently and form very different concepts in their heads. </p><p>A picture is worth a thousand words. Sketching is an essential skill to learn for any founder, as it’s the best medium to transfer your ideas with a low signal-noise ratio. People often misunderstand your words. If you’re not good at drawing, it’s good to learn how to sketch out a prototype digitally using free tools like Figma. I have even used Google Slides to build a low fidelity prototype for a client once! Sometimes I even screenshot parts of other apps and combine them into a Frankenstein of an image - anything to help bridge the gap between your vision and their imagination.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/07a9c/prototype-sketch.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Sketch of the app that turned into MeetButter" title="Sketch of the app that turned into MeetButter" src="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/fcda8/prototype-sketch.png" srcset="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/12f09/prototype-sketch.png 148w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/e4a3f/prototype-sketch.png 295w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/fcda8/prototype-sketch.png 590w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/efc66/prototype-sketch.png 885w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/c83ae/prototype-sketch.png 1180w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/07a9c/prototype-sketch.png 1440w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Sketch of the app that turned into MeetButter</figcaption>
  </figure><p>Based on the feedback and ideas from the team, this was the very first sketch for MeetButter that I built using Figma. After sharing it on our team Slack, we held a meeting to discuss the steps moving forward. We decided to cut out some features and instead focus on the queuing functionality as we were able to test it internally during our daily standup calls.</p><h3>Step 4 - Prototyping</h3><p>I won’t go into too much detail about how we built the prototype. This step will be different for every team: some teams will opt to do a no-code prototype using tools like AirTable and Google Forms; some will choose to do a “simulated” prototype using Figma or Zeplin; some will opt to build a fully functioning albeit minimal prototype using code. We decided to do the latter as it was the fastest for me to code something quickly.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c1b63/hackathon.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Developers during a hackathon weekend" title="Developers during a hackathon weekend" src="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/fcda8/hackathon.png" srcset="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/12f09/hackathon.png 148w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/e4a3f/hackathon.png 295w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/fcda8/hackathon.png 590w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/efc66/hackathon.png 885w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c83ae/hackathon.png 1180w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c1b63/hackathon.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Developers during a hackathon weekend</figcaption>
  </figure><p>The purpose of our prototype was to test:</p><ol><li><p>If the core hypothesis works. In this case, we wanted to test if allowing participants to queue would help meetings flow better.</p></li><li><p>If we could build the tech. Founders often underestimate the technical work that goes into creating their vision. Building a prototype allows you to do a mini feasibility test.</p></li></ol><div><p>Adam is typing something... (Click to reveal)</p><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><h3>Step 5 - Testing and Feedback</h3><figure>
    <span>
      <a href="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c1b63/mvp.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="It's alive!" title="It's alive!" src="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/fcda8/mvp.png" srcset="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/12f09/mvp.png 148w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/e4a3f/mvp.png 295w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/fcda8/mvp.png 590w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/efc66/mvp.png 885w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c83ae/mvp.png 1180w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c1b63/mvp.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>It's alive!</figcaption>
  </figure><p>Once you have your prototype, you need to get it in front of some test users. Finding test users can be tricky.  Ideally, the test users should be from within your team; this was the case for us with MeetButter. It meant that we were building a product for ourselves, that we were part of our target market. Building a product to solve your problems has some apparent benefits: </p><ol><li>It creates a shorter and more efficient feedback loop.</li><li>It’s easier to innovate on issues you face</li><li>It somewhat validates your market.</li></ol><p>If you are building a product that’s not for yourself, I’d suggest finding at least ten people within your networks who can become your loyal test users.</p><p>MeetButter was also super easy to integrate into our daily workflow. All we had to do was open up the web app during our regular standup calls. It’s essential to build some sort of feedback loop. I sent a Google Form to the participants of the meeting to gather initial feedback as soon as the meeting ended - it’s best to strike while the iron is hot. We also had several Slack threads discussing additional ideas that came up as we continued testing.</p><h3>Step 6 - Reiteration</h3><p>After testing our prototype, we collected the feedback and went back to the drawing board. At this point, you have to make a clear decision with your prototype - do you continue to reiterate, or do you kill the project? We found that our prototype worked quite well, and although we were skeptical, there was a sense that we were onto something. We started using the prototype in every meeting, so it was hard to deny that our team internally found it useful.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c1b63/feedback-loop.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The typical product development feedback loop" title="The typical product development feedback loop" src="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/fcda8/feedback-loop.png" srcset="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/12f09/feedback-loop.png 148w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/e4a3f/feedback-loop.png 295w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/fcda8/feedback-loop.png 590w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/efc66/feedback-loop.png 885w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c83ae/feedback-loop.png 1180w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c1b63/feedback-loop.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>The typical product development feedback loop</figcaption>
  </figure><p>We repeated the process of designing, reiterating, and receiving feedback several times. Our testing group grew from our internal team of five people out to our friends within our social circles.</p><h3>Final Step - Launch</h3><p>After a few rounds of iterations, our prototype slowly shed its pieces and morphed into something resembling a product. As soon as we exhausted our immediate networks, we knew that the next step was to launch MeetButter beyond internal test users.</p><p>I began to lay the groundwork for a codebase that could grow into a scalable project. Our tech stack ended up being the following:</p><ul><li>Frontend - NextJS with Redux and GraphQL</li><li>Backend - A mix of Firebase and an Express server that’s powered by Apollo GraphQL and Sequelize</li><li>Infrastructure - We used Netlify and AWS to deployment</li></ul><figure>
    <span>
      <a href="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c1b63/pmf.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Why it's important to fail fast" title="Why it's important to fail fast" src="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/fcda8/pmf.png" srcset="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/12f09/pmf.png 148w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/e4a3f/pmf.png 295w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/fcda8/pmf.png 590w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/efc66/pmf.png 885w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c83ae/pmf.png 1180w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c1b63/pmf.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Why it's important to fail fast</figcaption>
  </figure><p>Several factors allowed us to build and ship MeetButter quickly.</p><p>Firstly, we were fortunate to have had the experience and the skills to execute quickly. We didn’t run into many technical limitations, as each one of us had filled the significant roles that were needed. These roles include design/UI UX, software development, and marketing/networking.</p><p>Secondly, we tried to follow the best practices for idea generation. The brainstorm that led to MeetButter wasn’t the first one that we had together. It was probably our fifth brainstorm session after getting together as a team as Project Phoenix. With a lot of practice, we were able to build a set of best practices to have productive brainstorm sessions, get feedback, and reiterate.</p><p>Thirdly, we were close to our target market, which allowed us to test fast and slowly expand our test userbase.</p><p>Fourth, we threw perfection out the window. Our prototype didn’t work 100% of the time, had a bunch of bugs, and built with the bare minimum UI. Despite this, we still used it every single day for our video calls. It was good …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/">https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/</a></em></p>]]>
            </description>
            <link>https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642739</guid>
            <pubDate>Thu, 25 Jun 2020 16:55:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are peaceful protests more successful than violent ones?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642525">thread link</a>) | @BafS
<br/>
June 25, 2020 | https://blog.datawrapper.de/are-peaceful-protests-more-successful-than-violent-ones | <a href="https://web.archive.org/web/*/https://blog.datawrapper.de/are-peaceful-protests-more-successful-than-violent-ones">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
            
<p><em>Hi, I’m Edurne (Eddie), writer &amp; support intern here at Datawrapper and aspiring data journalist. Today’s Weekly Chart is about a question I’ve frequently asked myself in the last few years: can civil resistance foster social change and revolution?</em></p>
<p>Between 2017 and 2019, I had the opportunity to work as a foreign correspondent in Kenya, Japan, and Spain. It was not always easy, but I was lucky to learn many interesting things along the way. I was also constantly on the ‘wire’, reading stories from many countries and learning about their past, culture, and daily lives.</p>
<p>Even before that, while I was studying journalism, I  found myself reading and writing a lot about protests, like the <em>Umbrella Movement in Hong Kong</em> or the <em>Yellow Vests</em> (<em>Gilets Jaunes</em>) movement in France. The images from the Arab spring in 2010 stuck with me the most. And it’s not a coincidence that I read about protests so much: <a href="https://www.economist.com/graphic-detail/2020/03/10/political-protests-have-become-more-widespread-and-more-frequent" target="_blank" rel="noopener">the last few decades have seen an increase in campaigns</a>.</p>
<p>But not all protests are the same: There are violent and peaceful ones. I was wondering: Which of them are successful? To find out, I used data from The Non-violent and Violent Campaigns and Outcomes (<a href="https://dataverse.harvard.edu/dataverse/navco" target="_blank" rel="noopener">NAVCO</a>) project by Harvard University, the first of its kind to collect systematic data on violent insurgencies and non-violent civil resistance around the world:</p>





<p>NAVCO gathered data on 622 campaigns between 1900 and 2019. As we can see in the chart, in this time, half of the <strong>321 non-violent campaigns succeeded, while only a quarter of their 301 violent counterparts</strong> did. 56% of violent campaigns failed, compared to 30% of non-violent ones.</p>
<p>Erica Chenoweth, a researcher on violence and co-author of the NAVCO Data Project, found even more evidence that non-violent protests are more successful: “Countries in which there were nonviolent campaigns were about 10 times likelier to transition to democracies within a five-year period compared to countries in which there were violent campaigns – whether the campaigns succeeded or failed”, she explained to <a href="https://news.harvard.edu/gazette/story/2019/02/why-nonviolent-resistance-beats-violent-force-in-effecting-social-political-change/" target="_blank" rel="noopener">The Harvard Gazette</a>.</p>
<p>You can search through all the 622 campaigns that the NAVCO data set contains here:</p>





<h2 id="Data-concerns">Data concerns</h2>
<p>Because it’s a data set collected by hand instead of measured, it’s important to understand the decisions behind it better.</p>
<p>Launched by Harvard University, the NAVCO Data Project covers different aspects of civil resistance and insurgencies through time. For this article, I decided to analyze the 4th iteration of the project: the <strong><a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ON9XND" target="_blank" rel="noopener">NAVCO 1.3 data set</a></strong>, released on March 17 of this year.</p>
<p>While making statements like “non-violent campaigns are more successful”, we need to bear in mind that this data set might not include all campaigns, suffering a so-called <strong>underreporting bias</strong>. The authors of the NAVCO data set also note in their codebook that the included <strong>non-violent campaigns</strong> are <strong>biased toward success:</strong> the large, mature campaigns are most commonly reported. Some non-violent campaigns are crushed in their infancy (and therefore fail) and are not included in this data set.</p>
<p>This bias has, however, been mitigated by looking only at major campaigns with at least 1,000 people participating in the protest. The dataset also only includes protests with a maximalist objective, such as bringing down a government. Despite not being perfect, the NAVCO Data Project is still a reference <a href="https://www.eurekalert.org/pub_releases/2020-01/hu-imo012420.php" target="_blank" rel="noopener">for many researchers and journalists</a> to analyze the effects of both violent and non-violent protests in global politics.</p>
<h2 id="The-process">The process</h2>
<p>One thing I like about data visualization (although it can be daunting) is the amount of trial and error that it requires to come up with the right chart type. The table I finally created was not close to my first idea (at the beginning I wanted to create a scatterplot or even a map!), which shows that visualization can be really rich in variety as well!</p>
<p>Before looking at the data set, I started with a blank piece of paper and wrote down my initial questions. I believe this step comes from my journalistic background: <strong>I treat data sets as interviewees</strong>. The main question – are non-violent protests more or less successful than violent ones? – was easily answered with a pivot table in Google Sheets.</p>
<p>The main work needed to be done on the Datawrapper table. To help readers navigate this big amount of data, I opted for the use of <strong>emojis</strong> in the <strong>“Success”</strong> column. Now you just need a glance to know how the campaign ended. I also decided to bring ongoing campaigns to the front of the table, since those are the insurgencies and protests that are happening at the moment and people have likely been reading about them in the last few years. Finally, I decided to <strong>highlight the non-violent campaigns that ended up in success</strong>.</p>
<h2 id="References">References</h2>
<p>If you’d like to learn more about protests or recreate any of the charts above, have a look at the following sources:</p>
<ul>
<li>Visit this <a href="https://blog.datawrapper.de/protest-topics-in-germany-are-changing/">Weekly Chart</a> by my coworker Fabian to zoom into the rebellious history of Germans</li>
<li>You can also check out  <a href="https://foreignpolicy.com/2013/10/25/the-dissidents-toolkit/" target="_blank" rel="noopener">this article</a> by Erica Chenoweth on how demonstrations are not enough to undermine authoritarian governments</li>
<li>Some Datawrapper Academy articles on <a href="https://academy.datawrapper.de/article/247-examples-of-datawrapper-tables" target="_blank" rel="noopener">examples of tables</a>, how to format your text in <a href="https://academy.datawrapper.de/article/191-how-to-format-your-text-with-markdown" target="_blank" rel="noopener">Markdown</a> and how to insert <a href="https://academy.datawrapper.de/article/144-how-to-insert-flag-icons-in-tables" target="_blank" rel="noopener">flag icons in tables</a> also helped a lot with this article.</li>
</ul>
<hr>
<p><em>And that’s all for this week! I hope you enjoyed my first article here at Datawrapper. I would love to hear your thoughts on how to spark a revolution! Do you support any political movement? Is there any civil resistance group that you are particularly interested in? Leave a comment below or send me an email at <a href="mailto:edurne@datawrapper.de">edurne@datawrapper.de</a>. See you next Thursday!</em></p>

          </div></div>]]>
            </description>
            <link>https://blog.datawrapper.de/are-peaceful-protests-more-successful-than-violent-ones</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642525</guid>
            <pubDate>Thu, 25 Jun 2020 16:35:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Building a Free Game Assets Directory]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642352">thread link</a>) | @mpbeauj
<br/>
June 25, 2020 | https://moonlightgamedevs.com/free-assets | <a href="https://web.archive.org/web/*/https://moonlightgamedevs.com/free-assets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A curated List of the best free Game Assets!</p><p><span><svg width="24" height="24" viewBox="-3 -3 30 30" xmlns="http://www.w3.org/2000/svg" fill-rule="evenodd" clip-rule="evenodd"><path d="M10.605 0h-10.605v10.609l13.391 13.391 10.609-10.604-13.395-13.396zm-4.191 6.414c-.781.781-2.046.781-2.829.001-.781-.783-.781-2.048 0-2.829.782-.782 2.048-.781 2.829-.001.782.782.781 2.047 0 2.829z"></path></svg></span>Categories</p><div><p><a href="https://moonlightgamedevs.com/free-assets/category/audio">Audio</a><a href="https://moonlightgamedevs.com/free-assets/category/tools">Tools</a><a href="https://moonlightgamedevs.com/free-assets/category/-d%20-art(-models%20/%20-animations)">3D Art</a><a href="https://moonlightgamedevs.com/free-assets/category/tool">Tool</a><a href="https://moonlightgamedevs.com/free-assets/category/code">Code</a><a href="https://moonlightgamedevs.com/free-assets/category/-d%20-art(-sprites%20/%20-textures)">2D Art</a><a href="https://moonlightgamedevs.com/free-assets/category/u-i%20/%20-u-x">UI / UX</a><a href="https://moonlightgamedevs.com/free-assets/category/shader">Shader</a></p></div><p>Updated weekly - subscribe so you don't miss new Listings.</p><section id="newsletter"><div><h3>Newsletter</h3><p>Subscribe for updates on Blog Posts, Podcast Episodes, News, and more. Sent out every Week.</p><form method="post" name="newsletter-subscription"><p><label><p id="email-newsletter-subscription-error">Please enter a valid email</p></label></p><p><label><span>&nbsp;I have read and agree to the<!-- --> <a href="https://moonlightgamedevs.com/privacy-policy">data policy</a>.</span><p id="dataPolicy-newsletter-subscription-error">Please agree to the data policy</p></label></p><label></label></form></div></section></div></div>]]>
            </description>
            <link>https://moonlightgamedevs.com/free-assets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642352</guid>
            <pubDate>Thu, 25 Jun 2020 16:17:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critique of 2018 Turing Award for Drs. Bengio and Hinton and LeCun]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23642335">thread link</a>) | @jdp23
<br/>
June 25, 2020 | http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="arial">
<center>
.
<div>
<a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html"><img src="http://people.idsia.ch/~juergen/critique-turing754x288.png" alt="Critique of 2018 Turing Award for Bengio &amp; Hinton &amp; LeCun"></a>

<center>



<span size="4">
</span></center><span size="4">

<a name="abstract">
<hr>
</a><p><a name="abstract">
<b>Abstract.</b> ACM's 2018 A.M. Turing Award was about
<em>deep learning</em> in artificial neural networks.
ACM lauds the awardees for work based on algorithms
and conceptual foundations first published by other researchers 
whom the awardees failed to cite
(see </a><a href="#exec">Executive Summary</a>
and Sec. 
<a href="#I">I</a>,
<a href="#V">V</a>, 
<a href="#II">II</a>,
<a href="#XII">XII</a>,
<a href="#XIX">XIX</a>, 
<a href="#XXI">XXI</a>,
<a href="#XIII">XIII</a>, 
<a href="#XIV">XIV</a>,  
<a href="#XX">XX</a>, 
<a href="#XVII">XVII</a>).
ACM explicitly mentions "astonishing" deep learning breakthroughs in 4 fields:
<a href="#A"> (A) speech recognition</a>, 
<a href="#B">(B) natural language processing</a>, 
<a href="#C">(C) robotics</a>, 
<a href="#D">(D) computer vision</a>,
as well as "powerful" new deep learning tools in 3 fields: 
<a href="#VII">(VII) medicine, astronomy, materials science</a>.
Most of these breakthroughs and tools, however, were directly based on 
the results of my own labs in the past 3 decades 
 (e.g., Sec.  
<a href="#A">A</a>,
<a href="#B">B</a>,
<a href="#C">C</a>,
<a href="#D">D</a>,
<a href="#VII">VII</a>,
<a href="#XVII">XVII</a>,
<a href="#VI">VI</a>,
<a href="#XVI">XVI</a>). 
I correct ACM's distortions of deep learning history (e.g., Sec. 
<a href="#II">II</a>,  
<a href="#V">V</a>, 
<a href="#XX">XX</a>,
<a href="#XVIII">XVIII</a>) 
and also 
mention 8 of our direct priority disputes 
with Bengio &amp; Hinton (Sec.  <a href="#XVII">XVII</a>, <a href="#I">I</a>).


</p><hr>

<p>
<em>This document (~11,000 words)
reuses and expands some of the material in my <a href="http://people.idsia.ch/~juergen/critique-honda-prize-hinton.html">Critique of the 2019 Honda Prize</a> <a href="#HIN">[HIN]</a> (~3,000 words). 
It has several layers of hierarchical abstraction: 
<b><a href="#abstract">Abstract</a></b> (150 words), <b><a href="#exec">Executive Summary with links to details</a></b> (~1,000 words), <b><a href="#I">Body with 21 comments on 21 claims by ACM</a></b> (~7,700 words) and <b><a href="#conclusion">Conclusion</a></b> (~1,700 words). 
All backed up by  <a href="#References">over 200 references</a> (~6,500 words).
</em>

</p><hr>


<p>We must stop crediting the wrong people for inventions made by others.
Instead let's heed the recent call in the journal <em>Nature</em>:
<b>"Let 2020 be the year in which we value those who ensure that 
science is self-correcting"</b> <a href="#SV20">[SV20]</a>.
Like those who know me can testify, finding and citing original sources of scientific and technological innovations is important to me, whether they are mine or other people's <a href="#DL1">[DL1]</a> <a href="#DL2">[DL2]</a> <a href="#HIN">[HIN]</a> <a href="#NASC1">[NASC1-9]</a>. The present page is offered as a resource for computer scientists who share this inclination. 
By grounding research in its true intellectual foundations and crediting the original inventors, 
I am not diminishing important contributions made by popularizers of those inventions. 
My goal is to encourage the entire community to be more scholarly in its efforts, to recognize the foundational work that sometimes gets lost in the frenzy of modern AI and machine learning,
and to fight plagiarism in all of its more or less subtle forms. 
I am also inviting others to contribute additional relevant 
references (send them to <em>juergen@idsia.ch</em>). 



</p><p> I will focus on 
contributions praised by
ACM's official justification <a href="#T19">[T19]</a> of the 
2018 A.M. Turing Award for Drs. Bengio &amp; Hinton &amp; LeCun  <a href="#R1">[R1]</a> 
 published in 2019.
After the <a href="#exec">Executive Summary</a>,
ACM's full text <a href="#T19">[T19]</a> is split into 21 parts  
labeled by "<b>ACM:</b>" 
<a href="#I">I</a>, 
<a href="#II">II</a>, 
<a href="#III">III</a>, 
<a href="#IV">IV</a>,
<a href="#V">V</a>,
<a href="#VI">VI</a>,
<a href="#VII">VII</a>,
<a href="#VIII">VIII</a>,
<a href="#IX">IX</a>,
<a href="#X">X</a>,
<a href="#XI">XI</a>,
<a href="#XII">XII</a>,
<a href="#XIII">XIII</a>,
<a href="#XIV">XIV</a>,
<a href="#XV">XV</a>,
<a href="#XVI">XVI</a>,
<a href="#XVII">XVII</a>,
<a href="#XVIII">XVIII</a>,
<a href="#XIX">XIX</a>,
<a href="#XX">XX</a>,
<a href="#XXI">XXI</a>.
Each part is followed by a critical "<b>Comment</b>." 
Most of the comments are based on references to original papers and other material from
 recent 
blog posts <a href="#MIR">[MIR]</a> <a href="#DEC">[DEC]</a>  <a href="#HIN">[HIN]</a>.
<b>I'll point out 
that  highly cited publications of the awardees ignored fundamental 
relevant prior work—this may be the reason for some of  ACM's misattributions.</b>
Since ACM's text is a bit repetitive and redundant, so are the partially overlapping
sections of  my critique. 



</p><h2><a name="exec">
<hr>
Executive Summary (~1000 words, with links to details)
<hr>
</a></h2><a name="exec">

</a><p><a name="exec">
While Drs. LeCun &amp; Bengio &amp; Hinton (<b>LBH for short</b>)  
have made  useful improvements of algorithms for 
artificial neural networks (<b>NNs</b>) 
and deep learning (e.g., </a><a href="#I">Sec.  I</a>), ACM lauds
them for more visible 
work based on fundamental methods whose inventors they did not cite,
not even in later surveys
(this may actually explain some of  ACM's misattributions). I correct ACM's distortions of deep learning history.
Numerous <a href="#References">references</a> can be found under the relevant section links I-XXI 
which adhere to the sequential order of ACM's text <a href="#T19">[T19]</a>
(while this summary groups related sections together).


</p><p>
<b>Sec. <a href="#II">II</a>:</b> 
In contrast to ACM's claims, 
NNs for pattern recognition etc. were introduced long before the 1980s. 
 <b>Deep learning with multilayer perceptrons started in 1965</b> through Ivakhnenko &amp; Lapa
long before LBH who have never cited them, not even in recent work.
<b>In the 1980s,</b> "modern" gradient-based learning 
worked only for rather shallow NNs,
<b>but it became really deep in 1991 in my lab,</b>
first through 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%201">unsupervised pre-training of NNs</a>, 
then through 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">supervised LSTM</a>.
<b>Sec.  <a href="#I">I</a></b> contains 4 subsections 
<b><a href="#A">A</a>, <a href="#B">B</a>, <a href="#C">C</a>, <a href="#D">D</a></b>
on <b>the  4 deep learning "breakthroughs" explicitly 
mentioned by ACM</b>. ACM does not mention that they were 
mostly based on deep learning techniques of my team:

</p><p>
<b>Sec.
<a href="#A">A: Speech Recognition</a></b> (see also <a href="#VI">VI</a> &amp; <a href="#XI">XI</a> &amp; <a href="#XV">XV</a>): The first superior end-to-end neural speech recognition 
combines two methods from my lab: <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a> (1990s-2005) and CTC (2006), applied to speech in 2007. 
Hinton (2012) and Bengio (<a href="#XV">XV</a>)
still used an old hybrid approach of the 1980s and 90s;
Hinton et al. (2012) did not compare it to 
our revolutionary CTC-LSTM (<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">which was soon on most smartphones</a>).

</p><p>
<b>Sec. <a href="#B">B: Natural Language Processing</a></b> (see also  <a href="#VI">VI</a> &amp; <a href="#XI">XI</a> &amp;  <a href="#XVI">XVI</a>): 
The first superior end-to-end neural machine translation  
(<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">soon used for several billions of
translations each day by the big platform companies</a>)
was also based on our <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a>.

</p><p>
<b>Sec. <a href="#C">C: Robotics</a></b>.
Our LSTM trained by <b>Reinforcement Learning</b> (RL) was also the core of the 
most visible breakthroughs in robotics and video games.

</p><p>
<b>Sec. <a href="#D">D: Computer Vision</a></b>
(see also   
<a href="#XVIII">XVIII</a> &amp; <a href="#XIV">XIV</a>  &amp; <a href="#XI">XI</a>  &amp;  <a href="#VI">VI</a>)
was revolutionized by <b>convolutional NNs</b> (CNNs).
The basic CNN architecture is due to Fukushima (1979). 
NNs with convolutions were later (1987) combined by Waibel with backpropagation and weight sharing, 
and applied to speech. <b>All before</b> LeCun's CNN work  (<a href="#XVIII">XVIII</a>).
We showed twice (1991-95 and 2006-10) that 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">deep NNs 
don't need unsupervised 
pre-training</a> (in contrast to Hinton's claims). Our team (Ciresan et al.)  
made CNNs fast &amp; deep enough for  
<a href="http://people.idsia.ch/~juergen/computer-vision-contests-won-by-gpu-cnns.html">superior computer vision  in 2011</a>,
<b>winning 4 image recognition contests in a row
before Hinton's team won one</b>. ResNet (ImageNet 2015 winner)
is a special case of our earlier <a href="http://people.idsia.ch/~juergen/highway-networks.html">Highway Nets</a>.

</p><p>
<b>Sec.  <a href="#XIV">XIV:</a></b>
Again ACM recognizes work that failed to cite the pioneers.
Long before Hinton (2012), Hanson (1990) had a variant of <b>dropout</b>, 
and v. d. Malsburg (1973) had <b>rectified linear neurons</b>; Hinton did not cite them.
Already in 2011,
our deep &amp; fast CNN  more than <b>"halved the error rate for object recognition"</b> (ACM's wording) 
in a computer vision contest 
(<a href="http://people.idsia.ch/~juergen/superhumanpatternrecognition.html">where LeCun participated</a>), 
long before Hinton's similar CNN (2012). 
<b>Sec. <a href="#XI">XI</a>:</b>  ACM mentions GPU-accelerated NNs  
pioneered by Jung &amp; Oh (2004). LBH
did not cite them.
Our deep GPU-NN of 2010 debunked <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">unsupervised pre-training (introduced by myself in 1991 and later championed by Hinton)</a>, 
and our GPU-CNN of 2011 was the first  
to win contests in <b>computer 
vision</b> (explicitly mentioned by ACM).
 

</p><p>
<b>Sec.  
<a href="#XVIII">XVIII</a></b>:
ACM credits LeCun for developing CNNs. However, the foundations of CNNs were laid earlier by 
Fukushima and Waibel  (Sec. <a href="#D">D</a>).
 ACM also explicitly mentions <b>autonomous driving</b> and <b>medical image analysis</b>.
The first team to win relevant international contests in these fields 
through deep CNNs was ours (2011, 2012, 2013).
<b>Sec.  
<a href="#VII">VII</a>:</b> ACM explicitly mentions  <b>medicine</b> and
 <b>materials science</b>. Our deep NNs were the 
<a href="http://people.idsia.ch/~juergen/first-time-deep-learning-won-medical-imaging-contest-september-2012.html">first to win medical imaging competitions</a>
 in 2012 and 2013, and the first to apply deep NNs to material defect detection in industry (since 2010).


</p><p>
<b>Sec. <a href="#XII">XII</a> &amp; <a href="#XIX">XIX</a> &amp; <a href="#XXI">XXI</a>:</b> Modern 
<a href="http://people.idsia.ch/~juergen/who-invented-backpropagation.html">backpropagation</a>
was first published by Linnainmaa (1970), 
not by LeCun or Hinton or their collaborators (1985) who did not cite Linnainmaa, 
not even in later surveys. 
<b>Sec. 
<a href="#XIII">XIII</a>  &amp; 
<a href="#II">II</a> &amp; 
<a href="#V">V</a> 
</b>
(&amp; 
<a href="#III">III</a> &amp; 
<a href="#IX">IX</a> &amp;
<a href="#X">X</a> &amp;
<a href="#XX">XX</a>):
Ivakhnenko's deep feedforward nets (since 1965) <b>learned 
internal representations</b> long before Hinton's shallower ones (1980s).
Hinton has never cited him.
<b>Sec. <a href="#XX">XX</a>:</b> ACM credits LeCun for work on
<b>hierarchical feature representation</b> which did not cite Ivakhnenko's much earlier work
on this (since 1965).
<b>Sec. <a href="#XXI">XXI</a>:</b> ACM credits LeCun for work on
<b>automatic differentiation</b> which did not cite its inventor Linnainmaa (1970). 
And also for work on
<b>deep learning for graphs</b> that failed to cite 
the earlier work  by Sperduti &amp; Goller &amp; Küchler &amp; Pollack.



</p><p>
<b>Sec. 
<a href="#XV">XV</a>:</b> ACM credits Bengio for hybrids of NNs and  probabilistic models of sequences. 
His work
was not the first on this topic, and is 
not important for <b>modern deep learning speech recognition systems</b> (mentioned by ACM) based on our CTC-LSTM
 (Sec.  
<a href="#A">A</a> &amp; 
<a href="#B">B</a>).
<b>Sec.
<a href="#XVI">XVI</a>:</b> ACM 
credits Bengio for neural probabilistic language models.
Our 1995 neural probabilistic text model greatly predates Bengio's.
ACM mentions NNs that learn
 sequential <b>attention</b>. <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%209">We started this in 1990-93 long before LBH</a> who did not cite this.




</p><p>
<b>Sec.  <a href="#XVII">XVII</a>:</b>
ACM mentions
<b>Generative Adversarial Networks</b> (GANs, 2010-14) of Bengio's team, a special case of
my  Adversarial  
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%205"><b>Artificial Curiosity</b></a>
(1990) which he did not cite. 
I list 7 of 
our <b>additional priority disputes</b> with Bengio &amp; Hinton (more than can be explained by chance),  
on 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%203">vanishing gradients</a> (1991),
<a href="http://people.idsia.ch/~juergen/metalearner.html">meta-learning</a> (1987),
 <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%201">unsupervised pre-training</a> (1991),
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%202">compressing or distilling one NN into another</a> (1991), 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%208">fast weights  
through outer products</a> (1993), 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%209">learning sequential attention with NNs</a> (1990),
and other topics <a href="#R2">[R2-R6]</a>.








</p><p>
<b>Sec. <a href="#IV">IV</a></b> is on <a href="http://people.idsia.ch/~juergen/turing.html">Turing</a> (1936) and his predecessors
<a href="http://people.idsia.ch/~juergen/goedel.html">Gödel</a> (1931) and Church (1935).

</p><p>
<b>Sec. <a href="#conclusion">Conclusion:</a></b>
 In the recent <a href="http://people.idsia.ch/~juergen/2010s-our-decade-of-deep-learning.html">decade of deep learning</a>,
most major AI applications mentioned by ACM 
<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">(speech recognition, language translation, etc.) on billions of devices</a>  (also healthcare applications)
heavily depended on our deep learning techniques and conceptual foundations,
while LBH's most visible work ignored
 essential prior art since the 1960s—see, e.g., 
Sec. <a href="#II">II</a> &amp;  
<a href="#III">III</a> &amp; 
<a href="#V">V</a> &amp;
<a href="#XII">XII</a> &amp; 
<a href="#XIII">XIII</a> &amp; 
<a href="#XVII">XVII</a> &amp; 
<a href="#XIV">XIV</a> &amp; 
<a href="#XIX">XIX</a> &amp; 
<a href="#XX">XX</a> &amp; 
<a href="#XXI">XXI</a>, 
<a href="#DL1">[DL1]</a> <a href="#DL2">[DL2]</a> <a href="#DLC">[DLC]</a> <a href="#MIR">[MIR]</a> <a href="#HIN">[HIN]</a> <a href="#R4">[R2-R8]</a>.
But in science, by definition, the facts will always win in …</p></span></div></center></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642335</guid>
            <pubDate>Thu, 25 Jun 2020 16:15:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detecting Street Lanes for Self-Driving Cars in Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642306">thread link</a>) | @fifomihal
<br/>
June 25, 2020 | https://beta.deepnote.com/article/street-lanes-finder | <a href="https://web.archive.org/web/*/https://beta.deepnote.com/article/street-lanes-finder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="code-cell"><div><p><span>def</span> <span>averaged_lines</span><span>(</span>image<span>,</span> lines<span>)</span><span>:</span>
    right_lines <span>=</span> <span>[</span><span>]</span>
    left_lines <span>=</span> <span>[</span><span>]</span>
    <span>for</span> x1<span>,</span>y1<span>,</span>x2<span>,</span>y2 <span>in</span> lines<span>[</span><span>:</span><span>,</span> <span>0</span><span>]</span><span>:</span>
        parameters <span>=</span> np<span>.</span>polyfit<span>(</span><span>(</span>x1<span>,</span> x2<span>)</span><span>,</span> <span>(</span>y1<span>,</span> y2<span>)</span><span>,</span> <span>1</span><span>)</span>
        slope <span>=</span> parameters<span>[</span><span>0</span><span>]</span>
        intercept <span>=</span> parameters<span>[</span><span>1</span><span>]</span>
        <span>if</span> slope <span>&gt;=</span> <span>0</span><span>:</span> 
            right_lines<span>.</span>append<span>(</span><span>[</span>slope<span>,</span> intercept<span>]</span><span>)</span>
        <span>else</span><span>:</span>
            left_lines<span>.</span>append<span>(</span><span>[</span>slope<span>,</span> intercept<span>]</span><span>)</span>
            
    <span>def</span> <span>merge_lines</span><span>(</span>image<span>,</span> lines<span>)</span><span>:</span>
        <span>if</span> <span>len</span><span>(</span>lines<span>)</span> <span>&gt;</span> <span>0</span><span>:</span>
            slope<span>,</span> intercept <span>=</span> np<span>.</span>average<span>(</span>lines<span>,</span> axis<span>=</span><span>0</span><span>)</span>
            y1 <span>=</span> image<span>.</span>shape<span>[</span><span>0</span><span>]</span>
            y2 <span>=</span> <span>int</span><span>(</span>y1<span>*</span><span>(</span><span>1</span><span>/</span><span>2</span><span>)</span><span>)</span>
            x1 <span>=</span> <span>int</span><span>(</span><span>(</span>y1 <span>-</span> intercept<span>)</span><span>/</span>slope<span>)</span>
            x2 <span>=</span> <span>int</span><span>(</span><span>(</span>y2 <span>-</span> intercept<span>)</span><span>/</span>slope<span>)</span>
            <span>return</span> np<span>.</span>array<span>(</span><span>[</span>x1<span>,</span> y1<span>,</span> x2<span>,</span> y2<span>]</span><span>)</span>
        
    left <span>=</span> merge_lines<span>(</span>image<span>,</span> left_lines<span>)</span>
    right <span>=</span> merge_lines<span>(</span>image<span>,</span> right_lines<span>)</span>
    <span>return</span> left<span>,</span> right

<span>def</span> <span>hough_lines</span><span>(</span>image<span>,</span> rho<span>,</span> theta<span>,</span> threshold<span>,</span> min_line_len<span>,</span> max_line_gap<span>)</span><span>:</span>
    lines_image <span>=</span> np<span>.</span>zeros<span>(</span><span>(</span>image<span>.</span>shape<span>[</span><span>0</span><span>]</span><span>,</span> image<span>.</span>shape<span>[</span><span>1</span><span>]</span><span>,</span> <span>3</span><span>)</span><span>,</span> dtype<span>=</span>np<span>.</span>uint8<span>)</span>
    lines <span>=</span> cv2<span>.</span>HoughLinesP<span>(</span>image<span>,</span> rho<span>,</span> theta<span>,</span> threshold<span>,</span> np<span>.</span>array<span>(</span><span>[</span><span>]</span><span>)</span><span>,</span> minLineLength<span>=</span>min_line_len<span>,</span> maxLineGap<span>=</span>max_line_gap<span>)</span>
    <span>if</span> lines <span>is</span> <span>not</span> <span>None</span><span>:</span>
        lines <span>=</span> averaged_lines<span>(</span>image<span>,</span> lines<span>)</span>
        <span>for</span> line <span>in</span> lines<span>:</span>
            <span>if</span> line <span>is</span> <span>not</span> <span>None</span><span>:</span>
                x1<span>,</span>y1<span>,</span>x2<span>,</span>y2 <span>=</span> line
                cv2<span>.</span>line<span>(</span>lines_image<span>,</span> <span>(</span>x1<span>,</span> y1<span>)</span><span>,</span> <span>(</span>x2<span>,</span> y2<span>)</span><span>,</span> <span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>255</span><span>)</span><span>,</span> <span>20</span><span>)</span>
        plot_image<span>(</span>lines_image<span>,</span> <span>"lines"</span><span>)</span>
    <span>return</span> lines_image</p></div></div></div>]]>
            </description>
            <link>https://beta.deepnote.com/article/street-lanes-finder</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642306</guid>
            <pubDate>Thu, 25 Jun 2020 16:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Managed Services. Please]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642260">thread link</a>) | @dijit
<br/>
June 25, 2020 | http://www.mooreds.com/wordpress/archives/3358 | <a href="https://web.archive.org/web/*/http://www.mooreds.com/wordpress/archives/3358">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	    
	<!-- #masthead .site-header -->
    
	    
	<div id="main">
        	    
        <div>

		<div id="primary">
			

			
					
	
	
				
								
					<article id="post-3358">
    
    <div>
     <div>      
 		<p>“Use managed services.”</p>
<p>If there was one piece of advice I wish I could shout from the mountains to all cloud engineers, this would be it.</p>
<p>Operations, especially operations at scale, are a hard problem. Edge cases become commonplace. Failure is rampant. Automation and standardization are crucial. People with experience running software and hardware at this scale tend to be rare and expensive. The mistakes they’ve made and situations they’ve learned from aren’t easy to pick up.</p>
<p>When you use a managed service from one of the major cloud vendors, you’re getting access to all the wisdom of their teams and the power of their automation and systems, for the low price of their software.</p>
<p>A managed service is a service like AWS relational database service, Google Cloud SQL or Azure SQL Database. With all three of these services, you’re getting best of breed configuration and management for a relational database system. There’s configuration needed on your part, but hard or tedious tasks like setting up replication or backups can be done quickly and easily (take this from someone who fed and cared for a mysql replication system for years). Depending on your cloud vendor and needs, you can get managed services for key components of modern software systems like:</p>
<ul>
<li>File storage</li>
<li>Object caches</li>
<li>Message queues</li>
<li>Stream processing software</li>
<li>ETL tools</li>
<li>And more</li>
</ul>
<p>(Note that these are all components of your application, and will still require developer time to thread together.)</p>
<p>You should use managed services for three reasons.</p>
<ul>
<li>It’s going to be operated well. The expertise that the cloud providers can provide and the automation they can afford to implement will likely surpass what you can do, especially across multiple services.</li>
<li>It’s going to be cheaper. Especially when you consider employee costs. The most expensive AWS RDS instance is approximately $100k/year (full price). It’s not an apples to apples comparison, but in many countries you can’t get a database architect for that salary.</li>
<li>It’s going to be faster for development. Developers can focus on connecting these pieces of infrastructure rather than learning how to set them up and run them.</li>
</ul>
<p>A managed service doesn’t work for everyone. If you need to be able to tweak every setting, a managed service won’t let you. You may have stringent performance or security requirements that a managed service can’t meet. You may also start out with a managed service and grow out of it. (Congrats!)</p>
<p>Another important consideration is lock-in. Some managed services are compatible with alternatives (kubernetes services are a good example). If that is the case, you can move clouds. Others are proprietary and will require substantial reworking of your application if you need to migrate.</p>
<p>If you are working in the cloud and you need a building block for your application like a relational database or a message queue, start with a managed service (and self host if it doesn’t meet your needs). Leverage the operational excellence of the cloud vendors, and you’ll be able to build more, faster.</p>
		              </div>
    </div>
    
</article><!-- #post-3358 -->

				
									
	
	

			
			
		</div><!-- #primary .content-area -->

<!-- #secondary .widget-area -->
		</div><!--  .row -->
            
	</div><!-- #main .site-main -->

	<!-- #colophon .site-footer -->
</div></div>]]>
            </description>
            <link>http://www.mooreds.com/wordpress/archives/3358</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642260</guid>
            <pubDate>Thu, 25 Jun 2020 16:08:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM Mac: Why I'm Worried About Virtualization]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 283 (<a href="https://news.ycombinator.com/item?id=23642178">thread link</a>) | @bmalehorn
<br/>
June 25, 2020 | https://bmalehorn.com/arm-mac/ | <a href="https://web.archive.org/web/*/https://bmalehorn.com/arm-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It's late 2020 and you just got a brand-new Mac with Apple's own ARM processors. Exciting! But what will development be like?</p><h2>Docker</h2><p><img src="data:image/png;base64,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" width="150"></p><p>I would <strong>expect about a 5x slowdown running Docker images.</strong></p><p>Docker on a Mac utilizes a <strong>hypervisor</strong>. Hypervisors rely on running the <strong>same architecture on the host as the guest</strong>, and are about about 1x - 2x as slow as running natively.</p><p>Since you're running ARM Mac, these hypervisors can only run ARM Linux. They can't run x86_64 Linux.</p><p>What will happen instead? These tools will fall back on <strong>emulators</strong>. Emulators can run <strong>a different architecture between the host and the guest</strong>, but simulate the guest operating system at about 5x-10x slowdown.</p><div><p><img src="https://bmalehorn.com/static/perf-267ab9cfc29b6f68078fbe19892bce23.png"></p><p>A basic performance test comparing gzip performance on amd64 (hypervisor) and arm64v8 (emulator). Note that the emulator is over 6x slower. On an ARM Mac, the amd64 image will instead be 6x slower.</p></div><p>Why can't you update the Docker image to also support ARM? You theoretically could switch your backend to run ARM Linux. However, this would take months - renting out ARM instances, re-building all repositories, and a tense switch over. What if your hosting provider doesn't offer ARM instances with the same system requirements as x86_64? What if you complete this migration and find it runs at half the speed?</p><p>Worse, it might be impossible if your images include files downloaded off the internet, as those are often only compiled for x86_64.</p><div><p><img src="https://bmalehorn.com/static/phantomjs-615e9c8bc9d2deb5ca62a4533c1299d6.png"></p><p>An example of a Docker command that will only work on x86_64. PhantomJS does not release an arm build.</p></div><p>While moving your backend to ARM is far from impossible, it's a serious migration that you shouldn't take lightly. Getting a new laptop isn't enough justification to switch your backend architecture.</p><p>Another option is to <strong>run Docker remotely</strong>. You set up an x86_64 Linux server, then allow Docker to connect to it remotely. From then on, all Docker commands instead run on the server. This is also supported in Docker, <a href="https://www.digitalocean.com/community/tutorials/how-to-use-a-remote-docker-server-to-speed-up-your-workflow">here</a> is a tutorial on setting it up. This is what heavy Docker users will want to do.</p><h2>VirtualBox</h2><p><img src="https://bmalehorn.com/static/virtualbox-c37e4cc82b13d3c1c080f7ced273ae45.png" width="150"></p><p><strong>VirtualBox won't work.</strong></p><p>VirtualBox is a <strong>hypervisor</strong>. Therefore, <strong>it won't be able to run x86 Windows or x86 Linux</strong>.</p><p>You could use VirtualBox to run ARM Windows. Windows already supports ARM, and has a similar binary translation system to Apple's, so it can run x86 binaries. However, VirtualBox only supports x86 hosts and guests and is <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">unlikely to be ported by ARM</a>.</p><p>VMWare Fusion similarly is a hypervisor that only support x86, but <a href="https://twitter.com/VMwareFusion/status/1275483803536908288?s=20">they're thinking about supporting ARM</a>.</p><p>Instead of VirtualBox you might use QEMU, an emulator. However, QEMU is pretty low level and not often used to emulate Windows.</p><h2>Boot Camp</h2><p><img src="https://bmalehorn.com/static/boot-camp-f05493e57b0fe815dbc1d989ada98dd0.png" width="150"></p><p><strong>Boot Camp won't work.</strong></p><p><a href="https://support.apple.com/boot-camp">Boot Camp</a> is an Apple-approved way to dual-boot Mac OS and Windows. <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp?utm_campaign=theverge&amp;utm_content=chorus&amp;utm_medium=social&amp;utm_source=twitter">Boot Camp will definitely not be available on ARM Macs</a>. It might be added later with the ability to run ARM Windows, though Microsoft <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp">would have to approve</a>.</p><h2>Should I get an ARM Mac?</h2><p>The point of this post isn't to say that ARM Mac is a bad idea, but to give a realistic idea of what developing on one would look like assuming nothing changes. It's possible Apple could release more virtualization tools before the ARM Mac launches.</p><p>Should you get an ARM Mac if you're a developer? If you work largely on frontend, mobile, or native apps, you'll probably be fine. But if you use virtualization often, I wouldn't recommend it. There will be a lot of problems early on, and not all of them will have solutions. My biggest concern is getting an ARM Mac and realizing I simply can't run an essential application on it.</p><p>However if you like troubleshooting these issues and are excited about ARM Mac, go for it! My plan is for those kinds of people to fix these issues.</p><p>Know something I don't? Have questions? Email me at <a href="mailto:bmalehorn@gmail.com">bmalehorn@gmail.com</a>.</p></div></div>]]>
            </description>
            <link>https://bmalehorn.com/arm-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642178</guid>
            <pubDate>Thu, 25 Jun 2020 16:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using OAuth and PKCE to Add Authentication to Your Gatsby Site]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23642003">thread link</a>) | @mooreds
<br/>
June 25, 2020 | https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Gatsby is one of the most popular JavaScript static site generators available. While static sites offer excellent performance, they only store state locally in the user’s browser, so they can’t provide features like user authentication natively. If you want to add authentication to your Gatsby site, FusionAuth is an excellent solution.</p>

<!--more-->

<p>In this blog post, you’ll learn how to create a Gatsby site that uses FusionAuth to allow users to log in and access their profile securely. This application will use an <a href="https://fusionauth.io/learn/expert-advice/oauth/definitive-guide-to-oauth-2#52-code-flow--pkce">OAuth Authorization Code workflow and the PKCE extension</a> to log users in and a Node application to store your access token securely. PKCE stands for Proof Key for Code Exchange, and is often pronounced “pixie”.</p>

<p>At a high level, the authorization process looks like this:</p>

<figure>
        <img src="https://fusionauth.io/assets/img/diagrams/blogs/gatsby/oauth-gatsby.svg" alt="Diagram of the OAuth Authorization Code flow with PKCE extension using FusionAuth and Gatsby.">
        <figcaption>Diagram of the OAuth Authorization Code flow with PKCE extension using FusionAuth and Gatsby.</figcaption>
      </figure>

<p>In this tutorial, you’ll walk through the process step-by-step, but if you want to download the code, it is <a href="https://github.com/fusionauth/fusionauth-example-gatsby">available on Github</a>.</p>

<h2 id="what-well-cover">What we’ll cover</h2>
<ol>
  <li>Setting up FusionAuth</li>
  <li>Creating a new user</li>
  <li>Creating a Node proxy application</li>
  <li>Creating a Gatsby site</li>
  <li>Conclusion and next steps</li>
</ol>

<h2 id="what-youll-need">What you’ll need</h2>
<ul>
  <li><a href="https://fusionauth.io/download">FusionAuth</a></li>
  <li><a href="https://nodejs.org/en/">Node JS</a> (10+ preferred)</li>
  <li><a href="https://www.npmjs.com/">npm</a> package manager</li>
  <li>Web browser</li>
</ul>

<h2 id="setting-up-fusionauth">Setting up FusionAuth</h2>
<p>Before you start writing any code, download FusionAuth and get it running on your local machine. FusionAuth is available <a href="https://fusionauth.io/download">for all major operating systems</a> or it can be <a href="https://fusionauth.io/docs/v1/tech/installation-guide/docker">run in Docker</a>.</p>

<p>Once you have FusionAuth running, log into the admin panel and create a new Application. This process <a href="https://fusionauth.io/docs/v1/tech/5-minute-setup-guide">is outlined here</a>, but you’ll need to add your application’s URLs to the OAuth configuration:</p>

<ul>
  <li>Add <code>http://localhost:9000/oauth-callback</code> to the “Authorized redirect URLs”.</li>
  <li>Add <code>http://localhost:9000</code> to the “Authorized request origin URLs”.</li>
  <li>Enter <code>http://localhost:8000</code> in the “Logout URL” field.</li>
</ul>

<p>You’ll also want to save the “Client Id” and “Client secret” values as you’ll need them later.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/oauth-gatsby/application-setup.png" alt="FusionAuth configuration options for a Gatsby static site."></p>

<p>You’ll also need to create an API key. Go to “Settings”, then to “API Keys”. You may create one with adminstrative privileges for the purposes of this tutorial. For a production application, please follow the principle of least privilege and limit the endpoints available to the key. Save the API key off as you’ll need it later.</p>

<h2 id="creating-a-new-user">Creating a new user</h2>
<p>To test your Gatsby-based login, you’ll need to add a new user and register them for your application in FusionAuth. From the Users page in FusionAuth, click “+” to add a user. Enter an email address and password for your new user and click the save button.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/oauth-gatsby/create-user.png" alt="Creating a new user in FusionAuth."></p>

<p>Next, click “Add registration” to link this user to the application you created in Step 1. Click the save button when you’re finished.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/oauth-gatsby/register-user.png" alt="Registering a user in FusionAuth."></p>

<p>Now that a user is registered for your application, you can start building the Node app.</p>

<h2 id="creating-a-node-proxy-application">Creating a Node proxy application</h2>
<p>This project will use two separate applications: a Node app to securely store your access token and make calls to the FusionAuth API, and a Gatsby site to present information to the user. The Node app will have four endpoints:</p>

<ul>
  <li><code>/login</code> - Generates the FusionAuth login URL with a PKCE challenge</li>
  <li><code>/oauth-callback</code> - Trades the one-time authorization code and PKCE verifier for an access token which is added to session storage</li>
  <li><code>/user</code> - Uses the access token and the FusionAuth <code>introspect</code> endpoint to get information about the current user</li>
  <li><code>/logout</code> - Logs the user out and destroys the session</li>
</ul>

<p>You’ll create all the endpoints first, and then you’ll see how to call them from Gatsby.</p>

<h3 id="setting-up-the-node-app">Setting up the Node app</h3>
<p>Before you get started, you need to create a new subdirectory and initialize an Express app. Use a <a href="https://fusionauth.io/blog/2020/03/10/securely-implement-oauth-in-react">similar structure to the one outlined here</a>:</p>

<div><div><pre><code>fusionauth-gatsby
├─gatsby
├─server
└─config.js
</code></pre></div></div>

<p>Your <code>config.js</code> file should contain all your FusionAuth information. Add the following to the file with your FusionAuth application’s ID, client ID, and ports:</p>

<div><div><pre><code>module.exports = {
  // FusionAuth info (copied from the FusionAuth admin panel)
  clientID: '5eb76e67-c65e-474d-ba23-4cb61b0c8414',
  clientSecret: 'BVS1NIgID3HWE5U38HYSb4DOie3UbIySOsJKLT41WWg',
  redirectURI: 'http://localhost:9000/oauth-callback',
  applicationID: '5eb76e67-c65e-474d-ba23-4cb61b0c8414',

  // Your FusionAuth api key
  apiKey: 'skAHV4mOEhz2zYQcG_5l4BkhsCzmtYTU8VGOi8Y40zo',

  // Ports
  clientPort: 8000,
  serverPort: 9000,
  fusionAuthPort: 9011
};
</code></pre></div></div>

<p>Within the <code>./server</code> directory, create a new <a href="https://expressjs.com/">Express</a> app and install the <a href="https://www.npmjs.com/package/cors">cors</a>, <a href="https://www.npmjs.com/package/express-session">session</a> and <a href="https://www.npmjs.com/package/request">request</a> packages.</p>

<div><div><pre><code>npm init
<span># Complete all the questions as appropriate</span>
npm <span>install </span>express cors express-session request <span>--save</span>
</code></pre></div></div>

<p>Next, open up your <code>package.json</code> file and add a <code>"start"</code> script:</p>

<div><div><pre><code><span>//</span><span> </span><span>...</span><span>
</span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span>
  </span><span>"start"</span><span>:</span><span> </span><span>"node index.js"</span><span>
</span><span>}</span><span>,</span><span>
</span><span>//</span><span> </span><span>...</span><span>
</span></code></pre></div></div>

<p>Finally, create a new file in the <code>./server</code> directory called <code>index.js</code> that will initialize your Express app:</p>

<div><div><pre><code><span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>session</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express-session</span><span>'</span><span>);</span>
<span>const</span> <span>cors</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>cors</span><span>'</span><span>);</span>
<span>const</span> <span>config</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../config</span><span>'</span><span>);</span>

<span>// configure Express app and install the JSON middleware for parsing JSON bodies</span>
<span>const</span> <span>app</span> <span>=</span> <span>express</span><span>();</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>express</span><span>.</span><span>json</span><span>());</span>

<span>// configure sessions</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>session</span><span>(</span>
  <span>{</span>
    <span>secret</span><span>:</span> <span>'</span><span>1234567890</span><span>'</span><span>,</span>
    <span>resave</span><span>:</span> <span>false</span><span>,</span>
    <span>saveUninitialized</span><span>:</span> <span>false</span><span>,</span>
    <span>cookie</span><span>:</span> <span>{</span>
      <span>secure</span><span>:</span> <span>'</span><span>auto</span><span>'</span><span>,</span>
      <span>httpOnly</span><span>:</span> <span>true</span><span>,</span>
      <span>maxAge</span><span>:</span> <span>3600000</span>
    <span>}</span>
  <span>})</span>
<span>);</span>

<span>// configure CORS</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>cors</span><span>(</span>
  <span>{</span>
    <span>origin</span><span>:</span> <span>true</span><span>,</span>
    <span>credentials</span><span>:</span> <span>true</span>
  <span>})</span>
<span>);</span>

<span>// use routes</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/user</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./routes/user</span><span>'</span><span>));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/login</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./routes/login</span><span>'</span><span>));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/oauth-callback</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./routes/oauth-callback</span><span>'</span><span>));</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/logout</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./routes/logout</span><span>'</span><span>));</span>

<span>// start server</span>
<span>app</span><span>.</span><span>listen</span><span>(</span><span>config</span><span>.</span><span>serverPort</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>`FusionAuth example app listening on port </span><span>${</span><span>config</span><span>.</span><span>serverPort</span><span>}</span><span>.`</span><span>));</span>
</code></pre></div></div>

<p>In the following sections, you’ll create the route files listed in the code above.</p>

<h3 id="creating-the-login-route">Creating the login route</h3>
<p>To generate a login URL, your application will need to create a PKCE verifier and challenge. It will send the challenge to FusionAuth via query string parameters along with your client ID and a redirect URL.</p>

<p>Using PKCE adds an additional layer of security, as it is a one time use and guarantees that the Node application that generated the challenge is the same one that sent the verifier. Normally, PKCE is used where the client cannot keep a secret, such as a single page application.</p>

<p>To generate a <a href="https://www.oauth.com/oauth2-servers/pkce/">PKCE challenge and verifier</a>, you’ll need to use some of the <a href="https://nodejs.org/api/crypto.html">Node crypto functions</a>. Create a new folder in the <code>./server</code> directory called <code>helpers</code>. Add a new file called <code>pkce.js</code> to the folder. You will generate a verifier and challenge in this file:</p>

<div><div><pre><code><span>const</span> <span>crypto</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>crypto</span><span>'</span><span>);</span>

<span>function</span> <span>base64URLEncode</span><span>(</span><span>str</span><span>)</span> <span>{</span>
  <span>return</span> <span>str</span>
    <span>.</span><span>toString</span><span>(</span><span>"</span><span>base64</span><span>"</span><span>)</span>
    <span>.</span><span>replace</span><span>(</span><span>/</span><span>\+</span><span>/g</span><span>,</span> <span>"</span><span>-</span><span>"</span><span>)</span>
    <span>.</span><span>replace</span><span>(</span><span>/</span><span>\/</span><span>/g</span><span>,</span> <span>"</span><span>_</span><span>"</span><span>)</span>
    <span>.</span><span>replace</span><span>(</span><span>/=/g</span><span>,</span> <span>""</span><span>)</span>
<span>}</span>

<span>function</span> <span>sha256</span><span>(</span><span>buffer</span><span>)</span> <span>{</span>
  <span>return</span> <span>crypto</span><span>.</span><span>createHash</span><span>(</span><span>"</span><span>sha256</span><span>"</span><span>).</span><span>update</span><span>(</span><span>buffer</span><span>).</span><span>digest</span><span>()</span>
<span>}</span>

<span>module</span><span>.</span><span>exports</span><span>.</span><span>generateVerifier</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>base64URLEncode</span><span>(</span><span>crypto</span><span>.</span><span>randomBytes</span><span>(</span><span>32</span><span>))</span>
<span>}</span>

<span>module</span><span>.</span><span>exports</span><span>.</span><span>generateChallenge</span> <span>=</span> <span>(</span><span>verifier</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>base64URLEncode</span><span>(</span><span>sha256</span><span>(</span><span>verifier</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>The two exported functions, <code>generateVerifier</code> and <code>generateChallenge</code>, will be used in your login route to create a PKCE verifier. Create a new directory called <code>routes</code> in your <code>./server</code> directory and add a new file called <code>login.js</code> to it:</p>

<div><div><pre><code><span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>router</span> <span>=</span> <span>express</span><span>.</span><span>Router</span><span>();</span>
<span>const</span> <span>config</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../../config</span><span>'</span><span>);</span>
<span>const</span> <span>pkce</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../helpers/pkce</span><span>'</span><span>);</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/</span><span>'</span><span>,</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>// Generate and store the PKCE verifier</span>
  <span>req</span><span>.</span><span>session</span><span>.</span><span>verifier</span> <span>=</span> <span>pkce</span><span>.</span><span>generateVerifier</span><span>();</span>

  <span>// Generate the PKCE challenge</span>
  <span>const</span> <span>challenge</span> <span>=</span> <span>pkce</span><span>.</span><span>generateChallenge</span><span>(</span><span>req</span><span>.</span><span>session</span><span>.</span><span>verifier</span><span>);</span>

  <span>// Redirect the user to log in via FusionAuth</span>
  <span>res</span><span>.</span><span>redirect</span><span>(</span><span>`http://localhost:</span><span>${</span><span>config</span><span>.</span><span>fusionAuthPort</span><span>}</span><span>/oauth2/authorize?`</span><span>+</span>
    <span>`client_id=</span><span>${</span><span>config</span><span>.</span><span>clientID</span><span>}</span><span>&amp;redirect_uri=</span><span>${</span><span>config</span><span>.</span><span>redirectURI</span><span>}</span><span>&amp;response_type=code`</span><span>+</span>
    <span>`&amp;code_challenge=</span><span>${</span><span>challenge</span><span>}</span><span>&amp;code_challenge_method=S256`</span><span>);</span>
<span>});</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>router</span><span>;</span>
</code></pre></div></div>

<p>Now when users visit <code>localhost:9000/login</code> the Node app will generate a PKCE verifier and challenge, save the verifier to session storage, and redirect the user to FusionAuth with the challenge in the URL. The FusionAuth app will store this challenge and make sure that the verifier sent in the OAuth callback is valid.</p>

<h3 id="creating-the-oauth-callback">Creating the OAuth callback</h3>
<p>Once the user has entered their username and password, the FusionAuth server will check their credentials and redirect them to your Node app’s OAuth callback endpoint with an authorization code. Your app will use that code and the PKCE verifier generated in the previous step to request a <a href="https://fusionauth.io/docs/v1/tech/oauth/tokens">long-lived access token</a>.</p>

<p>Again, adding PKCE adds another layer of security by proving that the entity which sent the challenge is now requesting an access token. Your Node app will store the access token returned by FusionAuth in session storage and redirect the user to the Gatsby profile page we’ll create in the next step.</p>

<p>Create a new route called <code>oauth-callback.js</code> and add the following:</p>

<div><div><pre><code><span>const</span> <span>express</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>express</span><span>'</span><span>);</span>
<span>const</span> <span>router</span> <span>=</span> <span>express</span><span>.</span><span>Router</span><span>();</span>
<span>const</span> <span>request</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>request</span><span>'</span><span>);</span>
<span>const</span> <span>config</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../../config</span><span>'</span><span>);</span>

<span>router</span><span>.</span><span>get</span><span>(</span><span>'</span><span>/</span><span>'</span><span>,</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>request</span><span>(</span>
    <span>// POST request to /token endpoint</span>
    <span>{</span>
      <span>method</span><span>:</span> <span>'</span><span>POST</span><span>'</span><span>,</span>
      <span>uri</span><span>:</span> <span>`http://localhost:</span><span>${</span><span>config</span><span>.</span><span>fusionAuthPort</span><span>}</span><span>/oauth2/token`</span><span>,</span>
      <span>form</span><span>:</span> <span>{</span>
        <span>'</span><span>client_id</span><span>'</span><span>:</span> <span>config</span><span>.</span><span>clientID</span><span>,</span>
        <span>'</span><span>client_secret</span><span>'</span><span>:</span> <span>config</span><span>.</span><span>clientSecret</span><span>,</span>
        <span>'</span><span>code</span><span>'</span><span>:</span> <span>req</span><span>.</span><span>query</span><span>.</span><span>code</span><span>,</span>
        <span>'</span><span>code_verifier</span><span>'</span><span>:</span> <span>req</span><span>.</span><span>session</span><span>.</span><span>verifier</span><span>,</span>
        <span>'</span><span>grant_type</span><span>'</span><span>:</span> <span>'</span><span>authorization_code</span><span>'</span><span>,</span>
        <span>'</span><span>redirect_uri</span><span>'</span><span>:</span> <span>config</span><span>.</span><span>redirectURI</span>
      <span>}</span>
    <span>},</span>

    <span>// callback</span>
    <span>(</span><span>error</span><span>,</span> <span>response</span><span>,</span> <span>body</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>// save token to session</span>
      <span>req</span><span>.</span><span>session</span><span>.</span><span>token</span> <span>=</span> <span>JSON</span><span>.</span><span>parse</span><span>(</span><span>body</span><span>).</span><span>access_token</span><span>;</span>

      <span>// redirect to Gatsby</span>
      <span>res</span><span>.</span><span>redirect</span><span>(</span><span>`http://localhost:</span><span>${</span><span>config</span><span>.</span><span>clientPort</span><span>}</span><span>/profile`</span><span>);</span>
    <span>}</span>
  <span>);</span>
<span>});</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>router</span><span>;</span>
</code></pre></div></div>

<p>Your app now authenticates users and stores their access tokens in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site">https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/blog/2020/06/25/using-oauth-and-pkce-to-add-authentication-to-your-gatsby-site</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642003</guid>
            <pubDate>Thu, 25 Jun 2020 15:46:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2Ton Digital – Modern tools written in Assembly language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641887">thread link</a>) | @smartmic
<br/>
June 25, 2020 | https://2ton.com.au/Products/ | <a href="https://web.archive.org/web/*/https://2ton.com.au/Products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="lf-main">
<p>
	The standalone binaries here are subject to the same GPLv3 license that the <a href="https://2ton.com.au/HeavyThing/">HeavyThing library</a> itself is, and are provided as conveniences only so that downloading the entire library is not required. See the file <code>LICENSE</code> in the library distribution for further details.
</p>
<ul>
		<li><a href="https://2ton.com.au/HeavyThing/">HeavyThing</a> - x86_64 assembly language library that is the heart of 2 Ton Digital.
			
		</li>
		<li><a href="https://2ton.com.au/rwasa/">rwasa</a> - full featured web server that eclipses nginx.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/rwasa">rwasa</a><br>
			SHA256: a5f3ad1da5aac8051f31b62c9c27f953ac0a01642bae1e07d3af74c7f261163b<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/toplip/">toplip</a> - command line very strong encryption utility.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/toplip">toplip</a><br>
			SHA256: 9ea8978b9d59b2450bb1103972a0869b79622cdc0080d02b846e37abb27c33c4<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/sshtalk/">sshtalk</a> - ephemeral multi-person SSH chat.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/sshtalk">sshtalk</a><br>
			SHA256: bdbe7f4ec2f1e18148a913825fdc35b6c3ab5ce41999ba815969fe7b49d606a5<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/dhtool/">dhtool</a> - Diffie-Hellman parameter generator/verifier/converter.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/dhtool">dhtool</a><br>
			SHA256: 607d7e6241554651e7f7f78b19ff144a93e66047ca7519fe63ae6546d23ec020<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/hnwatch/">hnwatch</a> - HackerNews API realtime terminal watch/reader.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/hnwatch">hnwatch</a><br>
			SHA256: 511204246d9d80339dc46b3bea4ef0f4114216e1ab4c13695cee5467f5685ff1<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
		<li><a href="https://2ton.com.au/webslap/">webslap</a> - website quality assurance reporting tool.
			<p>
			Standalone binary download: <a href="https://2ton.com.au/standalone_binaries/webslap">webslap</a><br>
			SHA256: 45d811ed2c3a7c9e5143d3bcabb0a71ce8ca1946c2d11a8b442c6d1520f14aab<br>
			Source code: included with the HeavyThing library itself.
			</p>
		</li>
	</ul>


					</div></div>]]>
            </description>
            <link>https://2ton.com.au/Products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641887</guid>
            <pubDate>Thu, 25 Jun 2020 15:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Critical Considerations for a Return to the Office]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641857">thread link</a>) | @Gpetrium
<br/>
June 25, 2020 | https://gpetrium.com/critical-considerations-for-a-return-to-the-office/ | <a href="https://web.archive.org/web/*/https://gpetrium.com/critical-considerations-for-a-return-to-the-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="2842" data-elementor-settings="[]"><div><div><section data-id="39d49db" data-element_type="section"></section><section data-id="ec8fe89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_bottom&quot;:&quot;opacity-tilt&quot;}"><div><div><div data-id="c9e3186" data-element_type="column"><div><div><div data-id="572a9ee" data-element_type="widget" data-widget_type="image.default"><div><p><img width="1280" height="720" src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?fit=1280%2C720&amp;ssl=1" data-src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?fit=1280%2C720&amp;ssl=1" alt="" data-srcset="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?w=1280&amp;ssl=1 1280w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?resize=300%2C169&amp;ssl=1 300w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?resize=768%2C432&amp;ssl=1 768w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/cog-wheels-2125169_1280-min.jpg?resize=600%2C338&amp;ssl=1 600w" data-sizes="(max-width: 750px) 100vw, 750px"></p></div></div></div></div></div></div></div></section><section data-id="f267f03" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="699a2dc" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="767dab9" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="d033f7a" data-element_type="column"><div><div><div data-id="c4b6e30" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Amidst the pandemic, the world has had to cope with drastic changes in work related policies. A few organizations have even experienced a permanent move towards work from home (WFH) practices. While many are satisfied with the change for different reasons, others can’t seem to wait to get back to the way that work used to be. At this time, employers have to contend to the short and long-term ramifications of new working conditions and its impacts to productivity, communication, culture, cybersecurity and several other issues that have emerged as a result.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As considerations are made, organizations will need to take a holistic approach to ensure a successful transition to a new normal. Below are some of the key areas that leadership has to work with as it builds and implements a return to the office plan.</p></div></div></div><div data-id="4a9e017" data-element_type="widget" data-widget_type="heading.default"><p><h2>Legal &amp; Regulatory Compliance</h2></p></div><div data-id="3019c57" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There have been multiple public authorities at the federal, state/ provincial and municipal levels that have enacted policies to curb the spread of the pandemic and support all pillars of society. As usual, it falls onto the laps of leadership to ensure that their organization remains in compliance with said laws.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As the legal environment changes internationally and nationally, organizations have to consider the legal and financial implications of adopting and complying to new policies. Further deliberation regarding the safety of the workforce need to be taken into account. At this time, companies need to be proactive by revisiting internal policies such as Health and Safety policies, WFH policies, Code of Conduct policies, and Cybersecurity policies. As such, it is essential that senior executives work in tandem with officers on the ground to understand the current atmosphere of their organization, its impact on policies and expectations, as well as ensure that enacted policies reach their desired outcomes.</p></div></div></div><div data-id="7c67953" data-element_type="widget" data-widget_type="image.default"><div><p><img width="360" height="240" src="https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=360%2C240&amp;ssl=1" data-src="https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=360%2C240&amp;ssl=1" alt="" data-srcset="https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?w=1280&amp;ssl=1 1280w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=300%2C199&amp;ssl=1 300w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=1024%2C680&amp;ssl=1 1024w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=768%2C510&amp;ssl=1 768w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=360%2C240&amp;ssl=1 360w, https://i0.wp.com/gpetrium.com/wp-content/uploads/2020/06/hands-4917949_1280-min.jpg?resize=600%2C398&amp;ssl=1 600w" data-sizes="(max-width: 360px) 100vw, 360px"></p></div></div><div data-id="651f2b8" data-element_type="widget" data-widget_type="heading.default"><p><h2>Sanitary and Hygiene Practices</h2></p></div><div data-id="24e74cd" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In an office environment, organizations have to consider how and whether to shoulder the costs of PPE supplies and training for its employees and customers. If that is not an option, leaders have to contend with personally owned PPE which may be inadequate or non-existent. This may pose unintended consequences that may challenge return to the office efforts and increase customer and employee exposure, potentially leading to disruptions in operations. (<span><a href="https://www.nytimes.com/2020/05/19/technology/amazon-coronavirus-workers.html">‘Way Too Late’: Inside Amazon’s Biggest Outbreak</a></span>, NY Times).</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Good personal hygiene such as hand washing and social distancing remains a major part of the fight against COVID-19. To ensure good office practices and training, well positioned pamphlets, workshops, adequate infrastructure, supporting policies, and a culture of cleanliness are just a few of the major drivers of change.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Office cleanliness will remain a priority to both the organization and employees. Even if it is believed that employees are following sanitary and hygiene practices, the organization will likely need to increase the rate of commercial cleaning services throughout its establishment.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In a pandemic environment, sanitary and hygiene practices are not isolated factors that are bound to stay within the secrecy of a company. For example, a <span><a href="https://www.cbsnews.com/news/coronavirus-in-germany-meat-packing-plant-covid-19-outbreak-cases-r-reproduction-rate-up-today-2020-06-22/">single meat packing plant in Germany</a></span> is believed to be behind over 1,000 confirmed cases. Even in optimal conditions, outbreaks of this nature can have a direct impact on society, economic recovery, organizational operations and even raise risks to brand value.</p></div></div></div><div data-id="b6a4e69" data-element_type="widget" data-widget_type="heading.default"><p><h2>Shared Space and Common Area Policies</h2></p></div><div data-id="6fae723" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Prior to the pandemic, many organizations have moved their offices to shared work spaces and common areas within offices such as water coolers, cafeteria or entertainment rooms, were seen as standard infrastructure. Nowadays, there are concerns that these areas will often involve interactions in close proximity, which can further exacerbate pandemic related risks.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To lower said risks, organizations need to consider implementing physical distancing and hygiene measures and protocols. At this time, many governmental bodies have stipulated guidelines that can be used to support organizational procedures and help organizations navigate through the reopening of their workplace. The <span><a href="https://covid19.ca.gov/industry-guidance/">State of California</a></span>, <span><a href="https://www1.nyc.gov/site/doh/covid/covid-19-businesses-and-facilities.page">New York City</a></span>, and the <span><a href="https://www.toronto.ca/home/covid-19/covid-19-protect-yourself-others/community-settings-workplaces/">City of Toronto</a></span> are just a few examples of such guidelines being extended to organizations. It is important to follow local guidelines, but whenever possible, borrow additional innovative takes from other jurisdictions.</p></div></div></div><div data-id="776149d" data-element_type="widget" data-widget_type="heading.default"><p><h2>Back to the Office Employee Prioritization</h2></p></div><div data-id="16083af" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Teams or roles that demand a higher amount of physical interaction and can’t perform their duties well via online means should be considered as front-runners of back to the office policies. Simultaneously, leaders should critically assess if individuals whose roles are well suited for remote working, should only make the return to the office at the later phase of the pandemic reopening. Such efforts can help reduce health risks to employees and customers.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The IT department for example, may return back to the office on a rotational basis or in batches (team by team). Employees involved in the preparation and maintenance of physical technology (e.g. servers and hardware support) are likely to be prioritized while most of the software cast may be held back to later phases since their work may be accomplished remotely.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As leadership determines how to prioritize the return to the office, there are a few questions that should always be asked:</p><ul><li>Are there feasible technological or procedural options that can be taken to limit X role’s exposure? If so, would their work be impacted and how?</li><li>How big of a priority would it be to bring certain individuals back to the office under these circumstances?</li><li>Would the solution help potential future disruptions such as a 2<sup>nd</sup> COVID-19 wave?”</li></ul></div></div></div><div data-id="94b69f1" data-element_type="widget" data-widget_type="text-editor.default"><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Meeting rooms can follow similar protocols stipulated to shared spaces and common areas, given the limited square footage that such spaces traditionally have which can make it harder to enforce distancing rules and lead to an <span><a href="https://www.cebm.net/covid-19/what-is-the-evidence-to-support-the-2-metre-social-distancing-rule-to-reduce-covid-19-transmission/">increased risk of transmission</a></span>. In said cases, organizations may benefit from setting a threshold on the number of employees permitted per meeting and the distances that are expected. Office administrators may want to set delimitators such as a sign to stipulate social distancing and remove excess chairs to help set the precedent. Reminder mechanisms such as pamphlets to clean spaces before and once they have been used can also beneficial.</p></div></div><div data-id="40674cf" data-element_type="widget" data-widget_type="heading.default"><p><h2>Rotational Work Schedules</h2></p></div><div data-id="0e4000c" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To diminish contact, some organizations may benefit from building rotational work schedules where a department or group alternates every couple of weeks. This can help set better social distancing in offices that do not have the capacity to handle prior numbers of employees and clients. Some organizations have already started a two week in office and off office rotation, in which the workforce is divided into 2 groups (or more) which rotate the office space – as seen in the case of <span><a href="https://webstercity.com/2020/03/24/city-staff-to-rotate-on-shifts-in-response-to-covid-19/">Webster City</a></span>, Iowa.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It also allows teams to regain some of the interactions and experience that the office can provide while still having work from home flexibility. Organizations may find this to be the right mix of home comfort and office experience. Once COVID-19 related issues subside, organizations may find further operational efficiency in having a mixed policy, allowing it to move into smaller offices with lower costs.</p></div></div></div><div data-id="4111b59" data-element_type="widget" data-widget_type="image.default"><div><p><img width="360" height="240" src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?resize=360%2C240&amp;ssl=1" data-src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?resize=360%2C240&amp;ssl=1" alt="" data-srcset="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?resize=360%2C240&amp;ssl=1 360w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?zoom=2&amp;resize=360%2C240&amp;ssl=1 720w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/06/rattan-5330786_1280-min.jpg?zoom=3&amp;resize=360%2C240&amp;ssl=1 1080w" data-sizes="(max-width: 360px) 100vw, 360px"></p></div></div><div data-id="547cd1e" data-element_type="widget" data-widget_type="text-editor.default"><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Currently, most offices are not set-up to accommodate for COVID-19 related concerns such as social distancing. As organization decide when and who may return to the office, considerations over closed workspace, socially distanced offices, signs, contactless technology can be major drivers in helping leaders implement an employee first and health-driven culture.</p></div></div><div data-id="c8cf2f0" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The pandemic has shown that family and individuals can be impacted differently. To ensure a smooth transition back to the office, organizations may benefit from having structure, policies and procedures to handle exceptions. For instance, employees with children or elderly parents at home may have a difficult time procuring the necessary resources to support their needs. At times like these, the organization may benefit from giving the employee an extended work from home period where viable.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Clients may also prefer to have the option to attend meetings and consultations online. There is a fine balance between organizational, employee, and customer needs. Considerations over the complexity of exception handling should also be taken into account. Critical assessment of said implications and needs can help improve employee and customer satisfaction in the short run while also providing much needed experience on how to handle operational challenges that are bound to occur (crisis handling).</p></div></div></div><div data-id="8c003e6" data-element_type="widget" data-widget_type="heading.default"><p><h2>Clear, Open and Continuous Communication</h2></p></div><div data-id="5470e56" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In periods with trials and tribulations, society looks for leaders to guide them through rough patches. For an organization, employees and customers are actively looking for cues to understand its trajectory and how it will impact them.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; At this time, discrepancies in individual habits in relation to work from home and back to office may be front-center in a manager’s mind. Whether it is employee tardiness, commute, productivity, organizational networks and others, readjustment will take time and requires guidance. For that to happen, leaders will need to maintain a transparent, open and continuous communication to help clarify and facilitate solutions for issues that arise.</p></div></div></div><div data-id="ab5c68a" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Transitional periods can be challenging to many and will often lead to resistances. To ensure a smooth transition back to the office, it is important to note the origins of said challenges. At its base, resistance will often involve at least one of the following:</p><p>1) An uncomfortable level of …</p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gpetrium.com/critical-considerations-for-a-return-to-the-office/">https://gpetrium.com/critical-considerations-for-a-return-to-the-office/</a></em></p>]]>
            </description>
            <link>https://gpetrium.com/critical-considerations-for-a-return-to-the-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641857</guid>
            <pubDate>Thu, 25 Jun 2020 15:34:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BLEU Score: Bilingual Evaluation Understudy]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23641791">thread link</a>) | @keyboardman
<br/>
June 25, 2020 | https://leimao.github.io/blog/BLEU-Score/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/BLEU-Score/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>BLEU is a standard algorithm for evaluating the machine translations against the human translations. At first I thought it should be very straightforward to use. However, it turns out that there are a lot of caveats.</p>



<p>In this blog post, I am going to show the BLEU algorithm in detail and talk about the caveats.</p>

<h3 id="english-translation-example">English Translation Example</h3>

<p>We will use the following examples to illustrate how to compute the BLEU scores.</p>

<h4 id="example-1">Example 1</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the cat the cat on the mat</p>

<h4 id="example-2">Example 2</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the the the the the the the the</p>

<h3 id="precision">Precision</h3>

<p>We count each of the ngram in the candidate sentence whether it has shown in any of the reference sentences, gather the total counts for each of the unique ngram, sum up the total counts for each of the unique ngram, and divided by the number of ngrams in the candidate sentence.</p>

<h4 id="example-1-1">Example 1</h4>

<p>We first compute the unigram precision for example 1. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 7, and the total number of unigrams in the candidate sentence is 7. The unigram precision is 7/7 = 1.0 for example 1.</p>



<p>We then try to compute the bigram precision for example 1.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 5, and the total number of bigrams in the candidate sentence is 6. The bigram precision is 5/6 = 0.833 for example 1.</p>

<h4 id="example-2-1">Example 2</h4>

<p>We first compute the unigram precision for example 2. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 8, and the total number of unigrams in the candidate sentence is 8. The unigram precision is 8/8 = 1.0 for example 2.</p>



<p>We then try to compute the bigram precision for example 2.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="drawbacks">Drawbacks</h4>

<p>We can see from example 1 and 2 that unigram precision is very easy to be over-confident about the quality of the machine translation. To overcome this, clipped count and modified precision were proposed.</p>

<h3 id="modified-precision">Modified Precision</h3>

<p>For each unique ngram, we count its maximum frequency in each of the reference sentences. The minimum of this special count and the original count is called the clipped the count. That is to say, the clipped count is no greater than the original count. We then use this clipped count, in place of the original count, for computing the modified precision.</p>

<h4 id="example-1-2">Example 1</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique unigrams in the candidate sentence is 5, and the total number of unigrams in the candidate sentence is 7. The unigram modified precision is 5/7 = 0.714 for example 1.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 4, and the total number of unigrams in the candidate sentence is 6. The bigram modified precision is 4/6 = 0.667 for example 1.</p>

<h4 id="example-2-2">Example 2</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
    <td>2</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of unigrams in the candidate sentence is 8. The unigram modified precision is 2/8 = 0.25 for example 2.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="advantages">Advantages</h4>

<p>Compared to precision, we found that modified precision is a better metric, at least for unigrams.</p>

<h3 id="bleu">BLEU</h3>

<h4 id="algorithm">Algorithm</h4>

<p>BLEU is computed using a couple of ngram modified precisions. Specifically,</p>



<p>where $p_n$ is the modified precision for $n$gram, the base of $\log$ is the natural base $e$, $w_n$ is weight between 0 and 1 for $\log p_n$ and $\sum_{n=1}^{N} w_n = 1$, and BP is the brevity penalty to penalize short machine translations.</p>



<p>where $c$ is the number of unigrams (length) in all the candidate sentences, and $r$ is the best match lengths for each candidate sentence in the corpus. Here the best match length is the closest reference sentence length to the candidate sentences. For example, if there are three references with lengths 12, 14, and 17 words and the candidate translation is a terse 13 words, ideally the best match length could be either 12 or 14, but we arbitrary choose the shorter one which is 12.</p>



<p>Usually, the BLEU is evaluated on corpus where there are many candidate sentences translated from different source texts and each of them has several reference sentences. Then $c$ is the total number of unigrams (length) in all the candidate sentences, and $r$ is the sum of the best match lengths for each candidate sentence in the corpus.</p>



<p>It is not hard to find that BLEU is always a value between 0 and 1. It is because BP, $w_n$, and $p_n$ are always between 0 and 1, and</p>



<p>Usually, BLEU uses $N = 4$ and $w_n = \frac{1}{N}$.</p>

<h4 id="example-1-3">Example 1</h4>

<p>We have computed the modified precision for some of the ngrams. It is not hard to compute the others. Concretely, we have</p>





<p>Because the corpus only has one translation set and thus $c = 7$ and $r = 7$</p>



<p>We plugin these values to the BLEU equation, the BLEU is</p>



<p>We further compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the cat the cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4671379777282001</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0.467 which is exactly matching to the BLEU we computed manually.</p>

<h4 id="example-2-3">Example 2</h4>

<p>Similarly,</p>





<p>Because the corpus only has one translation set and thus $c = 8$ and $r = 7$</p>



<p>When we plugin these values to the BLEU equation, actually we would need to compute $\log 0$ which is not mathematically defined. We use a small number $10^{-100}$ instead of $0$ for $p_2$, $p_3$ and $p_4$. The BLEU is</p>



<p>We further also compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the the the the the the the the"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.2882297539194154e-231</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0 which is exactly matching to the BLEU we computed manually.</p>

<p>Note that in the above two examples, due to the candidate sentence is long and we only have one translation in the corpus, thus $\text{BP} = 1$. In practice, there could be scenarios where $\text{BP} &lt; 1$.</p>

<h3 id="caveats">Caveats</h3>

<p>In some scenarios, BLEU does not score the translation very well, especially for those short translations with few reference sentences. For example,</p>



<p>Chinese: 你准备好了吗？</p>

<p>Reference 1: are you ready ?</p>

<p>Candidate: you are ready ?</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>])</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.133422688662942e-154</span>
</code></pre></div></div>

<p>This is actually a very good machine translation to me. However, the BLEU score is 0, which means that the machine translation is totally wrong.</p>



<p>In NLTK, you are allowed to provide <a href="https://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.SmoothingFunction">smoothing functions</a>. For example,</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>],</span> <span>smoothing_function</span><span>=</span><span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>SmoothingFunction</span><span>().</span><span>method7</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4002926439114545</span>
</code></pre></div></div>

<p>This time, the value of <code>bleu</code> is 0.4, which is magically higher than the vanilla one we computed without using smoothing functions.</p>



<p>However, one should be always cautious about the smoothing function used in BLEU computation. At least we have to make sure that the BLEU scores we are comparing against are using no smoothing function or the exact same smoothing function.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.aclweb.org/anthology/P02-1040/">BLEU: a Method for Automatic Evaluation of Machine Translation</a></li>
  <li><a href="https://www.youtube.com/watch?v=DejHQYAGb7Q">BLEU - Andrew Ng</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/BLEU-Score/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641791</guid>
            <pubDate>Thu, 25 Jun 2020 15:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WWDC20: What’s Changed in Accessibility on iOS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641787">thread link</a>) | @eshtocof
<br/>
June 25, 2020 | https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b613">WWDC20</h2><h2 id="299f">Learn how accessibility has changed for the better in iOS 14</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@vhanagwal?source=post_page-----33e0f144e075----------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div><div><div><p><img src="https://miro.medium.com/max/60/1*9wSXSk7Fua06okhjIeQbtw.jpeg?q=20" width="2500" height="1031" role="presentation"></p><p><img src="https://miro.medium.com/max/5000/1*9wSXSk7Fua06okhjIeQbtw.jpeg" width="2500" height="1031" srcset="https://miro.medium.com/max/552/1*9wSXSk7Fua06okhjIeQbtw.jpeg 276w, https://miro.medium.com/max/1104/1*9wSXSk7Fua06okhjIeQbtw.jpeg 552w, https://miro.medium.com/max/1280/1*9wSXSk7Fua06okhjIeQbtw.jpeg 640w, https://miro.medium.com/max/1456/1*9wSXSk7Fua06okhjIeQbtw.jpeg 728w, https://miro.medium.com/max/1632/1*9wSXSk7Fua06okhjIeQbtw.jpeg 816w, https://miro.medium.com/max/1808/1*9wSXSk7Fua06okhjIeQbtw.jpeg 904w, https://miro.medium.com/max/1984/1*9wSXSk7Fua06okhjIeQbtw.jpeg 992w, https://miro.medium.com/max/2160/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1080w, https://miro.medium.com/max/2700/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1350w, https://miro.medium.com/max/3240/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1620w, https://miro.medium.com/max/3780/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1890w, https://miro.medium.com/max/4320/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2160w, https://miro.medium.com/max/4800/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2400w" sizes="100vw" role="presentation"></p></div></div></div></figure></div><div><div><p id="90e1">Apple has long integrated accessibility features into their software — and for good reason. By using accessibility features in your app, you’re allowing your app to reach a wider audience.</p><p id="d948">Sticking with their commitment to accessibility, Apple has introduced several new features at WWDC20 which help developers make their apps easier and more entertaining for users with disabilities. By making apps more accessible, developers eliminate the need for users to purchase clunky, expensive devices in order to use their apps — everything they need to interact with the app is built right into the device.</p><p id="df0d">In this article, you’ll learn about some of the biggest and best upgrades to accessibility, announced at this year’s WWDC.</p></div></div></section><hr><section><div><div><p id="ecb9">The first on the list is an interesting feature — which didn’t get talked about on stage. As the name suggests, Back Tap allows users to set single, double, or triple taps on the back of their iPhones and link them to certain tasks. For example, you could double tap on the back of your iPhone to open the weather app.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*-mtu69eu445jv1BwH76CoQ.jpeg?q=20" width="1200" height="732" role="presentation"></p><p><img src="https://miro.medium.com/max/2400/1*-mtu69eu445jv1BwH76CoQ.jpeg" width="1200" height="732" srcset="https://miro.medium.com/max/552/1*-mtu69eu445jv1BwH76CoQ.jpeg 276w, https://miro.medium.com/max/1104/1*-mtu69eu445jv1BwH76CoQ.jpeg 552w, https://miro.medium.com/max/1280/1*-mtu69eu445jv1BwH76CoQ.jpeg 640w, https://miro.medium.com/max/1400/1*-mtu69eu445jv1BwH76CoQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Setting up Back Tap on iOS 14.</figcaption></figure><p id="91c1">And since the tapping feature can be linked to Shortcuts, it opens up a whole range of possibilities with home automation and more! As seen in the example above, you could triple tap the back of your phone to quickly take notes, or you could use it to unlock your door when you’re about to enter the house. Easy, right?</p><p id="563c">For users with hearing impairments, Apple has added the ability to adjust sound frequencies on supported headphones. By doing this, users can now set their own preferences on what they want to hear more of and what they want to hear less of.</p><p id="dc81">The new feature also comes with pre-set profiles for specific outdoor situations, in case the user doesn’t want to manually configure the sound frequencies.</p><blockquote><p id="dba7">This new accessibility feature is designed to amplify soft sounds and adjust certain frequencies for an individual’s hearing, to help music, movies, phone calls, and podcasts sound more crisp and clear. Headphone Accommodations also supports Transparency mode on AirPods Pro, making quiet voices more audible and tuning the sounds of your environment to your hearing needs.</p><p id="8aab">— Apple Documentation</p></blockquote><p id="6a9f">Further, the new feature also supports Transparency Mode on AirPods Pro, which allows users to adjust how much of the surroundings they want to hear. If they want to amplify soft voices or listen to the environment in more detail, they now have that autonomy.</p><p id="d5d2">In the same vein, a new feature called <strong>Sound Recognition</strong> can pick up important sounds in the environment, such as Sirens, Fire Alarms, or Car Horns and alert the user of them. Through machine learning models built into the operating system, these sounds can be picked up and transmitted to the user in any way that they wish.</p></div></div></section><hr><section></section><hr><section><div><div><figure><div><div><div><div><p><img src="https://miro.medium.com/max/38/1*3WhAhhK1A2LktugVV3KGHw.png?q=20" width="700" height="1110" role="presentation"></p><p><img src="https://miro.medium.com/max/1400/1*3WhAhhK1A2LktugVV3KGHw.png" width="700" height="1110" srcset="https://miro.medium.com/max/552/1*3WhAhhK1A2LktugVV3KGHw.png 276w, https://miro.medium.com/max/1000/1*3WhAhhK1A2LktugVV3KGHw.png 500w" sizes="500px" role="presentation"></p></div></div></div></div><figcaption>Real-Time Text on the iPhone.</figcaption></figure><p id="2bf5">Group FaceTime calls have become more important than ever during the global pandemic, and Apple has added a small but important accessibility feature to them. Now, if a member of a group FaceTime call is using sign language to communicate, their video will be automatically pinned.</p><p id="ab6c">Using computer vision to detect this can be a boon to those with hearing loss, since reading sign language while the screen is moving around can be frustrating.</p><p id="43b4">In addition to this, Apple has made further improvements to its Real-Time Text feature, which is used for text based communication during phone calls. Previously, it was difficult for RTT users to multitask during phone calls, but it no longer requires the full screen.</p><p id="0458">When we think of accessibility on iOS, VoiceOver is often the first to come to mind. This year, VoiceOver received several significant updates, making it even more useful than before. If you aren’t familiar with it, VoiceOver is Apple’s screen reader, available on all platforms, including iOS, macOS, tvOS, and watchOS.</p><h2 id="ae54">VoiceOver Recognition</h2><p id="aa80">In the past, VoiceOver would require developers to adopt it inside their apps to work well on third-party apps.</p><blockquote><p id="210b">On-device intelligence recognizes key elements displayed on your screen to add VoiceOver support for app and web experiences that don’t have accessibility support built in. — Apple</p></blockquote><p id="2717">This year, Apple is tapping into their machine learning technology to semantically detect where and how to use VoiceOver on unsupported apps. This makes virtually all apps natively supported by VoiceOver and increases their accessibility for those with visual impairments.</p><h2 id="6119">Image Descriptions</h2><p id="6f0d">To make VoiceOver even more useful, Apple has used its computer vision library with <em>even more</em> machine learning to detect the contents of an image.</p><blockquote><p id="2f5f">VoiceOver reads complete-sentence descriptions of images and photos within apps and on the web. VoiceOver speaks the text it identifies within images and photos. — Apple</p></blockquote><p id="f5ed">Instead of simply stating that an image is present, VoiceOver can now provide detailed descriptions of what’s pictured in an image for more useful information to VoiceOver users. It can also detect text in an image through optical character recognition — another great way that machine learning is being used in the iOS 14 update!</p></div></div></section><hr><section><div><div><p id="d6f7">Evidently, there have been plenty of great updates at WWDC20 in accessibility, with even more that weren’t listed here. By releasing a large number of small features, Apple has made their devices more accessible than ever. And, they’ve supercharged many of their flagship accessibility solutions by coupling machine learning technology with them.</p><p id="ab7f">Be sure to <strong>smash that “clap” button</strong> as many times as you can, <strong>share this tutorial</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><hr><section><div><div><p id="08a6"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="7676"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="7977"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641787</guid>
            <pubDate>Thu, 25 Jun 2020 15:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Permacomputing]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23641719">thread link</a>) | @ibobev
<br/>
June 25, 2020 | http://viznut.fi/texts-en/permacomputing.html | <a href="https://web.archive.org/web/*/http://viznut.fi/texts-en/permacomputing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>This is a collection of random thoughts regarding the application of
permacultural ideas to the computer world.</p>

<p>Some have tried to connect these worlds before (<a href="http://wiki.c2.com/?PermaCulture">WikiWikiWeb's Permaculture
article</a>; <a href="https://en.wikipedia.org/wiki/Kent_Beck">Kent
Beck</a>'s short-lived idea of <a href="https://www.softwarequotes.com/showquotes.aspx?id=559&amp;name=Kent%20Beck">Permaprogramming</a>),
but these have mostly concentrated on enhancing software engineering
practices with some ideas from gardening. I am more interested in the aspect
of cultural and ecological permanence. That is, how to give computers a
meaningful and sustainable place in a human civilization that has a
meaningful and sustainable place in the planetary biosphere.</p>

<h2>1. Problem</h2>

<p>Over the last few hundred years of human civilization, there has been a
dramatic increase in the consumption of artificially produced energy. In the
overarching story, this is often equated with "progress".</p>

<p>In the computer world, this phenomenon gets multiplied by itself:
"progress" facilitates ever greater densities of data storage and digital
logic, thus dramatically exploding the availability of computing resources.
However, the abundance has also caused an equivalent explosion in
wastefulness, which shows in things like mindblowingly ridiculous hardware
requirements for even quite trivial tasks.</p>

<p>At the same time, computers have been failing their <a href="https://en.wikipedia.org/wiki/Computer_Lib/Dream_Machines">utopian
expectations</a>. Instead of amplifying the users' intelligence, they rather
amplify their stupidity. Instead of making it possible to scale down the
resource requirements of the material world, they have instead become a
major part of the problem. Instead of making the world more comprehensible,
they rather add to its incomprehensibility. And they often even manage to
become slower despite becoming faster.</p>

<p>In both computing and agriculture, a major issue is that problems are too
often "solved" by increasing controllability and resource use. Permaculture
takes another way, advocating methods that "let nature do the work" and thus
minimize the dependence on artificial energy input. Localness and
decentralization are also major themes in the thought.</p>

<p>What makes permacultural philosophy particularly appealing (to me) is
that it does not advocate "going back in time" despite advocating a dramatic
decrease in use of artificial energy. Instead, it trusts in human ingenunity
in finding clever hacks for turning problems into solutions, competition
into co-operation, waste into resources. Very much the same kind of creative
thinking I appreciate in computer hacking.</p>

<p>The presence of intelligent life in an ecosystem can be justified by its
strengthening effect. Ideally, humans could make ecosystems more flexible
and more resilient because of their ability to take leaps that are difficult
or impossible for "unintelligent" natural processes. The existence of
computers in a human civilization can be justified by their ability to
augment this potential.</p>

<h2>2. Physical resources</h2>

<h3>2.1. Energy</h3>

<p>Permaculture emphasizes resource-sensitivity. Computers primarily use
electricity, so to them resource-sensitivity primarily means 1) adapting to
changes in energy conditions and 2) using the available energy wisely.
Today's computers, even mobile ones, are surprisingly bad at this. This is
partially due to their legacy as "calculation factories" that are constantly
guaranteed all the resources they "need".</p>

<p>Intense non-urgent computation (such as long machine learning batches)
would take place only when a lot of surplus energy is being produced or
there is a need for electricity-to-heat conversion. This requires that the
computer is aware of the state of the surrounding energy system.</p>

<p>At times of low energy, both hardware and software would prefer to scale
down: background processes would freeze, user interfaces would become more
rudimentary, clock frequencies would decrease, unneeded processors and
memory banks would power off. At these times, people would prefer to do
something else than interact with computers.</p>

<p>It is often wise to store energy for later use. <a href="https://en.wikipedia.org/wiki/Flywheel_energy_storage">Flywheels</a>
are a potential alternative to chemical batteries. They have similar <a href="https://en.wikipedia.org/wiki/Energy_density">energy densities</a>
(MJ/kg) but require no rare-earth materials and last for decades or
centuries instead of mere years.</p>

<h3>2.2. Silicon</h3>

<p>IC fabrication requires large amounts of energy, highly refined machinery
and poisonous substances. Because of this sacrifice, the resulting
microchips should be treasured like gems or rare exotic spices. Their active
lifespans would be maximized, and they would never be reduced to their raw
materials until they are thoroughly unusable.</p>

<p>Instead of planned obsolescence, there should be planned longevity.</p>

<p>Broken devices would be repaired. If the community needs a kind of device
that does not exist, it should preferrably be built from existing components
that have fallen out of use. Chips should be designed open and flexible, so
that they can be reappropriated even for purposes they were never intended
for.</p>

<p>Complex chips should have enough redundancy and bypass mechanisms to keep
them working even after some of their internals wear out. (In a multicore
CPU, for instance, many partially functioning cores could combine into one
fully functioning one.)</p>

<p>Chips that work but whose practical use cannot be justified can find
artistic and other psychologically meaningful use. They may also be stored
away until they are needed again (especially if the fabrication quality and
the storage conditions allow for decades or centuries of "shelf life").</p>

<p>Use what is available. Even chips that do "evil" things are worth
considering if there's a landfill full of them. Crack their DRM locks,
reverse-engineer their black boxes, deconstruct their philosophies. It might
even be possible to reappropriate something like Bitcoin-mining ASICs for
something artistically interesting or even useful.</p>

<p>Minimized on-chip feature size makes it possible to do more computation
with less energy but it often also means increased fragility and shorter
lifespans. Therefore, the densest chips should be primarily used for
purposes where more computation actually yields more. (In entertainment use,
for example, a large use of resources is nothing more than a decadent
esthetic preference.)</p>

<p><a href="https://en.wikipedia.org/wiki/Unconventional_computing">Alternatives
to semiconductors</a> should be actively researched. <a href="https://www.researchgate.net/publication/328395242_Towards_fungal_computer">Living
cells</a> might be able to replace microchips in some tasks sometime in the
future.</p>

<p>Once perfectly clean ways of producing microchip equivalents have been
taken to use, the need for "junk fetishism" will probably diminish.</p>

<h3>2.3. Miscellaneous</h3>

<p>Whenever bright external light is available, displays should be able to
use it instead of competing against it with their own backlight. (See: <a href="https://en.wikipedia.org/wiki/Transflective_liquid-crystal_display">Transflective
LCD</a>)</p>

<p>Personally-owned computers are primarily for those who dedicate
themselves to the technology and thus spend considerable amounts of time
with it. Most other people would be perfectly happy with shared hardware.
Even if the culture and society embraced computers more than anything else,
requiring everyone to own one would be an overkill.</p>

<h2>3. Observation and interaction</h2>

<p>The first item in many lists of permacultural principles is "Observe and
interact." I interpret this as primarily referring to a bidirectional and
co-operative relationship with natural systems: you should not expect your
garden to be easily top-down controllable like an army unit but accept its
quirkiness and adapt to it.</p><h3>3.1. Observation</h3>

<p>Observation is among the most important human skills computers can augment.
Things that are difficult or impossible for humans to observe can be brought
within human cognitive capacity by various computational processes. Gathered
information can be visualized, slight changes and pattern deviances
emphasized, slow processes sped up, forecasts calculated. In Bill Mollison's
words, "Information is <em>the</em> critical potential resource. It becomes
a resource only when obtained and acted upon."</p>

<p>Computer systems should also make their own inner workings as observable as
possible. If the computer produces visual output, it would use a fraction of
its resources to visualize its own intro- and extrospection. A computer that
communicates with radio waves, for example, would visualize its own view of
the surrounding radio landscape.</p>

<p>Current consumer-oriented computing systems often go to ridiculous
lengths to actually prevent the user from knowing what is going on. Even
error messages have become unfashionable; many websites and apps just
pretend everything is fine even if it isn't. This kind of extreme
unobservability is a major source of technological alienation among computer
users.</p>

<p>The visualizations intended for casual and passive observation would be
pleasant and tranquil while making it easy to see the big picture and notice
the small changes. Tapping into the inborn human tendency to observe the
natural environment may be a good idea when designing visualizers. When the
user wants to observe something more closely, however, there is no limit in
how flashy, technical and "non-natural" the presentation can be, as long as
the observer prefers it that way.</p>

<h3>3.2. Yin and yang hacking</h3>

<p>Traditional computer hacking is often very "yang". A total understanding and
control of the target system is valued. Changing a system's behavior is
often an end in itself. There are predefined goals the system is pushed
towards. Optimization tends to focus on a single measurable parameter.
Finding a system's absolute limits is more important than finding its
individual strengths or essence.</p>

<p>In contrast, "yin" hacking accepts the aspects that are beyond rational
control and comprehension. Rationality gets supported by intuition. The
relationship with the system is more bidirectional, emphasizing
experimentation and observation. The "personality" that stems from
system-specific peculiarities gets more attention than the measurable specs.
It is also increasingly important to understand when to hack and when just
to observe without hacking.</p>

<p>The difference between yin and yang hacking is similar to the difference
between permaculture and …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://viznut.fi/texts-en/permacomputing.html">http://viznut.fi/texts-en/permacomputing.html</a></em></p>]]>
            </description>
            <link>http://viznut.fi/texts-en/permacomputing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641719</guid>
            <pubDate>Thu, 25 Jun 2020 15:20:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple is systematically erasing our stories]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23641646">thread link</a>) | @egocentric
<br/>
June 25, 2020 | https://www.flicktype.com/ResolutionKit/ | <a href="https://web.archive.org/web/*/https://www.flicktype.com/ResolutionKit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<h2>ResolutionKit</h2>
<p>
A framework for change.
</p>
<blockquote><p lang="en" dir="ltr">For the longest time, I've been afraid to speak up about my story with App Review, fearing I'd put my popular app at risk. I've now decided that being transparent and sharing my experience to help others is worth it, so here it goes:👇</p>— Kosta Eleftheriou (@keleftheriou) <a href="https://twitter.com/keleftheriou/status/1274356729224892416?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote> 

<p>
I admire Apple, and I believe the world is a better place because of them. As a developer, I’ve made my career on their platform and I’m grateful for it.
But I have some criticism. I’m&nbsp;<b>not</b>&nbsp;here to talk about my story, the 30% Apple developer cut, the App Review process, or to challenge any of their guidelines.
I want to talk about&nbsp;<em>transparency</em>, and <em>accountability</em>.
</p>
<p>
For far too long, developers have been discouraged from being able to share their rejection stories with the world.
"If you run to the press and trash us, it never helps", used to be the official guidance.
The risk too great for most, the fear of retribution overwhelming.
And so the stories have largely remained in the shadows, with only a few exceptions.
But there’s another, critical reason why such stories rarely see the light of day, one that hasn’t received enough attention:
</p>
<blockquote><b>Apple is systematically erasing our stories.</b></blockquote>

<p>
Unless we’re talking about your most recent submission, all communication you have <em>ever</em> sent or received through the "Resolution Center" is inaccessible to you.
Rejection notices, appeal results, anything you might want to reference to better understand previous about your product - it's all gone.
Unless you have meticulously and manually kept copies of all correspondence, what happened in the past will forever stay in the past. But why should it?
</p>
<p>
It’s not hard to see why Apple is doing this.
It <em>is</em> hard, however, to see a reason that benefits anyone but Apple.
In doing so, they gain more peace of mind, less worry about consistency and correctness in applying the public guidelines.
The appeal mechanism helps them improve, but only to the extent that Apple deems necessary.
If we ever wanted to know how well Apple is enforcing the guidelines, we have to take their word for it.
But who guards the guardians, when App Review’s accountability to the world has been intentionally reduced to the bare minimum?
</p>
<p>
Transparency is not always the solution.
We can’t expect Apple to be open about their future product plans, for example.
But when they communicate with developers, they should do so like everyone is watching - every time.
And to get there, the <em>possibility</em> that everyone might find out needs to always be on the table.
</p>
<p>
So Apple, please help us see App Review as a reliable ally.
Let us access our past communications with you - including phone call records if we choose to.
Show us that you want to be accountable for what you communicate to developers. There may be some legal challenges, but transparency is a prerequisite to accountability.
It’s only then that we can begin to have a fair and honest discussion with you about the actual process and guidelines.
Because until then, we’re in the shadows.
</p>
<p>
<a href="https://www.change.org/p/apple-let-us-browse-all-our-past-resolution-center-communications">Sign the petition</a>
</p>
<p>
⌚️<i>Thursday, 25 June 2020</i>
</p>
</div>
</div>
<div>
<h2>Are you a developer?</h2>
<p>
<a href="https://twitter.com/keleftheriou">Reach out</a> and share your story with <a href="mailto:kostas.eleftheriou@gmail.com">me</a>.
</p>
<h2>✌️</h2>
</div>
</div></div>]]>
            </description>
            <link>https://www.flicktype.com/ResolutionKit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641646</guid>
            <pubDate>Thu, 25 Jun 2020 15:13:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gloo API Gateway v1.4 – Kubernetes Ingress, Istio 1.6, MOAR Helm Values and]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641631">thread link</a>) | @cloudytoday
<br/>
June 25, 2020 | https://www.solo.io/blog/introducing-gloo-1-4-enhanced-scalability-kubernetes-ingress-and-istio-1-6-support-and-dev-to-ops-experience/ | <a href="https://web.archive.org/web/*/https://www.solo.io/blog/introducing-gloo-1-4-enhanced-scalability-kubernetes-ingress-and-istio-1-6-support-and-dev-to-ops-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-1024x230.png" data-src="https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-1024x230.png" alt="" width="1024" height="230" data-srcset="https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-1024x230.png 1024w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-768x172.png 768w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4.png 1320w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-1024x230.png 1024w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4-768x172.png 768w, https://www.solo.io/wp-content/uploads/2020/06/Hero_gloo-1.4.png 1320w"></p><p><span>Today we released version 1.4 of </span><a href="https://www.solo.io/products/gloo/"><span>Gloo, our Envoy Proxy based API Gateway</span></a><span>. In the past few months since our </span><a href="https://www.solo.io/blog/announcing-gloo-1-3-developer-portal-extensibility-performance-and-usability/"><span>1.3 release</span></a><span>, we have been working with our end users and customers to deliver new functionality and enhance existing features to address a wider range of use cases. This release includes an update to both the open source and enterprise versions of Gloo.</span></p><p><b>Highlights of the release include:</b></p><ul><li><span>Improvements to system scalability</span></li><li><span>Expanded support for Kubernetes Ingress&nbsp;</span></li><li><span>Support for the latest Istio 1.6 release</span></li><li>Security enhancements</li><li><span>User experience enhancements for Dev and Ops</span></li><li><span>Plus more options for configuring Gloo&nbsp;</span></li></ul><p><span>Join us for a webinar on </span><b>July 16th</b><span> to learn more about this latest release, get a deep dive into the features and demos – </span><a href="https://solo.zoom.us/webinar/register/WN_1w-yxlabQD6L9GkzP01eww"><span>Register today to save your seat.</span></a><span> Meanwhile, keep reading to get an overview of the new release.</span></p><h2><span>Improvements to System Scalability&nbsp;</span></h2><p><span>In this release we’ve made updates to improve the scalability of Gloo including managing multiple data planes with the </span><a href="https://github.com/solo-io/gloo/issues/2257"><span>ability set granular per gateway level external authentication and rate limiting policies</span></a><span> along with improved status reporting between the multiple instances, and the </span><span>ability to use </span><a href="https://github.com/solo-io/gloo/issues/3047"><span>multiple instances of Gloo to partition Ingress objects</span></a><span> within a single cluster.</span></p><h2><span>Expanded Support for the Kubernetes Ingress&nbsp;</span></h2><p><span>In addition to API Gateway, Gloo can be deployed as a Kubernetes Ingress Controller and in this release we’ve added configuration options including</span> <a href="https://github.com/solo-io/gloo/issues/3050"><span>support for named ports on Kubernetes Ingress </span></a><span>objects, ability to use </span><a href="https://github.com/solo-io/gloo/issues/3047"><span>multiple Gloo controllers to partition Ingress objects</span></a><span> within a single cluster using the customIngressClass variable to the Gloo Helm Chart, and a </span><a href="https://github.com/solo-io/gloo/issues/3051"><span>fix to keep the&nbsp; Ingress Controller</span></a><span> (ingress pod) processing Ingress updates even when a Ingress backend is incorrectly referencing a service port.&nbsp;</span></p><h2><span>Support for Istio 1.6&nbsp;</span></h2><p><span>Gloo seamlessly integrates with service mesh environments and provides mTLS between the ingress traffic to the rest of the cluster. In this release, Gloo has been tested and validated to work with the latest </span><a href="https://istio.io/latest/"><span>Istio 1.6</span></a><span> release. Additionally, </span><a href="https://github.com/solo-io/gloo/issues/2703"><span>Gloo now supports ALPN on the upstream</span></a><span> for more granular control on defining which protocol to use and helps with the integration to the latest version of Istio. Try the Gloo and Istio integration tutorial </span><a href="https://docs.solo.io/gloo/latest/guides/integrations/service_mesh/gloo_istio_mtls/"><span>here</span></a><span>.&nbsp;</span></p><h2><span>Security Enhancements&nbsp;</span></h2><p><span>In this release we expanded security capabilities to protect the Gloo system and applications in the environment including </span><a href="https://github.com/solo-io/gloo/issues/2929"><span>supporting TLS in the external auth service</span></a><span>&nbsp; instead of through an envoy sidecar to handle the TLS termination, the addition of </span><a href="https://github.com/solo-io/gloo/issues/1525"><span>audit logs for the Modsecurity Web Application Filter</span></a><span> (WAF) as part of the access logs to assist debugging and auditing purposes, encrypted communication is now possible with </span><a href="https://github.com/solo-io/gloo/issues/2134"><span>mTLS between Gloo and Envoy instances</span></a><span> for when these components are deployed to separate environments, and an </span><a href="https://github.com/solo-io/gloo/issues/3084"><span>update to the Gloo permissions</span></a><span> reduces the surface area for risk by enabling it to run in a fully restricted Kubernetes environment.&nbsp;</span></p><h2><span>User Experience Improvements for Developers and Operations</span></h2><p><span>Across the CLI and Admin UI we’ve made a number of improvements to expand the functionality of glooctl, expand observability capabilities and error handling to resolve system issues.&nbsp;</span></p><ul><li><b>glooctl</b><b> updates include</b><span> extending the timeout period for port forwarding from 3 to 30 seconds before a</span> <a href="https://github.com/solo-io/gloo/issues/2771"><span>connection refused errors is displayed</span></a><span> improves how commands like </span><span>glooctl check</span><span> or </span><span>glooctl proxy dump</span> <span>work in high latency environments with more time to finish, the </span><a href="https://github.com/solo-io/gloo/issues/2715"><span>glooctl add route</span></a><span> command no longer creates a route table or virtual service with the</span><span> –dry-run </span><span>flag, and </span><a href="https://github.com/solo-io/gloo/issues/2581"><span>glooctl check</span><span> now uses the default namespace</span></a><span> if a specific namespace flag is not provided.</span></li><li><span>The Admin UI has</span> <a href="https://github.com/solo-io/gloo/issues/2812"><span>new tags in the Granfana dashboards</span></a><span> for Envoy and Kubernetes and supports </span><a href="https://github.com/solo-io/gloo/issues/2804"><span>additional observailiby use case</span></a><span>s with gRPC access logging service metrics.</span></li></ul><ul><li><span>Better error handling by </span><a href="https://github.com/solo-io/gloo/issues/2905"><span>logging a clear message</span></a><span> when the upstream port does not match the underlying Kubernetes service, </span><a href="https://github.com/solo-io/gloo/issues/2660"><span>report a status</span></a><span> when an upstream points to a non-existent service, and an </span><a href="https://github.com/solo-io/gloo/issues/2880"><span>update to the error message display to only show the issue </span></a><span>vs. the entire message.</span></li></ul><h2><span>Expanded Configuration Options for Gloo&nbsp;</span></h2><p><span>As a flexible control plane to Envoy Proxy, Gloo is built to support a wide range of deployment scenarios and use cases. In this release we’ve added a number of new options for the admins to customize the behavior of the Gloo environment and traffic handling.</span></p><ul><li><b>New Buffer Filter Improves Request Handling:</b> <span>Gloo now supports enabling the </span><a href="https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/http/buffer/v3/buffer.proto#extensions-filters-http-buffer-v3-buffer"><span>Envoy buffer filter</span></a><span> which buffers the entire request before routing it to the service to process the request. This is important because it helps the system understand how big the request is (in case the request size is too big), which avoids having to deal with partial requests and high network latency. </span><a href="https://github.com/solo-io/gloo/issues/2444"><span>The buffer filter can be set </span></a><span>by configuring </span><span>spec.httpGateway.options.buffer </span><span>of the desired gateway and can optionally </span><a href="https://github.com/solo-io/gloo/issues/2835"><span>configure the bytes limit on the upstream connection</span></a><span> (default is 1MiB).&nbsp;</span></li><li><b>Update to validation webhook: </b><span>Now </span><a href="https://github.com/solo-io/gloo/issues/2114"><span>validates inja compilation syntax</span></a><span> before accepting/rejecting virtual services that use transformations, allowing users to properly validate whether configurations are valid against live clusters before applying them&nbsp;</span></li><li><b>SSL Configuration Update: </b><span>Now allows for </span><span>specifying </span><a href="https://github.com/solo-io/gloo/issues/2871"><span>empty SSL configurations for clients</span></a><span> depending on the use case.</span></li><li><b>Helm Chart Updates Expand Available Settings: </b><span>They include two enhancements for Knative including the ability to </span><a href="https://github.com/solo-io/gloo/issues/2778"><span>assign a static IP to the Knative external proxy</span></a><span> and to </span><a href="https://github.com/solo-io/gloo/pull/2683"><span>override the Service type</span></a><span> as an alternative to Load Balancer for Ingress Proxy and Knative. Additionally, the nodeport numbers for the gateway proxy service can now&nbsp; </span><a href="https://github.com/solo-io/gloo/issues/2899"><span>be predefined in the values.yml</span></a><span>. We also added a </span><a href="https://github.com/solo-io/gloo/issues/3016"><span>new value to disable the validation admission webhook</span></a><span> for users who cannot use webhooks but still want to use the Gloo validation API, this value makes it more straightforward to implement.&nbsp;</span></li><li><b>Improved heading formatting:</b><span> The Envoy </span><span>core.Http1ProtocolOptions.HeaderKeyFormat</span><span> is available in the Gloo API as </span><span>httpConnectionManager.http_protocol_options.proper_case_header_key_format</span><span> which</span> <a href="https://github.com/solo-io/gloo/issues/2940"><span>formats the header by proper casing</span></a> <span>which helps with validating the headers.</span></li></ul><ul><li><b>Upstream reference by name: </b><span>This allows virtual services, route tables, and upstreams to </span><a href="https://github.com/solo-io/gloo/issues/2730"><span>refer to an upstream by name only</span></a><span>, </span><span>without causing an error. Gloo will assume the upstream namespace is the namespace of the parent resource.&nbsp;</span></li></ul><p><span>Give the latest Gloo release a try and we’d love to get your feedback in the </span><a href="https://solo-io.slack.com/"><span>community slack</span></a><span> or </span><a href="https://github.com/solo-io/gloo"><span>file an issue/PR on Github</span></a><span>. If you’re already using Gloo, get the upgrade instructions </span><a href="https://docs.solo.io/gloo/latest/operations/upgrading/1.3.0/"><span>here</span></a><span> and </span><a href="https://solo.zoom.us/webinar/register/4415867127300/WN_neq5G0eAToSGoDXUNZMMzQ"><span>register for the upcoming webinar</span></a><span> to learn more.&nbsp; </span></p></div></div></div>]]>
            </description>
            <link>https://www.solo.io/blog/introducing-gloo-1-4-enhanced-scalability-kubernetes-ingress-and-istio-1-6-support-and-dev-to-ops-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641631</guid>
            <pubDate>Thu, 25 Jun 2020 15:11:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How coding.blog JAMStack blogs became effortlessly fast]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641457">thread link</a>) | @lorean_victor
<br/>
June 25, 2020 | https://coding.blog/blog/jamstack | <a href="https://web.archive.org/web/*/https://coding.blog/blog/jamstack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="-codedoc-container"><div><p><img src="https://coding.blog/img/under-the-hood-dark.svg" alt="Banner"></p><p><img src="https://coding.blog/img/under-the-hood.svg" alt="Banner"></p></div><p>Basics of providing content over the internet are fairly straight-forward: Browsers will send requests to your
server, and your server responds with some HTML potentially linked to some JS and CSS.</p><marker><br>

</marker><p>How and when you generate those HTML, CSS and JS content is however an entirely different thing. You might want
to prepare them all in advance and have your server just serve them (pre-rendering), 
you might have your server generate them on the fly (SSR), 
or you might have your server ship some code to the browser that will then generate them (client-side rendering, SPAs). 
You might even generate requested content on the server and ship it with the code that 
would generate subsequently requested content on the browser (isomorphic).</p><marker><br>

</marker><p>There is one particular approach pretty suitable for blogs: you prepare most of the content before hand, then
serve it alongside code that would wire-in interactive bits and generate fully dynamic components. This is called
the <a href="https://jamstack.org/">JAMStack</a>, and it is the approach used by <a href="https://coding.blog/"><code>coding.blog</code></a> and
<a href="https://codedoc.cc/"><strong>CODEDOC</strong></a> for content generation. In this post, we go through the reasons we chose this
approach, and how we implemented it.</p><hr><p>To better understand why we chose <em>JAMStack</em> for <code>coding.blog</code> and how we set our further design goals, its good
to first have a general overview of methods of web content generation/delivery:</p><marker><br>

</marker><p>Pre-Rendering</p><p>Pre-rendering simply means preparing your content before-hand, i.e. in the <em>build stage</em>. This is the fastest
delivery method, and allows you to simply use a CDN instead of writing a server for serving your content.</p><div><p><img src="https://coding.blog/img/blogs/pre-rendering-dark.svg" alt="Pre-Rendering"></p><p><img src="https://coding.blog/img/blogs/pre-rendering.svg" alt="Pre-Rendering"></p></div><p>Server Side Rendering (SSR)</p><p>Instead of preparing the content, you can generate them on-the fly on your server, in response to each request.
This is perhaps useful when your content needs to change based on incoming requests, and perhaps you need to
get some data from some API to be able to create the content. However, this approach is obviously much slower
than pre-rendering.</p><div><p><img src="https://coding.blog/img/blogs/ssr-dark.svg" alt="SSR"></p><p><img src="https://coding.blog/img/blogs/ssr.svg" alt="SSR"></p></div><p>Client-Side Rendering and SPAs</p><p>Highly interactive and dynamic content means you need to generate content on the client-side. To avoid having
content-generation code in multiple places (which is hard to maintain / scale), you could instead conduct all
content generation on the client browser, having your server just ship the content generation code.</p><p>To avoid shipping the content generation code for each page of your site, you can also take control of the 
navigation on the client side, which leads to a <em>Single Page Application</em> (SPA for short). This is the basis
of all modern front-end frameworks.</p><div><p><img src="https://coding.blog/img/blogs/csr-dark.svg" alt="CSR &amp; SPA"></p><p><img src="https://coding.blog/img/blogs/csr.svg" alt="CSR &amp; SPA"></p></div><p>Client-side rendering means the user should wait extra time for being able to see the content, since typically
servers are faster at generating content. It also messes up with SEO, since crawlers might not be able to even
get the content in its full form (since they are not browsers) and so might not be able to properly index it.</p><marker><br>

</marker><p>Isomorphic Apps</p><p>To overcome these issues without spreading the content generation code in multiple places, the concept of <em>isomorphic apps</em>
was introduced. The idea is to basically run the same code both on the server and on the client, while also shipping
the code itself to the client alongside content rendered on the server.</p><div><p><img src="https://coding.blog/img/blogs/isomorphic-dark.svg" alt="Isomorphic Apps"></p><p><img src="https://coding.blog/img/blogs/isomorphic.svg" alt="Isomorphic Apps"></p></div><p>The complexity of isomorphic apps inevitably brings extra constraints and overheads. For example, you need to re-hydrate
the content on client-side, which means you are limited on how you manipulate that content (e.g. for React SSR, React needs
to maintain full control of the DOM tree). These complexities also make it harder to optimize performance since many more
components and their interactions are affecting it.</p><marker><br>

</marker><p>JAMStack Apps</p><p>Another approach would be to pre-render all your static content and then ship the code for filling in dynamic/interactive
parts to the client. This would allow for the same delivery speed of pre-rendering without sacrificing interactivity
of the content. It also implies a clear separation in the code-base as opposed to isomorphic apps: there is code that
pre-renders stuff, and there is code that goes to client and makes stuff interactive.</p><div><p><img src="https://coding.blog/img/blogs/jamstack-dark.svg" alt="JAMStack"></p><p><img src="https://coding.blog/img/blogs/jamstack.svg" alt="JAMStack"></p></div><p>The JAMStack architecture is specifically suitable for mostly static content, which makes it a perfect choice
for likes of <strong>CODEDOC</strong> (which is for documentation / guides about codes) and <code>coding.blog</code> (which is for blogs about
coding / programming). The simplicity of the workflow allows for easy optimization and high degrees of interoperability
and extensibility.</p><hr><p>While the JAMStack architecture was the most suitable for <a href="https://codedoc.cc/"><strong>CODEDOC</strong></a> and <a href="https://coding.blog/"><code>coding.blog</code></a>,
it mandates a split of content generation code into bits that are executed at build stage and bits that are
shipped to the client. This can quickly add a lot of complexity/overhead for any growing project, so we had to
find a solution that addressed this particular issue.</p><p>In other words, we needed to:</p><ul><li>have a shared component system</li><li>easily mark client-side components so that they are not pre-rendered</li><li>seamlessly where these components were to be rendered in the DOM tree</li><li>conveniently and efficiently collect and bundle the code of these clients</li><li>conveniently attach these bundles to pre-rendered content</li></ul><marker><br>

</marker><p>Additionally, we wanted a minimal toolchain and stack with maximum extensibility and interoperability. Generally
we wanted knowledge of HTML/JS/CSS to suffice for serious customization, which made a <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>-based 
syntax an optimal choice for our component system (specifically as Typescript supports it out of the box).</p><p>However, we couldn't use a library like React (or any VirtualDOM based solution) since its sensitivity to external changes to 
the DOM tree meant limitations on how the DOM is manipulated by extensions, either during pre-rendering or on the client.
Besides, we needed our content to be as light-weight as possible, which simply prohibited relatively heavy-weight
operations such as VirtualDOM diffing.</p><hr><p>To satisfy our design goals, we created a JSX-based rendering tool which directly sits on top of DOM APIs.
This is called <a href="https://github.com/CONNECT-platform/connective-html">CONNECTIVE HTML</a>, and on a basic level
is merely a wrapper of DOM APIs that allows using them via JSX:</p><pre><code tabindex="0"><span><span></span><span></span><span></span><span></span></span><p><span>1</span><span>import</span> <span>{</span> Renderer <span>}</span> <span>from</span> <span>'@connectv/html'</span><span>;</span></p><p><span>2</span></p><p><span>3</span><span>const</span> renderer <span>=</span> <span>new</span> <span>Renderer</span><span>(</span><span>)</span><span>;</span></p><p><span>4</span>renderer<span>.</span><span>render</span><span>(</span><span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>Hellow World!</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>)</span><span>.</span><span>on</span><span>(</span>document<span>.</span>body<span>)</span><span>;</span></p><br></code></pre><p>For more dynamic/reactive content, we simply added plugins to allow rendering 
<a href="https://rxjs-dev.firebaseapp.com/guide/observable">RxJS Observables</a>:</p><pre><code tabindex="0"><span><span></span><span></span><span></span><span></span></span><p><span>1</span><span>import</span> <span>{</span> Renderer <span>}</span> <span>from</span> <span>'@connectv/html'</span><span>;</span></p><p><span>2</span><span>import</span> <span>{</span> timer <span>}</span> <span>from</span> <span>'rxjs'</span><span>;</span></p><p><span>3</span></p><p><span>4</span><span>const</span> renderer <span>=</span> <span>new</span> <span>Renderer</span><span>(</span><span>)</span><span>;</span></p><p><span>5</span>renderer<span>.</span><span>render</span><span>(</span><span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>You have been here for </span><span>{</span><span>timer</span><span>(</span><span>0</span><span>,</span> <span>1000</span><span>)</span><span>}</span><span> second(s).</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>)</span></p><p><span>6</span>        <span>.</span><span>on</span><span>(</span>document<span>.</span>body<span>)</span><span>;</span></p><br></code></pre><p>This of course meant that for interactive components familiarity with <a href="https://www.learnrxjs.io/">RxJS</a> was required, 
however, you generally do require familiarity with some reactive state management library to be able to 
properly create interactive components. RxJS might not be the easiest such library for people to dive in, but
considering its widespread usage and the overall performance gain, we felt this was a compromise well worth it.</p><blockquote><p>Fun fact: Historically CONNECTIVE HTML was developed first and CODEDOC as a tool to document it. However
as a result of popularity of CODEDOC and subsequently <code>coding.blog</code>, I haven't found the time to use it 
for its original purpose yet.</p></blockquote><hr><p>To meet the remainder of our design goals, we created a tool named <a href="https://github.com/CONNECT-platform/connective-sdh">CONNECTIVE SDH</a>. 
SDH stands for <em>Static/Dynamic HTML</em>, which means this library allowed us to seamlessly create both static (pre-rendered) 
and dynamic (rendered on client-side) HTML content.</p><p>This is how CONNECTIVE SDH works:</p><marker><br>

</marker><h2 id="static-content"><span data-ignore-text=""><span data-ignore-text="">link</span></span>Static Content</h2><p>For pre-rendering (or even SSR), the fact that CONNECTIVE HTML is pretty thin meant that we could simply combine it
with <a href="https://github.com/jsdom/jsdom">JSDOM</a> and add some nice functions for storing the results:</p><pre><code tabindex="0"><span><span></span><span></span><span></span><span></span></span><p><span>1</span><span>import</span> <span>{</span> compile <span>}</span> <span>from</span> <span>'@connectv/sdh'</span><span>;</span></p><p><span>2</span></p><p><span>3</span><span>compile</span><span>(</span><span>renderer</span> <span>=&gt;</span> </p><p><span>4</span>  <span><span><span>&lt;</span>html</span><span>&gt;</span></span><span></span></p><p><span>5</span>    <span><span><span>&lt;</span>head</span><span>&gt;</span></span><span></span></p><p><span>6</span>      <span><span><span>&lt;</span>title</span><span>&gt;</span></span><span>Hellow World Example</span><span><span><span>&lt;/</span>title</span><span>&gt;</span></span><span></span></p><p><span>7</span>    <span><span><span>&lt;/</span>head</span><span>&gt;</span></span><span></span></p><p><span>8</span>    <span><span><span>&lt;</span>body</span><span>&gt;</span></span><span></span></p><p><span>9</span>      <span><span><span>&lt;</span>h1</span><span>&gt;</span></span><span>Hellow World!</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span></span></p><p><span>10</span>    <span><span><span>&lt;/</span>body</span><span>&gt;</span></span><span></span></p><p><span>11</span>  <span><span><span>&lt;/</span>html</span><span>&gt;</span></span></p><p><span>12</span><span>)</span><span>.</span><span>save</span><span>(</span><span>'dist/index.html'</span><span>)</span><span>;</span></p><br></code></pre><marker><br>

</marker><p>Or for a more <em>component oriented</em> example:</p><div><div data-tab-title="Main Code" data-tab-id="Main Code"><pre><code tabindex="0"><span><span></span><span></span><span></span><span>main.tsx</span></span><p><span>1</span><span>import</span> <span>{</span> compile <span>}</span> <span>from</span> <span>'@connectv/sdh'</span><span>;</span></p><p><span>2</span><span>import</span> <span>{</span> Card <span>}</span> <span>from</span> <span>'./card'</span><span>;</span> </p><p><span>3</span></p><p><span>4</span><span>compile</span><span>(</span><span>renderer</span> <span>=&gt;</span> </p><p><span>5</span>  <span><span><span>&lt;</span>fragment</span><span>&gt;</span></span><span></span></p><p><span>6</span>    <span><span><span>&lt;</span>h1</span><span>&gt;</span></span><span>List of stuff</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span></span></p><p><span>7</span>    <span><span><span>&lt;</span><span>Card</span></span> <span>title</span><span><span>=</span><span>'</span>🥕Carrots<span>'</span></span> <span>text</span><span><span>=</span><span>'</span>they are pretty good for you.<span>'</span></span><span>/&gt;</span></span><span></span></p><p><span>8</span>  <span><span><span>&lt;/</span>fragment</span><span>&gt;</span></span></p><p><span>9</span><span>)</span><span>.</span><span>save</span><span>(</span><span>'dist/index.html'</span><span>)</span><span>;</span></p><br></code></pre></div><div data-tab-title="Component Code" data-tab-id="comp"><pre><code tabindex="0"><span><span></span><span></span><span></span><span>card.tsx</span></span><p><span>1</span><span>const</span> style <span>=</span> <span><span>`</span><span></span></span></p><p><span>2</span>  display: inline-block;</p><p><span>3</span>  vertical-align: top;</p><p><span>4</span>  padding: 8px;</p><p><span>5</span>  border-radius: 8px;</p><p><span>6</span>  margin: 8px;</p><p><span>7</span>  box-shadow: 0 2px 6px rgba(0, 0, 0, .2);</p><p><span>8</span><span>`</span><span>;</span></p><p><span>9</span></p><p><span>10</span><span>export</span> <span>function</span> <span>Card</span><span>(</span><span><span>{</span> title<span>,</span> text <span>}</span><span>,</span> renderer</span><span>)</span> <span>{</span></p><p><span>11</span>  <span>return</span> <span><span><span>&lt;</span>div</span> <span>style</span><span><span>=</span><span>{</span>style<span>}</span></span><span>&gt;</span></span><span></span></p><p><span>12</span>      <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span>{</span>title<span>}</span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><span></span></p><p><span>13</span>      <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>{</span>text<span>}</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span></span></p><p><span>14</span>    <span><span><span>&lt;/</span>div</span><span>&gt;</span></span></p><p><span>15</span><span>}</span></p><br></code></pre></div></div><marker><br>

</marker><h2 id="dynamic-content"><span data-ignore-text=""><span data-ignore-text="">link</span></span>Dynamic Content</h2><p>For dynamic components, i.e. components that are to be rendered on the client side, we needed to:</p><ul><li>Collect and bundle their code</li><li>Attach that bundle to pre-rendered content</li><li>Create placeholders to maintain their position in the DOM tree</li></ul><p>With CONNECTIVE SDH, this process looks like this:</p><div><div data-tab-title="Main Code" data-tab-id="Main Code"><pre><code tabindex="0"><span><span></span><span></span><span></span><span>main.tsx</span></span><p><span>1</span><span>import</span> <span>{</span> compile<span>,</span> save<span>,</span> Bundle <span>}</span> <span>from</span> <span>'@connectv/sdh'</span><span>;</span></p><p><span>2</span><span>import</span> <span>{</span> $Counter <span>}</span> <span>from</span> <span>'./counter'</span><span>;</span> </p><p><span>3</span></p><p><span>4</span><span>const</span> bundle <span>=</span> <span>new</span> <span>Bundle</span><span>(</span><span>'./bundle.js'</span><span>,</span> <span>'dist/bundle.js'</span><span>)</span><span>;</span></p><p><span>5</span></p><p><span>6</span><span>compile</span><span>(</span><span>renderer</span> <span>=&gt;</span></p><p><span>7</span>  <span><span><span>&lt;</span>fragment</span><span>&gt;</span></span><span></span></p><p><span>8</span>    <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span></span></p><p><span>9</span>      So this content will be prerendered, but the following component will be</p><p><span>10</span>      rendered on the client side.</p><p><span>11</span>    <span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span></span></p><p><span>12</span>     &lt;$Counter/&gt;</p><p><span>13</span>  <span><span><span>&lt;/</span>fragment</span><span>&gt;</span></span></p><p><span>14</span><span>)</span></p><p><span>15</span> <span>.</span><span>post</span><span>(</span>bundle<span>.</span><span>collect</span><span>(</span><span>)</span><span>)</span>                    </p><p><span>16</span><span>.</span><span>save</span><span>(</span><span>'dist/index.html'</span><span>)</span></p><p><span>17</span> <span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>save</span><span>(</span>bundle<span>)</span><span>)</span>                  </p><br></code></pre></div><div data-tab-title="Component Code" data-tab-id="comp"><pre><code tabindex="0"><span><span></span><span></span><span></span><span>counter.tsx</span></span><p><span>1</span><span>import</span> <span>{</span> state <span>}</span> <span>from</span> <span>"@connectv/core"</span><span>;</span></p><p><span>2</span> <span>import</span> <span>{</span> transport <span>}</span> <span>from</span> <span>"@connectv/sdh/transport"</span><span>;</span></p><p><span>3</span></p><p><span>4</span><span>const</span> style <span>=</span> <span><span>`</span><span></span></span></p><p><span>5</span>  border-radius: 3px;</p><p><span>6</span>  background: #424242;</p><p><span>7</span>  cursor: pointer;</p><p><span>8</span>  padding: 8px;</p><p><span>9</span>  color: white;</p><p><span>10</span>  display: inline-block;</p><p><span>11</span>  box-shadow: 0 2px 6px rgba(0, 0, 0, .12);</p><p><span>12</span><span>`</span><span>;</span></p><p><span>13</span></p><p><span>14</span><span>export</span> <span>function</span> <span>Counter</span><span>(</span><span>_<span>,</span> renderer</span><span>)</span> <span>{</span></p><p><span>15</span>  <span>const</span> count <span>=</span> <span>state</span><span>(</span><span>0</span><span>)</span><span>;</span></p><p><span>16</span>  <span>return</span> <span>(</span></p><p><span>17</span>    <span><span><span>&lt;</span>div</span> <span>style</span><span><span>=</span><span>{</span>style<span>}</span></span> <span>onclick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> count<span>.</span>value<span>++</span><span>}</span></span><span>&gt;</span></span><span></span></p><p><span>18</span>      You have clicked <span>{</span>count<span>}</span><span> times!</span></p><p><span>19</span>    <span><span><span>&lt;/</span>div</span><span>&gt;</span></span></p><p><span>20</span>  <span>)</span><span>;</span></p><p><span>21</span><span>}</span></p><p><span>22</span></p><p><span>23</span> <span>export</span> <span>const</span> $Counter <span>=</span> <span>transport</span><span>(</span>Counter<span>)</span><span>;</span> </p><br></code></pre></div></div><marker><br>

</marker><h3 id="placeholders"><span data-ignore-text=""><span data-ignore-text="">link</span></span>Placeholders</h3><p>In this example, <code>Counter</code> is a component that needs to be rendered on the client-side, i.e. it needs
to be <em>transported</em> to the client. This is done via …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coding.blog/blog/jamstack">https://coding.blog/blog/jamstack</a></em></p>]]>
            </description>
            <link>https://coding.blog/blog/jamstack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641457</guid>
            <pubDate>Thu, 25 Jun 2020 14:54:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complete Kafka workspace and cloud environment]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641179">thread link</a>) | @lensesio
<br/>
June 25, 2020 | https://lenses.io/blog/2020/06/perfect-environment-learn-develop-apache-kafka/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/06/perfect-environment-learn-develop-apache-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apache Kafka has gained traction as one of the most widely adopted technologies for building streaming applications - but introducing it (and scaling it) into your business can be a struggle.</p><p>The problem isn’t with Kafka itself so much as the different components you need to learn and different tools required to operate it.</p><p>For those motivated enough, you can invest money, effort and long Friday nights into learning, fixing and streamlining Kafka - and you’ll get there.&nbsp;</p><p>But for those that prefer to spend time focusing on the data and would rather master Kafka’s value than its inner-workings, fear not.&nbsp;</p><p>When we started Lenses.io, we experienced first-hand how difficult it can be to set up a Kafka development environment; so we decided to follow an anti-pattern and create a docker image with a full-fledged Kafka installation: the<a href="https://github.com/lensesio/fast-data-dev"> fast-data-dev docker</a>.&nbsp;</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/dH7CDIWIgsRCvAqBzqE31/90912a877cfab5860632ea82905ed00d/kafka_docker.PNG" alt="Lenses Kafka docker"></span></p><p>
The community loved it and we are grateful for this.&nbsp;</p><p>Fast forward and we created Lenses.io, understanding that now the challenge was operating Kafka and real-time applications and data. So we wanted to create a tool to provide the best developer experience for Kafka: Lenses.&nbsp;&nbsp;</p><p>It is only natural that we had to add it to fast-data-dev and make it free for developers, the people to whom we owe our success.</p><p>Hence, enter the Lenses Box; our most popular download!</p><h3>A complete Kafka-in-a-box</h3><p>To start with, the Box gives you an environment including:
</p><ul><li><p><b>1-node Kafka and Zookeeper</b>: your Kafka service, ready to receive data.</p></li><li><p><b>Kafka Connect</b>: use it to bring data in and out of Kafka, from DBs for example.</p></li><li><p><b>Schema Registry</b>: safely control the structure of your data in Kafka, powered by Avro.</p></li><li><p><b>Elasticsearch</b>: ship your streaming results here for powerful search.</p></li></ul><p>All in a single docker container.</p><p>That’s already quite a lot of time off your plate. Then we package....</p><h3>... A DataOps workspace</h3><p>
In the same container, you’ll get a Lenses.io workspace fully integrated with the Kafka environment.&nbsp;</p><p>If you’re not familiar with Lenses.io, it’s an engineering portal for building &amp; operating real-time applications on Apache Kafka.</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/7DWv3Bt0Hktaxp0wffQrPV/5732afddba639697e37f3342beafbe0d/Portal_blog_copy.jpg" alt="Lenses.io Box Apache Kafka docker container for localhost development"></span></p><h3>How does Box help me develop real-time applications?</h3><p>
As a docker container that unifies all these different technologies into a single developer experience, Box is a perfect solution to learn Kafka or to develop real-time applications on a local instance before promoting to another Kafka environment.&nbsp;</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/sXmd6nQXmkgivJ9ejXxhh/5d6cc3687660dd1ac5655348bf1bf240/Portal_blog2.jpg" alt="Portal blog2"></span></p><p>So, if you’re a developer, you can <code>docker&nbsp;run</code> Lenses.io Box on your machine and try out the following use cases.</p><h3>Connect custom applications &amp; explore data in streams</h3><p>Connect your custom application, written in whatever framework you choose, to the Kafka broker just like you would with any other Kafka environment. Once you’ve done this, you’ll have full visibility into your custom application within a workspace. This includes being able to explore data in the streams using SQL, viewing and alerting on lag. If you use the <a href="https://docs.lenses.io/dev/topology/index.html">Topology client</a>, you’ll be able to even see the full topology of your pipelines.&nbsp;
</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/56OrFbezKepp4RQZEqz7Xn/27a231c4ae58faddbd8e2f0025f74832/image.png" alt="IntelliJ - Connecting consumer or producer client to Lenses.io Box localhost Apache Kafka broker"></span></p><h3>Build &amp; evolve schemas</h3><p>
Your gateway into streaming structured data. With support for multiple standard serialization formats, custom formats, and Schema Registry, you can use Box to understand your data and experiment with schemas and evolution. Lenses SQL gives you a perfect playground to iterate and verify your schema changes.
</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/2D7lSbSE37jmPozW5CGMTb/be2ead015664934f37144a30082650c6/docker-run-lenses.PNG" alt="Docker run Kafka on Lenses"></span></p><p>Do you like SQL? If so, use it to create schemas directly. For example the following statement will create a topic with an AVRO schema for the value of the topic.&nbsp;
</p><pre>CREATE&nbsp;TABLE&nbsp;customers&nbsp;(id&nbsp;string,&nbsp;name&nbsp;string,&nbsp;postcode&nbsp;string,&nbsp;city&nbsp;string)</pre><pre></pre><pre>FORMAT&nbsp;(string,&nbsp;avro)</pre><pre></pre><pre>PROPERTIES&nbsp;(partitions=3,&nbsp;compacted=false);&nbsp;</pre><pre></pre><pre></pre><pre></pre><pre></pre><p>You can run these statements from the browser or from a CLI</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/nObbLUdN7CVPbGKWxf4n8/30e14ad7dbc9797d690238f2817fdcba/image.png" alt="Lenses.io CLI - create Apache Kafka topic and AVRO schema from command line with SQL"></span></p><h3>Test a microservice by injecting data into a stream using SQL</h3><p>
If you’re developing a streaming application that will be read from Kafka, you are effectively making a <b>Kafka consumer.</b> You will be connecting it to the Broker and you might want to test how it behaves when actually consuming data from a stream.
</p><p>That same SQL Engine I mentioned earlier, also extends to injecting data into a topic. For example:&nbsp;</p><pre>INSERT&nbsp;INTO&nbsp;customers&nbsp;(id,&nbsp;name,&nbsp;postcode,&nbsp;city)&nbsp;</pre><pre></pre><pre>VALUES&nbsp;('23423','Xavier',&nbsp;'75009',&nbsp;'Paris'),&nbsp;</pre><pre></pre><pre>('56456','Anne',&nbsp;'E24',&nbsp;'London'),&nbsp;</pre><pre></pre><pre>('8734','Todd',&nbsp;'10175',&nbsp;'New&nbsp;York'),&nbsp;</pre><pre></pre><pre>('6735463','Denise',&nbsp;'3207',&nbsp;'Melbourne');</pre><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/40FjAJMM5z8Apl3dv0kG7z/56918c58b7a96945dffe8e99539fcbad/image.png" alt="Insert data into an Apache Kafka topic via the Lenses.io CLI client and SQL statement"></span></p><h3>Configure Kafka Connect connectors</h3><p>The easiest way to bring data in and out of Kafka is with the Kafka Connect connectors. They are standard patterns of moving data between Kafka and other data systems.</p><p>
The environment is packaged with a number of popular connectors such as Mongo, Elastic 6, Influx but you can also import others.</p><p>
Want to bring in data from a database? Want to ship your results to Influx? No problem. Just a few clicks and Lenses will get those connectors running for you.</p><p>
This is perfect for testing out the Kafka Connect configuration and connection to those source and target systems. You benefit from the feedback loop: from error handling if you’ve mis-configured anything to seeing the performance of the flow. Not to mention being able to explore the data you are sourcing or sinking with SQL.&nbsp;</p><p><span><img src="https://images.ctfassets.net/tnuaj0t7r912/3bO29ixv0ZCEzQ9ugBBjId/9b6ddfec459225940cdb8897e88a794e/image.png" alt="View and manage Kafka Connect connectors from the Lenses.io Box"></span></p><h3>Build SQL Streaming applications</h3><p>
Last but not least, Box is an environment to build stream processing applications with SQL.&nbsp;</p><p>The Streaming SQL engine allows you to define real-time data processing applications that enrich, filter, aggregate or reshape data streams. Ask things like:
</p><ul><li><p><i>What’s my total number sales up-till-now? Real-time.</i></p></li><li><p><i>How many clients are on my website checking out my new product right now?</i></p></li></ul><p>The answer is in the data. And all it takes is a bit of SQL. No frameworks, no code, no rocket-science engineering.</p><p>Here's an example<i>

</i></p><pre>SET&nbsp;autocreate=true;</pre><pre></pre><pre>SET&nbsp;`auto.offset.reset`='earliest';</pre><pre></pre><pre>SET&nbsp;`commit.interval.ms`='10000';</pre><pre></pre><pre>INSERT&nbsp;INTO&nbsp;frauds_detection</pre><pre></pre><pre>WITH&nbsp;tableCards&nbsp;AS&nbsp;(</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;SELECT&nbsp;ccNumber,&nbsp;provider,</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;expiry,&nbsp;accountEnabled</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;FROM&nbsp;credit_cards_data</pre><pre></pre><pre>)</pre><pre></pre><pre>SELECT&nbsp;STREAM</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;p.provider,</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;p.ccNumber,</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;p.transaction.currency,</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;count(*)&nbsp;attempts</pre><pre></pre><pre>FROM&nbsp;credit_cards_payments&nbsp;AS&nbsp;p</pre><pre></pre><pre>INNER&nbsp;JOIN&nbsp;tableCards&nbsp;AS&nbsp;c&nbsp;ON&nbsp;p.ccNumber&nbsp;=&nbsp;c.ccNumber</pre><pre></pre><pre>WHERE&nbsp;c.accountEnabled&nbsp;=&nbsp;'no'</pre><pre></pre><pre>GROUP&nbsp;BY&nbsp;tumble(5,s),&nbsp;p.provider</pre><p>You don’t need extra services either.. The workload will run locally in your environment for Box. Of course with the full Lenses.io workspace, you can choose to deploy it over your existing Kubernetes infrastructure and run it at scale.</p><h3>“The Cloud”, you said?
</h3><p>As it’s next evolution, yes, Box is now available as a Cloud service!&nbsp; A full Lenses-Kafka developer environment with zero setup.&nbsp;</p><p>Sign up for free on our new <a href="http://portal.lenses.io/register">Lenses.io Portal.</a></p><p>Or if you prefer to run the Docker container yourself, get access to it from <a href="https://lenses.io/downloads/lenses/?path=wizard-form">here</a> <a href="https://lenses.io/downloads/lenses/?path=wizard-form"></a>
</p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/06/perfect-environment-learn-develop-apache-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641179</guid>
            <pubDate>Thu, 25 Jun 2020 14:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promote Imperfect People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23641051">thread link</a>) | @chesterarthur
<br/>
June 25, 2020 | https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You’ve likely experienced it: “You’re above and beyond everything we’re asking. There’s no promotion this round but all you need to do is <strong>__</strong>_”. Insert a semi-important but not absolutely necessary thing. Even worse if it’s something you’re really not good at.</p>

<p>One of the most demotivating things that an organization or manager can do is requiring “perfection” for a promotion. It’s a problem with two main dimensions:</p>
<ul>
  <li>It’s incommensurate with the value being added to the business.</li>
  <li>Perfection is subjective.</li>
</ul>

<h2 id="incommensurate-with-value-add">Incommensurate with Value-Add</h2>

<p>Ultimately all performance comes down to one thing: how much value are you adding to the business? Examples of where forcing perfection gets things out of whack:</p>
<ul>
  <li>I coded up a feature that brought in $10M to the business this year. I wasn’t promoted because they said I don’t speak enough in meetings.</li>
  <li>I saved the company from collapse because I was the only one who knew how to debug the system when it was melting. I wasn’t promoted because they said I show up too late every day.</li>
  <li>I identified a winning strategy for the entire business that drove us to another echelon of success. I wasn’t promoted because my design docs have typos.</li>
</ul>

<p>All that matters is the value being added to the business. There are nuances where behavior can set bad examples or cause issues for others, but that detracts from value added to the business and should be considered. The unfortunate and unbelievably common case is that some sort of benign missing strength is held against people.</p>

<h2 id="perfection-is-subjective">Perfection is Subjective</h2>

<p>When managers go down the rabbit whole of chasing perfect promotions they’re much more likely to be biased. In reality, most people’s internal picture of a perfect candidate for a promotion is something like “what did I look like when I got promoted?” That’s often the closest image a manager has of what a promotion at that level looks like.</p>

<p>In mild cases you get things like “when I got promoted I had to walk in the snow to work, uphill both ways.”</p>

<p>In more severe cases you get things like:</p>
<ul>
  <li>Men who don’t promote women because they’re not “aggressive enough” or they “don’t speak up enough”</li>
  <li>Extroverts who don’t promote introverts because they don’t like public speaking.</li>
  <li>Non-parents who don’t promote parents because they don’t work until midnight in the office.</li>
</ul>

<p>Promote people based on impact to the business, not their style of delivery.  Don’t hold people down because they deliver value in a way that isn’t comfortable, known, or practiced by you.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In promotions and growth, focus more on amplifying strengths than fixing “weaknesses”.  You’ll find it’s much easier and much more fruitful to have people play to their strengths.</p>

<p>Promote imperfect people - that’s all you’ve got.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641051</guid>
            <pubDate>Thu, 25 Jun 2020 14:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Wizards S4E6 Sundi Myint on the Visual Side of Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23640986">thread link</a>) | @smartlogic
<br/>
June 25, 2020 | https://smartlogic.io/podcast/elixir-wizards/s4e6-myint/ | <a href="https://web.archive.org/web/*/https://smartlogic.io/podcast/elixir-wizards/s4e6-myint/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header>
  

  <!-- Global site tag (gtag.js) - Google Ads: 743722644 -->
  
  
</header>

    <p><a href="https://smartlogic.io/">Home</a>

  
    &gt; <a href="https://smartlogic.io/podcast/">Podcast</a>
  

  
    &gt; <a href="https://smartlogic.io/podcast/elixir-wizards/">Elixir wizards</a>
  

  
    &gt; Sundi Myint on The Visual Side of Elixir, the History of Emojis, and Test- and Domain-Driven Architecture
  

</p>


  <main role="main">
    <section>
      </section>

    <div>

      <section>
        



        <h2>About this Episode</h2>
        <h3>
          Published June 25, 2020 |
          Duration: 45:58 |
          <a href="https://feeds.fireside.fm/smartlogic/rss">RSS Feed</a> |
          <a href="https://aphid.fireside.fm/d/1437767933/03a50f66-dc5e-4da4-ab6e-31895b6d4c9e/f14188bd-903b-49eb-bc8b-f52429966e63.mp3">Direct download</a>
          
          | <a href="https://smartlogic.io/podcast/elixir-wizards/transcripts/s4e6_Sundi_Myint.txt">Transcript</a>
          
        </h3>
        <!-- description copy starts here - pulled from fireside -->
        
        <p>Welcome to another episode of Elixir Wizards as we continue our journey into system and application architecture! Our featured guest today is Sundi Myint and she is here to share her journey with Elixir and her non-traditional path to programming. We hear about Sundi's interest in gaming, her role at Cava and a bit of the inspiration behind her amazing Instagram account! We discuss her first internship and how she found herself in the role quite suddenly before diving into the motivation behind her blog post on the history of emojis. Sundi did some serious research into this interesting subject and she shares some of the more technical aspects of the story with us on the show. We talk about architecture and both test and design-driven approaches. Sundi also explains her process and how mapping things out on a whiteboard has been her favored way to do things for some time. Andrea Leopardi then joins us for another edition of Pattern Matching with Todd! He answers Todd's questions about his home life, media favorites, future projects and more!</p>

<p>Key Points From This Episode:</p>

<ul>
<li>Sundi's Instagram aesthetic and her love of food and photography. </li>
<li>How Sundi got into programming and her first internship.<br></li>
<li>Getting hired at Cava and an introduction to Elixir and the community.</li>
<li>Video game programming and Sundi's thoughts on the possibility of pursuing this path. </li>
<li>Sundi's first paid job out of college and the tech stack at the company.</li>
<li>Thoughts on easily available learning resources and the power of Live View. </li>
<li>Some background on Sundi's amazing blog post on the history of emojis.</li>
<li>Understanding Unicode, how it works and its role in translation and interpretation. </li>
<li>Sundi's perspectives on architecture and domain-driven design.</li>
<li>Code design strategies, workflow and the idea and practice of test-driven code. </li>
<li>Conversations with stakeholders and moving to the planning stage. </li>
<li>How Sundi uses whiteboards to map out her work graphically and Elixir's part in this. </li>
<li>Andrea's travels and some of the amazing locations he has visited for conferences. </li>
<li>Home life and lifestyle in quarantine for Andrea in Italy.</li>
<li>Alternative career paths and Andrea's other interests; balancing creativity and logic. </li>
<li>Music, movies and television choices for Andrea.</li>
<li>Exciting new projects on the horizon for Andrea; a book, HTTP and more!</li>
</ul>

<p>Links Mentioned in Today’s Episode:</p>

<p>SmartLogic — <a href="https://smartlogic.io/" rel="nofollow">https://smartlogic.io/</a> <br>
Sundi Myint on Twitter — <a href="https://twitter.com/sundikhin" rel="nofollow">https://twitter.com/sundikhin</a><br>
Sundi Myint on Instagram — <a href="https://www.instagram.com/sundikhin" rel="nofollow">https://www.instagram.com/sundikhin</a><br>
Cava — <a href="https://cava.com/" rel="nofollow">https://cava.com/</a><br>
Hackers &amp; Painters — <a href="https://www.amazon.com/Hackers-Painters-Big-Ideas-Computer/dp/1449389554" rel="nofollow">https://www.amazon.com/Hackers-Painters-Big-Ideas-Computer/dp/1449389554</a><br>
Lonestar Elixir — <a href="https://lonestarelixir.com/" rel="nofollow">https://lonestarelixir.com/</a><br>
Bruce Tate — <a href="https://codesync.global/speaker/bruce-tate/" rel="nofollow">https://codesync.global/speaker/bruce-tate/</a><br>
EA — <a href="https://www.ea.com/" rel="nofollow">https://www.ea.com</a><br>
Groxio Learning — <a href="https://grox.io/training/elixir/home" rel="nofollow">https://grox.io/training/elixir/home</a><br>
Live View — <a href="https://support.google.com/maps/thread/11554255?hl=en" rel="nofollow">https://support.google.com/maps/thread/11554255?hl=en</a><br>
Build a real-time Twitter clone in 15 minutes with LiveView and Phoenix 1.5 — <a href="https://www.youtube.com/watch?v=MZvmYaFkNJI" rel="nofollow">https://www.youtube.com/watch?v=MZvmYaFkNJI</a><br>
The History of Emojis Blog Post — <a href="https://engineering.upside.com/emojis-a-history-75d595bbe4a5?gi=6cd53698e5d" rel="nofollow">https://engineering.upside.com/emojis-a-history-75d595bbe4a5?gi=6cd53698e5d</a><br>
Burgergate <a href="https://www.theverge.com/2017/10/30/16569346/burgergate-emoji-google-apple" rel="nofollow">https://www.theverge.com/2017/10/30/16569346/burgergate-emoji-google-apple</a><br>
Joy of Coding — <a href="https://joyofcoding.org/" rel="nofollow">https://joyofcoding.org/</a><br>
Test-driven development — <a href="https://en.wikipedia.org/wiki/Test-driven_development" rel="nofollow">https://en.wikipedia.org/wiki/Test-driven_development</a><br>
Mox — <a href="https://hexdocs.pm/mox/Mox.html" rel="nofollow">https://hexdocs.pm/mox/Mox.html</a><br>
Venmo — <a href="https://venmo.com/" rel="nofollow">https://venmo.com/</a><br>
Mint — <a href="https://www.mint.com/" rel="nofollow">https://www.mint.com/</a><br>
Avengers — <a href="https://www.marvel.com/movies/avengers-endgame" rel="nofollow">https://www.marvel.com/movies/avengers-endgame</a><br>
DC Elixir — <a href="https://www.meetup.com/DC-Elixir/" rel="nofollow">https://www.meetup.com/DC-Elixir/</a><br>
Todd Resudek — <a href="https://medium.com/@toddresudek" rel="nofollow">https://medium.com/@toddresudek</a><br>
Andrea Leopardi — <a href="https://andrealeopardi.com/" rel="nofollow">https://andrealeopardi.com/</a><br>
Brooklyn Zelenka — <a href="https://medium.com/@expede" rel="nofollow">https://medium.com/@expede</a><br>
The Lord of Rings — <a href="https://www.rottentomatoes.com/franchise/lord_of_the_rings" rel="nofollow">https://www.rottentomatoes.com/franchise/lord_of_the_rings</a><br>
Wes Anderson — <a href="https://www.imdb.com/name/nm0027572/" rel="nofollow">https://www.imdb.com/name/nm0027572/</a><br>
Scott Pilgrim vs. The World — <a href="https://www.rottentomatoes.com/m/scott_pilgrims_vs_the_world" rel="nofollow">https://www.rottentomatoes.com/m/scott_pilgrims_vs_the_world</a><br>
Community — <a href="https://www.rottentomatoes.com/tv/community" rel="nofollow">https://www.rottentomatoes.com/tv/community</a><br>
The Office — <a href="https://www.rottentomatoes.com/tv/the_office" rel="nofollow">https://www.rottentomatoes.com/tv/the_office</a><br>
Rick and Morty — <a href="https://www.rottentomatoes.com/tv/rick_and_morty" rel="nofollow">https://www.rottentomatoes.com/tv/rick_and_morty</a><br>
Justus Eapen on Twitter — <a href="https://twitter.com/justuseapen" rel="nofollow">https://twitter.com/justuseapen</a><br>
Eric Oestrich on Twitter — <a href="https://twitter.com/ericoestrich" rel="nofollow">https://twitter.com/ericoestrich</a></p><p>Special Guests: Andrea Leopardi and Sundi Myint.</p>
      
        <!-- end copy from fireside -->
      </section>

  </div></main>
  

  </div></div>]]>
            </description>
            <link>https://smartlogic.io/podcast/elixir-wizards/s4e6-myint/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640986</guid>
            <pubDate>Thu, 25 Jun 2020 14:15:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angular 10 Now Available]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23640966">thread link</a>) | @theodorejb
<br/>
June 25, 2020 | https://blog.angular.io/version-10-of-angular-now-available-78960babd41 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-10-of-angular-now-available-78960babd41">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.angular.io/@stephenfluin?source=post_page-----78960babd41----------------------" rel="noopener"><img alt="Stephen Fluin" src="https://miro.medium.com/fit/c/96/96/1*y_L34o3bW0QELQm1KOFMTw.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="0c65">Version 10.0.0 is here! This is a <a href="https://semver.org/#spec-item-8" target="_blank" rel="noopener">major</a> release that spans the entire platform, including the framework, Angular Material, and the CLI. This release is smaller than typical; it has only been 4 months since we released version 9.0 of Angular.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*NW08J81iLpExTFTz4wnWHQ.jpeg?q=20" width="2048" height="1365" role="presentation"></p><p><img src="https://miro.medium.com/max/4096/1*NW08J81iLpExTFTz4wnWHQ.jpeg" width="2048" height="1365" srcset="https://miro.medium.com/max/552/1*NW08J81iLpExTFTz4wnWHQ.jpeg 276w, https://miro.medium.com/max/1104/1*NW08J81iLpExTFTz4wnWHQ.jpeg 552w, https://miro.medium.com/max/1280/1*NW08J81iLpExTFTz4wnWHQ.jpeg 640w, https://miro.medium.com/max/1400/1*NW08J81iLpExTFTz4wnWHQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Photo of Butterfly Beach by Minko Gechev</figcaption></figure><p id="346b">We try to release two major versions each year to keep Angular synchronized with the rest of the JavaScript ecosystem and to have a predictable schedule. We plan to release version 11 this fall.</p><p id="156d"><strong>New Date Range Picker</strong></p><p id="ba59">Angular Material now includes a new date range picker.</p><figure><div><div><div><p><img src="https://miro.medium.com/max/60/0*ruU5G-8_hqEp3UBY?q=20" width="410" height="94" role="presentation"></p><p><img src="https://miro.medium.com/max/820/0*ruU5G-8_hqEp3UBY" width="410" height="94" srcset="https://miro.medium.com/max/552/0*ruU5G-8_hqEp3UBY 276w, https://miro.medium.com/max/820/0*ruU5G-8_hqEp3UBY 410w" sizes="410px" role="presentation"></p></div></div></div><figcaption>Image of the new date range picker</figcaption></figure><p id="f310">To use the new date range picker, you can use the <code>mat-date-range-input</code> and <code>mat-date-range-picker</code> components.</p><p id="5add">See <a href="https://stackblitz.com/angular/nknyovevygv?file=src%2Fapp%2Fdate-range-picker-overview-example.html" target="_blank" rel="noopener">this example on StackBlitz</a>.</p><p id="41ba">Learn more about <a href="https://next.material.angular.io/components/datepicker/overview#date-range-selection" target="_blank" rel="noopener">date range selection</a>.</p><p id="16c4"><strong>Warnings about CommonJS imports</strong></p><p id="aadf">When you use a dependency that is packaged with CommonJS, it can result in <a href="https://web.dev/commonjs-larger-bundles/" target="_blank" rel="noopener">larger slower applications</a>.</p><p id="9444">Starting with version 10, we now warn you when your build pulls in one of these bundles. If you’ve started seeing these warnings for your dependencies, let your dependency know that you’d prefer an ECMAScript module (ESM) bundle.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/0*udjNtSSP-495QNzL?q=20" width="1600" height="357" role="presentation"></p><p><img src="https://miro.medium.com/max/3200/0*udjNtSSP-495QNzL" width="1600" height="357" srcset="https://miro.medium.com/max/552/0*udjNtSSP-495QNzL 276w, https://miro.medium.com/max/1104/0*udjNtSSP-495QNzL 552w, https://miro.medium.com/max/1280/0*udjNtSSP-495QNzL 640w, https://miro.medium.com/max/1400/0*udjNtSSP-495QNzL 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>CommonJS or AMD dependencies can cause optimization bailouts</figcaption></figure><p id="dde5"><strong>Optional Stricter Settings</strong></p><p id="7e3d">Version 10 offers a more strict project setup when you create a new workspace with <code>ng new</code>.</p><pre><span id="4b6e">ng new --strict</span></pre><p id="9fa5">Enabling this flag initializes your new project with a few new settings that improve maintainability, help you catch bugs ahead of time, and allow the CLI to perform advanced optimizations on your app. Specifically, the <code>strict</code> flag does the following:</p><ul><li id="0ab9">Enables strict mode in TypeScript</li><li id="0f1b">Turns template type checking to Strict</li><li id="6313">Default bundle budgets have been reduced by ~75%</li><li id="855e">Configures linting rules to <a href="https://palantir.github.io/tslint/rules/no-any/" target="_blank" rel="noopener">prevent declarations of type </a><code><a href="https://palantir.github.io/tslint/rules/no-any/" target="_blank" rel="noopener">any</a></code></li><li id="cb7d">Configures your app as side-effect free to enable more advanced tree-shaking</li></ul><p id="2213"><strong>Keeping Up to Date with the Ecosystem</strong></p><p id="e568">As usual, we have made a few updates to the dependencies of Angular to stay synchronized with the JavaScript ecosystem.</p><ul><li id="0658">TypeScript bumped to <a href="https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-9.html" target="_blank" rel="noopener">TypeScript 3.9</a></li><li id="498e">TSLib has been updated to v<a href="https://github.com/microsoft/tslib/releases/tag/2.0.0" target="_blank" rel="noopener">2.0</a></li><li id="50e3">TSLint has been updated to v6</li></ul><p id="fcf0">We’ve also updated our project layout. Starting with version 10 you will see a new <code>tsconfig.base.json</code>. This additional <code><a href="https://www.typescriptlang.org/docs/handbook/tsconfig-json.html" target="_blank" rel="noopener">tsconfig.json</a></code><a href="https://www.typescriptlang.org/docs/handbook/tsconfig-json.html" target="_blank" rel="noopener"> file</a> better supports the way that IDEs and build tooling resolve type and package configurations.</p><p id="948c"><strong>New Default Browser Configuration</strong></p><p id="eb51">We’ve updated the browser configuration for new projects to exclude older and less used browsers.</p><p id="686d"><strong>v9 Defaults</strong></p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/46/0*jhzqz-biEH3Bd7zQ?q=20" width="787" height="1036" role="presentation"></p><p><img src="https://miro.medium.com/max/1574/0*jhzqz-biEH3Bd7zQ" width="787" height="1036" srcset="https://miro.medium.com/max/552/0*jhzqz-biEH3Bd7zQ 276w, https://miro.medium.com/max/1104/0*jhzqz-biEH3Bd7zQ 552w, https://miro.medium.com/max/1280/0*jhzqz-biEH3Bd7zQ 640w, https://miro.medium.com/max/1400/0*jhzqz-biEH3Bd7zQ 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="8574"><strong>v10 Defaults</strong></p><figure><div><div><div><p><img src="https://miro.medium.com/max/60/0*kLsNxh2hOj_aQ8HV?q=20" width="685" height="479" role="presentation"></p><p><img src="https://miro.medium.com/max/1370/0*kLsNxh2hOj_aQ8HV" width="685" height="479" srcset="https://miro.medium.com/max/552/0*kLsNxh2hOj_aQ8HV 276w, https://miro.medium.com/max/1104/0*kLsNxh2hOj_aQ8HV 552w, https://miro.medium.com/max/1280/0*kLsNxh2hOj_aQ8HV 640w, https://miro.medium.com/max/1370/0*kLsNxh2hOj_aQ8HV 685w" sizes="685px" role="presentation"></p></div></div></div></figure><p id="a101">This has the side effect of disabling ES5 builds by default for new projects. To enable ES5 builds and differential loading for browsers that require it (such as IE or UC Browser), simply <a href="https://github.com/browserslist/browserslist#browserslist-" target="_blank" rel="noopener">add the browsers you need to support</a> in the <code>.browserslistrc</code> file.</p><p id="df1c"><strong>Angular Team Fixit</strong></p><p id="4207">We’ve dramatically increased our investment in working with the community. In the last three weeks our open issue count has decreased by over 700 issues across <a href="https://github.com/angular/angular/issues" target="_blank" rel="noopener">framework</a>, <a href="https://github.com/angular/angular-cli/issues" target="_blank" rel="noopener">tooling</a>, and <a href="https://github.com/angular/components/issues" target="_blank" rel="noopener">components</a>. We’ve touched over 2,000 issues, and we plan to make large investments over the next few months, working with the community to do even more.</p><p id="c357"><strong>Deprecations and Removals</strong></p><p id="6e18">We’ve made several new deprecations and removals from Angular.</p><p id="61da">The <a href="https://g.co/ng/apf" target="_blank" rel="noopener">Angular Package Format</a> no longer includes ESM5 or FESM5 bundles, saving you 119MB of download and install time when running <code>yarn</code> or <code>npm install</code> for Angular packages and libraries. These formats are no longer needed as any downleveling to support ES5 is done at the end of the build process.</p><p id="a660">Based on heavy consultation with the community, we are deprecating support for older browsers including IE 9, 10, and <a href="https://en.wikipedia.org/wiki/Internet_Explorer_Mobile" target="_blank" rel="noopener">Internet Explorer Mobile</a>.</p><p id="4190">You can <a href="http://v10.angular.io/guide/deprecations" target="_blank" rel="noopener">read more about our deprecations and removals</a>.</p><p id="792e">Visit <a href="https://update.angular.io/" target="_blank" rel="noopener">update.angular.io</a> for detailed information and guidance. To have the best update experience, we recommend always upgrading one major release at a time.</p><p id="4859">To update:</p><pre><span id="d24d">ng update @angular/cli @angular/core</span></pre><p id="e72b">You can read more about this update in our <a href="https://v10.angular.io/guide/updating-to-version-10" target="_blank" rel="noopener">Updating to version 10 guide</a>.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-10-of-angular-now-available-78960babd41</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640966</guid>
            <pubDate>Thu, 25 Jun 2020 14:13:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logistic regression from scratch]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23640762">thread link</a>) | @pmuens
<br/>
June 25, 2020 | https://philippmuens.com/logistic-regression-from-scratch/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/logistic-regression-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>You can find working code examples (including this one) in my <a href="https://github.com/pmuens/lab">lab repository</a> on <a href="https://github.com/pmuens">GitHub</a>.</p><p>Sometimes it's necessary to split existing data into several classes in order to predict new, unseen data. This problem is called <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and one of the algorithms which can be used to learn those classes from data is called Logistic Regression.</p><p>In this article we'll take a deep dive into the Logistic Regression model to learn how it differs from other regression models such as <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear-</a> or <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a>, how to think about it from an intuitive perspective and how we can translate our learnings into code while implementing it from scratch.</p><h2 id="linear-regression-vs-logistic-regression">Linear Regression vs. Logistic Regression</h2><p>If you've read the post about <a href="https://philippmuens.com/linear-and-multiple-regression-from-scratch/">Linear- and Multiple Linear Regression</a> you might remember that the main objective of our algorithm was to find a best fitting line or <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> respectively.</p><p>To recap real quick, a line can be represented via the slop-intercept form as follows:</p><p>\[ y = mx + b \]</p><p>Here, \(m\) represents the slope and \(b\) the y-intercept.</p><p>In Linear Regression we've used the existing data to find a line in slope-intercept form (a \(m\) and \(b\) combination) which "best-fitted through" such data.</p><p>Extending the slope-intercept form slightly to support multiple \(x\) values and multiple slopes (we'll use \(\beta_n\) instead of \(m_n\)) yields the following:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>This "scaled-up" slope-intercept formula was used in the <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> model to find the \(\beta\) and \(b\) values for the <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> which "best-fitted" the data. Once found we were able to use it for predictions by plugging in \(x\) values to get respective \(y\) values.</p><p>Linear Regression models always map a set of \(x\) values to a resulting \(y\) value on a <a href="https://en.wikipedia.org/wiki/Continuous_function">continuous</a> scale. This means that the \(y\) value can e.g. be \(0\), \(42\) or \(5.023.212\). How would we use such a Regression model if our \(y\) value is categorical such as a binary value which is either \(0\) or \(1\)? Is there a way to define a threshold so that a value such as \(42\) is assigned to the category \(1\) while a small value such as \(0.002\) gets assigned to the category \(0\)?</p><p>That's where Logistic Regression comes into play. With Logistic Regression we can map any resulting \(y\) value, no matter its magnitude to a value between \(0\) and \(1\).</p><p>Let's take a closer look into the modifications we need to make to turn a Linear Regression model into a Logistic Regression model.</p><h2 id="sigmoid-functions">Sigmoid functions</h2><p>At the very heart of Logistic Regression is the so-called <a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid function</a>. A Sigmoid function is a class of functions which follows an S-shape when plotted.</p><p>The most prominent Sigmoid function is the so-called <a href="https://en.wikipedia.org/wiki/Logistic_function">Logistic function</a> which was developed by <a href="https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst">Pierre Francois Verhulst</a> to model <a href="https://en.wikipedia.org/wiki/Population_growth">population grown</a>. It's mathematically described via this formula:</p><p>\[ f(x) = \frac{1}{1+e^{-x}} \]</p><p>Don't be intimidated by the math! Right now all you need to know is that this function takes any \(x\) value and maps it to a \(y\) value which ranges from \(0\) to \(1\).</p><p>Plotting the function for a range of \(x\) values proofs this claim and results in the aforementioned S-shape curve:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zsigmoid_result.png"></figure><p>Note that the function gets closer and closer to the \(y\) value \(0\) or \(1\) as the \(x\) values get smaller or larger respectively. Also note that the \(x\) value \(0\) results in the \(y\) value \(0.5\).</p><p>This is exactly what we need. with this function we're able to "squish" any number, no matter its magnitude into a value ranging from \(0\) to \(1\). This makes the function outcome predictable which is useful when we later on define threshold values to associate function outputs with classes.</p><p>Let's turn the function into code:</p><pre><code>def sigmoid(x: float) -&gt; float:
    return 1 / (1 + exp(-x))

assert sigmoid(0) == 0.5</code></pre><p><strong><u>Note</u></strong>: Although there are many <a href="https://en.wikipedia.org/wiki/Sigmoid_function#Examples">different Sigmoid functions</a> to choose from, a lot of people use the name "Sigmoid function" when talking about the Logistic function. We'll adhere to this convention and use the term "Sigmoid function" as a synonym for Logistic function.</p><h2 id="from-linear-regression-to-logistic-regression">From Linear Regression to Logistic Regression</h2><p>Now that we've learned about the "mapping" capabilities of the Sigmoid function we should be able to "wrap" a Linear Regression model such as <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> inside of it to turn the regressions raw output into a value ranging from \(0\) to \(1\).</p><p>Let's translate this idea into Math. Recall that our Multiple Linear Regression model looks like this:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>"Wrapping" this in the Sigmoid function (we use \(\sigma\) to represent the Sigmoid function) results in the following:</p><p>\[ y = \sigma(\beta_1x_1 + ... + \beta_nx_n + b) \]</p><p>Easy enough! Let's turn that into code.</p><p>The first thing we need to do is to implement the underlying Multiple Linear Regression model. Looking at the Math it seems to be possible to use the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a> to calculate the \(\beta\) and \(x\) part to which we then add the single \(b\) value.</p><p>To make everything easier to calculate and implement we'll use a small trick. Multyping a value by the identify \(1\) yields the value so we prepend \(1\) to the \(x\) values and \(b\) to the \(\beta\) values. This way we can solely use the dot-product calculation without the necessity to add \(b\) separately later on. Here's the mathematical formulation of that trick:</p><p>\[ \vec{x} = \begin{pmatrix} 1 \\ x_1 \\ ... \\ x_n \end{pmatrix} \vec{\beta} = \begin{pmatrix} b \\ \beta_1 \\ ... \\ \beta_n \end{pmatrix} \]</p><p>\[ y = \vec{x} \cdot \vec{m} = \sum_{i=1}^n x_i \beta_i = x_1 \times \beta_1 + ... + x_n \times \beta_n \]</p><p>Once we've calculated the dot-product we need to pass it into the Sigmoid function such that its result is translated ("squished") into a value between \(0\) and \(1\).</p><p>Here's the implementation for the <code>dot</code> function which calculates the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a>:</p><pre><code>def dot(a: List[float], b: List[float]) -&gt; float:
    assert len(a) == len(b)
    return sum([a_i * b_i for a_i, b_i in zip(a, b)])

assert dot([1, 2, 3, 4], [5, 6, 7, 8]) == 70</code></pre><p>And here's the <code>squish</code> function which takes as parameters the \(x\) and \(\beta\) values (remember that we've prepended a \(1\) to the \(x\) values and the \(b\) to the \(\beta\) values), uses the <code>dot</code> function to calculate the dot-product of \(x\) and \(\beta\) and then passes this result into the Sigmoid function to map it to a value between \(0\) and \(1\):</p><pre><code>def squish(beta: List[float], x: List[float]) -&gt; float:
    assert len(beta) == len(x)
    # Calculate the dot product
    dot_result: float = dot(beta, x)
    # Use sigmoid to get a result between 0 and 1
    return sigmoid(dot_result)

assert squish([1, 2, 3, 4], [5, 6, 7, 8]) == 1.0</code></pre><h2 id="the-intuition-behind-the-0-1-range">The intuition behind the 0-1 range</h2><p>We've talked quite a lot about how the Sigmoid function is our solution to make the function outcome predictable as all values are mapped to a \(0\) - \(1\) range. But what does a value in that range represent? Let's take a look at an example.</p><p>The following is a data set which describes how long students have studied for an exam and whether they've passed the exam given the hours they've studied.</p><!--kg-card-begin: html--><table>
    <thead>
        <tr>
            <th>Hours studied</th>
            <th>Exam Passed</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>0,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>3,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>3,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>5,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>5,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>6,0</td>
            <td>1</td>
        </tr>
    </tbody>
</table><!--kg-card-end: html--><p>Taking a glance at the data it seems to be that the more hours the students studied, the more likely they were to pass the exam. Intuitively that makes sense.</p><p>Let's plot the data to ensure that our intuition is correct:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data.png"></figure><p>Looking at the plotted data we can immediately see that the values seem to "stick" to either the bottom or top of the graph. Given that it seems to be infeasible to use a Linear Regression model to find a line which best describes the data. How would this line be fitted through the data if the values we'd expect this line should produce are either \(o\) or \(1\)?</p><p>Let's try a thought experiment. What would happen if we've somehow found some coefficients \(\beta\) for the Linear Regression model which "best" describe the data and pass the result it computes through the Sigmoid function? Here's the graph from above with the Sigmoid function added to it:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data_w_sigmoid.png"></figure><p>Looking at the plotting above we can see that the Sigmoid function ensures that the result from the "underlying" Linear Regression model is mapped onto a scale between \(0\) and \(1\), which in turn makes it possible to e.g. define a threshold at \(0.5\) to say that a value which is greater than \(0.5\) might be a predictor for a student passing the exam while a value less than \(0.5\) might mean that she'll fail the exam.</p><p>Note that the wording in the last sentence isn't a coincidence. The value the Signoid function produces can be interpreted as a probability where \(0\) means \(0%\) probability and \(1\) means a \(100%\) probability.</p><h2 id="the-probability-density-function">The Probability Density Function</h2><p>As it turns out we can translate our findings from the previous section into a function called <a href="https://en.wikipedia.org/wiki/Probability_density_function">Probability density function</a> or (PDF for short).</p><p>In particular we can define a <a href="https://en.wikipedia.org/wiki/Conditional_probability">conditional probability</a> which states that given some \(\beta\) and \(x_i\), each corresponding \(y_i\) should equal \(1\) with probability \(\sigma(\beta x_i)\) and \(0\) with probability \(1-\sigma(\beta x_i)\):</p><p>\[ P(y_i \mid \beta x_i) = \sigma(\beta x_i)^{y_i} \times (1-\sigma(\beta x_i))^{1-y_i} \]</p><p>Looking at the formula above it might be a mystery how we deduced it from our verbal description from above. Here's something I want you to try: Please apply the formula by setting \(y_i\) to \(0\) and after that to \(1\) and see what happens. What you'll notice is that depending on what value you set \(y_i\) to, only one part of the formula stays the same while the other is canceled out.</p><p>Here's what we'll end up with if we set \(y_i\) to \(0\) and \(1\):</p><p>\[ 1-\sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 0 \]</p><p>\[ \sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 1 \]</p><p>And that's exactly the desired behavior we described above.</p><h2 id="deriving-a-loss-function">Deriving a Loss function</h2><p>With Logistic Regression our main objective is to find the models \(\beta\) parameters which maximize the likelihood that for a pair of \(x\) values the \(y\) value …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://philippmuens.com/logistic-regression-from-scratch/">https://philippmuens.com/logistic-regression-from-scratch/</a></em></p>]]>
            </description>
            <link>https://philippmuens.com/logistic-regression-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640762</guid>
            <pubDate>Thu, 25 Jun 2020 13:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building GitHub-Style Hovercards with Stimulus and HTML-over-the-Wire]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23640713">thread link</a>) | @kwood
<br/>
June 25, 2020 | https://boringrails.com/articles/hovercards-stimulus/ | <a href="https://web.archive.org/web/*/https://boringrails.com/articles/hovercards-stimulus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Somewhere along the way toward our current JavaScript hellscape, programmers decided that HTML was over. We’re done with it.</p>

<p>The emergence of tools like <a href="https://reactjs.org/docs/hello-world.html">React</a> shifted programmers away from writing HTML, instead writing <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>, a fancier tag-based markup language that worked nicely inside your JavaScript.</p>

<p>Backends were then relegated to being dumb JSON API endpoints. Or if you were fancy and chasing upvotes, you’d use <a href="https://graphql.org/">GraphQL</a>!</p>

<p>But HTML? Yuck!</p>

<h2 id="a-brief-history-of-html-over-the-wire">A Brief History of HTML-over-the-wire</h2>

<p>One of the key pillars of Rails is to <a href="https://rubyonrails.org/doctrine/#integrated-systems">“Value integrated systems”</a>. While the industry moves towards microservices, highly decoupled front-ends and teams, and the siren song of Programming via LEGO Bricks, Rails leans into one system that does it all – termed the <a href="https://m.signalvnoise.com/the-majestic-monolith/">Majestic Monolith</a>.</p>

<p>Instead of rebuilding much of what already works in Rails in a client-side JavaScript MVC framework, apps like Basecamp, GitHub, and Shopify are able to achieve snappy page loads using the concept of “HTML-over-the-wire”.</p>

<p>In his <a href="https://www.youtube.com/watch?v=SWEts0rlezA">seminal RailsConf 2016 talk</a>, <a href="https://twitter.com/sstephenson">Sam Stephenson</a> walks through the pieces of this stack.</p>

<p>By using <a href="https://github.com/turbolinks/turbolinks">Turbolinks</a> (or similar libraries like <a href="https://github.com/defunkt/jquery-pjax">pjax</a> or <a href="https://inertiajs.com/how-it-works">Inertia</a>) and fast HTML responses (aided by caching and avoiding excessive database queries to get <a href="https://www.youtube.com/watch?v=eBccDerJPJE">sub-100ms response times</a>), you could build high performance pages, while still hanging on to the understated benefits of stateless HTTP responses and server-side logic.</p>

<p>As Sam points out, it was truly a “Golden Age of Web Development”.</p>

<p><img src="https://boringrails.com/images/golden-age.png" alt=""></p>

<p>So while much of the industry went down the JavaScript rabbit hole – creating new innovations for <a href="https://reactjs.org/docs/reconciliation.html">reactive rendering</a>, <a href="https://github.com/reduxjs/redux-thunk">functional</a> <a href="https://redux.js.org/">state management containers</a>, and <a href="https://reach.tech/router">approximately</a> <a href="https://github.com/ReactTraining/react-router">seventy</a> <a href="https://github.com/frontarm/navi">different</a> <a href="https://blog.remix.run/p/remix-preview">client-side</a> <a href="https://redwoodjs.com/docs/redwood-router">routing</a> <a href="https://github.com/4Catalyzer/found">libraries</a> – the quiet rebellion in Rails-land was honing these techniques and plugging along building apps out of boring server-rendered HTML.</p>

<p>We’re seeing a renaissance of these tools in 2020 and the excitement (at least in a small corner of the Twitter!) is reaching a fever pitch as Basecamp launches HEY: a fully-featured email client with a tiny JavaScript footprint that pushed the boundaries of the HTML-over-the-wire approach.</p>

<blockquote><div lang="en" dir="ltr"><p>🤯 Basecamp is building a fully-featured, in-browser email client...using a ridiculously small amount of JavaScript. A tiny keyboard shortcut lib, one polyfill, and boring old Stimulus/Turbolinks/Rails...</p><p>🙏 to <a href="https://twitter.com/dhh?ref_src=twsrc%5Etfw">@dhh</a> for generously shipping source maps, amazing learning resource <a href="https://t.co/IEAvwjiKeO">pic.twitter.com/IEAvwjiKeO</a></p></div>— matt swanson 🤔 🦢 (@_swanson) <a href="https://twitter.com/_swanson/status/1253037966710181892?ref_src=twsrc%5Etfw">April 22, 2020</a></blockquote>


<h2 id="turbolinks--stimulus-20xx-the-future">Turbolinks / Stimulus 20XX: The Future</h2>

<p>The stack in 2014-2016 was:</p>

<ul>
  <li>Turbolinks/pjax</li>
  <li>Rails UJS + <code>js.erb</code> templates (<a href="https://signalvnoise.com/posts/3697-server-generated-javascript-responses">Server-generated JavaScript Responses</a>)</li>
  <li>Heavy HTML fragment caching</li>
  <li>Rails Asset Pipeline and <a href="https://coffeescript.org/">CoffeeScript</a></li>
</ul>

<p>You can even trace the origin of these techniques back even further. I was recently <a href="https://twitter.com/chris_vannoy/status/1274682764948844545">sent a link</a> to a nearly 15 year old REST “microformat” called <a href="http://microformats.org/wiki/rest/ahah">“AHAH: Asynchronous HTML and HTTP”</a>, which is an early version of the same ideas we’re so excited about today. (You shouldn’t be surprised to see <a href="https://twitter.com/dhh">David Hansson</a> listed as a contributor!)</p>

<p>Now a “state-of-the-art” 2020 version also includes:</p>

<ul>
  <li><a href="https://stimulusjs.org/handbook/introduction">StimulusJS</a> (see also <a href="https://github.com/alpinejs/alpine">AlpineJS</a>) for lightweight event management, data binding, and “sprinkles” of behavior</li>
  <li>Partial updates with Turbolinks via a new <code>&lt;template&gt;</code> command approach (replacing <code>js.erb</code> and supporting <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a>)</li>
  <li>Real-time Turbolinks updates via <a href="https://guides.rubyonrails.org/action_cable_overview.html">ActionCable</a> (see also <a href="https://docs.stimulusreflex.com/">StimulusReflex</a>/<a href="https://cableready.stimulusreflex.com/">CableReady</a>)</li>
  <li>First-party support for Webpack, ES6, and new CSS approaches like <a href="https://tailwindcss.com/">Tailwind</a> and <a href="https://purgecss.com/">PurgeCSS</a></li>
</ul>

<p>This stack is extremely powerful and the development experience allows you to really fly. You can build fast and interactive applications with a small team, all while still experiencing the joy of a 2014-era vanilla Rails codebase.</p>

<p>But years of a <a href="https://macwright.org/2020/05/10/spa-fatigue.html">JavaScript SPA-heavy monoculture</a> have made it hard to learn about this stack. The community is filled with practitioners, using the tools to build software and businesses. There simply has not been the same level of content produced and so many of these tools are unknown and can be unapproachable.</p>

<p>One of the ways I can contribute is to light the way for those want to know more by showing some real-world examples (not a <a href="http://todomvc.com/">TODO list</a> or a <a href="https://wsvincent.com/react-counter/">Counter</a>). Once you see how you can use tools like Stimulus and HTML responses to build features where you might instead reach for a tool like React, things will start to click.</p>

<h2 id="lets-build-something-real-hovercards">Let’s Build Something Real: Hovercards</h2>

<p>Hovercards show extra contextual information in a popup bubble when you hover over something in your app. You can see examples of this UI pattern on GitHub, Twitter, and even Wikipedia.</p>

<p><img src="https://boringrails.com/images/hovercard-examples.png" alt="Examples of hovercard UI"></p>

<p>This feature is really easy to build with Rails using an HTML-over-the-wire approach.</p>

<p>Here’s the plan:</p>

<ul>
  <li>Build a controller action to render the hovercard as HTML</li>
  <li>Write a tiny Stimulus controller to fetch the hovercard HTML when you hover</li>
</ul>

<p>…and that’s it.</p>

<p>We don’t need to make API endpoints and figure out how to structure all of the data we need. We don’t need to reach for React or Vue to make this a client-side component.</p>

<p>The beauty of this boring Rails approach is that the feature is dead-simple and it’s equally straightforward to build. It’s easy to reason about the code and super extensible.</p>

<p>For this example, let’s build the event feed for a sneaker marketplace app.</p>

<p><img src="https://boringrails.com/images/shoe-hovercard.gif" alt="Shoe feed hovercard example"></p>

<p>When you hover over a shoe, you see a picture, the name, the price, etc. Same for the user, you can see a mini-profile for each user.</p>

<h3 id="the-frontend-stimulus--fetch">The Frontend (Stimulus + fetch)</h3>

<p>The markup for the link looks like:</p>

<div><div><pre><code><span>&lt;!-- app/views/shoes/feed.html.erb --&gt;</span>

<span>&lt;div</span>
  <span>class=</span><span>"inline-block"</span>
  <span>data-controller=</span><span>"hovercard"</span>
  <span>data-hovercard-url-value=</span><span>"</span><span>&lt;%=</span> <span>hovercard_shoe_path</span><span>(</span><span>shoe</span><span>)</span> <span>%&gt;</span><span>"</span>
  <span>data-action=</span><span>"mouseenter-&gt;hovercard#show mouseleave-&gt;hovercard#hide"</span>
<span>&gt;</span>
  <span>&lt;%=</span> <span>link_to</span> <span>shoe</span><span>.</span><span>name</span><span>,</span> <span>shoe</span><span>,</span> <span>class: </span><span>"branded-link"</span> <span>%&gt;</span>
<span>&lt;/div&gt;</span>
</code></pre></div></div>

<p>Note: we are using the APIs from the <a href="https://github.com/stimulusjs/stimulus/pull/202">Stimulus 2.0</a> preview release!</p>

<p>One of the great features of Stimulus is that you can read the markup and understand what’s happening without diving into the JavaScript.</p>

<p>Without knowing anything else about the implementation, you could guess how it’s going to work: this link is wrapped in a <code>hovercard</code> controller, when you hover (via <code>mouseenter</code> and <code>mouseleave</code> events) the card is shown or hidden.</p>

<p>As recommended in <a href="https://boringrails.com/articles/better-stimulus-controllers/">Writing Better Stimulus Controllers</a>, you should pass in the URL for the hover card endpoint as a data property so that we can re-use the <code>hovercard_controller</code> for multiple types of cards. This also keeps us from having to duplicate the application routes in JavaScript.</p>

<div><div><pre><code><span>// app/javascript/controllers/hovercard_controller.js</span>

<span>import</span> <span>{</span> <span>Controller</span> <span>}</span> <span>from</span> <span>"</span><span>stimulus</span><span>"</span><span>;</span>

<span>export</span> <span>default</span> <span>class</span> <span>extends</span> <span>Controller</span> <span>{</span>
  <span>static</span> <span>targets</span> <span>=</span> <span>[</span><span>"</span><span>card</span><span>"</span><span>];</span>
  <span>static</span> <span>values</span> <span>=</span> <span>{</span> <span>url</span><span>:</span> <span>String</span> <span>};</span>

  <span>show</span><span>()</span> <span>{</span>
    <span>if</span> <span>(</span><span>this</span><span>.</span><span>hasCardTarget</span><span>)</span> <span>{</span>
      <span>this</span><span>.</span><span>cardTarget</span><span>.</span><span>classList</span><span>.</span><span>remove</span><span>(</span><span>"</span><span>hidden</span><span>"</span><span>);</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>fetch</span><span>(</span><span>this</span><span>.</span><span>urlValue</span><span>)</span>
        <span>.</span><span>then</span><span>((</span><span>r</span><span>)</span> <span>=&gt;</span> <span>r</span><span>.</span><span>text</span><span>())</span>
        <span>.</span><span>then</span><span>((</span><span>html</span><span>)</span> <span>=&gt;</span> <span>{</span>
          <span>const</span> <span>fragment</span> <span>=</span> <span>document</span>
            <span>.</span><span>createRange</span><span>()</span>
            <span>.</span><span>createContextualFragment</span><span>(</span><span>html</span><span>);</span>

          <span>this</span><span>.</span><span>element</span><span>.</span><span>appendChild</span><span>(</span><span>fragment</span><span>);</span>
        <span>});</span>
    <span>}</span>
  <span>}</span>

  <span>hide</span><span>()</span> <span>{</span>
    <span>if</span> <span>(</span><span>this</span><span>.</span><span>hasCardTarget</span><span>)</span> <span>{</span>
      <span>this</span><span>.</span><span>cardTarget</span><span>.</span><span>classList</span><span>.</span><span>add</span><span>(</span><span>"</span><span>hidden</span><span>"</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>disconnect</span><span>()</span> <span>{</span>
    <span>if</span> <span>(</span><span>this</span><span>.</span><span>hasCardTarget</span><span>)</span> <span>{</span>
      <span>this</span><span>.</span><span>cardTarget</span><span>.</span><span>remove</span><span>();</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This is all of the JavaScript we’re going to be writing for this feature: it’s only ~30 lines and we can use this for any other hovercards in the app. There isn’t really anything app specific about this controller either, you could pull it into a separate module and re-use it across projects. It’s totally generic.</p>

<p>The controller uses the <code>fetch</code> API to call the provided Rails endpoint, gets some HTML back, and then inserts it into the DOM. As a small improvement, we use the Stimulus <code>target</code> API for data binding to save a reference to the card so that subsequent hovers over this link can simply show/hide the markup without making another network request.</p>

<p><img src="https://boringrails.com/images/hovercard-network.gif" alt="Hovercard Network tab"></p>

<p>We also choose to remove the card when leaving the page (via the <code>disconnect</code> lifecycle method), but you could also opt to hide the card instead depending on how you want caching to work.</p>

<h3 id="the-backend-rails--server-rendered-html">The Backend (Rails + Server rendered HTML)</h3>

<p>There is nothing magic on the frontend and it’s the same story on the backend.</p>

<div><div><pre><code><span># config/routes.rb</span>
<span>Rails</span><span>.</span><span>application</span><span>.</span><span>routes</span><span>.</span><span>draw</span> <span>do</span>
  <span>resources</span> <span>:shoes</span> <span>do</span>
    <span>member</span> <span>do</span>
      <span>get</span> <span>:hovercard</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Setup a route for <code>/shoes/:id/hovercard</code></p>

<div><div><pre><code><span># app/controllers/shoes_controller.rb</span>
<span>class</span> <span>ShoesController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>...</span>

  <span>def</span> <span>hovercard</span>
    <span>@shoe</span> <span>=</span> <span>Shoe</span><span>.</span><span>find</span><span>(</span><span>params</span><span>[</span><span>:id</span><span>])</span>

    <span>render</span> <span>layout: </span><span>false</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Write a basic controller action, the only difference being that we set <code>layout: false</code> so that we do not use the global application layout for this endpoint.</p>

<p>You can even visit this path directly in your browser to quickly iterate on the content and design. The workflow gets even better when using a utility-based styling approach like Tailwind since you don’t even need to wait for your asset bundles to rebuild!</p>

<div><div><pre><code><span>&lt;!-- app/views/shoes/hovercard.html.erb --&gt;</span>

<span>&lt;div</span> <span>class=</span><span>"relative"</span> <span>data-hovercard-target=</span><span>"card"</span><span>&gt;</span>
  <span>&lt;div</span> <span>data-tooltip-arrow</span> <span>class=</span><span>"absolute bottom-8 left-0 z-50 bg-white shadow-lg rounded-lg p-2 min-w-max-content"</span><span>&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"flex space-x-3 items-center w-64"</span><span>&gt;</span>
      <span>&lt;%=</span> <span>image_tag</span> <span>@shoe</span><span>.</span><span>image_url</span><span>,</span> <span>class: </span><span>"flex-shrink-0 h-24 w-24 object-cover border border-gray-200 bg-gray-100 rounded"</span><span>,</span> <span>alt: </span><span>@shoe</span><span>.</span><span>name</span> <span>%&gt;</span>

      <span>&lt;div</span> <span>class=</span><span>"flex flex-col"</span><span>&gt;</span>
        <span>&lt;span</span> <span>class=</span><span>"text-sm leading-5 font-medium text-indigo-600"</span><span>&gt;</span>
          <span>&lt;%=</span> <span>@shoe</span><span>.</span><span>brand</span> <span>%&gt;</span>
        <span>&lt;/span&gt;</span>

        <span>&lt;span</span> <span>class=</span><span>"text-lg leading-0 font-semibold text-gray-900"</span><span>&gt;</span>
          <span>&lt;%=</span> <span>@shoe</span><span>.</span><span>name</span> <span>%&gt;</span>
        <span>&lt;/span&gt;</span>

        <span>&lt;span</span> <span>class=</span><span>"flex text-sm text-gray-500"</span><span>&gt;</span>
          <span>&lt;%=</span> <span>@shoe</span><span>.</span><span>colorway</span> <span>%&gt;</span>
          <span>&lt;span</span> <span>class=</span><span>"mx-1"</span><span>&gt;</span>
            <span>&amp;middot;</span>
          <span>&lt;/span&gt;</span>
          <span>&lt;%=</span> <span>number_to_currency</span><span>(</span><span>@shoe</span><span>.</span><span>price</span><span>.</span><span>to_f</span> <span>/</span> <span>100</span><span>)</span> <span>%&gt;</span>
        <span>&lt;/span&gt;</span>
      <span>&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
  <span>&lt;/div&gt;</span>
<span>&lt;/div&gt;</span>
</code></pre></div></div>

<p>The hovercard is built with a server-rended ERB template, same as any other …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boringrails.com/articles/hovercards-stimulus/">https://boringrails.com/articles/hovercards-stimulus/</a></em></p>]]>
            </description>
            <link>https://boringrails.com/articles/hovercards-stimulus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640713</guid>
            <pubDate>Thu, 25 Jun 2020 13:49:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Arrow Spark+AI Summit 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23640428">thread link</a>) | @cocobro
<br/>
June 25, 2020 | https://rohanhonwade.com/posts/apache-arrow-spark-ai-summit/ | <a href="https://web.archive.org/web/*/https://rohanhonwade.com/posts/apache-arrow-spark-ai-summit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<header>
			
		</header>
		
		<main role="main">
		
<article>
	<p>The Spark + AI summit for 2020 is currently happening from June 22nd to June 26th. There were talks by big names in the industry like Matei Zaharia
and even by Nate Silver from fivethirtyeight.com. There were multiple topics being talked about simultaneously and it was a difficult to just
pick one to listen to as all of them seemed interesting! I took some time to listen to Tomer Shiran, the founder of the Dremio project about the origins,
the need and use cases of Apache Arrow and how they used it in Dremio alongside the Apache Arrow Gandiva.</p>
<h2 id="the-data-querying-conundrum-in-data-lakes-paradigm">The data querying conundrum in Data Lakes paradigm</h2>
<p>Data Lakes are the talk of the town today! In today’s age where data is the chief asset that companies prize, they don’t want to lose any of it
and would rather have it stored in a Data Lake even if it does not make much sense to them right now, with the prospect of it being useful at a
later point in time. That very point makes the data unwieldy.</p>
<p>In such a scenario, when your data store has vast amounts of data, querying becomes slow because it is not just that the data is big but that
transferring data over the network when you query such stores also becomes a non-trivial factor. To get around this problem, companies again
copy part of their data from the Data Lake into Data Warehousing solutions like AWS Redshift. They then construct their OLAP cubes and
aggregations on top of this for fast querying of the underlying data. The drawback of this is that the flexibility of doing anything else with
this data reduces as you copy it into the Data Warehouse. This is the problem that the folks at Dremio / Apache Arrow are trying to solve -
how do you query your data directly from the Data Lake without having to copy it anywhere else?</p>
<h2 id="dremio">Dremio</h2>
<p>The folks at Dremio claim that they have built technology to query Data Lakes with 4 to 100 times better performance than existing solutions. The
way they were able to do it is by defining and implementing a new standard - Apache Arrow, of storing data in-memory in a columnar format for efficient
operations on today’s hardware. I will talk more about Apache Arrow later in this article.</p>
<p>Following are some features that power Dremio -</p>
<h3 id="data-reflections">Data Reflections</h3>
<p>Dremio creates a view of your data, an optimized data structure that lends itself well to boost different query patterns. This data structure can
also auto refresh itself.</p>
<h3 id="columnar-cloud-cache-c3">Columnar Cloud Cache (C3)</h3>
<p>The Columnar Cloud Cache feature takes advantage of local storage (generally NVMe - non-volatile memory express) for a distributed real time
caching solution that increases the amount of read throughput and reduces the amount of data transferred over the network. It is automatic, does
not need any user involvement and caches data based on SQL query patterns, workload management and file directory structures to optimize what to
store and evict.</p>
<h3 id="predictive-pipelining">Predictive Pipelining</h3>
<p>Dremio can predict access patterns of data which reduces its query response times. Based on usage patterns of analytical workloads and their understanding
of columnar data format, the Dremio folks provide this feature wherein they fetch data only before execution engine needs it.</p>
<h2 id="difference-between-dremio-and-facebooks-presto">Difference between Dremio and Facebook’s Presto</h2>
<p>Presto by Facebook is a distributed SQL engine over multiple data sources. Dremio offers more features on top of that. It sits between your
data over disparate sources and you who want an analysis of your data - it squashes the need for data warehousing solutions, OLAP cubes,
extracts and aggregations.</p>
<ul>
<li>Dremio claims to offer speeds of interactive nature with data of any volume</li>
<li>It has deep integrations with some data stores and is thus able to push down some compute when queries are made over those data sources</li>
<li>It is able to show how different datasets are related to each other by creating a lineage of data</li>
</ul>
<h2 id="apache-arrow">Apache Arrow</h2>
<p>Apache Arrow is a specification for storing data in a columnar format in memory, serializing the metadata and for transferring data over the network.
It uses Google Flatbuffers for metadata serialization. It was born out of Dremio’s internal memory format.</p>
<p>It provides constant time random access, data adjacency for sequential scans and lends itself easily for SIMD (single instruction, multiple data)
class of instructions in modern processors.</p>
<p>It serializes data as Arrow buffers / vectors which are basically arrays of the same size with different data types. This whole package together
constitutes its schema.</p>
<h2 id="gandiva">Gandiva</h2>
<p>Gandiva is a part of Dremio which provides a high performance execution engine over Apache Arrow data buffers. Gandiva takes a sql expression,
compiles it into LLVM bytecode and translates it to machine code. To get this high performance it is written in C++.</p>
<p>Tomer wrapped up the talk on Dremio with a demo of the platform as well.</p>
<p>Go give Dremio a try!</p>

</article>

		</main>
		
		
		
		
	</div></div>]]>
            </description>
            <link>https://rohanhonwade.com/posts/apache-arrow-spark-ai-summit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640428</guid>
            <pubDate>Thu, 25 Jun 2020 13:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Programming Shapes the Mind]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23640214">thread link</a>) | @pcmaffey
<br/>
June 25, 2020 | https://www.pcmaffey.com/how-programming-shapes-the-mind | <a href="https://web.archive.org/web/*/https://www.pcmaffey.com/how-programming-shapes-the-mind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What we pay attention to <a href="https://lithub.com/how-we-pay-attention-changes-the-very-shape-of-our-brains/" target="_blank">changes the shape of our brain</a>. Like water running through a landscape day after day after day, the neural pathways used in our work and routines cut familiar channels that give rise to the ecosystems of our mind. But paying attention is naturally selective. When we choose what to focus on, we are also choosing what to ignore.</p><p>I’ve been programming on and off since the 20th century. I see marked differences in myself, my behavior, perception, etc. when actively coding vs. not. It's finally time to investigate. What am I really paying attention to when programming? What are the implications?</p><p><i>And for the reader, what is your experience? Similar? Different? Or if you’re not a programmer, how does your discipline shape your perception?</i></p><p>When programming, I am writing the future. Every line of code is an instruction to be carried out predictably, if all goes well, a billion times over. Bits of simple logic—compounded across programs stacked on giant stacks of programs—create complex systems of logical inevitabilities.</p><p>To accomplish this, every command I write exercises a tiny mental loop:</p><ul><li><b><nobr>Step 1: </nobr></b><span>Research and understand the “inner logic” of relevant systems.</span></li><li><b><nobr>Step 2: </nobr></b><span>Formulate a hypothesis that models some new bit of logic.</span></li><li><b><nobr>Step 3: </nobr></b><span>Validate and iterate.</span></li></ul><p>Does it work? I test my code and expect an immediate response from the compiler. If yes, I move on to the next bit of logic in my day's lineup. If no, I retest my underlying arguments, breaking down my code into smaller and smaller bits. Every step of the way, my attention walks as efficiently as possible, a garden of forking yes/no paths. It's as if it were me, and not just an electric current, running through the logic gates of my computer’s circuit board.</p><p>When our brain focuses its attention, neuromodulators amplify its activated neural circuits. Like a spotlight on stage, the "speaking" actor is lit up. And likewise, the rest of the stage is intentionally dimmed. We actively suppress competing areas of the brain <code>"with slow waves in the alpha frequency band (between eight and twelve hertz), which inhibit a circuit by preventing it from developing coherent neural activity."</code></p><p>What part of my brain am I suppressing when I spend all day coding? The easy and obvious answer would be the opposite of logic—something to do with emotion. There’s certainly not much place for emotion in programming. This may influence why some of us gravitate more to front-end development—to be not so far from people. Or vice versa. But does programming suppress emotion? Let’s explore deeper.</p><h2>The Good</h2><p>I <a title="Click to expand">learned to code on LSD.</a><sup title="Click to expand">*</sup> Twenty-some years later, there are a few things I love about software development. But none more than the way it encourages and rewards mental plasticity through constant learning and unlearning.</p><p>We break systems apart in order to understand the imperative logic that glues them together. In the game of programming, the rules are entirely knowable… with enough digging. Somewhere, at some point in time, someone wrote them (and hopefully documented them). Debugging feels like the archeology of quirks, from programs layered atop older programs. There’s a real joy in discovery when we unlock a path forward. Over time, this clarity develops into confidence, and we approach systems knowing that yes, if needed, we could do the work to understand any part of this. Fortunately, this is far from what’s usually required; we rarely go deeper than the syntax and grammar of our immediate environment. But our environment still is always changing, and so we must always be learning.</p><p>The second joy of programming: I can build something out of nothing—or more specifically, out of logic and electricity. I’ve built with stone, wood, ink, plastic, etc. The freedom afforded by code is unique and specific—a kind of scalable mental scaffolding. Logically valid patterns can repeat ad infinitum into some functional space, limited for the most part only by their utility.</p><p>For me, programming enhances this way of seeing, which carries over into other areas of my life. My chess game improves drastically when actively coding. I see more clearly defined the risks and consequences of a position. Things seem more obvious, inevitable. I can break down an argument into its key dependencies, find flaws, and put it all back together efficiently optimized towards some solution. My mind begins to resemble the programs I work on.</p><h2>The Bad</h2><p>My mind begins to resemble the programs I work on. The ability to build applications is empowering; but I lose power when I become just another program in the stack for people to input instructions and expect outputs. I’ve seen it throughout my career. No one wants to be a code monkey. And yet, it’s a natural consequence of specialization. Developers are inevitably busy writing code all day, not talking to people. Yes, we’re a strange bunch to begin with, and to follow the stereotype, likely more comfortable with computers than people anyways. But it seems our work reinforces our role as awkward, estranged mental laborers.</p><p>I’d thought I could hack life with the same ease I could hack a program. But life is not an abstract model of logic where outcomes are inevitable and predictable. From where I stand as a microscopic organism inside an unknown number of infinite universes, math can only solve for so much. Certainly, many of society’s rules can be gamed. My heightened logic serves me well in certain domains. But, I struggle too—there’s a price I pay for spending days programming.</p><p>It’s difficult to be exact talking about this, but I feel it strongly in 3 areas of my life:</p><ul><li><b><nobr>1.</nobr></b><span>As I get older, the health impacts—physical and mental—become more apparent. I sit (or sometimes stand) staring into an artificial sun. My body becomes disoriented by space and time. My mind gets wound up, locked into the gears of software. My eyes go dim and blurry. Hiking with the dogs for an hour at the end of every day helps, but it’s not enough. I still find myself reaching for an easy jolt back to reality, often in the form of a drink.</span></li><li><b><nobr>2.</nobr></b><span>Programming requires a quite specific mental model that makes it difficult to balance in parallel with other, more creative activities (making art, creative writing, cooking, etc.). They all struggle for my attention like children with divergent needs. It’s not so simple as time boxing activities and switching modalities, as I have to travel half way around my mind to get from one headspace to another. Too often, I end up stuck wasting my time commuting between <a title="Click to expand">competing mindsets.</a><sup title="Click to expand">*</sup></span></li><li><b><nobr>3.</nobr></b><span>Finally, and perhaps the most significant consequence: I find it challenging to relate to others when in the mindset of programming. After spending my day communicating with the compiler in encoded logic, writing commands, and expecting immediate responses, talking with a human feels slow and inefficient.</span></li></ul><p>This last point is a bit of a trope, so I want to expand. When my attention is zeroed in programming, it’s not emotion that my mind suppresses, but rather, my ability to listen, to really listen. I notice it when talking with my wife (with whom I have 10+ years of observed patterns). After a day of programming, I hear her “inputs” and I can “output” the appropriate answer. But I lose touch with her human experience. What’s not explicitly defined ceases to register. Unless I’m being intentional about it, programming often degrades my capacity for empathy.</p><p>Empathy requires a different relationship to the unknown. It enables us to “hold space” for the valid, yet truly unknowable experience of another person. It saves us from projecting our ideas of ourselves, filled with expectations and judgements, into that space. That’s not to say we don’t try to understand or pattern-match. Or that we don’t share our own experience in response. It’s just that there’s no equation that can solve for two peoples life, history, genetics, etc. We try, of course, with derivatives, approximations, and metaphor. But this is where logic ends and art begins.</p><h2>The Unknown</h2><p>So what? Programming supports my way of life, my family. These side-effects are collateral damage. But I know that by seeking to understand them, I can at least begin to address negative impacts.</p><p>Perhaps, this is just one man’s experience and not something I should generalize. But my curiosity beckons, if what I’m writing about is an experience at all common to programmers, what are the implications?</p><h3>1. Can we find a healthier, more sustainable balance with programming?</h3><p>This obviously applies to computer work in general; the physical constraints and proposed solutions are well-documented—good ergonomics, exercise, etc. But on the mental side, how do we ground ourselves during a day spent riding the proverbial lightning? Stretched across the course of a career, how does this contribute to programming being a “young person’s game,” where individual contributors as they get older burn out and switch to manager roles?</p><h3>2. Looking through the wide-angle lens: is our work’s suppression of empathy at the root of the tech-lash?</h3><p>Tech has a lossy view of the human experience. We are degraded to a few million data points. Emotion is gamified for attention, dollars, and worse. Human activity online can be easily modeled by a bot. It's common to marvel at how advanced bots and algorithms have become. But on the flip side, it reveals how shallow our models of the human experience online actually are, that a few automated clicks and some NLP can fool us.</p><p>As they say, we only improve what we measure. But we don’t measure what we don’t know. We don’t talk about empathy because it’s not a variable or a metric in any of our systems. So how can we make space for empathy in our programs as they continue to eat the world?</p><h3>3. A final thought on the future of programming</h3><p>We're entering the terrain of science-fiction here, but what would it mean to program for empathy, to encode it in our systems? Here's one possible requirement: can our programs ever account for unknowable truths?</p><p>Pe…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pcmaffey.com/how-programming-shapes-the-mind">https://www.pcmaffey.com/how-programming-shapes-the-mind</a></em></p>]]>
            </description>
            <link>https://www.pcmaffey.com/how-programming-shapes-the-mind</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640214</guid>
            <pubDate>Thu, 25 Jun 2020 13:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture, part 2]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 118 (<a href="https://news.ycombinator.com/item?id=23640011">thread link</a>) | @kickout
<br/>
June 25, 2020 | http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-20">
		
	
	<div>
		
<p>Some commenters (/u/coderintherye chain notably) on the <a href="https://news.ycombinator.com/item?id=23630201">HN post</a> of the <a href="https://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">original article</a> brought up good points that I wanted to expand on and provide some additional context. Also for clarification: although farming is truly global, most ‘farming’ I refer to pertains to the United States (<a href="https://en.wikipedia.org/wiki/Agriculture_in_the_United_States">which is an agriculture juggernaut</a>), but in my experience should reasonably translate across agriculture zones (pending equivalent laws and climatic factors).</p>



<p><strong><em>There is ample VC money for Ag startups</em></strong></p>



<p>The original intention of the article wasn’t to bemoan the lack of capital available for <a href="https://agiowa.com/portfolio/">founders focused on agriculture</a> (there is actually plenty of capital–check out <a href="https://agfundernews.com/">AgFunderNews</a> for examples of successful raises). Instead, it is a recommendation for anyone entering the space to understand the industry and its history to harness existing synergies rather than try and swim upstream. Watching capital go to ‘solved’ problems is painful, because there are many opportunities for a unicorn ag startup if aimed in the correct space. Vertical farming for non-vegetables (or fruits) is likely dead-on-pitch. Yes, vertical farming <em>is</em> and <em>could be</em> successful, but those markets are very specific and probably 10x smaller than people think. Nice businesses no doubt, but not market shaping behemoths VCs are after. Agriculture is rightfully a commodity and the market will brutalize ideas/companies that can’t turn a profit. One bad year (droughts in 2011 and 2012 in the US Midwest) from external forces can absolutely put farmers out of business. Indoor farming has all of the risks of outdoor ag–and more! Indoor farming requires water (whose source can dry up and get shut off unexpectedly, just like a drought), has pests, and requires artificial lighting (power outage for 5 days? Uh oh). Herbicides (and sometimes pesticides) are actually an example of innovation pre-SV. Alternate technologies (i.e mechanical) didn’t work or were uneconomical for the time period; thus, chemical solutions seemed to thrive (glyphosate/glufosinate resistant corn/soy/wheat/cotton/sugar beets &amp; <a href="https://agrilife.org/lubbock/files/2020/02/BtTraitTable_FEB_2020.pdf">BT resistance for insects</a>). I predict in next 5-20 years we see that flip, where chemical and biological solutions fall out in favor of mechanized solutions (who wouldn’t want a semi-autonomous robot pulling weeds in fields in favor of a chemical solution that is <a href="https://www.nbcnews.com/news/us-news/bayer-reaches-10-5-billion-settlement-roundup-cancer-lawsuits-n1232026">open to litigation</a>)? We just have too little understanding of 2nd and 3rd order effects of disrupting nature at this scale (<a href="https://www.nature.com/articles/s41598-019-49660-6">gene drives included</a>, as promising as they appear) using these incredibly effective chemicals.</p>



<p><strong><em>Financing in the Heartland</em></strong></p>



<p>I won’t speak of financing agricultural operations in a municipality not located in the United States, as even understanding the US situation takes time and effort. Let’s be clear though: Most farmers <em>need</em> to borrow capital just to operate for a given year (hence, there is a note called an ‘operating loan’) and financing agriculture operations is more and more important as the size of farms increases. They buy seed, fertilizer, feed, chemicals, etc. to be able to produce an output to then (hopefully) sell at a profit–all to rinse and repeat. Buying big expensive new tractors ($300k+ USD), buildings to store the machines, grain storage, fencing, animal houses–all generally require a loan. Because of the huge cost to purchase these necessities, financing institutions generally need to have a <em>very</em> thorough understanding of the operation (Only farm 160 acres of corn,soy,or wheat? Good luck buying equipment). So bankers have become very good (not perfect) at evaluating and swaying farming practices to ensure maximum likelihood of repayment. Seriously, check of the used auction prices of ag machinery sometime–<a href="https://www.bigiron.com/Lots/2011JohnDeere8335RMFWDTractor-3">this tractor</a> is 10 years old and commands the price of a new Tesla. Is ag financing a place that needs disruption? Likely no because ag lending has evolved hand-in-hand in rural communities where agricultural production is the predominant industry. Because they evolved with ag, they likely have already captured the +EV that startups tend to seek because their very existence depends on it. So where <em>are</em> the value proposition? I know nothing of their founding, but the previous auction link is from <a href="https://www.bigiron.com/">Big Iron Auctions</a> and those founders likely understood ag (“hey, there is a robust secondary market for farm machinery”) and created on-line version of it–with what appears to be great success. I’d imagine these on-line secondary markets exist in Brazil and Eastern Europe given there agriculture exposure. </p>



<p><strong><em>Success Stories</em></strong></p>



<p>There are some truly incredible examples of engineering and innovation in agriculture that focus on the mechanization and scale <em>that already exists</em>. Transplanting vegetables in the Central Valley (CA) used to be labor intensive–<a href="https://www.planttape.com/">this brilliant solution solved that</a>. Auto-steer <a href="https://www.fieldbee.com/blog/fieldbee-tractor-autosteer-versus-other-systems/">systems</a> that leverage machinery that already exists. Sometimes the innovation is statistical/computation (<a href="https://www.annualreviews.org/doi/full/10.1146/annurev-animal-021815-111422">genomic prediction has revolutionized dairy cattle</a>) Starting businesses is hard and agriculture is no different.</p>



<p>Stay away from vertical farming–unless you plan on growing saffron or figure out a way to cultivate morel mushrooms!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640011</guid>
            <pubDate>Thu, 25 Jun 2020 12:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Java's Stream Implementation with Go Generics]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639960">thread link</a>) | @shagabutdinov
<br/>
June 25, 2020 | https://snake-ci.com/blog/go2go-stream/ | <a href="https://web.archive.org/web/*/https://snake-ci.com/blog/go2go-stream/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<div>
										
										<p>The Go team recently released a new post in the Go blog called
<a href="https://blog.golang.org/generics-next-step">Â«The Next Step in GenericsÂ»</a> and updated the design draft on
<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md">Â«Type ParametersÂ»</a> (a long one).</p>

<p>In the current post I’m going to describe how to port Java’s Stream to Go 2 Generics.</p>

<p>Let’s make it straightforward â€” define the Stream:</p>

<pre><code>type Stream(type Type) struct {
	slice    []Type
	parallel bool
}
</code></pre>

<p>Here we declare a new type using type parameter <code>Type</code> with underlying slice <code>[]Type</code>.</p>

<p>And let’s have a constructor:</p>

<pre><code>func Of(type Type)(slice []Type) *Stream(Type) {
	return &amp;Stream(Type){
		slice: slice,
	}
}
</code></pre>

<p>The parameter <code>(type Type)</code> after name of function and in type declaration is Type Parameter.
The type parameter is required whenever we are going to use generics.</p>

<p>Now we can implement core functions of a typical stream:</p>

<ul>
<li>Filter</li>
<li>Map</li>
<li>Reduce</li>
<li>ForEach</li>
<li>Collect</li>

<li><p>AnyMatch/AllMatch/NoneMatch</p>

<pre><code>func (stream *Stream(Type)) Filter(predicate func(Type) bool) *Stream(Type) {
	filtered := []Type{}
	for _, item := range stream.slice {
		if predicate(item) {
			filtered = append(filtered, item)
		}
	}
	stream.slice = filtered
	return stream
}

func Map(type Type, R)(stream *Stream(Type), predicate func(Type) R) *Stream(R) {
	slice := make([]R, len(stream.slice))
	for i, item := range stream.slice {
		slice[i] = predicate(item)
	}
	return Of(slice)
}

func Reduce(type Type, R)(stream *Stream(Type), predicate func(R, Type) R) R {
	var result R
	for _, item := range stream.slice {
		result = predicate(result, item)
	}
	return result
}

func (stream *Stream(Type)) ForEach(predicate func(Type)) *Stream(Type) {
	for _, item := range stream.slice {
		predicate(item)
	}
	return stream
}
</code></pre></li>
</ul>

<p>Notice that Map and Reduce functions are not declared on <code>Stream(Type)</code>. It’s one of unsolved problems of current generics
design draft â€” parametrized methods are not permitted.</p>

<p>It means that we can have a function that receives type <code>A</code> and returns type <code>B</code>:</p>

<pre><code>func foo(type A, B) (a A) B
</code></pre>

<p>But we can’t declare a parametrized method on type <code>Struct(A)</code> like this:</p>

<pre><code>func (s Struct(A)) foo(type B) (a A) B
</code></pre>

<blockquote>
<p>This design draft does not permit methods to declare type parameters that are specific to the method. The receiver may
have type parameters, but the method not add any type parameters.
<a href="https://go.googlesource.com/proposal/+/refs/heads/master/design/go2draft-type-parameters.md#no-parameterized-methods">Quote from the updated design draft</a></p>
</blockquote>

<p>It’s time for the cherry on top â€” <code>Stream(Type).Collect()</code>.</p>

<p>The signature of Collect function will be pretty simple:</p>

<pre><code>func Collect(type Type, Col)(
	stream *Stream(Type),
	collector collector.Collector(Type, Col),
) Col
</code></pre>

<p>Notice that now we have two type parameters â€” one for original type that was used for creating a stream and another one
for resulting collection.</p>

<p>Here is a interface for a typical collector that consists of four functions:</p>

<ul>
<li><code>Supply()</code> â€” a function that creates and returns a new result container.</li>
<li><code>Accumulate()</code> â€” a function that folds a value into a mutable result container.</li>
<li><code>Combine()</code> â€” a function that accepts two partial results and merges them. This is going to be used only in parallel mode.</li>

<li><p><code>Finish()</code> â€” while in Java this method converts from an intermediate type to the final result type, but in order to save
the simplicity of the implementation, it will return the same type.</p>

<pre><code>type Collector(type Type, Col) interface {
	Supply() Col
	Accumulate(Col, Type) Col
	Finish(Col) Col
	Combine(Col, Col) Col
}
</code></pre></li>
</ul>

<p>Now we have the interface, we need an implementation. But since we want to allow developers to add
their own implementations without declaring new types, we need a constructor that will accept functions, think of it
like <code>http.HandleFunc()</code> which is often used to wrap functions and returns <code>http.Handler</code>.</p>

<p>We will declare a new constructor for <code>Collector(Type, Col)</code> like we did for <code>Stream(Type)</code> that will return unexported
implementation of <code>Collector(Type, Col)</code> that will just call the given functions:</p>

<pre><code>func Of(type Type, Col)(
	supply func() Col,
	accumulate func(Col, Type) Col,
	finish func(Col) Col,
	combine func(Col, Col) Col,
) Collector(Type, Col) {
	return impl(Type, Col){
		supply:     supply,
		accumulate: accumulate,
		finish:     finish,
		combine:    combine,
	}
}
</code></pre>

<p>Notice that we also have to specify <code>(Type, Col)</code> for <code>Collector</code> even though we specified it later <code>impl(Type, Col)</code>.</p>

<p>The <code>impl(Type, Col)</code> type is going to be a holder of functions that implements the <code>Collector(Type, Col)</code> interface:</p>

<pre><code>type impl(type Type, Col) struct {
	supply     func() Col
	accumulate func(Col, Type) Col
	finish     func(Col) Col
	combine    func(Col, Col) Col
}

func (collector impl(Type, Col)) Supply() Col {
	return collector.supply()
}

func (collector impl(Type, Col)) Accumulate(collection Col, item Type) Col {
	return collector.accumulate(collection, item)
}

func (collector impl(Type, Col)) Finish(collection Col) Col {
	if collector.finish == nil {
		return collection
	}
	return collector.finish(collection)
}

func (collector impl(Type, Col)) Combine(collection1, collection2 Col) Col {
	return collector.combine(collection1, collection2)
}
</code></pre>

<p>Here we’re good, now let’s declare a simple collector that is going to convert a <code>Type</code> to <code>Map[Key]Value</code> â€” <code>ToMap</code>:</p>

<pre><code>func ToMap(type Type interface{}, Key comparable, Value interface{})(
	mapper func(Type) (Key, Value),
	accumulator func(Value, Value) Value,
) Collector(Type, map[Key]Value) {
	return Of(
		func() map[Key]Value {
			return map[Key]Value{}
		},
		func(table map[Key]Value, item Type) map[Key]Value {
			key, value := mapper(item)
			now, _ := table[key]
			table[key] = accumulator(now, value)
			return table
		},
		func(table map[Key]Value) map[Key]Value {
			return table
		},
		func(table1, table2 map[Key]Value) map[Key]Value {
			for k2, v2 := range table2 {
				v1, _ := table1[k2]
				table1[k2] = accumulator(v1, v2)
			}
			return table1
		},
	)
}
</code></pre>

<p>An interesting thing about this function is that while it has three separated type parameters, it returns
<code>Collector(Type, map[Key]Value)</code> that uses only two type parameters.</p>

<p>Note that we need to specify Type Constraint for Key <code>comparable</code> in order to use it as key of a map otherwise it just
wouldn’t work.</p>

<p><code>ToMap</code> expects two functions on input:</p>

<ul>
<li>Mapper <code>func(Type) (Key, Value)</code> â€” receives an original element and returns two values: first one is going to be used as key
of the map, and the second one is going to be used as the value of the map[key]</li>
<li>Accumulator <code>func(now Value, update Value) Value</code> â€” receives current value of map[key] and new value <code>update</code> that have to be
somehow accumulated into <code>now</code>.</li>
</ul>

<p>Let’s see how it will work out on practice:</p>

<ol>
<li><p>Declare a simple type that will describe a movie and a score that a user gave to the movie:</p>

<pre><code>type MovieVote struct {
	Name  string
	Score int
}
</code></pre></li>

<li><p>Create a stream of slice of some movies and user votes:</p>

<pre><code>items := stream.Of(
	[]MovieVote{
		{Name: "A", Score: 1},
		{Name: "A", Score: 2},
		{Name: "B", Score: 9},
		{Name: "B", Score: 10},
		{Name: "B", Score: 8},
		{Name: "C", Score: 7},
		{Name: "C", Score: 8},
		{Name: "C", Score: 7},
	},
)
</code></pre></li>

<li><p>Now let’s convert them into <code>map[Name]SumOfScore</code>:</p>

<pre><code>result := stream.Collect(
	items,
	collector.ToMap(MovieVote, string, int)(
		func(movie MovieVote) (string, int) {
			return movie.Name, movie.Score
		},
		func(total, score int) int {
			return total + score
		},
	),
)
fmt.Println(result)
</code></pre></li>
</ol>

<ul>
<li>The mapper returns name as key and score as value</li>
<li>The accumulator sums total and current score</li>
</ul>

<p>Output:</p>

<pre><code>map[A:3 B:27 C:22]
</code></pre>

<p>By the way, this collector also works in Parallel mode, check it out in the source code:</p>

<ul>
<li><a href="https://github.com/reconquest/goava/blob/master/stream/examples_test.go2#L91">how to use with Parallel()</a></li>
<li><a href="https://github.com/reconquest/goava/blob/master/stream/stream.go2#L148">implementation of concurrent Collect() using Combine()</a></li>
</ul>

<p>Source Code is available on GitHub: <a href="https://github.com/reconquest/goava">github.com/reconquest/goava</a></p>

<p>And a big shout-out to Matt Layher for his article about <a href="https://mdlayher.com/blog/go-generics-draft-design-building-a-hashtable/">building a hashtable with new Go generics</a>!</p>

<p>Cool stuff, heh!</p>

									</div>
								</div></div>]]>
            </description>
            <link>https://snake-ci.com/blog/go2go-stream/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639960</guid>
            <pubDate>Thu, 25 Jun 2020 12:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I overcame YouTube addiction and you should too]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639870">thread link</a>) | @goddamnsteve
<br/>
June 25, 2020 | https://praveenjuge.com/blog/how-i-overcame-youtube-addiction/ | <a href="https://web.archive.org/web/*/https://praveenjuge.com/blog/how-i-overcame-youtube-addiction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><hr><p itemprop="description">I don't use social media often, that's by design. I know if I start using it regularly, I will become addicted to it. So, imagine my surprise when on one Sunday afternoon I found out that I spent the entire day doing nothing but watching videos on YouTube.</p><p>The saddest thing is that I didn’t even remember what I was watching. It was just a clockwork for my brain at that point. Wake up, open YouTube, watch a video, continue watching videos.</p><p>I write this blog on another Sunday afternoon, almost three months after, to say that I watched YouTube for just 10 minutes this week to watch a work-related video that a colleague sent.</p><p>I’m a little proud of myself, to tell the truth.</p><p>This is a log of everything I did to overcome this addiction. If it helped me, it might help someone else too.</p><h2 id="how-and-why-i-became-addicted">How and Why I Became Addicted</h2><p>YouTube is a community where billions of people share their talents, interests and findings with you.</p><p><strong>That’s the hook.</strong></p><p>The <strong>real</strong> YouTube is a billion-dollar company where hundreds of researchers and designers manipulate an algorithm to deliver a low-quality video to you.</p><p>I thought about why I was addicted for a long time. It basically was three things,</p><ul><li>Types of videos I watch</li><li>YouTube’s Algorithm</li><li>YouTube’s Story</li></ul><h3 id="types-of-videos-i-watch">Types of videos I watch</h3><h4 id="gaming-30">Gaming (30%)</h4><p>This one was easy to justify for me, I like watching someone be good at something. Until I realized that this was a passive way of thinking about it.</p><p>I’m not raising my skill by watching this, so what’s the point? The only way I could get better at video games is to play it more, not by watching someone else play it.</p><h4 id="self-help-30">Self Help (30%)</h4><p><strong>Biggest trap of them all.</strong> Productivity, Self Help, Motivational channels might seem to have a good agenda on the onset but they can’t profit if you actually improve yourself.</p><p>Most of the YouTubers in this category are good people at heart. But they know that 90% of the people watching them won’t improve anything in their life. They just like the feeling of improving themselves.</p><p>Every time you watch one of the self-help videos, your brain plays a trick on you. It makes you think that you are actually improving yourself but when in reality you are just actually watching a video that you will forget in 40 minutes.</p><p>You will come for more when that rush is over. And YouTube tells them to create more videos quickly for us to consume.</p><p>For quick reference these are the only things they will say to you from now until eternity:</p><ul><li>Self Help YouTubers: Take care of yourself</li><li>Productivity YouTubers: Organize your life for deep work</li><li>Motivational YouTubers: Never stop the Hustle (This will lead to burnout by the way.)</li></ul><p>Ironically most of these YouTubers recommend you to read a book.</p><h4 id="design-and-development-20">Design and Development (20%)</h4><p>I’m a professional web designer, so it’s important for me to keep up with the latest developments in my field. Of course, that’s what I told myself.</p><p>Things always change but YouTube is not a place to capture it. YouTube videos seem to be the fast-food sector of the industry. Fast to the point but not impactful and everlasting.</p><p>I’ve found that written content like</p><ul><li>Blog Posts</li><li>Documentation</li><li>Best Practices</li><li>Newsletters</li><li>Case Studies</li></ul><p>are often more informative and educational. They let you,</p><ul><li>Read at your own pace</li><li>Accessible and Developer Friendly</li><li>Most of them are intended to be everlasting or updated frequently</li></ul><p>One might argue developer tutorials are inherently good and I agree, but I usually get a better flow in my work from written tutorials.</p><p>These are mostly for entertainment, but as I distance myself from these more and more I find them to be passive entertainment.</p><p>Netflix has a collection of marvelously produced entertainment that will take my entire lifetime to watch. Why should I settle for this glut?</p><h4 id="pointless-internet-drama-10">Pointless Internet Drama (10%)</h4><p>This was the cone of shame for me, I liked reality TV, YouTubers fighting with each other and mostly pointless drama. I was thinking about why I like this, and then a quote someone said came to me,</p><p>Don’t live on someone else’s life.</p><p>I was projecting. I have a simple life with no problems. So, I liked watching other people have problems. I thought I was superior to them in some way and that made me feel good.</p><p>Of course, I was the idiot watching videos while they simply got paid and went home.</p><h3 id="youtubes-algorithm">YouTube’s Algorithm</h3><p>Whenever I open YouTube, it shows me a carefully chosen list of videos that interests me. It’s a combination of what I recently liked, latest videos from the creators I like, trending videos from my location, and cute animals.</p><p><strong>It’s impossible not to click on any of these.</strong></p><p>YouTube’s algorithm is very powerful at this point, probably the most sophisticated recommendation engine in the world. You simply can’t win it.</p><p>You can, however, not participate in its game. Some steps you can take:</p><ul><li><p><strong>Do not <code>smash that like button</code> on any videos.</strong></p><p>If you want to see a video again, download it to your drive. The YouTube video can be removed, blocked, or altered but you can always have what you want.</p></li><li><p><strong>Do not <code>hit that bell icon</code>.</strong></p><p>Voluntarily having more notifications on your phone is the first step to becoming mindless and have other people dictate where you spend your time.</p></li><li><p><strong>Pause Watched History and Search History.</strong></p><p>Again, download important videos. 98% of what you watch is not worth it and the other 2% can easily be searched again.</p></li></ul><p>Clear watch history, remove previously liked videos, clear out your comments. Do not give any indication to YouTube on what you like.</p><p>I even ran a puppeteer (automated script) to remove all the videos from my recommendation but it just pops back up. The <code>Not Interested</code> option is not real.</p><p><strong>Ultimately, be utilitarian on what you want.</strong></p><p>If you want to learn <em>How to Tie a Tie</em>, search for it, learn it and close it. Don’t needlessly subscribe, like or engage in any way.</p><h3 id="youtubes-story">YouTube’s Story</h3><p>A brand’s story is what you want other people to tell about your brand. YouTube’s story is,</p><p>YouTube is a community of people giving free information and entertainment.</p><ul><li><p><strong>YouTube is not a community.</strong></p><p>Individual creators may create a community. But YouTube is a company that wants nothing but profits.</p></li><li><p><strong>YouTube is not free.</strong></p><p>Nothing Google does is free.</p></li><li><p><strong>YouTube gives low-quality information and entertainment.</strong></p><p>Only 5% of its millions of videos are actually helpful. Don’t take that burden of sifting through all that to find something you might like.</p></li></ul><h2 id="how-i-overcame-youtube">How I Overcame YouTube</h2><p>Here are some simple and actionable steps that I took over the months,</p><ol><li><p><strong>Cancelling YouTube Premium</strong></p><p>If you get pissed off at the ads like I do, then it’s good. You will quit the video soon.</p></li><li><p><strong>Turn off notifications</strong></p><p>Taylor Swift’s new music video is not that important to notify you. No one should have the right to disturb you anytime they want.</p></li><li><p><strong>Reducing subscriptions</strong></p><p>Go through your subscription list and remove anyone who you don’t need in your life anymore. I followed this and removed almost 300 subscriptions and I don’t even remember what they were now.</p></li><li><p><strong>Uninstalling apps</strong></p><p>YouTube is available everywhere, it doesn’t need to be on your phone or tablet. You can always watch in your mobile browser for something urgent.</p><p>Mobile apps have 30% higher engagement rate. We actively go back to an app more often than a website. That’s why everyone keeps pushing you to download their app. Don’t.</p></li><li><p><strong>Remove all subscriptions</strong></p><p>After some time, I naturally removed all my subscriptions, I found alternate sources to topics I was interested in. Books, Newsletters, Spotify, and Netflix was enough for me.</p><p>Tip: Subscribe to a channel called <code>Sub with no videos</code> to reduce the recommendations in your subscriptions tab.</p></li><li><p><strong>Add alternate habits</strong></p><p>My viewing hours reduced exponentially at this point. Now I opened YouTube, searched for some good creators, watched their latest video, and closed the site.</p><p>But to quit fully I knew I needed to replace YouTube time with something else. This can be a different thing for you and me. I started writing more often. The silence is great for creative thoughts and reflection.</p></li></ol><p>Today, after all this, I realized that I’m not addicted to YouTube anymore. I should be careful to make sure I don’t go back to it slowly. But I have high hopes for the future.</p><p>And always remember,</p><blockquote><p>“Too much of anything can make you sick” ~ Cheryl Cole</p></blockquote></article></div></div>]]>
            </description>
            <link>https://praveenjuge.com/blog/how-i-overcame-youtube-addiction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639870</guid>
            <pubDate>Thu, 25 Jun 2020 12:28:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker's Guide to PlantUML]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639826">thread link</a>) | @todsacerdoti
<br/>
June 25, 2020 | https://crashedmind.github.io/PlantUMLHitchhikersGuide/ | <a href="https://web.archive.org/web/*/https://crashedmind.github.io/PlantUMLHitchhikersGuide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Tip</p>
<p><a href="http://www.plantuml.com/plantuml/svg/SYWkIImgAStDKU3YAYueoYn9LL39JImgoynJY3OqCgWmD37HDpIBLQZc0j1YTykjipeOWCzxDPX_7Kh2tFybRIJILB7PAtJIxvrfkfonyo1vGKpxh-ByCeVhlytNv-oC--_Wm_iG_3_oty1UsAjxN8x-7XRMkeUDvTsVmavKunxthELFOUigkoz_0dlhtjaRVVmHBEp2TS_SwT_3swvxpLLs7yDhrztpAXyVms7XkcNUTHk0jc5nOrJuZIknSBZB0BWFnpttBeTmlSquODw6_HqMOK_k9eGmGhkm51ntNOc5mz6VONLXjzL1tNtOodfHdy798Y00xy0-MdYwUx3aUC049aWRi0lntkbzsHq-I9TVNDY1nRt0RXyUvqh9Q5rXtyD2_hBJaf-AHycTh-e6FBnmBtY_PFbrq6om1FicFBpu2Upb5wbPfxmDXyzWV_WGJSd0U_0mFuTzRxRPEx0RwaTmq9y-P0Ia_OgFz2aSv6Skc8W2zoquV0vBNDS08lKjsCM_WAF09XlmaVu6zh-5VHBPmf9VmYB_5WuAVx9awdLXmcThxVmjVE_r_gF04QAe3BLMPB4tuG--5eF2YNkZMhAaL1Hw2_xWGK3XWBt3P2VDMx3Alt_MqypBSZjF2yDx-4ZlUos8BkX9aaVIl4fV52OY9gWF5Xdv7UmCV9Mbh91ogIEbJ6tQ8iW8a12Wf52844aEQaLYJaT-1_UuA5d0c4jvW47VifsEHIv9fM5AfK85WL5iQWt2E3UzXRs5PsAgY5A85-sMG-GSOynCIKwF2NZ22DIzarXuezSnPKqfuT-RDXzJJDZoNBLYVS9u7a-Oa5ZXTTAth4sRFQpnxJOrPcYexWYiO6HY1eNT6jRaYiYiRYnnOsCUaT8tZEqEDsgCc0USIiaBEZxKcc8YAdBlalTJrjURAgp8qvNm0YPYoccqkbO4nBg4WOOh90uvvU0r8UNuZxyuXUbApZjy4X8aD-2CX8qXNs6PgSJC86rEG6LeafW14OhGQzV0_GRdauWXz06xMg4nbbktMTWcjCoHYb4VyJDYpN8BSdYXZVfqqnqkPsidrpcTKa6TdnVu59GLhqA760KiQIuIWux-Kcmg9QaxKtzWUi2rSpjF0eLx1a90IA_iT6Uevc41Gid2YfmhGWx-cH1pvTQmfFX8w1Rs4pu5RfmdJ4CX9i1IgwgMdI50mZhP7xegFOj5RX9-qix2BKruVBR820EkrAIjqdj0KfRlQOrgjh3GCEcOAxMVaFR5zmKC_MGSCW_O8GyAILwuDM5NcSMyojh-MWfmipbrZDt0Q60QtD2_UXMtiHoAsdYT-O5maOKcrIvqwqkuTc6amrzP6aqypFx_M2I5xHsqASWB-W9pL1W4qHP_LHHulEW4MgRcIjpQclQ7Nz5IY8N9Fs4ckSbVohTPy1eMwldHUcnf-Q8CgMBJCB6bJ_w6yGTM1xz86jxaKDjv8Ii-fd5-o2mX45hcxeYNX3nlDPM2bZwP7l3nXCKb-9h_fGKcbE5UQwqq_v619pm3kcw97UPUEEe9N5EoKqiKCh3EuqO0zOlc2KrWlD5KKaQQHLfPw1H4zlByhCju4fgnn8IFCucL9WG3o_t8yhM8pE9EM6WJ0NCgf5112oijhdn7XoYPj3IZe5wPiMdu2UUcVNO3xeM8snE-qrXI0KGiDxYXoBFSHrALEL9IgZNhCBxpW0FLKdBi0dUep1PMsW249UUIywNLZHkNQ51n2vmoAp77LD3CGIfkmZfMD-5UvmAXy9ec0AIcUR84E62RLEN20RV6HfLn16VWeqzOPI8MU4rFQkR9nYDREEMAZVBXMM0Jmkp5NC8m90ClwVQK6sCDtZa39vd7CXXtu0lCaEtpVw01knUO1BxBXZP53C1PE0FoMKLuXNbM-meVPYSH0AaPU4dFfQXXYMwcA9nIGOIYm2jCLGPuWREu4vRa6tpljxgTizDCEALSOR31kIjCDRbR8e5xWLqbQSoQ_eRFXZb7R-0w7_cbnnRMAHWEju3vl6pQCX0tfZNzA1hIuMno8sMTpO6jKT7XhU1ssoqMe7_IaAAx9F6YhWC6As-kuSKsjIAIj9NMSd2t724iXFkR9ca1vwh2MYQwD5JYTdECh2gsCe3Gx-3_qMftEwwhEXp0xy_J1FnXSmcawwtEkszCd9OqqpLhh-tvNumgMSgle8P1XZGRBF27RiQHl5dW1bksOhAMwlHdE1EFq9-v2Na4Zi_z1bkus91LVTJVmHW5kwmgOdGiZ7TuZKnPcEMwUBV-7s3w3hPiwZ9nMUYsts6AWosgfPXCH7FdvF0ZtPz5xs-r1KVWNq-r1KMBJXa7lK_w3ekgNc4WFaFf_Zgb6tmFYS5CY5XixtQ7VKsumhp2zzpXUpOMOJ9O-sxq7Ru72IqqWjjVmcQFpAzGsknB_89q1huECURixTQFSDxly3VfhRKY8zhwXpGLaL9_b_PtT_RsWVV7v_hiQFp0PS5EHDmVxx6zcAUhQ8-7SyweK-gz-TegR17HChVmJPX_0WRfVO1C2FdjJbU6sGyf8l7m1YJJpAlfiX-DY0g6mtwwaWrENy8v0pD4mpXS631yXc5Ke4J3CDpVm7wUQEjECAoOCpxd-jrrE9iS2biolE1qWyr5-14OSC9tsGTizMno_Ej4ov3JpJKOVW3EVbpfyiZroDXSmb69XiqbN6MFknCcoC7mtDkiyjFEYpk240fdG5vWo6jMbrMsIFXuhCjENraB0DVQLRSmk1Gbm-2PV0duNxA-LPSj1S69UYl-8dc-l7MBjLjmss9Ws9ATUtsu7_5oeSxUKB5o14nfIsLVv9LEgxjRMXx5505ZJa1roEBoUzmj-sEu5RQqfH2O411DRcpmJSxkFYmLRHPYO64okpvCFkcxkvlRS1i9Wdd8281sKkJoZ9CMmCKrE0V2cORS68o-hLlkKd8uHS9JxW8BxIoMntJPt60O3QFsSDbncF5vxfBT3O95sFVJcUoSIX7Mc3lFGoLjJpXc0H6VwvIIc5neeT7SaQxvvSQirHlvN0yvInz8PNn5ZsxsueR05kGvrq-vxrK9FToQmGLURavR1Em_hulSMsMQuL9DLXYWZzOEMe9WCldSO6Qnuw9Q79O1D_75RBA1y3PWborSUwsAI3DrtWcv96u7WcAoqMO3bG7JsGjKNlT2zkbN6BofdYqeiA0KWor-IGEMR46mPK0glisq49zD1zy1keqZeR2tE2VjGN_9UOHm2VmAX4lrTWlFY66p029i1vF7zo8BXiD7vfc_Y8fFXJABnHiao1GxrIe7mDxcBENSSVlFFH_tHJDnB2ppyTwgJA2rUA6ymIWK2Iixx8zdXqNr2YSG38JB0llZzLpKNfKqkp0CiIFc2vnzUM9lB99d_iBYO5JHKjGGNqPo9lz6efwZXaW0KV1sF7OL2B9NH0XXROyJXS66CLxk6US3hdCDVoiHXi5oWnFW9pX16CnyJ6vAwudg2GjVfpfb284jeiku7EOJzjAh5hW3EU4fhx2AFaifViG6d-DAorJx8kvoJXw8W-tnpmLa1XmkzPGXUm13OPFFnmCWbtgKUg_djx8W4XF6_RYg3uoUTzLwEqfrNkfHyMXhoXe6OxMBCUquojVQ1cRkJ5alSBMsTmtzVznwxVl3Z3O--7YFj94oP4khpIhVm___tpzjd45h8p4CXU_pAyImaDlCFOImi8HDe2cba5EQWp9MR7LiETXomz0_NwVJGW-zYCTxJtpw1Mhoo7B5X0467uk1z-QCmsXJB6B-HHyJt1mhrUgSVpqMmGpjQhZdIvjmMg_-pC5wrN-wwxPf92g1fuj2l7plBQ7TmOspWocMXO7NaXMKl8T0a50TfHS1TLX7cbWiQ0GIYvOWJ5MfAvanXzewqu0b4-p0uHl9Gi76oXBgsfcTsBeVy3jxKKdgM4Quonbl8noFJlMQbtq_9CoEJ60ndULAEtSS-oUFeeVzmvPrS8v7Ilb_OKFz8-ajfl6GgxF7mR5G_jNid0OFsytpvdG2bgo4fklgfT3y9J4b-0y0"><img alt="playbutton_index" src="https://crashedmind.github.io/PlantUMLHitchhikersGuide/_images/play6.png"></a> <strong>Press play</strong></p>
<blockquote>
<div><p>Imagine being able to</p>
<ol>
<li><p>share a model or diagram between all members of the team that they can all understand and contribute to and edit</p></li>
<li><p>draw diagrams like below automatically from a text description.</p></li>
<li><p>describe a system before you build it, when you’re building it, and as you maintain it into the future - keeping the description and the system current, and in sync.</p></li>
<li><p>maintain that text version in a source code repository beside the code for the system it is describing</p></li>
</ol>
<p>Imagine having a diagramming tool that</p>
<ol>
<li><p>fits with a developer workflow, and developers are comfortable using</p></li>
<li><p>enables <strong>lightweight just-enough</strong> <a href="http://agilemodeling.com/essays/barelyGoodEnough.html">AgileModeling</a> in a way that meets <a href="https://tdan.com/best-practices-for-agile-documentation/18936">AgileModelingBP</a></p></li>
<li><p>fits with modern practices of Continuous Integration Continuous Delivery - and “everything as code” including diagrams.</p></li>
</ol>
<p>Well that’s what PlantUML gives you, and more…</p>
</div></blockquote>
</div></div>]]>
            </description>
            <link>https://crashedmind.github.io/PlantUMLHitchhikersGuide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639826</guid>
            <pubDate>Thu, 25 Jun 2020 12:23:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula & Kubernetes: Comparing Two Container Orchestration Models]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639815">thread link</a>) | @amarti
<br/>
June 25, 2020 | https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/ | <a href="https://web.archive.org/web/*/https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-25483">

    <!-- .entry-header -->

    <div>

		
<div><div id="kt-layout-id_3efdd0-59"><div>
<div><div>
<p>📘 Check our <strong>step-by-step tutorial and screencast</strong> on how to easily deploy on <strong>AWS</strong> a single-node <strong>Firecracker cloud</strong> integrated with the <strong>Docker Hub</strong> marketplace:</p>



<figure><a href="https://support.opennebula.pro/hc/en-us/articles/360045029871-How-to-Use-miniONE-to-Deploy-a-Firecracker-Cloud-Integrated-with-Docker-Hub-on-AWS" target="_blank" rel="noopener noreferrer"><img src="https://opennebula.io/wp-content/uploads/2020/06/FC_AWS.jpg" alt=""></a></figure>
</div></div>



<div><div>
<p>Application container technologies, like <a href="https://www.docker.com/" target="_blank" rel="noreferrer noopener" aria-label="Docker (opens in a new tab)">Docker</a> and <a href="https://kubernetes.io/" target="_blank" rel="noreferrer noopener" aria-label="Kubernetes (opens in a new tab)">Kubernetes</a>, are becoming the de facto leading standards for packaging, deploying and managing applications with increased levels of agility and efficiency. Kubernetes is widely used for the orchestration of containers on clusters, offering features for automating application deployment, scaling, and management.&nbsp;<br></p>



<p>However, <strong>Kubernetes doesn’t necessarily work for every single use case</strong> nor solves all container management-related challenges an organization might face. Just to put an example, its support for multi-tenancy is actually quite limited, and it cannot guarantee perfectly secure isolation between tenants. The only way to run Kubernetes is by providing different teams with their own clusters. Upgrading clusters and patching vulnerabilities is not a quick and easy task, which in the end requires to build an <strong>expensive full-time admin team</strong>.&nbsp;<br></p>



<p>Moreover, Kubernetes does not offer cloud-like self-service provision features for users, nor accounting and advanced authorization features for administrators. Cloud providers and cloud management tools, like <a rel="noreferrer noopener" aria-label="Amazon EKS (opens in a new tab)" href="https://aws.amazon.com/eks/" target="_blank">Amazon Elastic Kubernetes Service (EKS)</a> or <a rel="noreferrer noopener" aria-label="Google Kubernetes Engine (opens in a new tab)" href="https://cloud.google.com/kubernetes-engine" target="_blank">Google Kubernetes Engine (GKE)</a>, try to bridge these gaps by offering <strong>managed Kubernetes-as-a-Service platforms</strong>. What these solutions do is to add an extra control layer that ends up <strong>increasing management complexity, resource consumption, and associated costs</strong>.&nbsp;</p>
</div></div>
</div></div></div>



<h2>OpenNebula 5.12 “Firework”</h2>



<p>The new <a rel="noreferrer noopener" aria-label="OpenNebula 5.12 “Firework” (opens in a new tab)" href="https://opennebula.io/firework/" target="_blank">OpenNebula 5.12 “Firework”</a> brings new exciting features to the container orchestration ecosystem by providing an <strong>innovative open source solution</strong> for organizations that need to build and manage a secure, self-service, multi-tenant cloud for serverless computing. Users of an OpenNebula cloud can now easily run isolated containers without the need to provision and manage servers or additional control layers, thus allowing them to focus on designing and building their applications instead of managing the underlying infrastructure. OpenNebula’s <strong>pioneering approach towards container orchestration</strong> integrates two main technologies: <a rel="noreferrer noopener" aria-label="AWS Firecracker (opens in a new tab)" href="https://firecracker-microvm.github.io/" target="_blank">AWS Firecracker</a> as the VMM that provisions, manages and orchestrates micro-VMs, and <a rel="noreferrer noopener" aria-label="Docker Hub (opens in a new tab)" href="https://hub.docker.com/" target="_blank">Docker Hub</a> as the marketplace for application containers from which users can obtain and seamlessly <strong>deploy Docker images as micro-VMs</strong>.&nbsp;<br></p>



<p>AWS Firecracker is an open source technology that makes use of KVM to launch lightweight Virtual Machines—called micro-VMs—for <strong>enhanced security, workload isolation, and resource efficiency</strong>. It is widely used by AWS as part of their <a href="https://aws.amazon.com/fargate/" target="_blank" rel="noreferrer noopener" aria-label="Fargate (opens in a new tab)">Fargate</a> and <a href="https://aws.amazon.com/lambda/" target="_blank" rel="noreferrer noopener" aria-label="Lambda (opens in a new tab)">Lambda</a> services. Firecracker opens up a whole new world of possibilities as the foundation for serverless solutions that need to quickly deploy critical applications as containers while keeping them in secure isolation. With the recent integration of Firecracker as a <strong>new supported virtualization technology</strong>, OpenNebula provides now an innovative solution to the classic dilemma between using containers—lighter but with weaker security—or Virtual Machines—with strong security but high overhead.&nbsp;&nbsp;<br></p>



<p>OpenNebula’s integration of Docker Hub as a new native marketplace provides users with immediate access to <strong>Docker Hub official images</strong>. Through this integration Docker images can be easily imported into an OpenNebula cloud, following a process similar to the way in which the OpenNebula Public Marketplace operates. The OpenNebula context packages are installed during the import process so, once an image is imported, it becomes fully functional (including auto IP configuration, SSH key management and custom scripts). The Docker Hub marketplace also creates a new VM template associated with the imported image. This template can be customized by the user (e.g. adding the desired kernel, tuning specific parameters, etc.).</p>







<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace-1024x532.png" alt="" width="768" height="399" srcset="https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace-1024x532.png 1024w, https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace-300x156.png 300w, https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace-768x399.png 768w, https://opennebula.io/wp-content/uploads/2020/06/dh_mktplace.png 1206w" sizes="(max-width: 768px) 100vw, 768px"></figure></div>







<h2>An Enterprise Cloud for Containerized Applications</h2>



<p>OpenNebula brings to the container world a series of unique features to <strong>build your own enterprise cloud for serverless computing</strong>. Its unique approach speeds up the deployment of <strong>containerized applications and multi-tier services</strong> within your development workflow. In particular, OpenNebula provides:</p>



<ul><li><strong>Fast startup times</strong>: With OpenNebula you can start containers in seconds by deploying them as Firecracker micro-VMs, without the need to provision and maintain Dockerized hosts or complex Kubernetes infrastructures.</li><li><strong>Direct access to applications</strong>:&nbsp; Deploying a container as a micro-VM allows your container to directly access your networks through the Firecracker micro-VM’s IP address. Furthermore, the micro-VM can be accessed via SSH and VNC by providing interactive modes that help with application development and troubleshooting.</li><li><strong>Hypervisor-level security: </strong>OpenNebula guarantees that your containerized application to run within a Firecracker micro-VM which, in turn, provides VM-grade security and isolation in a multi-tenant environment while preserving the efficiency of lightweight containers.</li><li><strong>Persistent storage: </strong>OpenNebula’s datastores can be used as persistent data volumes for containers by attaching them to your Firecracker micro-VMs. Read-only configuration or data files can be provided by using the OpenNebula file datastore, which can be used by the application within the micro-VM.</li><li><strong>Network access: </strong>Virtual Networks defined within an OpenNebula cloud (i.e. IPv4, IPv6, Dual Stack, Ethernet) can be easily configured so that containerized applications get direct access to the internet without requiring additional components (e.g. ingress controllers, load balancers, etc.). With OpenNebula Virtual Routers it is also possible to connect different virtual networks, allowing applications and Virtual Machines attached to different virtual networks to communicate with each other. It is possible to use security groups for ensuring network security for containers applications.</li><li><strong>Application horizontal scaling</strong>: Application deployed as complex, multi-tier services can be scaled up and down “manually” but also (via the OneFlow component) in an automatic manner, based on user-defined metrics and pre-defined criteria. An <em>init</em> script can be defined to send application metrics to OneGate, OpenNebula’s metadata server.&nbsp;</li><li><strong>Complete multi-tenant environments</strong> with ACLs, users, groups, resource UNIX-like permissions and VDCs, in which cloud admins can easily adapt OpenNebula to their organization’s infrastructure and DevOps requirements and set up independent sets of resources for specific purposes or groups of users (i.e. development, testing, integration and production).</li><li><strong>Geo-distributed applications</strong>: Thanks to its elastic cloud infrastructure feature (OneProvision), OpenNebula allows to build on-demand geo-distributed infrastructures for execution of containerized applications at the Edge.</li></ul>







<h2>Summary</h2>



<p>Although many IT departments providing container execution services have decided to implement their <strong>DevOps requirements on top of Kubernetes</strong>, that doesn’t mean that betting only on one horse is the wisest thing to do. Organizations requiring container orchestration capabilities should first of all state what their main objective is, and be careful not to make apples to oranges comparisons or to fall into <strong>unexpected costs or vendor lock-ins</strong>. Kubernetes is a <strong>very complex and demanding technology</strong>, and—temporary fashions aside—other technologies may actually be the best solution for some use cases.<br></p>



<p>Some of the features provided by Kubernetes (such as its declarative model, self healing, automated rollout and rollbacks, secret and configuration management, service discovery and load balancing) make it ideal for companies that need complete container orchestration services for the deployment and management of containerized workflows in a production environment. Yet, these organizations have to be able to cope with <strong>high operational costs</strong> if what they want is to build and manage a <strong>corporate Kubernetes deployment</strong>.<br></p>



<p><a rel="noreferrer noopener" aria-label="OpenNebula (opens in a new tab)" href="https://opennebula.io/firework/" target="_blank">OpenNebula</a>, on the other hand, becomes an ideal solution for companies that need to build <strong>multi-tenant Container-as-a-Service environments</strong>, but with <strong>lower operational costs</strong>. In this way, users and business units can develop and deploy applications easily and very fast, without their organizations having to manage dockerized hosts or complex orchestration infrastructures such as Kubernetes or OpenShift. With the release of its version 5.12 “Firework”, OpenNebula has become a real alternative for implementing an <strong>agile and serverless cloud paradigm for containerized workloads</strong> in production environments 🚀</p>







<figure><table><tbody><tr><td></td><td><figure><img src="https://opennebula.io/wp-content/uploads/2020/06/opennebula_cloud_logo_white_bg.png" alt=""></figure></td><td><figure><img src="https://opennebula.io/wp-content/uploads/2020/06/kubernetes-horizontal-color.png" alt=""></figure></td></tr><tr><td><strong>Use Case</strong></td><td>Container as a Service</td><td>Container Orchestration</td></tr><tr><td><strong>Purpose</strong></td><td>Create a CaaS multi-tenant Enterprise Cloud for containerized applications </td><td>Manage a cluster of Linux containers as a single system to accelerate development and simplify operations</td></tr><tr><td><strong>Use</strong></td><td>Deliver shared resources to groups of users for secure execution of their container workloads</td><td>Deployment, scaling, and operations of containers across a cluster of hosts of VMs for a single user or group of users</td></tr><tr><td><strong>Applications</strong></td><td>Containerized distributed applications</td><td>Containerized distributed applications</td></tr><tr><td><strong>Access to Applications</strong></td><td>Easy SSH, VNC access to the micro-VM </td><td>Container exec bash access. Hard to troubleshoot</td></tr><tr><td><strong>Orchestration Approach</strong></td><td>Imperative</td><td>Declarative</td></tr><tr><td><strong>Application Management</strong></td><td>User-driven life-cycle application management (create, delete, stop, resume)</td><td>Application rollback and updates, self-healing, service discovery &amp; load balancing</td></tr><tr><td><strong>Application Scheduling &amp; Resource Optimization</strong></td><td>Application micro-VMs are placed according to resource requirements (CPU and Memory), affinity rules, custom heuristics…</td><td>Automatic bin packing is used to place containers based on their resource requirements</td></tr><tr><td><strong>Network Access</strong></td><td>Full support of IPv4, IPv6, Dual Stack, Ethernet networks and security groups</td><td>Allocation of IPv4 and IPv6 …</td></tr></tbody></table></figure></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/">https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/</a></em></p>]]>
            </description>
            <link>https://opennebula.io/opennebula-kubernetes-comparing-two-container-orchestration-models/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639815</guid>
            <pubDate>Thu, 25 Jun 2020 12:22:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux on a Laptop, 2020 Edition]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639747">thread link</a>) | @piotrzientara
<br/>
June 25, 2020 | https://mkozak.pl/linux-on-laptop-2020-edition/ | <a href="https://web.archive.org/web/*/https://mkozak.pl/linux-on-laptop-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <!--kg-card-begin: markdown--><p>After 8 years of using Apple computers (mac mini and multiple MacBooks), I decided to say "Farewell" to Apple.</p>
<p>The quality of both software and hardware when it comes to their mobile computers went downhill in recent years.<br>
Butterfly keyboard issues, old CPUs (compared to what other manufacturers put in their machines), quite limited of memory (until latest iteration of 13" MacBooks Pro it was impossible to get more than 16GB of RAM), software issues with Catalina (audio glitches, random freezes, random reboots) - all of that led me to the point where I decided to sell my 2015-version of MacBook Pro (I still have one MBPro from 2019 that I'm using for work at current company, and I still need to live with this failing system)</p>
<p>When I had switched from 2012 mac mini to PC desktop three years ago (there was no reasonable alternative from Apple on the horizon) I've told myself I'm going to stick with Apple for mobile computing (and I partly do, I still don't see any alternatives to iPhone and iPad) based on my previous experiences with Linux on a laptop. But I decided to give it a try.<br>
When I previously used Linux on a laptop, it was between 2008 and 2011, and it was a mess - battery life was a joke compared to what I could achieve with Windows, constant issues with suspending and hibernation, failing wireless network card.<br>
That was when I joined Apple cult. It was quite the opposite - long battery life, beautiful UI, seamless integration between different products, quite good performance, lot of great apps. Too bad it's only partially true now.  I want to share my journey about looking for a suitable replacement for MacBook Pro in 2020, and I need to make clear that my needs for computing might not be usual. But hey, we're talking about MacBook <em>Pro</em>, and I mean this should be aimed at professionals. I'm 100% sure many people will be happy with their Macs.</p>
<p>Requirements:</p>
<ul>
<li>5-6 hours of battery life</li>
<li>As much memory as possible. I use a lot of Docker containers with memory-hungry applications. And I use Chrome, so there's no such thing as too much memory</li>
<li>Fast disks</li>
<li>Ideally - matte display</li>
<li>Screen no bigger than 14"</li>
<li>Reliably working Wi-Fi card</li>
</ul>
<p>You may think many products will meet these criteria, but you couldn't be more wrong.</p>
<p><a href="https://mkozak.pl/linux-on-laptop-2020-edition-choosing-the-right-machine/">Part 1 - choosing the right machine</a><br>
<a href="https://mkozak.pl/linux-on-a-laptop-2020-edition-arch-on-clevo/">Part 2 - Arch on Clevo</a></p>
<!--kg-card-end: markdown-->
  </div></div>]]>
            </description>
            <link>https://mkozak.pl/linux-on-laptop-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639747</guid>
            <pubDate>Thu, 25 Jun 2020 12:16:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Integer Parsing]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23639486">thread link</a>) | @fanf2
<br/>
June 25, 2020 | https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html | <a href="https://web.archive.org/web/*/https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Back with a post after 6 years of silence. If you had to parse a microsecond-resolution epoch timestamp as quickly as possible, how would you do it?  We’ll take a look at using compiler intrinsics to do it in log(n) time.</p>


        <h3 id="the-problem">The problem</h3>

<p>Let’s say, theoretically, you have some text-based protocol, or file that
contains microsecond timestamps. You need to parse these timestamps as quickly
as possible. Maybe it’s json, maybe it’s a csv file, maybe something else
bespoke. It’s 16 characters long, and this could also apply to credit card
numbers.</p>

<figure><pre><code data-lang="csv">timestamp,event_id
1585201087123567,a
1585201087123585,b
1585201087123621,c</code></pre></figure>

<p>In the end you have to implement a function similar to this:</p>

<figure><pre><code data-lang="cpp"><span>std</span><span>::</span><span>uint64_t</span> <span>parse_timestamp</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span>
<span>{</span>
  <span>// ???</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-native-solution">The native solution</h3>

<p>Let’s start with what’s available, and compare. We have
<a href="https://en.cppreference.com/w/cpp/string/byte/atoi"><code>std::atoll</code></a> , a function
inherited from C,
<a href="https://en.cppreference.com/w/cpp/io/basic_stringstream"><code>std::stringstream</code></a>
, the newer C++17
<a href="https://en.cppreference.com/w/cpp/header/charconv"><code>&lt;charconv&gt;</code></a> header, and
by request
<a href="https://www.boost.org/doc/libs/1_73_0/libs/spirit/doc/html/spirit/qi/reference/basics.html"><code>boost::spirit::qi</code></a>.
I’ll be using <a href="https://github.com/google/benchmark">Google Benchmark</a> to
measure the performance, and to have a baseline let’s compare against loading
the final result into a register - i.e. no actual parsing involved.</p>

<p>Let’s run the benchmarks! The code is not important here, it just shows what is being benchmarked.</p>

<figure><pre><code data-lang="cpp"><span>static</span> <span>void</span> <span>BM_mov</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>1585201087123789</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_atoll</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>std</span><span>::</span><span>atoll</span><span>(</span><span>example_timestamp</span><span>));</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_sstream</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>std</span><span>::</span><span>stringstream</span> <span>s</span><span>(</span><span>example_timestamp</span><span>);</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>s</span><span>.</span><span>seekg</span><span>(</span><span>0</span><span>);</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
    <span>s</span> <span>&gt;&gt;</span> <span>i</span><span>;</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>i</span><span>);</span>
  <span>}</span>
<span>}</span>
<span>static</span> <span>void</span> <span>BM_charconv</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>auto</span> <span>s</span> <span>=</span> <span>example_timestamp</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>std</span><span>::</span><span>from_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_boost_spirit</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>using</span> <span>boost</span><span>::</span><span>spirit</span><span>::</span><span>qi</span><span>::</span><span>parse</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>parse</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-native">
    </canvas>

</figure>

<p>Wow, <code>stringstream</code> is pretty bad. Not that it’s a fair comparison but parsing
a single integer using <code>stringstream</code> is 391 times slower than just loading our
integer into a register.  <code>&lt;charconv&gt;</code> and <code>boost::spirit</code> do a lot better by
comparison.</p>

<p>Since we know our string contains the number we’re trying to parse, and we
don’t need to do any whitespace skipping, can we be faster?  Just how much time
is spent in validation?</p>

<hr>

<h3 id="the-naive-solution">The naive solution</h3>

<p>Let’s write a good old for loop. Read the string character by character, and
build up the result.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_naive</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span><span>(</span><span>char</span> <span>digit</span> <span>:</span> <span>s</span><span>)</span>
  <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>digit</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-naive">
    </canvas>

</figure>

<p>That’s actually not bad for a simple for loop. If such a simple solution is
able to beat a standard-library implementation, it means there’s quite a lot of
effort that goes into input validation. As a sidenote - if you know your input,
or can do simpler validation you can get some significant speedups.</p>

<p>For further solutions and benchmarks, let’s ignore the standard library
functions. We should be able to go much faster than this.</p>

<hr>

<h3 id="the-brute-force-solution">The brute force solution</h3>

<p>If we know it’s 16 bytes, why even have a forloop? Let’s unroll it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_unrolled</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>

  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>2</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>3</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>4</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>5</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>6</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>7</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>8</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>9</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>10</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>11</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>12</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>13</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>14</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>15</span><span>]</span> <span>-</span> <span>'0'</span><span>);</span>

  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-brute-force">
    </canvas>

</figure>

<p>Ok, that’s slightly better again, but we’re still processing a character at a time.</p>

<hr>

<h3 id="the-byteswap-insight">The byteswap insight</h3>

<p>Let’s draw out the operations in the unrolled solution as a tree, on a
simplified example of parsing ‘1234’ into a 32-bit integer:</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-unrolled.png">

<figcaption><p>Unrolled solution graph of operations for ‘1234’</p>
</figcaption>

</figure>

<p>We can see that the amount of multiplications and additions is linear with the
amount of characters. It’s hard to see how to improve this, because every
multiplication is by a different factor (so we can’t multiply “in one go”), and at
the end of the day we need to add up all the intermediate results.</p>

<p>However, it’s still very regular. For one thing, the first character in the
string is multiplied by the largest factor, because it is the most significant
digit.</p>

<blockquote>
  <p>On a little-endian machine (like x86), an integer’s first byte contains the
least significant digits, while the first byte in a string contains the most
significant digit.</p>
</blockquote>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-byteswap-insight.png">

<figcaption><p>Looking at the string as an integer we can get closer to
the final parsed state in fewer operations - see how the hex representation is
<strong>almost</strong> what we want</p>
</figcaption>

</figure>

<p>Now to reinterpret the bytes of a string as an integer we have to use
<code>std::memcpy</code> (<a href="https://blog.regehr.org/archives/1307">to avoid strict-aliasing
violations</a>), and we have compiler
instrinsic <code>__builtin_bswap64</code> to swap the bytes in one instruction. The
<code>std::memcpy</code> will get optimized out, so this is a win so far.</p>

<figure><pre><code data-lang="cpp"><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>inline</span> <span>T</span> <span>get_zeros_string</span><span>()</span> <span>noexcept</span><span>;</span>

<span>template</span> <span>&lt;</span><span>&gt;</span>
<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>()</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>constexpr</span> <span>char</span> <span>zeros</span><span>[]</span> <span>=</span> <span>"00000000"</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>result</span><span>,</span> <span>zeros</span><span>,</span> <span>sizeof</span><span>(</span><span>result</span><span>));</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span>

<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>
  <span>chunk</span> <span>=</span> <span>__builtin_bswap64</span><span>(</span><span>chunk</span> <span>-</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>());</span>

  <span>// ...</span>
<span>}</span></code></pre></figure>

<p>But now that we have an integer that kind of, sort of looks like what we want,
how do we get it across the finish line without too much work?</p>

<hr>

<h3 id="the-divide-and-conquer-insight">The divide and conquer insight</h3>

<p>From the previous step, we end up with an integer whose bit representation 
has each digit placed in a separate byte. I.e. even though one byte can
represent up to 256 values, we have values 0-9 in each byte of the integer.
They are also in the right little endian order. Now we just need to “smash”
them together somehow.</p>

<p>We know that doing it linearly would be too slow, what’s the next possibility?
<strong>O(log(n))</strong>! We need to combine every adjacent digit into a pair in one step,
and then each pair of digits into a group of four, and so on, until we have the
entire integer.</p>

<p>After I posted the first version of this article, <a href="https://www.reddit.com/r/cpp/comments/gr18ig/faster_integer_parsing/frx9agb">Sopel97 on
reddit</a>
pointed out that the byteswap is not necessary. Combining adjacent digits works
either way - their order doesn’t matter.  I realized that it helped me with the
next insight, but could be omitted for the final code.</p>

<blockquote>
  <p>The key is working on adjacent digits simultaneously. This allows a tree of
operations, running in O(log(n)) time.</p>
</blockquote>

<p>This involves multiplying the even-index digits by a power of 10 and leaving the
odd-index digits alone. This can be done with bitmasks to selectively apply
operations</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-mask-insight.png">

<figcaption><p>By using bitmasking, we can apply operations to more than one digit at a time, to combine them into a larger group</p>
</figcaption>

</figure>

<p>Let’s finish the <code>parse_8_chars</code> function we started earlier by employing this
masking trick. As a neat side-effect of the masking, we don’t need to subtract
<code>'0'</code>, since it will be masked away.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>

  <span>// 1-byte mask trick (works on 4 pairs of single digits)</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0f000f000f000f00</span><span>)</span> <span>&gt;&gt;</span> <span>8</span><span>;</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000f000f000f000f</span><span>)</span> <span>*</span> <span>10</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 2-byte mask trick (works on 2 pairs of two digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x00ff000000ff0000</span><span>)</span> <span>&gt;&gt;</span> <span>16</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000ff000000ff</span><span>)</span> <span>*</span> <span>100</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 4-byte mask trick (works on pair of four digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0000ffff00000000</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000000000ffff</span><span>)</span> <span>*</span> <span>10000</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>return</span> <span>chunk</span><span>;</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-trick">The trick</h3>

<p>Putting it all together, to parse our 16-digit integer, we break it up into two
chunks of 8 bytes, run <code>parse_8_chars</code> that we have just written, and benchmark it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_trick</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>());</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>8</span><span>);</span>
  <span>return</span> <span>upper_digits</span> <span>*</span> <span>100000000</span> <span>+</span> <span>lower_digits</span><span>;</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_trick</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>parse_trick</span><span>(</span><span>example_stringview</span><span>));</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-trick">
    </canvas>

</figure>

<p>Not too shabby, we shaved almost 56% off of the unrolled loop benchmark! Still,
it feels like we are manually doing a bunch of masking and elementwise
operations. Maybe we can just let the CPU do all the hard work?</p>

<hr>

<h3 id="the-simd-trick">The SIMD trick</h3>

<p>We have the main insight:</p>

<ul>
  <li>Combine groups of digits simultaneously to achieve O(log(n)) time</li>
</ul>

<p>We also have a 16-character, or 128-bit string to parse - can we use SIMD? Of
course we can! <a href="https://en.wikipedia.org/wiki/SIMD">SIMD stands for Single Instruction Multiple
Data</a>, and is exactly what we are looking
for. SSE and AVX instructions are supported on both Intel and AMD CPUs, and
 they typically work with wider registers.</p>

<p>I used the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics
Guide</a> to find
the right compiler intrinsics for the right SIMD CPU instructions.</p>

<p>Let’s set up the digits in each of the 16 bytes first:</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_1…</span></code></pre></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</a></em></p>]]>
            </description>
            <link>https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639486</guid>
            <pubDate>Thu, 25 Jun 2020 11:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gopherspace in the Year 2020]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23639411">thread link</a>) | @sT370ma2
<br/>
June 25, 2020 | https://cheapskatesguide.org/articles/gopherspace.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/gopherspace.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

   <!-- Title -->
   
   <p><img src="https://cheapskatesguide.org/pics/gopher-240.jpg" alt="Gopher">
      I first had access to the early Internet--what there was of 
      it--through the university I attended.  I remember how different 
      the Internet was back in the mid-to-late 1980's.  We had 
      electronic mail, but almost no one used it.  We logged onto 
      remote computers with telnet and transferred files with FTP.  
      All this was done at the command line.  If I remember correctly, 
      very few graphical user interfaces existed then.  Those that 
      did were composed of ASCII characters.  The first web browser was 
      not released until 1991.  Remembering causes me some sadness, 
      though in some ways the Internet is better now.  It certainly 
      has many more users, and that is a good thing.  I just wish it had 
      more Internet-savvy users.</p>

   <p>I remember that many of the early computer networks and websites on 
      the Internet were run by imaginative people with great senses of 
      humor.  For example, the computer network that I used at the second 
      engineering company for which I worked in the late 1980's had seven 
      sun workstations named after the seven dwarves.  As you may imagine, 
      that provided us with no end of entertainment.  "Dopey is down, 
      AGAIN!"  "Grumpy is acting up."  "Sneezy died yesterday.  When is 
      the funeral?"</p>

   <p>Back then, computers were something special.  They were wondrous.  
      Individuals who owned them were mavericks in a sense.  Buying a 
      personal computer then was the same as painting the word "nerd" in big 
      red letters across your forehead, and being known as a nerd back then was 
      not something you wanted.  One of my highschool friends built a 
      Heathkit computer.  The only display it had was in the form of 
      one-inch, red LED digits on the front.</p>

   <p>Now, that computers permeate our society, no one bothers giving them 
      interesting names.  They've nearly become fungible commodities that we 
      use up and then throw away when they have outlived their usefulness.  
      Nearly everyone uses the Internet at least occassionally.  And, 
      strangely enough, being called a nerd is seen as a good thing.</p>
   <h2>Gopherspace</h2>
   <p>The Gopher protocol was released by the University of Minnesota in 
      1991.  Gopher servers provided users with access to various types 
      of files, including text, binary, image, sound, and GIF.  But the 
      milieu of gopherspace was text.   Text was mostly what Gopher users 
      saw.  Users could also access FTP, telnet, and 
      Usenet servers.  Back in the 1990's, Veronica search engines
      tied together the network of Gopher servers in a similar way as 
      modern search engines do today with the webservers of the
      modern Internet.  In the 1990's, Jughead search engines were designed 
      to search individual Gopher servers.  And, Archie was an FTP search 
      engine.  Archie, Veronica, and Jughead search engines were named 
      after characters in the Archie comics that first appeared in print in
      1941.  Back in the 1980's and early 1990's, when people who loved 
      computers still ran much of the Internet, it reflected their 
      personalities.  Now, the Internet is more a beige and gray  
      reflection of the corporate world.</p> 
  
   <p>Today the Gopher protocol has been supplanted almost completely 
      by the HTTP protocol upon which the World Wide Web is based.
      Though the Internet has changed considerably, Gopher servers are 
      still around.  Text is still mostly what users see 
      in gopherspace, and it can still be navigated with 
      gopher-capable Internet browsers.  Sadly, only one Veronica search 
      engine appears to operate today.  Now, When a user navigates through
      gopherspace with the Veronica search engine, by following links, or
      by entering URL's into his browser, he has an experience in many 
      ways similar to surfing the modern Internet.</p>
   
   <p>Though about <a href="https://en.wikipedia.org/wiki/Gopher_(protocol)"> 
      two dozen Internet browsers</a> can still access gopherspace, either 
      natively or with plugins, I will only talk about one.  I'll focus on the 
      Lynx browser, because it is readily available, easy to use, and 
      powerful.  The Lynx browser also runs on all the major 
      operating systems.  I'll show readers how to use the Lynx browser 
      to get into gopherspace and have a look around.</p>
   <h2>Installing and Using the Lynx Browser</h2>
   <p>The Lynx browser is a text-only Internet browser that has native 
      support for gopherspace.  Lynx allows a user to seamlessly navigate 
      around the Internet and gopherspace using only the keys on his computer's 
      keyboard.  Lynx does not use a mouse or touchpad.  Windows computer 
      users can download the Lynx browser from the 
      <a href="https://lynx.browser.org/">Lynx website</a>.</p>
 
   <div><p>Most Linux users can install Lynx simply by opening a Linux 
      terminal window and typing:
   </p></div><div>
<pre>sudo apt-get install lynx
</pre>
   </div>
   <p>

   Then, type "lynx" (without the quotes) at the command line to start 
   the Lynx browser.</p>

   <p>To go to a Gopher address using the Lynx browser, hit the "g" 
      key on your keyboard.  Near the bottom of the Lynx window, the 
      prompt "URL to open:" will appear.  Now, begin typing the Gopher 
      address.  Gopher URL's can also be copied and pasted from other 
      applications.  First, copy the URL from the other application, 
      then select the Lynx window, hit the right mouse button, and 
      select "paste".  Try going to this Gopher address for practice: 
      gopher://infinitelyremote.com/0/books/Internet_Gopher_Users_Guide.txt.  
      After you hit the "Enter" key, the text file entitled "Internet 
      Gopher Users Guide" should be visible in your Lynx window.</p>

   <p>Lynx has three user modes.  At this point, you are in the novice 
      user mode, so at the bottom of the page, the following instructions 
      should be visible: "-- press space for next page --  Arrow keys: 
      Up and Down to move.  Right to follow a link; Left to go back.  
      H)elp O)ptions P)rint G)o M)ain screen Q)uit /=search 
      [delete]=history list".</p>

   <p>At a basic level, Lynx is very easy to use, so a user does not 
      have to know much to navigate around gopherspace and read text 
      files.  I will go over the basic commands, and leave it to you 
      to learn more later.  To navigate around inside a text file that 
      contains no hyperlinks, press the space bar or the down arrow on 
      your keyboard to move down one page and the up arrow to move back 
      up one page.  The left arrow is like the back button in a modern 
      Internet browser; it takes you to the previous text file that you 
      visited.  In a text file with hyperlinks, pressing the up or down 
      arrow moves the cursor to the hyperlink above or below the 
      cursor's present position.  When the cursor is on a hyperlink, 
      pressing the "Enter" key or the right arrow takes you to the 
      document pointed to by the hyperlink.</p>

   <p>Some Gopher pages contain forms similar to HTML forms.  For 
      example, links to search engines may appear as a search line.  Use 
      the left or right arrow to move the cursor to the search line.  
      Then, type the key words you want to search for and hit the 
      "Enter" key.  This will take you to a search results page.</p>

   <p>To display the Gopher URL of the file you are currently reading, 
      hit the "=" key.  Then, hit the left arrow key to get back to the 
      file you were just reading.</p>

   <p>Exit from Lynx by hitting the "q" key.  By the way, most 
      command-line Linux programs that take control of a terminal 
      window can be exited by hitting either the "q" key or by typing 
      ":q".</p>

   <p>This is all the information you need to know to navigate around 
      in gopherspace (or on the rest of the Internet) using the Lynx 
      browser.  For additional instructions on the use of Lynx, bring 
      up Lynx and hit the "h" key.</p>
   <h2>Exploring Gopherspace</h2>
   <p>Now the fun begins.  Perhaps the best place to enter gopherspace 
      is gopher://gopher.floodgap.com/1/world.  There you will find 
      links to dozens of Gopher servers.  Floodgap claims that it 
      hosts the last Veronica search engine in existence.  So, from 
      Floodgap you can use the Veronica search engine to search 
      gopherspace by key words, or you can go to individual Gopher 
      user sites by following links to the Gopher servers that host them.</p>

   <p>One of the largest collections of Gopher user sites can be found 
      by following the Link on Floodgap labeled "'Greatest hits': most 
      recently verified Gopher servers".  From there, follow the link 
      labeled "sdf.org:70" to the Super-Dimensional Fortress (URL: 
      gopher://sdf.org/1).  There you will find many interesting phlogs 
      and files.  Gopher blogs are called phlogs.  One interesting 
      phlogger is Tomasino (gopher://sdf.org/1/users/tomasino/).  
      Another is solderpunk (gopher://sdf.org/1/users/solderpunk/).  
      There are also may others.  So, have fun and explore!</p>

   <p>For more interesting reading in gopherspace, try these:</p>
   <br>
   <ul>
      <li>gopher://gopher.floodgap.com/0/gopher/relevance.txt</li>
      <li>gopher://sdf.org/1/users/d1337/1990s-life</li>
      <li>gopher://gopherpedia.com/1/</li>
      <li>gopher://gopherddit.com/1/</li>
      <li>gopher://sdf.org/0/users/developer/PHLOG/earlydays.txt</li>
      <li>gopher://tilde.team/1/~ubergeek/news/</li>
      <li>gopher://hngopher.com/1</li>
      <li>gopher://sdf.org/1/users/sysdharma/phlog</li>
      <li>gopher://sdf.org/0/users/dbucklin/posts/2017-12-31-plain-text.txt</li>
      <li>gopher://sdf.org/0/users/dbucklin/posts/2016-03-11-mechanical-keyboards.txt</li>
      <li>gopher://tilde.town/</li>
      <li>gopher://1436.ninja/1/Port70News</li>
      <li>gopher://codevoid.de/1/cnn</li>
      <li>gopher://gopher.floodgap.com/1/feeds/today</li>
      <li>gopher://vger.cloud/1/pubnix</li>
      <li>gopher://sdfeu.org/1/</li>
      <li>gopher://zaibatsu.circumlunar.space/1/%7etfurrows/phlog</li>
      <li>gopher://1436.ninja/1/Phlog</li>
      <li>gopher://baud.baby</li>
      <li>gopher://sdf.org/1/users/xmanmonk/</li>
      <li>gopher://sdf.org/1/users/tokyogringo/</li>
      <li>gopher:/…</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cheapskatesguide.org/articles/gopherspace.html">https://cheapskatesguide.org/articles/gopherspace.html</a></em></p>]]>
            </description>
            <link>https://cheapskatesguide.org/articles/gopherspace.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639411</guid>
            <pubDate>Thu, 25 Jun 2020 11:33:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't build password-less login]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23639330">thread link</a>) | @jbarches
<br/>
June 25, 2020 | https://snaphabit.app/blog/password-less-login/ | <a href="https://web.archive.org/web/*/https://snaphabit.app/blog/password-less-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://snaphabit.app/blog/content/images/size/w300/2020/06/MagicLink-3.png 300w,
                            https://snaphabit.app/blog/content/images/size/w600/2020/06/MagicLink-3.png 600w,
                            https://snaphabit.app/blog/content/images/size/w1000/2020/06/MagicLink-3.png 1000w,
                            https://snaphabit.app/blog/content/images/size/w2000/2020/06/MagicLink-3.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://snaphabit.app/blog/content/images/size/w2000/2020/06/MagicLink-3.png" alt="Don't build password-less login">
            </figure>

            <section>
                <div>
                    <h3 id="a-metrics-driven-take-on-how-password-less-login-wasted-weeks-of-development-time-and-hurt-our-signup-funnel-">A metrics-driven take on how password-less login wasted weeks of development time and hurt our signup funnel.</h3><p>"Magic Link", also know as password-less login, enables users to sign in by clicking a link. With no need to remember a password or prove email ownership, <a href="https://medium.com/@kelvinvanamstel/should-we-embrace-magic-links-and-leave-passwords-alone-c73db7007fc4">many</a> <a href="https://techbeacon.com/security/your-passwordless-future-make-it-sooner-rather-later">people</a> have hailed "Magic Link" as the perfect authentication solution.</p><p>How it works on SnapHabit? After a user enters their enter email address, we direct them to their inbox to tap a link to sign in. Before diving into what went wrong, here's a snapshot of our authentication funnel:</p><ul><li><strong>11% of users</strong> required at least 4 magic-link emails before completing signing up.</li><li><strong>18% of users never finished signup (clicked the magic link)</strong>. On average, these users attempted signup twice, with several users submitting &gt; 10 times.</li></ul><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-why-would-you-use-magic-link-anyways">... why would you use magic link, anyways?</h2><p>Friends are core to SnapHabit, so the functionality to send a friend request is critical. Phone number or email felt like the cheapest way to support a unique identifier — as it could be used for both authentication and finding a friend.</p><p>Like most services, we first looked at using "Sign in with Google/Facebook". However, Apple recently adjusted App Store Guidelines... starting June 30, <strong>"apps that use a social login service ... must also offer Sign in with Apple"</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/Screen-Shot-2020-06-17-at-3.47.00-PM-2.png"><figcaption>App Store Guidelines, June 17, 2020</figcaption></figure><p>Apple Sign In supports <a href="https://support.apple.com/en-us/HT210425">"Hide My Email"</a>, so many users who sign in with Apple would not have a meaningful email attached to their account. Asking for a user's email after they chose to "hide it" would be a poor user experience.</p><p>So in summary, we had 4 options for account creation:</p><ol><li><strong>Email + Password</strong> ... requires forgot password and users to prove email ownership</li><li><strong>Support all third-party (Apple, Google, Facebook)</strong> ... and add a new unique identifier to allow friends to find each other, given email will not be sufficient</li><li><strong>Phone number magic link</strong> ... we were relying on Expo (previously did not support phone-number auth), and we also felt emails would be a good/cheap tool for communication</li><li><strong>Email magic link</strong> </li></ol><p>Email magic link felt... perfect! &nbsp;We built the login flow, complete with a custom email, instructional webpage, and deep linking. <strong>Hurrah, we had cracked the authentication funnel!</strong></p><!--kg-card-begin: html--><iframe width="560" height="315" src="https://www.youtube.com/embed/QoS2-mIuOZw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><!--kg-card-end: html--><h2 id="what-went-wrong-and-how-we-tried-to-solve">What went wrong and how we tried to solve</h2><p><em>If you're interested in the technical details of how we implemented some of these fixes, let me know and we'll consider publishing.</em></p><h3 id="1-users-clicking-the-link-on-another-device-">1. Users clicking the link on another device.</h3><p>Of 10 users we chatted with who had issues, 4 tried to click the link on another device. There are two routes to solving this:</p><ul><li>technical solution to support this behavior (clicking the link on desktop will authenticate the user on mobile)</li><li>better instructional text</li></ul><p><strong>The latter was simpler, so we started with that:</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/firstattempt.png"></figure><p><strong>And again.</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/email.png"></figure><p><strong>And more.</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/landingpage.png"></figure><h3 id="2-user-confusion-about-clicking-a-link-to-login">2. User confusion about clicking a link to login</h3><p>At least 2 people mentioned they simply did not understand that they needed to authenticate with email. &nbsp;To solve this, we added</p><ul><li>call-to-action to open Apple Mail or Gmail</li><li>disabled the "resend" button for 10 seconds, to encourage users to tap the mail CTA before attempting login again</li></ul><figure><img src="https://snaphabit.app/blog/content/images/2020/06/buttons.png"></figure><h3 id="3-users-entering-the-wrong-email">3. Users entering the wrong email</h3><p>Many users who did not finish finish signing up (eg. did not click email link) had accounts with a ".con" domain. &nbsp;We added an notice to alert users of a possibly unintended typo:</p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/dotcon.png"></figure><h2 id="-what-s-next">... What's next</h2><div><p>Despite attempting to solve 1, 2 and 3, our funnel drop-off is still larger than we'd like (~15% of users do not open the email correctly).</p><p>So after two months of solution hackery, we're cutting our losses and adding sign in with Google, Facebook and Apple options. If we still see users opting for email sign-in and failing to complete, we'll consider making the full-circle shift back to an email/password model.<br><strong><br>I hope our sharing this painful journey can save you from taking a similar path!</strong> &nbsp;Let me know if you have any questions or feedback at <a href="https://snaphabit.app/cdn-cgi/l/email-protection" data-cfemail="b6dcd7ddd3f6c5d8d7c6ded7d4dfc298d7c6c698">[email&nbsp;protected]</a></p></div><hr><p><em>Don't have SnapHabit yet? You can download the app on iOS <a href="https://apps.apple.com/us/app/snaphabit-ai-healthy-habits/id1494552185" rel="noopener noreferrer">here</a> and Android <a href="https://play.google.com/store/apps/details?id=io.gravitech.habit.staging" rel="noopener noreferrer">here</a>.</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://snaphabit.app/blog/password-less-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639330</guid>
            <pubDate>Thu, 25 Jun 2020 11:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foam]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23639161">thread link</a>) | @neilkakkar
<br/>
June 25, 2020 | https://foambubble.github.io/foam/ | <a href="https://web.archive.org/web/*/https://foambubble.github.io/foam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<p><strong>Foam</strong> is a personal knowledge management and sharing system inspired by <a href="https://roamresearch.com/">Roam Research</a>, built on <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>.</p>

<p>You can use <strong>Foam</strong> for organising your research, keeping re-discoverable notes, writing long-form content and, optionally, publishing it to the web.</p>

<p><strong>Foam</strong> is free, open source, and extremely extensible to suit your personal workflow. You own the information you create with Foam, and you’re free to share it, and collaborate on it with anyone you want.</p>

<blockquote>
  <p><strong>In a rush?</strong> You <em>could</em> jump to <a href="#getting-started">Getting started</a>, but I highly recommend reading the introductory sections first. <strong>Foam</strong> isn’t obvious.</p>
</blockquote>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#foam">Foam</a>
    <ul>
      <li><a href="#table-of-contents">Table of Contents</a></li>
      <li><a href="#how-do-i-use-foam">How do I use Foam?</a></li>
      <li><a href="#whats-in-a-foam">What’s in a Foam?</a></li>
      <li><a href="#getting-started">Getting started</a></li>
      <li><a href="#features">Features</a></li>
      <li><a href="#call-to-adventure">Call To Adventure</a></li>
      <li><a href="#thanks-and-attribution">Thanks and attribution</a></li>
      <li><a href="#license">License</a></li>
    </ul>
  </li>
</ul>

<h2 id="how-do-i-use-foam">How do I use Foam?</h2>

<p><strong>Foam</strong> is a tool that supports creating relationships between thoughts and information to help you think better.</p>

<p><img src="https://foambubble.github.io/foam/assets/images/foam-navigation-demo.gif" alt="Short video of Foam in use"></p>

<p>Whether you want to build a <a href="https://www.buildingasecondbrain.com/">Second Brain</a> or a <a href="https://zettelkasten.de/posts/overview/">Zettelkasten</a>, write a book, or just get better at long-term learning, <strong>Foam</strong> can help you organise your thoughts if you follow these simple rules:</p>

<ol>
  <li><a href="https://github.com/foambubble/foam-template/generate">Create a single <strong>Foam</strong> workspace</a> for all your knowledge and research.</li>
  <li>Write your thoughts in markdown documents (I like to call them <strong>Bubbles</strong>, but that might be more than a little twee). These documents should be atomic: Put things that belong together into a single document, and limit its content to that single topic. (<a href="https://zettelkasten.de/posts/overview/#principles">source</a>)</li>
  <li>Use Foam’s shortcuts and autocompletions to link your thoughts together with <code>[[wiki-links]]</code>, and navigate between them to explore your knowledge graph.</li>
  <li>Get an overview of your <strong>Foam</strong> workspace using a [<a href="https://foambubble.github.io/foam/graph-visualisation" title="Graph visualisation">graph-visualisation</a>] (⚠️ WIP), and discover relationships between your thoughts with the use of [<a href="https://foambubble.github.io/foam/backlinking" title="Backlinking">backlinking</a>].</li>
</ol>

<p>Foam is a like a bathtub: <em>What you get out of it depends on what you put into it.</em></p>

<h2 id="whats-in-a-foam">What’s in a Foam?</h2>

<p>Like the soapy suds it’s named after, <strong>Foam</strong> is mostly air.</p>

<ol>
  <li>The editing experience of <strong>Foam</strong> is powered by VS Code, enhanced by workspace settings that glue together [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] and preferences optimised for writing and navigating information.</li>
  <li>To back up, collaborate on and share your content between devices, Foam pairs well with <a href="http://github.com/">GitHub</a>.</li>
  <li>To publish your content, you can set it up to publish to <a href="https://pages.github.com/">GitHub Pages</a> with zero code and zero config, or to any website hosting platform like <a href="http://netlify.com/">Netlify</a> or <a href="https://foambubble.github.io/foam/vercel">Vercel</a>.</li>
</ol>

<blockquote>
  <p><strong>Fun fact</strong>: This documentation was researched, written and published using <strong>Foam</strong>.</p>
</blockquote>

<h2 id="getting-started">Getting started</h2>

<blockquote>
  <p>⚠️ Foam is still in preview. Expect the experience to be a little rough.</p>
</blockquote>

<p>These instructions assume you have a GitHub account, and you have Visual Studio Code installed.</p>

<ol>
  <li><a href="https://github.com/foambubble/foam-template/generate">Create a GitHub repository from foam-template</a>. If you want to keep your thoughts to yourself, remember to set the repository private.</li>
  <li>Clone the repository and open it in VS Code.</li>
  <li>When prompted to install recommended extensions, click <strong>Install all</strong> (or <strong>Show Recommendations</strong> if you want to review and install them one by one)</li>
</ol>

<p>After setting up the repository, open <a href="https://foambubble.github.io/foam/.vscode/settings.json">.vscode/settings.json</a> and edit, add or remove any settings you’d like for your Foam workspace.</p>

<p>To learn more about how to use <strong>Foam</strong>, read the [<a href="https://foambubble.github.io/foam/recipes" title="Recipes">recipes</a>].</p>

<p>There are [<a href="https://foambubble.github.io/foam/known-issues" title="Known Issues">known-issues</a>], and I’m sure, many unknown issues! Please <a href="http://github.com/foambubble/foam/issues">report them on GitHub</a>!</p>

<h2 id="features">Features</h2>

<p><strong>Foam</strong> doesn’t have features in the traditional sense. Out of the box, you have access to all features of VS Code and all the [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] you choose to install, but it’s up to you to discover what you can do with it!</p>

<p>Head over to [<a href="https://foambubble.github.io/foam/recipes" title="Recipes">recipes</a>] for some useful patterns and ideas, and</p>

<h2 id="call-to-adventure">Call To Adventure</h2>

<p>The goal of <strong>Foam</strong> is to be your personal companion on your quest for knowledge.</p>

<p>It’s is currently about “10% ready” relative to all the features I’ve thought of, but I’ve only thought of ~1% of the features it could have, and I’m excited to learn from others.</p>

<p>I am using it as my personal thinking tool. By making it public, I hope to learn from others not only how to improve Foam, but also to improve how I learn and manage information.</p>

<p>If that sounds like something you’re interested in, I’d love to have you along on the journey.</p>

<ul>
  <li>Check out [<a href="https://foambubble.github.io/foam/roadmap" title="Roadmap">roadmap</a>] to see what’s in the plans</li>
  <li>Read about our [<a href="https://foambubble.github.io/foam/principles" title="Principles">principles</a>] to understand Foam’s philosophy and direction</li>
  <li>Read the [<a href="https://foambubble.github.io/foam/contribution-guide" title="Contribution Guide">contribution-guide</a>] guide to learn how to participate.</li>
  <li>Feel free to open <a href="https://github.com/foambubble/foam/issues">GitHub issues</a> to give me feedback and ideas for new features.</li>
</ul>

<h2 id="thanks-and-attribution">Thanks and attribution</h2>

<p><strong>Foam</strong> is built by <a href="https://github.com/jevakallio">Jani Eväkallio</a> (<a href="https://twitter.com/jevakallio">@jevakallio</a>).</p>

<p><strong>Foam</strong> was inspired by <a href="https://roamresearch.com/">Roam Research</a> and the <a href="https://zettelkasten.de/posts/overview">Zettelkasten methodology</a></p>

<p><strong>Foam</strong> wouldn’t be possible without <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>, and relies heavily on our fantastic open source [<a href="https://foambubble.github.io/foam/recommended-extensions" title="Recommended Extensions">recommended-extensions</a>] and all their contributors:</p>

<h2 id="license">License</h2>

<p>Foam is licensed under the <a href="https://foambubble.github.io/foam/license">MIT license</a>.</p>






      
      
      
    </div></div>]]>
            </description>
            <link>https://foambubble.github.io/foam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639161</guid>
            <pubDate>Thu, 25 Jun 2020 10:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Server Side Rendering React App with Deno]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23638676">thread link</a>) | @kazade
<br/>
June 25, 2020 | https://dev.p.ota.to/post/server-side-rendering-react-app-with-deno-4qf28vm8axb/ | <a href="https://web.archive.org/web/*/https://dev.p.ota.to/post/server-side-rendering-react-app-with-deno-4qf28vm8axb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody mainEntityOfPage">
        <div><p><img src="https://dev.p.ota.to/images/5670392840585216/" alt="Image"></p>
<h2>Intro</h2>
<p>Two of my favourites things are React and dinosaurs.
In this article I will show how I’ve put them together to develop a server side rendering <a href="https://reactjs.org/">React</a> application with <a href="https://deno.land/">Deno</a>.</p>
<h2>Project Setup</h2>
<p>I will assume that we are all familiar with React and Deno. Knowing that Deno is pretty new, if you don’t know how to install it and how it works, I would highly suggest you to have a read at this great <a href="https://dev.p.ota.to/post/an-introduction-to-deno-4u3suut77w6/">introduction</a> before diving into this article.</p>
<p>Now let’s start creating the project structure and the files needed for this tutorial, I’m using <a href="https://code.visualstudio.com/">Visual Studio Code</a> but any editor will do.
Open your terminal and type:</p>
<pre><code>mkdir deno-react-ssr &amp;&amp; cd $_
code .
</code></pre>
<p>This will create a new folder called <code>deno-react-ssr</code> and will open it with vscode.
In this folder we will need to create three files, <code>app.tsx</code> that will contain the code of the React component, <code>server.tsx</code> for the server code and <code>deps.ts</code> will contain all our dependencies. Think of it as our version of a <code>package.json</code>.
You will end up with a structure like this:</p>
<pre><code>.
├── app.tsx
├── deps.ts
└── server.tsx
</code></pre>
<h2>Setting up the dependencies</h2>
<p>In <code>deps.ts</code> we will have to export all the dependencies needed for this application to run.
Copy the following code and add it to your file.</p>
<pre><code>// @deno-types="https://deno.land/x/types/react/v16.13.1/react.d.ts"
import React from 'https://jspm.dev/react@16.13.1';
// @deno-types="https://deno.land/x/types/react-dom/v16.13.1/server.d.ts"
import ReactDOMServer from 'https://jspm.dev/react-dom@16.13.1/server';
export { React, ReactDOMServer }
export { Application, Context, Router } from 'https://deno.land/x/oak@v4.0.0/mod.ts';
</code></pre>
<p>As you can see, in Deno you import the modules directly from a url. 
I’ve decided to import React and ReactDOMServer from <a href="https://jspm.org/">jspm</a> as suggested in the <a href="https://deno.land/#third-party-modules">documentation for third party modules</a> but you can use any other CDN that provides the same modules.</p>
<p>One unusual thing that may stand out to you could be this:<br>
<code>// @deno-types="https://deno.land/x/types/react/v16.13.1/react.d.ts"</code><br>
Since we are using typescript, this line of code will inform Deno of the location of the types it needs to import and will affect the <code>import</code> statement that follows. A more exhaustive explanation can be found in the <a href="https://deno.land/manual/getting_started/typescript#compiler-hint">Deno Type Hint</a> manual.</p>
<p>I’ve also decided to use <a href="https://github.com/oakserver/oak">Oak</a>, a middleware framework for <a href="https://doc.deno.land/https/deno.land/std/http/mod.ts">Deno's http server</a> that also provides a router, so I’m importing all the modules we will use in the server in addition to the <code>Context</code> type that typescript requires.</p>
<h2>Create your React component</h2>
<p>This is how our <code>app.tsx</code> component will look:</p>
<pre><code>import { React } from "./deps.ts";

const App = () =&gt; {
  const [count, setCount] = React.useState(0);

  const garden = {
    backgroundColor: 'green',
    height: 'auto',
    fontSize: '30px',
    maxWidth: '400px',
    padding: '20px 5px',
    width: '100%'
  };

  return (
    &lt;div className="pure-g pure-u"&gt;
      &lt;h2&gt;My DenoReact App&lt;/h2&gt;
      &lt;button className="pure-button" onClick={() =&gt; setCount(count + 1)}&gt;Add a 🦕 in your garden!&lt;/button&gt;
      &lt;p style={garden}&gt;
      { Array(count).fill(&lt;span&gt;🦕&lt;/span&gt;) }
      &lt;/p&gt;
    &lt;/div&gt;
  );
};

export default App;
</code></pre>
<p>As with any standard React component, we start by importing React from our <code>deps.ts</code> file.</p>
<p>Then we are going to declare our App component that uses <a href="https://reactjs.org/docs/hooks-intro.html">hooks</a> to implement a simple button counter that allows you to add as many dinosaurs as you want in your personal garden!</p>
<h2>Setting up the Server</h2>
<p>For the server I’m using <a href="https://github.com/oakserver/oak">Oak</a> and the code in <code>server.tsx</code> will look like this:</p>
<pre><code>import {
  Application,
  Context,
  React,
  ReactDOMServer,
  Router,
} from './deps.ts';

import App from "./app.tsx";

const PORT = 8008;

const app = new Application();
const jsBundle = "/main.js";

const js =
`import React from "https://jspm.dev/react@16.13.1";
 import ReactDOM from "https://jspm.dev/react-dom@16.13.1";
 const App = ${App};
 ReactDOM.hydrate(React.createElement(App), document.getElementById('app'));`;  


const html =
  `&lt;html&gt;
    &lt;head&gt;
      &lt;link rel="stylesheet" href="https://unpkg.com/purecss@2.0.3/build/pure-min.css"&gt;
      &lt;script type="module" src="${jsBundle}"&gt;&lt;/script&gt;
    &lt;/head&gt;
    &lt;body&gt;
      &lt;main id="app"&gt;${ReactDOMServer.renderToString(&lt;App /&gt;)}&lt;/main&gt;  
    &lt;/body&gt;
  &lt;/html&gt;`;

const router = new Router();
router
  .get('/', (context: Context) =&gt; {
    context.response.type = 'text/html';
    context.response.body = html;
  })
  .get(jsBundle, (context: Context) =&gt; {
    context.response.type = 'application/javascript';
    context.response.body = js;
  });

app.use(router.routes());
app.use(router.allowedMethods());

console.log(`Listening on port ${PORT}...`);

await app.listen({ port: PORT });
</code></pre>
<p>As always we need to import all the dependencies we will use in our server. 
We will also import our App we created earlier, as you can see the extension <code>.tsx</code> is required in Deno so don’t forget it!<br>
Next step is to create our Oak server application and we’ll also need to define some routes:</p>
<ul>
<li><code>'/'</code> will serve our HTML page that contains the rendered app.  </li>
<li><code>'/main.js'</code>  will serve our application code that is needed to <a href="https://reactjs.org/docs/react-dom.html#hydrate">hydrate</a> the client side React application.</li>
</ul>
<p>Finally we tell our application to use the route we just created and start listening on port <code>8008</code>. You can notice I’m also using <code>router.allowedMethods()</code>, it’s a middleware that lets the client know when a route is not allowed.</p>
<h2>Run the application</h2>
<p>Running the SSR React application we just created is extremely simple, you just need to use the following command:</p>
<pre><code>deno run --allow-net ./server.tsx
</code></pre>
<p>Deno is built secure by default, that means that a Deno application will not be able to access your network, to overcome this we'll just need to use Deno's <code>--allow-net</code> flag.<br>
Now the only thing missing is to open <code>http://localhost:8008/</code> and enjoy your new App!</p>
<h2>Conclusion</h2>
<p>I hope you enjoyed the brief tutorial illustrated in this article and I’m looking forward to seeing what will happen next and how more complex applications can be built with this stack.</p>
<p>If you are still unclear about anything we’ve done or want a full reference of the code, here’s the <a href="https://github.com/fleonard/deno-react-ssr">GitHub repository</a>.</p>
</div>
    </div></div>]]>
            </description>
            <link>https://dev.p.ota.to/post/server-side-rendering-react-app-with-deno-4qf28vm8axb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638676</guid>
            <pubDate>Thu, 25 Jun 2020 09:34:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Beautiful Visualisations with the Chord Package]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23638474">thread link</a>) | @shahinrostami
<br/>
June 25, 2020 | https://shahinrostami.com/posts/statistics/data-is-beautiful/animal-crossing-villagers-species-and-personalities/ | <a href="https://web.archive.org/web/*/https://shahinrostami.com/posts/statistics/data-is-beautiful/animal-crossing-villagers-species-and-personalities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="alert">
        <p><a href="https://stamilabs.com/">
        <img src="https://shahinrostami.com/images/stami-labs/cat.jpg"></a>
            <a href="https://stamilabs.com/">Join our Stami Labs Patreon</a> to get <b>Exclusive Downloads</b>, <b>Direct Support</b>, <b>Early Access</b>, <b>Voting Access</b>, our <b>Books for Free</b>, and so much more!
        </p>
    </div><div role="alert">
        <p><a href="https://store.shahinrostami.com/product/data-is-beautiful/">
        <img src="https://shahinrostami.com/images/data-is-beautiful/front.jpg"></a>
            Enjoying these notebooks and want to support the work?
            Get the <a href="https://store.shahinrostami.com/product/data-is-beautiful/">Data is Beautiful Book</a> or check out the <a href="https://www.youtube.com/playlist?list=PLwWiU_ClpuYpC1tEY47k_-CTzDKz1UYIN">Complementary Videos</a>.
        </p>
        </div></div>]]>
            </description>
            <link>https://shahinrostami.com/posts/statistics/data-is-beautiful/animal-crossing-villagers-species-and-personalities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638474</guid>
            <pubDate>Thu, 25 Jun 2020 09:04:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get your first 100 users as a SaaS startup founder?]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23638173">thread link</a>) | @nathanganser
<br/>
June 25, 2020 | https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx | <a href="https://web.archive.org/web/*/https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>You've got to start somewhere right. You've got your landing page and maybe even an MVP, but no one is visiting your website! How do you actually get those first 100 users? I've been there myself with  <a target="_blank" rel="noopener noreferrer" href="https://nat.app/">my startup</a>, and I would have loved to read such an article when I got started, so here it is! In honour of my past self and to help all fellow startup founders! </p>
<h2 id="get-started">Get started</h2>
<p>Here are a few basic tips you should get started with. They will pay off in the coming months. </p>
<h3 id="start-with-seo">Start with SEO</h3>
<p>SEO will not get you users overnight, but it's an amazing long term investment. Do it. 
Obviously, don't try to rank for super general keywords, instead, focus on niche keywords your audience is interested in. Here are a few examples from our own startup: </p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@nathanganser/which-contacts-am-i-losing-touch-with-find-out-now-25f2db1320c3">Which contacts am I losing touch with? Find out now</a> </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/what-is-a-gmail-metadata-integration-and-why-you-should-use-it-57b37fe54dbe">What is a Gmail Metadata integration and why you should use it</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/how-i-created-an-automated-relationship-management-tool-using-coda-zapier-8a31a6d2ebe2">How I created an Automated Relationship Management tool using Coda &amp; Zapier</a>  </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/the-ultimate-personal-relationship-manager-list-2ae87acf5070">Top 6 Best Personal CRM apps</a> </li>
</ul>
<p><em>Like passive income, those articles are generating a steady (albeit small) traffic to our app. But what's powerful about this traffic is that its super high-quality people. Only passionate people will find your articles, and when they do, they'll check out your app as well. </em></p>
<h3 id="quora-twitter-answer-to-questions">Quora &amp; Twitter: Answer to questions</h3>
<p>Create a company account and start replying to questions related to what you're doing. Twitter has a really good advanced search feature and Quora will suggest you more than enough questions you can reply to. If you spend a few hours each week generating good content on those platforms, you'll get a steady stream of clicks to your landing page as well. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1592240101831/sk3gE249t.png?auto=format&amp;q=60" alt="quora-answers-stats.png"></p>
<h3 id="pioneer-app">Pioneer.app</h3>
<p> <a target="_blank" rel="noopener noreferrer" href="https://pioneer.app/">Pioneer</a>  is an online accelerator that you can join for free. Every week, you submit a progress update and other users will give you feedback. This is a free way to get a few clicks to your app from startup founders. </p>
<h3 id="get-listed-on-10words-betalist">Get listed on 10words &amp; Betalist</h3>
<p> <a target="_blank" rel="noopener noreferrer" href="https://10words.io/">10words</a> and  <a target="_blank" rel="noopener noreferrer" href="https://blog.nat.app/betalist.com">BetaList</a> are like a small Product Hunts. They are much smaller, you can expect around 50 clicks to your website for each. Still worth something! </p>
<h3 id="list-your-startup-on-indie-hacker-makerlog">List your startup on Indie Hacker &amp; Makerlog</h3>
<p>Those are two cool communities. If you're active, you'll definitely get some attention and users! </p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://getmakerlog.com/">MakerLog</a> </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://blog.nat.app/indiehackers.com">Indie Hacker</a></li>
</ul>
<h3 id="product-hunt-ship">Product Hunt Ship</h3>
<p>Product Hunt has a place for upcoming apps called <strong> <a target="_blank" rel="noopener noreferrer" href="https://www.producthunt.com/ship">Ship</a> </strong>, I've not found it to be very useful, but it can get you a few additional users. </p>
<h2 id="growth-hacks">Growth hacks</h2>
<p>That's where stuff gets exciting. Use these growth hacks with moderation, there is a fine line between marketing and spamming. </p>
<h3 id="product-hunt-phantombuster-twitter">Product Hunt + PhantomBuster + Twitter</h3>
<p>If there are already a few apps on ProductHunt that are similar to what you're building, consider using  <a target="_blank" rel="noopener noreferrer" href="https://www.indiehackers.com/post/how-i-growth-hacked-my-way-to-500-waiting-list-subscribers-9612933fd3">this growth hack</a>. I've used it extensively myself. </p>
<h3 id="buy-targeted-email-lists">Buy targeted email lists</h3>
<p>I've built a tool myself that lets me scrape email addresses from founders on Indie Hacker. What's powerful is that you can filter by every filter available on Indie Hacker (revenue, location, business model, ...). You can use it to buy an email list here and use a tool like <a target="_blank" rel="noopener noreferrer" href="https://gmass.com/">Gmass</a> or Streak to reach out.  <a target="_blank" rel="noopener noreferrer" href="https://scrapeindiehacker.app/">Buy a list here</a>.</p>
<p>I don't recommend just sending the same email to everyone as this will impact your reputation. Instead, send personalized mass emails. It does take a bit longer, but it's worth every second considering the impact it will have on response rate and trust.</p>

<p>There are many chrome extensions out there that have tons of users but that are not maintained anymore. You can buy one for very cheap that is related to what you do and advertise your business on there. I bought  <a target="_blank" rel="noopener noreferrer" href="https://chrome.google.com/webstore/detail/google-contacts-opener/pjpambjkhcilibnmeihhfgdkhfelbdkj">Google Contacts Opener</a>  and it's been generating significant traffic to our website ever since. </p>
<h2 id="what-you-should-not-be-doing">What you should not be doing</h2>
<h3 id="advertising">Advertising</h3>
<p>It will cost you too much. Just don't think about it. In the early days, ads are not the way to go.</p>
<h3 id="launch-on-product-hunt">Launch on Product Hunt</h3>
<p>You've got only one shot at this, it better be big. You don't want to launch on Product Hunt before having built a mature product. Product Hunt is not for the launching phase, it's for the growth phase.  <a target="_blank" rel="noopener noreferrer" href="https://betalist.com/">BetaList</a> is a better place to start.</p>
<h3 id="my-startup-s-traffic">My startup's traffic</h3>
<p>Here is a breakdown of who visited our website recently. This will give you a better idea of what you should focus on. 
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1592241905463/7LrJ4YdmB.png?auto=format&amp;q=60" alt="website visitor origin.png"></p>
</div></div>]]>
            </description>
            <link>https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638173</guid>
            <pubDate>Thu, 25 Jun 2020 08:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Zoom works [slides]]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 143 (<a href="https://news.ycombinator.com/item?id=23638116">thread link</a>) | @Spidery
<br/>
June 25, 2020 | https://builtformars.co.uk/how-zoom-works/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/how-zoom-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="single" data-elementor-id="2530" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="c26fc93" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="28a6896" data-element_type="column">
			<div>
					<div>
				
				<div data-id="b04b2c1" data-element_type="widget" data-widget_type="theme-post-excerpt.default">
				<p>
			Zoom is a significant challenger in the video conferencing space, but is their UX any better than Skype or Cisco?		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="052a335" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4224d77" data-element_type="column">
			<div>
					<div>
				<div data-id="5ad8739" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="a001539" data-element_type="column">
			<div>
					<div>
				
				<div data-id="724633a" data-element_type="widget" data-widget_type="post-info.default">
				<div>
					<ul>
					<li itemprop="datePublished">
										<span>
															</span>
									<span>
							<span>📅 Added on</span>
										April 15, 2020					</span>
								</li>
				</ul>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2643ed8" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="a995590" data-element_type="column">
			<div>
					<div>
				<div data-id="c9f06a8" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="ec20c55" data-element_type="column">
			<div>
					<div>
				<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="3204" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="7b73c3c" data-element_type="section">
						<div>
				<div>
				<div data-id="d0a7d7b" data-element_type="column">
			<div>
					<div>
				<div data-id="cd0bf0c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><div><div role="region" aria-label="Slider"><p><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjkwMCIgPjwvc3ZnPg==" alt="Slider"></p></div></div></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="375357f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="353f855" data-element_type="column">
			<div>
					<div>
				<div data-id="891920c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>💡<strong>Tip:</strong> Try using the ⬅️ <span>➡️arrows on your keyboard to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9ffc41b" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="5f2393c" data-element_type="column">
			<div>
					<div>
				<div data-id="b2a958e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>Mobile tip:</strong> Try swiping ⬅️<span>👆➡️ left and right to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="5094e89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4d0fdca" data-element_type="column">
			<div>
					<div>
				
				<div data-id="560b6f9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>New case studies—packed with UX lessons—are published every <strong>14 days</strong>.</p>
				</div>
				</div>
				<div data-id="c135888" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>📮 No spam, ever.&nbsp; &nbsp;</span><span>📅 1 email a week.&nbsp; &nbsp;</span><span>👋 Unsubscribe anytime.</span></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3daa393" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4876312" data-element_type="column">
			<div>
					<div>
				<section data-id="05a68ee" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="09ef108" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				<div data-id="31901c7" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Subscribe and get a new case study like this every <strong>14 days</strong>!</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="94d99dd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="3a870f9" data-element_type="column">
			<div>
					<div>
				<div data-id="91f57f2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There’s always more to learn</p>
				</div>
				</div>
				<div data-id="2f5c033" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Dive into other case studies. They’re typically a <strong>5 minute read</strong>.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c62cabd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
					</div>
		</div>
		</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/how-zoom-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638116</guid>
            <pubDate>Thu, 25 Jun 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye, Bountysource]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23637831">thread link</a>) | @reddotX
<br/>
June 25, 2020 | https://blog.elementary.io/goodbye-bountysource-hello-github-sponsors/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/goodbye-bountysource-hello-github-sponsors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   We’re leaving Bountysource. Here’s&nbsp;why.

</h2>
    

    



<div>
  <p><img srcset="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=96&amp;d=blank 2x" src="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=48&amp;d=blank" alt="Avatar for Cassidy James Blaede">
  </p>
  
  <p><time datetime="2020-06-24">Wed, Jun 24, 2020</time>
  
    <span title="Estimated read time">
  
  4 min read
</span>


  
</p></div>


    


  </header>

  <section>
    <p><img src="https://blog.elementary.io/images/goodbye-bountysource-hello-github-sponsors/feature.png" alt="Bountysource → GitHub Sponsors" width="800" height="450" srcset="https://blog.elementary.io/images/goodbye-bountysource-hello-github-sponsors/feature@2x.png"></p>

<p>If you have used <a rel="nofollow noopener noreferrer" target="_blank" href="https://bountysource.com/">Bountysource</a> in the past, you may have received an email announcing new terms of service that included a clause that would forfeit unclaimed bounties. On June 16, Bountysource sent this message:</p>

<blockquote>
  <p>You are receiving this email because we are updating the Bountysource Terms of Service, effective 1st July 2020.</p>

  <h4 id="whats-changing">What’s changing?</h4>
  <p>We have added a Time-Out clause to the Bounties section of the agreement:</p>

  <blockquote>
    <p><em>2.13 Bounty Time-Out.</em></p>

    <p><em>If no Solution is accepted within two years after a Bounty is posted, then the Bounty will be withdrawn and the amount posted for the Bounty will be retained by Bountysource. For Bounties posted before June 30, 2018, the Backer may redeploy their Bounty to a new Issue by contacting <a href="mailto:support@bountysource.com">support@<wbr>bountysource.com</a> before July 1, 2020. If the Backer does not redeploy their Bounty by the deadline, the Bounty will be withdrawn and the amount posted for the Bounty will be retained by Bountysource.</em></p>
  </blockquote>

  <p>…</p>
  <h4 id="what-do-i-need-to-do">What do I need to do?</h4>
  <p>If you agree to the new terms, you don’t have to do anything… Or, if you do not agree with the new terms, please discontinue using Bountysource.</p>
</blockquote>

<p>This gave open source projects and their bounty hunters just two weeks to act; oftentimes it would take <em>longer than that</em> to even get a response from the support team. The controversial terms have since been withdrawn—at least for now. On June 17, Bountysource sent the following message (emphasis theirs):</p>

<blockquote>
  <p>You’re receiving this because we updated our Terms of Service.</p>

  <h4 id="withdrawal-of-new-terms-of-service">Withdrawal of new Terms of Service</h4>
  <p>Yesterday, we communicated a change to the Bountysource Terms of Service (ToS) agreement. <br>
<strong>These changes have been withdrawn and the ToS reverted to its prior state.</strong><br>
The ToS will be revised and clarified in the future.</p>

  <p>Thankyou</p>
</blockquote>

<p>In December, 2017, <a rel="nofollow noopener noreferrer" target="_blank" href="https://web.archive.org/web/20191008103840/https://blog.canya.com/2017/12/20/canya-acquires-majority-stake-in-bountysource-adds-over-46000-users/">Bountysource was acquired</a> by a cryptocurrency company called CanYa who redesigned the Bountysource site and service with a new cryptocoin focus. In addition to the general friction we’ve experienced with using the service since to get developers paid, we feel like this policy change–even withdrawn–is concerning. It calls into question the future of Bountysource as a platform and the stability of their business model. While we understand that operating a platform incurs costs, we want to make sure that funds are primarily going to developers, not being automatically scooped up by corporate stakeholders.</p>

<p>These events have led us to re-think our recommendation and use of Bountysource. As such, we’ve removed Bountysource from our website, removed any Bountysource integration with elementary repos on GitHub, withdrawn our funds, and closed our account. For backers and bounty hunters on Bountysource, your bounties on elementary projects will automatically be returned to you. You may also wish to withdraw any funds and close your account by emailing <a href="mailto:support@bountysource.com">support@<wbr>bountysource.com</a>.</p>



<p>As an alternative, we recommend checking out <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/sponsors/elementary">GitHub Sponsors</a>. We recently launched a few tiers on Sponsors, and have been very pleased with it.</p>

<p>You can directly sponsor <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/sponsors/elementary">organizations like elementary</a>, as well as individual contributors. For elementary specifically, we have a new $50/month tier that offers the closest equivalent to a bug bounty program: each month, backers at this tier can comment on any elementary issue to get at least an hour of our investigation time. This is a great way to help steer development in the direction you see fit while also directly supporting us.</p>



<p>GitHub also covers payment processing and doesn’t charge any fees for GitHub Sponsors; this means <strong>100% of your sponsorship goes to elementary</strong> to help fund our work.</p>

<p>If GitHub Sponsors isn’t your cup of tea, you can also check out the funding section on our <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved#funding">Get Involved</a> page to see other ways you can help support elementary OS.</p>


  </section>

  
<div>
  <hr>

  <h2>Thank You</h2>
  <p>Thanks to all of our supporters, backers, and customers! Your contributions make elementary possible. If you’d like to help build and improve elementary OS, don’t hesitate to <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved">Get Involved</a>.</p>

  
</div>




</article></div>]]>
            </description>
            <link>https://blog.elementary.io/goodbye-bountysource-hello-github-sponsors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23637831</guid>
            <pubDate>Thu, 25 Jun 2020 07:29:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No code tools for each stage of application development]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23637671">thread link</a>) | @GeneloJ
<br/>
June 25, 2020 | https://www.testcraft.io/no-code-tools-application-development/ | <a href="https://web.archive.org/web/*/https://www.testcraft.io/no-code-tools-application-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div id="mk-page-id-6013">
					<div itemprop="mainEntityOfPage">
							
	<article id="6013" itemscope="itemscope" itemprop="blogPost" itemtype="http://schema.org/BlogPosting">

					<h2 itemprop="headline">17 no-code tools for each stage of application development [Infographic]</h2>
	







<div itemprop="mainEntityOfPage">
	
<p>It seems that coding skills are becoming less and less of a barrier to building and launching a successful application.</p>
<p>No-code tools have offered everyone from small businesses to enterprises the opportunity to achieve digital transformation both simply and sustainably. In the <a href="https://www.forbes.com/sites/johneverhard/2019/01/15/what-really-is-low-codeno-code-development/#61935a6f2a8e" target="_blank" rel="noopener noreferrer">words of Forbes contributor John Everhard</a>, no-code, as well as often-associated low-code, solutions help “build powerful applications that can scale for any organization—without writing any code.”</p>
<p>Everhard further discussed in his article the powerful impact that no-code tools, also known as codeless tools, can have. With these types of software, IT teams no longer need to spend 60% of their time keeping their current systems working. Instead, no-code solutions help companies maintain a competitive edge over their peers with up to a 75% improvement on time to market.</p>
<p>Industry analysts have taken note of the “no-code movement” as well, with <a href="https://www.salesforce.com/blog/2019/08/gartner-lcap.html" target="_blank" rel="noopener noreferrer">Gartner predicting</a> that low-code application platforms (LCAP) will account for 65% of application development activity by 2024. Enterprises seem to be taking note as well, whether by <a href="https://www.testcraft.io/testcraft-joins-perforce/" target="_blank" rel="noopener noreferrer">acquiring codeless tools</a> or by releasing no-code capabilities of their own.</p>
<p>With that in mind, here is a list of different tools to keep on your radar in the no-code space. These tools cover every stage of application development, although there are other solutions that are not covered here, such as industry-specific solutions and payment applications.</p>

<h2><a href="https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development.pdf"><img src="https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1-410x1024.png" alt="17 no-code tools for each stage of application development infographic" width="410" height="1024" srcset="https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1-410x1024.png 410w, https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1-120x300.png 120w, https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1-768x1920.png 768w, https://www.testcraft.io/wp-content/uploads/2020/06/copy-of-17-no-code-tools-for-each-stage-of-application-development1-1.png 800w" sizes="(max-width: 410px) 100vw, 410px"></a></h2>
<h2>No-code web &amp; mobile application development tools</h2>
<ul>
<li><strong><a href="https://bubble.io/" target="_blank" rel="noopener noreferrer">Bubble</a></strong>: A visual programming language that helps anyone build a web application without coding knowledge.</li>
<li><strong><a href="https://www.glideapps.com/" target="_blank" rel="noopener noreferrer">Glide</a></strong>: A free no-code tool that allows users to build a mobile application in five minutes from Google Sheets.</li>
<li><strong><a href="https://www.voiceflow.com/" target="_blank" rel="noopener noreferrer">Voiceflow</a></strong>: A codeless way to develop voice apps for Amazon Alexa and Google Assistant.</li>
<li><strong><a href="https://webflow.com/" target="_blank" rel="noopener noreferrer">Webflow</a></strong>: An online visual editor platform that allows users to design, build, and launch responsive websites.</li>
<li><strong><a href="https://carrd.co/" target="_blank" rel="noopener noreferrer">Carrd</a></strong>: A free platform for building simple, fully responsive one-page web sites without code.</li>
</ul>
<h2>Codeless testing tools</h2>
<ul>
<li><strong><a href="https://www.testcraft.io/product/" target="_blank" rel="noopener noreferrer">TestCraft</a></strong>: A codeless Selenium test automation platform for continuous and regression testing of web applications.</li>
<li><strong><a href="https://www.accelq.com/codeless_api" target="_blank" rel="noopener noreferrer">AccelQ API</a></strong>: A no-code API test automation tool that allows companies to test REST APIs.</li>
<li><strong><a href="https://www.pcloudy.com/" target="_blank" rel="noopener noreferrer">pCloudy</a></strong>: A mobile test automation platform that helps users build and execute mobile tests without code.</li>
</ul>
<h2>No-code content and data management tools</h2>
<ul>
<li><strong><a href="https://airtable.com/" target="_blank" rel="noopener noreferrer">Airtable</a></strong>: A spreadsheet-database hybrid that helps teams manage content, projects, and other initiatives.</li>
<li><strong><a href="https://www.notion.so/" target="_blank" rel="noopener noreferrer">Notion</a></strong>: A no-code tool for managing documents, notes, tasks, spreadsheets, and databases.</li>
</ul>
<h2>Visual task automation tools</h2>
<ul>
<li><strong><a href="https://zapier.com/" target="_blank" rel="noopener noreferrer">Zapier</a></strong>: A codeless tool for connecting your applications and automating your workflows.</li>
<li><strong><a href="https://tryretool.com/" target="_blank" rel="noopener noreferrer">Retool</a></strong>: A platform for building internal tools without code.</li>
<li><strong><a href="https://www.actiondesk.io/" target="_blank" rel="noopener noreferrer">ActionDesk</a></strong>: A spreadsheet software that lets you import data from SQL, Stripe, Salesforce, HubSpot, and others to automate a variety of tasks.</li>
<li><strong><a href="https://build.stdlib.com/" target="_blank" rel="noopener noreferrer">Standard Library</a></strong>: A no-code library that helps users build automated workflows and APIs.</li>
</ul>
<h2>Codeless communication tools</h2>
<ul>
<li><strong><a href="https://www.typeform.com/" target="_blank" rel="noopener noreferrer">Typeform</a></strong>: A tool for designing surveys and other responsive forms without code.</li>
<li><strong><a href="https://mailchimp.com/" target="_blank" rel="noopener noreferrer">Mailchimp</a></strong>: A no-code email marketing service that gives users the ability to create professional, designed emails visually.</li>
<li><strong><a href="https://anchor.fm/" target="_blank" rel="noopener noreferrer">Anchor</a></strong>: A codeless platform for creating, hosting, and distributing podcast episodes.</li>
</ul>

<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-6302584c-b0f6-4c2f-b1f8-c05e4cede1aa"><span id="hs-cta-6302584c-b0f6-4c2f-b1f8-c05e4cede1aa"><!-- [if lte IE 8]>


<div id="hs-cta-ie-element"></div>


<![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/2539507/6302584c-b0f6-4c2f-b1f8-c05e4cede1aa" target="_blank" rel="noopener noreferrer"><img id="hs-cta-img-6302584c-b0f6-4c2f-b1f8-c05e4cede1aa" src="https://no-cache.hubspot.com/cta/default/2539507/6302584c-b0f6-4c2f-b1f8-c05e4cede1aa.png" alt="Selenium Testing eBook" width="800" height="160"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>
</div>



    
</article>

							
											</div>
					
					
				</div>
			</div></div>]]>
            </description>
            <link>https://www.testcraft.io/no-code-tools-application-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23637671</guid>
            <pubDate>Thu, 25 Jun 2020 07:02:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why AES-GCM Sucks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23637605">thread link</a>) | @yinso
<br/>
June 24, 2020 | https://soatok.blog/2020/05/13/why-aes-gcm-sucks/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>If you’re reading this wondering if you should stop using AES-GCM in some standard protocol (TLS 1.3), the short answer is “No, you’re fine”. </p>



<p>I specialize in secure implementations of cryptography, and my years of experience in this field have led me to dislike AES-GCM.</p>



<p>This post is about why I dislike AES-GCM’s design, not “why AES-GCM is insecure and should be avoided”. AES-GCM is still miles above what most developers reach for when they want to encrypt (e.g. <a href="https://blog.filippo.io/the-ecb-penguin">ECB mode</a> or <a href="https://robertheaton.com/2013/07/29/padding-oracle-attack/">CBC mode</a>).</p>



<p>To be clear: This is solely my opinion and not representative of any company or academic institution.</p>



<h2 id="what-is-aes-gcm">What is AES-GCM?</h2>



<p>AES-GCM is an authenticated encryption mode that uses the AES block cipher in counter mode with a polynomial MAC based on Galois field multiplication.</p>



<p>In order to explain why AES-GCM sucks, I have to first explain what I dislike about the AES block cipher. Then, I can describe why I’m filled with sadness every time I see the AES-GCM construction used.</p>



<h3 id="what-is-aes">What is AES?</h3>



<p>The Advanced Encryption Standard (AES) is a specific subset of a block cipher called Rijndael.</p>



<p>Rijndael’s design is based on a substitution-permutation network, which broke tradition from many block ciphers of its era (including its predecessor, DES) in not using a Feistel network.</p>



<p>AES only includes three flavors of Rijndael: AES-128, AES-192, and AES-256. The difference between these flavors is the size of the key and the number of rounds used, but–and this is often overlooked–not the block size.</p>



<p>As a block cipher, AES always operates on 128-bit (16 byte) blocks of plaintext, regardless of the key size.</p>



<p>This is generally considered acceptable because AES is a secure pseudorandom permutation (PRP), which means that every possible plaintext block maps directly to one ciphertext block, and thus <a href="https://en.wikipedia.org/wiki/Birthday_problem#Cast_as_a_collision_problem">birthday collisions</a> are not possible. (A pseudorandom function (PRF), conversely, does have birthday bound problems.)</p>



<h3 id="why-aes-sucks">Why AES Sucks</h3>







<h4 id="side-channels">Side-Channels</h4>



<p>The biggest reason why AES sucks is that its design uses a lookup table (called an S-Box) <a href="https://github.com/veorq/cryptocoding#avoid-table-look-ups-indexed-by-secret-data">indexed by secret data</a>, which is inherently vulnerable to cache-timing attacks (<a href="https://cr.yp.to/antiforgery/cachetiming-20050414.pdf">PDF</a>).</p>



<p>There are workarounds for this AES vulnerability, but they either require hardware acceleration (AES-NI) or a technique called <a href="https://github.com/jedisct1/libsodium/tree/1.0.14/src/libsodium/crypto_stream/aes128ctr/nacl">bitslicing</a>.</p>



<p>The short of it is: With AES, you’re either using hardware acceleration,<em> or </em>you have to choose between performance and security. You cannot get fast, constant-time AES without hardware support.</p>



<h4 id="block-size">Block Size</h4>



<p>AES-128 is considered by experts to have a security level of 128 bits.</p>



<p>Similarly, AES-192 gets certified at 192-bit security, and AES-256 gets 256-bit security.</p>



<p><strong>However, the AES block size is only 128 bits!</strong></p>



<p>That might not sound like a big deal, but it severely limits the constructions you can create out of AES.</p>



<p>Consider the case of <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_block_chaining_(CBC)">AES-CBC</a>, where the output of each block of encryption is combined with the next block of plaintext (using XOR). This is typically used with a random 128-bit block (called the initialization vector, or IV) for the first block.</p>



<p>This means you expect a collision after encrypting <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{64}" title="2^{64}"> (at 50% probability) blocks.</p>



<p>When you start getting collisions, you can break CBC mode, as this video demonstrates:</p>



<figure><p><span><iframe width="580" height="327" src="https://www.youtube.com/embed/v0IsYNDMV7A?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p><figcaption>Their attack on CBC mode completely hand-waves away the block size detail that the demo depends on, but so long as you keep that in mind, their attack is valid.</figcaption></figure>



<p>This is significantly smaller than the <img src="https://s0.wp.com/latex.php?latex=2%5E%7B128%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{128}" title="2^{128}"> you expect from AES.</p>



<h4 id="aes-post-quantum">Post-Quantum Security?</h4>



<p>Cryptographers estimate that AES-128 will have a post-quantum security level of  64 bits, AES-192 will have a post-quantum security level of 96 bits, and AES-256 will have a post-quantum security level of 128 bits.</p>



<p>This is because Grover’s quantum search algorithm can search <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="n" title="n"> unsorted items in <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="\sqrt{n}" title="\sqrt{n}"> time, which can be used to reduce the total number of possible secrets from <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{n}" title="2^{n}"> to <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7B2%5E%7Bn%7D%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="\sqrt{2^{n}}" title="\sqrt{2^{n}}">. This cuts the security level, expressed in bits, in half.</p>



<p><strong>But remember, even AES-256 operates on 128-bit blocks.</strong></p>



<p>Consequently, for AES-256, there should be approximately <img src="https://s0.wp.com/latex.php?latex=2%5E%7B128%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{128}" title="2^{128}"> (plaintext, key) pairs that produce any given ciphertext block.</p>



<p>Furthermore, there will be many keys that, for a constant plaintext block, will produce the same ciphertext block despite being a different key entirely. (n.b. This doesn’t mean for <em>all</em> plaintext/ciphertext block pairings, just some arbitrary pairing.)</p>



<p><strong>Concrete example:</strong> Encrypting a plaintext block consisting of sixteen NUL bytes will yield a specific 128-bit ciphertext exactly once for each given AES-128 key. However, there are <img src="https://s0.wp.com/latex.php?latex=2%5E%7B128%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{128}" title="2^{128}"> times as many AES-256 keys as there are possible plaintext/ciphertexts. Keep this in mind for AES-GCM.</p>



<p>This means it’s conceivable to accidentally construct a protocol that, despite using AES-256 safely, has a post-quantum security level on par with AES-128, which is only 64 bits.</p>



<p>This would <em>not</em> be nearly as much of a problem if AES’s block size was 256 bits.</p>



<h4 id="aes-signal-protocol">Real-World Example: Signal</h4>



<p>The Signal messaging app is the state-of-the-art for private communications. If you were previously <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">using PGP</a> and email, you should use Signal instead.</p>



<p>Signal aims to provide private communications (text messaging, voice calls) between two mobile devices, piggybacking on your pre-existing contacts list.</p>



<p>Part of their operational requirements is that they must be user-friendly and secure on a wide range of Android devices, stretching all the way back to Android 4.4.</p>



<p>The Signal Protocol uses <a href="https://github.com/signalapp/libsignal-protocol-java/blob/4f5e1ff299cea22cc75bb97249020a7da67b816d/java/src/main/java/org/whispersystems/libsignal/SessionCipher.java#L395-L413">AES-CBC</a> + <a href="https://github.com/signalapp/libsignal-protocol-java/blob/4f5e1ff299cea22cc75bb97249020a7da67b816d/java/src/main/java/org/whispersystems/libsignal/protocol/SignalMessage.java#L111-L139">HMAC-SHA256</a> for message encryption. Each message is encrypted with a different AES key (due to the <a href="https://signal.org/docs/specifications/doubleratchet/">Double Ratchet</a>), which limits the practical blast radius of a cache-timing attack and makes practical exploitation difficult (since you can’t effectively replay decryption in order to leak bits about the key).</p>



<p>Thus, Signal’s message encryption is still secure even in the presence of vulnerable AES implementations.</p>



<div><figure><img data-attachment-id="128" data-permalink="https://soatok.blog/hype/" data-orig-file="https://soatok.files.wordpress.com/2020/04/hype.png" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Hype!" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/hype.png?w=224" data-large-file="https://soatok.files.wordpress.com/2020/04/hype.png?w=224" src="https://soatok.files.wordpress.com/2020/04/hype.png?w=224" alt="Soatok is HYPED!!!" srcset="https://soatok.files.wordpress.com/2020/04/hype.png 224w, https://soatok.files.wordpress.com/2020/04/hype.png?w=150 150w" sizes="(max-width: 224px) 100vw, 224px"><figcaption>Hooray for well-engineered protocols managing to actually protect users.<br>Art by <a href="https://twitter.com/swizzlestixick">Swizz</a>.</figcaption></figure></div>



<p>However, the storage service in the Signal App uses <a href="https://github.com/signalapp/Signal-Android/blob/c24d285cd3e93f32fbcd94c7296aa6ac3a6967d0/libsignal/service/src/main/java/org/whispersystems/signalservice/api/storage/SignalStorageCipher.java">AES-GCM</a>, and this key has to be reused in order for the encrypted storage to operate.</p>



<p>This means, for older phones without dedicated hardware support for AES (i.e. low-priced phones from 2013, which Signal aims to support), <strong>the risk of cache-timing attacks is still present</strong>.</p>



<div><figure><img data-attachment-id="130" data-permalink="https://soatok.blog/computeranger/" data-orig-file="https://soatok.files.wordpress.com/2020/04/computeranger.png" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="This is outrageous!" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/computeranger.png?w=224" data-large-file="https://soatok.files.wordpress.com/2020/04/computeranger.png?w=224" src="https://soatok.files.wordpress.com/2020/04/computeranger.png?w=224" alt="Soatok angrily grasping computer monitor" srcset="https://soatok.files.wordpress.com/2020/04/computeranger.png 224w, https://soatok.files.wordpress.com/2020/04/computeranger.png?w=150 150w" sizes="(max-width: 224px) 100vw, 224px"><figcaption>This is unacceptable!</figcaption></figure></div>



<p>What this means is, a malicious app that can flush the CPU cache and measure timing with sufficient precision can siphon the AES-GCM key used by Signal to encrypt your storage without ever violating the security boundaries enforced by the Android operating system.</p>



<p>As a result of the security boundaries never being crossed, these kind of side-channel attacks would likely evade forensic analysis, and would therefore be of interest to the malware developers working for nation states.</p>



<p>Of course, if you’re on newer hardware (i.e. Qualcomm Snapdragon 835), you have hardware-accelerated AES available, so it’s probably a moot point.</p>



<h3 id="aes-gcm-worse">Why AES-GCM Sucks Even More</h3>



<p>AES-GCM is an authenticated encryption mode that also supports additional authenticated data. Cryptographers call these modes <a href="https://tonyarcieri.com/all-the-crypto-code-youve-ever-written-is-probably-broken">AEAD</a>.</p>



<p>AEAD modes are more flexible than simple block ciphers. Generally, your encryption API accepts the following:</p>



<ol><li>The plaintext message.</li><li>The encryption key.</li><li>A nonce (<img src="https://s0.wp.com/latex.php?latex=n_%7Bonce%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="n_{once}" title="n_{once}">: A number that must only be used once).</li><li>Optional additional data which will be authenticated but not encrypted.</li></ol>



<p>The output of an AEAD function is both the ciphertext and an authentication tag, which is necessary (along with the key and nonce, and optional additional data) to decrypt the plaintext.</p>



<p>Cryptographers almost universally recommend using AEAD modes for symmetric-key data encryption.</p>



<p>That being said, AES-GCM is possibly my least favorite AEAD, and I’ve got good reasons to dislike it beyond simply, “It uses AES”.</p>



<div><figure><img data-attachment-id="119" data-permalink="https://soatok.blog/soatok_stickerpack-rage/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Soatok Angery" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=512" alt="Grrrrrr" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-rage.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>The deeper you look into AES-GCM’s design, the harder you will feel this sticker.</figcaption></figure></div>



<h4 id="ghash">GHASH Brittleness</h4>



<p>The way AES-GCM is initialized is stupid: You encrypt an all-zero block with your AES key (in ECB mode) and store it in a variable called <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="H" title="H">. This value is used for authenticating all messages authenticated under that AES key, rather than for a given (key, nonce) pair.</p>



<figure><a href="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png" target="_blank"><img data-attachment-id="541" data-permalink="https://soatok.blog/1000px-gcm-galois_counter_mode_with_iv-svg_/" data-orig-file="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png" data-orig-size="1000,1099" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1000px-gcm-galois_counter_mode_with_iv.svg_" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=273" data-large-file="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=580" src="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=932" alt="" srcset="https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=932 932w, https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=136 136w, https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=273 273w, https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png?w=768 768w, https://soatok.files.wordpress.com/2020/05/1000px-gcm-galois_counter_mode_with_iv.svg_.png 1000w" sizes="(max-width: 932px) 100vw, 932px"></a><figcaption>Diagram describing Galois/Counter Mode, taken from <a href="https://en.wikipedia.org/wiki/Galois/Counter_Mode">Wikipedia</a>.</figcaption></figure>



<p>This is often sold as an advantage: Reusing <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="H" title="H"> allows for better performance. However, it makes GCM brittle: Reusing a nonce allows an attacker to recover H and then forge messages forever. This is called the “forbidden attack”, and led to <a href="https://eprint.iacr.org/2016/475">real world practical breaks</a>.</p>



<p>Let’s contrast AES-GCM with the other AEAD mode supported by TLS: ChaCha20-Poly1305, or ChaPoly for short.</p>



<p>ChaPoly uses one-time message authentication keys (derived from each key/nonce pair). If you manage to leak a Poly1305 key, the impact is limited to the messages encrypted under that (ChaCha20 key, nonce) pair.</p>



<p>While that’s still <em>bad</em>, it isn’t “decrypt all messages under that key forever” bad like with AES-GCM.</p>



<h4 id="short-nonces">Short Nonces</h4>



<p>Although the AES block size is 16 bytes, AES-GCM nonces are only 12 bytes. The latter 4 bytes are dedicated to an internal counter, which is used with AES in Counter Mode to actually encrypt/decrypt messages. </p>



<p>(Yes, you can use arbitrary length nonces with AES-GCM, but if you use nonces longer than 12 bytes, they get hashed into 12 bytes anyway, so it’s not a detail most people should concern themselves with.)</p>



<p>If you ask a cryptographer, “How much can I encrypt safely with AES-GCM?” you’ll get two different answers.</p>



<ol><li><strong>Message Length Limit: </strong>AES-GCM can be used to encrypt messages up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B36%7D+-+32&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{36} - 32" title="2^{36} - 32"> bytes long, under a given (key, nonce) pair.</li><li><strong>Number of Messages Limit: </strong>If you generate your nonces randomly, you have a 50% chance of a nonce collision after <img src="https://s0.wp.com/latex.php?latex=2%5E%7B48%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{48}" title="2^{48}"> messages.<p>However, 50% isn’t conservative enough for most systems, so the safety margin is usually much lower. Cryptographers generally set the key wear-out of AES-GCM at <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=0a0a0a&amp;fg=f0f0f0&amp;s=3" alt="2^{32}" title="2^{32}"> …</p></li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">https://soatok.blog/2020/05/13/why-aes-gcm-sucks/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/05/13/why-aes-gcm-sucks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23637605</guid>
            <pubDate>Thu, 25 Jun 2020 06:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Liberty (1859) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23636407">thread link</a>) | @mrfusion
<br/>
June 24, 2020 | https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf | <a href="https://web.archive.org/web/*/https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div p="">&gt; 
endobj
379 0 obj
&lt;&lt; /S 964 /O 1045 /Filter /FlateDecode /Length 380 0 R &gt;&gt; 
stream
ì+ªýc„-ÌéEÎØµ«°L½÷Ëÿé;ÄÛxÃ¼to•F$ˆ¡)•ãz§%u­ÌP¬5,‚|)äìº„H”˜Ïk‚Æ&nbsp;s˜Z‡}8kxgF¼�Ew�‰	ÕìC¸‡2÷¨ÿ&gt;JùwãÏ@ãù«z‰7s¹vëëœEªœ:Øy±cˆ[°ÅÄ§ÁôCEb´.&gt;øõ½ó¶B�š:DØ´×¸æ¢¬aqäÁ"Õ&gt;(¿ìøzF|ñlçJ´W‘~|‹§	|hÓwÎ�&gt;|³¹Žö™&amp;¬frË�/^@¦Šà°GM4mejD›ê²õ`X–Þrm¯ð²ÝUdñØ"LjÝÁ{um]4tÈj»­)6qbÕ<v%aÁ£œps1�l`Ôbä2[›;� qhu'…„+~€úmÿÓ‚Ámïx="£ËÝfÊÙÁš¨Ìâ|â3É5¸æ£gøÕû‘jªãt" Øl4ï="ù2Jd·”õ" ŠÖö*uxi«Áx4ãõ€�´�+otx‰³ö÷ö,¼Þ1¢fçÐ¾›ûødÝ^h¸ÚdÎÌ4bÅs×Çê†~k%’î¦—¦¨éå6xª+§qÔÒ„†hÐ[s¹="ˆžµ—QäyÀ½fî¤u*�su$ØÐwrg" endstream="" endobj="" 380="" 0="" obj="" 488="" 352="" <<="" type="" page="" parent="" 336="" r="" resources="" 366="" contents="" 371="" mediabox="" [="" 432="" 648="" ]="" cropbox="" rotate="">&gt; 
endobj
353 0 obj
&lt;&lt; 
/Count 1 
/First 354 0 R 
/Last 354 0 R 
&gt;&gt; 
endobj
354 0 obj
&lt;&lt; 
/Title (T¬Þô¯ø1n)
/Dest [ 4 0 R /Fit ] 
/Parent 353 0 R 
/First 355 0 R 
/Last 356 0 R 
/Count -11 
&gt;&gt; 
endobj
355 0 obj
&lt;&lt; 
/Title (š[ÌBe°†à0úg)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Next 365 0 R 
&gt;&gt; 
endobj
356 0 obj
&lt;&lt; 
/Title (‘'G`iŸ)
/Dest [ 320 0 R /Fit ] 
/Parent 354 0 R 
/Prev 357 0 R 
&gt;&gt; 
endobj
357 0 obj
&lt;&lt; 
/Title (°DÞ—9³Ùí+ Šk¹)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 358 0 R 
/Next 356 0 R 
&gt;&gt; 
endobj
358 0 obj
&lt;&lt; 
/Title (ø“€·+Š*—ÜI)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 359 0 R 
/Next 357 0 R 
&gt;&gt; 
endobj
359 0 obj
&lt;&lt; 
/Title (*I“KP8iÃ]3¨ŒÎÙÝÊÜ®%zÙ3k&gt;g’Bn~|‹Û°.¦7Z#Ð\(Ü²ÄÃhÿ"SÀv7�K/J\()
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 360 0 R 
/Next 358 0 R 
&gt;&gt; 
endobj
360 0 obj
&lt;&lt; 
/Title (D7A­­*!P])
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 361 0 R 
/Next 359 0 R 
&gt;&gt; 
endobj
361 0 obj
&lt;&lt; 
/Title (õËÃª5tT±ZOJR¨�»[¿5&lt;¿j+æN*œ§h4èÉÄo	É»W'±WßK¥ÞZ_š¦&amp;-M)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 362 0 R 
/Next 360 0 R 
&gt;&gt; 
endobj
362 0 obj
&lt;&lt; 
/Title (’›­öëQ“uö)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 363 0 R 
/Next 361 0 R 
&gt;&gt; 
endobj
363 0 obj
&lt;&lt; 
/Title (-hs~FD»M„íM±VleÁŸï!Å¤Ÿpnt­ô6qñ‡-Œí*üKª©)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 364 0 R 
/Next 362 0 R 
&gt;&gt; 
endobj
364 0 obj
&lt;&lt; 
/Title (:Gû¹ÀS ˜&nbsp;2)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 365 0 R 
/Next 363 0 R 
&gt;&gt; 
endobj
365 0 obj
&lt;&lt; 
/Title (²ú"0P“ºSf÷–wn&lt;)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Prev 355 0 R 
/Next 364 0 R 
&gt;&gt; 
endobj
366 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F5 368 0 R /F6 372 0 R /F7 375 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 378 0 R /GS2 377 0 R &gt;&gt; 
&gt;&gt; 
endobj
367 0 obj
&lt;&lt; 
/Type /FontDescriptor 
/Ascent 0 
/CapHeight 0 
/Descent 0 
/Flags 4 
/FontBBox [ -146 -274 1207 909 ] 
/FontName /HDDGLC+MSTT31c6b7 
/ItalicAngle 0 
/StemV 0 
/CharSet (ì»µ”±ßhZ\)0UŠ	wå*‹*Àá&nbsp;|B¬=ŠÉš¬b_Øö1ÈÖ2a¼-Sè�bœ”¿r«áÞ„’nòj"<tøþ˜Ì\ ¬ØtrùÇ;f[û<="" {²h[r)="" fontfile="" 369="" 0="" r="">&gt; 
endobj
368 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/Name /F5 
/FirstChar 31 
/LastChar 255 
/Widths [ 750 260 320 380 520 520 900 740 220 440 440 500 520 260 333 260 580 
556 556 556 556 556 556 556 556 556 556 260 260 520 520 520 400 
820 660 640 680 740 620 540 740 820 360 340 660 620 880 760 820 
580 800 660 520 660 780 640 900 740 520 600 440 260 440 520 500 
360 556 556 556 611 500 444 611 667 333 333 556 500 722 611 611 
500 611 556 444 556 611 556 778 611 556 500 280 260 280 520 750 
750 750 300 520 400 1000 500 500 420 1300 520 320 1000 750 750 750 
750 300 300 400 400 460 556 1000 420 980 444 320 833 880 750 520 
750 320 520 520 611 520 260 500 380 740 340 480 520 750 740 400 
400 520 312 312 360 580 600 320 300 312 360 480 780 780 780 400 
660 660 660 660 660 660 880 680 620 620 620 620 360 360 390 370 
740 760 820 820 820 820 820 520 820 780 780 780 780 520 580 888 
556 556 556 556 556 556 722 556 500 500 500 500 347 347 377 357 
611 611 611 611 611 611 611 520 611 611 611 611 611 556 500 556 
] 
/Encoding 370 0 R 
/BaseFont /HDDGLC+MSTT31c6b7 
/FontDescriptor 367 0 R 
&gt;&gt; 
endobj
369 0 obj
&lt;&lt; /Length 10526 /Length1 4144 /Length2 6380 /Length3 0 &gt;&gt; 
stream
zv¥gjQkÜuùxúõüó½�ÕñQÇ9;Õê¡ƒÀÉd¾Ñ®ôQÛçFeœ5íNRAžW!evÔ=Ë½ý™îžÍ8g(XmØpJe*åº0bÝæÆ¡]ó�úqÐÁÊ©OíiÂåt/x�Ò¿ÖUÑS3P¸43G`œŽZŽBª„zïùÖ§¶«X™Åe3?»¹ÏébÃè¦sQŒ–«;îWßê¾ý„ÆaçXOˆn&amp;7¸}ÃŠÈ�Æ³ed½‚$/´ñ?þ2ÿÓ#øKˆÖl%Ù“—0ñ‡ €Eê„†4áN-.‚ÑJHÊr	Ž×+«2¦wDqV/{±gp“™|Mú:4µ$�”yC¿¹
•ÞžœN:sâ-Ú¹(}4,O™�Ù€¡í½MMùcƒÂ–¯­.N¥UwîÈ#G‹©šÕÜ­Š�)~D<a€â-ÑÔší³’È¯=¬Éky÷Ãßm~•‚ 7µl¥”÷á’dï*§yc="" $="">�»‰NHÞVý×ÙpW{5 ÞCžYìg6´Ì�9BUÐñ1Ë^t^8ûªøo#žÞv“–†mEK["ˆ03IBè3F÷Éº ŒB°È:ô•\ˆ÷Gñx?½(Å’=c×ø†Ÿ$h‡ò0KÄqÛÍ°·Ú‘<a}×¨¦’mÑ2uýúsþã¶µf”�[g` dØhhœmí×¹Ä”Žýçfç’Ž’“g›‹%†�ËiÓí="" f{¹õûâð*¾o¶¡e�u©o‚‰Ïß="" %hÌ8ìr1³1<ÁÑ_?dqï½×°˜âÞ%»bb="" œll4beb="A§#Æ‘ìŠá°Fr×i1€" l‰²[r½$ï¨ð*lîn(0vq„Ý="" Ý�="" 5ºð²¢¤m}_‡pü&8r¡äÿu©)›r“boÏ%¶tÀpkÇr$e!óp¾éj”��.\˜þÏÎÌdå$«båý+��'b…wvÎØ.ºõ b£jt3mñ»-}ø¹¤é–Ývoàéƒg¡ìiõ*h0-n¬býá*cÀÍá›®á\="">ÔÅ¨
‚°ôæ‰Ä¦Š¬‡ìäóËp¯;tPÿúÿ$	ÿrëK[Õeœ15X&nbsp;Ñ—åûê	‘3º(uÕ•ÙÛ¯.W6¤Å3r®êÞí´&nbsp;MQtêã}ñ|µ²ÔSùòP^°êéËuÿi•”‚ï¼�Ë‘Ý[Í_Ký@¾Onj³ûö
Ç	âƒ
`IRùÁY…µlt‰¼õ;�(QAr­èz¹LÇœµ.:Ô�#@+‰71.�pU¤ØÄy
D|ÕˆÝ)ÛŸ¸ýáv»ƒo´{œs^áœ,:ïË£óéqžËJ4t¯Dp³ÐzzÑ8þ›+Vpó‘lºÓ±#Q¾Ø¬ªC©ºƒÉ«€{³¶&nbsp;c\tÇ6�OÍ¸A�ÇbXöÃ&amp;4¢­3)³1Ëì\hçÃ|£:’G?£¡¬:zrL{µ¹zÕ÷|b}Oƒ`(uš7êø0s!Ñø ¼Ne�8Ìütr|LYtc”ü†‡}Ñÿ$'Í?XÓœ&nbsp;f/¨•39
PÃál²®sY”0—�2xøZ*úÝÏêt°S?ê2•=¦bAPMóïtØÀªÁìµ¼™à}ZyÙ@	ÕD°—ÚhÄ©Í÷µÇ&gt;9²”0¼çáãB»Ûzû�‹L¾&amp;ãæjÂ¥L–1»#²=çsv)érÁb8A(jóO�o1L‹*Ì*âÃ
¨Ñý—ô”õq7™Ã�Q‰Â`“6Ù-óû/w¯-meèL�´\]
‹c’"øGÇw[®†#úr¯7 ŸFÂ·§°ŸCÀç´§
X¢+F£ŒKôxœŒcye�æÖÖÛ€õ&nbsp;Ã–˜š®[ø
}¿
N5åù?wúmÔ&amp;UZvfc¼“d¼š´ÖÁÕyÝ¥#b¥ôhÑéöÖš]�&amp;QóÞ¸tÄ�*Vù\ÿ~#BÿÛñeóÙuˆ/gÃØ2báwP¿,mÙ¦¥«õ)ã™‰™}°YWó¨ÞP`rÝN½¡ÎVè¸c}'œUà­&gt;?2G�±HÎh¸º¬x’6»î9ÏºÉÐØÓê=ø=ØR'ý‚7¨°}s;mÀ:ÿïp°6…!¬np‰·»Â¼7_ê»-ær?]«tí%I¡8òWÇðf¯?Zö++vÇo#Ò2¼±3Ùú×UP_XkÊGæ¨]8„ÈÞDTœý&amp;˜ðï³{Ô[_²�”‰Å%Z4Y†òvÛØãWááá„¿Œ‡kß(–×\�&nbsp;Ó&lt;¢c.æUp	YíÄª4æ¤g»¥�º%ö?UžÖ´Iõ§7²ø«{xÓóõˆxQ8L†™ÝÑìˆF~•TbÈÚf¥TGKoc	1Q$¯¾iÄFXÏ½¡øiÆÃZMÊ™õõh`3‰Ã}~}&nbsp;)â‡Žáåg¿ƒ«“ÁËÏÊŸ,«“–Ô&nbsp;5$Øe„w‚)î©'Íq‡WÌœìæLÒÅ8Î…6±¾¥6{f¾C&amp;l€@'´%LºJëº&lt;Ç8{;ÏÌ¶à5�\„_öotÝœNxí9NŒTNøÓ‚YVqN¥‰Â³'÷‹‘	€f¸Cù­¸‰Î{)À­ªã^vO/=0”º÷Å£VòŒÜ½þÇv4µÒO9Ôž„Qaœ%0t|'³]±Ý¥
åîSÛÞ9W^ì|�KwAKôpZ—ÚŽÒç.Ÿ@®[;œªc{e]`·h;ïý(¼ËTpÏí¾”éÉ.ïlŒšÖî3%@ö¥n¡Niƒ¦rg\¿°&lt;¥&gt;\î‚RðÆ?ÒO’×ôm“Å‚Þ»ûxæFX·áÛþ0ØË¬ûu5îîlPÁp:�ÖòsŽ#€¹žgv»ÞR—â¯”{È�	ÿ„O˜òþñŒ+i“Ú&nbsp;aJÙ¢aæ@¯ì-zØ ¬”`Úû˜Ã»§vñª¼ ;p9ý”¾!æ¡«Þ”9²&gt;&lt;Nž²Dc^Ìç7òÒý B€³§'×Ýš¬±�5Ã}I©ö¸gWªe´ÀÔââBùˆôç•o¾‘¸åw,TJlY¶�ŠS†×§ÄS/çÇµ-»PÏó¬T¥ÜäåÐÚômüçd›}_öû`$N;_l;Í�€ COH(WÃˆÙ»
¯ºzÒö/¦ç¦P®ð"z#oÈÅŒuà-K—AøXÁ�¿®SàB˜YÅDmŒþƒCÅ/‹Áp¶vø€qã¹ÔPsš3(‹Pïñ+LÒv7W¦&lt;Ô!¶²á+Áw{ml°Pç®r@nsuuTg°ÅHì0ÞG¸¬E/:|Ì�ûÀgGEl=²ìÑQÇF5_ô`Ct˜L&amp;r×ŠàÛãN¨çßIôÙ¯ÎÑÔrDì·³ütr6H›W³©á5Py†¸)´ FFdúøµê¤ö¿¼Ís&amp;XAÖÖ±\Ì6æ¬Ub:iÈ_1œ·´mb;½Šq•ñîË¯Í»8Í9ÊfKÅ³×[u&amp;âÛnª¦&amp;Ë"é¢õB·�˜ïuŸø©EîŸaà8qëÊ	ãíø*¿&lt;Ï *‹´fS15÷î¨©:â©Å¦-3öÈù´�ñEãÓ�A½}šd
Î™Òü= RGW?ÖUì˜U¿»²áŠÊNÇ…�(á­}b¢/WnT	Ï_DgòÝûnÌ¡”/EŒaç¢êÆV`�rø„BšOî|ŠÚ­TàìšÜyá‰»PPáûË £?T’Í¡CÊðs¡µì5x†y×�ñæáÜÏ_'§L´Ãx-(§�U&nbsp;bû[ír&gt;Co™»†j²	Býúç†íO,ô×‰²¬Œ•‰È�—T&nbsp;SæÂÖý²'‘|ã[0}&gt;vE&nbsp;âÐÚa†7LÉtàù0ÒÄH6nx×”ŒÚ¦E…è„žßÍC�³ˆ#”lÇ4ç&nbsp;}ÏG=x=í'´æ#árýÕtƒ,‚ÔÃŸp;¹ïÚrf¶Å[Î¡ÕH?”‚-ê'Ì¦ÜX¶Á-é‡dìõžIV
[�±	ƒ5Úñ¾d&lt;ÆŽž·L/î9þSGæOŒq;«T^�…œå�@¶x•ââñäïŸxœ0ë³­'ƒXòOaÐð‰³´+š“
®ˆ[ˆø;igV`Ôz}á±„n&gt;Éõ&gt;â¬@‚ù‡ç(ÏNwSF~›¨H¶;P’ñˆî´Õç)b½øG–�—ÂU–ÀQ/§Ð^Û¼d„vÚË–N?7½ùj¤‰Îï¼Y
kG–ˆ½À“ÊBÆç€EC`ÙîŸ?.„þù5âêEÉé&lt;¦Hªþ^øÔ!µÎÛe19ü,âlÝœITw sPÇFí�=µœÍ?Rn'Ds‡vK‹7m^„Ù¿p–ŒÑX
ÉÎb§R&nbsp;%ì))åðà gF©_¿Ðþ9ÌCÖúWGÂ@¹!~Ýã}rÂK÷¢Öµs5e[þIBn-É3ú*AUIž­±Š]�#l81nfŸc)ôLß¡g�
ˆ¼£¯FŠ\¸Ç^ïÒ¬�wÌ—0;öÑêä§GEóÓ"Ë³fó
øX*`‰{ˆÌB«3ÝŠmX¨&amp;ñþ·mÕŠ²©š]ºì�Ëó üˆqXi’“çñ(†aÜ
@0ö�.Díz«+êŒœ'µqX]&gt;�8óšª¤r(¤�ßW(¢eã‹‡‚YA,±õ/É–�hizjGž�,m.×Üˆ¯.Y+„nÈT‚7þp¯:|Goª‡­
‹X°¨‡Zø6&amp;L²×ú#Ÿ­Ÿí §sØ&nbsp;žä½×ùÃ
ÕJW$ç
8aY&nbsp;”†êkÿ²X=­ïIrd¯€ÃËÊ¤ž˜.•ÿä¶‹g™$Š^«&lt;Þø¥Ÿ•*ˆÐxEødèriR5YÖÏi‘+âÔ«x‰¶\®ÓÅ{
ŸîVå?B‡�&lt;ë] ëËî:Xå$÷SBáKN[F�¬ê¬è=C…‚³NƒO(ÞåÐPW&amp;ƒÃâ}Ã8wž¸3éJI”×9G#8NmW„ª±iI‰ûœÏ¤$ÍïNgr11§8‘É
îÐ–ÿ¹lžG­ƒÚËÔ3\x—HSâx˜ð"S…�á4@Wâ’•Ì@Õ(jE„ª
dã{8·2œŒþVŒÍð9q¬�ÏOtÅfyš%ÜpL\Öb±Õ„¥Ú™Žzåmí~þí¡Ö78R�âªË‹ÐÉúýÊ¨%&gt;L²È¶Õ™Žl–ý~ö
Ž\Å“#SöläQáù@z9ÒvÃ°�FZÕâU†“ç†c%†=þEdµ;¨£ÚCó•¥sf7OŒC�‹Û€€¾rqÁ([ü±‡X\•[Z›õmUõŸæîwk4³†	]?ÿY_áŠÀéj&amp;¬UáÃ(dW‡f¿%V†G"{ÏÛUdÑ×„W¿À„¡c&lt;•ˆUW.ùÂ<wemj%º‹Ü#‡øÚ\þf�Ïbàn…Ìçzq.hÚaŠš¸Ž+‚¦«Ú%¯ˆ¿’�i*‘¸ïžÇßrß†í£Ê²¦>#OZy?ªD½qÝfK¼cŸlÔ'åGÑºýõ‚Å-x²´ÎZGr—ôé‚÷óÄé+?XÝ#_[¤ì½	Å„6üsl5
ð‰Œ÷±ÌÑ~ù»ñàvÂ3ûÕï�HT¹OöMùˆƒ¹eL¤Âl™Y«(ê‘3mðbBO)Ï˜ø
æÍYb–&lt;î~óÖ¿x¡°S�ƒ
2âQÛTM±áÂæð¸¢Õÿ_:nºðÜ9ÒVŽA¨6¸&gt;ó½�h�H6¹™Ô±A²7NÕ¥žäæ|�Ìû.€rlêMsÐ•�läÛ(f0Û0Œ^€ªö·�¥áûsnÁ\._àñløÈ.�Qò¬à=e‘i¯Ä$Û½ÞN‘wIKÛ³”“ä›|iŽ1?ÆØÂ!n…øú¬ƒÁ(Iè ¶IÞ�'ÓîýêàCãþÜY€VÔ(œ,JV°ý�ÙYšWbÅé§»3?!äà”Òè5…ÕÍ…z?ï,GÀ°]úä±®+¨gùFÙ¿€qÝÐg¯Xç`ñý‘H|žZóëNGòŒ@×nù�ë!(Bå‚{XÊ(!‡ŽXó§ï$c[P$ßb¨Û/!lyîH�âi€1˜´NAbËåt;êN‘§éÐö`ô
Îj•ÓŽŠ¬SüËÜŸŽur!!«�)Sß£¹y¢¾i±iŽG³ŸÐwW×CµˆSc¬;ð–7íB-™“¢^ÂÈ ‚«O
{wã½„J§×üøŒó¤9�ZæÉb8£\‡Ï±™—¼^kO;YU,‚/ª°Xå¼ÌD‰+¼˜Àý¥&amp;q™&lt;1V&nbsp;Bhû3Ê… EùI®¨�±’gÐxeÚƒxK‡Ž^�«Cé¸q9WËñ§X["(ÓbQ·bÐs€4ûZ…º±Þžì»ëûU%*�nºi½&lt;Á®†·Gô»W†öõP‹³^¡9È¤K¯œ˜FCÒÏgó*s²ÁFç+ÒÍ°Pôe#÷a8›1òêOöë=ÕZÂ›Žw?¿Ò"™´f¤¼¿ƒÙ&nbsp;…â&gt;¾–Ly¨›¥˜Úýœ§sh¨?’9Þ×¤ƒ(ÕúfB�¬S×ùÉÏÍÞ„‚$Á�)Ø:&amp;…‰1oÛXÑÖ±òÜÂÇNï
œ±�þµðaØŽ`öâôãLò›Ñ�i„täj?Â�RBUF7+à%žÕ	î@š­ÌãBºšæ‚&amp;"À‹f&amp;ýµlÀ²MÓd-)nÐÅïWèùf[¨Ëä¤„…K!ê›Î =›s(æäæ¢ŽhZ?°àê,ˆOè]Ìé_YÝùäÙÉôÏ«X#«=Ãig‘Â8U³Èg~¸Y’þ•hx1Q6P!§}âj³)ÿÀzÐwÒÛG
&gt;\oÔ$
S�€´¾^ÔMmPÍjqË|QoÄ°áÒp£¡ÑVqAÑ—Ü)

˜eù)­€5¯£€�zè\^…ìýš3ãì*Á¹îí!]Oó„3Š9Ó^àø55È„È“—×¶t™R@„¯Ä®¦uŒéÖwÈV4,ª£Éœlïá)U[J¤Ù;aÑn�H‰Ž
y&lt;£«¹rÜû2ø�k4z®‚¢+¶¿&nbsp;èØñX×žÏ—Kÿe“zvIU­›»ÓaÕ&lt;Ô3®ÜÞæŸ|ÏvE€e&nbsp;]Ö1ú¨HÆÄ^êÄÐ\¥v™E=üPM&lt;Æé’ÉÅi¯„êœ1Ù,t‘rê0iìIø}âsI¦¤N|÷2˜è]€T½3;Ùã`{amPcÞád€ÏT˜N%&amp;Ô×G	¿ýHÍU~=@‚vœ0”9qØ@ˆ}ÆÐ­H°õfÞ—º‰ç½µúIiKØf�mOW¿“�ãì,lÁ¦¡S.C"bx*ú¥j}º–å›Vj¶´Ô§G@–]˜•5â£,³ü&nbsp;ºPÖ�GÉè"Ê�Àxó¯_d`�Á�Vtý¶&lt;ÛYýø,µ80ÖÔ§yœÓE5“v©4Œˆ_©—Œž¬ü¨÷l±2&lt;‡˜ÛÔ•Á„�&amp;�àÏ²‡u'ÖÍ\ü¥Ü.?àðšñ}ølá©¼#�·S‹enê2õo­Û«ïå`é—‡°,ËMµ�
¢T�ŽS“Ä9œæ¥£ôÐÎ–ÂMøèßb�6üú”fr3Á ÓYc�d£b¥•à±LŽ$«Æ†ˆ7ôQ³à�OU–uÕó7Neÿ*ókâØÅÿ`×©¿‘öÇxñtøpfã+Ýv'“^¥œ�èµìF
»~È9Þguq`ø™ü9î-BÉè³qâ¡Ì%h-Ûn…JF_¦[£Èw¥`&lt;\U.lÞZ´!(‡€âÙ²ÛDZ0®´*§ë›&nbsp;ÞÚ–še¡Õ"ÁÐy¥§~§TÒÅlÇ0SüxÄsG�8®�SS*5çó;†2JT»Ø‘UB&amp;f|î<púß¶¿93žg”tÏö|nº•×4|¨zx+vÖ]‰´)c‘¼ât¬› ðuÒ¥ãlà×‡j<¤îh="" ·^káqµt€èb}+lÑ©_="" ÍÃÈx‚¥þ£2üo0¦hc0«Ëô·z£="" e3©nt±”ÀÄlsq ¾l3§›š6k^Ü:ƒûìi…É"ü6ù×'¯c×Í®<p4Žêxspez1@¼¿²ÑÓ‚°âdàØiÐe¾À«»ˆlå†)–~ÛhgËf›@ºÏ°fãp†f="" %Ä2µk5aùÔi9nÀ"~ŸÄ­9}gqçz]%Çô±!15zvŸô-ezr)Æóiè:•còñ¾j3Ô%h="" ã�\à8îv¼›¦©“v§òñ‘“•~="" Ê6Ð="" mtft03="" i:¡‹ÿh¬akêt*& ="" {�ÕªÚôùù="" ·£Æ(ìÖ9üük#ðïŠwobi±l�(Ðœ?ñêˆ—Ôsq¡-r˜xÃ‹px%÷‰v}¼5‹•¡‹ùû„¸Ûho-¤ï„¢ÿŒÙuáe©øþ‰¤a`,a€m7ªi–rÛ÷�fez¬Ð…k.}sñÁ’¥8²�Óo'é?]?,¥-áºaÕ´vòfj�¼žÆÆ6_Ãé(u!ù3guùåólücr)3žzø59à�°6$øâ’ïÕ©§4ñÆhsñ‰�oµ»noÆ2="�ŒiêR‡#ÆµYª+hQJwCçBy/A´H&nbsp;Â" q¥u"„‹øé:c�ÆÑwòqx1p°?Ð+©™æx²�b|Üf="ŽªÄ²,q`”Õba}n•ñ|yŸYó;íÆÔEB­¿á�é¶L§’’8HÑÜÑµò‘jÎ�g­µLŒ&nbsp;¾`™Mºªhw™õò•·šÅæwT—†³Î�»R]3ºî�²Îúè/|‰°ˆ§vr1û£6ÎB¸´<<™»°ãLˆöˆ�×çS1·6ø!¼ñ—›" šv="">Í€½±1¨T5w¤Ò4öªV¶-_;­_÷üÀ¢càCò9V8äÈ‹Éw�àµ¦u1ÐCÒÍªþ3N†Üoˆ@#�ÙÈªÖ%ÎO¥ˆ¹
c?ÿOl2t¨»(–˜°1#*«QqÈ&gt;ä«ÇJø¸ƒJ¦SÝþùcåpÿ–Ãà�•ÓÎ-ÀŽ¢Ê”ÓF¥0Båò0¬ì&nbsp;/‡U�d"žŸéPebFX)ÞXx&amp;¢¤Ñh›ç&gt;PÌƒž³))ŒÚ÷`R&gt;†j=çtQå~Â;b£Ò{îyÊUÆ­+:mLbzi8…‘°AÙ~‰“OñËÿV½ooB•cQ­¾ÆRÞöÊ°/tI�­ü¹¹³ü
ç:Â;)û§{¡€RsÙ÷aß"Õ+¹I¼O#…Eº&nbsp;¯€*¦rudêdI/ÁÿØ†¿ößuÏ�!w†U2×Ì—`§ëgúÑv¿]¢&lt;+ÑrCË}É{‹	&gt;‚ýT¾I)¦E9Å®Tvý�ëÙ‰øÃó§¸@Yþù!¨Ø:n~H~ÜÖ3-£ýOL.-‡@}f„* ¹b2J6HyŠGHOª}É½«±à¬œ¤8RB°"úâ6zµNÖiu%eœM×uGŒåÅôµ‹p=£j²ö»_È°/_Œé oGªßFo_–HÑR1Ò€yNlê÷•[úûk€‡KÓdÏèvuSÉØïâ^®À‰Akü‰"y£9ÃJ+ÚLùòóË.ú»ÐMèŸvŒû¾Ëö7zOKvròF½Š#PF:ñ[k"ˆ°_/¡ÅîÇßþþ-ò+u�®�F•sMa•	òVëØ¨úúB+WÛFšÙ;(Ô&amp;4"Hë4'uÃ4C&amp;hfqÎ½&gt;k†ŒÕ"áÃ^†W_o	—·Äñ.OÓ&amp;ƒáº–g-éHvs8CÖñfµB$�âÛ:H=OþãJ¹¦Éú,Òœ?=™SëélË†;ðFÁ’ªàì†µ 5(hN„;™™;;³Û•SJN”þêd²kõM[Dq=p‹Æ©Á‚�
,Nò�ùœÝ!m|´y}QƒLX¼V 
#Aµ½)7•&gt;˜Ý+xÀó:4&gt;ªìÜçå=Mãt~LIÓJ‡´’„M|›’¤*0±	ñCË»–†éFç4ÕˆPüâ¤(…7Õ›Ð«qäá~ìA‹“´÷8ƒôUê`P&gt;</púß¶¿93žg”tïö|nº•×4|¨zx+vö]‰´)c‘¼ât¬›></wemj%º‹ü#‡øú\þf�ïbàn…ìçzq.húašš¸ž+‚¦«ú%¯ˆ¿’�i*‘¸ïžçßrß†í£ê²¦></a}×¨¦’mñ2uýúsþã¶µf”�[g`></a€â-ñôší³’è¯=¬éky÷ãßm~•‚></tøþ˜ì\></v%aá£œps1�l`ôbä2[›;�></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</a></em></p>]]>
            </description>
            <link>https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636407</guid>
            <pubDate>Thu, 25 Jun 2020 02:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix's design issue of device numbers being in stat() results for files]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23636376">thread link</a>) | @todsacerdoti
<br/>
June 24, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/FilesystemStatDeviceProblem | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/FilesystemStatDeviceProblem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Unix's design issue of device numbers being in stat() results for files</h2>

	<p><small>June 24, 2020</small></p>
</div><div><p>Sometimes, you will hear the view that Unix's design is without
significant issues, especially the 'pure' design of Research Unix
(before people who didn't really understand Unix like Berkeley and
corporate AT&amp;T got their hands on it). Unfortunately that is not
the case, and there are some areas where Research Unix made decisions
that still haunt us to this day. For reasons beyond the scope of
this entry, today's example is that part of the file attributes
that you get from <a href="https://man.openbsd.org/stat.2"><code>stat()</code></a> system
call and its friends is the 'device number' of the filesystem the
file is on.</p>

<p>(To be specific, this is the <code>st_dev</code> field of the <code>struct stat</code>
that <code>stat()</code> returns, which has been since <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/include/sys/stat.h">V7's stat.h</a>.
The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V6/usr/man/man2/stat.2">V6 stat()</a> was
even more explicit about what it was returning.)</p>

<p>In Unix, the user level file attributes you get back need some kind
of locally unique identifier for the filesystem that the file is
on, so the presence of some identifier is not a mistake. The
identifier being different between two files is how you detect
things like that you're at a filesystem mount point, that you can't
use <a href="https://man.openbsd.org/link.2"><code>link()</code></a>, or that two otherwise
identical looking files are not actually hardlinked together because
they're on different filesystems. It's also useful to have an
identifier that can be matched up with things like a list of mounted
filesystems.</p>

<p>However, early Unixes didn't make this merely some identifier, they
made this specifically the device number of the underlying disk
device that the filesystem was mounted from (hence its name as
'<code>st_dev</code>'). This had the unfortunate consequence of permanently
joining two logically separate identifier namespaces, the namespace
of (mounted) filesystems and the namespace of block devices.</p>

<p>Now, 40 odd years later, we have plenty of Unix filesystems that
don't have underlying block devices (especially singular ones).
Anything mounted using one of these filesystems needs to somehow
make up a 'device number' for itself, and this device number can't
be the same as any real block device. This generally requires Unixes
to carve out a section of their overall block device numbers that's
reserved for filesystems to do this with, in other words things
that aren't actually block devices. Fortunately modern Unixes have
generally made the namespace of device numbers be much larger than
it used to be.</p>

<p>(Then because device numbers for block devices are generally stable,
a certain amount of software expects the 'device number' returned as
part of file attributes to also be stable, for any arbitrary filesystem.
When the kernel and a filesystem has to make this number up on the fly,
this is not always the case.)</p>

<p>At the same time, this is a good design for V7 itself, in the time and
the context. V7 and its kernel were intended to be a small system, and
in a small system you don't want to go doing extra work unless you
absolutely have to, especially in the kernel. V7 could reuse the device
number to be the filesystem identifier essentially for free, so that's
what it did.</p>

<p>(V7's kernel took any number of shortcuts in the interests of having
a simple implementation. For instance, a lot of things were stored
in small fixed-sized arrays, because you would never have more than
a modest number of processes, open files, or so on.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/FilesystemStatDeviceProblem</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636376</guid>
            <pubDate>Thu, 25 Jun 2020 02:49:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Undervolting with SecureBoot in Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23636357">thread link</a>) | @kinghajj
<br/>
June 24, 2020 | https://kinghajj.github.io/blog/undervolting-with-secureboot-in-linux/ | <a href="https://web.archive.org/web/*/https://kinghajj.github.io/blog/undervolting-with-secureboot-in-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Many laptop users choose to undervolt their machines. This decreases thermal output, which, in turn, can increase program performance, since modern CPUs will automatically adjust their operating frequency depending on the available thermal headroom. Undervolting tools exist for all major operating systems; they typically require administrator rights, but otherwise are easy to use. In Linux, however, things aren't quite so simple: recent versions of the kernel prohibit the mechanism used for undervolting Intel CPUs when SecureBoot is enabled. The most common way around this, unsurprisingly, is just to disable SecureBoot. With a bit of work, though, it is possible to keep SecureBoot enabled, but allow controlled access to the undervolting mechanism.</p>
<p>The next sections will go into some background information on undervolting, SecureBoot, and why newer versions of Linux prevent the former while the latter is enabled. You can skip any of these if you're already familiar with the topic.</p>

<p>Some laptops today are well-known for having thermal issues. A common culprit is that these laptops ship with voltage settings that are higher than actually required. This is a good default behavior, since chips' performance can vary significantly, even within a SKU. High-end chips that are put into more expensive models of these laptops, however, tend to be better binned, and often work without errors at substantially lower voltage. Since all modern chips implement some sort of "auto-overclock" when there is enough thermal headroom, this can translate into increased clock speeds, and thus, better performance.</p>
<p>My current laptop is a Dell XPS 15 7590, with an 8-core Intel® i9-9980HK. This particular model performs better compared to its predecessors, but there is still room for improvement. Unfortunately, Dell's UEFI provides no way to control the voltage settings, so any adjustments must be done after booting up.</p>

<p>The <a href="https://wiki.debian.org/SecureBoot#What_is_UEFI_Secure_Boot.3F">Debian Wiki</a> has a great explanation of SecureBoot and Machine Owner Keys:</p>
<blockquote>
<p>UEFI Secure Boot (SB) is a verification mechanism for ensuring that code launched by a computer's UEFI firmware is trusted. It is designed to protect a system against malicious code being loaded and executed early in the boot process, before the operating system has been loaded. SB works using cryptographic checksums and signatures. Each program that is loaded by the firmware includes a signature and a checksum, and before allowing execution the firmware will verify that the program is trusted by validating the checksum and the signature. When SB is enabled on a system, any attempt to execute an untrusted program will not be allowed. This stops unexpected / unauthorized code from running in the UEFI environment.</p>
<p>...</p>
<p>A key part of the shim design is to allow users to control their own systems. The distro CA key is built in to the shim binary itself, but there is also an extra database of keys that can be managed by the user, the so-called Machine Owner Key (MOK for short).</p>
</blockquote>
<p>Large distros, like Ubuntu, ship with kernels signed by the same CA key used by Microsoft for Windows. This lets them be installed onto systems with SecureBoot without making the user go through the hassle of registering their own MOK and signing the kernel manually. If you want to run any custom kernel modules, however, you must create and register a MOK with the UEFI, and sign the driver(s) with it, or the kernel will refuse the load them.</p>

<p>Intel CPUs have had MSRs—<em>model-specific registers</em>—for quite some time. All sorts of tracing and debugging functionality is available through them, but, importantly for this topic, this is also how they provide a way to dynamically adjust voltages applied to the core and caches of the CPU. More troubling, though, is that these registers can also be used to violate protection rings, allowing user applications to read <em>and write</em> over kernel memory, including kernel code. This is why applications that use the MSRs have always required some sort of elevated privileges.</p>
<p>Previously, programs that wrote to the MSRs only required the <code>SYS_RAWIO</code> capability in Linux. Recent version of the kernel, however, don't allow any writes to the MSRs whatsoever when SecureBoot is enabled. (In kernel parlance, this is called "lockdown mode.") The motivation here is sound: the entire purpose of SecureBoot is to have a trusted environment that runs only the exact code that's been authorized, so any mechanism that potentially allows modification of kernel code at runtime flies in the face of that goal.</p>
<p>There has been at least <a href="https://lore.kernel.org/linux-security-module/38d18a24-c580-d56b-f0cd-91e8184e1f0d@gmail.com/T/">one recent proposal</a> to open up the subset of MSRs used for undervolting, even when the kernel is locked down. A consensus hasn't yet been reached, though, so for the time being, we must come up with our own solutions.</p>

<p>tl;dr: the easiest way to allow undervolting in Linux while using SecureBoot:</p>
<ul>
<li>Generate your own MOK and register it with the UEFI.</li>
<li>Patch the <code>msr</code> module to remove the checks for lockdown mode.</li>
<li>Build, sign, and install the patched module.</li>
<li>Install an undervolting tool, like <code>intel-undervolt</code>, and give it the
<code>RAW_IO</code> capability.</li>
<li>Rejoice!</li>
</ul>
<p>In my case, Ubuntu 20.04 uses kernel v5.4.0, and the patch looks like this:</p>
<pre><span>--- ./linux-source-5.4.0/arch/x86/kernel/msr.c.orig
+++ ./linux-source-5.4.0/arch/x86/kernel/msr.c
@@ -77,15 +77,15 @@
        u32 data[2];
        u32 reg = *ppos;
        int cpu = iminor(file_inode(file));
        int err = 0;
        ssize_t bytes = 0;

-       err = security_locked_down(LOCKDOWN_MSR);
-       if (err)
-               return err;
+       //err = security_locked_down(LOCKDOWN_MSR);
+       //if (err)
+       //      return err;

        if (count % 8)
                return -EINVAL; /* Invalid chunk size */

        for (; count; count -= 8) {
                if (copy_from_user(&amp;data, tmp, 8)) {
@@ -132,15 +132,15 @@
                        break;
                }
                if (copy_from_user(&amp;regs, uregs, sizeof(regs))) {
                        err = -EFAULT;
                        break;
                }
-               err = security_locked_down(LOCKDOWN_MSR);
-               if (err)
-                       break;
+               //err = security_locked_down(LOCKDOWN_MSR);
+               //if (err)
+               //      break;
                err = wrmsr_safe_regs_on_cpu(cpu, regs);
                if (err)
                        break;
                if (copy_to_user(uregs, &amp;regs, sizeof(regs)))
                        err = -EFAULT;
                break;
</span></pre>
<p>Pretty straightforward: look for all instances of <code>LOCKDOWN_MSR</code> in this file,
and comment-out the lockdown check &amp; error-handling code.</p>

<p>For all tests, these are the undervolt settings:</p>
<table><thead><tr><th>Component</th><th>ΔmV</th></tr></thead><tbody>
<tr><td>CPU Core</td><td>-99.6mV</td></tr>
<tr><td>CPU Cache</td><td>-99.6mV</td></tr>
</tbody></table>
<p>The first test is running Prime95 with default settings. Starting with the undervolt applied, I let the CPU frequency and temperature settle. Then, I set the voltage to stock settings, and let the system settle again. Measurements were done using the <code>intel-undervolt</code> tool. Here's the averaged &amp; rounded results:</p>
<table><thead><tr><th>Voltages</th><th>CPU Core (W)</th><th>CPU Core (°C)</th><th>CPU Core (Hz)</th></tr></thead><tbody>
<tr><td>Stock</td><td>38 W</td><td>92 °C</td><td>2350 Hz</td></tr>
<tr><td>Undervolted</td><td>34 W</td><td>92 °C</td><td>2950 Hz</td></tr>
</tbody></table>
<p>To see how this change would affect a realistic workload for myself, I compiled the latest trunk branches of Firefox and alacritty. Both of these runs were done with the same settings, and with a clean build tree.</p>
<table><thead><tr><th>Voltages</th><th>Firefox Time (s)</th><th>alacritty time (s)</th></tr></thead><tbody>
<tr><td>Stock</td><td>1401 s</td><td>139 s</td></tr>
<tr><td>Undervolted</td><td>1273 s</td><td>129 s</td></tr>
</tbody></table>
<p>These are only brief, non-rigorous tests, but the results suggest that undervolting can provide tangible benefits.</p>

<p>The obvious objection to this solution, of course, is that it makes SecureBoot useless. Or does it? If your system has multiple tenants, some of whom require the ability to grant programs the <code>SYS_RAWIO</code> capability, then this objection holds water. For the vast majority of laptop users, though, this isn't a threat. The owner decides which programs are allowed to perform raw I/O, and is responsible for their own security.</p>
<p>As for the common solution to this problem—disabling SecureBoot entirely—the drawbacks are pretty clear: you're throwing the baby out with the bathwater, abandoning any sense of security and peace-of-mind that comes from cryptographic verification of your operating system. Users shouldn't have to sacrifice critical security features for acceptable performance.</p>
<p>The best solution would satisfy the needs of both server and desktop use cases. If the kernel had an interface to control undervolting, without providing access to the raw MSRs, then we could have the best of both worlds: no way to violate the SecureBoot contract from userspace, and laptop users can get better performance. Designing a good, reusable interface for this would undoubtedly take some time; we don't want it to be married specifically to one vendor, architecture, or platform. Until such an interface gets made and merged, we'll have to stick to workarounds.</p>

<p>Undervolting can provide noticeable benefits for many laptop configurations. Unfortunately, some OEMs prevent adjusting these settings in their UEFI, requiring the use of runtime mechanisms. Even <em>more</em> unfortunately, the mechanism for Intel CPUs also comes with potential security holes, which make it a challenge to provide this functionality in a way that completely complies with protocols like SecureBoot. Linux, in particular, takes the most conservative approach, absolutely forbidding access to undervolting mechanisms when running under a secure context. That is a sane starting point, but it would certainly be worthwhile to figure out an acceptable solution.</p>

    </div></div>]]>
            </description>
            <link>https://kinghajj.github.io/blog/undervolting-with-secureboot-in-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636357</guid>
            <pubDate>Thu, 25 Jun 2020 02:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write PureScript react components to replace JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 72 (<a href="https://news.ycombinator.com/item?id=23636336">thread link</a>) | @JacksonGariety
<br/>
June 24, 2020 | https://thomashoneyman.com/articles/replace-react-components-with-purescript/ | <a href="https://web.archive.org/web/*/https://thomashoneyman.com/articles/replace-react-components-with-purescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  

<p>I have twice migrated large JavaScript apps to PureScript. At CitizenNet we replaced Angular with Halogen, and at Awake Security we’ve replaced most of a React application with PureScript React. Both companies have seen a dramatic drop in bugs in production.</p>

<p>It’s relatively easy to replace React due to PureScript’s <code>react</code> and <code>react-basic</code> libraries. The React mental model fits well with a strongly-typed, pure functional language like PureScript (or Reason), and using the same underlying library means that components can be shared between languages with little modification.</p>

<p>At Awake Security we share internationalization, a Redux store and middleware, and much more in an code base where PureScript regularly imports JavaScript and JavaScript regularly imports PureScript.</p>

<p>The best way to rewrite a significant app from one language to another is incrementally, while it runs. At first the new language can take over logically isolated parts of the app: the management dashboard, or the chat window, or a form. But eventually you must mix components from both languages together – for example, to support shared global state.</p>

<p>At this point you can’t just let the new language take over a DOM node. You need to support simple, clear features for intermixing the languages. Fortunately, you can transform the interface of idiomatic PureScript code into idiomatic JavaScript (and vice versa). With <code>react</code> and <code>react-basic</code> you can write business logic in PureScript but easily interoperating with the larger React ecosystem and your existing code.</p>

<p>In this article I will demonstrate how to replace part of a React application with simple components written in PureScript. Along the way, I’ll share best practices for making this interop convenient and dependable. The examples will be simple, but the same techniques also apply to complex components.</p>

<h4 id="sections">Sections</h4>

<ol>
<li><a href="#let-s-write-a-react-app-in-javascript">Write a tiny React application in JavaScript</a></li>
<li><a href="#setting-up-a-shared-purescript-javascript-project">Update the application to support PureScript</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react">Replace a React component with PureScript React, with the same interface and behavior as the original</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react-basic">Replace the component again with React Basic</a></li>
</ol>

<p>I encourage you to code along with this article; no code is omitted and dependencies are pinned to help ensure the examples are reproducible. This code uses Node <code>v11.1.0</code>, Yarn <code>v1.12.0</code>, and NPX <code>v6.5.0</code> installed globally, and PureScript tooling installed locally.</p>

<p>Peter Murphy has <a href="https://github.com/ptrfrncsmrph/purescript-react-tutorial">implemented the ideas in this article using React Hooks</a> if you’d like to see this in action.</p>




<h2 id="let-s-write-a-react-app-in-javascript">Let’s write a React app in JavaScript</h2>

<p>We are going to write a tiny React application which shows a few counters, and then we’re going to replace its components with PureScript. The resulting JavaScript code will be indistinguishable, aside from imports, from the original, and yet it will all be PureScript under the hood.</p>

<p>Let’s follow the official React docs in using <code>create-react-app</code> to initialize the project and then trim our source code to the bare minimum.</p>
<div><pre><code data-lang="sh"><span># Create the app</span>
npx create-react-app my-app <span>&amp;&amp;</span> <span>cd</span> my-app</code></pre></div>
<p>At the time of writing, <code>create-react-app</code> produces these React dependencies:</p>
<div><pre><code data-lang="json"><span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"react"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-dom"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-scripts"</span><span>:</span> <span>"3.0.1"</span>
  <span>}</span></code></pre></div>
<p>We have a handful of source files under <code>src</code>, but our application will need just two of them: <code>index.js</code>, the entrypoint for Webpack, and <code>App.js</code>, the root component of our application. We can delete the rest:</p>
<div><pre><code data-lang="sh"><span># Delete all the source files except for the entrypoint and</span>
<span># root app component</span>
find src -type f -not <span>\(</span> -name <span>'index.js'</span> -or -name <span>'App.js'</span> <span>\)</span> -delete</code></pre></div>
<p>Finally, let’s replace the contents of those two files with the bare minimum we’ll need for this article. From here on out I’ll supply diffs that you can supply to <code>git apply</code> to apply the same changes I did.</p>

<p>First, our entrypoint:</p>
<div><pre><code data-lang="jsx"><span>// src/index.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>
<span>import</span> <span>App</span> <span>from</span> <span>"./App"</span><span>;</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>App</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span></code></pre></div>
<p>Then our main app component:</p>
<div><pre><code data-lang="jsx"><span>// src/App.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>function</span> <span>App</span><span>()</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>h1</span><span>&gt;</span><span>My</span> <span>App</span><span>&lt;/</span><span>h1</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>export</span> <span>default</span> <span>App</span><span>;</span></code></pre></div>
<h3 id="writing-a-react-component">Writing a React component</h3>

<p>Let’s write our first React component: a counter. This is likely the first example of a React component you ever encountered; it’s the first example in the PureScript React libraries as well. It’s also small and simple enough to be replaced twice over the course of this article.</p>

<p>The counter will be a button which maintains the number of times it has been clicked. It will accept, as its only prop, a label to display on the button.</p>
<div><pre><code data-lang="jsx"><span>// src/Counter.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>class</span> <span>Counter</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>);</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span>
      <span>count</span><span>:</span> <span>0</span>
    <span>};</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=</span><span>&gt;</span> <span>this</span><span>.</span><span>setState</span><span>({</span> <span>count</span><span>:</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>count</span> <span>+</span> <span>1</span> <span>})}</span><span>&gt;</span>
        <span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>label</span><span>}</span><span>:</span> <span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>count</span><span>}</span>
      <span>&lt;/</span><span>button</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Counter</span><span>;</span></code></pre></div>
<p>Then, we’ll import our new counters into our main application:</p>
<div><pre><code data-lang="diff"><span>--- a/src/App.js
</span><span></span><span>+++ b/src/App.js
</span><span></span><span>@@ -1,9 +1,13 @@
</span><span></span> import React from "react";
<span>+import Counter from "./Counter";
</span><span></span>
 function App() {
   return (
     &lt;div&gt;
       &lt;h1&gt;My App&lt;/h1&gt;
<span>+      &lt;Counter label="Count" /&gt;
</span><span>+      &lt;Counter label="Clicks" /&gt;
</span><span>+      &lt;Counter label="Interactions" /&gt;
</span><span></span>     &lt;/div&gt;
   );
 }
</code></pre></div>
<p>With <code>yarn start</code> we can run the dev server and see our app in action.</p>

<p><img src="https://thomashoneyman.com/images/2019/running-app.gif" alt="running app"></p>



<p>We’ve written entirely too much JavaScript. Let’s support PureScript in this project as well. Our goal is to write code in either language and freely import in either direction without friction. To accomplish that, we will install PureScript tooling, create a separate PureScript source directory, and rely on the compiler to generate JavaScript code.</p>

<h3 id="1-install-the-compiler-and-package-manager">1. Install the compiler and package manager</h3>

<p>First we must install PureScript tooling. I recommend installing versions of the compiler and Spago (a package manager and build tool) which match those used in this article. I’ll use NPX to ensure all commands are run using local copies.</p>
<div><pre><code data-lang="sh"><span># Install the compiler and the Spago package manager however you prefer;</span>
<span># since we're already in a React project I'll use Yarn</span>
yarn add -D purescript@0.13.2 spago@0.8.4</code></pre></div>
<h3 id="2-initialize-the-project-and-package-set">2. Initialize the project and package set</h3>

<p>We can create a new PureScript project with <code>spago init</code>. As of version 0.8.4, Spago always initializes with the same package set, which means you should have identical package versions to those used to write this article. I’m using the <code>psc-0.13.0-20190607</code> package set.</p>
<div><pre><code data-lang="sh"><span># npx ensures we're using our local copy of Spago installed in node_modules.</span>
npx spago init</code></pre></div>
<p>Spago has created a <code>packages.dhall</code> file which points at the set of packages which can be installed and a <code>spago.dhall</code> file which lists the packages we’ve actually installed. We can now install any dependencies we need and we’ll know for sure the versions are all compatible.</p>

<p>Before installing anything, let’s update the existing <code>.gitignore</code> file to cover PureScript. For a Spago-based project this will work:</p>
<div><pre><code data-lang="sh"><span>echo</span> -e <span>"\noutput\n.psc*\n.purs*\.spago"</span> &gt;&gt; .gitignore</code></pre></div>
<h3 id="3-adjust-the-directory-structure">3. Adjust the directory structure</h3>

<p>Finally, let’s organize our source code. It’s typical to separate JavaScript source from PureScript source except when writing an FFI file for PureScript. Since we aren’t doing that in this project, our source files will be entirely separated. Let’s move all JavaScript code into a <code>javascript</code> subdirectory and create a new <code>purescript</code> folder next to it.</p>
<div><pre><code data-lang="sh">mkdir src/javascript src/purescript
mv src/App.js src/Counter.js src/javascript</code></pre></div>
<p>Next, we’ll adjust <code>index.js</code> to the new location of our root component:</p>
<div><pre><code data-lang="diff"><span>--- a/src/index.js
</span><span></span><span>+++ b/src/index.js
</span><span></span><span>@@ -1,5 +1,5 @@
</span><span></span> import React from "react";
 import ReactDOM from "react-dom";
<span>-import App from "./App";
</span><span></span><span>+import App from "./javascript/App";
</span><span></span>
 ReactDOM.render(&lt;App /&gt;, document.getElementById("root"));
</code></pre></div>
<p>We’ve just one task left. The PureScript compiler generates JavaScript into a directory named <code>output</code> in the root of the project. But <code>create-react-app</code> disables importing anything outside the <code>src</code> directory. While there are fancier solutions, for this project we’ll get around the restriction by symlinking the <code>output</code> directory into the <code>src</code> directory.</p>
<div><pre><code data-lang="sh"><span># we can now import compiled PureScript from src/output/...</span>
ln -s <span>$PWD</span>/output <span>$PWD</span>/src</code></pre></div>
<p>Your <code>src</code> directory should now look like this:</p>
<div><pre><code data-lang="sh">src
├── index.js
├── javascript
│ ├── App.js
│ └── Counter.js
├── output -&gt; ../output
└── purescript</code></pre></div>
<h2 id="replacing-a-react-component-with-purescript-react">Replacing a React component with PureScript React</h2>

<p>I like to follow four simple steps when replacing a JavaScript React component with a PureScript one:</p>

<ol>
<li>Write the component in idiomatic PureScript.</li>
<li>Write a separate interop module for the component. This module provides the JavaScript interface and conversion functions between PureScript and JavaScript types and idioms.</li>
<li>Use the PureScript compiler to generate JavaScript</li>
<li>Import the resulting code as if it were a regular JavaScript React component.</li>
</ol>

<p>We’ll start with the <code>react</code> library, which we use at Awake Security. It’s similar to <code>react-basic</code> but maps more directly to the underlying React code and is less opinionated. Later, we’ll switch to <code>react-basic</code>, which will demonstrate some differences between them.</p>

<p>As we take each step in this process I’ll explain more about why it’s necessary and some best practices to keep in mind. Let’s start: install the <code>react</code> library and prepare to write our component:</p>
<div><pre><code data-lang="sh"><span># install the purescript-react library</span>
npx spago install react

<span># build the project so editors can pick up the `output` directory</span>
npx spago build

<span># create the component source file</span>
touch src/purescript/Counter.purs</code></pre></div>
<h3 id="1-write-the-react-component-in-idiomatic-purescript">1. Write the React component in idiomatic PureScript</h3>

<p>Even though we are writing a component to be used from JavaScript, we should still write ordinary PureScript. As we’ll soon see, it’s possible to adjust only the interface of the component for JavaScript but leave the internals untouched. This is especially important if this component is meant to be used by both PureScript and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thomashoneyman.com/articles/replace-react-components-with-purescript/">https://thomashoneyman.com/articles/replace-react-components-with-purescript/</a></em></p>]]>
            </description>
            <link>https://thomashoneyman.com/articles/replace-react-components-with-purescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636336</guid>
            <pubDate>Thu, 25 Jun 2020 02:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Sabotaging Your Career with Short Stints]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23636077">thread link</a>) | @gmays
<br/>
June 24, 2020 | https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Life before a software engineering career is commonly a series of time-bound efforts to gain competency in a new area. This semester you learn geometry. That semester you learn history. Next semester you learn calculus. And so on.</p>

<p>As a result, most people entering the software engineering workforce equate learning with learning a brand new topic. I didn’t know ruby, I learned ruby. I didn’t know SQL, now I know SQL.</p>

<p>This kind of thinking leads people to 2 year cycles. On most modern software teams, it takes roughly one year to really feel like you have your feet under you. By that time the kind of learning novelty people are used to isn’t there. By 16 months they’re restless. By 24 months they’re gone.</p>

<p>This is a problem. It’s a problem because the majority of durable and transferable knowledge comes after achieving basic competency. Mastery of a skillset, understanding and learning from the outcomes of decisions made years ago, architecture and design, leading projects - these all come well after basic competency.</p>

<p>Not only does a life of cyclic learning work against reaching these next levels, but your ego and willpower also work against you. Those next-level skills are harder to learn. And once you’ve gained competency you lose the excuse of “I’m onboarding” or “still ramping up” when something goes wrong.</p>

<p>I always challenge engineers that want to make big changes in what they’re working on to consider whether they’re simply at the end of a novelty cycle. I always encourage them to go after those next level skills.</p>

<p>On the hiring front, I see a lot of people who have a career’s worth of 2-year stints. You can do that successfully for an entire career, and there are even some people that’ll tell you it’s a way to optimize earnings over time. If it does, I believe it only optimizes earnings for people who can’t get to those next level skills. The biggest earnings come from building and growing with a winning company.</p>

<p>24-monthers never deeply learn how things work. They’ll typically add value to a new company by carrying a collection of things they’ve seen before and shallowly applying them to similar problems. But when faced with a new problem that doesn’t map easily to the solutions they’ve seen, things start to break down.</p>

<p>The end-games for both careers are very different.</p>

<p>24-monthers eventually can get into C-level positions where it’s not uncommon to bring in someone who can just apply the common solutions to the similar task at hand. Their stints usually end right around the time where they’ve upleveled the company in some way and don’t know how to grow their team or evolve their strategy or deal with the short-comings of some of their decisions.</p>

<p>People who learn next level skills and how to deeply understand and react to the tasks at hand lead companies to uniquely successful outcomes. The best CEOs, the best CTOs, the best C-level anything - their careers are often a small handful of long-duration roles where they didn’t apply rote practices but innovated and reacted to change and created novel solutions based on deep understanding.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’m not saying you should stay with any given job. There are bad roles and bad bosses and everything in between. And skill diversification is important. But every job has problems. If you’re leaving because you’re chasing novelty or avoiding tackling your company’s challenges, you’ll start over in the cycle. Leave enough places for these reasons and you’ll find you’ve seriously limited your opportunities and earnings over time.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636077</guid>
            <pubDate>Thu, 25 Jun 2020 01:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anomaly Detection as a Foundation of Autonomous Monitoring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23635559">thread link</a>) | @gk1
<br/>
June 24, 2020 | https://www.zebrium.com/blog/log-metrics-anomaly-detection-as-a-foundation-of-autonomous-monitoring | <a href="https://web.archive.org/web/*/https://www.zebrium.com/blog/log-metrics-anomaly-detection-as-a-foundation-of-autonomous-monitoring">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>We believe the future of monitoring, especially for platforms like <a href="https://www.zebrium.com/k8s" rel=" noopener">Kubernetes</a>, is truly <a href="https://www.zebrium.com/blog/the-future-of-monitoring-is-autonomous" rel="noopener" target="_blank">autonomous</a>. Cloud native applications are increasingly distributed, evolving faster and failing in new ways, making it harder to monitor, troubleshoot and resolve incidents. Traditional approaches such as dashboards, carefully tuned alert rules and searches through logs are reactive and time intensive, hurting productivity, the user experience and MTTR. We believe machine learning can do much better – <a href="https://www.zebrium.com/blog/using-machine-learning-to-detect-anomalies-in-logs" rel=" noopener">detecting anomalous patterns</a> automatically, creating highly diagnostic incident alerts and shortening time to resolution.</p>
<!--more-->
<h3>What do you imagine when you see "Anomaly Detection"?</h3>
<p>When you think about anomaly detection, you probably visualize it for metrics: detection of outlier values like peaks, dropouts, or other deviations from normal. <img src="https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=303&amp;name=anomaly%20detection.png" alt="anomaly detection" width="303" srcset="https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=152&amp;name=anomaly%20detection.png 152w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=303&amp;name=anomaly%20detection.png 303w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=455&amp;name=anomaly%20detection.png 455w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=606&amp;name=anomaly%20detection.png 606w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=758&amp;name=anomaly%20detection.png 758w, https://www.zebrium.com/hs-fs/hubfs/anomaly%20detection.png?width=909&amp;name=anomaly%20detection.png 909w" sizes="(max-width: 303px) 100vw, 303px">In the realm of application monitoring metrics are a scheduled measurements of a large set (thousands) of system health attributes – such as CPU, memory, latency and throughput. So metrics anomaly detection can be a useful tool to detect application health incidents, with the metrics anomalies serving as symptoms of the incident. A challenge with traditional time series anomaly detection is that it is noisy – applications can generate thousands of metrics, and in any given day it’s common to see many of them deviating from their historical ranges. Alerting on all of these would be a noisy mess,so users need to do more work to avoid alert fatigue. They must handpick which ones really matter, carefully tune thresholds, make adjustments for seasonality and trend lines, plus be thoughtful about algorithm selection.</p>
<p><br>This approach is untenable to detect new failure modes (unknown failure modes with as yet unknown symptoms). And it does not take advantage of the fact that when software incidents occur, they almost never impact just one metric. For example, memory contention on a node impacts multiple containers. Similarly, network bottlenecks impact latency for many operations which show up in metrics.</p>
<img src="https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=307&amp;name=correlated%20metrics%20anomalies.png" alt="correlated metrics anomalies" width="307" srcset="https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=154&amp;name=correlated%20metrics%20anomalies.png 154w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=307&amp;name=correlated%20metrics%20anomalies.png 307w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=461&amp;name=correlated%20metrics%20anomalies.png 461w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=614&amp;name=correlated%20metrics%20anomalies.png 614w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=768&amp;name=correlated%20metrics%20anomalies.png 768w, https://www.zebrium.com/hs-fs/hubfs/correlated%20metrics%20anomalies.png?width=921&amp;name=correlated%20metrics%20anomalies.png 921w" sizes="(max-width: 307px) 100vw, 307px">

<p>To be useful for incident detection, anomaly detection has to work autonomously across all time series, but also separate the signal from&nbsp;the noise by picking out the hotspots of correlated anomalies that are indicators of real problems. And to be even more useful, it should automatically correlate these metric anomaly hotspots with something that is even harder to build rules for – anomalies in log events. &nbsp;&nbsp;</p>

<h3><span><strong>Anomaly detection applied to logs is very different</strong></span></h3>

<p>Log events are generated synchronous with execution of specific software paths. This makes them incredibly granular (micro-second or even finer resolution). They are also rich: since log events are only generated when specific conditions are encountered, they can selectively output data with almost unbounded cardinality (such as labels and IDs). Most significantly, events provide the best indication of causality. Where metrics measure aggregate symptoms about the application, log events are closely linked to specific code paths or error conditions in the software. For all of the above reasons, logs are an invaluable trove of information, so troubleshooting invariably involves digging through logs to find out root cause of an incident.&nbsp;</p>

<p>What if you didn’t have to do this reactively? Why couldn’t anomaly detection also be applied to events, with the goal of detecting highly unusual patterns of code execution, or rare errors or conditions. In other words, patterns that are diagnostic of a software problem, an infrastructure issue that impacts the application, or even security incidents. This is a bit harder to conceptualize than anomaly detection for metrics, but here is how it works.</p>
<h3>Learn what to track</h3>
<p>Metrics are explicitly tagged with labels and IDs – so it is clear what is being measured. Unfortunately, the link between a specific log event and the corresponding line of code is not explicit – most log events don’t contain references to source code, and they are typically unstructured, free form outputs coded by developers to help them troubleshoot. As a result, many of them look similar to the human eye because they contain similar keywords or strings.</p>

<p>Luckily machine learning can do far better than a human in this regard – it only needs to see a few variants of each message type to fully extract the fixed and variable parts of each message type – rapidly learning all the unique message types. This essentially constitutes the “dictionary” <strong><em>of all unique event types generated by the application stack</em></strong> – all that’s</p>
<p><img src="https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=974&amp;name=Structuring%20an%20event.png" alt="Structuring an event" width="974" srcset="https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=487&amp;name=Structuring%20an%20event.png 487w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=974&amp;name=Structuring%20an%20event.png 974w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=1461&amp;name=Structuring%20an%20event.png 1461w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=1948&amp;name=Structuring%20an%20event.png 1948w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=2435&amp;name=Structuring%20an%20event.png 2435w, https://www.zebrium.com/hs-fs/hubfs/Structuring%20an%20event.png?width=2922&amp;name=Structuring%20an%20event.png 2922w" sizes="(max-width: 974px) 100vw, 974px"></p>
<p>missing is the corresponding line # from the source code.</p>

<p>Note that this event type dictionary is not as big as you might think – an entire Atlassian suite has fewer than 1,000 unique event types.</p>
<h3>Learn the normal, detect the abnormal</h3>
<p>Once we’ve assembled this foundational dictionary of event types, another layer of ML learns<img src="https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=300&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png" alt="learn the normal and detect the abnormal" width="300" srcset="https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=150&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 150w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=300&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 300w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=450&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 450w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=600&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 600w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=750&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 750w, https://www.zebrium.com/hs-fs/hubfs/learn%20the%20normal%20and%20detect%20the%20abnormal.png?width=900&amp;name=learn%20the%20normal%20and%20detect%20the%20abnormal.png 900w" sizes="(max-width: 300px) 100vw, 300px"> the normal patterns of <strong><em>each event</em></strong> <strong><em>type</em></strong>. This includes things such as its frequency, periodicity, severity, and even the values of metrics embedded within each event type. Now when a log event breaks pattern significantly, it is anomalous.</p>

<p>Particularly important variants include the first occurrence of a very rare event, and the sudden stoppage of a normal event (e.g. a system heartbeat).</p>
<h3>Increase the contrast between signal and noise</h3>
<p>In practice you can’t stop there – most enterprise applications have dozens of service</p>
<img src="https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=207&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png" alt="machine learning for log anomaly detection" width="207" srcset="https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=104&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 104w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=207&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 207w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=311&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 311w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=414&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 414w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=518&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 518w, https://www.zebrium.com/hs-fs/hubfs/machine%20learning%20for%20log%20anomaly%20detection.png?width=621&amp;name=machine%20learning%20for%20log%20anomaly%20detection.png 621w" sizes="(max-width: 207px) 100vw, 207px">
<p>s, with hundreds if not thousands of instances (many of them ephemeral), scaling operations and frequent updates. Good anomaly detection can be very selective - picking out the one in a million event that is truly anomalous. However, one in a million would still be too many things to focus on in an environment that generates billions of messages a day. Once again, machine learning to the rescue – it takes advantage of the fact that a single anomaly in one event type is rarely alert worthy – but when tightly clustered group of anomalies pops up across multiple event streams – that IS almost always alert worthy. What constitutes “unusually tight cluster” depends on the specific deployment of an application, so it needs to be learned on the fly.</p>
<h3>See a complete narrative</h3>
<p>This type of anomaly clustering doesn’t just improve signal to noise by several orders of magnitude. It also constructs an automatic summary of the incident – picking out the sequence of anomalous events and the related anomalous metrics, as well as highlighting the hosts and log types that fully describe the incident.</p>

<p><img src="https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=908&amp;name=logs%20and%20metrics%20incident.png" alt="logs and metrics incident" width="908" srcset="https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=454&amp;name=logs%20and%20metrics%20incident.png 454w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=908&amp;name=logs%20and%20metrics%20incident.png 908w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=1362&amp;name=logs%20and%20metrics%20incident.png 1362w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=1816&amp;name=logs%20and%20metrics%20incident.png 1816w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=2270&amp;name=logs%20and%20metrics%20incident.png 2270w, https://www.zebrium.com/hs-fs/hubfs/logs%20and%20metrics%20incident.png?width=2724&amp;name=logs%20and%20metrics%20incident.png 2724w" sizes="(max-width: 908px) 100vw, 908px"></p>
<h3>Conclusion</h3>
<p>Done right, anomaly detection can <a href="https://www.zebrium.com/blog/is-autonomous-monitoring-the-anomaly-detection-you-actually-wanted" rel=" noopener">enable autonomous incident creation</a>, making it an incredibly powerful pillar of a monitoring strategy. It detects previously unknown problems the first time they occur, and reduces MTTR by automatically surfacing the unusual events and anomalies in metrics that describes an incident. But doing it right means understanding unique event types, learning the patterns and correlations of log events and metrics, and detecting anomaly clusters with good signal to noise. And for this to be practical, all of this has to work without extensive configuration, manual tuning, or impractical training windows.</p>

<p><span><a href="https://www.zebrium.com/sign-up?utm_campaign=Sign-up&amp;utm_source=adaa" rel=" noopener">Try it for yourself now</a></span>.</p></span>
</p>
<p id="hubspot-topic_data"> Tags:
<a href="https://www.zebrium.com/blog/tag/devops">devops</a>,
<a href="https://www.zebrium.com/blog/tag/observability">observability</a>,
<a href="https://www.zebrium.com/blog/tag/k8s">k8s</a>,
<a href="https://www.zebrium.com/blog/tag/kubernetes">kubernetes</a>,
<a href="https://www.zebrium.com/blog/tag/monitoring">monitoring</a>,
<a href="https://www.zebrium.com/blog/tag/autonomous-log-monitoring">autonomous log monitoring</a>,
<a href="https://www.zebrium.com/blog/tag/log-anomaly-detection">log anomaly detection</a>,
<a href="https://www.zebrium.com/blog/tag/autonomous-monitoring">autonomous monitoring</a>
</p>
</div></div>]]>
            </description>
            <link>https://www.zebrium.com/blog/log-metrics-anomaly-detection-as-a-foundation-of-autonomous-monitoring</link>
            <guid isPermaLink="false">hacker-news-small-sites-23635559</guid>
            <pubDate>Thu, 25 Jun 2020 00:44:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feasibility of Using a Corncob as a Football]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23635069">thread link</a>) | @a7b3fa
<br/>
June 24, 2020 | https://blog.nathanv.me/posts/corncob-football/ | <a href="https://web.archive.org/web/*/https://blog.nathanv.me/posts/corncob-football/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Table of Contents</h2>

<h2 id="background">Background</h2>
<p>I had written this a while ago to be a humorous post on
<a href="https://www.reddit.com/r/cfb" rel="noreferrer" target="_blank">/r/CFB</a>, but due to COVID-19, I totally
forgot to post it. This is not meant to be serious. Enjoy.</p>

<p>To begin with, we need to gather actual data from real footballs.
This is to help with our calculations for corncobs, and to provide as a reference
to ensure our process is correct.</p>
<h3 id="size-and-mass">Size and Mass</h3>
<p>First, we need the mass and frontal area of a football.
I don’t know if college footballs are different from NFL footballs, but I was able to
find that a NFL football should be between 14 to 15 ounces in weight and have
a circumference of 22 inches.
<a href="https://www.sportsrec.com/6560043/what-is-the-official-size-of-the-nfl-football" rel="noreferrer" target="_blank">Source.</a>
We’ll meet the weight half-way and
call it 14.5 ounces or 0.41 kg. With a circumference of 22 inches,
that means (assuming the football front is perfectly circular)
the frontal area is 38.52 in<sup>2</sup> or 0.0248 m<sup>2</sup>.</p>
<h3 id="throwing-velocity">Throwing Velocity</h3>
<p>So, how fast can a quarterback <em>actually</em> throw a football? More importantly, how much
<em>force</em> can a quarterback impart on a football? (you’ll see why later)
Based on some research, a fast throw is around 60 mph (26.82 m/s)
with a rotation of about 600 rpm (62.83 rad/s).
<a href="https://www.sportsrec.com/6938474/maximum-speed-of-a-football" rel="noreferrer" target="_blank">Source.</a>
However, that still doesn’t provide us
the force of the throw, as force equals mass times acceleration. In order to figure out
acceleration, we need to know how long the throw takes.
Using <a href="https://youtu.be/tVoqA-LKGb4?t=206" rel="noreferrer" target="_blank">this clip</a>,
I counted the throw taking 11 frames, from winding back,
to the ball leaving Drew’s hand. In that 30fps video, that’s 0.36 seconds,
which means the ball experienced about 74.5 m/s<sup>2</sup> of acceleration.
This means that about 30.545 Newtons of force was imparted onto the ball.</p>
<h3 id="throwing-height">Throwing Height</h3>
<p>Another important factor is at what height the football is thrown from. Someone taller
will be able to throw the ball farther. I don’t know much about football,
but it seems that when throwing the football, it’s released around head-height,
so we’ll estimate it as that. Therefore, we need an idea of idea of how tall
our average quarterback is. Thankfully, a quick search reveals that to be around
6’1” or about 1.55 meters.
<a href="https://www.ncsasports.org/football/recruiting-guidelines" rel="noreferrer" target="_blank">Source.</a></p>
<h3 id="air-properties">Air Properties</h3>
<p>Next, we need to figure out the properties of air (density, temperature, pressure)
that footballs are being thrown in,
as this affects the drag and trajectory. While we could just assume sea-level, let’s
find the average altitude of every college football stadium, and use a
standard atmosphere lookup table to find the air properties.</p>
<p>Unfortunately, I was unable to find a list of altitudes of college football stadiums.
Instead, I had to get creative. I <em>did</em> manage to find a list of
every college football stadium.
<a href="http://www.collegegridirons.com/comparisons.htm" rel="noreferrer" target="_blank">Source.</a>
From there, I wrote a script that ran each
stadium through the Google Maps API to get an elevation.
<a href="https://developers.google.com/maps/documentation/elevation/start" rel="noreferrer" target="_blank">Source.</a>
Just average all the values together, and ta-da, the average elevation
of every US college football stadium is around 285 meters.</p>
<p>With the average elevation, we can now determine the standard air density. This comes
out to:</p>
<ul>
<li>Density: 1.19183 kg/m<sup>3</sup></li>
<li>Temperature: 286.297 K</li>
<li>Pressure: 97947.8 Pa</li>
</ul>
<p><a href="https://www.digitaldutch.com/atmoscalc/" rel="noreferrer" target="_blank">Source.</a></p>
<h3 id="coefficient-of-drag">Coefficient of Drag</h3>
<p>A crucial number in determining the trajectory of a flying object is it’s
“coefficient of drag”. This is a unitless coefficient that represents how much
drag an object experiences. This is a very difficult number to calculate,
and is usually found experimentally.</p>
<p>Research shows that the coefficient of drag of a football is around 0.05-0.06.
<a href="http://users.df.uba.ar/sgil/physics_paper_doc/papers_phys/fluids/drag_football.pdf" rel="noreferrer" target="_blank">Source.</a>
However, to ensure our process is correct, I’d like to replicate this result with CFD
(computational fluid dynamics) software.</p>
<h4 id="3d-model">3D Model</h4>
<p>In order to compute our own coefficient of drag, we need a 3D model. Thankfully
a quick search on GrabCAD found the
<a href="https://grabcad.com/library/american-football-5" rel="noreferrer" target="_blank">perfect candidate</a>.
This model was hollow, so to avoid any weird effects in CFD, I filled in the model.</p>
<h4 id="cfd">CFD</h4>
<p>I setup a fluid simulation in SOLIDWORKS (my CAD program of choice), with the following
parameters, and an equation goal to compute the drag coefficient from the
drag force imparted on the football.
<a href="https://www.grc.nasa.gov/WWW/K-12/airplane/dragco.html" rel="noreferrer" target="_blank">Source.</a></p>
<p>Parameters:</p>
<ul>
<li>External Analysis
<ul>
<li>Exclude cavities without flow conditions</li>
<li>Exclude internal space</li>
</ul></li>
<li>Gravity on</li>
<li>Global rotation @ 62.83 rad/s</li>
<li>Air preset</li>
<li>Laminar and turbulent flow</li>
<li>Humidity effects on (default settings)</li>
<li>Turbulence effects on (default settings)</li>
<li>Adiabatic wall with 100 micrometer roughness</li>
<li>97947.8 Pa pressure</li>
<li>286.297 K temperature</li>
<li>-26.82 m/s flow velocity relative to rotating frame</li>
<li>Level 6 density global mesh</li>
<li>Computational Domain +/- 0.2 m on sides, +/- 0.3 m front-to-back.</li>
</ul>
<p>After it was done, I was pleasantly surprised to find my coefficient of drag to
come out to 0.0953. This means we’re in the right ballpark. (I didn’t expect to
hit the value exactly as CFD inherently has some error, and SOLIDWORKS flow
simulation isn’t a top-tier product)</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/football_cfd.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/football_cfd.png" alt="Football CFD">
</a>
<figcaption>Football CFD</figcaption>
</figure>
<h3 id="reference-calculations">Reference Calculations</h3>
<p>Finally, with all of this data, we can now plot theoretical trajectories.
<a href="https://www.grc.nasa.gov/www/k-12/airplane/flteqs.html" rel="noreferrer" target="_blank">Source.</a></p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/football_flights.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/football_flights.png" alt="Football Trajectories">
</a>
<figcaption>Football Trajectories</figcaption>
</figure>
<div><pre><code data-lang="txt">Thrown at 5 degrees, a football will fly for 0.85 seconds, landing 21.85 meters downfield.
Thrown at 10 degrees, a football will fly for 1.21 seconds, landing 30.28 meters downfield.
Thrown at 15 degrees, a football will fly for 1.6 seconds, landing 38.85 meters downfield.
Thrown at 20 degrees, a football will fly for 2.01 seconds, landing 46.67 meters downfield.
Thrown at 25 degrees, a football will fly for 2.41 seconds, landing 53.32 meters downfield.
Thrown at 30 degrees, a football will fly for 2.79 seconds, landing 58.52 meters downfield.
Thrown at 35 degrees, a football will fly for 3.15 seconds, landing 62.14 meters downfield.
Thrown at 40 degrees, a football will fly for 3.49 seconds, landing 64.08 meters downfield.
Thrown at 45 degrees, a football will fly for 3.8 seconds, landing 64.34 meters downfield.
Thrown at 50 degrees, a football will fly for 4.07 seconds, landing 62.93 meters downfield.
Thrown at 55 degrees, a football will fly for 4.32 seconds, landing 59.87 meters downfield.
Thrown at 60 degrees, a football will fly for 4.53 seconds, landing 55.23 meters downfield.
Thrown at 65 degrees, a football will fly for 4.72 seconds, landing 49.07 meters downfield.
Thrown at 70 degrees, a football will fly for 4.86 seconds, landing 41.51 meters downfield.
Thrown at 75 degrees, a football will fly for 4.98 seconds, landing 32.66 meters downfield.
Thrown at 80 degrees, a football will fly for 5.06 seconds, landing 22.66 meters downfield.
Thrown at 85 degrees, a football will fly for 5.11 seconds, landing 11.71 meters downfield.</code></pre></div>
<p>Thrown at an optimal 45 degrees, our theoretical football calculations say the
ball will fly about 64 meters. Based on record throw data from
<a href="https://www.topendsports.com/sport/gridiron/longest-throw.htm" rel="noreferrer" target="_blank">this site</a>
it looks like our data is pretty feasible, though maybe a bit on the short side.</p>
<h2 id="corncob">Corncob</h2>
<p>Time to perform the same analysis with a corncob.</p>
<h3 id="size-and-mass-1">Size and Mass</h3>
<p>Once again, we first need the
size and mass of a corncob. Research shows that the average ear of corn
was between 156.80 mm and 178.13 mm in length, depending on when it was picked.
<a href="https://www.researchgate.net/publication/303010127_Azospirillum_brasilense_promotes_increment_in_corn_production" rel="noreferrer" target="_blank">Source.</a>
(I know this research is from Africa. It’s best I could come up with
without going to the grocery store with a ruler looking like an idiot.)</p>
<p>Finding the mass of an average corncob was a bit trickier. I was able to find
that a pound of corn is about 1300 kernels, and that an ear of corn averages
800 kernels. This means that we can estimate that an ear of corn is about 0.615 pounds
or 0.279kg.
<a href="https://www.nefbfoundation.org/Images/FOUndation/Educators/Enriching-Activities/Corn-Calculations.pdf" rel="noreferrer" target="_blank">Source.</a></p>
<h3 id="throwing-velocity-1">Throwing Velocity</h3>
<p>So, how fast can you throw a corncob?
Given that the corncob has a mass of only 0.279 kg, this means with 30.545 Newtons
of force, the corncob can be accelerated at a rate of 109.48 m/s<sup>2</sup>. Over the same
0.36 second period, that’s 39.413 m/s or a little over 88 mph (where we’re going,
we don’t need roads).</p>
<h3 id="coefficient-of-drag-1">Coefficient of Drag</h3>
<h4 id="3d-model-1">3D Model</h4>
<p>I didn’t have any desire to 3D model an ear of corn, so I went looking for a model
I could download for free. Surprisingly, there weren’t many options. Thankfully,
I did manage to find one
<a href="https://free3d.com/3d-model/cornoncob-v01--775846.html" rel="noreferrer" target="_blank">free model</a>.
A quick measurement shows the length of the model falls within our acceptable range,
so no scaling required.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/corn_length.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/corn_length.png" alt="Corncob Length">
</a>
<figcaption>Corncob Length</figcaption>
</figure>
<p>In order to get the frontal area of our selected corncob, I simply measured
the diameter of the model, which happened to be a near-perfect circle with
a diameter of 35.49 mm.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/corn_diameter.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/corn_diameter.png" alt="Corncob Diameter">
</a>
<figcaption>Corncob Diameter</figcaption>
</figure>
<p>This gives the corncob a frontal area of 989.24 mm<sup>2</sup> or 0.00098924 m<sup>2</sup>.</p>
<h4 id="cfd-1">CFD</h4>
<p>I setup a very similar simulation as described above, just with a higher velocity
and smoother walls. I then fired off the simulation and let my processor chug
for about 20 minutes. This simulation took significantly longer as the model
was not a native SOLIDWORKS file, but a very complex imported geometry. Meshing
the model alone took about 5 minutes.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/cpu_usage.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/cpu_usage.png" alt="CPU Usage">
</a>
<figcaption>CPU Usage</figcaption>
</figure>
<p>After the simulation was finished, I was very surprised to have the coefficient of drag
come out to 0.184 (almost twice that of the football).
My best guess for this is despite the corncob’s small size,
the higher velocity and rougher surface contributed to more relative drag.
Another theory I have is that the kernels protruding create a lot of low-pressure areas,
increasing drag, as you can see in the image below with the sort of “ripples” of
pressure values.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/corncob_cfd.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/corncob_cfd.png" alt="Corncob CFD">
</a>
<figcaption>Corncob CFD</figcaption>
</figure>
<h3 id="throwing-distance">Throwing Distance</h3>
<p>Now, we bring it all together. How far can you actually throw a corncob? I plotted
theoretical trajectories using the same math as before.</p>
<figure>
<a href="https://blog.nathanv.me/posts/corncob-football/img/corncob_flights.png" target="_blank">
<img src="https://blog.nathanv.me/posts/corncob-football/img/corncob_flights.png" alt="Corncob Trajectories">
</a>
<figcaption>Corncob Trajectories</figcaption>
</figure>
<div><pre><code data-lang="txt">Thrown at 5 degrees, a corncob will fly for 1.01 seconds, landing 39.47 meters downfield.
Thrown at 10 degrees, a corncob will fly for 1.59 seconds, landing 61.1 meters downfield.
Thrown at 15 degrees, a corncob will fly for 2.22 seconds, landing 83.16 meters downfield.
Thrown at 20 degrees, a corncob will fly for 2.85 seconds, landing 103.55 meters downfield.
Thrown at 25 degrees, a corncob will fly for 3.48 seconds, landing 121.23 meters downfield.
Thrown at 30 degrees, a corncob will fly for 4.08 seconds, landing 135.46 meters downfield.
Thrown at 35 degrees, a corncob will fly for 4.65 seconds, landing 145.79 meters downfield.
Thrown at 40 degrees, a corncob will fly for 5.18 …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.nathanv.me/posts/corncob-football/">https://blog.nathanv.me/posts/corncob-football/</a></em></p>]]>
            </description>
            <link>https://blog.nathanv.me/posts/corncob-football/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23635069</guid>
            <pubDate>Wed, 24 Jun 2020 23:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Elasticsearch with Hollywood Movies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23634924">thread link</a>) | @lackoftactics
<br/>
June 24, 2020 | https://realptsdengineer.com/learn-elasticsearch-fun-way/ | <a href="https://web.archive.org/web/*/https://realptsdengineer.com/learn-elasticsearch-fun-way/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


			<div>
				<p>I am tired of boring Elasticsearch tutorials. Learning should be interactive; it shouldn't feel like reading lengthy technical documentation. Today we are going to learn the basics of Elasticsearch using a movie database. I have a small database of titles ready for you to import.</p><p>Don't we need some theory? You didn't click to view the typical technical blog post. If you are stubborn, jump to the workshop section and learn on the fly. Some people learn this way better, &nbsp;nothing wrong with that. If you want to get to know some essentials, go through Slideshare I created.</p><figure> 

</figure><p>Before we begin clone this repo: <code>git clone <a>git@github.com</a>:ptsdengineer/learn-elasticsearch-with-hollywood-movies.git</code> or<strong> <a href="https://github.com/ptsdengineer/learn-elasticsearch-with-hollywood-movies/archive/master.zip">download zip</a></strong></p><h3 id="installing-elasticsearch-and-seeding-data">Installing Elasticsearch and seeding data</h3><p><strong>For Mac users</strong>: the most comfortable way would be to install it from homebrew: <code>brew install Elasticsearch</code></p><p><strong>For Linux users</strong>: Please try this tutorial here: <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-14-04" rel="nofollow">https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-14-04</a></p><p><strong>Run Elasticsearch</strong></p><p><code>elasticsearch</code> on Mac</p><p> <code>sudo service elasticsearch start</code> on Ubuntu</p><p> Check if it's running on <a href="http://localhost:9200/" rel="nofollow">http://localhost:9200</a></p><h3 id="run-using-docker">Run using docker</h3><p>If you prefer docker way, you can also use it in tutorial. I have docker-compose file ready.</p><p><code>docker-compose up</code></p><p><strong>Credentials</strong>: user is <strong><code>elastic</code></strong> and password <strong><code>changeme</code></strong></p><p><strong>Use Postman, curl or Insomnia for making calls to Elasticsearch API</strong>. I can't recommend <a href="https://insomnia.rest/">Insomnia</a> enough, this piece of software makes life so much easier.</p><h2 id="creating-data">Creating data</h2><p>Create index for movies, it will hold all the movies documents that we will import in a minute. Open insomnia and make your first call.</p><figure><img src="http://realptsdengineer.com/content/images/2020/06/put-movies-1.png" alt="" srcset="http://realptsdengineer.com/content/images/size/w600/2020/06/put-movies-1.png 600w, http://realptsdengineer.com/content/images/size/w1000/2020/06/put-movies-1.png 1000w, http://realptsdengineer.com/content/images/size/w1600/2020/06/put-movies-1.png 1600w, http://realptsdengineer.com/content/images/size/w2178/2020/06/put-movies-1.png 2178w"></figure><p>Now let's import data into our index. I prepared JSON with all the documents that could be easily run.</p><figure><pre><code>curl -s --header "Content-Type:application/json"  -XPOST localhost:9200/_bulk --data-binary @movies.json
</code></pre><figcaption>Bulk import of movies from json</figcaption></figure><p>*Use option <code>-u</code> for typing user and password when running with docker.</p><p>If you want to learn more about this feature: <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html" rel="nofollow">Bulk import</a></p><h2 id="match-all">Match all</h2><p>Let's make the most straightforward possible query to our movies index. The query that returns all results, it's called match all query.</p><pre><code>GET &lt;name_of_index&gt;/_search
{
    "query": {
        "match_all": {}
    }
}
</code></pre><p>You should get this type of result in response:</p><pre><code>"hits": {
    "total": 306,
    "max_score": 1,
</code></pre><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-all-query.html" rel="nofollow">Match all docs</a></p><h4 id="exercise">Exercise</h4><p>Type this query into Insomnia. You will get results for the movies index.</p><h2 id="string-query">String query</h2><p>Still straightforward query, we will only search for a particular string.</p><pre><code>GET /_search
{
    "query": {
        "query_string" : {
            "default_field" : "content",
            "query" : "this AND that OR thus"
        }
    }
}
</code></pre><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html" rel="nofollow">String query documentation</a></p><h5 id="exercise-">Exercise.</h5><p>Using this knowledge find movie Scarface in the Elasticsearch. There should be only one result.</p><h3 id="operators">Operators</h3><p>Let's build on this. We want to extend our search capabilities. Elasticsearch uses operators like in programming, by default it uses <code>OR</code> but we can use <code>AND</code> to get an exact match.</p><pre><code>GET /_search
{
    "query": {
        "query_string" : {
            "default_field" : "content",
            "query" : "Strawberry pie with jello",
            "default_operator": "AND"
        }
    }
}
</code></pre><p>Now we will be sure that we will only get recipes we are interested.</p><h5 id="exercise--1">Exercise.</h5><p>Make a query to Elasticsearch that will return only <strong>one</strong> result on query <code>Captain America first avenger</code></p><pre><code>"hits": {
     "total": 1,
     "max_score": 11.263437,
     "hits": [
        {
           "_index": "movies",
           "_type": "movie",
           "_id": "139",
           "_score": 11.263437,
           "_source": {
              "title": "Captain America: The First Avenger",
              "plot": "Predominantly set during World War II, Steve Rogers is a sickly man from Brooklyn who's transformed into super-soldier Captain America to aid in the war effort. Rogers must stop the Red Skull – Adolf Hitler's ruthless head of weaponry, and the leader of an organization that intends to use a mysterious device of untold powers for world domination.",
              "genres": null,
</code></pre><h3 id="fuzziness">Fuzziness</h3><p>What about cases when users don't type query correctly? We should also handle those cases. Fortunately Elasticsearch has an answer, match query with a fuzzy query, it's a simpler cousin of string query.</p><pre><code>"query": {
  "match": {
    "text": {
      "query": "jomped over me!",
      "fuzziness": "AUTO",
      "operator":  "and"
    }
  }
}
</code></pre><p><code>"fuzziness": "AUTO"</code> generates an edit distance based on the length of the term. <code>0..2</code> must match exactly <code>3..5</code> one edit allowed <code>&gt;5</code> two edits allowed</p><p>You could also use number values, like <code>0, 1, 2</code>. Fuzziness is interpreted as Levenshtein Edit Distance. More about: <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/fuzziness.html" rel="nofollow">fuzziness</a></p><p><strong>Exercise.</strong></p><p>Write a query that will return all Captain America movies based on a query, which was mistyped: "Captaon America"</p><h2 id="filtering">Filtering</h2><h3 id="we-are-using-a-range-query-">We are using a range query.</h3><p>Matches documents with fields that have terms within a certain range. The Lucene query type depends on the field type, for string fields, the TermRangeQuery, while for number/date fields, the query is a NumericRangeQuery. The following example returns all documents where age is between 10 and 20:</p><pre><code>GET _search
{
    "query": {
        "range" : {
            "age" : {
                "gte" : 10,
                "lte" : 20,
                "boost" : 2.0
            }
        }
    }
}
</code></pre><p><strong>gte</strong> = Greater-than or equal to</p><p><strong>gt</strong> = Greater-than</p><p><strong>lte</strong> = Less-than or equal to</p><p><strong>lt</strong> = Less-than</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html" rel="nofollow">Range query</a></p><h4 id="exercise--2">Exercise.</h4><p>Create a query that would return movies with a running time between 60 and 90 minutes.<br>It should return 57 results.</p><h2 id="bool-query">Bool query</h2><p>The bool query takes a more-matches-is-better approach, so the score from each matching <code>must</code> or <code>should</code> clause will be added together to provide the final <code>_score</code> for each document.</p><p><code>must</code> - The clause (query) must appear in matching documents and will contribute to the score.</p><p><code>filter</code> - Filter clauses are executed in filter context. Scoring is ignored and clauses are considered for caching.</p><p><code>should</code> - The clause (query) should appear in the matching document.</p><p><strong>Example query:</strong></p><pre><code>POST _search
{
  "query": {
    "bool" : {
      "must" : {
        "term" : { "user" : "kimchy" }
      },
      "filter": {
        "term" : { "tag" : "tech" }
      },
      "must_not" : {
        "range" : {
          "age" : { "gte" : 10, "lte" : 20 }
        }
      },
      "should" : [
        { "term" : { "tag" : "wow" } },
        { "term" : { "tag" : "elasticsearch" } }
      ],
      "minimum_should_match" : 1,
      "boost" : 1.0
    }
  }
}
</code></pre><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html" rel="nofollow">Bool query</a></p><h4 id="exercise--3">Exercise.</h4><p>Create a query that will find superhero movies (keywords field: superhero) that are no longer than 120 minutes and no shorter than 60 minutes (field runtime) and must not have Robert Downey Jr. as a starring actor (actors field).</p><p>You should get 12 results for this query.</p><h2 id="aggregations">Aggregations</h2><p>Let's get some interesting stats for analytics. We want to get an overall view of how some value occurs through the documents. The stats aggregation would give us count, minimum value, maximum value, averages. It's useful for getting overall insight.</p><pre><code>{
    "aggs" : {
        "grades_stats" : { "stats" : { "field" : "grade" } }
    }
}
</code></pre><p>and returns:</p><pre><code>{
    ...

    "aggregations": {
        "grades_stats": {
            "count": 6,
            "min": 60,
            "max": 98,
            "avg": 78.5,
            "sum": 471
        }
    }
}
</code></pre><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html" rel="nofollow">Read more about aggregations here</a></p><h4 id="exercise--4">Exercise.</h4><p>Get overall data for ratings in movies: min, max, average. Do that using stats query.</p><h4 id="range-aggregation">Range Aggregation</h4><p>A multi-bucket value source-based aggregation enables the user to define a set of ranges - each representing a bucket.</p><pre><code>GET products/_search?size=0

{
  "aggs": {
    "weight_ranges": {
      "range": {
        "field": "weight",
        "ranges": [
          {
            "to": 500
          },
          {
            "from": 500,
            "to": 1000
          },
          {
            "from": 1000,
            "to": 1500
          }
        ]
      }
    }
  }
}
</code></pre><p>Returns aggregated data:</p><pre><code>    ...

    "aggregations": {
        "weight_ranges" : {
            "buckets": [
                {
                    "to": 500,
                    "doc_count": 20
                },
                {
                    "from": 500,
                    "to": 1000,
                    "doc_count": 4
                },
                {
                    "from": 1000,
                    "doc_count": 4
                }
            ]
        }
    }
}
</code></pre><h4 id="exercise--5">Exercise.</h4><p>Using range queries, count how many movies were in specific run times: below 60 minutes, between 60 and 75 minutes, between 90 and 120 minutes.</p><h2 id="histogram-aggregation">Histogram aggregation</h2><p>We can also use a histogram to bucket data instead of ranges. It's useful for prices in shops, so we can see how prices fall between different ranges like 0$-10$, 10$-20$.</p><pre><code>POST /sales/_search?size=0
{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 10
            }
        }
    }
}
</code></pre><p>Would return:</p><pre><code>{
    ...
    "aggregations": {
        "prices" : {
            "buckets": [
                {
                    "key": 0.0,
                    "doc_count": 1
                },
                {
                    "key": 50.0,
                    "doc_count": 1
                },
                {
                    "key": 100.0,
                    "doc_count": 0
                },
                {
                    "key": 150.0,
                    "doc_count": 2
                },
                {
                    "key": 200.0,
                    "doc_count": 3
                }
            ]
        }
    }
}
</code></pre><h4 id="exercise--6">Exercise.</h4><p>Create histogram aggregation for a rating in movies with interval equal 1.</p><h2 id="sorting">Sorting</h2><p>Allows adding one or more sort on specific fields. Each sort can be reversed as well. The sort is defined on a per-field level, with particular field name for <code>_score</code> to sort by score, and <code>_doc</code> to sort by index order.</p><pre><code>GET /my_index/my_type/_search
{
    "sort" : [
        { "post_date" : {"order" : "asc"}},
        …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://realptsdengineer.com/learn-elasticsearch-fun-way/">https://realptsdengineer.com/learn-elasticsearch-fun-way/</a></em></p>]]>
            </description>
            <link>https://realptsdengineer.com/learn-elasticsearch-fun-way/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634924</guid>
            <pubDate>Wed, 24 Jun 2020 23:11:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I deleted my Facebook, WhatsApp, and Instagram accounts, and felt great since]]>
            </title>
            <description>
<![CDATA[
Score 414 | Comments 228 (<a href="https://news.ycombinator.com/item?id=23634788">thread link</a>) | @shog_hn
<br/>
June 24, 2020 | https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/ | <a href="https://web.archive.org/web/*/https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2503">
	<!-- .entry-header -->

	<div>
		
<blockquote><p>I estimate that over the last 3 years, I’ve collectively <strong>saved around 2920 hours</strong> of time that would have otherwise been spent mindless scrolling through mostly uninteresting content.</p></blockquote>



<h2>The human problem</h2>



<p>It started with an urge to delete Facebook around 3 years ago.</p>



<p>I had noticed how Facebook was mostly just a highly filtered stream of content. Everyone’s happy thoughts and high moments in life, delivered to me in an algorithmically curated form.</p>



<p>I was part of the problem too. I posted things I was proud of, or the happy moments in my life. Very rarely anything else.</p>



<p>Facebook is for the most part, just a small, narrowly defined window into people’s lives.</p>



<p>We see the full picture of our own lives, but end up comparing what we have to this small, ‘happy’ slither of other people’s lives.</p>



<p>For those who don’t notice this unfair comparison, it can lead to moments of envy, anger, or even depression.</p>



<p>Don’t forget about the fake news, agendas, and other drivel that is posted around Facebook either. Scrolling through this kind of stuff on a daily basis will numb the mind and lead to one becoming complacant and perhaps even completely mislead.</p>



<p>One only has to look at how entire countries have been divided and swayed by lies posted to social media platforms to see how poisonous they can be.</p>



<p>The poison runs broad and deep on these platforms. There are many bad actors that wreak havoc, from state sponsored, to criminals and scam artists. They all have agendas to propagate, or nefarious goals to accomplish.</p>



<h2>The data problem</h2>



<p>The number one question to ask yourself whenever signing up for a ‘free’ account of any type is “<strong>Why is this free?</strong>“</p>



<p>A free product, is <a href="https://fee.org/articles/the-hidden-costs-of-free-social-media/" target="_blank" rel="noreferrer noopener" aria-label="not really free (opens in a new tab)">not really free</a>. There is always a catch. In the case of Facebook, you are paying with your own data.</p>



<p>Your own private life, details, habits, information and more is being collected in the background and used to make money for Facebook. They sell your data, and you pay with your privacy.</p>



<h2>Deleting Facebook</h2>



<p>As I mentioned at the start of this post, the urge to delete Facebook began around 3 years ago. It took me year of thinking about it before I took the plunge.</p>



<p>I exported all of my data as a .zip file, and uploaded it to some encrypted cloud storage for safe keeping.</p>



<p>Then I logged in, went to my account settings and requested that my account and data be deleted.</p>



<p>Facebook leaves your account in a ‘to be deleted’ state. They say that if you login again in the next week or so, it’ll automatically be re-enabled. This is a sneaky attempt at catching people out who have a habit of using Facebook on a daily basis.</p>



<p>I was diligent, and after a week or so my account was permanently deleted. Good riddance.</p>



<h2>Instagram purge</h2>



<p>Next up was <strong>Instagram</strong>. Facebook owns a bunch of products of course, Instagram being one of them. My Instagram account had been up and running from when the product had first launched, and was not a part of the Facebook group, but now that it was owned by Facebook, it had to go too.</p>



<p>The same reasons apply as I listed them above for Facebook.</p>



<p>Instagram was the easy one to delete, I didn’t really interact on the platform, and had just kept a bunch of interesting photos on my account. On a rare occasion I would browse through photos that others posted and that was about it.</p>



<p>The account was purged from my life with little fuss or care. More time cumulated over years to come for me to use on more <a href="https://www.shogan.co.uk/kubernetes/building-a-raspberry-pi-kubernetes-cluster-part-1-routing/" target="_blank" rel="noreferrer noopener" aria-label="useful endeavours (opens in a new tab)">useful endeavours</a>!</p>



<h2>Killing WhatsApp with fire</h2>



<p>WhatsApp hung around for a long time. This one was more difficult to get rid of. I had my family contacts and many friends on WhatsApp, and it had become my primary messaging platform.</p>



<p>I started using Telegram alongside WhatsApp and convinced quite a few friends to join.</p>



<p>Telegram is by far a superior product to WhatsApp. I’m not convinced it’s perfect, (hey it’s free too). But at least it’s not in the hands of a massive entity like Facebook. Less power to monopolies is a good thing.</p>



<p>About 9 months or so ago, I sent out a message to most of my WhatsApp contacts telling them I was deleting my account and telling them where to find me on Telegram if they joined there.</p>



<p>Shortly afterwards I deleted my WhatsApp account and have not looked back since.</p>



<p>Telegram offers far superior group chat options, more chat features, bots, and more. I’ve been very happy with it as a replacement for WhatsApp.</p>



<h2>Post Facebook, WhatsApp and Instagram</h2>



<p>I really feel happier without these three apps in my life. Facebook was a time sink, where I wasted time that could have been better used directly interacting with family and friends, or working on hobbies.</p>



<p>Instagram wasn’t too much of an issue, but there was (as with the others) the problem with my data being sold off.</p>



<p>WhatsApp was useful for messaging, but Telegram replaced that and gave me way more useful features.</p>



<p>I feel happier knowing that my data from WhatsApp is no longer up for sale, even though it was of course just a blip in a massive ocean of data.</p>



<p>I estimate that over the last 3 years, I’ve collectively <strong>saved around 2920 hours</strong> of time that would have otherwise been spent mindless scrolling through mostly uninteresting content. Simply as a result of me having deleted my Facebook, WhatsApp and Instagram accounts.</p>



<p>That’s 121 days of my life I have had available to use on better things already.</p>



<p>So that is the story of how I deleted my Facebook, WhatsApp, and Instagram accounts.</p>



<p>I encourage everyone reading this to take the plunge and delete your social media accounts wherever possible. Whether it be to save time in your lives, or to stop allowing your private data to be sold, you’ll be happier for it.</p>



<p>This is post #3 in my effort towards <a rel="noreferrer noopener" href="https://twitter.com/hashtag/100DaysToOffload" target="_blank">100DaysToOffload</a>.</p>
			</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</article></div>]]>
            </description>
            <link>https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634788</guid>
            <pubDate>Wed, 24 Jun 2020 22:55:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM, Microsoft, and Amazon Halt Sales of Facial Recognition to Police]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23634776">thread link</a>) | @andreyk
<br/>
June 24, 2020 | https://www.skynettoday.com/briefs/face-recog-police | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/briefs/face-recog-police">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>        
      
      
      <h4>Movements against unregulated police use of facial recognition, which compound its many ethical issues, are gaining speed</h4>
      
      </div><div>
      <h2 id="summary">Summary</h2>

<ul>
  <li>Recent protests in racial discrimination and police brutality led IBM to cease developing facial recognition technology and Microsoft and Amazon to pause selling face recognition technology to law enforcement.</li>
  <li>While this is a good starting point, as companies are not only acknowledging but addressing known flaws and biases in face recognition systems, much work remains to be done.</li>
  <li>In particular, continued pressure from the public is needed to ensure ethical developments and regulations of face recognition technology in the future.</li>
</ul>

<h2 id="what-happened">What Happened</h2>

<p>In a June 8 <a href="https://www.ibm.com/blogs/policy/facial-recognition-susset-racial-justice-reforms/">letter</a> to members of Congress, IBM declared its opposition to technologies that would enable surveillance, including facial recognition. 
Microsoft and Amazon followed suit on facial recognition, respectively <a href="https://www.washingtonpost.com/technology/2020/06/11/microsoft-facial-recognition/">banning police use</a> and placing a <a href="https://blog.aboutamazon.com/policy/we-are-implementing-a-one-year-moratorium-on-police-use-of-rekognition">one-year moratorium</a> on use. 
Other companies, <a href="https://www.theguardian.com/australia-news/2020/jun/19/victoria-police-distances-itself-from-controversial-facial-recognition-firm-clearview-ai">such as Clearview AI</a>, still offer the technology to police departments. 
As <a href="https://www.washingtonpost.com/technology/2020/06/11/ibm-facial-recognition/">The Washington Post</a> reports, IBM’s decision to drop facial recognition technology has been preceded by years of debate, particularly in response to a 2018 study called <a href="http://gendershades.org/overview.html">Gender Shades</a> which found that industry facial recognition systems have much higher error rates on darker-skinned faces.</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/briefs/face-recog-police/gender-shades.png" alt=" Gender classification disparities in darker vs. lighter skinned faces. From the 2018 Gender Shades study">
  <figcaption>
    Gender classification disparities in darker vs. lighter skinned faces. From the <a href="http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf">2018 Gender Shades study</a> .
  </figcaption>
</figure>

<iframe width="560" height="315" src="https://www.youtube.com/embed/TWWsW1w-BVo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Civil rights and justice groups, including the <a href="https://medium.com/@Joy.Buolamwini/ibm-leads-more-should-follow-racial-justice-requires-algorithmic-justice-and-funding-da47e07e5b58">Algorithmic Justice League</a> and <a href="https://www.aclu.org/press-releases/aclu-statement-amazon-face-recognition-moratorium">ACLU</a>, have commended these actions from IBM and Amazon:</p>

<blockquote>
  <p>The Algorithmic Justice League commends this decision as a first move forward towards company-side responsibility to promote equitable and accountable AI.</p>
</blockquote>

<blockquote>
  <p>It took two years for Amazon to get to this point, but we’re glad the company is finally recognizing the dangers face recognition poses to Black and Brown communities and civil rights more broadly.</p>
</blockquote>

<p>Facial recognition technology, capable of identifying a person from a digital image or video frame, has been under development for decades. 
With the major advances in deep learning over the past decade, facial recognition has also seen substantial progress. 
Modern AI-powered face recognition systems rely on large datasets of faces for two purposes: 1) training a neural network that can extract key features of human faces and 2) finding similar-looking faces using these features. 
There are multiple privacy and ethical concerns with collecting such large datasets, ranging from biased data that results in biased predictions to how these data <a href="https://onezero.medium.com/i-got-my-file-from-clearview-ai-and-it-freaked-me-out-33ca28b5d6d4">can be collected without consent</a>.</p>

<p>The recent controversies regarding face recognition are specifically centered around use by law enforcement. 
There are currently no federal laws, and few local ones, regulating how and when police and other government agencies can use such technologies. 
This is despite commercial offerings already being available for years, and <a href="https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html">being used</a> by some police departments. 
When these flawed systems are applied by law enforcement, they can place people of color at higher risk due to the higher error rate. 
Even if these systems worked perfectly, they can still be <a href="https://www.technologyreview.com/2020/06/12/1003482/amazon-stopped-selling-police-face-recognition-fight/">“easily weaponized against communities to harass them.”</a></p>

<h2 id="the-reactions">The Reactions</h2>

<p><strong>From the Press:</strong></p>

<ul>
  <li><a href="https://www.vox.com/recode/2020/6/10/21287194/amazon-microsoft-ibm-facial-recognition-moratorium-police">Vox</a> notes that public statements on facial recognition from such major companies is a step forward, but there are also concerns that smaller companies like Clearview AI may step in to take their place. Some are also skeptical of the recent moves by tech companies, calling them PR stunts:</li>
</ul>

<blockquote>
  <p>Evan Greer, the deputy director of Fight for the Future, called Amazon’s announcement “a public relations stunt.” The Surveillance Technology Oversight Project, a New York-based anti-surveillance legal organization, called the company’s move “too little, too late.” Its director, Albert Fox Cahn, added in an emailed statement, “Amazon shouldn’t just end this practice for one year or one decade; it should end it forever.”</p>
</blockquote>

<ul>
  <li><a href="https://www.forbes.com/sites/tomtaulli/2020/06/13/facial-recognition-bans-what-do-they-mean-for-ai-artificial-intelligence/#c15825c46ee3">Forbes</a> reports that with the condemnations and moratoriums, there is enough conflation between the different sorts of technology that people aren’t quite sure what exactly is being renounced. Nonetheless, the public attention on face recognition systems is a good starting point to ensure ethical developments of this technology in the future.</li>
</ul>

<blockquote>
  <p>This should then be backed up with a strong set of principles and ethical standards that the industry can follow. The result will likely be a stronger foundation for AI.</p>
</blockquote>

<ul>
  <li><a href="https://www.wired.com/story/ibm-withdrawal-wont-mean-end-facial-recognition/">Wired</a> also believes that we are far from the end with facial recognition, agreeing with Vox that plenty of smaller companies are still there to fill the void–the technology produced by these companies is prey to the same fatal flaws that resulted in the blowback against IBM et al in the first place.</li>
</ul>

<p><strong>From the Experts:</strong></p>

<ul>
  <li>Some, such as <a href="https://mobile.twitter.com/jathansadowski/status/1270855471222550528?cxt=HHwWgIC1tZqbgaMjAAAA">Jathan Sadowski</a> (research fellow at Monash U emerging tech lab), see the “victory” of pushback against facial recognition as merely symbolic and an opportunity to push harder.</li>
</ul>

<blockquote><p lang="en" dir="ltr">Yes, I see this not so much as winning a battle, but as an opportunity to go on the offensive, to push harder, to actually extract real and lasting victories. We've all had fight so hard just to gain enough ground to strike back. And I'm finally starting to feel a bit surefooted.</p>— Jathan Sadowski (@jathansadowski) <a href="https://twitter.com/jathansadowski/status/1270855471222550528?ref_src=twsrc%5Etfw">June 10, 2020</a></blockquote>


<ul>
  <li><a href="https://mobile.twitter.com/FoxCahn/status/1270840507971837954">Albert Fox Cahn</a> described the step as a milestone, but “like hearing an arsonist agree to stop pouring gasoline on a forest fire, without doing much to put out the blaze.”  \</li>
</ul>

<blockquote><p lang="en" dir="ltr">I agree that’s a huge milestone, but it feels like hearing an arsonist agree to stop pouring gasoline on a forest fire, without doing much to put out the blaze, and I hope many see it as a sign of just how much more can be accomplished through even more pressure.</p>— Albert Fox Cahn🔯 (@FoxCahn) <a href="https://twitter.com/FoxCahn/status/1270840507971837954?ref_src=twsrc%5Etfw">June 10, 2020</a></blockquote>


<ul>
  <li>Regardless, these steps, even Amazon’s one-year moratorium, are seen as <a href="https://mobile.twitter.com/EvanSelinger/status/1270838110625071106">a step in the right direction</a>.</li>
</ul>

<blockquote><p lang="en" dir="ltr">This is almost unbelievable! Nonstop activism + timing = Amazon has finally relented and is making a move in the right direction: implementing a one-year moratorium on the police use of its facial recognition tech, Rekognition! h/t <a href="https://twitter.com/BrendaKLeong?ref_src=twsrc%5Etfw">@BrendaKLeong</a> <a href="https://t.co/W5fWEaHtpY">https://t.co/W5fWEaHtpY</a></p>— Evan Selinger (@EvanSelinger) <a href="https://twitter.com/EvanSelinger/status/1270838110625071106?ref_src=twsrc%5Etfw">June 10, 2020</a></blockquote>


<p><strong>From the Source:</strong></p>

<p>After the announcements from IBM, Microsoft, and Amazon, Microsoft’s president <a href="https://www.cnn.com/2020/06/18/tech/brad-smith-microsoft-facial-recognition/index.html">repeated the call</a> for federal regulation of facial recognition technology:</p>

<blockquote>
  <p>“We need to start teasing this issue apart, to understand it better and move just beyond a binary conversation of: permit it or ban it,” Smith said. “And think about: what is the right way to regulate it?”</p>
</blockquote>

<p><strong>Summary</strong></p>

<ul>
  <li>The enthusiasm for IBM’s, Microsoft’s, and Amazon’s moves on facial recognition have been mixed.</li>
  <li>Adding to the worries are the existence of other companies peddling facial recognition technology, such as Clearview AI.</li>
  <li>While many see these announcements as a small step down a long road, they do see it as a step in the right direction.</li>
</ul>

<h2 id="our-perspective"><strong>Our Perspective</strong></h2>

<p>Amazon and Microsoft have engaged in the same marketing of facial recognition that is being lambasted today. 
While Amazon’s contracts are already public knowledge, Microsoft was recently found to have <a href="https://techcrunch.com/2020/06/17/microsoft-dea-facial-recognition/">pitched its facial recognition technology to the Drug Enforcement Administration</a> (DEA) as far back as 2017. 
The recent announcements from IBM, Microsoft, and Amazon are a promising step forward in the fight against unfettered use of facial recognition technology, particularly in policing. 
There are strong arguments that due to the inherent difficulties in fairly implementing automation technology in law enforcement, <a href="https://www.nytimes.com/2020/06/09/technology/facial-recognition-software.html">police should be banned from using facial recognition altogether</a>. 
In addition, as <a href="https://www.youtube.com/watch?v=jZjmlJPJgug">John Oliver</a> pointed out, development of facial recognition in and of itself has opened a Pandora’s Box that even some in Silicon Valley were too afraid to touch.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/jZjmlJPJgug" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>In particular, the following immediate issues remain:</p>

<ul>
  <li>Amazon is still engaged with the police in surveillance applications - Ring allegedly <a href="https://www.cnet.com/features/rings-work-with-police-lacks-solid-evidence-of-reducing-crime/">has partnered with over 1000 police departments in the US</a>.</li>
  <li>Even if Microsoft and Amazon decide to go as far as IBM has in the moral sense, the fact remains that companies like Clearview AI and Banjo continue to offer facial recognition services. As long as there are people who want to continue to use facial recognition for any purpose, its development will go on.</li>
  <li>Without substantive federal regulations on such technology, no one company (or three companies) will have much of an impact on the development and use of facial recognition technology and the associated risks.</li>
</ul>

<p>The current spotlight on the existing and potential abuses of face recognition technology is pressuring both industry leaders and governments to re-evaluate and re-imagine the future of face recognition. 
Congress is currently considering a police reform bill that limits face recognition in law enforcement. 
Many see this bill and the recent responses from tech companies as promising starting points. 
However, more pressure is needed to ensure fair and ethical uses of face recognition and other AI technologies with significant social impacts.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The moves by IBM, Microsoft, and Amazon to stop (or pause) development of face recognition technology, especially for law enforcement, at least until adequate federal regulations are in place, are promising starting points to ensure ethical uses of this technology. 
Although studies have revealed flaws in commercial face recognition systems for years, companies are only now taking action as a result of recent protests and the national conversation on racial discrimination and police brutality. 
This also suggests that continuous pressure from consumers, civil liberty groups, and the public at large is needed to ensure progress in the ethical development and regulation of face recognition technology.</p>

    </div></div>]]>
            </description>
            <link>https://www.skynettoday.com/briefs/face-recog-police</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634776</guid>
            <pubDate>Wed, 24 Jun 2020 22:53:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Chalice]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23634533">thread link</a>) | @aratno
<br/>
June 24, 2020 | https://aws.github.io/chalice/ | <a href="https://web.archive.org/web/*/https://aws.github.io/chalice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
	    <p><img src="https://aws.github.io/chalice/_static/img/coding.png" alt="Coding"></p><div>
                <h2>Focus on writing your application code</h2>
                <p>Focus on writing your application code
		   instead of the resources or services needed to deploy
		   your application.  Chalice automatically determines how to
		   provision the necessary resources for your application.</p>
            </div>
	    <p><img src="https://aws.github.io/chalice/_static/img/programming.png" alt="Coding"></p><div>
                <h2>A familiar decorator based API</h2>
                <p>Chalice's API for writing serverless application uses a familiar
		   decorator-based syntax used in frameworks such as Flask,
		   bottle, and FastAPI.  Skip the learning curve and get up and
		   running quickly.
		   </p>
            </div>
	    <p><img src="https://aws.github.io/chalice/_static/img/maintenance.png" alt="Coding"></p><div>
                <h2>Supports multiple deployment systems</h2>
                <p>Chalice supports multiple tools to deploy your application
		   including AWS CloudFormation, Terraform, and its own built-in
		   deployer based on the AWS SDK for Python.  Use the deployment
		   tools and services you're already familiar with.</p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://aws.github.io/chalice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634533</guid>
            <pubDate>Wed, 24 Jun 2020 22:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experts warn parts of U.S. on verge of being overwhelmed by Covid-19 resurgence]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 66 (<a href="https://news.ycombinator.com/item?id=23634517">thread link</a>) | @awnird
<br/>
June 24, 2020 | https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Here's what's happening around the world with COVID-19 on Wednesday.</p><div><p><span><span><span></span><span>Isolating COVID-19 cases and quarantining contacts is necessary in the Americas in order to prevent further lockdowns, says the World Health Organization.<!-- --> <!-- -->2:52</span></span></span></p><p><span><p><strong><em>The latest:</em></strong></p>  <ul>   <li><em><strong>IMF <a href="https://www.cbc.ca/news/business/img-downgrades-outlook-global-economy-1.5625010">sharply downgrades outlook</a> for global economy in face of COVID-19.</strong></em></li>   <li><strong><em>EU travel recommendations may <a href="https://www.cbc.ca/news/world/european-union-travel-americans-russians-coronavirus-1.5624911">impede Americans and Russians</a>.</em></strong></li>   <li><strong><em>Australia scrambles to <a href="https://www.cbc.ca/news/world/australia-scrambles-to-prevent-2nd-covid-19-wave-after-1st-death-in-a-month-1.5624963">prevent 2nd&nbsp;wave</a> after 1st death in a month.</em></strong></li>   <li><strong><em>Beware 2nd wave of coronavirus, <a href="https://www.cbc.ca/news/world/warning-second-wave-coronavirus-britain-1.5625074">medics warn Britain</a>.</em></strong></li>   <li><strong><em>Russia holds coronavirus-delayed <a href="https://www.cbc.ca/news/world/russia-victory-day-parade-1.5624914">Victory Day parade</a>.</em></strong></li>   <li><em><strong>Some countries <a href="https://www.cbc.ca/news/health/2-metres-coronavirus-covid-distancing-1.5624439">reconsider 2-metre rule</a> for physical distancing, but not Canada.</strong></em></li>   <li><em><strong>How Canada got into a pandemic economy — <a href="https://www.cbc.ca/news/politics/pandemic-covid-coronavirus-economy-debt-canada-1.5622374">and how it might get out</a>.</strong></em></li>   <li><em><strong>INTERACTIVE | <a href="https://newsinteractives.cbc.ca/coronavirustracker/">Tracking the coronavirus</a> in Canada and around the world.</strong></em></li>  </ul>  <p>A coronavirus resurgence is wiping out two months of progress <strong>in the U.S.</strong> and sending infections to dire new levels across the country's South and West, with hospital administrators and health experts warning Wednesday that politicians and a tired-of-being-cooped-up public are letting a disaster unfold.</p>  <p>The U.S. recorded a one-day total of 34,700 new COVID-19 cases, just short of the nation's late-April peak of 36,400, according to the count kept by Johns Hopkins University.</p>  <p>While new cases have been declining steadily in early U.S.&nbsp;hotspots such as New York and New Jersey, several other states set single-day case records this week, including Arizona, California, Mississippi, Nevada,&nbsp;Texas and Oklahoma. Some of them also broke hospitalization records, as did North Carolina and South Carolina.</p>  <p>"People got complacent," said Dr. Marc Boom, CEO of the Houston Methodist hospital system. "And it's coming back and biting us, quite frankly."</p>  <p><em><strong>WATCH |&nbsp;Long lines at COVID-19 test sites in U.S.:</strong></em></p>  <p><span><span><span></span><span>Traffic is seen at a standstill as drivers wait at drive-thru COVID-19 test sites in the U.S.<!-- --> <!-- -->1:11</span></span></span></p>  <p>The stock market slid sharply Wednesday as the virus's resurgence clouded investors' hopes for a relatively quick economic turnaround. The virus&nbsp;has been blamed for more than 120,000 deaths in the U.S. — the highest toll in the world — and more than 2.3 million confirmed infections there.</p>  <p>California, the most populous state, reported over 7,100 new cases, a record.&nbsp;Florida's single-day count of new confirmed cases surged Wednesday to 5,500&nbsp;—&nbsp;a 25 per cent jump from the record set last week.</p>  <p>In Texas, which began lifting its shutdowns on May 1, hospitalizations have doubled and new cases have tripled in two weeks. Gov. Greg Abbott told KFDA-TV that the state is facing a "massive outbreak" and might need new local restrictions to preserve hospital space.</p>  <p>The Houston area's intensive care units are nearly full, and two public hospitals are running at capacity, Mayor Sylvester Turner said. Houston Methodist's Boom said Texans need to "behave perfectly and work together perfectly" to slow the infection rate.</p>  <p>"When I look at a restaurant or a business where people ... are not following the guidelines, where people are just throwing caution to the wind, it makes me angry."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-texas.jpg 300w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-texas.jpg 460w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-texas.jpg 620w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas.jpg 780w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-texas.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas.jpg"></p></div><figcaption>A health-care worker takes down a patient's information at a COVID-19 testing site in Houston on Wednesday.<!-- --> <!-- -->(David J. Phillip/The Associated Press)</figcaption></figure></span></p>  <p>Just 17 percent of intensive-care beds were available Wednesday in Alabama — including just one in Montgomery — though hospitals can add more, said Dr. Don Williamson, head of the Alabama Hospital Association.</p>  <p>"There is nothing that I'm seeing that makes me think we are getting ahead of this," he said.</p>  <p>In Arizona, emergency rooms are seeing about 1,200 suspected COVID-19 patients a day, compared with around 500 a month ago. If the trends continue, hospitals will probably exceed capacity within the next several weeks, said Dr. Joseph Gerald, a University of Arizona public health policy professor.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-florida.jpg 300w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-florida.jpg 460w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-florida.jpg 620w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-florida.jpg 780w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-florida.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-florida.jpg"></p></div><figcaption>Volunteers prepare packages of personal protective equipment and sanitizers to be donated in Orlando, Fla., on Wednesday.<!-- --> <!-- -->(John Raoux/The Associated Press)</figcaption></figure></span></p>  <p>"We are in deep trouble," said Gerald, urging the state to impose new restrictions on businesses, which Gov. Doug Ducey has refused to do.</p>  <p>Infectious-disease expert Dr. Peter Hotez said he worries that the states will squander what time they have to head off a much larger crisis.</p>  <ul>   <li><strong><a href="http://cbc.ca/1.5626006">Democrats to hold mostly virtual presidential nomination convention due to pandemic</a></strong></li>  </ul>  <p>"We're still talking about subtlety, still arguing whether or not we should wear masks, and still not understanding that a vaccine is not going to rescue us," said Hotez, of the Baylor College of Medicine in Texas.</p>  <p>Texas Gov. Greg Abbott initially barred local officials from fining or penalizing anyone for not wearing a mask as the state reopened. After cases began spiking, he said last week that cities and counties could allow businesses to require masks. Both Abbott and Ducey are Republicans.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-texas-daily-life.jpg 300w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-texas-daily-life.jpg 460w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-texas-daily-life.jpg 620w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas-daily-life.jpg 780w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-texas-daily-life.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas-daily-life.jpg"></p></div><figcaption>A sign requiring face coverings at a business is seen in San Antonio, Texas, on Wednesday.<!-- --> <!-- -->(Eric Gay/The Associated Press)</figcaption></figure></span></p>  <p>North Carolina Gov. Roy Cooper, a Democrat, ordered people to wear masks in public as the daily count of hospitalizations and new cases hovered near records. In Florida, several counties and cities have recently started requiring masks in public places and cracking down on businesses that don't enforce social distancing rules.</p>  <p>In a sign of the shift in the outbreak, New York, Connecticut and New Jersey announced they will require visitors from states with high coronavirus infection rates to quarantine themselves for 14 days. That is a turnaround from March, when Florida Gov. Ron DeSantis issued such an order for visitors from the New York City area, where cases were surging at the time.</p>  <p>Cases are also surging in some other parts of the world. <strong>India </strong>reported a record daily increase of nearly 16,000 new cases, with an outbreak in the capital city of New Delhi becoming a rising concern. <strong>Mexico</strong>, where testing rates have been low, also set a record with more than 6,200 new cases.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/aptopix-virus-outbreak-india.jpg 300w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/aptopix-virus-outbreak-india.jpg 460w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/aptopix-virus-outbreak-india.jpg 620w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/aptopix-virus-outbreak-india.jpg 780w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/aptopix-virus-outbreak-india.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/aptopix-virus-outbreak-india.jpg"></p></div><figcaption>A health worker conducts a COVID-19 test on a patient as others wait in New Delhi on Wednesday.<!-- --> <!-- -->(Manish Swarup/The Associated Press)</figcaption></figure></span></p>  <p>But <strong>China </strong>appears to have tamed a new outbreak in Beijing, once again demonstrating its ability to quickly mobilize its vast resources by testing nearly 2.5 million people in 11 days. China on Wednesday reported 12 cases nationwide, down from 22 the day before.</p>  <p>In Europe, countries are both easing and increasing restrictions as the outbreaks evolve. <strong>Slovenia </strong>reintroduced mandatory use of face masks in public transportation and other enclosed public spaces after cases spiked in recent days, while <strong>Belgium </strong>said theatres and swimming pools could reopen next month. Infections there have nosedived over the past two months.</p>  <p><em><strong>WATCH |&nbsp;Belgian entrepreneur gives coronavirus masks the human touch:</strong></em></p>  <p><span><span><span></span><span>Photo booth operator makes custom masks to show the lower half of the wearer's face.<!-- --> <!-- -->1:59</span></span></span></p>  <p><strong>In Africa</strong>, the head of the Ethiopia-based Africa&nbsp;Centers for Disease Control and Prevention,&nbsp;John Nkengasong, said the outbreak is "picking up speed very quickly," with a steep increase in cases and deaths as more countries loosen lockdowns. Africa has seen nearly 325,000 cases and over 8,600 deaths.</p>  <p>Worldwide, more than 9.3&nbsp;million people have been confirmed infected, and more than 479,000 have died, <a href="https://coronavirus.jhu.edu/map.html">according to the Johns Hopkins&nbsp;count</a>.</p>  <hr>  <h2>What's happening with COVID-19 in Canada</h2>  <p>As of 7&nbsp;p.m. ET on Wednesday, Canada had 102,241 confirmed and presumptive coronavirus cases. Provinces and territories listed 65,091 of the cases as recovered or resolved. A CBC News tally of deaths based on provincial reports, regional health information and CBC's reporting stood at 8,530.</p>  <p>In Ontario, patios and hair salons were back in business in <a href="https://www.cbc.ca/news/canada/toronto/covid-coronavirus-ontario-toronto-peel-1.5624924" target="_blank">Toronto and Peel Region</a> on Wednesday.</p>  <p>Premier Doug&nbsp;Ford also announced&nbsp;a plan to&nbsp;<a href="https://www.cbc.ca/news/canada/windsor/ontario-government-announcement-plan-june24-windsor-essex-1.5625150" target="_blank">reopen&nbsp;parts of Windsor-Essex,</a>&nbsp;which until now has been the&nbsp;only region not cleared to move to the next phase of reopening, due to stubbornly high COVID-19 case numbers among migrant workers on farms in the region.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/covid-coronavirus-ottawa-mask.jpg 300w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/covid-coronavirus-ottawa-mask.jpg 460w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/covid-coronavirus-ottawa-mask.jpg 620w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/covid-coronavirus-ottawa-mask.jpg 780w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-coronavirus-ottawa-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/covid-coronavirus-ottawa-mask.jpg"></p></div><figcaption>People are seen wearing protective face coverings in Ottawa on Wednesday.<!-- --> <!-- -->(Andrew Lee/CBC)</figcaption></figure></span></p>  <p>British Columbia is <a href="https://www.cbc.ca/news/canada/british-columbia/covid-19-bc-phase-three-john-horgan-1.5625598">further easing restrictions</a>, meaning residents will be allowed to travel within the province as hotels, motels, resorts, spas&nbsp;and RV parks look to reopen.</p>  <p>Premier John Horgan announced Wednesday that B.C.&nbsp;will gradually be&nbsp;moving into Phase 3 of its restart plan, after the province managed&nbsp;to increase activity without seeing a spike in the number of COVID-19 cases in recent weeks.</p>  <p>Phase 3 of B.C.'s restart plan also means residents can travel within the province&nbsp;"safely and respectfully."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/senior-covid-survivor-walking-laps.jpg 300w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/senior-covid-survivor-walking-laps.jpg 460w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/senior-covid-survivor-walking-laps.jpg 620w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/senior-covid-survivor-walking-laps.jpg 780w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/senior-covid-survivor-walking-laps.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/senior-covid-survivor-walking-laps.jpg"></p></div><figcaption>People speak through a glass barrier at the Lynn Valley Care Centre in North Vancouver on Tuesday.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure></span></p>  <p>Canada's Atlantic provinces announced Wednesday they will move forward with <a href="http://www.cbc.ca/news/canada/prince-edward-island/pei-atlantic-bubble-covid19-1.5625133">a so-called travel bubble</a> as of July 3, allowing travellers in Prince Edward Island, New Brunswick, Nova Scotia and Newfoundland and Labrador to move between provinces without self-isolating.</p>  <p>Visitors from provinces and territories outside the region will still be required to self-isolate for 14 days and adhere to the local entry requirements in each of the four jurisdictions. However, once the self-isolation period has passed, these visitors will also be allowed to travel within the Atlantic region.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/politics/cerb-recipients-payments-ei-1.5623923">Why some CERB recipients are getting smaller payments this month</a></strong></li>   <li><strong><a href="http://cbc.ca/1.5625811">Yukon to open borders to B.C., N.W.T., and Nunavut residents July 1</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/british-columbia/bc-covid-update-june-23-1.5624328">B.C. runs risk of rapid rebound in COVID-19 cases if contacts exceed 65% of normal, health officials say</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/saskatoon/saskatchewan-interprovincial-travel-covid-19-1.5625045">Sask. working on 'more permissive approach' to interprovincial travel</a></strong></li>   <li><a href="https://www.cbc.ca/news/canada/edmonton/alberta-invests-10m-in-serology-testing-to-help-track-spread-of-covid-19-1.5623785"><strong>Alberta invests $10M in serology testing to help track spread of COVID-19</strong></a></li>   <li><strong><a href="https://www.cbc.ca/news/canada/manitoba/intellectual-disabilities-visits-manitoba-covid19-1.5624387">'Pure joy' as Manitoba adults with intellectual disabilities allowed to have loved ones over for visits</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/north/nwt-extends-state-of-emergency-1.5624556">N.W.T. extends state of emergency, public health emergency for 7th time</a></strong></li>  </ul></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634517</guid>
            <pubDate>Wed, 24 Jun 2020 22:19:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Driving Coast to Coast (To Coast): How to Take the Road Trip of a Lifetime]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23634127">thread link</a>) | @joebalcom
<br/>
June 24, 2020 | https://joebalcom.blog/2020/06/24/driving/ | <a href="https://web.archive.org/web/*/https://joebalcom.blog/2020/06/24/driving/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1248">
		<!-- .entry-header -->

	
	<div>
		
<figure><img data-attachment-id="1250" data-permalink="https://joebalcom.blog/2020/06/24/driving/image-6/" data-orig-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?fit=626%2C340&amp;ssl=1" data-orig-size="626,340" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-6" data-image-description="" data-medium-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?fit=300%2C163&amp;ssl=1" data-large-file="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?fit=525%2C285&amp;ssl=1" src="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=525%2C285&amp;ssl=1" alt="Driving cross-country" width="525" height="285" srcset="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?w=626&amp;ssl=1 626w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=300%2C163&amp;ssl=1 300w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=350%2C190&amp;ssl=1 350w" sizes="(max-width: 525px) 100vw, 525px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?w=626&amp;ssl=1 626w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=300%2C163&amp;ssl=1 300w, https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=350%2C190&amp;ssl=1 350w" data-lazy-src="https://i0.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-6.png?resize=525%2C285&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p><em>A word of caution: This post is being written during the COVID-19 pandemic that has swept across the United States and the rest of the world. Before taking any action on the information provided in this post, please be prepared to take the proper precautions: wear a mask, wash your hands, have plenty of hand sanitizer, distance yourself at least six feet away from others, and quarantine yourself for at least 14 days at the conclusion of any period of extended or out-of-state exposure. You might not feel that this applies to you, but I assure you, it does. The elderly and the more vulnerable people in your life are depending on you be responsible and take the virus and its effects seriously, regardless of what politicians on TV might be telling you. Have fun and live life but be responsible.</em></p>



<h4><strong>What’s in a Road Trip?</strong></h4>



<ul><li>17 sun-drenched days, 17 starry-skied nights (with a few gnarly storms here and there)</li><li>8,462 total miles driven (sorry, not sorry, Enterprise!)</li><li>120+ hours of fun, laughs, audiobooks, music, and podcasts in the car (estimated)</li><li>22 gas pumps (and lots of hand sanitizer)</li><li>16 States (PA, OH, IN, IL, IA, NE, CO, UT, AZ, NV, CA, NM, TX, OK, MO, WV)</li><li>11 State Capitals (Des Moines, Lincoln, Denver, Salt Lake City, Phoenix, Santa Fe, Oklahoma City, Springfield, Indianapolis, Columbus, Harrisburg)</li><li>Plains, mountains, forests, deserts, oceans, lots of cows, horses, elk, coyotes, roadrunners and tumbleweeds</li><li>Temperatures ranging between 36° in the Rocky Mountains and 108° in southern Arizona</li><li>Elevations ranging between 0’ at Redondo Beach, CA and 13,478’ in Rocky Mountain National Park</li><li>3+ large (1000+ acre) forest fires</li><li>10,000+ dead bugs on the front of the car</li><li>1 pull-over by Border Patrol in Southern New Mexico</li><li>Coral pink sand, red dirt, and inches of white salt in our shoes and tires (all from Utah)</li><li>Countless unexpected diversions that will make any long road trip truly unforgettable</li></ul>



<p>And it’s crazy to think that we haven’t even scratched the surface of America…</p>



<p>Over the past week I’ve recapped the 17 days of my road trip that that took me and my girlfriend from the Pocono Mountains in northeastern Pennsylvania through the arid northern Arizona desert, to the Pacific Ocean and back. If you want to check out some pictures or need a little motivation to get out and take the trip of your lifetime, I recommend checking out <a href="https://joebalcom.blog/2020/06/15/road-trip/">Part I</a> and <a href="https://joebalcom.blog/2020/06/23/road-trip-2/">Part II</a>.</p>



<p>My goal with this post is not just to show and tell my experiences, but primarily to set proper expectations and to show you exactly how to get up off the couch, out of your cubicle, out of bed, away from the TV, and into a car (fuel efficient if possible) that will take you on a trip that you will never forget.</p>



<p>The following is based solely on my own experiences, so I cannot promise that it will optimize for your specific needs. What it will do is give you a framework from which to build your own plan.</p>



<h4><strong>Layers of the Onion</strong></h4>



<p>Planning an extended road trip is a lot like peeling the layers of an onion. The conventional road trip, during normal times, has layers and layers of decisions that could effect each subsequent layer of decisions:</p>



<ul><li>Choosing between an RV, your own car, and a rental.</li><li>Selecting your destination and which cities and towns to stop in.</li><li>Navigation—which routes will get you to where you want to go within the parameters of your goals.</li><li>Deciding how much time you have and how much you want to cram into the trip.</li><li>Accounting for the difference between how much money you are willing/able to spend, and how much it will actually cost.</li><li>Identifying all expenses and hidden costs that will make up your total expenditure: gas, food, rentals, parks passes, insurance, lodging, etc.</li><li>How to stay sane in the car for hours on end.</li><li>Technology—how to communicate, or even navigate in areas with absolutely no cell phone service.</li></ul>



<p>These are just some of the complexities you would expect in normal times. But these are no normal times. COVID-19 has added new layers of complexity to the road trip, while simultaneously removing others. Different states have different restrictions and different attitudes. National parks are either closed or limited. Many businesses are closed or operating within tight constraints. But places to stay are widely available at cheaper prices than normal. Gas prices are at 10-20 year lows. The roads are emptier than ever. And the air is cleaner than ever. What better time to take the trip of a lifetime?</p>



<p>If you have never done an extended road trip, all of this might seem intimidating and overwhelming to the point where it might not even feel worth doing such a trip. But I have good news: you don’t have to reinvent the wheel. Just use my experience as a guide and shape it to fit your own aspirations for the perfect road trip.</p>



<h4><strong>Part 1: Decide and Commit</strong></h4>



<p>Like building a business or any large undertaking, dreams of a cross-country road trip can vanish before they ever materialize. And almost always, our indecision and inaction is the culprit. There are a million and one reasons to delay or put it off. Don’t. Decide what you want and make an irreversible decision, <a href="https://joebalcom.blog/2020/05/02/forcing-function/">a forcing function, to keep you from talking yourself out of it</a>.</p>



<p>Like many of my adventures, I didn’t plan this road trip with a lot of lead time (started planning 5/25, left on 6/5). Sure, anticipation is half the fun, but it is also the source of all second-guessing. To eliminate that possibility, my girlfriend and I set a goal to drive from the Pocono Mountains in Pennsylvania to Page, AZ. I made a simple spreadsheet with the dates that we felt comfortable with (for quarantine purposes and other obligations that would follow) and made the most sense. More on this in the next step.</p>



<p>Page, AZ is a town that we have previously visited and enjoyed it enough that we decided to make it a primary destination. It served as a strategic base, as it is accessible to many of the Southwest’s best national parks and destinations. So I booked a place in Page for nine days. You will soon see how quickly plans change.</p>



<h4><strong>Part 2: Prioritize Structure So You’re Free to Play</strong></h4>



<p>Do not over plan. It will take the fun, the serendipity, and the wonder out of the whole experience. What you want to do is build constraints or safety nets that will allow you the freedom to do what you want while ensuring that you don’t overextend yourself. As you can see in the tables below, due to unforeseen circumstances, our original plan and our actual outcome differ drastically.</p>



<p>While in Page, we decided that we might as well go all the way to the coast. What is a cross country road trip without seeing the Pacific Ocean?? That forced us to sacrifice the last two nights in Page (lodging costs in Part 5), and book places in new cities. Personal experience had taught me not to book everything from the original plan, as I knew things were bound to change.</p>



<p>Imagine if we planned everything down to the smallest detail and booked every hotel! It would be a logistical mess, or at the very least, a duller road trip.</p>



<figure><img data-attachment-id="1251" data-permalink="https://joebalcom.blog/2020/06/24/driving/image-7/" data-orig-file="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?fit=624%2C253&amp;ssl=1" data-orig-size="624,253" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-7" data-image-description="" data-medium-file="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?fit=300%2C122&amp;ssl=1" data-large-file="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?fit=525%2C213&amp;ssl=1" src="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=525%2C213&amp;ssl=1" alt="Plan for driving cross-country" width="525" height="213" srcset="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?w=624&amp;ssl=1 624w, https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=300%2C122&amp;ssl=1 300w, https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=350%2C142&amp;ssl=1 350w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?w=624&amp;ssl=1 624w, https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=300%2C122&amp;ssl=1 300w, https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=350%2C142&amp;ssl=1 350w" data-lazy-src="https://i2.wp.com/joebalcom.blog/wp-content/uploads/2020/06/image-7.png?resize=525%2C213&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Create a structure that will give you an idea of what you have to work with. Timeframe, distance, destinations. Knowing these will give you a sufficient framework and the freedom to adjust on the fly.</p>



<h4><strong>Part 3: Preparations</strong></h4>



<p><strong>(Note: All costs are listed in Part 5)</strong></p>



<ul type="1"><li>Rent a car. If you don’t have an RV or don’t want to drive your own car, rent a fuel-efficient car from Enterprise (I have no financial stake in that recommendation!). The reason I recommend Enterprise is that they do not charge petty fees for out of state driving or for mileage like most of the other “cheaper” rental companies. You can drive 10 miles, or 10,000 miles and you will still be charged the same. Go to a small town rental location, as they will probably have cheaper options, and more availability.</li><li>Be mindful of your thirst for adventure. You don’t want to drive off-road on rocks and sand, or up steep mountains in a Smart Car. But you also don’t want to break the bank with the rental or at the gas pump. Find the right balance for your needs.</li><li>Insurance: this decision comes down to your toleration of risk. You typically don’t have to take the rental company’s insurance if you are covered under your own plan. But some form of insurance is required.</li></ul>



<ul><li>Pack only what you <strong>need</strong>. It is tempting to take everything you own for a three-week trip, but you will feel much freer by travelling lighter. Odds are you will only use half of what you bring anyway. Like how a messy desk creates feelings of anxiety and disorganization at work, a messy car will create the same for you on the road.</li><li>Unfortunately for us, we were already coming from a rental property in the Poconos, so in addition to our clothes and food, I had my kettlebell and pullup bar and other random bags taking up space. Not ideal for being stopped by border patrol, but we made it work.</li></ul>



<ul><li>Searching for towns/lodging. This is totally subjective, as people range from minimalist campers to those who need every comfort and accommodation. We mainly kept it to Airbnb and simple hotel searches. Prices were cheaper than normal, and hotels were cheaper than Airbnb on average. Other than for Page, we didn’t book anything further out than three days. In busier times, that might have to change. But we valued flexibility over all else.</li><li>Location depended largely on our interests, and our stomach for longer drives. A rule of thumb for a cross country trip would be to take your total distance and divide it by how many days you plan on driving. From that you will have an average daily distance, which will give you an idea of where to stay each night. For us, we did a 24-hour drive on the first night (2pm in PA to 12 noon the next day in Boulder), which allowed for more time in the western part of the country. On the way back, I simply divided 2800 miles by 4 days, which gave me 700 miles each day. We then chose our return stops based on that. We had a consistent average of 65-70mph on the …</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://joebalcom.blog/2020/06/24/driving/">https://joebalcom.blog/2020/06/24/driving/</a></em></p>]]>
            </description>
            <link>https://joebalcom.blog/2020/06/24/driving/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634127</guid>
            <pubDate>Wed, 24 Jun 2020 21:33:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand WebAssembly in 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23634033">thread link</a>) | @jesuisundev
<br/>
June 24, 2020 | https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>WebAssembly joined HTML, CSS and Javascript as a web standard on December 5, 2019. This will be useful for many things, and in terms of performance, it’s something never seen before in a browser. If you’ve got five minutes, I need to explain the little revolution that’s going on.</p>



<h3>Once upon a time</h3>



<p>In 1995, Javascript was created <a rel="noreferrer noopener" href="https://thenewstack.io/brendan-eich-on-creating-javascript-in-10-days-and-what-hed-do-differently-today/" target="_blank">within 10 days</a> by <a rel="noreferrer noopener" href="https://twitter.com/BrendanEich" target="_blank">Brendan Eich</a>. And at that time, Javascript was not designed to be fast. <strong>It’s basically for form validation and it’s slow like crazy.</strong> As time went by it got better.</p>



<p>In 2008, Google came out of nowhere and put on the table its new browser: Google Chrome. Inside Chrome was a Javascript engine called V8. <strong>And the revolution of V8 was the Just in Time (JIT) compilation of Javascript.</strong> This change from interpreted code to  JIT compilation monstrously accelerated the performance of Javascript, and thus of browsers in general. This speed was going to allow the birth of technology like NodeJS or Electron and the explosion of popularity of Javascript.</p>



<figure><img src="https://i.imgur.com/YHJMavH.jpg" data-src="https://i.imgur.com/YHJMavH.jpg" alt="webassembly"></figure>



<p>In 2015, WebAssembly is announced for the first time with a <a href="https://www.eteknix.com/gaming-in-your-browser-is-about-to-get-interesting-with-webassembly/" target="_blank" rel="noreferrer noopener">small demo of a game</a> running under Unity. The game runs directly in the browser!</p>



<p>In 2019, the W3C made WebAssembly a new web standard. Just as the V8 engine was in its day, <strong>WebAssembly is shaping up to be the new performance revolution</strong>. So WebAssembly is already here, and it’s off to a flying start.</p>



<h3>What is WebAssembly?</h3>



<p>WebAssembly, abbreviated to wasm, is a way to use non-Javascript code and run it in your browser. This code can be C, C++, Rust and many others. <strong>It will be compile and run in your browser at near native speed on your CPU.</strong> This code is in the form of a binary file that you can use directly from Javascript as a module.</p>



<p><strong>WebAssembly is not there to replace Javascript</strong>. On the contrary, these two technologies are made to work together. By using the <a rel="noreferrer noopener" href="https://developer.mozilla.org/en-US/docs/WebAssembly/Using_the_JavaScript_API" target="_blank">Javascript API</a> you can load WebAssembly modules into your page. This means that you can take advantage of the performance of compiled code via WebAssembly with the flexibility of Javascript.</p>



<div><figure><img src="https://i.imgur.com/gbBMTTf.jpg" data-src="https://i.imgur.com/gbBMTTf.jpg" alt="internet"></figure></div>



<p>The name WebAssembly is a bit misleading. <strong>WebAssembly does indeed work for the Web, but it is not limited to it!</strong> The team that made WebAssembly has gone to a lot of trouble to make it generic so that it can be used everywhere. We’re starting to see <a href="https://github.com/wasmerio/wasmer" target="_blank" rel="noreferrer noopener">examples of this</a>.</p>



<p>Also, there’s a misconception that comes up all the time. <strong>WebAssembly is not a programming language.</strong> WebAssembly is an intermediate format, a <a href="https://en.wikipedia.org/wiki/Bytecode" target="_blank" rel="noreferrer noopener">bytecode</a>, which acts as a compilation target for other languages. Okay, it’s not clear, let’s make some drawings.</p>



<h3>How does it work?</h3>



<div><figure><img src="https://i.imgur.com/EHwFHv0.jpg" data-src="https://i.imgur.com/EHwFHv0.jpg" alt="webassembly"></figure></div>



<p>Did you see that? Another work of art. Do you believe me if I tell you I use Photoshop? Anyway !</p>



<ul><li><strong>Step 1</strong> : It’s you and your developer skills. <strong>You produce source code in C, C++</strong> (you can use others languages). This code is supposed to fix a problem or make a process too intensive for Javascript in the browser.</li></ul>



<ul><li><strong>Step 2 </strong>: you will use <a rel="noreferrer noopener" href="https://emscripten.org/index.html" target="_blank">Emscripten</a> to do the translation. <strong>Emscripten is a tool chain, built with <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/LLVM" target="_blank">LLVM</a>, that will compile your source code into WebAssembly</strong>. You can install it and compile whatever you want <a rel="noreferrer noopener" href="https://webassembly.org/getting-started/developers-guide/" target="_blank">in a few quick steps</a>, we’ll look at it later. At the end of this step, you will have a WASM file.</li></ul>



<ul><li><strong>Step 3</strong> : You will use the WASM file on your web page. <strong>If you come from the future, you can load this file like any ES6 module.</strong> Right now, the usage is slightly more complex, but nothing fancy.</li></ul>



<p>OK, let’s get our hands dirty.</p>



<h3>Show me the code</h3>



<p>First of all, we need a small piece of C++ code to compile. Where some people will offer you the whole <a href="https://d07riv.github.io/diabloweb/" target="_blank" rel="noreferrer noopener">Diablo 1  game in the browser</a> as an example, <strong>I’ll keep it simple with a function that adds two digits</strong>. We’re not going to prove the speed of C++ with that, it’s for the example.</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">int add(int firstNumber, int secondNumber) {
  return firstNumber + secondNumber;
}</pre>



<p>Then go to the Linux distribution of your choice. We will start by downloading and installing emscripten.</p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># installing dependencies (yes, you can use newer version of python)
sudo apt-get install python2.7 git

# gettin emscripten via a git clone.
git clone https://github.com/emscripten-core/emsdk.git

# downloading, installing and activating the sdk
cd emsdk
./emsdk install latest
./emsdk activate latestl
source ./emsdk_env.sh

# make sure the installation worked
emcc --version

# compiling the c++ file to a webassembly template
emcc helloWebassembly.cpp -s WASM=1 -o helloWebassembly.html

# we serve the HTML and look at the result
emrun helloWebassembly.html</pre>



<p>That was the hackerman way of doing the wasm. There’s a simpler way. </p>



<p>You can go to <a rel="noreferrer noopener" href="https://mbebenita.github.io/WasmExplorer/" target="_blank">this site</a> and put your C++ code on the left. Then you get the name of the exported function in the WAT part. <strong>Using the add function code showed before i got : “_Z3addii” as function name, we’ll use that just after</strong>. You just have to click on download and you will get your WASM file back. Easy !</p>



<p><strong>Now we can make WebAssembly work directly in the browser without all the annoying noise around.</strong> </p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;WASM test&lt;/title&gt;
    &lt;link rel="stylesheet" href="/stylesheets/style.css" /&gt;
  &lt;/head&gt;

  &lt;body&gt;
    &lt;script&gt;
      const getRandomNumber = () =&gt; Math.floor(Math.random() * 10000);

      WebAssembly.instantiateStreaming(
        fetch("https://012q1.sse.codesandbox.io/wasm/add.wasm")
      )
        .then(obj =&gt; obj.instance.exports._Z3addii)
        .then(add =&gt; {
          document.getElementById("addTarget").textContent = add(
            getRandomNumber(),
            getRandomNumber()
          );
        });
    &lt;/script&gt;

    &lt;h1&gt;Résultat du C++&lt;/h1&gt;
    &lt;p id="addTarget"&gt;&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre>



<p>This is it. This html web page allows you to use C++ compiled into WebAssembly ! I skip all the HTML and obvious stuff to go directly to line 11 with the <strong>InstantiateStreaming </strong>function. As the <a rel="noreferrer noopener" href="https://developer.mozilla.org/fr/docs/Web/JavaScript/Reference/Objets_globaux/WebAssembly/instantiateStreaming" target="_blank">Mozilla documentation</a> says, this function allows you to compile and instantiate our WebAssembly module via a simple fetch.</p>



<p>Then, I use the add function via the function name we retrieved earlier and use it to replace a piece of DOM. And voila ! <strong>C++ via Javascript inside your browser.</strong> How crazy is that? Look, I even made you a <a rel="noreferrer noopener" href="https://codesandbox.io/s/webassembly-en-5-minutes-012q1?fontsize=14&amp;hidenavigation=1&amp;module=%2Fpublic%2Findex.html&amp;theme=dark" target="_blank">codesandbox</a> with a working demo. I’m embedding it right here, play with it !</p>







<p>You’re gonna tell me it’s complicated just to do this, and you’re right. <strong>They’re working to replace the instantiation javascript bit with a simple import into the future.</strong> So be patient, it’s coming. </p>



<figure><img src="https://i.imgur.com/4FjTgL7.jpg" data-src="https://i.imgur.com/4FjTgL7.jpg" alt="fast"></figure>



<h3>Epilogue</h3>



<p>We’ve already been talking for five minutes, so I’ll stop here. If you want to know more about WebAssembly and you have time in front of you : i<strong> recommend this <a rel="noreferrer noopener" href="https://www.javascriptjanuary.com/blog/webassembly-neither-web-nor-assembly-but-revolutionary" target="_blank">excellent article</a> to go deeper in the subject.</strong> For the rest of the story, I’m looking forward to what this opening of the Web to other languages will bring. There’s a lot of potential and i can’t wait for the web to get even faster !</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634033</guid>
            <pubDate>Wed, 24 Jun 2020 21:23:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My 10 Year Game Development Journey]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23633738">thread link</a>) | @cedricr
<br/>
June 24, 2020 | http://nicotuason.com/10years.html | <a href="https://web.archive.org/web/*/http://nicotuason.com/10years.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>My 10 Year Game Development Journey</p>
		<h4>June 24, 2020</h4>
        <hr>
	
		<p>Hello! My name is Nico Tuason and I'm an indie game developer from the Philippines. This year marks the 10th year of my game development journey. I'd like to share my entire story with you - my failures, triumphs, and major life events. I hope it will be worth your time.</p>
		<h2>2010 - A Leap of Faith</h2>
		<p>At the start of the decade, I was 23 years old and had just left my job at a local web development company. I had been working there for a year and was making about <strong>22,000 PHP</strong> or <strong>440 USD</strong> a month. The pay was not bad for a fresh grad, but I was unproductive and unhappy. Additionally, my girlfriend of 4 years was dropping plenty of hints of her desire to get married, and 20k pesos just wasn't going to cut it.</p>
		<p>Being Asian (Filipinos are Asian too!) it was not acceptable for my parents that I was not either working or studying, so I applied for a post-grad Multimedia course in Singapore. Little did my parents know, shortly after applying I had received a rejection letter. I would keep telling them that "my application was pending", because I was secretly working on a passion project - my first game.</p>
		<p>To me, video games were more than a fun past-time. They were my refuge during hard and lonely times growing up. I spent almost all my free time playing games on the family PC. One of the first video games I ever received was Star Wars Rebel Assault II, a short but cinematic game. I played through it on every difficulty multiple times. After that, my parents bought me Command and Conquer and my fate was sealed. Growing up, I spent all my money on upgrading the family PC and buying boxed copies of games.</p>
		<p>Being in web development, I learned to use Flash to create banner ads and menu navigation for our clients. Out of necessity, I also had to learn how to create attractive UI and graphic design. While researching, I stumbled across a website called FGL.com (Flash Game License) that allowed anyone in the world to upload a Flash game and have sponsor websites bid on the right to put their logo on the game. They showed what some of the games were bidding for - <strong>3000 USD</strong>,  <strong>5000 USD</strong>! To me this looked like an incredible amount of money. There were even some mythical games going for <strong>10,000 - 20,000 USD</strong>! I devoured all the tutorials I could find. Before I had an idea for a game, I wanted to see if I could do a basic animation.</p>

		<div><p><img src="http://nicotuason.com/img/10years/male1_walk_side.gif"></p><p>My first animation</p>
		</div>
		
		<p>It looked good! But I knew I wanted to make a game in the isometric perspective. I had fallen in love with classic isometric RPGs like Baldur's Gate, and I was sure that any game I made had to be in isometric view. So, I repeated the animation but from different angles.</p>

		<div><p><img src="http://nicotuason.com/img/10years/male1_sheet.gif"></p><p>My first spritesheet</p>
		</div>

		<div><p><img src="http://nicotuason.com/img/10years/iso_walk.gif"></p><p>Resulting animation</p>
		</div>

		<p>The next step was to see if it actually looked good moving around a surface.</p>

		<div><p><img src="http://nicotuason.com/img/10years/walk_test1.gif"></p><p>Yes!</p>
		</div>

		
		<p>I didn't know any game math, but I knew from tutorials that in an isometric perspective, a square is twice as wide as it is tall. So, any movement along the y-axis had to be halved. This made for a very simple isometric transform:</p>
		<div>
		<p>screen_x = x;</p>
		<p>screen_y = y*0.5;</p>
		</div>
		<p>Ok, after I got the basics down, It was time for a stress test.</p>

		<div><p><img src="http://nicotuason.com/img/10years/walk_test2.gif"></p><p>Stress me out</p>
		</div>
		
		<p>By now I was waking up at 6am and jumping right into the computer to make more sprite sheets. It was intoxicating. Every day I felt a step closer to realizing my dream of making a game.</p>
		<p>I did a bunch more tests and I found the fastest way to draw stuff on screen using Flash was to use a method called "copyPixels". The tutorials called it "bitmap blitting" but I only cared that it was super fast. Most flash games those days used Vector graphics - very sharp and smooth shapes. This was a huge burden on CPUs around the world (and eventually led to Flash's demise), but by using copyPixels my game could have way more stuff onscreen than other Flash games.</p>

		<div><p><img src="http://nicotuason.com/img/10years/walk_test3.gif"></p><p>Walk all over me</p>
		</div>
		
		<p>Ok, the tech looked good, so it was time to start thinking about what kind of game this was going to be. At the time, tower defense was a very popular genre, and I loved RTS games. I decided that the simplest route was to make a bunch of enemies walk in one direction while you try to stop them, with lasers. Taking heavy influence from Starship Troopers and Starcraft, I created a suitable enemy that you could have fun slaughtering by the hundreds.</p>

		<div><p><img src="http://nicotuason.com/img/10years/walk_test4.gif"></p><p>Blizzard dont sue pls</p>
		</div>
		
		<p>I kept developing the game like this, working on one thing at a time and making sure it was acceptable before moving on to the next thing. If I don't stop myself, I could probably talk about every little detail that went into making the game, but we still have a long way to go.</p>
		<p><strong>7 months later...</strong></p>
		<p>I had a small but complete game on my hands. I called it "Desert Moon".</p>

		<div><p><img src="http://nicotuason.com/img/10years/desert_moon.gif"></p><p>C'mon you apes, you wanna live forever!?</p>
		</div>

		
		<p>It was time to put the game up for bidding. I uploaded the game to FGL.com and proceeded to not sleep for the next few days. I wish I took more screenshots of this process. I think at the time the bidding period lasted 1 month. After many tens-of-thousands of "reload page" clicks later, there was finally a winning bid. It was <strong>8500 USD</strong>! I don't know how to describe how I felt, but my head must have grown very large. I showed my girlfriend and my parents, the latter finally accepting that I wasn't going to grad school.</p>
		<p>My girlfriend, Terry, also loved Tower Defense games and she was the main play-tester during development. This was a very happy time for us.</p>
		<p>All I had to do was slap the Sponsor's logo onto the game and we could release it to the world.</p>


		<div><p><img src="http://nicotuason.com/img/10years/maxgames_intro.gif"></p><p>Thank you business daddy!</p>
		</div>

		<p>The game launched on the major Flash game portals (Kongregate, Newgrounds, Armorgames, etc.) on December 11, 2010, and thus began my gamedev career.</p>
		


		<h2>2011 - Indie to Employee</h2>
		<p>Flash games are free, so once a game is out there's not much you can do to make more money besides make another game. It takes a while before securing a sponsor and the game finally being released so I immediately started on another game called "Solarmax".</p>

		<div><p><img src="http://nicotuason.com/img/10years/solarmax_test.gif"></p><p>First prototype</p>
		</div>
		
		<p>One of my favorite games of all time is Homeworld. There's just nothing like the epic feeling of the fate of your entire race, your entire <em>history</em>, resting on your shoulders. I couldn't do anything near a 3D RTS like Homeworld, but there was a popular genre of Flash game called "Swarm" defense / strategy. I think Phage Wars was the most popular of these. I thought it would work well translated into epic space battles.</p>

		<div><p><img src="http://nicotuason.com/img/10years/solarmax.gif"></p><p>Scientifically accurate depiction of orbital mechanics</p>
		</div>
		
		<p>I spent some time learning 3D modeling software for this game. I was quite tired of pixel art after doing all the spritesheets for Desert Moon and exporting 3D models as a png sequence seemed like a good way to get all the angles needed for an isometric perspective without having to manually draw every frame.</p>

		<div><p><img src="http://nicotuason.com/img/10years/solarmaxb.gif"></p><p>pew pew!</p>
		</div>
		
		<p>The game was completed in 3 months, much faster than my first project! I was able to get it sponsored for <strong>6000 USD</strong>. A bit less than before, but it was a "non-exclusive" sponsorship meaning I could still sell "sitelocked" versions of the game. This was a common practice back then of having 1 version that would spread to all the portals, and many "sitelocked" versions that had a different site's branding but could only be played on their site.</p>
		<p>I planned to keep building small games like this as my skills grew, but then something unexpected happened. I got a job!</p>
		<p>I got an email from the CEO of a tech company in the U.S. who had seen my games and was looking for a flash programmer for a game they were making. Who knew CEOs were randomly playing flash games and emailing the developer?</p>
		<p>My first response was actually to decline the offer, because number 1 - I'm a dunce, and number 2 - I thought I could just make small flash games forever. Luckily this guy was persistent and I would still get to work on Flash games, but with more team members! And and... they were going to fly me out to the States to attend <strong>GDC</strong>!!!</p>

		<div><p><img src="http://nicotuason.com/img/10years/gdc1.jpg"></p><p>I'm in GDC!</p>
		</div>

		<div><p><img src="http://nicotuason.com/img/10years/gdc2.jpg"></p><p>I'm in San Francisco!</p>
		</div>

		<div><p><img src="http://nicotuason.com/img/10years/gdc4.jpg"></p><p>Another time, baby</p>
		</div>
		
		<p>I'm so grateful to the people who made this happen! As a young game dev, going to GDC is like going to see the Vatican if you're ultra-Catholic. I was over the moon.</p>
		<p>Plus, the salary... it was <strong>3000 USD</strong> a month! A U.S.-based salary for someone living in the Philippines! I have to tell you, I really thought I was hot shit at the time.</p>
		<p>After I got my first paycheck, I proposed to my girlfriend Terry, who I was sure would say yes because the year before her lawyer-auntie cornered me and demanded a deposition on why I had not married her niece yet.</p>
		<p>Things were going great!</p>



		<h2>2012 - Life... finds a way</h2>
		<p>In January, Terry and I got married! I was imagining that the next few years would be just the two of us, traveling together to different countries... making up for all the times we weren't allowed to travel together because the Philippines is a conservative country and it would be scandalous.</p>

		<div><p><img src="http://nicotuason.com/img/10years/wedding.jpg"></p><p>Our wedding Jeepney</p>
		</div>
		
		<p>Instead, 9 months later we had our first child! Which is great too I guess haha... ha.</p>

		<div><p><img src="http://nicotuason.com/img/10years/andres.jpg"></p><p>Yup, that's a baby alright</p>
		</div>
		
		<p>Becoming a dad mostly just means that a full-night's sleep is a thing of the past, at least in the beginning. I was working from home anyway so the arrangement was very doable.</p>
		<p>Meanwhile, work as an employee started out great and we produced lots of small games in a short time frame. Over the months though things started to drag. I felt myself becoming less and less productive. I missed the feeling of always learning something new and putting what I learned into a game. Maybe I'm just a bad employee?</p>
		<p>To prove how bad of an employee I was, here are some prototypes I made <em>mostly</em> during my free time.</p>
		<p>An isometric aerial dogfighting game in a fantasy WW1 setting:</p>
		
		<div><p><img src="http://nicotuason.com/img/10years/dogfight.gif"></p><p>I challenge you to a duel, good sir!</p>
		</div>
		
		<p>A pixel-ly survival game where you explore a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://nicotuason.com/10years.html">http://nicotuason.com/10years.html</a></em></p>]]>
            </description>
            <link>http://nicotuason.com/10years.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633738</guid>
            <pubDate>Wed, 24 Jun 2020 20:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's learn about Protocol Buffers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23633542">thread link</a>) | @forthwall
<br/>
June 24, 2020 | https://docs.shub.club/data/protobufs | <a href="https://web.archive.org/web/*/https://docs.shub.club/data/protobufs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div id="main-content">
<p><strong>Protocol Buffers</strong>  or <strong>“Protobufs”</strong> is a term often thrown around the rooms of big tech companies when designing <a href="https://systems-analysis.net/application/definition.html">application systems</a>. Application systems can contain hundreds of thousands of machines all communicating with each other. At that scale, many companies try to optimize in any way possible—Protocol Buffers is tool you can use to send data between your applications at high speeds. </p>
<p>In this article, I’ll be shedding some light on protocol buffers and showing you how to use it!</p>
<p>Protobufs are often paired with gRPCs (<a href="https://grpc.io/">Remote Procedure Calls</a>), which are a topic of its own. I’ll try to cover it in a few weeks.</p>
<div>
    <picture>
      <source srcset="https://shub.sfo2.digitaloceanspaces.com/docs/data/protobufs/cover.png, https://shub.sfo2.digitaloceanspaces.com/docs/data/protobufs/cover@2x.png 2x">
    <img height="289" width="516" src="https://shub.sfo2.digitaloceanspaces.com/docs/data/protobufs/cover@2x.png" alt=" High-speed 'Protobuf Railway' vs crowded 'JSON Expressway'">
    </picture>
        <p>What would you take your data on?</p>
</div>
<h2 id="the-gist">The Gist</h2>
<p>Protobufs is an <a href="https://stackoverflow.com/questions/670630/what-is-idl">interface definition language</a> and <a href="https://simple.wikipedia.org/wiki/Communication_protocol">communication protocol</a> used to build applications and transport data between them. Protobufs accomplishes this by enforcing a common data structure in the sections of code where data will be transmitted between applications. These data structures are defined in <code>.proto</code> files. A commandline tool, <code>protoc</code>, uses those <code>.proto</code> files to generate class files that are used to write your applications. </p>
<p>These classes come with a few helper functions that can convert data defined in a class to binaries--which then is used to transmit data between two servers. </p>
<p>Protobufs can be compared to JSON, the two differences are:</p>
<ol>
<li>You need to pre-define how your structure looks like in <code>.proto</code> files</li>
<li>The data stored in protobufs are modified by helper functions provided by the autogenerated classes from those <code>.proto</code> files</li>
</ol>
<p>Any time you transmit JSON between two servers; you could replace that with a protobuf binary instead. Sending data via protobuf binaries can offer performance improvements in faster download times between 4 to 78% depending on the situation (I discuss more in Tradeoffs and Benefits).</p>
<p>In my mind, there are two processes when developing with protobufs: the development process and the implementation process. The development process deals with creating and managing protobufs. The implementation process is the use of protobuf classes to build our applications/servers/services.</p>
<div>
    <picture>
      <source srcset="https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/proto-dev-cycle-1x.png, https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/proto-dev-cycle-2x.png 2x">
    <img height="428" width="600" src="https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/proto-dev-cycle-1x.png" alt="Protobuf development process visualized, explained below">
    </picture>
    <p>The development process, visualized</p>
</div>
<p>Let's look at these processes by example. Let's say we're developing an application that returns us a list of customers our company has. </p>
<p>Our development process looks like the following:</p>
<ol>
<li>A developer writes some data structures called <code>CustomerList</code> and <code>Customer</code> in a <code>customerlist.proto</code> file</li>
<li>A command line tool that comes with the protobuf library, called <code>protoc</code>, reads <code>.proto</code> files and generates classes in the programming langauge of the developer's choice.</li>
<li>The developer commits the <code>.proto</code> and generated code into their codebase</li>
<li>If any changes are needed to that datastructure, we start again at step one.</li>
</ol>
<p>The generated code in our case is the classes <code>CustomerList</code> and <code>Customer</code>. We can now use these classes to build out application. </p>
<p>When the time comes to send data between two systems, we can invoke a helper function that's attached to these classes to convert our Class data into a string. An invoked REST/gRPC/etc call passes this data to another service. Our listener on our other service can then use the same classes to deserialize the string back into language readable data.</p>
<h2 id="implementing-protobufs">Implementing protobufs</h2>
<div>
    <picture>
      <source srcset="https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/protobuf-our-system.png, https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/protobuf-our-system@2x.png 2x">
    <img height="176" width="600" src="https://shub.sfo2.cdn.digitaloceanspaces.com/docs/data/protobufs/protobuf-our-system.png" alt="Our system diagram. This details a client communicating to a web server communicating to a database server">
    </picture>
    <p>Let's build something like this!</p>
</div>
<p>Let’s build a system that transports a list of customers from our python application server to a Node.js webserver and shows us that list on a table.</p>
<p>This application is a bit complicated, so I have provided a Github link below for you to follow along:<br>
<a href="https://github.com/4shub/protobufs-example">https://github.com/4shub/protobufs-example</a></p>
<p>The file structure of our application should look like the following:</p>
<pre><code>// @language-override:Our folder
application_root
|_src
   |_ generated
   |_ protos</code></pre>
<p>First let’s build a <code>customerlist.proto</code> in <code>src/protos</code>:</p>
<pre><code>// @language-override:proto3
syntax = "proto3";

message Customer {
  required string name = 1;
  required int32 id = 2;
  required string email = 3; 
  required bool isNewCustomer = 4;
}

message CustomerList {
  repeated Customer customer = 1;
}</code></pre>
<p>Above I created our data structure following the <a href="https://developers.google.com/protocol-buffers/docs/proto3">proto3 language</a>. </p>
<p>Then we need to run following command in our application root:</p>
<pre><code>// @language-override:Terminal
protoc --python_out=src/generated --js_out=import_style=commonjs,binary:src/generated src/protos/customerlist.proto -I src/protos</code></pre>
<p>This command will generate our classes in files named <code>customerlist_pb.py</code> and <code>customerlist_pb.js</code> in a folder called <code>generated</code>.</p>
<p>Now let’s build our python server</p>
<pre><code># @language-override:Python + Flask
import flask
from generated import customerlist_pb2

app = flask.Flask(__name__)

# creating our "database"
customer1 = customerlist_pb2.Customer(name='Shubham', id=0, email='<a href="https://docs.shub.club/cdn-cgi/l/email-protection" data-cfemail="6d1e05180f2d1e05180f430e01180f">[email&nbsp;protected]</a>')
customer2 = customerlist_pb2.Customer(name='Rui', id=1, email='<a href="https://docs.shub.club/cdn-cgi/l/email-protection" data-cfemail="ccbeb9a58cb8a3a3e2afa3a1">[email&nbsp;protected]</a>', isNewCustomer=True)

customer_list = customerlist_pb2.CustomerList()
customer_list.customer.append(customer1)
customer_list.customer.append(customer2)


@app.route('/customer-list')
def get_customer_list():
    # `SerializeToString` is a helper function that serializes customer_list to a binary format
    return customer_list.SerializeToString()

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=3001)</code></pre>
<p>In the code above, I instantiate the class <code>CustomerList</code> and populate it with some customer data. Then I convert that data into a protobuf binary and pass it anyone who requests <code>/customer-list</code>.</p>
<p>Our node server will act as our receiving server, it will host a html page that would contain a button that requests us the customer list stored on the python server. The node.js server will make the request on behalf of the client to get that data.</p>
<pre><code>// @language-override:Node.js + Express
const path = require('path');
const axios = require('axios');
const express = require('express');
const app = express();
const port = 3000;

const { CustomerList } = require('./generated/customerlist_pb');
const PYTHON_SERVER_URL = 'http://localhost:3001';

app.get('/customers', async (req, res) =&gt; {
    try {
        const binaryData = await axios.get(`${PYTHON_SERVER_URL}/customer-list`);

        // convert string to base64 to be read by `deserializeBinary`
        const base64data = Buffer.from(binaryData.data).toString('base64')

        const customerList = CustomerList.deserializeBinary(base64data)

        // convert to json
        res.send(customerList.toObject());
    } catch (e) {
        console.log(e)
        res.send(404);
    }
});

app.get('/', (req, res) =&gt; res.sendFile(path.join(__dirname, './index.html')));

app.listen(port, () =&gt; console.log(`Example app listening at http://localhost:${port}`))</code></pre>
<p>We see <code>CustomerList</code>'s helper function <code>deserializeBinary</code> converting our binary string into a workable <code>CustomerList</code> class object. We use <code>toObject</code> to convert our class data into a JSON. We finally pass the JSON to the client.</p>
<h2 id="tradeoffs-and-benefits">Tradeoffs and Benefits</h2>
<p><strong>Not everything you build requires protobufs!</strong></p>
<p>Sometimes it’s easier and more efficient to not deal with sophisticated methods over sending data. In a study by Auth0 [0], where they compared JSON vs protobuf binary performance, Protobufs significantly improved data transmission rates from java server to java server communication (78% download time reduction), while java server to client communication had only a 4% download time reduction. </p>
<p>Auth0 also did a second test from a java server to the client in an “uncompressed” environment. Download time was improved by 21%. Using this information, if your goal is just to enhance performance, it's much better just to compress your JSON data and forget implementing protobufs.</p>
<p>Outside optimizations, protobufs provides a method of documenting and enforcing a data structure. This is super useful with keeping data consistent across multiple programming languages and multiple teams. </p>
<p>What do tradeoffs and benefits mean for you, the developer? It means that sometimes a tool you could use in one part of your application system might not be useful elsewhere. Or it could mean that maybe the additional development time to enforce protobufs on your whole application is worth it. In the end, it's up to you as a developer to see if a solution is viable for your product or use-case. </p>
<h2 id="conclusion">Conclusion</h2>
<p>Building an application ecosystem can be daunting, but with protobufs in your toolkit you can optimize your networking capacity to its full potential. Companies like Square, Google and Netflix use it every day in their systems. Maybe you can try and build something cool with it too. As always, let me know what you’ve built with protobufs.</p>
<p>[0] <a href="https://auth0.com/blog/beating-json-performance-with-protobuf/">https://auth0.com/blog/beating-json-performance-with-protobuf/</a></p></div>
        </div></div>]]>
            </description>
            <link>https://docs.shub.club/data/protobufs</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633542</guid>
            <pubDate>Wed, 24 Jun 2020 20:36:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developers are artists not factory workers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23633493">thread link</a>) | @doorknobguy
<br/>
June 24, 2020 | https://usehaystack.io/blog/post/software-development-metrics-measuring-what-matters-2/ | <a href="https://web.archive.org/web/*/https://usehaystack.io/blog/post/software-development-metrics-measuring-what-matters-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><h2>Most teams don't know what or how to measure. You're not alone.</h2><p>After advising hundreds of CTOs - I noticed a set of questions that consistently came up. They seem simple at face value but in reality they are some of the hardest questions to answer as an engineering leader.</p><p>‍</p><h2>Common Questions:</h2><ol role="list"><li>Are we getting better?</li><li>Where can we improve?</li><li>Are we even good at all?</li></ol><p>‍</p><p>As a manager it can be incredibly frustrating to not have the answers to these questions - &nbsp;even more so when you have to answer to outside stakeholders.</p><p>We often rely on trust and culture - but even in the best cases these questions largely go unanswered. It's incredibly difficult to quantify a team's progress and many go so far as to say "it's impossible" and "wrong to even try".</p><p>The end result? </p><p>‍</p><h3><em>"We're flying blind. And we know it."</em></h3><p>‍</p><p>‍</p><h2>Software Metrics are incredibly hard.</h2><p>The history of software development metrics has shown many (flawed) attempts at measuring developer productivity. Half baked metrics can ruin teams, destroy culture and make developers live miserable. We've seen it time and time again from lines of code to coding days per week - failed after failed attempt.</p><p>‍</p><h3>Common Metrics That Fail - Output Metrics</h3><ol role="list"><li>Commits</li><li>Lines of Code</li><li>Pull Request Count</li><li>Velocity Points</li><li>"Impact"</li></ol><p>‍</p><h3>Output Cannot Be Measured Accurately</h3><p>These metrics fail because they attempt to measure output - but software development isn't a factory assembly line where we can count up the number of widgets produced and quickly determine how much they cost.</p><p>‍</p><h3>Software Development is more like art</h3><p>Throwing more paint on the canvas is often more harmful than helpful. More lines of code or commits is often the opposite of what we want and just as it may take an artist a full day to find out the perfect brush stroke - a single line of code can take an immense amount of effort to get right.</p><p>‍</p><h3><em>"There are many things we can measure but very few things we should."</em></h3><p>‍</p><p>‍</p><h2>So what should we measure?</h2><p>To answer that, we need to think about why we're measuring at all. Most of us simply want to drive improvement and express our efforts in a tangible way. </p><p>‍</p><p>Ultimately what we want is a productive, happy team. But what does developer productivity look like? What do you imagine when you think of a productive team? </p><p>‍</p><p>Are you imagining a lot of lines written? A ton of pull requests created? What about a super high velocity count? Probably not. You're probably imagining a team that's responsive to one another, collaborating effectively, and has a really efficient process - and the metrics you use should reflect that.</p><p>‍</p><p>‍</p><h2>Measure what matters - Process Metrics</h2><p>Use software development metrics that enable productivity. </p><p>‍</p><p>Measuring <strong>responsiveness, collaboration, and process</strong> allows the team to improve how they work together. What's great about process metrics is - as developers - we really care about this stuff. They directly impact our day to day and allow us to improve while having concrete numbers to show our organization.</p><p>‍</p><p>When we measure process we drive productivity - ultimately giving leaders quantitative ways to express improvement while enabling developers to drive meaningful change in their day-to-day experience.</p><p>‍</p><h3><em>"Process metrics enhance culture. Not hurt it."</em></h3><p>‍</p><p>‍</p><h2>What are process metrics?</h2><p><a href="https://usehaystack.io/engineering-management-ebook.html?utm_source=blog&amp;utm_medium=measure%20what%20matters&amp;utm_campaign=inside%20blog">Download our Book of Engineering</a> for a <strong>full list of process metrics</strong> and how you can use them on your team.</p><p>You can also subscribe to our newsletter or reach out to us directly at <a href="mailto:julian@usehaystack.io?subject=I%20just%20read%20your%20blog%20and%20want%20to%20connect!">julian@usehaystack.io</a>. We'd be happy to help you design what metrics are best for your team.</p><p>‍</p><p>‍</p><figure id="w-node-18b2bd14c5bd-0cbffd4a"><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5ef130052901e5cad8432b81_Haystack_Designed_Presentation.png" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=measure%20what%20matters&amp;utm_campaign=inside%20blog">Haystack</a> helps engineering leaders identify blockers and trends. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get alerts in your inbox every morning. Plus a dashboard to track improvements over time.</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=measure%20what%20matters&amp;utm_campaign=inside%20blog">Try it for free</a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://usehaystack.io/blog/post/software-development-metrics-measuring-what-matters-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633493</guid>
            <pubDate>Wed, 24 Jun 2020 20:31:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google blew a 10 years lead – Because they only seek to hit competitors]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23633440">thread link</a>) | @snird
<br/>
June 24, 2020 | https://snir.dev/blog/google-10-years-lead | <a href="https://web.archive.org/web/*/https://snir.dev/blog/google-10-years-lead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>An interesting essay caught my eye today at HN about how <a href="https://secondbreakfast.co/google-blew-a-ten-year-lead">google blew a 10 years lead </a> , mostly in services. The essay described how most services that were the peak of innovation 10 years ago have subsequently stood stagnant and lost their technology edge to small companies. </p> <p>Gmail is less innovative than HEY (and superhuman and many others). Google docs is not as good as Notion for knowledge sharing and collaboration. And the list goes on. </p> <p>Initially, I thought it was because Google targets only big business customers, competing with Microsoft 365. Other product innovations do not scare them, they still offer a package with mail, video conferencing, docs, sheets, drive, etc. This is great for big business collaboration tools. Competitors like Notion and HEY are too small for Google business to care. </p> <p>Docs, sheets, drive, mail are all products targeted at corporate collaboration. These are directly competing with Microsoft alone. What about Google Cloud? What about Android? What happened there? </p> <p>Google consistently follows the market preventing its competitors from achieving market control. And in Google's case, "the market" is Amazon, Microsoft, Apple, and Facebook. </p> <img alt="google logo" src="https://snir.dev/blog/google-10-years-lead/google.png"> <p>We'll start with Microsoft since they were the first. And beating them down took place ~10 years ago, that's why it seems like the tech from back then never progressed much. Because the hit had already struck. </p> <p>Microsoft dominated the corporate world with its mail software Outlook, and with its Office suite, Word, Excel, etc. Google is native to the web and they leveraged their position to slowly hit Microsoft in this spot. Gmail first, then Google Drive, and then Chrome to kill IE as a final strike. And it was successful. </p> <p>Amazon got big into the tech business through AWS. Google brought Google Cloud to the fight. The offering is no only cheaper, it also provides technologies that can't be explained any other way than as a way to hit AWS. Kubernetes as an open platform is against any business textbook rukes to lock in customers. But it will allow for an easy way out of AWS in the long run, preferably to GCP, but it can be any other cloud provider that provides Kubernetes service as well. It is strategically more of a hit to the front runner, Amazon, than a benefit to GCP. </p> <p>Google's first priority is to hit the front runner, then everything else. This can also be seen with the Apple case. Android came after the iPhone. It has a much larger market share, and yet, generates far less revenue to Google than the iPhone is to Apple. That's because the main goal is to prevent Apple from winning the market. And in that, it is successful. </p> <p>Google Buzz. Ouch. Google Plus. Double ouch. Google spent so much effort into hitting Facebook as hard as they can. They were not succeful here, but from the history of things it is obvious how Google try to hit Facebook. They did not try to create a new social platform, no. Otherwise they would come up with something that is not.. well, exactly like facebook. </p> <p>Google home initially released at 2016. Amazon Alexa in 2014.</p> <p>I have so many more examples that comes to mind as I write, but the point is already clear. </p> <p>On a final note, I'll say, Google is not only trying to bend down competitors. Google Glass is one new product market they tried to create. The self-driving cars initiative is another example the comes to mind. They do innovate. </p> <p>They just have so much money, blocking out other big tech companies is a strategy they are not willing to give up. And when this is the strategy, well, Google sheets already took a huge chunk from Microsoft, what more does it need? </p> <form action="https://snir.substack.com/api/v1/free?nojs=true" method="post" min-width="400 500 600 700 800"> <div data-style="minimal">  <ul data-element="errors" data-group="alert"></ul>  <p>I wont send you spam. Unsubscribe at any time.</p></div> </form></article></div>]]>
            </description>
            <link>https://snir.dev/blog/google-10-years-lead</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633440</guid>
            <pubDate>Wed, 24 Jun 2020 20:26:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Water Demo with Godot]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23633174">thread link</a>) | @homarp
<br/>
June 24, 2020 | https://captainproton42.github.io/DynamicWaterDemo/ | <a href="https://web.archive.org/web/*/https://captainproton42.github.io/DynamicWaterDemo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      

<p>Click anywhere to interact with objects or spawn crates. You can also change the quality of the water texture and reset the scene.</p>

<h2 id="about">About</h2>

<p>View this page without the runnable demo scene <a href="https://captainproton42.github.io/DynamicWaterDemo/no_demo/">here</a>.</p>

<p>The entire code of this project is hosted on <a href="https://github.com/CaptainProton42/DynamicWaterDemo">GitHub</a>. It is lincensed under MIT so feel free to do with it whatever you want.</p>

<p>You can also find me on Twitter <a href="https://twitter.com/CaptainProton42">@CaptainProton</a> and on Reddit <a href="https://www.reddit.com/user/captainproton42">u/CaptainProton42</a>.</p>

<p>Below you will find a step-by-step explanation of the implementation.</p>

<h2 id="how-i-did-this">How I did this</h2>

<p>My implementation uses a finite-differencing method in order to solve the wave equation on a grid. I used the paper <a href="https://www.researchgate.net/publication/221314832_Real-Time_Open_Water_Environments_with_Interacting_Objects">Real-Time Open Water Environments with Interacting Objects</a> by H. Cords and O. Staadt as a reference. If you want to know more about the technical aspects of this implementation or more advanced techniques like infinite water, it’s a really good read.</p>

<h3 id="the-wave-equation">The wave equation</h3>

<p>A very important equation in phyiscs is the <a href="https://en.wikipedia.org/wiki/Wave_equation">wave equation</a>. It describes the propagation of many types of waves like water waves, sound waves, and even light. It therefore plays a large role in many fields of physics like fluid dynamics, acoustics, and optics. We can use it to describe the behaviour of our waves as well.</p>

<p>The equation itself is a <a href="https://en.wikipedia.org/wiki/Hyperbolic_partial_differential_equation">hyperbolic partial differential equation of second order</a>. If this sounds very complex, don’t worry, the equation itself is actually quite short:</p>



<p>Here,  is the current time,  is the position on the water surface and  is the wave speed.  then denotes the displacement, that is the height, of the water surface at position  and time .</p>

<p>The opertator  is the so-called Laplace operator and denotes the sum of the second spatial derivatives in every direction:</p>



<p>Thus we can see that the wave equation connects the second spatial derivates of the wave height with its second derivative in time. This property results in the motion of waves as we would observe it in nature.</p>

<h3 id="the-finite-difference-method">The finite difference method</h3>

<p>So now that we know what equation we want to solve we still have to figure out how to obtain a solution. Generally, this cannot be done analytically so we resort to a very popular numerical method: <a href="https://en.wikipedia.org/wiki/Finite_difference_method">the finite difference method</a>. In this method, we discretise the area in which we want to solve our equation into a grid. We then determina an approximate solution at each point of that grid.</p>

<p>Since we are discretising the water surface, we need to discretise the wave equation as well. For this, we use <em>stencils</em>. More specifically, a <em>five point stencil</em> for the Laplace operator and a <em>three point stencil</em> for the second derivative in time.</p>

<p>Let’s start with the Laplace operator: As previously stated, we dicretise the water surface as a grid. Let’s denote  as the value of the function  at the grid coordinates . Using a <em>five point stencil</em>, we can then <em>approximate</em> the derivative at that point as</p>



<p>where  is the distance between two grid points which is assumed to be equal in  and  direction. So, in order get the second spatial derivative at point  we need to sample all direct (non-diagonal) neighbours of that point (see the figure below).</p>

<p><img width="30%" src="https://raw.githubusercontent.com/CaptainProton42/DynamicWaterDemo/media/stencil.png"></p>

<p>However, the wave equation also contains a second time derivative which we need to discretise as well. For the time discretisation, we simply use the physics process delta time  (which is constant in Godot). We use the upper index  to denote the point in time. The complete notation is  for the displacement at grid coordinates  and time . In order to now approximate the second time derivate, we can just use the following three-point-stencil:</p>



<p>Now that we have dicretized both derivatives, let’s just plug them back into the initial wave equation and solve for :</p>



<p>where we introduce . In order to obtain a stable simulation,  needs to hold true. We thus have some limits on our choice of $\Delta t$ and $h$, depending on how fast our waves should propagate. Grids with less points (and thus large ) are generally more stable but also less accurate. It is desirable to keep  as small as reasonably possible which means high framerates will benefit our simulation.</p>

<p><strong>Let’s break down the final equation:</strong> In order to update and retreive , we need to know the grid neighbouring grid values at time  as well as the previous displacement values at time  and . We can start our grid from any arbitrary initial conditions and let it evolve over time.</p>

<p>Now that we know the theory, let’s get to the actual implementation.</p>

<h3 id="implementation-of-the-finite-difference-method">Implementation of the finite difference method</h3>

<p>In order to bring the finite difference method to life, we use fragment shaders. Textures are basically just two-dimensional grids that can hold values (colors) at each grid point (pixel). We make use of this convenient property and simply use a texture as the grid for our finite difference method.</p>

<p>In the editor, we create a new viewport called <code>SimulationViewport</code>. This viewport in return contains a <code>ColorRect</code> as shown below.</p>

<p><img width="30%" src="https://raw.githubusercontent.com/CaptainProton42/DynamicWaterDemo/media/implementation.PNG"></p>

<p>We then apply a shader to the <code>ColorRect</code> which contains the simulation code. The size (in pixels) of the <code>ColorRect</code> thus defines the size of the simulation grid. Two textures are passed as uniforms to this shader: <code>z_tex</code> which holds the grid values  and <code>z_old_tex</code> which holds the grid values . The resulting values  are then rendered to the <code>ColorRect</code> by the fragment shader. In order to retreive the current grid values, we can then simply retreive the contents of <code>SimulationViewport</code> with a <code>ViewportTexture</code>.</p>

<p>The snippet below contains the part of the simulation shader assigned to <code>ColorRect</code> which does the heavy lifting:</p>

<div><div><pre><code>void fragment() {
    float pix_size = 1.0f/grid_points;

    vec4 z = a * (texture(z_tex, UV + vec2(pix_size, 0.0f))
                  + texture(z_tex, UV - vec2(pix_size, 0.0f))
		  + texture(z_tex, UV + vec2(0.0f, pix_size)) 
		  + texture(z_tex, UV - vec2(0.0f, pix_size)))
	     + (2.0f - 4.0f * a) * (texture(z_tex, UV))
	     - (texture(old_z_tex, UV));

    float z_new_pos = z.r; // positive waves are stored in the red channel
    float z_new_neg = z.g; // negative waves are stored in the green channel

    ...

    COLOR.r = z_new_pos;
    COLOR.g = z_new_neg;
}
</code></pre></div></div>

<p><em>Note that we store “positive” waves in the red and “negative” waves in the green channel. This is not particularly important now and we will explain it later on.</em></p>

<p>You can see that we first read the neighbouring grid values as well as the current and last values at the grid position and then combine them according to our formula. The resulting value is then assigned to <code>COLOR</code>.</p>

<p><code>a</code> can be se at initialisation of the scene as a <code>uniform</code> since the physics frame rate is constant.</p>

<p>We also need a script that updates the simulation as well as grid textures each step. This is done in a script assigned to the <code>Water</code> Node. <code>_update</code> is called each physics frame:</p>

<div><div><pre><code>func _update():
    ...
    update_height_map()

    # Render one frame of the simulation viewport to update the simulation
    simulation_viewport.render_target_update_mode = Viewport.UPDATE_ONCE

    # Wait until the frame is rendered
    yield(get_tree(), "idle_frame")
    ...

func update_height_map():
    # Update the height maps
    var img = simulation_texture.get_data() # Get currently rendered map
    # Set current map as old map
    var old_height_map = simulation_material.get_shader_param("z_tex")
    simulation_material.get_shader_param("old_z_tex") \
        .set_data(old_height_map.get_data())
    # Set the current height map from current render
    simulation_material.get_shader_param("z_tex").set_data(img)
</code></pre></div></div>

<p>And that’s it for our basic simulation. We now know how to propagate waves along the surface but have yet to create them.</p>

<h3 id="creating-waves">Creating waves</h3>

<p>When considering a boat moving through water, we need to be aware of two “types” of waves, <em>bow</em> waves and <em>stern</em> waves. Bow waves are created were the the boat’s hull pushes away the water. Stern waves, on the other hand, are created behind the boat, where water is rushing back to fill the space the boat previously occupied. We thus create <em>positive</em> bow waves in front of the boat and <em>negative</em> stern waves behind the boat. Creating positive or negative waves just means manually setting grid points to positive or negative values.</p>

<p>The intensity of both creatd wave types will also depend on the speed of the boat: The faster the boat, the higher the waves.</p>

<p>In order to create waves we first need to know <em>where</em> to create them. We thus need to know the intersection of the boat’s hull with the water surface.</p>

<p>We use a little trick to accomplish this:</p>

<p>Let’s create a second viewport called <code>CollisionViewport</code>. This viewport will hold the texture which contains the intersection areas of all objects with the surface.</p>

<p>We then add a new camera called <code>CollisionCamera</code> to <code>CollisionViewport</code>. This camera uses on orthogonal projection and has its size set to that of the water surface. The near plane is set to match the water surface and the far plane should be moved sufficiently far away, as shown below.</p>

<p><img width="75%" src="https://raw.githubusercontent.com/CaptainProton42/DynamicWaterDemo/media/viewing_frustum.png"></p>

<p>Next, we add an additional mesh to every node that should be able to create waves and call it <code>CollisionMesh</code>. This mesh defines the hull of our boat.</p>

<p><img width="30%" src="https://raw.githubusercontent.com/CaptainProton42/DynamicWaterDemo/media/collision_mesh.png"></p>

<p>This mesh has a special material which consists of two passes: The first one is a <code>ShaderMaterial</code> with a shader <code>collision.shader</code> that looks like this (this can also be done with a <code>SpatialMaterial</code> but I find this variant to be more verbose):</p>

<div><div><pre><code>shader_type spatial;

uniform float speed;

render_mode cull_front;

void fragment() {
    ALBEDO.r = speed;
}
</code></pre></div></div>

<p>The second pass is just a <code>SpatialMaterial</code> with albedo set to black and a <em>higher</em> render priority (so that front faces are drawn in front of back faces).</p>

<p>The resulting material will draw the <em>inside</em> of the mesh whatever color we set from <code>speed</code> and the <em>outside</em> plain black. Since the camera culls every fragment above the water surface (its near plane), it will draw the colored inside of objects that intersect the surface. The viewport texture will then be black where there is no intersection and colored for all areas where a hull intersects.</p>

<p>We can also give …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://captainproton42.github.io/DynamicWaterDemo/">https://captainproton42.github.io/DynamicWaterDemo/</a></em></p>]]>
            </description>
            <link>https://captainproton42.github.io/DynamicWaterDemo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23633174</guid>
            <pubDate>Wed, 24 Jun 2020 20:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operating Systems via Development]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632833">thread link</a>) | @simedw
<br/>
June 24, 2020 | https://www.theerlangelist.com/article/operating_via_development | <a href="https://web.archive.org/web/*/https://www.theerlangelist.com/article/operating_via_development">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>About two years ago I decided to add HTTPS support to this site, using automatic certification via Let’s Encrypt. All the articles on the subject relied on a tool called <a href="https://certbot.eff.org/">certbot</a>. A couple of variations were mentioned, some requiring the tool to run while the site is down, others using nginx + certbot combination. It seemed that installing and running some additional external tool(s) in production was mandatory.</p>
<p>At that point The Erlangelist was a standalone Elixir-powered system which required no external program. It seemed that now I have to start worrying about setting up additional services and interact with them using their custom DSLs. This would complicate operations, and create a disconnect between production and development. Any changes to the certification configuration would need to be tested directly in production, or alternatively I’d have to setup a staging server. Either way, testing of certification would be done manually.</p>
<p>Unhappy with this state I started the work on <a href="https://hexdocs.pm/site_encrypt/readme.html">site_encrypt</a>, a library which takes a different approach to automatic certification:</p>
<ol>
<li>site_encrypt is a library dependency, not an external tool. You’re not required to install any OS-level package to use it.
</li>
<li>The certification process and periodical renewal are running in the same OS process as the rest of the system. No other OS processes need to be started.
</li>
<li>Everything is configured in the same project where the system is implemented.
</li>
<li>Interaction with site_encrypt is done via Elixir functions and data. No yaml, ini, json, or other kind of DSL is required.
</li>
<li>It’s trivial to run the certification locally, which reduces the differences between prod and local dev.
</li>
<li>The support for automatic testing of the certification is provided. There’s no need to setup staging machines, or make changes directly on the production system.
</li>
</ol>
<p>This is an example of what I call “integrated operations”. Instead of being spread across a bunch of yamls, inis, jsons, and bash scripts, somehow all glued together at the OS-level, most of the operations is done in development, i.e. the same place where the rest of the system is implemented, using the same language. Such approach significantly reduces the technical complexity of the system. The Erlangelist is mostly implemented in Elixir, with only a few administrative tasks, such as installation of OS packages, users creation, port forwarding rules, and similar provisioning tasks being done outside of Elixir.</p>
<p>This also simplifies local development. The <a href="https://github.com/sasa1977/erlangelist/#running-the-site-locally">instructions to start the system locally</a> are very simple:</p>
<ol>
<li>Install build tools (Elixir, Erlang, nodejs)
</li>
<li>Fetch dependencies
</li>
<li>Invoke a single command to start the system
</li>
</ol>
<p>The locally started system will be extremely close to the production version. There is almost nothing of significance running on production which is not running locally. The only two differences of note I can think of are:</p>
<ol>
<li>Ports 80/443 are forwarded in prod
</li>
<li>The prod version uses Lets Encrypt for certification, while the local version uses a local CA server (more on this later).
</li>
</ol>
<p>Now, this may not sound like much for a simple blog host, but behind the scene The Erlangelist is a bit more than a simple request responder:</p>
<ol>
<li>The Erlangelist system runs two separate web servers. The public facing server is the one you use to read this article. Another internal server uses the <a href="https://hexdocs.pm/phoenix_live_dashboard/Phoenix.LiveDashboard.html">Phoenix Live Dashboard</a> to expose some metrics.
</li>
<li>A small hand-made database is running which collects, aggregates, and persists the reading stats, periodically removing older stats from the disk.
</li>
<li>The system periodically renews the certificate.
</li>
<li>Locally and on CI, another web server which acts as a local certificate authority (CA) is running.
</li>
</ol>
<p>In other words, The Erlangelist is more than just a blog, a site, a server, or an app. It’s a system consisting of multiple activities which collectively work together to support the full end-user service, as well as the operational aspects of the system. All of these activities are running concurrently. They don’t block each other, or crash each other. The system utilizes all CPU cores of its host machine. For more details on how this works take a look at my talk <a href="https://www.youtube.com/watch?v=JvBT4XBdoUE">The soul of Erlang and Elixir</a>.</p>
<p>Let’s take a closer look at site_encrypt.</p>
<h2>Certification</h2>
<p>Let’s Encrypt supports automatic certification via the <a href="https://tools.ietf.org/html/rfc8555">ACME (Automatic Certificate Management Environment) protocol</a>. This protocol describes the conversation between the client, which is a system wanting to obtain the certificate for some domain, and the server, which is the certificate authority (CA) that can create such certificate. In ACME conversation, our system asks the CA to provide the certificate for some domain, and the CA asks us to prove that we’re the owners of that domain. The CA gives us some random bytes, and then makes a request at our domain, expecting to get those same bytes in return. This is also called a challenge. If we successfully respond to the challenge, the CA will create the certificate for us. The real story is of course more involved, but this simplified version hopefully gives you the basic idea.</p>
<p>This conversation is an activity of the system. It’s a job which needs to be occasionally done to allow the system to provide the full service. If we don’t do the certification, we don’t have a valid certificate, and most people won’t use the site. Likewise, if I decide to shut the site down, the certification serves no purpose anymore.</p>
<p>In such situations my preferred approach is to run this activity together with the rest of the system. The less fragmented the system is, the easier it is to manage. Running some part of the system externally is fine if there are stronger reasons, but I don’t see such reasons in this simple scenario.</p>
<p><a href="https://hexdocs.pm/site_encrypt/readme.html#quick-start">site_encrypt makes this task straightforward</a>. Add a library dep, fill in some blanks, and you’re good to go. The certification configuration is provided by defining the <code>certification</code> function:</p>
<pre><code><span>def</span><span> </span><span>certification</span><span> </span><span data-group-id="0390845481-1">do</span><span>
  </span><span>SiteEncrypt</span><span>.</span><span>configure</span><span data-group-id="0390845481-2">(</span><span>
    </span><span>client</span><span>:</span><span> </span><span>:native</span><span>,</span><span>
    </span><span>domains</span><span>:</span><span> </span><span data-group-id="0390845481-3">[</span><span>"mysite.com"</span><span>,</span><span> </span><span>"www.mysite.com"</span><span data-group-id="0390845481-3">]</span><span>,</span><span>
    </span><span>emails</span><span>:</span><span> </span><span data-group-id="0390845481-4">[</span><span>"contact@mysite.com"</span><span>,</span><span> </span><span>"another_contact@mysite.com"</span><span data-group-id="0390845481-4">]</span><span>,</span><span>
    </span><span>db_folder</span><span>:</span><span> </span><span>"/folder/where/site_encrypt/stores/files"</span><span>,</span><span>
    </span><span>directory_url</span><span>:</span><span> </span><span>directory_url</span><span data-group-id="0390845481-5">(</span><span data-group-id="0390845481-5">)</span><span>,</span><span>
  </span><span data-group-id="0390845481-2">)</span><span>
</span><span data-group-id="0390845481-1">end</span></code></pre>
<p>This code looks pretty declarative, but it is executable code, not just a collection of facts. And that means that we have a lot of flexibility to shape the configuration data however we want. For example, if we want to make the certification parameters configurable by the system operator, say via a yaml file, nothing stops us from invoking <code>load_configuration_from_yaml()</code> instead of hardcoding the data. Say we want to make only some parameters configurable (e.g. domains and email), while leaving the rest hardcoded. We can simply do <code>Keyword.merge(load_some_params_from_yaml(), hardcoded_data)</code>. Supporting other kinds of config sources, like etcd or a database, is equally straightforward. You can always build declarative on top of imperative, while the opposite will require some imagination and trickery, such as running external configuration generators, and good luck managing that in production :-)</p>
<p>It’s also worth mentioning that site_encrypt internally ships with two lower-level modules, a sort of plumbing to this porcelain. There is a <a href="https://hexdocs.pm/site_encrypt/SiteEncrypt.Acme.Client.html#content">mid-level module</a> which provides workflow-related operations, such as “create an account”, or “perform the certification”, and a <a href="https://hexdocs.pm/site_encrypt/SiteEncrypt.Acme.Client.API.html#content">lower-level module</a> which provides basic ACME client operations. These modules can be used when you want a finer grained control over the certification process.</p>
<h2>Reducing the dev-production mismatch</h2>
<p>There’s one interesting thing happening in the configuration presented earlier:</p>
<pre><code><span>def</span><span> </span><span>certification</span><span> </span><span data-group-id="3249251622-1">do</span><span>
  </span><span>SiteEncrypt</span><span>.</span><span>configure</span><span data-group-id="3249251622-2">(</span><span>
    </span><span># ...</span><span>
    </span><span>directory_url</span><span>:</span><span> </span><span>directory_url</span><span data-group-id="3249251622-3">(</span><span data-group-id="3249251622-3">)</span><span>,</span><span>
  </span><span data-group-id="3249251622-2">)</span><span>
</span><span data-group-id="3249251622-1">end</span></code></pre>
<p>The <code>directory_url</code> property defines the CA where site_encrypt will obtain the certificate. Instead of hardcoding this url, we’re invoking a function to compute it. This happens because we need to use different urls for production vs staging vs local development. Let’s take a look:</p>
<pre><code><span>defp</span><span> </span><span>directory_url</span><span> </span><span data-group-id="5360223777-1">do</span><span>
  </span><span>case</span><span> </span><span>System</span><span>.</span><span>get_env</span><span data-group-id="5360223777-2">(</span><span>"MODE"</span><span>,</span><span> </span><span>"local"</span><span data-group-id="5360223777-2">)</span><span> </span><span data-group-id="5360223777-3">do</span><span>
    </span><span>"production"</span><span> </span><span>-&gt;</span><span> </span><span>"https://acme-v02.api.letsencrypt.org/directory"</span><span>
    </span><span>"staging"</span><span> </span><span>-&gt;</span><span> </span><span>"https://acme-staging-v02.api.letsencrypt.org/directory"</span><span>
    </span><span>"local"</span><span> </span><span>-&gt;</span><span> </span><span data-group-id="5360223777-4">{</span><span>:internal</span><span>,</span><span> </span><span>port</span><span>:</span><span> </span><span>4002</span><span data-group-id="5360223777-4">}</span><span>
  </span><span data-group-id="5360223777-3">end</span><span>
</span><span data-group-id="5360223777-1">end</span></code></pre>
<p>Here, we’re distinguishing production from staging from development based on the <code>MODE</code> OS env (easily replaceable with other source, owing to programmable API). If the env is not provided, we’ll assume that the system running locally.</p>
<p>On a production machine, we go to the real CA, while for staging we’ll use Let’s Encrypt staging site. But what about the <code>{:internal, port: 4002}</code> thing which we use in local development? If we pass this particular shape of data to site_encrypt, an internal ACME server will be started on the given port, a sort of a local mock of Let’s Encrypt. This server is running inside the same same OS process as the rest of the system.</p>
<p>So locally, site_encrypt will start a mock of Let’s Encrypt, and it will use that mock to obtain the certificate. In other words, locally the system will certify itself. Here’s an example of this in action on a local version of The Erlangelist:</p>
<pre><code>$ iex -S mix phx.server

[info]  Running ErlangelistWeb.Blog.Endpoint at 0.0.0.0:20080 (http)
[info]  Running ErlangelistWeb.Blog.Endpoint at 0.0.0.0:20443 (https)
[info]  Running local ACME server at port 20081
[info]  Creating new ACME account for domain theerlangelist.com
[info]  Ordering a new certificate for domain theerlangelist.com
[info]  New certificate for domain theerlangelist.com obtained
[info]  Certificate successfully obtained!</code></pre>
<h2>Testability</h2>
<p>Since local Erlangelist behaves exactly as the real one, we can test more of the system behaviour. For example, even on the local version HTTP requests are redirected to HTTPS. Here’s a test verifying this:</p>
<pre><code><span>test</span><span> </span><span>"http requests are redirected to https"</span><span> </span><span data-group-id="4049071146-1">do</span><span>
  </span><span>assert</span><span> </span><span>redirected_to</span><span data-group-id="4049071146-2">(</span><span>Client</span><span>.</span><span>get</span><span data-group-id="4049071146-3">(</span><span>"http://localhost/"</span><span data-group-id="4049071146-3">)</span><span>,</span><span> </span><span>301</span><span data-group-id="4049071146-2">)</span><span> </span><span>==</span><span>
    </span><span>"https://localhost/"</span><span>
</span><span data-group-id="4049071146-1">end</span></code></pre>
<p>Like…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theerlangelist.com/article/operating_via_development">https://www.theerlangelist.com/article/operating_via_development</a></em></p>]]>
            </description>
            <link>https://www.theerlangelist.com/article/operating_via_development</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632833</guid>
            <pubDate>Wed, 24 Jun 2020 19:35:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom Hires Jason Lee as CISO]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632731">thread link</a>) | @l8rpeace
<br/>
June 24, 2020 | https://blog.zoom.us/zoom-hires-jason-lee-as-chief-information-security-officer/ | <a href="https://web.archive.org/web/*/https://blog.zoom.us/zoom-hires-jason-lee-as-chief-information-security-officer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              
              <div>
                <p><a href="https://blog.zoom.us/author/zoom/" title="Zoom">
                                            <img data-src="https://blog.zoom.us/wp-content/uploads/2020/06/Zoom-Icon-62x62.png" alt="Zoom" title="Zoom" src="https://blog.zoom.us/wp-content/uploads/2020/06/Zoom-Icon-62x62.png">
                                      </a>
                </p>
                <div>
                  <p><a href="https://blog.zoom.us/author/zoom/" title="https://blog.zoom.us/author/zoom/">Zoom</a></p><p>June 24, 2020<span>3 min read</span></p>
              </div>
            </div>
                          <p><img data-src="https://blog.zoom.us/wp-content/uploads/2020/06/Jason-Lee-Headshot.png" alt="Zoom Hires Jason Lee as Chief Information Security Officer" src="https://blog.zoom.us/wp-content/uploads/2020/06/Jason-Lee-Headshot.png">
                                      </p>
                <!--?xml encoding="UTF-8" ?--><p>Today Zoom <a rel="noreferrer noopener" href="http://www.globenewswire.com/news-release/2020/06/24/2052921/0/en/Zoom-Hires-Jason-Lee-as-Chief-Information-Security-Officer.html" target="_blank">announced</a> that Jason Lee will join the company as its Chief Information Security Officer, effective June 29, 2020. Lee brings 20 years of expertise in information security and operating mission-critical services. He was most recently the Senior Vice President of Security Operations at Salesforce, and previously was Principal Director of Security Engineering at Microsoft. Lee will lead Zoom’s security team and report to Aparna Bawa, Zoom’s Chief Operating Officer.&nbsp;</p>



<p>Zoom is nearing the end of its 90-day security and privacy plan, put into place during a time of unprecedented growth that has made Zoom the platform of choice for over 300 million daily meeting participants, including those at some of the world’s largest enterprises. Lee will focus on continuing Zoom’s path of putting the security and privacy of its users first by ensuring that the frictionless and easy-to-use platform remains secure.&nbsp;&nbsp;</p>



<p>“Our customers’ security is extremely important and is at the core of everything we do. We are excited to welcome Jason, who has deep industry experience, understands the complexity of servicing a wide variety of users, and can lead Zoom’s efforts to strengthen the security of our platform during this time of rapid expansion,” said Bawa.</p>



<p>“Zoom is on an incredible journey of growth and I am thrilled to bring my experience of running world-class security organizations to the company. Ensuring that customers trust our products is of the utmost importance and I look forward to working with the team to continue instilling security into the DNA of Zoom,” said Lee.&nbsp;</p>



<h3><strong>About Jason Lee</strong></h3>



<p>Jason Lee is the Chief Information Security Officer at Zoom with 20 years of experience in technology, with a specialization in information security and operating mission-critical services. He was recently the Senior Vice President of Security Operations at Salesforce where he was accountable for the global organization delivering critical end-to-end security operations to customers and employees including company-wide network and system security, incident response, threat intel, data protection, vulnerability management, intrusion detection, identity and access management, and the offensive security team. Prior to Salesforce, he held the position of Principal Director of Security Engineering for the Windows and Devices division in Microsoft with the charter of protecting the online services of Windows Update, XBOX Live, and the Microsoft online store. He was also the Senior Director of Developer Services where he was responsible for the design and management of the mission-critical PKI for all products across Microsoft. This included cryptographic services in products such as Windows and SQL Server, and cloud services such as Azure and Office 365. Additionally, Jason was responsible for the codesigning and anti-malware services supporting Microsoft in that role.</p>
                              
            </div></div>]]>
            </description>
            <link>https://blog.zoom.us/zoom-hires-jason-lee-as-chief-information-security-officer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632731</guid>
            <pubDate>Wed, 24 Jun 2020 19:28:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Types of Indexes in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632663">thread link</a>) | @boshomi
<br/>
June 24, 2020 | https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/ | <a href="https://web.archive.org/web/*/https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
<p>Finding relevant information quickly speeds up performance. For example, while reading a book <span>in which you have to find a topic that you would like to read, if you know that it is in a certain chapter then you will simply go to that chapter, perhaps look through it and start reading the desired topic. </span></p>



<p><span>However if you don’t know then you can consult with the book index that’s usually available at the end of the book first, and find out which pages might list the desired topic. This way you will go only those pages to look for the topic. However if the index is not available then you will have to browse through the whole book looking for the pages of interest. This will obviously consume a lot of time in finding the relevant pages instead of quickly jumping to the desired pages right away.</span></p>



<p><span>The analogy of using a book index for searching the desired pages is similar to searching a database table for the desired tuples. If you can create an index on a database table the query execution may get quite fast and if you don’t have the index then it may end up taking quite a lot of time. I used the word “may” because in some cases a full table scan might be faster than an index scan, we will explore some of these in this blog moving forward.</span></p>



<p><span>PostgreSQL provides a variety of indexes and also quite a number of ways to create these indexes. The blog provides a brief introduction of all the different index types available in PostgreSQL, and also provides some examples to elaborate the index types.</span></p>



<h3><strong>1. B-Tree Index</strong></h3>



<p><span>It is the default index type in PostgreSQL that gets created when you do a ‘CREATE INDEX’ statement without mentioning the index name.</span></p>



<p><span>This index is much suitable for the data that can be sorted and can handle equality and range queries.</span> <span>The following command is used to create a btree index:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table (column); or
CREATE INDEX name ON table USING BTREE (column);</pre>



<h3><strong>2. Hash Index</strong></h3>



<p><span>The hash index prior to PostgreSQL version 10 were almost discouraged for various reasons such as:</span></p>



<ul><li><span>Not WAL logged hence not crash safe</span></li><li><span>Not replicated to stand-by server</span></li><li><span>Performance is not so good and may take a long time to build the index (depending on the&nbsp; table size)</span></li></ul>



<p><span>However since version 10, these problems have been resolved. They are now crash safe and are able to be replicated to standby server. They sometimes perform better than b-tree indexes and are also space efficient.</span></p>



<p><span>The Hash index only works with equality operators that means that you can only look up for data that matches exactly. However it is now much optimized and does a much faster lookup which makes this index a bit of specialized index that can be used where equal comparison is more important. </span><span>The following command is used to create a hash index:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table USING HASH (column);</pre>



<h3><strong>3. Gist Index</strong></h3>



<p><span>Gist or Generalized Search Tree are useful when the data to be indexed is more complex than to do a simple equate or ranged comparison like finding nearest-neighbor and pattern matching. The example of such data includes geometric data, network address comparisons and full-text searches.&nbsp;</span></p>



<p><span>The Gist index itself provides an infrastructure to implement different strategies for indexing data such as B-trees and R-trees. </span><span>The following command is used to create a hash index:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table USING gist (column);</pre>



<h3><strong>4. SP-Gist Index</strong></h3>



<p><span>SP-Gist or Space partitioned Gist indexes are useful when the data can be grouped into non-overlapping groupings. Like Gist index, it also provides an infrastructure for implementing different indexing strategies. However SP-Gist is non-balanced in nature and divides data in partitions, so it allows the implementation of </span><span>quad-trees, k-d trees, and radix trees (tries).</span></p>



<h3><strong>5. Gin Index</strong></h3>



<p><span>Generalized Inverted indexes are useful in indexing data that consist of multiple elements in a single column such as arrays, json documents (jsonb) or text search documents (tsvector).</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table USING gin (column);</pre>



<h3><strong>6. BRIN Index</strong></h3>



<p><span>Block Range Indexes are useful for large size tables that have columns with some natural sort order. The BRIN index divides the table into block ranges and keeps a summary of those blocks. This summary includes min, max values of the range. </span><span>The following command is used to create a hash index:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE INDEX name ON table USING brin (column);</pre>



<p>The above list&nbsp;discribes&nbsp;the available&nbsp;index algorithms&nbsp;availble in&nbsp;postgres database, now lets see&nbsp;some of the characteristics of&nbsp;indexes&nbsp;that&nbsp;can be used to&nbsp;further&nbsp;tweek&nbsp;and&nbsp;enhance&nbsp;the performance of&nbsp;indexes.</p>



<h2><span>Multicolumn Indexes</span></h2>



<p><span>PostgreSQL does allow creation of an index on multiple columns. However you can only have a maximum of 32 columns and such indexes only work with Btree, Gist, Gin and Brin. An example of such index is:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int, y int);
CREATE INDEX multi_idx ON test (x, y);

postgres=# EXPLAIN (costs off) SELECT * from test WHERE x = 10 AND y = 100;
               QUERY PLAN                
-----------------------------------------
 Index Only Scan using multi_idx on test
   Index Cond: ((x = 10) AND (y = 100))
(2 rows)
</pre>



<h2><span>Unique Indexes</span></h2>



<p><span>A unique index enforces the uniqueness of the values in the column. In PostgreSQL a unique index can be created on one or multiple columns. If a unique index is created for multiple columns the uniqueness is ensured using the combined values of columns.&nbsp;however only&nbsp;B-tree&nbsp;index can be&nbsp;declared&nbsp;unique.</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int, y int);
CREATE UNIQUE INDEX unique_idx ON test (x);
postgres=# \d test
                Table "public.test"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Indexes:
    "unique_idx" UNIQUE, btree (x)
</pre>



<p>Let’s create a multi-column index.</p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE UNIQUE INDEX unique_multi_col_idx ON test (x, y);
postgres=# \d test
                Table "public.test"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Indexes:
    "unique_idx" UNIQUE, btree (x)
    "unique_multi_col_idx" UNIQUE, btree (x, y)
</pre>



<p><span>NULL values are not considered equal, hence they are considered unique values. Adding multiple NULLs in a unique column won’t result in index violation.</span></p>



<p><span>Also note that, if you declare a unique constraint or primary key for a column, PostgreSQL automatically creates a unique index. An example of such index is:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int PRIMARY KEY, y int UNIQUE);
postgres=# \d test
                Table "public.test"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           | not null | 
 y      | integer |           |          | 
Indexes:
    "test_pkey" PRIMARY KEY, btree (x)
    "test_y_key" UNIQUE CONSTRAINT, btree (y)
</pre>



<h2><span>Indexes on Expressions</span></h2>



<p><span>It is also possible in PostgreSQL database to create the indexed columns based on the result of a function or scalar expression computed from one or more columns of the table. Since the result of computed expression is stored on the index and it won’t be computed at run time, the access to table data becomes much faster. However the insertion and updation of the data becomes more expensive. Some example of this index are:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int, y text);
postgres=# EXPLAIN (costs off) SELECT * from test WHERE lower(y) = 'value';
              QUERY PLAN              
--------------------------------------
 Seq Scan on test
   Filter: (lower(y) = 'value'::text)
(2 rows)
</pre>



<p><span>Now lets create an indexed expression and see the query again. It should show the index being built using the expression now, instead of the table field.</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">postgres=# CREATE INDEX expr_idx ON test (lower(y));
CREATE INDEX
postgres=# EXPLAIN (costs off) SELECT * from test WHERE lower(y) = 'value';
                   QUERY PLAN                   
------------------------------------------------
 Bitmap Heap Scan on test
   Recheck Cond: (lower(y) = 'value'::text)
   -&gt;  Bitmap Index Scan on expr_idx
         Index Cond: (lower(y) = 'value'::text)
(4 rows)

postgres=# \d test
                Table "public.test"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | text    |           |          | 
Indexes:
    "expr_idx" btree (lower(y)
</pre>



<h2><span>Partial Indexes</span></h2>



<p><span>There are some situations where you don’t want to index the whole table, instead you will want to filter out some specific data based on some conditions. This kind of index is called a partial index. The partial index only contains the data for those rows that fulfill that specific condition.</span></p>



<p><span>These indexes contain a WHERE clause and result in much smaller index sizes than the usual indexes (without conditions). Since they have a smaller footprint, they result in faster data access. An example of such index is:</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">CREATE TABLE test (x int, y text);
postgres=# EXPLAIN (costs off) SELECT * from test WHERE y IS NULL;
      QUERY PLAN       
-----------------------
 Seq Scan on test
   Filter: (y IS NULL)
(2 rows)
</pre>



<p><span>Lets create a partial index</span></p>



<pre data-enlighter-language="sql" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="false" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">postgres=# CREATE INDEX partial_idx ON test (y) WHERE y IS NULL;
CREATE INDEX
postgres=# EXPLAIN (costs off) SELECT * from test WHERE y IS NULL;
               QUERY PLAN               
----------------------------------------
 Bitmap Heap Scan on test
   Recheck Cond: (y IS NULL)
   -&gt;  Bitmap Index Scan on partial_idx
(3 rows)
</pre>



<h2><span>Index-Only Scans</span></h2>



<p><span>Index only scans are the index where all the needed data by the query is available directly from the index. Normally when an index is created, it is stored separately from the table data and whenever a query is executed to fetch the data rows it is …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/">https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/</a></em></p>]]>
            </description>
            <link>https://www.highgo.ca/2020/06/22/types-of-indexes-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632663</guid>
            <pubDate>Wed, 24 Jun 2020 19:24:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why not just use bitmap fonts?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632572">thread link</a>) | @stargrave
<br/>
June 24, 2020 | https://dataswamp.org/~lich/musings/bitmap-fonts.html | <a href="https://web.archive.org/web/*/https://dataswamp.org/~lich/musings/bitmap-fonts.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><small><em>Fri, 26 Jun 2020 14:31:01 +0200</em></small></p>

<p><strong>Disclaimer: In this text, as all of mine, I am writing from a
perspective of a Linux user. Then my remarks won’t hold fully true for
MacOS users or Windows users as their setups might be different.</strong></p>

<p><a href="https://i.pinimg.com/474x/fb/ec/45/fbec45ac5ba8cdee978b3b460f982104.jpg">I am angry. Angry about GNOME and the modern GUI design.</a> After reading
<a href="https://tonsky.me/blog/monitors/">an article by tonsky</a>, I realised how most of projects have forgotten
about bitmap fonts. It is one of these weird occurences, as bitmap
fonts are much simpler to program and use. I think that BDF fonts are
the only font format that is human readable in the raw form.</p>



<p>In his blogpost tonsky argued that you should buy a 4K display as on
lower PPI displays outline fonts look terrible. They do, and it is a
fact for any person that cares about fonts. I hold that at &gt;150 PPI
outline fonts should be auxillary. They ought to be used in the
necessary cases (for example: typesetting, official documents, etc.).
In any other uses, they are unbearable to look at as they are not
designed to work without antialiasing nor hinting.</p>

<p>On the other hand, bitmap fonts are designed <em>against</em> antialising and
hinting. They are not meant to be resized so they stay at maximum in
couple of sizes. That keeps them predictable and efficient. There are
no issues related to bluriness, as pixels themselves are the determine
their borders and they follow the limitations of displays. Their
formats, such as ancient BDF are so simple that they are human
readable. Thus it is much easier to customise, than the sanity
questioning of outline fonts and the hellscape of <code>fontforge(1)</code>.</p>

<p>Look at this code of a glyph (from <a href="https://notabug.org/invest/atarist-lich">Atarist</a> font) in BDF format in 142 bytes.</p>

<pre><code>STARTCHAR HEBREW LETTER HE
ENCODING 1492
SWIDTH 512 0
DWIDTH 8 0
BBX 8 16 0 -2
BITMAP
00
00
7E
7E
06
66
66
66
66
66
66
66
00
00
00
00
ENDCHAR
</code></pre>

<p>You are instantly aware of each element of the glyph and how it will
behave within this format. Such is not as easy for outline fonts. I do
not need to give screenshots to explain what is going on.</p>



<p>As bitmap fonts just became non-standard fonts they are treated worse
than outline fonts. The change in <a href="https://blogs.gnome.org/mclasen/2019/08/07/pango-1-44-wrap-up/">Pango 1.44</a> to only use .otb fonts
which are not something what indsutry was used to. Majority of
software which uses Pango now struggles with .otb bitmap fonts and
gives them wrong outlines, or just does not print them at all (i.e.
zathura or dunst).</p>

<p>The description of the change in Pango 1.44 shows the lack of
responsibiltiy of GNOME developers. They push the task of solving the
issue they created towards ‘the internet community’. These fonts are
supposed be easiest to handle and should not be treated like this.</p>

<p>Also, nobody offers any reliable solution for scaling bitmap fonts on
high DPI displays. There, a simple proportional scaling would be fine
for solving this problem.</p>

<p>I do not want to worry about fonts, I just want them to be readable
and non-blurry on my display. Such is not achievable (on low PPI
displays) with greatly promoted outline fonts. That’s that. When I
want a high PPI display, then I can use my e-reader, or better yet -
print it.</p>
</article></div>]]>
            </description>
            <link>https://dataswamp.org/~lich/musings/bitmap-fonts.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632572</guid>
            <pubDate>Wed, 24 Jun 2020 19:17:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memorable Passwords]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23632533">thread link</a>) | @espadrine
<br/>
June 24, 2020 | https://espadrine.github.io/blog/posts/memorable-passwords.html | <a href="https://web.archive.org/web/*/https://espadrine.github.io/blog/posts/memorable-passwords.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <article>

<p>We are slowly getting to a comfortable password situation.</p>
<p>Research has improved on which passwords are easier to remember.
Cryptographers have <a href="https://password-hashing.net/argon2-specs.pdf">strenghtened the cost</a> of cracking weak passwords.
People are more aware of the security risks,
and the usage of password managers grows.</p>
<p>The consensus on password handling is this:</p>
<ol>
<li>Keep a very strong master password in your head, stored nowhere.</li>
<li>Use it to unlock your password manager.</li>
<li>Use your password manager to store and create very random passwords for individual websites.
You would never be able to remember them, but you only need to remember the master password.
Typically, for alphanumerical outputs, you need ⌈128÷log2(26·2+10)⌉ = 22 characters.</li>
<li>The websites, and more importantly, the password manager,
use a key derivation function such as <a href="https://password-hashing.net/argon2-specs.pdf">Argon2</a> either on the front-end
(server relief) or on the backend, and only stores the output.
It ensures computation is both time-hard and memory-hard, with settings kept up-to-date
to ensure that each computation takes 0.5 seconds and/or 4 GB of RAM.</li>
</ol>
<p>But some details are left unset: exactly how strong should the master password be?
How do we even know?
Can this situation converge to an easier user experience for login on the Web?</p>
<h2>Password hashing</h2>
<p>Some accurate statements may be surprising to the general population.
This is one:</p>
<p><strong>Multiple passwords can unlock your account.</strong></p>
<p>The reason? Your password is not compared byte-for-byte (thankfully!)
but through a hashing method that does not map one-to-one.</p>
<p>Indeed, hashes have fixed sizes (typically 256 bits),
while passwords have arbitrary length.</p>
<p>Overall, this consideration is unimportant,
because virtually no password is strong enough
to even compete with the collision risk of the hash:
it is tremendously more likely for a collision to be caused by
the generation process, than by the hash,
whose collision risk is 2<sup>N÷2</sup>
where N is the size of the hash, typically 256 bits nowadays.</p>
<p>On top of this, some companies build their login system
in a way that is more resilient to user error,
such as <a href="https://www.zdnet.com/article/facebook-passwords-are-not-case-sensitive-update">having caps lock on</a>.</p>
<p>That too is irrelevant, since the search space is typically only reduced
by one bit (corresponding to the choice between setting caps lock or not).</p>
<h2>Target strength</h2>
<p><a href="https://crypto.stackexchange.com/questions/60815/recommended-minimum-entropy-for-online-passwords-in-2018">Some suggestions target specific cryptographic algorithms</a>.
But this pushes machine limits into human constraints:
algorithms require 128-bit security, not because 127 is not enough,
but because it is a power of two that neatly fits with various engineering techniques.</p>
<p>The real human constraint is your lifetime.
Once you are dead, it does not matter too much to your brain whether your secrets are out,
since your brain becomes mulch.</p>
<p>The longest person alive is a French woman that died nearly reaching 123.
Let’s imagine that health will improve
such that someone will live double that amount, Y = 246 years.
What is the minimum strength needed to ensure they won’t have their secrets cracked alive?</p>
<p>Current compute costs hover around €3/month on low-end machines.
Let’s imagine that it will improve a hundredfold in the coming century.</p>
<p>The NSA yearly budget is estimated at B = €10 billion.
Can they hack you before you die?</p>
<p>First, under those assumptions,
assuming the NSA consumes its whole budget cracking you,
how many computers will it use to crack you in parallel?
The result is P = B ÷ 12 ÷ 0.03 = 28 billion servers.</p>
<p>If your password has an N-bit entropy,
it will take 2<sup>N-1</sup>·0.005÷P÷3600÷24÷365 years on average,
assuming the NSA is brute-forcing with CPUs that can do one attempt every 5 milliseconds
(a hundredth of the <a href="https://password-hashing.net/argon2-specs.pdf">Argon2</a> recommended setting,
to account for the possibility that the NSA has machines a hundred times more powerful
than the rest of us, which is both unlikely, and would not cost what we estimated).</p>
<p>As a result, our formula for picking strength is
N = log2(B÷12÷0.03 · Y·365·24·3600÷0.005) + 1 = 77 bits of security.</p>
<p>Note that we can assume that a good KDF is used,
since we are only worried about password strength for the password manager,
which should be pretty good at choosing the right design.
The password manager will generate all normal passwords above 128 bits of security anyway.
(Except for those pesky websites that inexplicably have an upper password length limit.
But those are beyond saving.)</p>
<p>I parameterized some values so that you can plug your own situation.
For instance, if you make a password for your startup
that you believe will beat the odds of an average 5-year lifespan,
and become a behemoth a thousand years into the future, you can set Y = 1000
and get a very slight increase to 79 bits.</p>
<p>If you instead believe that your adversary will spend a trillion euros every year,
you can bump things up to 83 bits of security.</p>
<h2>Master password generation</h2>
<p>How do you convert a number of bits of security into a master password?
Well, those bits represent the amount of entropy of the random generator.
Or in other words, the quantity of uncertainty of the password-making process.</p>
<p>Each bit represents one truly random choice between two options.
If you have four options, it is as if you made two choices, and so on.</p>
<p>A good way to make memorable master passwords is to pick words among large dictionaries,
since picking from a long list adds a lot of entropy (since there are so many binary choices)
but each word is very distinctively evocative.</p>
<p>However, each word is independent, and therefore,
making stories in your head that combines those words gets harder the more words there are.
So we randomize the word separators as symbols,
which both adds entropy (so that we can have less words),
and is not too hard to remember. Besides, breaking words apart ensures that
we don’t lose entropy by ending up with two words that, concatenated,
are actually a single word from the same dictionary.</p>
<p>I implemented these principles on <a href="https://espadrine.github.io/passphrase/">this passphrase generation page</a>.</p>
<h2>Thank you, Next</h2>
<p>I feel strongly that passwords are passé.
I would love to talk about my hopes for the future of Web authentication.</p>
<p><a href="https://www.reddit.com/r/programming/comments/hf63bp/generate_cryptographically_secure_passphrases_at/">Reddit comments here</a>.
<a href="https://news.ycombinator.com/item?id=23632533">HN comments here</a>.</p>

    
  </article>
</div></div>]]>
            </description>
            <link>https://espadrine.github.io/blog/posts/memorable-passwords.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23632533</guid>
            <pubDate>Wed, 24 Jun 2020 19:15:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolution of Precomputation Technology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23631987">thread link</a>) | @samanticora
<br/>
June 24, 2020 | https://kyligence.io/blog/the-evolution-of-precomputation-technology/ | <a href="https://web.archive.org/web/*/https://kyligence.io/blog/the-evolution-of-precomputation-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                
<div><figure><img src="https://siteprod-s3-azcdn.kyligence.io/2020/06/Evolution.png" alt="Precompute Evolution" srcset="https://siteprod-s3-azcdn.kyligence.io/2020/06/Evolution.png 558w, https://siteprod-s3-azcdn.kyligence.io/2020/06/Evolution-300x152.png 300w" sizes="(max-width: 558px) 100vw, 558px"></figure></div>



<p>Precomputation is commonly used in information retrieval and analysis. With precomputation, we compute the results once and then store them in a table or other data structure, either on a disk or in memory. In this table, each input (or combination of inputs) maps to an output value. In order to answer a question, we just need to find the output value corresponding to the input value(s). </p>







<h2>Early Forms of Precomputation</h2>



<div><figure><img src="https://siteprod-s3-azcdn.kyligence.io/2020/06/Multiplication-Table.png" alt="Figure 1: Multiplication Table (Wikipedia.org)"><figcaption><strong>Figure 1: Multiplication Table (Wikipedia.org)</strong></figcaption></figure></div>



<p> The form you are likely familiar with, and probably the most common form of precomputation, is the multiplication table (Figure 1). In this table, to find the result of 7*8, all you need to do is find row 7 (or 8) and then move across to column 8 (or 7) â€“ and there is your answer: 56! Most of us memorized the multiplication table in grade school, so we donâ€™t even realize that we are actually using this table when we perform these operations now.</p>



<div><figure><img src="https://siteprod-s3-azcdn.kyligence.io/2020/06/Logarithms-Table.png" alt="Figure 2: Logarithms Table (Wikipedia.org) " srcset="https://siteprod-s3-azcdn.kyligence.io/2020/06/Logarithms-Table.png 304w, https://siteprod-s3-azcdn.kyligence.io/2020/06/Logarithms-Table-300x241.png 300w" sizes="(max-width: 304px) 100vw, 304px"><figcaption><strong>Figure 2: Logarithms Table (Wikipedia.org)</strong> </figcaption></figure></div>



<p> Another, more advanced, example of precomputation is the logarithms table (Figure 2). If you donâ€™t remember how to use it, Iâ€™m sure youâ€™re not alone. Fun fact: The first tables of logarithms were published independently by Scottish mathematician John Napier in 1614 and Swiss mathematician Justus Byrgius in 1620. Napier actually started his work in 1594 and it took him 20 years to complete the tables </p>







<h2>From Database to Big Data to The Cloud</h2>



<p>Precomputation has been used in databases for many years. To
save time on joining tables and calculating columns, we can run these queries
upfront and save the results into materialized views. Future queries will be
directed to these materialized views to retrieve their results.</p>



<p>In 1993, Edgar F. Codd, the father of the relational database, coined the term <a href="https://kyligence.io/apache-kylin-overview/" target="_blank" rel="noreferrer noopener" aria-label="OLAP (opens in a new tab)">OLAP</a> for On-Line Analytical Processing in a white paper published by Arbor Software. In OLAP, transactional data is extracted from operational systems and loaded into data warehouses where data is organized for fast reporting performance. However, the query performance is still not satisfactory for interactive analysis. </p>



<p>For this purpose, OLAP systems calculate common queries from data warehouses and store those results in a data structure called a cube. When an OLAP product receives a query, it simply looks up the data already stored in the cube and fetches the result. This method significantly reduces query times. Over time, â€œOLAPâ€� and â€œCubeâ€� became synonyms, although, later â€œOLAPâ€� was expanded into <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Online_analytical_processing#Multidimensional_OLAP_(MOLAP)" target="_blank">MOLAP</a>, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Online_analytical_processing#Relational_OLAP_(ROLAP)" target="_blank">ROLAP</a>, and <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Online_analytical_processing#Hybrid_OLAP_(HOLAP)" target="_blank">HOLAP</a> architectures. </p>



<div><figure><img src="https://siteprod-s3-azcdn.kyligence.io/2020/06/Data-Cube.png" alt="Data Cube" srcset="https://siteprod-s3-azcdn.kyligence.io/2020/06/Data-Cube.png 320w, https://siteprod-s3-azcdn.kyligence.io/2020/06/Data-Cube-300x259.png 300w" sizes="(max-width: 320px) 100vw, 320px"></figure></div>



<p>As illustrated in the cube diagram here, if you need to analyze sales volume based on three attributes â€“ e.g. Products, Cities, and Time â€“ you can create a three-dimensional cube. This cube is basically a three-dimensional spreadsheet. </p>



<p>Keep in mind that although the data structure is called a <em>cube</em>, in reality most applications have more than three dimensions, but obviously there is no easy way to illustrate that in a diagram. OLAP cubes became quite popular in late 90sâ€™ with products like <a rel="noreferrer noopener" aria-label="Microsoft SSAS (opens in a new tab)" href="https://kyligence.io/solution/replace-ssas-and-scale-olap%e2%80%8b/" target="_blank">Microsoft SSAS</a>, <a href="https://kyligence.io/solution/cognos-olap%e2%80%8b-migration/" target="_blank" rel="noreferrer noopener" aria-label="Cognos (opens in a new tab)">Cognos</a>, MicroStrategy, etc. </p>



<p>In the big data and cloud era, we have seen various
technologies try to address query performance issues for large volumes of data.
From query engines to cloud data warehouses to data virtualization products,
these technologies use different forms of MPP (Massive Parallel Processing)
architecture. Although they have improved dramatically over the years, their
performances still degrade when running complex aggregate queries against a large
amount of data.</p>



<p>Caching, as a special type of precomputation, is commonly used by these products to improve performance. Query engines cache result sets in memory so the exact same query can reuse the same result set. Cloud Data Warehouses bring tables into the compute layer to avoid future network traffic between the compute and storage layers. </p>



<p>These techniques can speed up a very limited subset of queries and donâ€™t really solve the fundamental problem â€“ they donâ€™t truly support citizen analysts conducting ad-hoc analysis on large amounts of data, at the speed of thought. </p>







<h2>Kyligence â€“ A New Generation of Precomputation Technology</h2>



<p>Kyligence fundamentally changes how modern analytics is done with its breakthrough precomputation technology. When <a href="https://kyligence.io/blog/apache-kylin-through-the-eyes-of-the-founders-episode-one/" target="_blank" rel="noreferrer noopener" aria-label="the creators of the Apache Kylin project (opens in a new tab)">the creators of the Apache Kylin project</a> founded the company back in 2016, they had a vision to create a platform that could enable citizen analysts to do their jobs without worrying about the size of their data and the number of concurrent users. Today, its products are being used by some of the world largest banks, insurance companies, retailers, manufacturers, and so on.</p>







<p><strong>Know the Questions Before They Are Asked</strong></p>



<p>Wouldnâ€™t it be nice to be fully prepared and know all the questions you will be asked before you walk into an interview? Thatâ€™s exactly the approach Kyligence takes. By learning past query histories, analystsâ€™ behaviors, data profiles, and system logs, Kyligence automatically predicts the common questions people ask, and prepares answers based on its predictions. </p>



<p>This process is driven by its AI engine, and the more queries it processes, the more accurately it predicts the questions. The system analysts can further optimize the AI engineâ€™s work based on human knowledge about their business processes. </p>







<p><strong>Blazing Fast Processing Speed</strong></p>



<p>Knowing what questions users are going to ask is just the first step. The software needs to prepare the answers in time so they are available when users need them. This is the â€˜computeâ€™ part of precomputation technology. Kyligenceâ€™s Spark-based compute engine adopts many optimization techniques to speed up the building of aggregate indexes. </p>



<p>In addition to the typical batch mode, indexes can also be refreshed through a pre-scheduled incremental load, or real-time updates from messaging products such as Kafka. The fast processing speed allows users to incorporate the latest information into the aggregate index and gives them the most accurate picture of their business.</p>







<p><strong>Built for the Modern Data Platform</strong></p>



<p>Kyligenceâ€™s flagship products, <a rel="noreferrer noopener" aria-label="Kyligence Cloud (opens in a new tab)" href="https://kyligence.io/kyligence-cloud/" target="_blank">Kyligence Cloud</a> and <a href="https://kyligence.io/kyligence-enterprise/" target="_blank" rel="noreferrer noopener" aria-label="Kyligence Enterprise (opens in a new tab)">Kyligence Enterprise</a>, are built from the ground up for the modern data platform. They leverage the latest technologies to increase manageability and reduce infrastructure cost. </p>



<p>In the cloud, Kyligence can be deployed on AWS, Azure, and Google Cloud, either directly from the Kyligence portal or through the AWS and Azure Marketplace. It works with modern Cloud Data Warehouses as well as cloud data storage systems. Kyligence Cloud takes advantage of the elasticity of the cloud platform so that enterprises donâ€™t have to overpay for infrastructure and still have the capability to support usage spikes. </p>







<p><strong>Unlimited Scale</strong></p>



<p>Kyligenceâ€™s aggregate index is stored in Parquet files, a modern storage format best suited for analytics workloads. The aggregate index is stored either in cloud object stores or on Hadoop File Systems, when deployed on-premises. This type of distributed storage makes it possible to build an aggregate index 100s of times larger than other precomputation products. </p>



<p>One of our clients stores petabytes of data in the aggregate index so that <em>all</em> historical information is <em>always</em> available for their analysts. Businesses no longer have to choose between having complete access to historical data and the speed of their analytics.</p>







<p><strong>Constantly Improving</strong></p>



<p>Traditional precomputation products, such as OLAP Cubes, were very rigid. Adding an extra measure or dimension meant you had to rebuild the cubes, which lead to extra development costs and system downtime. Kyligence can handle the source schema changes and adjust measures and dimensions accordingly, and conveniently update the aggregate index. </p>



<p>The system also automatically adjusts the index to balance the often-conflicting requirements of query performance, storage space, update time, etc. Users can adjust these settings and the software will train itself to fine tune the indexes based on user behaviors.</p>







<h2>Summary<br></h2>



<p>In this blog, we looked at the history of precomputation and introduced Kyligenceâ€™s game-changing precomputation technology. This technology opens the doors for enterprises and their data scientists to conduct analytics at unprecedented speed and scale.</p>
                            </div></div>]]>
            </description>
            <link>https://kyligence.io/blog/the-evolution-of-precomputation-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631987</guid>
            <pubDate>Wed, 24 Jun 2020 18:33:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Device Firmware Update Cookbook]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23631985">thread link</a>) | @fra
<br/>
June 24, 2020 | https://interrupt.memfault.com/blog/device-firmware-update-cookbook | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/device-firmware-update-cookbook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>Implementing OTA (Over The Air) firmware updates is a rite of passage for
firmware engineers. Device firmware update is a key component of most hardware
projects. Often, it is also one of the more complicated components.</p>

<p>I have worked on multiple firmware update systems over the year, and every time
I have learned something new. How do I package my images? How do I make sure I
don’t brick the device? How do I share information between my bootloader and my
application? Little by little all firmware engineers accumulate answers to
those questions and develop favored design patterns.</p>

<!-- excerpt start -->
<p>In this post, I share the device firmware update architecture I would implement
knowing everything I know now. I also highlight a few design patterns that are
particularly useful. The example comes with a fully functional example of a
multi-stage bootloader with DFU functionality.
<!-- excerpt end --></p>

<p>I learned some of these lessons in this post the hard way, and I hope I can spare
you and your colleagues a few sleepless nights spent debugging firmware update
problems in the wild!</p>

<p><em>Like Interrupt? <a href="http://eepurl.com/gpRedv">Subscribe</a> to get our latest posts
straight to your mailbox</em></p>

<h2 id="table-of-contents">Table of Contents</h2>

<!-- prettier-ignore -->
<ul id="markdown-toc">
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of Contents</a></li>
  <li><a href="#setup" id="markdown-toc-setup">Setup</a>    <ul>
      <li><a href="#renode" id="markdown-toc-renode">Renode</a></li>
      <li><a href="#toolchain" id="markdown-toc-toolchain">Toolchain</a></li>
      <li><a href="#building--running-the-example" id="markdown-toc-building--running-the-example">Building &amp; Running the Example</a></li>
    </ul>
  </li>
  <li><a href="#high-level-architecture" id="markdown-toc-high-level-architecture">High-Level Architecture</a>    <ul>
      <li><a href="#dfu-should-be-separate-from-the-application" id="markdown-toc-dfu-should-be-separate-from-the-application">DFU should be separate from the application</a></li>
      <li><a href="#dfu-code-should-be-updatable" id="markdown-toc-dfu-code-should-be-updatable">DFU code should be updatable</a></li>
      <li><a href="#dfu-should-use-minimal-code-space" id="markdown-toc-dfu-should-use-minimal-code-space">DFU should use minimal code space</a></li>
      <li><a href="#dfu-failures-should-not-brick-the-device" id="markdown-toc-dfu-failures-should-not-brick-the-device">DFU failures should not brick the device</a></li>
    </ul>
  </li>
  <li><a href="#design-patterns--recipes" id="markdown-toc-design-patterns--recipes">Design Patterns &amp; Recipes</a>    <ul>
      <li><a href="#image-metadata" id="markdown-toc-image-metadata">Image Metadata</a></li>
      <li><a href="#loading-images" id="markdown-toc-loading-images">Loading Images</a></li>
      <li><a href="#writing--committing-images" id="markdown-toc-writing--committing-images">Writing &amp; Committing Images</a></li>
      <li><a href="#shared-memory" id="markdown-toc-shared-memory">Shared Memory</a></li>
      <li><a href="#boot-stability" id="markdown-toc-boot-stability">Boot Stability</a></li>
    </ul>
  </li>
  <li><a href="#closing" id="markdown-toc-closing">Closing</a></li>
</ul>

<h2 id="setup">Setup</h2>

<p>All the code in this post was written for the STM32F429 MCU by ST Micro. While
the examples run fine on the STM32F429i discovery board they were developed in
Renode, a popular MCU emulation platform.</p>

<p>You can find the complete code example for this blog post in the <a href="https://github.com/memfault/interrupt/tree/master/example/fwup-architecture">Interrupt
Github repository</a></p>

<h3 id="renode">Renode</h3>

<p>Since writing about Renode for Interrupt, I’ve been looking for an opportunity
to use it for another project. This blog post was the perfect pretext. If you
are not familiar with Renode, I recommend reading <a href="https://interrupt.memfault.com/intro-to-renode">my previous blog post</a> on
the topic.</p>

<p>Because we use true firmware images <code>.bin</code>’s rather than <code>elf</code> files in this post, I had to make two
change to the Renode configuration:</p>

<ol>
  <li>I used <code>sysbus LoadBinary $bin 0x8000000</code> rather than <code>LoadELF</code> to load the
firmware.</li>
  <li>I manually set the Vector Table Offset with <code>sysbus.cpu VectorTableOffset
0x8000000</code>. By default, Renode looks for the vector table at <code>0x0</code> which
different from the default behavior of the STM32.</li>
</ol>

<p>Additionally, I had to modify Renode slightly to enable software-controlled
resets. Cortex-M microcontrollers can be reset by writing to the AICR register,
which was not fully implemented in the emulator. As of this writing, this change
is still in review and not yet merged into the emulator. You can find the pull
request <a href="https://github.com/renode/renode-infrastructure/pull/15/files">on Github</a>.</p>

<p>Thankfully, building our own version of Renode is relatively
straightforward using <a href="https://renode.readthedocs.io/en/latest/advanced/building_from_sources.html">their
instructions</a>.</p>

<p>I updated my <code>start.sh</code> script to run my home-built Renode instance rather than
the installed binary:</p>

<div><div><pre><code><span>#!/bin/sh</span>

<span>RENODE_EXE_PATH</span><span>=</span>~/code/renode/output/bin/Release/Renode.exe

mono64 <span>$RENODE_EXE_PATH</span> renode-config.resc
</code></pre></div></div>

<p>You will have to update this script to point at your own <code>Renode.exe</code>.</p>

<h3 id="toolchain">Toolchain</h3>

<p>I used the following tools to build my firmware:</p>
<ul>
  <li>GNU Make 4.2.1 as the build system</li>
  <li><code>arm-none-eabi-gcc</code> version 9.2.1 20191025 (release) as compiler</li>
</ul>

<p>Rather than the STM32Cube HAL, I used an open source MCU HAL called <code>libopencm3</code>
with excellent support for the STM32. I find it easier to use, and like that it
is open source and on Github. The included <code>Makefile</code> will clone <code>libopencm3</code>
during your first build.</p>

<h3 id="building--running-the-example">Building &amp; Running the Example</h3>

<p>The example can be built with Make. From the <code>examples/fwup-architecture</code>
directory:</p>

<div><div><pre><code><span>$</span> make
<span>  LD            build/fwup-example-boot.elf
  OBJCOPY       build/fwup-example-boot.bin
  LD            build/fwup-example-app.elf
  OBJCOPY       build/fwup-example-app.bin
  XXD           build/app_bin.c
  LD            build/fwup-example-loader.elf
  OBJCOPY       build/fwup-example-loader.bin
  CAT           build/fwup-example.bin
</span></code></pre></div></div>

<p>After which you can call <code>./start.sh</code> to start Renode. You will need to type the
<code>start</code> command in the Renode window to get the emulation going.</p>

<p><img src="https://interrupt.memfault.com/img/fwup-architecture/renode-running.png" alt=""></p>

<h2 id="high-level-architecture">High-Level Architecture</h2>

<p>Over the years, I’ve come up with a set of basic requirements most DFU systems
should fulfill. Let’s walk through these one by one and iteratively design our
system.</p>

<p>We start with the simplest possible description of what we want to achieve with
DFU: an application that updates itself.</p>



<p>
  <svg viewBox="0 0 256 120" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
   // Set labels to nodes.
   A [label = "Application"];
   A -&gt; A [label = "Updates", fontsize=8];
}
</desc>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="67" y="46"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="64" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="128" y="66">Application</text>
  <path d="M 192 60 L 208 60" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 208 60 L 208 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 128 25 L 208 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 128 25 L 128 32" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="128,39 124,32 132,32 128,39" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="46" x="153" y="4"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="30" x="176" y="14">Updates</text>
</svg>

</p>

<p>This is not a practical design. For one, self-modifying code is easy
to mess up. Let’s see how we might modify this architecture to get to something
we’re happy with.</p>

<h3 id="dfu-should-be-separate-from-the-application">DFU should be separate from the application</h3>

<p>The only time I ever broke DFU on a device, I did it without changing a line of
code related to DFU. Unbeknownst to me, our DFU processes accidentally depended on an
uninitialized variable which up until then had always ended up being <code>0</code>.
Inevitably a new version reshuffled the content of the stack, and all of a
sudden our uninitialized variable held a “1”. This prevented DFU from taking
place.<sup id="fnref:chris-dfu-debug"><a href="#fn:chris-dfu-debug">1</a></sup></p>

<p>The moral to this story: keep your DFU process and your application code
separate. Firmware update code is critical and should not be changed unless
absolutely necessary. Separating application code from firmware update code
allows us to update our application code without risking problems with DFU.</p>

<p>How do we modify our architecture to meet this requirement? We simply split the
firmware into a “Loader” and an “Application”. The loader verifies the
application, runs it, and can update it.</p>



<p>
  <svg viewBox="0 0 556 120" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
    span_width = 100;
    // Set labels to nodes.
    A [label = "App Loader"];
    B [label = "Application"];
    A -&gt; B [label = "Loads, Updates", fontsize=8];
}
</desc>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="103" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="46"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="100" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="164" y="66">App Loader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="392" y="66">Application</text>
  <path d="M 228 60 L 320 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,60 320,56 320,64 327,60" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="39"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="49">Loads, Updates</text>
</svg>

</p>

<h3 id="dfu-code-should-be-updatable">DFU code should be updatable</h3>

<p>While we want to update our DFU code as little as possible, updating it should
still be <em>possible</em>. Inevitably we will find a bug in our firmware update code
which we must fix. We may want to change our memory map to allocate more code
space to our app, or to rotate a security key baked into our Loader.</p>

<p>But where should the code that updates our Loader live? It cannot be in the
application, or else we would violate the previous principle. It cannot be in
the Loader itself either. That leaves one option: a third program tasked with
updating the loader. We’ll call it the “Updater”.</p>

<p>The Updater is loaded by the Loader, perhaps when a specific input is received.
All it knows how to do is update the Loader.</p>



<p>
  <svg viewBox="0 0 556 200" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
    span_width = 100;
    // Set labels to nodes.
    A [label = "App Loader"];
    B [label = "Application"];
    A -&gt; B [label = "Loads, Updates", fontsize=8];

    E [label = "Updater"];
    A -&gt; E [label = "Loads, Updates", fontsize=8];
    E -&gt; A [label = "Updates", fontsize=8];
}
</desc>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="103" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="126"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="100" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="164" y="66">App Loader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="392" y="66">Application</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="120"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="42" x="392" y="146">Updater</text>
  <path d="M 228 60 L 320 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,60 320,56 320,64 327,60" stroke="rgb(0,0,0)"></polygon>
  <path d="M 228 60 L 278 60" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 278 60 L 278 140" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 278 140 L 320 140" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,140 320,136 320,144 327,140" stroke="rgb(0,0,0)"></polygon>
  <path d="M 456 140 L 481 140" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 481 140 L 481 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 164 25 L 481 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 164 25 L 164 32" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="164,39 160,32 168,32 164,39" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="39"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="49">Loads, Updates</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="119"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="129">Loads, Updates</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="46" x="458" y="104"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="30" x="481" y="114">Updates</text>
</svg>

</p>

<h3 id="dfu-should-use-minimal-code-space">DFU should use minimal code space</h3>

<p>Every firmware project I’ve ever worked on has run out of code space. At Pebble,
we spent months porting our 3.0 firmware to the original watch; most of that
time was spent slimming down the code so it could fit within the 512KB of Flash
available on that device<sup id="fnref:pebble-3"><a href="#fn:pebble-3">2</a></sup>.</p>

<p>With that in mind, we should make sure our Loader and Updater do not take more
code space than absolutely necessary. Are there ways we can update our design to
use less code space? Absolutely!</p>

<p>The key insight here is that the Updater needs to run very rarely and that it
never needs to coexist with the application. We can, therefore, use the same
“slot” in flash for both the Updater and the Application. The main tradeoff here
is that our Loader update flow becomes more complicated as we need to do a DFU
to get the Updater, then another to update the loader, then a third to load the
application back. In other words:</p>

<p>Go to Loader → DFU Updater in the Application’s place → Load Updater →
DFU the new Loader → Reboot into Loader → DFU the Application back in its slot</p>

<p>We can tolerate this complexity because it should not be used often.</p>

<p>
  <svg viewBox="0 0 556 200" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
    span_width = 100;
    // Set labels to nodes.
    A [label = "App Loader"];
    B [label = "Application"];
    A -&gt; B [label = "Loads, Updates", fontsize=8];

    E [label = "Updater"];
    A -&gt; E [label = "Loads, Updates", fontsize=8];
    E -&gt; A [label = "Updates", fontsize=8];

    group {
        label = "Slot 1";
        color = "LightPink";
        A;
    }
    group {
        label = "Slot 2";
        color = "LemonChiffon";
        B; E;
    }
}
</desc>
  <rect fill="rgb(255,182,193)" height="60" style="filter:url(#filter_blur)" width="152" x="88" y="30"></rect>
  <rect fill="rgb(255,250,205)" height="140" style="filter:url(#filter_blur)" width="152" x="316" y="30"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="103" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="126"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="100" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="164" y="66">App Loader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="392" y="66">Application</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="120"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="42" x="392" y="146">Updater</text>
  <path d="M 228 60 L 320 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,60 320,56 320,64 327,60" stroke="rgb(0,0,0)"></polygon>
  <path d="M 228 60 L 278 60" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 278 60 L 278 140" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 278 140 L 320 140" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="327,140 320,136 320,144 327,140" stroke="rgb(0,0,0)"></polygon>
  <path d="M 456 140 L 481 140" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 481 140 L 481 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 164 25 L 481 25" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 164 25 L 164 32" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="164,39 160,32 168,32 164,39" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="39"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="49">Loads, Updates</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="77" x="240" y="119"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="61" x="278" y="129">Loads, Updates</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="46" x="458" y="104"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="30" x="481" y="114">Updates</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="164" y="36">Slot 1</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="392" y="36">Slot 2</text>
</svg>

</p>

<h3 id="dfu-failures-should-not-brick-the-device">DFU failures should not brick the device</h3>

<p>This one should be obvious. Whether there is a bug in our DFU process, or a power loss event while we are
writing firmware, the device should be able to recover. It may operate in a
degraded mode for a bit, but it should at least be able to update itself back to
a good state.</p>

<p>Our design already does a reasonable job of this: if we lose power in the middle
of an Application update, we can reboot into our Loader and start our update
again. There are however two failure modes we must deal with.</p>

<p>First, in the event we lose power while updating the Loader, we could find
ourselves with no valid image at the address the chip boots from (<code>0x0</code> by
default for Cortex-M, but aliased to <code>0x80000000</code> on STM32). The solution is to
add a small, immutable bootloader whose sole job is to sit at the start address
and load our Loader.</p>

<p>Second, what happens if we find ourselves without a functional Loader? We would
want to fall back to the Updater. Here again, the small bootloader is the
solution. In the event no valid Loader is found, it should try to load whatever
is found in the “Application” slot.</p>



<p>
  <svg viewBox="0 0 784 280" xmlns="http://www.w3.org/2000/svg" xmlns:inkspace="http://www.inkscape.org/namespaces/inkscape" xmlns:xlink="http://www.w3.org/1999/xlink">
  <defs id="defs_block">
    <filter height="1.504" id="filter_blur" inkspace:collect="always" width="1.1575" x="-0.07875" y="-0.252">
      <feGaussianBlur id="feGaussianBlur3780" inkspace:collect="always" stdDeviation="4.2"></feGaussianBlur>
    </filter>
  </defs>
  <title>blockdiag</title>
  <desc>
blockdiag {
    span_width = 100;
    // Set labels to nodes.
    C [label = "Bootloader"];
    A [label = "App Loader"];
    B [label = "Application"];
    C -&gt; A [label = "Loads", fontsize=8];
    A -&gt; B [label = "Ld, Updt", fontsize=8];

    E [label = "Updater"];
    A -&gt; E [label = "Ld, Updt", fontsize=8];
    E -&gt; A [label = "Updates", fontsize=8];
    C -&gt; E [label = "Loads", style=dashed, fontsize=8];

    group {
        label = "Slot 0";
        color = "PaleGreen";
        C;
    }
    group {
        label = "Slot 1";
        color = "LightPink";
        A;
    }
    group {
        label = "Slot 2";
        color = "LemonChiffon";
        B; E;
    }
}
</desc>
  <rect fill="rgb(152,251,152)" height="60" style="filter:url(#filter_blur)" width="152" x="88" y="30"></rect>
  <rect fill="rgb(255,182,193)" height="60" style="filter:url(#filter_blur)" width="152" x="544" y="30"></rect>
  <rect fill="rgb(255,250,205)" height="140" style="filter:url(#filter_blur)" width="152" x="316" y="110"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="103" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="559" y="46"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="126"></rect>
  <rect fill="rgb(0,0,0)" height="40" stroke="rgb(0,0,0)" style="filter:url(#filter_blur);opacity:0.7;fill-opacity:1" width="128" x="331" y="206"></rect>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="100" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="164" y="66">Bootloader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="556" y="40"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="60" x="620" y="66">App Loader</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="120"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="66" x="392" y="146">Application</text>
  <rect fill="rgb(255,255,255)" height="40" stroke="rgb(0,0,0)" width="128" x="328" y="200"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="42" x="392" y="226">Updater</text>
  <path d="M 228 60 L 548 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="555,60 548,56 548,64 555,60" stroke="rgb(0,0,0)"></polygon>
  <path d="M 228 60 L 278 60" fill="none" stroke="rgb(0,0,0)" stroke-dasharray="4"></path>
  <path d="M 278 60 L 278 220" fill="none" stroke="rgb(0,0,0)" stroke-dasharray="4"></path>
  <path d="M 278 220 L 320 220" fill="none" stroke="rgb(0,0,0)" stroke-dasharray="4"></path>
  <polygon fill="rgb(0,0,0)" points="327,220 320,216 320,224 327,220" stroke="rgb(0,0,0)"></polygon>
  <path d="M 620 80 L 620 100" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 392 100 L 527 100" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 527.0 100.0 A4,4 0 0 1 535.0 100.0" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 535 100 L 620 100" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 392 100 L 392 112" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="392,119 388,112 396,112 392,119" stroke="rgb(0,0,0)"></polygon>
  <path d="M 620 80 L 620 180" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 392 180 L 527 180" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 527.0 180.0 A4,4 0 0 1 535.0 180.0" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 535 180 L 620 180" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 392 180 L 392 192" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="392,199 388,192 396,192 392,199" stroke="rgb(0,0,0)"></polygon>
  <path d="M 456 220 L 531 220" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 531 220 L 531 60" fill="none" stroke="rgb(0,0,0)"></path>
  <path d="M 531 60 L 548 60" fill="none" stroke="rgb(0,0,0)"></path>
  <polygon fill="rgb(0,0,0)" points="555,60 548,56 548,64 555,60" stroke="rgb(0,0,0)"></polygon>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="37" x="374" y="39"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="21" x="392" y="49">Loads</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="37" x="260" y="199"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="21" x="278" y="209">Loads</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="50" x="424" y="84"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="34" x="449" y="94">Ld, Updt</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="50" x="424" y="164"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="34" x="449" y="174">Ld, Updt</text>
  <rect fill="white" height="12" stroke="rgb(0,0,0)" width="46" x="483" y="184"></rect>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="8" font-style="normal" font-weight="normal" text-anchor="middle" textLength="30" x="506" y="194">Updates</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="164" y="36">Slot 0</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="620" y="36">Slot 1</text>
  <text fill="rgb(0,0,0)" font-family="sans-serif" font-size="11" font-style="normal" font-weight="normal" text-anchor="middle" textLength="36" x="392" y="116">Slot 2</text>
</svg>

</p>

<p>In summary, we end up with four programs:</p>

<ol>
  <li>An immutable Bootloader whose sole job is to load the Loader, and fallback to
another image if the Loader is invalid.</li>
  <li>A Loader that can verify our Application image, load it, and update it.</li>
  <li>An Application which does not do any updates itself</li>
  <li>An Updater that temporarily replaces the Application and can update the
Loader.</li>
</ol>

<p>This is not the only valid firmware update architecture, but it avoids many of
the pitfalls of DFU without consuming too much code space.</p>

<h2 id="design-patterns--recipes">Design Patterns &amp; Recipes</h2>

<p>I have put together a full implementation of the Bootloader, the Loader, and the
Application in the <a href="https://github.com/memfault/interrupt/tree/master/example/fwup-architecture">Interrupt
Github
repository</a>.
While discussing every line in detail is outside of the scope of this
conversation, I want to highlight a few patterns I have learned over the years.
These include ways to package firmware images, write them to flash, share data
between programs, and more!</p>

<p>This post builds upon many ideas previously written about on Interrupt. If you
haven’t read them already, I recommend the following:</p>
<ul>
  <li><a href="https://interrupt.memfault.com/how-to-write-a-bootloader-from-scratch">How to Write a Bootloader from Scratch</a></li>
  <li><a href="https://interrupt.memfault.com/how-to-write-linker-scripts-for-firmware">How to Write Linker Scripts for Firmware</a></li>
  <li><a href="https://interrupt.memfault.com/gnu-build-id-for-firmware">GNU Build IDs for Firmware</a></li>
  <li><a href="https://interrupt.memfault.com/firmware-shell">Building a Tiny CLI Shell for Tiny Firmware</a></li>
</ul>

<h3 id="image-metadata">Image Metadata</h3>

<p>Firmware images typically …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/device-firmware-update-cookbook">https://interrupt.memfault.com/blog/device-firmware-update-cookbook</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/device-firmware-update-cookbook</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631985</guid>
            <pubDate>Wed, 24 Jun 2020 18:33:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Harm of Studying Abroad]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 109 (<a href="https://news.ycombinator.com/item?id=23631503">thread link</a>) | @jeffreyrogers
<br/>
June 24, 2020 | https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html | <a href="https://web.archive.org/web/*/https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631503</guid>
            <pubDate>Wed, 24 Jun 2020 17:59:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux is Most Used OS in Microsoft Azure]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23631370">thread link</a>) | @crpietschmann
<br/>
June 24, 2020 | https://build5nines.com/linux-is-most-used-os-in-microsoft-azure-over-50-percent-fo-vm | <a href="https://web.archive.org/web/*/https://build5nines.com/linux-is-most-used-os-in-microsoft-azure-over-50-percent-fo-vm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-28288">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					
<p>For the last few years, Microsoft has stated during event keynotes and in other places that Linux is a rapidly growing operating system (OS) being used within Microsoft Azure. They had proudly stated that 50% of new VMs running in Azure were running Linux. (This is the latest stat I remember Microsoft saying publicly a while back already.) Well, I came across an interesting<a href="https://www.linkedin.com/posts/adirron_linuxonazure-progress-activity-6665502370795003905-DY1G" target="_blank" rel="noopener"> infographic recently (thanks to Adir Ron) </a>that gives some statistics and other information regarding the percentage and overall usage of the Linux OS in Microsoft Azure.</p>



<p>Based on the past growth of Linux adoption in Microsoft Azure, I’ve long suspected that Microsoft Azure hosts more Linux VMs than Windows VMs. This infographic looks to shed some light on this most likely being true, as it states “More than 50% of VM cores runs Linux on Azure”.</p>



<p>Before you look at the infographic itself, here are a few stats listed in it that I’d like to point out:</p>



<ul><li>More than 50% of VM cores runs Linux on Azure</li><li>Linux-based images comprise 60% of Azure Marketplace images</li><li>Top 100 Microsoft customers deploy Linux workloads on Azure</li><li>Azure Tuned Kernels provide 25% faster network throughput</li><li>Microsoft supports all major Linux distros, like: Red Hat, SUSE, Ubuntu, Oracle Linux, Debian, CentOS, CoreOS, and OpenSUSE <em>(Related: Azure also supports FreeBSD)</em></li><li>Azure offers two natively supported managed Kubernetes orchestration services: Azure Kubernetes Service, and Azure Red Hat OpenShift</li></ul>



<p>Here’s the “Did you know? Linux is the fastest growing platform on Azure” <a href="https://build5nines.com/tag/infographic/">infographic</a> below:</p>



<figure><a href="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?ssl=1" target="_blank" rel="noopener noreferrer"><img data-attachment-id="28289" data-permalink="https://build5nines.com/linux-is-most-used-os-in-microsoft-azure-over-50-percent-fo-vm-cores/linux-fastest-growing-platform-on-microsoft-azure-2020-05-11/" data-orig-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=1200%2C4464&amp;ssl=1" data-orig-size="1200,4464" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11" data-image-description="" data-medium-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=81%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=275%2C1024&amp;ssl=1" src="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=275%2C1024&amp;ssl=1" alt="Linux is Most Used OS in Microsoft Azure - over 50 percent of VM cores 1" width="275" height="1024" srcset="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?w=1200&amp;ssl=1 1200w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=275%2C1024&amp;ssl=1 275w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=768%2C2857&amp;ssl=1 768w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=413%2C1536&amp;ssl=1 413w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=1080%2C4018&amp;ssl=1 1080w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=980%2C3646&amp;ssl=1 980w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=480%2C1786&amp;ssl=1 480w" sizes="(max-width: 275px) 100vw, 275px" title="Linux is Most Used OS in Microsoft Azure - over 50 percent of VM cores 1" data-lazy-srcset="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?w=1200&amp;ssl=1 1200w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=275%2C1024&amp;ssl=1 275w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=768%2C2857&amp;ssl=1 768w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=413%2C1536&amp;ssl=1 413w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=1080%2C4018&amp;ssl=1 1080w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=980%2C3646&amp;ssl=1 980w, https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?resize=480%2C1786&amp;ssl=1 480w" data-lazy-src="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/05/Linux-fastest-growing-platform-on-microsoft-azure-2020-05-11.jpg?fit=275%2C1024&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>Happy running Linux in Azure!</p>



<blockquote><p>P.S. If you’re looking to save money hosting VMs in Microsoft Azure (both Windows and Linux), you should read my article showing you how to <a href="https://build5nines.com/properly-shutdown-azure-vm-to-save-money/">properly shutdown Azure VMs to save money</a>!</p></blockquote>

<br><h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is a <strong>Microsoft MVP</strong> and has 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
						
										</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

				 <!-- end #sidebar -->
		</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>https://build5nines.com/linux-is-most-used-os-in-microsoft-azure-over-50-percent-fo-vm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631370</guid>
            <pubDate>Wed, 24 Jun 2020 17:51:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Built Calendly in 3 Hours]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23631119">thread link</a>) | @benn_88
<br/>
June 24, 2020 | https://anvil.works/learn/examples/calendly | <a href="https://web.archive.org/web/*/https://anvil.works/learn/examples/calendly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <svg width="100%" height="110" viewBox="0 0 460.8 20" xmlns="http://www.w3.org/2000/svg" version="1.1" preserveAspectRatio="xMidYMax slice" style="fill:#f7fdff;stroke:none;">
          <use xlink:href="#img-concave"></use>
        </svg>
        
  <section>
      <div>
          <article>
              



<p><a href="https://anvil.works/learn/examples/meter-feeder">Part 1 of this series: Meter Feeder in 1.5 hours &gt;</a></p>

<p>How long <em>does</em> it take to prototype a startup? When we look at a product like <a href="https://calendly.com/">Calendly</a>, it’s hard to imagine scheduling meetings without it. But when Tope Awotona first had the idea, it wasn’t obvious that it would take off. He had to build a prototype.</p>

<p>Prototyping is always a risk – it’s easy to spend months building something that nobody wants. But if you <em>have</em> a prototype, those conversations with initial customers are so much easier. So we’re setting out to see how fast we can get that crucial prototype. If we can get it down to days, or even hours, we’re onto a winner:</p>

<div>
    
    <div>
        <p>Launching a mediocre product as soon as possible, and then talking to customers and iterating, is much better than waiting to build the “perfect” product.</p>
        <h4>Geoff Ralston and Michael Seibel</h4>
        <h5>in Y Combinator’s <a href="https://blog.ycombinator.com/ycs-essential-startup-advice/">Essential Startup Advice</a></h5>
    </div>
</div>

<p>Our secret weapon is <a href="https://anvil.works/">Anvil</a>. It’s a platform for building web apps without the fuss: it’s got a visual interface designer, client- and server-side code is all in Python, and it deploys to the cloud with one click.</p>

<hr>

<h2 id="the-build">The Build</h2>

<p>I’ll walk you through the design process, show you some screenshots, and give a breakdown of how long each stage took:</p>

<h3 id="1-google-integration-and-user-setup-30-minutes">1. Google Integration and User Setup (30 minutes)</h3>

<p>Calendly connects to your calendar to automatically check availability, so you don’t need those endless back-and-forth emails. Integrating an OAuth flow with Google Calendar could take all day, but Anvil’s <a href="https://anvil.works/docs/integrations/google">Google integration</a> makes it really simple:</p>

<div title="Client-side Python" tabindex="0"><div><pre><code data-lang="python"><span>anvil</span><span>.</span><span>google</span><span>.</span><span>auth</span><span>.</span><span>login</span><span>([</span><span>'https://www.googleapis.com/auth/calendar'</span><span>])</span></code></pre></div></div>


<p>That gives us a login screen:</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/google_auth_screen.png" alt="Google OAuth Screen"> <figcaption>
                <p>Google OAuth Screen</p>
            </figcaption>
    </figure>
</div>

<p>And now we have the OAuth tokens to use with the Calendar API:
</p><div title="Server-side Python" tabindex="0"><div><pre><code data-lang="python"><span>refresh_token</span> <span>=</span> <span>anvil</span><span>.</span><span>google</span><span>.</span><span>auth</span><span>.</span><span>get_user_refresh_token</span><span>()</span>
<span>access_token</span>  <span>=</span> <span>anvil</span><span>.</span><span>google</span><span>.</span><span>auth</span><span>.</span><span>refresh_access_token</span><span>(</span><span>refresh_token</span><span>)</span></code></pre></div></div>


<p>To keep the refresh token secure from prying eyes, we encrypt it with Anvil’s <a href="https://anvil.works/docs/security/encrypting-secret-data">Secrets Service</a>, then store it in a <a href="https://anvil.works/docs/data-tables">Data Table</a>:</p>

<div title="Server-side Python" tabindex="0"><div><pre><code data-lang="python"><span>user</span><span>[</span><span>'refresh_token'</span><span>]</span> <span>=</span> <span>anvil</span><span>.</span><span>secrets</span><span>.</span><span>encrypt_with_key</span><span>(</span><span>'token_key'</span><span>,</span> <span>refresh_token</span><span>)</span></code></pre></div></div>


<hr>

<h3 id="2-basic-interaction-1-hour-15-minutes">2. Basic Interaction (1 hour 15 minutes)</h3>

<p>There are two parties here - the Organiser, who is advertising their availability, and the Attendee, who is picking a meeting time with them.</p>

<p>We make a <strong>Settings</strong> page, so the Organiser can specify the length of their meeting slots, and give them a unique URL they can provide to their attendees:</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/beta_settings.png" alt="The Organiser configures their settings"> <figcaption>
                <p>The Organiser configures their settings</p>
            </figcaption>
    </figure>
</div>

<p>When the Attendee clicks that link, they get the <strong>Booking</strong> page, where they can choose a meeting (at any time, for now), then provide their details to confirm their slot.</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/attendee_details.png" alt="The Attendee enters their details"> <figcaption>
                <p>The Attendee enters their details</p>
            </figcaption>
    </figure>
</div>

<p>We create a calendar event by POSTing to the <a href="https://developers.google.com/calendar/concepts">Google Calendar API</a>, using the Organiser’s OAuth tokens. (Google’s API docs are somewhat confusing, but the <a href="https://anvil.works/docs/integrations/google/google-rest-apis">Anvil docs</a> show us how.)</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/calendar_event.png" alt="Calendar event"> <figcaption>
                <p>Calendar event</p>
            </figcaption>
    </figure>
</div>

<p>We then send an email to tell the Organiser about the new booking:<br>(Sending email is <a href="https://anvil.works/docs/email/sending_and_receiving#sending-email">one line of code</a> with Anvil – it’s all built in!)

</p><div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/email_example.png" alt="Example email"> <figcaption>
                <p>Example email</p>
            </figcaption>
    </figure>
</div>

<hr>

<h3 id="3-adjust-availability-55-mins">3. Adjust Availability (55 mins)</h3>

<p>Of course, the real magic of Calendly is that the Organiser can specify their availability, and we avoid clashing with existing appointments.</p>

<p>Let’s tackle the first one first: We need a page for the Organiser to set up the times they’re willing to meet:</p>


<div>
    <figure><img src="https://anvil-website-static.s3.eu-west-2.amazonaws.com/learn/examples/calendly/availability.gif" alt="Booking a meeting"> <figcaption>
                <p>Booking a meeting</p>
            </figcaption>
    </figure>
</div>

<p>The data structure was the tricky part here, but Python’s <code>datetime</code> module simplified this process – especially as we can use <a href="https://anvil.works/python-browser">Python in the browser</a> too!</p>

<p>I didn’t need to keep translating from Python <code>datetime</code> objects, to JSON, to Javascript <code>Date</code> objects, and back again. This melted my brain a lot less than it might have done.</p>

<hr>

<h3 id="4-timezone-awareness-15-minutes">4. Timezone Awareness (15 minutes)</h3>

<p>Timezones are a minefield. Having an Organiser in one timezone and an Attendee in a different timezone is a real headache – we can’t sensibly ask the Attendee to mentally convert the times in their head!</p>

<p>Nobody wants to write their own timezone module, but Python has <code>pytz</code>, which is available on the Anvil server, and we can use Anvil’s <a href="https://anvil.works/docs/server/dealing-with-timezones">timezone library</a> to capture the timezone of the browser:</p>

<div title="Client-side Python" tabindex="0"><div><pre><code data-lang="python"><span>import</span> <span>anvil.tz</span>
<span>browser_tz</span> <span>=</span> <span>anvil</span><span>.</span><span>tz</span><span>.</span><span>tzlocal</span><span>()</span></code></pre></div></div>


<p>So if the Organiser is in the UK, and available from 12pm-3pm on Thursdays, and I’m in Malaysia…</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/timezone.png" alt="Pick a slot &amp;ndash; in my timezone!"> <figcaption>
                <p>Pick a slot – in my timezone!</p>
            </figcaption>
    </figure>
</div>

<hr>

<h3 id="5-avoiding-calendar-clashes-20-minutes">5. Avoiding Calendar Clashes (20 minutes)</h3>

<p>A booking system would be useless if it allowed two bookings at the same time! So we use the Google Calendar API to get a list of events when the Organiser is ‘busy’, and only offer Attendees slots when the Organiser is available:</p>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/calendar_busy_1.png" alt="Prior engagement"> <figcaption>
                <p>Prior engagement</p>
            </figcaption>
    </figure>
</div>


<div>
    <figure><img src="https://anvil.works/learn/examples/img/calendly/calendar_busy_2.png" alt="No slots due to prior engagement"> <figcaption>
                <p>No slots due to prior engagement</p>
            </figcaption>
    </figure>
</div>

<hr>

<h2 id="total-time-3-hours-15-minutes">Total Time: 3 hours 15 minutes</h2>

<p>And that’s it! We’ve prototyped a fully functioning booking system, and <strong>it’s not even lunchtime</strong>.</p>

<p>We can spend the afternoon showing it to potential users, and watching them interact with it. If they get stuck on something, we can rebuild it tomorrow!</p>

<hr>

<p>Want to see the source code and explore it yourself? Click this fine link:</p>




<p><em>To run the app yourself, you’ll need your own <code>client_id</code> and <code>client_secret</code> for the Google API. Following the steps in the Anvil docs: <a href="https://anvil.works/docs/integrations/google/linking-google-and-anvil">Linking Google to Anvil</a>.</em></p>

<hr>

<h2 id="more-rapid-prototypes">More Rapid Prototypes</h2>

<p>Want to see more rapid prototyping? We’ve rebuilt a few famous startups in record time.</p>

<p>Here’s another one:</p>




          </article>
      </div>
      
  </section>

    </div></div>]]>
            </description>
            <link>https://anvil.works/learn/examples/calendly</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631119</guid>
            <pubDate>Wed, 24 Jun 2020 17:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Organisational Benefits of Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23630537">thread link</a>) | @mstipetic
<br/>
June 24, 2020 | https://www.msb.com/post/organisational-benefits-of-kubernetes | <a href="https://web.archive.org/web/*/https://www.msb.com/post/organisational-benefits-of-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.10.5"><div dir="ltr"><div><div id="viewer-6scun"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.msb.com/post/organisational-benefits-of-kubernetes" data-pin-media="https://static.wixstatic.com/media/nsplsh_437073544155506f536377~mv2.jpg/v1/fit/w_5000,h_4000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/nsplsh_437073544155506f536377~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-bavv2">Before actual collaboration with companies and providing our professional Kubernetes training, we often have to explain the benefits of Kubernetes to several stakeholders, especially at the enterprise level.</p><p id="viewer-4ceqi">We believe that the Kubernetes community does a very good job explaining the technical details and benefits of switching to its technology base. However we also believe that we can do an even better job at advocating it at the management level.</p><p id="viewer-43jln">Technical champions inside organisations sometimes have a hard time understanding the perspectives of various stakeholders inside their organisations, so we thought we'd make a "how to convince your boss" list of benefits of a Kubernetes transition to communicate its advantages more effectively.</p><p id="viewer-7j4al">Most benefits can be summarised in one word - standardisation, but let's dig a bit into specifics.</p><p id="viewer-9a4oj">Some of the benefits of a Kubernetes transition include:</p><ol><li id="viewer-cso6i"><p>Standardised hiring</p></li><li id="viewer-c7lvl"><p>Standardised configuration management, removing knowledge silos</p></li><li id="viewer-bblnl"><p>Enforcing standards</p></li><li id="viewer-117hv"><p>Easy access to a huge software ecosystem</p></li><li id="viewer-63hfg"><p>Removing vendor lock-in</p></li></ol><h2 id="viewer-1u0ie">Standardised hiring</h2><p id="viewer-24hq1">A standard job post for a backend/DevOps person just a few years ago used to include a list of requirements which usually included a permutation of several of the many technologies available at the time (Puppet, Chef, Ansible, Docker Swarm, Mesos...), mostly driven by the requirements bespoke backends of each company.</p><p id="viewer-4dcjd">To achieve things coming out-of-the-box with Kubernetes, backend and DevOps teams usually built their own solutions out of necessity, using tools they were personally familiar with. <span>This made finding people with exact needed skillsets hard and usually included a long onboarding time.</span></p><p id="viewer-5gpog"><span>Looking at job postings of companies utilising k8s right now we see a simplified job posting, focusing on Kubernetes experience with a few "nice to have" skills.</span></p><p id="viewer-b4hgh"><span>A big objection to keep in mind is that Kubernetes is a fairly young technology and finding qualified engineers can be harder, but a whole ecosystem of education and certification has sprung up in recent years (including MSB), so it's becoming less relevant.</span></p><h2 id="viewer-95rl0"><span>Standardised configuration management</span></h2><p id="viewer-3g20d"><span>A major advantage, that we feel is not being talked about enough is standardisation of configuration management inside k8s.</span></p><p id="viewer-51jbs"><span>In every company I've personally worked in the past, a large part of onboarding has been just knowing how to store, use and find various configurations necessary to access in my services. There were usually a few "old-timer" DevOps who knew how everything fits together and where the various configurations were stored, and they were indispensable to the running of the company.</span></p><p id="viewer-16kj9"><span>In companies that are advanced k8s users we currently see the DevOps teams being freed up to focus on process automation, building whole project templates that allow you spin up and integrate whole services in no time, with security, secret management and processes built in, so engineers can focus on building the actual services. This allows engineers not only to build their own services, but also to be able to quickly jump into other teams' services and have a good understanding of how things work.</span></p><h2 id="viewer-3frfv"><span>Enforcing standards</span></h2><p id="viewer-d1aau"><span>A big part of Kubernetes' mechanisms that don't get enough attention are mechanisms that allow you to encode various security and process requirements into the cluster itself, ensuring a standard baseline of security and governance practices that have to be respected before a workload is permitted to be deployed on the cluster.</span></p><p id="viewer-ckorf"><span>Various </span><a href="https://kubernetes.io/blog/2019/03/21/a-guide-to-kubernetes-admission-controllers/" target="_blank" rel="noopener"><span><u>admission controllers</u></span></a><span> allow you to enforce best practices through code and reduce micromanagement overhead of your teams.</span></p><p id="viewer-3hl1c"><span>This is a somewhat advanced topic, but we think it's not discussed enough and important enough that we have a </span><a href="https://msb.com/bootcamp" target="_blank" rel="noopener"><span><u>whole day training</u></span></a><span> devoted just for this topic.</span></p><h2 id="viewer-c6e8"><span>Easy access to a huge software ecosystem</span></h2><p id="viewer-78d9r">Almost every open-source or commercial project currently offers a Helm chart or a Custom Operator to deploy directly into your cluster using a standardised and fully configurable interface.</p><p id="viewer-ekvv2">Here's an example of a highly available postgres cluster being deployed with one command and visualised using the MSB platform:</p><p id="viewer-1bh23">This allows teams to choose technologies needed for running their services and spend minimal time deploying them, while knowing best practices are followed. Most engineers are not experts in deploying things like high availability elasticsearch clusters, and before k8s a lot of preparation had to take place to ensure a production-ready system. Currently we get the benefit of the community or vendors spending time optimising their packages, so we can easily configure and use them.</p><h2 id="viewer-e3d4">Removing vendor lock-in</h2><p id="viewer-sgsh">This point has been reiterated multiple times, and research shows that organisations rarely take advantage of it, but it's still important to keep in mind. Kubernetes provides a standard API to which all cloud providers have to conform to, giving you the flexibility to negotiate and switch providers once operating at a significant scale.</p><p id="viewer-a1ig9">We hope you'll take these points into consideration when deciding on your Kubernetes strategy, or they will be useful to you to convince your organisation to make the switch.</p><p id="viewer-69s9s">If you'd like to hear first hand from a professional selling k8s into organisations, please have a listen to our <a href="https://www.msb.com/podcast/episode/37572d1a/001-kubernetes-enterprise-adoption-with-jeroen-overmaat" target="_blank" rel="noopener"><u>podcast episode</u></a> with Jeroen Overmaat, Rancher NEMEA Regional Director</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.msb.com/post/organisational-benefits-of-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-23630537</guid>
            <pubDate>Wed, 24 Jun 2020 16:54:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mathematics and Its Symbols]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23630288">thread link</a>) | @R3G1R
<br/>
June 24, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><p> <span>T</span>he language and vocabulary of mathematics contain a large amount of <strong>symbols</strong> — some being more technical than others. Like letters in the alphabet, they can be used to form words, phrases and sentences that would constitute a larger part of the mathematical lexicon. \[ \begin{gather*}x \longrightarrow x+1 \longrightarrow (x+1)^2 \longrightarrow (x+1)^2 \ge 0 \\ \longrightarrow \forall x \in \mathbb{R} [ (x+1)^2 \ge 0 ] \end{gather*} \] A math symbol can be used for different <strong>purposes</strong> from one mathematical subfield to another (e.g., $\sim$ as logical negation and similarity of triangle), just as multiple symbols can be used to delineate the same concept or relation (e.g., $\times$ and $\cdot$ in multiplication).</p><p>A basic understanding about mathematical terminology is essential to a solid foundation in higher mathematics. To that end, the following is a compilation of some of the most well-adapted, <strong>commonly-used symbols</strong> in mathematics.</p><p>Moreover, these symbols are further categorized by their <strong>function</strong>&nbsp;into tables. More comprehensive lists of symbols — as categorized by <strong>subject</strong>&nbsp;and <strong>type</strong> — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" srcset="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png 400w, https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover-309x400.png 309w, https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover-300x389.png 300w" sizes="(max-width: 400px) 100vw, 400px" title="Math Symbols eBook Cover" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png 400w, https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover-309x400.png 309w, https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover-300x389.png 300w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p> </div></div></div></div><h2><span id="Constants"></span>Constants<span></span></h2><p>In mathematics, constants are symbols that are used to refer to <strong>non-varying objects</strong>. These can include key numbers, key mathematical sets, key mathematical infinities and other key mathematical objects (such as the identity matrix $I$).</p><p>Mathematical constants often take form of an <a href="https://mathvault.ca/hub/higher-math/math-symbols/greek-hebrew-latin-symbols/" target="_blank" rel="noopener noreferrer"><strong>alphabet letter</strong></a> — or a derivative of it. In some occasions, a constant might be regarded as a variable in the larger context. The following tables feature some of the most commonly-used constants, along with their name, meaning and usage.</p><h3><span id="Key_Mathematical_Numbers"></span>Key Mathematical Numbers<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$0$ (<strong>Zero</strong>)</td><td>Additive identity of common numbers</td><td>$3 + 0 =3$</td></tr><tr><td>$1$ (<strong>One</strong>)</td><td>Multiplicative identity of common numbers</td><td>$5 \times 1 = 5$</td></tr><tr><td>$\sqrt{2}$ (<strong>Square root of $2$</strong>)</td><td>Positive number whose square is $2$. Approximately $1.41421$.</td><td>$(\sqrt{2} + 1)^2 = 3 + 2\sqrt{2}$</td></tr><tr><td>$e$ (<strong><a href="https://en.wikipedia.org/wiki/E_(mathematical_constant)" target="_blank" aria-label="Euler's constant (opens in a new tab)" rel="noreferrer noopener">Euler’s constant</a></strong>)</td><td>Base of the natural logarithm. Limit of the sequence $(1+\frac{1}{n})^n$. Approximately $2.71828$.</td><td>$\ln (e^2) = 2 $</td></tr><tr><td>$\pi$ (<strong><a href="https://en.wikipedia.org/wiki/Pi" target="_blank" aria-label="Pi (opens in a new tab)" rel="noreferrer noopener">Pi</a></strong>, Archimedes’ constant)</td><td>Ratio of a circle’s circumference to its diameter. Half-circumference of a unit circle. Approximately $3.14159$.</td><td>$\dfrac{\pi^2}{6} = \dfrac{1}{1^2} + \dfrac{1}{2^2} + \cdots$</td></tr><tr><td>$\varphi$ (<strong>Phi</strong>, <a href="https://en.wikipedia.org/wiki/Golden_ratio" target="_blank" aria-label="golden ratio (opens in a new tab)" rel="noreferrer noopener">golden ratio</a>)</td><td>Ratio between a larger number $a$ and a smaller number $b$ when $\frac{a+b}{a} = \frac{a}{b}$. Positive solution to the equation $x^2-x-1 = 0$.</td><td> $\varphi = \dfrac{1+\sqrt{5}}{2} \approx 1.61803$</td></tr><tr><td>$i$ (<strong><a href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank" aria-label="Imaginary unit (opens in a new tab)" rel="noreferrer noopener">Imaginary unit</a></strong>)</td><td>The principal root of $-1$. Foundational component of a complex number.</td><td>$(1+i)^2 = 2i$</td></tr></tbody></table></figure><h3><span id="Key_Mathematical_Sets"></span>Key Mathematical Sets<span></span></h3><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Key_Mathematical_Sets" target="_blank" rel="noopener noreferrer"><strong>key mathematical sets in algebra</strong></a>.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\varnothing$ (<strong>Empty set</strong>)</td><td>Set with no element</td><td>$|\varnothing| = 0$</td></tr><tr><td>$\mathbb{N}$ (<strong>N</strong>)</td><td>Set of natural numbers</td><td>$\forall x, y \in \mathbb{N}$,<br>$x+y \in \mathbb{N}$</td></tr><tr><td>$\mathbb{Z}$ (<strong>Z</strong>)</td><td>Set of integers (Z stands for zahlen, number in German)</td><td>$ \mathbb{N} \subseteq \mathbb{Z}$</td></tr><tr><td>$\mathbb{Z}_+$ (<strong>Z-plus</strong>)</td><td>Set of positive integers</td><td>$3 \in \mathbb{Z}_+$</td></tr><tr><td>$\mathbb{Q}$ (<strong>Q</strong>)</td><td>Set of rational numbers (Q stands for quotient)</td><td>$\sqrt{2} \notin \mathbb{Q}$</td></tr><tr><td>$\mathbb{R}$ (<strong>R</strong>)</td><td>Set of real numbers</td><td>$\forall x \in \mathbb{R}, x^2 \ge 0$</td></tr><tr><td>$\mathbb{R}_+$ (<strong>R-plus</strong>)</td><td>Set of positive real numbers</td><td>$\forall x,y \in \mathbb{R}_+$, $xy \in \mathbb{R}_+$</td></tr><tr><td>$\mathbb{C}$ (<strong>C</strong>)</td><td>Set of complex numbers</td><td>$\exists z \in \mathbb{C}\, (z^2 + 1 =0)$</td></tr><tr><td>$\mathbb{Z}_n$ (<strong><a href="https://en.wikipedia.org/wiki/Modular_arithmetic#Integers_modulo_n" target="_blank" aria-label="Z-n (opens in a new tab)" rel="noreferrer noopener">Z-n</a></strong>)</td><td>Set of integers modulo $n$</td><td>In the world of $\mathbb{Z}_2$, $1+1=0$.</td></tr><tr><td>$\mathbb{R}^3$ (<strong><a href="https://en.wikipedia.org/wiki/Three-dimensional_space" target="_blank" aria-label="R-three (opens in a new tab)" rel="noreferrer noopener">R-three</a></strong>)</td><td>Three-dimensional Euclidean space</td><td>$(5, 1, 2) \in \mathbb{R}^3$</td></tr></tbody></table></figure><h3><span id="Key_Mathematical_Infinities"></span>Key Mathematical Infinities<span></span></h3><p>In mathematics, many different types of <a href="https://mathvault.ca/math-glossary/#infinite"><strong>infinity</strong></a> exist. These include the purely notational use of the lemniscate symbol ($\infty$), and the use of the following symbols in the context of cardinal/ordinal infinities:</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\aleph_0$ (<strong><a href="https://en.wikipedia.org/wiki/Aleph_number#Aleph-naught" target="_blank" aria-label="Aleph-naught (opens in a new tab)" rel="noreferrer noopener">Aleph-naught</a></strong>)</td><td>Cardinality of the set of natural numbers</td><td>$\aleph_0 + 5 = \aleph_0$</td></tr><tr><td>$\mathfrak{c}$ (<strong><a href="https://en.wikipedia.org/wiki/Continuum_(set_theory)" target="_blank" aria-label="Continuum (opens in a new tab)" rel="noreferrer noopener">Continuum</a></strong>)</td><td>Cardinality of the set of real numbers</td><td>$\mathfrak{c}=2^{\aleph_0}$</td></tr><tr><td>$\omega$ (<strong><a href="https://en.wikipedia.org/wiki/Aleph_number#Aleph-null" target="_blank" aria-label="Omega (opens in a new tab)" rel="noreferrer noopener">Omega</a></strong>)</td><td>Smallest infinite ordinal number</td><td>$\forall n \in \mathbb{N}, n &lt; \omega$</td></tr></tbody></table></figure><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/set-theory-symbols/#Cardinalityrelated_Symbols" target="_blank" rel="noopener noreferrer"><strong>cardinality-related symbols</strong></a>.</p><h3><span id="Other_Key_Mathematical_Objects"></span>Other Key Mathematical Objects<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\mathbf{0}$ (<strong>Zero</strong>)</td><td>Zero vector of a vector space</td><td>$\forall \mathbb{v} \in V$,<br>$\mathbf{v} + \mathbf{0} = \mathbf{v}$</td></tr><tr><td>$e$ (<strong>E</strong>)</td><td><a href="https://en.wikipedia.org/wiki/Identity_element" target="_blank" aria-label="Identity element (opens in a new tab)" rel="noreferrer noopener">Identity element</a> of a group</td><td>$e \circ e = e$</td></tr><tr><td>$I$ (<strong>I</strong>)</td><td><a href="https://en.wikipedia.org/wiki/Identity_matrix" target="_blank" aria-label="Identity matrix (opens in a new tab)" rel="noreferrer noopener">Identity matrix</a></td><td>$AI = IA =I$</td></tr><tr><td>$C$ (<strong>C</strong>)</td><td><a href="https://en.wikipedia.org/wiki/Constant_of_integration" target="_blank" aria-label="Constant of integration (opens in a new tab)" rel="noreferrer noopener">Constant of integration</a></td><td>$\displaystyle \int 1 \, \mathrm{d}x =$<br>$x + C$</td></tr><tr><td>$\top$ (<strong><a href="https://en.wikipedia.org/wiki/Tautology_(logic)" target="_blank" aria-label="Tautology (opens in a new tab)" rel="noreferrer noopener">Tautology</a></strong>)</td><td>A sentence in formal logic which is unconditionally true</td><td>For each proposition $P$, $P \land \top \equiv P$.</td></tr><tr><td>$\bot$ (<strong><a href="https://en.wikipedia.org/wiki/Contradiction#In_formal_logic" target="_blank" aria-label="Contradiction (opens in a new tab)" rel="noreferrer noopener">Contradiction</a></strong>)</td><td>A sentence in formal logic which is unconditionally false</td><td>For each proposition $P$, $P \land \lnot P \equiv \bot.$</td></tr><tr><td>$Z$ (<strong>Z</strong>)</td><td><a href="https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution" target="_blank" aria-label="Standard normal distribution (opens in a new tab)" rel="noreferrer noopener">Standard normal distribution</a></td><td>$Z \sim N(0,1)$</td></tr></tbody></table></figure><h2><span id="Variables"></span>Variables<span></span></h2><p>A mathematical variable is a symbol that functions as a placeholder for <strong>varying expressions</strong> or <strong>quantities</strong>. The same variable can be used on a repeated basis to refer to the same thing — or <i>quantified</i> to form sentences that have a more definite meaning: \begin{gather*}x, y \longrightarrow x + e^x = y \longrightarrow \exists y \in \mathbb{R}\, (x + e^x = y) \\ \longrightarrow \forall x \in \mathbb{R} \, \exists y \in \mathbb{R}\, (x + e^x = y) \end{gather*} In some cases, variables can be thought of as <strong>constants</strong> in narrower contexts (e.g., as parameters), while in other cases, variables are used in conjunction with <strong>subscripts</strong> to make up for the lack of letters (e.g., $x_3$).</p><p>While variables in mathematics are often used to represent <strong>numbers</strong>, they can also be used to represent other objects such as vectors, functions and matrices. The following tables document some of the most common conventions for variables — along with the context where they are adopted and used.</p><h3><span id="Variables_for_Numbers"></span>Variables for Numbers<span></span></h3><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td>$m, n, p, q$</td><td><strong>Integers</strong> and <strong>natural numbers</strong></td><td>If $mn$ is odd, then both $m$ and $n$ are odd.</td></tr><tr><td>$a, b, c$</td><td><strong>Coefficients</strong> of functions and equations</td><td>A line of the form $ax+by=0$ passes through the origin.</td></tr><tr><td>$x, y, z$</td><td><strong>Unknowns</strong> in functions and equations</td><td>If $2x + 5= 3$, then $x=-1$.</td></tr><tr><td>$\Delta$</td><td><strong><a href="https://mathvault.ca/quadratic-factorisation/#The_General_Method_Theory">Discriminant</a></strong></td><td>$\Delta = b^2 – 4ac$ for quadratic polynomials</td></tr><tr><td>$i, j, k$</td><td><strong>Index variables</strong> in summations and products</td><td>$\sum _{i=1}^{10} i = 55$</td></tr><tr><td>$t$</td><td><strong>Time</strong></td><td>At $t=5$, the velocity is $v(5)=32$.</td></tr><tr><td>$z$</td><td><strong>Complex numbers</strong></td><td>$z \overline{z} = |z|^2$</td></tr></tbody></table></figure><h3><span id="Variables_in_Geometry"></span>Variables in Geometry<span></span></h3><p>For more symbols in geometry and trigonometry, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/geometry-trigonometry-symbols/" target="_blank" rel="noopener noreferrer"><strong>geometry and trigonometry symbols</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td> $P, Q, R, S$</td><td> <strong>Vertices </strong></td><td> $\overline{PQ} \perp \overline{QR}$</td></tr><tr><td> $\ell$</td><td><strong>Lines</strong></td><td> $\ell_1 \parallel \ell_2$</td></tr><tr><td> $\alpha, \beta, \gamma, \theta$</td><td> <strong>Angles</strong></td><td> $\alpha + \beta + \theta = 180^{\circ}$</td></tr></tbody></table></figure><h3><span id="Variables_in_Calculus"></span>Variables in Calculus<span></span></h3><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/calculus-analysis-symbols/#Constants_and_Variables" target="_blank" rel="noopener noreferrer"><strong>constants and variables in calculus</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td> $f(x), g(x,y),h(z)$</td><td><strong>Functions</strong></td><td> $f(2) = g(3,1) + 5$</td></tr><tr><td> $a_n, b_n, c_n$</td><td><strong>Sequences</strong></td><td> $\displaystyle a_ n = \frac{3}{n+2} $</td></tr><tr><td> $h, \Delta x$</td><td><strong>Limiting variables</strong> in derivatives</td><td> $\displaystyle \lim_{h \to 0} \frac{e^{h}-e^{0}}{h} = 1$</td></tr><tr><td> $\delta, \varepsilon$</td><td><strong>Small quantities</strong> in <a href="https://en.wikipedia.org/wiki/(%CE%B5,_%CE%B4)-definition_of_limit#Precise_statement_and_related_statements" target="_blank" aria-label="proofs involving limits (opens in a new tab)" rel="noreferrer noopener">proofs involving limits</a></td><td> For all $\varepsilon &gt;0$, there is a $\delta &gt;0$ such that $|x|&lt;\delta$ implies $|2x|&lt;\varepsilon$.</td></tr><tr><td> $F(x), G(x)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Antiderivative" target="_blank" aria-label="Antiderivatives (opens in a new tab)" rel="noreferrer noopener">Antiderivatives</a></strong></td><td> $F(x)’ = f(x)$</td></tr></tbody></table></figure><h3><span id="Variables_in_Linear_Algebra"></span>Variables in Linear Algebra<span></span></h3><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/algebra-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>variables in algebra</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td> $\mathbf{u}, \mathbf{v}, \mathbf{w}$</td><td><strong>Vectors</strong></td><td> $3\mathbf{u}+4\mathbf{v}=\mathbf{w}$</td></tr><tr><td> $A, B, C$</td><td><strong>Matrices</strong></td><td> $AX = B$</td></tr><tr><td> $\lambda$</td><td><strong><a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Formal_definition" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">Eigenvalues</a></strong></td><td> $A\mathbf{v}=\lambda \mathbf{v}$</td></tr></tbody></table></figure><h3><span id="Variables_in_Set_Theory_and_Logic"></span>Variables in Set Theory and Logic<span></span></h3><p>For more comprehensive lists on the topics, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/logic-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>variables in logic</strong></a> and <a href="https://mathvault.ca/hub/higher-math/math-symbols/set-theory-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>variables in set theory</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td>$A, B, C$</td><td><strong>Sets</strong></td><td>$A \subseteq B \cup C$</td></tr><tr><td>$a, b, c$</td><td><strong>Elements</strong></td><td>$a \in A$</td></tr><tr><td> $P, Q, R$</td><td><strong>Propositions</strong></td><td> $P \lor \lnot P \equiv \top$</td></tr></tbody></table></figure><h3><span id="Variables_in_Probability_and_Statistics"></span>Variables in Probability and Statistics<span></span></h3><p>For a more comprehensive list, see <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Variables" target="_blank" rel="noopener noreferrer"><strong>variables in probability and statistics</strong></a>.</p><figure><table><thead><tr><th>Symbol(s)</th><th>Used For</th><th>Example</th></tr></thead><tbody><tr><td> $X, Y, Z$</td><td><strong><a href="https://en.wikipedia.org/wiki/Random_variable#Definition" target="_blank" aria-label="Random variables (opens in a new tab)" rel="noreferrer noopener">Random variables</a></strong></td><td>$E(X + Y) =$ <br>$E(X) + E(Y)$</td></tr><tr><td>$\mu$</td><td><strong>Population means</strong></td><td>$H_0\!:\mu = 5$</td></tr><tr><td>$\sigma$</td><td><strong>Population standard deviations</strong></td><td>$\sigma_1 = \sigma_2$</td></tr><tr><td>$s$</td><td><strong>Sample standard deviations</strong></td><td>$s \ne \sigma$</td></tr><tr><td>$n$</td><td><strong>Sample sizes</strong></td><td>If $n\ge 30$, use the normal distribution.</td></tr><tr><td>$\rho$</td><td><strong>Population correlations</strong></td><td>$H_a\!: \rho &lt; 0$</td></tr><tr><td>$r$</td><td><strong>Sample correlations</strong></td><td>If $r = 0.75$, then $r^2 = 0.5625$.</td></tr><tr><td>$\pi$</td><td><strong>Population proportions</strong></td><td>$\pi = 0.5$</td></tr><tr><td>$p$</td><td><strong>Sample proportions</strong></td><td>$p = \dfrac{X}{n}$</td></tr></tbody></table></figure><h2><span id="Delimiters"></span>Delimiters<span></span></h2><p><span data-wfid="0ff7d9a9b3d1"><span>Similar to punctuation marks in English, delimiters are a set of symbols which indicate the <strong>boundaries</strong> between independent mathematical expressions. They are often used to specify the scope for which an operation or rule would apply, and can occur both as an isolate symbol or as a pair of opposite-looking symbols.</span></span></p><p><span data-wfid="8b278eb88b07"><span>In many scenarios, delimiters are used primarily for <strong>grouping purposes</strong>. The following table features some of the most commonly-used delimiters, along with their function and usage.</span></span></p><figure><table><thead><tr><th>Symbol(s)</th><th>Function</th><th>Example</th></tr></thead><tbody><tr><td>$.$</td><td><strong><a href="https://en.wikipedia.org/wiki/Decimal_separator" target="_blank" aria-label="Decimal separator (opens in a new tab)" rel="noreferrer noopener">Decimal separator</a></strong></td><td>$25.9703$</td></tr><tr><td>$:$</td><td><strong><a href="https://en.wikipedia.org/wiki/Ratio#Notation_and_terminology" target="_blank" aria-label="Ratio indicator (opens in a new tab)" rel="noreferrer noopener">Ratio indicator</a></strong></td><td>$1:4:9 =$<br>$3:12:27$</td></tr><tr><td>$,$</td><td><strong><a href="https://mathworld.wolfram.com/Comma.html" target="_blank" aria-label="Object separator (opens in a new tab)" rel="noreferrer noopener">Object separator</a></strong></td><td>$(3, 5, 12)$</td></tr><tr><td>$(), [], \{\}$</td><td><strong><a aria-label="Order-of-operation (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Order_of_operations" target="_blank">Order-of-operation</a> indicators</strong></td><td>$(a + b) \times c$</td></tr><tr><td>$(), []$</td><td><strong><a href="https://en.wikipedia.org/wiki/Bracket_(mathematics)#Intervals" target="_blank" aria-label="Interval indicators (opens in a new tab)" rel="noreferrer noopener">Interval indicators</a></strong></td><td>$3\notin (3,4]$,<br> $4 \in (3,4]$.</td></tr><tr><td> $(), []$</td><td><strong>Vector/matrix builder</strong></td><td> $\begin{pmatrix} 1 &amp; 4 \\ 3 &amp; 6 \end{pmatrix}$</td></tr><tr><td>$\{\}$</td><td><strong>Set builder</strong></td><td>$\{ \pi, e, i\}$</td></tr><tr><td>$|$, $\, :$</td><td><strong><a href="https://en.wikipedia.org/wiki/Set-builder_notation#Sets_defined_by_a_predicate" target="_blank" aria-label="&quot;Such that&quot; markers (opens in a new tab)" rel="noreferrer noopener">“Such that” markers</a></strong></td><td>$\{ x \in \mathbb{R} \, |\, x^2 – 2 =0 \}$</td></tr><tr><td>$| |, \| \|$</td><td><strong><a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Notation" target="_blank" aria-label="Norm-related operators (opens in a new tab)" rel="noreferrer noopener">Norm-related operators</a></strong></td><td>$\| (3, 4) \| = 5$</td></tr><tr><td>$\begin{cases}\end{cases}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Piecewise#Notation_and_interpretation" target="_blank" aria-label="Piecewise-function marker (opens in a new tab)" rel="noreferrer noopener">Piecewise-function marker</a></strong></td><td>$f(x) = \begin{cases} 1 &amp; x \ge 0 \\ 0 &amp; x &lt; 0 \end{cases}$</td></tr><tr><td>$\langle\rangle$</td><td><strong><a href="https://en.wikipedia.org/wiki/Inner_product_space#Definition" target="_blank" aria-label="Inner product (opens in a new tab)" rel="noreferrer noopener">Inner product</a> operator</strong></td><td>$\langle ka, b\rangle = k\langle a, b \rangle$</td></tr><tr><td>$\lceil \rceil$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Ceiling operator (opens in a new tab)" rel="noreferrer noopener">Ceiling operator</a></strong></td><td>$\lceil 2.476 \rceil = 3$</td></tr><tr><td>$\lfloor \rfloor$</td><td><strong><a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" target="_blank" aria-label="Floor operator (opens in a new tab)" rel="noreferrer noopener">Floor operator</a></strong></td><td>$\lfloor \pi \rfloor = 3$</td></tr></tbody></table></figure><h2><span id="Operators"></span>Operators<span></span></h2><p>An operator is a symbol used to denote an <strong><a href="https://mathvault.ca/math-glossary/#operation">operation</a></strong> — a function which takes one or multiple objects to another similar object. Most of the operators are unary and binary in nature (i.e., taking one and two inputs to their …</p></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/hub/higher-math/math-symbols/">https://mathvault.ca/hub/higher-math/math-symbols/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23630288</guid>
            <pubDate>Wed, 24 Jun 2020 16:40:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture]]>
            </title>
            <description>
<![CDATA[
Score 341 | Comments 311 (<a href="https://news.ycombinator.com/item?id=23630201">thread link</a>) | @kickout
<br/>
June 24, 2020 | http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23630201</guid>
            <pubDate>Wed, 24 Jun 2020 16:36:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redash Is Joining Databricks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23629862">thread link</a>) | @atriix
<br/>
June 24, 2020 | https://blog.redash.io/redash-joins-databricks/ | <a href="https://web.archive.org/web/*/https://blog.redash.io/redash-joins-databricks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                <div>
                    <p>We’re happy to announce that Redash is joining Databricks. We’ve been an open-source company grounded in helping our community of users make sense of their data. We found this same culture and values in Databricks, and we’re excited to be able to carry on our vision to democratize access to data — now in a larger home where we can bring this to even more people.</p><p>We’re excited to be one of the many open-source projects that Databricks supports. They’re the original creators of Apache Spark™, the standard for large-scale data processing, as well as Delta Lake for reliable data lakes, MLflow for the machine learning lifecycle, Koalas for data science productivity on Spark. Now, Redash joins this community of open source projects for collaborative SQL queries and dashboarding. We look forward to growing the Redash engineering team and have a lot of plans in our road map to deliver an even better experience with Redash, with more functionality, security and support. Open Source Redash remains in its current code repo, and we will be releasing a new v9 shortly so stay tuned for more details.</p><p>As part of this acquisition, we will be offering a new way to use Redash from directly within Databricks. For our current Redash SaaS paid customers, your service will continue unchanged, and we will be sharing more details in the coming months on how we’re planning to expand the service. You can learn more in our <a href="https://redash.io/help/faq/databricks">customer FAQ</a>.</p>
                </div>
            </section>

            


        </article>


    </div>
</div></div>]]>
            </description>
            <link>https://blog.redash.io/redash-joins-databricks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629862</guid>
            <pubDate>Wed, 24 Jun 2020 16:20:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New technology for aluminum production promises zero CO2 emission]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 67 (<a href="https://news.ycombinator.com/item?id=23629859">thread link</a>) | @dagurp
<br/>
June 24, 2020 | https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/ | <a href="https://web.archive.org/web/*/https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  
    

        
          <p>
 A new Icelandic technology intended for aluminum production offers hopes of eliminating CO2 emissions from the production,
 <em>
  <a href="https://www.mbl.is/frettir/innlent/2020/06/22/gaeti_minnkad_losun_co2_um_thridjung/" target="_blank">
   mbl.is
  </a>
 </em>
 reports.
</p>

        
          <p>
 The company Arctus Metals, in cooperation with Innovation Center Iceland, reached a milestone recently, when it successfully produced aluminum with this new method in a large pot. Instead of creating CO2 emissions, the process emits oxygen.
</p>

        
          <p>
 The main part of the innovation consists of using multiple,&nbsp;vertical inert metal-alloy anodes and ceramic cathodes, instead of using electrodes made of carbon.
</p>

        
          <p>
 This innovation could potentially eliminate CO2 emissions from aluminum smelters in Iceland and elsewhere.
</p>

        
          
  
  

  



        
          <p>
 “Iceland’s three aluminum smelters produce more than 800,000 tons of aluminum a year and emit more than 1.6 million tons of CO2 a year,” states Arctus Metals CEO Jón Hjaltalín Magnússon. “Their emissions make up 30 percent of Iceland’s total CO2 emissions.”
</p>

        
          <p>
 “If all our aluminum smelters adopted this new technology, Iceland’s CO2 emissions would be reduced by 30 percent,
 <span>
  ”
 </span>
 he adds,
 <span>
  “
 </span>
 enabling us to fulfill our international obligations and more. Using the new Arctus Metals method, an aluminum smelter, the size of [Rio Tinto’s] in Straumsvík [Southwest Iceland] would produce as much oxygen as a forest covering 500 square kilometers.”
</p>

        
          <p>
 Jón reports that a cooperation agreement has been signed between the German company Trimet Aluminum, one of the world’s largest producers of aluminum, which will continue the development process by starting production in larger pots, and planning to eventually convert production in their four smelters to this method.
</p>

        
          <p>
 The project was presented to Icelandic President Guðni Th. Jóhannesson yesterday at the offices of Innovation Center Iceland.
</p>

        
          <p>
 In the video above, you can see the first chunk of aluminum processed in this new way, presented by CEO Jón Hjaltalín Magnússon.
</p>

        
          <p>
 You can read more about the company and the project
 <a href="http://www.sustainordic.com/portfolio/items/arctus-metals/" target="_blank">
  here
 </a>
 .
</p>

    

  

  

      </div></div>]]>
            </description>
            <link>https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629859</guid>
            <pubDate>Wed, 24 Jun 2020 16:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Relay by Puppet: IFTTT for DevOps]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23629644">thread link</a>) | @bradhe
<br/>
June 24, 2020 | https://relay.sh/blog/relay-public-beta/ | <a href="https://web.archive.org/web/*/https://relay.sh/blog/relay-public-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today we announce <a href="https://relay.sh/">Relay</a>, an event-driven automation platform. <a href="https://app.relay.sh/signup">Sign up now</a> and try it out! Relay connects infrastructure and operations platforms, APIs, and tools together into a cohesive, easy-to-automate whole. Relay is simple enough for you to start automating common, <em>if-this-then-that</em> (IFTTT) style DevOps tasks in minutes and powerful enough to model multi-step, branching, parallelized DevOps processes when the need arises.</p>
<p>Why bother? Because for all the progress we’ve made as builders and operators, <a href="https://landscape.cncf.io/">things are more complicated than ever</a>. Modern applications comprise a growing variety of runtimes, clouds, infrastructure platforms, 3rd party services, and APIs. Mounting sophistication (<a href="https://www.youtube.com/watch?v=dtI5dMpBmQo">and complexity</a>) of how applications are constructed complicates how we operate and manage them. As a result, accomplishing many basic operational tasks can involve touching many different components, with different APIs, different semantics, from different upstreams, vendors and dev teams. Connecting all of these components together is tough, and automating anything across them all can range from tedious to nightmare fuel.</p>
<p>At layers above the plumbing, <a href="https://relay.sh/blog/rise-of-the-apis/">managing infrastructure stops looking like classic configuration management and starts looking like orchestrating workflows</a>. However, workflows can be tricky. Connectivity, secrets handling, event listening, ordering, parallelism, error handling, and control flow all conspire to make writing workflows from scratch pretty gnarly. The complexity adds up fast. We can do better!</p>
<blockquote>
<p>“Automated workflows are the bedrock of all software organizations.”<br>
— Jason Warner, CTO @ GitHub</p>
</blockquote>
<p>Relay lets you represent any DevOps workflow as code, composed of triggers that listen for incoming events, and steps that define the task you’re automating. Relay does not limit what you can talk to. A single workflow could listen for alerts from PagerDuty, query metrics from DataDog, reconfigure infrastructure with Terraform, and send a notification via Slack. It’s easy to leverage pre-existing triggers, steps, and workflows, and it’s simple to make your own if the need arises.</p>
<p>As a hosted service, Relay supervises things on your behalf. It will automatically trigger your workflow based on incoming events, execute your workflow’s steps in parallel, notify you if you need to intervene, and keep meticulous records of everything done. Relay does this all automatically, so you don’t have to.</p>
<p>Today, we’re proud to announce <a href="https://relay.sh/">beta availability</a> for Relay. Read on to see how it works!</p>
<h2>Workflows</h2>
<p>Relay’s core method of automation is <a href="https://relay.sh/docs/using-workflows/"><em>the workflow</em></a>. Workflows combine useful activities together to accomplish a particular task:</p>
<ul>
<li>When we detect an unused Azure Disk, delete it <em>(so we can save money)</em></li>
<li>When they go unused, nuke any AWS authentication keypairs <em>(so we can reduce our attack surface)</em></li>
<li>When a PagerDuty alert fires with a certain severity, create tickets in Jira and a room in Slack <em>(so we can more quickly troubleshoot issues)</em></li>
</ul>
<p>Relay lets you succinctly express these types of workflows, and beyond, <a href="https://relay.sh/docs/reference/relay-workflows/">as code</a>. And like code, workflows can be versioned, reviewed, refactored, and reused. We’re Puppet; <a href="https://www.google.com/search?hl=en&amp;q=puppet%20infrastructure%20as%20code">we wouldn’t have it any other way</a>.</p>
<p>Running your first workflow is easy, and should only take you about a minute. As tradition demands, here’s “Hello, world” (<a href="https://app.relay.sh/login">log in</a> and follow along!):</p>
<p><img src="https://relay.sh/debec11953b60317076234251dc8c4f0/hello-world.gif" alt="Hello, world!"></p>
<p>Because workflows are code, you can treat them like code. Modifying a workflow is straightforward. Let’s change the workflow, adding a step to emit the current date:</p>
<p><img src="https://relay.sh/2105fe13ad95afadea7d0e9dc45e3976/cli.gif" alt="Change the workflow using the CLI"></p>
<p>That covered <a href="https://relay.sh/docs/getting-started/#install-the-cli">getting the CLI installed</a>, authenticating against the service, downloading your workflow, modifying the logic, and then letting Relay know the code is updated.</p>
<h2>Triggers and steps</h2>
<p>Workflows contain <em>triggers</em> and <em>steps</em>: Triggers determine when Relay should execute your workflow: manually, on a schedule, or when pinged by an external source. Steps represent the set of actions and activities necessary to make your workflow accomplish its goals. Steps are just <a href="https://www.docker.com/resources/what-container">containers</a>, so you’re pretty unconstrained when it comes to what a step can do. Both triggers and steps <a href="https://relay.sh/docs/integrating-with-relay/">are easy to create, remix, and share</a>. With these building blocks, Relay is capable of modeling a huge variety of workflows, and executing them on your behalf. There are a bunch already written, and it’s straightforward to <a href="https://relay.sh/docs/getting-started/">make your own</a>.</p>
<p>Here’s a more interesting example workflow that <a href="https://relay.sh/workflows/ec2-reaper/">cleans up some unneeded EC2 instances</a>. It has more steps, including some that consume AWS credentials, and one which represents a <em>manual approval</em> gate:</p>
<p><img src="https://relay.sh/18f91058f6a39345a357bc6d72855ed8/ec2-reaper.gif" alt="Cleaning up some EC2 instances"></p>
<p>It’s easy to add, remove, or replace triggers and steps to suit your liking. Some modifications for the preceding example could include adding a webhook-based trigger for the workflow, adding a notification step at the end, or better integrating it into your GitOps setup. Perhaps a step that takes the list of terminated instances, computes their money you just saved, then buys an equivalent amount of stuff from your Amazon wish list? Ops is hard work - treat yourself!</p>
<p>Our examples thus far have shown short, linear sequences of steps but you can also express some pretty elaborate processes just as easily. Here’s a picture of the execution graph of one of workflows we use to manage Relay itself:</p>
<p><span>
      <a href="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/065ce/relay-graph.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="A more complex workflow graph" title="A more complex workflow graph" src="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/64756/relay-graph.png" srcset="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/a8a0d/relay-graph.png 300w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/dface/relay-graph.png 600w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/64756/relay-graph.png 1200w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/28bdc/relay-graph.png 1800w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/98e2c/relay-graph.png 2400w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/065ce/relay-graph.png 2680w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
  </a>
    </span></p>
<h2>The Relay service</h2>
<p>Listening for events and running workflows might appear conceptually simple, but there are a lot of practical details that need to be worked out. Relay’s execution environment (and <a href="https://github.com/puppetlabs/relay-core">underlying engine</a>):</p>
<ul>
<li>Manages <a href="https://relay.sh/docs/using-workflows/adding-connections/">connections</a> to upstream/downstream APIs and services, making them securely available to the workflows that need them</li>
<li>Automatically creates <a href="https://relay.sh/docs/reference/relay-workflows/#push"><em>push triggers</em></a> for your workflows, complete with workflow-specific security tokens, so you can easily kick it off from all kinds of other tools</li>
<li>Automatically constructs an environment for running webhooks, so your workflows can respond to events from webhook-only services</li>
<li>Sandboxes workflow and step execution, for fault isolation</li>
<li>Manages your workflows with all the necessary <em>ops accoutrements</em> (e.g. monitoring, logging, error handling)</li>
<li>Supervises the execution of your workflows, invoking steps in the right order (with automatic parallelization)</li>
<li>Standardizes the interfaces between all these pieces so steps, triggers, and connections are reusable and remixable across workflows</li>
</ul>
<p>Relay takes care of this stuff so you don’t have to. Instead, you can focus on the logic of your workflow, the core of what you’re trying to automate.</p>
<p>After all, isn’t that the point?</p>
<h2>Automation for everyone</h2>
<p>How many unique applications are running out there across the planet (<a href="https://twitter.com/lkanies/status/1182350689529298944">or above it</a>)? Thousands? Millions? <a href="https://www.merriam-webster.com/dictionary/bajillion">Bajillions</a>? How many of them are running on identical infrastructure stacks, built with identical technology stacks, managed in identical ways at an identical scale? There’s a truly staggering variety of approaches and constraints.</p>
<p>If there’s no <em>One True Stack</em>, then there’s no <em>One True Way To Manage It</em>. The tools you employ should thrive in this sort of world because that’s the world we’ve got.</p>
<p>Relay’s core value lies in letting you tie a <a href="https://relay.sh/integrations/">wide variety of services, APIs, and platforms</a> together. It’s constructed in a deliberately pluggable way. Users can readily extend the system to talk to new technologies, respond to new kinds of events, and take action in new ways…no CS degree required. Those extensions should be easy to share, so the entire user community can benefit. The ecosystems around the tools we use are every bit as important as the tools themselves.</p>
<p>Even though it’s early days, Relay can already do quite a lot. The future holds many possibilities: new workflows, more integrations with more tools and platforms, higher-level workflow syntax, a more streamlined authoring experience, simplified input/output from steps, and more. Early users have already given us a ton of great suggestions, and we’d love to hear yours!</p>
<h2>Next steps</h2>
<p>The next step (and best step) is to <a href="https://relay.sh/">try it out</a>! And if you’d like to learn more about Relay, you can check out:</p>
<ul>
<li><a href="https://relay.sh/blog/relay-and-open-source/">How to get involved</a>, extend Relay to better meet your needs, and become part of Relay community</li>
<li><a href="https://relay.sh/docs/">The documentation</a> does a great job of introducing Relay, its usage, core concepts, and extension points</li>
<li><a href="https://relay.sh/workflows/">Peruse some workflows</a> to see what they can do. The code and its graphical execution plan are available on every workflow’s page.</li>
<li><a href="https://puppetcommunity.slack.com/archives/CMKBMAW2K">Slack</a> - come linger in the #relay channel! The more the merrier</li>
</ul>
<p>Thanks, and let a thousand workflows bloom!</p></section></div>]]>
            </description>
            <link>https://relay.sh/blog/relay-public-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629644</guid>
            <pubDate>Wed, 24 Jun 2020 16:07:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Sborex, a minimal-code visual service designer with web builder (POC)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23629607">thread link</a>) | @fedd
<br/>
June 24, 2020 | http://sborex.com/poc/ | <a href="https://web.archive.org/web/*/http://sborex.com/poc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>
                    This is a P.O.C. of a flexible and visually configurable platform for creation of different 
                    kinds of applications, from small micro-services to enterprise-level information systems.
                </p>
                <p>
                    In a nutshell, Sborex is a visual diagram 
                    execution engine with extended web and integration capabilities.
                </p>
                <p><a href="http://sborex.com/poc/sborex-poc.jar">Download</a></p><p>
                    It runs on Java and starts a webserver on port <span>8585</span>.
                </p>

                <h2>
                    What's Inside
                </h2>
                <p>
                    This is a demo app to try how the system will work. 
                   The entities described below are automatically deployed for demonstration purposes.
                </p>

                <h3>
                    Customer
                </h3>
                <p>                    
                    This is an example of a customer record representation and a contact dialogue initial form.
                </p>
                <p>
                    <img src="http://sborex.com/poc/customer.png" alt="Customer View">
                </p>
                <p>
                    The customer lifecycle process and a simple interaction script
                    for a user contacting the customer are defined in a 
                    <a href="http://www.bpmn.org/">BPMN</a>-like diagram:
                </p>
                <p>
                    <img src="http://sborex.com/poc/customer.svg" alt="Customer Process Definition">
                </p>
                <p>
                    The User Tasks and the customer data presentations are designed visually in a view editor:
                </p>
                <p>
                    <img src="http://sborex.com/poc/form.png" alt="Customer Process Definition">
                </p>

                <p>
                    <img src="http://sborex.com/poc/view.png" alt="Customer Process Definition">
                </p>






                <h3>
                    Register
                </h3>
                <p>
                    The Register flowchart defines a process that acquires a customer data file via web or from a filesystem, 
                    transforms it and then passes to a Customer process, iterating over each line of the input file.
                </p>
                <p>
                    Note the integration points that are serviced by embedded <a href="https://camel.apache.org/">Apache Camel</a> 
                    framework.
                </p>
                <p>
                    <img src="http://sborex.com/poc/register.svg" alt="Register Process Definition">
                </p>


                <h3>
                    SIP Server
                </h3>
                <p>
                    This process demonstrates how a simple or complex technical service can be designed in the system. Any of the 
                    <a href="https://camel.apache.org/components/latest/">Camel components</a> can be used with or without 
                    little initial configuration, all made in a Sborex process definition.
                </p>
                <p>
                    <img src="http://sborex.com/poc/sipserver.svg" alt="SIP Server Process Definition">
                </p>

                <h3>
                    Session
                </h3>
                <p>
                    This is a technical process that gets started for each of the new web sessions. 
                </p>
                <p>
                    With the help of LDAP integration process elements
                    it may query your enterprise user database for roles and permissions, or you may configure access to a custom 
                    user storage, but currently it just stores the username entered by the user.
                </p>
                <p>
                    For simplicity this process also provides a process editor available to the user right on the app's home page.
                </p>
                <p>
                    <img src="http://sborex.com/poc/session.svg" alt="Session Process Definition">
                </p>



                <h2>
                    Try It Yourself
                </h2>
                <p>
                    To try it out, download the Java executable file below:
                </p>
                <p><a href="http://sborex.com/poc/sborex-poc.jar">Download</a></p><p>
                    Place it in a dedicated folder as it will create a database directory and files along with it.
                </p>
                <p>
                    Run it as a Java program:
                </p>
                <p>
                    java -jar sborex-poc.jar
                </p>
                <p>
                    After the system starts go to the system's web server:
                </p>
                <p>
                    <a href="http://localhost:8585/">http://localhost:8585/</a>
                </p>
                <p>
                    (Replace <span>localhost</span> with the actual machine address if you are accessing 
                    it from outside the running host)
                </p>
                <p>
                    Log in as a user with the name <span>fedd</span> and start exploring the system.
                </p>
                <p>
                    In process definition editor pages, you may click the elements (rectangles, circles and diamonds) 
                    and choose the gear icon to see the element configuration.
                </p>
                <p>
                    <img src="http://sborex.com/poc/edit.png" alt="Customer Process Definition">
                </p>
                <h3>
                    Load File and See Customers
                </h3>
                <p>
                    To test the load and transform capabilities, go to 
                </p>
                <p>
                    <a href="http://localhost:8585/register">http://localhost:8585/register</a>
                </p>
                <p>
                    and follow the instructions. 
                </p>

                <h3>
                    Troubleshooting
                </h3>
                <p>
                    If the ports 8585 and 5060 are occupied on the host machine, we may override the default 
                    configuration by providing other port numbers at start time:
                </p>
                <p>
                    java -jar sborex-poc.jar -Dintegration.web.port=8586 -Dintegration.sip.port=5061
                </p>

                <h2>
                    Technical Details
                </h2>
                <p>
                    The system is written in Java and is able to run on versions 8+. It doesn't utilize Spring Boot or Spring whatsoever. 
                    It's not based on any of the opensource BPMN engines.
                </p>
                <p>
                    Apache Camel included in the system is of version 2.24.0. It runs an embedded Jetty webserver 
                    for the web pages, rest services and websockets.
                </p>
                <p>
                    For the demo it is configured to run with Derby database, also embedded version. It can be configured to use 
                    PostgreSQL or any other relational database servers or Elasticsearch as its datastore.
                </p>
                <p>
                    The neat <a href="https://bpmn.io/">bpmn.io</a> library is used for displaying and editing the process definitions. 
                    There are plans to add a modeler specifically designed for Sborex to ease the use of the system's features that are not 
                    actually compliant with BMPN standard.
                </p>
                <p>
                    There is also a thirdparty web page designer that opens by Edit Layout button wherever the element is accompanied with 
                    a web page template. (Please note that it is not yet fully integrated.)
                </p>

                <h2>
                    Status and Prospects
                </h2>
                <p>
                    Sborex is currently not production ready and requires further investment. 
                    The current refactoring iteration may experience performance problems under high load.
                </p>
                <p>
                    As mentioned before, the current process modeler will also be redesigned. Visual editors 
                    for transformation, service, configuration artifacts will also be added to provide a 
                    "low code" experience.
                </p>
                <p>
                    The latest refactoring effort was taken to get the product ready for embedding the neural 
                    networking solutions and distributed computing for higher loads. 
                </p>

                <h2>
                    Contact
                </h2>
                <p>
                    My name is Fyodor "Fedd" Kravchenko. You may contact me via <a href="https://www.linkedin.com/in/kfedd/">LinkedIn</a> or 
                    drop me <a href="mailto:info@sborex.com">an email</a>. 
                </p>

            </div></div>]]>
            </description>
            <link>http://sborex.com/poc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629607</guid>
            <pubDate>Wed, 24 Jun 2020 16:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Active Record: Using Subqueries in Rails]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23629450">thread link</a>) | @moritzplassnig
<br/>
June 24, 2020 | https://pganalyze.com/blog/active-record-subqueries-rails | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/active-record-subqueries-rails">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Active Record provides a great balance between the ability to perform simple queries simply, and also the ability to access the raw SQL sometimes required to get our jobs done. In this article, we will see a number of real-life examples of business needs that may arise at our jobs.</p>
<p>They will come in the form of a request for data from someone else at the company, where we will first translate the request into SQL, and then into the Rails code necessary to find those records. We will be covering five different types of subqueries to help us find the requested data.</p>
<p>Let's take a look at why subqueries matter:</p>
<!-- -->

<svg version="1.1" xmlns:xl="http://www.w3.org/1999/xlink" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns="http://www.w3.org/2000/svg" viewBox="29.5 167 879.5 452" width="879.5" height="452">
  <defs>
    <font-face font-family="Helvetica Neue" font-size="16" panose1="2 0 8 3 0 0 0 9 0 4" units-per-em="1000" underline-position="-100" underline-thickness="50" slope="0" x-height="524" cap-height="722" ascent="975.0061" descent="-216.99524" font-weight="700">
      <font-face-src>
        <font-face-name name="HelveticaNeue-Bold"></font-face-name>
      </font-face-src>
    </font-face>
    <marker orient="auto" overflow="visible" markerUnits="strokeWidth" id="FilledArrow_Marker" strokelinejoin="miter" strokemiterlimit="10" viewBox="-1 -4 10 8" markerWidth="10" markerHeight="8" color="#cc0102">
      <g>
        <path d="M 8 0 L 0 -3 L 0 3 Z" fill="currentColor" stroke="currentColor" stroke-width="1"></path>
      </g>
    </marker>
    <marker orient="auto" overflow="visible" markerUnits="strokeWidth" id="Arrow_Marker" strokelinejoin="miter" strokemiterlimit="10" viewBox="-1 -4 10 8" markerWidth="10" markerHeight="8" color="#346591">
      <g>
        <path d="M 8 0 L 0 -3 L 0 3 Z" fill="none" stroke="currentColor" stroke-width="1"></path>
      </g>
    </marker>
    <marker orient="auto" overflow="visible" markerUnits="strokeWidth" id="FilledArrow_Marker_2" strokelinejoin="miter" strokemiterlimit="10" viewBox="-1 -4 10 8" markerWidth="10" markerHeight="8" color="#cb0200">
      <g>
        <path d="M 8 0 L 0 -3 L 0 3 Z" fill="currentColor" stroke="currentColor" stroke-width="1"></path>
      </g>
    </marker>
    <font-face font-family="Monaco" font-size="14" units-per-em="1000" underline-position="-37.597656" underline-thickness="75.68359" slope="0" x-height="545.41016" cap-height="757.8125" ascent="1000" descent="-250" font-weight="400">
      <font-face-src>
        <font-face-name name="Monaco"></font-face-name>
      </font-face-src>
    </font-face>
    <font-face font-family="Monaco" font-size="13" units-per-em="1000" underline-position="-37.597656" underline-thickness="75.68359" slope="0" x-height="545.41016" cap-height="757.8125" ascent="1000" descent="-250" font-weight="400">
      <font-face-src>
        <font-face-name name="Monaco"></font-face-name>
      </font-face-src>
    </font-face>
  </defs>
  <g id="Canvas_1" style="stroke-dasharray:none" fill-opacity="1" fill="none" stroke-opacity="1" stroke="none">
    <title>Canvas 1</title>
    <g id="Canvas_1: Layer 1">
      <title>Layer 1</title>
      <g id="Graphic_2">
        <rect x="765.5" y="177" width="133.5" height="43.75" fill="#326691"></rect>
        <text transform="translate(770.5 189.14294)" fill="white">
          <tspan font-family="Helvetica Neue" font-size="16" font-weight="700" fill="white" x="27.67" y="16">Postgres</tspan>
        </text>
      </g>
      <g id="Graphic_3">
        <rect x="39.5" y="177" width="133.5" height="43.75" fill="#cc0100"></rect>
        <text transform="translate(44.5 189.14294)" fill="white">
          <tspan font-family="Helvetica Neue" font-size="16" font-weight="700" fill="white" x="42.958" y="16">Rails</tspan>
        </text>
      </g>
      <g id="Graphic_9">
        <text transform="translate(309.538 466.27576)" fill="black">
          <tspan font-family="Helvetica Neue" font-size="16" font-weight="700" fill="black" x="0" y="16">Advanced Active Record with Subqueries:</tspan>
        </text>
      </g>
      <g id="Line_12">
        <line x1="106.25" y1="220.75" x2="106.25" y2="608.5" stroke="#c00" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Line_13">
        <line x1="831.75" y1="220.75" x2="831.75" y2="608.5" stroke="#326690" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Line_15">
        <line x1="117.5" y1="296.5" x2="811.1" y2="296.5" marker-end="url(#FilledArrow_Marker)" stroke="#cc0102" stroke-width="1"></line>
      </g>
      <g id="Line_17">
        <line x1="821" y1="328" x2="127.4" y2="328" marker-end="url(#Arrow_Marker)" stroke="#346591" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Line_18">
        <line x1="117.5" y1="375" x2="811.1" y2="376.97186" marker-end="url(#FilledArrow_Marker_2)" stroke="#cb0200" stroke-width="1"></line>
      </g>
      <g id="Graphic_20">
        <text transform="translate(350.01 224.35327)" fill="black">
          <tspan font-family="Helvetica Neue" font-size="16" font-weight="700" fill="black" x="0" y="16">Simple usage of Active Record:</tspan>
        </text>
      </g>
      <g id="Graphic_21">
        <rect x="94.5" y="293" width="22.5" height="119" fill="#cc0100"></rect>
      </g>
      <g id="Graphic_25">
        <rect x="821" y="293" width="22.5" height="38.25049" fill="#326691"></rect>
      </g>
      <g id="Graphic_40">
        <text transform="translate(320.5 273.54273)" fill="black">
          <tspan font-family="Monaco" font-size="14" font-weight="400" fill="black" x="0" y="14">SELECT AVG(salary) FROM employees</tspan>
        </text>
      </g>
      <g id="Graphic_43">
        <text transform="translate(431.8181 309.16504)" fill="black">
          <tspan font-family="Monaco" font-size="13" font-weight="400" fill="black" x="0" y="13">99306.4</tspan>
        </text>
      </g>
      <g id="Graphic_44">
        <text transform="translate(265.8911 352.83105)" fill="black">
          <tspan font-family="Monaco" font-size="14" font-weight="400" fill="black" x="0" y="14">SELECT * FROM employees WHERE salary &gt; 99306.4</tspan>
        </text>
      </g>
      <g id="Line_48">
        <line x1="821" y1="408.7495" x2="127.4" y2="408.7495" marker-end="url(#Arrow_Marker)" stroke="#346591" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Graphic_47">
        <rect x="821" y="372.64905" width="22.5" height="38.25049" fill="#326691"></rect>
      </g>
      <g id="Graphic_46">
        <text transform="translate(435.71875 389.91455)" fill="black">
          <tspan font-family="Monaco" font-size="13" font-weight="400" fill="black" x="0" y="13">Result</tspan>
        </text>
      </g>
      <g id="Line_53">
        <line x1="117.5" y1="534" x2="811.1" y2="534" marker-end="url(#FilledArrow_Marker_2)" stroke="#cb0200" stroke-width="1"></line>
      </g>
      <g id="Graphic_52">
        <text transform="translate(151.27197 511.0972)" fill="black">
          <tspan font-family="Monaco" font-size="14" font-weight="400" fill="black" x="0" y="14">SELECT * FROM employees WHERE salary &gt; (SELECT AVG(salary) FROM employees)</tspan>
        </text>
      </g>
      <g id="Line_51">
        <line x1="821" y1="565.0156" x2="127.4" y2="565.0156" marker-end="url(#Arrow_Marker)" stroke="#346591" style="stroke-dasharray:4.0,4.0" stroke-width="1"></line>
      </g>
      <g id="Graphic_50">
        <rect x="821" y="529.76514" width="22.5" height="38.25049" fill="#326691"></rect>
      </g>
      <g id="Graphic_49">
        <text transform="translate(438.71875 546.1807)" fill="black">
          <tspan font-family="Monaco" font-size="13" font-weight="400" fill="black" x="0" y="13">Result</tspan>
        </text>
      </g>
      <g id="Graphic_54">
        <rect x="94.5" y="530.0156" width="22.5" height="38.25049" fill="#cc0100"></rect>
      </g>
    </g>
  </g>
</svg>
<p>In the first case, without subqueries, we are going to the database twice: First to get the average salary, and then again to get the result set. With a subquery, we can avoid the extra roundtrip, getting the result directly with a single query.</p>
<h2 id="working-with-active-record-in-rails"><a href="#working-with-active-record-in-rails" aria-label="working with active record in rails permalink"></a>Working with Active Record in Rails</h2>
<p>Active Record is a little like a walled garden. It protects us as developers (and our users) from the harsh realities of what lies beyond those walls: Differences in SQL between databases (MySQL, Postgres, SQLite), knowing how to properly escape strings to avoid <a href="https://en.wikipedia.org/wiki/SQL_injection">SQL injection attacks</a>, and generally providing an elegant abstraction to interact with our database using the language of our choice, Ruby.</p>
<p>But, SQL is extremely powerful! By understanding the SQL that Active Record is executing, we can open the gate in our walled garden to <strong>reach beyond what you may think is possible to accomplish in Rails</strong>, taking advantage of optimizations and flexibility that may be difficult to achieve otherwise.</p>
<h2 id="what-are-subqueries-in-rails"><a href="#what-are-subqueries-in-rails" aria-label="what are subqueries in rails permalink"></a>What are Subqueries in Rails</h2>
<p>In this article, we will be learning how to use subqueries in Active Record. Subqueries are what their name implies: A query within a query. We will look at how to embed subqueries into the <code>SELECT</code>, <code>FROM</code>, <code>WHERE</code>, and <code>HAVING</code> clauses of SQL, to meet the demands of our business counterparts who are asking to view data in different and interesting ways.</p>
<p>We'll be playing the role of a developer fielding questions from HR. They are asking for reports about our employees at BCE (Best Company Ever), and we'll do our best to find the data they need using Active Record.</p>
<p>The <a href="https://github.com/pganalyze/subqueries-rails-example">source code for this article</a> is available on GitHub.</p>
<h2 id="an-overview-of-our-data"><a href="#an-overview-of-our-data" aria-label="an overview of our data permalink"></a>An Overview of our Data</h2>
<p>Our database has 4 tables:</p>
<ul>
<li><strong>roles</strong>: The job roles of our employees (Finance, Engineering, Sales, HR, etc...)</li>
<li><strong>employees</strong>: The people that work for BCE</li>
<li><strong>performance_reviews</strong>: Performance reviews carried out by an employee's manager, giving them a score between 0 and 100</li>
<li><strong>vacations</strong>: Keeping track of when employees have taken vacation</li>
</ul>
<p>Using <a href="https://dbdiagram.io/">https://dbdiagram.io/</a> we're able to see how these tables relate to each other:</p>
<p>
<span>
      <a href="https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/c2d9c/subqueries-rails-diagram-dark.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="An Overview of how 4 tables in our database relate to each other" title="An Overview of how 4 tables in our database relate to each other" src="https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/8c557/subqueries-rails-diagram-dark.png" srcset="https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/4edbd/subqueries-rails-diagram-dark.png 175w, https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/13ae7/subqueries-rails-diagram-dark.png 350w, https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/8c557/subqueries-rails-diagram-dark.png 700w, https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/e996b/subqueries-rails-diagram-dark.png 1050w, https://pganalyze.com/static/544de74e19f0479f8d32a99abbac1d1a/c2d9c/subqueries-rails-diagram-dark.png 1326w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
</p>
<p>If you are following along, the <code>rails db:seed</code> command will generate 1,000 employees, 1,000 vacations, and 10,000 performance reviews.</p>
<h2 id="the-where-subquery"><a href="#the-where-subquery" aria-label="the where subquery permalink"></a>The Where Subquery</h2>
<p>Now that we have our data set and we’re ready to go let’s help our HR team with their first request:</p>
<blockquote>
<p>Leigh, could you find us all the employees that make <em>more than the average salary</em> at BCE?</p>
</blockquote>
<p>Here we will use a subquery within the <code>WHERE</code> clause to find the employees that match HR's request:</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>*</span>
<span>FROM</span> employees
<span>WHERE</span>
  employees<span>.</span>salary <span>&gt;</span> <span>(</span>
    <span>SELECT</span> <span>avg</span><span>(</span>salary<span>)</span>
    <span>FROM</span> employees<span>)</span></code></pre></div>
<p>My first attempt at replicating the query above looked like this:</p>
<div data-language="ruby"><pre><code><span>Employee</span><span>.</span>where<span>(</span><span>'salary &gt; :avg'</span><span>,</span> avg<span>:</span> <span>Employee</span><span>.</span>average<span>(</span><span>:salary</span><span>)</span><span>)</span></code></pre></div>
<p><em>But what it produced was two queries</em>: One to find the average, and a second to query employees with a salary greater than that number. Not technically wrong, but <strong>it doesn't line up with the SQL we were going for.</strong> There is also a potential performance impact of two round-trip requests to the database server, along with potential inconsistencies if a new employee making $1B/year is hired between queries one and two. Although this is unlikely in this particular scenario, it’s something to consider as a potential risk.</p>
<div data-language="sql"><pre><code>
<span>SELECT</span> <span>AVG</span><span>(</span><span>"employees"</span><span>.</span><span>"salary"</span><span>)</span> <span>FROM</span> <span>"employees"</span>

<span>SELECT</span> <span>"employees"</span><span>.</span><span>*</span> <span>FROM</span> <span>"employees"</span> <span>WHERE</span> <span>(</span>salary <span>&gt;</span> <span>99306.4</span><span>)</span></code></pre></div>
<p>What we shouldn’t forget about <a href="https://guides.rubyonrails.org/active_record_querying.html">Active Record</a> is that certain methods, such as <code>average(:salary)</code>, actually execute the query and return a result, while other methods implement <a href="https://en.wikipedia.org/wiki/Method_chaining">Method Chaining</a>, allowing you to chain multiple Active Record methods together, building up more complex SQL statements prior to their execution.</p>
<div data-language="ruby"><pre><code><span>Employee</span><span>.</span>where<span>(</span><span>'salary &gt; (:avg)'</span><span>,</span> avg<span>:</span> <span>Employee</span><span>.</span>select<span>(</span><span>'avg(salary)'</span><span>)</span><span>)</span></code></pre></div>
<p>This produces the SQL we want, but note that we had to wrap the placeholder condition <code>:avg</code> in brackets, because the database wants subqueries wrapped in brackets as well.</p>
<p>Because the seed data is generated randomly, your results will vary from mine, but I am seeing <em>487</em> matching employees, getting a result that looks like this:</p>
<div data-language="text"><pre><code>#&lt;ActiveRecord::Relation [#&lt;Employee id: 4, role_id: 5, name: "Bob Williams", salary: 127053.0, created_at: "2020-04-26 18:42:53", updated_at: "2020-04-26 18:42:53"&gt;, #&lt;Employee id: 5, role_id: 4, name: "Bob Florez", salary: 149218.0, created_at: "2020-04-26 18:42:53", updated_at: "2020-04-26 18:42:53"&gt;, ...]&gt;</code></pre></div>
<h3 id="where-not-exists"><a href="#where-not-exists" aria-label="where not exists permalink"></a>Where Not Exists</h3>
<blockquote>
<p>Leigh, we would like to encourage employees to have a healthy work-life balance, and were hoping you could provide us with a list of all the <em>employees who have yet to take any vacation time</em>.</p>
</blockquote>
<p>For this case, <code>NOT EXISTS</code> is a perfect fit, since it only matches records that <strong>do not</strong> have a match in the subquery. An alternative is to perform a left outer join, only choosing the records with no matches on the right side. This is referred to as an <a href="https://gerardnico.com/data/type/relation/sql/anti_join">anti-join</a>, where the purpose of the join is to find records that <strong>do not</strong> have a matching record.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>*</span>
<span>FROM</span> employees
<span>WHERE</span>
  <span>NOT</span> <span>EXISTS</span> <span>(</span>
    <span>SELECT</span> <span>1</span>
    <span>FROM</span> vacations
    <span>WHERE</span> vacations<span>.</span>employee_id <span>=</span> employees<span>.</span>id<span>)</span></code></pre></div>
<p>If you're interested in the <strong>LEFT OUTER JOIN</strong> equivalent, it might look like this:</p>
<div data-language="sql"><pre><code><span>SELECT</span> employees<span>.</span><span>*</span>
<span>FROM</span>
  employees
  <span>LEFT</span> <span>OUTER</span> <span>JOIN</span> vacations <span>ON</span> vacations<span>.</span>employee_id <span>=</span> employees<span>.</span>id
<span>WHERE</span> vacations<span>.</span>id <span>IS</span> <span>NULL</span></code></pre></div>
<p>The subquery depends on a match between the <code>employees.id</code> column and the <code>vacations.employee_id</code> column, making it a <a href="https://learnsql.com/blog/correlated-sql-subqueries-newbies/">correlated subquery</a>. Because Rails follows standard naming conventions when querying (the downcased plural form of our model), we can add the above condition into our subquery without too much difficulty.</p>
<div data-language="ruby"><pre><code><span>Employee</span><span>.</span>where<span>(</span>
  <span>'NOT EXISTS (:vacations)'</span><span>,</span>
  vacations<span>:</span> <span>Vacation</span><span>.</span>select<span>(</span><span>'1'</span><span>)</span><span>.</span>where<span>(</span><span>'employees.id = vacations.employee_id'</span><span>)</span>
<span>)</span></code></pre></div>
<p>Using my seed data, I am seeing <em>369</em> employees that have yet to take any vacations.</p>
<div data-language="text"><pre><code>#&lt;ActiveRecord::Relation [#&lt;Employee id: 2, role_id: 2, name: "Alice Florez", salary: 86920.0, created_at: "2020-04-26 18:42:53", updated_at: "2020-04-26 18:42:53"&gt;, #&lt;Employee id: 5, role_id: 4, name: "Bob Florez", salary: 149218.0, created_at: "2020-04-26 18:42:53", updated_at: "2020-04-26 18:42:53"&gt;, ...]&gt;</code></pre></div>
<h2 id="the-select-subquery"><a href="#the-select-subquery" aria-label="the select subquery permalink"></a>The Select Subquery</h2>
<blockquote>
<p>Leigh, could you provide us with a list of employees, <em>including the average salary</em> of a BCE employee, and how much this <em>employee's salary differs from the average</em>?</p>
</blockquote>
<div data-language="sql"><pre><code><span>SELECT</span>
  <span>*</span><span>,</span>
  <span>(</span><span>SELECT</span> <span>avg</span><span>(</span>salary<span>)</span>
    <span>FROM</span> employees<span>)</span> avg_salary<span>,</span>
  salary <span>-</span> <span>(</span>
    <span>SELECT</span> <span>avg</span><span>(</span>salary<span>)</span>
    <span>FROM</span> employees<span>)</span> above_avg
<span>FROM</span> employees</code></pre></div>
<p>Because the subquery is repeated, we can save ourselves a little bit of hassle by placing the subquery SQL into a variable that we'll embed into the outer query. The <code>to_sql</code> method is perfect for this, but it's also fantastic to peak into the SQL that Rails is producing without actually executing the query.</p>
<div data-language="ruby"><pre><code>avg_sql <span>=</span> <span>Employee</span><span>.</span>select<span>(</span><span>'avg(salary)'</span><span>)</span><span>.</span>to_sql

<span>Employee</span><span>.</span>select<span>(</span>
  <span>'*'</span><span>,</span>
  <span>"(<span><span>#{</span>avg_sql<span>}</span></span>) avg_salary"</span><span>,</span>
  <span>"salary - (<span><span>#{</span>avg_sql<span>}</span></span>) avg_difference"</span>
<span>)</span></code></pre></div>
<p>This query does not limit the results in any way, but instead selects two additional columns (<code>avg_salary</code> and <code>avg_difference</code>). Looking at the first three results, I am seeing:</p>
<div data-language="ruby"><pre><code><span>[</span>
  <span>{</span><span>"id"</span><span>=</span><span>&gt;</span><span>1</span><span>,</span> <span>"role_id"</span><span>=</span><span>&gt;</span><span>1</span><span>,</span> <span>"name"</span><span>=</span><span>&gt;</span><span>"Joe Serna"</span><span>,</span> <span>"salary"</span><span>=</span><span>&gt;</span><span>86340.0</span><span>,</span> <span>"avg_salary"</span><span>=</span><span>&gt;</span><span>99306.4</span><span>,</span> <span>"avg_difference"</span><span>=</span><span>&gt;</span><span>-</span><span>12966.399999999994</span><span>}</span><span>,</span> 
  <span>{</span><span>"id"</span><span>=</span><span>&gt;</span><span>2</span><span>,</span> <span>"role_id"</span><span>=</span><span>&gt;</span><span>2</span><span>,</span> <span>"name"</span><span>=</span><span>&gt;</span><span>"Alice Florez"</span><span>,</span> <span>"salary"</span><span>=</span><span>&gt;</span><span>86920.0</span><span>,</span> <span>"avg_salary"</span><span>=</span><span>&gt;</span><span>99306.4</span><span>,</span> <span>"avg_difference"</span><span>=</span><span>&gt;</span><span>-</span><span>12386.399999999994</span><span>}</span><span>,</span> 
  <span>{</span><span>"id"</span><span>=</span><span>&gt;</span><span>3</span><span>,</span> <span>"role_id"</span><span>=</span><span>&gt;</span><span>3</span><span>,</span> <span>"name"</span><span>=</span><span>&gt;</span><span>"Amanda Florez"</span><span>,</span> <span>"salary"</span><span>=</span><span>&gt;</span><span>93600.0</span><span>,</span> <span>"avg_salary"</span><span>=</span><span>&gt;</span><span>99306.4</span><span>,</span> <span>"avg_difference"</span><span>=</span><span>&gt;</span><span>-</span><span>5706.399999999994</span><span>}</span>
<span>]</span></code></pre></div>
<p>As with any SQL query, there are often many ways to arrive at the same result. In this example we used subqueries to find the average employee salary, but it may have been better to use <a href="https://www.postgresql.org/docs/current/tutorial-window.html">window functions</a> instead. They give us the same result, but provide a simpler query which is actually more performant as well. Even on a small dataset of 1000 employees, this query takes approximately 12ms vs 18ms for the subquery equivalent.</p>
<div data-language="sql"><pre><code><span>SELECT</span>
  <span>*</span><span>,</span>
  <span>avg</span><span>(</span>salary<span>)</span> <span>OVER</span> <span>(</span><span>)</span> <span>AS</span> avg_salary<span>,</span>
  salary <span>-</span> <span>avg</span><span>(</span>salary<span>)</span> <span>OVER</span> <span>(</span><span>)</span> <span>AS</span> avg_salary
<span>FROM</span>
  employees</code></pre></div>
<p>The window function approach is actually easier to write in Rails as well!</p>
<div data-language="ruby"><pre><code><span>Employee</span><span>.</span>select<span>(</span>
  <span>'*'</span><span>,</span>
  <span>"avg(salary) OVER () avg_salary"</span><span>,</span>
  <span>"salary - avg(salary) OVER () avg_difference"</span>
<span>)</span></code></pre></div>
<h2 id="the-from-subquery"><a href="#the-from-subquery" aria-label="the from subquery permalink"></a>The From Subquery</h2>
<blockquote>
<p>Leigh, we'd like to know the <em>average performance review score</em> given across all our managers.</p>
</blockquote>
<p>After clarifying with HR, they are looking to take the average score each manager has given, and then take the average of those averages. In other words, the average average. When you are dealing with an <strong>aggregate of aggregates</strong>, it needs to be accomplished in two steps. This can be done using a subquery as the <code>FROM</code> clause, essentially giving us a temporary table to then select from, allowing us to find the average of those averages.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>avg</span><span>(</span>avg_score<span>)</span> reviewer_avg
<span>FROM</span> <span>(</span>
  <span>SELECT</span> reviewer_id<span>,</span> <span>avg</span><span>(</span>score<span>)</span> avg_score
  <span>FROM</span> performance_reviews
  <span>GROUP</span> <span>BY</span> reviewer_id<span>)</span> reviewer_avgs</code></pre></div>
<p>To keep our Ruby code clean, we'll place the subquery into a variable which can then be embedded into the main query.</p>
<div data-language="ruby"><pre><code>from_sql <span>=</span>
  <span>PerformanceReview</span><span>.</span>select<span>(</span><span>:reviewer_id</span><span>,</span> <span>'avg(score) avg_score'</span><span>)</span><span>.</span>group<span>(</span>
    <span>:reviewer_id</span>
  <span>)</span><span>.</span>to_sql

<span>PerformanceReview</span><span>.</span>select<span>(</span><span>'avg(avg_score) reviewer_avg'</span><span>)</span><span>.</span>from<span>(</span>
  <span>"(<span><span>#{</span>from_sql<span>}</span></span>) as reviewer_avgs"</span>
<span>)</span><span>.</span>take<span>.</span>reviewer_avg</code></pre></div>
<p>The result of this query is <code>50.652</code>. This makes sense given that the seed data …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/active-record-subqueries-rails">https://pganalyze.com/blog/active-record-subqueries-rails</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/active-record-subqueries-rails</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629450</guid>
            <pubDate>Wed, 24 Jun 2020 15:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hey.com Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23628952">thread link</a>) | @manuw
<br/>
June 24, 2020 | https://schipplock.org/rants/hey.html | <a href="https://web.archive.org/web/*/https://schipplock.org/rants/hey.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://schipplock.org/rants/hey.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628952</guid>
            <pubDate>Wed, 24 Jun 2020 15:25:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Blew a Ten-Year Lead]]>
            </title>
            <description>
<![CDATA[
Score 834 | Comments 542 (<a href="https://news.ycombinator.com/item?id=23628761">thread link</a>) | @secondbreakfast
<br/>
June 24, 2020 | https://secondbreakfast.co/google-blew-a-ten-year-lead | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/google-blew-a-ten-year-lead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        
          



<p>Back when there were rumors of Google building an operating system, I thought<span></span> <span>“</span>Lol.”</p>
<p>Then I watched then-PM Sundar Pichai <a href="https://www.youtube.com/watch?v=0QRO3gKj3qw">announce Chrome <span>OS</span></a>. My heart raced. It was perfect.</p>
<p>I got my email through Gmail, I wrote documents on Docs, I listened to Pandora, I viewed photos on TheFacebook. Why did I need all of Windows Vista?</p>
<p>In 2010, I predicted that by 2020 Chrome <span>OS</span> would be the most popular desktop <span>OS</span> in the world. It was fast, lightweight, and $0.</p>
<p><span>“</span>Every Windows and <span>OS</span> X app will be re-built for the browser!” I thought. Outlook-&gt;Gmail. Excel-&gt;Sheets. Finder-&gt;Dropbox. Photoshop-&gt;Figma. Terminal-&gt;Repl.it.</p>
<p>All of your files would be accessible by whoever you wanted, wherever you wanted, all the time. It was obvious. Revolutionary.</p>
<p>I haven’t installed <span>MSFT</span> Office on a machine since 2009. Sheets and Docs have been good enough for me. The theoretical unlimited computing power and collaboration features meant Google Docs was better than Office (and free!).</p>
<p>Then something happened at Google. I’m not sure what. But they stopped innovating on cloud software.</p>
<p>Docs and Sheets haven’t changed in a decade. Google Drive remains impossible to navigate. Sharing is complicated. Sheets freezes up. I can’t easily interact with a Sheets <span>API</span> (I’ve tried!). Docs still shows page breaks by default! <span>WTF</span>!</p>
<p>Even though I have an iPhone and a MacBook, I’ve been married to Google services. I browse Chrome. I use Gmail. I get directions and lookup restaurants on Maps. I’m a YouTube addict.</p>
<p>Yet I’ve been ungluing myself from Google so far this year. Not because of Google-is-reading-my-emails-and-tracking-every-keystroke reasons, but because I like other software so much more that it’s worth switching.</p>
<p>At <span>WWDC</span>, Apple shared Safari stats for macOS Big Sur. It reminded me how much Chrome makes my machine go <span>WHURRRRRR</span>. Yesterday, I made Safari my default browser again.</p>
<p>My Gmail inbox has become a mailbox stuffed with clothing flyers, SaaS mailers, and Rollbar alerts. I love when people respond to Second Breakfast, but their responses get lost amid a sea of plastic bottles. I started using <span>HEY</span> last week. My new email is <a href="mailto:billy@hey.com">billy@hey.com</a>. I love it so far.</p>
<p>I’ve given up on Google Docs. I can never find the documents Andy shares with me. The formatting is tired and stuck in the you-might-print-this-out paradigm. Notion is a much better place to write and brainstorm with people.</p>
<p>The mobile Google results page is so cluttered that I switched my iPhone’s default search to DuckDuckGo. The results are a tad worse, but I’m never doing heavy-duty searches on the go. And now I don’t have to scroll past 6 ads to get the first result. DuckDuckGo’s privacy is an added bonus.</p>
<p>I still use Google Sheets heavily. But wow, Airtable makes Sheets feel decrepit. Where’s the easy API? New ways of formatting? Better collaboration? Simple sheet-as-a-database?</p>
<p>My new usage patterns:</p>
<ul>
<li>Email: <del>Gmail</del> <span>HEY</span></li>
<li>Search: <del>Google</del> DuckDuckGo (mobile) and Google (desktop)</li>
<li>Maps: Google</li>
<li>Docs: <del>Google</del> Notion</li>
<li>Sheets: Google</li>
<li>Video: YouTube (but increasingly I’m noticing other people use Twitch, Instagram, and TikTok)</li>
<li>Video Calls: <del>Google Meet</del> Zoom</li>
</ul>
<p>I’m a long shareholder of Google. It’s amazing how they have four monopolies and only monetize one of them. I’m confident they have a bright future ahead.</p>
<p>But the lack of innovation is frustrating. The product goals are all over the place. Microsoft has a new clear mission: The Cloud. What’s Google’s clear mission?</p>
<p>It feels like they blew a 10 year lead.</p>

          
          
          
          <div>
            <div>
              <p>
                I write almost every day. Subscribe to get new posts as you sip your coffee each morning.
                <span>When you join I'll also send you the posts that've made the front page of HN.</span>
              </p>
            </div>
            
          </div>
                
          
      

      </div>
    </div></div>]]>
            </description>
            <link>https://secondbreakfast.co/google-blew-a-ten-year-lead</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628761</guid>
            <pubDate>Wed, 24 Jun 2020 15:12:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stock Analysis in Python]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23628196">thread link</a>) | @rbanffy
<br/>
June 24, 2020 | https://beta.deepnote.com/article/stock-analysis-in-python | <a href="https://web.archive.org/web/*/https://beta.deepnote.com/article/stock-analysis-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://beta.deepnote.com/article/stock-analysis-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628196</guid>
            <pubDate>Wed, 24 Jun 2020 14:23:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review of Hooked – How to Build Habit-Forming Products]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23628099">thread link</a>) | @herrkra
<br/>
June 24, 2020 | https://jochemgerritsen.com/2020/06/book-review-hooked/ | <a href="https://web.archive.org/web/*/https://jochemgerritsen.com/2020/06/book-review-hooked/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><img src="https://jochemgerritsen.com/wp-content/uploads/2020/06/Hooked-How-to-Build-Habit-Forming-Products-image-199x300.jpg" alt="Image of the Hooked book" width="199" height="300" srcset="https://jochemgerritsen.com/wp-content/uploads/2020/06/Hooked-How-to-Build-Habit-Forming-Products-image-199x300.jpg 199w, https://jochemgerritsen.com/wp-content/uploads/2020/06/Hooked-How-to-Build-Habit-Forming-Products-image.jpg 331w" sizes="(max-width: 199px) 100vw, 199px"><br>
What makes you check your phone 100 times per day? Why do you always use Google instead of Bing? Or why do lay awake at night, scrolling through your Instagram feed, even when you know you should be sleeping?</p>
<p>In <a href="https://amzn.to/2Bww2Ak">Hooked: How to Build Habit Building Products</a>, Nir Eyal provides the exact model that many digital products use to make us addicted. According to the author, all these apps use the Hook model — finding ways to intertwine their usage into our daily lives, routines and habits.</p>
<p>The book has been praised by many well-known entrepreneurs, such as Eric Ries (the Lean Startup), Dave McClure (500 Startups) and Boris Veldhuijzen van Zanten (The Next Web). So clearly, Hooked is a great read for company founders, particularly when you want to dive into the psychology of user interaction and making your app or product ‘stick’. So if you want a quick overview of the model without needing to read the entire book, you can find a summary and my book review of Hooked below.</p>


<h2>Highlights of Hooked: The Hook Model</h2>
<p>In summary, the book Hooked provides a model to ‘hook’ users. It’s a model to make them come again and again (I suppose ‘Addicted’ could have been an alternative title for the book but one with a bit less flair).</p>
<p>As you can see in the image below, the Hook model consists of four different steps. The Trigger, the Action, the Variable Reward, and the Investment. Specifically, users are:</p>
<ol>
<li>Triggered to open your app or product;</li>
<li>After which they perform an action within the product;</li>
<li>This results in a variable reward;</li>
<li>And finally they make an investment to improve their experience.</li>
</ol>
<p><img src="https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2014/01/the_hook-520x403.png" alt="the_hook"></p>
<p>Take any social media platform as an example, such as Instagram. Suppose you’re at work, and suddenly your phone shows a notification. A friend commented on your Instagram photo! This notification serves as a trigger for you to open the Instagram app. You look at the picture, and perhaps you like your friend’s comment. This is the action you’ve just taken. Consequently, you mindlessly scroll through your feed, hoping to find interesting photos, videos or other hidden gems. Considering that you sometimes find a hidden gem, and sometimes you don’t, this is the variable reward. And finally, you leave a comment somewhere, and perhaps you take a work selfie that you upload to the app. This is the investment you make.</p>
<p>This is a simple example of the Hooked model; in the book, the author expands on each different section — which I will do here shortly too.</p>
<h3>Trigger</h3>
<p>The Hook Model starts with the trigger. In this example, the trigger was a notification on your phone. According to Eyal, the trigger can be both internal and external.</p>
<p>In this case, the Instagram notification is an external trigger. Similarly, an advertisement, email, or even word-of-mouth marketing may be the external trigger you need as a user to start engaging with a product.</p>
<p>Alternatively, a trigger can be internal. This is the case when users have already gone through the Hooked model (and the circle in the image above) once or several times. You yourself trigger a need or want to open the Instagram app, without any external interference.</p>
<h3>Action</h3>
<p>What is the action you want a user to take in/with your product? The goal of the product team is to (among many other things) make the action as easy as possible.</p>
<p>In both this model and life in general, an action consists of three aspects: motivation, ability, and trigger. This is also called the Fogg Behavioral Model, represented as B = MAT. Take a simple example: the behavior (or action) of doing groceries. If you do groceries you need to be 1) motivated to do so, 2) able to do so, and 3) you need a certain trigger. So if it’s Friday night and you don’t feel like going outside (motivation), if your car has stopped working (ability) or if you have a full fridge (trigger), you’re not very likely to go to the supermarket.</p>
<h3>Variable Reward</h3>
<p>Interestingly, a reward a user gets from a product should not be the same every time. Just like with gambling, there should be a variable reward — sometimes you get X, sometimes you get Y, or perhaps sometimes you get nothing at all.</p>
<p>Preferably, a product has so-called “infinite variability”. You can find this infinite variability in the un-ending scroll of products like Instagram, Reddit, Pinterest or even certain news sites. You never know what you can expect, making the product new and exciting, every time you open it.</p>
<h3>Investment</h3>
<p>Users making an investment into your product helps them get back to the product in several ways. First, investing in the product usually improves the product itself. For instance, LinkedIn adding more information to their profile makes the entire platform more useful for other users.</p>
<p>In addition, one bias (or fallacy) we all face is the sunk cost fallacy. I’ve mentioned <a href="https://jochemgerritsen.com/2019/11/making-unrestricted-choices/">cognitive biases</a> before, and the sunk cost fallacy is the idea that when you put more effort or energy into something, it becomes more difficult to let it go or step away. In this sense, a user’s investment in your product will make it more likely for him/her to stick with your product, even if there are better alternatives on the market.</p>

<h2>Applying the Lessons of Hooked</h2>
<p>Whenever you read a business book, it’s important to look at how to apply it to your specific case. Luckily, Nir Eyal provides several questions and small to-do’s at the end of every chapter that you can use to apply the Hooked model to your product.</p>
<p>Specifically, you could look at your product (or service) and answer questions such as:</p>
<ul>
<li>Which internal trigger does your user experience most frequently?</li>
<li>Which resources are limiting your users’ ability to accomplish the tasks [or actions] that will become habits?</li>
<li>What are 3 ways your product might increase users’ search for variable rewards?</li>
<li>What ‘bit of work’ [or investment] are your users doing to increase their likelihood of returning?</li>
</ul>
<p>These are just a couple of questions from the book; if you truly want to apply this model to your product, I recommend reading (and answering) all of them.</p>

<h2>Hooked Book Review by an entrepreneur</h2>
<p>In my opinion, the Hooked model and book is particularly relevant for entrepreneurs and company founders building B2C digital products. Whether you’re building a new kind of social media platform, a videogame, an app to order groceries, or something else, the Hooked model can help you to increase the chances of your users returning to your product.&nbsp;That said, the ideas in the book are useful for B2B products too, but it really depends on your product whether the model is relevant.</p>
<p>While the book’s theory isn’t entirely ground-breaking, I think it’s very useful to have a model which you can apply to the interactions of your users with your product. As founders or product managers, we often talk about a <em>customer journey</em>, which is a good way of looking at it. However, by using the Hooked model, you may find new improvements you can make to that customer journey, that you wouldn’t have found otherwise.</p>
<p>This particularly applies to the ‘variable reward’ and ‘investment’ steps of the Hooked circle. Most people designing a product know the trigger leading to a user interaction, and the action they want their users to take. However, creating a variable reward, and ensuring that a user goes beyond ‘just interacting’ to actually investing in the product, is something that often comes as an after-thought. Applying this model to your product, makes you really think about the different ways and new functionalities you could implement to enable these two steps.</p>
<p>Overall, I found the book quite enjoyable. As is usually the case with books that offer a model, it is not entirely necessary to read the whole book. By reading this article, you already have a fair understanding of the model, and otherwise you could simply read some extra material on <a href="https://www.nirandfar.com/hooked-user-behavior-resources/">the author’s blog</a>. However, reading the entire book does make everything sink in better, and if you want to apply the model directly to your product, it may be useful to <a href="https://amzn.to/2Bww2Ak">get yourself a copy</a>.</p>
<p><span>Note that I only write about books that I’ve actually read and products I’ve actually used — this post contains an affiliate link from Amazon; as an Amazon Associate I may earn a small commission if you click and buy the product in question.</span></p>
<hr>
					</div></div>]]>
            </description>
            <link>https://jochemgerritsen.com/2020/06/book-review-hooked/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628099</guid>
            <pubDate>Wed, 24 Jun 2020 14:15:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boring Benefits of Lisp]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627627">thread link</a>) | @selff
<br/>
June 24, 2020 | https://justinmeiners.github.io/boring-benefits-of-lisp/ | <a href="https://web.archive.org/web/*/https://justinmeiners.github.io/boring-benefits-of-lisp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>Lisp advocates are famous for having extravagant reasons for why Lisp is their favorite language.
You might have heard that its the <a href="http://www.paulgraham.com/avg.html">most powerful language</a>,
due to feature like <a href="http://www.paulgraham.com/onlisp.html">macros</a> or <a href="https://en.wikipedia.org/wiki/Homoiconicity">homioconicty</a>.
Certainly, Common Lisp and Scheme have no shortage of beautiful ideas,
but due to their influence, most of their benefits have now been included
in modern languages, and as you may know fancy language abstractions <a href="https://justinmeiners.github.io/think-in-math/">don’t
appeal to me</a>.
I am now interested in it for very simple and practical reasons;</p>

<ol>
<li>Lisp is a fully standardized language. Consequently, it is well understood, cross-platform, and has multiple implementations, including several with free licenses.</li>
<li>Lisp has great documentation, books, and learning resources. SICP is “the book” for Scheme. Common Lisp has several good ones.</li>
<li>Lisp is mature and extremely stable. Code be written once, and run again years later, without modification.</li>
<li>Lisp implementations are reasonably fast. The true believers claim Common Lisp is as fast as C. In general it’s not even close, but for a high-level, dynamic, language, <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/lisp.html">it’s pretty fast</a>.</li>
<li>Lisp is well designed and follows solid computer science principles.
It has a focused selection of features and an elegant evaluation model which make it easy to
write and compose functionality.</li>
</ol>


<p>These features don’t appear too remarkable or unique to Lisp.
In fact, this pattern of requirements was actually established by ANSI C first, and later adopted by Lisp.
But, the surprising thing is how few languages since have followed the pattern.
Of course satisfaction lies on a spectrum; some languages do more than others,
but very few follow it to a degree that can be asserted with confidence.
Usually, you can say a language somewhat satisfies it, followed by a list of ugly qualifications.</p>

<p>Take Python for example. It’s well designed, has great resources, is fairly stable.
It has an <a href="https://norvig.com/python-lisp.html">elegant design</a> like Lisp.
But, is it standardized? Kind of, they have a spec, but it has one defacto implementation.
CPython does whatever they want, and others follow along.
The alternative implementations all have compatibility compromises.
Neither is it fast, unless you use a [JIT] implementation which makes it tolerable,
but that has its own quirks, and you can’t use many libraries with it.</p>

<p>So are Lisp and C the only languages that do this? No, but there aren’t as many as you think.
Lisp just happens to be one of them, and it’s a design that I enjoy using and learning about.</p>


</div>]]>
            </description>
            <link>https://justinmeiners.github.io/boring-benefits-of-lisp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627627</guid>
            <pubDate>Wed, 24 Jun 2020 13:29:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Styling Browser Console]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627456">thread link</a>) | @tsl143
<br/>
June 24, 2020 | https://itsopensource.com/how-to-format-browser-console/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/how-to-format-browser-console/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><code>console.log</code> is the most widely used debugging technique used by Javascript developers. While debugging <code>console.log</code> is sprinkled almost anywhere in the code, after code execution, console panel is full of console messages, this blog lists some useful console commands which can help to format and declutter console panel for more meaningful console messages.</p>
<h3><center> console.(log/info/warn/error) </center></h3>
<h4>Basic usage</h4>
<div data-language="javascript"><pre><code>console<span>.</span><span>log</span><span>(</span><span>123</span><span>)</span><span>;</span>


console<span>.</span><span>log</span><span>(</span><span>"abc"</span><span>,</span> <span>123</span><span>)</span><span>;</span>


console<span>.</span><span>log</span><span>(</span><span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>]</span><span>,</span> <span>"abc"</span><span>,</span> <span>123</span><span>)</span><span>;</span>
</code></pre></div>
<h4>Substitution in console</h4>
<div data-language="javascript"><pre><code>console<span>.</span><span>log</span><span>(</span><span>"This is a %s example also accept %d number, and %o object too"</span><span>,</span> <span>"substitution"</span><span>,</span> <span>33</span><span>,</span> <span>{</span> a<span>:</span> <span>1</span> <span>}</span><span>)</span><span>;</span></code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/969f4/substitution-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="substitution-console" title="substitution-console" src="https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/799d3/substitution-console.png" srcset="https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/00d96/substitution-console.png 148w,
https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/0b23c/substitution-console.png 295w,
https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/799d3/substitution-console.png 590w,
https://itsopensource.com/static/0c8ee580f41c12f778b419b6b2269061/969f4/substitution-console.png 776w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
<em>Please take care of the sequence of params</em></p>
<h4>Styling in console</h4>
<p><code>console</code> accepts CSS styles we can use <code>%c</code> to pass CSS styles 😎. Styles apply to whatever text is after <code>%c</code>. It can be mixed with substitutions too, but again make sure of the sequence of parameters.</p>
<div data-language="javascript"><pre><code>console<span>.</span><span>log</span><span>(</span><span>"This is some %cShow off console message"</span><span>,</span> <span>"font-size:30px; color: #fff; background: #3d7e9a"</span><span>)</span><span>;</span></code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/fd398/styled-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="styled-console" title="styled-console" src="https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/799d3/styled-console.png" srcset="https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/00d96/styled-console.png 148w,
https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/0b23c/styled-console.png 295w,
https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/799d3/styled-console.png 590w,
https://itsopensource.com/static/b51a12408365feff4d934e102ecbff7b/fd398/styled-console.png 767w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<hr>
<h3><center> console.assert </center></h3>
<p>This is generally used for conditional logging, accepts a <code>condition</code> as the first param, and logs the next params only if the given condition is false with <code>Assertion failed</code> error.</p>
<div data-language="javascript"><pre><code><span>const</span> a <span>=</span> <span>1</span><span>;</span>
console<span>.</span><span>assert</span><span>(</span>a<span>===</span><span>1</span><span>,</span> <span>"a is not equal to 1"</span><span>)</span><span>;</span>

console<span>.</span><span>assert</span><span>(</span>a<span>===</span><span>2</span><span>,</span> <span>"a is not equal to 2"</span><span>)</span><span>;</span>
</code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/275e0/assert-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="assert-console" title="assert-console" src="https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/275e0/assert-console.png" srcset="https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/00d96/assert-console.png 148w,
https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/0b23c/assert-console.png 295w,
https://itsopensource.com/static/d6749a94989266cd09be0d34b0ce7ca1/275e0/assert-console.png 492w" sizes="(max-width: 492px) 100vw, 492px" loading="lazy">
  </a>
    </span></p>
<hr>
<h3><center> console.(time/timeLog/timeEnd) </center></h3>
<p>When we try to measure the performance of a website or a function we use to add <code>console.log(Date.now)</code> before and after a function and do the maths to get execution time. Javascript has a native way to achieve this. <code>console.time</code> marks the start of time, <code>console.timeEnd</code> stops the timer and gives the total time taken. <code>console.time</code> takes label as a parameter in case you want to use multiple timers. <code>console.timeLog</code> can be used anywhere in between to check time elapsed till then.</p>
<div data-language="javascript"><pre><code><span>function</span> <span>checkTime</span><span>(</span><span>)</span> <span>{</span>
  console<span>.</span><span>time</span><span>(</span><span>"checkTime"</span><span>)</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;=</span> <span>300000000</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
		<span>if</span> <span>(</span>i <span>===</span> <span>15000000</span><span>)</span> console<span>.</span><span>timeLog</span><span>(</span><span>"checkTime"</span><span>)</span><span>;</span>
	<span>}</span>
	console<span>.</span><span>timeEnd</span><span>(</span><span>"checkTime"</span><span>)</span><span>;</span>
<span>}</span>
<span>checkTime</span><span>(</span><span>)</span><span>;</span>


</code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/68a6d/time-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="time-console" title="time-console" src="https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/68a6d/time-console.png" srcset="https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/00d96/time-console.png 148w,
https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/0b23c/time-console.png 295w,
https://itsopensource.com/static/2e483794c9918a1dcb5c155c9498d05d/68a6d/time-console.png 484w" sizes="(max-width: 484px) 100vw, 484px" loading="lazy">
  </a>
    </span></p>
<hr>
<h3><center> console.(count/countReset) </center></h3>
<p>There are times where we want to count how many times a function is called, we need to create a dummy counter just for logging, <code>console.count</code> handles this, every time it is called it increments by 1 and consoles the value against the passed <code>label</code> or <code>default</code>. We can use multiple counters in the same code with different labels. Any counter can be reset with <code>console.countRest</code> passing respective label or nothing in case of <code>default</code>.</p>
<div data-language="javascript"><pre><code>console<span>.</span><span>count</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>

console<span>.</span><span>count</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>

console<span>.</span><span>count</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>

console<span>.</span><span>countReset</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>

console<span>.</span><span>count</span><span>(</span><span>"myCounter"</span><span>)</span><span>;</span>
</code></pre></div>
<p><span>
      <a href="https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/20978/count-console.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="count-console" title="count-console" src="https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/20978/count-console.png" srcset="https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/00d96/count-console.png 148w,
https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/0b23c/count-console.png 295w,
https://itsopensource.com/static/df10483a24aee1f15b0d6815cdbc403b/20978/count-console.png 515w" sizes="(max-width: 515px) 100vw, 515px" loading="lazy">
  </a>
    </span></p></section></div>]]>
            </description>
            <link>https://itsopensource.com/how-to-format-browser-console/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627456</guid>
            <pubDate>Wed, 24 Jun 2020 13:14:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slate Star CoDoxxed]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627301">thread link</a>) | @mhb
<br/>
June 24, 2020 | https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html | <a href="https://web.archive.org/web/*/https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-451966706447828793" itemprop="description articleBody">
<div dir="ltr" trbidi="on"><p>
Get it? Because he says they're "doxxing" him.</p><p>

"Doxxing" is a type of cyber-bullying in which the bully publicly reveals private information about the target, such as their home phone number or address, their employer's information, photos of the target's children, and so on. This is considered to be extremely threatening. Imagine that someone publicly posts a photo of your small child playing at the park, along with the Google Maps link to the park and a comment to the effect of, "This is where that racist Joe plays with his kids." That's doxxing. Yes, it's bad.</p><p>

But that's not what's happening to Dr. Scott Alexander So-and-So. Let's dive in.</p><h3>
First, The Back-Story</h3>
<p>
Go ahead and cruise on over to slatestarcodex.com to get Dr. Scott Alexander So-and-So's version of the story. It goes something like this: A writer from <i>The New York Times</i> wanted to write a story about a popular blog that generates a lot of interest and that maybe got some things right about COVID-19 early on. That was fine with Dr. Scott Alexander So-and-So until the journalist said, "By the way, I've been able to figure out what the So-and-So stands for, and I'm going to put that into my story." Dr. Scott freaks out a little and says no, don't do that. The journalist says it's company policy.</p>

<p>
So, Dr. Scott Alexander So-and-So deleted his whole blog, saying that <i>The New York Times</i> was trying to endanger him by doxxing him "for clicks."</p>

<p>
Before I go on, I would like to remind my readers of my previous posts about Dr. Scott Alexander So-and-So. <a href="https://www.stationarywaves.com/search?q=slate+star+codex" target="_blank">Here's a link</a>. You will see from what I've written before that I consider the guy to be really weird. It's not just that I dislike his blog - and I do - it's that he seems emblematic of a very bizarre strain of Silicon Valley culture, and the deeper you get into this crowd, the heebier the jeebies, if you catch my drift.&nbsp;</p>

<p>
His blog rose to prominance when some well-regarded bloggers started linking to his posts. They all seemed to consider him very smart and thoughtful. Soon enough, "everyone" was reading him. Over time, his posts have become more performative. He started out writing like a self-conscious nerd, and now he writes as though he is playing the part of a self-conscious nerd who thinks he is a really smart and funny guy. That's fine. Fame changes you. I don't care.</p>

<p>
What I do care about is the content of his blog. Each post tackles any number of topics. He's written on climate science and economics and technology and artificial intelligence and psychiatry and biology and sociology and anything else. He always presents his views as though he is an expert, but quite often it's painfully obvious that he's just done a couple of hours of internet research. There's no shame in doing some casual research and blogging about it, but when everyone starts calling you an expert, and you keep doing light research and presenting it as Dr. Scott Alexander So-and-So Presents The Answer To A Problem That People Have Been Trying To Solve For Decades, then it starts to get on my nerves.</p>

<p>
I mean, it's <i>dorky</i> to do what effectively amounts to college homework assignments as an adult passing the time. But it's problematic to be taken seriously for it. </p>
<br>
<h3>
An "Anonymous" Blogger</h3>
<p>
Dr. Scott Alexander So-and-So openly admits that his name is a pseudonym. First question: Why is he using a pseudonym? Maybe it's like a stage name. Lots of people have stage names. Stage names can be a lot of fun. But that's not why Dr. Scott Alexander So-and-So says he uses a pseudonym. Instead, he says it's because he wants to remain anonymous.</p>

<p>
But Dr. Scott Alexander So-and-So <i>also</i> says that Scott Alexander is his real-life first and last name. That sure is an odd choice of pseudonyms for someone who wishes to remain anonymous. The legendary whistleblower "Deep Throat" wasn't a guy named Deep Throat McInnis, and if he was, going by "Deep Throat" wouldn't exactly be a cloak of anonymity. "Deep Throat" was not a pseudonym that resembled his or her real name at all. It was an obviously made-up moniker; it was intended to be <i>obviously</i> made up, because if everyone knows that Deep Throat's real name is nothing whatsoever resembling Deep Throat, then no one has any idea what Deep Throat's real name is. That's true anonymity. That's not what Dr. Scott Alexander So-and-So wanted, obviously. If he wanted <i>that kind</i> of anonymity, then he would have chosen a pseudonym more like "Deep Throat," or "Alone" (the pseudonym of the writer of <i>The Last Psychiatrist</i> blog), or "Slate Star Codex Guy" or something.</p>

<p>
Pretty much everyone knows that Mark Twain is Samuel Clemens. Samuel Clemens didn't choose "Mark Twain" as a pen name because he wanted to be anonymous. He chose it because he thought he could sell more books under the name "Mark Twain" than under the name "Samuel Clemens," and he was probably right. Mark Twain sounds way better. But when the press discovered his real name, Samuel Clemens didn't delete all his books and complain about being doxxed. He just did what any normal person using a pen name would do: He said, yep, but I write books under the name Mark Twain. And there was no issue.</p>

<p>
The matter was slightly different with "Publius," or "Publicus," or whatever name they were using to write <i>The Federalist Papers</i>. In that case, they had to be anonymous because they could have been killed for treason. Notice again how "Publius" bears scant resemblance to "John Jay" or "John Adams."</p>

<p>
It gets worse, of course. Not only did Dr. Scott Alexander So-and-So choose a "pseudonym" that was actually just his real name, he published many old links to all his old blog posts, in which he discussed personal details of his life. He discussed the experiences of the patients he saw in his clinical psychiatric practice. He held public meet-ups, advertised on his blog and on his social media accounts, where he agreed to meet with pretty much any old person who happened to read his blog or follow him on Twitter. He didn't meet strangers with a cloak and a mask, either. He met them using his real face and his real name and as his own, real, self. In short, he presented himself publicly as Dr. Scott Alexander So-and-So, Please Don't Use My Last Name Because I Want To Be Anonymous, Honest.</p>

<p>
Not exactly the behavior of a man who seeks anonymity, is it?</p>

<h3>
Playing At Being Famous</h3>
<p>
But okay, maybe he was just naive about the matter. That could be the explanation, right?</p>

<p>
Still, <i>fifteen years</i> of naivete over the course of progressively building internet fame seems to strain credulity. Once you start getting calls from <i>The Times</i>, wouldn't you reconsider your willy-nilly attitude toward divulging personal details? I mean, if it mattered to you that you remain anonymous, and you started to become famous, wouldn't you then quietly cull your blog of all references to your real life and real identity, and then just stick to publishing bi-weekly homework essays? Wouldn't you cool it with the public meet-ups and stuff?</p>

<p>
You would indeed, <i>if you cared about anonymity</i>.</p>

<p>
So, another possible explanation here is that Dr. Scott Alexander So-and-So liked being famous and well-regarded for publishing homework essays on the internet. He liked being able to organize meet-ups and watch strangers show up, wanting to meet him. He got a taste for fame, and decided he wanted to keep up with it. That's find and dandy, too. I don't fault a man for wanting to be famous. Lots of people want that.&nbsp;</p>

<p>
Then, this feature in the <i>New York Times</i> should be his big break, right? Finally he gets his big spotlight in the press. Finally he can divulge his true identity, set up a Patreon account, publish a book, and maybe secure a regular writing spot at <i>Slate Magazine</i>, or Vox, or The Atlantic or something. If you wanted to be a famous public intellectual, isn't that what you'd do? That's what I would do. I would work hard for my big break, and when it finally came, I would try to make the most of it. I'd try to capitalize.</p>

<p>
But that's not what Dr. Scott Alexander So-and-So would do. What would he do? <i>Delete his whole blog and complain that he's being persecuted.</i> Weird, right?</p>

<h3>
Another Possibility</h3>
<p>
I'm just going to float this theory. I have no idea if it's true, and no skin in the game one way or the other. But it's a theory that makes sense to me.</p>

<p>
Imagine you did homework essays for fun. Imagine you were kind of a nerd who lived with ten other people in the same house, you've gone on record saying that you don't have much luck with women, and you're basically just a clinical psychiatrist somewhere. Then imagine one day a lot of genuinely smart public intellectuals start reading your homework and say, "Hey, look at this guy. He seems smart."</p>

<p>
So then imagine that you decide to keep up with the homework. People are reading your posts. You feel well-regarded. Heck, you <i>are</i> well-regarded. You get a taste of fame, and you decide you enjoy it and you want more of it. So you keep at your homework, and people keep reading you and linking to you.</p>

<p>
And it's all pretty nice because it comes easy to you. You can do a couple of hours of internet research and write about it, no problem. So that's what you do. But at the bottom of it all, you know you're not really solving any problems. You know that your lengthy essays aren't really all that meritorious. You don't think you're all that smart, but everyone keeps saying that you are anyway. Thus, you enjoy the position you're in, you love the fame and the accolades, you like the meet-ups, maybe you even get more romantic attention than you did before.</p>

<p>
But you don't have what it takes to capitalize on your fame because, at the bottom of it, you only have the willingness to do a couple hours' internet research per week. You know that people who write books - people like Malcolm Gladwell and James Altucher - actually spend a lot of time and money on research and interviews and collecting information. You know that it's their full-time job. And you know …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html">https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html</a></em></p>]]>
            </description>
            <link>https://www.stationarywaves.com/2020/06/slate-star-codoxxed.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627301</guid>
            <pubDate>Wed, 24 Jun 2020 12:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breaking into a house using a Power Bank]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627143">thread link</a>) | @novamostra
<br/>
June 24, 2020 | https://novamostra.com/2020/06/23/breaking-into-a-house-using-a-power-bank/ | <a href="https://web.archive.org/web/*/https://novamostra.com/2020/06/23/breaking-into-a-house-using-a-power-bank/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-214">
	
	<!-- .entry-header -->

	<div>
		<p>Or… how insecure is the two wire video doorbell implementation from Avidsen.</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/gtnDg_UzcPE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p>About a month ago I bought the <a href="https://www.avidsenstore.com/visiophone-ylva-2-lecteur-rfid-p.html">Avidsen Visiophone YLVA 2+</a> and the reason why I chose to buy a wired video doorbell over a wireless one, was due to security concerns. Lucky me… I found that with the current device it takes almost the same time for someone with a Quick Charge enabled Power Bank to enter my house as with someone with the door’s key!</p>
<p>Immediately after unboxing the doorbell and removing the single screw from the doorbell for an initial inspection I noticed that both Entry Gate’s and Door’s control electrical contacts where located at the doorbell site. Wait… it couldn’t be, I may be wrong… let’s read the <a href="https://www.avidsen.com/cache/documents/product/notice-112249-avidsen.pdf">manual</a>.</p>
<p><strong>Page 27 of the PDF</strong> (Page 7 of the English Version manual):<br>
No! Bad luck! Exactly what I thought!<br>
<img src="https://novamostra.com/wp-content/uploads/2020/05/doorphone.png" alt="Avidsen videophone"><br>
<strong>Page 29 of the PDF:</strong><br>
The doorbell, with all the controls, is secured in place with a <strong>single</strong> Philips screw without any form of tamper protection!<br>
<img src="https://novamostra.com/wp-content/uploads/2020/05/singleScrew.png" alt="Doorphone installation"></p>
<p><strong>Page 32 of the PDF:</strong><br>
How to control a 12V electric strike plate for the door and the Gateway entry control:<br>
<img src="https://novamostra.com/wp-content/uploads/2020/05/installation.png" alt="Door and Gate control"></p>
<h2>How to get 12V from a QC Power Bank</h2>
<p>Power Bank’s rated as QuickCharge 3 (QC3) and later, can output 12V by using Sam Mallicoat’s <a href="https://hackaday.com/2017/03/04/unlocking-12v-quick-charge-on-a-usb-power-bank/#comment-4199744">reply from hackaday</a>:</p>
<blockquote>
<p>It’s easy to set a QC3 supply to 12V with just two resistors and a toggle or push button switch. Here’s how: Take a 10K Ohm and a 2.2K Ohm and solder in series across the Vbus (red) to ground(black wire). The tap between the two resistors will measure about a Volt. Solder D+ (green to this tap. Then wire the D- (white) through a N.O. switch to the same tap.<br>
Apply adapter or power pack supply and wait 1.5 seconds to push the button. Presto, 12V @1.5! No need to hold the button, the supply stays at 12.</p>
</blockquote>
<h2>Schematic</h2>
<p><img src="https://novamostra.com/wp-content/uploads/2020/05/qc12V.jpg" alt="Get 12V from Quickharge"></p>
<p><strong>The output when using a Blitzwolf BW-P6, 10000 mAH with Quick charge 3.0</strong></p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/xZJG_Px8mw0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h2>Breaking into the house</h2>
<p>So the procedure is as follows:<br>
<strong>1st Step:</strong> Unscrew the single Philips Screw.<br>
<strong>2nd Step:</strong> Apply 12 volts to LK+ and LK- contacts.<br>
<strong>3rd Step:</strong> Get into the house! (Optional, screw the doorbell  back to leave no traces)</p>
<h2>This is a serious security issue and every owner should be aware of.</h2>
<p>I tried to contact Avidsen from their site’s Contact Form and using two emails from their contact page without any luck. I hope that this post will reach owners out there to avoid any bad situations.</p>
<h2>Furthermore, my doorbell is not the only model. There are many more :</h2>
<ul>
<li><a href="https://www.avidsenstore.com/interphone-video-asgard-2-fils-p.html">Asgard</a></li>
<li><a href="https://www.avidsenstore.com/visiophone-2-fils-bulla-p.html">Bulla</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-effet-miroir-p.html">Effet miroir</a></li>
<li><a href="https://www.avidsenstore.com/visiophone-couleur-ultra-plat-design-effet-miroir.html">Effet miroir ref: 642277</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-krasten-2-fils-p.html">Krasten 2</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-nora-noir-p.html">Nora Noir</a></li>
<li><a href="https://www.avidsenstore.com/visiophone-thomson-smart-p.html">Smart 761</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-thomson-ecran-18-cm-p.html">Thomson 7" ref: 512162</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-ylva-ecran-11cm-p.html">Ylva</a>, <a href="https://www.avidsenstore.com/visiophone-ylva-2-lecteur-rfid-p.html">2+</a>, <a href="https://www.avidsenstore.com/visiophone-2-fils-avec-ecran-7-pouces-ylva-3-avidsen.html">3</a>, <a href="https://www.avidsenstore.com/visiophone-2-fils-avec-ecran-4-et-acces-rfid-ylva-3-compact.html">3+</a>, <a href="https://www.avidsenstore.com/visiophone-2-fils-avec-ecran-4-et-acces-rfid-ylva-3-compact.html">3+ Compact</a><br>
<h3>The worst of all is that they are aware of this issue:</h3>
<p>It seems that Avidsen’s – Thomson Smart Bracket 2 model suggests in the manual the use of silicone as a solution:<br>
From <a href="https://www.avidsenstore.com/cache/documents/product/qs-visiophone-smart-bracket-2-maisonic-1496.pdf">Visiophone Smart Bracket 2 – Thomson manual</a>:<br>
<img src="https://novamostra.com/wp-content/uploads/2020/05/silicone.png" alt="Secure with Silicone"></p>
</li>
</ul>
<p><strong>Even some of their 4 wire Video doorbells have the same vulnerability:</strong></p>
<ul>
<li><a href="https://www.avidsenstore.com/visiophone-compact-horizon-p.html">Horizon</a></li>
<li><a href="https://www.avidsenstore.com/interphone-video-ultra-plat-nordstrom-vision-4-p.html">Nordström Vision 4+</a></li>
</ul>
<p><strong>The same problem seems to exist on their wireless model also:</strong></p>
<ul>
<li><a href="https://www.avidsenstore.com/visiophone-sans-fil-izzy-tomson-p.html">IZZY-768W</a></li>
</ul>
<h2>Be careful… this is not the only company with this vulnerability</h2>
<p>After my findings with the current device, I found out that there are many companies out there using two wire implementations for doorbells leaving entrance control exposed. Pay special attention if you plan to buy or already using a wired doorbell for the way the entrance control works. Most of the times the manuals are online, so you can avoid situations like this one.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://novamostra.com/2020/06/23/breaking-into-a-house-using-a-power-bank/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627143</guid>
            <pubDate>Wed, 24 Jun 2020 12:36:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tuvalu Makes $4M a Year]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23627010">thread link</a>) | @jwdmsd1
<br/>
June 24, 2020 | https://factinator.com/tuvalu-island/ | <a href="https://web.archive.org/web/*/https://factinator.com/tuvalu-island/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
		<div id="content">
	<div id="primary">
		<main id="main">

		
<article id="post-14">
	<!-- .entry-header -->



	<div>
		<p>Tuvalu, a tiny island midway between Hawaii and Australia with a population of just 9,860, receives yearly payment of almost $4 million for literally doing nothing at all. The reason? This is the money that the Tuvalu government receives from royalties from the country’s domain name, <strong>.tv</strong>!</p>
<p><img src="https://factinator.com/wp-content/uploads/2014/01/tv.jpg" alt="tv" width="268" height="175"></p>
<p><span id="more-14"></span>Before you all fire up your calculator, let me burst your bubble that the money comes down to just about $405 per person and also that this money goes to the Tuvalu’s government. Tuvalu commercialized its internet TLD, .tv, in 1988 and started receiving royalties which now account for almost 10% of the government’s total revenue.</p>

<p><img src="https://factinator.com/wp-content/uploads/2014/01/Tuvalu.jpg" alt="Tuvalu" width="600" height="380" srcset="https://factinator.com/wp-content/uploads/2014/01/Tuvalu.jpg 600w, https://factinator.com/wp-content/uploads/2014/01/Tuvalu-300x190.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"></p>
<p>Isn’t it amazing that a country that’s merely a speck in ocean (10 sq miles to be exact) with nothing but hundreds of miles of water around it controls something so crucial to the internet world?! [via: Neeharika Palaka on <a href="mailto:http://www.quora.com/Neeharika-Palaka/answers?share=1">Quora</a> ]</p>


	</div><!-- .entry-content -->

<!--	<footer class="entry-footer">
		<span class="cat-links">Posted in <a href="https://factinator.com/category/read/" rel="category tag">Read Something</a></span><span class="tags-links">Tagged <a href="https://factinator.com/tag/facts/" rel="tag">facts</a>, <a href="https://factinator.com/tag/internet-facts/" rel="tag">internet facts</a>, <a href="https://factinator.com/tag/tuvalu-tv/" rel="tag">Tuvalu tv</a></span>	</footer>--><!-- .entry-footer -->
</article><!-- #post-14 -->

		
			
	
			
		

<ins data-ad-format="autorelaxed" data-ad-client="ca-pub-4948218261801237" data-ad-slot="8302572482"></ins>


			
                            
	
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>https://factinator.com/tuvalu-island/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627010</guid>
            <pubDate>Wed, 24 Jun 2020 12:19:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graphics Study: Red Dead Redemption 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23627009">thread link</a>) | @strangecasts
<br/>
June 24, 2020 | https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/ | <a href="https://web.archive.org/web/*/https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                

<p>One of my favorite games of all time, <a href="https://en.wikipedia.org/wiki/Red_Dead_Redemption" target="_blank">Red Dead Redemption</a>
returned with a <a href="https://en.wikipedia.org/wiki/Red_Dead_Redemption_2" target="_blank">prequel</a> for consoles in 2018. Then it came for PCs in 2019.
I finally managed to play the game and amazed by its graphics immediately.
But I got upset because I can barely play the game on medium settings at 25 FPS with a 1050Ti laptop GPU.
I know that I don't have a good rig but 25 FPS on medium settings?</p>

<p>Today, we are going to look at some frame captures from the game and try to analyze graphics techniques used in the game.</p>

<h2 id="foreword">Foreword</h2>

<p>This isn't an official breakdown of the game. It just me analyzing <a href="https://renderdoc.org/" target="_blank">RenderDoc</a> frame captures.
If you want to learn from the actual developers,
you can check the slides from a SIGGRAPH talk by <a href="https://twitter.com/globbbe" target="_blank">Fabian Bauer</a>.
<a href="https://advances.realtimerendering.com/s2019/index.htm" target="_blank">Slides</a> (At the bottom of the page), <a href="https://dl.acm.org/doi/10.1145/3305366.3335036" target="_blank">Video</a> (starts at 1:58:00)</p>

<p>You can also read a graphics analysis of GTA5 by Adrian Courrèges <a href="https://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/" target="_blank">here</a>.
Since both RDR2 and GTA5 are from the same company and uses the same engine, some of the techniques from GTA5 present here as well.</p>

<p>Another important thing is that, I am not a senior graphics programmer or anything like that.
I am still a junior in this field.
So, there will be plenty of things that I don't understand. If you find any mistakes or things that can be improved, please reach out to me. Here we go!</p>

<h2 id="dissecting-a-frame">Dissecting a frame</h2>

<p>Here is the main frame for dissecting:</p>

<p><img src="https://imgeself.github.io/img/mainframe.jpg" alt="MainFrame">
<em>Captured on PC, medium settings.</em></p>

<blockquote>
<p>When it comes to a game like RDR2, it's almost impossible to see all the techniques in one frame.
It amortizes its work across multiple frames.
Because of that, I captured more than a single frame but this is the main one we are going to be focusing on.
It contains a lot of properties like; spot and point lights, directional light (it's very subtle but it's there), buildings, NPCs, a horse, trees, vegetation, clouds, etc. It should demonstrate most of the rendering techniques used in the game.</p>
</blockquote>

<p>RDR2 is an open-world game that streams data constantly. Because of that, the frame starts with a bunch of tasks like creating and deleting textures, shader resource views, unordered access views, updating descriptors, buffers, etc.</p>

<h3 id="mud-map">Mud map</h3>

<p>Mud plays a big role in the game. Beside being a game mechanic, it makes envrionments more realistic. The game renders footprint textures of humans and horses into a displacement map along with trail textures of horse wagon wheels. This accumulated texture is used for <a href="https://developer.amd.com/wordpress/media/2012/10/Tatarchuk-POM.pdf" target="_blank">Parallax Occlusion Mapping</a> when rendering terrain.</p>

<p><img src="https://imgeself.github.io/img/mudmap.png" alt="MudMap">
<em>Mud map: 2048x2048 <code>R16_UNORM</code></em></p>

<h3 id="sky-and-clouds">Sky and clouds</h3>

<p>After the mud pass, the game does a lot of work on GPU compute. Most of them related to sky and clouds.
Clouds, fog, and volumetrics are RDR2's prominent effects.
You can find more information about this stage on Fabian's slides. He explains in far more detail than I could ever explain.</p>

<h3 id="environment-map">Environment map</h3>

<p>Environment maps are the main source of reflections in RDR2 as well as GTA5.
<a href="http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/#environment-cubemap" target="_blank">Like the GTA5</a>, RDR2 generates an environment cubemap from the camera position.
It generates a thin GBuffer for the envrionment map, similar to <a href="https://www.youtube.com/watch?v=rD6KcxcCl_8" target="_blank">Far Cry 4</a>.</p>

<p><img src="https://imgeself.github.io/img/envalbedo.jpg" alt="EnvironmentMapAlbedo">
<em>Environment Cubemap Faces (Albedo): <code>RGBA8_SRGB</code></em></p>

<p><img src="https://imgeself.github.io/img/envnormal.jpg" alt="EnvironmentMapNormal">
<em>Environment Cubemap Faces (Normal): <code>RGBA8_UNORM</code></em></p>

<p><img src="https://imgeself.github.io/img/envdepth.jpg" alt="EnvironmentMapDepth">
<em>Environment Cubemap Faces (Depth): <code>D32S8</code></em></p>

<p>Environment cubemap generation in every frame can be a heavy task. RDR2 does some optimizations to reduce the cost.
For example, the game only draws static and opaque objects, does <a href="https://www.gamedev.net/tutorials/programming/general-and-gameplay-programming/frustum-culling-r4613/" target="_blank">frustum culling</a> before rendering each face, and draws lower LOD versions of models.
Although, I've found that poly count of the terrain is still very high for environment maps.</p>

<p>After the G-Buffer pass, a sky environment cubemap is generated using a sky paraboloid map and cloud-related textures.
The next step is convolution. RDR2 uses <a href="https://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf" target="_blank">split sum approximation</a> for Image Based Lighting.
That method uses a pre-filtered environment cubemap along with an environment BRDF LUT.
For filtering, the game convolutes an environment cubemap and stores convoluted versions in the cubemap's mipmap levels.</p>

<p>Before executing a lighting pass for the environment cubemap, RDR2 renders baked large-scale ambient occlusion into another cubemap texture.
The game uses screen space ambient occlusion but SSAO can help you on a small scale.
Baked ambient occlusion helps to darken on a large scale such as darkening in patios and interiors.</p>

<p><img src="https://imgeself.github.io/img/envao.jpg" alt="EnvironmentMapBakedAO">
<em>Environment Cubemap Faces (Baked AO): <code>R8_UNORM</code></em></p>

<p>Even though the game generates a GBuffer, it doesn't render lights the same way as classic <a href="https://en.wikipedia.org/wiki/Deferred_shading" target="_blank">deferred rendering</a>.
The lighting is done in one single compute pass instead of rendering every light's volume.
So it's more like a forward rendering without shadows.
The game also uses the "top-down world lightmap" technique, <a href="https://www.gdcvault.com/play/1017710/Rendering-Assassin-s-Creed" target="_blank">similar to Assassin's Creed III</a>, for baked lighting.</p>

<p>For each cubemap face, RDR2 renders the final color on top of the sky environment texture.
Then it filters the environment cubemap same as the sky environment cubemap.</p>

<p><img src="https://imgeself.github.io/img/envfinal.jpg" alt="EnvironmentMapFinal">
<em>Environment Cubemap Faces (Final): <code>R11G11B10_FLOAT</code></em></p>

<p>RDR2 also loads envrionment maps that located in building interiors when the player is near a building.
These are also cubemap G-Buffers streamed from the disk.</p>

<p><img src="https://imgeself.github.io/img/bakedenvalbedo.jpg" alt="BakedEnvironmentMapAlbedo">
<em>Baked Environment Cubemap Faces (Albedo): <code>BC3_SRGB</code> (Baked AO stored in alpha channel)</em></p>

<p><img src="https://imgeself.github.io/img/bakedenvnormal.jpg" alt="BakedEnvironmentMapNormal">
<em>Baked Environment Cubemap Faces (Normal): <code>BC3_UNORM</code></em></p>

<p><img src="https://imgeself.github.io/img/bakedenvdepth.jpg" alt="BakedEnvironmentMapDepth">
<em>Baked Environment Cubemap Faces (Depth): <code>R16_UNORM</code></em></p>

<p>The game calculates the lighting of these maps and filters them like the previous ones.
It only calculates one baked environment map at a time and only recalculates them when the time of day changes.
All of the environment maps are stored in a texture cubemap array. There isn't any <a href="http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/#cubemap-to-dual-paraboloid-map" target="_blank">cubemap to dual-paraboloid map conversion</a>.</p>

<h3 id="g-buffer-pass">G-Buffer Pass</h3>

<p>This stage starts with terrain depth prepass and then the game renders scene into G-Buffers.</p>

<table>
<thead>
<tr>
<th>GBuffer 0 <code>RGB</code></th>
<th>GBuffer 0 <code>A</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/albedo.jpg" alt="AlbedoTarget"></td>
<td><img src="https://imgeself.github.io/img/albedoa.jpg" alt="AlbedoTargetA"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RGBA8_SRGB</code> - This buffer contains albedo(base color) in RGB channels. I'm not sure what the alpha channel data is for but it's used on anti-aliasing stage.
</li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 1 <code>RGB</code></th>
<th>GBuffer 1 <code>A</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/normal.jpg" alt="NormalTarget"></td>
<td><img src="https://imgeself.github.io/img/normala.jpg" alt="NormalTargetA"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RGBA8_UNORM</code>: The RGB channels contain normals and the alpha channel contains something related to cloth and hair.
</li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 2 <code>RGB</code></th>
<th>GBuffer 2 <code>A</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/material.jpg" alt="MaterialTarget"></td>
<td><img src="https://imgeself.github.io/img/materiala.jpg" alt="MaterialTargetA"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RGBA8_UNORM</code>: This target is for material properties.

<ul>
<li>R: Reflectance(f0)</li>
<li>G: Smoothness</li>
<li>B: Metallic</li>
<li>A: Contains some shadowing (this channel will be used as a shadow mask at later stages)
</li>
</ul></li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 3 <code>R</code></th>
<th>GBuffer 3 <code>B</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/cavity.jpg" alt="Material2TargetR"></td>
<td><img src="https://imgeself.github.io/img/cavityb.jpg" alt="Material2TargetB"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RGBA8_UNORM</code>: The red channel contains cavity. There is another mystery data in the blue channel. And hair related data in the alpha channel. I can't find anything on the green channel.
</li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 4 <code>RG</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/motionblur.jpg" alt="MotionBlurTarget"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>RG16_FLOAT</code>: This buffer contains screen space velocity for motion blur.
</li>
</ul>

<table>
<thead>
<tr>
<th>GBuffer 5 <code>Depth</code></th>
<th>GBuffer 5 <code>Stencil</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/depth.jpg" alt="DepthTarget"></td>
<td><img src="https://imgeself.github.io/img/stencil.jpg" alt="StencilTarget"></td>
</tr>
</tbody>
</table>

<ul>
<li><code>D32S8</code>: Like the GTA5, RDR2 is also using <a href="https://developer.nvidia.com/content/depth-precision-visualized" target="_blank">reversed-z</a> for depth and using the stencil buffer to assign certain values to certain group of meshes.
</li>
</ul>

<p>There is another target is generated from baked data:</p>

<table>
<thead>
<tr>
<th>GBuffer 6 <code>R</code></th>
<th>GBuffer 6 <code>G</code></th>
</tr>
</thead>

<tbody>
<tr>
<td><img src="https://imgeself.github.io/img/gitarget.jpg" alt="BakedAO"></td>
<td><img src="https://imgeself.github.io/img/gitargetg.jpg" alt="MysteryTarget"></td>
</tr>
</tbody>
</table>

<p>This buffer contains baked ambient occlusion in the red channel, the same as in the environment map stage.
But there are other channels in this texture. The green channel contains some data that looks like the data in GBuffer 3's blue channel.
Again, I don't know what is this data used for. And I can't find any data in blue and alpha channels on my captures. I will investigate this further.</p>

<h3 id="shadow-map-generation">Shadow Map Generation</h3>

<p>After the G-Buffer stage, the game starts to render shadow maps.
It uses 2D texture arrays for point light shadow maps and texture cube arrays for point light shadow maps.</p>

<p>Some games use big shadow atlas texture for shadow maps (<a href="http://advances.realtimerendering.com/s2016/Siggraph2016_idTech6.pdf" target="_blank">e.g DOOM</a>).
One of the advantages of that method is shadow map size can vary based on distance.
When you use texture arrays, you lose that flexibility because all of the textures in texture arrays must be the same size.
RDR2 has 3 different texture arrays for different quality.
For example, spotlights have:</p>

<ul>
<li><strong>512x768 D16</strong> for distant lights</li>
<li><strong>1024x1536 D16</strong> for medium distance(and closer distance on medium setting) lights</li>
<li><strong>2048x3072 D16</strong> for closer lights (on high/ultra settings)</li>
</ul>

<p>Point lights cast shadows in all directions. To deal with that problem, games use a technique called <a href="https://learnopengl.com/Advanced-Lighting/Shadows/Point-Shadows" target="_blank">Omnidirectional Shadow Mapping</a>
where you render the scene into a depth cubemap from the camera position. Campfire shadows and shadows from Arthur's lantern are rendered using this technique.
Point light shadows have 3 different arrays for different quality settings same as spotlights.</p>

<p>Most of the static point lights in the game have baked shadow cubemaps.
So, the game uses baked shadows whenever it can and only generates shadow maps when the player is near a light-volume.
But things get more interesting than that.</p>

<p>Most of the lights on walls are spotlights but the game doesn't generate an omnidirectional shadow map for them.
Instead, it generates a spotlight shadow map and copies that shadow map's memory into pointlight shadow map cube array.</p>

<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td><img width="512" height="768" src="https://imgeself.github.io/img/spotshadow.jpg"></td>
<td><img width="128" height="768" src="https://imgeself.github.io/img/pointshadow.jpg"></td>
</tr>
</tbody>
</table>

<p><em>Left image is a 1024x1536 spotlight shadow map, right image is the same image data in 512x512 texture cube format</em></p>

<blockquote>
<p>Note that local light shadow maps stores linear z.</p>
</blockquote>

<p>That explains why they are not using a square sized shadow map for spotlights.
Pixel count for spotlight shadow and point light texture cubemap should be the same.
I am sure that you noticed some weird slice pattern in the right image.
That happens because the width of spot and point light shadow map is different.</p>

<p>Also note that this texture doesn't cover 360 degrees.
But luckily, lights on buildings generally have a wall on their backside and baked shadow maps cover it.</p>

<p>Another interesting thing is that this process is vice-versa.
For example, in Saint Denis -one of the biggest cities in the game- the game generates omnidirectional shadow maps for spotlights
and copies that data into spotlight shadow map array.
I don't know why RDR2 doing shadow mapping like this. I couldn't find any similar technique on the internet.</p>

<p>Directional light shadow mapping in RDR2 is pretty much the <a href="http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/#shadows" target="_blank">same as in GTA5</a>. <a href="https://docs.microsoft.com/en-us/windows/win32/dxtecharts/cascaded-shadow-maps" target="_blank">Cascaded Shadow Mapping</a> with 4 cascades.
Each 1024x1024 tile of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/">https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/</a></em></p>]]>
            </description>
            <link>https://imgeself.github.io/posts/2020-06-19-graphics-study-rdr2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23627009</guid>
            <pubDate>Wed, 24 Jun 2020 12:18:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text-Only Websites]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 113 (<a href="https://news.ycombinator.com/item?id=23626929">thread link</a>) | @lcnmrn
<br/>
June 24, 2020 | https://sjmulder.nl/en/textonly.html | <a href="https://web.archive.org/web/*/https://sjmulder.nl/en/textonly.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>By <a href="https://sjmulder.nl/en/">Sijmen J. Mulder</a></p>

<p>This is a directory of websites that <strong>primarily stick with
simple, marked up, hyperlinked text</strong>. I appreciate these sites
because they load quickly, scroll smoothly, spare my battery, are more
compact, and lack the usual nonsense that infects many websites.</p>

<p><small><sup>*</sup> not <em>quite</em> text-only, see preceding
parapgraph. See <a href="#notquite">Honorable mentions</a> below
for sites that aren't quite ‘text-only’ but lightweight
and worth visiting nonetheless.</small></p>

<h3>News</h3>

<ul>
  <li><a href="http://thin.npr.org/">NPR</a></li>
  <li><a href="http://lite.cnn.io/en">CNN</a></li>
  <li>
    <a href="https://www.csmonitor.com/layout/set/text/textedition">
      The Christian Science Monitor
    </a>
  </li>
  <li><a href="https://noslite.nl/">NOS</a> (Dutch)</li>
  <li><a href="https://legiblenews.com/">Legible News</a></li>
  <li><a href="https://lite.poandpo.com/">POST Online Media</a></li>
  <li><a href="https://www.ard-text.de/mobil/">ARD Teletext</a></li>
</ul>

<h3>Social</h3>

<ul>
  <li><a href="https://lobste.rs/">Lobsters</a></li>
  <li>
    <a href="https://rawtext.club/">rawtext.club</a>
    – “<em>Resist</em> the dazzling spectacle”
  </li>
</ul>

<h3>Technology</h3>

<ul>
  <li><a href="https://news.ycombinator.com/">Hacker News</a></li>
  <li>
    <a href="https://www.rfc-editor.org/rfc-index-100a.html">
      RFC index
    </a>
  </li>
  <li>
    <a href="https://www.freesoft.org/CIE/Topics/index.htm">Connected</a>,
    an internet encyclopedia.
  </li>
  <li>
    <a href="https://bearblog.dev/">Bear Blog</a>,
    text-first blogging platform
  </li>
  <li>
    <a href="https://mataroa.blog/">Mataroa blog</a>,
    another text-first blogging platform
  </li>
  <li>
    <a href="http://manpages.bsd.lv/index.html">Practical UNIX Manuals</a>,
    on <em>mdoc</em> and history
  </li>
</ul>

<h3>Blogs &amp; Personal</h3>

<ul>
  <li>
    <a href="http://idlewords.com/talks/">Maciej Cegłowski</a>
    (talks on various topics, not quite text only)
  </li>
  <li>
    <a href="http://sommarskog.se/">Erland Sommarskog</a> (mostly SQL)
  </li>
  <li>
    <a href="http://bactra.org/">Cosma's Home Page</a>
  </li>
  <li>
    <a href="http://blog.fefe.de/" hreflang="de">Fefes Blog</a>
    (German)
  </li>
  <li>
    <a href="https://gir.st/">Tobias Girstmair</a>,
    <a href="https://gir.st/blog">blog</a>
    (hardware &amp; software hacker)
  </li>
  <li>
    <a href="http://verisimilitudes.net/">verisimilitudes.net</a>
  </li>
  <li><a href="https://lukesmith.xyz/blogindex">Luke Smith</a></li>
  <li><a href="http://www.tomcooks.com/">Tom Cooks</a></li>
  <li><a href="http://danluu.com/">Dan Luu</a></li>
  <li>
    <a href="https://www.artemix.org/">Artemix</a>
    (back end and UX)
  </li>
  <li>
    <a href="https://idle.nprescott.com/">Nolan Prescott</a>,
    or “Idle Thoughts” (tech &amp; thinking)
  </li>
  <li>
    <a href="https://prog21.dadgum.com/">Programming in the Twenty-First Century</a>
  </li>
  <li>
     <a href="https://nullprogram.com/">null program</a>
     by Chris Wellons
  </li>
  <li>
    <a href="https://greghendershott.com/">Greg Hendershott</a>
    (mostly Racket)
  </li>
  <li><a href="https://terkel.com/">Terkel</a></li>
  <li><a href="https://brokensandals.net/">Jacob Williams</a></li>
  <li>
    <a href="http://www.jaruzel.com/">Jaruzel’s Home</a>
    of Retro and Other Curios
  </li>
  <li><a href="https://allstead.dev/">Willis Allstead</a></li>
  <li><a href="https://www.thomasjost.com/">Thomas Jost</a></li>
  <li><a href="https://wildauer.io/">Manuel Wildauer</a></li>
  <li>
    <a href="https://rgz.ee/">Roman Zolotarev</a>
    (<a href="https://www.openbsd.org/">OpenBSD</a> enthousiast)
  </li>
  <li>
    <a href="https://drewdevault.com/">Drew DeVault</a>,
    creator of <a href="https://sourcehut.org/">SourceHut</a>
  </li>
  <li>
    <a href="http://jrm4.com/">John R. Marks, IV</a>
    (created with <a href="http://zim-wiki.org/">Zim</a>)
  </li>
  <li>
    <a href="https://creativegood.com/">Creative Good</a>
    <span>– Since 1997</span>
  </li>
  <li><a href="https://patrickcollison.com/">Patrick Collison</a></li>
  <li><a href="http://eradman.com/">Eric Radman</a> (BSD &amp; SQL)</li>
</ul>

<h3>Music &amp; Podcasts</h3>

<ul>
  <li>
    <a href="https://vulfpeck.com/">Vulfpeck</a>,
    an American funk band
  </li>
  <li><a href="https://techtonic.fm/">Techtonic</a></li>
  <li><a href="https://19hz.info/">Electronic Music Calendars</a></li>
</ul>

<h3>Misc</h3>

<ul>
  <li>
    <a href="https://gopherpedia.com/">Gopherpedia</a>
    (<a href="https://en.wikipedia.org/wiki/Gopher_(protocol)">Gopher</a> interface to Wikipedia)
  </li>
  <li><a href="http://wttr.in/">wttr</a> (weather)</li>
  <li>
    <a href="http://rate.sx/">rate.sx</a>
    (crypto rates, same author)
  </li>
  <li>
    <a href="https://yarchive.net/">Usenet Archives</a>
    by Norman Yarvin
  </li>
  <li>
    <a href="https://every.sdf.org/">every.sdf.org</a>,
    a collection of plain-text files
  </li>
  <li><a href="https://www.craigslist.org/">Craigslist</a>
</li></ul>

<p>Please send me suggestions on <a href="mailto:ik@sjmulder.nl">ik@sjmulder.nl</a>.</p>

<p><a href="#top">Back to top</a></p>

<hr>

<h2 id="notquite">Honorable mentions</h2>

<p>Note quite as ‘text-only’ but lightweight and worth
visiting nonetheless!</p>

<h3>News</h3>

<ul>
  <li>
    <a href="https://readspike.com/">Readspike</a>
    "Simple news aggregator"
  </li>
  <li><a href="https://spidr.today/">Spidr</a> (aggregator)</li>
  <li>
    <a href="https://www.svt.se/svttext/web/pages/100.html">SVT Text</a>
    (Swedish teletext service)
  </li>
  <li><a href="https://radfi.com/">Radio Fidelity</a> (aggregator)</li>
</ul>

<h3>Social</h3>

<ul>
  <li>
    <a href="https://subreply.com/">Subreply</a>
    (social network)
  </li>
  <li>
    <a href="https://needgap.com/">Needgap</a>
    (“problem validation”)
  </li>
  <li>
    <a href="https://midnight.pub/">midnight</a>
    (“networked writing” platform)
  </li>
</ul>

<h3>Technology</h3>

<ul>
  <li>
    <a href="https://sourcehut.org/">SourceHut</a>
    (git, mailing lists, etc)
  </li>
  <li>
    <a href="https://archive.vn/">archive.today</a>
    (web archiving)
  </li>
</ul>

<h3>Blogs &amp; Personal</h3>

<ul>
  <li>
    <a href="https://engineeringblogs.xyz/">Engineering Blogs</a>,
    a curated collection
  </li>
  <li>
    <a href="http://lucumr.pocoo.org/">Armin Ronacher</a> (mostly Rust)
  </li>
  <li>
    <a href="https://www.gwern.net/">Gwern Branwen</a> (various topics)
  </li>
  <li>
    <a href="https://hugotunius.se/">Hugo Tunius</a> (programming)
  </li>
  <li><a href="https://usmanity.com/">Muhammad Usman</a></li>
  <li>
    <a href="https://sgolem.com/">Stjepan Golemac</a>
    (JS, React, Node, Rust)
  </li>
  <li>
    <a href="http://maddox.xmission.com/">”The Best Page in the Universe”</a>
  </li>
  <li><a href="https://lawzava.com/">Law Zava</a></li>
  <li><a href="https://hitstartup.com/">hitstartup</a></li>
  <li><a href="https://jvns.ca/">Julia Evans</a> (tech)</li>
  <li>
    <a href="https://wingolog.org/">Wingolog</a>
    (mostly functional programming)
  </li>
  <li>
    <a href="http://matt.might.net/">Matt Might</a>
    (medicine and computer science)
  </li>
  <li><a href="https://mnmlist.com/">mnmlist</a></li>
  <li>
    <a href="https://neil.computer/">Neil Panchal</a>
    – “quantum integrated circuits”!
  </li>
  <li>
    <a href="https://www.imperialviolet.org/">ImperialViolet</a>
    by adam Langley (mostly crypto)
  </li>
  <li><a href="https://sirodoht.com/">sirodoht</a></li>
  <li><a href="https://sheep.horse/">Andrew Stephens</a></li>
  <li><a href="https://fnune.com/">Fausto</a></li>
  <li>
    <a href="https://noncombatant.org/">Noncombatant</a>
    (tech, music, more)
  </li>
  <li>
    <a href="https://daringfireball.net/">Daring Fireball</a>
    (predominantly Apple)
  </li>
  <li>
    <a href="https://inessential.com/">Inessential</a>
    by Brent Simmons, author of NetNewsWire
  </li>
</ul>

<h3>Misc</h3>

<ul>
  <li>
    <a href="https://wiby.me/">Wiby</a>,
    a search engine for these kinds of sites
  </li>
  <li><a href="http://www.jimmyr.com/">JimmyR</a> (aggregator)</li>
  <li>
    <a href="http://amasci.com/">Science Hobbyist</a>
    (90s design warning!)
  </li>
  <li>
    <a href="https://tilde.pt/~fimdomeio/index2.html">Web 0.5</a>
    (only for text browsers!)
  </li>
  <li>
    <a href="http://gutenberg.net.au/">Project Gutenberg Australia</a>
  </li>
  <li>
    <a href="http://www.rowlingindex.org/">The J.K. Rowling Index</a>
  </li>
  <li><a href="https://copypastelist.com/">Copy Paste List</a></li>
</ul>

<p><a href="#top">Back to top</a></p>
</div>]]>
            </description>
            <link>https://sjmulder.nl/en/textonly.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626929</guid>
            <pubDate>Wed, 24 Jun 2020 12:08:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Tools That You Can’t Go Without]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23626841">thread link</a>) | @NaeosPsy
<br/>
June 24, 2020 | https://serokell.io/blog/popular-machine-learning-tools | <a href="https://web.archive.org/web/*/https://serokell.io/blog/popular-machine-learning-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When you choose a machine learning tool, you choose your future. We all know how quickly everything changes in the world of artificial intelligence, so it is important to keep the balance between “old dog, old tricks” and “just made it yesterday”.</p><p>In this post, we are going to have a look at 18 popular machine learning tools. This review will cover ML platforms, frameworks, and ML libraries.</p><h2 id="top-machine-learning-frameworks%2C-libraries-and-platforms">Top machine learning frameworks, libraries and platforms</h2><p><img src="https://serokell.io/files/do/dogamq3v.1_(24).jpg" alt="top ML tools and platforms"></p><p>First, we are going to talk about platforms. They are built on a single channel architecture and designed in a way that it is convenient to program tasks. They may offer other services like work in the cloud, collaborative working options, or graphic processors for data visualization. They also use popular frameworks by Google, Microsoft, or Amazon.</p><p>Then, we will have a look at the frameworks to use when developing an ML application.</p><h3 id="machine-learning-platforms">Machine learning platforms</h3><p>If you are starting to work with ML, a platform with ready-made datasets and standard model templates will allow you to create your first solutions quicker and with fewer bugs. These platforms install all the necessary tools to let you start working in no time.</p><h4 id="1.-ai-platform-and-datasets-on-google-cloud">1. AI Platform and Datasets on Google Cloud</h4><p>The fundamental problem of any ML model is that you need a correct dataset to train it. They are expensive to make and take lots of time. <a href="https://cloud.google.com/public-datasets">Google Cloud Public Datasets</a> are datasets curated by Google that are regularly updated. The formats are very different: from images to audio, video, and texts. The data is intended for a wide range of researchers with different use cases.</p><p>In addition, Google offers other <a href="https://cloud.google.com/ai-platform">useful services</a> that you could find interesting:</p><ul>
<li>AI platform for training and managing ML models;</li>
<li>Natural language processing services;</li>
<li>Vision AI (models for computer vision);</li>
<li>Speech synthesis software in more than 30 languages etc.</li>
</ul><p>Google is known for their expertise in AI, so you can feel confident about using their solutions for your own projects.</p><h4 id="2.-amazon-web-services">2. Amazon Web Services</h4><p><img src="https://serokell.io/files/o7/o7x09kqd.2_(16).jpg" alt="Amazon Web Services"></p><p><a href="https://aws.amazon.com/machine-learning/">AWS</a> is a platform that provides artificial intelligence and machine learning services to developers. It is possible to choose one of the pre-trained AI services to work with computer vision, language recognition, speech generation, build recommender system and prediction models.</p><p>Using <a href="https://aws.amazon.com/sagemaker/">Amazon SageMaker</a>, you can quickly create, train, and deploy scalable machine learning models, or create custom models that support all the popular open-source ML platforms.</p><p>You can also use Amazon’s services to provide new functionality to existing business solutions. They can be easily integrated with different software, for example, to modernize the contact center and increase customer retention. AWS can help achieve higher customer satisfaction and expand the standard set of business tools.</p><h4 id="3.-microsoft-azure">3. Microsoft Azure</h4><p><a href="https://azure.microsoft.com/">Azure Machine Learning Studio</a> allows developers who don’t have experience in machine learning to use the drag-and-drop functionality. This platform allows you to build solutions directly “on the cloud” and easily create BI applications regardless of the quality of the data.</p><p>Microsoft also offers Cortana Intelligence, a tool that allows you to fully manage big data and analytics and transform data into meaningful information and subsequent actions.</p><p>Overall, Azure can be used by teams and large organizations to work on ML solutions together in the cloud. It has a wide set of tools for different purposes, which makes it so loved by international corporations.</p><h4 id="4.-rapidminer">4. RapidMiner</h4><p><a href="https://rapidminer.com/">RapidMiner</a> is a platform for data science and machine learning. It has a convenient graphical interface and allows to process data from a variety of different formats, including .csv, .txt, .xls, .pdf. Due to this ease of use and respect for privacy, Rapid Miner is used by thousands of enterprises around the world.</p><p>This tool is good when you need to build automated models quickly. It will help you to automatically analyze data and identify common quality problems with correlations, missing values, and stability. However, in order to solve more complex research problems, it is better to use other tools.</p><h4 id="5.-ibm-watson">5. IBM Watson</h4><p><img src="https://serokell.io/files/h0/h0ururfe.3_(13).jpg" alt="IBM Watson"></p><p>If you’re looking for a fully-functional platform with a number of tools for both research teams and enterprises, check out the <a href="https://www.ibm.com/watson">Watson platform by IBM</a>.</p><p>Watson is an open-source API suite. Its users have access to sample codes, a starter toolkit, and can create cognitive search engines and virtual agents. Their tools can be used by any developer to create their own software in the cloud, and the prices are very customer-friendly, which makes it a good solution for small and medium-sized businesses.</p><p>In addition, Watson has a chatbot creation platform that can be used by machine learning beginners for faster bot training.</p><h4 id="6.-anaconda">6. Anaconda</h4><p><a href="https://www.anaconda.com/">Anaconda</a> is an open-source ML platform for data analytics that works with Python and R. It can run on any supported operating systems for other platforms. It allows developers to use more than 1,500 Python and R data science packages, manage libraries and environments (including Dask, NumPy, and pandas).</p><p>Anaconda has great visualization capabilities for reports and modeling. This tool is popular because it brings together many tools with just one install.</p><p>Now, let us have a closer look at frameworks, libraries, and other tools for machine learning that you cannot miss out on.</p><h2 id="popular-languages-for-machine-learning">Popular languages for machine learning</h2><p><img src="https://serokell.io/files/d0/d0pza5ia.4_(8).jpg" alt="what is the best language for artificial intelligence?"></p><p>Python is one of the most popular ML languages. It is flexible and easy to learn. Python is an old language, and it has a rich set of libraries and frameworks that are regularly updated. These resources help to develop machine learning solutions faster thanks to sets of pre-programmed elements.</p><p>Another fairly popular language for machine learning applications is R. This language was created in order to work with statistical analysis. It has powerful visualization capabilities. If you want to work with R, you will need special packages. Ubuntu Pit has collected <a href="https://www.ubuntupit.com/best-r-machine-learning-packages/">20 best R packages</a> for you to use in ML.</p><p>You will find tools for these languages and more (like C++, Julia, Ruby, and Scala) below.</p><h3 id="python-tools">Python tools</h3><p><img src="https://serokell.io/files/9w/9wikp9ie.5_(6).jpg" alt="Machine Learning Tools: Experts' Top Picks 2020"></p><p>Python is the most widely used language in the domain of machine learning. Therefore, many important libraries for machine learning are in Python.</p><h4 id="7.-tensorflow">7. TensorFlow</h4><p><a href="https://www.tensorflow.org/">TensorFlow</a> is a set of open-source deep learning software libraries by Google. Using TensorFlow tools, ML specialists can create highly accurate and feature-rich machine learning models.</p><p>This software simplifies the process of building and deploying complex neural networks. TensorFlow offers APIs for Python and C/C ++ languages ​​that allow exploring its possibilities for research purposes. Moreover, enterprises all around the world get powerful tools for working with their own data and processing it in a cheap cloud environment.</p><p>TensorFlow libraries significantly simplify the integration of self-learning elements for applications designed to solve high complexity problems like speech recognition, computer vision, or natural language processing.</p><h4 id="8.-scikit-learn">8. Scikit-learn</h4><p><a href="https://scikit-learn.org/stable/">Scikit-learn</a> simplifies the process of creating classification, regression, dimensionality reduction algorithms, and helps with predictive data analytics. This library is open-source and can be used for both research and commercial purposes. Sklearn is built on <a href="https://www.youtube.com/watch?v=oYTs9HwFGbY">NumPy, SciPy, pandas, and matplotlib</a>, which are indispensable tools for ML programming in Python.</p><h4 id="9.-jupyter-notebook">9. Jupyter Notebook</h4><p><img src="https://serokell.io/files/e1/e1zq4m9t.6_(2).jpg" alt="Jupyter Notebook"></p><p><a href="https://jupyter.org/">Jupyter Notebook</a> is a command shell for interactive computing. This tool can be used not only with Python, but also with other programming languages: Julia, R, Haskell, and Ruby. It is often used for data analytics, statistical modeling, and machine learning.</p><p>Basically, Jupyter Notebook helps with interactive representations of projects in the field of data science. It allows to create beautiful analytics reports and to store and share code, visualizations, and comments.</p><h4 id="10.-colab">10. Colab</h4><p>Another handy tool you might want to have if you’re working with Python is Colab. Colaboratory, or simply Colab, allows you to write and execute Python in the browser. It requires zero configuration, gives you access to GPU power, and the results are easy to share.</p><h4 id="11.-pytorch">11. PyTorch</h4><p><a href="https://pytorch.org/">PyTorch</a> is a Python-based open-source framework for deep learning based on Torch. It does GPU-accelerated tensor computing like NumPy. On top of this, PyTorch offers a large library of APIs for programming neural network applications.</p><p>PyTorch differs from other machine learning services. Unlike TensorFlow or Caffe2, it doesn’t use static graphs. On the contrary, graphs in PyTorch are <a href="https://datascience.stackexchange.com/questions/45019/static-graphs-v-s-dynamic-graphs">dynamic and calculated on the go</a>. Working with dynamic graphs makes PyTorch easier to work with for some people and allows even beginners to apply deep learning in their projects.</p><h4 id="12.-keras">12. Keras</h4><p><a href="https://keras.io/">Keras</a> is a neural network API that provides a deep learning library for Python. Keras is the most widely-chosen deep learning framework among winning teams on <a href="https://www.kaggle.com/">Kaggle</a>. This is one of the best tools for those who start their career as a machine learning specialist. Compared to other libraries, Keras is much easier to understand. Also, it is more high-level, therefore, it is easier to conceptualize the big picture using Keras. Popular Python frameworks such as TensorFlow, CNTK, or Theano can work with it as well.</p><h3 id="other-frameworks">Other frameworks</h3><p>Machine learning is realized with a great variety of different languages and tools. Here are some frameworks that are not exclusively “for Python”.</p><h4 id="13.-knime">13. Knime</h4><p>You will need <a href="https://www.knime.com/knime-open-source-story">Knime</a> to work with data analytics and form reports. This open-source machine learning tool integrates numerous components for machine learning and data mining through its modular data pipelining concept. This software has regular releases and excellent support.</p><p>One of the big advantages of this tool is that It can integrate the code of various programming languages like C, C++, R, Python, Java, and JavaScript. It can easily be adopted by a team with different programming skills.</p><h4 id="14.-apache-spark-mllib">14. Apache Spark MLlib</h4><p><img src="https://serokell.io/files/j6/j69fht4j.8.jpg" alt="Apache Spark MLlib"></p><p><a href="http://spark.apache.org/mllib/">Apache Spark MLlib</a> is a data processing framework that has an expansive database of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/popular-machine-learning-tools">https://serokell.io/blog/popular-machine-learning-tools</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/popular-machine-learning-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626841</guid>
            <pubDate>Wed, 24 Jun 2020 11:56:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python should not be taught as a foundational language]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23626768">thread link</a>) | @illuminated
<br/>
June 24, 2020 | https://thedropout.dev/why-python-should-not-be-taught-in-colleges/ | <a href="https://web.archive.org/web/*/https://thedropout.dev/why-python-should-not-be-taught-in-colleges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://thedropout.dev/content/images/size/w300/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg 300w,
                            https://thedropout.dev/content/images/size/w600/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg 600w,
                            https://thedropout.dev/content/images/size/w1000/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg 1000w,
                            https://thedropout.dev/content/images/size/w2000/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://thedropout.dev/content/images/size/w2000/2019/07/chris-ried-ieic5Tq8YMk-unsplash.jpg" alt="Why Python should not be taught as a foundational language">
            </figure>

            <section>
                <div>
                    <p>Let me preface by adding "to Computer Science/Engineering majors". I think Python is a fine language and that it is very useful in a lot of situations, but I also think using Python as a foundational language is setting students up for a lot of unnecessary headache later on.</p><h3 id="syntax-and-semantics">Syntax and semantics</h3><p>My main gripe with Python is the syntax and semantics. Python looks something like this:</p><!--kg-card-begin: code--><pre><code>def some_func(var_one, var_two):
	for i in range(10):
    	num = i
    	print(i)
    # we can still see num here
    print(num)
    
some_func("thing1", "thing2")</code></pre><!--kg-card-end: code--><p>Right off the bat you should notice a few things, the lack of types, functional scope, and the lack of curly braces. The typing issue I can get over, Python is meant to be dynamically typed, and it is not as weird about it as <a href="https://thedropout.dev/javascript-the-bad-parts/">JavaScript is</a> and it recently added support for defining variable types in function parameters so it's OK in my book. </p><p>However Python does suffer from the same scoping issue as JavaScript, and scoping is done on a functional, rather than block, level. This can be confusing, especially since Python takes the insanity a step further and gets rid of the <code>var</code> ,<code>let</code> ,<code>const</code> keywords entirely, meaning there is not even a concept of a constant variable in Python. </p><p>Lastly, the most obvious difference from most languages you have likely seen is that there are no curly braces. This is because Python decided it would be a fun idea to govern blocks using whitespace, instead of wrapping everything in braces. In theory this might seem OK since you should already be properly indenting blocks of code, however in practice I find that it is much less legible and more kludgy to work with.</p><h3 id="naming-quirks">Naming Quirks</h3><p>Python also decided to go above and beyond and do things differently from most other languages. Part of this is the break from C-Style syntax, and they also name things differently. For instance, what is called an "Array" in pretty much every mainstream language, is instead called a "List" in Python. Key-Value stores that are usually called a "Map" or a "HashMap" are instead referred to as a "Dictionary".</p><h3 id="strings">Strings</h3><p>Then there are Strings, Strings in Python are horribly over-complicated. In most languages you have a <code>char</code> which is a single character, you can have a <code>char[]</code> or just an array of characters, and then a <code>String</code> that is usually some fancy wrapper around a regular <code>char[]</code>. When creating a string in most mainstream languages you can usually just do something along the lines of <code>var s = "string"</code> or for a <code>char</code> you usually use single quotes <code>var c = 'c'</code>. Python decided this was too simple and not specific enough. You can create a string the "normal" way, <code>s = "string"</code> or you can use single quotes <code>s = 'string'</code> or if you want a unicode string you would do <code>uni = u'unicode'</code> or you can craft a binary string <code>bin = b'some binary'</code>. You can also tell it directly what encoding you want to use, <code>utf = "some string".encode("utf-8")</code>. And you can also cast to string using <code>string = str("something")</code> because why not add another way to do things? Now I'm not saying its bad to specify what encoding you're using, but maybe if you could make it a bit more clear or use a syntax that is more common. </p><h3 id="version-split">Version split</h3><p>Another issue with Python is that it is essentially two different languages, there's Python 2.7 and Python 3+. Code written using Python &lt;= 2.7 will <em>sometimes </em>work on Python 3+, and code written using Python 3+ will <em>sometimes</em> work with Python &lt;= 2.7. This is because there were quite a few breaking changes introduced, that make many features that worked in 2.7, no longer work, or work differently in 3+. This as simple as the <code>print</code> function now work differently, for instance:</p><!--kg-card-begin: code--><pre><code>print 'Hello World'</code></pre><!--kg-card-end: code--><p>will work using Python &lt;= 2.7, however with Python 3+ this will raise a SyntaxError as you have to do</p><!--kg-card-begin: code--><pre><code>print('Hello World')</code></pre><!--kg-card-end: code--><p>Another popular feature in Python 2 was <code>xrange</code> which basically created an iterable object that is useful, and a bit quicker than <code>range</code>, in for loops. However, it was simply removed in Python 3. So, if I wanted to write the same code as above to be compatible for python 2.7, I would do something like this:</p><!--kg-card-begin: code--><pre><code>def some_func(var_one, var_two):
	for i in xrange(10):
    	num = i
    	print i
    # we can still see num here
    print num
    
some_func("thing1", "thing2")</code></pre><!--kg-card-end: code--><p>It is very common for languages to introduce new, backwards incompatible features. Especially with major revisions. However it is fairly uncommon to break so many widely used parts of the language that most code written before 3 simply cannot be run on the newer interpreter. The fact is that so much was broken that the community essentially split, and many people are staying on Python 2.7 as their libraries wont work on 3+ or they don't want to maintain 2 version of their codebase for backwards compatibility. This means that even though you are coding in 'Python', depending on which version you pick you are isolating yourself to a subset of the possible libraries or dependencies you can use. </p><p>All of these issues, and more, contribute to some serious headaches for new programmers. If you start by learning Python as a foundational language, when you inevitably switch to another language like C++ or Java, you have to learn an entire new vocabulary and grammar on top of the more difficult concepts as well. And Python's many quirks and irregularities don't make it the simplest language to learn from the get-go either.</p>
                </div>
            </section>

            <section>
                <h3>Subscribe to The Dropout Dev</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            

<!--            <section class="post-full-comments">-->
<!--                <div id="disqus_thread"></div>-->
<!--                <script>-->

<!--                    /**-->
<!--                     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.-->
<!--                     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/-->
<!--                    var disqus_config = function () {-->
<!--                    this.page.url = "https://thedropout.dev/why-python-should-not-be-taught-in-colleges/";  // Replace PAGE_URL with your page's canonical URL variable-->
<!--                    this.page.identifier = "ghost-5d1fc5f9114174269e1bf2b1"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable-->
<!--                    };-->
<!--                    (function() { // DON'T EDIT BELOW THIS LINE-->
<!--                        var d = document, s = d.createElement('script');-->
<!--                        s.src = 'https://the-dropout-dev.disqus.com/embed.js';-->
<!--                        s.setAttribute('data-timestamp', +new Date());-->
<!--                        (d.head || d.body).appendChild(s);-->
<!--                    })();-->
<!--                </script>-->
<!--                <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>-->
<!--            </section>-->

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://thedropout.dev/why-python-should-not-be-taught-in-colleges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626768</guid>
            <pubDate>Wed, 24 Jun 2020 11:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking eye centers location with Rust and OpenCV]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23626594">thread link</a>) | @todsacerdoti
<br/>
June 24, 2020 | https://www.blog.nodrama.io/rust-opencv-eye-center-localisation/ | <a href="https://web.archive.org/web/*/https://www.blog.nodrama.io/rust-opencv-eye-center-localisation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>Ever since finding <a href="https://github.com/twistedfall/opencv-rust/">OpenCV Rust bindings</a> I’ve been looking for a good project to try it out.
Than a <a href="https://github.com/jpmonettas/">friend</a> sparked my curiosity when talking about gesture recognition project he was implementing.</p>

<p>This inspired me to create a tool which can read frames from the camera, track eye movements and translate them to mouse cursor movements.
I reckoned Rust is a good fit for writing performant, numerical code.
First step would be to implement an algorithm responsible for tracking the location of eye center in a frame (the pupil), and this blog post is dedicated to describing one possible approach.</p>

<p>I started researching the subject and quickly found that the current state-of-the art is described in <a href="https://www.inb.uni-luebeck.de/fileadmin/files/PUBPDFS/TiBa11b.pdf">Timm and Barth, 2011</a> - I highly recommend reading the paper.
A bit more searching revealed that <a href="https://github.com/trishume/eyeLike">trishume</a> did all the hard work of implementing the algorithm in C++ using OpenCV.
Armed with this reference implementation and the original paper I could easily port it to Rust.</p>



<p>The algorithm described in the paper, which I will colloquially refer to as Timm-Barth, aims at finding a centre of a circular object.
It does so by optimizing (finding a maximum) of an objective function, which is a (weighted) sum of dot products of two vectors:</p>
<ul>
  <li>the normalized gradient vector  at pixel position  such that  and</li>
  <li>the displacement vector 
where  is a possible center.</li>
</ul>

<p>Formally:</p>



<p>The weights  are a way of incorporating prior knowledge: since the pupil is darker than the sclera or facial skin, darker pixels are more likely to be the centers.
If we consider that $I^*$ is the (smoothed and in a greyscale, as per paper’s suggestion) input frame, than at pixel with coordinates  we have that: .</p>



<p>An image gradient is a directional change in the or color intensity of the image.
At each pixel point of the frame, the gradient is a vector that points in the direction of the largest intensity increase, and the length of this vector corresponds to the rate of the change.</p>

<p>More formally the gradient of a two variable function  is defined as a vector of partial derivatives of that function in each direction:</p>

<!-- $$\nabla f = {\begin{bmatrix}g_{x}\\g_{y}\end{bmatrix}}={\begin{bmatrix}{\frac {\partial f}{\partial x}}\\{\frac {\partial f}{\partial y}}\end{bmatrix}$$ -->
<p><img src="https://www.blog.nodrama.io/images/2020-07-01-rust-opencv-eye-center-localisation/CodeCogsEqn.gif" alt="_config.yml"></p>

<p>Since the intensity function of a digital image is known only at discrete points, derivatives of this function cannot be defined, unless we assume some known, differentiable function which has been sampled at these points.</p>

<p>This is why typically the derivative of an image is approximated using <a href="https://en.wikipedia.org/wiki/Finite_difference">finite differences</a>
The <a href="https://github.com/trishume/eyeLike">implementation by trishume</a> implements a procedure where for inner rows of a given frame  which calculates the gradient for inner rows as a central difference.
<!-- For $$\forall (i,j), \: i\neq j$$ the gradient in direction $$x$$ is: --></p>



<p>and in direction :</p>



<p>For the edge rows the gradient value is the difference between the value and the adjacent position.</p>



<p>I decided to deviate a bit from the reference implementation.
Similar to what the paper describes I start by detecting the face region using framework descibed by <a href="https://www.researchgate.net/publication/220660094_Robust_Real-Time_Face_Detection">Viola and Jones, 2004</a>:</p>

<div><div><pre><code><span>let</span> <span>face_detector_name</span> <span>:</span> <span>&amp;</span><span>str</span> <span>=</span> <span>"/opt/opencv/opencv-4.2.0/data/haarcascades/haarcascade_frontalface_alt.xml"</span><span>;</span>
<span>let</span> <span>camera_window_name</span> <span>=</span> <span>"camera"</span><span>;</span>

<span>highgui</span><span>::</span><span>named_window</span><span>(</span><span>camera_window_name</span><span>,</span> <span>highgui</span><span>::</span><span>WINDOW_AUTOSIZE</span><span>)</span><span>?</span><span>;</span>

<span>let</span> <span>face_features</span> <span>=</span> <span>core</span><span>::</span><span>find_file</span><span>(</span><span>face_detector_name</span><span>,</span> <span>true</span><span>,</span> <span>false</span><span>)</span><span>?</span><span>,</span>
<span>let</span> <span>mut</span> <span>face_model</span> <span>:</span> <span>objdetect</span><span>::</span><span>CascadeClassifier</span> <span>=</span> <span>objdetect</span><span>::</span><span>CascadeClassifier</span><span>::</span><span>new</span><span>(</span><span>&amp;</span><span>face_features</span><span>)</span><span>?</span><span>;</span>

<span>let</span> <span>mut</span> <span>frame</span> <span>=</span> <span>Mat</span><span>::</span><span>default</span><span>()</span><span>?</span><span>;</span>
<span>cam</span><span>.read</span><span>(</span><span>&amp;</span><span>mut</span> <span>frame</span><span>)</span><span>?</span><span>;</span>

<span>face_model</span><span>.detect_multi_scale</span><span>(</span>
    <span>&amp;</span><span>frame</span><span>,</span> <span>// input image</span>
    <span>&amp;</span><span>mut</span> <span>faces</span><span>,</span> <span>// output : vector of rects</span>
    <span>1.1</span><span>,</span> <span>// scaleFactor: The classifier will try to upscale and downscale the image by this factor</span>
    <span>2</span><span>,</span> <span>// minNumNeighbors: How many true-positive neighbor rectangles do you want to assure before predicting a region as a face? The higher this face, the lower the chance of detecting a non-face as face, but also lower the chance of detecting a face as face.</span>
    <span>objdetect</span><span>::</span><span>CASCADE_SCALE_IMAGE</span><span>,</span>
    <span>core</span><span>::</span><span>Size</span> <span>{</span>
            <span>width</span><span>:</span> <span>150</span><span>,</span>
            <span>height</span><span>:</span> <span>150</span>
    <span>},</span> <span>// min_size. Objects smaller than that are ignored (poor quality webcam is 640 x 480, so that should do it)</span>
    <span>core</span><span>::</span><span>Size</span> <span>{</span>
            <span>width</span><span>:</span> <span>0</span><span>,</span>
            <span>height</span><span>:</span> <span>0</span>
    <span>}</span> <span>// max_size</span>
  <span>)</span><span>?</span><span>;</span>
</code></pre></div></div>

<p>The article posits selecting the eye regions as fractions of the face region.
I opted for using viola-jones algorithm again, but this time with a model trained to detect eyes in the face region:</p>

<div><div><pre><code><span>if</span> <span>faces</span><span>.len</span> <span>()</span> <span>&gt;</span> <span>0</span> <span>{</span>
  <span>// region of interest (submatrix), first detected face</span>
  <span>let</span> <span>face_region</span> <span>=</span> <span>Mat</span><span>::</span><span>roi</span> <span>(</span><span>&amp;</span><span>enhanced_frame</span><span>,</span> <span>faces</span><span>.get</span> <span>(</span><span>0</span><span>)</span><span>?</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>face</span> <span>=</span> <span>faces</span><span>.get</span> <span>(</span><span>0</span><span>)</span><span>?</span><span>;</span>
  <span>// calls viola-jones eyes classifier</span>
  <span>let</span> <span>eyes</span> <span>=</span> <span>detect_eyes</span> <span>(</span><span>&amp;</span><span>face_region</span><span>,</span>
                          <span>&amp;</span><span>mut</span> <span>eyes_model</span><span>)</span><span>?</span><span>;</span>
 <span>}</span>
</code></pre></div></div>

<p>Finally for each detected eye I apply the implemented Timm-Barth algorithm:</p>

<div><div><pre><code><span>if</span> <span>eyes</span><span>.len</span> <span>()</span> <span>==</span> <span>2</span> <span>{</span>
  <span>let</span> <span>left_eye</span> <span>=</span> <span>eyes</span><span>.get</span> <span>(</span><span>0</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>left_eye_region</span> <span>=</span> <span>Mat</span><span>::</span><span>roi</span> <span>(</span><span>&amp;</span><span>face_region</span><span>,</span> <span>left_eye</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>left_eye_center</span> <span>=</span> <span>timm_barth</span><span>::</span><span>find_eye_center</span> <span>(</span><span>&amp;</span><span>left_eye_region</span><span>,</span> <span>left_eye</span><span>.width</span><span>)</span><span>?</span><span>;</span>

  <span>let</span> <span>right_eye</span> <span>=</span> <span>eyes</span><span>.get</span> <span>(</span><span>1</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>right_eye_region</span> <span>=</span> <span>Mat</span><span>::</span><span>roi</span> <span>(</span><span>&amp;</span><span>face_region</span><span>,</span> <span>right_eye</span><span>)</span><span>?</span><span>;</span>
  <span>let</span> <span>right_eye_center</span> <span>=</span> <span>timm_barth</span><span>::</span><span>find_eye_center</span> <span>(</span><span>&amp;</span><span>right_eye_region</span><span>,</span> <span>right_eye</span><span>.width</span><span>)</span><span>?</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>The implementation itself can be found in a repository <a href="https://github.com/fbielejec/rust-opencv/blob/master/src/timm_barth.rs#L142">here</a>,
and pretty-much follows the reference implementation.
The same repository contains the working code, as well as instructions on installing the OpenCV framework (see <a href="https://github.com/fbielejec/rust-opencv#install-image-and-video-io-libraries">README</a>).</p>

<p>Here is a video of the algorithm in action:</p>

<video width="640" height="480" controls="controls" poster="https://www.blog.nodrama.io/images/2020-07-01-rust-opencv-eye-center-localisation/screenshot.png">
  <source src="https://www.blog.nodrama.io/images/2020-07-01-rust-opencv-eye-center-localisation/screencast_2.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>

<p>Thanks for reading!</p>

  </div></div>]]>
            </description>
            <link>https://www.blog.nodrama.io/rust-opencv-eye-center-localisation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626594</guid>
            <pubDate>Wed, 24 Jun 2020 11:18:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HEY Email is a niche offering masquerading as a category disruptor]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23626542">thread link</a>) | @latc
<br/>
June 24, 2020 | https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_29_9de">

<div>
<div id="slimcalltoaction"><p>This is box title</p><p>All content, including this exclusive article, is free to access during the launch month of June. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>



<p>HEY is the new email client pledging to make email great again, it’s landing page is an open letter detailing the failed state of current email services, naming Gmail, Yahoo, Outlook and Apple as the service providers that simply “let it happen”. Along with its ‘reinvention’ of email, HEY is also introducing a $99 annual subscription model – with 2 character emails costing up to $999 per user. Its justification for the pricing is that free email charges users in the form of data mining and advertising, acknowledging that while $99 is expensive for certain (developing) markets it is the price tag of a private, ad-free email space.&nbsp;</p>



<p>From the outset it’s obvious that HEY is targeted at a niche user base, the aim here isn’t to be a ‘fresh start’ for the hundreds of millions of people using free email at the moment. In fact moving away from a ubiquitous, free model toward a premium subscription model is akin to the friction of returning to SMS texting rather than Whatsapp or Messenger. HEY’s premium user experience is a product strategy used to target niche high-frequency users. While this limited user base is willing to move away from ingrained digital habits, the true disruption of email would require a widely accessible innovation of its core utility.</p>



<h3>Returning to the ‘wonder’ of emails: necessity or marketing</h3>



<p>UI/UX differentiation is a competitive method used to service saturated markets, it is targeted at carving out segments of the existing market rather than creating new demand. HEY is addressing the ‘experience problem’ of emails, hoping to make it more effective, personable and enjoyable. The idea is that email has devolved into a heap of spam and unwanted contact, becoming a chore to wade through. HEY’s vision statement implies that it wants to get back to the days when email used to be a “wonder”, tapping into the nostalgia of what snail-mail used to represent.&nbsp;</p>



<p>Let’s address this first: is email supposed to be enjoyable? Maybe at the outset it was a replication of snail mail, holiday cards from family or the primary way of keeping in contact with long-distance friends. While these are still things we treasure, social media, instant messaging and niche applications have replaced the need for email to serve this function. Email has very much become a practical function of our lives, aggregating bills and newsletters – that isn’t necessarily a ‘problem’.&nbsp;</p>



<h3>Converting free users into subscription users</h3>



<p>In a saturated market like email services, capturing a niche comes at the cost of servicing the masses. Where HEY cannot preserve its private and ad-free proposition while maintaining a free or even a more affordable subscription model, it opts to provide a premium service. A profit making alternative to the currently free email model is yet to emerge.&nbsp;</p>



<p>The conversion of free users into subscription users hinges on HEY’s ability to convince these users that its features are more value adding than the $99 fee. From the user’s end there is also the need to relearn email habits – even when these are seemingly more efficient habits, this is a big ask in the world of user services. This leaves HEY with access to a smaller set of users who are already looking to renovate their email habits – their marketing strategy needing to play a big role in expanding this user pool.</p>



<p>Hey is basically targeting two focus areas, improved user experience (ad-free, organisational features) and better privacy. These can act as two separate user desires, users may be drawn in on the premise of either or both. The privacy based niche is already being competed for by several contenders. HEY’s premium pricing might prompt users to opt for other privacy focused email services, free or subscription-based, like Protonmail or Fastmail. This makes HEY’s UI/UX offering all the more important, their one point of unique potential to win customer loyalty. Given that UI/UX improvements – no matter how great – are only marginal improvements in the eyes of the user (as opposed to product innovation) this strategy often falls back on aggressive marketing efforts.&nbsp;</p>



<p>In this scenario there are two ways that this business model can extract value:</p>



<ul><li>Subscription model that is more suitable for a niche market&nbsp;</li><li>Free service that banks on similar monetisation avenues available in the existing services&nbsp;</li></ul>



<p>UI/UX solutions for ubiquitous and free services tend to opt for a subscription-based offering as a form of capturing value, reaping the rewards of a more condensed user base and opting out of the tradeoffs necessary for disrupting the ubiquitous forms of use. However, a subscription model, as we discussed earlier, creates a ceiling on adoption – relegating it in the near term to a novel solution.</p>



<p>Regardless of speculation on the true motive behind it, HEY’s recent and very public dispute with Apple over its IOS App store listing was a boon for the product’s virality. HEY’s strategy initially started with an invite-only exclusive approach, but the apparent struggle with Apple has had much further reaching impact on product awareness. As HEY leans into the anti-big-tech narrative to leverage its marketing potential, it needs to tread carefully such that it doesn’t risk seeming intellectually dishonest – especially given that it is not providing a truly accessible alternative to the large email service providers it claims to be competing with.&nbsp;</p>



<p>HEY’s ability to retain users on the platform will become dependent on their ability to continue convincing users that there is value in the experience of an email – especially where functionality remains abundant on much larger competing platforms. HEY’s annual subscription is an intentional habit building funnel, user’s who subscribe will have a year to become familiar with – and hopefully attached to – the service’s features. Given that there is always the potential for habits to be transferred across platforms though, it will be imperative that HEY continues innovating its unique proposition.</p>



<p><span>Down the Rabbit Hole</span>
</p>



<h3>1. Red ocean traps demonstrate the pitfalls faced by founders attempting to find or create fertile grounds for products and services</h3>



<p>As market power increasingly moves from companies to consumers, competition intensifies. Long-term success will increasingly “depend on the ability to generate new demand and create and capture new markets.” “Red ocean traps” are pitfalls that hinder the creation or identification of new markets.</p>



<p>“We have come to think of them as red ocean traps, because they effectively anchor managers in red oceans—crowded market spaces where companies engage in bloody competition for market share—and prevent them from entering blue oceans, previously unknown and uncontested market spaces with ample potential.”</p>



<p>Red ocean traps confuse strategies for competitive advantages with creating new markets.</p>



<p><strong>Trap one: seeing market-creating strategies as customer-oriented approaches</strong></p>



<p>Focusing on existing customers keeps companies mired in red oceans.&nbsp;</p>



<p><strong>“</strong>an organization needs to turn its focus to noncustomers and why they refuse to patronize an industry’s offering. Noncustomers, not customers, hold the greatest insight into the points of pain and intimidation that limit the boundary of an industry.”</p>



<p><strong>Trap two: treating market-creating strategies as niche strategies</strong></p>



<p>Segmenting existing markets into finer segments to identify niches is not the same as creating new markets.</p>



<p>“Successful market-creating strategies don’t focus on finer segmentation. More often, they “desegment” markets by identifying key commonalities across buyer groups that could help generate broader demand.”</p>



<p><strong>Trap three: confusing technology innovation with market-creating strategies</strong></p>



<p>“Value innovation, not technology innovation, is what launches commercially compelling new markets. Successful new products or services open market spaces by offering a leap in productivity, simplicity, ease of use, convenience, fun, or environmental friendliness. But when companies mistakenly assume that market creation hinges on breakthrough technologies, their organizations tend to push for products or services that are too “out there,” too complicated, or, like the Segway, lacking a necessary ecosystem.“</p>



<p><strong>Trap four: equating creative destruction with market creation</strong></p>



<p>Creative destruction refers to a new invention replacing an existing product or technology. But creating new markets does not always require creative destruction.&nbsp;</p>



<p>“Many market-creating moves are nondestructive, because they offer solutions where none previously existed. We’ve also seen this happen with the social networking and crowdfunding industries. And even when a certain amount of destruction is involved in market creation, nondestructive creation is often a larger element than you might think. Nintendo’s Wii game player, for example, complemented more than replaced existing game systems, because it attracted younger children and older adults who hadn’t previously played video games.”</p>



<p><strong>Trap five: equating market-creating strategies with differentiation</strong></p>



<p>Differentiation is when a competitor stands out from the competition by providing premium value and the trade-off is higher costs for both the consumer and the competitor.</p>



<p>“In reality, a market-creating move breaks the value-cost trade-off. It is about pursuing differentiation and low cost simultaneously… A market-creating move is a “both-and,” not an “either-or,” strategy. …when companies mistakenly assume that market creation is synonymous with differentiation, they often focus on what to improve or create to stand apart and pay scant heed to what they can eliminate or reduce to simultaneously achieve low cost.”</p>



<p><strong>Trap six: equating market-creating strategies with low-cost strategies</strong></p>



<p>“This …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/">https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/</a></em></p>]]>
            </description>
            <link>https://4thquadrant.io/exclusive/hey-can-a-ui-ux-makeover-disrupt-the-free-email/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626542</guid>
            <pubDate>Wed, 24 Jun 2020 11:08:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Entropy]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23626253">thread link</a>) | @1penny42cents
<br/>
June 24, 2020 | https://camhashemi.com/2020/06/23/software-entropy/ | <a href="https://web.archive.org/web/*/https://camhashemi.com/2020/06/23/software-entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-195">
			<!-- .entry-header -->
		<div>
		
<h2>Defining Entropy</h2>



<p>Entropy is a measure of chaos, or disorder, in a system.</p>



<p>My college physics professor described entropy using two shoe closets.</p>



<p>Imagine a clean shoe closet, where all shoes are paired and sorted by color. The closet’s entropy is the total number of arrangements its shoes can have. A clean closet’s entropy is relatively small. There may be a few pairs of grey or blue shoes that can be switched around – but this doesn’t add much complexity. In a closet with low entropy, it’s easy to add or remove shoes from that closet as needed.</p>



<p>Now imagine a messy shoe closet. None of the shoes are paired, and they’re all tangled in a big pile. How many possible combinations can these shoes be in? You can quickly find out by trying to pull out the pair you want. The messy shoe closet has a much greater entropy than the clean one.</p>



<p>In short, we measure entropy by counting the number of possible states a system can be in. More states mean more entropy.</p>



<h2>Entropy in Software</h2>



<p>In software, our building blocks are simple enough for us to measure entropy in a crude way. Take this model for example:</p>


<pre title="">Transaction(
  createdAt: String
  buyerId: String,
  sellerId: String
  amount: Int
)
</pre>


<p>As simple as it seems, this model is like our messy shoe closet. There are many more ways for this model to be wrong than there are for it to be right. We can see that by comparing it to an organized shoe closet:</p>


<pre title="">Transaction(
  createdAt: DateTime,
  buyerId: UserId,
  sellerId: UserId,
  amount: Price
)
</pre>


<p>When `createdAt` was an arbitrary string, it could take on invalid values “foo” and “bar” just as easily as a valid value “06-23-2020”. There are many more possible states that the field can be in, and most of them are invalid. This choice of a broad data type allows chaos into our model. This unwanted chaos leads to misunderstandings, bugs, and wasted energy.</p>



<p>When each model is strongly typed to a strict set of values, this chaos is minimized. DateTime, UserId, and Price are typed such that all possible values are valid. Accordingly, these types are more predictable, easier to manipulate, and lead to less surprises in practice.</p>



<p>As in life, entropy is not all bad – some of it is desirable and some of it is not. In software, we need entropy to a certain extent: our code is valuable <em>because </em>it supports a variety of possible dates, users, and prices. But when this chaos grows beyond the value it adds, our software becomes painful to use and painful to maintain.</p>



<h2>Modeling Software Entropy</h2>



<p>Given our observations, we can describe a simple rule:</p>



<p><code>complexity = number of total possible states</code></p>



<p>A construct with only a few possible states is simple. Booleans and enums are much simpler than strings. A system with one moving piece is much simpler than a system with many moving pieces.</p>



<p>Sometimes, our problems are essentially complex. In these cases, our solutions need some essential complexity to match. But when does essential complexity become unnecessary? In these cases, we can use another rule:</p>



<p><code>cleanliness = number of <strong>valid</strong> possible states / number of <strong>total</strong> possible states</code></p>



<p>If there are thousands of total possible states, but only two of them are valid: it’s a messy solution. A simple example of this is representing a boolean value as a string.</p>


<pre title="">if value == "true": do this
else if value == "false": do that
else: throw error
</pre>


<p>There are many ways for this code to go wrong; not just in execution but also in interpretation. Keeping our solutions clean improves correctness, readability, and maintainability. It’s one of the primary measures of “quality” in my view.</p>



<h2>Minimizing Software Entropy</h2>



<p>Given these definitions, we can ask ourselves some questions to guide our software decisions:</p>



<ol><li>How many possible states does this solution have?</li><li>How many of those states are invalid?</li><li>Is there any way to make the solution simpler, by trimming the number of <em>total</em> possible states?</li><li>Is there any way to make the solution cleaner, by trimming the number of <em>invalid</em> possible states?</li></ol>



<p>The power of this concept is that it smoothly scales up and down the ladder of abstraction. It applies to basic data types just as well as it does to solution architecture and product development.</p>



<p>How many moving pieces does our solution need? When an unimaginable requirement flies in and tries to blow our solution to the ground, how many pieces can be left standing? When an unexpected input arrives, do invalid states propagate across the system, or are they contained and eliminated on sight? In short, how clean is our solution?</p>



<p>To make life possible, we utilize chaos by creating complex systems that support a diversity of people and their use cases. To make life predictable, we combat undesirable chaos by keeping those systems as clean and orderly as possible.</p>



<p>In software, we work in a world where chaos is measurable and cleanliness is achievable. We just need the right set of signals and responses to make it happen.</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://camhashemi.com/2020/06/23/software-entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626253</guid>
            <pubDate>Wed, 24 Jun 2020 10:20:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making $32k/month building websites for churches]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23626159">thread link</a>) | @vinrob92
<br/>
June 24, 2020 | https://productizedstartups.com/making-32k-month-building-websites-for-churches/ | <a href="https://web.archive.org/web/*/https://productizedstartups.com/making-32k-month-building-websites-for-churches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1490">

	
<!-- .entry-header -->

	<div>

		<div>

			
<figure><img src="https://productizedstartups.com/wp-content/uploads/2020/06/Building-Websites-for-Churches-02-1.jpg" alt="" srcset="https://productizedstartups.com/wp-content/uploads/2020/06/Building-Websites-for-Churches-02-1.jpg 1024w, https://productizedstartups.com/wp-content/uploads/2020/06/Building-Websites-for-Churches-02-1-300x150.jpg 300w, https://productizedstartups.com/wp-content/uploads/2020/06/Building-Websites-for-Churches-02-1-768x384.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3><strong>1. Hello! Who are you and what is your business?</strong></h3>



<p>I’m Paul, I run a company called <a href="https://thechurchco.com/">The Church Co</a>. It’s a website builder for churches. The key difference being that, compared to other website builders out there (building your own), we build the websites for the church in 7 days and then hand it over for them to maintain. We think that maintaining a website and building a website are two different skill sets.&nbsp;</p>



<p>I got my degree in digital media in The Internet and Interactive Design back in 2007. Then I decided to go to Bible school. I moved to Sydney, Australia (where I went to Bible school) and ended up getting hired at a church there, going back and doing web design. During that process, I started learning about using my skills together and combining two of the passions that I had. I started The Church Co years later, which is ultimately the combination of both of those things.</p>



<p>I had some friends that worked at different churches and was able to reach out to them to trial it. We ran it for free for a year and a half before ever taking payments. We lost half of our customers the day we turned the payments on, and then just started building them back. It all grew word of mouth via happy customers and Facebook groups.</p>



<p>The Church Co makes <strong>$30k-32k a month</strong> in subscriptions. We have optional add-ons like custom themes, sermon and blog imports. If you need more than the 15 pages that will do for free in the build. There are one-time fees which accounts for around $3,000 a month in addition to the subscriptions.</p>



<p>Our pricing plans start at $20 for basic, $50 at premium, and ultimate for $199. The basic plan is simply everything you need for a standard website: web pages, blogs, sermons (which are podcast events systems). The premium plan has nice church features that we’ve added that are geared towards interaction with members that come to your church. One example is a sermon note-taker where the pastor can outline their sermon notes and you can follow along via your phone, add your own notes, and then compile and send them to yourself. We also have a small group locator, which shows small groups that meet in the community that are all part of your church. We’ve got options for live streams, chats, and online giving/donations through stripe.</p>



<p>These features are all niche-targeted features that make it easier to manage and get more interactions. From here, we incentivize people to upgrade as well. The ultimate plan has all the same features as premium, but we manage your content for you. You’ll basically never have to log into your website — just email us and tell us to do something for Christmas and we’ll spin up a page for you.</p>



<p>For expenses, we vary between like $9k-11k each month. This includes salaries, servers, intercom, etc. We pay contractors in addition to our full-time people (myself and one other individual) that we have to build other websites for the churches. This varies with how many people sign up and how many hours it takes them to build the sites.&nbsp;</p>



<p>Before COVID I would’ve considered a customer a day (totaling about 30 for the month) to be a great month. Then we started doing the same amount in a week when stay-at-home orders came to the point of gaining 100 new customers in a month — which was wild! We spend a lot of time on customer support and brought on a lot of contractors to kind of help get that done.&nbsp;</p>



<p>It was mind-blowing that there were so many fully functioning organizations that had never had websites. It was an unfortunate event that was bad for a lot of people, but it really pushed many into a digital space, which we were prepared for. In the last three months, we did the equivalent of how many sites we did all of last year, so it scaled quickly. And luckily the processes were all in place to make that happen.</p>



<h3><strong>2. How do you attract and retain your customers?</strong></h3>



<p>The main way we’ve grown is word of mouth, especially through really niche Facebook groups. My background from working in the communications role at a church helped me get involved in those groups, just to be a help to other people. I never spammed my product (nor did I ever have to). We haven’t invested money into any ads except maybe a few dollars for some Google ads and a few dollars for some retargeting Facebook ads.&nbsp;</p>



<p>As far as retaining customers, one of the beauties of websites is, you don’t change them that often. We work really hard to get you on your domain name, and once you’re on that, then you’re typically going to stay for 3+ years. We do a lot of work in the beginning stages to onboard people, build their site, and get them up through launching. What makes it different to most SaaS products is that you can see if someone stops logging in — that’s when they churn. But for us, that’s when they’re happy, and good to go. Really happy customers could log in once a week just to add a new event or upload a podcast from the weekend.&nbsp;</p>



<p>One of the reasons that we found why organizations churn is when they get a new volunteer that is familiar with another website builder. We ensure they stick around by separating the data from the design, which means you can change your theme at any time and it auto adjusts the layout.&nbsp;</p>



<p>We release new themes every year. The goal is that if you’ve been on the platform for 5 or so years, and want a new look, you can just browse our theme library, preview and activate without needing additional work.&nbsp;</p>



<p>This is the big focus: getting people onto the domain and then making sure we’re releasing new features. It’s helped with keeping customers.&nbsp;</p>



<h3><strong>3. What were your challenges and obstacles of growing your business?</strong></h3>



<p>When I started this company, I thought people would see the website and think that it’s much better than what they could build themselves. I realized that <strong>you’re not actually selling the final product — it’s the experience of making the product.</strong>&nbsp;</p>



<p>It was within the first 6 weeks with our first trial customer that I realized people were not going to build their own websites (or they’d take 6 months to do it, which was way too long of a sales cycle). I thought, <em>well, I built the system, I can do it pretty quick.</em> So we started offering our done-for-you website building, which was a game changer. It ran great for a while when we did it all for free (but requested payment for site launch).&nbsp;</p>



<p>Then we burned out a few times. So we started asking for credit card information first, as a commitment to do this, and we would build a website — which worked great until we got websites that requested 500 pages. That would take us a month to build, and there’s no way it was sustainable.&nbsp;</p>



<p>This was iterated down to the point we are today: we start building the website which is a free 15 pages, (about the average size of a church website). Making money was never the goal.&nbsp;</p>



<p>Before I had contractors I used to get up at 5am and go to a coffee shop, build three websites and go to my day job for 8 hours. Then I’d come home, have some family time and then, after everyone’s asleep, jump back on and build more websites. It wasn’t the most fun in that stage, and it continued that way until it scaled enough with revenue to hire people to do that for me. I think a lot of people quit when they hit that first wall, instead of thinking: <em>what’s the wildest solution to this (even if it’s not like a fun one)?</em>&nbsp;</p>



<p>We pivoted from my original idea, in that I thought people would build their own websites (which was not the case). Currently, I’m in the middle of a bit of a pivot as well, adding design to our service.</p>



<p>We’ve never been a design tool. We’re no code and we’re no design. Our ideal customer is a church that doesn’t have a creative staff member. and the value is on the content. We convert about 25% of trials into customers, which is pretty high; but the feedback we get from the other 75% are usually about design related things (i.e. they have a design in mind they wanted to implement). Part of the big push on version 2 is adding more design capabilities and flexibility for the people that want it.&nbsp;</p>



<p>There were a lot of assumptions I made around design in the initial version that looking back, I would have done a little bit more research: i.e. surveying a few people working in churches that weren’t my friends to see what they were struggling with and what they needed.&nbsp;</p>



<p>I would have also made strategic partnerships earlier (I was very anti-affiliates for a long time). I would see 10 people spamming affiliate links in the Facebook groups and would immediately be biased against the products because it needs affiliates to sell. While I don’t think we suffered from refusing to do affiliates, a lot of competitors did which kept paired them up with influencers in the space. We ended up caving and now have an affiliate plan.&nbsp;</p>



<p>Another challenge was letting go of control on intercom, but it needed to happen. It’s the only communication we have; there’s no phone line. Anyone who gets the role needs to be well vetted in communication skills and sales, the ability to convert someone that’s just browsing into a paying customer.&nbsp;</p>



<p>I was a bit too close to the product. I’m more prone to talk about specific technical things that customers would simply not understand. Handing the role off to someone else has made more sales and has overall been one of the best moves I’ve made.</p>



<h3><strong>4. What has been helpful to help you to grow your business?</strong></h3>



<p>The Indie Hackers community. I think having really ‘<em>switched-on’</em> people that are willing to give you constructive and honest feedback is really valuable. I suppose it’s a bit like having a life coach. It’s gotten us to where we are today.&nbsp;</p>



<p>When we added a chat to the dashboard, it helped drive sales (despite chat being the bane of my existence). You can’t log into any of the major competitors’ sites (that I know of), and live chat with a web developer to ask them questions. We do, and it was a tool that really …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://productizedstartups.com/making-32k-month-building-websites-for-churches/">https://productizedstartups.com/making-32k-month-building-websites-for-churches/</a></em></p>]]>
            </description>
            <link>https://productizedstartups.com/making-32k-month-building-websites-for-churches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626159</guid>
            <pubDate>Wed, 24 Jun 2020 10:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Empty Ubuntu to Live Reload: Haskell IHP Web Framework and Nix]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23625978">thread link</a>) | @_query
<br/>
June 24, 2020 | https://codygman.dev/posts/2020-06-24-Haskell-IHP-Web-Framework-and-Nix.html | <a href="https://web.archive.org/web/*/https://codygman.dev/posts/2020-06-24-Haskell-IHP-Web-Framework-and-Nix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I came across <a href="https://www.reddit.com/r/haskell/comments/hee4r4/ihp_is_a_modern_batteriesincluded_web_framework/">IHP is a modern batteries-included Web Framework, built on top of Haskell and Nix</a> today and being about web frameworks <em>and</em> nix it immediately caught my eye. I read the comments first, got mildly annoyed at the first comment being about “it’s nix only”, and kept scrolling until I saw a comment (you’ll see in the stream) that properly motivated me to actually read the link attached :D</p>
<p>I then resolved to stream playing around with this cool framework and also to do it from an ubuntu vm in virtualbox to show how seamless nix can make the setup (or can it?!?). Here’s a video of the stream in case you missed it:</p>
<center><iframe src="https://player.twitch.tv/?video=659859279&amp;parent=codygman.dev" frameborder="0" allowfullscreen="true" scrolling="no" height="378" width="620"></iframe></center>
<p>If this generates much interest, I’ll try doing a follow up soon where we get to the more complex pieces like adding custom Haskell packages (or even in Hackage or nixpkgs).</p>
    </section>
</article></div>]]>
            </description>
            <link>https://codygman.dev/posts/2020-06-24-Haskell-IHP-Web-Framework-and-Nix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625978</guid>
            <pubDate>Wed, 24 Jun 2020 09:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indexing Jsonb Columns in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23625883">thread link</a>) | @dijit
<br/>
June 24, 2020 | https://vsevolod.net/postgresql-jsonb-index/ | <a href="https://web.archive.org/web/*/https://vsevolod.net/postgresql-jsonb-index/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Since time immemorial PostgreSQL supports JSON fields and can even index
them. By immemorial I mean this functionality was added in versions 9.2 and 9.4
that are unsupported now. </p>
<p>I perfectly remember the world where PostgreSQL had no JSON support because 9.2
<a href="https://www.postgresql.org/docs/9.2/release-9-2.html">was released</a> in 2012,
and before that, I worked in a company that used MongoDB (we suffered
greatly<a href="https://vsevolod.net/postgresql-jsonb-index/#note1"><sup id="back1">[1]</sup></a>). It was an ample bit of marketing
for Mongo back then: "you can store any document without tediously defining an
ungodly schema! You gain so much flexibility!"</p>
<p>Little did we know back then that the world does not work that way, and
relational SQL databases are actually way more flexible than document-oriented
DBs, columnar DBs, or whatever.<a href="https://vsevolod.net/postgresql-jsonb-index/#note2"><sup id="back2">[2]</sup></a> Because
often we don't know what exactly are we going to do with the data, and with
relational DBs we can lay out the data however seems reasonable, and then add
indexes to support our use cases. </p>
<p>In document-oriented DBs you need to lay out your data exactly the way you're
going to query it later. Or else you'll need to migrate data inside your
schema-less database to another layout, which is way more cumbersome and
error-prone than adding some indexes and JOINs. </p>
<p>Don't trust me - there is an exceptional talk on <a href="https://www.youtube.com/watch?v=HaEPXoXVf2k">Advanced Design Patterns for
DynamoDB</a> by Rick Houlihan, a
Principal Technologist at AWS. He explains that and so much more - it's a very
information-dense presentation with interesting ideas. I found it useful even
though I don't plan to use DynamoDB nor MongoDB in the near future.</p>
<p>Anyway, JSON support was added into PostgreSQL a long time ago, because
sometimes it is useful to store some documents in the database. And it can be
indexed in <a href="https://www.postgresql.org/docs/current/datatype-json.html#JSON-INDEXING">two different
ways</a> -
full <abbr title="Generalized Inverted Index">GIN</abbr> and a special
<code>jsonb_path_ops</code> that supports indexing the <code>@&gt;</code> operator only. It means
"contains" and can be used like this:</p>
<pre><span>SELECT * FROM table WHERE jsonb_field @&gt; '{"employer": {"country": "ZA"}}';
</span></pre>
<p>Let me tell you a story about how I cleverly used this feature and it bit me in
the ass.</p>
<h2 id="story-time">Story time<a href="#story-time" aria-label="Anchor link for: story-time">🔗</a></h2>
<p>I am a co-founder at <a href="https://www.prophy.science/">www.prophy.science</a> which is
a product that can understand, search and recommend scientific papers and
experts. To do that well, we need a collection of all scientific papers, and
papers are often provided by many different providers with different ids. There
are <a href="https://www.ncbi.nlm.nih.gov/pubmed/">PubMed</a> (30M+ articles), <a href="https://www.ncbi.nlm.nih.gov/pmc/">PubMed
Central</a> (6M+ articles),
<a href="https://www.crossref.org/">Crossref</a> (80-100M+),
<a href="https://inspirehep.net/">INSPIRE</a>, there are preprint servers like
<a href="https://arxiv.org/">arXiv</a>, <a href="https://www.biorxiv.org/">biorXiv</a>,
<a href="https://www.medrxiv.org/">medRxiv</a> and many others.</p>
<p>There is a widespread system of <abbr title="Digital object
identifier">DOIs</abbr> that are used to persistently identify journal articles,
research reports and data sets. It was introduced in the year 2000, and, as many
of these bibliographic databases predate DOI standard, they have their own
identifiers. Sometimes they even cross-link their IDs between different
services, and sometimes they cross-link wrong articles.</p>
<p>Some monitoring services download data from Crossref, Pubmed, PMC and some other
sources, add them and report that they have 180 million articles, 220 million,
or some other bullshit. We strive to merge the same article from different
sources into one entity with many external identifiers. We called these
identifiers "origin ids" and stored them in a special <code>jsonb</code> column, so one row
could have a record like this:</p>
<pre><span>{"pubmed": "3782696", "pmc": "24093010", "doi": "10.3389/fnhum.2013.00489"}
</span></pre>
<p>It was a simple key-value document with a <code>jsonb_path_ops</code> index on it. And
whenever we needed to fetch an article by an origin id, we queried it using a
<code>@&gt;</code> operator like that:</p>
<pre><span>SELECT id FROM articles WHERE origin_ids @&gt; '{"pubmed": "123456"}';
</span></pre>
<p>It is a bit easier to store ids this way, no need to maintain a separate table
with hundreds of millions of rows.</p>
<p>One problem arose when we tried to query the index with many different origin
ids. There is no <code>IN</code> nor <code>ANY()</code>, so we stitched lots of <code>OR</code>s together:</p>
<pre><span>SELECT id FROM articles WHERE 
    origin_ids @&gt; '{"pubmed": "123456"}' OR 
    origin_ids @&gt; '{"pubmed": "654321"}' OR 
    origin_ids @&gt; '{"pubmed": "123321"}' OR 
    origin_ids @&gt; '{"pubmed": "456654"}';
</span></pre><h2 id="explain-everything">Explain everything<a href="#explain-everything" aria-label="Anchor link for: explain-everything">🔗</a></h2>
<p>And with enough <code>OR</code>s the query gets really slow. Why? <code>EXPLAIN</code> helpfully says
that it becomes a sequential scan (I shortened output for clarity):</p>
<pre><span>EXPLAIN
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}' OR
        origin_ids @&gt; '{"pubmed": "654321"}' OR
        ....;   - x200
                        QUERY PLAN
------------------------------------------------------------
 Seq Scan on articles  (rows=7805036)
   Filter: ((origin_ids @&gt; '{"pubmed": "123456"}') OR
            (origin_ids @&gt; '{"pubmed": "654321"}') OR   ...x200)
</span></pre>
<p>Why? For some reason it thinks that this query will return millions of rows. But
one origin id can match at most one article if my data is correct, so 200
filters should only match 0..200 rows. Let's look at <code>EXPLAIN ANALYZE</code> to check:</p>
<pre><span>EXPLAIN ANALYZE
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}' OR
        origin_ids @&gt; '{"pubmed": "654321"}' OR
        ....;   - x200
                        QUERY PLAN
------------------------------------------------------------
 Seq Scan on articles  (rows=7805036) (actual rows=200)
   Filter: ((origin_ids @&gt; '{"pubmed": "123456"}') OR
            (origin_ids @&gt; '{"pubmed": "654321"}') OR   ...x200)
</span></pre>
<p>It does indeed return only 200 rows. Hmmm... Let's check one row:</p>
<pre><span>EXPLAIN ANALYZE
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}';
                        QUERY PLAN
------------------------------------------------------------
 Bitmap Heap Scan on articles  (rows=43038) (actual rows=1)
   Recheck Cond: (origin_ids @&gt; '{"pubmed": "123456"}')
    -&gt;  Bitmap Index Scan on  ... (rows=43038) (actual rows=1)
         Index Cond: (origin_ids @&gt; '{"pubmed": "123456"}')
</span></pre>
<p>Supposedly 43 thousand rows for only one filter! And 7.8 million rows are 39
thousand times more than 200, which is pretty close. At the time I fired these
queries we had only 43 million of articles. PostgreSQL <a href="https://www.postgresql.org/docs/current/planner-stats.html">gathers some
statistics</a> about
values in different columns to be able to produce reasonable query plans, and
looks like it's shooting blanks for this column.</p>
<p>What's the simplest fix? Oftentimes
<a href="https://www.postgresql.org/docs/current/sql-analyze.html"><code>ANALYZE</code></a> on a table
is enough to fix broken statistics, but this time it didn't help at
all. Sometimes it's useful to adjust how many rows are analyzed to gather
statistics, and it can be adjusted down to a per-column basis with <a href="https://www.postgresql.org/docs/current/sql-altertable.html"><code>ALTER TABLE ... ALTER COLUMN ... SET STATISTICS</code></a>, but
here it had no effect as well.</p>
<p>Since version 10 PostgreSQL supports <a href="https://www.postgresql.org/docs/current/sql-createstatistics.html"><code>CREATE STATISTICS</code></a>
to gather complex statistics for inter-column dependencies and whatnot, but our
filter is single-column, no luck here as well.</p>
<h2 id="contsel">Contsel<a href="#contsel" aria-label="Anchor link for: contsel">🔗</a></h2>
<p>So I dug some more, and more... And found that operator <code>@&gt;</code> uses something
called <code>contsel</code>. It was mentioned in <a href="https://www.postgresql.org/message-id/23452.1288288224@sss.pgh.pa.us">PostgreSQL mailing
list</a>
in 2010. I tried to decrypt what <code>contsel</code> means and I think it stands for
"contains selectivity". Then I tried searching PostgreSQL sources for <a href="https://github.com/postgres/postgres/search?q=contsel&amp;unscoped_q=contsel"><code>contsel</code>
mentions</a>
and found exactly <a href="https://github.com/postgres/postgres/blob/master/src/backend/utils/adt/geo_selfuncs.c#L80">one
place</a>
in C code which mentions it:</p>
<pre><span>Datum
contsel(PG_FUNCTION_ARGS)
{
	PG_RETURN_FLOAT8(0.001);
}
</span></pre>
<p>0.001? That looks exactly like the ratio between 43 million rows in the table
and an estimated 43 thousand rows in the result. However, if we just multiply 43
thousand by 200 filters we should get 8.6 million, and PostgreSQL estimated only
7.8M. This discrepancy bothered me for a minute because I like to understand
things completely, so they won't set me up for an unpleasant surprise later<a href="https://vsevolod.net/postgresql-jsonb-index/#note3"><sup id="back3">[3]</sup></a>.</p>
<p>After a minute of contemplating the difference I realized that it's probability
in play - PostgreSQL thinks that every filter can match 0.1% of the total number
of rows and they can overlap. The actual math is:</p>
<pre><span>1 - 0.999 ** 200 = 1 - 0.819 = 0.181
</span></pre>
<p>18.1% of 43 million is 7.8 million (I'm rounding numbers here). Itch scratched
successfully.</p>
<p>And, depending on the <a href="https://www.postgresql.org/docs/current/runtime-config-query.html#RUNTIME-CONFIG-QUERY-CONSTANTS">different
costs</a>
of various factors in the config, Postgres will select either sequential scan or
will use an index. Our first solution was to slice these filters into batches
with no more than 150 of them per query. It worked quite well for a couple of
years.</p>
<h2 id="domain-modeling-failure">Domain modeling failure<a href="#domain-modeling-failure" aria-label="Anchor link for: domain-modeling-failure">🔗</a></h2>
<p>Until we learned that one article could have more than one such external
identifier per type. For example, some pre-print services grant new DOI for each
version. <a href="https://dx.doi.org/10.26434/chemrxiv.11938173.v8">10.26434/chemrxiv.11938173.v8</a>
has eight of them at the time of writing. And then it has the main DOI without
version
<a href="https://dx.doi.org/10.26434/chemrxiv.11938173">10.26434/chemrxiv.11938173</a>, and
will have another one if it will be published after peer review. There are other
cases for some other identifier types (we call these types "origin name").</p>
<p>We had two options:</p>
<ul>
<li>
<p>Store origin ids in a separate table with columns <code>article_id</code>, <code>origin_name</code>
and <code>origin_id</code> with two indexes - one on <code>article_id</code> and the other on
<code>(origin_name, origin_id)</code>;</p>
</li>
<li>
<p>Accommodate many values per key in <code>jsonb</code>. Two more possible options here:</p>
<ul>
<li>Many values per key: <code>{"doi": ["10.26434/3", "10.26434/3.v1"]}</code></li>
<li>List of pairs: <code>[["doi", "10.26434/3"], ["doi", "10.26434/3.v1"]]</code></li>
</ul>
<p>Both can be queried with <code>@&gt;</code>, but it's getting even more uglier than it was.</p>
</li>
</ul>
<p>We ended up doing kind of both - we created a separate table that's much easier
to query with many origin ids at once, and we store a list of pairs in a
separate non-indexed column so it's convenient to query.</p>
<h2 id="separate-table-speed-up">Separate table speed-up<a href="#separate-table-speed-up" aria-label="Anchor link for: separate-table-speed-up">🔗</a></h2>
<p>As a bonus, it's much-much faster to query a btree index with lots of filters
than a GIN one. With a GIN every <code>@&gt;</code> turns into a separate Bitmap Index Scan
that costs approximately millisecond for each (0.7-1.2 ms each if in
cache). With a btree index on two columns we construct a query that looks like
this:</p>
<pre><span>SELECT article_id FROM articles_origin_ids WHERE
    (origin_name = $1 AND origin_id = ANY($2)) OR
    (origin_name = $3 AND origin_id = ANY($4)) OR
    (origin_name = $5 AND origin_id = ANY($6));
</span></pre>
<p>Accessing a btree index is faster even by itself, I get 0.07 ms for Bitmap Index
Scan node in <code>EXPLAIN ANALYZE</code> for one <code>origin_name</code>, <code>origin_id</code> pair. …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vsevolod.net/postgresql-jsonb-index/">https://vsevolod.net/postgresql-jsonb-index/</a></em></p>]]>
            </description>
            <link>https://vsevolod.net/postgresql-jsonb-index/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625883</guid>
            <pubDate>Wed, 24 Jun 2020 09:26:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Techniques to regain control of your Legacy codebase]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23625819">thread link</a>) | @a7b3fa
<br/>
June 24, 2020 | https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>🇫🇷 Si tu souhaites lire cet article en français, je l’ai écris à l’origine <a href="https://www.jesuisundev.com/7-techniques-pour-reprendre-le-controle-de-ton-legacy-code/">en tant qu’article invité sur jesuisundev.com</a>.</em></p><p>Let’s face it: we spend most of our time changing existing code. Usually, we didn’t even write that code in the first place. Often, there’s no test. Sometimes, the authors of the code are long gone! And yet, we have to understand and modify this code – without introducing any bug, thank you.</p><p>You’d love to change any part of the code with confidence… but you never have time! This change has been estimated as a 2-day task and there are many others to ship before the end of the Sprint/demo to the client/delivery/<em>&lt;insert your deadline here<!-- -->&gt;</em>. Nightmare!</p><p>But what if you had a secret weapon? Techniques to approach this Legacy efficiently, reach your goal without getting distracting with all the Technical Debt? You could regain control of this project and make it easier to maintain, each iteration!</p><p>Working on Legacy Code is indeed no fun… but it could be.</p><p>Here are 7 concrete techniques that will help you regain control of your Legacy.</p><h2 id="1-the-brain-dump-🧠"><a href="#1-the-brain-dump-%F0%9F%A7%A0" aria-label="1 the brain dump 🧠 permalink"></a>1. The Brain Dump 🧠</h2><p>Your brain is not optimized to memorize a lot of things. You can only juggle with a limited number of thoughts.</p><p>The problem is: your Legacy is a jungle. It’s full of badly named variables, non-standard structures, useless indirections, bad abstractions… To reach your goal, you need to go through a lot of traps you can’t anticipate. When you move something, you reveal 3 more issues that were hidden behind!</p><p>If you try to juggle with all of these things in your head, you’ll get lost.</p><p>It’s the “I’m almost done on this ticket” effect. You have been repeating that for the past 3 days during stand-up. This usually ends up with Pull Requests that are too long and contain many more changes than expected.</p><p>You need to get these ideas out to not getting lost. The easiest way to do that is <strong>a sheet of paper</strong>.</p><p>Take a sheet and a pencil. Start by dumbing everything you want to do on this code. Write down a TODO list.</p><p>Then, choose a first task and start doing it.</p><p>As you move on this task, you’ll have new ideas. New tasks that you discover. Refactors you want to do. When it happens, don’t do them: <strong>write them down!</strong></p><p><undefined>
  <a href="https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/6ed10/brain-dump.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="brain dump" title="" src="https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/799d3/brain-dump.png" srcset="https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/00d96/brain-dump.png 148w,https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/0b23c/brain-dump.png 295w,https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/799d3/brain-dump.png 590w,https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/2a3d6/brain-dump.png 885w,https://understandlegacycode.com/static/1ca540bf66618f065082a0318a734da6/6ed10/brain-dump.png 900w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Writing them down on your piece of paper has 2 main benefits:</p><ol><li><strong>You calm your mind.</strong> It knows information is out of your head and you won’t forget it. Thus, you’ll stop rehashing this idea every 5 minutes and you can focus on the ongoing task!</li><li><strong>You’ll avoid the tunnel effect.</strong> You’ll end what you started before you start something else. You’ll cross off the task that is done, commit, and take a break! You’ll have a clearer vision of your progress instead of a vague feeling of “almost done”.</li></ol><p>If you know <a href="https://gettingthingsdone.com/">the GTD method</a>, this will feel familiar.</p><h2 id="2-the-mikado-method-🥢"><a href="#2-the-mikado-method-%F0%9F%A5%A2" aria-label="2 the mikado method 🥢 permalink"></a>2. The Mikado Method 🥢</h2><p>The Mikado Method is a similar concept than the Brain Dump, but with more structure. It’s perfect when you want to reach a particular goal and you don’t know what will get in your way.</p><p>Here again, you just need a sheet and a pencil.</p><p>Start writing down your main goal. Circle it twice. Then, try to achieve it.</p><p>If you realize you need something else to do this task, do these 2 very important things:</p><ol><li>Cancel your pending changes (<code>git reset --hard</code>)</li><li>Write down the subtask you need to do and link it to the main task.</li></ol><p>Then, start over from the subtask. Iterate if you realize you miss something again.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/5d675/mikado.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="mikado" title="" src="https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/799d3/mikado.png" srcset="https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/00d96/mikado.png 148w,https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/0b23c/mikado.png 295w,https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/799d3/mikado.png 590w,https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/2a3d6/mikado.png 885w,https://understandlegacycode.com/static/3b727308693fc6ab11943c10c646142a/5d675/mikado.png 1000w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>At some point, the subtask will be so small that you’ll be able to do it without trouble. Great! Commit that, cross off that task, and celebrate internally!</p><p>Then, take another subtask and continue. As you achieve subtasks, you make the main one easier. At some point, doing it will be really easy!</p><p>Just like the Brain Dump, you’ll feel less stressed and you’ll have a better view of your progress. You’ll be able to push intermediate Pull Requests that will progressively make the main goal easier to achieve.</p><p>If you want to learn more, I’ve dedicated <a href="https://understandlegacycode.com/blog/a-process-to-do-safe-changes-in-a-complex-codebase">a full post on this</a> and <a href="https://www.manning.com/books/the-mikado-method">there’s a book on that</a>.</p><h2 id="3-over-committing-"><a href="#3-over-committing-" aria-label="3 over committing  permalink"></a>3. Over-committing ➿</h2><p>When you work on Legacy Code, it’s very easy to get stuck in a position where nothing works anymore and you don’t really know why.</p><p>In this context, I recommend taking a safer approach.</p><p>I mean, if only you had a way to have checkpoints for every single step you take in the right direction! With this, you won’t have to start over again if you do one or two wrong moves. You could just go back to the last checkpoint!</p><p>Well, this is <em>exactly</em> where your version control system excels. Create checkpoints.</p><p>My advice: when you work on Legacy Code, commit very very very often. You should commit more often than you imagine. Here are 2 options:</p><ol><li><strong>Commit every 5 minutes.</strong> That’s easy to do, you only need a timer. Each time it rings, commit and run the timer again.</li><li><strong>If you practice the Mikado Method, commit every subtask you achieve.</strong> The technique is optimized to make you do small changes, therefore it’s perfect for frequent commits.</li></ol><p><undefined>
  <a href="https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/3c21b/overcommit.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="overcommit" title="" src="https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/799d3/overcommit.png" srcset="https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/00d96/overcommit.png 148w,https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/0b23c/overcommit.png 295w,https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/799d3/overcommit.png 590w,https://understandlegacycode.com/static/268aa13a160fdfe7f8172d8b9e7b9969/3c21b/overcommit.png 777w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>It’s OK if your commit messages are messy or duplicated. You can (should) edit them before you push on the shared repository. I frequently create commits that I squash later. Having too many commits will help you more than not having enough.</p><p>Practice this technique and you’ll see the quality of your Pull Requests raise up after a few weeks. But most of all, you’ll have your checkpoints!</p><h2 id="4-adrs-"><a href="#4-adrs-" aria-label="4 adrs  permalink"></a>4. ADRs 📝</h2><p>Sometimes, you’ll hit a very annoying obstacle: lack of context.</p><p>It’s terrible when you don’t know why something is written that way. It makes you face a dilemma: keep the code as it is and work around, or change it and take the risk of breaking something unexpected. At best, this will just take longer to solve. Tracing back to the original decision behind the code you have in front of you feels like archaeology, and it’s not easy!</p><p>Unfortunately, I don’t have a magic spell to generate missing documentation for you. But I still have a technique that will stop your code from bleeding so hard. Here’s an advice that’s more pragmatic than “just write the doc”.</p><p>Meet <strong>Architecture Decision Records</strong> (ADRs).</p><p>Here’s the concept: each time you make a non-trivial decision, write a note about it. The good news is that you don’t really have to maintain this note. It captures the “why” behind your decision like a snapshot. Your future self will thank you for taking 5 extra minutes to write this down!</p><p>Here’s what it looks like:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/74b92/adrs.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="adrs" title="" src="https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/799d3/adrs.png" srcset="https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/00d96/adrs.png 148w,https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/0b23c/adrs.png 295w,https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/799d3/adrs.png 590w,https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/2a3d6/adrs.png 885w,https://understandlegacycode.com/static/2ffc68d37c322bf50a6b1b3c1f3b6248/74b92/adrs.png 945w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>The structure is simple:</p><ol><li>The title that recaps the decision you’re taking</li><li>The date</li><li>Context around this decision. Explain why you’re going this way instead of another. Describe your constraints, what you know, how things work today, etc. Everything that motivates this decision.</li><li>The decision itself</li><li>Consequences of this decision, good and bad. Maybe this comes with compromise, document them!</li></ol><p>Keep ADRs versioned along with the code. It’s simple, easy to find, and to search when you’re looking for a particular decision.</p><p>Make a habit to write these ADRs. It’s a little investment that quickly pays off. From my experience, that also helps the reviewer of the Pull Request!</p><p>Finally, I’d recommend you use <a href="https://github.com/npryce/adr-tools">the adr-tools CLI</a>. It makes all of this so easy that you won’t have any excuse not to write them.</p><p>If you want to learn more about ADRs, <a href="https://understandlegacycode.com/blog/earn-maintainers-esteem-with-adrs">I wrote a detailed post on this topic</a> too.</p><h2 id="5-approval-testing-"><a href="#5-approval-testing-" aria-label="5 approval testing  permalink"></a>5. Approval Testing ✅</h2><p>This technique feels like a secret weapon.</p><p>This is the fastest way I know to write tests on existing code, so you can refactor it safely.</p><p>You may know it under a different name: Characterization Tests, Golden Master, or Snapshot Tests.</p><p>It comes in 3 main steps:</p><ol><li>📸 Generate an output you can snapshot</li><li>✅ Use test coverage to find all input combinations</li><li>👽 Use mutations to verify your snapshots</li></ol><h3 id="1--generate-an-output-you-can-snapshot"><a href="#1--generate-an-output-you-can-snapshot" aria-label="1  generate an output you can snapshot permalink"></a>1. 📸 Generate an output you can snapshot</h3><p>The first step is also the most complex. Generate a text you can write in some file: this will be your snapshot.</p><p>If the code you’re testing returns a value, you already have it. Otherwise, you’ll likely need to intercept calls made in your code to log the parameters that are given… A different approach is to introduce logs in your code.</p><p>Here’s an example using the Jest library, in JavaScript:</p><pre data-language="js"><code><span><span>it</span><span>(</span><span>"should update quality"</span><span>, () </span><span>=&gt;</span><span> {</span></span>
<span><span>  </span><span>expect</span><span>(</span><span>updateQuality</span><span>(</span><span>"foo"</span><span>, </span><span>0</span><span>, </span><span>0</span><span>)).</span><span>toMatchSnapshot</span><span>()</span></span>
<span><span>})</span></span></code></pre><p>The first time you run the test, it passes and stores the result in a file. Then, it compares the result of further runs with the one that was stored. If it’s different, the test will fail. The idea is to detect if anything changed!</p><h3 id="2--use-test-coverage-to-find-all-input-combinations"><a href="#2--use-test-coverage-to-find-all-input-combinations" aria-label="2  use test coverage to find all input combinations permalink"></a>2. ✅ Use test coverage to find all input combinations</h3><p>Once you have your first snapshot, you have 1 scenario covered. There is certainly much more you need to find out before you can feel confident changing your code.</p><p>This is where test coverage is a very useful tool. It tells you which code is not tested!</p><p>Here’s an example:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/5d675/gilded-rose.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="gilded rose" title="" src="https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/799d3/gilded-rose.png" srcset="https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/00d96/gilded-rose.png 148w,https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/0b23c/gilded-rose.png 295w,https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/799d3/gilded-rose.png 590w,https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/2a3d6/gilded-rose.png 885w,https://understandlegacycode.com/static/031e5ae187cbdecc3aa7a648e5095867/5d675/gilded-rose.png 1000w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Red lines are the ones that are not covered. Your goal is to have no red line. Change all inputs you can so you cover as many scenarios as possible!</p><h3 id="3--use-mutations-to-verify-your-snapshots"><a href="#3--use-mutations-to-verify-your-snapshots" aria-label="3  use mutations to verify your snapshots permalink"></a>3. 👽 Use mutations to verify your snapshots</h3><p>Once you’ve covered everything with tests, there’s one last thing to check: that you’re actually covering the code.</p><p>This is the limit of test coverage: it doesn’t prove the quality of your tests. You can have 100% test coverage without testing much. This is why I never set a % of test coverage as a metric. It’s a useful tool, but it can’t be an objective.</p><p>How do you quickly verify the quality of your tests? By introducing “mutations”. Concretely, this means you should introduce bugs in the source code deliberately, so you can check a test is failing.</p><p>My preferred way of doing so is to comment code. Comment a line of code, then run the tests:</p><ul><li>If they fail, you can rejoice to know that you have a safety net if you introduce a bug here.</li><li>If they pass, you need to find the combination of the missing inputs that will cover this scenario.</li></ul><h3 id="why-does-it-work"><a href="#why-does-it-work" aria-label="why does it work permalink"></a>Why does it work?</h3><p>When you’re done, you can restructure your code safely. If you do a mistake, you’ll know …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/">https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/</a></em></p>]]>
            </description>
            <link>https://understandlegacycode.com/blog/7-techniques-to-regain-control-of-legacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625819</guid>
            <pubDate>Wed, 24 Jun 2020 09:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improving API Performance with Telnet]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23625795">thread link</a>) | @tosh
<br/>
June 24, 2020 | https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html | <a href="https://web.archive.org/web/*/https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><header><img src="https://blog.teller.io/images/authors/stevegraham.jpg"></header><p>As you may or may not know, banks do not generally provide third party developers with API access. This is because providing developers with easy API access to customer accounts means actual competition and ultimately compressed margins. In fairness to banks, building a new API channel costs a lot of money and if all it does is increase competitive pressure why would you spend any time or money on it? It's a rational response given their incentives.</p>

<p>Despite this people still want to connect their bank accounts to services they trust, and companies still want to build those services.</p>

<p>So, where does this leave us? Thankfully the market has stepped in to provide solutions that enable us all to connect trusted apps with our financial accounts, despite this banks still actively block third party access by blocking their traffic.</p>

<h2 id="all-ip-addresses-are-not-created-equal">All IP addresses are not created equal</h2>

<p>The way we have solved this is to route our financial institution traffic onto the public internet via mobile phone carrier networks.</p>

<p>The great thing about carrier IP ranges is that carriers have significantly more customers than they have IP addresses, meaning public internet breakout is heavily <a href="https://en.wikipedia.org/wiki/Network_address_translation">NAT</a>-ed, i.e. a single address is shared and used by many customers simultaneously. The other great thing is there is good chance you're on mobile data when you use your bank's mobile app and your IP address is in the carrier’s IP range.</p>

<p>By sending our traffic onto the internet using the same IP addresses shared by millions of a bank’s own customers using the bank’s mobile app, we both make it significantly more difficult to identify and subsequently block our traffic and we also increase the collateral damage of any hostile action a bank might take against us and our users, i.e. erroneously blocking their own customers using their mobile banking app.</p>

<svg width="405px" height="279px" viewBox="0 0 405 279" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 52.6 (67491) - http://www.bohemiancoding.com/sketch -->
    <title>Untitled 4</title>
    <desc>Created with Sketch.</desc>
    <defs>
        <linearGradient x1="50%" y1="0%" x2="50%" y2="100%" id="linearGradient-1">
            <stop stop-color="#FBFBFB" offset="0%"></stop>
            <stop stop-color="#FFFFFF" offset="100%"></stop>
        </linearGradient>
        <rect id="path-2" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-3">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <rect id="path-4" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-5">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <linearGradient x1="50%" y1="2.30762283%" x2="50%" y2="100%" id="linearGradient-6">
            <stop stop-color="#F4F4F4" offset="0%"></stop>
            <stop stop-color="#FFFFFF" offset="100%"></stop>
        </linearGradient>
        <rect id="path-7" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-8">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <rect id="path-9" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-10">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
    </defs>
    <g id="Page-2" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Direct" transform="translate(3.000000, 2.000000)">
            <g id="Teller">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-3)" xlink:href="#path-2"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-2"></use>
                </g>
                <g id="logo-icon" transform="translate(19.462069, 19.931034)">
                    <path d="M14.8827586,31.6551724 L32.6275862,42.3854528 C29.5320561,44.1410729 25.9869012,45.137931 22.2194476,45.137931 C19.6460127,45.137931 17.1762988,44.6728122 14.8827586,43.8184589 L14.8827586,31.6551724 Z" id="Path" fill="#7985F2"></path>
                    <path d="M0,25.873964 L10.8758621,20.5172414 L10.8758621,42.2068966 C5.10335134,38.7926982 0.978977218,32.8443874 0,25.873964 Z" id="Path" fill="#F279D2"></path>
                    <path d="M0,21.6896552 C0.271210478,15.10675 3.30641844,9.24809514 7.95952004,5.27586207 L18.8896552,11.6748484 L11.488822,16.0076248 L0,21.6896552 Z" id="Path" fill="#F27979"></path>
                    <path d="M21.7854166,0 C24.5975441,0 27.2879935,0.532858373 29.7655172,1.5052445 L29.7655172,14.0689655 L10.8758621,2.91406436 C14.1003847,1.05844846 17.8220523,0 21.7854166,0 Z" id="Path" fill="#FFD780"></path>
                    <path d="M43.5034483,19.4519397 L33.2,25.2068966 L33.2,3.51724138 C38.6814991,6.95475181 42.5720341,12.7258567 43.5034483,19.4519397 Z" id="Path" fill="#91E673"></path>
                    <path d="M44.0758621,24.0344828 C43.7596445,30.6495208 40.6674041,36.5184923 35.9655559,40.4482759 L25.7586207,34.4203712 L44.0758621,24.0344828 Z" id="Path" fill="#79DEF2"></path>
                </g>
            </g>
            <g id="Bank" transform="translate(316.000000, 1.000000)">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-5)" xlink:href="#path-4"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-4"></use>
                </g>
                <text id="🏦" font-family="AppleColorEmoji, Apple Color Emoji" font-size="42" font-weight="normal" fill="#616161">
                    <tspan x="21" y="56">🏦</tspan>
                </text>
            </g>
            <path d="M84.5,43.4482759 L310,43.4482759" id="Line" stroke="#DC6F6F" stroke-width="3" stroke-linecap="square"></path>
            <polygon id="Triangle" fill="#DC6F6F" transform="translate(307.000000, 43.000000) rotate(-270.000000) translate(-307.000000, -43.000000) " points="307 35 315 51 299 51"></polygon>
            <text id="😤" font-family="AppleColorEmoji, Apple Color Emoji" font-size="30" font-weight="normal" fill="#616161">
                <tspan x="306" y="92">😤</tspan>
            </text>
            <path d="M183,57.9974594 C182.925417,57.9991501 182.850628,58 182.775641,58 C177.376704,58 173,53.5942914 173,48.1595745 C173,42.7248575 177.376704,38.3191489 182.775641,38.3191489 C182.918809,38.3191489 183.061258,38.322247 183.202926,38.3283802 C183.803357,28.6569802 191.785809,21 201.544872,21 C208.207767,21 214.042526,24.5691708 217.265242,29.9117828 C218.12594,29.7462314 219.014455,29.6595745 219.923077,29.6595745 C227.697547,29.6595745 234,36.0037948 234,43.8297872 C234,51.6557796 227.697547,58 219.923077,58 C219.270736,58 218.628759,57.9553331 218,57.8688719 L218,58 L183,58 L183,57.9974594 Z" id="Cloud" stroke="#979797" stroke-width="3" fill="url(#linearGradient-6)"></path>
            <text id="Cloud-traffic-is-eas" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="38.278" y="117.551724">Cloud traffic is easily detectable and trivial to block</tspan>
            </text>
        </g>
        <g id="Telnet" transform="translate(3.000000, 158.000000)">
            <g id="Teller">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-8)" xlink:href="#path-7"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-7"></use>
                </g>
                <g id="logo-icon" transform="translate(19.462069, 19.931034)">
                    <path d="M14.8827586,31.6551724 L32.6275862,42.3854528 C29.5320561,44.1410729 25.9869012,45.137931 22.2194476,45.137931 C19.6460127,45.137931 17.1762988,44.6728122 14.8827586,43.8184589 L14.8827586,31.6551724 Z" id="Path" fill="#7985F2"></path>
                    <path d="M0,25.873964 L10.8758621,20.5172414 L10.8758621,42.2068966 C5.10335134,38.7926982 0.978977218,32.8443874 0,25.873964 Z" id="Path" fill="#F279D2"></path>
                    <path d="M0,21.6896552 C0.271210478,15.10675 3.30641844,9.24809514 7.95952004,5.27586207 L18.8896552,11.6748484 L11.488822,16.0076248 L0,21.6896552 Z" id="Path" fill="#F27979"></path>
                    <path d="M21.7854166,0 C24.5975441,0 27.2879935,0.532858373 29.7655172,1.5052445 L29.7655172,14.0689655 L10.8758621,2.91406436 C14.1003847,1.05844846 17.8220523,0 21.7854166,0 Z" id="Path" fill="#FFD780"></path>
                    <path d="M43.5034483,19.4519397 L33.2,25.2068966 L33.2,3.51724138 C38.6814991,6.95475181 42.5720341,12.7258567 43.5034483,19.4519397 Z" id="Path" fill="#91E673"></path>
                    <path d="M44.0758621,24.0344828 C43.7596445,30.6495208 40.6674041,36.5184923 35.9655559,40.4482759 L25.7586207,34.4203712 L44.0758621,24.0344828 Z" id="Path" fill="#79DEF2"></path>
                </g>
            </g>
            <g id="Bank" transform="translate(316.000000, 1.000000)">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-10)" xlink:href="#path-9"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-9"></use>
                </g>
                <text id="🏦" font-family="AppleColorEmoji, Apple Color Emoji" font-size="42" font-weight="normal" fill="#616161">
                    <tspan x="21" y="56">🏦</tspan>
                </text>
            </g>
            <path d="M84.5,43.4482759 L310,43.4482759" id="Line" stroke="#9EDC6F" stroke-width="3" fill="#9EDC6F" stroke-linecap="square"></path>
            <polygon id="Triangle" fill="#9EDC6F" transform="translate(307.000000, 43.000000) rotate(-270.000000) translate(-307.000000, -43.000000) " points="307 35 315 51 299 51"></polygon>
            <text id="📱" font-family="AppleColorEmoji, Apple Color Emoji" font-size="45" font-weight="normal" fill="#616161">
                <tspan x="178" y="61">📱</tspan>
            </text>
            <text id="😌" font-family="AppleColorEmoji, Apple Color Emoji" font-size="30" font-weight="normal" fill="#616161">
                <tspan x="306" y="92">😌</tspan>
            </text>
            <text id="Traffic-routed-via-c" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="5.728" y="117.551724">Traffic routed via carrier networks passes through undetected</tspan>
            </text>
        </g>
    </g>
</svg>

<p>Until recently we used a third party provider for mobile carrier network transit, but suddenly without warning their performance and availabilty degraded to unacceptable levels. Requests occasionally took 20-30 seconds to complete. A single Teller API transaction might actually involve several requests to the financial institution, and even if we can parallelize some of these it's a disaster for us if any of them take 30 seconds.</p>

<p>Teller provides live access to financial accounts. <strong>When you request an account balance, Teller synchronously fetches that data live from the financial institition and returns it to you</strong>. Fast and reliable network access is an absolute must in order for us to provide that level of access. Other providers can get away with lesser network performance because they don't actually ever return live data in an API call. They periodically poll the institution a couple of times a day, and give you the most recent data they have when you make your API call.</p>

<p>We immediately began to design and build an in house solution to solve this problem once and for all.</p>

<h2 id="introducing-telnet">Introducing Telnet</h2>

<p>Telnet is our propietary mobile carrier proxy network. The name is a portmanteau of Teller Network, but if we're honest it began as an internal joke as it's built on top of <a href="https://en.wikipedia.org/wiki/Secure_Shell">SSH</a>, the remote access protocol that obsoleted the original <a href="https://en.wikipedia.org/wiki/Telnet">Telnet</a>.</p>

<p>Telnet is composed of a large number of edge nodes, which are single board Linux computers with LTE modems attached running our own software written using <a href="https://www.nerves-project.org/">Nerves</a>. When nodes boot they reverse SSH into our network and register themselves as available to route API traffic. Our infrastructure then routes our financial institution traffic via our Telnet edge nodes, egressing onto the internet on carrier IP ranges.</p>

<svg width="362px" height="360px" viewBox="0 0 362 360" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 52.6 (67491) - http://www.bohemiancoding.com/sketch -->
    <title>Graph</title>
    <desc>Created with Sketch.</desc>
    <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Graph" transform="translate(1.000000, -3.000000)">
            <g id="Vendor" transform="translate(16.000000, 39.000000)">
                <text id="Vendor-A" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="21" y="323">Vendor A</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="300"></rect>
            </g>
            <g id="Telnet" transform="translate(129.000000, 312.000000)">
                <text font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="32" y="50">Telnet</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="27"></rect>
            </g>
            <g id="Direct" transform="translate(242.000000, 327.000000)">
                <text font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="32" y="35">Direct</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="12"></rect>
            </g>
            <g id="Axes" transform="translate(0.000000, 36.000000)" stroke="#979797" stroke-linecap="square" stroke-width="3">
                <path d="M0.5,0.5 L0.5,302.5" id="Line"></path>
                <path d="M0.5,302.5 L359.100943,302.5" id="Line-2"></path>
            </g>
            <text id="Request-latency" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="130.065" y="13">Request latency</tspan>
            </text>
        </g>
    </g>
</svg>

<p><strong>It works amazingly well</strong>. We have not only cut the latency overhead to the bone, according to our logs requests failing due to proxy errors have become a thing of the past too.</p>

<p>Credit goes to the team for shipping this so quickly. They went from bare git repo to production deployment of a fleet of embedded devices with OTA software updates in weeks. I'm very proud of them.</p>

<p>Follow <a href="https://twitter.com/tellerapi">@tellerapi</a> for a future blog post on how we built Telnet.</p>

<p>Think this is cool? <a href="https://jobs.lever.co/teller">We're hiring</a>.</p>
</article></div></div>]]>
            </description>
            <link>https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625795</guid>
            <pubDate>Wed, 24 Jun 2020 09:08:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is an API? Learn by Building One, Without Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23625373">thread link</a>) | @mmckeaveney
<br/>
June 24, 2020 | https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/ | <a href="https://web.archive.org/web/*/https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Learn how to leverage integromat and other tools to build an HTTP API that could be integrated with thousands of different applications and platforms</p><div><p>Think about this:</p><p><strong>How do you retrieve information from computer?</strong></p><p>Take this scenario - you have navigated to your favourite news site or subreddit to procrastinate for a while on that thing you really <strong>should</strong> be doing. In doing so, how often do you think about <em>how</em> the website appeared on your screen? Where do those cat memes on your screen actually come from?</p><p>Humans and computers comprehend data very differently. We as humans can read words on a screen, or process the experiences presented to us in the form of websites, applications and command line interfaces. We can make assumptions about things that we see, based on our previous experiences and memories.</p><p>Computers, on the other hand, cannot. They process numbers at their lowest level. Based on the sequences of numbers, the computer will perform a specific set of tasks. This makes computers extremely good at repetitive tasks that would be either very tedious or very difficult for a human to do as quickly and as consistently as a computer can.</p><p>There are a a lot of intermediate steps that occur between the purely logical, number crunching power of your computers internals and the beautiful, highly immersive visual experiences that modern technology allows us to enjoy today. How does the computer perform its work and tell us what we want to know in a format <em>we</em> understand?</p><p>A website making it from a web server to your eyeballs is not possible without an <strong>Application Programming Interface</strong> (API).  APIs are how your computer interacts with data and are the foundations on which a majority of the modern web is built. An API is a simplified interface allowing a developer to integrate their program with another existing one. You could think of an API as a book that only your computer knows how to read from or write in.</p><p><img src="https://www.martinmck.com/images/daria-nepriakhina-xY55bL5mZAM-unsplash.jpg"></p><p>Some simple examples:</p><ul><li>When you visit your favourite news site, you get the latest news stories from that sites API.</li><li>You can build an app that sends email by using the gmail API.</li><li>You can sign in to many websites with just your facebook account by using the facebook authentication API</li></ul><p>APIs generally define a contract which details the operations the application that uses the API can and cannot do. Staying with the book analogy above, this would mean certain books only let you write specific words in them, in a specific language. This helps prevent bad actors from doing rather annoying things such as abusing your API and potentially crashing your server, or getting access to your data.</p><p>With hundreds of thousands of APIs available and thousands more being created every day, thereâ€™s really no escaping APIs when you are building software. Most applications are enhanced a great deal when they are integrated with others. This is true regardless of whether you are building applications with code or no-code tools.</p><p>To build an API <em>with</em> code, you generally need knowledge around the following software development topics:</p><ul><li>Server side programming languages (Python, Ruby, Java, NodeJS etc.)</li><li>Databases</li><li>HTTP (the protocol that powers the internet by allowing communication between web browsers and web servers)</li><li>Infrastructure and deployment - getting your code to run on a public server so other people can use it</li></ul><p>There are many tools that make the above much easier, but thereâ€™s still a lot to learn if you just want to a simple API that works for you.</p><p>In this post, we are going to build our very own web API <em>without</em> any code at all. </p><p>In a time where <a href="https://a16z.com/2011/08/20/why-software-is-eating-the-world/" title="Software is eating the world">software is eating the world</a>, itâ€™s increasingly important to understand the concepts behind the devices and technology that you are likely to use for a large portion of your day. Being able to explore technical topics without learning programming is a very powerful for anyone with interest in how the world around them works.</p><p>Letâ€™s get into it.</p><h2>Our Tools</h2><p>We are going to use 3 tools in this tutorial:</p><ul><li><strong>Integromat</strong> - an automation platform that lets us glue different applications together without code</li><li><strong>Postman</strong> - an API testing tool. We are going to use this to interact with our API</li><li><strong>Google Sheets</strong> - We are going to use google sheets as our â€œdatabaseâ€�. This is where the data sent to our API will be stored.</li></ul><h2>Our API</h2><p>We are going to use the slightly contrived example of building an HTTP API allowing people to vote for places to go for lunch near the office. We want consumers of the API to be able to register their vote for a particular lunch spot near the office. This will increment the count of a particular lunch spot by one. </p><h3>Setting Up Our Google Sheet</h3><p>First of all we need to create a google sheet. Nothing particularly challenging here. Just go to google sheets and create a blank spreadsheet. Letâ€™s call it â€œLunch Voterâ€�.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2013.43.20.png"></p><h3>Integromat</h3><p>We now have our â€œdatabaseâ€� set up. Letâ€™s create our actual API now to interact with it. First of all, you will need to <a href="https://www.integromat.com/en/register" title="create an integromat account">create an integromat account</a> to get started.</p><p>Integromat is billed as the â€œglue of the internetâ€� and for good reason. It allows you to connect well over 200+ different applications with each other. For example if you want to automatically save gmail attachments to your dropbox account, or send you zoom links directly via WhatsApp for an upcoming calendar meeting, Integromat is your friend. </p><p>The above example are some of the simplest things you could possibly do with integromat - you can automate almost anything with the platform.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2013.48.26.png"></p><h4>Creating an Integromat Scenario</h4><p>Integromat uses a very intuitive flowchart structure for you to define your workflows or â€œscenariosâ€� as they are known. Letâ€™s create a new scenario for our lunch voter API by Navigating to the integromat dashboard and clicking the â€œCreate a new scenarioâ€� button. </p><p>You will be taken to a page allowing you to select integrations you want to use. This step is optional, as we will have access to all the integrations that we need when we get into the integromat builder. Letâ€™s click â€œskipâ€� for now.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2013.56.53.png"></p><p>You will then be presented with the integromat scenario builder. This is where we configure and edit our scenario. Before we build anything, itâ€™s always important to outline the steps we plan to take before we execute. For our lunch voter API, we want to:</p><ul><li>Allow someone to interact with our API telling us the name of the restaurant they want to upvote</li><li>If it doesnâ€™t exist, create a new row in our spreadsheet</li><li>If it exists, update itâ€™s vote count by 1</li></ul><p>Letâ€™s focus on the first item, and provide a way for people to interact with our API. The way we do that is through a <strong>webhook</strong>, which is at its core a way to let applications notify each other of events over the internet. </p><p>Letâ€™s build one.</p><h3>Creating a Webhook</h3><p>To create a Webhook in integromat, click the first module (with the large question mark) and you will see a menu to select an integration. Search for â€œWebhooksâ€� and select it and you will see the options for your webhook. Select â€œCustom Webhookâ€�.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2014.09.36.png"></p><p>Click â€œAddâ€� to add a new webhook. We are going to call ours â€œLunch Voter Webhookâ€�.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2014.10.04.png"></p><p>Click save and you will see a URL. This is how we will talk to our API. Copy this URL to your clipboard by clicking â€œCopy address to clipboardâ€�. </p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2014.10.43.png"></p><h3>Testing the Webhook</h3><p>We now have an API to interact with, but it isnâ€™t very useful yet. We need to tell the webhook what our data will â€œlook likeâ€� so itâ€™s able to understand when we interact with it.</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2014.21.14.png"></p><p>The webhook is now waiting for you to interact with it. We do this by making an HTTP request to that URL. For context, an HTTP request is what happens when you visit a website. Your browser makes an HTTP request for google.com when you try to navigate there, for instance. </p><p>We are going to use a tool called Postman to make our HTTP request. You can download it <a href="https://www.postman.com/downloads/" title="Download Postman">here</a>.  Open up postman and create a new request then paste in the URL you copied earlier from your webhook in integromat. Change the dropdown beside your URL from <strong>GET</strong> to <strong>POST</strong>.  Finally: </p><ul><li>click the â€œBodyâ€� tab</li><li>click the â€œrawâ€� option</li><li>Select â€œJSONâ€� from the dropdown on the right</li><li>paste in the following to the large textarea:</li></ul><pre><code>{
  "restaurant": "My Favourite Restaurant"
}
</code></pre><p>Your Postman Screen should look something like this:</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2015.25.40.png"></p><p>Click the blue â€œSendâ€� button to send your HTTP request and interact with your integromat webhook.</p><p>Back in integromat, you will see a message telling you that the shape of your data has been successfully determined. Letâ€™s store it in our spreadsheet!</p><h3>Google Sheets</h3><p>In order to update our google sheet, we need to check whether or not a row for the restaurant already exists before either updating the vote count by one or creating a new row. Hereâ€™s a reminder of our steps to save you scrolling:</p><ul><li>Check if a row exists with the restaurant name we sent in our JSON data</li><li>If it doesnâ€™t exist, create a new row in our spreadsheet</li><li>If it exists, update that restaurants vote count by 1</li></ul><h4>Searching For An Existing Row</h4><p>Letâ€™s set up the google sheets module in integromat to search for a row. Click your webhook module and click the plus button to creae a new module in your integromat scenario. </p><ul><li>Search for â€œgoogle sheetsâ€� in the search bar, click it </li><li>Select the â€œSearch Rowsâ€� module.</li></ul><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2021.52.04.png"></p><p>To configure your search rows module, you need to authenticate integromat with your google account by adding your google account connection. Once you have done that, then select your Lunch Voter spreadsheet and sheet.</p><p>Finally, set up your filter. This is how integromat will search your google sheet to check if a restaurant already exists. We want to check if any value in column <strong>A</strong> matches the data we are passing to our API. Your module setup should look like the following:</p><p><img src="https://www.martinmck.com/images/Screenshot%202020-06-20%20at%2021.05.59.png"></p><p>Click OK when done.</p><h4>If This, Then That</h4><p>Now to move on to the next step, which is to perform one action if the restaurant exists, or another if it doesnâ€™t. In order to do that in integromat, we must use a <strong>router</strong>. A router is basically a fork in the road, where you can perform 2 different actions …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/">https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/</a></em></p>]]>
            </description>
            <link>https://www.martinmck.com/posts/what-is-an-api-learn-by-building-one-without-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625373</guid>
            <pubDate>Wed, 24 Jun 2020 08:03:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t Fly During Ramadan (2013)]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23625215">thread link</a>) | @luu
<br/>
June 24, 2020 | https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/ | <a href="https://web.archive.org/web/*/https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A couple of weeks ago, I was scheduled to take a trip from New York (JFK) to Los Angeles on JetBlue. Every year, my family goes on a one-week pilgrimage, where we put our work on hold and spend time visiting temples, praying, and spending time with family and friends. To my Jewish friends, I often explain this trip as vaguely similar to the <a href="https://en.wikipedia.org/wiki/Sabbath" target="_blank" rel="noopener">Sabbath</a>, except we take one week of rest per year, rather than one day per week.</p>
<p>Our family is not Muslim, but by coincidence, this year, our trip happened to be during the last week of <a href="https://en.wikipedia.org/wiki/Ramadan" target="_blank" rel="noopener">Ramadan</a>.</p>
<p>By further coincidence, this was <em>also</em> the same week that I was moving out of my employer-provided temporary housing (at NYU) and moving into my new apartment. The night before my trip, I enlisted the help of two friends and we took most of my belongings, in a couple of suitcases, to my new apartment. The apartment was almost completely unfurnished – I planned on getting new furniture upon my return – so I dropped my few bags (one containing an air mattress) in the corner. Even though I hadn’t decorated the apartment yet, in accordance with Hindu custom, I taped a single photograph to the wall in my bedroom — a long-haired saint with his hands outstretched in <em><a href="https://www.google.com/search?q=pronam&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ei=fR8WUre0GIG28wSH94DwCw&amp;ved=0CAcQ_AUoAQ&amp;biw=1046&amp;bih=733" target="_blank" rel="noopener">pronam</a></em> (a sign of reverence and respect).</p>
<p>The next morning, I packed the rest of my clothes into a suitcase and took a cab to the airport. I didn’t bother to eat breakfast, figuring I would grab some yogurt in the terminal while waiting to board.</p>
<p>I got in line for security at the airport and handed the agent my ID. Another agent came over and handed me a paper slip, which he said was being used to track the length of the security lines. He said, “just hand this to someone when your stuff goes through the x-ray machines, and we’ll know how long you were in line.’ I looked at the timestamp on the paper: 10:40.</p>
<p>When going through the security line, I opted out (as I always used to) of the millimeter wave detectors. I fly often enough, and have opted out often enough, that I was prepared for what comes next: a firm pat-down by a TSA employee wearing non-latex gloves, who uses the back of his hand when patting down the inside of the thighs.</p>
<p>After the pat-down, the TSA agent swabbed his hands with some cotton-like material and put the swab in the machine that supposedly checks for explosive residue. The machine beeped. “We’re going to need to pat you down again, this time in private,” the agent said.</p>
<p>Having been selected before for so-called “random” checks, I assumed that this was another such check.</p>
<p>“What do you mean, ‘in private’? Can’t we just do this out here?”</p>
<p>“No, this is a different kind of pat-down, and we can’t do that in public.” When I asked him why this pat-down was different, he wouldn’t tell me. When I asked him specifically why he couldn’t do it in public, he said “Because it would be obscene.”</p>
<p>Naturally, I balked at the thought of going somewhere behind closed doors where a person I just met was going to touch me in “obscene” ways. I didn’t know at the time (and the agent never bothered to tell me) that the TSA has a policy that requires two agents to be present during every private pat-down. I’m not sure if that would make me feel more or less comfortable.</p>
<p>Noticing my hesitation, the agent offered to have his supervisor explain the procedure in more detail. He brought over his supervisor, a rather harried man who, instead of explaining the pat-down to me, rather rudely explained to me that I could either submit immediately to a pat-down behind closed-doors, or he could call the police.</p>
<p>At this point, I didn’t mind having to leave the secure area and go back through security again (this time not opting out of the machines), but I didn’t particularly want to get the cops involved. I told him, “Okay, fine, I’ll leave”.</p>
<p>“You can’t leave here.”</p>
<p>“Are you detaining me, then?” I’ve been through enough “<a href="https://www.flexyourrights.org/" target="_blank" rel="noopener">know your rights</a>” training to know how to handle police searches; however, TSA agents are not law enforcement officials. Technically, they don’t even have the right to detain you against your will.</p>
<p>“We’re not detaining you. You just can’t leave.” My jaw dropped.</p>
<p>“Either you’re detaining me, or I’m free to go. Which one is it?” I asked.</p>
<p>He glanced for a moment at my backpack, then snatched it out of the conveyor belt. “Okay,” he said. “You can leave, but I’m keeping your bag.”</p>
<p>I was speechless. My bag had both my work computer and my personal computer in it. The only way for me to get it back from him would be to snatch it back, at which point he could simply claim that I had assaulted him. I was trapped.</p>
<p>While we waited for the police to arrive, I took my phone and quickly tried to call my parents to let them know what was happening. Unfortunately, my mom’s voicemail was full, and my dad had never even set his up.</p>
<p>“Hey, what’s he doing?” One of the TSA agents had noticed I was touching my phone.<br>
“It’s probably fine; he’s leaving anyway,” another said.</p>
<p>The cops arrived a few minutes later, spoke with the TSA agents for a moment, and then came over and gave me one last chance to submit to the private examination. “Otherwise, we have to escort you out of the building.” I asked him if he could be present while the TSA agent was patting me down.</p>
<p>“No,” he explained, “because when we pat people down, it’s to lock them up.”</p>
<p>I only realized the significance of that explanation later. At this point, I didn’t particularly want to miss my flight. Foolishly, I said, “Fine, I’ll do it.”</p>
<p>The TSA agents and police escorted me to a holding room, where they patted me down again – this time using the front of their hands as they passed down the front of my pants. While they patted me down, they asked me some basic questions.</p>
<p>“What’s the purpose of your travel?”</p>
<p>“Personal,” I responded, (as opposed to business).</p>
<p>“Are you traveling with anybody?”</p>
<p>“My parents are on their way to LA right now; I’m meeting them there.”</p>
<p>“How long is your trip?”</p>
<p>“Ten days.”</p>
<p>“What will you be doing?”</p>
<p>Mentally, I sighed. There wasn’t any other way I could answer this next question.</p>
<p>“We’ll be visiting some temples.” He raised his eyebrow, and I explained that the next week was a religious holiday, and that I was traveling to LA to observe it with my family.</p>
<p>After patting me down, they swabbed not only their hands, but also my backpack, shoes, wallet, and belongings, and then walked out of the room to put it through the machine again. After more than five minutes, I started to wonder why they hadn’t said anything, so I asked the police officer who was guarding the door. He called over the TSA agent, who told me,</p>
<p>“You’re still setting off the alarm. We need to call the explosives specialist”.</p>
<p>I waited for about ten minutes before the specialist showed up. He walked in without a word, grabbed the bins with my possessions, and started to leave. Unlike the other agents I’d seen, he wasn’t wearing a uniform, so I was a bit taken aback.</p>
<p>“What’s happening?” I asked.</p>
<p>“I’m running it through the x-ray again,” he snapped. “Because I can. And I’m going to do it again, and again, until I decide I’m done”. He then asked the TSA agents whether they had patted me down. They said they had, and he just said, “Well, try again”, and left the room. Again I was told to stand with my legs apart and my hands extended horizontally while they patted me down all over before stepping outside.</p>
<p>The explosives specialist walked back into the room and asked me why my clothes were testing positive for explosives. I told him, quite truthfully, “I don’t know.” He asked me what I had done earlier in the day.</p>
<p>“Well, I had to pack my suitcase, and also clean my apartment.”</p>
<p>“And yesterday?”</p>
<p>“I moved my stuff from my old apartment to my new one”.</p>
<p>“What did you eat this morning?”</p>
<p>“Nothing,” I said. Only later did I realize that this made it sound like I was fasting, when in reality, I just hadn’t had breakfast yet.</p>
<p>“Are you taking any medications?”</p>
<p>The other TSA agents stood and listened while the explosives specialist and asked every medication I had taken “recently”, both prescription and over-the-counter, and asked me to explain any medical conditions for which any prescription medicine had been prescribed. Even though I wasn’t carrying any medication on me, he still asked for my complete “recent” medical history.</p>
<p>“What have you touched that would cause you to test positive for certain explosives?”</p>
<p>“I can’t think of anything. What does it say is triggering the alarm?” I asked.</p>
<p>“I’m not going to tell you! It’s right here on my sheet, but I don’t have to tell you what it is!” he exclaimed, pointing at his clipboard.</p>
<p>I was at a loss for words. The first thing that came to my mind was, “Well, I haven’t touched any explosives, but if I don’t even know what chemical we’re talking about, I don’t know how to figure out why the tests are picking it up.”</p>
<p>He didn’t like this answer, so he told them to run my belongings through the x-ray machine and pat me down again, then left the room.</p>
<p>I glanced at my watch. Boarding would start in fifteen minutes, and I hadn’t even had anything to eat. A TSA officer in the room noticed me craning my neck to look at my watch on the table, and he said, “Don’t worry, they’ll hold the flight.”</p>
<p>As they patted me down for the fourth time, a female TSA agent asked me for my baggage claim ticket. I handed it to her, and she told me that a woman from JetBlue corporate security needed to ask me some questions as well. I was a bit surprised, but agreed. After the pat-down, the JetBlue representative walked in and cooly introduced herself by name.</p>
<p>She explained, “We have some questions for you to determine whether or not you’re permitted to fly today. Have you flown on JetBlue before?”</p>
<p>“Yes”</p>
<p>“How often?”</p>
<p>“Maybe about ten times,” I guessed.</p>
<p>“Ten what? Per month?”</p>
<p>“No, ten times total.”</p>
<p>She paused, then asked,</p>
<p>“Will you have any trouble following the instructions of the crew and flight attendants on board the flight?”</p>
<p>“No.” I had no idea why this would even be in doubt.</p>
<p>“We have some female …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/">https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/</a></em></p>]]>
            </description>
            <link>https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625215</guid>
            <pubDate>Wed, 24 Jun 2020 07:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL Query JIT]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23624751">thread link</a>) | @kureikain
<br/>
June 23, 2020 | https://solovyov.net/blog/2020/postgresql-query-jit/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/postgresql-query-jit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody">
  <p>We’re proud users of PostgreSQL. Proud in a sense we’re really glad that our main data store is such a stable, performant, introspective, and overall great DBMS. It’s been very reliable for us and in times of turbulence made it possible to understand what the issue is. Overall, I love it.</p>

<p>We were on 10.x since ages - upgraded a month after it came out. We did a regular old school upgrade using <code>pg_upgrade</code>. You see, one of PG traits is that on-disk data layout is different between major versions. That means that version 10 can’t work with data from version 9 (and vice versa) and you have to convert the data to run a new version. It’s a PITA but gives you time to test and see if everything is okay, etc.</p>

<p>But when 11th came out something stopped us from upgrading (I don’t remember what). Plus around that time we started using <a href="https://www.2ndquadrant.com/en/resources/pglogical/">pglogical</a> for a purpose of having, for example, an analytical replica. Or a partial replica to speed up something. And our idea of the next major upgrade was to use logical replication to copy data from our main db to the new node with newer PostgreSQL. It’s one of the cool features of logical replication - you can replicate data between nodes with different major versions.</p>

<p>Then pg12 came out. It was a great (as always) release, with a lot of performance improvements (CTE is not an optimization fence anymore, woohoo!), plus JIT was improved and enabled by default, and some new exciting features (jsonpath anyone?). And we’re experienced users of logical replication now.</p>

<p>It is time to upgrade then, right? Not so fast, amigo. 2ndQuadrant, authors of pglogical, had some problems with rolling out new release for pg12. I don’t know details here, but after some time they figured stuff out and February saw release of pglogical 2.3.</p>

<p>Cool! So after weeks of preparation on one uneventful (so far) night of 16th of April, a designated person did a migration. Well, a migration was done by logical replication before, so he switched pgbouncer to the new main db.</p>

<p>As a logical (heh) consequence of that - we did not really test pg12 on production traffic. Is that because of blind faith? Or laziness? It’s a hard question.</p>

<p>For some time everything was normal. New PostgreSQL, running smoothly, yada-yada-yada. And then the traffic came. It wasn’t even some peak sale or anything. Our daily campaigns start at 6:00, so that’s the start of the day for the site. Right at 6:00 pg started to feel unwell.</p>

<p>At 6:40, when I was woken up, site barely moved. We tracked slowdown to a very popular query, which selected a user from db: it was executed on every request which required authentication.</p>

<p>And what was wrong? Query plan for this query was so wildly weird that we’ve tried to use our intuition first and just disabled non-critical parts which we knew were heavy. This improved our mean API timings from 10s to 5s. Which is still strictly in “site is unresponsive” category.</p>

<p>Okay, back to investigation. Explain for that query was the same as on pg10, but explain analyze said that 12.9s of 13s of execution (API timings are lower because of caches) are spent on joining <code>auth_user</code> and <code>user_userprofile</code>. We’re an ex-Django site and that means some peculiarities in database design. For example, having a table called <code>product_product</code>, or that stuff where <code>auth_user</code> is a table about users and <code>user_userprofile</code> is about users data. So the interesting part of the query plan looks like this:</p>

<pre><code>-&gt;  Nested Loop  (cost=0.86..12.89 rows=1 width=310) (actual time=13708.286..13708.290 rows=1 loops=1)
      -&gt;  Index Scan using auth_user_pkey on auth_user u  (cost=0.43..6.44 rows=1 width=97) (actual time=0.108..0.108 rows=1 loops=1)
            Index Cond: (id = 7002298)
      -&gt;  Index Scan using user_userprofile_user_id_key on user_userprofile p  (cost=0.43..6.44 rows=1 width=217) (actual time=0.087..0.088 rows=1 loops=1)
            Index Cond: (user_id = 7002298)
</code></pre>

<p>What is the magic here? How does <code>0.08 + 0.1</code> results in <code>13708</code>? Is this the real life or is this just fantasy? We’ve spent half an hour pondering on that question until <a href="https://vsevolod.net/">Vsevolod</a> woke up and told me there is a JIT report at the end of the query plan:</p>

<pre><code> Planning Time: 2.515 ms
 JIT:
   Functions: 138
   Options: Inlining true, Optimization true, Expressions true, Deforming true
   Timing: Generation 108.775 ms, Inlining 888.683 ms, Optimization 7700.314 ms, Emission 5091.838 ms, Total 13789.610 ms
 Execution Time: 13821.487 ms
</code></pre>

<p>I blame this on both being too sleepy (being woken up in the wrong sleep phase is a pain) and having absolutely zero experience with JIT. Somehow this <code>Optimizations</code> word has captured my attention and I’ve spent quite a bit of time reading up on new optimizations in PostgreSQL and how to disable them. No idea why <code>Emission</code> did not have my attention - I guess its time just didn’t come yet. :-)</p>

<p>JIT got disabled. API response timings dropped from 5s to whatever they are normally. Things went back to usual state.</p>

<h2>Reasons</h2>

<p>Discussion on <a href="https://lobste.rs/s/r6ydjp/postgresql_query_jit">lobste.rs</a> was coming to a conclusion that 14 seconds is too much for a JIT and maybe we triggered some bug in PostgreSQL. So I went up to reproduce this, but with more verbose query plan (literally <code>explain (analyze, verbose, buffers) ...</code>). And got this:</p>

<pre><code> Planning Time: 2.240 ms
 JIT:
   Functions: 101
   Options: Inlining false, Optimization false, Expressions true, Deforming true
   Timing: Generation 13.719 ms, Inlining 0.000 ms, Optimization 3.280 ms, Emission 83.755 ms, Total 100.753 ms
 Execution Time: 102.812 ms
</code></pre>

<p>My first reaction was of course “argh it fixed itself or what?!” But then it hit me: this is one of the most frequent queries in our database and JIT adding 100 ms of CPU time (because just in time compilation for sure is not some I/O wait) put such a massive load on our CPUs that eventually that 100 ms went up to being 14 seconds.</p>

<h2>Conclusion</h2>

<p>We should have tested more. Also, we need more monitoring to see that one query became too slow. I’ve been thinking that not skipping PG11 would’ve helped to test JIT and identify this issue early. OTOH it seems it wasn’t that straightforward to enable.</p>

<p>With all that said, I can’t shake off the feeling that JIT being enabled by default is a bit too early.</p>

  </section></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/postgresql-query-jit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23624751</guid>
            <pubDate>Wed, 24 Jun 2020 06:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Ideas, Through the Looking Glass  (2005) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23624575">thread link</a>) | @peter_d_sherman
<br/>
June 23, 2020 | https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf | <a href="https://web.archive.org/web/*/https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23624575</guid>
            <pubDate>Wed, 24 Jun 2020 05:58:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going for a 100% Lighthouse Score? Read this]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23624555">thread link</a>) | @arunoda
<br/>
June 23, 2020 | https://arunoda.me/blog/lighthouse-syndrome?on=hn | <a href="https://web.archive.org/web/*/https://arunoda.me/blog/lighthouse-syndrome?on=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://arunoda.me/blog/lighthouse-syndrome?on=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23624555</guid>
            <pubDate>Wed, 24 Jun 2020 05:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go Out]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23624176">thread link</a>) | @patwalls
<br/>
June 23, 2020 | https://patwalls.com/go-out | <a href="https://web.archive.org/web/*/https://patwalls.com/go-out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/go-out</link>
            <guid isPermaLink="false">hacker-news-small-sites-23624176</guid>
            <pubDate>Wed, 24 Jun 2020 04:42:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Staring into the COM Abyss]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 66 (<a href="https://news.ycombinator.com/item?id=23623994">thread link</a>) | @todsacerdoti
<br/>
June 23, 2020 | https://cmpct.info/~calvin/Articles/COMAbyss/ | <a href="https://web.archive.org/web/*/https://cmpct.info/~calvin/Articles/COMAbyss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		
		<p>
			If you're aware of how software is developed on Windows, chances are you're eventually going to run into COM. While Windows exposes some simple C APIs (and these APIs were much better than its contemporaries like Toolbox, X, or Intuition), pretty much anything more complex than USER32 is exposed through COM interfaces, from Internet Explorer to DirectX. COM is also used to <em>extend</em> applications too: Office, Visual Studio, even the Windows shell provide COM interfaces to applications to hook into. Microsoft loves using COM for everything in Windows, even if third-parties don't like it as much (Usually, out of portability/complexity reasons.). Using COM to its full extent can <a href="https://www.joelonsoftware.com/2009/09/23/the-duct-tape-programmer/">make your application 34% sparklier</a>, but it's a lot of work to properly use those interfaces (and there's a lot of them!).
		</p>
		<p>
			Unfortunately not many were able to take advantage of COM, let alone in more obscure scenarios such as extending the shell. The people who could do so were quite rare, as Spolsky pointed out. Naturally, I was <a href="https://xkcd.com/356/">nerd sniped</a> by a friend to write a <a href="https://docs.microsoft.com/en-us/windows/win32/shell/nse-works">shell namespace extension</a>, one of the more obscure (little documentation, few did it, few know they exist) categories of COM extension. A shell namespace extension adds a "namespace" (basically virtual folder) to the shell, which has further objects represented in it. Common use cases for them include MTP for phones, inline ZIP file viewing, etc.
		</p>
		<p>
			My extension was simple enough I thought I could implement it (and I did... with difficulty, as you'll see) myself. It would enumerate all the open Windows Explorer windows, and put links to them in a namespace. The point of this is that this was accessible from the stock system file dialogs, which is useful if you have a bunch of Explorer windows open, but want to save to one of them quickly. This was inspired by an OS/2 Workplace Shell feature (the one good feature of OS/2!). The challenge was going from a bare minimum knowledge of COM to knowing just enough to be <del>dangerous</del> able to make a shell namespace extension that works.
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/os2-version.jpg" alt="The OS/2 feature" title="The OS/2 feature">
		<h2>A Brief Primer on COM</h2>
		<p>
			For something with a near-legendary reputation of complexity, it turns out COM is actually based on some very simple primitives. COM is based on interfaces (in the C++ manner) that implement vtables (a structure full of functions). These interfaces have a fixed shape, so they can be used from C. Every COM class implements the interface <code>IUnknown</code>, which implements three functions:
		</p>
		<ul>
			<li><code>AddRef</code>, which increments the reference count. Every COM object is reference counted, so you'll use this when you make a copy of a held-on reference.</li>
			<li><code>Release</code>, which decrements the reference count. The object frees itself when the count hits zero.</li>
			<li><code>QueryInterface</code>, which gives you the vtable of another interface if the object implements it (casting). The interfaces are identified by a GUID.</li>
		</ul>
		<p>
			This isn't so bad. Of course, objects can implement a <em>lot</em> of interfaces, and because interfaces have a fixed shape, to extend an interface later, you have to create another interface. Microsoft ends up numbering them, so you get into situations where you have an <a href="https://docs.microsoft.com/en-us/windows/win32/api/shobjidl_core/nn-shobjidl_core-ishellfolder2"><code>IShellFolder2</code></a>. And as Microsoft implements more features that require more interfaces, a class can get unwieldy if you're not careful. And then you have to assume the interfaces are well documented! And for extensibility, debugging isn't (as far as I'm aware) very great beyond printf macros.
		</p>
		<p>
			COM classes are registered (that's what REGSVR32 is for), where they become known by other applications. A <a href="https://docs.microsoft.com/en-us/windows/win32/midl/com-dcom-and-type-libraries">type library</a> provides metadata, and is usually generated by an IDL file.
		</p>
		<p>
			While you can use COM from C, it can get a bit unwieldy, because COM benefits from an environment of RAII and scoped destructors. ATL provides a template-based wrapper around COM for C++, and is what Microsoft recommends for COM development. Visual Studio greatly assists in terms of generating the boilerplate for categories of COM classes.
		</p>
		<h2>Do You Eat Your Burgers With or Without the Shell?</h2>
		<p>
			The beautiful part of Windows is how extensible it is. The ugly part of Windows is how no one can extend it properly. Trying to write a shell namespace extension from scratch is a Sisyphean endeavour. I don't think anyone's done it. Instead, you have to do things like your average Windows programmer in 2002 would have done - read someone much smarter than you's <a href="https://www.codeproject.com/Articles/1649/The-Complete-Idiot-s-Guide-to-Writing-Namespace-Ex">article on CodeProject</a>, the site people copied and pasted from <em>before</em> Stack Overflow. His examples are helpful, but they have a critical flaw - they implement the list view on their own, instead of delegating out to the interface which handles using the stock one and its default behaviours for you. (For example, the example will crash on XP and newer because it doesn't handle the new ListView views.) Insightful, but back to the drawing board.
		</p>
		<p>
			Round two. The <a href="https://www.codeproject.com/Articles/7973/An-almost-complete-Namespace-Extension-Sample">example by Pascal Hurni</a> is while slightly rougher, closer to what we want. His example uses the system ShellView, which gives you default behaviours and the ability to use it from a stock file dialog, which is what we want. The example enumerates through the registry (specifically, favourites for the file manager <a href="https://www.gpsoft.com.au/">Directory Opus</a>) and represents real filesystem entities, which is close to what we want - just swap out the enumerator.
		</p>
		<p>
			I took some code I wrote for experimenting with actually listing Explorer windows. First I thought I'd have to enumerate all visible windows and filter on <code>CabinetWClass</code>, then figure out what messages to send to it in order to get useful information out, but it turns out an easier way was possible through COM. You create an instance of <code>IShellWindows</code>, then call <code>get_Count</code> and <code>Item</code>, which returns an <code>IDispatch</code> representing your window. <code>IDispatch</code> is essentially <code>IUnknown</code> with reflection, intended for situations like VBA where you want to enumerate methods and properties. We can cast it to an <code>IWebBrowser</code> (a remnant of when Internet Explorer and Windows Explorer were welded together), and get the location from there. Grafting it onto Pascal's example (and ripping out what code I didn't need for clarity), I had a working MVP (with bugs, of course)
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/explorer-windows.png" alt="Windows XP, opened Explorer windows" title="Windows XP, opened Explorer windows">
		<h2>PIDLy Details</h2>
		<p>
			I <del>cargo-culted (first step of learning)</del> learned some things about the shell, and there's still a lot more I don't know about. Tip of the iceberg as follows:
		</p>
		<ul>
			<li>A PIDL is basically an ID used by Explorer to represent items, since entities may not have real FS representation. A PIDL is basically a free-form struct that has what you want tagged with its size, and what your NSE will use to identify items. They can be absolute or relative (where it only matters to you), like a path.</li>
			<li>It likes to request wrapped PIDLs in the form of <code>IDataObject</code>, one of those can-contain-anything OLE structures usually used for the clipboard.</li>
			<li>Namespaces can be registered at a <em>junction point</em>, which makes it accessible from places other than making a shortcut to its CLSID (GUID). There's also some ceremony in registering the namespace at all; there's a registry resource script that gets called whenever the DLL is registered to make it easier. Some information on creating namespaces (but from a customizer's perspective, so pointing it at existing locations) and making it known in places is available <a href="http://virtualplastic.net/html/ui_shell.html">here</a>.</li>
			<li>Some software (cough, Office) requires an NSE represent a real location before it'll show it. The example works around this by using the temporary directory as a physical manifestation. This can result in weird behaviour, but it's the price to pay to have it work.</li>
			<li>Late in XP's lifecycle and especially Vista, Microsoft extended the column scheme to have property keys. These represent metadata more faithfully, can be extended, and is actively used for search. Namespace extensions can of course, implement these. However, it's not clear on what's the bare minimum you implement to get things like tile view subtitles working. You're almost led to believe you need an <code>IPropertyStore</code> and XML file representing custom metadata columns, but I was seemingly lucky enough I could just use built-in property keys and (I believe) the real filesystem entities have their metadata fill in. I just had to map the (most; I didn't notice anything bad from not mapping everything) column IDs I was using to the system included property keys and handle the property keys that resolve to other property keys for what to display on tiles and such.</li>
		</ul>
		<p>
			The real sad part is for things like this, because the documentation is so lacking/missing, is that you may run into issues where not even Stack Overflow can help you. Experimentation or blind trust in ancient Usenet posts may be required. Or maybe you can be lucky enough to know someone who was there, remembers, and still cares. Remember, not many at the time knew how to use these effectively, and the number of people who do dwindles, to a point of extinction, another point to the <a href="https://www.devever.net/~hl/windowsdefeat">cultural defeat of Windows</a>.
		</p>
		<p>
			I also found <a href="https://www.viksoe.dk/code/regfolder.htm">someone who implemented a wrapper class library and a bunch of samples around them</a>, which probably would be handy if I didn't discover it <em>after</em> actually managing to make it. It might have been useful, but it does a lot for you, so perhaps it was for the best to understand how the shell/COM works at a lower level.
		</p>
		<h2>IActuallyDidIt2</h2>
		<p>
			I managed to actually write the extension. It's available <a href="https://github.com/NattyNarwhal/OpenWindows">on GitHub</a>, and I hope it provides a clearer example of a shell namespace extension (since you're likely not going to find many, let alone many who know it) as well as be useful to Explorer freaks. I had also contacted Pascal about the licensing ambiguities (since people just did open source in Windows circles by the edge of their seats back then) - it's MIT licensed for sure. Now you know how the ISausage is made, and it is delicious - if only people could figure out the best way to eat it.
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/save-dialog.png" alt="Windows Vista, save dialog" title="Windows Vista, save dialog">
	

</div>]]>
            </description>
            <link>https://cmpct.info/~calvin/Articles/COMAbyss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623994</guid>
            <pubDate>Wed, 24 Jun 2020 04:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From English Major to Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23623709">thread link</a>) | @breyerjs
<br/>
June 23, 2020 | https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer | <a href="https://web.archive.org/web/*/https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><h4>What's This?</h4><p>I studied English as an undergraduate, but since then I've taken an untraditional path into software engineering. Years later, I'm working as an Engineering Manager at Yelp. </p><p>I've heard everything from curiosity to outright scorn when people learn my background. </p><p>I'm writing for the curious, to share how I changed from one career to a very different one. I'm also writing for those who are considering a similar jump. Hopefully my story sheds some light on the road ahead.</p><h4>English Major</h4><p>I majored in English for the usual reasons. I like reading, writing, diagramming sentences, and picking apart complex narratives. I wanted to learn more about those things. And at eighteen years old, I was not particularly concerned about the future.</p><p>As graduation approached, I realized that in order to make money, I would need a job. So which job?</p><h4>Law</h4><p>Law seemed like a good fit. It's meaningful and interesting work. There is plenty of reading, writing, and picking apart complex narratives.</p><p>But becoming a lawyer means law school, which is expensive and itself requires the LSAT. And the LSAT takes months of study in order to do well. I needed time to scope out the industry before committing all that money. </p><p>So I became a paralegal. I worked at Cadwalader, Wickersham, and Taft (CWT), which is a very old, very large, and very traditional law firm. If you've heard of BigLaw, that's CWT.</p><p>I had a productive first year at CWT. I got the LSAT score I needed, I secured some strong recommendations, and I feel like I got an excellent window into the industry. </p><p>After all that, I was dismayed to admit: I didn't want to be a lawyer. While I liked many of the people I met at CWT, the lifestyle of the profession didn't appeal to me at all.</p><p>As someone who self-identifies as "quirky" at minimum, I felt like I would need to drastically alter my personality to suit the profession. Even more frightening: I thought I might be capable of doing that. What a terrible fate.</p><p>Back to square one. My paralegal job felt like a dead-end and law school felt like an expensive mistake. What to do?</p><h4>Learn Everything</h4><p>While continuing on as a paralegal, I tried to learn everything I could about other industries. Maybe one of them would stand out.</p><p>After a few months, my friend said to me: "You like linguistics, right? How about you try programming in Python. There are lots of cool linguistic applications for Python programming." </p><p>I'd never programmed before, but...sure. Why not? </p><p>So at 23-years-old, I wrote my first line of code. And let me tell you, when I saw "hello world" printed in the terminal, it was glorious. </p><p>Silly as it was, I was drunk with power. I could make the computer print out <em>anything</em>. In a strange way, I found programming similar to the creative / logical act of sentence diagramming, which I loved. So I was hooked. I started spending all of my free time programming. </p><h4>Learn Programming</h4><p>There were several initial hurdles to overcome. What curriculum would I follow? What language should I learn? Heck, what editor should I use to write code and where could I even execute it?</p><p>I imagine these things are obvious to someone who goes to school for Computer Science. But I was sitting at home with just the internet and a few spare hours. Fortunately, I had two great resources. </p><p>First, my programmer friends. I'm sure they got sick of my endless questions, but their help was invaluable. Working on your own, it's easy to get lost in StackOverflow posts and wind up dismayed. My friends kept me on track and cleared up a lot of confusing points. ("What's a constructor function?" "What's a list comprehension?") </p><p>Second, I found a fantastic e-book called <a href="https://inventwithpython.com/invent4thed/">Invent Your Own Computer Games With Python</a>. It's targeted at an audience...much younger than I was. As a result, the writing is exceptionally clear and simple. Perfect for an absolute beginner with limited guidance. </p><p>Armed with these tools, I wrote <em>lots</em> of sloppy, beginner-style programs. My crowning glory was a dinky chatbot that had hard-coded responses to common phrases. Success was just around the corner.</p><p>Except it wasn't.</p><p>I sent out a blizzard of internship applications, and every single one was rejected. It was a seemingly endless stream: rejection after rejection after rejection. I even got rejected from Yelp, where I currently work.</p><p>Around this time, a well-meaning acquaintance told me that I should give up trying to be a software engineer. It was too hard, there was too much math, and didn't I know? Software Engineers were <em>really</em> smart.  </p><p>Boy did that make me mad. I'm still mad, just thinking about it. </p><p>Any thoughts I had of giving up were promptly sidelined. I was <em>sure</em> I could break into the industry, given enough time. Maybe I needed more education.</p><h4>What Sort of Education?</h4><p>By whatever fortune, during that period I was blessed with clarity of vision. I was going to be a software engineer, full stop. I wanted to build the foundation for my life's professional work.</p><p>Around this time, programming bootcamps had become very popular. I spent a long time weighing them against a traditional graduate school.</p><p>It's easy to understand bootcamps' appeal. They teach you industry-relevant skills, they help you apply for jobs, and they promise to help you shift careers at supersonic speed: often in just a few months. </p><p>I thought for a long time about enrolling in a bootcamp. But, for whatever reason, it seemed risky. </p><p>Maybe it was the horror stories about poorly-run bootcamps. Maybe it was a personal bias towards traditional education. Maybe it was the impression I got online, that companies looked down on bootcamp graduates. Or a worry that I'd miss out on theoretical aspects of Computer Science. </p><p>Switching careers already felt risky, and I was desperate to reduce uncertainty. Bootcamps were out.</p><p>I've met many bootcamp graduates since then, most of them highly driven and intelligent. Some have found success, some not. </p><p>It's worth acknowledging that I enjoy several privileges which made it possible for me to quit my job and spend two years in grad school. I am very fortunate in that respect, and very grateful.</p><h4>Applying to Grad School</h4><p>Applying to grad school was pretty straightforward. The GRE felt like a piece of cake after the LSAT. I just needed to relearn high-school math (English major, remember?). </p><p>Few schools would accept me without a bachelor's in Computer Science. So that narrowed the field for me, in some ways a blessing. I applied to about five schools.</p><p>Of those, Brandeis was my top pick. There, I could take remedial undergraduate classes while I did my Master's. And they had a strong Computational Linguistics program to boot.</p><p>My background actually made parts of the application very easy. Writing a personal statement? No problem. Verbal portion of the GRE? Forget about it. </p><p>After submitting the applications, I took a mid-summer trip to Boracay, a remote island in the Philippines. I ducked in from the white-sand beach to check my email and found out that Brandeis had accepted me. Despite all the surf and sun, I could only dream of Boston in winter.</p><h4>First Year at Brandeis</h4><p>Brandeis was as great as Boston was cold.</p><p>I spent my time learning Computer Science, surrounded by intelligent people who had similar interests. It was like paradise.</p><p>Except for Discrete Math, that is. Everyone's got that one class where they struggle. But even tougher than the material was the imposter syndrome I felt as a result. It was my first semester and, heck, I was just an English major. If I was already struggling, maybe I didn't belong in a Computer Science program? Surely I'd be exposed as a fraud.</p><p>In the end, I managed to scrape out a hard-won B+. And boy was I grateful. I won't say it fully alleviated my imposter syndrome, but it was a good start.</p><p>There were high points too. Like the few Computational Linguistics classes I managed to sneak in. Boy were they fun. Finally I was back to diagramming sentences, but now the computer did it for me.</p><h4>Internship</h4><p>That summer, I was lucky to get an internship with Ginger.io, out in mythical San Francisco. I'd never been to SF, and didn't know much about Ginger.io. But on paper, it was perfect. </p><p>Ginger.io was a small-ish startup, with ~20 engineers. Their goal was to provide mental healthcare to people without the usual means of access—something I'm personally passionate about. </p><p>Their tech-stack was Python-based too. That meshed with the programming I'd done at Brandeis. Finally, <em>this time</em> success was just around the corner.</p><p>Except it wasn't.</p><p>The people at Ginger.io were patient and kind. But, to be frank, I was woefully underprepared. </p><p>I'd done very little collaborative programming. I was somewhat baffled by the command line, and <em>exceptionally</em> baffled by git. I'd never even dreamed of a codebase bigger than a few files. </p><p>It was one of the most difficult periods of my life. I spent much of the summer trying to learn all the things software engineers take for granted—automated testing, development environments, version control, architectural patterns, and so forth. I worked very slowly and I felt like I'd let the team down. It was doubly painful, since I cared deeply about the company's mission.</p><h4>Second Year at Brandeis</h4><p>As difficult as it was, that summer at Ginger.io was transformative for my education. I was determined to be better prepared for the next opportunity.</p><p>Suddenly, it was obvious which courses I should take. It was obvious which modules I needed to pay close attention to. I still managed to take a few Computational Linguistics courses, but I added other electives like Databases and Web Development. </p><p>As the year wound down, I felt vastly more prepared for professional software engineering than I had the previous summer. Letting the challenges of my internship guide my education was one of the most effective things I've done.</p><h4>Interviewing</h4><p>Many people have written about the software industry's interviewing practices. I won't dwell on that, except to say that it ain't no fun.</p><p>The process is long, emotionally fraught, and exhausting. As many as …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer">https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer</a></em></p>]]>
            </description>
            <link>https://www.jacksonbreyer.com/words/from-english-major-to-software-engineer</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623709</guid>
            <pubDate>Wed, 24 Jun 2020 03:28:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thank you, next (On gerontocracy: government run by old people)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23623445">thread link</a>) | @feross
<br/>
June 23, 2020 | https://blog.dcpos.ch/thank-you-next | <a href="https://web.archive.org/web/*/https://blog.dcpos.ch/thank-you-next">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_body_1527779">
    
      <div><p>A gerontocracy is a government run by old people.<br></p><div><p>Societies are usually run by people in the second half of their lives--people in their 40s, 50s, sometimes 60s. That's normal and healthy. Wisdom and empathy both come from experience. You cross the line into gerontocracy when power concentrates into people in their 70s and beyond.</p></div><div id="posthaven_gallery[1553143]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/medium_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/medium_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-medium-width="800" data-medium-height="334" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/large_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-large-width="1200" data-large-height="501" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/thumb_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/xlarge_Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-xlarge-width="1672" data-xlarge-height="698" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429868/c-a-Eqb8EAkBswUMGjOmGtmyyEU/Screen_Shot_2020-04-06_at_2.57.02_AM.png" data-orig-width="1672" data-orig-height="698" data-posthaven-id="2429868">
        </p>
          
        </div>
<p>Historically, gerontocracy has not gone well. The USSR in the early 1980s, China in the 1900s, Austria heading into WW1: if you look around you and the people in charge are all very old, expect turbulence.<br></p><p>The reasons from this range from the poetic to the dry and actuarial.</p><p><b>First, gerontocracy represents a failure of imagination.</b> Time horizons become compressed. It's rare for an 80 year old to start a brand new project. People at that age naturally want to <i>complete</i> some vision. Whatever dissonance they still feel in their own story, they want to see it resolve. They want closure. This is actually a beautiful impulse, but when too much power ends up in the hands of people who are heads-down finishing their final chapter, it sucks the air out of the room and leaves no space for new ideas.<br></p><div><p><b>Second, it represents a process failure.</b> Every society has a process for generational transfer, renewal, some kind of changing of the guard. When the seats of power are filled with people over 75, it's direct evidence that this process has stopped working.</p><p><b>Third, it predicts disruption.</b> Someone who's 40, elected to an 8-year term in office, has a 97% chance of being able to finish.[1] A 60-year-old has a 90% chance. Someone who's 80 today, a coin flip. And those numbers don't count all the other things that can go wrong, short of dying in office. Reagan had Alzheimer's towards the end of his presidency. When those things happen, real decision-making shifts from leaders to other, less publicly accountable people around them. The shift can be gradual and subtle. History shows it to be dangerous.</p></div><p><b>And ultimately, gerontocracy rusts the gears, and government kind of... seizes up.</b><br>
</p><div>
<br>        <div id="posthaven_gallery[1553144]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/medium_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/medium_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-medium-width="800" data-medium-height="313" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/large_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-large-width="1200" data-large-height="469" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/thumb_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/xlarge_Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-xlarge-width="1812" data-xlarge-height="708" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429869/E6KyYT7Ah7MbBjbnXmzK7QxZ8Vo/Screen_Shot_2020-04-06_at_3.07.10_AM.png" data-orig-width="1812" data-orig-height="708" data-posthaven-id="2429869">
        </p>
          
        </div>
</div><p>Source: [4], [5]<br>
</p><p>The ability to absorb new information, synthesize, and commit to decisions. The capacity for clear thinking and communication. The executive function to follow through.<br>
</p><div><p>The uncomfortable truth is that each of us will eventually lose those things. When too many leaders hit the steep part of their curve, the organization as a whole loses those capabilities, too. The dysfunction trickles down.</p><p>We're in a difficult moment in America. I collected data about the top positions in our politics over the last 100 years, and it supports what I suspected. <b>Our current political leaders are the oldest we've ever had.</b></p></div><div>
<p>Our president, the house speaker and senate majority leader were all born in the 1940s. Their median age is now 78.<br>
</p></div><div>        <div id="posthaven_gallery[1553141]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/medium_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/medium_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-medium-width="800" data-medium-height="338" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/large_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-large-width="1200" data-large-height="507" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/thumb_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/xlarge_Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-xlarge-width="2400" data-xlarge-height="1014" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2429866/rKB1QaWvJajByTQqD7Qt-W1iTrk/Screen_Shot_2020-04-06_at_2.36.49_AM.png" data-orig-width="2480" data-orig-height="1048" data-posthaven-id="2429866">
        </p>
          
        </div>
</div><div>
<p>
Regardless of what happens this year, we are on track to break that record repeatedly over the next few years.</p></div><p>--</p><div><p>The boomers had a vision: a backyard, a quiet street, two cars in every garage, global hegemony. It succeeded, to an extent, and it was beautiful, for some people. Idyllic, even. That vision has frayed. The yards and streets multiplied into sprawl and traffic.Â&nbsp; The cars in every garage are now measurably cooking the planet. And the global hegemony is probably ending. Whatever comes next will be different.</p><p>The good news is that the present situation is so clearly transitional that it's motivating people. For the first time in a long time, we have a cluster of youth based movements starting to articulate a new vision.</p><p>A new vision needs clarity. The kind of reactive politics that gets likes and retweets won't help us. We can't be defined by what we're against. Nor can we talk in vagaries and -isms. If you're the type who thinks that "capitalism" is in its late stage and will be replaced by "socialism", prepare to get concrete about what those words mean to you.</p></div><p>A vision is specific. It has to be <i>visual</i>. Visceral. It has to be as clear as that backyard with the green grass, grill going, kids playing tag, Buick sitting in the garage. <br>
</p><div><p>Then, the challenge is to do the hard work of building power. The time is past ripe.</p><p>--</p></div></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.dcpos.ch/thank-you-next</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623445</guid>
            <pubDate>Wed, 24 Jun 2020 02:49:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One of the best projects I worked on had zero-overhead communication]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23623360">thread link</a>) | @y39qpcen
<br/>
June 23, 2020 | https://sidhion.com/blog/posts/zero-overhead-communication/ | <a href="https://web.archive.org/web/*/https://sidhion.com/blog/posts/zero-overhead-communication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>There’s a project I worked on some time ago that provided me one of the most pleasant experiences I had.
When I say pleasant, I mean it in the project management sense.</p>
<p>The work itself wasn’t that fancy:
I had to migrate a lot of machines to a new system.
Nothing cutting edge, no new products, just some migration to a much better system that
would allow us to control the machines smoothly.
The trick is that these machines were serving a really big number of customers,
and we couldn’t just stop them.
On top of that, the code running on the machines was in some cases over 10 years old,
and of course we didn’t have a single person with knowledge about the entire thing.</p>
<p>I don’t really want to talk about the technical side of the project because it’s boring:
you perform a few tests with machines not serving production traffic,
then you start to slowly roll out the migration to machines serving customers,
you’ll then learn of a few scenarios you missed because
the scale of the traffic you tested with wasn’t big enough
(a good problem to have?),
and then you figure out how to deal with that,
incorporate the learnings into the product code,
and resume the migration.</p>
<p>What I want to focus on, though, is my experience leading this migration,
and why I think this was a very pleasant experience.</p>
<p>Given the nature of the problem,
it was somewhat easy to convince management that
there really wasn’t a timeline we could realistically follow.
Machine migrations take time, you need to do it under heavy control to
avoid cases where too many machines are brought offline and you’re unable to serve your traffic.
Sometimes, you’ll also need to replace certain machines,
because they could have some underlying issues that you just can’t
manually investigate due to the scale (this was a migration of over 20,000 machines).
We also had 2 people dedicated on this,
and we knew we’d hit some roadblocks along the way,
but we didn’t really know which ones.
Nobody knew 100% of the code running on the machines,
as it was a really big codebase.</p>
<p>Even though management was ok without some kind of “hard” deadline,
we still aimed at moving things as fast as possible.
Some prep work would need to be done before the migration,
and since we’re talking about a Big N company here,
you can imagine all kinds of internal systems we had to mess around with to make this possible.</p>
<p>Here’s the really nice part:
I felt like the other person working on this project was completely in sync with me.
They didn’t know everything involved in the migration
(I handled a lot of human coordination transparently for them),
but they knew enough about the code running on the machines to
understand all the prep work we’d need.
They knew about some edge cases we’d need to cover.
When talking about the initial steps for this project,
things went so well and we finished discussing so quickly that I
even became worried they hadn’t understood some of the things we’d need to do.
I let them roll with it, though,
and when reviewing the code patches I was really surprised:
in the few minutes we talked about the prep stuff,
we’d synced about the approaches to take,
and then we just started doing it.
Contrast this to either of the following two (way more common) scenarios I encountered in the past:
someone needs a lot of help to understand parts of the code or the system,
and needs some mentoring to figure things out;
or someone holds some strong beliefs about the way things should be done,
and an unproductive discussion arises about how to do things,
when pretty much every alternative proposed is good enough and there is just no right answer.</p>
<p>When we found a roadblock, syncing up was also so easy and smooth,
because nobody held any strong opinions on which approach to take.
We knew which alternatives would solve the problem,
and we favored gettings things done rather than finding some mythical
perfect solution.
Reporting on the progress of the migration was also pretty smooth.
We kept a simple spreadsheet with a bunch of information of things that were already done,
and things that still needed to be done,
and both of us dedicated a few minutes every day to update things there.
If we were to track those using the company’s task management system,
it would’ve taken ages to update information the same way we did with the spreadsheet.
There were days we didn’t even talk at all,
because we were aware of what needed to be done,
and we knew what things were already done just by looking at a somewhat simple table.
No standups required.</p>
<p>Overall, working with this person felt like I was just working with an extension of myself.
I say this in the good sense.
Working with people all in the same mindset might skew projects towards some
below average solutions and not bring enough diversity to the table.
This wasn’t the case here.
We both thought about different approaches to solve the problems we faced,
but we also knew well how to evaluate them,
and knew when they were good enough and discussing more wouldn’t help much.</p>
<p>After we finished this project,
I realized that I had become addicted to the way this project was going.
It was just so pleasant that I didn’t want it to end.
To this day, I still regularly think about this project,
and wonder if I’ll ever be part of or help build a team full of people like this.
Is this how high performing teams work?
Is this how working at very productive companies feels like?
If it is, I want more of it.</p>

    </div></div>]]>
            </description>
            <link>https://sidhion.com/blog/posts/zero-overhead-communication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623360</guid>
            <pubDate>Wed, 24 Jun 2020 02:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prescriptions Are a Dead End]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23623306">thread link</a>) | @gbasin
<br/>
June 23, 2020 | https://garybasin.com/prescriptions-are-a-dead-end/ | <a href="https://web.archive.org/web/*/https://garybasin.com/prescriptions-are-a-dead-end/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1988">
		<div>
		<!-- .entry-header -->

		<div>
			
<p>I love to read about how great people accomplish great things. It’s similar to getting advice — I’m left with a high. I imagine that if I can follow the instructions, then I too will accomplish what they have. It’s a logical and tantalizing idea: follow the prescription, get the reward. In practice, it tends to fall short.</p>



<p>Kapil Gupta and Naval did a <a href="https://youtu.be/sBtuqpNZwio" data-rel="lightbox-video-0">great interview</a> where they touched on this pitfall. </p>



<p>The catch is, to achieve something truly remarkable, you have to do something new. It’s practically in the definition. Copying others can help you learn a domain. Imitation is good practice. But to do something new — to create art — you inevitably have to write your own script.</p>



<p>I expanded on these thoughts in a <a href="https://twitter.com/garybasin/status/1274859897826488322?s=19">Twitter thread here</a>, also touching on how prescriptions can act like false Gods.</p>
					</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</div>

	
</article></div>]]>
            </description>
            <link>https://garybasin.com/prescriptions-are-a-dead-end/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623306</guid>
            <pubDate>Wed, 24 Jun 2020 02:30:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why People Become Internet Trolls]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23623017">thread link</a>) | @rchaudhary
<br/>
June 23, 2020 | https://dradambell.com/why-people-become-internet-trolls/ | <a href="https://web.archive.org/web/*/https://dradambell.com/why-people-become-internet-trolls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="1c056633" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<p><span>When I was 10 years old and first introduced to the miracle of the World Wide Web, chat rooms were by far my favorite thing. Talking to random people from all over the world about anything you want — what more could a bored kid ask for?</span></p>

<p><span>I’d spend hours in these chat rooms, asking my new friends how old they were, what they had for breakfast, and how much pocket money their parents gave them. I shared this experience with a friend who didn’t own a computer and had never used the internet.</span></p>

<p><span>He asked if he could have a go. “Sure!” I said, excited for him to experience the wonder of the internet. Without hesitation, he began typing the worst insults and swear words he could think of. Horrified I had awoken a dark and malevolent force, and fearing he had forever ruined my friendship with strawberry88, I shut down my computer and didn’t invite him to play on the internet again.</span></p>

<p><span>To this day, I remain baffled by this behavior. When faced with the endless possibility of the internet, my childhood friend’s first impulse was to verbally abuse strangers. This innocent 10-year-old had become a troll.</span></p>

<h4 id="02ff"><span>Wretched impulses</span></h4>

<p><span>John Oliver once described the internet as a “dark carnival of humanity’s most wretched impulses.” Was it these wretched impulses that had consumed my childhood friend?</span></p>

<p><span>The act of trolling is best described from where its name&nbsp;<a href="https://www.etymonline.com/word/troll" target="_blank" rel="noreferrer noopener">may have come from</a>&nbsp;— the form of fishing where a lure is dangled off a moving boat.</span></p>

<figure><span><img src="https://miro.medium.com/max/3200/0*f3HYZpvSGgrg1vHC" alt=""></span></figure>

<p><span>The troll casts his bait (the offensive comment) into the water of the internet. An unsuspecting fish (the targeted user) sees the bait and feels compelled to go for it (the defensive comment). Soon they are hooked and reeled in without mercy. But unlike trolling for fish, which delivers a clear and edible reward, the troll’s reward isn’t entirely clear.</span></p>

<p><span>Trolling is a hard concept to define because there are various methods of trolling and differing degrees of depravity. Some are abhorrent, like “suicide baiting,” where trolls encourage vulnerable users to kill themselves, or “RIP trolls” who vandalize Facebook memorial sites of the recently deceased. But others, like “griefers” who play online games in a manner that purposely disrupts other players, are more of a nuisance.</span></p>

<p><span>Who are these trolls, and what drives them?</span></p>

<h4 id="4d5f"><span>The dark tetrad</span></h4>

<p><span>Psychologists have found&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886914000324" target="_blank" rel="noreferrer noopener">a link between trollish behavior</a>&nbsp;and a set of personality traits called “the dark tetrad.”</span></p>

<figure><span><img src="https://miro.medium.com/max/2974/0*sAMy6kU4hSsBKYQy" alt=""></span></figure>

<p><span>The dark tetrad comprises:</span></p>

<ul>
<li><span>Sadism — deriving pleasure from another’s pain</span></li>
<li><span>Psychopathy — impairment of empathy and remorse</span></li>
<li><span>Machiavellianism — manipulative and emotionally “cold” behavior</span></li>
<li><span>Narcissism — self-involvement and a need for admiration</span></li>
</ul>

<p><span><a href="https://www.academia.edu/41115419/Loneliness_moderates_the_relationship_between_Dark_Tetrad_personality_traits_and_internet_trolling" target="_blank" rel="noreferrer noopener">In a recent study</a>, trolls were positively correlated with three of the four dark tetrad traits, with narcissism being the odd one out. They found trolls were manipulative, lacked empathy, and enjoyed hurting others. Men exhibited these traits more commonly than women and were more likely to troll. Loneliness was also a significant predictor of trolling when in the presence of Machiavellianism or psychopathy.</span></p>

<p><span>Most studies on trolls use internet surveys to collect data, which is questionable: Can we really trust trolls to complete surveys accurately? This method may also not account for those who don’t consider their behavior to be trollish or those unaware of their trollish behavior.</span></p>

<p><span>In the book&nbsp;<a href="https://www.hardiegrant.com/au/publishing/bookfinder/book/troll-hunting-by-ginger-gorman/9781743794357" target="_blank" rel="noreferrer noopener"><em>Troll Hunting</em></a>, journalist Ginger Gorman spends years building relationships with the worst trolls she can find in an attempt to understand what drives them. To her surprise, trolls were not uneducated lost souls who lacked social skills and lived in their mother’s basement. These trolls had partners, children, and full-time jobs. They showed leadership skills as commanders of&nbsp;<a href="https://www.theguardian.com/books/2019/jan/28/it-was-like-being-skinned-alive-ginger-gorman-goes-hunting-for-trolls" target="_blank" rel="noreferrer noopener">large trolling syndicates</a>. They were socially intelligent and able to pinpoint users’ weaknesses with vicious precision. But what was driving them?</span></p>

<p><span>Many saw trolling as a hobby — something that entertained or amused. Some were ideologically driven, attacking anybody opposing their belief system. But both types of troll tended to engage users that threatened their beliefs or sense of self.</span></p>

<p><span>Some of the trolls exhibited dark tetrad traits. In these trolls, she saw a common pattern — excessive internet use with little to no parental supervision between the ages of 11 and 16. But some trolls didn’t fit the dark tetrad personality type. These trolls were pleasant, friendly, and compassionate when she engaged them directly. How could these trolls behave so antisocially online yet appear to function as typical members of society offline?</span></p>

<h4 id="7160"><span>Empathy deficit</span></h4>

<p><span>The human brain was primarily designed for face-to-face interaction. It hasn’t had time to adapt to communication over the internet.</span></p>

<p><span>Nonverbal communication — facial expressions, gestures, and voice qualities — provides the precise social context of an interaction. While the claim that 93% of communication being nonverbal is&nbsp;<a href="https://cornerstone.lib.mnsu.edu/cgi/viewcontent.cgi?article=1000&amp;context=ctamj" target="_blank" rel="noreferrer noopener">inaccurate</a>, it is a crucial part of how we communicate. Words alone can only go so far. Even if we used the full&nbsp;<a href="https://englishlive.ef.com/blog/language-lab/many-words-english-language/" target="_blank" rel="noreferrer noopener">170,000 words</a>&nbsp;currently in use in the English language, we still couldn’t convey what an expressive face or a suggestive voice could.</span></p>

<p><span>Most internet discussions only allow words. Well, words and emojis and GIFs and stickers and all the other substitutes created to replace nonverbal cues.</span></p>

<p><span>If you say something mean to my face and make me cry, you will probably start to feel uncomfortable. Unless you’re especially mean or psychopathic, my distress will trigger an empathic response and lead you to have mercy. If you tweet something mean and make me cry, no amount of emojis can convey what the sight of a grown man weeping can. If there is no social cue to elicit an empathic response, you might continue your tirade of meanness.</span></p>

<p><span>The absence of nonverbal feedback leads to an “empathy deficit,” and this is what sociopaths suffer from.</span></p>

<h4 id="53a2"><span>Toxic disinhibition</span></h4>

<p><span>When you combine an empathy deficit with the anonymity of online interactions, you get “<a href="https://en.wikipedia.org/wiki/Online_disinhibition_effect" target="_blank" rel="noreferrer noopener">toxic disinhibition</a>,” which is more than just the phenomenon of being rude to bar staff after that fifth shot of tequila.</span></p>

<p><span>Anonymity can lead to “<a href="https://en.wikipedia.org/wiki/Deindividuation" target="_blank" rel="noreferrer noopener">deindividuation</a>” — a temporary loss of one’s identity leading to behavior incongruent with one’s character. It explains why groups of civilized people can engage in riots. It also explains trolling. If a lack of nonverbal cues is what makes us detached from the other person’s suffering, deindividuation is what makes us detached from the awareness of our misconduct.</span></p>

<p><span>True anonymity offers protection from real-world social repercussions, and this has profound effects on human behavior. The image-based bulletin board 4chan, where registration isn’t possible and users remain anonymous, has been&nbsp;<a href="https://theconversation.com/4chan-raids-how-one-dark-corner-of-the-internet-is-spreading-its-shadows-68394" target="_blank" rel="noreferrer noopener">infamous as a troll incubator</a>&nbsp;for this reason. When there are no real-world consequences to your actions, it liberates you from a lifetime of societally inhibited behaviors. Society discourages antisocial behavior and encourages prosocial behavior, so it is antisocial behavior that seeks liberation.</span></p>

<p><span>We are a delicate balance between prosocial humans and antisocial primates. When society cannot enforce prosocial human behavior, the antisocial primate may come back into power. And thus the troll is created.</span></p>

<h4 id="f597"><span>Troll begets troll</span></h4>

<p><span>Researchers at Stanford and Cornell universities performed a large-scale data analysis on&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5791909/" target="_blank" rel="noreferrer noopener">over 16 million comments</a>&nbsp;from December 2012 to August 2013 on CNN.com and found 1 in 4 posts flagged as abusive were from users with no prior record of trollish behavior. This suggests trolling isn’t always a full-time occupation and that one may indulge sporadically.</span></p>

<p><span>The researchers could predict the likelihood of trolling based on the nature of other comments in the discussion and the user’s mood. If earlier comments were negative, the propensity to troll was greater. Like a bad mood, trolling is contagious. All it takes is another user’s trollish comment and a bad mood to create an environment in which our inner troll can blossom.</span></p>

<h4 id="b294"><span>The inner troll</span></h4>

<p><span>It is easier to view trolls as bad apples than see them as something inside all of us, waiting for the right environment to let loose. But when we condemn trolls as inherently malicious individuals, we limit our understanding of what may drive these behaviors.</span></p>

<p><span>While RIP trolls or suicide baiters are likely to be dark tetrad personality types who use the internet as an outlet to indulge their darkest impulses, lesser trolls may be part-time participants who will engage with the right combination of a bad day and a noxious environment. We have only begun to scratch the surface in our understanding of trolls, but the evidence we have suggests we may all be vulnerable.</span></p>

<p><span>Is anyone exempt from toxic disinhibition? Few respond to a tweet that offends them with “Excuse me, I really don’t want to be rude, but if I may could I please respectfully disagree with your opinion for these reasons …” While an offhand remark may appear harmless, the less empathic our online interactions collectively become, the greater risk we all stand of becoming trolls. The gentle ripples of impolite tweets may become crashing toxic waves of disinhibited hatred.</span></p>

<p><span>Trolling isn’t black and white, it is somewhere in the grey between prosocial human and antisocial primate. Ultimately, our propensity for antisocial behavior in the physical world is likely to predict similar online behavior.</span></p>

<h4 id="9272"><span>How can we manage our inner trolls?</span></h4>

<p><span>The more accountable we are for our behavior, the less potential we have of becoming trolls. Employing&nbsp;<a href="https://scholarspace.manoa.hawaii.edu/bitstream/10125/41373/1/paper0224.pdf" target="_blank" rel="noreferrer noopener">less anonymity may help</a>, but this raises privacy concerns for many. Anonymity can also be a good thing. Benign disinhibition — the friendly sibling of toxic disinhibition — is where users freely discuss their deepest insecurities and concerns with other users. This can be very therapeutic and shouldn’t be discouraged. But by using anonymity only where it is necessary, we reduce the likelihood of toxic disinhibition.</span></p>

<p><span>Empathy doesn’t come …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dradambell.com/why-people-become-internet-trolls/">https://dradambell.com/why-people-become-internet-trolls/</a></em></p>]]>
            </description>
            <link>https://dradambell.com/why-people-become-internet-trolls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623017</guid>
            <pubDate>Wed, 24 Jun 2020 01:51:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated Landscape Painting in the Style of Bob Ross [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23622971">thread link</a>) | @kmstout
<br/>
June 23, 2020 | https://uwspace.uwaterloo.ca/bitstream/handle/10012/2761/AlexKalaidjianThesis.pdf | <a href="https://web.archive.org/web/*/https://uwspace.uwaterloo.ca/bitstream/handle/10012/2761/AlexKalaidjianThesis.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://uwspace.uwaterloo.ca/bitstream/handle/10012/2761/AlexKalaidjianThesis.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622971</guid>
            <pubDate>Wed, 24 Jun 2020 01:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk and the Value of Localism-What We Should Do Instead of Going to Mars]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23622970">thread link</a>) | @richeyrw
<br/>
June 23, 2020 | https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/ | <a href="https://web.archive.org/web/*/https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><span>If you prefer to listen rather than read, this blog is available as a podcast <a href="https://itunes.apple.com/us/podcast/we-are-not-saved/id1175122428">here</a>. Or if you want to listen to just this post:</span></p>

<p><span><a href="https://traffic.libsyn.com/secure/wearenotsaved/Elon_Musk_and_the_Value_of_Localism_or_What_We_Should_Do_Instead_of_Going_to_Mars.mp3">Or download the MP3</a></span></p>
<hr>
<p><strong>I.</strong></p>
<p><span>Elon Musk has asserted, accurately in my opinion, that unless humanity becomes a two planet species that we are eventually doomed (absent some greater power out there which saves us, which could </span><a href="https://wearenotsaved.com/2016/08/27/fermis-paradox-as-a-proof-of-the-existence-of-god/"><span>include either God or aliens</span></a><span>). And he has built an entire company, SpaceX, around making sure that this happens (the two planet part, not the doomed part). As I mentioned, I think this is an accurate view of how things will </span><em><span>eventually</span></em><span> work out, but it’s also </span><a href="https://wearenotsaved.com/2017/01/14/how-to-save-humanity/"><span>incredibly costly and difficult</span></a><span>. Is it possible that in the short term we can achieve most of the benefits of a Mars colony with significantly less money and effort? Might this be yet another 80/20 situation, where 80% of the benefits can be achieved for only 20% of the resources?</span></p>
<p><span>In order to answer that question, it would help to get deeper into Musk’s thinking and reasoning behind his push for a self-sustaining outpost on Mars. To quote from the man himself:</span></p>
<p><em><span>I think there are really two fundamental paths. History is going to bifurcate along two directions. One path is we stay on Earth forever, and then there will be some eventual extinction event — I don’t have an immediate doomsday prophecy … just that there will be some doomsday event. The alternative is to become a space-faring civilization and a multiplanet species.</span></em></p>
<p><span>While I agree with Musk that having a colony on Mars will prevent some doomsday scenarios, I’m not sure I agree with his implied assertion that it will prevent all of them, that if we choose the alternative of being a space-faring civilization, that it forever closes off the other alternative of doomsday events. To see why that might be, we need to get into a discussion of what potential doomsdays await us, or to use the more common term, what existential risks, or x-risks are we likely to face?</span></p>
<p><span>If you read my round up of the </span><a href="https://wearenotsaved.com/2020/06/05/books-i-finished-in-may/"><span>books I finished in May</span></a><span>, one of my reviews covered </span><a href="https://www.amazon.com/Precipice-Existential-Risk-Future-Humanity/dp/0316484911"><span>Toby Ord’s book, The Precipice: Existential Risk and the Future of Humanity</span></a><span> which was entirely dedicated to a discussion of this very subject. For those who don’t remember, Ord produced a chart showing what he thought the relative odds were for various potential x-risks. Which I’ll once again include.</span></p>
<table>
<tbody>
<tr>
<td><strong>Existential catastrophe via</strong></td>
<td><strong>Chance within the next 100 years</strong></td>
</tr>
<tr>
<td><span>Asteroid/comet Impact</span></td>
<td><span>~1 in 1,000,000</span></td>
</tr>
<tr>
<td><span>Supervolcanic eruption</span></td>
<td><span>~1 in 10,000</span></td>
</tr>
<tr>
<td><span>Stellar explosion</span></td>
<td><span>~1 in 1,000,000</span></td>
</tr>
<tr>
<td><em><span>Total natural risk</span></em></td>
<td><span>~1 in 10,000</span></td>
</tr>
<tr>
<td><span>Nuclear war</span></td>
<td><span>~1 in 1,000</span></td>
</tr>
<tr>
<td><span>Climate change</span></td>
<td><span>~1 in 1,000</span></td>
</tr>
<tr>
<td><span>Other environmental damage</span></td>
<td><span>~1 in 1,000</span></td>
</tr>
<tr>
<td><span>Naturally arising pandemics</span></td>
<td><span>~1 in 10,000</span></td>
</tr>
<tr>
<td><span>Engineered pandemics</span></td>
<td><span>~1 in 30</span></td>
</tr>
<tr>
<td><span>Unaligned artificial intelligence</span></td>
<td><span>~1 in 10</span></td>
</tr>
<tr>
<td><span>Unforeseen anthropogenic risks</span></td>
<td><span>~1 in 30</span></td>
</tr>
<tr>
<td><span>Other anthropogenic risks</span></td>
<td><span>~1 in 50</span></td>
</tr>
<tr>
<td><em><span>Total anthropogenic risks</span></em></td>
<td><span>~1 in 6</span></td>
</tr>
<tr>
<td><em><span>Total existential risk</span></em></td>
<td><span>~1 in 6</span></td>
</tr>
</tbody>
</table>
<p><span>Reviewing this list, which x-risks are entirely avoided by having a self-sustaining colony on Mars? The one it most clearly prevents is the asteroid/comet impact, and indeed that’s the one everyone thinks of. I assume it would also be perfect for protecting humanity from a supervolcanic eruption and a naturally arising pandemic. I’m less clear on how well it would do at protecting humanity from a stellar explosion, but I’m happy to toss that in as well. But you can instantly see the problem with this list, particularly if you read my book review. These are all naturally arising risks, and as a category they’re all far less likely (at least according to Ord) to be the cause of our extinction. What we really need to be hedging against is the category of anthropogenic risks. And it’s not at all clear that a Mars colony is the cheapest or even the best way to do that.&nbsp;</span></p>
<p><span>The risks we’re trying to prevent are often grouped into the general category of “having all of our eggs in one basket”. But just as we don’t want all of our eggs in the “basket” of Earth, I don’t think we want all of our risk mitigation to end up in the “basket” of a Mars colony. To relate it to my </span><a href="https://wearenotsaved.com/2020/06/13/dont-make-the-second-mistake/"><span>last post</span></a><span>, this is very similar to my caution against a situation where we all make the same mistake. Only this time rather than a bunch of independent actors all deciding to independently take the same ultimately catastrophic action, here the consensus happens a little more formally, with massive time and effort put into one great effort. One of the reasons this effort seems safe is that it’s designed to reduce risk, but that doesn’t really matter, it could still be a mistake. A potential mistake which is aggravated by focusing on only one subset of potential x-risks, naturally occurring ones, and this one method for dealing with them, a Mars Colony. In other words in attempting to avoid making a mistake we risk making a potentially different mistake. The mistake of having too narrow a focus. Surviving the next few hundred years is a hugely complicated problem (one I hope to bring greater attention to by </span><a href="https://wearenotsaved.com/2019/12/14/i-finally-figure-out-what-i-want-to-be-when-i-grow-up-an-eschatologist/"><span>expanding the definition and discipline of eschatology</span></a><span>). And the mistakes we could make are legion. But, in my opinion, focusing on a Mars Colony, as the best and first step in preventing those mistakes </span><em><span>turns out to be a mistake itself</span></em><span>.&nbsp;</span></p>
<p><strong>II.</strong></p>
<p><span>At this point it’s only natural to ask what I would recommend instead. And as a matter of fact I do have a proposal:</span></p>
<p><span>Imagine that instead of going to Mars that we built a couple of large underground bunkers, something similar to NORAD. In fact we might even be able to repurpose, or piggyback on NORAD for one of them. Ideally the other one would be built at roughly the opposite spot on the globe from the first. So maybe something in Australia. Now imagine that you paid a bunch of people to live there for two years. You would of course supply them with everything they needed, entertainment, food, power, etc. In fact as far as food and power you’d want to have as robust a supply of those on hand as you could manage. But as part of it they would be </span><em><span>completely cut off from everything</span></em><span> for those two years, no internet connection, no traffic in our out, no inbound communication of any sort. You would of course have plenty of ways to guarantee the necessities like air, food and water. Basically you make this place as self-contained and robust as possible.&nbsp;</span></p>
<p><span>When I say “a bunch of people”, you’d want as many as you could afford, but in essence you want to have enough people in either bunker that </span><em><span>by themselves</span></em><span> they could regenerate humanity if, after some unthinkable tragedy, they were all that remained. The minimum number I’ve seen is 160, with 500 seeming closer to ideal. Also if you wanted to get fancy/clever you could have 80% of the population be female, with lots of frozen sperm. Also it should go without saying that these people should be of prime child bearing age, with a fertility test before they went in.</span></p>
<p><span>Every year you’d alternate which of the bunkers was emptied and refilled with new people. This ensures that neither bunker is empty at the same time and that the period where even one bunker was empty would only be a week or so.</span></p>
<p><span>Beyond all of the foregoing, I’m sure there are many other things one could think of to increase the robustness of these bunkers, but I think you get the idea. So now let’s turn to Ord’s list of x-risks and compare my bunker idea to Musks’ Mars plan.&nbsp;</span></p>
<p><span>All natural risks: Mars is definitely superior, but two things to note, first, even if you combine all possible natural risks together, they only have a 1 in 10,000 chance, according to Ord, of causing human extinction in the next century. I agree that you shouldn’t build a bunker just to protect against natural x-risks, but it also seems like a weak reason to go to Mars as well. Second, don’t underestimate the value the bunker provides even if Ord is wrong and the next giant catastrophe we have to worry about is natural. There are a whole host of disasters one could imagine where having the bunker system I described would be a huge advantage. But, even if it’s not, we’re mostly worried about anthropogenic risks, and it’s when we turn to considering them that the bunker system starts to look like the superior option.&nbsp;</span></p>
<p><span>Taking each anthropogenic risk in turn:</span></p>
<p><span>Nuclear war- Bunkers as a protection against nuclear weapons is an idea almost as old as the weapons themselves. Having more of them, and making sure they’re constantly occupied, could only increase their protective value. Also Ord only gives nuclear war a 1 in 1000 chance of being the cause of our extinction, mostly because it would be so hard to </span><strong>completely</strong><span> wipe humanity out. The bunker system would make that even harder. A Mars colony doesn’t seem necessarily any better as a protection against this risk, for one thing how does it end up escaping this hypothetical war? And if it doesn’t, it would seem to be very vulnerable to attack. At least as vulnerable as a hardened bunker and perhaps far more so given the precariousness of any Martian existence.</span></p>
<p><span>Climate Change- I don’t deny the reality of climate change, but I have a hard time picturing how it wipes out every last human. Most people when pressed on this issue say that the disruption it causes leads to Nuclear War, which just takes us back to the last item.&nbsp;</span></p>
<p><span>Environmental Damage- Similar to climate change, also if we’re too dumb to prevent these sorts of slow moving extinction events on Earth, what makes you think we’ll do any better on Mars?&nbsp;</span></p>
<p><span>Engineered Pandemics- The danger of the engineered pandemic is the malevolent actor behind it, preventing this x-risk means keeping this malevolent actor from infecting everyone, in such a way that we all die. Here the advantage Mars has is its great distance from Earth, meaning you’d have to figure out a way to have a simultaneous outbreak on both planets. The advantage the bunker has is that it’s whole function is to avoid x-risks. Meaning anything that might protect from this sort of threat is not only allowed but expected. The kind of equipment necessary to synthesis a disease? Not allowed in the …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/">https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/</a></em></p>]]>
            </description>
            <link>https://wearenotsaved.com/2020/06/24/elon-musk-and-the-value-of-localism-or-what-we-should-do-instead-of-going-to-mars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622970</guid>
            <pubDate>Wed, 24 Jun 2020 01:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OneDev 3.2 – Self-Hosted All-in-One DevOps Platform]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23622908">thread link</a>) | @robinshen
<br/>
June 23, 2020 | https://www.onedev.io/v3.2.0 | <a href="https://web.archive.org/web/*/https://www.onedev.io/v3.2.0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Got bunch of feedbacks from OneDev users and this major version ships some of them. Thank you for getting OneDev even better! </p>
<h3>OpenID connect integration</h3>
<p>With OIDC integration, it is now possible to login via GitHub, Gmail, Okta, or any other OIDC compliant identify providers. Besides authentication, this integration can also authorize users with appropriate permissions based on group claims. Check usage scenarios <a href="https://code.onedev.io/projects/onedev-manual/blob/3.2/pages/okta-sso.md">here</a> and <a href="https://code.onedev.io/projects/onedev-manual/blob/3.2/pages/github-sso.md">here</a> for details</p>
<p><span>
      <a href="https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/25c1c/oidc.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="OpenID connect integration" title="OpenID connect integration" src="https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/fcda8/oidc.png" srcset="https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/12f09/oidc.png 148w,
https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/e4a3f/oidc.png 295w,
https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/fcda8/oidc.png 590w,
https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/efc66/oidc.png 885w,
https://www.onedev.io/static/84ad90df8004dc795401cee246cbd5d5/25c1c/oidc.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Clone with custom credential in CI job</h3>
<p>For security reason, OneDev clones source in CI job with a default credential which does not have permission to access other projects, or push back commits. To get additional permissions, one has to define custom job secrets accessible to certain branches, and use these secrets in CI job to clone source. Refer to usage scenario <a href="https://code.onedev.io/projects/onedev-manual/blob/3.2/pages/clone-submodules-via-ssh.md">here</a> for example setup</p>
<p><span>
      <a href="https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/25c1c/custom-clone-credential.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="clone with custom credential" title="clone with custom credential" src="https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/fcda8/custom-clone-credential.png" srcset="https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/12f09/custom-clone-credential.png 148w,
https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/e4a3f/custom-clone-credential.png 295w,
https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/fcda8/custom-clone-credential.png 590w,
https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/efc66/custom-clone-credential.png 885w,
https://www.onedev.io/static/d907b034a8cc26e7ec0c7703a54baee6/25c1c/custom-clone-credential.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Reworked pull request workflow</h3>
<p>Instead of merging pull requests automatically after getting all approvals from revewers, assignee has to merge them manually to ensure responsibilities, as well as crafting commit message if necessary. Also merged commits from target branch will be excluded when displaying incremental pull request changes to make it easier to understand</p>
<p><span>
      <a href="https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/25c1c/pull-request-assignees.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="pull request assignees" title="pull request assignees" src="https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/fcda8/pull-request-assignees.png" srcset="https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/12f09/pull-request-assignees.png 148w,
https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/e4a3f/pull-request-assignees.png 295w,
https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/fcda8/pull-request-assignees.png 590w,
https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/efc66/pull-request-assignees.png 885w,
https://www.onedev.io/static/753c01e3ffb458db46a31ef3f7a4d77f/25c1c/pull-request-assignees.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Show review and build status in pull request list</h3>
<p>To help users getting a better glance of what happened in pull requests, review and build status now get displayed in pull request list</p>
<p><span>
      <a href="https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/25c1c/pull-request-list.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="pull request list status" title="pull request list status" src="https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/fcda8/pull-request-list.png" srcset="https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/12f09/pull-request-list.png 148w,
https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/e4a3f/pull-request-list.png 295w,
https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/fcda8/pull-request-list.png 590w,
https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/efc66/pull-request-list.png 885w,
https://www.onedev.io/static/7a7d35672c53b7c09c14953278093fc8/25c1c/pull-request-list.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>UI to compose complex sorts</h3>
<p>Previously one has to use <em>order by</em> clause to sort issues, builds and pull requests. Now this task is easier via a smart sort widget. Just select fields to order, and OneDev will compose the query automatically </p>
<p><img src="https://www.onedev.io/5818d4a1f54412d7be2f8292473840a0/orderby.gif" alt="order by widget"></p>
<h3>Publish and render markdown in build</h3>
<p>Besides ordinary artifacts and html reports, one can also publish markdown in a build process and get it rendered in a separate build tab to make important information explicit</p>
<p><span>
      <a href="https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/25c1c/markdown-report.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="markdown report" title="markdown report" src="https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/fcda8/markdown-report.png" srcset="https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/12f09/markdown-report.png 148w,
https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/e4a3f/markdown-report.png 295w,
https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/fcda8/markdown-report.png 590w,
https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/efc66/markdown-report.png 885w,
https://www.onedev.io/static/aba8d21dfc88d7be1f6ba80bfac9a2c6/25c1c/markdown-report.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Rule to transit inactive issues to specified state</h3>
<p>Sometimes it is desirable to transit inactive issues to a certain state, for instance to mark it idle and notify relevant participants, and finally close it if no one cares about it. Now this is possible via a custom state transition rule</p>
<p><span>
      <a href="https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/25c1c/inactive-transition.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="idle-issue-transition" title="idle-issue-transition" src="https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/fcda8/inactive-transition.png" srcset="https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/12f09/inactive-transition.png 148w,
https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/e4a3f/inactive-transition.png 295w,
https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/fcda8/inactive-transition.png 590w,
https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/efc66/inactive-transition.png 885w,
https://www.onedev.io/static/fe1e5fa89bb15733cae5977fd7cae3fa/25c1c/inactive-transition.png 1047w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3><a href="https://code.onedev.io/projects/onedev-server/builds/797/fixed-issues?query=%22State%22+is+%22Released%22+order+by+%22Type%22+asc+and+%22Priority%22+desc">And many more</a></h3></section></div>]]>
            </description>
            <link>https://www.onedev.io/v3.2.0</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622908</guid>
            <pubDate>Wed, 24 Jun 2020 01:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur and the Temptation of the App Store]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23622783">thread link</a>) | @GavinAnderegg
<br/>
June 23, 2020 | https://anderegg.ca/2020/06/23/big-sur-and-the-temptation-of-the-app-store | <a href="https://web.archive.org/web/*/https://anderegg.ca/2020/06/23/big-sur-and-the-temptation-of-the-app-store">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<section id="content">
				<article>
					
					<h3>June 23, 2020</h3>
					<p>At WWDC this year, Apple announced their switch to “<a href="https://www.apple.com/newsroom/2020/06/apple-announces-mac-transition-to-apple-silicon/">Apple silicon</a>” for Mac hardware. This had been heavily rumoured for years, and there was a lot of discussion about it. Some worried that Apple would use the transition as an excuse to lock down app delivery further — perhaps only allowing apps to be installed from the Mac App Store.</p>

<p>This didn’t happen. You can still choose to <a href="https://support.apple.com/en-ca/HT202491">install apps from identified developers</a>, or <a href="https://support.apple.com/en-ca/guide/mac-help/mh40616/mac">install an unsigned app</a> if you trust it. But something else happened instead: Apple announced that iOS apps are coming directly to the Mac. Specifically, Macs that use their new chips and run the upcoming version of macOS, <a href="https://www.apple.com/macos/big-sur-preview/">Big Sur</a>.</p>

<p>I’m worried about this. Here’s my thinking.</p>

<p>There are an order of magnitude more <a href="https://www.theverge.com/2019/1/29/18202736/apple-devices-ios-earnings-q1-2019">iOS devices</a> than <a href="https://techcrunch.com/2018/10/30/there-are-now-100-million-macs-in-use/">macOS devices</a> in use. I couldn’t find hard numbers, but I’d bet there are similarly way more iOS developers than macOS developers. This makes sense, as iOS is the newer and more exciting platform. Apple focused a lot of attention on iOS since introducing the iPhone, and the Mac became a bit more of a workhorse over time. People still develop apps for macOS, but there have been fewer over time. Also, many new Mac apps are developed with cross-platform tools like Electron.</p>

<p>That Electron piece is interesting. Slack is the poster-child for Electron on desktops, <a href="https://twitter.com/slackhq/status/931599784137363459">but their iOS app is native</a>. Personally, I think the Slack experience on iOS is nicer. With iOS apps coming to Big Sur, it’s not crazy to imagine Slack eventually shipping their iOS app on the Mac instead of the Electron version. Other developers with both macOS and iOS software would be in a similar position.</p>

<p>The thing about those iOS apps is that they have to come from the App Store, even on the Mac. Of course, developers can always choose to use the iOS version as a starting point and build a custom <a href="https://swiftwithmajid.com/2019/10/23/reusing-swiftui-views-across-apple-platforms/">SwiftUI</a>/<a href="https://developer.apple.com/mac-catalyst/">Mac Catalyst</a> version specifically for macOS – but going the easier route will be pretty tempting. Writing something once and publishing for multiple platforms saves on developer time, which is why Slack uses Electron for their desktop apps. It makes sense to put more resources into the version with the bigger audience as well, which probably why I prefer Slack on my iPad.</p>

<p>The worst part is that Apple seems to be doing this themselves. Just before WWDC this year, <a href="https://www.macrumors.com/2020/06/15/apple-developer-app-for-mac/">Apple released a Mac version of their Developer app</a>. It’s a Mac Catalyst port of the iPad version, and <a href="https://pilky.me/apples-developer-app/">it really doesn’t feel at home on macOS</a>. Is it better than nothing? Sure. It just <a href="https://daringfireball.net/linked/2020/06/17/developer-app-for-mac">doesn’t fill me with hope</a> for the quality of Mac apps going forward.</p>

<p>Before WWDC, I wasn’t worried about the ARM transition meaning the Mac would go App Store only. Sure, Apple would love for more apps to be in the App Store for security (and monetary) reasons, but the platform needs apps that the App Store can’t support. The whole “iOS apps on the Mac” wasn’t something I saw coming, though. Apple won’t enforce this change, but I worry that developing a “good enough” iOS app for the Mac might become the future of the platform.</p>

<hr>

<p><a href="https://news.ycombinator.com/item?id=23622783">Discuss on Hacker News</a></p>

				</article>
			</section>
		</div></div>]]>
            </description>
            <link>https://anderegg.ca/2020/06/23/big-sur-and-the-temptation-of-the-app-store</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622783</guid>
            <pubDate>Wed, 24 Jun 2020 01:19:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bastions on demand in an AWS VPC]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 31 (<a href="https://news.ycombinator.com/item?id=23622728">thread link</a>) | @mooreds
<br/>
June 23, 2020 | https://theconsultingcto.com/posts/bastions-on-demand/ | <a href="https://web.archive.org/web/*/https://theconsultingcto.com/posts/bastions-on-demand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Any time you have a VPC, you’ll likely need some way to gain access to the resources within the VPC from your local box. Typically, the way to do that is to run a bastion (or jumpbox) which you and your team can SSH into. The downside is that you are exposing an entry point into your network that is accessible by multiple people and running 24x7. And depending on how you manage permissions, you may not be able to restrict access to the box via IAM. Obviously, this is not ideal.</p>
<p>Luckily, we have <a href="https://aws.amazon.com/fargate/">Fargate</a>.</p>
<p>With Fargate, we no longer need to maintain permanent bastion instances—we can create bastions when needed and tear them down when no longer in use. We can lock down bastion instances to an individual user both in terms of SSH keys and IP address. And we can restrict access via IAM to both the API used to manage bastions and to which SSH keys are used to log into an instance.</p>
<p>All in all, we save on infrastructure spend while reducing our attack surface.</p>
<p>Throughout this guide, I’ll be referencing the code from my <a href="https://github.com/jdhollis/bastions-on-demand/"><code>bastions-on-demand</code></a> repo. If you want to skip the explanation, just clone it and follow the directions in the <a href="https://github.com/jdhollis/bastions-on-demand/blob/master/README.md">README.md</a> to get started.</p>
<p>If you run into any trouble, <a href="https://github.com/jdhollis/bastions-on-demand/issues/new/choose">create an issue</a>, and I’ll respond as best I can.</p>
<p>Otherwise, buckle up. This is going to be a bit in-depth.</p>
<h2 id="architecture">Architecture</h2>
<p>There are two key components to bastions on demand—<a href="https://github.com/jdhollis/bastions-on-demand/tree/master/bastion">the infrastructure for managing the bastion image</a> and <a href="https://github.com/jdhollis/bastions-on-demand/tree/master/service">the bastion service itself</a>.</p>
<p>The <a href="#container-infrastructure">container infrastructure</a> consists of an <a href="https://aws.amazon.com/ecr/">ECR</a> repository, a Docker container, an IAM role for fetching a user’s public keys, and scripts for building and pushing images. Typically, I share this infrastructure across multiple services because the requirements don’t vary much. But if a team wants complete service isolation or needs to customize their bastion image, it’s trivial to make that work.</p>
<p>The <a href="#bastion-service">bastion service</a> consists of an <a href="https://aws.amazon.com/ecs/">ECS</a> task, a task role that enables access to any required resources, an API to create and destroy bastion instances, and a set of scripts to make it easy for team members to do just that. The bastion service module should be included in any service that needs bastions—keep it in the service’s repository for ease of access and deploy it alongside the parent service.</p>
<p>Naturally, all of this infrastructure is managed with <a href="https://www.terraform.io/">Terraform</a>.</p>
<p>I owe a debt of gratitude to the following authors as they provided valuable examples that helped me develop this approach:</p>
<ul>
<li><a href="https://ig.nore.me/2018/07/serverless-bastions-on-demand/">Serverless Bastions on Demand</a> &amp; <a href="https://github.com/ArjenSchwarz/workshop-fargate-bastion">ArjenSchwarz/workshop-fargate-bastion</a></li>
<li><a href="https://github.com/alex0ptr/fargate-bastion">alex0ptr/fargate-bastion</a></li>
<li><a href="https://cloudonaut.io/manage-aws-ec2-ssh-access-with-iam/">Manage AWS EC2 SSH access with IAM</a></li>
</ul>
<p>While I recommend using multiple AWS accounts for security and isolation, in this guide, I’m going to use a single account so that we can focus on the essentials. If there’s interest, I will address how to modify this approach for use with multiple accounts in a separate guide. Everything in this guide assumes you’re using the <code>default</code> profile, but you can override via the <code>AWS_PROFILE</code> environment variable.</p>
<p>I’m also deliberately not using <a href="https://www.terraform.io/docs/state/remote.html">Terraform remote state</a> in this guide to make it easier for you to try out my code. If you’re going to use this in a live account, you absolutely should use remote state—insert your own backend configuration where appropriate. And if you don’t have a remote backend, have a look at my <a href="https://github.com/jdhollis/remote-state">remote-state</a> repo for an example of how to set one up on S3 with DynamoDB and KMS.</p>
<p>Now, let’s get started.</p>
<h2 id="initial-setup">Initial Setup</h2>
<p>If you haven’t already, create a role for API Gateway logging:</p>
<section>
<div><pre><code data-lang="hcl"><span>data</span> <span>"aws_iam_policy_document" "assume_role"</span> {
  <span>statement</span> {
    actions <span>=</span> [<span>"sts:AssumeRole"</span>]

    <span>principals</span> {
      identifiers <span>=</span> [<span>"apigateway.amazonaws.com"</span>]
      type        <span>=</span> <span>"Service"</span>
    }
  }
}

<span>data</span> <span>"aws_iam_policy_document" "logger"</span> {
  <span>statement</span> {
    actions <span>=</span> [
      <span>"logs:CreateLogGroup"</span>,
      <span>"logs:CreateLogStream"</span>,
      <span>"logs:DescribeLogGroups"</span>,
      <span>"logs:DescribeLogStreams"</span>,
      <span>"logs:FilterLogEvents"</span>,
      <span>"logs:GetLogEvents"</span>,
      <span>"logs:PutLogEvents"</span>,
    ]

    resources <span>=</span> [<span>"*"</span>]
  }
}

<span>resource</span> <span>"aws_iam_role" "logger"</span> {
  name               <span>=</span> <span>"api-gateway-cloudwatch-logger"</span>
  assume_role_policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>assume_role</span>.<span>json</span>
}

<span>resource</span> <span>"aws_iam_role_policy" "logger"</span> {
  name   <span>=</span> <span>"api-gateway-cloudwatch-logger"</span>
  policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>logger</span>.<span>json</span>
  role   <span>=</span> <span>aws_iam_role</span>.<span>logger</span>.<span>name</span>
}

<span>resource</span> <span>"aws_api_gateway_account" "global"</span> {
  cloudwatch_role_arn <span>=</span> <span>aws_iam_role</span>.<span>logger</span>.<span>arn</span>
}
</code></pre></div>  
</section>
<p>Logging API Gateway access is a good idea in general. Unfortunately, this is a global account setting, so use with caution. API Gateway has a lot of stateful corners. I typically manage this logger in a separate repository since it’s shared across all services running in an account.</p>
<h2 id="container-infrastructure">Container Infrastructure</h2>
<p>Creating the ECR repository is straightforward:</p>
<section>
<div><pre><code data-lang="hcl"><span>resource</span> <span>"aws_ecr_repository" "bastion"</span> {
  name <span>=</span> <span>"bastion"</span>
}
</code></pre></div>  
</section>
<p>Next we need to create a role that can fetch a user’s public keys.</p>
<section>
<div><pre><code data-lang="hcl"><span>data</span> <span>"aws_caller_identity" "env"</span> {}<span>
</span><span>
</span><span># …
</span><span></span>
<span>data</span> <span>"aws_iam_policy_document" "assume_role"</span> {
  <span>statement</span> {
    actions <span>=</span> [<span>"sts:AssumeRole"</span>]

    <span>principals</span> {
      identifiers <span>=</span> [<span>"arn:aws:iam::${data.aws_caller_identity.env.account_id}:root"</span>]
      type        <span>=</span> <span>"AWS"</span>
    }
  }
}

<span>data</span> <span>"aws_iam_policy_document" "public_key_fetcher"</span> {
  <span>statement</span> {
    actions <span>=</span> [
      <span>"iam:GetSSHPublicKey"</span>,
      <span>"iam:ListSSHPublicKeys"</span>,
    ]

    resources <span>=</span> [<span>"arn:aws:iam::${data.aws_caller_identity.env.account_id}:user/*"</span>]
  }
}

<span>resource</span> <span>"aws_iam_role" "public_key_fetcher"</span> {
  name               <span>=</span> <span>"public-key-fetcher"</span>
  assume_role_policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>assume_role</span>.<span>json</span>
}

<span>resource</span> <span>"aws_iam_role_policy" "public_key_fetcher"</span> {
  name   <span>=</span> <span>"public-key-fetcher"</span>
  policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>public_key_fetcher</span>.<span>json</span>
  role   <span>=</span> <span>aws_iam_role</span>.<span>public_key_fetcher</span>.<span>id</span>
}
</code></pre></div>  
</section>
<p>This role will be used by the bastion instance to fetch a user’s keys when the user attempts to SSH into the instance, as we’ll see below.</p>
<h3 id="dockerfile">Dockerfile</h3>
<p>Creating the container image is fairly straightforward. We start with <a href="https://alpinelinux.org/">Alpine Linux</a> because it’s small and security-oriented and add the scripts we’ll need to start <code>sshd</code> and handle login.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>FROM</span><span> alpine:3.11</span><span>
</span><span>
</span><span></span><span>WORKDIR</span><span> /root</span><span>
</span><span>
</span><span></span><span>ADD</span> fetch_authorized_keys.sh /usr/local/bin/fetch_authorized_keys.sh<span>
</span><span></span><span>ADD</span> entrypoint.sh /usr/local/bin/entrypoint.sh<span>
</span></code></pre></div>  
</section>
<p>Next, we install dependencies including the <a href="https://aws.amazon.com/cli/">AWS CLI</a>. If you typically need any other packages for your bastion, add ‘em to the list. (It still bugs me that AWS doesn’t provide checksums for its CLI bundle. Oh well.)</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Installing dependencies..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  apk --no-cache <span>\
</span><span></span>    add <span>\
</span><span></span>      bash <span>\
</span><span></span>      curl <span>\
</span><span></span>      openssh <span>\
</span><span></span>      python <span>\
</span><span></span>      tini <span>\
</span><span></span>  <span>&amp;&amp;</span> <span>\
</span><span></span>  <span>echo</span> <span>"Installing AWS CLI..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  wget https://s3.amazonaws.com/aws-cli/awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  unzip awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  rm awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws <span>&amp;&amp;</span> <span>\
</span><span></span>  rm -R awscli-bundle <span>&amp;&amp;</span> <span>\
</span><span></span>  /usr/local/bin/aws --version<span>
</span></code></pre></div>  
</section>
<p>Now we need a user to log in as.</p>
<p>You could use <code>root</code>. I have in the past with small teams that needed the additional flexibility. But if you’re providing an image to teams that are independent of whoever handles security, you don’t necessarily want people making changes to the bastion that could open up holes in your network.</p>
<p>Instead, we create a user named <code>ops</code> and unlock the account for login.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Creating user \"ops\"..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  adduser ops --disabled-password<span>
</span><span>
</span><span></span><span>RUN</span> <span>echo</span> <span>"Unlocking \"ops\"..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s/ops:!:/ops:*:/g"</span> /etc/shadow<span>
</span></code></pre></div>  
</section>
<p>With that out of the way, we now configure <code>sshd</code>.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Configuring sshd..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#AuthorizedKeysCommand none:AuthorizedKeysCommand /usr/local/bin/fetch_authorized_keys.sh:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#AuthorizedKeysCommandUser nobody:AuthorizedKeysCommandUser nobody:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#GatewayPorts no:GatewayPorts yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#PasswordAuthentication yes:PasswordAuthentication no:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#PermitTunnel no:PermitTunnel yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:AllowTcpForwarding no:AllowTcpForwarding yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:AuthorizedKeysFile .ssh/authorized_keys:AuthorizedKeysFile none:g"</span> /etc/ssh/sshd_config<span>
</span></code></pre></div>  
</section>
<p>We’re configuring <code>sshd</code> to do a few different things.</p>
<p>We’re setting the <code>AuthorizedKeysCommand</code> to use <code>fetch_authorized_keys.sh</code>, and we’re disabling both password logins and the ability to use an <code>AuthorizedKeysFile</code> on the instance. The intention here is to make it possible to only use the logic in <code>fetch_authorized_keys.sh</code> to authenticate the user.</p>
<p>We’re also setting <code>sshd</code> up for proxying.</p>
<p>Finally, we configure the <code>ENTRYPOINT</code>:</p>
<section>
<div><pre><code data-lang="dockerfile"><span>ENTRYPOINT</span> [ <span>"/sbin/tini"</span>, <span>"--"</span> ]<span>
</span><span></span><span>CMD</span> [ <span>"/bin/sh"</span>, <span>"/usr/local/bin/entrypoint.sh"</span> ]<span>
</span></code></pre></div>  
</section>
<p>The only interesting thing here is we’re using <a href="https://github.com/krallin/tini"><code>tini</code></a>. If you’re interested in why, check out <a href="https://github.com/krallin/tini/issues/8">this GitHub issue</a>.</p>
<h3 id="entrypointsh">entrypoint.sh</h3>
<p>On container startup, the first thing we need to do is generate host keys.</p>
<section>
  
</section>
<p>Then we export the global environment which includes the AWS credentials injected into the container, the role for fetching SSH keys, and the user name of the person for whom this bastion instance is intended.</p>
<section>
<div><pre><code data-lang="sh"><span>echo</span> <span>"export AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=</span><span>$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI</span><span>"</span> &gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_DEFAULT_REGION=</span><span>$AWS_DEFAULT_REGION</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_EXECUTION_ENV=</span><span>$AWS_EXECUTION_ENV</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_REGION=</span><span>$AWS_REGION</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export ECS_CONTAINER_METADATA_URI=</span><span>$ECS_CONTAINER_METADATA_URI</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export ASSUME_ROLE_FOR_AUTHORIZED_KEYS=</span><span>$ASSUME_ROLE_FOR_AUTHORIZED_KEYS</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export USER_NAME=</span><span>$USER_NAME</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
</code></pre></div>  
</section>
<p>Because <code>fet…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theconsultingcto.com/posts/bastions-on-demand/">https://theconsultingcto.com/posts/bastions-on-demand/</a></em></p>]]>
            </description>
            <link>https://theconsultingcto.com/posts/bastions-on-demand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622728</guid>
            <pubDate>Wed, 24 Jun 2020 01:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How effective communication can be achieved in a digital work environment]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23622241">thread link</a>) | @markshepard
<br/>
June 23, 2020 | https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/ | <a href="https://web.archive.org/web/*/https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1668">
	

	




	<div>
		
<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-1024x692.png" alt="" width="412" height="278" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-1024x692.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-300x203.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-768x519.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3.png 1384w" sizes="(max-width: 412px) 100vw, 412px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>A multi-billion dollar company. A winning presidential
campaign. A happy marriage. What do these three things have in common? The
foundation of success in each is effective communication. </p>



<p>Effective communication has the power to amass riches and
make history. With it, governments have been transformed, along with the lives
of billions of people. With it, enterprises like Amazon, Apple, and Alibaba
rise from obscurity. </p>



<p>It’s no wonder that all successful businesses need strong
communication infrastructures in order to grow and prosper. But that’s not what
this article is about. The topic of communication is so vast that you can get a
Ph.D. in it. This article would have to be a book, maybe three, to properly
cover the topic. </p>



<p>What this article focuses on is a single concept that, if
grasped, can give your organization a big push in the right direction towards
effective communication in a digital work environment. The concept is this:</p>



<blockquote><p><em>Chat is like a river; Wiki is like a dam.</em></p></blockquote>



<h2>River? Dam?</h2>



<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-1024x734.png" alt="" width="357" height="255" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-1024x734.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-300x215.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-768x551.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5.png 1109w" sizes="(max-width: 357px) 100vw, 357px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>A while ago, we published an article that dives into
synchronous and asynchronous communication. Synchronous communication is communication
that happens in real time. It’s a company meeting on Zoom or an active chat
room. Asynchronous communication is communication that happens… not in real
time. It’s that email you send to a client which you know you won’t get a
response to until weeks later, or notes on that Zoom company meeting posted to
an online bulletin. Both are important because different types of information
do best in different formats. </p>



<p>Synchronous communication is fast, immediate, brief. Information
flows like a river — as it does in a chat. This format is best for times of uncertainty
and/or urgency. It’s good for exploring ideas together, having discussions to
make decisions, and addressing crisis situations. </p>



<p>Asynchronous communication is slower, usually more
considered and voluminous. Information gathers like a dam — as it does in a
Wiki. This format is best for adding context to real time communication after
it has happened, putting together detailed information, and explaining complex
concepts.</p>



<p>When used properly, synchronous and asynchronous
communication together form effective communication.</p>



<h2>Increasing Effective Communication in Your Organization</h2>



<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp.png" alt="" width="364" height="291" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp.png 1000w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp-300x240.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp-768x615.png 768w" sizes="(max-width: 364px) 100vw, 364px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>When synchronous and asynchronous communication are used
appropriately in an organization, communication is at its best and collaboration
is smooth and easy. In a digital work environment, some of the most common modes
of communication are chat and Wiki. As mentioned before, chat facilitates
synchronous communication and a Wiki facilitates asynchronous communication. </p>



<p>Increasing effective communication in your organization is
as simple as having both chat and a Wiki available to everyone and then making
it clear which medium to use for each type of interaction. In other words, the
roadmap to achieving effective communication in a digital work environment is:</p>



<ol><li><strong>Provide
the right tools</strong> – Have chat and a Wiki available to all team members and
get everyone accustomed to using them. </li><li><strong>Ensure the tools are used correctly</strong> – Do
this by training management on the concept of synchronous and asynchronous
communication (or “<em>Chat is like a river;
Wiki is like a dam.”) </em>and have them lead by example so the rest of your organization
follows.</li></ol>



<h2>Chat and Wiki in AirSend</h2>



<p>In AirSend, each channel has both a chat section and a Wiki
section. The chat is great for quickly discussing new developments, exchanging links
to articles or tidbits of information, and scheduling calls for further
discussion. The Wiki is great for storing, sharing, and collaborating on more detailed,
complex items.</p>



<p>Having the chat and Wiki together in one place makes communication
much smoother and more efficient than the previous model of emailing back and
forth with document links or attachments. </p>



<figure><video controls="" src="https://www.airsend.io/blog/wp-content/uploads/2020/05/Chat-Wiki-GIF-S10.mp4"></video></figure>



<h2>Finding Balance </h2>



<p>Effective communication is powerful, and one of the key factors of communicating effectively in a digital environment is finding the balance between synchronous and asynchronous communication. When used together correctly, chat and Wiki can streamline the communication process for clutter-free collaboration, resulting in increased productivity. </p>



<p>Just remember: <em>Chat is like a river; Wiki is like a dam.</em></p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622241</guid>
            <pubDate>Wed, 24 Jun 2020 00:18:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feedback Canvas: A tool for receiving honest feedback from your team]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23621805">thread link</a>) | @stanete
<br/>
June 23, 2020 | https://stanete.com/feedback-canvas | <a href="https://web.archive.org/web/*/https://stanete.com/feedback-canvas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  

  

  <p>You can read this post in Spanish <a href="https://stanete.com/es/feedback-canvas">here</a>.</p>

<p>My first <em>Feedback Canvas</em> was tough. I remember the days after. I was angry, upset, sad, happy and excited at the same time. It made me realize that I was not used to receive <em>honest feedback</em>. It affected me so much that I didn’t really know what to do afterwards nor what actions to take.</p>

<p>4 months later I had my second <em>Feedback Canvas</em>. This time it felt different. The tool didn’t change. I did. In these 4 months, I learned how to receive feedback and what strategy to follow afterwards. I’m going to share with you my own experience, the feedback my team has given me and the actions I am taking based on that feedback.</p>

<h2 id="why-does-it-work">Why does it work?</h2>

<p>As with any feedback, it only works if the people know you. And I mean, really know you. <a href="https://youtu.be/qg0_FinB6EE">The real you</a>. If they don’t, their feedback is going to be shallow, empty, and useless.</p>

<p>It works because feedback is <a href="https://www.youtube.com/watch?v=iUaHMOWRYpI">a constant</a> in your day to day. If requesting feedback is not a habit, this tool doesn’t work.</p>

<p>It works because you are the one who is requesting the feedback. You are being proactive. You are humble and you understand that you have so much to improve. Because <a href="https://www.youtube.com/watch?v=0iGYp3vTabU">you want to improve</a>, right?</p>

<p><img src="https://stanete.com/images/good_team.png" alt=""></p>

<h2 id="what-is-feedback-canvas">What is <em>Feedback Canvas</em>?</h2>

<p>Basically, you put a bunch of people together in a room to give you the most honest feedback of your life. Hopefully. It’s kind of an <a href="https://www.youtube.com/watch?v=sNAbnnHKZFE">Intervention</a> but requested by yourself. The format is very similar to a retrospective but you are the subject the team is analyzing.</p>

<p>In Creditas, where I currently work, we give feedback grouped in 7 categories, which happen to be the principles on which the company’s culture is built on: <strong>Love our customers</strong>, <strong>Brutally Honest</strong>, <strong>Learn Fast</strong>, <strong>Thinking like Owners</strong>, <strong>True Team Players</strong>, <strong>Technical Knowledge</strong>, <strong>Warriors and Play to Win</strong>. We also take into account what is expected from somebody in your role. <a href="https://www.patkua.com/blog/the-definition-of-a-tech-lead/">Here</a> you can find an example of what is expected from a Tech Lead. Change all this to what suits your context.</p>

<h2 id="how-to-organize-one">How to organize one?</h2>

<p>Pick <strong>between 5 and 9 people</strong> you are closest to in your day to day. The people you really work with. If you are leading a team, as I am, they must be there. Your manager should be there too.</p>

<p>Pick a facilitator who will take care of scheduling the event, keeping everything on track, maintaining the structure, explaining how the <em>Feedback Canvas</em> works and moderating the session. Can be anyone.</p>

<p>The session takes <strong>between one and two hours</strong> depending on the frequency you do it and the amount of people you invited. Use a countdown timer and keep it visible.</p>

<p>If you want to say something before starting, do it. I thanked everybody for coming and asked them to be as honest and direct as possible without any filter.</p>

<h3 id="fill-the-retrospective-board">Fill the retrospective board</h3>

<p>This is the main activity of the <em>Feedback Canvas</em>. It takes around 20 minutes and its purpose is to receive detailed feedback from each member of your team and make a detailed and conscious self assessment.</p>

<p>I know retrospectives can be <a href="https://www.funretrospectives.com/">organized in different ways</a> depending on the objective. However, in a <em>Feedback Canvas</em>, the structure needs to be kept as simple as possible. Divide the board in 3 columns: <strong>Good points</strong>, <strong>Points to improve</strong> and <strong>Improvement actions</strong>. Everybody, your team and yourself, writes their points privately and fill the board when they are finished. Some teams fill the board one point at the time. Try both and see what works better. There are a couple of rules to follow:</p>

<ol>
  <li>
    <p>For every <strong>point to improve</strong> anybody writes, they should also write an <strong>improvement action</strong> as a suggestion. Sometimes it is difficult to find an <strong>improvement action</strong>. When that happens, the feedback can be discussed and you can find something together.</p>
  </li>
  <li>
    <p>Write the feedback using the first person: <em>David, you are cool</em> instead of <em>David is cool</em>. The feedback should be direct.</p>
  </li>
</ol>

<p>You can use <a href="https://www.groupmap.com/">Groupmap</a> or <a href="https://miro.com/">Miro</a> but any other online board will do. A Google Sheet would do too.</p>

<p><img src="https://stanete.com/images/scrum_board.png" alt=""></p>

<h3 id="give-a-score-for-each-feedback-category">Give a score for each feedback category</h3>

<p>It takes around 5 minutes and its purpose is to compare how you perceive yourself with how others perceive you. The activity is very similar to a <a href="https://es.wikipedia.org/wiki/Planning_poker">Planning Poker</a>. Disclarimer. I’m just using Planning Poker as an example, please don’t use it as a real tool in your day to day. Please. Please.</p>

<p>Give a note from 1 to 5 for every feedback category. We in Creditas use the company principles and values. You should adapt it to your own context.</p>

<p>3 means <strong>as expected</strong>, 1 means <strong>hugely over expected</strong> and 5 means <strong>hugely under expected</strong>. It’s rare to have a 1 and its rare to have a 5. Yourself and your team vote privately at the same time and then share it with everybody to compare the results.</p>

<p>You can use <a href="https://www.mentimeter.com/">Mentimeter</a> but I’m sure a Google Sheet would do too.</p>

<h3 id="compare-the-score">Compare the score</h3>

<p>Show the results of the category score and compare your results with the ones from your team. This score should reflect what you and your team just put in the retrospective board.</p>



<p>At the left you can see my own assessment. At the right you can see the weighted average of the scores my team gave me. I thought I did what was expected but I could’ve done more. However, my team thinks a little bit more of myself than I do.</p>

<h3 id="read-the-retrospective-board">Read the retrospective board</h3>

<p>Start with the second and third column. Every <strong>Point to improve</strong> is read together with its related <strong>Improvement action</strong>. You read your own out loud first. Then, the facilitator reads the rest. The main reason of organizing a <em>Feedback Canvas</em> are the <strong>Points to improve</strong>. In your day to day it is easier to receive feedback about the good stuff. This is the what will make you improve.</p>

<p>Don’t agree or disagree with the feedback. It’s not the place nor the time to do that. You can ask for clarifications or examples though. You can also ask for who wrote the feedback. The feedback is not anonymous. This whole thing would be just a charade if it were.</p>

<p>Finish with the <strong>Good points</strong>. You read out loud your own assessment first. Then, the facilitator reads the rest.</p>

<p>Here is an excerpt from my own retrospective board. Just the <strong>Points to improve</strong> and related <strong>Improvement actions</strong>. If you are interested, and I know you are, you can find the whole thing <a href="https://stanete.com/images/feedback_canvas_retrospective_board.jpeg">here</a>. Disclaimer! You’ll find English, Portuguese and Spanish in there. Use Google Translate.</p>

<!-- Retrospective board -->
<table>
  <colgroup>
    <col width="50%">
    <col width="50%">
  </colgroup>
  <thead>
    <tr>
      <th>Points to improve</th>
      <th>Actions to improve</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <em>HONEST</em> - Sometimes I have the feeling of hurting other people. I’m
        also not good at comforting others.
      </td>
      <td>
        <em>HONEST</em> - I need to be more careful of how I express what I have to
        say. Being brutally honest needs to also take into account how others
        perceive the feedback.
      </td>
    </tr>
    <tr>
      <td>
        <em>OWNER</em> - Sometimes you don’t have control over your passion. That
        generates anxiety and frustration that are not friends of a leadership
        role.
      </td>
      <td>
        <em>OWNER</em> - I’m going to recommend you some articles and a couple of books
        that talk about emotional intelligence.
      </td>
    </tr>
    <tr>
      <td>
        <em>TEAM</em> - You are constantly improving but you don’t make others improve
        as much as you do.
      </td>
      <td>
        <em>TEAM</em> - Let others take the lead in technical discoveries. Help others
        give a talk in a meetup.
      </td>
    </tr>
  </tbody>
</table>
<!-- -->

<h2 id="actions-to-take-afterwards">Actions to take afterwards</h2>

<p>Although nothing should come as a <a href="https://www.youtube.com/watch?v=u5CVsCnxyXg">surprise</a>, this is a lot to process. You can see that everyone kind of agrees on the same points. And probably you do too.</p>

<p>The first step is to start thinking about what everybody just said and read the results of your <em>Feedback Canvas</em> a few days later.</p>

<p>The second step is take the results to your <em>Team Lead</em> or <em>Manager</em> and talk about them. You need to talk about the results with somebody that can help you find the right strategy and the areas of action. If you don’t have a <em>Manager</em>, talk with a mentor. Or talk with a friend. You need help.</p>

<p><img src="https://stanete.com/images/conversation.png" alt=""></p>

<p>So I went and talked with my <em>Team Lead</em> and with my <em>Engineering Manager</em> and they helped me identify 4 main areas of action:</p>

<ol>
  <li>
    <p>Give others more space to improve and help them grow. The sooner I have somebody in my team that can take my place the sooner I can move forward. This will be my main focus.</p>
  </li>
  <li>
    <p>Keep improving soft skills and emotional intelligence. I identified that my soft skills get worse when I’m hungry, angry, lonely and tired. This is normal for everybody but it can be more drastic in people that need to be more self aware, like me. I’ll read a couple of books on this topic too. This will take time.</p>
  </li>
  <li>
    <p>Make others have the same enthusiasm as I do. It can’t be done directly. Enthusiasm and passion are contagious up to a point. I need to understand better which are the strengths, weaknesses and motivations of the people in my team. Then I can focus on creating the proper environment for enthusiasm to appear spontaneously. This will require patience.</p>
  </li>
  <li>
    <p>Give honest and true feedback to every member of the team. That won’t be possible if I don’t have a <a href="https://www.youtube.com/watch?v=01ZCnCXpG4A">real connection</a> with the members of my team. Building true relationships is hard. I’m starting an initiative called <em>Honest coffee</em> that’ll allow me to get to know better the people I work with. To be honest, my <em>Feedback Canvas</em> shouldn’ve been harsher.This will improve my feedback’s quality and the quality of the feedback my team gives me.</p>
  </li>
</ol>

<p>You should organize another <em>Feedback Canvas</em> session some months later. At least 3 months later. Not earlier. You need time to work on the feedback you just received. On the next session your team will mention that you have improved. And, ideally, they will focus their feedback on other topics.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p><em>Feedback Canvas</em> is a tool and, as any tool, you need to adapt it to your context. <a href="https://medium.com/@reinaldocamargo/feedback-canvas-2-0-2f2040aa4a49">Here</a> you can find another post explaining it differently and <a href="https://medium.com/@reinaldocamargo/a-feedback-canvas-real-implementation-6fb8e65b0253">here</a> you can find a different implementation of it.</p>

<p>The first sessions will be messy and you won’t see its the value immediately. Probably. Most companies are not used to give honest and direct feedback. A <em>Feedback Canvas</em> session may seem as a lot to begin with. But you need to start somewhere.</p>

<p>Huge thanks to <a href="https://undraw.co/">undraw.com</a> for the illustrations. You can subscribe to my newsletter <strong>W…</strong></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stanete.com/feedback-canvas">https://stanete.com/feedback-canvas</a></em></p>]]>
            </description>
            <link>https://stanete.com/feedback-canvas</link>
            <guid isPermaLink="false">hacker-news-small-sites-23621805</guid>
            <pubDate>Tue, 23 Jun 2020 23:33:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU Guix: Reproducible research articles, from source code to PDF]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23621655">thread link</a>) | @snicker7
<br/>
June 23, 2020 | https://hpc.guix.info/blog/2020/06/reproducible-research-articles-from-source-code-to-pdf/ | <a href="https://web.archive.org/web/*/https://hpc.guix.info/blog/2020/06/reproducible-research-articles-from-source-code-to-pdf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Early this year, <a href="https://rescience.github.io/">ReScience</a>, which is
concerned with publishing replications (successful or not) of
previously-published articles, organized the <a href="https://rescience.github.io/ten-years/">Ten Years Reproducibility
Challenge</a>.  The idea is simple:
pick a paper of yours that is at least ten years old, and try to
replicate its results.  The first difficulty is usually to get the
source code of the software used to produce the results and to get that
code to build and run.  This challenge helped highlight
<a href="https://en.wikipedia.org/wiki/Replication_crisis">again</a> ways in which
research practices can and must be improved.  We took it as an
opportunity to devise new practices and tools to ensure reproducibility
and provenance tracking for articles, end-to-end: from source code to
PDF.</p><p>Over fifty people <a href="https://github.com/ReScience/ten-years/issues/1">took up on the
challenge</a>.  My
personal challenge was a paper from 2006; I <a href="https://doi.org/10.5281/zenodo.3886739">successfully reproduced its
results</a> and, more importantly,
came up with a methodology and tool set to do so:</p><blockquote><p>This article reports on the effort to reproduce the results shown in
<a href="https://hal.inria.fr/hal-00187069/en"><em>Storage Tradeoffs in a Collaborative Backup Service for Mobile
Devices</em></a>, an article published
in 2006, more than thirteen years ago.  The article presented the
design of the storage layer of such a backup service.  It included an
evaluation of the efficiency and performance of several storage
pipelines, which is the experiment we replicate here.</p><p>Additionally, this article describes a way to capture the complete
dependency graph of this article and the software and data it refers
to, making it fully reproducible, end to end.  Using
<a href="https://hal.inria.fr/hal-01161771/en">GNU&nbsp;Guix</a>, we bridge together
code that deploys the software evaluated in the paper, scripts that
run the evaluation and produce plots, and scripts that produce the
final PDF file from LaTeX source and plots.  The end result—and the
major contribution of this article—is approximately 400 lines of code
that allow Guix to rebuild the whole article <em>and the experiment it
depends on</em> with a well-specified, reproducible software environment.</p></blockquote><p><a href="https://doi.org/10.5281/zenodo.3886739">The article</a> describes the
methodology and use of Guix in some detail, explains its pratical
benefits, and compares to widespread methods and tools—Jupyter notebooks
and container images, to name the most popular ones.  The code to build
the whole software stack used in the article, to run its experiments,
produce charts, and produce the final PDF from its LaTeX code is in
<code>guix.scm</code> and <code>article/guix.scm</code> in <a href="https://gitlab.inria.fr/lcourtes-phd/edcc-2006-redone">the source
repository</a>.</p><p>The article concludes on our vision:</p><blockquote><p>We hope our work could serve as the basis of a template for
reproducible papers in the spirit of <a href="http://maneage.org/">Maneage</a>.
We are aware that, in its current form, our reproducible pipeline
requires a relatively high level of Guix expertise—although, to be
fair, it should be compared with the wide variety of programming
languages and tools conventionally used for similar purposes.  We
think that, with more experience, common build processes and idioms
could be factorized as libraries and high-level programming
constructs, making it more approachable.</p><p>[…] We look forward to a future where reproducible scientific
pipelines become commonplace.</p></blockquote><p>As Konrad Hinsen <a href="https://github.com/ReScience/submissions/issues/32#issuecomment-634149030">put
it</a>
during the review process, this is “advanced reproducibility wizardry”
and can be seen as a “proof of concept for future technology”.  Let’s
build that technology!</p></div></div>]]>
            </description>
            <link>https://hpc.guix.info/blog/2020/06/reproducible-research-articles-from-source-code-to-pdf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23621655</guid>
            <pubDate>Tue, 23 Jun 2020 23:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubectl Cheatsheet – Optimized for Usability]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23621392">thread link</a>) | @BlueMatador
<br/>
June 23, 2020 | https://www.bluematador.com/learn/kubectl-cheatsheet | <a href="https://web.archive.org/web/*/https://www.bluematador.com/learn/kubectl-cheatsheet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="cluster-management" data-widget-type="cell" data-x="3" data-w="9">

<div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<p><span id="hs_cos_wrapper_module_1588089319145250_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><h2>Cluster Management</h2>
<p>Display endpoint information about the master and services in the cluster</p>
<pre><code>kubectl cluster-info</code></pre>

<p>Display the Kubernetes version running on the client and server</p>
<pre><code>kubectl version</code></pre>

<p>Get the configuration of the cluster</p>
<pre><code>kubectl config view</code></pre>

<p>List the API resources that are available</p>
<pre><code>kubectl api-resources</code></pre>

<p>List the API versions that are available</p>
<pre><code>kubectl api-versions</code></pre>

<p>List everything</p>
<pre><code>kubectl get all --all-namespaces</code></pre>

<h2>Daemonsets</h2>
<p><strong>Shortcode = ds</strong></p>
<p>List one or more daemonsets</p>
<pre><code>kubectl get daemonset</code></pre>

<p>Edit and update the definition of one or more daemonset</p>
<pre><code>kubectl edit daemonset &lt;daemonset_name&gt;</code></pre>

<p>Delete a daemonset</p>
<pre><code>kubectl delete daemonset &lt;daemonset_name&gt;</code></pre>

<p>Create a new daemonset</p>
<pre><code>kubectl create daemonset &lt;daemonset_name&gt;</code></pre>

<p>Manage the rollout of a daemonset</p>
<pre><code>kubectl rollout daemonset</code></pre>

<p>Display the detailed state of daemonsets within a namespace</p>
<pre><code>kubectl describe ds &lt;daemonset_name&gt; -n &lt;namespace_name&gt;</code></pre>

<h2>Deployments</h2>
<p><strong>Shortcode = deploy</strong></p>
<p>List one or more deployments</p>
<pre><code>kubectl get deployment</code></pre>

<p>Display the detailed state of one or more deployments</p>
<pre><code>kubectl describe deployment &lt;deployment_name&gt;</code></pre>

<p>Edit and update the definition of one or more deployment on the server</p>
<pre><code>kubectl edit deployment &lt;deployment_name&gt;</code></pre>

<p>Create one a new deployment</p>
<pre><code>kubectl create deployment &lt;deployment_name&gt;</code></pre>

<p>Delete deployments</p>
<pre><code>kubectl delete deployment &lt;deployment_name&gt;</code></pre>

<p>See the rollout status of a deployment</p>
<pre><code>kubectl rollout status deployment &lt;deployment_name&gt;</code></pre>

<h2>Events</h2>
<p><strong>Shortcode = ev</strong></p>
<p>List recent events for all resources in the system</p>
<pre><code>kubectl get events</code></pre>

<p>List Warnings only</p>
<pre><code>kubectl get events --field-selector type=Warning</code></pre>

<p>List events but exclude Pod events</p>
<pre><code>kubectl get events --field-selector involvedObject.kind!=Pod</code></pre>

<p>Pull events for a single node with a specific name</p>
<pre><code>kubectl get events --field-selector involvedObject.kind=Node, involvedObject.name=&lt;node_name&gt;</code></pre>

<p>Filter out normal events from a list of events</p>
<pre><code>kubectl get events --field-selector type!=Normal</code></pre>

<h2>Logs</h2>
<p>Print the logs for a pod</p>
<pre><code>kubectl logs &lt;pod_name&gt;</code></pre>

<p>Print the logs for the last hour for a pod</p>
<pre><code>kubectl logs --since=1h &lt;pod_name&gt;</code></pre>

<p>Get the most recent 20 lines of logs</p>
<pre><code>kubectl logs --tail=20 &lt;pod_name&gt;</code></pre>

<p>Get logs from a service and optionally select which container</p>
<pre><code>kubectl logs -f &lt;service_name&gt; [-c &lt;$container&gt;]</code></pre>

<p>Print the logs for a pod and follow new logs</p>
<pre><code>kubectl logs -f &lt;pod_name&gt;</code></pre>

<p>Print the logs for a container in a pod</p>
<pre><code>kubectl logs -c &lt;container_name&gt; &lt;pod_name&gt;</code></pre>

<p>Output the logs for a pod into a file named ‘pod.log’</p>
<pre><code>kubectl logs &lt;pod_name&gt; pod.log</code></pre>

<p>View the logs for a previously failed pod</p>
<pre><code>kubectl logs --previous &lt;pod_name&gt;</code></pre>

<p>For logs we also recommend using a tool developed by Johan Haleby called Kubetail. This is a bash script that will allow you to get logs from multiple pods simultaneously. You can learn more about it at its <a href="https://github.com/johanhaleby/kubetail">Github repository.</a> Here are some sample commands using Kubetail.</p>

<p>Get logs for all pods named with pod_prefix</p>
<pre><code>kubetail &lt;pod_prefix&gt;</code></pre>

<p>Include the most recent 5 minutes of logs</p>
<pre><code>kubetail &lt;pod_prefix&gt; -s 5m</code></pre>

<h2>Manifest Files&nbsp;</h2>
<p>Another option for modifying objects is through Manifest Files. We highly recommend using this method. It is done by using yaml files with all the necessary options for objects configured. We have our yaml files stored in a git repository, so we can track changes and streamline changes.</p>

<p>Apply a configuration to an object by filename or stdin. Overrides the existing configuration.</p>
<pre><code>kubectl apply -f manifest_file.yaml</code></pre>

<p>Create objects</p>
<pre><code>kubectl create -f manifest_file.yaml</code></pre>

<p>Create objects in all manifest files in a directory</p>
<pre><code>kubectl create -f ./dir</code></pre>

<p>Create objects from a URL</p>
<pre><code>kubectl create -f ‘url’</code></pre>

<p>Delete an object</p>
<pre><code>kubectl delete -f manifest_file.yaml</code></pre>

<h2>Namespaces</h2>
<p><strong>Shortcode = ns</strong></p>
<p>Create namespace &lt;name&gt;</p>
<pre><code>kubectl create namespace &lt;namespace_name&gt;</code></pre>

<p>List one or more namespaces</p>
<pre><code>kubectl get namespace &lt;namespace_name&gt;</code></pre>

<p>Display the detailed state of one or more namespace</p>
<pre><code>kubectl describe namespace &lt;namespace_name&gt;</code></pre>

<p>Delete a namespace</p>
<pre><code>kubectl delete namespace &lt;namespace_name&gt;</code></pre>

<p>Edit and update the definition of a namespace</p>
<pre><code>kubectl edit namespace &lt;namespace_name&gt;</code></pre>

<p>Display Resource (CPU/Memory/Storage) usage for a namespace</p>
<pre><code>kubectl top namespace &lt;namespace_name&gt;</code></pre>

<h2>Nodes</h2>
<p><strong>Shortcode = no</strong></p>
<p>Update the taints on one or more nodes</p>
<pre><code>kubectl taint node &lt;node_name&gt;</code></pre>

<p>List one or more nodes</p>
<pre><code>kubectl get node</code></pre>

<p>Delete a node or multiple nodes</p>
<pre><code>kubectl delete node &lt;node_name&gt;</code></pre>

<p>Display Resource usage (CPU/Memory/Storage) for nodes</p>
<pre><code>kubectl top node</code></pre>

<p>Resource allocation per node</p>
<pre><code>kubectl describe nodes | grep Allocated -A 5</code></pre>

<p>Pods running on a node</p>
<pre><code>kubectl get pods -o wide | grep &lt;node_name&gt;</code></pre>

<p>Annotate a node</p>
<pre><code>kubectl annotate node &lt;node_name&gt;</code></pre>

<p>Mark a node as unschedulable</p>
<pre><code>kubectl cordon node &lt;node_name&gt;</code></pre>

<p>Mark node as schedulable</p>
<pre><code>kubectl uncordon node &lt;node_name&gt;</code></pre>

<p>Drain a node in preparation for maintenance</p>
<pre><code>kubectl drain node &lt;node_name&gt;</code></pre>

<p>Add or update the labels of one or more nodes</p>
<pre><code>kubectl label node</code></pre>

<h2>Pods</h2>
<p><strong>Shortcode = po</strong></p>
<p>List one or more pods</p>
<pre><code>kubectl get pod</code></pre>

<p>Delete a pod</p>
<pre><code>kubectl delete pod &lt;pod_name&gt;</code></pre>

<p>Display the detailed state of a pods</p>
<pre><code>kubectl describe pod &lt;pod_name&gt;</code></pre>

<p>Create a pod</p>
<pre><code>kubectl create pod &lt;pod_name&gt;</code></pre>

<p>Execute a command against a container in a pod</p>
<pre><code>kubectl exec &lt;pod_name&gt; -c &lt;container_name&gt; &lt;command&gt;</code></pre>

<p>Get interactive shell on a a single-container pod</p>
<pre><code>kubectl exec -it &lt;pod_name&gt; /bin/sh</code></pre>

<p>Display Resource usage (CPU/Memory/Storage) for pods</p>
<pre><code>kubectl top pod</code></pre>

<p>Add or update the annotations of a pod</p>
<pre><code>kubectl annotate pod &lt;pod_name&gt; &lt;annotation&gt;</code></pre>

<p>Add or update the label of a pod</p>
<pre><code>kubectl label pod &lt;pod_name&gt;</code></pre>

<h2>Replication Controllers</h2>
<p><strong>Shortcode = rc</strong></p>
<p>List the replication controllers</p>
<pre><code>kubectl get rc</code></pre>

<p>List the replication controllers by namespace</p>
<pre><code>kubectl get rc --namespace=”&lt;namespace_name&gt;”</code></pre>

<h2>ReplicaSets</h2>
<p><strong>Shortcode = rs</strong></p>
<p>List ReplicaSets</p>
<pre><code>kubectl get replicasets</code></pre>

<p>Display the detailed state of one or more ReplicaSets</p>
<pre><code>kubectl describe replicasets &lt;replicaset_name&gt;</code></pre>

<p>Scale a ReplicaSet</p>
<pre><code>kubectl scale --replicas=[x]&nbsp;</code></pre>

<h2>Secrets</h2>
<p>Create a secret</p>
<pre><code>kubectl create secret</code></pre>

<p>List secrets</p>
<pre><code>kubectl get secrets</code></pre>

<p>List details about secrets</p>
<pre><code>kubectl describe secrets</code></pre>

<p>Delete a secret</p>
<pre><code>kubectl delete secret &lt;secret_name&gt;</code></pre>

<h2>Services</h2>
<p><strong>Shortcode = svc</strong></p>
<p>List one or more services</p>
<pre><code>kubectl get services</code></pre>

<p>Display the detailed state of a service</p>
<pre><code>kubectl describe services</code></pre>

<p>Expose a replication controller, service, deployment or pod as a new Kubernetes service</p>
<pre><code>kubectl expose deployment [deployment_name]</code></pre>

<p>Edit and update the definition of one or more services</p>
<pre><code>kubectl edit services</code></pre>

<h2>Service Accounts</h2>
<p><strong>Shortcode = sa</strong></p>
<p>List service accounts</p>
<pre><code>kubectl get serviceaccounts</code></pre>

<p>Display the detailed state of one or more service accounts</p>
<pre><code>kubectl describe serviceaccounts</code></pre>

<p>Replace a service account</p>
<pre><code>kubectl replace serviceaccount</code></pre>

<p>Delete a service account</p>
<pre><code>kubectl delete serviceaccount &lt;service_account_name&gt;</code></pre>

<h2>StatefulSet</h2>
<p><strong>Shortcode = sts</strong></p>
<p>List StatefulSet</p>
<pre><code>kubectl get statefulset</code></pre>

<p>Delete StatefulSet only (not pods)</p>
<pre><code>kubectl delete statefulset/[stateful_set_name] --cascade=false</code></pre>

<h2>Common Options</h2>
<p>In Kubectl you can specify optional flags with commands. Here are some of the most common and useful ones.</p>

<p>-o Output format. For example if you wanted to list all of the pods in ps output format with more information.</p>
<pre><code>kubectl get pods -o wide&nbsp;</code></pre>

<p>-n Shorthand for --namespace. For example, if you’d like to list all the Pods in a specific Namespace you would do this command:</p>
<pre><code>kubectl get pods --namespace=[namespace_name]</code></pre>

<pre><code>kubectl get pods -n=[namespace_name]</code></pre>

<p>-f Filename, directory, or URL to files to use to create a resource. For example when creating a pod using data in a file named newpod.json.</p>
<pre><code>kubectl create -f ./newpod.json</code></pre>

<p>-l Selector to filter on, supports ‘=’, ‘==’, and ‘!=’.</p>

<p>Help for kubectl</p>
<p>-h</p>
</span></p>

</div><!--end widget-span -->
</div><!--end row-->
</div><!--end row-wrapper -->

</div></div>]]>
            </description>
            <link>https://www.bluematador.com/learn/kubectl-cheatsheet</link>
            <guid isPermaLink="false">hacker-news-small-sites-23621392</guid>
            <pubDate>Tue, 23 Jun 2020 22:52:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Amplified – Changing the patent system for good]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23621371">thread link</a>) | @cigrainger
<br/>
June 23, 2020 | https://www.amplified.ai/blog/amplified-for-good | <a href="https://web.archive.org/web/*/https://www.amplified.ai/blog/amplified-for-good">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-f43b59689e12c26a06bb"><div><h2>Amplified's AI platform enables anyone to find expert prior art for a fraction of the time and cost</h2><p>Yesterday after three years of research and development in artificial intelligence, testing on over 1.5 million patent applications, and the contributions of nearly 600 beta users we launched the Amplified AI platform. This a paradigm shift in finding prior art that will transform patents.</p><p>The patent system is overloaded with information. Specialized patent search has become a bottleneck for the whole system and the lack of certainty in search results diverts time, money, and attention away from innovation. We have watched attorneys, inventors, and professional searchers use Amplified to change the way they interact with patents. Now we are making the Amplified platform widely available to help bring true innovations to market faster and with greater peace of mind.</p><h3>This is a paradigm shift for three reasons:</h3><ol data-rte-list="default"><li><p>Finding the vast majority of patent prior art no longer requires complicated software or specialized skills</p></li><li><p>Missing prior art due to keyword queries and human error is much more difficult</p></li><li><p>Faster and easier patent prior art frees patent and search experts to focus on harder to find information and interpreting their findings</p></li></ol><p>While many have tried to make prior art search more efficient, Amplified is the first in the world to enable better and more complete searches at a fraction of the time and cost. Compared to professional prior art searches which typically take four to 40 hours, most searches in Amplified are complete in under an hour and a rough search can be as short as a couple of minutes.</p><h2>Instead of trying to replicate human logic, we set out to complement it</h2><p>This has not been an easy journey. To be fair, we didn't think it would be. Patent search databases and automated search solutions existed well before Amplified was founded. We know because we used them all in previous lives as professional patent searchers and experienced first-hand the waste and inefficiency. The problems have been around long enough that they are now part of the system.</p><p> Unlike the existing tools, our goal isn't to make patent search more efficient — we're building a systemic solution to solve a systemic problem. But until now the technology wasn't there. Research in natural language processing (NLP), machine learning (ML), and artificial intelligence (AI) have already upended areas like legal document search and news analysis without producing similar results for patents.</p><h2>Incremental change isn't enough </h2><p>To really change patents we needed a paradigm shift. Our experience in patent search had taught us that much and from our work in artificial intelligence and data science we knew existing approaches were already nearly maxed out. The paradigm shift was going to have to come from something new, so we focused ourselves singularly on research in a new field of AI that was just emerging.</p><p>We used over 120 million patents to train an AI model to understand technology and inventiveness. No class code, citation network, or text mining shortcuts. Just holistically reading text and interpreting in the context of tens of millions of other patents around it. The results exceeded our wildest expectations.</p><p> But that wasn't enough. Searching is an iterative process. There's not a magic button to always find exactly what you're looking for because often what you are looking for depends on what you find. And not everyone is looking for the same thing every time. We wanted power, flexibility, and control — a way of partnering with AI to empower you.</p><h2><strong>Here it is: Amplified.</strong></h2></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592955500101_79609"><div><p>No tricks or sleight of hand, no artificially limiting results with clever class code filters or keywords. Just a cutting edge machine learning model, a lightning fast search architecture, and an intuitive interface. Using it is simple. Just start writing.</p><ul data-rte-list="default"><li><p>Results load in seconds and update automatically as you add patents or write more</p></li><li><p>Use keyword highlights to make review easier then toggle them on and off to filter results</p></li><li><p>As you find and save relevant results Amplified learns and automatically adjusts</p></li></ul><h3><strong>Reliability and performance</strong></h3><p>Amplified reduces the time needed to comprehensively identify relevant, useful patents by orders of magnitude. To confirm reliability, we tested 4.5 million known relevant patents found by expert searchers across 1.5 million filings. To determine if we could find results missed by human search we also tested against prior art that was not found during examination and successfully used to later overturn an already granted patent. In both cases we found prior art as well as the expert search and, in the case of the opposition and challenges, better. Over the past six months professional searchers, patent attorneys, and inventors verified this performance on more than 2200 examples.</p><p><strong>The implications of making prior art this readily available are far-reaching:</strong></p><ul data-rte-list="default"><li><p>Examiners can find the vast majority of relevant art up front instead of missing information because they ran out of time.</p></li><li><p>Professional searchers can finish their patent work quickly and focus on adding value instead of trawling through thousands of irrelevant patents.</p></li><li><p>Inventors and researchers at private companies can identify risks upfront before committing significant time and money to the already risky endeavor of R&amp;D.</p></li><li><p>Attorneys who have to wait weeks for prior art results from a third-party can instead work iteratively with their clients and with the best prior art always on hand.</p></li></ul><h3><strong>Anyone can quality-check the patent system just by virtue of being knowledgeable in their own field.</strong></h3><p>The patent system today, overburdened with information, is a hidden tax on innovation. Radically reducing the challenges of finding prior art is our first step towards removing that burden. We envision a future where the patent system once again functions the way it was intended — as an engine of progress, growth, and jobs.</p></div></div></div>]]>
            </description>
            <link>https://www.amplified.ai/blog/amplified-for-good</link>
            <guid isPermaLink="false">hacker-news-small-sites-23621371</guid>
            <pubDate>Tue, 23 Jun 2020 22:49:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wolfram.org Is Not Wolfram.com]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23621039">thread link</a>) | @max_
<br/>
June 23, 2020 | http://wolfram.org/business/wolframresearch.html | <a href="https://web.archive.org/web/*/http://wolfram.org/business/wolframresearch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">







<strong><a href="http://wolfram.org/eric/" title="Eric's Biography/">Eric Wolfram</a>'s

Business: Not Wolfram Research</strong>



<!-- CONTENT STARTS HERE -->



<h2>Wolfram.org is not Wolfram.com</h2>

Once upon a time, Stephen Wolfram's assistant, Scott Koranda, offered me $4000 for my domain name -- wolfram.org. (Otherwise, this site is not affiliated with <a href="http://www.wolfram.com/">Wolfram Research</a>, Math, mathematics, mathematical functions.)

<p>

I understand from <a href="http://www.stephenwolfram.com/about-sw/">Stephen Wolfram's Biography</a> that he is a genius. He was so busy writing his book about the "future of science" that he didn't foresee the popularity of the web in 1997, which is when my friend Bill Morris registered wolfram.org for me. (hmmm) So I must have been totally lucky that he didn't register wolfram.org when he secured wolfram.com.

</p><p>

A while later, Scott Korandaan asked if he could have wolfram.org for a new school that they're building. I was disappointed when he refused my counter offer to trade wolfram.org domain for wolfram.com. I also offered to lease wolfram.org to them because I wasn't using it yet. He said no to both those offers -- of course. By then I <em>knew</em> Dr. Wolfram was smart.

</p><p>

Next, Dr. Wolfram's assistant offered to buy me ewolfram.com, and exchange it for my wolfram.org! I guess I deserved that, but I didn't write back. Only then, a few weeks later, did they offer $4000 for wolfram.org! Wow, $4k for a ".org" address -- I was impressed. But although 4k is a lot of money for something I only paid $70 for (over 2000% profit?) I didn't feel good about selling it. It is my name.

</p><p>

I figured, I got to wolfram.org first. And obviously I registered it for a reason. And $4K is chicken feed compared to a location that is mine for the annals of web history. Put it this way, after taxes, $4K is more like $2K, and $2K isn't even a months rent in San Francisco!

</p><p>

I finally did some research and discovered that Stephen Wolfram was running a $350 million dollar company and he had already registered all these other domains!

<a href="http://wolfram-science.org/">wolfram-science.org</a> ,

<a href="http://stephen-wolfram.org/">stephen-wolfram.org</a> ,

<a href="http://stephenwolfram.org/">stephenwolfram.org</a> ,

<a href="http://complex-systems.org/">complex-systems.org</a> ,

<a href="http://cellularautomata.org/">cellularautomata.org</a> ,

<a href="http://wolframscience.org/">wolframscience.org</a> ,

<a href="http://cellular-automata.org/">cellular-automata.org</a> ,

<a href="http://wolfram-institute.org/">wolfram-institute.org</a> ,

<a href="http://math-world.com/">math-world.com</a> ,

<a href="http://mathsites.com/">mathsites.com</a> ,

<a href="http://wizpower.com/">wizpower.com</a> ,

<a href="http://wri.com/">wri.com</a> ,

<a href="http://mathematica.com/">mathematica.com</a> ,

<a href="http://scienceworld.com/">scienceworld.com</a> ,

<a href="http://wolfram.com/">wolfram.com</a> ,

<a href="http://science-world.com/">science-world.com</a> ,

<a href="http://wolfram-media.com/">wolfram-media.com</a> ,

<a href="http://graphica.com/">graphica.com</a> ,

<a href="http://new-science.com/">new-science.com</a> ,

<a href="http://activesites.com/">activesites.com</a> ,

<a href="http://integrals.com/">integrals.com</a> ,

<a href="http://mathsource.com/">mathsource.com</a> ,

<a href="http://wolfram-research.com/">wolfram-research.com</a> ,

<a href="http://mathlink.com/">mathlink.com</a> ,

<a href="http://mathworld.com/">mathworld.com</a> ,

<a href="http://howabout.com/">howabout.com</a> ,

<a href="http://tgjb.com/">tgjb.com</a> ,

<a href="http://publicon.com/">publicon.com</a> ,

<a href="http://mathscript.com/">mathscript.com</a> ,

<a href="http://bignumbers.com/">bignumbers.com</a> ,

<a href="http://mathjournal.com/">mathjournal.com</a> ,

<a href="http://mathematica-journal.com/">mathematica-journal.com</a> ,

<a href="http://specialfunctions.com/">specialfunctions.com</a> ,

<a href="http://mathchat.com/">mathchat.com</a> ,

<a href="http://mathdirect.com/">mathdirect.com</a> ,

<a href="http://wolfram-science.com/">wolfram-science.com</a> ,

<a href="http://wolframresearch.com/">wolframresearch.com</a> ,

<a href="http://stephenwolfram.com/">stephenwolfram.com</a> ,

<a href="http://stephen-wolfram.com/">stephen-wolfram.com</a> ,

<a href="http://wolframscience.com/">wolframscience.com</a> ,

<a href="http://wolfram-institute.com/">wolfram-institute.com</a> ,

<a href="http://complex-systems.com/">complex-systems.com</a> ,

<a href="http://calculuswiz.com/">calculuswiz.com</a>

</p><p>

Why did he need wolfram.org too? Many of his domains still aren't in use. <b>Why would someone who wants to unify physics into a single fundamental theory need 45 domain names to unify his web pages?</b> The very thought was absurd!

</p><p>

I believe that a single web address can accomplish all that Dr. Stephen Wolfram needs to say -- his views on what science will be like this new milinium, his thoughts on creating machines that think, our hopes of finding extraterrestrial intelligence, and his views on changing the way basic science is organized. One -- maybe two or three -- domains but certainly not 45 domains. Certainly not MINE too!

</p><p>

I started to understand that Mr. Wolfram simply needed a good information designer -- not another domain name. I tried to tell him that. I tried to offer my services, which at the time, I thought were most excellent. But Mr. Wolfram's assistant insisted that they needed my domain (I know, I know -- it's the marketing people...)

</p><p>

So I went to my calculater and figured that those 44 domains they already bought had cost them $3080 to buy plus $1540 per year to maintain! Wow, they have a domain name budget! So I decided to base the price on Dr. Wolfram's net worth (I figured $100,000 was a fair point to start), and, in addition, I decided to ask for perpetual use of the email addresses eric@wolfram.org, eric@wolfram.com, and the web domains eric.wolfram.com and eric.wolfram.org.

</p><p>

I quickly got a reply. For some reason, they decided to "stop wasting both of our times", as they put it, and said "Wolfram Research and its related companies are not prepared to enter into any of the arrangements which you describe...however, in the future, if you decide that you would like to sell the wolfram.org domain, please do get in touch with me."

</p><p>

Ha! Ya right!

</p><p>

What got me was that when they frist contacted me it was "hey, I'm an assistant from a Dr. at a university who wants to open a new school" and now it's all "Wolfram Research and Related company" It's come to this?!? They did, however, sent me a copy of Mathematica and I appreciated that and thanked them! A mighty find gesture.

</p><p>

Still, I must say that I was a tad miffed because I never got to speak with the Good Doctor himself, nor did I get to discuss my views on what science will be like in the 21st century. (which he could have put in his book!) And they never sent me the signed copy of Mr. Wolfram's book, which I requested. I just waited and waited. Oh well, no one realized that the book would actually come out until 2002 -- not 1998 like they were planning. And I guess they forgot about me and my domain by now. And I probably would have read his book too...

</p><p>

In an alternate universe, however, this site might have been about math -- now it's just about me -- Eric Wolfram.

</p><p>
It's not about mathematica sdk, mathworld, partition of unity, statistics, trigonometric identities, substitution integral or a linear bounded either.



<!-- CONTENT ENDS HERE -->



</p><hr size="1">

List of <a href="http://wolfram.org/business/">Mr. Wolfram's Businesses</a>







</div>]]>
            </description>
            <link>http://wolfram.org/business/wolframresearch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23621039</guid>
            <pubDate>Tue, 23 Jun 2020 22:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from looking at every AI/ML tool I could find]]>
            </title>
            <description>
<![CDATA[
Score 451 | Comments 106 (<a href="https://news.ycombinator.com/item?id=23620757">thread link</a>) | @amrrs
<br/>
June 23, 2020 | https://huyenchip.com/2020/06/22/mlops.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/06/22/mlops.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>To better understand the landscape of available tools for machine learning production, I decided to look up every AI/ML tool I could find. The resources I used include:</p>

<ul>
  <li><a href="https://github.com/alirezadir/Production-Level-Deep-Learning">Full stack deep learning</a></li>
  <li><a href="https://landscape.lfai.foundation/">LF AI Foundation landscape</a></li>
  <li><a href="http://dfkoz.com/ai-data-landscape/">AI Data Landscape</a></li>
  <li>Various lists of top AI startups by the media</li>
  <li>Responses to my <a href="https://twitter.com/chipro/status/1202815757593108480">tweet</a> and <a href="https://www.linkedin.com/posts/chiphuyen_machinelearning-machinelearningproduction-activity-6608605129010753536-bdZ7">LinkedIn post</a></li>
  <li>People (friends, strangers, VCs) share with me their lists</li>
</ul>

<p>After filtering out applications companies (e.g. companies that use ML to provide business analytics), tools that aren’t being actively developed, and tools that nobody uses, I got 202 tools. See <a href="https://docs.google.com/spreadsheets/d/1OV0cMh2lmXMU9bK8qv1Kk0oWdc_Odmu2K5sOULS9hHQ/edit?usp=sharing">the full list</a>. Please let me know if there are tools you think I should include but aren’t on the list yet!</p>

<p><strong>Disclaimer</strong></p>

<ol>
  <li>This list was made in November 2019, and the market must have changed in the last 6 months.</li>
  <li>Some tech companies just have a set of tools so large that I can’t enumerate them all. For example, Amazon Web Services offer over 165 fully featured services.</li>
  <li>There are many stealth startups that I’m not aware of, and many that died before I heard of them.</li>
</ol>

<p>This post consists of 6 parts:</p>

<p>I. Overview<br>
II. The landscape over time<br>
III. The landscape is under-developed<br>
IV. Problems facing MLOps<br>
V. Open source and open-core<br>
VI. Conclusion<br></p>

<h2>I. Overview</h2>
<p><a href="https://github.com/chiphuyen/machine-learning-systems-design">In one way to generalize the ML production flow that I agreed with</a>, it consists of 4 steps:</p>

<ol>
  <li>Project setup</li>
  <li>Data pipeline</li>
  <li>Modeling &amp; training</li>
  <li>Serving</li>
</ol>

<p>I categorize the tools based on which step of the workflow that it supports. I don’t include <strong>Project setup</strong> since it requires project management tools, not ML tools. This isn’t always straightforward since one tool might help with more than one step. Their ambiguous descriptions don’t make it any easier: “we push the limits of data science”, “transforming AI projects into real-world business outcomes”, “allows data to move freely, like the air you breathe”, and my personal favorite: “we lived and breathed data science”.</p>

<p>I put the tools that cover more than one step of the pipeline into the category that they are best known for. If they’re known for multiple categories, I put them in the <strong>All-in-one</strong> category. I also include the <strong>Infrastructure</strong> category to include companies that provide infrastructure for training and storage. Most of these are Cloud providers.</p>

<h2>II. The landscape over time</h2>
<p>I tracked the year each tool was launched. If it’s an open-source project, I looked at the first commit to see when the project began its public appearance. If it’s a company, I looked at the year it started on Crunchbase. Then I plotted the number of tools in each category over time.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/mlops/mlops_1.png">
</figure>
</center>

<p>As expected, this data shows that the space only started exploding in 2012 with the renewed interest in deep learning.</p>

<h3>Pre-AlexNet (pre-2012)</h3>
<p>Up until 2011, the space is dominated by tools for modeling and training, with some frameworks that either are still very popular (e.g. scikit-learn) or left influence on current frameworks (Theano). A few ML tools that started pre-2012 and survived until today have either had their IPOs (Cloudera, Datadog, Alteryx), been acquired (Figure Eight), or become popular open-source projects actively developed by the community (Spark, Flink, Kafka).</p>

<h3>Development phase (2012-2015)</h3>
<p>As the machine learning community took the “let’s throw data at it” approach, the ML space became the data space. This is even more clear when we look into the number of tools started each year in each category. In 2015, 57% (47 out of 82 tools) are data pipeline tools.</p>

<center>
<figure>
<img alt="Number of tools started each year" src="https://huyenchip.com/assets/pics/mlops/mlops_2.png">
</figure>
</center>

<h3>Production phase (2016-now)</h3>
<p>While it’s important to pursue pure research, most companies can’t afford it unless it leads to short-term business applications. As ML research, data, and off-the-shelf models become more accessible, more people and organizations would want to find applications for them, which increases the demand for tools to help productionize machine learning.</p>

<p>In 2016, Google announced <a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html">its use of neural machine translation to improve Google Translate</a>, marking the one of the first major applications of deep learning in the real world. Since then, many tools have been developed to facilitate serving ML applications.</p>

<h2>III. The landscape is under-developed</h2>
<p>While there are many AI startups, most of them are application startups (providing applications such as business analytics or customer support) instead of tooling startups (creating tools to help other companies build their own applications). Or in VC terms, most startups are vertical AI. Among <a href="https://www.forbes.com/sites/jilliandonfro/2019/09/17/ai-50-americas-most-promising-artificial-intelligence-companies/#2ecf64d9565c">Forbes 50 AI startups in 2019</a>, only 7 companies are tooling companies.</p>

<p>Applications are easier to sell, since you can go to a company and say: “We can automate half of your customer support effort.” Tools take longer to sell but can have a larger impact since you’re not targeting a single application but a part of the ecosystem. Many companies can coexist providing the same application, but for a part of the process, usually a selected few tools can coexist.</p>

<p>After extensive search, I could only find ~200 AI tools, which is puny compared to the number of traditional software engineering tools. If you want testing for traditional Python application development, you can find at least 20 tools within 2 minutes of googling. If you want testing for machine learning models, there’s none.</p>

<h2>IV. Problems facing MLOps</h2>
<p>Many traditional software engineering tools can be used to develop and serve machine learning applications. However, many challenges are unique to ML applications and require their own tools.</p>

<p>In traditional SWE, coding is the hard part, whereas in ML, coding is a small part of the battle. Developing a new model that can provide significant performance improvements in real world tasks is very hard and very costly. Most companies won’t focus on developing ML models but will use an off-the-shelf model, e.g. “if you want it put a BERT on it.”</p>

<p>For ML, applications developed with the most/best data win. Instead of focusing on improving deep learning algorithms, most companies will focus on improving their data. Because data can change quickly, ML applications need faster development and deployment cycles. In many cases, you might have to deploy a new model every night.</p>

<p>The size of ML algorithms is also a problem. The pretrained large BERT model has 340M parameters and is 1.35GB. Even if it can fit on a consumer device (e.g. your phone), the time it takes for BERT to run inference on a new sample makes it useless for many real world applications. For example, an autocompletion model is useless if the time it takes to suggest the next character is longer than the time it takes for you to type.</p>

<p>Git does versioning by comparing differences line by line and therefore works well for most traditional software engineering programs. However, it’s not suitable for versioning datasets or model checkpoints. Pandas works well for most traditional dataframe manipulation, but doesn’t work on GPUs.</p>

<p>Row-based data formats like CSV work well for applications using less data. However, if your samples have many features and you only want to use a subset of them, using row-based data formats still requires you to load all features. Columnar file formats like PARQUET and OCR are optimized for that use case.</p>

<p>Some of the problems facing ML applications development:</p>

<ul>
  <li><strong>Monitoring</strong>: How to know that your data distribution has shifted and you need to retrain your model? Example: <a href="https://www.dessa.com/">Dessa</a>, supported by Alex Krizhevsky from AlexNet and acquired by Square in Feb 2020.</li>
  <li><strong>Data labeling</strong>: How to quickly label the new data or re-label the existing data for the new model? Example: <a href="https://www.snorkel.org/">Snorkel</a>.</li>
  <li><strong>CI/CD test</strong>: How to run tests to make sure your model still works as expected after each change, since you can’t spend days waiting for it to train and converge? Example: <a href="https://argoproj.github.io/">Argo</a>.</li>
  <li><strong>Deployment</strong>: How to package and deploy a new model or replace an existing model? Example: <a href="https://octoml.ai/">OctoML</a>.</li>
  <li><strong>Model compression</strong>: How to compress an ML model to fit in consumer devices? Example: Xnor.ai, a startup spun out of Allen Institute to focus on model compression, raised $14.6M at the valuation of $62M in May 2018. In January 2020, Apple bought it for ~$200M and shut down its website.</li>
  <li><strong>Inference Optimization</strong>: How to speed up inference time for your models? Can we fuse operations together? Can we use lower precision? Making a model smaller might make its inference faster. Example: <a href="https://developer.nvidia.com/tensorrt">TensorRT</a>.</li>
  <li><strong>Edge device</strong>: Hardware designed to run ML algorithms fast and cheap. Example: <a href="https://coral.ai/products/som/">Coral SOM</a>.</li>
  <li><strong>Privacy</strong>: How to use user data to train your models while preserving their privacy? How to make your process GDPR-compliant? Example: <a href="https://github.com/OpenMined/PySyft">PySyft</a>.</li>
</ul>

<p>I plotted the number of tools by the main problems they address.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/mlops/mlops_3.png">
</figure>
</center>

<p>A large portion focuses on the data pipeline: data management, labeling, database/query, data processing, data generation. Data pipeline tools are also likely to aim to be all-in-one platforms. Because data handling is the most resource-intensive phase of a project, once you’ve had people put their data on your platform, it’s tempting to provide them with a couple of pre-built/pre-trained models.</p>

<p>Tools for modeling &amp; training are mostly frameworks. The deep learning frameworks competition cooled down to be mostly between PyTorch and TensorFlow, and higher-level frameworks that wrap around these two for specific families of tasks such as NLP, NLU, and multimodal problems. There are frameworks for distributed training. There’s also this new framework coming out of Google that every Googler who hates TensorFlow has been raving about: <a href="https://github.com/google/jax">JAX</a>.</p>

<p>There are standalone tools for experiment tracking, and popular frameworks also have their own experiment tracking features built-in. Hyperparameter tuning is important and it’s not surprising to find several that focus on it, but none seems to catch on because the bottleneck for hyperparameter tuning is not the setup, but the computing power needed to run it.</p>

<p>The most exciting problems yet to be solved are in the deployment and serving space. One reason for the lack of serving solutions is the lack of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2020/06/22/mlops.html">https://huyenchip.com/2020/06/22/mlops.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2020/06/22/mlops.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23620757</guid>
            <pubDate>Tue, 23 Jun 2020 21:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Language Server Protocol]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23620152">thread link</a>) | @maastaar
<br/>
June 23, 2020 | https://microsoft.github.io/language-server-protocol/ | <a href="https://web.archive.org/web/*/https://microsoft.github.io/language-server-protocol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

            <p>Adding features like auto complete, go to definition, or documentation on hover for a programming language takes significant effort. Traditionally this work had to be repeated for each development tool, as each tool provides different APIs for implementing the same feature.</p>
            <p>A <i>Language Server</i> is meant to provide the language-specific smarts and communicate with development tools over a protocol that enables inter-process communication.</p>
            <p>The idea behind the <i>Language Server Protocol (LSP)</i> is to standardize the protocol for how such servers and development tools communicate. This way, a single <i>Language Server</i> can be re-used in multiple development tools, which in turn can support multiple languages with minimal effort.</p>
            <p>LSP is a win for both language providers and tooling vendors!</p>
        </div></div>]]>
            </description>
            <link>https://microsoft.github.io/language-server-protocol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23620152</guid>
            <pubDate>Tue, 23 Jun 2020 20:57:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improving API Performance with Telnet]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23619567">thread link</a>) | @gyre007
<br/>
June 23, 2020 | https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html | <a href="https://web.archive.org/web/*/https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><header><img src="https://blog.teller.io/images/authors/stevegraham.jpg"></header><p>As you may or may not know, banks do not generally provide third party developers with API access. This is because providing developers with easy API access to customer accounts means actual competition and ultimately compressed margins. In fairness to banks, building a new API channel costs a lot of money and if all it does is increase competitive pressure why would you spend any time or money on it? It's a rational response given their incentives.</p>

<p>Despite this people still want to connect their bank accounts to services they trust, and companies still want to build those services.</p>

<p>So, where does this leave us? Thankfully the market has stepped in to provide solutions that enable us all to connect trusted apps with our financial accounts, despite this banks still actively block third party access by blocking their traffic.</p>

<h2 id="all-ip-addresses-are-not-created-equal">All IP addresses are not created equal</h2>

<p>The way we have solved this is to route our financial institution traffic onto the public internet via mobile phone carrier networks.</p>

<p>The great thing about carrier IP ranges is that carriers have significantly more customers than they have IP addresses, meaning public internet breakout is heavily <a href="https://en.wikipedia.org/wiki/Network_address_translation">NAT</a>-ed, i.e. a single address is shared and used by many customers simultaneously. The other great thing is there is good chance you're on mobile data when you use your bank's mobile app and your IP address is in the carrier’s IP range.</p>

<p>By sending our traffic onto the internet using the same IP addresses shared by millions of a bank’s own customers using the bank’s mobile app, we both make it significantly more difficult to identify and subsequently block our traffic and we also increase the collateral damage of any hostile action a bank might take against us and our users, i.e. erroneously blocking their own customers using their mobile banking app.</p>

<svg width="405px" height="279px" viewBox="0 0 405 279" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 52.6 (67491) - http://www.bohemiancoding.com/sketch -->
    <title>Untitled 4</title>
    <desc>Created with Sketch.</desc>
    <defs>
        <linearGradient x1="50%" y1="0%" x2="50%" y2="100%" id="linearGradient-1">
            <stop stop-color="#FBFBFB" offset="0%"></stop>
            <stop stop-color="#FFFFFF" offset="100%"></stop>
        </linearGradient>
        <rect id="path-2" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-3">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <rect id="path-4" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-5">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <linearGradient x1="50%" y1="2.30762283%" x2="50%" y2="100%" id="linearGradient-6">
            <stop stop-color="#F4F4F4" offset="0%"></stop>
            <stop stop-color="#FFFFFF" offset="100%"></stop>
        </linearGradient>
        <rect id="path-7" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-8">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
        <rect id="path-9" x="0" y="0" width="83" height="85" rx="11"></rect>
        <filter x="-6.0%" y="-4.7%" width="112.0%" height="111.8%" filterUnits="objectBoundingBox" id="filter-10">
            <feOffset dx="0" dy="1" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset>
            <feGaussianBlur stdDeviation="1.5" in="shadowOffsetOuter1" result="shadowBlurOuter1"></feGaussianBlur>
            <feColorMatrix values="0 0 0 0 0   0 0 0 0 0   0 0 0 0 0  0 0 0 0.5 0" type="matrix" in="shadowBlurOuter1"></feColorMatrix>
        </filter>
    </defs>
    <g id="Page-2" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Direct" transform="translate(3.000000, 2.000000)">
            <g id="Teller">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-3)" xlink:href="#path-2"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-2"></use>
                </g>
                <g id="logo-icon" transform="translate(19.462069, 19.931034)">
                    <path d="M14.8827586,31.6551724 L32.6275862,42.3854528 C29.5320561,44.1410729 25.9869012,45.137931 22.2194476,45.137931 C19.6460127,45.137931 17.1762988,44.6728122 14.8827586,43.8184589 L14.8827586,31.6551724 Z" id="Path" fill="#7985F2"></path>
                    <path d="M0,25.873964 L10.8758621,20.5172414 L10.8758621,42.2068966 C5.10335134,38.7926982 0.978977218,32.8443874 0,25.873964 Z" id="Path" fill="#F279D2"></path>
                    <path d="M0,21.6896552 C0.271210478,15.10675 3.30641844,9.24809514 7.95952004,5.27586207 L18.8896552,11.6748484 L11.488822,16.0076248 L0,21.6896552 Z" id="Path" fill="#F27979"></path>
                    <path d="M21.7854166,0 C24.5975441,0 27.2879935,0.532858373 29.7655172,1.5052445 L29.7655172,14.0689655 L10.8758621,2.91406436 C14.1003847,1.05844846 17.8220523,0 21.7854166,0 Z" id="Path" fill="#FFD780"></path>
                    <path d="M43.5034483,19.4519397 L33.2,25.2068966 L33.2,3.51724138 C38.6814991,6.95475181 42.5720341,12.7258567 43.5034483,19.4519397 Z" id="Path" fill="#91E673"></path>
                    <path d="M44.0758621,24.0344828 C43.7596445,30.6495208 40.6674041,36.5184923 35.9655559,40.4482759 L25.7586207,34.4203712 L44.0758621,24.0344828 Z" id="Path" fill="#79DEF2"></path>
                </g>
            </g>
            <g id="Bank" transform="translate(316.000000, 1.000000)">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-5)" xlink:href="#path-4"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-4"></use>
                </g>
                <text id="🏦" font-family="AppleColorEmoji, Apple Color Emoji" font-size="42" font-weight="normal" fill="#616161">
                    <tspan x="21" y="56">🏦</tspan>
                </text>
            </g>
            <path d="M84.5,43.4482759 L310,43.4482759" id="Line" stroke="#DC6F6F" stroke-width="3" stroke-linecap="square"></path>
            <polygon id="Triangle" fill="#DC6F6F" transform="translate(307.000000, 43.000000) rotate(-270.000000) translate(-307.000000, -43.000000) " points="307 35 315 51 299 51"></polygon>
            <text id="😤" font-family="AppleColorEmoji, Apple Color Emoji" font-size="30" font-weight="normal" fill="#616161">
                <tspan x="306" y="92">😤</tspan>
            </text>
            <path d="M183,57.9974594 C182.925417,57.9991501 182.850628,58 182.775641,58 C177.376704,58 173,53.5942914 173,48.1595745 C173,42.7248575 177.376704,38.3191489 182.775641,38.3191489 C182.918809,38.3191489 183.061258,38.322247 183.202926,38.3283802 C183.803357,28.6569802 191.785809,21 201.544872,21 C208.207767,21 214.042526,24.5691708 217.265242,29.9117828 C218.12594,29.7462314 219.014455,29.6595745 219.923077,29.6595745 C227.697547,29.6595745 234,36.0037948 234,43.8297872 C234,51.6557796 227.697547,58 219.923077,58 C219.270736,58 218.628759,57.9553331 218,57.8688719 L218,58 L183,58 L183,57.9974594 Z" id="Cloud" stroke="#979797" stroke-width="3" fill="url(#linearGradient-6)"></path>
            <text id="Cloud-traffic-is-eas" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="38.278" y="117.551724">Cloud traffic is easily detectable and trivial to block</tspan>
            </text>
        </g>
        <g id="Telnet" transform="translate(3.000000, 158.000000)">
            <g id="Teller">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-8)" xlink:href="#path-7"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-7"></use>
                </g>
                <g id="logo-icon" transform="translate(19.462069, 19.931034)">
                    <path d="M14.8827586,31.6551724 L32.6275862,42.3854528 C29.5320561,44.1410729 25.9869012,45.137931 22.2194476,45.137931 C19.6460127,45.137931 17.1762988,44.6728122 14.8827586,43.8184589 L14.8827586,31.6551724 Z" id="Path" fill="#7985F2"></path>
                    <path d="M0,25.873964 L10.8758621,20.5172414 L10.8758621,42.2068966 C5.10335134,38.7926982 0.978977218,32.8443874 0,25.873964 Z" id="Path" fill="#F279D2"></path>
                    <path d="M0,21.6896552 C0.271210478,15.10675 3.30641844,9.24809514 7.95952004,5.27586207 L18.8896552,11.6748484 L11.488822,16.0076248 L0,21.6896552 Z" id="Path" fill="#F27979"></path>
                    <path d="M21.7854166,0 C24.5975441,0 27.2879935,0.532858373 29.7655172,1.5052445 L29.7655172,14.0689655 L10.8758621,2.91406436 C14.1003847,1.05844846 17.8220523,0 21.7854166,0 Z" id="Path" fill="#FFD780"></path>
                    <path d="M43.5034483,19.4519397 L33.2,25.2068966 L33.2,3.51724138 C38.6814991,6.95475181 42.5720341,12.7258567 43.5034483,19.4519397 Z" id="Path" fill="#91E673"></path>
                    <path d="M44.0758621,24.0344828 C43.7596445,30.6495208 40.6674041,36.5184923 35.9655559,40.4482759 L25.7586207,34.4203712 L44.0758621,24.0344828 Z" id="Path" fill="#79DEF2"></path>
                </g>
            </g>
            <g id="Bank" transform="translate(316.000000, 1.000000)">
                <g id="Rectangle">
                    <use fill="black" fill-opacity="1" filter="url(#filter-10)" xlink:href="#path-9"></use>
                    <use fill="url(#linearGradient-1)" fill-rule="evenodd" xlink:href="#path-9"></use>
                </g>
                <text id="🏦" font-family="AppleColorEmoji, Apple Color Emoji" font-size="42" font-weight="normal" fill="#616161">
                    <tspan x="21" y="56">🏦</tspan>
                </text>
            </g>
            <path d="M84.5,43.4482759 L310,43.4482759" id="Line" stroke="#9EDC6F" stroke-width="3" fill="#9EDC6F" stroke-linecap="square"></path>
            <polygon id="Triangle" fill="#9EDC6F" transform="translate(307.000000, 43.000000) rotate(-270.000000) translate(-307.000000, -43.000000) " points="307 35 315 51 299 51"></polygon>
            <text id="📱" font-family="AppleColorEmoji, Apple Color Emoji" font-size="45" font-weight="normal" fill="#616161">
                <tspan x="178" y="61">📱</tspan>
            </text>
            <text id="😌" font-family="AppleColorEmoji, Apple Color Emoji" font-size="30" font-weight="normal" fill="#616161">
                <tspan x="306" y="92">😌</tspan>
            </text>
            <text id="Traffic-routed-via-c" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="5.728" y="117.551724">Traffic routed via carrier networks passes through undetected</tspan>
            </text>
        </g>
    </g>
</svg>

<p>Until recently we used a third party provider for mobile carrier network transit, but suddenly without warning their performance and availabilty degraded to unacceptable levels. Requests occasionally took 20-30 seconds to complete. A single Teller API transaction might actually involve several requests to the financial institution, and even if we can parallelize some of these it's a disaster for us if any of them take 30 seconds.</p>

<p>Teller provides live access to financial accounts. <strong>When you request an account balance, Teller synchronously fetches that data live from the financial institition and returns it to you</strong>. Fast and reliable network access is an absolute must in order for us to provide that level of access. Other providers can get away with lesser network performance because they don't actually ever return live data in an API call. They periodically poll the institution a couple of times a day, and give you the most recent data they have when you make your API call.</p>

<p>We immediately began to design and build an in house solution to solve this problem once and for all.</p>

<h2 id="introducing-telnet">Introducing Telnet</h2>

<p>Telnet is our propietary mobile carrier proxy network. The name is a portmanteau of Teller Network, but if we're honest it began as an internal joke as it's built on top of <a href="https://en.wikipedia.org/wiki/Secure_Shell">SSH</a>, the remote access protocol that obsoleted the original <a href="https://en.wikipedia.org/wiki/Telnet">Telnet</a>.</p>

<p>Telnet is composed of a large number of edge nodes, which are single board Linux computers with LTE modems attached running our own software written using <a href="https://www.nerves-project.org/">Nerves</a>. When nodes boot they reverse SSH into our network and register themselves as available to route API traffic. Our infrastructure then routes our financial institution traffic via our Telnet edge nodes, egressing onto the internet on carrier IP ranges.</p>

<svg width="362px" height="360px" viewBox="0 0 362 360" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 52.6 (67491) - http://www.bohemiancoding.com/sketch -->
    <title>Graph</title>
    <desc>Created with Sketch.</desc>
    <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Graph" transform="translate(1.000000, -3.000000)">
            <g id="Vendor" transform="translate(16.000000, 39.000000)">
                <text id="Vendor-A" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="21" y="323">Vendor A</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="300"></rect>
            </g>
            <g id="Telnet" transform="translate(129.000000, 312.000000)">
                <text font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="32" y="50">Telnet</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="27"></rect>
            </g>
            <g id="Direct" transform="translate(242.000000, 327.000000)">
                <text font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#616161">
                    <tspan x="32" y="35">Direct</tspan>
                </text>
                <rect id="Rectangle" fill="#DDE8FF" x="0" y="0" width="100" height="12"></rect>
            </g>
            <g id="Axes" transform="translate(0.000000, 36.000000)" stroke="#979797" stroke-linecap="square" stroke-width="3">
                <path d="M0.5,0.5 L0.5,302.5" id="Line"></path>
                <path d="M0.5,302.5 L359.100943,302.5" id="Line-2"></path>
            </g>
            <text id="Request-latency" font-family="HelveticaNeue, Helvetica Neue" font-size="14" font-weight="normal" fill="#2D2D2D">
                <tspan x="130.065" y="13">Request latency</tspan>
            </text>
        </g>
    </g>
</svg>

<p><strong>It works amazingly well</strong>. We have not only cut the latency overhead to the bone, according to our logs requests failing due to proxy errors have become a thing of the past too.</p>

<p>Credit goes to the team for shipping this so quickly. They went from bare git repo to production deployment of a fleet of embedded devices with OTA software updates in weeks. I'm very proud of them.</p>

<p>Follow <a href="https://twitter.com/tellerapi">@tellerapi</a> for a future blog post on how we built Telnet.</p>

<p>Think this is cool? <a href="https://jobs.lever.co/teller">We're hiring</a>.</p>
</article></div></div>]]>
            </description>
            <link>https://blog.teller.io/2020/06/23/improving-api-performance-with-telnet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23619567</guid>
            <pubDate>Tue, 23 Jun 2020 20:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promoted to Dev Team: What they didn't tell me]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23619213">thread link</a>) | @davetwichell
<br/>
June 23, 2020 | https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="630208ab" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/superman2.png" alt="Dev team lead: Sometimes they suffer from Superman complex." srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/superman2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/superman2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/superman2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/superman2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>



<h2><strong>Getting promoted to dev team lead</strong></h2>



<p>I was 24 years old. A baby.&nbsp;</p>



<p>Three years into my software engineering career and loving it.&nbsp;</p>



<p>Life was great. I lived in a small apartment in Southie (Boston) with <a rel="noreferrer noopener" href="https://www.linkedin.com/in/vinh-quang-van-ha-b7023a10/" target="_blank">my college roommate “Q”</a>. I had a good job at a tech start-up called CloudLock. I hammered out code 12-14 hours a day. I worked so much I never knew what day it was and my bosses had to force me to go home. When I wasn’t working, I was playing <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cornhole" target="_blank">bags (aka cornhole)</a> with my friends, lighting people up in Super Smash Bros Melee, or sleeping. Not a care in the world.&nbsp;</p>



<p>Then a freight train hit me.&nbsp;</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/train_V2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/train_V2.png" alt="Getting promoted to dev team lead felt like getting hit my a freight train." srcset="https://linearb.io/wp-content/uploads/2020/06/train_V2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/train_V2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/train_V2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/train_V2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/train_V2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>



<p>My boss, our VP of Engineering <a href="https://www.linkedin.com/in/michael-zeldich-b788a8/" target="_blank" rel="noreferrer noopener">Michael Zeldich</a>, pulled me aside one day. He explained our team was growing fast and it was getting tough for him to have 15+ engineers reporting to him directly. We needed to put some team leads in place so we could scale our org and make sure everyone was getting enough attention.&nbsp;</p>



<p>Would I be interested?&nbsp;</p>



<figure><img src="https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1024x482.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2-1536x723.png 1536w, https://linearb.io/wp-content/uploads/2020/06/head_explosion_V2.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>&nbsp;Ok… I’m not going to lie. I was surprised. But it wasn’t the first time I thought about it.&nbsp;</p>



<p>CloudLock was my second job out of college. My first job was working for Nuance Communications. I got a taste of what it might be like to lead a team when my boss went on vacation for two weeks. He nominated me to be the engineering contact for tech support while he was out. In those two weeks, my network within the company expanded, I got on customer calls for the first time and I got to see what it was like being responsible for more than just my own code. It was pretty fun and I was good at it!&nbsp;</p>



<p>That experience was in my mind that day while Michael and I were talking. I wanted to say yes but I had a million questions.&nbsp;</p>



<p>I don’t remember his exact words, but he gist of what Michael said was “Don’t worry. You’re going to be great. I’ll help you and we’ll make it work together.”&nbsp;</p>



<p>Michael is a really good guy. I trusted and respected him. So that was all I needed to hear.&nbsp;</p>







<h3><strong>My first few months on the job&nbsp;</strong></h3>



<p>Looking back on it, in those first few months, I didn’t really understand the job.&nbsp;</p>



<p>I was going through the motions. Mimicking all of the things I had seen other dev team leads do.&nbsp;</p>



<p>Don’t get me wrong. I did some good. But I also had quite a few struggles.&nbsp;</p>



<p>For starters, every time there was a problem, I went into Superman mode. Single-handedly fixing it at the speed of light. After all, I was a great coder and had an expanding set of knowledge of the entire system. And I was good at helping other developers fix their problems. That is why I got promoted to team lead, right? (Kinda.)&nbsp;</p>



<p>Some of the team actually liked it at first. They acknowledged me for getting my hands dirty and being helpful and responsive.&nbsp;</p>



<p>But some of the team didn’t like it. It came across as controlling. And the ones who liked it initially stopped liking it because they were making the same mistakes over and over again and not getting better. Our weaker devs stayed weak and our stronger devs weren’t growing.</p>



<p>There were more mistakes. Like when I waited too long to fire a bad developer who’s negative behavior was hurting the team.&nbsp;</p>







<h2><strong>8 things they didn’t tell me&nbsp;</strong></h2>



<p>I believe being a leader is a never-ending journey. There’s always more to learn. Thankfully, I had great mentors who taught me a lot. And I also learned some lessons the hard way.&nbsp;</p>



<p>Here’s 8 things I wish I knew back then.</p>







<h3><strong>1. Many of your skills don’t translate.&nbsp;</strong></h3>



<p>The cruel irony is that there is a reverse connection between strong individual dev skills and dev team lead skills. The strongest devs will have more of an uphill battle starting out as managers.&nbsp;</p>



<p>75% of the issues we face as a dev team lead are not technical. The job is mostly about people and processes. Once I realized this, everything changed for me.&nbsp;</p>



<p>I could fix anything in the codebase. I was great at finding creative solutions to fix problems other devs were having. Not only are those skills not super relevant anymore, there are other traits of great devs that can actually hurt you as manager:&nbsp;</p>



<p><strong>Superman complex.</strong> If the team has a technical problem (bug, technical blocker), great devs often have the instinct to jump in and fix it right that second. In fact, when I did that as a dev, I received praise from my peers and leaders for being a great team player. As a manager when you do that, you’re the opposite of a team player.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png.webp 1700w" sizes="(max-width: 1700px) 100vw, 1700px">
<img src="https://linearb.io/wp-content/uploads/2020/06/superman2.png" alt="Dev team lead: Sometimes they suffer from superman complex" srcset="https://linearb.io/wp-content/uploads/2020/06/superman2.png 1700w, https://linearb.io/wp-content/uploads/2020/06/superman2-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/06/superman2-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/06/superman2-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/06/superman2-1536x723.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px">
</picture>
</figure>







<p>Instead, we need to enable our people to solve the problem. Even if it takes longer the first time. Even if they make mistakes. Even if they don’t do it as well we would.&nbsp;</p>



<p>By helping your team figure it out, instead of doing it for them, you’ll get many benefits. Your people will see that you trust them. They’ll learn more. They’ll become more self-sufficient over time. And they’ll also learn to help each other which will bring the team closer together.&nbsp;</p>



<p><strong>Pro tip:</strong> Avoid judgment at all costs. When your people feel free to get out of their comfort zone and make mistakes without fear of criticism, you’ll see their true creativity come out and you’ll be amazed at what they’re capable of.&nbsp;</p>



<div><p><strong>Pro tip: </strong>You can scale yourself by educating your people on your thought process. Help them understand why your instincts kicked in about a problem. Explain the process you go through to diagnose the issue. Explain your mental model for identifying fix options. Explain how you would communicate everything to the rest of the team.</p><p><strong>Deep focus.</strong> Another skill that did not serve me well as a manager was deep focus. As a dev, you have to get in the zone. I was good at locking in and focusing all of my energy on a single problem. That will kill you as a dev team lead.&nbsp;</p></div>



<p>Great leaders embrace context switching. They move around. They talk to a lot of people. If you find yourself locked in on a technical problem for hours, that’s probably a sign that you need to delegate more.&nbsp;</p>



<p>When you do have the luxury of deep focus time, use it to think about strategic initiatives. Like how to propose your next big non-functional investment to your executive team or the profile of your next three dev hires.</p>







<h3><strong>2. Keep your instincts. Change your behavior.&nbsp;</strong></h3>



<p>Great devs have great instincts. Your intuition, which comes from your experiences, your expansive knowledge of the system, and your understanding of the end-to-end process, allows you to feel things even before you can even put your finger on exactly what it is. You sense when you went down the wrong path in your code. You sense when your team’s iteration is behind schedule.&nbsp;</p>



<p>Continue to hone these instincts. Just don’t act on them the same way you used to.&nbsp;</p>



<p>You need your spidey sense even more now to figure out when others need help:</p>



<ul><li>When you hear something in your daily stand-up that doesn’t sound right.&nbsp;</li><li>When someone can’t find the root cause of a production issue.&nbsp;</li><li>When you’re helping out on a code review.&nbsp;</li></ul>



<p>But if we aren’t jumping in like Spiderman to save the day, then what?&nbsp;</p>



<p>(Superman? Spiderman? Make up your mind, Dude! I know. Actually, Deadpool is my favorite superhero. What’s the best Deadpool quote about engineering leadership you ask? “House blowing up builds character.”)&nbsp;</p>



<figure><img src="https://linearb.io/wp-content/uploads/2020/06/DP-1-1024x595.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/06/DP-1-1024x595.png 1024w, https://linearb.io/wp-content/uploads/2020/06/DP-1-300x174.png 300w, https://linearb.io/wp-content/uploads/2020/06/DP-1-768x446.png 768w, https://linearb.io/wp-content/uploads/2020/06/DP-1-1536x893.png 1536w, https://linearb.io/wp-content/uploads/2020/06/DP-1.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>First, take a breath. I process things quickly but that can be a disadvantage as a manager. Keep listening and take extra time to process.</p>



<p>If you aren’t hearing enough info, ask questions. Gather as much information as possible before you offer any advice. Sometimes, just asking the right question helps your dev think about the issue in a new way and come up with a solution on their own.&nbsp;</p>



<p><strong>Pro tip: </strong>The stand-up is an especially useful time to listen for things that might be slightly off. If I was <a href="https://linearb.io/blog/my-team-goes-home-on-time-every-night/" target="_blank" rel="noreferrer noopener">worried someone was not on track</a>, these questions always helped me figure out if I needed to dig deeper:</p>



<ul><li>Has (fill in the dev or team who is dependent on this work) reviewed this?</li></ul>



<ul><li>What are you thinking for scalability testing?</li><li>Tell me about your feature roll-out plan?</li></ul>







<h3><strong>3. Communicate “why” more than “what” and “how”.&nbsp;</strong></h3>



<p>As developers, we’re used to dealing with what and how. As dev managers, those are still relevant but it’s more important for us to focus on why.&nbsp;</p>



<p>There’s four reasons for this:</p>



<p><strong>Customer alignment:</strong> Product managers are hopefully delivering stories that clearly explain the customer problem and use case. But it’s still easy for devs to get in the weeds. If you constantly remind your team to come back to the problem and user experience, you’ll deliver a higher quality product more often.&nbsp;</p>



<p><strong>Pro tip:</strong> Another question I Iike to ask when a dev is stuck: “Can you describe what your user is going to be doing before, during, and after using this feature?” If they can’t, they need more info.&nbsp;</p>



<p><strong>Pro tip: </strong>Encourage your devs to listen to customer support calls and sales prospects calls. In my experience, lots of teams say they are going to do this then they don’t. At LinearB we have a rule (voted on by the team) that every dev attends two customer calls minimum every month.&nbsp;</p>



<p><strong>Business alignment: </strong>A big part of being a dev leader is <a href="https://linearb.io/blog/being-vp-of-software-development-is-harder-than-being-ceo/" target="_blank" rel="noreferrer noopener">translating executives to engineers</a> and aligning your team’s work to business objectives. I believe there is a business decision behind every line of code. Is the ultimate goal to acquire more customers and generate revenue? Or are we trying to increase customer satisfaction and drive renewals? Are we making a strategic investment in non-functional work to save money and drive higher profit? The more your people understand the big picture impact of what they are working on, the more they’ll be able to think strategically and make better decisions about how to write their code.&nbsp;</p>



<p><strong>Mission and motivation:</strong> Most people want to feel part of something bigger. Sharing the why with your team helps connect them to the rest of the company. Also, regardless of what your company does, you have customers that rely on your product. Real people. Sharing “why” helps …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/">https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23619213</guid>
            <pubDate>Tue, 23 Jun 2020 19:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Join the Ruqqus, a new and uncensored Reddit challenger]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23618875">thread link</a>) | @PatrolX
<br/>
June 23, 2020 | https://ruqqus.com/signup?ref=Arador | <a href="https://web.archive.org/web/*/https://ruqqus.com/signup?ref=Arador">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>

<div id="register-form">

<p>Looks like someone wants you to make a ruckus.</p>

</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://ruqqus.com/signup?ref=Arador</link>
            <guid isPermaLink="false">hacker-news-small-sites-23618875</guid>
            <pubDate>Tue, 23 Jun 2020 19:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lossless compression of English messages using GPT-2]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23618465">thread link</a>) | @kleiba
<br/>
June 23, 2020 | http://textsynth.org/sms.html | <a href="https://web.archive.org/web/*/http://textsynth.org/sms.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      
      
      

      <div>
        <p>
          This lossless compressor achieves a much higher compression
          rate on English texts than general purpose compressors. Its
          typical compression ratio is 15% (number of output bits
          divided by the number of input bits).
        </p>
        <p>
        The compression is achieved by using the probability of the
        next word computed by
        the <a href="https://openai.com/blog/better-language-models/">GPT-2
        language model</a> released by OpenAI. It is a neural network
        of 1.5 billion parameters based on the Transformer
        architecture. An arithmetic coder generates the bit
        stream. For this demo, each compressed character holds 15 data
        bits by using the CJK and the Hangul Syllables unicode ranges.
        </p>
        <p>
        It is implemented using the
        <a href="https://bellard.org/nncp">LibNC library</a> and runs
        on a standard PC. The Linux standalone command line
        version (<code>gpt2tc</code>) can be downloaded
        <a href="https://bellard.org/nncp/gpt2tc.html">here</a>. Compression
        ratios on several text compression benchmarks is listed in
        the <a href="https://bellard.org/nncp/readme-gpt2tc.txt"><code>gpt2tc</code>
        documentation</a>.
        </p>
        <p>
        The same model can be used to <a href="http://textsynth.org/index.html">complete text messages</a>.
        </p>
        <p>[2020-06-23: Temporary switch to a smaller model (345M) to
        reduce the server load]</p>
        
      </div>
      
      
    </div></div>]]>
            </description>
            <link>http://textsynth.org/sms.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23618465</guid>
            <pubDate>Tue, 23 Jun 2020 18:51:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elevator-as-a-Service]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23618177">thread link</a>) | @ralphmender
<br/>
June 23, 2020 | https://mender.io/blog/elevator-as-a-service | <a href="https://web.archive.org/web/*/https://mender.io/blog/elevator-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

 
    <section>
      <div> 

        <div>
          <div>

              
    <div>
      
            
      <p>As we move toward a more software driven world, industry after industry is up for a strong shake up. Probably no industry, except from the governmentally protected or monopolies, should feel safe. The shift from a physical read-only world (produce a product, ship it, never change it), to a virtual writable world (offer a service, keep improving it) imposes massive challenges to incumbents. </p>
<p>Below follows a thought exercise on how a “hard” industry like the elevator market might be up for disruption. C-suites around the world need to wake up and equip their company for the software revolution before it is too late.</p>
<h3>Elevator as a product</h3>
<p>Elevators are sold as a product with running maintenance costs throughout its lifetime. Maintenance ensures continued elevator operations, but it is costly both for the customer and the vendor. </p>
<p>The main reason maintenance is expensive stems from vendors needing to send engineers out in the field to conduct the maintenance on the elevators. Further, due to lack of proper understanding of the current condition of an elevator, vendors add unnecessary costs by replacing spare-parts just to be on the safe side. Also, the lack of real-time insight into the actual state of an elevator leads to more urgent service needs due to things that break unexpectedly.</p>
<h3>The costs and margins of Elevator as a product</h3>
<p>Let’s assume an elevator costs 100. Its lifetime is 20 years, and the customer needs to pay 7% annual maintenance cost. For the customer the total price for the elevator would then be 12 per year.</p>
<p>From the vendor side, let’s assume 100% margin on the selling price of an elevator, and 20% margin on the annual maintenance costs (sold at 7 above). The total annual cost for the vendor would then be 8.1, leaving an annual profit margin of 48.50% (3.9). To keep it simple inflation and compound interests are kept out.</p>
<p><img alt="" src="https://mender.io/images/8/8/b/d/2/88bd2e2328a3beba454bfad928ba1d1812cc15e4-image-1.png"></p>
<h3>The costs and margins of Elevator-as-a-Service</h3>
<p>Now, let’s assume a vendor that starts to offer Elevators-as-a-Service. Thanks to being a software-driven company, it is capable of remotely (OTA) updating the software and gain real-time insight into the state of an elevator and conduct certain functions remotely, like testing that the alarm button works.</p>
<p>Thanks to software, this vendor does not have to send out engineers into the field at the same rate as the traditional vendor. Furthermore, due to real-time insight into the actual state of the elevator, they don’t have to replace parts just to be safe, or “since the engineer is out there anyway”. The rate of emergency calls will drop due to much improved predictive maintenance enabled by software. In conclusion, costs associated with maintenance will be much lower for this vendor than their competitor.</p>
<p>Let’s assume that instead of the traditional margin of 20% on maintenance, this new vendor achieves an annual maintenance margin of 40% due to reduced manual labor and parts costs.</p>
<p>Under this scenario the total annual costs for the new vendor is only 6.7 versus 8.1. Lower costs means higher margin. In this case the margins grow to 79.10% (versus 48.50%).</p>
<p><img alt="" src="https://mender.io/user/pages/blog/79.elevator-as-a-service/image%202.png"></p>
<h3>Why Elevator-as-a-Service will win</h3>
<p>As seen above, a new software driven vendor will be capable to both drive down its own costs and improve end-user satisfaction. These competitive wins lead to market share gains. </p>
<p>As an example, by offering an elevator as a service at 9.9 per year instead of the normal 12, the SaaS vendor ends up with the same margins as the traditional vendor. The customer achieves significant savings (17.3%, from 12 to 9.9) 17%. In addition due to the improved predictive maintenance the customer will experience fewer visits by the elevator engineers and great reduction in both planned and unplanned downtime of their elevator. This will increase the end-customer satisfaction. Have you ever been at a big hotel where at least one of the elevators is out of service?</p>
<p><img alt="" src="https://mender.io/user/pages/blog/79.elevator-as-a-service/image%203.png"></p>
<h3>Conclusions</h3>
<p>The numbers and arguments presented above illustrate the importance of making products ready for the software driven world. No industry is protected. Companies leading the revolution undoubtedly will gain significant market share. The promise of software driven products includes both improved end customer satisfaction (fewer elevator outages / issues), and reduced costs, savings that can be given to the customer to increase market share, while still keeping industry standard margins. The text is written on the wall.</p>


              
        
      
        
        
    </div>


    
 
    

          </div>
        </div>


        

      </div>

    </section>
  </div></div>]]>
            </description>
            <link>https://mender.io/blog/elevator-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-23618177</guid>
            <pubDate>Tue, 23 Jun 2020 18:31:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Prophecy Spark IDE public beta]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23617963">thread link</a>) | @ibains
<br/>
June 23, 2020 | https://www.prophecy.io/blogs/prophecy-public-beta | <a href="https://web.archive.org/web/*/https://www.prophecy.io/blogs/prophecy-public-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Hey, we've been hard at work developing a new category of <strong>Code-First Data Engineering</strong> products, and we're <strong>super excited</strong> to share this with you and get your feedback! </p><p><a href="https://landing.prophecy.io/public-beta-home" target="_blank">Sign up for your account here!</a></p><p>Prophecy uniquely provides a <strong>visual editor</strong> and <strong>code editor</strong> (with instantaneous toggle between the two) to author Spark code that is standardized, performant and maintainable, enabling more users to productively develop high quality Spark pipelines.</p><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5ee951980c3dad59abcbb5dd_visual_and_code.jpg" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5ee951980c3dad59abcbb5dd_visual_and_code-p-500.jpeg 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5ee951980c3dad59abcbb5dd_visual_and_code-p-800.jpeg 800w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5ee951980c3dad59abcbb5dd_visual_and_code-p-1600.jpeg 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5ee951980c3dad59abcbb5dd_visual_and_code.jpg 1866w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Sign up, and we'll spin up an account for you with Prophecy and send you an e-mail with login credentials. You'll be able to do the following</p><ul role="list"><li>Create new workflows or see examples using Code &amp; Visual editors.</li><li>Develop in your preferred language - Visual with SQL, Scala (Python coming soon)</li><li>One-click spin-up of Databricks Spark clusters on Azure (included free)</li><li>Interactively execute the workflows and explore the data </li></ul><p>Prophecy provides many other features that we'll be releasing at a regular cadence, one every few weeks including unit and data quality testing, column level lineage, Spark cluster orchestration and scheduling.</p><p><a href="https://landing.prophecy.io/public-beta-home" target="_blank">Sign up for your account here!</a></p><p>We'd love to hear what you think!&nbsp;Write to us at feedback@prophecy.io</p></div></div></div>]]>
            </description>
            <link>https://www.prophecy.io/blogs/prophecy-public-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-23617963</guid>
            <pubDate>Tue, 23 Jun 2020 18:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Design Resources for Startups]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23617806">thread link</a>) | @jmilinovich
<br/>
June 23, 2020 | https://www.aesthetic.com/resources | <a href="https://web.archive.org/web/*/https://www.aesthetic.com/resources">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><p><img src="https://www.aesthetic.com/_next/static/images/resources-1e98e5062d393651113e116664f0d226.svg"></p><div><p>One of the most common questions from founders is what tools we recommend they use to maximize design quality and throughput, especially in the absence of a dedicated designer. We've compiled those resources here.</p><p>While there are hundreds of options out there for some of these categories, our goal isnâ€™t to provide you with an exhaustive list but rather curate a list of our favorites. Enjoy!</p></div></div></div><div><div><p><h4>Trusted by 100+ fast growing companies worldwide</h4></p></div></div></div></div>]]>
            </description>
            <link>https://www.aesthetic.com/resources</link>
            <guid isPermaLink="false">hacker-news-small-sites-23617806</guid>
            <pubDate>Tue, 23 Jun 2020 18:06:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: DeepDiff 5 is Here: Delta, Deep Distance of any Python objects and more]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23617358">thread link</a>) | @seperman
<br/>
June 23, 2020 | https://zepworks.com/posts/deepdiff-5-released/ | <a href="https://web.archive.org/web/*/https://zepworks.com/posts/deepdiff-5-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">



<article>
  <header>
    
    
  </header>
  
  <section id="js-article">
    <p><a href="https://zepworks.com/deepdiff/5.0.0/">DeepDiff 5</a> is finally here!</p>
<a href="#delta-object"></a>
<p>The <a href="https://zepworks.com/deepdiff/5.0.0/delta.html">Delta object</a> is introduced.</p>
<p>DeepDiff Delta is a directed delta that when applied to t1 can yield t2 where delta is the difference between t1 and t2.
Delta objects are like git commits but for structured data.
You can convert the diff results into Delta objects, store the deltas, and later apply to other objects.</p>
<p>Example:</p>
<div><pre><code data-lang="py">
<span>&gt;&gt;&gt;</span> t1 <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>[</span><span>3</span><span>,</span> <span>5</span><span>,</span> <span>6</span><span>]]</span>
<span>&gt;&gt;&gt;</span> t2 <span>=</span> <span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>[</span><span>3</span><span>,</span> <span>6</span><span>,</span> <span>8</span><span>]]</span>

<span>&gt;&gt;&gt;</span> diff <span>=</span> DeepDiff<span>(</span>t1<span>,</span> t2<span>,</span> ignore_order<span>=</span><span>True</span><span>,</span> report_repetition<span>=</span><span>True</span><span>)</span>
<span>&gt;&gt;&gt;</span> diff
<span>{</span><span>'values_changed'</span><span>:</span> <span>{</span><span>'root[0]'</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>3</span><span>,</span> <span>'old_value'</span><span>:</span> <span>1</span><span>},</span> <span>'root[2][1]'</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>8</span><span>,</span> <span>'old_value'</span><span>:</span> <span>5</span><span>}}}</span>
<span>&gt;&gt;&gt;</span> delta <span>=</span> Delta<span>(</span>diff<span>)</span>
<span>&gt;&gt;&gt;</span> delta
<span>&lt;</span>Delta<span>:</span> <span>{</span><span>'values_changed'</span><span>:</span> <span>{</span><span>'root[0]'</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>3</span><span>},</span> <span>'root[2][1]'</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>8</span><span>}}}</span><span>&gt;</span>

<span>&gt;&gt;&gt;</span> t1 <span>+</span> delta <span>==</span> t2
<span>True</span>
</code></pre></div><p>Note that we can apply delta to objects different than the original objects they were made from:</p>
<div><pre><code data-lang="py"><span>&gt;&gt;&gt;</span> t3 <span>=</span> <span>[</span><span>"a"</span><span>,</span> <span>2</span><span>,</span> <span>[</span><span>3</span><span>,</span> <span>"b"</span><span>,</span> <span>"c"</span><span>]]</span>
<span>&gt;&gt;&gt;</span> t3 <span>+</span> delta
<span>[</span><span>3</span><span>,</span> <span>2</span><span>,</span> <span>[</span><span>3</span><span>,</span> <span>8</span><span>,</span> <span>'c'</span><span>]]</span>
</code></pre></div><p>And it comes with Numpy support:</p>
<div><pre><code data-lang="py"><span>&gt;&gt;&gt;</span> <span>from</span> <span>deepdiff</span> <span>import</span> DeepDiff<span>,</span> Delta
<span>&gt;&gt;&gt;</span> <span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>&gt;&gt;&gt;</span> t1 <span>=</span> np<span>.</span>array<span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>])</span>
<span>&gt;&gt;&gt;</span> t2 <span>=</span> np<span>.</span>array<span>([</span><span>2</span><span>,</span> <span>2</span><span>,</span> <span>7</span><span>,</span> <span>5</span><span>])</span>
<span>&gt;&gt;&gt;</span> diff <span>=</span> DeepDiff<span>(</span>t1<span>,</span> t2<span>)</span>
<span>&gt;&gt;&gt;</span> delta <span>=</span> Delta<span>(</span>diff<span>)</span>
<span>&gt;&gt;&gt;</span> delta <span>+</span> t1
array<span>([</span><span>2</span><span>,</span> <span>2</span><span>,</span> <span>7</span><span>,</span> <span>5</span><span>])</span>
<span>&gt;&gt;&gt;</span> delta <span>+</span> t2 <span>==</span> t2
array<span>([</span> <span>True</span><span>,</span>  <span>True</span><span>,</span>  <span>True</span><span>,</span>  <span>True</span><span>])</span>
</code></pre></div><p>There is way more to Delta from serialization for storing Delta to other details.</p>
<p>Read more about <a href="https://zepworks.com/deepdiff/5.0.0/delta.html">Delta object here</a>.</p>
<a href="#deep-distance"></a>
<p>The concept of <a href="https://zepworks.com/deepdiff/5.0.0/deep_distance.html">Deep Distance</a> is introduced.</p>
<p>Deep Distance is the distance between 2 objects. It is a floating point number between 0 and 1. Deep Distance in concept is inspired by <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein Edit Distance</a>.</p>
<p>At its core, the Deep Distance is the number of operations needed to convert one object to the other divided by the sum of the sizes of the 2 objects capped at 1. Note that unlike Levensthtein Distance, the Deep Distance is based on the number of operations and NOT the “minimum” number of operations to convert one object to the other. The number is highly dependent on the granularity of the diff results. And the granularity is controlled by the parameters passed to DeepDiff.</p>
<div><pre><code data-lang="py"><span>&gt;&gt;&gt;</span> <span>from</span> <span>deepdiff</span> <span>import</span> DeepDiff
<span>&gt;&gt;&gt;</span> DeepDiff<span>(</span><span>10.0</span><span>,</span> <span>10.1</span><span>,</span> get_deep_distance<span>=</span><span>True</span><span>)</span>
<span>{</span><span>'values_changed'</span><span>:</span> <span>{</span><span>'root'</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>10.1</span><span>,</span> <span>'old_value'</span><span>:</span> <span>10.0</span><span>}},</span> <span>'deep_distance'</span><span>:</span> <span>0.0014925373134328302</span><span>}</span>
<span>&gt;&gt;&gt;</span> DeepDiff<span>(</span><span>10.0</span><span>,</span> <span>100.1</span><span>,</span> get_deep_distance<span>=</span><span>True</span><span>)</span>
<span>{</span><span>'values_changed'</span><span>:</span> <span>{</span><span>'root'</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>100.1</span><span>,</span> <span>'old_value'</span><span>:</span> <span>10.0</span><span>}},</span> <span>'deep_distance'</span><span>:</span> <span>0.24550408719346048</span><span>}</span>
<span>&gt;&gt;&gt;</span> DeepDiff<span>(</span><span>10.0</span><span>,</span> <span>1000.1</span><span>,</span> get_deep_distance<span>=</span><span>True</span><span>)</span>
<span>{</span><span>'values_changed'</span><span>:</span> <span>{</span><span>'root'</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>1000.1</span><span>,</span> <span>'old_value'</span><span>:</span> <span>10.0</span><span>}},</span> <span>'deep_distance'</span><span>:</span> <span>0.29405999405999406</span><span>}</span>
<span>&gt;&gt;&gt;</span> DeepDiff<span>([</span><span>1</span><span>],</span> <span>[</span><span>1</span><span>],</span> get_deep_distance<span>=</span><span>True</span><span>)</span>
<span>{}</span>
<span>&gt;&gt;&gt;</span> DeepDiff<span>([</span><span>1</span><span>],</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>],</span> get_deep_distance<span>=</span><span>True</span><span>)</span>
<span>{</span><span>'iterable_item_added'</span><span>:</span> <span>{</span><span>'root[1]'</span><span>:</span> <span>2</span><span>},</span> <span>'deep_distance'</span><span>:</span> <span>0.2</span><span>}</span>
<span>&gt;&gt;&gt;</span> DeepDiff<span>([</span><span>1</span><span>],</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>],</span> get_deep_distance<span>=</span><span>True</span><span>)</span>
<span>{</span><span>'iterable_item_added'</span><span>:</span> <span>{</span><span>'root[1]'</span><span>:</span> <span>2</span><span>,</span> <span>'root[2]'</span><span>:</span> <span>3</span><span>},</span> <span>'deep_distance'</span><span>:</span> <span>0.3333333333333333</span><span>}</span>
<span>&gt;&gt;&gt;</span> DeepDiff<span>([[</span><span>2</span><span>,</span> <span>1</span><span>]],</span> <span>[[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]],</span> ignore_order<span>=</span><span>True</span><span>,</span> get_deep_distance<span>=</span><span>True</span><span>)</span>
<span>{</span><span>'iterable_item_added'</span><span>:</span> <span>{</span><span>'root[0][2]'</span><span>:</span> <span>3</span><span>},</span> <span>'deep_distance'</span><span>:</span> <span>0.1111111111111111</span><span>}</span>
</code></pre></div><p>Read more about <a href="https://zepworks.com/deepdiff/5.0.0/deep_distance.html">Deep Distance here.</a></p>
<a href="#improved-granularity-of-results-when-ignore_ordertrue"></a>
<div><pre><code data-lang="py"><span>&gt;&gt;&gt;</span> <span>from</span> <span>pprint</span> <span>import</span> pprint
<span>&gt;&gt;&gt;</span> <span>from</span> <span>deepdiff</span> <span>import</span> DeepDiff
<span>&gt;&gt;&gt;</span> t1 <span>=</span> <span>[</span>
<span>...</span>     <span>{</span>
<span>...</span>         <span>'key3'</span><span>:</span> <span>[[[[[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]]]]],</span>
<span>...</span>         <span>'key4'</span><span>:</span> <span>[</span><span>7</span><span>,</span> <span>8</span><span>],</span>
<span>...</span>     <span>},</span>
<span>...</span>     <span>{</span>
<span>...</span>         <span>'key5'</span><span>:</span> <span>'val5'</span><span>,</span>
<span>...</span>         <span>'key6'</span><span>:</span> <span>'val6'</span><span>,</span>
<span>...</span>     <span>},</span>
<span>...</span> <span>]</span>
<span>&gt;&gt;&gt;</span> 
<span>&gt;&gt;&gt;</span> t2 <span>=</span> <span>[</span>
<span>...</span>     <span>{</span>
<span>...</span>         <span>'key5'</span><span>:</span> <span>'CHANGE'</span><span>,</span>
<span>...</span>         <span>'key6'</span><span>:</span> <span>'val6'</span><span>,</span>
<span>...</span>     <span>},</span>
<span>...</span>     <span>{</span>
<span>...</span>         <span>'key3'</span><span>:</span> <span>[[[[[</span><span>1</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>4</span><span>]]]]],</span>
<span>...</span>         <span>'key4'</span><span>:</span> <span>[</span><span>7</span><span>,</span> <span>8</span><span>],</span>
<span>...</span>     <span>},</span>
<span>...</span> <span>]</span>
</code></pre></div><p>In DeepDiff 4:</p>
<div><pre><code data-lang="py"><span>&gt;&gt;&gt;</span> pprint<span>(</span>DeepDiff<span>(</span>t1<span>,</span> t2<span>,</span> ignore_order<span>=</span><span>True</span><span>))</span>
<span>{</span><span>'iterable_item_added'</span><span>:</span> <span>{</span><span>'root[0]'</span><span>:</span> <span>{</span><span>'key5'</span><span>:</span> <span>'CHANGE'</span><span>,</span> <span>'key6'</span><span>:</span> <span>'val6'</span><span>},</span>
                         <span>'root[1]'</span><span>:</span> <span>{</span><span>'key3'</span><span>:</span> <span>[[[[[</span><span>1</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>4</span><span>]]]]],</span>
                                     <span>'key4'</span><span>:</span> <span>[</span><span>7</span><span>,</span> <span>8</span><span>]}},</span>
 <span>'iterable_item_removed'</span><span>:</span> <span>{</span><span>'root[0]'</span><span>:</span> <span>{</span><span>'key3'</span><span>:</span> <span>[[[[[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]]]]],</span>
                                       <span>'key4'</span><span>:</span> <span>[</span><span>7</span><span>,</span> <span>8</span><span>]},</span>
                           <span>'root[1]'</span><span>:</span> <span>{</span><span>'key5'</span><span>:</span> <span>'val5'</span><span>,</span> <span>'key6'</span><span>:</span> <span>'val6'</span><span>}}}</span>
</code></pre></div><p>In DeepDiff 5:</p>
<div><pre><code data-lang="py"><span>&gt;&gt;&gt;</span> pprint<span>(</span>DeepDiff<span>(</span>t1<span>,</span> t2<span>,</span> ignore_order<span>=</span><span>True</span><span>,</span> cache_size<span>=</span><span>5000</span><span>,</span> cutoff_intersection_for_pairs<span>=</span><span>1</span><span>))</span>
<span>{</span><span>'values_changed'</span><span>:</span> <span>{</span><span>"root[0]['key3'][0][0][0][0][1]"</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>3</span><span>,</span>
                                                       <span>'old_value'</span><span>:</span> <span>2</span><span>},</span>
                    <span>"root[1]['key5']"</span><span>:</span> <span>{</span><span>'new_value'</span><span>:</span> <span>'CHANGE'</span><span>,</span>
                                        <span>'old_value'</span><span>:</span> <span>'val5'</span><span>}}}</span>
</code></pre></div><a href="#pretty-print"></a>
<p>Use the pretty method for human readable output regardless of what view you have used to generate the results.</p>
<div><pre><code data-lang="py"><span>&gt;&gt;&gt;</span> <span>from</span> <span>deepdiff</span> <span>import</span> DeepDiff
<span>&gt;&gt;&gt;</span> t1<span>=</span><span>{</span><span>1</span><span>,</span><span>2</span><span>,</span><span>4</span><span>}</span>
<span>&gt;&gt;&gt;</span> t2<span>=</span><span>{</span><span>2</span><span>,</span><span>3</span><span>}</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span>DeepDiff<span>(</span>t1<span>,</span> t2<span>)</span><span>.</span>pretty<span>())</span>
Item root<span>[</span><span>3</span><span>]</span> added to <span>set</span><span>.</span>
Item root<span>[</span><span>4</span><span>]</span> removed <span>from</span> <span>set.</span>
Item root<span>[</span><span>1</span><span>]</span> removed <span>from</span> <span>set.</span>
</code></pre></div><a href="#new-optimizations"></a>
<p>Many new optimizations are introduced, especially when dealing with nested data structures, numeric lists and, Numpy arrays.</p>
<p><a href="https://zepworks.com/deepdiff/5.0.0/optimizations.html">Read about optimizations here.</a></p>
<a href="#caching"></a><h2 id="caching"><a href="#caching">Caching&nbsp;</a> </h2>
<p>Caching can dramatically improve the performance for nested objects especially when ignore_order=True.</p>
<p>For example, lets take a look at the performance of the benchmark_deeply_nested_a in the <a href="https://github.com/seperman/deepdiff-benchmark/blob/master/benchmark.py">DeepDiff-Benchmark repo</a>.</p>
<p>Without any caching it takes 10 seconds to do the diff!</p>
<p><img src="https://zepworks.com/deepdiff/5.0.0/_images/benchmark_deeply_nested_a__3.8__ignore_order=True__cache_size=0__cache_tuning_sample_size=0__cutoff_intersection_for_pairs=1.png" alt="without caching"></p>
<p>And with caching it takes under a second:</p>
<p><img src="https://zepworks.com/deepdiff/5.0.0/_images/benchmark_deeply_nested_a__3.8__ignore_order=True__cache_size=5000__cache_tuning_sample_size=0__cutoff_intersection_for_pairs=1.png" alt="with caching"></p>
<a href="#improved-numpy-support"></a><h2 id="improved-numpy-support"><a href="#improved-numpy-support">Improved Numpy Support&nbsp;</a> </h2>
<p>Previously, DeepDiff barely supported Numpy. DeepDiff 5 comes with a much more comprehensive support of Numpy.</p>
<p>For example, a <a href="https://zepworks.com/deepdiff/5.0.0/optimizations.html#optimizations-for-diffing-numbers">sample diff with numbers</a> took up to 30 seconds without the optimizations:</p>
<p><img src="https://zepworks.com/deepdiff/5.0.0/_images/benchmark_array_no_numpy__3.8__ignore_order=True__cache_size=0__cache_tuning_sample_size=0__cutoff_intersection_for_pairs=1.png" alt="without numpy optimizations"></p>
<p>And 5 seconds with Numpy optimizations:</p>
<p><img src="https://zepworks.com/deepdiff/5.0.0/_images/benchmark_numpy_array__3.8__ignore_order=True__cache_size=0__cache_tuning_sample_size=0__cutoff_intersection_for_pairs=1.png" alt="numpy optimizations"></p>
<p><a href="https://zepworks.com/deepdiff/5.0.0/optimizations.html">Read more about optimizations here.</a></p>
<a href="#conclusion"></a>
<p>DeepDiff 5 comes with many new features and improvements. Please star it on <a href="https://github.com/seperman/deepdiff">github</a> if you find it useful.</p>
<p>I would like to thank everybody who helped this release possible from creating PR’s, to beta testings, and providing feedback.</p>
<ul>
<li><a href="https://github.com/nathanielobrown">Nathaniel Brown</a> Adds support for datetime.time</li>
<li><a href="https://github.com/MKaras93">Michał Karaś</a> for the pretty view</li>
<li><a href="https://github.com/chkothe">Christian Kothe</a> for the basic support for diffing numpy arrays</li>
<li><a href="https://github.com/timson">Timothy</a> for truncate_datetime</li>
<li><a href="https://github.com/laike9m">laike9m</a> for beta testing</li>
<li><a href="https://github.com/David-Herman">David Herman</a> for beta testing</li>
<li><a href="https://github.com/wlad">Wlad</a> for beta testing</li>
</ul>

  </section>
    



    



  
</article>
  </div></div>]]>
            </description>
            <link>https://zepworks.com/posts/deepdiff-5-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23617358</guid>
            <pubDate>Tue, 23 Jun 2020 17:37:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free mentorship for 2k people from underrepresented communities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23617201">thread link</a>) | @qhoang09
<br/>
June 23, 2020 | https://www.platohq.com/community-circles | <a href="https://web.archive.org/web/*/https://www.platohq.com/community-circles">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><span>Wether you are looking to raise your awareness in Diversity &amp; Inclusion, come from an under-represented groups and willing to look up at someone or looking to learn from the top tech leaders, we got you!</span></span></p></div></div></div>]]>
            </description>
            <link>https://www.platohq.com/community-circles</link>
            <guid isPermaLink="false">hacker-news-small-sites-23617201</guid>
            <pubDate>Tue, 23 Jun 2020 17:27:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can't tell people anything (2004)]]>
            </title>
            <description>
<![CDATA[
Score 404 | Comments 187 (<a href="https://news.ycombinator.com/item?id=23617188">thread link</a>) | @memexy
<br/>
June 23, 2020 | http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/ | <a href="https://web.archive.org/web/*/http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-5">
                <h3>You can't tell people anything</h3> 
                <p>This is sort of Morningstar’s version of Murphy’s Law.</p>
<p>When we were assembling our catalog of the things we had learned over the past decade and a half in this business, we almost didn’t include this one because it seems so banal.  But I keep finding that it’s often the first thing I say when people ask me what about my experiences (and another thing I’ve learned is to pay attention to things I find myself saying; that way I’ll know what I really think).  And, upon reflection, I think it’s actually one of the more important lessons that we’ve learned.</p>
<p>We all spend a lot of our time talking to bosses or investors or marketing people or press or friends or other developers. I’m totally convinced that a new idea or a new plan or a new technique is never really understood when you just explain it. People will often think they understand, and they’ll say they understand, but then their actions show that it just ain’t so.</p>
<p>Years ago, before Lucasfilm, I worked for <a href="http://xanadu.com/">Project Xanadu</a> (the original hypertext project, way before this newfangled World Wide Web thing). One of the things I did was travel around the country trying to evangelize the idea of hypertext. People loved it, but nobody <i>got</i> it. Nobody. We provided lots of explanation.  We had pictures.  We had scenarios, little stories that told what it would be like. People would ask astonishing questions, like “who’s going to pay to make all those links?” or “why would anyone want to put documents online?”  Alas, many things really must be experienced to be understood.  We didn’t have much of an experience to deliver to them though — after all, the whole point of all this evangelizing was to get people to give us money to pay for developing the software in the first place!  But someone who’s spent even 10 minutes using the Web would never think to ask some of the questions we got asked.</p>
<p>In 1988 we began consulting to Fujitsu, when they licensed Habitat from Lucasfilm to create Fujitsu Habitat in Japan. We started out with a week long seminar at Skywalker Ranch for their team, explaining everything we knew about Habitat. We gave them copious documentation and complete source code listings. Following that, for the next couple of years they had unlimited access to us via fax, phone and email to answer any questions they might have. We made several visits to Japan to advise them. On our visits they often asked questions that seemed a little, well, odd. We chalked it up to the language barrier, but still, there were clearly things they weren’t getting. For example, their server ran on five (not four, not six, five) Fujitsu A60 minicomputers, and became hopelessly bogged down after about 80 concurrent users. We were never able to get a clear picture of why. We asked lots of questions and they’d try to answer them, but none of the explanations made any sense that we could puzzle out.  They were trying to tell us, you see, but you can’t tell people anything.</p>
<p>The mystery was solved a few years later when we began the WorldsAway project, still consulting to Fujitsu but in a role that was much more hands-on. Our initial plan had been to work from the Fujitsu Habitat code, back porting the client to Macs and Windows, and cleaning up their server (80 users, yeesh). When we took apart their code, we finally figured out what had been puzzling us all that time: <i>they had lost the architecture.</i> In spite of all the information we gave them, we had completely failed to communicate how things worked.  Their guys hadn’t understood the whole client-server concept, which for that day and place was somewhat exotic, so they just implemented what they knew, which was a terminal-mainframe architecture. Their “client” was basically a fancy, highly specialized graphics terminal; all the real work was done on the server.  For example, when you issued a command to an object, instead of sending a command message to the object on the server, the client would send the X-Y coordinates of your mouse click. The server would then render its own copy of the scene into an internal buffer to figure out what object you had clicked on. Not only was this extremely inefficient, but the race conditions inherent a multi-user environment meant that it also sometimes just got the wrong answer. It was amazing…</p>
<p>What’s going on is that without some kind of direct experience to use as a touchstone, people don’t have the context that gives them a place in their minds to put the things you are telling them. The things you say often don’t stick, and the few things that do stick are often distorted.  Also, most people aren’t very good at visualizing hypotheticals, at imagining what something they haven’t experienced might be like, or even what something they <i>have</i> experienced might be like if it were somewhat different. One of the things I really miss from my days at Lucasfilm is having artists on staff, being able to run down the hall and say, “hey Gary, draw me this picture.”</p>
<p>Eventually people can be educated, but what you have to do is find a way give them the experience, to put them in the situation. Sometimes this can only happen by making real the thing you are describing, but sometimes by dint of clever artifice you can simulate it.</p>
<p>With luck, eventually there will be an “Aha!”.  If you’re really good, the “Aha!” will followed by “Oh, so <i>that’s</i> what you meant”.  But don’t be too surprised or upset if the “Aha!” is instead followed by “Why didn’t you <i>tell</i> me that?”.  At Communities.com we developed a system called Passport (I’ll save the astonishing trademark story for a later posting) that let us do some pretty amazing things with web browsers.  For example, with just a few magic HTML tags we could stick avatars on a web page — pretty much any web page.  For months Randy kept getting up at management meetings and saying, “We’ll be able to put avatars on web pages.  Start thinking about what you might do with that.”  Mostly, nobody reacted much.  After a couple of months of this we had things working, and so he got up and presented a demo of avatars walking around on top of our company home page. People were amazed, joyful, and enthusiastic.  But they also pretty much all said the same thing: “why didn’t you <i>tell</i> us that we could put avatars on web pages?”  You can’t tell people anything.</p>
<p>When people ask me about my life’s ambitions, I often joke that my goal is to become independently wealthy so that I can afford to get some work done. Mainly that’s about being able to do things without having to explain them first, so that the finished product can be the explanation.  I think this will be a major labor saving improvement.</p>
<p>One final point: I expect none of you to really get what I’m talking about here, because this principle also applies to itself. But I fully expect I’ll get the occasional email saying “Oh! so <i>that’s</i> what you meant.” or “Why didn’t you <i>tell</i> me that?”  I did, but you can’t tell people anything.</p>

            </div></div>]]>
            </description>
            <link>http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23617188</guid>
            <pubDate>Tue, 23 Jun 2020 17:26:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Query 1.6B rows in milliseconds, live]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 92 (<a href="https://news.ycombinator.com/item?id=23616878">thread link</a>) | @bluestreak
<br/>
June 23, 2020 | http://try.questdb.io:9000/index.html | <a href="https://web.archive.org/web/*/http://try.questdb.io:9000/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://try.questdb.io:9000/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23616878</guid>
            <pubDate>Tue, 23 Jun 2020 17:08:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some of the Biggest Business Mistakes in History]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23616458">thread link</a>) | @vedu_x
<br/>
June 23, 2020 | https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/ | <a href="https://web.archive.org/web/*/https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1767" itemscope="itemscope" itemtype="http://schema.org/BlogPosting" itemprop="blogPost">

	<!-- .entry-header-wrapper -->

	<div itemprop="text">
		
<figure><img data-attachment-id="1793" data-permalink="https://arcanelost.com/pexels-photo-356043/" data-orig-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?fit=1880%2C1149&amp;ssl=1" data-orig-size="1880,1149" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="black and white blackboard business chalkboard" data-image-description="" data-medium-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?fit=300%2C183&amp;ssl=1" data-large-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?fit=730%2C446&amp;ssl=1" src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=730%2C446&amp;ssl=1" alt="Some Of the Biggest Business Mistakes In History" srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=1024%2C626&amp;ssl=1 1024w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=300%2C183&amp;ssl=1 300w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=768%2C469&amp;ssl=1 768w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=1536%2C939&amp;ssl=1 1536w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=1200%2C733&amp;ssl=1 1200w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=229%2C140&amp;ssl=1 229w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?w=1880&amp;ssl=1 1880w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?w=1460&amp;ssl=1 1460w" sizes="(max-width: 730px) 100vw, 730px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=1024%2C626&amp;ssl=1 1024w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=300%2C183&amp;ssl=1 300w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=768%2C469&amp;ssl=1 768w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=1536%2C939&amp;ssl=1 1536w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=1200%2C733&amp;ssl=1 1200w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=229%2C140&amp;ssl=1 229w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?w=1880&amp;ssl=1 1880w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?w=1460&amp;ssl=1 1460w" data-lazy-src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/pexels-photo-356043.jpeg?resize=730%2C446&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by Pixabay on Pexels.com</figcaption></figure>



<p>Who doesn’t make mistakes? It’s a part of life and serves as a stepping stone for potential success in future. Many of the famous people went on to achieve great things even after making costly mistakes. In fact, this is how learning history is the most beneficial; to learn from past mistakes. Fortunately for most of us, our worst mistakes are minuscule compared to some of the massive corporate blunders in business history. Whether it be the Video game crash of 1983 or the downfall of Nokia, history has shown us how some mistakes led to the downfall of the giants of their industry or the industry itself. Let’s take a look at some of the biggest and costliest corporate mistakes in business history.</p>



<h2>The Video Game Crash of 83′</h2>



<figure><img data-attachment-id="1783" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/video-game-crash/#main" data-orig-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?fit=468%2C500&amp;ssl=1" data-orig-size="468,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="video-game-crash" data-image-description="" data-medium-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?fit=281%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?fit=468%2C500&amp;ssl=1" src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?resize=504%2C538&amp;ssl=1" alt="Video Game Crash of '83" width="504" height="538" srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?w=468&amp;ssl=1 468w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?resize=281%2C300&amp;ssl=1 281w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?resize=131%2C140&amp;ssl=1 131w" sizes="(max-width: 504px) 100vw, 504px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?w=468&amp;ssl=1 468w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?resize=281%2C300&amp;ssl=1 281w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?resize=131%2C140&amp;ssl=1 131w" data-lazy-src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/video-game-crash.jpeg?resize=504%2C538&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>source: ign.com</figcaption></figure>



<p>The crash of 1983′ is something most of the gaming enthusiasts know about. It is interesting to note how few mistakes crippled the fastest growing industry of that time. The revenue of the industry fell from 3.2 billion $ in 1983 to 100 million $ by 1985 (a drop of almost 97 percent). Many prominent companies went bankrupt or stopped making games entirely. Equally toy stores who had been the main distributors for video games stopped promoting them owing to the losses they suffered. Analysts expressed doubts over the revival of video gaming consoles and its software after the crash. If it weren’t for&nbsp;<strong>NES</strong>&nbsp;(Nintendo Entertainment System), we may not have a video gaming console industry today.&nbsp;<strong>So what exactly led to this disaster?</strong></p>



<h3>Market Saturation</h3>



<figure><img data-attachment-id="1897" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/video-game-industry/#main" data-orig-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?fit=1300%2C600&amp;ssl=1" data-orig-size="1300,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Video-game-industry" data-image-description="" data-medium-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?fit=300%2C138&amp;ssl=1" data-large-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?fit=730%2C337&amp;ssl=1" src="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?fit=730%2C337&amp;ssl=1" alt="video game controller" srcset="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?w=1300&amp;ssl=1 1300w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=300%2C138&amp;ssl=1 300w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=1024%2C473&amp;ssl=1 1024w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=768%2C354&amp;ssl=1 768w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=1200%2C554&amp;ssl=1 1200w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=303%2C140&amp;ssl=1 303w" sizes="(max-width: 730px) 100vw, 730px" data-lazy-srcset="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?w=1300&amp;ssl=1 1300w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=300%2C138&amp;ssl=1 300w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=1024%2C473&amp;ssl=1 1024w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=768%2C354&amp;ssl=1 768w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=1200%2C554&amp;ssl=1 1200w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?resize=303%2C140&amp;ssl=1 303w" data-lazy-src="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Video-game-industry.jpg?fit=730%2C337&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Source: howtogeek.com</figcaption></figure>



<p>The crash was attributed to various factors including market saturation in the number of gaming consoles and available games, and diminishing interest in console games in favour of the computer which was getting priced comparably. Gamers had dozens of console choices to choose from, which led to confusion. In the early ’80s,<strong>&nbsp;Atari</strong>&nbsp;had unsuccessfully sued to regulate third-party development for their consoles. This allowed every small studio or company to try their hands on making video games. Next, we know the market was flooded with crap video games trying to be the next hit. Even companies like&nbsp;<strong>Quaker Oats</strong>&nbsp;and&nbsp;<strong>Purina Dog Food</strong>&nbsp;joined the wave.</p>



<h3>Fall of Atari</h3>



<figure><img data-attachment-id="1789" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/atari-et1/#main" data-orig-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?fit=1517%2C1517&amp;ssl=1" data-orig-size="1517,1517" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Atari-ET1" data-image-description="" data-medium-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?fit=730%2C730&amp;ssl=1" src="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?fit=730%2C730&amp;ssl=1" alt="Atari E.T. Extra-Terrestrial" width="716" height="776" srcset="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?zoom=2&amp;resize=716%2C776&amp;ssl=1 1432w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?zoom=3&amp;resize=716%2C776&amp;ssl=1 2148w" sizes="(max-width: 716px) 100vw, 716px" data-lazy-srcset="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?zoom=2&amp;resize=716%2C776&amp;ssl=1 1432w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?zoom=3&amp;resize=716%2C776&amp;ssl=1 2148w" data-lazy-src="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Atari-ET1.jpg?fit=730%2C730&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Source: PCMag.com</figcaption></figure>



<p>This course of crap games culminated with several high profile flops created a backlash against console games.&nbsp;<strong>Atari VCS</strong>&nbsp;(or <strong>Atari 2600</strong>) was the most popular console at that time. Atari made an adaption of hit arcade game Pac-Man but it was a highly watered-down version which received a lot of criticism. To make things worse, they overestimated the success of the game and overprinted the cassettes. They just didn’t learn it the first time and did it again when they made the licensed game of hit movie franchise&nbsp;<strong>E.T. The Extra-Terrestrial</strong>&nbsp;– a game so bad that it is still considered the worst game ever by many. As a result of overprinting and overestimating the success of these titles, Atari suffered huge losses and buried&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.cnbc.com/2014/04/28/atari-cartridges-found-in-new-mexico-landfill.html">millions of never sold copies in a landfill in New Mexico</a>. These mistakes of Atari (including the failure to regulate third-party development) were the leading cause of the crash of 83′.</p>



<figure><p><span><iframe width="730" height="411" src="https://www.youtube.com/embed/rR71hEbWNmk?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p><figcaption>Pacman on Atari 2600 V Pacman on Arcade</figcaption></figure>



<h2>New Coke Formula</h2>



<figure><img data-attachment-id="1771" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/new-coke/#main" data-orig-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?fit=1024%2C688&amp;ssl=1" data-orig-size="1024,688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="New-Coke" data-image-description="" data-medium-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?fit=300%2C202&amp;ssl=1" data-large-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?fit=730%2C490&amp;ssl=1" src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?resize=550%2C369&amp;ssl=1" alt="New coke formula" width="550" height="369" srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?resize=300%2C202&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?resize=768%2C516&amp;ssl=1 768w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?resize=208%2C140&amp;ssl=1 208w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?resize=300%2C202&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?resize=768%2C516&amp;ssl=1 768w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?resize=208%2C140&amp;ssl=1 208w" data-lazy-src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/New-Coke.jpg?resize=550%2C369&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>image source: Pinterest.com</figcaption></figure>



<p>In the ’70s <strong>Coca-Cola</strong> had been the best-selling drink but they were losing the market share. Pepsi was slowly nibbling away the market share from Coca-Cola. Pepsi achieved it by gradually improving the taste of their drink. Having lost a lot of market to Pepsi, Coca-Cola decided to beat Pepsi at their own game; they decided to tweak the formula of their popular drink. The risk was huge so Coke wanted to play it safe; after performing approx 200k double-blind placebo-controlled test, they concluded that the new formula not only beat the original one but also the Pepsi. Despite all efforts, hype, test and advertisements, <strong>Coke II</strong> failed miserably. It was such a big disaster, Coca-Cola never admitted how much money they lost exactly. Soon after the release of Coke II, they took a step back and announced the return of the original drink under the name ‘<strong>Coca-Cola Classic</strong>‘.&nbsp;<strong>But why did the best Coke ever fail?</strong></p>



<h3>Going All In</h3>



<figure><img data-attachment-id="1799" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/corporate-gamble-1/#main" data-orig-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?fit=1024%2C644&amp;ssl=1" data-orig-size="1024,644" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Corporate-gamble-1" data-image-description="" data-medium-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?fit=300%2C189&amp;ssl=1" data-large-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?fit=730%2C459&amp;ssl=1" src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?w=730&amp;ssl=1" alt="going all in" srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?resize=300%2C189&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?resize=768%2C483&amp;ssl=1 768w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?resize=223%2C140&amp;ssl=1 223w" sizes="(max-width: 730px) 100vw, 730px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?resize=300%2C189&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?resize=768%2C483&amp;ssl=1 768w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?resize=223%2C140&amp;ssl=1 223w" data-lazy-src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Corporate-gamble-1.jpeg?w=730&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by Drew Rae on Pexels.com</figcaption></figure>



<p>This episode till now serves as a cautionary tale to what happens when you change something really popular. Lab results are not always a good representation of the real world. Coca-Cola’s decision to replace its 99-year-old recipe entirely with a new Coke was a blind gamble. They could have played it safe if they launched the new drink alongside the original rather than replacing the old one.</p>



<h3>Peer Pressure</h3>



<figure><img data-attachment-id="1796" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/peer-pressure/#main" data-orig-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?fit=1880%2C1254&amp;ssl=1" data-orig-size="1880,1254" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="peer-pressure" data-image-description="" data-medium-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?fit=730%2C487&amp;ssl=1" src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?w=730&amp;ssl=1" alt="peer pressure" srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=1536%2C1025&amp;ssl=1 1536w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=210%2C140&amp;ssl=1 210w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?w=1460&amp;ssl=1 1460w" sizes="(max-width: 730px) 100vw, 730px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=1536%2C1025&amp;ssl=1 1536w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?resize=210%2C140&amp;ssl=1 210w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?w=1460&amp;ssl=1 1460w" data-lazy-src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/peer-pressure.jpeg?w=730&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by mentatdgt on Pexels.com</figcaption></figure>



<p>&nbsp;In most of the tests, they conducted for the new Coke, they had a very high approval rate. But, they failed to comprehend how few who don’t like the taste might influence the others. Coke II was received well initially – most Coke drinkers responded positively for the new drink. However, this soon changed as it met with heavy protests in the Southeast. More and more people were resenting the new formula now. Coca-Cola received nearly 400k letters and calls from the people complaining about the new Coke.&nbsp;</p>



<h3>Law of Scarcity</h3>



<figure><img data-attachment-id="1776" data-permalink="https://arcanelost.com/desk-white-design-quote/" data-orig-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?fit=1880%2C1253&amp;ssl=1" data-orig-size="1880,1253" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="less is more" data-image-description="" data-medium-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?fit=730%2C486&amp;ssl=1" src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=730%2C486&amp;ssl=1" alt="law of scarcity" srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=1024%2C682&amp;ssl=1 1024w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=210%2C140&amp;ssl=1 210w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?w=1460&amp;ssl=1 1460w" sizes="(max-width: 730px) 100vw, 730px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=1024%2C682&amp;ssl=1 1024w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=210%2C140&amp;ssl=1 210w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?w=1880&amp;ssl=1 1880w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?w=1460&amp;ssl=1 1460w" data-lazy-src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/desk-white-design-quote.jpg?resize=730%2C486&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by Kaboompics .com on Pexels.com</figcaption></figure>



<p>Demand for anything is always greater when supply is limited. People want what they can’t have, and so scarcity creates value. When Coca-Cola was testing the new Coke II, it was special and limited. Respondents were trying something very few people have tasted before or could taste again. However, when they released the new Coke, old coke became rarer; hence, more valuable.</p>



<h2>Kodak’s denial</h2>



<figure><img data-attachment-id="1769" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/kodak/#main" data-orig-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?fit=550%2C358&amp;ssl=1" data-orig-size="550,358" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Kodak" data-image-description="" data-medium-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?fit=300%2C195&amp;ssl=1" data-large-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?fit=550%2C358&amp;ssl=1" src="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?w=730&amp;ssl=1" alt="kodak original poster" srcset="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?w=550&amp;ssl=1 550w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?resize=300%2C195&amp;ssl=1 300w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?resize=215%2C140&amp;ssl=1 215w" sizes="(max-width: 550px) 100vw, 550px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?w=550&amp;ssl=1 550w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?resize=300%2C195&amp;ssl=1 300w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?resize=215%2C140&amp;ssl=1 215w" data-lazy-src="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Kodak.jpg?w=730&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>image source: Wikipedia.com</figcaption></figure>



<blockquote><p>“Once a new technology rolls over you, if you’re not part of the steam roller, you’ve part of the road “</p><cite>– Stewart Brand</cite></blockquote>



<p>Above quote aptly explains how Kodak messed up. Kodak’s missed opportunities to adapt to a revolutionary technology (digital photography) in which it had a lead – they invented it in 1977 and still failed to transition to it decades later – serves as a reminder to what happens when you try to stop the revolution. During its peak, Kodak captured most of the US film market share. Immense success in the film industry made it product-oriented rather than focussing on its customers’ needs. As a result, Kodak filed for bankruptcy in 2012.&nbsp;<strong>How did Kodak mess it up?</strong></p>



<h3> Failed to reinvent itself</h3>



<figure><img data-attachment-id="1790" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/film-and-photo-sales-trend/#main" data-orig-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?fit=600%2C358&amp;ssl=1" data-orig-size="600,358" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Film-and-photo-sales-trend" data-image-description="" data-medium-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?fit=300%2C179&amp;ssl=1" data-large-file="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?fit=600%2C358&amp;ssl=1" src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?w=730&amp;ssl=1" alt="digital and analog camera sales comparison" srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?w=600&amp;ssl=1 600w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?resize=300%2C179&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?resize=235%2C140&amp;ssl=1 235w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?w=600&amp;ssl=1 600w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?resize=300%2C179&amp;ssl=1 300w, https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?resize=235%2C140&amp;ssl=1 235w" data-lazy-src="https://i0.wp.com/arcanelost.com/wp-content/uploads/2020/06/Film-and-photo-sales-trend.jpg?w=730&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>image source: Jake Nielson via Twitter</figcaption></figure>



<figure><img data-attachment-id="1791" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/film-n-analog-comparison/#main" data-orig-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?fit=525%2C263&amp;ssl=1" data-orig-size="525,263" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="film-n-analog-comparison" data-image-description="" data-medium-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?fit=300%2C150&amp;ssl=1" data-large-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?fit=525%2C263&amp;ssl=1" src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?w=730&amp;ssl=1" alt="digital and analog photography sales" srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?w=525&amp;ssl=1 525w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?resize=300%2C150&amp;ssl=1 300w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?resize=279%2C140&amp;ssl=1 279w" sizes="(max-width: 525px) 100vw, 525px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?w=525&amp;ssl=1 525w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?resize=300%2C150&amp;ssl=1 300w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?resize=279%2C140&amp;ssl=1 279w" data-lazy-src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/film-n-analog-comparison.jpg?w=730&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>source: thirdway.org</figcaption></figure>



<p>Kodak made so much money on film, it didn’t introduce the technology at the time to the public. Kodak continued its&nbsp;focus on traditional film cameras even when it was clear that digital photography was the future – They just couldn’t let it go. </p>



<p>Kodak spent more than $500 M to develop and launch Advantix film and camera system. Advantix was a digital camera hence it allowed the users to preview their shots before. Yet it still used film and emphasized print as Kodak was a giant of film, chemical, and paper business. Kodak wanted to use digital photography to boost its film and analog photography sales rather than a standalone product. As a result Advantix flopped. Who will buy a digital camera and still pay for film and prints? Kodak failed to realize that online photo sharing was the new business, not just a way to expand the printing business. When it finally got into the digital market, Kodak was selling cameras at a loss and couldn’t compete with the market.</p>



<h3> Lack of distant vision</h3>



<figure><img data-attachment-id="1895" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/lack-of-vision/#main" data-orig-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?fit=1024%2C711&amp;ssl=1" data-orig-size="1024,711" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lack-of-vision" data-image-description="" data-medium-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?fit=300%2C208&amp;ssl=1" data-large-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?fit=730%2C507&amp;ssl=1" src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?w=730&amp;ssl=1" alt="lack of vision " srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?w=1024&amp;ssl=1 1024w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?resize=300%2C208&amp;ssl=1 300w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?resize=768%2C533&amp;ssl=1 768w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?resize=202%2C140&amp;ssl=1 202w" sizes="(max-width: 730px) 100vw, 730px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?w=1024&amp;ssl=1 1024w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?resize=300%2C208&amp;ssl=1 300w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?resize=768%2C533&amp;ssl=1 768w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?resize=202%2C140&amp;ssl=1 202w" data-lazy-src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/lack-of-vision.jpeg?w=730&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by Pixabay on Pexels.com</figcaption></figure>



<p>Kodak couldn’t adapt to the changing needs of the market as it was focussing on short-term goals rather than the lasting ones.</p>



<p>Chunka Mui via <a href="https://www.forbes.com/sites/chunkamui/2012/01/18/how-kodak-failed/#1d6191726f27" target="_blank" rel="noopener">Forbes</a>:</p>



<p>“<em>In 1988, Kodak bought Sterling Drug for $5.1B, deciding that it was a chemical business, with a part of that business being a photography company. Kodak soon learned that chemically treated photo paper isn’t all that similar to hormonal agents and cardiovascular drugs, and it sold Sterling in pieces, for about half of the original purchase price. In 1989, the Kodak board of directors had a chance to take make a course change when Colby Chandler, the CEO, retired. The choices came down to Phil Samper and Kay R. Whitmore. Whitmore represented the traditional film business, where he had moved up the rank for three decades. Samper had a deep appreciation for digital technology. The board chose Whitmore</em>. <em>For more than another decade, a series of new Kodak CEOs would bemoan his predecessor’s failure to transform the organization to digital, declare his own intention to do so, and proceed to fail at the transition, as well.</em>“</p>



<blockquote><p>Mr. Whitmore said he would make sure Kodak stayed closer to its core businesses in film and photographic chemicals.</p><cite><a rel="noreferrer noopener" href="http://www.nytimes.com/1989/12/09/business/click-up-down-and-out-at-kodak.html" target="_blank">via The New York Times (12/9/1989)</a></cite></blockquote>



<h2>Excite turned down Google</h2>



<figure><img data-attachment-id="1781" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/excite-turns-down-google/#main" data-orig-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?fit=974%2C508&amp;ssl=1" data-orig-size="974,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Excite-turns-down-Google" data-image-description="" data-medium-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?fit=300%2C156&amp;ssl=1" data-large-file="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?fit=730%2C381&amp;ssl=1" src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?w=730&amp;ssl=1" alt="excite turned down google" srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?w=974&amp;ssl=1 974w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?resize=300%2C156&amp;ssl=1 300w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?resize=768%2C401&amp;ssl=1 768w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?resize=268%2C140&amp;ssl=1 268w" sizes="(max-width: 730px) 100vw, 730px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?w=974&amp;ssl=1 974w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?resize=300%2C156&amp;ssl=1 300w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?resize=768%2C401&amp;ssl=1 768w, https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?resize=268%2C140&amp;ssl=1 268w" data-lazy-src="https://i1.wp.com/arcanelost.com/wp-content/uploads/2020/06/Excite-turns-down-Google.png?w=730&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Image Source: netbeans.com</figcaption></figure>



<p><strong>Google</strong> was founded by Larry Page and Sergey Brin in January 1996 when they were both PhD students at Stanford University. In the beginning, they called it “<strong>BackRub</strong>”. Back in 1999, <strong>Excite </strong>was the no 2 search engine – second only to Yahoo – and Google was the new kid on the block.&nbsp;</p>



<p>Larry Page offered to sell Google to<strong> Excite</strong> for $1 million (though with the stipulation that Excite would replace their technology with Google Search tech). George Bell (CEO of Excite then) rejected the offer even when Vinod Khosla convinced Larry and Sergey to bring down the price to $ 750k. It is disputed that&nbsp;<a rel="noreferrer noopener" target="_blank" href="http://www.internethistorypodcast.com/2014/11/the-real-reason-excite-turned-down-buying-google-for-750000-in-1999/">why did George make that choice.&nbsp;</a>&nbsp;Excite was later on acquired by Ask Jeeves (now Ask.com) in march 2004. But had Bell accepted the duo’s offer, he would have made immense fortune from the deal. Excite’s refusal to buy what became a&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://www.nytimes.com/2020/01/16/technology/google-trillion-dollar-market-cap.html">trillion-dollar&nbsp;</a>company in 2020 is labelled by many as one of the biggest corporate mistakes.</p>



<h2>Downfall of Nokia</h2>



<figure><img data-attachment-id="1894" data-permalink="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/nokia-lumia/#main" data-orig-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?fit=1024%2C682&amp;ssl=1" data-orig-size="1024,682" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Nokia-Lumia" data-image-description="" data-medium-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?fit=300%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?fit=730%2C486&amp;ssl=1" src="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?w=730&amp;ssl=1" alt="nokia" srcset="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?w=1024&amp;ssl=1 1024w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?resize=210%2C140&amp;ssl=1 210w" sizes="(max-width: 730px) 100vw, 730px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?w=1024&amp;ssl=1 1024w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?resize=300%2C200&amp;ssl=1 300w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?resize=768%2C512&amp;ssl=1 768w, https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?resize=210%2C140&amp;ssl=1 210w" data-lazy-src="https://i2.wp.com/arcanelost.com/wp-content/uploads/2020/06/Nokia-Lumia.jpg?w=730&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Photo by JÉSHOOTS on Pexels.com</figcaption></figure>



<p>Finnish papermaker – turned – phone vendor produced most of the top twenty best-selling phones ever. You might remember Nokia …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/">https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/</a></em></p>]]>
            </description>
            <link>https://arcanelost.com/2020/06/22/some-biggest-business-mistakes-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23616458</guid>
            <pubDate>Tue, 23 Jun 2020 16:45:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trump Made $70k by Praising Foreign Leaders and Bashing the Fed on Twitter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23615860">thread link</a>) | @bingdig
<br/>
June 23, 2020 | https://govtrades.org/research/trump-tweets | <a href="https://web.archive.org/web/*/https://govtrades.org/research/trump-tweets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5eaad121b0caa85f5c597629" id="sections">
  
    <section data-section-id="5eaad121b0caa85f5c59762b" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
  &quot;imageOverlayOpacity&quot; : 0.15,
  &quot;video&quot; : {
    &quot;playbackSpeed&quot; : 0.5,
    &quot;filter&quot; : 1,
    &quot;filterStrength&quot; : 0,
    &quot;zoom&quot; : 0
  },
  &quot;backgroundWidth&quot; : &quot;background-width--full-bleed&quot;,
  &quot;sectionHeight&quot; : &quot;section-height--medium&quot;,
  &quot;horizontalAlignment&quot; : &quot;horizontal-alignment--center&quot;,
  &quot;verticalAlignment&quot; : &quot;vertical-alignment--middle&quot;,
  &quot;contentWidth&quot; : &quot;content-width--wide&quot;,
  &quot;sectionTheme&quot; : &quot;&quot;,
  &quot;sectionAnimation&quot; : &quot;none&quot;,
  &quot;backgroundMode&quot; : &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1592930517060" id="item-5ef0056135e2b301b604e1ff"><div><div><div data-block-type="2" id="block-ec8ddff2743bdcd323e3"><div><p>Last week, GovTrades launched a <a href="https://www.govtrades.com/executive">new dashboard</a> tracking President Donald Trump’s investments in publicly traded stocks and privately held businesses. This post, focusing on Trump’s publicly traded investments, is the first in a series investigating the relationship between Trump’s financial holdings and his behavior in office.&nbsp;</p><p>We find that Trump avoids investing in individual stocks, and instead holds broad-market funds with returns that are closely correlated with the S&amp;P 500 index. With this knowledge, we dig into how Trump may impact overall market returns in ways not necessarily aligned with the national interest. Specifically, we combine data from GovTrades with recent academic research on how Trump’s Twitter presence shapes market returns to quantify the impact of each tweet on the president’s financial wealth. Our results suggest that Trump earns up to $70,000 for tweets praising foreign leaders, relating to trade policy, and criticizing the Federal Reserve. While concerning, these results do not necessarily imply conflicts of interest with respect to Trump’s publicly traded portfolio, since Trump makes money when the stock market broadly performs well. Future research will investigate Trump’s privately held assets, which are much less transparent and constitute a much larger fraction of the president’s total wealth.</p><h3><strong>Basic facts about President Trump’s publicly traded investments</strong></h3><p>Trump hired JPMorgan Chase &amp; Co to manage three trusts that hold publicly traded investments, meaning he does not have direct input over investment choices. Like the general public, however, he knows what holdings the funds contain, and therefore may take into account how his policy decisions as President impact his personal fortune.</p><p>First, none of Trump’s investments are in individual stocks or bonds. Instead, he holds mutual funds, exchange-traded funds, and other securities that invest in many assets.&nbsp;</p><p>Second, 89% of Trump’s portfolio is invested in equity funds, compared with only 11% invested in comparatively safer bond funds. On face, such a high equity allocation seems like poor financial planning for a 74-year-old. Indeed, most retirement funds reduce their equity exposure to around 30% for people who are Trump’s age [<a href="https://govtrades.org/research/trump-tweets/#footnotes">1</a>], and even more aggressive economic models put optimal equity exposure around 60% [<a href="https://govtrades.org/research/trump-tweets/#footnotes">2</a>]. However, this allocation may make sense for Trump in particular. First, he holds much of his fortune in cash accounts — over $50 million dollars, according to our analysis of his private holdings. Second, Trump’s immense wealth means he can afford a more aggressive investment strategy — even in poor market conditions, he would remain wealthy in <em>absolute </em>terms. Without existential downside risk, it makes sense to pick a portfolio with higher potential upside. Finally, much of Trump’s wealth is likely invested on behalf of his children, who have a much longer investment horizons and hence would prefer the higher long-run expected returns that equities offer.</p><p>Third, Trump’s largest investment is in a fund that tracks the S&amp;P 500 index, which constitutes almost 25% of his portfolio. For context, the next largest investment — a <a href="https://am.jpmorgan.com/blob-gim/1383520618456/83456/FS-GREI-R6.PDF?segment=AMERICAS_US_ADV&amp;locale=en_US">JPMorgan-managed mutual fund</a> that invests in large global companies such as Microsoft, Apple, and Nestle — constitutes only 6% of his portfolio.&nbsp;</p><p>As a consequence of these facts, Trump’s portfolio returns are closely tied to S&amp;P 500 returns. Figure 1 plots the daily percentage return of Trump’s portfolio on the horizontal axis against the daily percentage return of the S&amp;P 500 on the vertical axis. The blue line shows the relationship between the two, with a slope of 0.6. This implies that a 10% increase in the S&amp;P 500 produces a 6% increase in Trump’s portfolio. In fact, variation in the S&amp;P 500 explains 97% of the variation in Trump’s daily returns.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592864493692_5778"><div><p>The fact that Trump’s wealth moves in almost perfect lock step with the overall stock market puts a new perspective on his <a href="https://www.nytimes.com/2019/04/09/opinion/trump-stock-market-results.html">obsession with market performance</a>. Of course, a booming market could <a href="https://www.sciencedirect.com/science/article/pii/S0261379413000723?casa_token=VBo0vYk_GYAAAAAA:hErojiHUiiUew4Y8W0cEjhToJ_SGgz9H_BhWw39qYYrWztf2Q2vO-7dioEgEEQQhDVR2sWICiw">improve Trump’s approval ratings</a>, possibly boosting his re-election odds. However, this analysis reveals another reason for Trump to keep financial markets happy -- it’s important for his bottom line.&nbsp;</p><h3><strong>The impacts of Trump’s tweets on market performance</strong></h3><p>Given the broad-market composition of Trump’s publicly traded portfolio, any conflicts of interest are less likely to arise through preference for particular companies or sectors. Instead, we should look for incidents in which Trump’s individual actions impact market returns in ways that are not necessarily in the public interest.</p><p>Recent research suggests that Trump’s Twitter feed represents an important way that the president can directly manipulate market returns. In a <a href="https://drive.google.com/file/d/1khrQPCwg-XrdzcwEqjdvXyHBYWVIOPu0/view"><span>working paper</span></a> issued by the National Bureau of Economic Research in January 2020, economists Francesco Bianchi (Duke), Thilo Kind (London Business School), and Howard Kung (London Business School) use high-frequency data on transactions immediately before and after Trump’s tweets to measure impacts on financial markets [<a href="https://govtrades.org/research/trump-tweets/#footnotes">3</a>]. The authors study two types of tweets: (i) tweets expressing sentiments about foreign leaders or trade and tariff policy; and (ii) tweets criticizing Federal Reserve policy and Fed chair Jerome Powell.&nbsp;</p><p>Data from GovTrades allows us to quantify how much money Trump makes from these tweets through their impact on his personal publicly traded financial holdings. <strong>We find that each tweet increases the value of his portfolio by up to $70,000.</strong></p><h4><em>Tweets about trade and tariff policy</em></h4><p>Trump often uses Twitter to express his views on trade and tariff policy, or otherwise express sentiments about foreign leaders that markets may interpret as signaling his planned policy course. For instance, on December 3, 2018, at 8:54am, Trump tweeted the following about his meeting with Chinese Premier Xi Jinping:&nbsp;</p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/realDonaldTrump&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p lang=\&quot;en\&quot; dir=\&quot;ltr\&quot;>My meeting in Argentina with President Xi of China was an extraordinary one. Relations with China have taken a BIG leap forward! Very good things will happen. We are dealing from great strength, but China likewise has much to gain if and when a deal is completed. Level the field!</p>\u2014 Donald J. Trump (@realDonaldTrump) <a href=\&quot;https://twitter.com/realDonaldTrump/status/1069575605199482881?ref_src=twsrc%5Etfw\&quot;>December 3, 2018</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/realdonaldtrump/status/1069575605199482881?lang=en&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Donald J. Trump&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1592788596742_4302"><div><blockquote><p lang="en" dir="ltr">My meeting in Argentina with President Xi of China was an extraordinary one. Relations with China have taken a BIG leap forward! Very good things will happen. We are dealing from great strength, but China likewise has much to gain if and when a deal is completed. Level the field!</p>— Donald J. Trump (@realDonaldTrump) <a href="https://twitter.com/realDonaldTrump/status/1069575605199482881?ref_src=twsrc%5Etfw">December 3, 2018</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592788596742_4367"><div><p>The authors of the study collected all such tweets between Trump’s election and November 2019, and classified them as either expressing positive or negative sentiments about trade policy and foreign leaders. To measure the impact on the S&amp;P 500, the study compared the change in index value from five seconds before each tweet to five minutes afterwards [<a href="https://govtrades.org/research/trump-tweets/#footnotes">4</a>]. Focusing on this narrow window ensured that changes represent the impact of the tweets themselves, as opposed to other confounding factors that may influence market value.</p><p>The study suggests that Trump’s tweets expressing <em>positive</em> sentiments boost the S&amp;P 500 by about 2.9% [<a href="https://govtrades.org/research/trump-tweets/#footnotes">5</a>]. This translates to an increase of about 1.75% in Trump’s publicly traded portfolio, given the association between his returns and the S&amp;P 500. According to our estimates of Trump’s portfolio value, this implies that <strong>each positive tweet about trade policy or foreign leaders earns about $70,000.</strong></p><p>Trump tweets about trade policy and foreign leaders all the time. Why hasn’t the cumulative effect of these tweets pushed the S&amp;P continually up? Although <em>positive</em> tweets push <em>up</em> market values, <em>negative</em> tweets — criticizing foreign leaders or arguing for more restrictive trade policy — push them <em>down</em>. Considering all of Trump’s tweets on trade and foreign leaders together, the authors find no net effect.&nbsp;</p><p>Does that mean that Trump is not profiting from these tweets? It’s hard to say for sure. But without the optimism reflected in Trump’s positive tweets, it is possible that markets would more fully reflect the negative economic impacts of his restrictive trade policies, and therefore earn lower returns. In this sense, the language that Trump chooses for his tweets may reflect an attempt to guard against the market losses potentially imposed by his economic policy agenda. In the process, Trump also saves a lot of money himself.</p><h4><em>Tweets about the Federal Reserve</em></h4><p>Trump’s tweets about trade policy may feel relatively innocuous. A more dovish stance by Trump on trade may facilitate economic growth, generally a plus for the country. The fact that he also personally profits from this growth isn’t <em>necessarily</em> a problem.&nbsp;</p><p>However, Trump has recently taken to attacking the Federal Reserve and chair Jerome Powell, with the goal of pressuring the Fed to keep interest rates low. For instance, on April 16, 2018, Trump tweeted the following:&nbsp;</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1592788596742_6257"><div><blockquote><p lang="en" dir="ltr">Russia and China are playing the Currency Devaluation game as the U.S. keeps raising interest rates. Not acceptable!</p>— Donald J. Trump (@realDonaldTrump) <a href="https://twitter.com/realDonaldTrump/status/985858100149309441?ref_src=twsrc%5Etfw">April 16, 2018</a></blockquote> </div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592788596742_6323"><div><p>The Federal Reserve sets targets for the Federal funds rate. This important economic indicator impacts interest rates throughout the economy, from rates on loans between banks to rates on consumer mortgage and auto loans. Lower rates increase stock market valuations both by stimulating economic activity and by increasing the risk premium for holding stocks. However, the consensus among economists is that the Federal Reserve ought to behave <em>independently</em> of political pressure when setting interest rates — otherwise, the US risks slipping into a high inflation environment akin to the 1970s and 1980s, when <a href="https://fred.stlouisfed.org/series/FPCPITOTLZGUSA">annual inflation peaked at 13%</a>. If Trump’s tweets succeed in pressuring the Federal Reserve to lower interest rates — eroding its independence from the political branch — then he may achieve his goal of higher stock market valuations at the expense of broader economic health.&nbsp;</p><p>It is possible to infer real-time market expectations for future Federal Reserve policy using transaction prices for financial derivatives called Federal funds futures contracts. The value of these products changes based on the <em>actual</em> Federal funds rate in future months. …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://govtrades.org/research/trump-tweets">https://govtrades.org/research/trump-tweets</a></em></p>]]>
            </description>
            <link>https://govtrades.org/research/trump-tweets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615860</guid>
            <pubDate>Tue, 23 Jun 2020 16:11:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust at CNCF]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23615854">thread link</a>) | @biggestlou
<br/>
June 23, 2020 | https://www.cncf.io/blog/2020/06/22/rust-at-cncf/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/blog/2020/06/22/rust-at-cncf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="post-46335">

	<div>

		<div>
			
			
				<div>
					
										
					<p><em>Staff Post</em></p>
<p><a href="https://www.rust-lang.org/"><span>Rust</span></a><span> is a systems language originally created by </span><a href="https://insights.stackoverflow.com/survey/2019#technology-_-most-loved-dreaded-and-wanted-languages"><span>Mozilla</span></a><span> to power parts of its experimental </span><a href="https://servo.org/"><span>Servo</span></a><span> browser engine. Once highly experimental and little used, Rust has become dramatically more stable and mature in recent years and is now used in a wide variety of settings, from databases to operating systems to web applications and far beyond. And developers seem to really </span><a href="https://insights.stackoverflow.com/survey/2019#most-loved-dreaded-and-wanted"><span>love it</span></a><span>.</span></p>
<p><span>You may be surprised to find out that the venerable Rust has established a substantial toehold here at CNCF as well. In fact, two of our</span><a href="https://branding.cncf.io/#incubating-projects"> <span>incubating</span></a><span> projects, </span><a href="https://tikv.org/"><span>TiKV</span></a><span> and </span><a href="https://linkerd.io/"><span>Linkerd</span></a><span>, have essential components written in Rust and both projects would be profoundly different—and potentially less successful—in another language.</span></p>
<p><span>In this post, I’d like to shed light on how TiKV and Linkerd are contributing to the Rust ecosystem.</span></p>
<h2>TiKV</h2>
<p><a href="https://tikv.org/"><span>TiKV</span></a><span> is a distributed, transactional key-value database originally created by the company</span><a href="https://pingcap.com/"> <span>PingCAP</span></a><span>. Its core concepts are drawn from</span><a href="https://research.google/pubs/pub39966/"><span> the venerable </span><span>Google Spanner</span></a><span> and</span><a href="https://hbase.apache.org/"><span> Apache HBase</span></a><span> and it’s primarily used to provide lower-level key/value—the “KV” in “TiKV”—storage for higher-level databases, such as</span><a href="https://github.com/pingcap/tidb"> <span>TiDB</span></a><span>.</span></p>
<p><span>In addition to the</span><a href="https://github.com/tikv/tikv"> <span>core repo</span></a><span>, the TiKV project has contributed a number of libraries to the Rust ecosystem:</span></p>
<ul>
<li><a href="https://docs.rs/crate/grpcio/0.5.0-alpha.5"><span>grpc-rs</span></a><span>, a Rust wrapper for</span><a href="https://github.com/grpc/grpc"> <span>gRPC core</span></a><span>.</span></li>
<li><a href="https://github.com/tikv/raft-rs"><span>raft-rs</span></a><span>, a Rust implementation of the Raft consensus protocol. This is the consensus protocol used by TiKV as well as</span><a href="https://etcd.io/"> <span>etcd</span></a><span>, the distributed key-value store used by Kubernetes and a fellow CNCF project.</span></li>
<li><a href="https://github.com/tikv/fail-rs"><span>fail-rs</span></a><span>, for injecting “fail points” at runtime</span></li>
<li><a href="https://github.com/tikv/async-speed-limit"><span>async-speed-limit</span></a><span>, a library for asynchronously speed-limiting multiple byte streams</span></li>
<li><a href="https://github.com/tikv/rust-prometheus"><span>rust-prometheus</span></a><span>, a</span><a href="https://prometheus.io/"> <span>Prometheus</span></a><span> client for Rust that enables you to instrument your Rust services, i.e. to expose properly formatted metrics to be scraped by Prometheus.</span></li>
<li><a href="https://github.com/tikv/pprof-rs"><span>pprof-rs</span></a><span>, a CPU profiler that can be integrated into Rust programs. Enables you to create flame graphs of CPU activity and offers support for</span><a href="https://developers.google.com/protocol-buffers"> <span>Protocol Buffers</span></a><span> output.</span></li>
</ul>
<p><span>PingCAP’s blog has also featured some highly regarded articles on Rust, including </span><a href="https://pingcap.com/blog/rust-compilation-model-calamity"><span>The Rust Compilation Model Calamity</span></a> <span>and </span><a href="https://pingcap.com/blog/2017-09-26-whyrust"><span>Why did we choose Rust over Golang or C/C++ to develop TiKV?</span></a> <span>If you’re like me and excited about witnessing a new generation of databases written in Rust, you should really keep tabs on TiKV and its contributions to the Rust ecosystem.</span></p>
<h2>Linkerd</h2>
<p><a href="https://linkerd.io/"><span>Linkerd</span></a><span> is a service mesh that’s relentlessly focused on simplicity and user-friendliness. If you’ve ever felt frustrated or overwhelmed by the complexity of other service mesh technologies, I cannot recommend the breath of fresh air that is the Linkerd</span><a href="https://linkerd.io/2/getting-started/"> <span>Getting Started</span></a><span> guide more highly. And in case you missed it, Linkerd had a</span><a href="https://www.cncf.io/blog/2020/01/20/linkerd-2019-year-in-review/"> <span>huge 2019</span></a><span> and is continuing apace in</span><a href="https://github.com/linkerd/linkerd2/blob/master/CHANGES.md"> <span>2020</span></a><span>.</span></p>
<p><span>Arguably the most important component of Linkerd is its</span><a href="https://github.com/linkerd/linkerd2-proxy"> <span>service proxy</span></a><span>, which lives alongside your services in the same Kubernetes</span><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/"> <span>Pod</span></a><span> and handles </span><i><span>all</span></i><span> network traffic to and from the service. Services proxies are hard to write because they need to be fast, they need to be safe, and they need to have the smallest memory footprint that’s commensurate with speed and safety.</span></p>
<p><span>The Linkerd creators opted for Rust for the Linkerd service proxy. Why did they make this choice? I reached out to Linkerd co-creator</span><a href="https://twitter.com/olix0r"> <span>Oliver Gould</span></a><span> to provide the breakdown:</span></p>
<p><i><span>When we started building Linkerd ~5 years ago, some of our first prototypes were actually in Rust (well before the language hit 1.0). Unfortunately, at the time, it wasn’t mature enough for our needs, so Linkerd’s first implementation grew out of Twitter’s Scala ecosystem. As we were working on Linkerd 1.x, Rust’s</span></i><a href="https://tokio.rs/"> <i><span>Tokio</span></i></a><i><span> runtime started to take shape and was especially promising for building something like a proxy. So in early 2017 we set out to start rewriting Linkerd with a Go control plane and a Rust data plane. Tokio (with its sister projects,</span></i><a href="https://github.com/carllerche/tower-web"> <i><span>Tower</span></i></a><i><span> &amp;</span></i><a href="https://github.com/hyperium/hyper"> <i><span>Hyper</span></i></a><i><span>) made this all possible by extending Rust’s safe, correct memory model with asynchronous networking building blocks. These same building blocks are now being used in a variety of performance-sensitive use cases outside of Linkerd, and we’ve built a great community of contributors around both projects. If this is interesting to you, please come get involved!</span></i></p>
<p>In terms of contributions back to the Rust ecosystem, Linkerd has upstreamed core components to <a href="https://github.com/carllerche/tower-web">Tower</a> and <a href="https://github.com/tokio-rs/tokio">Tokio</a>, such as Linkerd’s load balancer and Tokio’s <a href="https://github.com/tokio-rs/tracing">tracing</a> module.</p>
<p><span>In addition, the project also undertook a security audit of the </span><a href="https://github.com/ctz/rustls"><span>rustls</span></a><span> library (sponsored by CNCF). As the name suggests, rustls is a transport security layer (TLS) library for Rust that’s used by the Linkerd proxy for its mutual TLS (mTLS) feature, which is crucial to the security guarantees that the Linkerd service mesh provides. You can see the result of the audit in </span><a href="https://github.com/ctz/rustls/raw/master/audit/TLS-01-report.pdf"><span>this PDF</span></a><span>. </span><a href="https://cure53.de/"><span>Cure53</span></a><span>, the firm responsible for security audits of several other CNCF projects, was “unable to uncover any application-breaking security flaws.” A sterling result if I say so myself!</span></p>
<h2>More to come?</h2>
<p><span>I’m a huge fan of Rust myself, though I’ve really only </span><a href="https://github.com/lucperkins/rust-graphql-juniper-actix-diesel-postgres"><span>dabbled</span></a><span> in it. I have my fingers crossed that TiKV and Linkerd are just the beginning and that we’ll see a whole lot more Rust in the cloud native universe, be that in the form of new CNCF projects written in Rust, existing projects porting components into Rust, or new Rust client libraries for existing systems.</span></p>
<p><span>And if you’re curious about </span><i><span>all</span></i><span> of the programming languages in use amongst CNCF’s </span><a href="https://www.cncf.io/projects/"><span>many projects</span></a><span>, stay tuned for an upcoming blog post on precisely that topic.</span></p>
						
				</div><!--/content-inner-->

						
		</div><!--/post-content-->

	</div><!--/inner-wrap-->
		
</article><!--/article-->

						   


					
			</div></div>]]>
            </description>
            <link>https://www.cncf.io/blog/2020/06/22/rust-at-cncf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615854</guid>
            <pubDate>Tue, 23 Jun 2020 16:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lighthouse Syndrome]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23615643">thread link</a>) | @arunoda
<br/>
June 23, 2020 | https://arunoda.me/blog/lighthouse-syndrome | <a href="https://web.archive.org/web/*/https://arunoda.me/blog/lighthouse-syndrome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://arunoda.me/blog/lighthouse-syndrome</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615643</guid>
            <pubDate>Tue, 23 Jun 2020 15:55:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cybersecurity Practices for Remote Workers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23615431">thread link</a>) | @yarapavan
<br/>
June 23, 2020 | https://www.cira.ca/resources/cybersecurity/guide-how/free-cybersecurity-course-cybersecurity-practices-remote-workers | <a href="https://web.archive.org/web/*/https://www.cira.ca/resources/cybersecurity/guide-how/free-cybersecurity-course-cybersecurity-practices-remote-workers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-off-canvas-main-canvas="">
    



<div id="site">
  <!-- site-header -->
      

    <!-- /site-header -->

  <!-- page_system -->
      
    
    
    <!-- /page_system -->

  <!-- main -->
  <main class="page">
    <!-- page-header -->
    
    <!-- page-header -->

    <!-- sidebar-left -->
        <!-- /sidebar-left -->

    <!-- page-content -->
    <section id="main-content" data-container-breakpoint="">
          

    
        
  
  




<article data-history-node-id="8591" role="article" about="/resources/cybersecurity/guide-how/free-cybersecurity-course-cybersecurity-practices-remote-workers">
  <section>
          

    
          
      
      
      


<div>
  
      <div>
      
            <div><h2>Cybersecurity when working from home</h2>
<p>Working from home is the new normal. Even before a global crisis, roughly half of Canadians were working from home a couple days per week.</p>
<p>Now, pretty much everyone who is able to is either working or studying from home for the foreseeable future.</p>
<p>Most offices and schools have some level of IT and cybersecurity protection for people on their networks. Unfortunately, most people do not have those same protections at home.</p>
<p>Just because you’re cozy on the couch doing your work, it doesn’t mean you’re suddenly less vulnerable to cyber-attacks.</p>
<p>Whether you’re working or studying from home, you’re still using work devices, email addresses and systems. Getting attacked or compromised at home means other people in your organization are at risk as well.</p>
<p>This is why cybersecurity at home is extremely important.</p>
<p>Fortunately, you can do a lot to protect yourself when working from home with some simple tips and practices.</p>
<p>We’re going to cover those in this course so you can protect yourself and your organization.</p>
</div>
      
        </div>
</div>


          
    
  
  

      

        
  

<p id="text-version">

      

      <h2>
                        Contents
            </h2>


</p>

      





      

        
  

<p id="wifi">

      

      <h2>
                        Protect your Wi-Fi
            </h2>


</p>

      


<div>
  
      <div>
      
            <div><p>The most important part of your work-from-home setup is your Wi-Fi network.</p>
<p>Your network is the bridge that connects your devices with each other and the internet. If a bad actor were to gain access to your network, they can use this information to take over your devices and hold them for ransom, or steal your personal and financial information. They could also use this information to steal from your organization.</p>
<p>The first (and easiest!) step is to make sure your default administrative password and login for your router are changed. Many brands use common default credentials like “admin” and “password”, which make it easy for anyone to hijack their way in.</p>
<h3>Other ways you can protect your home Wi-Fi</h3>
<h4>Enable WPA2 encryption</h4>
<p>Encryption scrambles the information that your router exchanges with a device on your network, so only the device can see it.</p>
<p>This way, if someone is trying to sniff this data from outside your network, the data they get won’t make any sense.</p>
<h4>Create a guest network</h4>
<p>You should turn on your guest network and use that for all of your personal devices, like IoT (internet of things) devices, smart speakers, game consoles, children’s devices, and for anyone visiting.</p>
<p>Then, use your normal non-guest network only for work devices.</p>
<h4>Replace old routers</h4>
<p>Like all technology, older devices are less likely to get security updates from their manufacturer, and are more likely to have security vulnerabilities.</p>
<p>Replace routers every several years to take advantage of the latest security features and updates. You’ll also likely get improved Wi-Fi coverage!</p>
<h3>Watch out for public Wi-Fi</h3>
<p>The café might make a great latté but they aren’t cybersecurity experts (unless they took this course as well!) You have to assume that any shared, public, open Wi-Fi can put you at risk.</p>
<p>You should not use networks at cafés, hotels, and airports to access work documents or systems without additional protection, like a virtual private network (VPN).</p>
<p>If you do not have a VPN, but you do have a work phone, you can consider using it as a Wi-Fi hotspot to tether your laptop through a secure connection.</p>
<p>These can use a lot of data that your company has to pay for, so check with them first to see if your device allows it.</p>
</div>
      
        </div>
</div>


      

        
  

<p id="passwords">

      

      <h2>
                        Strong passwords and multi-factor authentication
            </h2>


</p>

      


<div>
  
      <div>
      
            <div><p>Strong, unique passwords are your most important form of protection from cyber-attacks.</p>
<p>Never, ever re-use passwords—especially between your personal and work accounts. Every account should have its own unique password.</p>
<p>It is very easy to identify which accounts are linked together, especially through email. If one of your accounts gets compromised, and that password is shared with another account, it won’t be long before you lose both accounts.&nbsp;</p>
<h3>What makes a strong password?</h3>
<h4>Make it long</h4>
<p>Longer passwords are harder to crack. Make your password as long as possible. We recommend passwords that are at least 15 characters.</p>
<h4>Use special characters</h4>
<p>Include numbers, symbols and spaces in your password whenever possible.</p>
<h4>Avoid patterns and personal words</h4>
<p>Do not include personal information like birthdates and pet names in your passwords. These clues are usually posted on social media!</p>
<h4>Avoid substitutions</h4>
<p>Do not replace letters with numbers (like E and 3) on already short, weak passwords.</p>
<h4>Pro tip:</h4>
<p>Remembering so many long, unique passwords is super tough, especially when people have so many accounts these days. This is where password managers come in, like LastPass or 1Password. They can generate strong passwords for you, and auto-populate them when you try to login to a website or app.</p>
<h3>Use multi-factor authentication</h3>
<p>Multi-factor (or two-factor) authentication is a way of confirming your identify using multiple factors beyond just a password.</p>
<p><strong>These factors are usually something:</strong></p>
<ul><li>
<p>You <strong>know</strong> (like a password)</p>
</li>
<li>
<p>You <strong>have </strong>(like a token or SMS code)</p>
</li>
<li>
<p>You <strong>are</strong> (like a fingerprint or face scan)</p>
</li>
</ul><p>This is why some apps ask to send you a text code before you can login or verify an account. That’s multi-factor authentication! If you have the option to set it up for a device or account, do it.</p>
<p>The best form of authentication is “token-based”, which creates a single-use login code right when you need it. Popular apps for this include Google and Microsoft Authenticator.</p>
</div>
      
        </div>
</div>


      

        
  

<p id="vpn">

      

      <h2>
                        Virtual Private Networks (VPNs)
            </h2>


</p>

      


<div>
  
      <div>
      
            <div><p>A VPN is a way to create a secure tunnel to another network over the internet. It’s a powerful and simple way to protect the information you’re sending and receiving when on your home network.</p>
<p>Many employers provide a VPN option that allows an employee’s home computer to securely connect to their work network. Sometimes this is the only way to access certain files or systems.</p>
<p>If you’re interested in getting a VPN, speak with your IT team. They can help you set up their preferred VPN correctly.</p>
<p>If you work in a smaller team, or you just want one for yourself, there are many cloud-based options that are easy to setup. With VPNs, you get what you pay for, so spend a little bit of money from a reputable vendor.</p>
</div>
      
        </div>
</div>


      

        
  

<p id="confidential-info">

      

      <h2>
                        Protecting confidential information
            </h2>


</p>

      


<div>
  
      <div>
      
            <div><p>When you’re working from home, you need to treat documents and information with the same level of privacy and confidentiality that you would if you were in an office.</p>
<p>At work, you usually have a clean-desk policy, where you can’t leave documents or devices open for anyone to access. This is especially important in a household where family members or roommates could see confidential information.</p>
<p>Do not store files onto your personal device if you’re using it for work. If you have to print documents, or save files to a USB drive, double check with your employer to see what your shredding, destruction, and file security policies are.</p>
</div>
      
        </div>
</div>


      

        
  

<p id="personal-devices">

      

      <h2>
                        Protecting personal devices
            </h2>


</p>

      


<div>
  
      <div>
      
            <div><p>Before using a personal device for work, check with your employer about your Bring Your Own Device policies. You may need special security software or permissions added before you can use your personal devices to access work files or systems.</p>
<p>If you’ve logged in to a work system from a personal device, and your personal device gets compromised, your work systems can also become compromised.</p>
<p><strong>Good digital hygiene for personal devices includes:</strong></p>
<ul><li>
<p>Updating software and operating systems when prompted</p>
</li>
<li>
<p>Only download verified apps from approved App stores</p>
</li>
<li>
<p>Use anti-virus software</p>
</li>
</ul><p>Device hygiene is extremely important when sharing your device with family members—you might not know what they’re downloading!</p>
<h3>Always update your devices</h3>
<p>It’s important to update all of your work and personal devices when prompted because updates might include important security and bug fixes.</p>
<p>If you’re able to, turn on automatic updates so you never forget.</p>
<p>You can schedule automatic updates for the end of your workday, or overnight, so you’re not tempted to hit snooze on your update when it happens.</p>
<h3>Don't work near smart speakers</h3>
<p>We don’t want to spook you, but smart speakers listen to a lot of stuff, and those audio recordings are often saved somewhere that you don’t have access to.</p>
<p>Some employers may have policies preventing you from working near them, because they may pick up audio from confidential calls and video conferences.</p>
<p>IoT devices are notorious for having poor security patching support, so in general it’s a best practice to put them on a separate network and avoid working near them.</p>
</div>
      
        </div>
</div>


      

        
  

<p id="phishing">

      

      <h2>
                        Watch out for phishing
            </h2>


</p>

      


<div>
  
      <div>
      
            <div><p>Phishing scams are where cyber criminals try to extract information, login credentials and even money from you by impersonating real people and companies through email, phone calls, text messages, and social media.</p>
<p>We’re all familiar with the CRA phone scams, or fake text messages from Netflix or Apple asking to update your billing information.</p>
<p>These may seem silly and obvious, but the fact is, they work. Over 93% of all …</p></div></div></div></section></article></section></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cira.ca/resources/cybersecurity/guide-how/free-cybersecurity-course-cybersecurity-practices-remote-workers">https://www.cira.ca/resources/cybersecurity/guide-how/free-cybersecurity-course-cybersecurity-practices-remote-workers</a></em></p>]]>
            </description>
            <link>https://www.cira.ca/resources/cybersecurity/guide-how/free-cybersecurity-course-cybersecurity-practices-remote-workers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615431</guid>
            <pubDate>Tue, 23 Jun 2020 15:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[List oList of useful commands for Docker first timers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23615363">thread link</a>) | @Igor_Wiwi
<br/>
June 23, 2020 | http://amortizedcost.net/list-of-useful-commands-for-docker-first-timers/ | <a href="https://web.archive.org/web/*/http://amortizedcost.net/list-of-useful-commands-for-docker-first-timers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<!--kg-card-begin: markdown--><p>I found those commands useful during my first weeks using Docker. Hopefully, you will find it useful as well.</p>
<blockquote>
<p>Docker and Git have in common one cool feature: you can use only <em>part</em> of a container hash code. For example instead of <code>5e7fc43</code> you can use just <code>5e7</code></p>
</blockquote>
<h3 id="checkallrunningcontainers">Check all running containers</h3>
<pre><code>docker ps -a
</code></pre>
<h3 id="checkcreatednetworks">Check created networks</h3>
<pre><code>docker network ps
</code></pre>
<h3 id="showallimages">Show all images</h3>
<pre><code>docker images
</code></pre>
<h3 id="loginintoacontainerasarootuser">Login into a container as a root user</h3>
<pre><code>docker exec -u 0 -it CONTAINER_ID /bin/bash
</code></pre>
<h3 id="executeacommandonacontainerwithoutloggingin">Execute a command on a container without logging in</h3>
<pre><code>docker exec -it CONTAINER_ID cat /etc/krb5.conf  
</code></pre>
<h3 id="copyafiletofromacontainer">Copy a file to/from a container</h3>
<p>The code below will copy hosts file from a container into a current directory on your local machine</p>
<pre><code>docker cp CONTAINER_ID:/etc/hosts hosts
</code></pre>
<h3 id="usedockercomposeforsettingupenvironmentswithtwoormoreintercommunicatingcontainers">Use docker-compose for setting up environments with two or more intercommunicating containers</h3>
<p>It does not only have  better human-readable syntax but also adding a default network for those containers</p>
<!--kg-card-end: markdown-->
			</section>

			<section>

				

				

				

						

			</section>


			

      <section>
				<p>Get the latest posts delivered right to your inbox.</p>
        


      </section>

			


		</div>
	</article>
</div></div>]]>
            </description>
            <link>http://amortizedcost.net/list-of-useful-commands-for-docker-first-timers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615363</guid>
            <pubDate>Tue, 23 Jun 2020 15:38:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go vs. Crystal Performance]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 160 (<a href="https://news.ycombinator.com/item?id=23615303">thread link</a>) | @open-source-ux
<br/>
June 23, 2020 | https://ptimofeev.com/go-vs-crystal-perfomance/ | <a href="https://web.archive.org/web/*/https://ptimofeev.com/go-vs-crystal-perfomance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://ptimofeev.com/go-vs-crystal-perfomance/"><img src="https://ptimofeev.com/images/go-vs-crystal.png" alt="Go vs Crystal"></a></p>

<p>Itâ€™s a follow up post to the previous <a href="https://ptimofeev.com/ruby-vs-crystal-performance/">Ruby vs Crystal Performance</a>.</p>

<p>I guess this time it will be a fair performance comparison as both languages are compiled and statically typed.</p>

<p>We will perform a couple of tests:</p>
<ul>
  <li>Finding a number in the Fibonacci sequence as in the previous post</li>
  <li>Running an HTTP server locally and performing benchmarks with wrk</li>
</ul>

<p>Language versions installed my machine are:</p>
<ul>
  <li>go version go1.14.3 darwin/amd64</li>
  <li>Crystal 0.34.0 (2020-04-07)</li>
</ul>

<p>Iâ€™m curious to find out how Go and Crystal perform in comparison to each other.</p>

<!-- more -->

<h3 id="compilation">Compilation</h3>

<p>For the tests we will be running previously compiled programs. We will use the release flag to enable optimizations in Crystal:</p>
<div><div><pre><code>crystal build <span>--release</span> program.cr
</code></pre></div></div>

<p>Go binaries donâ€™t have a release version and we wonâ€™t be using any flags. So, itâ€™s just:</p>


<h2 id="fibonacci">Fibonacci</h2>

<p>Alright, first we will write code to generate a Fibonacci sequence for a given number. Letâ€™s find the 47th number which is 2,971,215,073.</p>

<p>Go version:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>"fmt"</span>

<span>func</span> <span>fibonacci</span><span>(</span><span>n</span> <span>uint32</span><span>)</span> <span>uint32</span> <span>{</span>
  <span>if</span> <span>n</span> <span>&lt;</span> <span>2</span> <span>{</span>
    <span>return</span> <span>n</span>
  <span>}</span>
  <span>return</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
  <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>fibonacci</span><span>(</span><span>47</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>Crystal version:</p>

<div><div><pre><code><span>def</span> <span>fibonacci</span><span>(</span><span>n</span> <span>:</span> <span>UInt32</span><span>)</span>
  <span>return</span> <span>n</span> <span>if</span> <span>n</span> <span>&lt;</span> <span>2</span>
  <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
  <span>end</span>

<span>puts</span> <span>fibonacci</span><span>(</span><span>47</span><span>)</span>
</code></pre></div></div>

<p>Results on my machine (MacBook Pro 2.2 GHz Intel Core i7):</p>

<table>
  <tbody>
    <tr>
      <td><strong>Language</strong></td>
      <td><strong>Binary size</strong></td>
      <td><strong>Run time</strong></td>
      <td><strong>Memory usage</strong></td>
    </tr>
    <tr>
      <td>go</td>
      <td>2.1M</td>
      <td>21.28s</td>
      <td>2.01M</td>
    </tr>
    <tr>
      <td>Crystal</td>
      <td>418k</td>
      <td>19.69s</td>
      <td>1.72M</td>
    </tr>
  </tbody>
</table>

<p>Crystal is slightly winning here.</p>

<p>A few observations here:</p>

<p>Crystalâ€™s binary size is 5 times smaller than Goâ€™s. Though, they can be slightly reduced in size when we omit the debug information:</p>
<div><div><pre><code>go build <span>-ldflags</span><span>=</span><span>"-w"</span> fibonacci_golang.go
</code></pre></div></div>
<p>This way the binary size goes down from 2.1M to 1.7M.</p>

<p>Also, not in this particular example, but generally Goâ€™s compilation time is much much faster than Crystalâ€™s.</p>

<h2 id="http-server">HTTP Server</h2>

<p>Now, letâ€™s create a simple HTTP server using standard libraries. Both Goâ€™s <em>net/http</em> and Crystalâ€™s <em>http/server</em> employ concurrency: Go uses goroutines and Crystal uses fibers.</p>

<p>Go version:</p>
<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>HelloServer</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>

<span>func</span> <span>HelloServer</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"Hello from %s!"</span><span>,</span> <span>r</span><span>.</span><span>URL</span><span>.</span><span>Path</span><span>[</span><span>1</span><span>:</span><span>])</span>
<span>}</span>
</code></pre></div></div>

<p>Crystal version:</p>
<div><div><pre><code><span>require</span> <span>"http/server"</span>

<span>server</span> <span>=</span> <span>HTTP</span><span>::</span><span>Server</span><span>.</span><span>new</span> <span>do</span> <span>|</span><span>context</span><span>|</span>
  <span>context</span><span>.</span><span>response</span><span>.</span><span>content_type</span> <span>=</span> <span>"text/plain"</span>
  <span>context</span><span>.</span><span>response</span><span>.</span><span>print</span> <span>"Hello from </span><span>#{</span><span>context</span><span>.</span><span>request</span><span>.</span><span>path</span><span>}</span><span>!"</span>
<span>end</span>

<span>puts</span> <span>"Listening on http://127.0.0.1:8080"</span>
<span>server</span><span>.</span><span>listen</span><span>(</span><span>8080</span><span>)</span>
</code></pre></div></div>

<p>For benchmarking we will be using <a href="https://github.com/wg/wrk" target="_blank" rel="noopener noreferrer">wrk</a>. If youâ€™re not familiar with this tool itâ€™s like a pretty well known ApacheBench (ab) but a modern version.</p>

<p>Here is how we can run a benchmark for 60 seconds, using 8 threads, and keeping 400 HTTP connections open:</p>

<div><div><pre><code>wrk <span>-t8</span> <span>-c400</span> <span>-d60s</span> http://localhost:8080/hello
</code></pre></div></div>

<p>Results for the Go server:</p>
<div><div><pre><code>Running 1m test @ http://localhost:8080/hello
  8 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.56ms    2.26ms  95.31ms   92.00%
    Req/Sec     8.77k     2.24k   15.75k    64.66%
  4190457 requests in 1.00m, 535.51MB read
  Socket errors: connect 157, read 100, write 0, timeout 0
Requests/sec:  69757.81
Transfer/sec:      8.91MB
</code></pre></div></div>

<p>Results for the Crystal server:</p>
<div><div><pre><code>Running 1m test @ http://localhost:8080/hello
  8 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.89ms    0.97ms  19.01ms   80.34%
    Req/Sec    10.54k     3.41k   18.14k    60.85%
  5035284 requests in 1.00m, 513.82MB read
  Socket errors: connect 157, read 85, write 0, timeout 0
Requests/sec:  83917.26
Transfer/sec:      8.56MB
</code></pre></div></div>

<p>Results:</p>

<table>
  <tbody>
    <tr>
      <td><strong>Language</strong></td>
      <td><strong>Binary size</strong></td>
      <td><strong>Memory usage</strong></td>
      <td><strong>CPU usage</strong></td>
      <td><strong>Throughput</strong></td>
    </tr>
    <tr>
      <td>go</td>
      <td>7.4M</td>
      <td>20.2M</td>
      <td>300%</td>
      <td>69,757</td>
    </tr>
    <tr>
      <td>Crystal</td>
      <td>966kb</td>
      <td>19.1M</td>
      <td>99%</td>
      <td>83,917</td>
    </tr>
  </tbody>
</table>

<p>Crystal again shows better results.</p>

<p>CPU utilization over 100% in the table might seem confusing. But it simply means the system uses multiple cores. One core at max is 100%.</p>

<p>My machine has 8 cores as it can be seen with the following command on macOs:</p>


<h2 id="conclusion">Conclusion</h2>

<p>Frankly speaking, we have only performed a couple of small tests to make any conclusions but Iâ€™m still excited for Crystal as a young language but showing great results.</p>


  </div></div>]]>
            </description>
            <link>https://ptimofeev.com/go-vs-crystal-perfomance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615303</guid>
            <pubDate>Tue, 23 Jun 2020 15:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Touchpad Like a MacBook update: progress on multitouch]]>
            </title>
            <description>
<![CDATA[
Score 270 | Comments 126 (<a href="https://news.ycombinator.com/item?id=23615218">thread link</a>) | @wbharding
<br/>
June 23, 2020 | https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/ | <a href="https://web.archive.org/web/*/https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="comments">

		<div id="respond">
		<h3 id="reply-title">Leave a Reply <small></small></h3><form action="https://bill.harding.blog/wp-comments-post.php" method="post" id="commentform" novalidate=""><p><span id="email-notes">Your email address will not be published.</span> Required fields are marked <span>*</span></p><p><label for="comment">Comment</label> </p><p><label for="author">Name <span>*</span></label> </p>
<p><label for="email">Email <span>*</span></label> </p>
<p><label for="url">Website</label> </p>
<p> <label for="wp-comment-cookies-consent">Save my name, email, and website in this browser for the next time I comment.</label></p>
<!-- Anti-spam plugin wordpress.org/plugins/anti-spam/ --><div><p><label>Current ye@r <span>*</span></label>
					
					
				  </p>

</div><!--\End Anti-spam plugin --></form>	</div><!-- #respond -->
	
</div></div>]]>
            </description>
            <link>https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615218</guid>
            <pubDate>Tue, 23 Jun 2020 15:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing Between Web APIs and Message Streaming]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23614909">thread link</a>) | @derberg
<br/>
June 23, 2020 | https://www.asyncapi.com/blog/choosing_between_web_apis_and_message_streaming/ | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/choosing_between_web_apis_and_message_streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<blockquote>
<p>This post originally appeared on <a href="https://medium.com/capital-one-tech/choosing-between-rest-web-apis-and-message-streaming-8e2f4813a058" target="_blank">Capital One Tech</a></p>
</blockquote>

<p>When faced with a variety of options, how are developers building APIs supposed to know which is the right one for their solution? In this article, I’m going to outline the common characteristics for both REST APIs and message streaming so developers can better understand when (and when not) to use each one.</p>

<h2 id="characteristics-of-rest-based-web-apis">Characteristics of REST-Based Web APIs<a href="#characteristics-of-rest-based-web-apis" arialabel="Anchor"> #︎</a> </h2>

<p>REST-based web APIs create a conversation between a client (the API consumer) and an API server (the backend). When we build REST-based APIs within Capital One, we use HTTP as our protocol. Our designs depend heavily on HTTP, from the methods (e.g. GET, POST, PUT, PATCH, DELETE) to the headers that help us communicate between client and server (e.g. Authorization, Accept, Content-Type).</p>

<p><img src="https://www.asyncapi.com/images/posts/choosing_between_web_apis_and_message_streaming/convo-1.webp" alt="Request/response client-server list conversation"></p>

<pre><code>GET /projects
Accept: application/json

200 OK
Content-Type: application/json
 
 [
  { "projectId":"...", "name":"..." },
  { "projectId":"...", "name":"..." },
  { "projectId":"...", "name":"..." },
  ...
 ]
</code></pre>

<p><img src="https://www.asyncapi.com/images/posts/choosing_between_web_apis_and_message_streaming/convo-2.webp" alt="Request/response client-server create conversation"></p>

<pre><code>POST/projects
Content-Type: application/json

{ "name":"...", ... }

201 Created
Content-Type: application/json
 
 { "projectId":"...", "name":"...", ... }

</code></pre>

<p>The client (or API consumer) is the app, which sends a message (i.e. an HTTP request) to the API whenever it needs something. The server then replies with the response, including a status code that indicates if the request was processed successfully (2xx error code), failed due to client error (4xx error code), or failed due to server error (5xx error code). All communication flows from the consumer to the API backend.</p>

<p>When we add in hypermedia links, we extend the conversation with some additional information that may be helpful to the client:</p>

<p><img src="https://www.asyncapi.com/images/posts/choosing_between_web_apis_and_message_streaming/convo-3.webp" alt="Request/response client-server hypermedia conversation"></p>

<pre><code>GET /projects/12345
Accept: application/json

200 OK
Content-Type: application/json
 
 { 
 "name":"...", ...,
 "_links": {
   { "self" :"/projects/1234" }, 
   { "related_projects": [
     { "4567" :"/projects/4567" }, 
     { "8901" :"/projects/8901" }, 
     { "9012" :"/projects/9012" } 
   ]}, 
   { "members": [
     { "1" :"/users/1" }, 
     { "2" :"/users/2" }, 
     { "3" :"/users/3" }, 
     { "4" :"/users/4" }, 
     { "5" :"/users/5" } 
   ]}
 }
</code></pre>

<p>REST-based APIs have a specific set of characteristics that are summarized below:</p>

<ul>
<li><strong>Request/response model</strong> — API consumers send requests to an API server and receive a response.</li>
<li><strong>Pull-based interaction</strong> — API consumers send an API request when data or functionality is required (e.g. user interface, at a pre-scheduled time).</li>
<li><strong>Synchronous</strong> — API consumers receive the response after a request is sent.</li>
<li><strong>Multiple content types</strong> — since REST APIs are built upon HTTP, responses may be JSON, XML, or other content types as necessary to support consumer needs (e.g. CSV, PDF).</li>
<li><strong>Flexible interactions</strong> — Building upon the available HTTP verbs, consumers may interact with REST-based APIs through resources in a variety of ways: queries/search, creating new resources, modifying existing resources, and deleting resources. We can also build complex workflows by combining these interactions into higher-level processes.</li>
<li><strong>Caching and concurrency protocol support</strong> — HTTP has caching semantics built-in, allow for caching servers to be placed between the consumer and API server, as well as cache control of responses and eTags for concurrency control to prevent overwriting content.</li>
<li><strong>Internal and external access</strong> — REST APIs may be restricted for internal use or for external use by partners or public developers.</li>
</ul>

<p>For most solutions, offering a REST-based API is a great starting point, allowing any application or automation script to interact with your API over HTTP.</p>

<h2 id="characteristics-of-message-streaming">Characteristics of Message Streaming<a href="#characteristics-of-message-streaming" arialabel="Anchor"> #︎</a> </h2>

<p>Unlike REST APIs, message streaming is better at providing notifications when new messages arrive. Once subscribed, the client will be notified when new messages are available:</p>

<p><img src="https://www.asyncapi.com/images/posts/choosing_between_web_apis_and_message_streaming/convo-4.webp" alt="Event-based API subscription"></p>

<pre><code>POST /subscriptions
Content-Type: application/json

{ "callbackUrl":"https://my.callback/path", ... }

201 Created
Content-Type: application/json
 
</code></pre>

<p>Now that the client is subscribed to a topic, it will receive notifications when new messages are available. This may be the result of a REST API processing incoming requests from a web or mobile app, then adding messages into the message stream topic to notify anyone that is interested:</p>

<p><img src="https://www.asyncapi.com/images/posts/choosing_between_web_apis_and_message_streaming/convo-5.webp" alt="Event-based API notifications"></p>

<pre><code>POST https://my.callback/path
&lt;&lt;project created event&gt;&gt;

POST https://my.callback/path
&lt;&lt;project archived event&gt;&gt;

POST https://my.callback/path
&lt;&lt;project updated event&gt;&gt;
</code></pre>

<p>Notice how our conversation became more interesting. We now can be notified when things change or critical business events occur; without needing to modify and redeploy the API to support a new integration that emerges in the future. This is called loose coupling, and it helps our systems be used in new ways without the originator of the messages even knowing about current and future subscribers.</p>

<p>Those familiar with message brokers will realize that this is familiar. The difference between a message broker and message streaming is that <em>message streaming allows us to revisit past messages in sequence as well</em>:</p>

<p><img src="https://www.asyncapi.com/images/posts/choosing_between_web_apis_and_message_streaming/convo-6.webp" alt="Streaming API conversation"></p>

<pre><code>&lt;&lt;request last 12 messages from project_messages topic&gt;&gt;

&lt;&lt;retrieve and send last 12 messages from project_messages topic&gt;&gt;
</code></pre>

<p>This feature is useful when we need to go aggregate values or perform a new calculation we previously didn’t realize we needed.</p>

<p>Note — we can’t filter messages or perform other aggregate queries when requesting the messages — only the client can do this after requesting the messages from the topic. REST APIs are better suited for performing ad hoc queries than message streams.</p>

<p>As you are discovering, message streaming is a different style of interaction than REST-based APIs. Additional characteristics of message streaming are summarized below:</p>

<ul>
<li><strong>Publish/subscribe model</strong> — Apps or APIs publish messages to a topic which may have zero, one, or many subscribers rather than a request/response model.</li>
<li><strong>Subscriber notification interaction</strong> — Apps receive notification when a new message is available, such as when data is modified or new data is available.</li>
<li><strong>Asynchronous</strong> — Unlike REST APIs, apps cannot use message streams to submit a request and receive a response back without complex coordination between parties.</li>
<li><strong>Single content-type</strong> — At Capital One, our message streaming is built upon Avro, a compact binary format useful for data serialization. Unlike HTTP, Avro doesn’t support other content types (e.g. CSV, PDF).</li>
<li><strong>Replayability</strong> — At Capital One, our message streaming is built on Kafka, subscribers may revisit and replay previous messages sequentially.</li>
<li><strong>No caching or concurrency protocol support</strong> — Message streaming doesn’t offer caching semantics, cache-control, or concurrency control between publisher and subscriber.</li>
<li><strong>Internal access only</strong> — Subscribers must be internal to the organization, unlike HTTP which may be externalized to partner or public consumers.</li>
</ul>

<p>Message streaming offers some additional communication options that REST-based APIs do not — push-based notifications when new data or state changes occur, and the option of revisiting past messages in the stream to perform new calculations or re-execute logic that failed previously. When combined together, REST-APIs enable consuming apps to integrate easily with an HTTP API, while message streaming allow consumers to be notified of changes without needing to check with the REST API first. This can be a powerful combination that can satisfy use cases that exist today, while allowing emerging use cases to be handled in the future — all without modifying existing systems to accommodate new solutions.</p>

<h2 id="summary">Summary<a href="#summary" arialabel="Anchor"> #︎</a> </h2>

<p>As you may have realized, choosing between a web API and message streaming isn’t difficult, as long as you understand the characteristics of each one. REST APIs are best suited to request/response interactions where the client application sends a request to the API backend over HTTP. Message streaming is best suited to notification when new data or events occur that you may want to take action upon. Just be sure to match the needs of the consumer with one or more approaches to offer a robust interface to your solution’s capabilities.</p>
</div></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/choosing_between_web_apis_and_message_streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614909</guid>
            <pubDate>Tue, 23 Jun 2020 15:10:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How not to use jsonb fields and their indexes in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23614887">thread link</a>) | @murkt
<br/>
June 23, 2020 | https://vsevolod.net/postgresql-jsonb-index/ | <a href="https://web.archive.org/web/*/https://vsevolod.net/postgresql-jsonb-index/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Since time immemorial PostgreSQL supports JSON fields and can even index
them. By immemorial I mean this functionality was added in versions 9.2 and 9.4
that are unsupported now. </p>
<p>I perfectly remember the world where PostgreSQL had no JSON support because 9.2
<a href="https://www.postgresql.org/docs/9.2/release-9-2.html">was released</a> in 2012,
and before that, I worked in a company that used MongoDB (we suffered
greatly<a href="https://vsevolod.net/postgresql-jsonb-index/#note1"><sup id="back1">[1]</sup></a>). It was an ample bit of marketing
for Mongo back then: "you can store any document without tediously defining an
ungodly schema! You gain so much flexibility!"</p>
<p>Little did we know back then that the world does not work that way, and
relational SQL databases are actually way more flexible than document-oriented
DBs, columnar DBs, or whatever.<a href="https://vsevolod.net/postgresql-jsonb-index/#note2"><sup id="back2">[2]</sup></a> Because
often we don't know what exactly are we going to do with the data, and with
relational DBs we can lay out the data however seems reasonable, and then add
indexes to support our use cases. </p>
<p>In document-oriented DBs you need to lay out your data exactly the way you're
going to query it later. Or else you'll need to migrate data inside your
schema-less database to another layout, which is way more cumbersome and
error-prone than adding some indexes and JOINs. </p>
<p>Don't trust me - there is an exceptional talk on <a href="https://www.youtube.com/watch?v=HaEPXoXVf2k">Advanced Design Patterns for
DynamoDB</a> by Rick Houlihan, a
Principal Technologist at AWS. He explains that and so much more - it's a very
information-dense presentation with interesting ideas. I found it useful even
though I don't plan to use DynamoDB nor MongoDB in the near future.</p>
<p>Anyway, JSON support was added into PostgreSQL a long time ago, because
sometimes it is useful to store some documents in the database. And it can be
indexed in <a href="https://www.postgresql.org/docs/current/datatype-json.html#JSON-INDEXING">two different
ways</a> -
full <abbr title="Generalized Inverted Index">GIN</abbr> and a special
<code>jsonb_path_ops</code> that supports indexing the <code>@&gt;</code> operator only. It means
"contains" and can be used like this:</p>
<pre><span>SELECT * FROM table WHERE jsonb_field @&gt; '{"employer": {"country": "ZA"}}';
</span></pre>
<p>Let me tell you a story about how I cleverly used this feature and it bit me in
the ass.</p>
<h2 id="story-time">Story time<a href="#story-time" aria-label="Anchor link for: story-time">🔗</a></h2>
<p>I am a co-founder at <a href="https://www.prophy.science/">www.prophy.science</a> which is
a product that can understand, search and recommend scientific papers and
experts. To do that well, we need a collection of all scientific papers, and
papers are often provided by many different providers with different ids. There
are <a href="https://www.ncbi.nlm.nih.gov/pubmed/">PubMed</a> (30M+ articles), <a href="https://www.ncbi.nlm.nih.gov/pmc/">PubMed
Central</a> (6M+ articles),
<a href="https://www.crossref.org/">Crossref</a> (80-100M+),
<a href="https://inspirehep.net/">INSPIRE</a>, there are preprint servers like
<a href="https://arxiv.org/">arXiv</a>, <a href="https://www.biorxiv.org/">biorXiv</a>,
<a href="https://www.medrxiv.org/">medRxiv</a> and many others.</p>
<p>There is a widespread system of <abbr title="Digital object
identifier">DOIs</abbr> that are used to persistently identify journal articles,
research reports and data sets. It was introduced in the year 2000, and, as many
of these bibliographic databases predate DOI standard, they have their own
identifiers. Sometimes they even cross-link their IDs between different
services, and sometimes they cross-link wrong articles.</p>
<p>Some monitoring services download data from Crossref, Pubmed, PMC and some other
sources, add them and report that they have 180 million articles, 220 million,
or some other bullshit. We strive to merge the same article from different
sources into one entity with many external identifiers. We called these
identifiers "origin ids" and stored them in a special <code>jsonb</code> column, so one row
could have a record like this:</p>
<pre><span>{"pubmed": "3782696", "pmc": "24093010", "doi": "10.3389/fnhum.2013.00489"}
</span></pre>
<p>It was a simple key-value document with a <code>jsonb_path_ops</code> index on it. And
whenever we needed to fetch an article by an origin id, we queried it using a
<code>@&gt;</code> operator like that:</p>
<pre><span>SELECT id FROM articles WHERE origin_ids @&gt; '{"pubmed": "123456"}';
</span></pre>
<p>It is a bit easier to store ids this way, no need to maintain a separate table
with hundreds of millions of rows.</p>
<p>One problem arose when we tried to query the index with many different origin
ids. There is no <code>IN</code> nor <code>ANY()</code>, so we stitched lots of <code>OR</code>s together:</p>
<pre><span>SELECT id FROM articles WHERE 
    origin_ids @&gt; '{"pubmed": "123456"}' OR 
    origin_ids @&gt; '{"pubmed": "654321"}' OR 
    origin_ids @&gt; '{"pubmed": "123321"}' OR 
    origin_ids @&gt; '{"pubmed": "456654"}';
</span></pre><h2 id="explain-everything">Explain everything<a href="#explain-everything" aria-label="Anchor link for: explain-everything">🔗</a></h2>
<p>And with enough <code>OR</code>s the query gets really slow. Why? <code>EXPLAIN</code> helpfully says
that it becomes a sequential scan (I shortened output for clarity):</p>
<pre><span>EXPLAIN
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}' OR
        origin_ids @&gt; '{"pubmed": "654321"}' OR
        ....;   - x200
                        QUERY PLAN
------------------------------------------------------------
 Seq Scan on articles  (rows=7805036)
   Filter: ((origin_ids @&gt; '{"pubmed": "123456"}') OR
            (origin_ids @&gt; '{"pubmed": "654321"}') OR   ...x200)
</span></pre>
<p>Why? For some reason it thinks that this query will return millions of rows. But
one origin id can match at most one article if my data is correct, so 200
filters should only match 0..200 rows. Let's look at <code>EXPLAIN ANALYZE</code> to check:</p>
<pre><span>EXPLAIN ANALYZE
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}' OR
        origin_ids @&gt; '{"pubmed": "654321"}' OR
        ....;   - x200
                        QUERY PLAN
------------------------------------------------------------
 Seq Scan on articles  (rows=7805036) (actual rows=200)
   Filter: ((origin_ids @&gt; '{"pubmed": "123456"}') OR
            (origin_ids @&gt; '{"pubmed": "654321"}') OR   ...x200)
</span></pre>
<p>It does indeed return only 200 rows. Hmmm... Let's check one row:</p>
<pre><span>EXPLAIN ANALYZE
 SELECT id, origin_ids
   FROM articles
  WHERE origin_ids @&gt; '{"pubmed": "123456"}';
                        QUERY PLAN
------------------------------------------------------------
 Bitmap Heap Scan on articles  (rows=43038) (actual rows=1)
   Recheck Cond: (origin_ids @&gt; '{"pubmed": "123456"}')
    -&gt;  Bitmap Index Scan on  ... (rows=43038) (actual rows=1)
         Index Cond: (origin_ids @&gt; '{"pubmed": "123456"}')
</span></pre>
<p>Supposedly 43 thousand rows for only one filter! And 7.8 million rows are 39
thousand times more than 200, which is pretty close. At the time I fired these
queries we had only 43 million of articles. PostgreSQL <a href="https://www.postgresql.org/docs/current/planner-stats.html">gathers some
statistics</a> about
values in different columns to be able to produce reasonable query plans, and
looks like it's shooting blanks for this column.</p>
<p>What's the simplest fix? Oftentimes
<a href="https://www.postgresql.org/docs/current/sql-analyze.html"><code>ANALYZE</code></a> on a table
is enough to fix broken statistics, but this time it didn't help at
all. Sometimes it's useful to adjust how many rows are analyzed to gather
statistics, and it can be adjusted down to a per-column basis with <a href="https://www.postgresql.org/docs/current/sql-altertable.html"><code>ALTER TABLE ... ALTER COLUMN ... SET STATISTICS</code></a>, but
here it had no effect as well.</p>
<p>Since version 10 PostgreSQL supports <a href="https://www.postgresql.org/docs/current/sql-createstatistics.html"><code>CREATE STATISTICS</code></a>
to gather complex statistics for inter-column dependencies and whatnot, but our
filter is single-column, no luck here as well.</p>
<h2 id="contsel">Contsel<a href="#contsel" aria-label="Anchor link for: contsel">🔗</a></h2>
<p>So I dug some more, and more... And found that operator <code>@&gt;</code> uses something
called <code>contsel</code>. It was mentioned in <a href="https://www.postgresql.org/message-id/23452.1288288224@sss.pgh.pa.us">PostgreSQL mailing
list</a>
in 2010. I tried to decrypt what <code>contsel</code> means and I think it stands for
"contains selectivity". Then I tried searching PostgreSQL sources for <a href="https://github.com/postgres/postgres/search?q=contsel&amp;unscoped_q=contsel"><code>contsel</code>
mentions</a>
and found exactly <a href="https://github.com/postgres/postgres/blob/master/src/backend/utils/adt/geo_selfuncs.c#L80">one
place</a>
in C code which mentions it:</p>
<pre><span>Datum
contsel(PG_FUNCTION_ARGS)
{
	PG_RETURN_FLOAT8(0.001);
}
</span></pre>
<p>0.001? That looks exactly like the ratio between 43 million rows in the table
and an estimated 43 thousand rows in the result. However, if we just multiply 43
thousand by 200 filters we should get 8.6 million, and PostgreSQL estimated only
7.8M. This discrepancy bothered me for a minute because I like to understand
things completely, so they won't set me up for an unpleasant surprise later<a href="https://vsevolod.net/postgresql-jsonb-index/#note3"><sup id="back3">[3]</sup></a>.</p>
<p>After a minute of contemplating the difference I realized that it's probability
in play - PostgreSQL thinks that every filter can match 0.1% of the total number
of rows and they can overlap. The actual math is:</p>
<pre><span>1 - 0.999 ** 200 = 1 - 0.819 = 0.181
</span></pre>
<p>18.1% of 43 million is 7.8 million (I'm rounding numbers here). Itch scratched
successfully.</p>
<p>And, depending on the <a href="https://www.postgresql.org/docs/current/runtime-config-query.html#RUNTIME-CONFIG-QUERY-CONSTANTS">different
costs</a>
of various factors in the config, Postgres will select either sequential scan or
will use an index. Our first solution was to slice these filters into batches
with no more than 150 of them per query. It worked quite well for a couple of
years.</p>
<h2 id="domain-modeling-failure">Domain modeling failure<a href="#domain-modeling-failure" aria-label="Anchor link for: domain-modeling-failure">🔗</a></h2>
<p>Until we learned that one article could have more than one such external
identifier per type. For example, some pre-print services grant new DOI for each
version. <a href="https://dx.doi.org/10.26434/chemrxiv.11938173.v8">10.26434/chemrxiv.11938173.v8</a>
has eight of them at the time of writing. And then it has the main DOI without
version
<a href="https://dx.doi.org/10.26434/chemrxiv.11938173">10.26434/chemrxiv.11938173</a>, and
will have another one if it will be published after peer review. There are other
cases for some other identifier types (we call these types "origin name").</p>
<p>We had two options:</p>
<ul>
<li>
<p>Store origin ids in a separate table with columns <code>article_id</code>, <code>origin_name</code>
and <code>origin_id</code> with two indexes - one on <code>article_id</code> and the other on
<code>(origin_name, origin_id)</code>;</p>
</li>
<li>
<p>Accommodate many values per key in <code>jsonb</code>. Two more possible options here:</p>
<ul>
<li>Many values per key: <code>{"doi": ["10.26434/3", "10.26434/3.v1"]}</code></li>
<li>List of pairs: <code>[["doi", "10.26434/3"], ["doi", "10.26434/3.v1"]]</code></li>
</ul>
<p>Both can be queried with <code>@&gt;</code>, but it's getting even more uglier than it was.</p>
</li>
</ul>
<p>We ended up doing kind of both - we created a separate table that's much easier
to query with many origin ids at once, and we store a list of pairs in a
separate non-indexed column so it's convenient to query.</p>
<h2 id="separate-table-speed-up">Separate table speed-up<a href="#separate-table-speed-up" aria-label="Anchor link for: separate-table-speed-up">🔗</a></h2>
<p>As a bonus, it's much-much faster to query a btree index with lots of filters
than a GIN one. With a GIN every <code>@&gt;</code> turns into a separate Bitmap Index Scan
that costs approximately millisecond for each (0.7-1.2 ms each if in
cache). With a btree index on two columns we construct a query that looks like
this:</p>
<pre><span>SELECT article_id FROM articles_origin_ids WHERE
    (origin_name = $1 AND origin_id = ANY($2)) OR
    (origin_name = $3 AND origin_id = ANY($4)) OR
    (origin_name = $5 AND origin_id = ANY($6));
</span></pre>
<p>Accessing a btree index is faster even by itself, I get 0.07 ms for Bitmap Index
Scan node in <code>EXPLAIN ANALYZE</code> for one <code>origin_name</code>, <code>origin_id</code> pair. …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vsevolod.net/postgresql-jsonb-index/">https://vsevolod.net/postgresql-jsonb-index/</a></em></p>]]>
            </description>
            <link>https://vsevolod.net/postgresql-jsonb-index/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614887</guid>
            <pubDate>Tue, 23 Jun 2020 15:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome killed my extension and won’t tell me why]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23614601">thread link</a>) | @mikob
<br/>
June 23, 2020 | https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/ | <a href="https://web.archive.org/web/*/https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <hr><!--kg-card-begin: markdown--><p><em>(Part I is <a href="https://blog.lipsurf.com/after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">here</a> or <a href="https://medium.com/@miko_89964/after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why-83a3f8d65cbc">here</a>)</em></p>
<!--kg-card-end: markdown--><p>We won the battle but not the war.</p><p>I got lucky. If I didn’t win the <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/" rel="noopener">internet attention lottery that day</a>, we may have shutdown and left our users stranded with an unmaintained tool that their daily lives depend on. The fate of web accessibility for thousands of people with disabilities, and our business lie in the hands of a single faceless gatekeeper who made a mistake.</p><p>The story may sound familiar. In short: our Chrome Extension was taken down because it supposedly didn't meet policy. After lots of development work, numerous failed resubmissions, and a week delisted from the store without communication – we complained loudly on <a href="https://www.reddit.com/r/programming" rel="noopener">Reddit</a>. Noticing our post, someone with internal access to the Chrome Webstore reached out to us on <a href="https://twitter.com/DotProto/status/1273845280668966912" rel="noopener">Twitter</a>, they said that it was a mistake and apologized. We resubmitted and were restored later that day.</p><p>Complaining on the internet should not be a support channel. Developers should not have to rely on the internet attention lottery. The Chrome Webstore has been around 10 years and needs to get its act together. We, at <a href="https://www.lipsurf.com/" rel="noopener">LipSurf</a>, want to use our temporary position of attention privilege to improve the system and help other extension developers.</p><p>Firstly, we are very thankful to the unequivocal hero, <a href="https://twitter.com/DotProto">@DotProto</a>. He not only saved <a href="https://www.lipsurf.com/" rel="noopener">us</a>, but has saved <a href="https://blog.pushbullet.com/2020/05/15/our-extension-is-safe/" rel="noopener">PushBullet recently</a>, among others. Furthermore, he does it in <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvb8mgf?utm_source=share&amp;utm_medium=web2x" rel="noopener">his free time</a>.</p><p>Although <a href="https://twitter.com/DotProto">@DotProto</a> says CWS is working to <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvb8mgf?utm_source=share&amp;utm_medium=web2x" rel="noopener">improve internally</a>, it would be foolish for us to stand on the sidelines, just waiting ,  hoping. The issues are clearly systemic, as cries for help <a href="https://groups.google.com/a/chromium.org/forum/#!forum/chromium-extensions" rel="noopener">litter the CWS forums</a>, and our Reddit post was <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9haxs?utm_source=share&amp;utm_medium=web2x" rel="noopener">full</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvaosgv?utm_source=share&amp;utm_medium=web2x" rel="noopener">of</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9to0o?utm_source=share&amp;utm_medium=web2x" rel="noopener">“me too”</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9pkca?utm_source=share&amp;utm_medium=web2x" rel="noopener">stories</a>. </p><p>This can and will happen again.</p><p>Therefore, we are starting a group today for Chrome Extension developers to work together in check with CWS. It's not a technical support channel, nor a platform to get attention when CWS is unresponsive. It's a place for Chrome Extension developers to rally together and discuss improving the foundation we stand on (it also won't be hosted nor managed by Google).</p><p>United, we can have a stronger, common voice to:</p><ol><li><strong>Pressure Google Chrome to allow for 3rd party extension stores.</strong></li></ol><p>This would break down the walled garden of extensions, give extension developers a leveler playing field, and lower the risk of getting wiped out on CWS's whim.</p><p>2. <strong>Pressure CWS to be more fair and communicative with extension publishers.</strong></p><p>Canned emails about rejections with only general policy information are “lose-lose” for publishers and CWS alike. Both parties waste time because of all the guesswork involved currently — especially when CWS makes a mistake.</p><hr><p>We need to start building our defenses and forging relationships today. If we don’t unite and speak together, we will forever be powerless and at the mercy of our gatekeeper. We also open our forum to CWS staff, and extension advocates like <a href="https://twitter.com/DotProto">@DotProto</a>. We don’t want to work against each other, after all – a good platform should &nbsp;work &nbsp;<em>with us</em> &nbsp;not &nbsp;<em>against us</em>.</p><p><strong>If you are a extension developer, or know any extension developers, please share or start by joining us by filling out the form below.</strong> We plan to open the forum once we know that there's enough interest.</p><h3 id="faqs">FAQs</h3><p><em>What power will we have together?</em></p><p>Building awareness to start. We will rally support from other developers and end users alike. One extreme example could be a coordinated a Chrome Extension blackout date. A less extreme example would be proposing ideas as a group, instead of as individuals to Google Chrome that would improve the experience for extensions (eg. improved permissions).</p><p><em>What about adware, or privacy intruding extensions?</em></p><p>If 3rd party extension stores were possible, they would be free to setup their own barriers – monetary or otherwise. It's very possible for a 3rd party extension store to do a <a href="https://www.reddit.com/r/IAmA/comments/dwfbmf/im_brendan_eich_inventor_of_javascript_and/f7mhhay?utm_source=share&amp;utm_medium=web2x">better job</a> <a href="https://forklog.media/google-chrome-extension-with-32m-downloads-has-malicious-add-ons-that-steal-data-report/">than Google</a> at blocking malicious extensions. </p><!--kg-card-begin: html--><!--kg-card-end: html-->
    </div></div>]]>
            </description>
            <link>https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614601</guid>
            <pubDate>Tue, 23 Jun 2020 14:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cohort Analysis Makes a Difference]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23614345">thread link</a>) | @emiratli
<br/>
June 23, 2020 | https://tractific.com/blog/customer-cohort-analysis | <a href="https://web.archive.org/web/*/https://tractific.com/blog/customer-cohort-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Analytics is hard. What is harder than analyzing data is coming up with actionable insights to convert more. Most people are confused with the cohort analysis because they know that their reason to analyze data is to gain actionable insights, however, cohort analysis is hard to interpret. In this article, we are going to explain cohort analysis in-depth but simple enough to enable you to interpret your users' actions. Let's start with the definition.</p><h2>Definition of Cohort Analysis</h2><p>As a definition, cohort analysis is a technique that focuses on the behavior of specific 'cohorts' of visitors/users overtime to uncover insights about their experience with your website/product. We can say that cohort analysis is a combination of behavioral analysis and user experience.</p><p>What makes it different from others and a little difficult to interpret is cohort analysis is dynamic. Instead of summing your session or page activities over a fixed time range, cohort analysis describes behaviors of specific groups of users <b>OVER TIME</b> on your website - which makes the analysis somewhat harder to interpret and turn it into action. </p><h2>Cohort Analysis is Great For</h2><p>The cohort is super helpful for a variety of things but it is especially helpful to analyze your visitors' experience and behaviors after changing your website.  No matter what you change you change to increase your UX/UI or to add value to your product. With cohort analysis, you can understand whether it worked and how it affected.</p><p>You can start your cohort analysis by choosing a group of customers and a time period. You can choose your group by their referrers, age, industry, etc. Let's say you chose SaaS founders living in Estonia and a week of the time period. What you have to do before changing your website is to analyze this group's experience with your product over a week. After you change the website analyze the <b>same group over a week</b>. And compare the results to see the effects of the change you made on SaaS founders living in Estonia and their experience with your product. What you might see can be a decrease/increase in retention, increase/decrease in session time, etc. With this comparison, you will interpret the effectiveness of the change you made. Other examples to analyze with Cohort Analysis: </p><p><img src="https://tractific.com/res/images/5ef1cd4ab7fd714923784975.gif" alt="Dashboard gif"></p><ul>      <li>Ad content</li><li>Channels</li><li>Campaigns/experiments</li><li>Website redesigns</li><li>New product lines and service offerings</li><li>Sales, discounts, promotion campaigns</li></ul><h2>Pitfalls in Cohort Analysis</h2><p>There are some cases that you cannot identify a user as a part of a cohort thus cannot analyze their behaviors and experiences with your product. Some examples are as following:</p><ul><li>Clearing browser cookies</li><li>Visiting site on a different device or browser</li><li>Visiting the site on incognito mode</li></ul><p>Other than these factors there might and probably will be confounding variables which are factors that affect the dependent variable, in this case user behavior, other than dependent variable, the change you made. Confounding variables could be the device your user is using to access your website or time of day they use your product. These variables can affect their behaviors. To decrease these factors' effect you have to continuously use Cohort Analysis and compare results between time periods. But always remember to <b>compare the same cohorts</b>.</p><p>Another factor that can affect the cohort analysis is a discount. Discounts can affect your users' retention and they must be carefully analyzed. If you make a %50 discount this week, your retention will probably increase. However, you should use cohort analysis and look if other reasons are also increasing your retention such as your new features and design. The only way to be sure is again comparing the <b>results of the same cohort</b>. If you use Cohort Analysis after the discount and see the same retention then you can come to a conclusion.</p><h2>Vanity Metrics in Cohort Analysis</h2><p>Vanity Metrics, again. Cohort Analysis is really important but there are still vanity metrics to consider after your analysis to make the best out of your analysis and efforts. Lean Startup has a great example of this. Let's say we wanted to measure  your app's engagement by number of photos sent. Each week, we take all the users who joined, and then look at the average number of photos each user send in their first day. We work really hard for 4 weeks, and we hope to see this number rise. Instead, we see this:</p><table><tbody><tr><th>Weeks</th><th>Number of photos sent per user</th><th>Total photos sent</th></tr><tr><td>Week 1</td><td>5</td><td>100</td></tr><tr><td>Week 2</td><td>5</td><td>200</td></tr><tr><td>Week 3</td><td>5</td><td>350</td></tr><tr><td>Week 4</td><td>5</td><td>400</td></tr></tbody></table><p>Did you notice how <b>total photos sent</b> increases but the metric that should be increasing, <b>the number of photos sent per user</b> is still 5. This is an excellent visualization of a vanity metric. What this example tells us is choosing the right metrics is essential for Cohort Analysis. If you chose total photos as a metric, you cannot grow.</p><table><tbody><tr><th>Weeks        </th><th>Number of photos sent per user</th><th>Total photos sent</th></tr><tr><td>Week 1</td><td>5</td><td>100</td></tr><tr><td>Week 2</td><td>6</td><td>250</td></tr><tr><td>Week 3</td><td>8</td><td>400</td></tr><tr><td>Week 4</td><td>10</td><td>600</td></tr></tbody></table><h2>Conclusion</h2><p>Cohort analysis is a hard to interpret data analysis technique but if you can understand it, it is extremely useful to understand a group of users' behaviors and experiences with your product. We hope that this simple guide helped you to better understand Cohort Analysis.</p><p><em>Stay Optimized!</em></p></div><p>Join early Tractific users getting product updates, blog posts, and free access to beta.</p></div>]]>
            </description>
            <link>https://tractific.com/blog/customer-cohort-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614345</guid>
            <pubDate>Tue, 23 Jun 2020 14:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is WebP really better than JPEG?]]>
            </title>
            <description>
<![CDATA[
Score 422 | Comments 304 (<a href="https://news.ycombinator.com/item?id=23614305">thread link</a>) | @kasabali
<br/>
June 23, 2020 | https://siipo.la/blog/is-webp-really-better-than-jpeg | <a href="https://web.archive.org/web/*/https://siipo.la/blog/is-webp-really-better-than-jpeg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<div>
				<section id="content" role="main">
					<div>
												<div>
									<article id="post-214">
			<section>
				
				
				<div>
					                                                                                    <p>If you have used tools like Google’s PageSpeed Insights, you probably have run into a suggestion to use “next-gen image formats”, namely Google’s <a href="https://developers.google.com/speed/webp">WebP image format</a>. Google <a href="https://developers.google.com/speed/webp/docs/webp_study">claims that</a> their WebP format is 25 – 34% smaller than JPEG at equivalent quality.</p>
<p>When testing out WebP using a <a href="https://github.com/siiptuo/pio">perceptual image optimizer</a>, I ran into a peculiar issue: the WebP files were of very similar size compared to compressed JPEGs, in many cases larger. I’m not only one who noticed this, but Mozilla also noted in <a href="https://research.mozilla.org/2013/10/17/studying-lossy-image-compression-efficiency/">their 2013 study</a> that WebP doesn’t generally have much better compression efficiency when compared to JPEG. (Note that Mozilla somewhat walked back from this and implemented <a href="https://hacks.mozilla.org/2019/01/firefox-65-webp-flexbox-inspector-new-tooling/">WebP support</a> for Firefox in 2019)</p>
<p>I think Google’s result of 25-34% smaller files is mostly caused by the fact that they compared their WebP encoder to the JPEG reference implementation, Independent JPEG Group’s <a href="https://linux.die.net/man/1/cjpeg">cjpeg</a>, not Mozilla’s improved <a href="https://calendar.perfplanet.com/2014/mozjpeg-3-0/">MozJPEG</a> encoder. I decided to run some tests to see how cjpeg, MozJPEG and WebP compare. I also tested the new AVIF format, based on the open AV1 video codec. AVIF support is already in Firefox behind a flag and should be coming soon to Chrome if <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=960620">this ticket</a> is to be believed.</p>
<h2>Images and Tools</h2>
<p>For the testing I used the <a href="http://r0k.us/graphics/kodak/">Kodak image dataset</a> in 3 different sizes: 500 px, 1000px and 1500px.</p>
<ul>
<li>For JPEG conversion I used cjpeg with <code>--optimize</code> flag, <code>--progressive</code>  flag and 4:2:0 chroma subsampling.</li>
<li>For MozJPEG conversion I used MozJPEG with <code>--optimize</code> flag, <code>--progressive</code>  flag and 4:2:0 chroma subsampling</li>
<li>For WebP  I used cwebp with <code>-m 6</code> flag for maximum compression and <code>-af</code> for auto filter which presumably trades encoding time for increased quality. WebP only supports 4:2:0 subsampling so this doesn’t need to be specified separately.</li>
<li>For AVIF I used <a href="https://github.com/joedrago/colorist">colorist</a> with flags <code>--tonemap off</code>, <code>--yuv 420</code> and <code>--speed 0</code> which is the slowest but highest quality encoding</li>
</ul>
<p>In addition to these, ImageMagick was used to scale down the images from the originals and converting between PNG, WebP and TGA (cwebp only supports TGA input). All conversions were done in sRGB color space.</p>
<p>For comparing the quality I used kornelski’s <a href="https://github.com/kornelski/dssim">dssim utility</a> which calculates <a href="https://en.wikipedia.org/wiki/Structural_similarity">structural similarity</a> index between images. My target SSIM is 0.0044 which <a href="https://gist.github.com/joppuyo/12fe6fb5e5fa532b21e2c8098634c7c9">roughly corresponds</a> to JPEG quality of 85.</p>
<h2>Results for 500px images</h2>

<p><a href="https://webp-test-500.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=6b39e3fd553c4abb419975a7ae5e4541" srcset="https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=6b39e3fd553c4abb419975a7ae5e4541 1400w,https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=6b39e3fd553c4abb419975a7ae5e4541 1080w,https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=6b39e3fd553c4abb419975a7ae5e4541 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 11% smaller, WebP is 18% smaller compared and AVIF is 31% smaller at the equivalent SSIM index.</p>
<h2>Results for 1000px images</h2>

<p><a href="https://webp-test-1000.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-700x475.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6" srcset="https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 1400w,https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 1080w,https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-700x475.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 11% smaller, WebP is also 11% smaller compared and avif is 28% smaller at the equivalent SSIM index.</p>
<h2>Results for 1500px images</h2>

<p><a href="https://webp-test-1500.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0" srcset="https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 1400w,https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 1080w,https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 9% smaller, WebP is the same size as cjpeg and AVIF is 28% smaller at the equivalent SSIM index.</p>
<h2>Average for all image sizes</h2>
<p>Just for fun, I graphed the averages of all image sizes. I know this might not be a fair comparison but still, here you go:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/all-sizes-target-quality-85-average-file-size.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-700x475.png?ver=4c2aa46286fabb012d9e6339114fb697" srcset="https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-1400x950.png?ver=4c2aa46286fabb012d9e6339114fb697 1400w,https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-1080x733.png?ver=4c2aa46286fabb012d9e6339114fb697 1080w,https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-700x475.png?ver=4c2aa46286fabb012d9e6339114fb697 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>As you can see, when compared to cjpeg, MozJPEG is about 9% smaller, WebP is 6% smaller and AVIF is 30% smaller.</p>
<p>If you are interested, you can view the raw data for all the images as a spreadsheet <a href="https://docs.google.com/spreadsheets/d/1j-5ZqbSnIt0qtxh1T83sVjfR7YZIhfdgtWG28F3I8U8/edit?usp=sharing">here</a>. Source code for the comparison app and raw images are available on GitHub: <a href="https://github.com/joppuyo/compare-app-webp-500">500px</a>, <a href="https://github.com/joppuyo/compare-app-webp-1000">1000px</a> and <a href="https://github.com/joppuyo/compare-app-webp-1500">1500px</a>. Check the originals directory for the raw images.</p>
<h2>Conclusions</h2>
<h3>Is WebP better than JPEG?</h3>
<p>So, is WebP better than JPEG? It depends if you are using the reference libjpeg library or the improved MozJPEG encoder.</p>
<p>WebP seems to have about 10% better compression compared to libjpeg in most cases, except with 1500px images where the compression is about equal.</p>
<p>However, when compared to MozJPEG, WebP only performs better with small 500px images. With other image sizes the compression is equal or worse.</p>
<p>I think MozJPEG is the clear winner here with consistently about 10% better compression than libjpeg.</p>
<p>Since most of the time WebP is used alongside JPEG fallback, by using WebP you will essentially double your storage costs with little benefit. So, in the end, I would recommend using WebP in only the following cases:</p>
<ul>
<li>You have a lot of small images in the 500 px range.</li>
<li>You can’t use MozJPEG.</li>
<li>You pick an arbitrary fixed quality instead of using a metric like SSIM.</li>
</ul>
<p>In any case, when converting images to WebP, check that they are actually smaller than the JPEG equivalent. There’s no need to serve larger images to your users than needed.</p>
<h3>How do image formats derived from video codecs differ from JPEG?</h3>
<p>One notable difference between JPEG encoders compared to WebP (based on VP8) and AVIF (based on AV1) is that it’s pretty easy to see how the latter were derived from video codecs. JPEG compression uses the same quantization factor for each 16x16 “macroblock” so the compression is consistent throughout the image.</p>
<p>WebP and AVIF on the other hand use different compression factors for different parts of the image so while the detailed parts of the image retain their quality, surfaces like skin or the sky which have low detail are “smoothed out”. This is especially noticeable with the red window shutters in this image.</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/jpeg-vs-webp-vs-avif.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-700x194.png?ver=63b1240368ae03d4ad9fa923e352b44f" srcset="https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1440x399.png?ver=63b1240368ae03d4ad9fa923e352b44f 1440w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1400x388.png?ver=63b1240368ae03d4ad9fa923e352b44f 1400w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1080x300.png?ver=63b1240368ae03d4ad9fa923e352b44f 1080w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-700x194.png?ver=63b1240368ae03d4ad9fa923e352b44f 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>While the bricks in the image look sharp, the doors look almost like they have a “Smart blur” Photoshop filter applied to them.</p>
<p>I think this kind of adaptive compression is a valuable thing to have. Think about a photo with a forest and the sky. A traditional image encoder would have to decide a single compression ratio for the whole image. While it’s good to use a lot of bits for the forest trees with high-frequency detail, they are wasted for the sky with low-frequency detail.</p>
<p>A smarter encoder like WebP or AVIF will be able to process these areas separately to use the available bits efficiently.</p>
<h3>Is AVIF the future of image formats?</h3>
<p>I think AVIF is a really exciting development and compared to WebP it seems like a true next-generation codec with about 30% better compression ratio compared to libjpeg. Only concern I have is the excessive blurring of low detail areas. It remains to be seen if this can be improved when more advanced tooling becomes available.</p>
<p>Right now the tooling is a bit spotty. <a href="https://github.com/joedrago/colorist">Colorist</a> was the only program I found which can reliably encode AVIF files. Encoding AVIF files is also really slow! A big image can take several minutes to encode. I’m using the AOM encoder but <a href="https://github.com/xiph/rav1e">rav1e</a> might be faster. Browser support also still in progress. Firefox has AVIF support but it’s behind a flag and it doesn’t seem to <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1634741">read ICC profiles correctly</a>. Still, it’s more browser support than Apple’s "next-gen" HEIF which <a href="https://caniuse.com/heif">isn’t even supported in Safari</a>.</p>
<p>I think in the next year or so we might see a radically different landscape. With Chrome on board, we could see supported browsers jump to something like 70% of all browsers which means AVIF would be a pragmatic thing to support in web projects.</p>
<h2>Caveats</h2>
<p>In this test, I only used photographic images. WebP may be better when compressing graphics, for example, since it supports lossy compression for the alpha channel which PNG and JPEG do not.</p>
<p>I also tested the images in “Web quality” target of 85 so WebP may perform differently in very high or very low-quality settings.</p>
<p>Also, Google’s study used <a href="http://mehdi.rabah.free.fr/SSIM/">a different program</a> to compute the SSIM values. In my tests, I used the <a href="https://github.com/kornelski/dssim">dssim</a> utility which computes multi-scale SSIM in …</p></div></section></article></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://siipo.la/blog/is-webp-really-better-than-jpeg">https://siipo.la/blog/is-webp-really-better-than-jpeg</a></em></p>]]>
            </description>
            <link>https://siipo.la/blog/is-webp-really-better-than-jpeg</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614305</guid>
            <pubDate>Tue, 23 Jun 2020 14:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starving to Health: Fasting-Mimicking Diet]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 13 (<a href="https://news.ycombinator.com/item?id=23614196">thread link</a>) | @tosh
<br/>
June 23, 2020 | https://artlapinsch.com/2020/06/23/starving-to-health-fasting-mimicking-diet/ | <a href="https://web.archive.org/web/*/https://artlapinsch.com/2020/06/23/starving-to-health-fasting-mimicking-diet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1660">
			
	
	<div>
		<div>
			<p><em><strong>Disclaimer:</strong> I’m not a medical professional and this is <span>not</span> medical advice. This post is a summary of my personal experience and my best understanding of the science behind it. </em></p>
<p><em>Before committing to any diet do your own research and consult with your doctor.&nbsp;</em></p>
<hr>
<p>My girlfriend asked me if I’d be interested to try the Fasting-Mimicking Diet <em>(FMD)</em>.</p>
<p><strong>The promise:</strong> Restrict your calories for 5 days to improve your health.</p>
<figure><img src="https://media1.giphy.com/media/3ohzdFCn9mYfmuAmEU/giphy.gif?cid=ecf05e473c4a6681a4cb7459bab39b41c30eccddc5a4c4a6&amp;rid=giphy.gif" alt="When I think of fasting I think of this (source: https://gph.is/2oOBcP0)" width="498" height="372"><figcaption>When I think of fasting I think of this (source: <a href="https://gph.is/2oOBcP0" rel="nofollow">https://gph.is/2oOBcP0</a>)</figcaption></figure>
<p>I said ‘yes’ and we gave it a try.</p>
<hr>

<p>Before diving into our experience it helps to define/clarify a few key concepts:</p>
<h3>What Is the Fasting Mimicking Diet and How Does it Work</h3>
<p><span>FMD summary:</span></p>
<ul>
<li><strong>Why:</strong> Improve metabolic markers/risk factors to increase healthy lifespan</li>
<li><strong>How:</strong> 1 FMD cycle = 5 consecutive days of restricted feeding <em>(25-35% of normal calorie needs)</em></li>
<li><strong>What:</strong> Macro-nutrient composition: ~ 10% protein / 45% fat / 45% carbohydrates</li>
<li><strong>Who:</strong> Popularized by <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6816332/" target="_blank" rel="noopener">Dr. Valter Longo</a> via his book <em>‘The Longevity Diet’</em> and a series of clinical studies (e.g. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6816332/" target="_blank" rel="noopener"><em>“Fasting-mimicking diet and markers/risk factors for aging, diabetes, cancer, and cardiovascular disease”</em></a>)</li>
</ul>
<p><span><iframe width="1088" height="612" src="https://www.youtube.com/embed/bsrJuTF3K98?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p><span>From the research paper:</span> <em>“Calorie restriction or changes in dietary composition can enhance healthy aging, but the inability of most subjects to adhere to chronic and extreme diets, as well as potentially adverse effects, limits their application.”</em></p>
<p>As a result Dr. Longo developed FMD increase adherence/success of the diet, while allowing the body to activate autophagy.</p>
<h3>Autophagy: “Healthy Auto-Cannibalism”</h3>
<p><a href="https://en.wikipedia.org/wiki/Autophagy" target="_blank" rel="noopener">Autophagy</a> <em>‘is the natural, regulated mechanism of the cell that removes unnecessary or disfunctional components.’</em></p>
<p><span><iframe width="1088" height="612" src="https://www.youtube.com/embed/Hqs1WzTwBEU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<h3>Ketosis: Say ‘Hi’ to Your New Metabolic State</h3>
<p><em><a href="https://en.wikipedia.org/wiki/Ketosis" target="_blank" rel="noopener">Ketosis</a> is a metabolic state characterized by elevated levels of ketone bodies in the blood or urine.[1] Physiologic ketosis is a normal response to low glucose availability, such as low-carbohydrate diets or fasting, that provides an additional energy source for the brain in the form of ketones.</em></p>
<p>Under optimal conditions, your body will switch to nutritional ketosis during FMD to generate energy from available resources.</p>
<hr>

<blockquote><p>“By failing to prepare, you are preparing to fail.” ― <strong>Benjamin Franklin</strong></p></blockquote>
<p>FMD is a <a href="https://en.wikipedia.org/wiki/Complexity" target="_blank" rel="noopener">complex</a> diet, since its components are interconnected and have a small margin of error:</p>
<ul>
<li><strong>Calorie count</strong>
<ul>
<li><span>Day 1:</span> 10-16 calories per kg of body weight</li>
<li><span>Days 2-5:</span> 7-11 calories per kg of body weight</li>
</ul>
</li>
<li><strong>Macro composition</strong> <em>(protein/fat/carbs)</em>
<ul>
<li><span>Day 1:</span> 10/56/34</li>
<li><span>Day 2-5:</span> 9/44/47</li>
</ul>
</li>
<li><strong>Measurement</strong>
<ul>
<li>If you want to know what is actually going on and if the diet is effective you need to measure</li>
</ul>
</li>
<li><strong>Energy levels</strong>
<ul>
<li>Your energy levels are changing due to an adaptation in metabolism</li>
</ul>
</li>
</ul>
<p>All of the above need prep and planning.</p>
<h3>Meal Planning</h3>
<p>There are at least 2 ways of doing FMD:</p>
<ol>
<li><strong>Pre-made:</strong> Buying pre-packaged meals from <a href="https://prolonfmd.com/" target="_blank" rel="noopener">Prolon</a></li>
<li><strong>DIY:</strong> Create your own meal plan.</li>
</ol>
<p>We decided to create our own meal plan, since it was cheaper and arguably tastier. We pre-planned our meals in a <a href="https://docs.google.com/spreadsheets/d/1mwz9QcQTp1jRIv03WNCKmz43ueivMBP6LkM0CnCYuo0/edit#gid=0" target="_blank" rel="noopener">google sheet</a> <em>(you can copy the sheet and to create/use/edit your own version)</em>.</p>
<p>The planning sheet consists of 4 main areas:</p>
<ol>
<li><a href="https://docs.google.com/spreadsheets/d/1mwz9QcQTp1jRIv03WNCKmz43ueivMBP6LkM0CnCYuo0/edit#gid=0" target="_blank" rel="noopener"><strong>Master sheet:</strong></a> Enter body weight to calculate your daily calorie + macro targets.</li>
<li><a href="https://docs.google.com/spreadsheets/d/1mwz9QcQTp1jRIv03WNCKmz43ueivMBP6LkM0CnCYuo0/edit#gid=1394988095" target="_blank" rel="noopener"><strong>Ingredients:</strong></a> List of ingredients and their nutritional values. This sheet is used to feed data into the meal plans.</li>
<li><a href="https://docs.google.com/spreadsheets/d/1mwz9QcQTp1jRIv03WNCKmz43ueivMBP6LkM0CnCYuo0/edit#gid=36342745" target="_blank" rel="noopener"><strong>Meal plans:</strong></a> For each day of the diet we would come up with a recipe <em>(see gif below)</em> to arrive as close as possible at the caloric/nutritional target values.</li>
<li><a href="https://docs.google.com/spreadsheets/d/1mwz9QcQTp1jRIv03WNCKmz43ueivMBP6LkM0CnCYuo0/edit#gid=1633513243" target="_blank" rel="noopener"><strong>Measurements:</strong></a> Sheet to record measurements. In our case it was primarily data from our smart scale, the glucose measuring device, and a set of ketone strips.</li>
</ol>
<figure data-shortcode="caption" id="attachment_1681" aria-describedby="caption-attachment-1681"><img data-attachment-id="1681" data-permalink="https://artlapinsch.com/2020/06/23/starving-to-health-fasting-mimicking-diet/kapture-2020-06-23-at-14-21-37/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/06/kapture-2020-06-23-at-14.21.37.gif" data-orig-size="2132,838" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Typical meal planning workflow" data-image-description="<p>Typical meal planning workflow</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/06/kapture-2020-06-23-at-14.21.37.gif?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2020/06/kapture-2020-06-23-at-14.21.37.gif?w=1024" src="https://qndtoolkit.files.wordpress.com/2020/06/kapture-2020-06-23-at-14.21.37.gif?w=1088&amp;h=428" alt="Typical meal planning workflow" width="1088" height="428"><figcaption id="caption-attachment-1681">Typical meal planning workflow</figcaption></figure>
<p>Since we were 2 people we had both of our target values on each day’s meal planning sheets. After preparing a meal plan for the ∑ of our caloric/nutritional targets we would split the food out by the relative percentages and weigh/distribute it accordingly.</p>
<p><span>Example:</span> 100g of salad = 43g for person 1 and 57g for person 2.</p>
<h3>Food</h3>
<p>We primarily ended up eating the following:</p>
<ul>
<li><strong>Vegetable Stews/Soups:</strong> Easy to prepare in batch. Large amount of food/volume while low in calories.</li>
<li><strong>Olives &amp; Olive Oil:</strong> Quick and easy way to hit your fat target.</li>
<li><strong>Nuts:</strong> Snack full of good fats and proteins.</li>
<li><strong>Vegetable Salads:</strong> Spinach + Broccoli + Avocado + Dressing // Helps to change up the taste palette.</li>
</ul>
<p>We supplemented omega-3 fish oil, magnesium, green superfood powder, and <a href="https://www.youtube.com/watch?v=ho4qdUfHqHY" target="_blank" rel="noopener">glycerol</a> in accordance with FMD.</p>
<h3>Measurement</h3>
<p>If you don’t want to <em>‘fly blindly’</em> you should measure certain markers to get a quantifiable measure of your diet’s success <em>(or lack thereof)</em>.</p>
<p>We used 3 tools to get our measures:</p>
<ul>
<li><strong><a href="https://www.amazon.de/RENPHO-K%C3%B6rperfettwaage-Personenwaage-Skelettmuskel-Knochengewicht/dp/B01N1UX8RW" target="_blank" rel="noopener">Smart scale</a>:</strong> Body weight; body fat %; visceral fat; lean body mass; etc. // Overall it feels like the scale we have is not 100% precise since body fat seems to be a function of body weight, but at least you can get a directionally-correct indicator.</li>
<li><a href="https://www.beurer.com/web/de/produkte/medical/blutzucker/blutzuckermessgeraete/gl-50-evo-mg-dl.php" target="_blank" rel="noopener"><strong>Blood glucose measuring device:</strong></a> Pricking your finger in the morning is fun.</li>
<li><a href="https://www.amazon.com/Ketone-Strips-Smackfat-High-Quality/dp/B00SODYZQK" target="_blank" rel="noopener"><strong>Ketone strips:</strong></a> Shows if ketone levels in your urine exceed 0.5 mmol/l – if so, it means you entered into nutritional ketosis.</li>
</ul>
<h3>Timing</h3>
<p>Since we wanted to avoid an energy dip during the work week we decided to start the 5-day cycle on a Saturday.</p>
<p>It was a good choice.</p>
<hr>

<p>We noticed a couple of things during our 5-day FMD cycle.</p>
<h3>Days 1 &amp; 2: Low Energy Levels and Mild Headaches</h3>
<p>Days 1 and 2 were kind of tough.</p>
<p>I started having a mild but persistent headache, which was most likely caused by caffeine withdrawal. Usually I drink 1-2 cups of filter coffee per day.</p>
<p>During the diet we switched over to tea <em>(rooibos tea; herbal teas)</em> and decaf coffee. Mix decaf coffee with MCT/Coconut oil and a pinch of sea salt and it tastes like a bullet-proof coffee. At least you have a tasty substitute for the real thing.</p>
<figure data-shortcode="caption" id="attachment_1696" aria-describedby="caption-attachment-1696"><img data-attachment-id="1696" data-permalink="https://artlapinsch.com/2020/06/23/starving-to-health-fasting-mimicking-diet/processed-with-vsco-with-hb1-preset-5/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg" data-orig-size="2306,2317" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;Processed with VSCO with hb1 preset&quot;,&quot;created_timestamp&quot;:&quot;1592332325&quot;,&quot;copyright&quot;:&quot;Copyright 2020. All rights reserved.&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.083333333333333&quot;,&quot;title&quot;:&quot;Processed with VSCO with hb1 preset&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Vegetable Quinoa Stew FTW" data-image-description="<p>Vegetable Quinoa Stew FTW</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg?w=300" data-large-file="https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg?w=1019" src="https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg?w=1019&amp;h=1024" alt="Vegetable Quinoa Stew FTW" width="1019" height="1024" srcset="https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg?w=1019&amp;h=1024 1019w, https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg?w=2038&amp;h=2048 2038w, https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg?w=150&amp;h=150 150w, https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg?w=300&amp;h=300 300w, https://qndtoolkit.files.wordpress.com/2020/06/caa79004-ed4c-4c45-97f4-b3428a4d3e93-51cbdb7f-7166-4ed6-97d5-98c182705b34.jpg?w=768&amp;h=772 768w" sizes="(max-width: 1019px) 100vw, 1019px"><figcaption id="caption-attachment-1696">Vegetable Quinoa Stew FTW</figcaption></figure>
<p>We noticed a gradual decline in energy over the course of the first 48 hours. Regular tasks <em>(housekeeping; cooking; etc.)</em> was easy but anything involving physical activity <em>(extended walks; climbing stairs; etc.)</em> was noticeably more difficult. We decided to stay in, watch TV shows, and take it easy.</p>
<p>Mentally or physically taxing activities would have been tough for us.</p>
<h3>Days 3 – 5: Ketosis and Newly-Found Energy</h3>
<p>At around 36-48 hours into the diet both of us noticed a clear shift. We felt more focused, less hungry, less tired.</p>
<p>According to our ketone levels we had entered nutritional ketosis.&nbsp;All in all it felt much bette than expected and we didn’t really have crazy food cravings.</p>
<figure data-shortcode="caption" id="attachment_1697" aria-describedby="caption-attachment-1697"><img data-attachment-id="1697" data-permalink="https://artlapinsch.com/2020/06/23/starving-to-health-fasting-mimicking-diet/processed-with-vsco-with-hb1-preset-6/" data-orig-file="https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg" data-orig-size="3024,3040" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8 Plus&quot;,&quot;caption&quot;:&quot;Processed with VSCO with hb1 preset&quot;,&quot;created_timestamp&quot;:&quot;1592397313&quot;,&quot;copyright&quot;:&quot;Copyright 2020. All rights reserved.&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.11111111111111&quot;,&quot;title&quot;:&quot;Processed with VSCO with hb1 preset&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Zucchini noodles with tomato sauce" data-image-description="<p>Zucchini noodles with tomato sauce</p>
" data-medium-file="https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg?w=298" data-large-file="https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg?w=1019" src="https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg?w=1019&amp;h=1024" alt="Zucchini noodles with tomato sauce" width="1019" height="1024" srcset="https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg?w=1019&amp;h=1024 1019w, https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg?w=2038&amp;h=2048 2038w, https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg?w=150&amp;h=150 150w, https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg?w=298&amp;h=300 298w, https://qndtoolkit.files.wordpress.com/2020/06/38a74ca7-48fa-47c4-adc3-cb5e6924cd11-9cd9c2db-7b81-4dbf-9867-20829fbdb414.jpg?w=768&amp;h=772 768w" sizes="(max-width: 1019px) 100vw, 1019px"><figcaption id="caption-attachment-1697">Zucchini noodles with tomato sauce</figcaption></figure>
<p>On day 5 it started to get boring.</p>
<h3>Day 6: Easy Refeeding</h3>
<p>After the diet you are supposed to start easy with broths and simple foods <em>(pasta; potatoes; etc.)</em> to not overload your digestive system.</p>
<hr>

<ul>
<li><strong>Adherence to diet:</strong> I found it helpful to do FMD with someone else. It motivates you and helps you stick to the plan.</li>
<li><strong>Short-term benefits:</strong> Both of us recorded some weight loss and it is an interesting exercise from a mental perspective.</li>
<li><strong>Learnings for next round:</strong> Next time around we will do blood work before and after FMD to evaluate impact on additional health markers.</li>
</ul>
<p>Since both of us are healthy the recommendation for FMD would be to do 1-2 cycles per year. We can see ourselves doing it each January – after holiday season and at some point during the summer.</p>
<p>It’s easy/short enough to do it on a regular basis. We will do it again.</p>
<hr>
<h2>Further Reading/Listening:</h2>
<ul>
<li><strong><a href="https://www.foundmyfitness.com/episodes/valter-longo" target="_blank" rel="noopener">Valter Longo, Ph.D. on the Fasting-Mimicking Diet &amp; Fasting for Longevity, Cancer &amp; Multiple Sclerosis</a></strong>: Interviewed by Dr. Rhonda Patrick. Good primer for FMD.</li>
<li><a href="https://www.foundmyfitness.com/episodes/valter-longo-2" target="_blank" rel="noopener"><strong>Dr. Valter Longo on Resetting Autoimmunity and Rejuvenating Systems with Prolonged Fasting &amp; the FMD</strong></a>: Round #2 with Dr. Rhonda Patrick.</li>
<li><strong><a href="https://tim.blog/2018/06/05/the-tim-ferriss-show-transcripts-dom-dagostino-the-power-of-the-ketogenic-diet/" target="_blank" rel="noopener">The Tim Ferriss Show Transcripts: Dom D’Agostino — The Power of the Ketogenic Diet (#172)</a></strong>: Solid introduction into the Ketogenic diet. Not specifically about FMD.</li>
<li><strong><a href="https://foreverfreefrom.com/fasting-mimicking-diet-guide/" target="_blank" rel="noopener">Fasting Mimicking Diet Do-It-Yourself Guide:</a></strong> Great write for DIY meal prep.</li>
<li><strong><a href="https://www.quantifiedbob.com/fasting-mimicking-diet/" target="_blank" rel="noopener">Mimicking the Fasting Mimicking Diet – My 5-Day Experiment:</a></strong> Good reference for tools and resources for DIY FMD.</li>
</ul>

<h2>Tools/etc</h2>
<ul>
<li><a href="https://docs.google.com/spreadsheets/d/1mwz9QcQTp1jRIv03WNCKmz43ueivMBP6LkM0CnCYuo0/edit#gid=0" target="_blank" rel="noopener"><strong>Our FMD google sheet:</strong></a> Copy it to adjust to your specific use case.</li>
</ul>
					</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</div>
</article></div>]]>
            </description>
            <link>https://artlapinsch.com/2020/06/23/starving-to-health-fasting-mimicking-diet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614196</guid>
            <pubDate>Tue, 23 Jun 2020 14:18:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a mysterious bug taught us about how Docker stores registry credentials]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23614084">thread link</a>) | @kklin
<br/>
June 23, 2020 | https://kelda.io/blog/how-docker-stores-registry-credentials/ | <a href="https://web.archive.org/web/*/https://kelda.io/blog/how-docker-stores-registry-credentials/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><picture id="hero-thumbnail">
<source data-srcset="https://kelda.io/img/blog/docker-credentials.webp" type="image/webp"></picture><p><h2>Published on Jun 22, 2020</h2></p></section><p>We recently ran into a mysterious bug that required hours of digging into the
arcane details of Docker’s registry credentials store to figure out. Although
in the end the fix turned out to be easy, we learned a thing or two along the
way about the design of the credentials store and how, if you’re not careful,
it can be configured insecurely.</p><p><a href="http://kelda.io/blimp">Blimp</a>, sometimes needs to pull private images from a
Docker registry in order to boot those images in the cloud. This typically
works fine, but unfortunately, when some users started
Blimp, they were getting the following error message:</p><pre><code>Get https://1234.dkr.ecr.us-east-1.amazonaws.com/v2/blimp/blimp/manifests/v0.1: no basic auth credentials
</code></pre><p>At first, we were completely baffled by this cryptic message and had no clue it
was related to our handling of credentials. To understand how we figured it
out, first you need to know a little about how modern Docker credentials are
handled.</p><h2 id="dockers-external-credentials-store">Docker’s External Credentials Store</h2><p>The recommended way to store your Docker credentials is in an external
credentials store. In your Docker config file, which is usually located at
<code>~/.docker/config.json</code>, there are two fields you can use to configure how
Docker gets and stores credentials: <code>credsStore</code> and <code>credHelpers</code>.</p><p><code>credsStore</code> tells Docker which helper program to use to interact with the
credentials store. All helper programs have names that begin with
<code>docker-credential-</code> – the value of <code>credsStore</code> is the suffix of the helper
program.</p><p>For example, if you work on a Mac laptop, you might decide to use the Mac OS
keychain. The name of the helper program to use the keychain is
<code>docker-credential-osxkeychain</code>. So your <code>config.json</code> would include the
following:</p><div><pre><code data-lang="json">{
  <span>"credsStore"</span>: <span>"osxkeychain"</span>
}
</code></pre></div><p>If you want to see what credentials Docker currently has for you, you can use <code>list</code>. For example:</p><pre><code>docker-credential-osxkeychain list
</code></pre><p>The result is a list of pairs of servers and usernames. For example:</p><div><pre><code data-lang="json">{
  <span>"http://quay.io"</span>:<span>"kklin"</span>,
  <span>"https://index.docker.io"</span>:<span>"kevinklin"</span>
}
</code></pre></div><p>You may also notice <code>credHelpers</code> in your <code>config.json</code>. These helpers are similar
to <code>credsStore</code>, but are used to generate short lived credentials. For example,
if you use <a href="http://gcr.io/">gcr</a>, <code>gcloud</code> installs a <code>credHelper</code> that uses
your Google login to get tokens. This way, Docker never has your Google
credentials directly – the <code>docker-credential-gcloud</code> acts as a middleman
between Docker and your Google credentials.</p><p>Once again, here’s the error message our users were getting:</p><pre><code>Get https://1234.dkr.ecr.us-east-1.amazonaws.com/v2/blimp/blimp/manifests/v0.1: no basic auth credentials
</code></pre><p>We were able to run the <code>docker-credential-osxkeychain</code> <code>list</code> and <code>get</code>
commands to see the credentials for <code>1234.dkr.ecr.us-east-1.amazonaws.com</code>, so
why were we getting an error that there weren’t any credentials??</p><h2 id="in-the-beginning-docker-stores-your-registry-password-in-your-config-file">In the Beginning: Docker Stores Your Registry Password In Your Config File</h2><p>It turns out that external credentials stores weren’t
<a href="https://github.com/moby/moby/pull/20107">added</a> to Docker until version 1.11,
in 2016. Before 1.11, Docker stored credentials via a config field called
<code>auths</code>. This field is stored in the same file as the <code>credStore</code>: <code>~/.docker/config.json</code>.</p><p>Whenever you logged into a registry, Docker would set the value of auths to
your password. For
<a href="https://www.projectatomic.io/blog/2016/03/docker-credentials-store/">example</a>,
your config file might contain the following:</p><div><pre><code data-lang="go">{
    <span>"auths"</span>: {
        <span>"https://index.docker.io/v1/"</span>: {
            <span>"auth"</span>: <span>"YW11cmRhY2E6c3VwZXJzZWNyZXRwYXNzd29yZA=="</span>
        },
        <span>"localhost:5001"</span>: {
            <span>"auth"</span>: <span>"aGVzdHVzZXI6dGVzdHBhc3N3b3Jk"</span>
        }
    }
}
</code></pre></div><p>What we learned the hard way is that there’s a quirk with Docker’s <code>login</code>
command. When you log in using <code>docker login</code>, Docker adds an entry via the
<code>credsStore</code> <strong>and</strong> in <code>auths</code>, using slightly different server names. Your
credentials are properly stored in the credentials store, but the entry in
<code>auths</code> doesn’t contain the username or password. The result looks something
like this:</p><div><pre><code data-lang="go">{
<span>"auths"</span>: {
  <span>"https://index.docker.io/v1/"</span>: {}
}
</code></pre></div><p>The problem is that Blimp grabs credentials from both <code>auths</code> <strong>and</strong>
<code>credsStore</code>. So it was passing two copies of the credentials to the Docker
image puller – one with the correct username and password, and one without the
password at all.</p><p>Unfortunately, Docker preferred the <code>https://</code> version of the credential, and
attempt to pull the image with the empty credential. Thus, the <code>no basic auth credentials</code> error.</p><p>Once we figured out that the problem was that an empty duplicate entry was
getting added to the insecure store, it was easy to <a href="https://github.com/kelda/blimp/blob/master/cli/up/up.go">fix the
problem</a>. All we
needed to do was add an <code>if</code> statement to skip empty credentials:</p><div><pre><code data-lang="go">	<span>addCredentials</span> <span>:=</span> <span>func</span>(<span>authConfigs</span> <span>map</span>[<span>string</span>]<span>clitypes</span>.<span>AuthConfig</span>) {
		<span>for</span> <span>host</span>, <span>cred</span> <span>:=</span> <span>range</span> <span>authConfigs</span> {
			<span>// Don't add empty config sections.
</span><span></span>			<span>if</span> <span>cred</span>.<span>Username</span> <span>!=</span> <span>""</span> <span>||</span>
				<span>cred</span>.<span>Password</span> <span>!=</span> <span>""</span> <span>||</span>
				<span>cred</span>.<span>Auth</span> <span>!=</span> <span>""</span> <span>||</span>
				<span>cred</span>.<span>Email</span> <span>!=</span> <span>""</span> <span>||</span>
				<span>cred</span>.<span>IdentityToken</span> <span>!=</span> <span>""</span> <span>||</span>
				<span>cred</span>.<span>RegistryToken</span> <span>!=</span> <span>""</span> {
				<span>creds</span>[<span>host</span>] = <span>types</span>.<span>AuthConfig</span>{
					<span>Username</span>:      <span>cred</span>.<span>Username</span>,
					<span>Password</span>:      <span>cred</span>.<span>Password</span>,
					<span>Auth</span>:          <span>cred</span>.<span>Auth</span>,
					<span>Email</span>:         <span>cred</span>.<span>Email</span>,
					<span>ServerAddress</span>: <span>cred</span>.<span>ServerAddress</span>,
					<span>IdentityToken</span>: <span>cred</span>.<span>IdentityToken</span>,
					<span>RegistryToken</span>: <span>cred</span>.<span>RegistryToken</span>,
				}
			}
		}
	}
</code></pre></div><h2 id="a-potential-docker-credentials-security-risk">A Potential Docker Credentials Security Risk</h2><p>In the process of uncovering this bug, we noticed a potential security risk
that you may not be aware of. As we learned, it’s best practice to use an
external store to store your external registry credentials. However, depending
on how and when you installed Docker it’s possible you could still be using the
legacy <code>auths</code> method. If you are, your <code>~/.docker/config.json</code> might look
something like this:</p><div><pre><code data-lang="go">{
    <span>"auths"</span>: {
        <span>"https://index.docker.io/v1/"</span>: {
            <span>"auth"</span>: <span>"YW11cmRhY2E6c3VwZXJzZWNyZXRwYXNzd29yZA=="</span>
        },
        <span>"localhost:5001"</span>: {
            <span>"auth"</span>: <span>"aGVzdHVzZXI6dGVzdHBhc3N3b3Jk"</span>
        }
    }
}
</code></pre></div><p>This may look reasonable secure, the passwords appear to be a garbled bunch of
gibberish. Surely those passwords are <em>encrypted</em>, right?</p><p>Guess again. All Docker did was encode the passwords using base64. And as David
Rieger pointed out on <a href="https://hackernoon.com/getting-rid-of-docker-plain-text-credentials-88309e07640d">Hacker
Noon</a>,
base64</p><blockquote><p>may look like encryption on first glance, but it’s not. Base64 is a scheme
for encoding, not encryption. You can simply copy the base64 string and
convert it to ASCII in a matter of seconds.</p></blockquote><p>That seemingly secure password of <code>aGVzdHVzZXI6dGVzdHBhc3N3b3Jk</code>? All you need to do to read the password is base64 decode it:</p><pre><code>$ echo aGVzdHVzZXI6dGVzdHBhc3N3b3Jk| base64 -D
hestuser:testpassword
</code></pre><h2 id="the-moral-of-our-story-double-check-your-docker-credentials-security">The Moral of Our Story: Double Check Your Docker Credentials’ Security</h2><p>So that’s the bad news: if Docker config file isn’t properly set up, Docker is
storing your credentials password in plain text.</p><p>The good news is that it’s easy to fix the problem.</p><p>All you and your team members need to do is take a quick look at
<code>~/.docker/config.json</code>. If it contains an <code>auths</code> password, get rid of it and
switch over to using a credentials store. To do so, just download the
appropriate <code>docker-credential-</code> helper for your system, and update the
<code>credsHelper</code> field in <code>~/.docker/config.json</code>.</p><p>Hope that helps!</p><hr><p>By: Kevin Lin</p></div></div>]]>
            </description>
            <link>https://kelda.io/blog/how-docker-stores-registry-credentials/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614084</guid>
            <pubDate>Tue, 23 Jun 2020 14:09:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Will We Run Out of Fossil Fuels? Likely, Never]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23613815">thread link</a>) | @shubhamjain
<br/>
June 23, 2020 | https://shubhamjain.co/2020/06/06/when-will-we-run-out-of-fossil-fuels-likely-never | <a href="https://web.archive.org/web/*/https://shubhamjain.co/2020/06/06/when-will-we-run-out-of-fossil-fuels-likely-never">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
                
                    <p>This article began with a simple question - when will we run out of oil to drill? Itâ€™s likely that you must have come across the answer that puts the date around 2050, which is derived by dividing the proven reserves we have by the annual consumption. Another answer considers the game of demand and supply. Oil will progressively get expensive as we run out of it, in the face of which, the alternatives will become much cheaper. That is true, but it still carries an unspoken assumption that we are, in fact, running out of oil pretty quickly.</p>

<p>But, the surprising truth is the exact opposite. We have so much untapped fossil fuels reserves that it can last us for a really long time and still remain affordable. The bad news is to save the planet earth we have to reduce emissions anyway.</p>

<h2 id="running-out-of-oil-a-history">Running Out of Oil: A History</h2>
<p>Prediction that we are running out of oil is as old as the oil industry itself. Big reason why Rockefeller was able to become the wealthiest person wasnâ€™t just his ruthless tactics but his ability to bet big when it was widely held belief that the industry didnâ€™t have that many years left.</p>

<p>In <strong>1855</strong>, an advertisement for Kierâ€™s Rock Oil advised consumers to â€œhurry, before this wonderful product is depleted from Natureâ€™s laboratory.â€� (<a href="http://www.ncpathinktank.org/pdfs/bg159.pdf">ref.</a>)</p>

<p>In <strong>1874</strong>, the state geologist of Pennsylvania, the nationâ€™s leading oil producing state, estimated that only enough U.S. oil remained to keep the nationâ€™s kerosene lamps burning for <strong>four years</strong>. (<a href="http://www.ncpathinktank.org/pdfs/bg159.pdf">ref.</a>)</p>

<p>In <strong>1914</strong>, <em>U.S. Bureau of Mines</em> projected that the world will run out of oil in <strong>10 years</strong>. (<a href="https://www.e-education.psu.edu/eme801/node/486">ref.</a>)</p>

<p>In <strong>1919</strong>, David White, chief geologist of the United States Geological Survey, wrote of US petroleum: â€œâ€¦ the peak of production will soon be passed, possibly within <strong>3 years</strong>. (<a href="https://en.wikipedia.org/wiki/Peak_oil">ref.</a>)</p>

<p>In <strong>1953</strong>, Eugene Ayers, a researcher for Gulf Oil, projected that if US ultimate recoverable oil reserves were 100 billion barrels, then production in the US would peak no later than <strong>1960</strong>. (<a href="https://en.wikipedia.org/wiki/Peak_oil">ref.</a>)</p>

<p>In <strong>1973</strong>, a report title <em>Limits to Growth,</em> estimated that the world will run out of oil and other fossil fuels by <strong>1990</strong>. (<a href="https://www.e-education.psu.edu/eme801/node/486">ref.</a>)</p>

<p>In <strong>1989</strong>, one expert forecast that world oil production would peak that very year and oil prices would reach $50 a barrel by <strong>1994</strong>. (<a href="http://www.ncpathinktank.org/pdfs/bg159.pdf">ref.</a>)</p>

<p>In <strong>1995</strong>, a respected geologist predicted in World Oil that petroleum production would peak in 1996, and after <strong>1999</strong> major increases in crude oil prices would have dire consequences. He warned that â€œ[m]any of the worldâ€™s developed societies may look more like todayâ€™s Russia than the U.S.â€� (<a href="http://www.ncpathinktank.org/pdfs/bg159.pdf">ref.</a>)</p>

<p>A <strong>1998</strong> Scientific American article entitled â€œThe End of Cheap Oilâ€� predicted that world oil production would peak in <strong>2002</strong> and warned that â€œwhat our society does face, and soon, is the end of the abundant and cheap oil on which all industrial nations depend. (<a href="http://www.ncpathinktank.org/pdfs/bg159.pdf">ref.</a>)</p>

<p>The most famous of all projections is Hubbertâ€™s Peak Oil theory. American geophysicist, M. King Hubbert, predicted that oil production will follow a bell shaped curve. He predicted that oil production in US would peak around 1970; from then, it will be a gradual decline. Oil production in US did mimic Hubbertâ€™s peak for a long while, so much so that it induced a panic in the US Government about energy security during the 70s. And thenâ€¦ it deviated.</p>

<p><img src="https://shubhamjain.co/assets/images/notion/3f0d416c-5d9f-4aac-b49e-c159a4e08ec4.png" alt=""></p>
<h2 id="why-do-we-never-run-out">Why Do We Never Run Out?</h2>

<blockquote>
  <p>In 1949, after 50 years of drilling, analysts estimated that just 47Â&nbsp;million barrels remained in reserves (at Kern River Oil Field) â€”a rounding error in the oil business. Kern River, it seemed, was nearly played out. Instead, oil companies removed 945Â&nbsp;million barrels in the next 40Â&nbsp;years. In 1989, analysts again estimated Kern reserves: 697Â&nbsp;million barrels. By 2009, Kern had produced more than 1.3 billion additional barrels, and reserves were estimated to be almost 600 million barrels. (<a href="https://www.theatlantic.com/magazine/archive/2013/05/what-if-we-never-run-out-of-oil/309294/">ref.</a>)</p>
</blockquote>

<p>What happened at Kern River Oil Field is what has happened at almost every oil field. The derricks start to pump out oil, and after several years, itâ€™s predicted that the field has reached its limit. But until youâ€™ve drilled, it isnâ€™t entirely clear how big the oil field is. New set of tools, and technology, enables you to drill previously inaccessible oil. For instance: In 1998, an oil rig near the Kern Oil Field found an oil gusher at 17,657 feet. This was several thousand feet deeper than deepest wells at that time.</p>

<p>Of course, fields do run out, but the point of highlight here is technology. The oil industry keeps finding newer ways to drill resources to keep up with the demand. There is no better example of it than what happened in the last decade that changed the entire energy landscape: fracking and shale oil boom in US.</p>

<p>Fracking is the process of the process of injecting liquid at high pressure into rocks to force open existing fissures and extract oil or gas. Fracking isnâ€™t recent innovation, it goes back to early 50s, but a combination of technological innovations (I have to research further what they were) skyrocketed US domestic oil production. By 2018, US became worldâ€™s largest crude oil producer leaving behind even  Saudi Arabia (the deviation in Hubbertâ€™s peak).</p>

<p>The engine of innovation is so powerful that how much reserves we have now is a short-sighted question. The better question is whatâ€™s our potential?</p>
<h2 id="potential-oil">Potential Oil</h2>
<p>Itâ€™s impossible to ascertain reserves we have. And even with those we know of, we canâ€™t say for sure if they will be feasible in the future. Technology can reach its limit. But even with those considerations, it helps to know where we can tap in the future.</p>

<p>Two facts that will help us put in perspective the figures that follow :</p>
<ol>
  <li>Human consume around 100M barrels of crude oil per day. It can go up in future once developing countriesâ€™ economies grow, but other factors like efficiency and new sources of energy would try to balance that out. Itâ€™s not far-fetched to assume that 100 Â± 50M / day barrels might be our peak consumption.</li>
  <li>Humans have consumed around 1.3 Trillion barrels of oil since 1870. (<a href="https://www.sciencedaily.com/releases/2009/05/090507072830.htm">ref.</a>)</li>
</ol>

<p>Fossil fuel figures:</p>
<ol>
  <li>The world has around 1.65T barrels of convention oil left (2016 figure) (<a href="https://www.worldometers.info/oil/">ref.</a>). 2050 figure is based on just this.</li>
  <li>The world also has 6T barrels of shale oil deposits, out of which 1.2T barrels (<a href="https://pubs.acs.org/doi/pdf/10.1021/bk-2010-1032.ch001">ref.</a>) is proven to high quality and economically viable to be recoverable.</li>
  <li>The estimated deposits of tar sands is around 2T barrels. (<a href="https://en.wikipedia.org/wiki/Oil_sands#Major_deposits">ref.</a>) Tar sands are a bit energy intensive to extract from but we can predict that in future they could be extracted more economically.</li>
  <li>And to top of that we have methane hydrate deposits, which by an estimate, contain more energy than all the fossil fuels combined. (<a href="https://www.cbc.ca/news/technology/methane-hydrates-energy-s-most-dangerous-game-1.701176">ref.</a>) Currently, it hasnâ€™t become commercially viable to extract gas from these resources, but research is under way and just as we saw in case of shale gas, one day it will become economical.</li>
</ol>

<p>And this doesnâ€™t cover all potential discoveries we will potentially make. Oil wells are doing deeper and venturing further into the ocean. Drilling will indeed get expensive, and crude oil wonâ€™t remain a $20-30/barrel commodity, but even around $50-60/barrel, it would still be affordable.</p>
<h2 id="the-future">The Future</h2>
<p>Itâ€™s clear that we wonâ€™t run out of fossil fuels anytime soon. Any commercial telling the consumers to save for the future generation is misleading and it detracts from a more crucial message - we have to make the switch anyhow. The clock on climate change is ticking and itâ€™s imperative we switch to cleaner energy regardless of economic incentives.</p>


                
            </div></div>]]>
            </description>
            <link>https://shubhamjain.co/2020/06/06/when-will-we-run-out-of-fossil-fuels-likely-never</link>
            <guid isPermaLink="false">hacker-news-small-sites-23613815</guid>
            <pubDate>Tue, 23 Jun 2020 13:44:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Just Hit $100k/year On GitHub Sponsors]]>
            </title>
            <description>
<![CDATA[
Score 1457 | Comments 488 (<a href="https://news.ycombinator.com/item?id=23613719">thread link</a>) | @calebporzio
<br/>
June 23, 2020 | https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it | <a href="https://web.archive.org/web/*/https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                
    <span>Jun 2020</span>

    

    <p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/3735079629.png"></a></p>
<p>I have a story to tell.</p>
<p>My last year as a full-time developer (at <a href="https://tighten.com/">Tighten</a>) was 2018. (Read <a href="https://calebporzio.com/n-leaving-my-day-job">â€œOn Leaving My Day Jobâ€�</a> for that story)</p>
<p>My income for that year was ~$90k:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%209.53.07%20AM.png" alt="90k in income on a W2"></p>
<p>Developer salaries vary like crazy, but $90k was pretty solid for me. Combined with my wifeâ€™s income and some <a href="https://www.mrmoneymustache.com/blog/">Mustachianism</a> it was plenty to save up a chunk of cash for a rainy day. (Or for a few months of working un-paid on open source lol - SPOILER ALERT ðŸ˜¬)</p>
<p>After needing a change of scenery, I left Tighten on January 11th, 2019 to go on a â€œsabbaticalâ€� (fancy word for â€œtake a break and do whatever the hell I wantâ€œ ðŸ˜›) and then start freelancing or something after a couple of months.</p>
<p>4 days into my Sabbatical, I read <a href="https://dockyard.com/blog/2018/12/12/phoenix-liveview-interactive-real-time-apps-no-need-to-write-javascript">this post</a> and hastily made a proof of concept for <a href="https://laravel.com/">Laravel</a>.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.07.30%20AM.png" alt="Original Livewire tweet"></p>
<p>This day marked the abrupt end of my sabbatical. I was completely enamored with the project (now called <a href="https://laravel-livewire.com/">Livewire</a>) and couldnâ€™t stop working on it full-time. (Iâ€™ve never stopped. Iâ€™m STILL enamored with it full-time.)</p>
<p>(I also created a pretty popular JS framework along the way called <a href="https://github.com/alpinejs/alpine">AlpineJS</a> that I work on too, but thatâ€™s a story for another timeâ€¦)</p>
<p>Believe it or not, open-source software doesnâ€™t quite pay the bills, so I took on some small code mentorship clients to stay above the water for the entire year of 2019.</p>
<p>Here was my income for 2019 from that freelance work:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%209.51.34%20AM.png" alt="$21k in self employed income for 2018"></p>
<p>I reduced my salary by ~$70k so I could pursue my passion. It seemed risky, but I knew it would only get harder to make this kind of move in life.</p>
<p>Lots of kind folks reached out to me along the way asking how they could help support the project. Sending me messages like this:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.13.29%20AM.png" alt="Email from a Livewire user asking to support on Patreon"></p>
<p>I avoided creating a Patreon for a long time because I kept picturing a world where a handful of people give me five bucks a month. Which would be nice, but never seemed worth it to me.</p>
<p>Then I saw <a href="https://github.com/sponsors">GitHub Sponsors</a>. ðŸ˜�</p>
<p>It seemed perfect. Hosted directly on GitHub and new enough that thereâ€™s some excitement around it.</p>
<p>I was accepted into GitHub Sponsors on Dec. 12th of 2019.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.17.23%20AM.png" alt="@faustbrian github user sponsoring at $24/mo on Dec 12th">
(Thanks for being my first sponsor, Brian! â�¤ï¸�)</p>
<p>Iâ€™ve since received ~$25k in cash from GitHub sponsorsâ€¦
(They match the first $5k, and they take a ZERO percent cut. You keep EVERYTHING ðŸ™ŒðŸ�»â�¤ï¸�)</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-14%20at%201.36.58%20PM.png" alt="A payout statement from GH sponsors showing $25k in payouts"></p>
<p>â€¦and as of this writing, Iâ€™ve grown my annual GitHub sponsors revenue to $112,680/yr. ðŸŽ‰</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-17%20at%205.23.46%20PM.png" alt="A screenshot of github sponsors dashboard showing $112680 in yearly revenue"></p>
<p>Wow.</p>
<p>I am now making more money than Iâ€™ve ever made while developing open-source software for a community that I adore. Pinch me, Iâ€™m dreaming.</p>
<p>Was it luck? thereâ€™s certainly been a lot of that.</p>
<p>Was it fate? Letâ€™s leave religion out of this mmkay?â€¦</p>
<p>Was it that the software I built was so incredibly compelling that it forced 535 people to give me at least $14/mo. to keep working on it? â€¦I wish.
Itâ€™s more than that though. There were some key things I did along the way to get here. Let me tell you all about them.</p>
<p>Here we go!</p>
<h2>Phase 1: Good-Hearted Folks</h2>
<p>At first, GitHub Sponsors was a place to send loyal/generous followers that wanted to support the project. </p>
<p>However saintly these people are, there arenâ€™t that many of them compared to the number of people actually using the software (and often making money on it).</p>
<p>Because of the nature of open-source, people are already getting the software for free, so without ADDING any value to their lives, this strategy is seriously limiting.</p>
<p>The first section of this income graph is solely from kind folks who just wanted to pitch in.</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/3023657946.png"></a></p>
<p>Huge thank you to all those people.</p>
<p>Now letâ€™s talk about that first spike. </p>
<h2>Phase 2: Sponsorware</h2>
<p>Hereâ€™s where things started to get wild.</p>
<p>I had a cool idea for a small little Laravel package.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/7B10BCF2-60A7-421D-ACAC-EF1679BE70A2.png" alt="Sushi Laravel package tweet"></p>
<p>While recording an episode of <a href="https://noplanstomerge.com/">No Plans To Merge</a> with my buddy <a href="https://twitter.com/DCoulbourne">Daniel</a> on how to monetize it, we cooked up a novel idea called: â€œSponsorwareâ€�</p>
<iframe src="https://player.vimeo.com/video/394690352" width="640" height="480" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
<p>(<a href="https://noplanstomerge.simplecast.com/episodes/funding-opensource-software-aka-sponsorware">Listen To Full Episode</a>)</p>
<p>Hereâ€™s how Sponsorware works:</p>
<ul>
<li>Create a cool piece of software</li>
<li>Make it exclusive to people who sponsor you until you reach a certain number of sponsors</li>
<li>Then open source the project to the world</li>
</ul>
<p>Itâ€™s a win-win.</p>
<p>It worked incredibly well and I increased my yearly revenue by $11k in a matter of days.</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/1455106854.png"></a></p>
<p>I did an entire writeup on â€œSponsorwareâ€� <a href="https://calebporzio.com/sponsorware">here</a> and was interviewed about the process on <a href="https://changelog.com/podcast/381">this episode of The Changelog Podcast</a>.</p>
<p>Also, a friend of mine <a href="https://twitter.com/enunomaduro">Nuno Maduro</a> recently replicated the technique with his project called <a href="https://pestphp.com/">Pest</a> and had similar success:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/C9AFA1F2-F052-4D7A-A3FE-A2B3A74E3EA6.png" alt="Nuno's tweet about Pest"></p>
<p>This technique is fantastic, but it requires me to have a constant stream of new ideas. All of which would become projects I would have to maintain ongoing. I needed something more reasonable for the long haul.</p>
<h2>Phase 3: Sponsored Screencasts</h2>
<p>This is where the VAST majority of my sponsorships came from.</p>
<p>The chart speaks for itself:</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/2049117902.png"></a></p>
<p>So whatâ€™s the secret?</p>
<h3>Educational content.</h3>
<p>Building a useful piece of software is one thing. Educating people on how to use it is an entirely different thing. (A much less fun thing I might add)</p>
<p>I try to make <a href="https://laravel-livewire.com/docs">the docs</a> as good as possible, but thereâ€™s always a need for more advanced content.</p>
<p>Rather than taking on the huge task of creating an entire course or book on  Livewire. I decided to go a different route.</p>
<p>Hereâ€™s exactly what I did that took me from ~$40k to &gt;$100k in ~3 months:</p>
<p>I released a free set of screencasts on the basics of using Livewire:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/FE07E488-D224-4072-9508-05ECD3D6A250.png" alt="My tweet about new Livewire free screencasts"></p>
<p>I added links to other parts of the documentation pointing people towards them so they know theyâ€™re there:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/6D245849-06E2-42A5-82A6-2580BF6BF4EF.png" alt="A call to action telling docs visitors to watch the screencasts"></p>
<p>A few weeks later I added a new â€œprivateâ€� group of screencasts for GitHub sponsors only.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/54ECAE52-5CE3-4E9C-A990-CE0E04E2D9F4.png" alt="A screenshot of a video being restricted to sponsors only"></p>
<p>THIS is the secret sauce ðŸŒ¶ï¸�.</p>
<p>(To make all this happen I built a Laravel app with GitHub authentication that calls on the GitHub API to verify a userâ€™s sponsorship)</p>
<p>Now, people watching the screencasts will naturally encounter these â€œprivateâ€� screencasts and if they like the free ones, they will sponsor me (at $14/mo.) to get access.</p>
<p>I release a new batch of videos every time a new feature comes out, or I decide to cover a new Livewire technique.</p>
<p>I also provide sponsors with access to the source code for each lesson (which is hosted on a separate repo and will eventually become an entire web app written with Livewire).</p>
<p>In terms of income, this has been the single most impactful idea I have EVER had.</p>
<p>It raised my annual revenue by ~$80k in 90 days. Itâ€™s like magic.</p>
<p>Now I have a constant stream of income without having to spend all my time on major course launches. I can keep building the software I love for the community I love and release new screencasts over time (which I actually enjoy doing).</p>
<h2>Nuggets Iâ€™ve Picked Up Along The Way:</h2>
<h3>Make good stuff</h3>
<p>All of this works because I spent years and years honing my craft and producing software that is truly useful. Iâ€™ve poured everything I have into that work, and there are no shortcuts there. You saw earlier how I worked full-time on an open-source project for almost an entire year before seeing any returns. The work people are sponsoring for has to be quality and remain the #1 priority.</p>
<h3>Build an audience</h3>
<p>You can build the greatest tool on the internet, but it means nothing if no oneâ€™s paying attention to you. Building an audience is ESSENTIAL for any of this to work. Twitter followers and email subscribers are your most valuable asset. Again, no shortcuts here. Just hard work, and providing value to people publicly and consistently for a long time.</p>
<h3>Charge an impactful amount</h3>
<p>The biggest mistake people make with GitHub sponsors is offering too small of a first tier.</p>
<p>If people have the option of paying $1-5/mo. instead of &gt;$14, they will pay the lesser amount.</p>
<p>I realized early on that if I want to really make a go of this, Iâ€™d need more than five dollar sponsorships. I started at $9 for a long time and then bumped it to $14 for the screencasts.</p>
<p>Iâ€™ve added a $7 tier that gets no perks for kind folks that just want to say thanks but donâ€™t need anything in return. (These people are the aforementioned Saints ðŸ™�ðŸ�»)</p>
<h3>Pick better tier names</h3>
<p>When you are setting up your sponsorship tiers, pick names that describe the type of person the tier is suited for.</p>
<p>For example. For a higher tier, label it something like â€œThe Agencyâ€� or something that implies that a business should be sponsoring at a higher tier, rather than something vague like â€œPlatinumâ€�.</p>
<p>This way, when people are reading the tiers they will think to themselves: â€œWhat level of usage do I fall underâ€�, rather than: â€œHow much money do I want to spend per monthâ€�.</p>
<h3>Donâ€™t be afraid to talk about your sponsorships and how much you make</h3>
<p>I grew up thinking it was rude to talk about money. This is a lie. I got a ten thousand dollar raise once because a coworker told me how much they made. After I learned what they made I felt comfortable asking for that same amount. Nothing would have happened if they didnâ€™t tell me.</p>
<p>Transparency is health.</p>
<p>I donâ€™t hide what I make because Iâ€™ve benefited from others not hiding what they make.</p>
<p>Even if itâ€™s astronomically higher than me, Iâ€™m never bitter or entitled about it, Iâ€™m only ever excited and inspired. My hope is that others feel the same way.</p>
<p>On top of that, if youâ€™re excited about your GitHub sponsors revenue, others will be too!</p>
<p>Itâ€™s not rude to be totally up-front that you rely on this money and it helps you build the software people are using and benefiting from every day.</p>
<h3>Donâ€™t feel guilty about making a lot of money.</h3>
<p>I always remind myself that I am not a code missionary. If my sponsorship revenue climbs beyond a modest living, THATâ€™S OK. Itâ€™s not a non-profit.</p>
<p>Itâ€™s OK for my income to be proportional to the value my software adds to other peopleâ€™s lives.</p>
<p>This isnâ€™t holy work Iâ€™m doing. itâ€™s software that businesses use to make money. They profit from it. Itâ€™s OK to profit as well.</p>
<h2>Well Wishes</h2>
<p>I hope this saga at least amuses you, and at most provides a blueprint for making your own open-source projects financially sustainable.</p>
<p>SO many open source projects are started with enthusiasm …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it</a></em></p>]]>
            </description>
            <link>https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-23613719</guid>
            <pubDate>Tue, 23 Jun 2020 13:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Three Kinds of Tacit Knowledge]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23613714">thread link</a>) | @durmonski
<br/>
June 23, 2020 | https://commoncog.com/blog/three-kinds-of-tacit-knowledge/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/three-kinds-of-tacit-knowledge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://commoncog.com/blog/three-kinds-of-tacit-knowledge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23613714</guid>
            <pubDate>Tue, 23 Jun 2020 13:36:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Prometheus's AWS, Azure and GCP Service Discovery to Monitor Cloud VMs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23613571">thread link</a>) | @yetiops
<br/>
June 23, 2020 | https://yetiops.net/posts/prometheus-service-discovery-aws-gcp-azure/ | <a href="https://web.archive.org/web/*/https://yetiops.net/posts/prometheus-service-discovery-aws-gcp-azure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>Prometheus has multiple methods to discover services to monitor. You can use static configuration (i.e. specifying the IP and ports of services to monitor), <a href="https://yetiops.net/posts/prometheus-srv-discovery/">discovery via DNS SRV records</a>, files with targets listed in them, and <a href="https://yetiops.net/posts/prometheus-consul-node_exporter/">Hashicorp’s Consul</a>. You can leverage these to monitor resources on premise or in the cloud.</p>
<p>Prometheus can also use the APIs of some cloud providers to discover services. This means less operational overhead (eg no need for Consul clusters or updating DNS records), while still being able to discovering hosts and services dynamically.</p>
<h2 id="outline">Outline</h2>
<p>In this post we will cover building a cloud instance in AWS (EC2), Azure (Virtual Machine) and the Google Cloud Platform (Compute Instance) using Terraform.</p>
<p>We will install the Prometheus Node Exporter on each instance, and then create a user that has enough API access for instance and service discovery.</p>
<p>Finally, we will configure a Prometheus instance with access to each platform, allowing it to discover and monitor the cloud instances.</p>
<h2 id="terraform">Terraform</h2>
<p><a href="https://www.terraform.io/">Terraform</a> is an Infrastructure-as-Code tool, allowing you to define virtual machines, cloud applications and more. The configuration files can also be committed to a version control system. This means that if you need to rebuild your environment and create similar/identical environments you can take the Terraform files and recreate/update them for your needs. You can also look at changes in your infrastructure by looking through the commit history in your version control system (eg Git)</p>
<p>You can find more information about Terrafrom <a href="https://www.terraform.io/intro/index.html">here</a>.</p>
<p>The <a href="https://www.terraform.io/downloads.html">Terraform binaries</a> (i.e. the application which will turn your Terraform configuration files into infrastructure) are available for Linux, macOS, Windows, FreeBSD, OpenBSD and Solaris.</p>
<h3 id="configure-terraform">Configure Terraform</h3>
<p>Once the Terraform binary is installed, you can configure your Terraform environment.</p>
<p>First, I create a Terraform directory and turn it into a Git repository: -</p>
<div><pre><code data-lang="bash"><span># Create the directory</span>
$ mkdir terraform

<span># Go into the directory</span>
$ cd terraform

<span># Initialize git</span>
$ git init

<span># Create a directory for creating virtual machines</span>
$ mkdir basic-vms

<span># Create a directory for the Prometheus users</span>
$ mkdir prometheus-access
</code></pre></div><p>You can choose to layout your Terraform directory however you want. You could have all files in one directory, directories per cloud provider, directories per environment, or directories by resource type. For this, I have chosen to have a directory for the cloud instances (for all providers) and another for the Prometheus user/role access.</p>
<h2 id="aws">AWS</h2>
<p>Cloud Instances within AWS are known as EC2s, ranging from small virtual machines with 512M of memory with single vCPUs, all the way bare metal with hundreds of gigabytes of memory and tens of CPU cores.</p>
<p>You can sign up for an AWS account <a href="https://portal.aws.amazon.com/billing/signup#/start">here</a>. This comes with a years access to their <a href="https://aws.amazon.com/free/">free tier</a>, which includes their <code>t2.micro</code> (1 vCPU and 1G of memory) and <code>t3.micro</code> (the same specs as the <code>t2.micro</code>, but on a newer generation of hardware) EC2 instances.</p>
<p>Once you have signed up, you’ll need to install the AWS CLI tool. Terraform uses the credentials and configuration files that the AWS CLI generates.</p>
<h3 id="install-the-aws-cli">Install the AWS CLI</h3>
<p>The AWS CLI can be installed via your platforms package manager (eg <code>apt install awscli</code> or <code>brew install awscli</code>).</p>
<p>Alternatively you can use Python’s PIP command. PIP will get you the latest stable version, rather than what is packaged in your operating systems repository. You can install with PIP by using <code>pip install awscli</code> (or <code>pip3</code> for the Python 3 version).</p>
<h3 id="configure-your-credentials">Configure your credentials</h3>
<p>To configure your credentials, use the <code>aws configure</code> command. This will give the following options: -</p>
<div><pre><code data-lang="bash">$ aws configure
AWS Access Key ID <span>[</span>None<span>]</span>: <span>###ACCESS_KEY###</span> 
AWS Secret Access Key <span>[</span>None<span>]</span>: <span>###SECRET_KEY###</span>
Default region name <span>[</span>None<span>]</span>: eu-west-2 <span>### Replace this with whatever region you prefer (eg us-east-1, ap-southeast-1)</span>
Default output format <span>[</span>None<span>]</span>:
</code></pre></div><h4 id="access-key-and-secret-key">Access Key and Secret Key</h4>
<p>The Access Key and Secret Key can be obtained from the AWS Console. This can either be for your AWS account’s root user, or an IAM (Identity &amp; Access Management) User (i.e. a user created within the account). Typically you should use an IAM user, so that permissions can be restricted to only what is necessary. However for the purposes of this article, I am going to use the root user.</p>
<p>Log into the AWS Console, go to the right hand corner and click on your username: -</p>
<p><img src="https://yetiops.net/img/prometheus/aws-account-menu.png" alt="AWS Account Menu"></p>
<p>Click on <strong>My Security Credentials</strong>, then <strong>Access Keys (access key ID and secret access key)</strong> and then <strong>Create New Access Key</strong>. You’ll be presented with a popup that has the Access Key and Secret Access Key. Make sure you save these, as the Secret Key is not shown again.</p>
<h3 id="configure-terraform---ec2s">Configure Terraform - EC2s</h3>
<p>Now that you have generated the correct configuration with the AWS CLI, you can use Terraform with AWS.</p>
<p>Navigate to the Terraform directory we created earlier, and then the <code>basic-vms</code> directory (<code>cd terraform/basic-vms</code>).</p>
<p>In here, create a <code>providers.tf</code> file. This tells Terraform that we are going to configure resources in AWS, and what our default region is: -</p>
<div><pre><code data-lang="hcl"><span># AWS Provider
</span><span></span><span>provider</span> <span>"aws"</span> {
  region  <span>=</span> <span>"eu-west-2"</span>
}
</code></pre></div><p>After this, run <code>terraform init</code>. This downloads the AWS Terraform provider binary: -</p>
<div><pre><code data-lang="bash">$ terraform init

Initializing the backend...

Initializing provider plugins...
- Checking <span>for</span> available provider plugins...
- Downloading plugin <span>for</span> provider <span>"aws"</span> <span>(</span>hashicorp/aws<span>)</span> 2.67.0...

The following providers <span>do</span> not have any version constraints in configuration,
so the latest version was installed.

To prevent automatic upgrades to new major versions that may contain breaking
changes, it is recommended to add version <span>=</span> <span>"..."</span> constraints to the
corresponding provider blocks in configuration, with the constraint strings
suggested below.

* provider.aws: version <span>=</span> <span>"~&gt; 2.67"</span>

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running <span>"terraform plan"</span> to see
any changes that are required <span>for</span> your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration <span>for</span> Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to <span>do</span> so <span>if</span> necessary.
</code></pre></div><h3 id="define-the-infrastructure---ec2s">Define the infrastructure - EC2s</h3>
<p>You can create the configuration files for your first EC2 instance. The below is from the file <code>aws.tf</code> in the <code>terraform/basic-vms</code> directory: -</p>
<div><pre><code data-lang="hcl"><span>data</span> <span>"aws_ami" "ubuntu"</span> {
  most_recent <span>=</span> <span>true</span>

  <span>filter</span> {
    name   <span>=</span> <span>"name"</span>
    values <span>=</span> [<span>"ubuntu/images/hvm-ssd/ubuntu-bionic-18.04-amd64-server-*"</span>]
  }

  <span>filter</span> {
    name   <span>=</span> <span>"virtualization-type"</span>
    values <span>=</span> [<span>"hvm"</span>]
  }

  owners <span>=</span> [<span>"099720109477"</span>]<span> # Canonical
</span><span></span>}

<span>data</span> <span>"aws_vpc" "default"</span> {
  default <span>=</span> <span>true</span>
}

<span>resource</span> <span>"aws_key_pair" "yetiops-aws-prom"</span> {
  key_name <span>=</span> <span>"yetiops-aws-prom"</span>
  public_key <span>=</span> <span>file</span>(<span>"~/.ssh/id_rsa.pub"</span>)
}

<span>resource</span> <span>"aws_instance" "yetiops-aws-prom"</span> {
  ami           <span>=</span> <span>data</span>.<span>aws_ami</span>.<span>ubuntu</span>.<span>id</span>
  instance_type <span>=</span> <span>"t2.micro"</span>
  user_data     <span>=</span> <span>data</span>.<span>template_file</span>.<span>ubuntu</span>.<span>template</span>

  key_name <span>=</span> <span>aws_key_pair</span>.<span>yetiops</span><span>-</span><span>aws</span><span>-</span><span>prom</span>.<span>key_name</span>

  vpc_security_group_ids <span>=</span> [
    <span>aws_security_group</span>.<span>yetiops</span><span>-</span><span>aws</span><span>-</span><span>prom</span>.<span>id</span>
  ]

  tags <span>=</span> {
    Name <span>=</span> <span>"yetiops-aws-prom"</span>
    prometheus <span>=</span> <span>"true"</span>
    node_exporter <span>=</span> <span>"true"</span>
  }
}

<span>resource</span> <span>"aws_security_group" "yetiops-aws-prom"</span> {
  name        <span>=</span> <span>"yetiops-aws-prom"</span>
  description <span>=</span> <span>"AWS Security Group for yetiops-aws-prom"</span>
  vpc_id      <span>=</span> <span>data</span>.<span>aws_vpc</span>.<span>default</span>.<span>id</span>

  tags <span>=</span> {
    Name <span>=</span> <span>"yetiops-aws-prom"</span>
  }
}

<span>resource</span> <span>"aws_security_group_rule" "ingress_ssh_in"</span> {
  type              <span>=</span> <span>"ingress"</span>
  to_port           <span>=</span> <span>22</span>
  protocol          <span>=</span> <span>"tcp"</span>
  from_port         <span>=</span> <span>22</span>
  cidr_blocks       <span>=</span> [
    <span>"$MY_PUBLIC_IP/32"</span>
  ]
  security_group_id <span>=</span> <span>aws_security_group</span>.<span>yetiops</span><span>-</span><span>aws</span><span>-</span><span>prom</span>.<span>id</span>
}

<span>resource</span> <span>"aws_security_group_rule" "ingress_node_exporter_in"</span> {
  type              <span>=</span> <span>"ingress"</span>
  to_port           <span>=</span> <span>9100</span>
  protocol          <span>=</span> <span>"tcp"</span>
  from_port         <span>=</span> <span>9100</span>
  cidr_blocks       <span>=</span> [
    <span>"$MY_PUBLIC_IP/32"</span>
  ]
  security_group_id <span>=</span> <span>aws_security_group</span>.<span>yetiops</span><span>-</span><span>aws</span><span>-</span><span>prom</span>.<span>id</span>
}

<span>resource</span> <span>"aws_security_group_rule" "egress_allow_all"</span> {
  type              <span>=</span> <span>"egress"</span>
  to_port           <span>=</span> <span>0</span>
  protocol          <span>=</span> <span>"-1"</span>
  from_port         <span>=</span> <span>0</span>
  cidr_blocks       <span>=</span> [
    <span>"0.0.0.0/0"</span>
  ]
  security_group_id <span>=</span> <span>aws_security_group</span>.<span>yetiops</span><span>-</span><span>aws</span><span>-</span><span>prom</span>.<span>id</span>
}
</code></pre></div><p>To summarize what we are doing here, we are: -</p>
<ul>
<li>Using a Terraform <strong>data</strong> source (i.e. a read only view) to retrieve the latest Amazon Machine Image (i.e. a pre-defined virtual machine image) for Ubuntu 20.04
<ul>
<li>The owner ID of <code>099720109477</code> is the AWS account of Canonical (i.e. the makers of Ubuntu)</li>
</ul>
</li>
<li>Using another <strong>data</strong> source, we discover the default Virtual Public Cloud (i.e. the private Amazon network for our account)</li>
<li>Create an SSH keypair in AWS, based upon one we have generated on our machine (you could generate one in AWS instead if you wish)</li>
<li>Creating an Amazon EC2 of type <code>t2.micro</code>, with a <strong>Security Group</strong> attached, specifying <strong>user-data</strong> (i.e. first boot configuration) and applying some <strong>tags</strong> (key-value pairs) to the instance</li>
<li>Creating a <strong>Security Group</strong> (a network firewall), residing in our VPC</li>
<li>Adding rules to the security group to allow SSH and TCP port 9100 (the Prometheus Node Exporter) port from my public IP address</li>
<li>Allowing all outbound traffic from the virtual machine</li>
</ul>
<p>The <code>user_data</code> is specified in a different file, called <code>user_data.tf</code>: -</p>
<div><pre><code data-lang="hcl"><span>data</span> <span>"template_file" "ubuntu"</span> {
  template <span>=</span> <span>"${file("${path.module}/files/ubuntu.tpl")}"</span>
}

<span>data</span> <span>"template_cloudinit_config" "ubuntu"</span> {
  gzip          <span>=</span> <span>false</span>
  base64_encode <span>=</span> <span>false</span>

  <span>part</span> {
    filename     <span>=</span> <span>"init.cfg"</span>
    content_type <span>=</span> <span>"text/cloud-config"</span>
    content      <span>=</span> <span>data</span>.<span>template_file</span>.<span>ubuntu</span>.<span>rendered</span>
  }
}
</code></pre></div><p>The above file serves two purposes. First, it sources the template from a file. In this case, the file is <code>terraform/basic-vms/files/ubuntu.tpl</code> (<code>${path.module}</code> refers to the path relative to where you define your resources). Secondly, it produces a <code>template_cloudinit_config</code> resource as well from the same …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yetiops.net/posts/prometheus-service-discovery-aws-gcp-azure/">https://yetiops.net/posts/prometheus-service-discovery-aws-gcp-azure/</a></em></p>]]>
            </description>
            <link>https://yetiops.net/posts/prometheus-service-discovery-aws-gcp-azure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23613571</guid>
            <pubDate>Tue, 23 Jun 2020 13:23:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News Upvote]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23613417">thread link</a>) | @a_imho
<br/>
June 23, 2020 | https://upvotes.club/buy/hacker-news-upvote/ | <a href="https://web.archive.org/web/*/https://upvotes.club/buy/hacker-news-upvote/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2> Hacker News Upvote</h2><p><span><span>$</span>1.95</span></p><div><p><strong>(max: 10/new post)</strong></p><p>We upvote with very strong accounts; if you don’t make it on the main page after 10 upvotes, more won’t help. Explanation <a href="https://upvotes.club/internet-marketing-tips/" target="_blank" rel="noopener noreferrer">on our “marketing tips” page</a>. For posts that are already on the main or second page, you can order at most 115 upvotes.)</p><p><a href="https://news.ycombinator.com/" target="_blank" rel="noopener noreferrer">HN</a> is about “anything that gratifies one’s intellectual curiosity”. Use it to promote Tech/IT/B2B products/services/articles. The <a href="https://news.ycombinator.com/showhn.html" target="_blank" rel="noopener noreferrer">“Show HN” area</a> brings a lot of traffic to new projects. If we need to vouch for your post in order to un-shadow it (banned domain or flagged as spam), two upvotes will be deducted from the work that we need to provide.</p></div><meta data-product_id="34" data-product_image_src="https://upvotes.club/wp-content/uploads/buy-hacker-news-upvote.png" data-product_image_width="400" data-product_image_height="400"></div></div>]]>
            </description>
            <link>https://upvotes.club/buy/hacker-news-upvote/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23613417</guid>
            <pubDate>Tue, 23 Jun 2020 13:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asp.net Core: Saturating 10GbE at 7M request/s]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23613321">thread link</a>) | @smusamashah
<br/>
June 23, 2020 | https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/ | <a href="https://web.archive.org/web/*/https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
    <h3>7+ Million HTTP requests per second from a single server</h3>
    
    <p><em>It’s coming up to 2 years since I last posted about the performance of ASP.NET Core; 
<a href="https://www.ageofascent.com/2016/02/18/asp-net-core-exeeds-1-15-million-requests-12-6-gbps/">during its preview, pre version 1.0</a>. As <a href="https://blogs.msdn.microsoft.com/webdev/2019/01/29/aspnet-core-3-preview-2/">preview 2 of has ASP.NET Core 3.0</a> 
has just been to released; it’s time to follow up, and find out how its evolved.</em></p>

<h2>ASP.NET Core 2.2 (Current)</h2>

<p>Looking at the latest run from the <a href="https://www.techempower.com/benchmarks/#section=test&amp;runid=8ca46892-e46c-4088-9443-05722ad6f7fb&amp;hw=ph&amp;test=plaintext">TechEmpower Benchmarks continuous results</a>
ASP.NET 2.2 is the 3rd fastest webserver (0.046% off the top spot); able to respond to 7 Million HTTP request per second:</p>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-techempower-plaintext-top10.png" alt="TechEmpower Top 10 WebServers"></p>

<p>I recently saw another post; about a different product, where throughput that was measured monthly; 
so if we use that time period, that’s 18.1 trillion HTTP requests per month.</p>

<p>It’s also an extraordinary amount of bandwidth; enough to continuously saturate a 10GBps link.
These results are with the webserver and load tester running inside Docker containers, 
on two different physical Linux machines <strong>*</strong>; connected with a 10GbE network.</p>

<p><strong>All this throughput from a single server!</strong> ASP.NET Core is <em>fast</em> on Linux (and on Windows).</p>

<p><em><strong>*</strong><a href="https://www.techempower.com/benchmarks/#section=environment">“Citrine” Environment: 14 Core, 28 HT, 32 GB RAM</a></em></p>

<h4>Compared with Other Servers</h4>

<p>How does it compare to other well known servers?</p>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-techempower-other-servers.png" alt="Common servers' ranking"></p>

<p>In these “platform” comparisons that’s:</p>

<ul>
  <li><strong>x1.78</strong> faster than ngnix</li>
  <li><strong>x2.93</strong> faster than Java’s Servlet (<strong>x7.76</strong> faster than Servlet on Tomcat)</li>
  <li><strong>x7.36</strong> faster than Golang’s “net/http” package</li>
  <li><strong>x8.06</strong> faster than node.js running as a <a href="https://github.com/TechEmpower/FrameworkBenchmarks/blob/11473a3030b4e3cdded0d006b52e1474cc0a9bb5/frameworks/JavaScript/nodejs/app.js#L2-L8">cluster of 28 processes</a> (as node.js is single threaded)</li>
</ul>

<h4>Internet Facing Server</h4>

<p>ASP.NET Core’s Kestrel Webserver;
which is used in these benchmarks, 
is an edge server so can be used as an 
<a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/kestrel?view=aspnetcore-2.2#when-to-use-kestrel-with-a-reverse-proxy">internet facing webserver, as explained in the documentation</a>:</p>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-kestrel-edge-server.png" alt="ASP.NET Kestrel WebServer Deployment options"></p>

<p>It doesn’t need a second webserver acting as a reverse-proxy server in front and can go full speed. 
It also works with reverse-proxies if that fits more with your infrastructure.</p>

<h2>Data Access Performance</h2>

<p>I often hear the defeatist argument that performance like this doesn’t matter because “my database is slow”; well times are a changing…</p>

<h4>Postgres</h4>

<h5>Test type 5: Database updates</h5>

<blockquote>
  <p>Exercises the ORM’s persistence of objects and the database driver’s performance at running <code>UPDATE</code> statements or similar. 
The spirit of this test is to exercise a variable number of read-then-write style database operations.</p>
</blockquote>

<p>HTTP api request =&gt; 20 database queries =&gt; 20 database updates</p>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-techempower-database-updates.png" alt="TechEmpower Database Updates Benchmark"></p>

<p>ASP.NET Core occupies the 8th, 9th and 10th positions out of 331 entries, 
for raw, middleware and mvc (which are “platform”, “micro-framework”, and “full-framework” respectively)</p>

<p>The “platform” level runs 550,120 SQL statements per second (13,753 * (20 <code>SELECT</code> + 20 <code>UPDATE</code>))</p>

<p>Looking that over longer time periods that’s:</p>

<ul>
  <li><code>          550,120</code> per second</li>
  <li><code>       33,007,200</code> per minute</li>
  <li><code>    1,980,432,000</code> per hour</li>
  <li><code>   47,530,368,000</code> per day</li>
  <li><code>1,425,911,712,955</code> per month</li>
</ul>

<h5>Test type 4: Fortunes</h5>

<p>This is the most full featured test, most closely mimicking a wider range of activities a web application executes in combination to produce a web page:</p>

<blockquote>
  <p>Exercises the ORM, database connectivity, dynamic-size collections, sorting, server-side templates, XSS countermeasures, and character encoding.</p>
</blockquote>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-techempower-fortunes.png" alt="TechEmpower Fortunes Benchmark"></p>

<p>ASP.NET Core performs well here also with 298,477 requests served per second; coming 7th out of 350 entries.</p>

<ul>
  <li><code>        298,477</code> per second</li>
  <li><code>     17,908,620</code> per minute</li>
  <li><code>  1,074,517,200</code> per hour</li>
  <li><code> 25,788,412,800</code> per day</li>
  <li><code>773,652,384,000</code> per month</li>
</ul>

<p>.NET runs on the Common Language Runtime, which is language neutral, so its also not all about C#; with VB.NET in 14th position.</p>

<h4>MySql</h4>

<p>.NET can work with many different databases; so looking at MySQL</p>

<h5>Test type 3: Multiple database queries</h5>

<blockquote>
  <p>Multiple rows are fetched to more dramatically punish the database driver and connection pool.
At the highest queries-per-request tested (20), this test demonstrates all frameworks’ convergence 
toward zero requests-per-second as database activity increases.</p>
</blockquote>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-techempower-mysql.png" alt="TechEmpower MySql Query Benchmark"></p>

<p>ASP.NET comes 6th out of 178 MySql entries; performing 419,460 queries per second (20,973 * 20)</p>

<ul>
  <li><code>          419,460</code> per second</li>
  <li><code>       25,167,600</code> per minute</li>
  <li><code>    1,510,056,000</code> per hour</li>
  <li><code>   36,241,344,000</code> per day</li>
  <li><code>1,087,240,320,000</code> per month</li>
</ul>

<h2>Why is Performance Important?</h2>

<p>At Illyriad Games we are building a new scale of gaming for <a href="https://www.ageofascent.com/">Age of Ascent</a>, 
an Ultra-MMO with real-time twitch combat at unprecedented scale. 
High performance at a business level means we can do more with less – which directly affects our bottom line.</p>

<p>So the choice and performance of a framework is very important to us.</p>

<p>In the words of <a href="https://www.techempower.com/benchmarks/#section=motivation">TechEmpower as to the motivations for setting up their benchmarks</a>:</p>

<blockquote>
  <p>Application performance can be directly mapped to hosting dollars, and for companies both large and small, hosting costs can be a pain point.</p>

  <p>Weak performance can also cause premature and costly scale pain by requiring earlier optimization efforts and increased architectural complexity. 
Finally, slow applications yield poor user experience and may suffer penalties levied by search engines.</p>

  <p>What if building an application on one framework meant that at the very best your hardware is suitable for one tenth as much load as 
it would be had you chosen a different framework?</p>
</blockquote>

<p>This has become all the more important with cloud-based hosting; where rather than paying a fixed cost for a server, 
you pay for only what you need and the usage of that at per minute granularity.</p>

<h2>What are .NET Core and ASP.NET Core?</h2>

<p>They are fully open-source frameworks under the <a href="https://dotnetfoundation.org/">.NET Foundation</a>; commonly used with 
<a href="https://github.com/dotnet/csharplang">C#</a>, <a href="https://github.com/dotnet/vblang">VB.NET</a> 
and <a href="https://github.com/fsharp/fsharp">F#</a> languages which are all also open source and designed on GitHub.</p>

<p>They run on the open-source “Common Language Runtime” which has the aim:</p>

<blockquote>
  <p>The goal of the CLR is to make programming easy - <em>from the <a href="https://github.com/dotnet/coreclr/blob/master/Documentation/botr/intro-to-clr.md#the-primary-goal-of-the-clr">Book of the Runtime</a></em></p>
</blockquote>

<p>.NET Core and ASP.NET Core were born in the open-sourcing of .NET and the reimagining of ASP.NET; 
which also took them from Windows only to cross-platform; 
additionally supporting macOS and flavors of Linux, BSD and adding ARM to the supported chipsets.</p>

<p>The .NET Community has embraced the open-sourcing of .NET; 
and its progress has never been so vibrant. A .NET renaissance has begun!</p>

<p>(Graph below from: <a href="https://mattwarren.org/2018/12/04/Open-Source-.Net-4-years-later">Matt Warren’s: Open Source .NET – 4 years later</a>)</p>

<p><img src="https://cdn.ageofascent.net/assets/2019/dotnet-core-community.png" alt=".NET Core Community Contributions"></p>

<p>While grounded in .NET’s original aim of being highly productive to empower developers to achieve more;
along the journey they gained a laser like focus on performance so your servers too can achieve more!</p>

<h4>Ready for Production?</h4>

<p>Yes, we use .NET Core and ASP.NET Core, <a href="https://blogs.msdn.microsoft.com/dotnet/2018/08/20/bing-com-runs-on-net-core-2-1/">Bing.com uses them</a> 
and ASP.NET Core’s webserver Kestrel is already the <strong>12th</strong> <a href="https://w3techs.com/technologies/overview/web_server/all">most used Webserver on the Internet</a>
even though it was only first released less than 2.5 years ago.</p>

<p>Jump in, the water’s warm!</p>

<h2>ASP.NET Core 3.0 (Preview 2)</h2>

<p>Every version of .NET Core has been making huge improvements in performance both to the framework’s core libraries (examples <a href="https://blogs.msdn.microsoft.com/dotnet/2017/06/07/performance-improvements-in-net-core/">in 2.0</a>
and <a href="https://blogs.msdn.microsoft.com/dotnet/2018/04/18/performance-improvements-in-net-core-2-1/">in 2.1</a>) and introducing new types and concepts to allow higher performance:</p>
<ul>
  <li><a href="https://msdn.microsoft.com/en-us/magazine/mt814808.aspx">Span</a></li>
  <li><a href="https://blogs.msdn.microsoft.com/dotnet/2018/11/07/understanding-the-whys-whats-and-whens-of-valuetask/">ValueTask</a></li>
  <li><a href="https://ndportmann.com/system-threading-channels/">System.Threading.Channels</a></li>
  <li><a href="https://blogs.msdn.microsoft.com/dotnet/2018/07/09/system-io-pipelines-high-performance-io-in-net/">System.IO.Pipelines</a></li>
  <li><a href="https://blogs.msdn.microsoft.com/dotnet/2018/08/02/tiered-compilation-preview-in-net-core-2-1/">Tiered Compilation</a></li>
</ul>

<p>Continuing in these improvements, there are many changes in <a href="https://blogs.msdn.microsoft.com/dotnet/2019/01/29/announcing-net-core-3-preview-2/">.NET Core 3.0 Preview 2</a> but 
perhaps the biggest to us is the <a href="https://blogs.msdn.microsoft.com/dotnet/2018/10/10/using-net-hardware-intrinsics-api-to-accelerate-machine-learning-scenarios/">.NET Hardware Intrinsics API</a></p>

<center>

</center>

<p>Which allows the Intel SSE, SSE2, AVX2 and Arm/Arm64 SIMD hardware instrinsics to be used directly from managed code
(e.g. 
<a href="https://github.com/dotnet/coreclr/pull/22127">dotnet/coreclr#22127</a>,
<a href="https://github.com/dotnet/coreclr/pull/21073">dotnet/coreclr#2107</a>, <a href="https://github.com/dotnet/coreclr/pull/22187">dotnet/coreclr#22187</a>, <a href="https://github.com/dotnet/coreclr/pull/22118">dotnet/coreclr#22118</a>);
and many aspects of the runtime are moving from the C++ portion of the runtime to C# where the JIT can easily 
target exactly the CPU it’s running on and achieve higher performance (e.g. <a href="https://github.com/dotnet/coreclr/pull/21729">dotnet/coreclr#21729</a>).</p>

<h4>Reduced Allocations</h4>

<p>One of the big focuses of the performance work in the frameworks has been to reduce allocations; as the less allocations, the less work the Garbage Collector has to do.</p>

<p>The allocations and performance of the .NET’s async statemachine has been dramatically improved:</p>

<center>

</center>

<p>As have the allocations in ASP.NET Core:</p>

<center>

</center>

<h4>Zero Allocations</h4>

<p>In fact combined, with the merging of these two Pull Requests (PRs) 
<a href="https://github.com/aspnet/AspNetCore/pull/4601">aspnet/AspNetCore#4601</a> and <a href="https://github.com/dotnet/coreclr/pull/21159">dotnet/coreclr#21159</a>
 the steady state allocations for Plaintext on at the platform level has been entirely eliminated and is now zero allocation.</p>

<p>What does Zero allocations look like?</p>

<p><strong>Running a 6 minute, 64 connection test on localhost:</strong></p>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-requests.png" alt="6 minute, 64 connection test on localhost"></p>

<p><strong>Results in 122,946,688 HTTP requests and responses; and the allocations?</strong></p>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-allocations-0-7.png" alt="Allocations for over 100 Million Requests"></p>

<p><strong>Less than 1MB allocated in total for processing more than 122 Million requests and generating their responses!</strong></p>

<h2>Continuous Performance Monitoring</h2>

<p>I mentioned earlier “a laser like focus on performance”; but what does that really mean?</p>

<p>All the ASP.NET Core repositories have micro-benchmarks using the great tool <a href="https://benchmarkdotnet.org/articles/overview.html">BenchmarkDotNet</a>
to verify in isolation changes and how they will affect performance.</p>

<p>However, more importantly there is an <a href="https://github.com/aspnet/Benchmarks">entire suite of full system benchmarks</a> of over 100 scenarios, 
which are then run on both Linux and Windows, physical servers and cloud for a total of 400+ full system performance tests, 
running continuously as part of their Continuous Integration (CI) several times a day to catch any regressions early.</p>

<h4>Public Performance Dashboard</h4>

<p>As its fully open source and open to contributors; the full 10 pages of all performance KPIs and time series graphs 
is completely available and public: <a href="https://aka.ms/aspnet/benchmarks">aspnet/Benchmarks Results</a></p>

<p>Looking at the “KPIs - Baselines” page:</p>

<p><img src="https://cdn.ageofascent.net/assets/2019/asp-net-core-ci-monitoring-kpis.png" alt="ASP.NET Core Baseline Key Performance Indicators (KPI)"></p>

<p>We already saw how ASP.NET Core was fast; but looking at the dashboard it shows 
<strong>ASP.NET Core 3.0 is already 30% faster than ASP.NET Core 2.2</strong> for some scenarios!</p>

<p>You can also see that 3.0 preview is tracked and compared against all prior versions 
as are all the current patch and servicing releases; so there are no surprise impacts 
from any patching.</p>

<p>It’s not only public; but the dashboard is on continuous display in the Microsoft offices:</p>

<center>

</center>

<h4>More Than Raw Throughput</h4>

<p>As well as throughput; latency; time from cold start to first response, and memory usage is 
closely tracked over time; for every scenario.</p>

<p>Memory usage for ASP.NET …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/">https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/</a></em></p>]]>
            </description>
            <link>https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23613321</guid>
            <pubDate>Tue, 23 Jun 2020 13:03:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating Hydraulic Erosion]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23612749">thread link</a>) | @schnautzi
<br/>
June 23, 2020 | https://jobtalle.com/simulating_hydraulic_erosion.html | <a href="https://web.archive.org/web/*/https://jobtalle.com/simulating_hydraulic_erosion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p><span>14 Jun 2020</span></p><h2>Simulating hydraulic erosion</h2><p><em>Hydraulic erosion</em> is the process by which water transforms terrain over time. This is mostly caused by rainfall, but also by ocean waves hitting the shore and the flow of rivers. Figure 1 shows the considerable effects that a small stream has had on the rocky environment around it. When creating realistically looking environments, the effects of erosion need to be accounted for. I have experimented with procedural terrain generation before to generate scenes for <a href="https://jobtalle.com/layered_voxel_rendering.html" target="_blank">layered voxel rendering</a> and to demonstrate <a href="https://jobtalle.com/cubic_noise.html" target="_blank">cubic noise</a>. These terrains were very basic and did not account for erosion. Therefore, they lack a lot of detail, making them unrealistic at closer inspection.</p><figure title="A small waterfall on La Palma"><img src="https://jobtalle.com/posts/2020_6_14/img/waterfall.jpg"><figcaption>Figure 1: A small waterfall.</figcaption></figure><p>In this article, I will detail a simple and fast method that approximates the effects of hydraulic erosion. The aim of this method is to create believable environments rather than reaching a high degree of realism. Fidelity may be sacrificed for the sake of speed, as long as the results look natural. Summarized, the method should do the following:</p><ul><li>The results must look <em>natural</em>.</li><li>The algorithm must be <em>simple</em>.</li><li>The algorithm must be <em>fast</em>.</li><li>The algorithm should simulate hydraulic erosion caused by <em>rainfall</em> and <em>rivers</em>.</li></ul><h2>Multiple approaches</h2><p>There are several different approaches when it comes to simulating erosion. All methods simulate the same phenomenon: water moving from high places to low places, eroding terrain as it flows, and depositing sediment as they go further down their paths. This process always results in a number of recognizable terrain features like gulleys and valleys where rivers flow, deltas where they meet their destination and <a href="https://en.wikipedia.org/wiki/Alluvial_fan" target="_blank">alluvial fans</a> where smaller streams combine into bigger rivers. While reading about this topic, I have encountered the following distinct strategies in research literature:</p><ul><li>Erosion is simulated by keeping track of where water is for every position on the terrain. A grid (or 2D array) is created for the environment, and water levels and pressures are kept for every cell. When updating, the pressures determine where the water flows to. While flowing, water moves sediment around.</li><li>Erosion is simulated by dropping many particles simulating raindrops on the terrain. The particles then move down the slopes of the terrain. They can bring sediment with them or deposit it.</li></ul><figure title="An island with simulated erosion"><img src="https://jobtalle.com/posts/2020_6_14/img/island.jpg"><figcaption>Figure 2: An island after erosion has been applied to it.</figcaption></figure><p>Mostly for performance reasons, I've chosen to implement a drop based method. Because most drops don't flow very far, many inactive drop simulations can be terminated early and the bulk of the processing power will go to the drops that actually carve out terrain features. The grid based simulation will need to simulate every part on the terrain for every update cycle.</p><h2>Snowballs</h2><p>The drops in the simulation can be seen as <em>snowballs</em> instead of raindrops. Within the context of the simulation, I believe this is a better analogy. The snowballs start small when they are dropped, but gain more material as they roll down the hills. When they become too big, they start shedding material as they go. When they stop rolling in valleys or in the sea, the snowballs fall apart and leave their material on the terrain.</p><p>The complete erosion algorithm (in <em>Javascript</em>) can be read below. This code uses a <code>heightMap</code> object to erode. This height map can be read from and written to, and the <code>sampleNormal</code> function can be used to get the surface normal. This is a 3D vector pointing upwards from the terrain, so it can be used to determine the slope direction and steepness.</p><pre>/**
 * Let a snowball erode the height map
 * @param {Number} x The X coordinate to start at
 * @param {Number} y The Y coordinate to start at
 */
trace = function(x, y) {
  const ox = (random.getFloat() * 2 - 1) * radius; // The X offset
  const oy = (random.getFloat() * 2 - 1) * radius; // The Y offset
  let sediment = 0; // The amount of carried sediment
  let xp = x; // The previous X position
  let yp = y; // The previous Y position
  let vx = 0; // The horizontal velocity
  let vy = 0; // The vertical velocity

  for (let i = 0; i &lt; maxIterations; ++i) {
    // Get the surface normal of the terrain at the current location
    const surfaceNormal = heightMap.sampleNormal(x + ox, y + oy);

    // If the terrain is flat, stop simulating, the snowball cannot roll any further
    if (surfaceNormal.y === 1)
      break;

    // Calculate the deposition and erosion rate
    const deposit = sediment * depositionRate * surfaceNormal.y;
    const erosion = erosionRate * (1 - surfaceNormal.y) * Math.min(1, i * iterationScale);

    // Change the sediment on the place this snowball came from
    heightMap.change(xp, yp, deposit - erosion);
    sediment += erosion - deposit;

    vx = friction * vx + surfaceNormal.x * speed;
    vy = friction * vy + surfaceNormal.z * speed;
    xp = x;
    yp = y;
    x += vx;
    y += vy;
  }
};

// Simulate 50000 snowballs
const snowballs = 50000;

for (let i = 0; i &lt; snowballs; ++i)
  trace(
    random.getFloat() * width,
    random.getFloat() * height);

// Blur the height map to smooth out the effects
heightMap.blur();
</pre><p>The algorithm has a few notable properties:</p><ul><li>The variables <code>ox</code> and <code>oy</code> encode the <em>offset</em> of a snowball. They are used to read the terrain slope with a certain offset to make the snowball motion a bit rougher, which prevents snowball paths from converging too much.</li><li>When the surface normal points perfectly upwards (when the y value of that normal equals one), the snowball terminates. In practice, this means that snowballs that have reached the edge of the simulated are or the sea floor stop simulating there. Because nothing happens in those areas, simulating erosion would be a waste of processing power.</li><li>When changing the amount of sediment, the snowball edits the height map at its previous position instead of its current position. Erosion and deposition take place behind it to prevent snowballs from digging themselves in.</li><li>After simulating erosion, gaussian blur is applied to the height map. Because the height map in these examples has a low resolution, blur is required to keep the surfaces smooth enough to be visually appealing.</li></ul><p>Because the offset is used while eroding, and because the erosion rate is quite high, every traced snowball has a larger influence on the terrain than a smaller node that looks more like a raindrop would. This results in a fast simulation, but it reduces precision.</p><h2>Results</h2><figure title="The results of the erosion algorithm"><img src="https://jobtalle.com/posts/2020_6_14/img/results.jpg"><figcaption>Figure 3: The results of the erosion algorithm.</figcaption></figure><p>Applying the algorithm above with varying snowball counts gives the results rendered in Figure 3. The algorithm <a href="https://jobtalle.com/HydraulicErosion" target="_blank">works in a browser</a>, and the source code can be found <a href="https://github.com/jobtalle/HydraulicErosion" target="_blank">on GitHub</a>. Pressing the space bar generates a new island. The "starting material" for the algorithm is shown in the first image of figure 3. This island shape was generated using a very similar algorithm to the one I used in <a href="https://jobtalle.com/layered_voxel_rendering.html" target="_blank">my layered voxel rendering example terrains</a>. While the shape does contain some details and ridges, it is very smooth and contains no traces of hydraulic erosion.</p><p>The second image shows the same island after dropping 35.000 snowballs on it. They are dropped randomly and evenly spaced. Because of the random initial conditions of the starting shape, valleys and river like structures form where the snowballs find the quickest way to the sea. 35.000 may seem like a high number, but recall that snowballs that reach the sea floor or the edge of the map terminate early. The majority of drops don't fall on the island, so only a small number will actualy roll down one of the valleys that can be seen in the image.</p><p>The third image shows the same island after dropping 50.000 snowballs. Compared to the previous image, no new details form, although the terrain features are more pronounced.</p><p>The last image shows the island after dropping 100.000 snowballs. This is clearly too much; the ridges become very deep and the shore is very rough. At this point, the results start looking less realistic too. The valleys carve out very sharp terrain features that would erode away themselves.</p><p>All islands in the images above can be generated within half a second on my desktop computer, with the algorithm running on a single CPU thread. Therefore, it is not necessary to reduce the number of snowballs for performance reasons in most applications. The algorithm is fast enough as it is.</p><h2>Conclusion</h2><p>The proposed algorithm provides a fast method to approximate hydraulic erosion. While realism was no priority, erosion and deposition patterns that one would expect do show up when testing the method on various terrains.</p><p>Because the code runs very fast (contrary to most alternative solutions that can be found in the literature), it may be suitable for applications like procedural terrain generation in games. In those applications, it is desirable to produce results quickly, while the results do not need to be very realistic; they just need to look credible.</p><p>The method can be extended to track the paths of river beds. Valleys where many snowballs roll through would realistically be rivers. When an area reaches a certain threshold of "snowball traffic", a river or lake can be created there.</p><p>Another interesting addition would be a texture that keeps track of the amount of erosion and deposition of material on the terrain. This data can then be used to color the terrain; if lots of material is deposited, sand and small particles will accumulate there. Areas where little erosion has taken place will look different from heavily eroded slopes.</p><h2>Appendix: rendering shore waves</h2><figure title="Waves"><img src="https://jobtalle.com/posts/2020_6_14/img/waves.jpg"><figcaption>Figure 4: Rendering shore waves.</figcaption></figure><p>The <a href="https://jobtalle.com/HydraulicErosion" target="_blank">animated example</a> contains waves that move towards the shore of the islands. Besides clarifying the shape of the shore, they don't really serve a purpose with regards to the erosion, but it makes the scene prettier.</p><p>Figure 4 shows the steps that create the wave animation:</p><ol>    <li>First, a <a href="https://en.wikipedia.org/wiki/Voronoi_diagram" target="_blank"><em>Voronoi diagram</em></a> is created around the island shore. Instead of creating a diagram from points, the diagram is created from …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jobtalle.com/simulating_hydraulic_erosion.html">https://jobtalle.com/simulating_hydraulic_erosion.html</a></em></p>]]>
            </description>
            <link>https://jobtalle.com/simulating_hydraulic_erosion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612749</guid>
            <pubDate>Tue, 23 Jun 2020 12:02:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Is the Human Brain So Efficient?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23612473">thread link</a>) | @CapitalistCartr
<br/>
June 23, 2020 | http://m.nautil.us/issue/86/energy/why-is-the-human-brain-so-efficient-rp | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/86/energy/why-is-the-human-brain-so-efficient-rp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>T</span>he brain is complex; in humans it consists of about 100 billion neurons, making on the order of 100 trillion connections. It is often compared with another complex system that has enormous problem-solving power: the digital computer. Both the brain and the computer contain a large number of elementary units—neurons and transistors, respectively—that are wired into complex circuits to process information conveyed by electrical signals. At a global level, the architectures of the brain and the computer resemble each other, consisting of largely separate circuits for input, output, central processing, and memory.<sup>1</sup></p> <p>Which has more problem-solving power—the brain or the computer? Given the rapid advances in computer technology in the past decades, you might think that the computer has the edge. Indeed, computers have been built and programmed to defeat human masters in complex games, such as chess in the 1990s and recently Go, as well as encyclopedic knowledge contests, such as the TV show <i>Jeopardy!</i> As of this writing, however, humans triumph over computers in numerous real-world tasks—ranging from identifying a bicycle or a particular pedestrian on a crowded city street to reaching for a cup of tea and moving it smoothly to one’s lips—let alone conceptualization and creativity.</p> <p>So why is the computer good at certain tasks whereas the brain is better at others? Comparing the computer and the brain has been instructive to both computer engineers and neuroscientists. This comparison started at the dawn of the modern computer era, in a small but profound book entitled <i>The Computer and the Brain</i>, by John von Neumann, a polymath who in the 1940s pioneered the design of a computer architecture that is still the basis of most modern computers today.<sup>2</sup> Let’s look at some of these comparisons in numbers (Table 1).</p> <figure data-alt="Luo_BR"><img src="http://static.nautil.us/14525_0bd97cb91b8d57dad18542081fb8f2b1.png" width="733" alt=""></figure><p>The computer has huge advantages over the brain in the speed of basic operations.<sup>3</sup> Personal computers nowadays can perform elementary arithmetic operations, such as addition, at a speed of 10 billion operations per second. We can estimate the speed of elementary operations in the brain by the elementary processes through which neurons transmit information and communicate with each other. For example, neurons “fire” action potentials—spikes of electrical signals initiated near the neuronal cell bodies and transmitted down their long extensions called axons, which link with their downstream partner neurons. Information is encoded in the frequency and timing of these spikes. The highest frequency of neuronal firing is about 1,000 spikes per second. As another example, neurons transmit information to their partner neurons mostly by releasing chemical neurotransmitters at specialized structures at axon terminals called synapses, and their partner neurons convert the binding of neurotransmitters back to electrical signals in a process called synaptic transmission. The fastest synaptic transmission takes about 1 millisecond. Thus both in terms of spikes and synaptic transmission, the brain can perform at most about a thousand basic operations per second, or 10 million times slower than the computer.<sup>4</sup><br></p> <p>The computer also has huge advantages over the brain in the precision of basic operations. The computer can represent quantities (numbers) with any desired precision according to the bits (binary digits, or 0s and 1s) assigned to each number. For instance, a 32-bit number has a precision of 1 in 232 or 4.2 billion. Empirical evidence suggests that most quantities in the nervous system (for instance, the firing frequency of neurons, which is often used to represent the intensity of stimuli) have variability of a few percent due to biological noise, or a precision of 1 in 100 at best, which is millionsfold worse than a computer.<sup>5</sup></p> <blockquote><p>A pro tennis player can follow the trajectory of a ball served at a speed up to 160 mph.</p> </blockquote><p>The calculations performed by the brain, however, are neither slow nor imprecise. For example, a professional tennis player can follow the trajectory of a tennis ball after it is served at a speed as high as 160 miles per hour, move to the optimal spot on the court, position his or her arm, and swing the racket to return the ball in the opponent’s court, all within a few hundred milliseconds. Moreover, the brain can accomplish all these tasks (with the help of the body it controls) with power consumption about tenfold less than a personal computer. How does the brain achieve that? An important difference between the computer and the brain is the mode by which information is processed within each system. Computer tasks are performed largely in serial steps. This can be seen by the way engineers program computers by creating a sequential flow of instructions. For this sequential cascade of operations, high precision is necessary at each step, as errors accumulate and amplify in successive steps. The brain also uses serial steps for information processing. In the tennis return example, information flows from the eye to the brain and then to the spinal cord to control muscle contraction in the legs, trunk, arms, and wrist.<br></p> <p>But the brain also employs massively parallel processing, taking advantage of the large number of neurons and large number of connections each neuron makes. For instance, the moving tennis ball activates many cells in the retina called photoreceptors, whose job is to convert light into electrical signals. These signals are then transmitted to many different kinds of neurons in the retina in parallel. By the time signals originating in the photoreceptor cells have passed through two to three synaptic connections in the retina, information regarding the location, direction, and speed of the ball has been extracted by parallel neuronal circuits and is transmitted in parallel to the brain. Likewise, the motor cortex (part of the cerebral cortex that is responsible for volitional motor control) sends commands in parallel to control muscle contraction in the legs, the trunk, the arms, and the wrist, such that the body and the arms are simultaneously well positioned to receiving the incoming ball.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/12/Feedback/building-the-perfect-painkiller" data-trval="building-the-perfect-painkiller" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/3079_f44ee263952e65b3610b8ba51229d1f9.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Neuroscience">Also in Neuroscience</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/12/Feedback/building-the-perfect-painkiller" data-trval="building-the-perfect-painkiller" data-trlbl="foc_rec" data-tract="internal_art">Building the Perfect Painkiller</a></h4>
<p>By Maia Szalavitz</p>
<p>
Opioid addiction can be seen as an infinite loop, a bug in the brain’s programming. Take drug. Feel better. Come down. Repeat.   Of the people who use opioid drugs recreationally, between 8 and 23 percent become addicted—sometimes fatally....<strong><a href="http://m.nautil.us/issue/12/Feedback/building-the-perfect-painkiller" data-trval="building-the-perfect-painkiller" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div> <p>This massively parallel strategy is possible because each neuron collects inputs from and sends output to many other neurons—on the order of 1,000 on average for both input and output for a mammalian neuron. (By contrast, each transistor has only three nodes for input and output all together.) Information from a single neuron can be delivered to many parallel downstream pathways. At the same time, many neurons that process the same information can pool their inputs to the same downstream neuron. This latter property is particularly useful for enhancing the precision of information processing. For example, information represented by an individual neuron may be noisy (say, with a precision of 1 in 100). By taking the average of input from 100 neurons carrying the same information, the common downstream partner neuron can represent the information with much higher precision (about 1 in 1,000 in this case).<sup>6</sup></p> <p>The computer and the brain also have similarities and differences in the signaling mode of their elementary units. The transistor employs digital signaling, which uses discrete values (0s and 1s) to represent information. The spike in neuronal axons is also a digital signal since the neuron either fires or does not fire a spike at any given time, and when it fires, all spikes are approximately the same size and shape; this property contributes to reliable long-distance spike propagation. However, neurons also utilize analog signaling, which uses continuous values to represent information. Some neurons (like most neurons in our retina) are nonspiking, and their output is transmitted by graded electrical signals (which, unlike spikes, can vary continuously in size) that can transmit more information than can spikes. The receiving end of neurons (reception typically occurs in the dendrites) also uses analog signaling to integrate up to thousands of inputs, enabling the dendrites to perform complex computations.<sup>7</sup></p><blockquote><p>Your brain is 10 million times slower than a computer.</p> </blockquote><p>Another salient property of the brain, which is clearly at play in the return of service example from tennis, is that the connection strengths between neurons can be modified in response to activity and experience—a process that is widely believed by neuroscientists to be the basis for learning and memory. Repetitive training enables the neuronal circuits to become better configured for the tasks being performed, resulting in greatly improved speed and precision.<br></p> <p>Over the past decades, engineers have taken inspiration from the brain to improve computer design. The principles of parallel processing and use-dependent modification of connection strength have both been incorporated into modern computers. For example, increased parallelism, such as the use of multiple processors (cores) in a single computer, is a current trend in computer design. As another example, “deep learning” in the discipline of machine learning and artificial intelligence, which has enjoyed great success in recent years and accounts for rapid advances in object and speech recognition in computers and mobile devices, was inspired by findings of the mammalian visual system.<sup>8</sup> As in the mammalian visual system, deep learning employs multiple layers to represent increasingly abstract features (e.g., of visual object or speech), and the weights of connections between different layers are adjusted through learning rather than designed by engineers. These recent advances have expanded the repertoire of tasks the computer is capable of performing. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/86/energy/why-is-the-human-brain-so-efficient-rp">http://m.nautil.us/issue/86/energy/why-is-the-human-brain-so-efficient-rp</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/86/energy/why-is-the-human-brain-so-efficient-rp</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612473</guid>
            <pubDate>Tue, 23 Jun 2020 11:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Neuroscientist’s Theory of Everything]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23612457">thread link</a>) | @CapitalistCartr
<br/>
June 23, 2020 | http://m.nautil.us/issue/86/energy/a-neuroscientists-theory-of-everything | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/86/energy/a-neuroscientists-theory-of-everything">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>K</span>arl Friston wanted me to know he had plenty of time. That wasn’t quite true. He just didn’t want our conversation—about his passion, the physics of mental life—to end. Once it did, he would have to step outside, have a cigarette, and get straight back to modeling COVID-19. I caught the University College London neuroscientist at 6 p.m., his time, just after he had sat on a panel at a COVID-related press conference. He apologized for still having on a tie and seemed grateful to me for supplying some “light relief and a distraction.”</p><p>A decade ago, Friston published a paper called “<a href="https://www.nature.com/articles/nrn2787" target="_blank">The Free-Energy Principle: A Unified Brain Theory?</a>” It spells out the idea that the brain works as an editor, constantly minimizing, “squashing” input from the outside world, and in the process balancing internal models of the world with sensations and perceptions. Life, in Friston’s view, is about minimizing free energy. But it’s not just a view of the brain. It’s more like a theory of everything. Friston’s free-energy theory practically sets your brain on fire when you read it, and it has become one of the most-cited papers in the world of neuroscience. This May, Friston published a new paper, “<a href="https://www.mdpi.com/1099-4300/22/5/516" target="_blank">Sentience and the Origins of Consciousness</a>,” that takes his ideas into new intellectual territory.</p><figure data-alt="Gallagher_BREAKER"><img src="http://static.nautil.us/17310_9da6afb4840df51ceee399e5dea42598.png" width="733" alt=""><figcaption><span><strong>NOT A FAN OF SURPRISES:</strong> Karl Friston (above) has argued that lifeforms, in order to survive, must limit the long-term average of surprise they experience in their sensory exchanges with the world. Being surprised too often is tantamount to a failure to resist a natural tendency toward disorder.</span><span>Kate Peters</span></figcaption></figure><p>Friston, currently a Wellcome Trust Principal Fellow and Scientific Director of the Wellcome Trust Centre for Neuroimaging, invented statistical parametric mapping, a brain scanning technique that has allowed neuroscientists to assess, as never before, the activity in specific brain regions and their roles in behavior. The discoveries he’s helping to make about the nature of the brain come out of a psychiatrist’s concern for the well-being of his patients, suffering from chronic schizophrenia. “Most of our practical work on causal modeling, data analysis, and imaging sciences was motivated and actually funded by schizophrenia research,” Friston said. “It has been a central part of my life and career for decades.”<br></p><p>The applications of Friston’s research are tangible and have made major contributions to mental disease, brain imaging, and now the COVID-19 pandemic. Venturing into the theory behind them, however, is a safari through a jungle of fascinating and at times beguiling concepts. Friston’s ideas have been on my radar for some time, so I was excited to jump right in. He was a passionate tour guide, taking us through a landscape of some of the most stimulating topics in science today, from consciousness to quantum physics to psychedelics.</p><p><b>In “The Free-Energy Principle,” you write the world is uncertain and full of surprises. Action and human perception, you argue, are all about minimizing surprise. Why is it important that things—including us—minimize surprise?</b></p><p>If we minimize surprise now, then on average over time, we’re minimizing the average surprise, which is entropy. If a thermostat could have beliefs about its world—it might say, “My world is about living at 22 degrees centigrade”—so any sensory information from its thermal receptors that departs from that is surprising. It will then act on the world to try and minimize that surprise and bring that prediction error back to zero. Your body’s homeostasis is doing exactly the same thing.</p><p><b>Does the brain minimize surprise in order to conserve energy?</b></p><p>You could certainly say that. But I wouldn’t quite put it like that. It’s not that the brain has a goal to exist. It just exists. It looks as if it has a goal to exist. What does existing mean? It’s always found in that configuration. The brain has to sample the world in a way that it knows what’s going to happen next. If it didn’t, you’d be full of surprises and you’d die.</p><blockquote><p>Anything you talk about is really just an explanation for your lived world.</p> </blockquote><p><b>What’s the core argument of the free energy principle?</b><br></p><p>Variational free energy is basically a quantity that stands in for surprise. It’s the ultimate goal-function of life. Why is there a difference between free energy and surprise? Let’s say I tasked you with engineering an oil droplet. You want to engineer an oil droplet and sell it on Amazon. You would have to write down its equations of motion, flows on gradients, where these gradients are defined by surprise, and the surprise defines the likely configuration that characterizes an oil droplet. The problem is, when you come to evaluate that surprise, that potential energy, it becomes numerically impossible to do because of all the different ways in which its configuration could have been caused. This means that flows can’t physically be realized by you—trying to engineer your Amazon oil droplet.</p><p><b>So how can you build an oil droplet, or anything, for that matter?</b></p><p>There is a way of doing it, invented by the physicist Richard Feynman. He had exactly the same problem in quantum electrodynamics. He wanted to evaluate the probability of all the ways that this electron could get from the initial state in which it was prepared to some final or end state. The number of paths that a particle could take is infinite. Feynman was facing an enormous problem. He wanted to calculate the most likely electron path, but he couldn’t evaluate all the possible ways that the particle could get from here to here, let alone start looking up the most likely path.</p><p>So he came up with variational free energy, which is essentially a mathematical quantity that is always bigger than the surprise. If you squash or reduce the free energy, which you can measure quite easily, you can do your gradient descent, and get to the bottom of free energy. What Feynman effectively did was replace an impossible integration problem with a tractable optimization problem. If you want to emulate self-organization, you’re going to have to change the problem from the way the world works into an approximation of the way the world works, and develop an optimization scheme.</p><p>You can see why free energy starts to take a key role in articulating these ideas about how the brain works. It may well be that it wasn’t just Richard Feynman that realized this was the way to self-evidence efficiently and effectively. It might be that evolution has also realized this. This variational trick—minimizing Feynman variational free energy—has become installed in us.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/15/Turbulence/your-brain-is-on-the-brink-of-chaos" data-trval="your-brain-is-on-the-brink-of-chaos" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/3728_460b491b917d4185ed1f5be97229721a.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Neuroscience">Also in Neuroscience</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/15/Turbulence/your-brain-is-on-the-brink-of-chaos" data-trval="your-brain-is-on-the-brink-of-chaos" data-trlbl="foc_rec" data-tract="internal_art">Your Brain Is On the Brink of Chaos</a></h4>
<p>By Kelly  Clancy</p>
<p>
In one important way, the recipient of a heart transplant ignores its new organ: Its nervous system usually doesn’t rewire to communicate with it. The 40,000 neurons controlling a heart operate so perfectly, and are so self-contained, that a heart...<strong><a href="http://m.nautil.us/issue/15/Turbulence/your-brain-is-on-the-brink-of-chaos" data-trval="your-brain-is-on-the-brink-of-chaos" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div><p><b>The idea of a Markov blanket shows in your recent paper on the origins of consciousness. Who was Markov, and what is this blanket named after him?</b></p><p>Andrey Markov was one of the grandfathers of stochastic processes and probability theory. The notion of a Markov blanket arises, not in consciousness research, and not really even in neuroscience—it’s much more fundamental than that. Any <i>thing</i> necessarily exists as a Markov blanket. Because if it didn’t, you wouldn’t be able to measure anything that distinguished the thing from something else. It’s absolutely crucial. If something doesn’t have a Markov blanket, it doesn’t exist. From the perspective of systems neuroscience, the Markov blanket is a new and important thing in the toolkit that allows you to demystify and talk with a different calculus, and a different language, about things such as sentience.</p><p><b>What’s a good example of something that illustrates the Markov blanket?</b></p><p>Let’s go back to our oil droplet. Imagine it in a glass of water. The agenda is to understand, “Why does the oil droplet hang together? Why does it resist the tendency to be dispersed, dissolve, dissipate, and distribute all its molecules around the solvent?” There’s something special about certain things or systems, like the oil droplet, that manage to distinguish themselves from the universe, or the environment in which they are immersed.</p><p><b>The Markov blanket helps explain how things can exist—but what is it, exactly?</b></p><p>The Markov blanket is a permeable interface between the inside and the outside, enabling a two-way exchange. Stuff on the outside—the environment, the universe, the heat bath—impacts what’s going on inside via the sensory part of the Markov blanket. The Markov blanket has sensory and active states. Stuff on the outside, the external states, influence the blanket’s sensory states, what the blanket senses. And stuff on the inside of the blanket, the internal states, influence the blanket’s active states. The active states close that circle of causality, or, if you like, they disclose what’s going on inside by acting on the outside state. With that mathematical construct in place, you can go a lot further than 20th-century physics, which was all about equilibrium statistics and thermodynamics—the kind of physics that you would have been taught in school. Implicit in equilibrium physics is the notion that you’ve got an isolated or a closed system immersed in a heat bath—without ever asking where the heat bath came from. That implicitly assumed the Markov blanket.</p><blockquote><p>The brain has to sample the world in a way to what’s going to happen next.</p> </blockquote><p><b>Where can the Markov blanket take physics in the 21st century?</b><br></p><p>You can start to address what most people in physics—not most, but those with a more adventurous mind and the time and money to do it—want to ask and address. Which is, “How do things self-organize when they are exposed to something out there?” Open systems, in other words. Systems that are far from equilibrium—non-equilibrium steady states that persist despite the fact that they are in exchange with …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/86/energy/a-neuroscientists-theory-of-everything">http://m.nautil.us/issue/86/energy/a-neuroscientists-theory-of-everything</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/86/energy/a-neuroscientists-theory-of-everything</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612457</guid>
            <pubDate>Tue, 23 Jun 2020 11:20:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eyes in the Sky]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23612412">thread link</a>) | @wheresvic3
<br/>
June 23, 2020 | https://restofworld.org/2020/india-magh-mela/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/india-magh-mela/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>I</span>t’s 3:13 a.m., and Radio Inspector Ashok Kumar turns around to look at his computer. His face stiffens. He zooms in on the screen and squints at an unauthorized SUV crossing a pontoon bridge.</p>



<p>Kumar and his team are in the Integrated Command and Control Center (ICCC) overlooking operations for this year’s Magh Mela, an annual Hindu pilgrimage and festival that draws millions of people in a single day. Each year, devotees from all across the country congregate at the spot where the Ganges, Yamuna, and mythical Saraswati rivers converge at Prayagraj in the northern Indian state of Uttar Pradesh. There, devotees dip in the water, which they believe cleanses them of their sins.</p>



<p>It is here at the ICCC, a big white room with two rows of desks, that the police keep a vigil over the mela (the Hindi word for “fair”). At each terminal, policemen hunch over computer screens as they monitor feeds from around 700 closed-circuit TV cameras. A video wall dominates, with 55-inch screens arranged in a 10 by 2 matrix along the length of the room. Khaki jackets emblazoned with “Uttar Pradesh Police” hang on the backs of the chairs. Tapping their shoeless feet on the carpeted floor, the officers glance at each other regularly, followed by tentative nods implying that everything is fine.</p>



<p>The monitoring team is on high alert. Kumar and his team have been here since 8 p.m. last night, on a 12-hour shift, and the first bathing rituals began at 3 a.m. Today is February 9, and it is the full moon day of Maghi Purnima. Police are expecting a crowd of 7.5 million — down from a single-day peak of 11 million two weeks earlier. Millions of pilgrims will be leaving after today’s dip. Many are joined by their families, who have come to take them home.</p>



<p>Kumar’s job is to keep this massive crowd under control. Stampedes, terror attacks, and theft are on his mind. He places a call, and minutes after the SUV is vetted, a police officer appears on-screen to set up a barricade at the foot of the bridge.</p>



<p>Outside, as LED lights switch off, an easterly sunrise turns the sky several shades of crimson. On the water, the boats stand out in silhouette. The air contains a mix of piety and festivity.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela077-1-2800x1575.jpg 2800w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela077-1-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela077-1-768x432.jpg 768w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>

    <figure>
      <ul>
        <li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela011-1-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela011-1-768x432.jpg 768w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela009-1-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela009-1-768x432.jpg 768w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
      </ul>
      <figcaption>Police from the Integrated Command and Control Centre monitor the crowd of devotees with around 700 closed-circuit TV cameras.</figcaption>
    </figure>


<hr>



<p><strong>The Magh Mela</strong> is a smaller version of the<a href="https://en.wikipedia.org/wiki/Kumbh_Mela"> Kumbh Mela</a>, the<a href="https://en.wikipedia.org/wiki/List_of_largest_peaceful_gatherings"> largest human gathering</a> on earth. The Kumbh is held every six years, and the previous one was held in 2019. Over 49 days last year, more than 250 million people took a dip in the <em>sangam</em>, the point where the three rivers meet, with the biggest one-day crowd reaching 50 million. It was the second-largest <a href="https://en.wikipedia.org/wiki/List_of_largest_peaceful_gatherings">gathering</a> in history.</p>



<p>To prepare for the melas, tens of thousands of officials spend months setting up a massive temporary city on the banks of the Ganges. Viewed from above, it is a colorful patchwork divided by big and small bodies of water. Much of this — tents, floating bridges, and metal sheet roads — is built specifically for the festival. As the riverbed floods every year, the city lasts for only several months before the Ganges threatens to reclaim the land.</p>



<p>The physical structure of the mela changes each year, depending on the river. The groundwork usually starts in October, after monsoon season, when the Ganges retreats. Temporary roads are marked, and pontoon bridges are built to join land separated by water. Jetties are built on the banks; the roads are lined with metal sheets; pipelines and electricity cables are laid. Bathing stations are set up along a 3-mile floating jetty, with nets spread underneath to catch those who fall in.</p>



<p>This year, the Ganges’ water levels remained high later than usual. “We could reclaim land only by the end of November, but heavy rains kept hampering civil works until December,” says Rajneesh Mishra, a civil servant who oversees the Mela. This year’s mela was spread over 270 hectares (667 acres), about 30% bigger than Monaco, and divided into six sectors for administrative purposes. Setting up the infrastructure was — and is — an immense logistical feat. The mela has 13 police stations, 40 police outposts, and five thermal power stations. There are five hospitals with operation theaters and 25 beds each, as well as labs, testing facilities, and on-site ambulances.</p>



<p>All of this requires a substantial budget. For this year’s mela, the state<strong> </strong>government budgeted $77 million. Last year, for the Kumbh, it spent $558 million.</p>



<p>All IT operations for the festival are run by the ICCC, which is based in a three-story concrete building that was inaugurated a little over a year ago by Prime Minister Narendra Modi. It’s one of the few permanent structures in the mela area, besides a temple and a 16th-century fort. The center itself is divided up between the monitoring room, which uses a video surveillance system to keep a bird’s-eye view on the mela; the wireless grid room, which liaises between monitors and the ground staff; the war room, where personnel from the fire, water, and police departments as well as the military are on hand at all hours to deal with emergencies; and, finally, a call center.</p>



<p>The key tool in the ICCC’s arsenal is the crowd management application (CMA) system, which keeps an eye on crowd density across all 700 camera feeds. The system is taught how much ground area each CCTV camera covers, which then allows it to estimate, with 85% accuracy, the number of people in a space at any given time. If there are more than three people per square meter, the system issues a warning, and the ground police team is notified and instructed to stop, hold, or divert the crowd.</p>



<p>The Prayagraj Smart City Mission team, which oversees the ICCC, considered various methods for crowd management before settling on the CMA. One option was to estimate crowd size by measuring an area’s smartphone density. But this idea was quickly scrapped. Most devotees at Magh Mela are not smartphone users, says assistant manager Vipin Singh. Only <a href="https://www.news18.com/news/tech/smartphone-users-in-india-crossed-500-million-in-2019-states-report-2479529.html">500 million</a> people in India — roughly one-third of the population — own smartphones. Additionally, many families share one phone, and rural residents (who form as much as 95% of mela attendees, according to police estimates) often don’t use them at all. “If the system shows three people,” says Singh, “there might actually be 100, where 97 are carrying basic mobile phones or no phones at all.”</p>



<p>Last year, officials also experimented with a facial recognition system. The idea was that the technology would provide accurate headcounts, track patterns of movement, and measure time spent between distinct points. But that didn’t work either, as people often carry big bags on their heads as they navigate mela crowds. That meant that, for every face the system could see, a piece of luggage might conceal several more.</p>



<p>Cars have proven easier to track. The automated number plate recognition (ANPR) system records the license number of every vehicle entering or exiting the city, checking it against a database containing the license numbers of stolen vehicles and ones involved in crimes. If a match is found, an alert goes off. For this Magh Mela, says Singh, the administration installed ANPR-aided cameras at eight locations on the city’s periphery. But there are plans to ramp up. “For the next mela,” he says, “we’re looking to increase this to 28 locations.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/06/MaghMela107-1-2800x1575.jpg 2800w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela107-1-1600x900.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/06/MaghMela107-1-768x432.jpg 768w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>It’s 7:17 a.m.</strong> Mamta Sharma<strong> </strong>stands knee-deep in the river.</p>



<p>Facing east toward the Ganges, she presses her hands in a namaste. She bows her head several times and chants a prayer under her breath. And then she takes a dip in the river, repeating it four times.</p>



<p>Seagulls glide over the heads of bowing devotees, but neither seem to mind the other. When pilgrims toss bits of fruit into the river, the seagulls scoop them up before they land in the water.</p>



<p>Some devotees hire boats to get to the point believed to be the exact location where the three rivers meet. There, people offer their respects to the river, take dips, and fill plastic cans with sacred water. At the <em>sangam</em>, you can see colors mixing, says boatman Ajay Nishad. “The whitish water is that of the Ganges, and the black that of the Yamuna,” he says. Stare long enough and one might think that he is right.</p>



<p>People who can’t afford to hire a boat, which is most pilgrims, instead bathe close to the bank. The mela administration encourages this to avoid overcrowding.</p>



<p>Sharma comes out of the river. Still dripping, she makes a video call to her mother, who could not come with her. She pans her phone to show the <em>sangam</em> to her mother, who offers namaste multiple times, her eyes welling up.</p>



<p>While she dries off, Sharma keeps looking up expectantly. On some auspicious days, the mela administration showers flowers on bathing devotees from a helicopter. She has seen videos of it on social media. “We were all excited about it, but it hasn’t happened today,” she says.</p>



<p>“Still, the holy dip is quite an experience.”</p>



<p>Sharma, who lives in Kolkata in eastern India, has come to the Magh Mela with a group of 12. They live in different cities but come from the same family in Jaunpur, over 100 kilometers from here. Most are elderly. At 31, Sharma is the youngest.</p>



<p>Nishad, the boatman, has been ferrying visitors to the <em>sangam</em> for three years, and he says the melas are always very well organized. Police designate holding areas to keep people safe when crowds swell, and are good at managing foot traffic to prevent bottlenecks. While it can take several hours to find missing people — pilgrims getting separated is a common problem at melas — he says the administration always tracks them down.</p>



<p>But, lately, he has noticed something new. Officials …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/india-magh-mela/">https://restofworld.org/2020/india-magh-mela/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/india-magh-mela/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612412</guid>
            <pubDate>Tue, 23 Jun 2020 11:12:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup, know where you are]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23612382">thread link</a>) | @KingOfCoders
<br/>
June 23, 2020 | https://www.svese.de/essay/phases-ands-steps-startup-know-where-you-are | <a href="https://web.archive.org/web/*/https://www.svese.de/essay/phases-ands-steps-startup-know-where-you-are">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Marketing spends thousands or millions of dollars on performance and growth marketing. Product management is trying to convert customers. But like water customers are leaking left and right. The founders seek new investments to increase the running out cash. Sounds familiar? I have seen many startups working this way. The reason is they do not know where they stand. One part of the company is in scaling mode, one part of the company is in cost cutting mode, founders are desperately looking for money – while the company has not found product market fit, which is the root of all the bad things happening. </p><p>‍<br>If a startup is not aligned on the phase it is in, people do things that do not match or support each other. Not only do they not match, they hinder each other and cancel each other out. Product management is flooded with requests that do not contribute to product market fit. Founders hire too many developers to get something going. Founders hire too many marketeers and increase marketing spend for artificial growth.</p><p>‍<br>But what to do instead? You need to know your startup phase and act accordingly.</p><p>‍<br>Startups run through several phases or steps over the years. Each phase has its special challenges and tasks. The seven phases of a company are: Ideation, Prototype, MVP, Product Market Fit, Scaling, Potential Profitability and Cash Cow.</p></div><div><p><strong>1.</strong></p><p>‍<br>The first phase is Ideation. Here a startup needs to find the right problem to solve and the right idea for a solution. Many founders have their idea and jump over this phase and neglect it. Whether you have an idea or not, do not skip this phase. There might be a slightly different, slightly better idea. Getting the idea right prevents a lot of costly work later. This phase is often characterized by Design Thinking to help find an idea for a problem. You can use a fake landing page to early test demand. There is no need for technology, a developer or for marketing in this phase.<br>‍</p><p><strong>2. </strong><br>‍</p><p>Next, it is time to build a prototype. The goal is to test an idea, play with the idea, test feasibility and have something to show around to friends, potential customers, potential employees and investors. Technology is characterized by cheapness. There often is no need to write code. Instead no-code or low-code solutions are enough here. If the technology of your idea is challenging and not of-the-shelf, you can use that technology in the prototype to see if you can make it work. Remember that people will judge your idea by how it looks. Either take that into account when evaluating feedback, manage expectations or invest in a designer. Again, in this phase, you do not need developers or marketing.<br>‍</p><p><strong>3.</strong></p><p>‍<br>Build an MVP. The difference of the minimum viable product (MVP) to a prototype is that the MVP is something people could buy and would pay for. Many startups confuse an MVP with a prototype and mix these two phases up. If you build an MVP to test the feasibility of your idea, you are doing it wrong. As Paul Graham says, “Make something people want”. Validate the idea with the market and potential customers. Learn about the jobs to be done (JTBD) from potential customers and round out your product to something a customer is willing buy. Iterate on the idea until it is right. Often startups use exotic technology, the newest shiny kid on the block. Do not do that. Use a mainstream coding framework to create your MVP. Everything mainstream should be fine, be it PHP, Ruby, Python or JavaScript. The main benefit is a framework where you do not have to write all the code yourself. One developer is enough in this phase, you do not need marketing. One common mistake is to hire marketing in this phase or more than one developer.<br>‍</p><p><strong>4.</strong></p><p>‍<br>The fourth phase is the most difficult one, where startups make the most mistakes. It is about finding product market fit (PMF). You need to concentrate every effort in the startup on finding product market fit. Do not deviate and do not get sidetracked. In this phase the lean startup methodology really shines and helps you find PMF. Product market fit means that the market pushes into your product and you no longer need to pull everyone in from the market. Product market fit means sticking customers and tailwind from the market. The biggest mistake is to not find product market fit and buy growth with investor money. This often happens when you have significant investment before you have achieved PMF. Then VCs might push for growth. Many startups think they have PMF when they have not. They cannot endure the time it takes to find product market fit and skip this phase to premature scaling. Scaling on top of a product without PMF leads to high churn and low customer satisfaction. Every penny spent on scaling in this phase is wasted. Startups need only a few developers in this phase as finding product market fit is not parallelizable. Resist hiring too many developers to “get more done”. You urgently need product marketing in this phase. Product marketing tells customers about the product, explains the product, tells customers about new features and increases feature usage. When customers use your features, they will stick. You do not need performance marketing, growth marketing and obviously not brand marketing before product market fit.<br>‍</p><p><strong>5.</strong></p><p>‍<br>Now it is time to spend money. The scaling phase is here. The goal is to find a profitable marketing and distribution channel and find channel market fit. Then spend money with the channel that is working to scale your startup. You have a working product, but in the scaling phase you might need to adapt technology to your growth. So, parts of your tech stack need to be specialized other parts need to be replaced. Not only do customers grow in this phase, but so does you startup. To scale you need many developers. Marketing spend is a mix of product marketing and performance marketing to support and fuel growth. The beginning of the phase is the last time to take risks. The time to take risks in a startup is as early as possible. The earlier the better. With growing customer numbers and growing revenue, the appetite for risk vanishes. <br>‍</p><p><strong>6.</strong></p><p>‍<br>Then there is profitability, or at least potential profitability. After growth is maxed out or growth money has dried up it is time to look at the costs. The goal of this phase is to get into a position where you can decide to be profitable or not. If you cut marketing down, you are profitable. If you want to grow faster and spend more on marketing, you decide not to be profitable. But it is your decision not something forced on you by costs. You still have many developers working on the product and marketing works on product marketing, performance marketing and brand marketing. It is now time search for new product development and find a new product or new main feature that drives your next growth curve. Many companies miss this point and move into the next phase without having started new development.<br>‍</p><p><strong>7.</strong></p><p>‍<br>The last phase for a product is cash cow. The product has achieved a high market share and future growth is limited. The goal of this phase is to get all the money that is left in the product. Optimize for costs to increase margins. After the beginning of becoming a cash cow is the last point to find the next star. It is already late to start a new product as most of your employees that can invent and scale a product probably have already moved on. The biggest mistake in this phase is not to stick to new product development. A new product is like a new startup, it takes years to succeed. You only need very few developers in this phase. Companies usually have too many developers working on their cash cow because they have not moved into new product development. Developers develop features that do not move the needle. Marketing is mostly brand marketing.<br>‍</p><p>How can you make this work for you? To prevent frustration a startup needs to know in which phase it is in and act accordingly. Do the right marketing for the step, hire the right amount of developers and align the whole company. Every employee needs to clearly know where the startup stands, what is the goal of the current phase and what needs to be achieved to successfully get to the next step. Then success does not depend on luck and everyone is acting in concert.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.svese.de/essay/phases-ands-steps-startup-know-where-you-are</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612382</guid>
            <pubDate>Tue, 23 Jun 2020 11:09:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indie Code Catalog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23612333">thread link</a>) | @feross
<br/>
June 23, 2020 | https://blog.licensezero.com/2020/06/23/Indie-Code-Catalog.html | <a href="https://web.archive.org/web/*/https://blog.licensezero.com/2020/06/23/Indie-Code-Catalog.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  
  <p>You’re searching through your favorite software registry.  Maybe npm, maybe crates.io, maybe RubyGems, maybe pkg.go.dev.  You find what you’re looking for.  It’s not a big, corporate project.  But the signs of a maintainer who cares are all there.</p>

<p>You’re glancing the metadata for “MIT” or “BSD” or “Apache”, but alas, you don’t see it.  Instead there’s a link to a webpage.  Something about “free for open source”.  A big button to “buy a license”.  Not what you were hoping for.</p>

<p>You tab back to your search, and dig deeper.  You find a few more candidates, but none of them feels 100%.  One seems unfinished.  One looks like it never really got started.  Another looks earnest, but hasn’t been touched in a year or more.  Probably thrown over the wall from somebody’s contract gig.</p>

<p>Code is code, even thrown over a wall, so you dive in.  You find yourself swimming.  Not your style.  Not your design.  Different tooling.  Unclear where to add what you need.  Copy, paste, notice, and patch, at best.</p>

<p>That frustrated, impatient feeling sets in.  You’re think about working around it, putting off the feature.  You’re thinking about taking time to code it up from scratch yourself.  But the clock says you’re already behind.  You glance up at your tabs and see the licensing page for the ready-to-go option still open.  You take another look.</p>

<p>The rules actually aren’t that complicated.  It’s just that they aren’t good for you.  You’re at work, and this is a work project.  It’s not open source.  It’s for a client.  There’s a free trial, but the client wants something for the long term.</p>

<p>It’s not about a donation, but there’s nobody policing the rules.  It’s all on the honor system.  You figure yourself pretty honorable, but suspect you’ll forget about when a trial ends.  You don’t want it blowing up on you later.  That means the buy button, which you don’t particularly want to click.</p>

<p>But the price is right.   Not nothing, but not a gazillion dollars, either.  And it’s a one-time charge, not some sleazy subscription everyone knows you’ll probably forget to cancel.  So you click through and fill out the form: name, address, e-mail, and credit card.  Fuck it.  You buy.  It’s easy.  You can figure out how to expense it later.</p>

<p>Immediately, you get an e-mail.  There’s a PDF receipt.  Looks like a license, the kind of thing a lawyer would want to see.  You file that away for safekeeping.  While you’re doing that, another e-mail, this time from the developer, comes in.  A canned message.  Thanks for buying a license and supporting my work.  But also an invite to a private web forum, for roadmap talk and peer support.</p>

<p>You set all that aside, and get back to work.  Integration goes pretty well.  The doc is good and the API is clean.  Your tests start passing, but you’re not sure you’ve done it right.  So you drop into the forum and post a quick call for confirmation, as you move onto other things.  By the end of the day, you’ve got a few thumbs-up emoji.  You’re on the right track.  Eventually, the maintainer themself weighs in.  Another thumbs-up.  But also a thanks for support.  They mention the project page.</p>

<p>Sure enough, your name now appears on the page for the project, showing you bought a license.  Along with a mess of other names, including a few you vaguely recognize from the forum.  You see a few company names, too.  Clicking around the site, you see the same for other projects.  You can find more in your language with a couple of links.</p>

<p>Figuring it couldn’t hurt, you go ahead and create an account.  It remembers the project you just bought into, and lists it on your profile page.  But more than that, the site welcomes you to offer your <em>own</em> work on the honor system, too.  Just hook up your Stripe account and go.</p>

<hr>

<p>I will build this platform shortly.  If you’d like to try the approach for your own work, <a href="mailto:kyle@artlessdevices.com?subject=Indie%20Code%20Catalog">send me an e-mail</a>.  I am actively assembling a group of early adopters.</p>

<p>This approach would represent an evolution of License Zero.  But also enough of a departure, and enough of an opportunity, to warrant a new brand.  A few points of comparison:</p>

<ul>
  <li>
    <p>License Zero <a href="https://licensezero.com/commitment#relationships">came with a commitment to leave promotion entirely in developers’ hands</a>.  The new system would go beyond that, to actively assisting in promoting projects.  The commitment was important for License Zero, especially early on.  The new rule is essential for taking the next step and building a critical mass.</p>
  </li>
  <li>
    <p>License Zero struck a fundamentally critical tone.  More “No Future” than “Kumbaya”.  The new system would emphasize the alternative offered over the flaws and abuses of the status quo.</p>
  </li>
  <li>
    <p>License Zero put the tool of software licenses up front.  The new system will continue to leverage licensing to fit into the payments and business system as we know it.  But will emphasize the deal being offered—free for open source—over the means by which it’s implemented.</p>
  </li>
</ul>

<p>A website with a showcase needs something to showcase.  If you’re interested in offering one of the first projects at launch—either new work or a new version of an existing project—I’d be very grateful for the chance to raise you up.  Both as part of the seed of a new platform to bring effective indie business models to software, but also as an active participant in guiding and feeding back on the design, early on.</p>

</article></div>]]>
            </description>
            <link>https://blog.licensezero.com/2020/06/23/Indie-Code-Catalog.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612333</guid>
            <pubDate>Tue, 23 Jun 2020 11:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sysinternals ProcDump for Linux]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23612212">thread link</a>) | @GordonS
<br/>
June 23, 2020 | https://build5nines.com/sysinternals-procdump-for-linux/ | <a href="https://web.archive.org/web/*/https://build5nines.com/sysinternals-procdump-for-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>Sysinternals are very widely used tools from Microsoft in the Windows world, and now the ProcDump utility has been ported over to Linux as an Open Source project from Microsoft. ProcDump is a command-line (CLI) utility for monitoring an application for CPU spikes and generates crash dumps during the spike. An admin or developer can use these crash dumps to determine the cause of the spike. This tool was originally built for Windows, and now it’s available for use on Linux as well!</p>



<p>This is not a community port, but rather an official Open Source project from Microsoft. As such, this is the official Linux version of Sysinternals ProcDump created and maintained by Microsoft. Plus, it’s licensed under the MIT License.</p>



<br><h2>Linux ProcDump Usage</h2>



<pre><code>Usage: procdump [OPTIONS...] TARGET
   OPTIONS
      -h          Prints this help screen
      -C          Trigger core dump generation when CPU exceeds or equals specified value (0 to 100 * nCPU)
      -c          Trigger core dump generation when CPU is less than specified value (0 to 100 * nCPU)
      -M          Trigger core dump generation when memory commit exceeds or equals specified value (MB)
      -m          Trigger core dump generation when when memory commit is less than specified value (MB)
      -T          Trigger when thread count exceeds or equals specified value.
      -F          Trigger when filedescriptor count exceeds or equals specified value.
      -I          Polling frequency in milliseconds (default is 1000)
      -n          Number of core dumps to write before exiting (default is 1)
      -s          Consecutive seconds before dump is written (default is 10)
      -d          Writes diagnostic logs to syslog
   TARGET must be exactly one of these:
      -p          pid of the process
      -w          Name of the process executable</code></pre>



<h2>Linux ProcDump Examples</h2>



<p>Create core dump immediately:</p>



<pre><code>sudo procdump -p 1234</code></pre>



<p>Create 3 core dumps 10 seconds apart:</p>



<pre><code>sudo procdump -n 3 -p 1234</code></pre>



<p>Create 3 core dumps 5 seconds apart:</p>



<pre><code>sudo procdump -n 3 -s 5 -p 1234</code></pre>



<p>Create a core dump each time the process has CPU usage &gt;= 65%, up to 3 times, with at least 10 seconds between each dump:</p>



<pre><code>sudo procdump -C 65 -n 3 -p 1234</code></pre>



<p>Create a core dump when CPU usage is outside the range [10,65]:</p>



<pre><code>sudo procdump -c 10 -C 65 -p 1234</code></pre>



<h2>Download Sysinternals ProcDump for Linux</h2>



<p>The Sysinternals ProcDump for Linux utility is licensed under MIT License, and available over in it’s GitHub repo: <a href="https://github.com/Microsoft/ProcDump-for-Linux" target="_blank" rel="noopener">https://github.com/Microsoft/ProcDump-for-Linux</a></p>



<br><h3>System Requirements</h3>



<ul><li>Minimum Operating System<ul><li>Red Hat Enterprise Linux (RHEL) / CentOS 7</li><li>Fedora 29</li><li>Ubuntu 16.04 LTS</li></ul></li><li>gdb &gt;= 7.6.1</li><li>zlib (buil-time only)</li></ul>







<p>Happy monitoring your process dumps and troubleshooting your apps!</p>

<br><h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is a <strong>Microsoft MVP</strong> and has 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
						
										</div></div>]]>
            </description>
            <link>https://build5nines.com/sysinternals-procdump-for-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612212</guid>
            <pubDate>Tue, 23 Jun 2020 10:47:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Low-Latency Rematch: Performance of modern Java on data-heavy workloads]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23612063">thread link</a>) | @cangencer
<br/>
June 23, 2020 | https://jet-start.sh/blog/2020/06/23/jdk-gc-benchmarks-rematch | <a href="https://web.archive.org/web/*/https://jet-start.sh/blog/2020/06/23/jdk-gc-benchmarks-rematch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>This post is a part of a series:</p>
<ul>
<li><a href="https://jet-start.sh/blog/2020/06/09/jdk-gc-benchmarks-part1">Part 1</a></li>
<li><a href="https://jet-start.sh/blog/2020/06/09/jdk-gc-benchmarks-part2">Part 2</a></li>
<li>Part 3 (you are here)</li>
</ul>
<p>This is a followup on Part 1 of the blog post series we started earlier
this month, analyzing the performance of modern JVMs on workloads that
are relevant to the use case of real-time stream processing.</p>
<p>As a quick recap, in Part 1 we tested the basic functionality of
<a href="https://github.com/hazelcast/hazelcast-jet">Hazelcast Jet</a> (sliding
window aggregation) on two types of workload: lightweight with a focus
on low latency, and heavyweight with a focus on the data pipeline
keeping up with high throughput and large aggregation state. For the
low-latency benchmarks we chose the JDK 14 as the most recent stable
version and three of its garbage collectors: Shenandoah, ZGC, and G1 GC.</p>
<p>Our finding that Shenandoah apparently fared worse than the other GCs
attracted some reactions, most notably from the Shenandoah team who
reproduced our finding, created an
<a href="https://bugs.openjdk.java.net/browse/JDK-8247358">issue</a>, came up with
a fix, and committed it to the jdk/jdk16 repository, all in the span of
a few days. The change pertains to the heuristics that decide how much
work the GC should do in the background in order to exactly match the
applications allocation rate. This component is called the <em>pacer</em>. It
was constantly detecting it's falling behind the application, triggering
a brief "panic mode" in order to catch up. The fix fine-tunes the
pacer's heuristics to make the background GC work more proactive.</p>
<p>Given this quick development, we wanted to test out the effects of the
fix, but also take the opportunity to zoom in on the low-latency
streaming case and make a more detailed analysis.</p>
<p>Here are our main conclusions:</p>
<ol>
<li>ZGC is still the winner and the only GC whose 99.99th percentile
latency stayed below 10 ms across almost all of our tested range</li>
<li>Shenandoah's pacer improvement showed a very strong effect, reducing
the latency by a factor of three, but still staying well above 10 ms
except in the very lowest part of our tested range</li>
<li>G1 kept its 99.99th percentile latency below 13 ms across a wide
range of throughputs</li>
</ol>
<h2>The JDK We Tested</h2>
<p>Since this is all so fresh, we couldn't use an existing JDK release, not
even EA, to see the effects of the fix. JDK version 14.0.2 is slated to
be released on July 14. To nevertheless make progress, we took the
source code from the jdk14u tree, at the changeset number
<a href="http://hg.openjdk.java.net/jdk-updates/jdk14u/rev/e9d41bbaea38">57869:e9d41bbaea38</a>,
and applied the changeset number
<a href="https://hg.openjdk.java.net/jdk/jdk/rev/29b4bb22b5e2">59746:29b4bb22b5e2</a>
from the main jdk tree on top of it. The jdk14u tree is where JDK 14.0.2
will be released from and the changeset 59746:29b4bb22b5e2 applies the
patch resolving the mentioned Shenandoah issue.</p>
<h2>The JVM Options</h2>
<p>There are two HotSpot JVM options whose default values change
automatically when you use the ZGC so we had to decide which choice to
make when testing the other garbage collectors.</p>
<ul>
<li><p><code>-XX:-UseBiasedLocking</code>: biased locking has for a while been under
criticism that it causes higher latency spikes due to bias revocation
that must be done within a GC safepoint. In the upcoming JDK version
15, biased locking will be <a href="https://openjdk.java.net/jeps/374">disabled by default and
deprecated</a>. Any low-latency Java
application should have this disabled and we disabled it in all our
measurements.</p></li>
<li><p><code>-XX:+UseNUMA</code>: Shenandoah and ZGC can query the NUMA layout of the
host machine and optimize their memory layout accordingly. The only
reason why Shenandoah doesn't do it by default is a general precaution
against suddenly changing the behavior for upgrading users, but the
precaution is no longer necessary. It will be <a href="https://openjdk.java.net/jeps/163">enabled by
default</a> in upcoming JDK versions,
and we saw no harm in enabling it in all cases as well. <strong>Late
update</strong>: G1 can also optimize for the NUMA layout, but we didn't use
<code>UseNUMA</code> for it. However, we also checked the c5.4xlarge instance
with <code>numactl</code> and it indicated that the entire machine was a single
NUMA node anyway.</p></li>
</ul>
<p>There is also a JVM feature that is simply incompatible with ZGC's
colored pointers: compressed object pointers. In other words, ZGC
applies <code>-XX:-UseCompressedOops</code> without the option to enable it.
A compressed pointer is just 32 bits long but handles heaps of up to
32 GB and it's usually beneficial to both memory usage and performance.
We left this option enabled for Shenandoah.</p>
<p>For the G1 collector, we also set <code>-XX:MaxGCPauseMillis=5</code>, same as in
the previous testing round, because the default of 200 milliseconds is
optimized for throughput and the G1 can give you much better latency
than that.</p>
<p>We performed all our tests on an EC2 c5.4xlarge instance. It has 16
vCPUs and 32 GB of RAM.</p>
<h2>The Data Pipeline</h2>
<p>To get a more nuanced insight into the performance, we made some
improvements to the testing code. Whereas in the first iteration we just
reported the maximum latency, this time around we wanted to capture the
entire latency profile. To this end we had to increase the number of
reports per second the pipeline outputs. Initially we set it to 10 times
per second, a number which results in too few data points for the
latency chart. The pipeline in this round emits 100 reports per second.
The event rate and the length of the time window are the same: 1 million
events per second and 10 seconds, respectively. This results in 1,000
hashtables each holding 10,000 keys as the aggregation state. We tested
across a wide range of keyset sizes, starting from 5,000 up to 105,000.</p>
<p>Note that the size of the keyset, somewhat counterintuitively, does not
affect the size of the aggregation state. As long as the 10,000 input
events received during one time slice of 10 milliseconds all use
distinct keys, the state is fixed as described above. Only in the lowest
setting, 5,000, the state is half as large since every hashtable
contains just 5,000 keys.</p>
<p>What the keyset size does affect is allocation rate. The pipeline emits
the full keyset every 10 milliseconds. For example, with 50,000 keys
that's 5,000,000 result items per second. If we add to that the rate of
the input stream (a fixed million events per second), we get a value
that is a good proxy for the overall allocation rate. This is why we
chose combined input+output rate as the x-axis value in the charts that
we'll be showing below.</p>
<p>Here is the basic code of the pipeline, available on
<a href="https://github.com/mtopolnik/jet-gc-benchmark/blob/round-2/src/main/java/org/example/StreamingRound2.java">GitHub</a>:</p>
<pre><code><span>StreamStage</span><span><span>&lt;</span><span>Long</span><span>&gt;</span></span> source <span>=</span> p<span>.</span><span>readFrom</span><span>(</span><span>longSource</span><span>(</span>EVENTS_PER_SECOND<span>)</span><span>)</span>
                            <span>.</span><span>withNativeTimestamps</span><span>(</span><span>0</span><span>)</span>
                            <span>.</span><span>rebalance</span><span>(</span><span>)</span><span>;</span>
<span>StreamStage</span><span><span>&lt;</span><span>Tuple2</span><span>&lt;</span><span>Long</span><span>,</span> <span>Long</span><span>&gt;</span><span>&gt;</span></span> latencies <span>=</span> source
        <span>.</span><span>groupingKey</span><span>(</span>n <span>-&gt;</span> n <span>%</span> NUM_KEYS<span>)</span>
        <span>.</span><span>window</span><span>(</span><span>sliding</span><span>(</span>WIN_SIZE_MILLIS<span>,</span> SLIDING_STEP_MILLIS<span>)</span><span>)</span>
        <span>.</span><span>aggregate</span><span>(</span><span>counting</span><span>(</span><span>)</span><span>)</span>
        <span>.</span><span>filter</span><span>(</span>kwr <span>-&gt;</span> kwr<span>.</span><span>getKey</span><span>(</span><span>)</span> <span>%</span> DIAGNOSTIC_KEYSET_DOWNSAMPLING_FACTOR <span>==</span> <span>0</span><span>)</span>
        <span>.</span><span>mapStateful</span><span>(</span><span>DetermineLatency</span><span>::</span><span>new</span><span>,</span> <span>DetermineLatency</span><span>::</span><span>map</span><span>)</span><span>;</span>

latencies<span>.</span><span>filter</span><span>(</span>t2 <span>-&gt;</span> t2<span>.</span><span>f0</span><span>(</span><span>)</span> <span>&lt;</span> TOTAL_TIME_MILLIS<span>)</span>
         <span>.</span><span>map</span><span>(</span>t2 <span>-&gt;</span> <span>String</span><span>.</span><span>format</span><span>(</span><span>"%d,%d"</span><span>,</span> t2<span>.</span><span>f0</span><span>(</span><span>)</span><span>,</span> t2<span>.</span><span>f1</span><span>(</span><span>)</span><span>)</span><span>)</span>
         <span>.</span><span>writeTo</span><span>(</span><span>Sinks</span><span>.</span><span>files</span><span>(</span><span>"/home/ec2-user/laten"</span><span>)</span><span>)</span><span>;</span>
latencies
      <span>.</span><span>mapStateful</span><span>(</span><span>RecordLatencyHistogram</span><span>::</span><span>new</span><span>,</span> <span>RecordLatencyHistogram</span><span>::</span><span>map</span><span>)</span>
      <span>.</span><span>writeTo</span><span>(</span><span>Sinks</span><span>.</span><span>files</span><span>(</span><span>"/home/ec2-user/bench"</span><span>)</span><span>)</span><span>;</span>
</code></pre>
<p>The main part, sliding window aggregation, remains the same, but the
following stages that process the results are new. We write the data to
two files: <code>laten</code>, containing all the raw latency data points, and
<code>bench</code>, containing an <a href="https://hdrhistogram.github.io/HdrHistogram/plotFiles.html">HDR
Histogram</a>
of the latencies.</p>
<p>Another key difference is that, in the original post, we measured the
latency of <em>completing</em> to emit a result set, but here we measure the
latency of <em>starting</em> to emit it. Since we are changing the size of the
output, if we kept measuring the completion latency, we'd be introducing
a different amount of application-induced latency at each data point.</p>
<p>There's another, relatively minor technical point worth mentioning:
since we tested on a cloud server instance, we used Jet's client-server
mode, which means we separately start a Jet node and then deploy the
pipeline to it using Jet's command <code>jet submit</code>. The code available on
GitHub is the client code and the Jet server code was a build from a
recent state of the Jet master branch. It uses a pipeline feature that
will be released with Jet 4.2, which is the reason we couldn't use a
released Jet version. We expect all the results to be reproducible with
Jet 4.2 once released.</p>
<h2>What Exactly We Measured</h2>
<p>We measured the latency as the timestamp at which the pipeline emits a
given result minus the timestamp to which the result pertains, giving us
end-to-end latency (the only kind the user actually cares about).</p>
<p>Keep especially in mind that latency does not equal a GC pause.
Normally, neither Shenandoah nor ZGC enter anything more than a
millisecond of GC pause, but their background work shares the limited
system capacity with the application. With G1 the equivalence is much
stronger and its 10-20 millisecond latencies are primarily the result of
GC pauses that long.</p>
<h2>The Measurements</h2>
<p>To come up with the charts below, for each data point we let the
pipeline warm up for 20 seconds and then gathered the latencies for 4
minutes, collecting 24,000 samples.</p>
<p>Here is the latency histogram taken at 2 million items per second,
close to the bottom of our range:</p>
<p><img src="https://jet-start.sh/blog/assets/2020-06-23-histo-2m.png" alt="Latency on JDK 14.0.2 pre-release, 2M items per second"></p>
<p>Unpatched Shenandoah seems like the winner, except for the single
worst-case latency. With the patch applied, latency increases sooner but
more gently and doesn't have a strong peak. ZGC comes somewhere between,
but overall all three cases show pretty similar behavior. G1 is clearly
worse and its latency exceeds the 10 ms mark before even reaching the
99th percentile. Since our pipeline emits a new result set ever 10 ms,
we shall consider 10 ms as the cutoff point: everything above 10 ms
should be considered a failure for our use case.</p>
<p>Next, let's take a look at the latencies after increasing the throughput
a bit, to 3 million items per second:</p>
<p><img src="https://jet-start.sh/blog/assets/2020-06-23-histo-3m.png" alt="Latency on JDK 14.0.2 pre-release, 3M items per second"></p>
<p>Wow, what an unexpected difference! Now we can clearly see the pacer
improvement doing its thing, lowering the latency about threefold.
However, even with the improvement, Shenandoah unfortunately crosses the
10 ms mark pretty early, below the 99th percentile, and is worse than G1
at almost every percentile. ZGC …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jet-start.sh/blog/2020/06/23/jdk-gc-benchmarks-rematch">https://jet-start.sh/blog/2020/06/23/jdk-gc-benchmarks-rematch</a></em></p>]]>
            </description>
            <link>https://jet-start.sh/blog/2020/06/23/jdk-gc-benchmarks-rematch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612063</guid>
            <pubDate>Tue, 23 Jun 2020 10:29:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React in a Business Perspective]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23611954">thread link</a>) | @piotrzientara
<br/>
June 23, 2020 | https://pagepro.co/blog/react-in-a-business-perspective/ | <a href="https://web.archive.org/web/*/https://pagepro.co/blog/react-in-a-business-perspective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<h2>Introduction</h2>
		<p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://pagepro.co/blog/wp-content/uploads/2020/06/ilustration-1.png" alt="Ilustration">
		</p>
		<h3>Why did we create this report?</h3>
		<p>Finding a general knowledge about <strong>React JS</strong> &amp; <strong>React Native</strong> is relatively easy.</p>
		<h4>You can use:</h4>
		<ul>
			<li>Clear and precise <a href="https://reactjs.org/" rel="nofollow noopener noreferrer" target="_blank">React documentation</a></li>
			<li>Tons of blog articles and videos</li>
			<li>Open source projects</li>
			<li>Online courses</li>
			<li>etc.</li>
		</ul>
		<p>The bigger problem is to find an exact top-level business knowledge about it. In other words, a knowledge
			about: </p>

		<h3>How using React is actually impacting my business?</h3>

		<p>React as any other piece of software is here to <strong>efficiently build web &amp; mobile products</strong>,
			but how is it actually impacting the modern world of development? </p>
		<p>We know the number of downloads, number of repositories or number of open source projects, but what if these
			numbers are just vanity metrics and a true valuable business knowledge is somewhere hidden?</p>
		<p>This report was made to help C-level executives decide <strong>if they should use React in their
				organizations or not</strong>.</p>

		<p>It will also help organizations understand if using React is a good idea in a longer term and if they should
			keep this technology in their stack for the future. </p>

		<h3>Who should read it?</h3>

		<p><strong>We made it for:</strong></p>

		<ul>
			<li>Top-level tech leaders </li>
			<li>Founders</li>
			<li>Top-level Executives</li>
			<li>Team Leaders</li>
			<li>Senior Developers</li>
		</ul>

		<p>That cares about efficiency in building web and mobile apps.</p>
		<p>The truth is, each and every day technology is changing, and what seems to be a great idea one day, becomes
			outdated the other.</p>
		<p>Developers became more demanding, and it is only becoming harder to find the one that will find a common
			language in the team.</p>
		<p>This is why we spoke to people like <strong>CTOs with a need of clear understanding</strong> on how modern
			technology is able to fix common issues, make their work easier, and stay safe in the perspective of
			constant growth and rapid changes.</p>
		<p>There are many <strong>C-level executives that are still hesitating</strong> if React is able to keep its
			promises, as to make appealing calculations of pros and cons appears to be extremely hard in such a
			technology rush.</p>
		<p>There are also many <strong>top-level executives that may want to switch to React</strong> already, but still
			cannot find a good and convincing business reason to make the move.</p>
		<p>There are hundreds of <strong>founders that would like to implement modern technology</strong>, and are still
			searching for the perfect one.</p>
		<p>Also, <strong>companies working with React already</strong> will find great pieces of advice and insights
			from other top-level executives.</p>
		<p>At the end, there are people that want, but are not sure how, or where to start <strong>without carrying a
				huge cost of baggage</strong>.</p>
		<p>This report is for all of you.</p>
	</div>
</div><div>
	<div>
		<h2>Market Context</h2>



		<p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://pagepro.co/blog/wp-content/uploads/2020/06/ilustration-2.png" alt="Ilustration">
		</p>



		<p>In 2020 most tech teams starting a new project are choosing one of three most popular solutions (React,
			Angular and Vue) for building their products. </p>
		<p>Let’s start with checking if React is worth our interest by investigating some key market metrics.</p>




		






		<div data-trigger-hook="0.8">
			<div>
				<div>
					<h4>
						React VS Competition:
					</h4>
					<div>

						

						<div>
							<div>

								<figure>
									<img alt="Trophy ilustration" src="https://pagepro.co/blog/wp-content/uploads/2020/06/static_img_cup.svg">
								</figure>

								<p><span><strong>React</strong> (33%)</span>
							</p></div>
						</div>

						

					</div>
				</div>
			</div>
		</div>






		<div>
			<div>

				<div>
					<div>

						<h3>
							Which JavaScript frameworks are regularly used?
						</h3>


						<p>
							At the beginning of 2019, JetBrains polled almost 7,000 developers to identify the State of
							Developer Ecosystem. Let’s check how React was seen by the developers.
						</p>

					</div>
				</div>


				


				

			</div>
		</div>






		<div data-trigger-hook="0.8">
			<div>
				<div>
					<h4>
						React VS Competition:
					</h4>
					<div>

						

						<div>
							<div>

								<figure>
									<img alt="Trophy ilustration" src="https://pagepro.co/blog/wp-content/uploads/2020/06/static_img_cup.svg">
								</figure>

								<p><span><strong>React (74% with React Native)</strong>
									(54%)</span>
							</p></div>
						</div>

						

					</div>
				</div>
			</div>
		</div>






		<h4>The need of React Developers</h4>
		<p>Let’s take a look at the industry demand for specific developers by scanning Indeed job portal in different
			main development centers in Europe.</p>


		<p><strong>London, UK</strong></p>
		<ul>
			<li>React: <strong>1,643 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://www.indeed.co.uk/React-javascript-jobs-in-London">https://www.indeed.co.uk/React-javascript-jobs-in-London</a>
			</li>
			<li>Vue: <strong>286 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://www.indeed.co.uk/Vue-javascript-jobs-in-London">https://www.indeed.co.uk/Vue-javascript-jobs-in-London</a>
			</li>
			<li>Angular: <strong>832 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://www.indeed.co.uk/Angular-javascript-jobs-in-London">https://www.indeed.co.uk/Angular-javascript-jobs-in-London</a>
			</li>
		</ul>

		<p><strong>Paris, France</strong></p>
		<ul>
			<li>React: <strong>759 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://www.indeed.fr/Paris-Emplois-react-javascript">https://www.indeed.fr/Paris-Emplois-react-javascript</a>
			</li>
			<li>Vue: <strong>336 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://www.indeed.fr/Paris-Emplois-vue-javascript">https://www.indeed.fr/Paris-Emplois-vue-javascript</a>
			</li>
			<li>Angular: <strong>785 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://www.indeed.fr/Paris-Emplois-angular-javascript">https://www.indeed.fr/Paris-Emplois-angular-javascript</a>
			</li>
		</ul>

		<p><strong>Berlin, Germany</strong></p>
		<ul>
			<li>React: <strong>634 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://de.indeed.com/react-javascript-Jobs-in-Berlin">https://de.indeed.com/react-javascript-Jobs-in-Berlin</a>
			</li>
			<li>Vue: <strong>212 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://de.indeed.com/vue-javascript-Jobs-in-Berlin">https://de.indeed.com/vue-javascript-Jobs-in-Berlin</a>
			</li>
			<li>Angular: <strong>356 jobs</strong> <a target="_blank" rel="nofollow noopener noreferrer" href="https://de.indeed.com/angular-javascript-Jobs-in-Berlin">https://de.indeed.com/angular-javascript-Jobs-in-Berlin</a>
			</li>
		</ul>



		<div data-trigger-hook="0.8">
			<div>
				<div>
					<h4>
						React VS Competition:
					</h4>
					<div>

						

						<div>
							<div>

								<figure>
									<img alt="Trophy ilustration" src="https://pagepro.co/blog/wp-content/uploads/2020/06/static_img_cup.svg">
								</figure>

								<p><span><strong>React</strong> (3036)</span>
							</p></div>
						</div>

						

					</div>
				</div>
			</div>
		</div>






		<div>
			<div>

				<div>
					<div>

						<h3>
							Developers’ satisfaction of using React
						</h3>


						<p>
							In the last year, Stack Overflow survey developers responded that React is the most loved
							web framework used in 2019.
						</p>

					</div>
				</div>


				


				

			</div>
		</div>




		<div data-trigger-hook="0.8">
			<div>
				<div>
					<h4>
						React VS Competition:
					</h4>
					<div>

						

						<div>
							<div>

								<figure>
									<img alt="Trophy ilustration" src="https://pagepro.co/blog/wp-content/uploads/2020/06/static_img_cup.svg">
								</figure>

								<p><span><strong>React</strong> (75,5%)</span>
							</p></div>
						</div>

						

					</div>
				</div>
			</div>
		</div>





		<h4>New coming React developers on the market</h4>
		<p>React is the framework most developers want to learn 32% of Hackerrank HackerRank Developer Skills Survey
			says it’s the framework they’re learning next.</p>
		<p>That means we can expect more React developers on the market to fulfill the demand gap.</p>



		<div>
			<div>

				<div>
					<p>

						<h3>
							Which frameworks do you plan on learning next?
						</h3>


					</p>
				</div>


				


				

			</div>
		</div>




		<div data-trigger-hook="0.8">
			<div>
				<div>
					<h4>
						React VS Competition:
					</h4>
					<div>

						

						<div>
							<div>

								<figure>
									<img alt="Trophy ilustration" src="https://pagepro.co/blog/wp-content/uploads/2020/06/static_img_cup.svg">
								</figure>

								<p><span><strong>React</strong> (32,3%)</span>
							</p></div>
						</div>

						

					</div>
				</div>
			</div>
		</div>


	</div>


	<div>
		<div>
			<div>
				<h3>
					Market Context Key Takeaways
				</h3>

				<ul>

					<li>
						React is the most popular web &amp; mobile development tool on the market.
					</li>

					<li>
						Developers like to work with React, companies are demanding React developers.
					</li>

					<li>
						Vue is getting traction, but mostly for developer’s non commercial projects. Companies are not
						still convinced and not actively hiring people knowing Vue.
					</li>

					<li>
						Angular has almost as great adoption rate as React, companies prefer to hire Angular developers
						than Vue, unfortunately, Angular developers are the less satisfied developers of their
						technology.
					</li>

				</ul>
			</div>
		</div>
	</div>


</div><div>
	<div>

		<h2>About the Research</h2>



		<p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://pagepro.co/blog/wp-content/uploads/2020/06/ilustration-4.png" alt="Ilustration">
		</p>



		<p>The research was made to help you uncover the advantages of using React from a business perspective.</p>
		<p>We asked about 500 CTOs from:</p>
		<ul>
			<li>UK</li>
			<li>France</li>
			<li>Germany</li>
			<li>Australia</li>
			<li>Netherlands</li>
		</ul>
		<p>to share their experiences with React and React Native.</p>
		<p>Our survey contained closed and open-ended questions that were strictly related with business topics around
			software development.</p>
		<p>After receiving the results we have also asked industry experts to share their thoughts and comments.</p>
	</div>
	<div>
		<p>
			<h3>Now, here we are! Super excited to share it all with you!</h3>
		</p>
	</div>
</div><div>
	<div>
		<h2>Survey Results</h2>
		<p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://pagepro.co/blog/wp-content/uploads/2020/06/ilustration-3.png" alt="Ilustration">
		</p>



		<p>Let’s take a look at how our respondents answered key business-oriented questions. Under the answers, we also
			have some comments from industry experts.</p>



		<div>
			<div>
				<div>
					<p>
						Q1
					</p>
					<h3>
						Is React moving in the right direction?
					</h3>
				</div>
			</div>
		</div>
		



		<h4>Why do you think React is moving in the right direction?</h4>



		<div>
			<div>
				<div>
					<blockquote>

						<p>I agree that React is moving in the right direction. It has already helped transform many
							businesses, and has been adopted as the front-end technology of choice by many large tech
							companies such as Netflix.</p>
						<p>React components are easier to extend and maintain. These components help empower front-end
							development teams to increase productivity and save businesses time and money. In addition,
							React’s reusable nature suits multivariate testing, and helps teams deliver better user
							experiences which have a positive knock-on effect to goal conversion rates.</p>

					</blockquote>
					
				</div>
			</div>
		</div>





		<div>
			<div>
				<div>
					<blockquote>

						<p>React has been so modern and seems to have a good finger on the pulse of where modern web
							development is going.</p>
						<p>Using and developing their context API to take away some of the complexity that newer
							developers may experience while using something like Redux, and they keep updating.</p>
						<p>That’s why I think React is moving in the right direction. It seems to be taking the
							strengths and weaknesses of all types of programs, whether they are new or old, and coming
							up with solutions fairly often updating the library to match that.</p>
						<p>In terms of React and Gatsby, I think that it’s getting easier to create static sites versus
							things like WordPress. I’m seeing a lot of things like React Library and a really
							good-looking React templates come online so people are able to get a really nice website
							faster instead of having it totally coded from the beginning.</p>

					</blockquote>
					
				</div>
			</div>
		</div>





		<div>
			<div>
				<div>
					<p>
						Q2
					</p>
					<h3>
						For what types of projects are you mainly using React?
					</h3>
				</div>
			</div>
		</div>




		



		<h4>In what kind of projects do you think React is the best tool to use and why?</h4>



		<div>
			<div>
				<div>
					<blockquote>

						<p>I personally believe that React fits for most of the general use cases. Our respondents are
							usually using React in business (B2C and B2B projects), but this is just the preference of
							our respondents, not the whole market. Our developers are applying it in their daily routine
							and I can see people using it more and more in their everyday life, as React can be easily
							used to speed up and improve many areas that we cope with.</p>
						<p>In general, the more we use web and mobile, the more we can use React to improve what we do.
						</p>

					</blockquote>
					
				</div>
			</div>
		</div>




		<div>
			<div>
				<div>
					<blockquote>

						<p>I would personally use react for all these cases, however the only thing i can think of for
							not using it in b2b is because react leaves more decisions up to you and is less opinionated
							…</p></blockquote></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pagepro.co/blog/react-in-a-business-perspective/">https://pagepro.co/blog/react-in-a-business-perspective/</a></em></p>]]>
            </description>
            <link>https://pagepro.co/blog/react-in-a-business-perspective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611954</guid>
            <pubDate>Tue, 23 Jun 2020 10:15:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’ve decided to rename Riot]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 222 (<a href="https://news.ycombinator.com/item?id=23611863">thread link</a>) | @anotherevan
<br/>
June 23, 2020 | https://blog.riot.im/the-world-is-changing/ | <a href="https://web.archive.org/web/*/https://blog.riot.im/the-world-is-changing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Hi all,</p><p>It's almost four years since we launched Riot, and it's been a crazy journey - going from a relatively bare bones Matrix app through to today's all-singing, all-dancing encrypted-by-default collaboration tool used by folks ranging from Mozilla to the French Government and beyond.</p><p>However, as some may know, we’ve had a few problems with the name Riot over the years. &nbsp;Firstly, the biggest by far has been from a certain large games company that has consistently blocked us from being able to trademark Riot or even Riot.im - which has been a huge issue when it comes to defending users against abusive forks of the app. We’re in a terrible position if someone forks Riot using the same or similar name and logo, makes some dubious changes, and we can’t take action to persuade the app stores to remove it.</p><p>Secondly, we picked the name “Riot” to evoke something disruptive and vibrant - like a “riot of colour.” &nbsp;There’s a reason the loading animation on the mobile apps has been of the logo running riot through completely different versions of the logo. &nbsp;However, many people hear the word Riot and assume that the app is focused on violence - which it is not.</p><p>Finally, we’ve found that users can get very confused by the different brands that surround Riot. We can’t get away from the fact that Riot builds on Matrix rather than being yet another siloed communication app (and it's very deliberate that Riot is not named after Matrix). However, how come Riot is made by a company called New Vector? Why should I get a server for Riot from Modular, and what do they have to do with Riot or New Vector? What’s RiotX? After all, when I use Slack, it’s made by a company called Slack, who provide hosting called… Slack. Likewise Discord. Likewise Rocket.chat and many others. Back in 2016 it may have made sense to create three different brands (Riot, Modular, New Vector) to spell out the modularity of the ecosystem - but nowadays there are lots of other Matrix clients, vendors and hosting providers that demonstrate perfectly the diversity of the Matrix ecosystem.</p><p><strong>Therefore, we’ve decided to rename Riot (and New Vector, and Modular).</strong></p><p>The new name will be announced in a few weeks once we’re ready, but we wanted to give everyone a heads up so it doesn’t come as a shock. </p><p>This is obviously a bold move: we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. Renaming is inevitably going to cause some confusion. We know that many of you reading this will have put their neck on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users.</p><p>However, we are extremely confident that now is the right time to fix the name. We’re in the process of landing gigantic improvements to Riot’s user experience and usability which will unrecognisably improve the app. &nbsp;So unrecognisably, in fact, that we can shed our skin and celebrate our long-awaited transition into being a truly mainstream-usable app. &nbsp;And most importantly, we’ve finally found a name which we’re really excited about (much more than we ever were about Riot!), and we hope you’ll like it too!</p><p>So… watch this space. We’re going to have our heads down for the next few weeks while we pull together all the waves of improvements we have in flight, and then all shall be revealed.</p><p>Thanks for using and supporting Riot. &nbsp;We’ll see you on the other side!</p><p>Matthew, Amandine &amp; all of New Vector (and Riot, and Modular)</p><p>P.S. discussion over at <a href="https://news.ycombinator.com/item?id=23611863">HN</a><br></p>
			</section></div>]]>
            </description>
            <link>https://blog.riot.im/the-world-is-changing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611863</guid>
            <pubDate>Tue, 23 Jun 2020 10:01:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[User-space vs. Linux kernel TCP for HTTPS proxying]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23611846">thread link</a>) | @krizhanovsky
<br/>
June 23, 2020 | http://tempesta-tech.com/blog/user-space-tcp | <a href="https://web.archive.org/web/*/http://tempesta-tech.com/blog/user-space-tcp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><i>Posted on June 15, 2020</i></p><p>We develop a fast and scalable HTTPS proxy server <a href="https://github.com/tempesta-tech/tempesta">Tempesta FW</a>. Tempesta FW works in the Linux kernel, as part of the TCP/IP stack, to achieve the highest performance and lowest response latency. The development started in 2014, when kernel bypass technologies for fast networking, such as <a href="https://www.dpdk.org/">DPDK</a> and <a href="http://info.iet.unipi.it/~luigi/netmap/">Netmap</a>, were gaining their popularity. We still believe that the decision was right for the reverse proxy and it's quite unlikely that we make a technological pivot to a kernel bypass. Let's see what specific about reverse proxies and why do they benefit from being in-kernel. </p><p>Recently there was a conversation whether it makes sense to port Tempesta FW to <a href="https://github.com/F-Stack/f-stack">F-Stack</a>, a port of FreeBSD networking stack to DPDK, or a similar technology, e.g. <a href="https://github.com/mtcp-stack/mtcp">mTCP</a>. So we spent quite a time for an investigation of F-Stack project and this article will reference the project as an example of a user-space network stack. </p><h2>The simple packet case</h2><p> CloudFlare <a href="https://blog.cloudflare.com/kernel-bypass/">made a good example</a> for kernel bypass applicability in 2015. The article discusses the high speed firewall rules filtering out UDP packets on a particular port. That was much earlier before <a href="https://en.wikipedia.org/wiki/Express_Data_Path">XDP</a>, so the guys compared <code>iptables</code> performance versus DPDK and other kernel bypass approaches. Later, in 2017, they showed quite the similar scenario, but using XDP. XDP (the Linux eXpress Data Path) works in a network adapter's driver hook, just after the interrupt processing, even before a packet descriptor <code>sk_buff</code> is allocated. The XDP programs are quite limited in their structure and size, but simple tasks like packet filtering or forwarding <a href="http://vger.kernel.org/lpc_net2018_talks/presentation-lpc2018-xdp-future.pdf">can be done in a very efficient way</a>. </p><p>In fact, simple traffic processing, like filtration by the TCP/UDP prots or IP source/destination addresses, can be easily and efficiently done with either DPDK or XDP. </p><h2>TCP implementations maturity</h2><p> Ok, we're good with packet headers processing and doing simple logic with the packet. But what if we need the real TCP, for example, to proxy HTTPS traffic? We can parse TCP segment header, but we also need to handle TCP streams, including out of order segments, doubled segments, overlapped segments and many other corner cases. Moreover, if we need a proxy, then we need to keep TCP control block for both the connection peers (typically, for a client and server connections) to perform flow and congestion control. The robust TCP/IP stack is quite a huge task, for example let's see at the Linux TCP/IP stack: </p><pre><code>
        [linux-linus]$ find net/ipv4 net/ipv6 -name \*.[ch] |xargs wc -l|tail -1
        172221 total
    </code></pre><p> More than 170,000 lines of C code and that's not the whole code. You might reply that the Linux TCP/IP stack is a known hog and this is why the people are moving to user-space TCP/IP stacks. Having the code small is good, but with the TCP implementations we usually go to not only tiny, but also immature, code. </p><p>We can use a simple test to check a TCP/IP stack for maturity -just check it for <a href="https://en.wikipedia.org/wiki/TCP_delayed_acknowledgment">TCP delayed acknowledgment</a> - quite a reasonable TCP feature to improve network performance. For example, for F-stack: </p><pre><code>
        [f-stack]$ grep -ri 'delayed.ack' *|wc -l
        74
    </code></pre><p> The Linux kernel: </p><pre><code>
        [linux-linus]$ grep -ri 'delayed.ack' ./net/ipv4/|wc -l
        51
    </code></pre> <p><a href="https://en.wikipedia.org/wiki/LwIP">lwIP</a>: </p><pre><code>
        [lwip]$ grep -ri 'delayed.ack' *|wc -l
        13
    </code></pre> <p><a href="https://github.com/mtcp-stack/mtcp">mTCP</a>: </p><pre><code>
        [mtcp]$ grep -ri 'delayed.ack' *|wc -l
        0
    </code></pre> <p><a href="https://github.com/scylladb/seastar">Seastar</a>: </p><pre><code>
        [seastar]$ grep -ri 'delayed.ack' *|wc -l
        0
        $ find . -name \*tcp\* |xargs wc -l 
         169 ./src/net/tcp.cc
          50 ./include/seastar/net/tcp-stack.hh
        2135 ./include/seastar/net/tcp.hh
          75 ./demos/tcp_demo.cc
         205 ./demos/tcp_sctp_server_demo.cc
         279 ./demos/tcp_sctp_client_demo.cc
        2913 total
    </code></pre><p> OK... F-Stack uses the FreeBSD TCP/IP stack. LwIP is an old and well-developed TCP/IP stack. But Seastar is the new one and the whole TCP code, including demos, is less than 3,000 lines of code. Let's see for TODO and FIXME comments in the source code of <code>tcp.hh</code>: </p><pre><code>
        void do_time_wait() {
            // FIXME: Implement TIME_WAIT state timer
        ...
        // 3.4 fourth check the SYN bit
        if (th-&gt;f_syn) {
            ...
            if (th-&gt;f_ack) {
                // // TODO: clean retransmission queue
        ...
        // FIN_WAIT_2 STATE
        if (in_state(FIN_WAIT_2)) {
            // In addition to the processing for the ESTABLISHED state, if
            // the retransmission queue is empty, the user’s CLOSE can be
            // acknowledged ("ok") but do not delete the TCB.
            // TODO
        ...
        // TIME_WAIT STATE
        if (in_state(TIME_WAIT)) {
            // The only thing that can arrive in this state is a
            // retransmission of the remote FIN. Acknowledge it, and restart
            // the 2 MSL timeout.
            // TODO
        ...
        // 4.6 sixth, check the URG bit
        if (th-&gt;f_urg) {
            // TODO
        }
    </code></pre><p> It seems a lot of TCP functionality isn't implemented yet. </p><p>That's the reason why F-Stack also <a href="https://github.com/F-Stack/f-stack/blob/dev/doc/F-Stack_Development_Guide.md#revise-of-freebsd-network-stack-and-dpdk-based">started from their own TCP/IP stack</a>, but moved to FreeBSD's one: <i>"At the beginning of this work, F-Stack used a simple TCP/IP stack that developed by ourselves. However, with the growth of various services, this stack couldn't meet the needs of these services while continue to develop and maintain a complete network stack will cost high. So the FreeBSD network stack was ported into F-Stack. The FreeBSD network stack provides complete features and can follow up the improvement from the community." </i></p><h2>Scaling and performance</h2><p> While a normal operating system network stack being ported to user space might show very scalable <a href="https://github.com/F-Stack/f-stack#nginx-testing-result">benchmarks</a> (unfortunately F-stack team didn't <a href="https://github.com/F-Stack/f-stack/issues/519">precise</a> details of the benchmark), it can <a href="https://github.com/F-Stack/f-stack/issues/507">deliver</a> even worse performance than a kernel TCP/IP stack on small number of connections. </p><p>Normal Socket API implies data copying between user and kernel spaces. Being porter from the kernel to the user space as is, a network stack still <a href="https://github.com/F-Stack/f-stack/issues/467">struggles</a> from memory copies. As discussed in the referenced thread on the F-Stack bug tracker, the kernel bypass project is mostly about <i>scaling on CPU cores</i> rather than <i>pure performance</i>. </p><p>During <a href="https://github.com/tempesta-tech/tempesta/wiki/HTTP-transactions-performance">our performance test</a> of the kernel TCP/IP stack scalability in a virtual environment, we faced the <a href="https://github.com/tempesta-tech/tempesta/issues/1419">known issue</a> with the Linux connection hash table. The issue was also <a href="https://blog.cloudflare.com/revenge-listening-sockets/">reported and well described by CloudFlare</a>. The core of the problem is an old-fashioned hash table with collision chains on linked lists. The hash table is protected by a spin lock. Once you have too many TCP connections (in <code>TIME-WAIT</code> state in this case), all the CPUs stuck on locking the hash table. Even 4 CPUs spend more than 70% of time on the lock's contention: </p><pre><code>
        36.28%  [kernel]            [k] __inet_check_established
        20.68%  [kernel]            [k] _raw_spin_lock_bh
        14.76%  [kernel]            [k] _raw_spin_lock
        11.17%  [kernel]            [k] native_queued_spin_lock_slowpath
         9.23%  [kernel]            [k] __inet_hash_connect
         3.14%  [kernel]            [k] inet_ehashfn
    </code></pre><p> There are modern research in highly concurrent hash tables (see for example <a href="https://jira.mariadb.org/browse/MDEV-20630#comment-154175">our recent study</a> on the similar problem with 64 cores high contention on a hash table in MariaDB). We were wondering whether F-stack did something different to get a more concurrent code of the connections hash table. The hash table is <code>struct inpcbinfo</code> declared in <code>freebsd/netinet/in_pcb.h</code> and scanned, for example, by <code>in_pcblookup_mbuf()</code> call from <code>tcp_input()</code> function. We see quite the similar read lock as for Linux in the hash lookup function: </p><pre><code>
        static struct inpcb *
        in_pcblookup_hash(...)
        {
            struct inpcb *inp;

            INP_HASH_RLOCK(pcbinfo);
            inp = in_pcblookup_hash_locked(...);
            ...
    </code></pre><p>The Socket API and, most importantly, the internal synchronization mechanisms, must be reworked in a TCP/IP stack to deliver significantly better scalability and performance in a multi-core environment. Just using kernel bypass technology, like DPDK or Netmap, doesn't fix the concurrency issues in an existing TCP/IP stack. </p><p>The example with the TCP connections hash table is interesting, because it's quite hard to avoid a single data structure, shared and updated by many CPUs: you need to track all available and acquired TCP ports on the system. This is simple example and you might guess that there is a routing table, various caches and many other data structures, which must be accessed by many CPUs. </p><h2>The HTTP layer bottleneck</h2><p> Some time ago we made comparison of in-kernel <a href="https://github.com/tempesta-tech/tempesta">Tempesta FW</a> with DPDK-based HTTP server <a href="https://github.com/scylladb/seastar">Seastar</a> (see our <a href="https://netdevconf.info/2.1/session.html?krizhanovsky">Netdev talk</a>). Basically, Tempesta FW provides the similar speed and there are 2 reasons for this: </p><ul><li>both the servers work on the network application layer with a heavy-weight and complex HTTP processing logic, so the bottleneck isn't in the network, TCP/IP, layer <b>if</b> the key socket API overheads are removed; </li><li>Tempesta FW doesn't use the high-level socket API, based on file descriptors, so many locks and queues were removed (the usual reason why Nginx and other fast user space servers stop scaling on multi-core systems). </li></ul><p>The same problem might be observed for <a href="https://github.com/F-Stack/f-stack/issues/463">Redis on top of F-Stack</a>: fast network layer doesn't impact to much to the final application performance. </p><p>While CloudFlare heavily adopts XDP and kernel bypass technologies, they still <a href="https://blog.cloudflare.com/why-we-use-the-linux-kernels-tcp-stack/">use the Linux TCP/IP stack</a> for HTTP layer processing: the real bottleneck is in the application logic and there is no sense to move out from a mature TCP/IP stack which provide many debugging and traffic management tools (e.g. tcpdump, tc, nftables, ipvs, eBPF and many others). </p><p>The reverse proxy example adds a lot of data structures, which must be shared and updated by all the CPUs: web cache, various statistics, connections tracking, <a href="https://natsys-lab.blogspot.com/2018/03/http-requests-proxying.html">HTTP message queues</a>, and many many others. You can use very efficient lock-free algorithms to access and update the data structures, but …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tempesta-tech.com/blog/user-space-tcp">http://tempesta-tech.com/blog/user-space-tcp</a></em></p>]]>
            </description>
            <link>http://tempesta-tech.com/blog/user-space-tcp</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611846</guid>
            <pubDate>Tue, 23 Jun 2020 09:58:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archival Identifiers for Digital Files]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23611459">thread link</a>) | @todsacerdoti
<br/>
June 23, 2020 | https://blog.adamretter.org.uk/archival-identifiers-for-digital-files/ | <a href="https://web.archive.org/web/*/https://blog.adamretter.org.uk/archival-identifiers-for-digital-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
</figure>
<section>
<div>
<p>As part of Project Omega for TNA (<a href="https://www.nationalarchives.gov.uk/">The National Archives</a>), I have been thinking about how identifiers for Digital Files should be constructed. This blog entry continues on from my previous entry: <a href="https://blog.adamretter.org.uk/archival-catalog-identifiers/">Archival Catalogue Record Identifiers</a>.<strong> </strong></p><p>When considering development of a new archival catalogue that can describe both physical, digitised, and born digital records, we quickly realised that unlike its predecessors this catalogue will also need to describe digital files.</p><p>At this point you might think that I am mixing current concerns between what archives' have often thought of as two separate systems, 1) their Archival catalogue, and 2) their Digital Preservation system. Yes, I am, and intentionally so! However, I would argue that this soup has been cooking for some time; I have seen that until now digital preservation systems have had to include some aspect of cataloguing (for their digital records) as the traditional archival catalogues, that were already in-place, were ill-equipped to describe the new digital world. I believe that a clean and mutually-beneficial separation between cataloguing and (digital) preservation activities can be established, but that as practitioners we are still very much writing the book on digital preservation.</p><p>Anyway, I digress! The archival concept of a Digital File is a complex one, as archivists we have to ask difficult questions like:</p><ul>
<li>What is a digital file?</li>
<li>How do I describe a digital file?</li>
<li>Is a copy of a file the same digital file?</li>
<li>If I change the name of the file, is it still the same digital file?</li>
</ul>
<p>All of these things have to be considered when designing a scheme for local identifiers of Digital File. Without writing an extended article on various principles of digital preservation, it is perhaps enough to say that the file's path and/or name are not suitable for use as an identifier; in no small part due to both their transient nature, and inability to be combined with files from other systems which may cause rise to naming conflicts.</p><h3 id="the-current-approach">The Current Approach</h3><p>To date the predominant approach in digital preservation for generating identifiers for digital files has been to simply assign them a <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">UUID</a> (Universally Unique Identifier); more specifically a Version 4 UUID. This approach has several nice properties:</p><ul>
<li>
<p>These can be generated independently of each other.</p>
<p>You can just <em>magic</em> a UUID into existence without concern for other UUIDs that have gone before or come after it.</p>
<p>The chance of a collision is <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_(random)#Collisions">incredibly small</a> - "<em>the probability to find a duplicate within 103 trillion version-4 UUIDs is one in a billion</em>".</p>
</li>
<li>
<p>They are relatively compact and presentable.</p>
<p>A UUID is just a 128-bit positive integer. This is typically formatted for presentation as a hexadecimal string of five components, totaling 36 printable characters, albeit they are not very human friendly.</p>
</li>
<li>
<p>They are cheap to compute.</p>
<p>On a modern laptop we can easily generate over 500,000 every second.</p>
</li>
</ul>
<h3 id="a-new-approach-content-identifiers"><br>A New Approach - Content Identifiers</h3><p>As an alternative to UUIDs, I am proposing a new approach for generating an identifier for Digital File which is computed from the content of the file itself.</p><p>I should be clear that this is not some stroke of genius on my part, similar approaches are already widely used in other domains. For example, the <a href="https://git-scm.com/">Git</a> SCM (Source Code Management) uses SHA1 digests to identify files and changes. Likewise, the <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> (InterPlanetary File System) uses <a href="https://docs.ipfs.io/guides/concepts/cid/">its definition of a CID</a> (Content Identifier), which is a hash function's digest of a file's content to address that file.</p><p>To avoid any confusion between IPFS CID's and our "Content Identifiers", I will herein use the abbreviation ACID (Archival Content Identifier) to refer to my proposal for identifiers.</p><p>The main part of an ACID is generated by computing the digest of the byte-stream (i.e. content) of the digital file via a hash function. This raises the question, of which hash function should be used? There is a wealth of <a href="https://en.wikipedia.org/wiki/List_of_hash_functions">different hash algorithms</a> available with various properties and different trade-offs. That being said, I am going to suggest that we use a <a href="https://blake2.net/">BLAKE2b</a>-256 hash for the following reasons:</p><ul>
<li>Recognised and verified by NIST.</li>
<li>Likelihood of collision is incredibly small.</li>
<li>Much faster to generate than equivalents such as SHA-256.</li>
<li>At least as secure as SHA-3.</li>
</ul>
<p>For example, if we wanted to generate a BLAKE2b-256 hash digest for the Apache 2.0 License file, we could run:</p><pre><code>curl https://www.apache.org/licenses/LICENSE-2.0.txt | b2sum --length 256 --binary</code></pre><p>This yields a 256-bit number encoded into a hexadecimal string totaling 64 printable characters:</p><pre><code>3cbae8f16217ad44981e5843100092cd582202e69d452eb094480f2d24abdb49</code></pre><p>This hexadecimal string has some interesting properties:</p><ul>
<li>
<p>It can be used an an identifier for the Digital File.</p>
</li>
<li>
<p>Verifiable Descriptions.</p>
<p>Provoided with both, 1) the description and identifier of a digital file and, 2) the file itself, we can verify that the description is indeed about the file by re-computing the hash digest of the file and comparing the result with the digital file identifier.</p>
</li>
<li>
<p>Verifiable Preservation.</p>
<p>Similarly to above, if the hash digest of the file changes over time, then we can assert that there has been an issue with its preservation, e.g. <a href="https://en.wikipedia.org/wiki/Data_degradation">data-rot</a>.</p>
</li>
</ul>
<p>There are some down-sides to using a hash digest as opposed to a UUID:</p><ul>
<li>
<p>More expensive to compute.</p>
<p>A hash digest is much more expensive to compute than a UUID, and the larger the file being digested the more expensive it becomes.</p>
</li>
<li>
<p>Less compact.</p>
<p>Our 256-bit hash generates a result which is twice as long as a UUID.</p>
</li>
</ul>
<p>I believe that the down-sides of a hash digest are outweighed by its advantage of offering verifiability.</p><p><strong>Which Hash Function was it?</strong></p><p>For the purposes of preservation and interoperability, one thing that we have not yet considered is how one determines which hash function was used to generate an identifier. Sure, I said we would use BLAKE2b-256, but what if you want to use a different hash function? Also, from an digital archaeological perspective, given an identifier like:</p><pre><code>3cbae8f16217ad44981e5843100092cd582202e69d452eb094480f2d24abdb49</code></pre><p>You might be able to infer that it is a hash digest, and the selection of characters used and the number of them would indicate that it could be a 256-bit hash... but which hash function was used?</p><p>Ideally, we need a mechanism to also communicate the hash function that was used. In fact IPFS already thought about this, and they use an encoding called <a href="https://multiformats.io/multihash/">Multihash</a> which prefixes their CIDs with a code indicating the hash function used. Whilst we could adopt Multihash here, it's much more complex than we need (famous last words?!?). Instead, I propose that our ACID's have a single ASCII character at the start that indicates the hash function that was used. A single ASCII character has the advantage of a fixed-length numeric encoding, and it makes the number of characters in the hexadecimal string representation an odd number, thus providing a hint to a digital archeologist that perhaps this ACID is similar to a digest but with an extra character. I will go one step further and say that this character should be outside of the hexadecimal alphabet (and ignorant of case-sensitivity), this should make it glaringly obvious to such a digital archeologist that the prefix character has a meaning which is distinct from the rest of the string.</p><p>An ACID is then formatted from a template like this:</p><pre><code>{Hash Function Type}{Hash Digest}</code></pre><p>For the Hash Function Type, I am going to reserve the <code>!</code> character to indicate BLAKE2b-256. Why? Because, I think it looks cool! This would mean that our earlier digital file identifier now simply becomes:</p><pre><code>!3cbae8f16217ad44981e5843100092cd582202e69d452eb094480f2d24abdb49</code></pre><p><br><strong>What about Collisions?</strong></p><p>Sure, generating a digital file identifier with BLAKE2b-256 has a very small chance of generating a collision (i.e. two different files with the same identifier), but what if...?</p><p>If you detect a collision, I will build you a new digital archive system for free... Nope! Just joking! We actually already have a mechanism for coping with this, the Hash Function Type; for the new file which creates the collision you could switch to a different hash function, perhaps a 512-bit one! This would at least give you a different unique identifier. But... what to do about the original file which is on the other side of the collision, it's probably deeply embedded in your archive by now! You could re-catalogue it, but maybe you don't even need to???<br></p><p><br>I have in mind the idea to write another article about further encoding such ACID's for compact machine use. Okay… that’s enough for today!</p>
</div>
</section>

</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.adamretter.org.uk/archival-identifiers-for-digital-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611459</guid>
            <pubDate>Tue, 23 Jun 2020 08:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The EU General Data Protection Regulation (GDPR) Explained by Americans]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23611186">thread link</a>) | @hugoroy
<br/>
June 23, 2020 | https://hroy.eu/posts/gdprExplainedByUS/ | <a href="https://web.archive.org/web/*/https://hroy.eu/posts/gdprExplainedByUS/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://hroy.eu/posts/gdprExplainedByUS/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611186</guid>
            <pubDate>Tue, 23 Jun 2020 08:16:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning operating system development using Linux kernel and Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 440 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23611081">thread link</a>) | @weeber
<br/>
June 23, 2020 | https://s-matyukevich.github.io/raspberry-pi-os/ | <a href="https://web.archive.org/web/*/https://s-matyukevich.github.io/raspberry-pi-os/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<p>This repository contains a step-by-step guide that teaches how to create a simple operating system (OS) kernel from scratch. I call this OS Raspberry Pi OS or just RPi OS. The RPi OS source code is largely based on <a href="https://github.com/torvalds/linux">Linux kernel</a>, but the OS has very limited functionality and supports only <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">Raspberry PI 3</a>.</p>

<p>Each lesson is designed in such a way that it first explains how some kernel feature is implemented in the RPi OS, and then it tries to demonstrate how the same functionality works in the Linux kernel. Each lesson has a corresponding folder in the <a href="https://github.com/s-matyukevich/raspberry-pi-os/tree/master/src">src</a> directory, which contains a snapshot of the OS source code at the time when the lesson had just been completed. This allows the introduction of new concepts gracefully and helps readers to follow the evolution of the RPi OS. Understanding this guide doesn’t require any specific OS development skills.</p>

<p>For more information about project goals and history, please read the <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Introduction.html">Introduction</a>. The project is still under active development, if you are willing to participate - please read the <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Contributions.html">Contribution guide</a>.</p>

<p>
  <a href="https://twitter.com/RPi_OS" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/twitter.png" alt="Follow @RPi_OS on twitter" height="34">
  </a>

  <a href="https://www.facebook.com/groups/251043708976964/" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/facebook.png" alt="Follow Raspberry Pi OS on facebook" height="34">
  </a>

  <a href="https://join.slack.com/t/rpi-os/shared_invite/enQtNDQ1NTg2ODc1MDEwLWVjMTZlZmMyZDE4OGEyYmMzNTY1YjljZjU5YWI1NDllOWEwMjI5YzVkM2RiMzliYjEzN2RlYmUzNzBiYmQyMjY" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/slack.png" alt="Join Raspberry Pi OS in slack" height="34">
  </a>

  <a href="https://www.producthunt.com/upcoming/raspberry-pi-os" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/subscribe.png" alt="Subscribe for updates" height="34">
  </a>
</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Introduction.html">Introduction</a></strong></li>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Contributions.html">Contribution guide</a></strong></li>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Prerequisites.html">Prerequisites</a></strong></li>
  <li><strong>Lesson 1: Kernel Initialization</strong>
    <ul>
      <li>1.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/rpi-os.html">Introducing RPi OS, or bare metal “Hello, world!”</a></li>
      <li>Linux
        <ul>
          <li>1.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/project-structure.html">Project structure</a></li>
          <li>1.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/build-system.html">Kernel build system</a></li>
          <li>1.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/kernel-startup.html">Startup sequence</a></li>
        </ul>
      </li>
      <li>1.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 2: Processor initialization</strong>
    <ul>
      <li>2.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/rpi-os.html">RPi OS</a></li>
      <li>2.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/linux.html">Linux</a></li>
      <li>2.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 3: Interrupt handling</strong>
    <ul>
      <li>3.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/rpi-os.html">RPi OS</a></li>
      <li>Linux
        <ul>
          <li>3.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/low_level-exception_handling.html">Low level exception handling</a></li>
          <li>3.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/interrupt_controllers.html">Interrupt controllers</a></li>
          <li>3.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/timer.html">Timers</a></li>
        </ul>
      </li>
      <li>3.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 4: Process scheduler</strong>
    <ul>
      <li>4.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/rpi-os.html">RPi OS</a></li>
      <li>Linux
        <ul>
          <li>4.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/basic_structures.html">Scheduler basic structures</a></li>
          <li>4.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/fork.html">Forking a task</a></li>
          <li>4.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/scheduler.html">Scheduler</a></li>
        </ul>
      </li>
      <li>4.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 5: User processes and system calls</strong>
    <ul>
      <li>5.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/rpi-os.html">RPi OS</a></li>
      <li>5.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/linux.html">Linux</a></li>
      <li>5.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 6: Virtual memory management</strong>
    <ul>
      <li>6.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson06/rpi-os.html">RPi OS</a></li>
      <li>6.2 Linux (In progress)</li>
      <li>6.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson06/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 7: Signals and interrupt waiting</strong> (To be done)</li>
  <li><strong>Lesson 8: File systems</strong> (To be done)</li>
  <li><strong>Lesson 9: Executable files (ELF)</strong> (To be done)</li>
  <li><strong>Lesson 10: Drivers</strong> (To be done)</li>
  <li><strong>Lesson 11: Networking</strong> (To be done)</li>
</ul>


      </section>
    </div></div>]]>
            </description>
            <link>https://s-matyukevich.github.io/raspberry-pi-os/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611081</guid>
            <pubDate>Tue, 23 Jun 2020 08:00:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Denoising Diffusion Probabilistic Models]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23610915">thread link</a>) | @baylearn
<br/>
June 23, 2020 | https://hojonathanho.github.io/diffusion/ | <a href="https://web.archive.org/web/*/https://hojonathanho.github.io/diffusion/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <h2>Algorithms and Results</h2>
                <p>We show that diffusion probabilistic models resemble denoising score matching with Langevin dynamics sampling, yet provide log likelihoods and rate-distortion curves in one evaluation of the variational bound.<br></p>
                <p><img src="https://hojonathanho.github.io/diffusion/assets/img/algorithms.png"><em>Our training and sampling algorithms for diffusion probabilistic models. Note the resemblance to denoising score matching and Langevin dynamics.</em>
                <img src="https://hojonathanho.github.io/diffusion/assets/img/cifar10.png"><em>Unconditional CIFAR10 samples. Inception Score=9.46, FID=3.17.</em>
                <img src="https://hojonathanho.github.io/diffusion/assets/img/rate.png"><em>CIFAR10 sample quality and lossless compression metrics (left), unconditional test set rate-distortion curve for lossy compression (right).</em>
            </p></div>
        </div>
    </div></div>]]>
            </description>
            <link>https://hojonathanho.github.io/diffusion/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23610915</guid>
            <pubDate>Tue, 23 Jun 2020 07:36:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres Indexes for ActiveRecord Join Tables in Rails Apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23610820">thread link</a>) | @pawurb
<br/>
June 23, 2020 | https://pawelurbanek.com/rails-postgres-join-indexes | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/rails-postgres-join-indexes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title="Indices in join tables are represented by two ducks. Photo by Amir-abbas Abdolali on Unsplash" alt="Indices in join tables are represented by two ducks. Photo by Amir-abbas Abdolali on Unsplash" data-src="https://pawelurbanek.com/assets/join-table-ducks-72def049bca485bb43a5a080927b84a423708cb67d6ff5e2082a13e88e45a427.jpg" src="https://pawelurbanek.com/assets/join-table-ducks-thumb-c8c5c20ca540035f7c20d43e016a4073c625d8114434217f0069ebd62817b6e4.jpg">
    </p>
  

  

  <p>Join tables are a common citizen in Ruby on Rails apps. Their use case is to provide many to many relation between database models. Adding correct Postgres indexes on join tables is not obvious. I’ve noticed that some tutorials, Stack Overflow posts, and even Rails itself provide incorrect advice on how to do it. In this tutorial, we’ll look into how compound PostgreSQL indexes work and how to correctly use them with join tables.</p>

<p>We will start by explaining the basics of join models and later deep dive into analyzing the output of the PostgreSQL EXPLAIN query plan with different database indexes.</p>

<h2 id="what-is-a-join-table-and-model-in-rails">What is a join table and model in Rails?</h2>

<p>Many to many relation is often necessary to model the business logic of a web app. Let’s illustrate it with a flagship scenario: a user that has many favorite products.</p>

<p>If you already have a Product and User models, you can well <em>join</em> them using a join table by writing the following migration:</p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>CreateUsersProducts</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Migration</span>
  <span>def</span> <span>change</span>
    <span>create_table</span> <span>:users_products</span> <span>do</span> <span>|</span><span>t</span><span>|</span>
      <span>t</span><span>.</span><span>integer</span> <span>:user_id</span><span>,</span> <span>null: </span><span>false</span>
      <span>t</span><span>.</span><span>integer</span> <span>:product_id</span><span>,</span> <span>null: </span><span>false</span>
      <span>t</span><span>.</span><span>timestamps</span>
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p>Let’s look at the model files now:</p>

<p><code>app/models/product.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>Product</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:user_products</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:users</span><span>,</span> <span>through: :user_products</span>
<span>end</span></code></pre></figure>

<p><code>app/models/user.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:user_products</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:products</span><span>,</span> <span>through: :user_products</span>
<span>end</span></code></pre></figure>

<p><code>app/models/user_product.rb</code></p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>UserProduct</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>self</span><span>.</span><span>table_name</span> <span>=</span> <span>"users_products"</span>

  <span>belongs_to</span> <span>:user</span>
  <span>belongs_to</span> <span>:product</span>
<span>end</span></code></pre></figure>

<p>With this structure in place, you can assign multiple users to products and vice versa:</p>

<figure><pre><code data-lang="ruby"><span>product</span> <span>=</span> <span>Product</span><span>.</span><span>last</span>
<span>user</span> <span>=</span> <span>User</span><span>.</span><span>last</span>

<span>product</span><span>.</span><span>users</span> <span>&lt;&lt;</span> <span>user</span>
<span>product</span><span>.</span><span>users</span> <span>#=&gt; [user]</span>
<span>user</span><span>.</span><span>products</span> <span>#=&gt; [product]</span></code></pre></figure>

<p>If you need more fine tuned control you can use the join model directly:</p>

<figure><pre><code data-lang="ruby"><span>product</span> <span>=</span> <span>Product</span><span>.</span><span>last</span>
<span>user</span> <span>=</span> <span>User</span><span>.</span><span>last</span>

<span>UserProduct</span><span>.</span><span>create!</span><span>(</span>
  <span>product_id: </span><span>product</span><span>.</span><span>id</span><span>,</span>
  <span>user_id: </span><span>user</span><span>.</span><span>id</span>
<span>)</span>

<span>product</span><span>.</span><span>users</span> <span>#=&gt; [user]</span>
<span>user</span><span>.</span><span>products</span> <span>#=&gt; [product]</span></code></pre></figure>

<h3 id="avoid-using-has_and_belongs_to_many">Avoid using <code>has_and_belongs_to_many</code>!</h3>

<p>You could use <a href="https://api.rubyonrails.org/classes/ActiveRecord/Associations/ClassMethods.html#method-i-has_and_belongs_to_many" target="_blank">has_and_belongs_to_many</a> relation with <a href="https://api.rubyonrails.org/classes/ActiveRecord/ConnectionAdapters/SchemaStatements.html#method-i-create_join_table" target="_blank">create_join_table</a> migration helper method and omit to declare the <code>UserProduct</code> model. I don’t recommend this approach. It might be quicker to start with but much more constrained in the long run. E.g., <code>create_join_table</code> generates a table without a primary key, so you couldn’t easily add a customizable join model afterward.</p>

<h2 id="how-to-add-proper-indexes-to-the-join-table-in-rails">How to add proper indexes to the join table in Rails?</h2>

<p>You might have noticed that we did not add any indexes to the <code>users_products</code> table yet. For larger dataset, this setup could result in slow queries killing the performance of a web app. Let’s analyze how Postgres handles fetching objects through the join table without indexes.</p>

<h3 id="query-explain-plan-when-indexes-are-missing">Query EXPLAIN plan when indexes are missing</h3>

<p>Unfortunately, ActiveRecord does not support <code>EXPLAIN ANALYZE</code> out of the box. You can use <a href="https://github.com/pawurb/activerecord-analyze" target="_blank">this gem</a> if you’d like to measure the actual performance of the queries. In the below examples, we’ll use the built-in <code>explain</code> method, which displays the detailed PostgreSQL plan for executing the query.</p>

<figure><pre><code data-lang="ruby"><span>user</span><span>.</span><span>products</span><span>.</span><span>to_sql</span>

<span>"SELECT products.* FROM products
  INNER JOIN users_products
    ON products.id = users_products.product_id
  WHERE users_products.user_id = 5"</span>

<span>user</span><span>.</span><span>products</span><span>.</span><span>explain</span>


<span># Nested Loop</span>
<span># -&gt;  Seq Scan on user_products</span>
<span>#       Filter: (user_id = 2392)</span>
<span># -&gt;  Index Scan using products_pkey on products</span>
<span>#       Index Cond: (id = user_products.product_id)</span>

<span>user</span><span>.</span><span>products</span><span>.</span><span>where</span><span>(</span><span>id: </span><span>1</span><span>).</span><span>to_sql</span>

<span>"SELECT products.* FROM products
  INNER JOIN users_products
    ON products.id = users_products.product_id
  WHERE users_products.user_id = 5 AND products.id = 1"</span>

<span>user</span><span>.</span><span>products</span><span>.</span><span>where</span><span>(</span><span>id: </span><span>1</span><span>).</span><span>explain</span>

<span># Nested Loop</span>
<span># -&gt;  Index Scan using products_pkey on products</span>
<span>#       Index Cond: (id = '1')</span>
<span># -&gt;  Seq Scan on user_products</span>
<span>#       Filter: ((product_id = '1') AND (user_id = 2392))</span></code></pre></figure>

<p>Output truncated for brevity</p>


<p>As you can see in both cases, it is performing a <code>Seq Scan</code> on <code>users_products</code> table. <code>Seq Scan</code> means that Postgres has to loop through all the rows of a table to run the query. For a larger dataset, it is usually terribly inefficient.</p>

<p>Let’s add indexes to see how it will change the behavior.</p>

<h3 id="query-explain-plan-with-two-compound-indexes">Query EXPLAIN plan with two compound indexes</h3>

<p>We’ll start with the approach I often see mentioned in tutorials. Even Rails <a href="https://edgeguides.rubyonrails.org/active_record_migrations.html#creating-a-standalone-migration" target="_blank">suggests adding two compound indexes</a> when generating migration using <code>create_join_table</code> helper.</p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>AddIndexesToUsersProducts</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Migration</span>
  <span>disable_ddl_transaction!</span>

  <span>def</span> <span>change</span>
    <span>add_index</span> <span>:users_products</span><span>,</span> <span>[</span><span>:product_id</span><span>,</span> <span>:user_id</span><span>],</span>
      <span>unique: </span><span>true</span><span>,</span> <span>algorithm: :concurrently</span>

    <span>add_index</span> <span>:users_products</span><span>,</span> <span>[</span><span>:user_id</span><span>,</span> <span>:product_id</span><span>],</span>
      <span>unique: </span><span>true</span><span>,</span> <span>algorithm: :concurrently</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p>Unless you have a non-standard use case, you should add unique indexes to validate join objects on the database level.</p>

<p>Using <code>disable_ddl_transaction!</code> and <code>algorithm: :concurrently</code> is the best practice that allows you to add indexes even to large tables without acquiring a full table lock. Otherwise, migration could easily bring down your production.</p>

<p>You can check out <a href="https://pawelurbanek.com/rails-mistakes-downtime">my other blog post</a> if you want to learn more exciting tricks on how to crash your production servers.</p>

<p>Let’s start by replying our previous queries:</p>

<figure><pre><code data-lang="bash">user.products.explain

<span># Nested Loop</span>
<span># -&gt;  Bitmap Heap Scan on users_products</span>
<span>#   Recheck Cond: (user_id = 2392)</span>
<span>#     -&gt;  Bitmap Index Scan on</span>
<span>#         index_users_products_on_user_id_and_product_id</span>
<span>#           Index Cond: (user_id = 2392)</span>
<span>#     -&gt;  Index Scan using products_pkey on products</span>
<span>#         Index Cond: (id = users_products.product_id)</span>

user.products.where<span>(</span><span>id</span>: 1<span>)</span>.explain

<span># Nested Loop</span>
<span># -&gt;  Index Scan using products_pkey on products</span>
<span>#   Index Cond: (id = '1')</span>
<span>#   -&gt;  Index Only Scan using</span>
<span>#      index_users_products_on_user_id_and_product_id</span>
<span>#      on users_products</span>
<span>#      Index Cond: ((user_id = 2392) AND (product_id = '1'))</span></code></pre></figure>

<p>As you can see <code>Seq Scan</code> has been replaced by <code>Index Scan</code>. But if you analyze <code>Index Cond</code>, you’ll see that only the second query uses both fields from the compound <code>index_users_products_on_user_id_and_product_id</code> index.</p>

<p>Let’s see what will happen if we query the other side of the relation:</p>

<figure><pre><code data-lang="bash">product.users.explain

<span># Nested Loop</span>
<span># -&gt;  Bitmap Heap Scan on users_products</span>
<span>#     Recheck Cond: (product_id = 74190)</span>
<span>#       -&gt;  Bitmap Index Scan on</span>
<span>#           index_users_products_on_product_id_and_user_id</span>
<span>#           Index Cond: (product_id = 74190)</span>
<span># -&gt;  Index Scan using users_pkey on users</span>
<span>#     Index Cond: (id = users_products.user_id)</span>

product.users.where<span>(</span><span>id</span>: 1<span>)</span>.explain

<span># Nested Loop</span>
<span># -&gt;  Index Scan using users_pkey on users</span>
<span>#       Index Cond: (id = '1')</span>
<span># -&gt;  Index Only Scan using</span>
<span>#     index_users_products_on_user_id_and_product_id</span>
<span>#     on users_products</span>
<span>#     Index Cond: ((user_id = '1') AND (product_id = 74190))</span></code></pre></figure>

<p>The first query behaves as expected. It uses <code>product_id</code> <code>Index Cond</code> from <code>index_users_products_on_product_id_and_user_id</code> index. But if you look at the second output, you’ll notice that it is still using the same index as the query executed in another direction!</p>

<p>It means that duplicating the compound indexes for join tables is unnecessary. Postgres is smart enough to use both keys of a compound index if they are matching, regardless what’s the order of columns in a query.</p>

<p>I’ve validated this behavior with PostgreSQL from version 9 up to 12.</p>

<h3 id="simpler-sql-query">Simpler SQL query</h3>

<p>The above examples might be a bit convoluted. Here’s a more straightforward query you can use to replicate this behavior:</p>

<figure><pre><code data-lang="ruby"><span>query_a</span> <span>=</span> <span>UserProduct</span><span>.</span><span>where</span><span>(</span><span>user_id: </span><span>1</span><span>,</span> <span>product_id: </span><span>2</span><span>)</span>

<span>query_a</span><span>.</span><span>to_sql</span>

<span>"SELECT users_products.* FROM users_products
  WHERE users_products.user_id = 1
  AND users_products.product_id = 2"</span>

<span>query_a</span><span>.</span><span>explain</span>

<span># Index Scan using</span>
<span>#   index_users_products_on_user_id_and_product_id</span>
<span>#   on users_products</span>
<span>#     Index Cond: ((user_id = 1) AND (product_id = 2))</span>

<span>query_b</span> <span>=</span> <span>UserProduct</span><span>.</span><span>where</span><span>(</span><span>product_id: </span><span>2</span><span>,</span> <span>user_id: </span><span>1</span><span>)</span>

<span>query_b</span><span>.</span><span>to_sql</span>

<span>"SELECT users_products.* FROM users_products
  WHERE users_products.product_id = 2
  AND users_products.user_id = 1"</span>

<span>query_b</span><span>.</span><span>explain</span>

<span># Index Scan using</span>
<span>#   index_users_products_on_user_id_and_product_id</span>
<span>#   on users_products</span>
<span>#     Index Cond: ((user_id = 1) AND (product_id = 2))</span></code></pre></figure>

<p>Both compound indexes were present when running those queries. One was working hard looking up the query results. The other one was sitting there, useless, doing nothing.</p>

<p>Usually, you can track unused indexes with tools that display those that are getting few hits e.g., <a href="https://github.com/pawurb/rails-pg-extras#unused_indexes" target="_blank">Rails PG Extras</a>. Unfortunately, detecting a partially used compound index is not that simple using automated tooling.</p>

<h3 id="correct-indexes-migration-for-join-tables">Correct indexes migration for join tables</h3>

<p>To optimize usage of database resources, the migration adding a join table to your Rails app could look like that:</p>

<figure><pre><code data-lang="ruby"><span>class</span> <span>CreateUsersProducts</span> <span>&lt;</span> <span>ActiveRecord</span><span>::</span><span>Migration</span>
  <span>def</span> <span>change</span>
    <span>create_table</span> <span>:users_products</span> <span>do</span> <span>|</span><span>t</span><span>|</span>
      <span>t</span><span>.</span><span>integer</span> <span>:user_id</span><span>,</span> <span>null: </span><span>false</span>
      <span>t</span><span>.</span><span>integer</span> <span>:product_id</span><span>,</span> <span>null: </span><span>false</span>
      <span>t</span><span>.</span><span>timestamps</span>
    <span>end</span>

    <span>add_index</span> <span>:users_products</span><span>,</span> <span>[</span><span>:product_id</span><span>,</span> <span>:user_id</span><span>],</span> <span>unique: </span><span>true</span>
    <span>add_index</span> <span>:users_products</span><span>,</span> <span>:user_id</span>
  <span>end</span>
<span>end</span></code></pre></figure>

<p>With those indexes in place accessing any side of relation will generate to following EXPLAIN query plan output:</p>

<figure><pre><code data-lang="ruby"><span>product</span><span>.</span><span>users</span><span>.</span><span>explain</span>

<span># Nested Loop</span>
<span># -&gt;  Bitmap Heap Scan on users_products</span>
<span>#     Recheck Cond: (product_id = 74655)</span>
<span>#      -&gt;  Bitmap Index Scan on</span>
<span>#       index_users_products_on_product_id_and_user_id</span>
<span>#         Index Cond: (product_id = 74655)</span>
<span># -&gt;  Index Scan using users_pkey on users</span>
<span>#     Index Cond: (id = users_products.user_id)</span>

<span>product</span><span>.</span><span>users</span><span>.</span><span>where</span><span>(</span><span>id: </span><span>1</span><span>).</span><span>explain</span>

<span># Nested Loop</span>
<span># -&gt;  Index Scan using users_pkey on users</span>
<span>#     Index Cond: (id = '1')</span>
<span># -&gt;  Index Only Scan using</span>
<span>#     index_users_products_on_product_id_and_user_id</span>
<span>#     on users_products</span>
<span>#       Index Cond: ((product_id = 74655) AND (user_id = '1'))</span>

<span>user</span><span>.</span><span>products</span><span>.</span><span>exp…</span></code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/rails-postgres-join-indexes">https://pawelurbanek.com/rails-postgres-join-indexes</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/rails-postgres-join-indexes</link>
            <guid isPermaLink="false">hacker-news-small-sites-23610820</guid>
            <pubDate>Tue, 23 Jun 2020 07:23:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Sabotaging Your Career with Short Stints]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23610701">thread link</a>) | @fgerschau
<br/>
June 23, 2020 | https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Life before a software engineering career is commonly a series of time-bound efforts to gain competency in a new area. This semester you learn geometry. That semester you learn history. Next semester you learn calculus. And so on.</p>

<p>As a result, most people entering the software engineering workforce equate learning with learning a brand new topic. I didn’t know ruby, I learned ruby. I didn’t know SQL, now I know SQL.</p>

<p>This kind of thinking leads people to 2 year cycles. On most modern software teams, it takes roughly one year to really feel like you have your feet under you. By that time the kind of learning novelty people are used to isn’t there. By 16 months they’re restless. By 24 months they’re gone.</p>

<p>This is a problem. It’s a problem because the majority of durable and transferable knowledge comes after achieving basic competency. Mastery of a skillset, understanding and learning from the outcomes of decisions made years ago, architecture and design, leading projects - these all come well after basic competency.</p>

<p>Not only does a life of cyclic learning work against reaching these next levels, but your ego and willpower also work against you. Those next-level skills are harder to learn. And once you’ve gained competency you lose the excuse of “I’m onboarding” or “still ramping up” when something goes wrong.</p>

<p>I always challenge engineers that want to make big changes in what they’re working on to consider whether they’re simply at the end of a novelty cycle. I always encourage them to go after those next level skills.</p>

<p>On the hiring front, I see a lot of people who have a career’s worth of 2-year stints. You can do that successfully for an entire career, and there are even some people that’ll tell you it’s a way to optimize earnings over time. If it does, I believe it only optimizes earnings for people who can’t get to those next level skills. The biggest earnings come from building and growing with a winning company.</p>

<p>24-monthers never deeply learn how things work. They’ll typically add value to a new company by carrying a collection of things they’ve seen before and shallowly applying them to similar problems. But when faced with a new problem that doesn’t map easily to the solutions they’ve seen, things start to break down.</p>

<p>The end-games for both careers are very different.</p>

<p>24-monthers eventually can get into C-level positions where it’s not uncommon to bring in someone who can just apply the common solutions to the similar task at hand. Their stints usually end right around the time where they’ve upleveled the company in some way and don’t know how to grow their team or evolve their strategy or deal with the short-comings of some of their decisions.</p>

<p>People who learn next level skills and how to deeply understand and react to the tasks at hand lead companies to uniquely successful outcomes. The best CEOs, the best CTOs, the best C-level anything - their careers are often a small handful of long-duration roles where they didn’t apply rote practices but innovated and reacted to change and created novel solutions based on deep understanding.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’m not saying you should stay with any given job. There are bad roles and bad bosses and everything in between. And skill diversification is important. But every job has problems. If you’re leaving because you’re chasing novelty or avoiding tackling your company’s challenges, you’ll start over in the cycle. Leave enough places for these reasons and you’ll find you’ve seriously limited your opportunities and earnings over time.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23610701</guid>
            <pubDate>Tue, 23 Jun 2020 07:03:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My FreeBSD Laptop Build]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23610611">thread link</a>) | @rodrigo975
<br/>
June 22, 2020 | https://corrupted.io/2020/06/21/my-freebsd-laptop-build.html | <a href="https://web.archive.org/web/*/https://corrupted.io/2020/06/21/my-freebsd-laptop-build.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">

<p>I have always liked Thinkpad hardware and when I started to do more commuting I decided I needed something that had a decent sized screen but fit well on a bus. Luckily about this time Lenovo gave me a nice gift in the <a href="https://www.lenovo.com/us/en/laptops/thinkpad/thinkpad-x/X390/p/22TP2TX3900">Thinkpad X390</a>. Its basically the famous X2xx series but with a 13” screen and smaller bezel.</p>
<p>So with this laptop I figured it was time to actually put the docs together on how I got my FreeBSD workstation working on it. I will here in the near future have another post that will cover this for HardenedBSD as well since the steps are similar but have a few extra gotchas due to the extra hardening.</p>

<h2 id="hardware">Hardware</h2>
<p>The guts are:</p>
<ul>
<li>8th Generation Intel Core i7 1.9 GHz</li>
<li>16 GB Ram</li>
<li>Replaced the 512GB NVMe Disk with a 1TB Samsung Evo Pro NVMe disk</li>
<li>13.3” 1920x1080 IPS display</li>
<li>Intel Graphics</li>
<li>Intel Wireless 9560 802.11AC card (2x2)</li>
<li>Bluetooth 5.0</li>
</ul>
<p>Some of the more important parts of this is it supports USB-C and charging from USB-C. I’ve been moving more and more to all of my mobile tech charging from USB-C so I can strip down what I am carrying. It has became a requirement for me. For the people that start asking “Well how do you deal with needing high performance or high power processors for <strong>__</strong>”. My answer is what it has been for nearly 15 years now. I have 3 6 core 12 thread Xeon workstations at home. If the laptop cant do it in a reasonable time it was the wrong device for the job and the job gets offloaded to my workstations.</p>
<p>But I digress, really the only way this could get better is if it used open firmware like the System76 laptops that are coming out. Im keeping an eye on the newer System76 machines and honestly if I get the spare money to just experiment with a new toy or one magics itself onto my door step this laptop will live a full service life but the next one will probably be a System76 for various ethical and peace of mind reasons. But if a shiny new System76 laptop wills itself into existence in my fleet you can bet It will get BSD poured onto it and you all will hear about it.</p>
<p>What works:</p>
<ul>
<li>Wireless</li>
<li>Keyboard</li>
<li>Trackpad</li>
<li>Trackpoint</li>
<li>Backlight</li>
<li>Sleep and Resume</li>
<li>Sound</li>
</ul>
<p>What I couldn’t get working:</p>
<ul>
<li>MicroSD reader</li>
<li>Hibernate</li>
</ul>
<p>So with the hardware in hand the next part is the first step, bsdinstall.</p>
<h2 id="installer">Installer</h2>
<p>So this is based on using 13-Current or newer. The X390 needs 13-Current due to iwm changes. The iwm driver on release as of 2020-06-21 does not support the card in this. The standard high points to hit for the installer:</p>
<ul>
<li>ZFS on root</li>
<li>Full disk encryption, My mobile machines with SSDs always get encrypted disks</li>
<li>Hardening options
<ul>
<li>Random PIDs
<ul>
<li>This doesn’t seem to break anything, take away any functionality I use, and provides some extra protection from stuff guessing PIDs for apps.</li>
</ul>
</li>
<li>Disable syslog sockets
<ul>
<li>I don’t ship my syslog off of my laptop</li>
</ul>
</li>
<li>Clean tmp on startup
<ul>
<li>Clean your tmp where you can.</li>
</ul>
</li>
<li>Disable sendmail
<ul>
<li>Its a laptop, not a mail server. Might as well lighten the load</li>
</ul>
</li>
</ul>
</li>
<li>Disable sshd
<ul>
<li>again its a laptop lighten the load</li>
</ul>
</li>
<li>Enable powerd</li>
<li>Enable moused</li>
<li>Enable ntpd</li>
</ul>
<p>With that on first boot I do a <code>pkg bootstrap</code> and pull down my core packages.</p>
<h2 id="core-package-list">Core Package List</h2>
<p>Boiled down I install a few packages every time that are common to every role. These are mostly particular to me but they give me a KDE5 desktop.</p>
<ul>
<li>xorg</li>
<li>kde5</li>
<li>sddm</li>
<li>devcpu-data</li>
<li>intel-backlight</li>
<li>u2f-devd</li>
<li>firefox</li>
<li>chromium</li>
<li>libreoffice</li>
<li>git</li>
<li>subversion</li>
<li>portlint</li>
<li>diffstat</li>
<li>base64</li>
<li>sudo</li>
<li>neovim</li>
<li>drm-kmod</li>
</ul>
<p>After these are loaded I make a few changes to some files around the system to enable hardware and make things work to my liking.</p>
<h2 id="files">Files</h2>
<h3 id="loaderconf">loader.conf</h3>
<div><div><pre><code># Lets not wait on the boot loader
autoboot_delay=0

# I know that my root will never be on a USB disk, if it is we went sideways somewhere around albuquerque 
hw.usb.no_boot_wait="1"

# Load the webcam drivers
cuse_load="YES"

# Pull in the ACPI video power control for backlight control
acpi_video_load="YES"

# Intel has problems, we know they do, lets load their patches.
cpu_microcode_load="YES"
cpu_microcode_name="/boot/firmware/intel-ucode.bin"

# This is something I borrowed from colin percival to deal with an annoying warning that will be fixed soon and I'll test axing it later.
compat.linuxkpi.i915_disable_power_well="0"

# Load temperature sensors.
coretemp_load="YES"

# My processor should support accelerated AES no reason to not use it.
aesni_load="YES"
</code></pre></div></div>
<h3 id="sysctlconf">Sysctl.conf</h3>
<div><div><pre><code># The hardware bell is deafening, I don't frequently want it, so go away!
kern.vt.enable_bell=0
</code></pre></div></div>
<h3 id="pfconf">pf.conf</h3>
<p>I use PF for my workstation firewall because I know it and I have a basic rule. The rule set is, block all ingress, ignore the loopback adapter, pass all egress.</p>
<div><div><pre><code>block in all
set skip on lo0
pass out keep state
</code></pre></div></div>
<h2 id="configuration">Configuration</h2>
<h3 id="services">Services</h3>
<p>So these are things I have enabled and the flags they need.</p>
<div><div><pre><code># I want my webcam
sysrc webcamd_enable="YES"

# These are parts of having my DE actually work as expected
sysrc sddm_enable="YES"
sysrc dbus_enable="YES"
sysrc hald_enable="YES"
sysrc avahi_daemon_enable="YES"
sysrc avahi_dnsconfd_enable="YES"

# I do have a scanner that sometimes works, I should kill it off one day...
sysrc saned_enable="YES"

# I want to have power control enabled. When the new power control drivers come in this wont be needed and is broken since it stops exposing frequencies but that just means you can kill this
sysrc powerd_enable="YES"
sysrc powerd_flags="-N"

# Lets use the video drivers from packages/ports and not the kernel
sysrc kldlist="/boot/modules/i915kms.ko"

# I want my wireless to be ready for me to use.
sysrc wlans_iwm0="wlan0"
sysrc ifconfig_wlan0="WPA DHCP"
</code></pre></div></div>
<h3 id="user-groups">User Groups</h3>
<p>My user will need to be part of the following groups to use all the devices attached.</p>
<ul>
<li>webcamd</li>
<li>u2f</li>
<li>operator
<ul>
<li>This allows me to use power commands like halt and reboot without sudo.</li>
</ul>
</li>
<li>wheel</li>
<li>sound</li>
<li>video</li>
<li>games</li>
</ul>
<h2 id="notes">Notes</h2>
<h3 id="backlight">Backlight</h3>
<p>Need to put the devd rules in place <code>cp /usr/local/share/examples/intel-backlight/acpi-video-intel-backlight.conf /usr/local/etc/devd/</code></p>
<p>The keys for it sometimes work sometimes don’t there is some tweaking of a patch that has been pending review for a while that fixes this. Once it makes it in the Thinkpad function keys will be less fiddly</p>
<h3 id="future-wifi-improvements">Future Wifi Improvements</h3>
<p>Probably should consider trunking it</p>
<div><div><pre><code>sysrc ifconfig_em0="ether MY:WI:FI:MAC:ADD:RESS"
sysrc ifconfig_ue0="ether MY:WI:FI:MAC:ADD:RESS"
sysrc cloned_interfaces="lagg0"
sysrc ifconfig_lagg0="laggproto failover laggport em0 laggport ue0 laggport wlan0 DHCP"
</code></pre></div></div>
<h3 id="usb-audio-devices">USB Audio Devices</h3>
<p>SDDM runs kmix as part of the accessibility stack. If you have a usb audio card plugged in when SDDM starts it causes the kernel to enter an eternal loop waiting for a kmix detach that is never going to come, see <a href="https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=194727">this bug</a> for some nitty gritty on it. Near as I can tell from experimenting if I cause the card to detach ahead of sleep or shutdown, OR kill kmix as part of a sleep script it goes away. Probably should circle back around at some code for this because IMO the correct behavior should be the kernel says “hey guys please release your FDs” then after some period of time the kernel comes back around with an angry face and goes “Okay asking didn’t work, your FDs are not released, have a nice day” But handling that correctly could be complex and it may be a case where we accept that not all FDs are created equally and some should interrupt the kernel and others the software should be told to sod off.</p>
<br>
</div></div>]]>
            </description>
            <link>https://corrupted.io/2020/06/21/my-freebsd-laptop-build.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23610611</guid>
            <pubDate>Tue, 23 Jun 2020 06:47:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Item Store]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23610389">thread link</a>) | @stokesyio
<br/>
June 22, 2020 | https://tinyprojects.dev/projects/one_item_store | <a href="https://web.archive.org/web/*/https://tinyprojects.dev/projects/one_item_store">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<nav>
		<a href="https://tinyprojects.dev/">Home</a>
		<a href="https://tinyprojects.dev/projects">Projects</a>
		<a href="https://tinyprojects.dev/guides">Guides</a>
		<a href="https://tinyprojects.dev/blog">Blog</a>
	</nav>
	
<a href="https://www.producthunt.com/posts/one-item-store?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-one-item-store" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=208263&amp;theme=dark" alt="One Item Store - Micro online store builder. Just sell your stuff. | Product Hunt Embed" width="250px" height="54px"></a>
	<p><i>June 22nd 2020</i></p>
	<ul>
		<li><i>Cost: <strong>£41.00</strong></i></li>
		<li><i>Time: <strong>50 hours</strong></i></li>
	</ul>

	<p>The past two weeks I built &amp; launched a tiny e-commerce store builder called <a href="https://oneitem.store/" target="_blank">One Item Store</a>. It lets people sell their single product online for free. Basically, think of a tiny version of Shopify. </p>

	<img src="https://i.gyazo.com/0a3d723ada235af4ead35d39574dce60.png" alt="one item store editor">

	<h2>Idea</h2>

	<p>What if you were someone who just wanted sell your one product online? Maybe you make handcrafted candles, perhaps you sell delicious pineapples?</p>

	<p><i>Well that's easy, there's eBay, Etsy, Gumtree.. the possibilities are endless.</i></p>

	<p>Okay, but what if you wanted your own actual store?</p>

	<p><i>Website builders! Squarespace, Shopify, Wordpress - ever heard of those?</i></p>

	<p>Now, I'm pretty fond of Squarespace, and often advise people to use Squarespace when they ask me to build their website. But, when I do suggest this, I usually get the same responses:</p>
	<ul>
		<li><b>"Its too expensive":</b> not wrong, it has some pretty hefty monthly fees. Especially if you want to sell stuff.</li>
		<li><b>"This is too confusing, can't you build just build a website for me in Squarespace?":</b> well yes, but that kind of defeats the point.</li>
	</ul>

	<p>Website builders are actually quite overwhelming. To the inexperienced, their UI looks like the controls of a spaceship, and their endless settings, templates and features can almost be as daunting as coding.</p>

	<p>I wanted to solve this problem; to let any person setup an online store (for free), no matter their technical expertise. So I decided to build <a href="https://oneitem.store/" target="_blank">One Item Store</a>.</p>

	<img src="https://i.gyazo.com/08ba2bfdd65518d0f9467b74de26cce4.png" alt="one item store homepage">

	<h2>Build</h2>

	<p>I'm not going to lie, building One Item Store was a massive slog. The goal was to build a fully usuable online store builder. At first I thought: "Well hey, guess I just need a way to accept some payments for my users, EZ - project over, next project please". Oh, how naive I was.</p>

	<p>But anyway, this project once again spanned two weeks (oops). Let's rewind.</p>

	<h3>Week 1</h3><h4>(Monday - Wednesday): Failing &amp; Planning</h4>

	<p>After finsihing up my last project, the <a href="https://tinyprojects.dev/projects/battle_royale" target="_blank">8-bit Battle Royale</a>, I instantly started thinking about my next project: An AI that trades Crypto.</p>

	<p>As you can see, that didn't end up going too well. Long story short, I wasn't able to get API keys on time. Therefore, I moved onto the next item on my list: a tiny e-commerce builder. </p>

	<p>I started this project by just buying the domain name <a href="https://oneitem.store/" target="_blank">oneitem.store</a>. I'm not sure why, but spending some money on a project early on makes it more real for me. It gives me motivation (and .store domain names are pricey, so I needed to make my money back).</p>

<!-- 	<img src="https://i.gyazo.com/2b0871b6078394d819de4681e98e19a2.png" alt="oneitem.store domain name on website"/> -->

	<h3>(Thursday - Friday): Store Builder</h3>

	<img src="https://i.gyazo.com/2cf40d9389db8f8b1a529403b2e59d99.gif" alt="one item store storebuilder">

	<p>Time to begin coding. One Item Store is built in Angular, so when it came to creating a store builder, I made use of two-way binding to make it seem like live updates were happening to the website.</p>

	<p>The goal was to make the user put in as little effort as possible, so I only asked for absolute essential information, namely: Item Name, Item Description, and Item Price. I then included some fields for uploading images, as I guess you probably want to see what you're buying too.</p>

	<h3>(Saturday - Sunday): Store Designs</h3>

	<img src="https://i.gyazo.com/964934a6d7c7d1b4f0e2bf3bfcdf695f.gif" alt="change one item store design gif">

	<p>No need to drag and drop elements to create your store, in One Item Store there are two beautiful designs to choose from. You heard me, 2!</p>

	<p>In all seriousness, I only had time to create two very simple styles: "Minimal" and "Dark Minimal". They're basic, but get the job done for a single page shop. This is an area where I can just pump out new designs quite easily in the future, and will give One Item Store a bit more of an appeal.</p>

	<h3>Week 2</h3><h3>(Monday - Tuesday): Payments</h3>

	<img src="https://i.gyazo.com/265a10574b825acb83c0d1f05e0ce2c2.png" alt="one item store payments">

	<p>Let's make some money. I needed some way for users of One Item Store to get paid when they sell their stuff on their shop. For this, I opted for Stripe.</p>

	<p>In particular, I used Stripe Connected Express Accounts. This is what services like Uber, Airbnb and Lyft use to pay their workers. Essentially, its a fast way for me to pay store owners when they make a sale on One Item Store. It also allows me to set fees so I can get a slice of every transaction.</p>

	<p>Below is the first live payment that went through my system. I bought a virtual pineapple off myself.</p>

	<img src="https://i.imgur.com/6TgMxly.png" alt="first one item store live payment">

	<h3>(Wednesday - Thursday): Order Dashboard</h3>

	<img src="https://i.gyazo.com/2090e4fc64383baf780d7ccfe30c1b07.gif" alt="one item store order dashboard">

	<p>How are my store owners going to manage the hundreds of sales they're going to receive through their One Item Store? Well, they needed an Order Dashboard.</p>

	<p>I'm really happy with how this turned out (in a minimalist, geeky way). The user can see all the orders they've received from their store, and click through to see the customer who purchased a specific order. Once the order is shipped, then the user can tag it as fulfilled.</p>

	<h3>(Friday - Saturday): Email Notifications</h3>

	<img src="https://i.imgur.com/gB153Ra.png" alt="email notification from one item store">

	<p>The final piece of the puzzle to making this a legitamate online store platform was some way for store owners to get notified when they made a sale, and buyers to get emails about the status of their order.</p>

	<p>For this I used nodemailer, which was really painful to set up with a Gmail account.</p>

	<h3>(Sunday): Launch</h3>

	<img src="https://i.gyazo.com/ce2b59cf0f43437ae66921215ebad721.gif" alt="custom domain names">

	<p>One Item store was ready to role. As a final touch I added custom domain names, so people could have their own unique links that they could share.</p>

	<h2>Challenges</h2>

	<p>This project had quite a few technical challenges, most notibly was getting payments working in Firebase Functions. However, it also had some meta-challenges.</p>

	<p>The final third of the project was, and not really sure how to put this, quite boring.</p>

	<p>Don't get me wrong, I'm happy with the final product, I think its actually really cool. But building it.. it was just a bit boring. There were lots of bugs, and I started to get a bit burnt out thinking about the endless list of things required for a good online store builder.</p>

	<p>But anyway, this is the whole point of Tiny Projects - trying out these ideas, seeing which ones are exciting, and sticking with the best ones.</p>

	

	<h2>Monetization</h2>

	<p>Let me tell you a little secret, One Item Store may have no monthly costs, but for every sale I've set it to take a 1% cut - gasp! I've never operated a fee-taking business, but I'm genuinely excited to see if I can make a few cents off this.</p>

	<h2>Conclusion</h2>

	<p>The past two weeks I successfully managed to build my own tiny online e-commerce platform. Like I mentioned, this didn't turn out to be the funnest project to work on, but I'm still really glad I saw it through.</p>

	<p>It's been a month since my first blog post "Tiny Websites Are Great" went viral on Hacker News. Since then I have gained 400 twitter followers and 287k page views on this website. Thanks for all your support - who knows where we'll be by next month!</p>

	<p>Next week I'm actually going to try and build a bot that trades crypto.</p>

	<p>There's also a sparkly new email subscription button below this text if you want to be notified via email about new projects.</p>

	
	
	
	
	
	

</div>]]>
            </description>
            <link>https://tinyprojects.dev/projects/one_item_store</link>
            <guid isPermaLink="false">hacker-news-small-sites-23610389</guid>
            <pubDate>Tue, 23 Jun 2020 06:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seamfulness: A UI/UX paradigm that prioritizes intuition over seamlessness]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23610227">thread link</a>) | @latc
<br/>
June 22, 2020 | https://4thquadrant.io/articles/transformations/beautiful-seamfulness-the-new-ui-ux-paradigm/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/articles/transformations/beautiful-seamfulness-the-new-ui-ux-paradigm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_28_4f9">

<div>
<p>The automotive is one of the few products that’s prioritised both form and function since its inception. From the over-styled design of the 59’Cadillac to teslas today you’ll be hard pressed to find a buyer that doesn’t have specific expectations for both design and efficiency. Alternatively in the tech space, function has been king for the most part – at times, a no-frill prioritisation of function over form was the perceptively superior strategy. But product development is changing, not only in favour of a preference for form but toward entirely new modes of design experience.&nbsp;</p>



<p>If we think about experience in the human context, it’s very multi-dimensional. Something as simple as listening to music is actually the physical stimulation of hair cells in the cochlea translating into electrical signals that trigger the release of dopamine. Similarly choosing to paint requires neural messages travelling from the brain to the fingers, optical nerves translating colour, and mental cognition deciphering form. All these things happen simultaneously in a heartbeat, a fluid transition from internal cognition to external action. Consumers increasingly want product design that creates experiences of a similar breed, an intuitive extension of our intentions. As form moves into a more central role in product development, changing expectations are setting a new bar for the UI/UX paradigm.</p>



<p>This refocus on form isn’t an overnight revelation though, it’s the latest step in a series of steps that have defined digital product development over the last two decades. As product developers sought to meet customer needs, there has been a process of prioritisation that loosely follows a focus on primary functions, followed by augmented functions and now finally form. If we were to oversimplify this otherwise interconnected process it may look something like this:</p>



<p><strong>1 – Horizontal scaling of functionality:</strong> essentially creating and optimising all of the core offerings of a product type – for example, what are the fundamentals the tool should offer to appeal to customers&nbsp;</p>



<p><strong>2 – Vertical scaling of functionality:</strong> this meant adding features and nuanced elements to each major point of functionality – the moving parts that made the tool more complex and capable so it could remain competitive in an increasingly saturated product category&nbsp;</p>



<p><strong>3 – Refocused scaling of form: </strong>as we reach an upper bound on the horizontal and vertical scaling of primary and augmented&nbsp; functions, design and experience USPs offer the next stage of growth for products as well as users – how well users are able to interact with the tool and therefore how well the tool retains customers in a saturated market</p>



<p>Most products today optimise their form within the parameters of the predominant UI/UX philosophy – the seamless experience. The seamless philosophy has been around long enough to pervade our consumer habits – this is something I noticed acutely a few months ago as I was shuffling between a few workplace/productivity tools trying to land on the best one. What struck me was the ease with which I was discarding several options, if a tool had caused me even a moment of cognitive expense – poor navigation or non-intuitive features – I swiftly discarded it. This is the pace and expectation with which today’s consumers make decisions – “how seamless is my experience?”.&nbsp;</p>



<h3>Seamless Experience: the decision creation and concealment loop</h3>



<p>If we trace back to the origins of this paradigm, we can see that the seamless experience was created to offset the rampant creation of decision points in increasingly complex products. I like to think of it as a compounding loop of decision creation and concealment.&nbsp;</p>



<ol><li><strong>Increase in the number of products and features:</strong> As the number of products and product features exploded across the market, product developers appended more and more moving parts to their core offering.&nbsp;</li><li><strong>Increase in number of seams</strong>: As developers stitched all the sub-components into a cohesive system, more seams emerged. While more choice is good, decision making is hard.&nbsp;</li><li><strong>Finding a balance: </strong>To preserve the benefit of increasingly complex and capable products (choice) without the pitfalls (decision friction) developers have and continue to aspire to a seamless, ultra-convenient user experience.&nbsp;</li><li><strong>Repeat:</strong> as convenience is restored, developers are free to continue adding complexity and choice, only to repeat the process</li></ol>



<p>The seamless model has served us well up to this point and will probably continue to do so for the foreseeable future, but in a time when competition is finally turning toward form as the next phase of growth, frontrunners are more likely to seek out&nbsp; ‘new’ modes of experience to create defensible USPs.&nbsp;</p>



<h3>Seamful experience: literally visible but effectively invisible</h3>



<p>These new modes of experience should add value to the user, equal to or greater than the ease of the seamless paradigm – while further convenience is one way to go, it may not lead to the ‘edge’ product developers are looking for. Here it might be useful for design (once again) to draw from the lessons of nature. What stood out in the experiences of listening to music or painting was the fluidity with which multiple sub-components of the human body interacted with one another. It indicated that on a subconscious level we are trained to inherently understand the points of interaction between our brain’s cognition and our motor functions – we know where the seams are and how to manipulate them. The power in being able to manipulate the seams creates an elevated experience, one that emulates the ease of a seamless experience with the added power of control. Where seams help you identify how any one element interacts with the broader environment, the knowledge of ‘beautiful seams’ could become invaluable to the user experience.&nbsp;</p>



<h3>Notion: a case of seamfulness in productivity&nbsp;</h3>



<p>If I circle back to my experience with productivity tools, it’s easy to understand why a seamful design could very well be the next definitive phase of UI/UX. If you’re not already familiar with it, Notion is a $2 billion workspace application that’s pulled away in a saturated productivity market – it’s also the tool that I landed on after exploring several options. Notion allows users to build individual workspaces as well as collaborative workflows specific to user needs, largely built on a foundation of modular features that can be moved, manipulated and customised. Where a more rigid, default workflow application like Trello would look largely similar for users across the world, functionalities in Notion could potentially look very different for two people sitting across from each other in the same room.&nbsp;</p>



<p>In Notion, design and function are inextricably linked and it gives users the power to manipulate the seams rather than concealing them in favour of default settings or templates. Notion’s design transitions its users to a stage of inherently fluid interaction, through using it I’ve intuitively learnt what kind of data requires which modules to work most effectively. This is the perfect example of how seamful design creates “literally visible but effectively invisible” seams – elevating the experience beyond ease.&nbsp; As consumers increasingly seek a more nuanced experience, seamful design could act as the growth stimulant product developers are looking for in our current phase (3- refocused scaling of form). And If It’s any indication of the potential in seamful UI/UX design, Notion’s 1 million user base in 2019 has <a href="https://www.nytimes.com/2020/04/01/technology/notion-startup-fund-raising.html" target="_blank" rel="noreferrer noopener">grown</a> to more than four times that size in a matter of months.&nbsp;</p>



<h3>The spectrum: seamless to seamful</h3>



<p>As this transformation takes course, businesses can place themselves along a spectrum of seamless to seamful, some business models benefiting more from seamful design than others.&nbsp;</p>



<p><strong>The seamless end:</strong> applications that design for the lowest common denominator, they will&nbsp; continue to optimise for convenience and seamlessness&nbsp;</p>



<p><strong>The seamful end:</strong> extensive visibility/access to seams that cater to a more nuanced experience</p>



<p>Despite the concept of seamful design floating around for a while now, it’s likely that a refocus on form and design will push it into more mainstream UI/UX philosophy. But there have been instances where ‘seamful’ design has naturally crept into our lives and the products we interact with the most – perhaps too subtle to have noticed.&nbsp; The initial facebook platform was an example of a seamless application, it seamlessly integrated static social interaction with your network (the feed) and live social interactions with your closest friends (messenger). As users naturally showed an inclination toward the chat feature Facebook saw value in spinning the Messenger app into a standalone platform allowing users to experience ‘live’ interactions in silo. As much as the messenger app remains a seamless one, it acts as a pronounced seam of the Facebook ecosystem – a separate mode of experience now capturing its own value as the second largest messaging platform in the world with 1.3 billion monthly active users.&nbsp;</p>



<p>In the coming decade, we could see products allowing third party developers and/or users to create seams (different modes of experience) that add to the applications’ core functionality. This could lead to greater UI/UX innovation – moving beyond just night-mode functions and customised skins to create truly unique, defensible user experiences.&nbsp;</p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/articles/transformations/beautiful-seamfulness-the-new-ui-ux-paradigm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23610227</guid>
            <pubDate>Tue, 23 Jun 2020 05:32:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discovering Symbolic Models from Deep Learning with Inductive Biases]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23609989">thread link</a>) | @hardmaru
<br/>
June 22, 2020 | https://astroautomata.com/paper/symbolic-neural-nets/ | <a href="https://web.archive.org/web/*/https://astroautomata.com/paper/symbolic-neural-nets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        </header>
      

      <section itemprop="text">
        
        <p><a href="https://arxiv.org/abs/2006.11287">Paper</a>
<a href="https://github.com/MilesCranmer/symbolic_deep_learning">Code</a>
<a href="https://colab.research.google.com/github/MilesCranmer/symbolic_deep_learning/blob/master/GN_Demo_Colab.ipynb">Interactive Notebook</a></p>

<p>Paper authors: Miles Cranmer, Alvaro Sanchez-Gonzalez, Peter Battaglia, Rui Xu, Kyle Cranmer, David Spergel, Shirley Ho</p>



<p>At age 19, I read an <a href="https://blogs.scientificamerican.com/cross-check/troublemaker-lee-smolin-says-physics-8211-and-its-laws-8211-must-evolve/">interview</a> of physicist Lee Smolin. One quote from the article would shape my entire career direction:
<!--<b>Horgan</b>: Do you—or did you ever--believe in a final theory of physics, as defined by Stephen Hawking?  <br>--></p>
<blockquote>
... let’s focus on quantum theory and relativity and their relation; if we succeed it will take generations to sort out the ramifications. We are still engaged in finishing the revolution Einstein started. This is, not surprisingly, a long process.
</blockquote>
<p>This statement disturbed me. The idea that a foreseeable limit exists on our understanding of physics by the end of my life was profoundly unsettling. I felt frustrated that I might never witness solutions to the great mysteries of science, no matter how hard I work.</p>

<p>But… perhaps one can find a way to tear down this limit. Artificial intelligence presents a new regime of scientific inquiry, where we can automate the research process itself. In automating science with computation, we might be able to strap science to Moore’s law and watch our knowledge grow exponentially rather than linearly with time.</p>

<h2 id="when-does-a-model-become-knowledge">When does a model become knowledge?</h2>

<p>To automate science we need to automate knowledge discovery. However, when does a machine learning model become knowledge? Why are Maxwell’s equations considered a fact of science, but a deep learning model just an interpolation of data? For one, deep learning doesn’t generalize near as well as symbolic physics models. Yet there also seems to exist something that makes simple symbolic models uniquely powerful as descriptive models of the world. The origin of this connection hides from our view:</p>
<blockquote>
<p>
The miracle of the appropriateness of the language of mathematics for the formulation of the laws of physics is a wonderful gift which we neither understand nor deserve. We should be grateful for it and hope that it will remain valid in future research and that it will extend, for better or for worse, to our pleasure, even though perhaps also to our bafflement, to wide branches of learning.
</p>
<p>—Eugene Wigner, <a href="https://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html"><em>The Unreasonable Effectiveness of Mathematics in the Natural Sciences</em></a></p>
</blockquote>
<p>From a pure machine learning perspective, symbolic models also boast many advantages: they’re compact, present explicit interpretations, and generalize well. “<em>Symbolic regression</em>” is one such machine learning algorithm for symbolic models: it’s a supervised technique that assembles analytic functions to model a dataset. However, typically one uses genetic algorithms—essentially a brute force procedure as in <a href="https://science.sciencemag.org/content/324/5923/81.abstract">Schmidt &amp; Lipson (2009)</a>—which scale poorly with the number of input features. Therefore, many machine learning problems, especially in high dimensions, remain intractable for traditional symbolic regression.</p>

<table>
  <thead>
    <tr>
      <th>
		<img src="https://astroautomata.com/assets/images/gp_symbolic_regression.gif" alt="" width="600">
	  </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Symbolic regression using a genetic algorithm. A binary tree of operators and variables represents an equation. Mutations and crossovers iterate on and combine the best models. <a href="https://www.computer.org/csdl/journal/tb/2018/01/07707365/13rRUwhHcPr">Source</a>.</em></td>
    </tr>
  </tbody>
</table>

<p>On the other hand, deep learning proves extraordinarily efficient at learning in high-dimensional spaces, but suffers from poor generalization and interpretability. So, does there exist a way to combine the strengths of both?</p>

<h2 id="method">Method</h2>

<p>We propose a technique in our <a href="https://arxiv.org/abs/2006.11287">paper</a> to do exactly this. In our strategy, the deep model’s job is not only to predict targets, but to do so while broken up into small internal functions that operate on low-dimensional spaces. Symbolic regression then approximates each internal function of the deep model with an analytic expression. We finally compose the extracted symbolic expressions to recover an equivalent analytic model. This can be restated as follows:</p>

<ol>
  <li>Design a deep learning model with a separable internal structure and inductive bias motivated by the problem.</li>
  <li>Train the model end-to-end using available data.</li>
  <li>While training, encourage sparsity in the latent representations at the input or output of each internal function.</li>
  <li>Fit symbolic expressions to the distinct functions learned by the model internally.</li>
  <li>Replace these functions in the deep model by the equivalent symbolic expressions.</li>
</ol>

<p>In the case of interacting particles, we choose <a href="https://arxiv.org/abs/1806.01261">“<em>Graph Neural Networks</em>” (GNN)</a> for our architecture, since the internal structure breaks down into three modular functions which parallel the physics of particle interactions. The GNN’s “message function” is like a force, and the “node update function” is like Newton’s law of motion. The GNN has also found success in many physics-based applications.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://astroautomata.com/assets/images/graphnet_experiments_v3.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>An illustration of the internal structure of the GNN we use in some of our experiments. Note that unlike Newtonian mechanics, the messages form high-dimensional latent vectors, the nodes need not represent physical particles, the edge and node model learn arbitrary functions, and the output need not be an updated state.</em></td>
    </tr>
  </tbody>
</table>

<p>By encouraging the messages in the GNN to grow sparse, we lower the dimensionality of each function. This makes it easier for symbolic regression to extract an expression.</p>

<h2 id="experiments">Experiments</h2>

<p>To validate our approach, we first generate a series of N-body simulations for many different force laws in two and three dimensions.</p>

<table>
  <thead>
    <tr>
      <th>
		<img width="600" alt="" src="https://astroautomata.com/assets/images/particle_animate.png" id="particleImage">
      </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      
      <td><em>A gif showing various N-body particle simulations used in our experiments.</em></td>
    </tr>
  </tbody>
</table>

<p>We train GNNs on the simulations, and attempt to extract an analytic expression from each. We then check if the message features equal the true force vectors. Finally, we see if we can recover the force law without prior knowledge using symbolic regression applied to the message function internal to the GNN. This is summarized in the image below.</p>

<table>
  <thead>
    <tr>
      <th>
		<img src="https://astroautomata.com/assets/images/advanced_screenshot.png">
      </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>A diagram showing how we combine a GNN and symbolic regression to distill an analytic expression.</em></td>
    </tr>
  </tbody>
</table>

<p>The sparsity of the messages shows its importance for the easy extraction of the correct expression. If one does not encourage sparsity in the messages, the GNN seems to encode redundant information in the messages. This training procedure over time is visualized in the following video, showing that the sparsity encourages the message function to become more like a force law:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/2vwwu59RPL8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><em>A video of a GNN training on N-body simulations with our inductive bias.</em></p>

<h2 id="knowledge-discovery">Knowledge Discovery</h2>

<table>
  <thead>
    <tr>
      <th><img src="https://astroautomata.com/assets/images/quijote.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>The <a href="https://github.com/franciscovillaescusa/Quijote-simulations">Quijote Dark Matter simulations</a> which we use as a dataset for our GNN.</em></td>
    </tr>
  </tbody>
</table>

<p>Finally, we apply our approach to a real-world problem: dark matter in cosmology. Cosmology studies the evolution of the Universe from the Big Bang to the complex structures like galaxies and stars that we see today. The interactions of various types of matter and energy drive this evolution, though dark matter alone consists of ~85% of the total matter in the Universe (<a href="https://iopscience.iop.org/article/10.1086/377226/meta">Spergel et al., 2003</a>). Dark matter spurs the development of galaxies. Dark matter particles clump together and act as gravitational basins called “dark matter halos” which pull regular baryonic matter together to produce stars, and form larger structures such as filaments and galaxies. An important challenge in cosmology is to infer properties of dark matter halos based on their “environment”— the nearby dark matter halos. Here we study the problem: how can we predict the excess amount of matter, , in a halo  using only its properties and those of its neighbor halos?</p>

<p>We employ the same GNN model as before, only now we predict the overdensity of a halo instead of the instantaneous acceleration of particles. Each halo has connections (edges) in the graph to all halos within a 50 <a href="https://en.wikipedia.org/wiki/Parsec#Megaparsecs_and_gigaparsecs">Mpc/h</a> radius. The GNN learns this relation accurately, beating the following hand-designed analytic model:</p>



<p>where  is position,  is mass, and  are constants.</p>

<p>Upon inspection, the messages passed within this GNN only possess a single significant feature, meaning that the GNN has learned it only needs to sum a function over neighbors (much like the hand-designed formula). We then fit the node function and message function, each of which output a scalar, and find a new analytic equation to describe the overdensity of dark matter given its environment:</p>



<p>This achieves a mean absolute error of 0.088, while the hand-crafted analytic equation only gets 0.12. Remarkably, our algorithm has discovered an analytic equation which beats the one designed by scientists.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://astroautomata.com/assets/images/discovering_symbolic_eqn_gn.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>An illustration of how our technique learns a symbolic expression: first, a neural network undergoes supervised learning, then, symbolic regression approximates internal functions of the model.</em></td>
    </tr>
  </tbody>
</table>

<h2 id="generalization">Generalization</h2>

<p>Given that symbolic models describe the universe so accurately, both for core physical theories and empirical models, perhaps by converting a neural network to an analytic equation, the model will generalize better. This is in some sense a prior on learned models.</p>

<p>Here we study this on the cosmology example by masking 20% of the data: halos which have . We then proceed through the same training procedure as before. Interestingly, we obtain a functionally identical expression when extracting the formula from the graph network on this subset of the data. Then, we compare how well the GNN and symbolic expression generalize. The graph network itself obtains an average error of 0.0634 on the training set, and 0.142 on the out-of-distribution data. Meanwhile, the symbolic expression achieves 0.0811 on the training set, but 0.0892 on the out-of-distribution data. Therefore, for this problem, it seems a symbolic expression generalizes much better than the very graph neural network it was extracted from. This alludes back to Eugene Wigner’s article: the language of simple, symbolic models effectively describes the universe.</p>

<!--[HTML version](/data/symb_gn2.html)-->

<!--[arXiv:]()-->


        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://astroautomata.com/paper/symbolic-neural-nets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23609989</guid>
            <pubDate>Tue, 23 Jun 2020 04:40:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cheap tricks for high-performance Rust]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23609434">thread link</a>) | @O_H_E
<br/>
June 22, 2020 | https://deterministic.space/high-performance-rust.html | <a href="https://web.archive.org/web/*/https://deterministic.space/high-performance-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>So you’re writing Rust but it’s not fast enough?
Even though you’re using <code>cargo build --release</code>?
Here’s some small things you can do to increase the runtime speed of a Rust project
– practically without changing any code!</p>

<p>Please remember that the following suggestions <strong>do not</strong> replace actual profiling and optimizations!
I also think it goes without saying that the only way to detect if any of this helps
is having benchmarks that represent how your application behaves under real usage.</p>

<h2 id="tweaking-our-release-profile">Tweaking our <code>release</code> profile</h2>

<p>Let’s first of all enable some more optimizations
for when we do <code>cargo build --release</code>.
The deal is pretty simple:
We enable some features that make building release builds even slower
but get more thorough optimizations as a reward.</p>

<p>We add the flags described below to our main <code>Cargo.toml</code> file,
i.e., the top most manifest file in case you are using a <a href="https://doc.rust-lang.org/1.41.1/book/ch14-03-cargo-workspaces.html">Cargo workspace</a>.
If you don’t already have a section called <code>profile.release</code>, add it:</p>



<h3 id="link-time-optimization">Link-time optimization</h3>

<p>The first thing we’ll do is enable <a href="https://llvm.org/docs/LinkTimeOptimization.html">link-time optimization</a> (LTO).
It’s a kind of whole-program or inter-module optimization as it runs as the very last step
when linking the different parts of your binary together.
You can think of it as allowing
better inlining across dependency boundaries
(but it’s of course more complicated that that).</p>

<p>Rust can use multiple linker flavors,
and the one we want is “optimize across all crates”, which is called “fat”.
To set this, add the <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#lto"><code>lto</code></a> flag to your profile:</p>



<h3 id="code-generation-units">Code generation units</h3>

<p>Next up is a similar topic.
To speed up compile times, Rust tries to split your crates into small chunks
and compile as many in parallel as possible.
The downside is that there’s less opportunities for the compiler
to optimize code across these chunks.
So, let’s <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#codegen-units">tell it</a> to do one chunk per crate:</p>



<h3 id="setting-a-specific-target-cpu">Setting a specific target CPU</h3>

<p>By default, Rust wants to build a binary that works on as many machines
of the target architecture as possible.
However, you might actually have a pretty new CPU with cool new features!
To <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#target-cpu">enable</a> those, we add</p>



<p>as a “Rust flag”,
i.e. the environment variable <code>RUSTFLAGS</code>
or the target’s <code>rustflags</code> field in your <a href="https://doc.rust-lang.org/1.41.1/cargo/reference/config.html"><code>.cargo/config</code></a>.</p>

<h3 id="aborting">Aborting</h3>

<p>Now we get into some of the more unsafe options.
Remember how Rust by default uses <a href="https://doc.rust-lang.org/1.41.1/nomicon/unwinding.html">stack unwinding</a>
(on the most common platforms)?
That costs performance!
Let’s skip stack traces and the ability to catch panics
for reduced code size and better cache usage:</p>



<p>Please note that some libraries might depend on unwinding
and will explode horribly if you enable this!</p>

<h2 id="using-a-different-allocator">Using a different allocator</h2>

<p>One thing many Rust programs do is allocate memory.
And they don’t just do this themselves but actually use an (external) library for that:
an allocator.
Current Rust binaries use the default system allocator by default,
previously they included their own with the standard library.
(This change has lead to smaller binaries and better debug-abiliy
which made some people quite happy).</p>

<p>Sometimes your system’s allocator is not the best pick, though.
Not to worry, we can change it!
I suggest giving both <a href="https://github.com/jemalloc/jemalloc">jemalloc</a> and <a href="https://github.com/microsoft/mimalloc">mimalloc</a> a try.</p>

<h3 id="jemalloc">jemalloc</h3>

<p><a href="https://github.com/jemalloc/jemalloc">jemalloc</a> is the allocator that Rust previously shipped with
and that the Rust compiler still uses itself.
Its focus is to reduce memory fragmentation and support high concurrency.
It’s also the default allocator on FreeBSD.
If this sounds interesting to you, let’s give it a try!</p>

<p>First off, add the <a href="https://docs.rs/jemallocator"><code>jemallocator</code></a> crate as a dependency:</p>

<div><div><pre><code><span>[dependencies]</span>
<span>jemallocator</span> <span>=</span> <span>"0.3.2"</span>
</code></pre></div></div>

<p>Then in your applications entry point (<code>main.rs</code>),
set it as the global allocator like this:</p>

<div><div><pre><code><span>#[global_allocator]</span>
<span>static</span> <span>GLOBAL</span><span>:</span> <span>jemallocator</span><span>::</span><span>Jemalloc</span> <span>=</span> <span>jemallocator</span><span>::</span><span>Jemalloc</span><span>;</span>
</code></pre></div></div>

<p>Please note that jemalloc doesn’t support all platforms.</p>

<h3 id="mimalloc">mimalloc</h3>

<p>Another interesting alternative allocator is <a href="https://github.com/microsoft/mimalloc">mimalloc</a>.
It was developed by Microsoft, has quite a small footprint,
and some innovative ideas for free lists.</p>

<p>It also features configurable security features
(have a look at <a href="https://github.com/purpleprotocol/mimalloc_rust/blob/c6bf4578d3258a0b6a28696196ede6d50e5ee8c2/Cargo.toml#L25-L28">its <code>Cargo.toml</code></a>).
Which means we can turn them off more performance!
Add the <a href="https://docs.rs/mimalloc"><code>mimalloc</code> crate</a> as a dependency like this:</p>

<div><div><pre><code><span>[dependencies]</span>
<span>mimalloc</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.1.17"</span><span>,</span> <span>default-features</span> <span>=</span> <span>false</span> <span>}</span>
</code></pre></div></div>

<p>and, same as above, add this to your entry point file:</p>

<div><div><pre><code><span>#[global_allocator]</span>
<span>static</span> <span>GLOBAL</span><span>:</span> <span>mimalloc</span><span>::</span><span>MiMalloc</span> <span>=</span> <span>mimalloc</span><span>::</span><span>MiMalloc</span><span>;</span>
</code></pre></div></div>

<h2 id="profile-guided-optimization">Profile Guided Optimization</h2>

<p>This is a neat feature of LLVM
but I’ve never used it.
Please read <a href="https://doc.rust-lang.org/1.41.1/rustc/profile-guided-optimization.html">the docs</a>.</p>

<h2 id="actual-profiling-and-optimizing-your-code">Actual profiling and optimizing your code</h2>

<p>Now this is where you need to actually adjust your code
and fix all those <code>clone()</code> calls.
Sadly, this is a topic for another post!
(While you wait another year for me to write it, you can read about <a href="https://deterministic.space/secret-life-of-cows.html">cows</a>!)</p>

<p><strong>Edit:</strong> People keep asking for those actual tips on how to optimize Rust code.
And luckily <del>I tricked them</del> they had some good material for me to link to:</p>

<ul>
  <li>The very convenient <a href="https://github.com/flamegraph-rs/flamegraph"><code>cargo flamegraph</code></a> (also works as a standalone tool)</li>
  <li>Christopher Sebastian recently published <a href="https://likebike.com/posts/How_To_Write_Fast_Rust_Code.html">How To Write Fast Rust Code</a></li>
  <li>Jack Fransham’s <a href="http://troubles.md/posts/rustfest-2018-workshop/">Fastware Workshop</a> from RustFest 2018</li>
</ul>


  </div></div>]]>
            </description>
            <link>https://deterministic.space/high-performance-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23609434</guid>
            <pubDate>Tue, 23 Jun 2020 02:44:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Singapore's TraceTogether Token Teardown Time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23609339">thread link</a>) | @sohkamyung
<br/>
June 22, 2020 | https://rolandturner.com/2020/06/22/TraceTogether_Token_Teardown_Time | <a href="https://web.archive.org/web/*/https://rolandturner.com/2020/06/22/TraceTogether_Token_Teardown_Time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

<p>Singapore's Minister for Foreign Affairs and Minister-in-Charge of the Smart Nation Initiative — <a href="https://www.mfa.gov.sg/About-MFA/Organisation-Chart/Dr-Vivian-Balakrishnan">Vivian Balakrishnan</a> — invited several makers and open-source advocates to a session with <a href="https://www.tech.gov.sg/">GovTech</a> on Friday, during which a teardown of the first version of the <a href="https://www.tracetogether.gov.sg/">TraceTogether</a> token was performed. The purpose of the session included allowing us an opportunity to examine and learn about the token, and to propose improvements.</p>

<p>The need to protect the integrity of an in-progress <a href="https://www.tech.gov.sg/media/media-releases/2020-06-16-tracetogether-token-media-statement">limited tender</a> process for the second batch of tokens meant that there were tight limits on what could be disclosed to us, so this post is very much an initial view. Even allowing for that, the opportunities to learn some things about the token, to advocate improvements, and to publish some details of what we learned were worthwhile. A hackathon to permit developing open     firmware for the tokens is proposed after the tender closes on June 30; if that goes ahead then full technical details will need to be made public in which case I'll be able to expand on this post.</p>

<p>Some highlights:</p>

<ul>
<li>I can state with reasonable confidence that the token contains only the components reasonably necessary to provide contact tracing assistance similar to that provided by the TraceTogether app. In particular, there is no GPS receiver or anything of that type.</li>
<li><strong>The token will not need recharging!</strong> Instead it is expected to operate for ~9 months on its internal battery. This is really impressive; I had taken regular charging for granted.</li>
<li>There is reason to believe that appropriate information security measures are in place.</li>
<li>Unfortunately the convenience of not having to recharge comes with an extraordinarily tight power budget, which in turn makes several of the things on my wishlist rather challenging. In particular, publication of the complete firmware source code seems unlikely. However, a challenge has been laid before the open community: <strong>Can we come up with token firmware that will do the job, safely, even if its source code is public?</strong></li>
</ul>



<p>(This section is quite long. Feel free to jump to <a href="#The_teardown_session">The teardown session</a> if you're in a great hurry, but I have been finding it necessary to explain the background to people in detail in order for them to make sense of my view of the token. I encourage you to read the whole thing.)</p>

<h2>Contact tracing</h2>

<p>A pillar of communicable disease control is the <a href="https://en.wikipedia.org/wiki/Contact_tracing">tracing of a patient's contacts</a>, so that both:</p>

<ul>
<li>those contacts themselves can be offered counselling, testing, protection from infection, and/or treatment; and</li>
<li>the public at large can be protected from those contacts if they're likely to be infectious, by placing them into a quarantine facility, requiring them to remain at home, or just excluding them from particularly high transmission-risk situations (e.g. large crowds).</li>
</ul>

<p>The contacts are usually identified by interviewing the patient about their movements during the period that they were likely to be infectious. This process is time-consuming, potentially stressful and — depending upon the nature of the disease and the patient's state of mind — likely to miss many relevant contacts.</p>

<h2>Bluetooth proximity detection as a contact tracing aid</h2>

<p>Where there are records available to help jog the patient's memory, their use is often helpful:</p>

<blockquote>
<p><em>Interviewer</em>: "OK, June 11. Did you leave your home at any time on that day?"</p>

<p><em>Patient</em>: "I really can't recall." </p>

<p><em>Interviewer</em>: "It looks as though you were near a large number of people between 20:10 and 22:45, does this ring any bells?"</p>

<p><em>Patient</em>: "Oh, yes, I went to the cinema at {location} to see {film} with {list of friends}."</p>
</blockquote>

<p>A team within GovTech realised that <a href="https://en.wikipedia.org/wiki/Bluetooth_Low_Energy#Proximity_sensing">Bluetooth proximity detection</a> implemented as a smartphone app could provide a useful tool to support this process, while maintaining strong privacy protections, so worked with Ministry of Health contact tracers to develop TraceTogether. In the example above, not only would it provide a prompt to jog the patient's memory, if epidemiological data indicated that sitting in a cinema containing an infectious person was a transmission risk then it would also provide the means to reach a large number of potentially exposed people whom the patient did not know. With or without TraceTogether, the contact tracer might also contact the cinema and seek contact information for other identifiable patrons who were seated nearby, or at list in the same room (those who paid by credit card, are part of a loyalty program, etc.), but those who paid cash for their tickets could not be identified this way.</p>

<p>There are two key points here:</p>

<ul>
<li>TraceTogether helps the contact tracer job the patient's memory in order to develop a more complete list of contacts.</li>
<li>TraceTogether helps the contact tracer make contact with potentially exposed people whom the patient does not know.</li>
</ul>

<p>In the meantime Singapore has developed the process still further, including getting the process from days down to hours, which materially reduces how much transmission an asymptomatic carrier can give rise to, backward-looking tracing (using antibody testing as the biological test, rather than PCR) to track all of a cluster, and proactive testing of contacts of contacts to further cut the time that asymptomatic carriers are infecting people.</p>

<h2>Centralised vs. decentralised</h2>

<p>One rather simplistic way to use smartphones to help contact tracers is to record location histories detected by the phone, and continually upload them to a health authority database. This is so obviously a bad idea that TraceTogether doesn't do it, but astonishingly, <a href="https://techcrunch.com/2020/06/15/norway-pulls-its-coronavirus-contacts-tracing-app-after-privacy-watchdogs-warning/">Norway's health authority did</a>, and didn't shut it down until their privacy regulator told them to!</p>

<p>At the other extreme is a situation in which the series of random phone-generated temporary identifiers transmitted during a patient's infectious period are uploaded and published after testing positive, and then checked by each user's phone to see whether it received any of those and to alert its user to get tested if it did. This has the great benefit that a malicious actor in government simply can't use the system to learn anything about a patient's contacts, but it also means that the system can't be used to support contact tracers in performing their work, meaning that many more cases go undetected so infection spreads further and faster. This is approximately how Apple/Google's <a href="https://en.wikipedia.org/wiki/Exposure_Notification">Exposure Notificaton</a> (EN) works.</p>

<p>TraceTogether is something of a hybrid:</p>

<ul>
<li>Detections are only uploaded after a person has tested positive in order to support the contact tracing interview. &gt;99.9% of detections never leave the phone.</li>
<li>The ability for contact tracers to reach out to contacts does require some means of initiating contact. The approach chosen was to register phone numbers. Push notifications are known to be problematic (the Australian government's COVIDSafe is derived from TraceTogether; their published <a href="https://www.health.gov.au/resources/publications/covidsafe-application-privacy-impact-assessment">Privacy Impact Assessment</a> addresses this in detail). Consequently a centralised contact database is difficult to avoid.</li>
</ul>

<p>This has led to some commentators referring to TraceTogether as a centralised system. I'd suggest that a more precise description is that it's a mostly-decentralised hybrid which includes <a href="https://en.wikipedia.org/wiki/Digital_contact_tracing#Reporting_centralization">centralised report processing</a>.</p>

<h2>Technical problems</h2>

<p>Neither Android nor iOS was designed with support for this sort of use in mind. By sheer happenstance, the app could be implemented efficiently on Android but not on iOS, because of the limits on Bluetooth access for apps running in a low power background mode on iOS. (I am not a mobile app developer, no doubt I don't have the specifics quite right, but that's the thrust of it.) The initial rollout of the app in Singapore therefore presented power and usability problems to iOS users, but still materially supported the contact tracing process.</p>

<p>Apple was approached and — skipping a few steps — jointly developed with Google an Exposure Notification capability that can be used solely by qualifying health authorities to develop efficient apps to help potentially exposed people discover the need to get tested. As I understand it, at the outset Apple was aiming to standardise contact tracing support, but somewhere along the way the approach shifted to one which simply enabled encouraging potentially exposed people to get tested without requiring that any information about people's contacts ever be exposed to government. If advising a potentially exposed person that they should get tested was the only important outcome of contact tracing then this might have been enough but, as above, this simply isn't true.</p>

<p>Given Apple's ongoing difficulties with governments demanding that it betray its customers by weakening its products (e.g. to make a compromised iOS to allow evidence to be extracted from phones without the owner's involvement), and the overlap of this idea with the usual <a href="https://en.wikipedia.org/wiki/Technolibertarianism">technolibertarian</a> fantasy of replacing all government with cryptographically-enabled technical systems, it is perhaps not a surprise that the idea took hold, but I suspect that the ultimate price for this will be a substantial loss of human life.</p>

<h2>71% coverage</h2>

<p>One of the problems with using Bluetooth proximity detection as a tool for inferring potential exposure is that its usefulness depends upon its level of adoption. A detection can only occur if both carrier and infected contact are both running the app, meaning that detection rate varies <a href="https://en.wikipedia.org/wiki/Quadratic_function">quadratically</a>, i.e. with the square of coverage:</p>

<ul>
<li>If there are just two users then the fraction of infections detected will be essentially zero.</li>
<li>If the entire population has adopted, then almost all infections will have corresponding Bluetooth detections.</li>
<li>However, if, say, 50% of the population has adopted, and assuming that adoption is uncorrelated with infection, then only 25% of infections will have a corresponding detection (i.e. 50% of 50%).</li>
</ul>

<p>This means that 71% coverage represents an interesting milestone (assuming uncorrelated adoption), as it's the point at which more exposures will be detected than will not …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rolandturner.com/2020/06/22/TraceTogether_Token_Teardown_Time">https://rolandturner.com/2020/06/22/TraceTogether_Token_Teardown_Time</a></em></p>]]>
            </description>
            <link>https://rolandturner.com/2020/06/22/TraceTogether_Token_Teardown_Time</link>
            <guid isPermaLink="false">hacker-news-small-sites-23609339</guid>
            <pubDate>Tue, 23 Jun 2020 02:24:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Download macOS 11 Big Sur Developer Beta]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23609203">thread link</a>) | @pat_moore
<br/>
June 22, 2020 | https://sizeof.cat/post/macos-11/ | <a href="https://web.archive.org/web/*/https://sizeof.cat/post/macos-11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><div><div id="content"><article><div><p><a href="https://sizeof.cat/post/macos-11/img/cover.jpg"><img src="https://sizeof.cat/post/macos-11/img/cover.jpg" alt="Apple macOS 11 Big Sur (and how to download it)"></a></p><p>Yesterday, <a href="https://www.apple.com/apple-events/june-2020/" rel="noreferrer">Apple announced</a> new versions of all their operating systems, including macOS 11 named “Big Sur”, which they describe as the biggest change to macOS since Mac OS X. Apple also announced the widely-expected macOS on ARM (or Apple Silicon as they’ve branded their chips). Apple will enable you to ship Universal binaries containing both ARM and Intel code (Universal 2 format), and support for Apple Silicon should simply require a recompile in Xcode for most apps if your third party libraries have been updated. They will also ship Rosetta 2, an emulator layer that allows you to run old applications on new Macs.</p><h2 id="release-date">Release date</h2><p>The release date for macOS 11 Big Sur is <strong>“Coming this fall”</strong> – <a href="https://apple.com/macos/big-sur-preview/" rel="noreferrer">link</a></p><h2 id="devices">Devices</h2><ul><li>iMac 2014+</li><li>iMac Pro 2017</li><li>Mac Pro 2013+</li><li>MacMini 2014+</li><li>MacBook 2015+</li><li>MacBook Air 2013+</li><li>MacBook Pro 2013+</li><li><del>MacBook Pro (mid 2012 &amp; Retina)</del>*</li><li><del>Mac mini (late 2012)</del>*</li><li><del>MacBook Air (mid 2012)</del>*</li><li><del>iMac (late 2012-2013)</del>*</li></ul><p><em>* not supported</em></p><h2 id="download">Download</h2><p>Backup your currnt macOS system using TimeMachine and beware that stuff might (WILL) break.</p><p>From Apple:</p><ul><li><del>App Store</del> – Unavailable until official public release.</li><li><a href="http://developer.apple.com/" rel="noreferrer">developer.apple.com</a> – You can download the new beta if you are a paid developer.</li><li><a href="https://beta.apple.com/sp/betaprogram/" rel="noreferrer">Apple Beta sign up program</a></li></ul><p>Or you can just enroll in the <code>DeveloperSeed</code> and skip the part where you need to have an Apple Developer Account:</p><div><pre><code data-lang="shell"><span># Enroll in Developer Beta</span>
$ sudo /System/Library/PrivateFrameworks/Seeding.framework/Versions/A/Resources/seedutil enroll DeveloperSeed
<span># or you can just force softwareupdate to use the DeveloperSeed catalog but beware that the ability to specify a custom catalog will be removed in a future release of macOS.</span>
<span># $ sudo /usr/sbin/softwareupdate --set-catalog https://swscan.apple.com/content/catalogs/others/index-10.16seed-10.16-10.15-10.14-10.13-10.12-10.11-10.10-10.9-mountainlion-lion-snowleopard-leopard.merged-1.sucatalog.gz</span>
<span># Check for updates</span>
$ sudo /usr/sbin/softwareupdate -l
<span># Open System Preferences -&gt; Software Update</span>
$ /usr/bin/open <span>"x-apple.systempreferences:com.apple.preferences.softwareupdate?client=bau"</span>
<span># or just force-download it.</span>
<span># $ sudo softwareupdate --fetch-full-installer --full-installer-version 10.16</span></code></pre></div><p><img src="https://sizeof.cat/post/macos-11/img/big-sur-beta.png" alt="macOS 11 Big Sur"></p><p><strong>NOTE</strong>: Yes, the download is mislabeled as 10.16 but it’s really macOS 11 beta.</p><p>To reset and unenroll:</p><div><pre><code data-lang="shell"><span># Enroll in Developer Beta</span>
$ sudo /System/Library/PrivateFrameworks/Seeding.framework/Versions/A/Resources/seedutil unenroll
<span># or you can reset softwareupdate catalog back to production</span>
<span># $ sudo softwareupdate --clear-catalog</span>
<span># Check for updates</span>
$ sudo /usr/sbin/softwareupdate -l
<span># Open System Preferences -&gt; Software Update</span>
$ /usr/bin/open <span>"x-apple.systempreferences:com.apple.preferences.softwareupdate?client=bau"</span></code></pre></div><p><img src="https://sizeof.cat/post/macos-11/img/catalina.png" alt="macOS 11 Big Sur"></p><h2 id="links">Links</h2><ul><li><a href="https://www.apple.com/macos/big-sur-preview/" rel="noreferrer">macOS 11 Big Sur</a></li><li><a href="https://www.apple.com/macos/big-sur-preview/features/" rel="noreferrer">macOS 11 Big Sur features</a></li><li><a href="https://developer.apple.com/design/human-interface-guidelines/macos/overview/whats-new-in-macos/" rel="noreferrer">Human Interface Guidelines</a></li><li><a href="https://www.apple.com/apple-events/june-2020/" rel="noreferrer">WWDC20 Keynote</a></li><li><a href="https://developer.apple.com/forums/" rel="noreferrer">Apple Developer forums</a></li><li><a href="https://developer.apple.com/documentation/xcode-release-notes/xcode-12-beta-release-notes" rel="noreferrer">Xcode 12 beta</a></li><li><a href="https://developer.apple.com/documentation/xcode-release-notes/xcode-12-for-macos-universal-apps-beta-release-notes" rel="noreferrer">Xcode 12 beta for macOS Universal Apps</a></li></ul></div><div><details open=""><summary>Meta</summary><p><span>author</span>
</p><p><span>license</span>
<span><a rel="license noopener" href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0</a></span></p><p><span>created</span>
<span>23 Jun 2020 01:11 +0000</span></p><p><span>tags</span>
<a href="https://sizeof.cat/tags/apple/">apple</a>, <a href="https://sizeof.cat/tags/macos/">macos</a>, <a href="https://sizeof.cat/tags/ios/">ios</a></p></details></div><div><details><summary>Webmentions</summary><h3>Manual submission</h3><div><p>Have you written a <a rel="noreferrer" href="https://indieweb.org/responses">response</a> to this post? Let me know the URL:</p></div><p>Below you can find the interactions that this page has had using <a rel="noreferrer" href="http://indieweb.org/webmention">WebMention</a>.</p></details></div></article></div></div></div></div>]]>
            </description>
            <link>https://sizeof.cat/post/macos-11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23609203</guid>
            <pubDate>Tue, 23 Jun 2020 01:58:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distributed Denial of Secrets]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23609077">thread link</a>) | @coronadisaster
<br/>
June 22, 2020 | https://ddosecrets.com/data/ | <a href="https://web.archive.org/web/*/https://ddosecrets.com/data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="chapter"><div id="body-inner"><p>Browse the sub-menu to the left to discover the various categories of data we hold.</p></div></div></div>]]>
            </description>
            <link>https://ddosecrets.com/data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23609077</guid>
            <pubDate>Tue, 23 Jun 2020 01:35:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust at CNCF]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23609069">thread link</a>) | @tabarr
<br/>
June 22, 2020 | https://www.cncf.io/blog/2020/06/22/rust-at-cncf/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/blog/2020/06/22/rust-at-cncf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="post-46335">

	<div>

		<div>
			
			
				<div>
					
										
					<p><em>Staff Post</em></p>
<p><a href="https://www.rust-lang.org/"><span>Rust</span></a><span> is a systems language originally created by </span><a href="https://insights.stackoverflow.com/survey/2019#technology-_-most-loved-dreaded-and-wanted-languages"><span>Mozilla</span></a><span> to power parts of its experimental </span><a href="https://servo.org/"><span>Servo</span></a><span> browser engine. Once highly experimental and little used, Rust has become dramatically more stable and mature in recent years and is now used in a wide variety of settings, from databases to operating systems to web applications and far beyond. And developers seem to really </span><a href="https://insights.stackoverflow.com/survey/2019#most-loved-dreaded-and-wanted"><span>love it</span></a><span>.</span></p>
<p><span>You may be surprised to find out that the venerable Rust has established a substantial toehold here at CNCF as well. In fact, two of our</span><a href="https://branding.cncf.io/#incubating-projects"> <span>incubating</span></a><span> projects, </span><a href="https://tikv.org/"><span>TiKV</span></a><span> and </span><a href="https://linkerd.io/"><span>Linkerd</span></a><span>, have essential components written in Rust and both projects would be profoundly different—and potentially less successful—in another language.</span></p>
<p><span>In this post, I’d like to shed light on how TiKV and Linkerd are contributing to the Rust ecosystem.</span></p>
<h2>TiKV</h2>
<p><a href="https://tikv.org/"><span>TiKV</span></a><span> is a distributed, transactional key-value database originally created by the company</span><a href="https://pingcap.com/"> <span>PingCAP</span></a><span>. Its core concepts are drawn from</span><a href="https://research.google/pubs/pub39966/"><span> the venerable </span><span>Google Spanner</span></a><span> and</span><a href="https://hbase.apache.org/"><span> Apache HBase</span></a><span> and it’s primarily used to provide lower-level key/value—the “KV” in “TiKV”—storage for higher-level databases, such as</span><a href="https://github.com/pingcap/tidb"> <span>TiDB</span></a><span>.</span></p>
<p><span>In addition to the</span><a href="https://github.com/tikv/tikv"> <span>core repo</span></a><span>, the TiKV project has contributed a number of libraries to the Rust ecosystem:</span></p>
<ul>
<li><a href="https://docs.rs/crate/grpcio/0.5.0-alpha.5"><span>grpc-rs</span></a><span>, a Rust wrapper for</span><a href="https://github.com/grpc/grpc"> <span>gRPC core</span></a><span>.</span></li>
<li><a href="https://github.com/tikv/raft-rs"><span>raft-rs</span></a><span>, a Rust implementation of the Raft consensus protocol. This is the consensus protocol used by TiKV as well as</span><a href="https://etcd.io/"> <span>etcd</span></a><span>, the distributed key-value store used by Kubernetes and a fellow CNCF project.</span></li>
<li><a href="https://github.com/tikv/fail-rs"><span>fail-rs</span></a><span>, for injecting “fail points” at runtime</span></li>
<li><a href="https://github.com/tikv/async-speed-limit"><span>async-speed-limit</span></a><span>, a library for asynchronously speed-limiting multiple byte streams</span></li>
<li><a href="https://github.com/tikv/rust-prometheus"><span>rust-prometheus</span></a><span>, a</span><a href="https://prometheus.io/"> <span>Prometheus</span></a><span> client for Rust that enables you to instrument your Rust services, i.e. to expose properly formatted metrics to be scraped by Prometheus.</span></li>
<li><a href="https://github.com/tikv/pprof-rs"><span>pprof-rs</span></a><span>, a CPU profiler that can be integrated into Rust programs. Enables you to create flame graphs of CPU activity and offers support for</span><a href="https://developers.google.com/protocol-buffers"> <span>Protocol Buffers</span></a><span> output.</span></li>
</ul>
<p><span>PingCAP’s blog has also featured some highly regarded articles on Rust, including </span><a href="https://pingcap.com/blog/rust-compilation-model-calamity"><span>The Rust Compilation Model Calamity</span></a> <span>and </span><a href="https://pingcap.com/blog/2017-09-26-whyrust"><span>Why did we choose Rust over Golang or C/C++ to develop TiKV?</span></a> <span>If you’re like me and excited about witnessing a new generation of databases written in Rust, you should really keep tabs on TiKV and its contributions to the Rust ecosystem.</span></p>
<h2>Linkerd</h2>
<p><a href="https://linkerd.io/"><span>Linkerd</span></a><span> is a service mesh that’s relentlessly focused on simplicity and user-friendliness. If you’ve ever felt frustrated or overwhelmed by the complexity of other service mesh technologies, I cannot recommend the breath of fresh air that is the Linkerd</span><a href="https://linkerd.io/2/getting-started/"> <span>Getting Started</span></a><span> guide more highly. And in case you missed it, Linkerd had a</span><a href="https://www.cncf.io/blog/2020/01/20/linkerd-2019-year-in-review/"> <span>huge 2019</span></a><span> and is continuing apace in</span><a href="https://github.com/linkerd/linkerd2/blob/master/CHANGES.md"> <span>2020</span></a><span>.</span></p>
<p><span>Arguably the most important component of Linkerd is its</span><a href="https://github.com/linkerd/linkerd2-proxy"> <span>service proxy</span></a><span>, which lives alongside your services in the same Kubernetes</span><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/"> <span>Pod</span></a><span> and handles </span><i><span>all</span></i><span> network traffic to and from the service. Services proxies are hard to write because they need to be fast, they need to be safe, and they need to have the smallest memory footprint that’s commensurate with speed and safety.</span></p>
<p><span>The Linkerd creators opted for Rust for the Linkerd service proxy. Why did they make this choice? I reached out to Linkerd co-creator</span><a href="https://twitter.com/olix0r"> <span>Oliver Gould</span></a><span> to provide the breakdown:</span></p>
<p><i><span>When we started building Linkerd ~5 years ago, some of our first prototypes were actually in Rust (well before the language hit 1.0). Unfortunately, at the time, it wasn’t mature enough for our needs, so Linkerd’s first implementation grew out of Twitter’s Scala ecosystem. As we were working on Linkerd 1.x, Rust’s</span></i><a href="https://tokio.rs/"> <i><span>Tokio</span></i></a><i><span> runtime started to take shape and was especially promising for building something like a proxy. So in early 2017 we set out to start rewriting Linkerd with a Go control plane and a Rust data plane. Tokio (with its sister projects,</span></i><a href="https://github.com/carllerche/tower-web"> <i><span>Tower</span></i></a><i><span> &amp;</span></i><a href="https://github.com/hyperium/hyper"> <i><span>Hyper</span></i></a><i><span>) made this all possible by extending Rust’s safe, correct memory model with asynchronous networking building blocks. These same building blocks are now being used in a variety of performance-sensitive use cases outside of Linkerd, and we’ve built a great community of contributors around both projects. If this is interesting to you, please come get involved!</span></i></p>
<p>In terms of contributions back to the Rust ecosystem, Linkerd has upstreamed core components to <a href="https://github.com/carllerche/tower-web">Tower</a> and <a href="https://github.com/tokio-rs/tokio">Tokio</a>, such as Linkerd’s load balancer and Tokio’s <a href="https://github.com/tokio-rs/tracing">tracing</a> module.</p>
<p><span>In addition, the project also undertook a security audit of the </span><a href="https://github.com/ctz/rustls"><span>rustls</span></a><span> library (sponsored by CNCF). As the name suggests, rustls is a transport security layer (TLS) library for Rust that’s used by the Linkerd proxy for its mutual TLS (mTLS) feature, which is crucial to the security guarantees that the Linkerd service mesh provides. You can see the result of the audit in </span><a href="https://github.com/ctz/rustls/raw/master/audit/TLS-01-report.pdf"><span>this PDF</span></a><span>. </span><a href="https://cure53.de/"><span>Cure53</span></a><span>, the firm responsible for security audits of several other CNCF projects, was “unable to uncover any application-breaking security flaws.” A sterling result if I say so myself!</span></p>
<h2>More to come?</h2>
<p><span>I’m a huge fan of Rust myself, though I’ve really only </span><a href="https://github.com/lucperkins/rust-graphql-juniper-actix-diesel-postgres"><span>dabbled</span></a><span> in it. I have my fingers crossed that TiKV and Linkerd are just the beginning and that we’ll see a whole lot more Rust in the cloud native universe, be that in the form of new CNCF projects written in Rust, existing projects porting components into Rust, or new Rust client libraries for existing systems.</span></p>
<p><span>And if you’re curious about </span><i><span>all</span></i><span> of the programming languages in use amongst CNCF’s </span><a href="https://www.cncf.io/projects/"><span>many projects</span></a><span>, stay tuned for an upcoming blog post on precisely that topic.</span></p>
						
				</div><!--/content-inner-->

						
		</div><!--/post-content-->

	</div><!--/inner-wrap-->
		
</article><!--/article-->

						   


					
			</div></div>]]>
            </description>
            <link>https://www.cncf.io/blog/2020/06/22/rust-at-cncf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23609069</guid>
            <pubDate>Tue, 23 Jun 2020 01:34:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Blog post on Portainer 2.0 and upcoming features]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23608687">thread link</a>) | @neilcresswell
<br/>
June 22, 2020 | https://www.portainer.io/2020/06/portainer-2-0-and-the-development-balancing-act/ | <a href="https://web.archive.org/web/*/https://www.portainer.io/2020/06/portainer-2-0-and-the-development-balancing-act/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
		<p>Over the coming weeks we will announce the availability of Portainer Community Edition 2.0. We expect to ship code mid Q3, however it’s always dangerous to announce a date too early.</p>
<p><strong><em>But before I talk about 2.0, I want to talk a bit about prioritization and decision making. </em></strong></p>
<p>We have limited resources at Portainer, and a list of feature requests and opportunities as long as Route 66. We must make priority decisions every day, and inevitably, someone somewhere gets upset because we haven’t delivered to their expectations. &nbsp;We know this, and it’s something that we don’t like to see happening, but we must work within our means.</p>
<p>The way we make decisions on requested functionality additions / fixes to Portainer is as follows:</p>
<ul>
<li>is this addressing a security vulnerability or potential exploit? if so, add it;</li>
<li>is this a feature that we feel would have wide appeal? if so, add it;</li>
<li>is this a feature that has at least 20 “thumbs up” or “hearts” inside Github? if so, add it;</li>
<li>is this a feature that would benefit professional users of Portainer? if so, add it.</li>
</ul>
<p>When there are feature requests / issues that exist only with a specific use cases, judged either by us or through a lack of community “thumbs up” then these sit “pending” until enough demand is identified for them (so don’t forget to thumbs up issues you care about). Also, it’s important to note that we don’t automatically maintain feature parity with Docker, so when they bring out new features in Docker CE, we evaluate each based on the 4 criteria above before deciding whether to add it to Portainer. With our current resources, we only add support for features we feel have real demand.</p>
<p><strong><em>So, what’s going to be in Portainer Community Edition 2.0…</em></strong></p>
<p>Of all the platforms Portainer supports, Docker and Docker Swarm are our fundamental roots; we would not be where we are today without what we built for these two underlying technologies, and as such, we plan to keep support for them as long as it makes sense. Lately though we have seen several issues opened with us relating to Swarm and these users are either hitting undocumented limitations in Swarm (eg 128 max ports exposed via Ingress) or known issues in Swarm that have been open and unresolved for 2+ years. This concerns us, as we cannot work around these issues in Portainer, so these issues/limitations become our issues/limitations too. We will be guided by our community on what features we need to continue to bring to Swarm deployments; we have our view and have collated a list of feature requests that meet our 4 criteria, and these will be added in the next 1-2 releases.</p>
<p>The biggest feature we will be adding to Portainer 2.0 is support for Kubernetes. We sat on the Kubernetes feature request for a long time as we struggled to come up with a simple UI/UX for it, but after cracking that nut late last year, we have advanced our development significantly. We want to add Kubernetes “without compromise”, and by that, what we mean is that we want to offer as many of the features we offer today for swarm, tomorrow for Kubernetes.</p>
<p>We have a lot of work to do though, and this means that most of our developers are focused on this Kubernetes activity. That said, we have assigned developers to keep working through the backlog of Swarm / standalone issues, starting with the most “in demand” and working down from there. We are also continuing to add functionality to our “serverless” options (Azure ACI support), and plan to keep building out our edge compute management functionality too.</p>
<p>In the diagram below (click to enlarge), we have tried to depict where we are focusing our development efforts over the coming 6 months.</p>
<p><a href="https://pronto-core-cdn.prontomarketing.com/354/wp-content/uploads/sites/2/2020/06/dev_timelines.png"><img data-attachment-id="5341" data-permalink="https://www.portainer.io/2020/06/portainer-2-0-and-the-development-balancing-act/dev_timelines/#main" data-orig-file="https://pronto-core-cdn.prontomarketing.com/354/wp-content/uploads/sites/2/2020/06/dev_timelines.png" data-orig-size="5398,3084" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="dev_timelines" data-image-description="" data-medium-file="https://pronto-core-cdn.prontomarketing.com/354/wp-content/uploads/sites/2/cache/2020/06/dev_timelines/1715794396.png" data-large-file="https://pronto-core-cdn.prontomarketing.com/354/wp-content/uploads/sites/2/cache/2020/06/dev_timelines/786456166.png" src="https://pronto-core-cdn.prontomarketing.com/354/wp-content/uploads/sites/2/2020/06/dev_timelines-1.png" alt="" width="740" height="423"></a>Thats all for now.... we have product to build....</p>
<p>Neil</p>
	</div></div>]]>
            </description>
            <link>https://www.portainer.io/2020/06/portainer-2-0-and-the-development-balancing-act/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23608687</guid>
            <pubDate>Tue, 23 Jun 2020 00:33:10 GMT</pubDate>
        </item>
    </channel>
</rss>
